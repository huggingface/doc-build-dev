import{S as ekt,i as okt,s as rkt,e as a,k as l,w as F,t as o,M as tkt,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as akt,L as I}from"../../chunks/vendor-hf-doc-builder.js";import{T as pXr}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as re}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function nkt(L){let g,v,p,m,_,d,h,Mo,mi,_f,rt,gi,hi,yA,uf,je,We,pi,yn,LA,Ln,xn,xA,_i,$n,$A,ui,bf,Ca;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),_=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Mo=o(`, make sure its
`),mi=a("code"),_f=o("model_type"),rt=o(" attribute is set to the same key you use when registering the config (here "),gi=a("code"),hi=o('"new-model"'),yA=o(")."),uf=l(),je=a("p"),We=o("Likewise, if your "),pi=a("code"),yn=o("NewModel"),LA=o(" is a subclass of "),Ln=a("a"),xn=o("PreTrainedModel"),xA=o(`, make sure its
`),_i=a("code"),$n=o("config_class"),$A=o(` attribute is set to the same class you use when registering the model (here
`),ui=a("code"),bf=o("NewModelConfig"),Ca=o(")."),this.h()},l(Qe){g=n(Qe,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var J$=s(p);m=r(J$,"NewModelConfig"),J$.forEach(t),_=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var bi=s(d);h=r(bi,"PretrainedConfig"),bi.forEach(t),Mo=r(Ae,`, make sure its
`),mi=n(Ae,"CODE",{});var Y$=s(mi);_f=r(Y$,"model_type"),Y$.forEach(t),rt=r(Ae," attribute is set to the same key you use when registering the config (here "),gi=n(Ae,"CODE",{});var K$=s(gi);hi=r(K$,'"new-model"'),K$.forEach(t),yA=r(Ae,")."),Ae.forEach(t),uf=i(Qe),je=n(Qe,"P",{});var Eo=s(je);We=r(Eo,"Likewise, if your "),pi=n(Eo,"CODE",{});var wa=s(pi);yn=r(wa,"NewModel"),wa.forEach(t),LA=r(Eo," is a subclass of "),Ln=n(Eo,"A",{href:!0});var Z$=s(Ln);xn=r(Z$,"PreTrainedModel"),Z$.forEach(t),xA=r(Eo,`, make sure its
`),_i=n(Eo,"CODE",{});var vf=s(_i);$n=r(vf,"config_class"),vf.forEach(t),$A=r(Eo,` attribute is set to the same class you use when registering the model (here
`),ui=n(Eo,"CODE",{});var ek=s(ui);bf=r(ek,"NewModelConfig"),ek.forEach(t),Ca=r(Eo,")."),Eo.forEach(t),this.h()},h(){c(Ln,"href","/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel")},m(Qe,Ae){b(Qe,g,Ae),e(g,v),e(g,p),e(p,m),e(g,_),e(g,d),e(d,h),e(g,Mo),e(g,mi),e(mi,_f),e(g,rt),e(g,gi),e(gi,hi),e(g,yA),b(Qe,uf,Ae),b(Qe,je,Ae),e(je,We),e(je,pi),e(pi,yn),e(je,LA),e(je,Ln),e(Ln,xn),e(je,xA),e(je,_i),e(_i,$n),e(je,$A),e(je,ui),e(ui,bf),e(je,Ca)},d(Qe){Qe&&t(g),Qe&&t(uf),Qe&&t(je)}}}function skt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

config.unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config.unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ikt(L){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Mo=s(p);m=r(Mo,"use_auth_token=True"),Mo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function dkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ckt(L){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Mo=s(p);m=r(Mo,"use_auth_token=True"),Mo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function fkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _kt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ukt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Fkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Tkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Mkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ekt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ckt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Akt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ykt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Lkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $kt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Skt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Rkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Pkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Bkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ikt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Nkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Dkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Gkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Okt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Vkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Xkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Wkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Qkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Hkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ukt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Jkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ykt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Kkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Zkt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _St(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ESt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ASt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ySt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $St(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ISt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function OSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function USt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZSt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oRt(L){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rRt(L){let g,v,p,m,_,d,h,Mo,mi,_f,rt,gi,hi,yA,uf,je,We,pi,yn,LA,Ln,xn,xA,_i,$n,$A,ui,bf,Ca,Qe,Ae,J$,bi,Y$,K$,Eo,wa,Z$,vf,ek,AOe,pqe,vi,Ff,_oe,kA,yOe,uoe,LOe,_qe,kn,xOe,boe,$Oe,kOe,voe,SOe,ROe,uqe,SA,bqe,ok,POe,vqe,Tf,Fqe,Fi,Mf,Foe,RA,BOe,Toe,IOe,Tqe,Co,PA,NOe,BA,qOe,rk,jOe,DOe,GOe,IA,OOe,Moe,VOe,XOe,zOe,Er,NA,WOe,Eoe,QOe,HOe,Ti,UOe,Coe,JOe,YOe,woe,KOe,ZOe,eVe,A,Ef,Aoe,oVe,rVe,tk,tVe,aVe,nVe,Cf,yoe,sVe,lVe,ak,iVe,dVe,cVe,wf,Loe,fVe,mVe,nk,gVe,hVe,pVe,Af,xoe,_Ve,uVe,sk,bVe,vVe,FVe,yf,$oe,TVe,MVe,lk,EVe,CVe,wVe,Lf,koe,AVe,yVe,ik,LVe,xVe,$Ve,xf,Soe,kVe,SVe,dk,RVe,PVe,BVe,$f,Roe,IVe,NVe,ck,qVe,jVe,DVe,kf,Poe,GVe,OVe,fk,VVe,XVe,zVe,Sf,Boe,WVe,QVe,mk,HVe,UVe,JVe,Rf,Ioe,YVe,KVe,gk,ZVe,eXe,oXe,Pf,Noe,rXe,tXe,hk,aXe,nXe,sXe,Bf,qoe,lXe,iXe,pk,dXe,cXe,fXe,If,joe,mXe,gXe,_k,hXe,pXe,_Xe,Nf,Doe,uXe,bXe,uk,vXe,FXe,TXe,qf,Goe,MXe,EXe,bk,CXe,wXe,AXe,jf,Ooe,yXe,LXe,vk,xXe,$Xe,kXe,Df,Voe,SXe,RXe,Fk,PXe,BXe,IXe,Gf,Xoe,NXe,qXe,Tk,jXe,DXe,GXe,Of,zoe,OXe,VXe,Mk,XXe,zXe,WXe,Vf,Woe,QXe,HXe,Ek,UXe,JXe,YXe,Xf,Qoe,KXe,ZXe,Ck,eze,oze,rze,zf,Hoe,tze,aze,wk,nze,sze,lze,Wf,Uoe,ize,dze,Ak,cze,fze,mze,Qf,Joe,gze,hze,yk,pze,_ze,uze,Hf,Yoe,bze,vze,Lk,Fze,Tze,Mze,Uf,Koe,Eze,Cze,xk,wze,Aze,yze,Jf,Zoe,Lze,xze,$k,$ze,kze,Sze,Yf,ere,Rze,Pze,kk,Bze,Ize,Nze,Kf,ore,qze,jze,Sk,Dze,Gze,Oze,Zf,rre,Vze,Xze,Rk,zze,Wze,Qze,em,tre,Hze,Uze,Pk,Jze,Yze,Kze,om,are,Zze,eWe,Bk,oWe,rWe,tWe,rm,nre,aWe,nWe,Ik,sWe,lWe,iWe,tm,sre,dWe,cWe,Nk,fWe,mWe,gWe,am,lre,hWe,pWe,qk,_We,uWe,bWe,nm,ire,vWe,FWe,jk,TWe,MWe,EWe,sm,dre,CWe,wWe,Dk,AWe,yWe,LWe,lm,cre,xWe,$We,Gk,kWe,SWe,RWe,im,fre,PWe,BWe,Ok,IWe,NWe,qWe,dm,mre,jWe,DWe,Vk,GWe,OWe,VWe,cm,gre,XWe,zWe,Xk,WWe,QWe,HWe,fm,hre,UWe,JWe,zk,YWe,KWe,ZWe,mm,pre,eQe,oQe,Wk,rQe,tQe,aQe,gm,_re,nQe,sQe,Qk,lQe,iQe,dQe,hm,ure,cQe,fQe,Hk,mQe,gQe,hQe,pm,bre,pQe,_Qe,Uk,uQe,bQe,vQe,_m,vre,FQe,TQe,Jk,MQe,EQe,CQe,um,Fre,wQe,AQe,Yk,yQe,LQe,xQe,bm,Tre,$Qe,kQe,Kk,SQe,RQe,PQe,vm,Mre,BQe,IQe,Zk,NQe,qQe,jQe,Fm,Ere,DQe,GQe,eS,OQe,VQe,XQe,Tm,Cre,zQe,WQe,oS,QQe,HQe,UQe,Mm,wre,JQe,YQe,rS,KQe,ZQe,eHe,Em,Are,oHe,rHe,tS,tHe,aHe,nHe,Cm,yre,sHe,lHe,aS,iHe,dHe,cHe,wm,Lre,fHe,mHe,nS,gHe,hHe,pHe,Am,xre,_He,uHe,sS,bHe,vHe,FHe,ym,$re,THe,MHe,lS,EHe,CHe,wHe,Lm,kre,AHe,yHe,iS,LHe,xHe,$He,xm,Sre,kHe,SHe,dS,RHe,PHe,BHe,$m,Rre,IHe,NHe,cS,qHe,jHe,DHe,km,Pre,GHe,OHe,fS,VHe,XHe,zHe,Sm,Bre,WHe,QHe,mS,HHe,UHe,JHe,Rm,Ire,YHe,KHe,gS,ZHe,eUe,oUe,Pm,Nre,rUe,tUe,hS,aUe,nUe,sUe,Bm,qre,lUe,iUe,pS,dUe,cUe,fUe,Im,jre,mUe,gUe,_S,hUe,pUe,_Ue,Nm,Dre,uUe,bUe,uS,vUe,FUe,TUe,qm,Gre,MUe,EUe,bS,CUe,wUe,AUe,jm,Ore,yUe,LUe,vS,xUe,$Ue,kUe,Dm,Vre,SUe,RUe,FS,PUe,BUe,IUe,Gm,Xre,NUe,qUe,TS,jUe,DUe,GUe,Om,zre,OUe,VUe,MS,XUe,zUe,WUe,Vm,Wre,QUe,HUe,ES,UUe,JUe,YUe,Xm,Qre,KUe,ZUe,CS,eJe,oJe,rJe,zm,Hre,tJe,aJe,wS,nJe,sJe,lJe,Wm,Ure,iJe,dJe,AS,cJe,fJe,mJe,Qm,Jre,gJe,hJe,yS,pJe,_Je,uJe,Hm,Yre,bJe,vJe,LS,FJe,TJe,MJe,Um,Kre,EJe,CJe,xS,wJe,AJe,yJe,Jm,Zre,LJe,xJe,$S,$Je,kJe,SJe,Ym,ete,RJe,PJe,kS,BJe,IJe,NJe,Km,ote,qJe,jJe,SS,DJe,GJe,OJe,Zm,rte,VJe,XJe,RS,zJe,WJe,QJe,eg,tte,HJe,UJe,PS,JJe,YJe,KJe,og,ate,ZJe,eYe,BS,oYe,rYe,tYe,rg,nte,aYe,nYe,IS,sYe,lYe,iYe,tg,ste,dYe,cYe,NS,fYe,mYe,gYe,ag,lte,hYe,pYe,qS,_Ye,uYe,bYe,ng,ite,vYe,FYe,jS,TYe,MYe,EYe,sg,dte,CYe,wYe,DS,AYe,yYe,LYe,lg,cte,xYe,$Ye,GS,kYe,SYe,RYe,ig,fte,PYe,BYe,OS,IYe,NYe,qYe,dg,mte,jYe,DYe,VS,GYe,OYe,VYe,cg,gte,XYe,zYe,XS,WYe,QYe,HYe,fg,hte,UYe,JYe,zS,YYe,KYe,ZYe,mg,pte,eKe,oKe,WS,rKe,tKe,aKe,gg,_te,nKe,sKe,QS,lKe,iKe,dKe,hg,ute,cKe,fKe,HS,mKe,gKe,hKe,pg,bte,pKe,_Ke,US,uKe,bKe,vKe,_g,vte,FKe,TKe,JS,MKe,EKe,CKe,ug,Fte,wKe,AKe,YS,yKe,LKe,xKe,bg,Tte,$Ke,kKe,KS,SKe,RKe,PKe,vg,Mte,BKe,IKe,ZS,NKe,qKe,jKe,Fg,Ete,DKe,GKe,eR,OKe,VKe,XKe,Tg,Cte,zKe,WKe,oR,QKe,HKe,UKe,Mg,wte,JKe,YKe,rR,KKe,ZKe,eZe,Eg,Ate,oZe,rZe,tR,tZe,aZe,nZe,Cg,yte,sZe,lZe,aR,iZe,dZe,cZe,wg,fZe,Ag,qA,mZe,Lte,gZe,Mqe,Mi,yg,xte,jA,hZe,$te,pZe,Eqe,wo,DA,_Ze,GA,uZe,nR,bZe,vZe,FZe,OA,TZe,kte,MZe,EZe,CZe,Cr,VA,wZe,Ste,AZe,yZe,Aa,LZe,Rte,xZe,$Ze,Pte,kZe,SZe,Bte,RZe,PZe,BZe,k,Sn,Ite,IZe,NZe,sR,qZe,jZe,lR,DZe,GZe,OZe,Rn,Nte,VZe,XZe,iR,zZe,WZe,dR,QZe,HZe,UZe,Pn,qte,JZe,YZe,cR,KZe,ZZe,fR,eeo,oeo,reo,Lg,jte,teo,aeo,mR,neo,seo,leo,Bn,Dte,ieo,deo,gR,ceo,feo,hR,meo,geo,heo,xg,Gte,peo,_eo,pR,ueo,beo,veo,$g,Ote,Feo,Teo,_R,Meo,Eeo,Ceo,kg,Vte,weo,Aeo,uR,yeo,Leo,xeo,In,Xte,$eo,keo,bR,Seo,Reo,vR,Peo,Beo,Ieo,Nn,zte,Neo,qeo,FR,jeo,Deo,TR,Geo,Oeo,Veo,qn,Wte,Xeo,zeo,MR,Weo,Qeo,ER,Heo,Ueo,Jeo,Sg,Qte,Yeo,Keo,CR,Zeo,eoo,ooo,Rg,Hte,roo,too,wR,aoo,noo,soo,jn,Ute,loo,ioo,AR,doo,coo,yR,foo,moo,goo,Pg,Jte,hoo,poo,LR,_oo,uoo,boo,Dn,Yte,voo,Foo,xR,Too,Moo,$R,Eoo,Coo,woo,Gn,Kte,Aoo,yoo,kR,Loo,xoo,SR,$oo,koo,Soo,On,Zte,Roo,Poo,RR,Boo,Ioo,PR,Noo,qoo,joo,Bg,eae,Doo,Goo,BR,Ooo,Voo,Xoo,Vn,oae,zoo,Woo,IR,Qoo,Hoo,NR,Uoo,Joo,Yoo,Xn,rae,Koo,Zoo,qR,ero,oro,jR,rro,tro,aro,zn,tae,nro,sro,DR,lro,iro,GR,dro,cro,fro,Wn,aae,mro,gro,OR,hro,pro,VR,_ro,uro,bro,Qn,nae,vro,Fro,XR,Tro,Mro,zR,Ero,Cro,wro,Hn,sae,Aro,yro,WR,Lro,xro,QR,$ro,kro,Sro,Ig,lae,Rro,Pro,HR,Bro,Iro,Nro,Un,iae,qro,jro,UR,Dro,Gro,JR,Oro,Vro,Xro,Ng,dae,zro,Wro,YR,Qro,Hro,Uro,Jn,cae,Jro,Yro,KR,Kro,Zro,ZR,eto,oto,rto,Yn,fae,tto,ato,eP,nto,sto,oP,lto,ito,dto,Kn,mae,cto,fto,rP,mto,gto,tP,hto,pto,_to,qg,gae,uto,bto,aP,vto,Fto,Tto,Zn,hae,Mto,Eto,nP,Cto,wto,sP,Ato,yto,Lto,es,pae,xto,$to,lP,kto,Sto,iP,Rto,Pto,Bto,jg,_ae,Ito,Nto,dP,qto,jto,Dto,os,uae,Gto,Oto,cP,Vto,Xto,fP,zto,Wto,Qto,rs,bae,Hto,Uto,mP,Jto,Yto,gP,Kto,Zto,eao,ts,vae,oao,rao,hP,tao,aao,pP,nao,sao,lao,as,Fae,iao,dao,_P,cao,fao,uP,mao,gao,hao,ns,Tae,pao,_ao,bP,uao,bao,vP,vao,Fao,Tao,ss,Mae,Mao,Eao,FP,Cao,wao,TP,Aao,yao,Lao,ls,Eae,xao,$ao,MP,kao,Sao,EP,Rao,Pao,Bao,Dg,Cae,Iao,Nao,CP,qao,jao,Dao,is,wae,Gao,Oao,wP,Vao,Xao,AP,zao,Wao,Qao,Gg,Aae,Hao,Uao,yP,Jao,Yao,Kao,Og,yae,Zao,eno,LP,ono,rno,tno,ds,Lae,ano,nno,xP,sno,lno,$P,ino,dno,cno,cs,xae,fno,mno,kP,gno,hno,SP,pno,_no,uno,fs,$ae,bno,vno,RP,Fno,Tno,PP,Mno,Eno,Cno,Vg,kae,wno,Ano,BP,yno,Lno,xno,ms,Sae,$no,kno,IP,Sno,Rno,NP,Pno,Bno,Ino,gs,Rae,Nno,qno,qP,jno,Dno,jP,Gno,Ono,Vno,hs,Pae,Xno,zno,DP,Wno,Qno,GP,Hno,Uno,Jno,ps,Bae,Yno,Kno,OP,Zno,eso,VP,oso,rso,tso,_s,Iae,aso,nso,XP,sso,lso,zP,iso,dso,cso,Xg,Nae,fso,mso,WP,gso,hso,pso,us,qae,_so,uso,QP,bso,vso,HP,Fso,Tso,Mso,zg,jae,Eso,Cso,UP,wso,Aso,yso,Wg,Dae,Lso,xso,JP,$so,kso,Sso,Qg,Gae,Rso,Pso,YP,Bso,Iso,Nso,Hg,Oae,qso,jso,KP,Dso,Gso,Oso,bs,Vae,Vso,Xso,ZP,zso,Wso,eB,Qso,Hso,Uso,Ug,Xae,Jso,Yso,oB,Kso,Zso,elo,vs,zae,olo,rlo,rB,tlo,alo,tB,nlo,slo,llo,Fs,Wae,ilo,dlo,aB,clo,flo,nB,mlo,glo,hlo,Ts,Qae,plo,_lo,sB,ulo,blo,lB,vlo,Flo,Tlo,Ms,Hae,Mlo,Elo,iB,Clo,wlo,dB,Alo,ylo,Llo,Es,Uae,xlo,$lo,cB,klo,Slo,fB,Rlo,Plo,Blo,Cs,Jae,Ilo,Nlo,mB,qlo,jlo,gB,Dlo,Glo,Olo,Jg,Yae,Vlo,Xlo,hB,zlo,Wlo,Qlo,Yg,Kae,Hlo,Ulo,pB,Jlo,Ylo,Klo,ws,Zae,Zlo,eio,_B,oio,rio,uB,tio,aio,nio,As,ene,sio,lio,bB,iio,dio,vB,cio,fio,mio,ys,one,gio,hio,FB,pio,_io,TB,uio,bio,vio,Kg,rne,Fio,Tio,MB,Mio,Eio,Cio,Zg,tne,wio,Aio,EB,yio,Lio,xio,eh,ane,$io,kio,CB,Sio,Rio,Pio,Ls,nne,Bio,Iio,wB,Nio,qio,AB,jio,Dio,Gio,oh,sne,Oio,Vio,yB,Xio,zio,Wio,rh,lne,Qio,Hio,LB,Uio,Jio,Yio,th,ine,Kio,Zio,xB,edo,odo,rdo,xs,dne,tdo,ado,$B,ndo,sdo,kB,ldo,ido,ddo,ah,cne,cdo,fdo,SB,mdo,gdo,hdo,nh,fne,pdo,_do,RB,udo,bdo,vdo,$s,mne,Fdo,Tdo,PB,Mdo,Edo,BB,Cdo,wdo,Ado,ks,gne,ydo,Ldo,IB,xdo,$do,NB,kdo,Sdo,Rdo,Ss,hne,Pdo,Bdo,qB,Ido,Ndo,jB,qdo,jdo,Ddo,Rs,pne,Gdo,Odo,DB,Vdo,Xdo,GB,zdo,Wdo,Qdo,sh,Hdo,lh,XA,Udo,_ne,Jdo,Cqe,Ei,ih,une,zA,Ydo,bne,Kdo,wqe,Ao,WA,Zdo,QA,eco,OB,oco,rco,tco,HA,aco,vne,nco,sco,lco,He,UA,ico,Fne,dco,cco,ya,fco,Tne,mco,gco,Mne,hco,pco,Ene,_co,uco,bco,Y,dh,Cne,vco,Fco,VB,Tco,Mco,Eco,ch,wne,Cco,wco,XB,Aco,yco,Lco,fh,Ane,xco,$co,zB,kco,Sco,Rco,mh,yne,Pco,Bco,WB,Ico,Nco,qco,gh,Lne,jco,Dco,QB,Gco,Oco,Vco,hh,xne,Xco,zco,HB,Wco,Qco,Hco,ph,$ne,Uco,Jco,UB,Yco,Kco,Zco,_h,kne,efo,ofo,JB,rfo,tfo,afo,uh,Sne,nfo,sfo,YB,lfo,ifo,dfo,bh,Rne,cfo,ffo,KB,mfo,gfo,hfo,vh,Pne,pfo,_fo,ZB,ufo,bfo,vfo,Fh,Bne,Ffo,Tfo,eI,Mfo,Efo,Cfo,Th,Ine,wfo,Afo,oI,yfo,Lfo,xfo,Mh,Nne,$fo,kfo,rI,Sfo,Rfo,Pfo,Eh,qne,Bfo,Ifo,tI,Nfo,qfo,jfo,Ch,jne,Dfo,Gfo,aI,Ofo,Vfo,Xfo,wh,Dne,zfo,Wfo,nI,Qfo,Hfo,Ufo,Ah,Gne,Jfo,Yfo,sI,Kfo,Zfo,emo,yh,One,omo,rmo,lI,tmo,amo,nmo,Lh,Vne,smo,lmo,iI,imo,dmo,cmo,xh,Xne,fmo,mmo,dI,gmo,hmo,pmo,$h,zne,_mo,umo,cI,bmo,vmo,Fmo,kh,Wne,Tmo,Mmo,fI,Emo,Cmo,wmo,Sh,Qne,Amo,ymo,mI,Lmo,xmo,$mo,Rh,Hne,kmo,Smo,gI,Rmo,Pmo,Bmo,Ph,Une,Imo,Nmo,hI,qmo,jmo,Dmo,Bh,Jne,Gmo,Omo,pI,Vmo,Xmo,zmo,Ih,Yne,Wmo,Qmo,_I,Hmo,Umo,Jmo,Nh,Kne,Ymo,Kmo,uI,Zmo,ego,ogo,qh,Zne,rgo,tgo,bI,ago,ngo,sgo,jh,lgo,Dh,igo,Gh,JA,dgo,ese,cgo,Aqe,Ci,Oh,ose,YA,fgo,rse,mgo,yqe,yo,KA,ggo,ZA,hgo,vI,pgo,_go,ugo,ey,bgo,tse,vgo,Fgo,Tgo,Ue,oy,Mgo,ase,Ego,Cgo,wi,wgo,nse,Ago,ygo,sse,Lgo,xgo,$go,he,Vh,lse,kgo,Sgo,FI,Rgo,Pgo,Bgo,Xh,ise,Igo,Ngo,dse,qgo,jgo,Dgo,zh,cse,Ggo,Ogo,TI,Vgo,Xgo,zgo,Wh,fse,Wgo,Qgo,MI,Hgo,Ugo,Jgo,Qh,mse,Ygo,Kgo,EI,Zgo,eho,oho,Hh,gse,rho,tho,CI,aho,nho,sho,Uh,hse,lho,iho,wI,dho,cho,fho,Jh,pse,mho,gho,AI,hho,pho,_ho,Yh,_se,uho,bho,yI,vho,Fho,Tho,Kh,use,Mho,Eho,LI,Cho,who,Aho,Zh,bse,yho,Lho,xI,xho,$ho,kho,ep,vse,Sho,Rho,$I,Pho,Bho,Iho,op,Fse,Nho,qho,kI,jho,Dho,Gho,rp,Tse,Oho,Vho,SI,Xho,zho,Who,tp,Mse,Qho,Hho,RI,Uho,Jho,Yho,ap,Ese,Kho,Zho,PI,epo,opo,rpo,np,Cse,tpo,apo,BI,npo,spo,lpo,sp,ipo,lp,dpo,ip,ry,cpo,wse,fpo,Lqe,Ai,dp,Ase,ty,mpo,yse,gpo,xqe,Lo,ay,hpo,yi,ppo,II,_po,upo,NI,bpo,vpo,Fpo,ny,Tpo,Lse,Mpo,Epo,Cpo,tt,sy,wpo,xse,Apo,ypo,Li,Lpo,$se,xpo,$po,qI,kpo,Spo,Rpo,cp,Ppo,Je,ly,Bpo,kse,Ipo,Npo,La,qpo,Sse,jpo,Dpo,Rse,Gpo,Opo,Pse,Vpo,Xpo,zpo,x,fp,Bse,Wpo,Qpo,jI,Hpo,Upo,Jpo,mp,Ise,Ypo,Kpo,DI,Zpo,e_o,o_o,gp,Nse,r_o,t_o,GI,a_o,n_o,s_o,hp,qse,l_o,i_o,OI,d_o,c_o,f_o,pp,jse,m_o,g_o,VI,h_o,p_o,__o,_p,Dse,u_o,b_o,XI,v_o,F_o,T_o,up,Gse,M_o,E_o,zI,C_o,w_o,A_o,bp,Ose,y_o,L_o,WI,x_o,$_o,k_o,vp,Vse,S_o,R_o,QI,P_o,B_o,I_o,Fp,Xse,N_o,q_o,HI,j_o,D_o,G_o,Tp,zse,O_o,V_o,UI,X_o,z_o,W_o,Mp,Wse,Q_o,H_o,JI,U_o,J_o,Y_o,Ep,Qse,K_o,Z_o,YI,euo,ouo,ruo,Cp,Hse,tuo,auo,KI,nuo,suo,luo,wp,Use,iuo,duo,ZI,cuo,fuo,muo,Ap,Jse,guo,huo,eN,puo,_uo,uuo,yp,Yse,buo,vuo,oN,Fuo,Tuo,Muo,Lp,Kse,Euo,Cuo,rN,wuo,Auo,yuo,xp,Zse,Luo,xuo,tN,$uo,kuo,Suo,$p,ele,Ruo,Puo,aN,Buo,Iuo,Nuo,kp,ole,quo,juo,nN,Duo,Guo,Ouo,Sp,rle,Vuo,Xuo,sN,zuo,Wuo,Quo,Rp,tle,Huo,Uuo,lN,Juo,Yuo,Kuo,Pp,ale,Zuo,e6o,iN,o6o,r6o,t6o,Bp,nle,a6o,n6o,dN,s6o,l6o,i6o,Ip,sle,d6o,c6o,cN,f6o,m6o,g6o,Np,lle,h6o,p6o,fN,_6o,u6o,b6o,qp,ile,v6o,F6o,mN,T6o,M6o,E6o,jp,dle,C6o,w6o,gN,A6o,y6o,L6o,Dp,cle,x6o,$6o,hN,k6o,S6o,R6o,Gp,fle,P6o,B6o,pN,I6o,N6o,q6o,Op,mle,j6o,D6o,_N,G6o,O6o,V6o,Ps,gle,X6o,z6o,uN,W6o,Q6o,bN,H6o,U6o,J6o,Vp,hle,Y6o,K6o,vN,Z6o,e1o,o1o,Xp,ple,r1o,t1o,FN,a1o,n1o,s1o,zp,_le,l1o,i1o,TN,d1o,c1o,f1o,Wp,ule,m1o,g1o,MN,h1o,p1o,_1o,Qp,ble,u1o,b1o,EN,v1o,F1o,T1o,Hp,vle,M1o,E1o,CN,C1o,w1o,A1o,Up,Fle,y1o,L1o,wN,x1o,$1o,k1o,Jp,Tle,S1o,R1o,AN,P1o,B1o,I1o,Yp,Mle,N1o,q1o,yN,j1o,D1o,G1o,Kp,Ele,O1o,V1o,LN,X1o,z1o,W1o,Zp,Cle,Q1o,H1o,xN,U1o,J1o,Y1o,e_,wle,K1o,Z1o,$N,ebo,obo,rbo,o_,Ale,tbo,abo,kN,nbo,sbo,lbo,r_,yle,ibo,dbo,SN,cbo,fbo,mbo,t_,Lle,gbo,hbo,RN,pbo,_bo,ubo,a_,xle,bbo,vbo,PN,Fbo,Tbo,Mbo,n_,$le,Ebo,Cbo,BN,wbo,Abo,ybo,s_,kle,Lbo,xbo,IN,$bo,kbo,Sbo,l_,Sle,Rbo,Pbo,NN,Bbo,Ibo,Nbo,i_,Rle,qbo,jbo,qN,Dbo,Gbo,Obo,d_,Ple,Vbo,Xbo,jN,zbo,Wbo,Qbo,c_,Ble,Hbo,Ubo,DN,Jbo,Ybo,Kbo,f_,Ile,Zbo,e2o,GN,o2o,r2o,t2o,m_,Nle,a2o,n2o,ON,s2o,l2o,i2o,g_,qle,d2o,c2o,VN,f2o,m2o,g2o,h_,jle,h2o,p2o,XN,_2o,u2o,b2o,p_,Dle,v2o,F2o,zN,T2o,M2o,E2o,__,Gle,C2o,w2o,WN,A2o,y2o,L2o,u_,Ole,x2o,$2o,QN,k2o,S2o,R2o,b_,Vle,P2o,B2o,HN,I2o,N2o,q2o,v_,Xle,j2o,D2o,UN,G2o,O2o,V2o,F_,zle,X2o,z2o,JN,W2o,Q2o,H2o,T_,Wle,U2o,J2o,YN,Y2o,K2o,Z2o,M_,Qle,e4o,o4o,KN,r4o,t4o,a4o,E_,Hle,n4o,s4o,ZN,l4o,i4o,d4o,C_,Ule,c4o,f4o,eq,m4o,g4o,h4o,w_,Jle,p4o,_4o,oq,u4o,b4o,v4o,A_,Yle,F4o,T4o,rq,M4o,E4o,C4o,y_,Kle,w4o,A4o,tq,y4o,L4o,x4o,L_,Zle,$4o,k4o,aq,S4o,R4o,P4o,x_,eie,B4o,I4o,nq,N4o,q4o,j4o,$_,oie,D4o,G4o,sq,O4o,V4o,X4o,k_,rie,z4o,W4o,lq,Q4o,H4o,U4o,S_,tie,J4o,Y4o,iq,K4o,Z4o,evo,R_,aie,ovo,rvo,dq,tvo,avo,nvo,P_,nie,svo,lvo,cq,ivo,dvo,cvo,B_,sie,fvo,mvo,fq,gvo,hvo,pvo,I_,lie,_vo,uvo,mq,bvo,vvo,Fvo,N_,iie,Tvo,Mvo,gq,Evo,Cvo,wvo,q_,die,Avo,yvo,hq,Lvo,xvo,$vo,j_,cie,kvo,Svo,pq,Rvo,Pvo,Bvo,D_,fie,Ivo,Nvo,_q,qvo,jvo,Dvo,G_,mie,Gvo,Ovo,uq,Vvo,Xvo,zvo,O_,gie,Wvo,Qvo,bq,Hvo,Uvo,Jvo,V_,hie,Yvo,Kvo,vq,Zvo,eFo,oFo,X_,pie,rFo,tFo,Fq,aFo,nFo,sFo,z_,_ie,lFo,iFo,Tq,dFo,cFo,fFo,W_,uie,mFo,gFo,Mq,hFo,pFo,_Fo,Q_,bie,uFo,bFo,Eq,vFo,FFo,TFo,H_,vie,MFo,EFo,Cq,CFo,wFo,AFo,U_,Fie,yFo,LFo,wq,xFo,$Fo,kFo,J_,Tie,SFo,RFo,Aq,PFo,BFo,IFo,Y_,Mie,NFo,qFo,yq,jFo,DFo,GFo,K_,Eie,OFo,VFo,Lq,XFo,zFo,WFo,Z_,Cie,QFo,HFo,xq,UFo,JFo,YFo,eu,wie,KFo,ZFo,$q,eTo,oTo,rTo,ou,Aie,tTo,aTo,kq,nTo,sTo,lTo,ru,yie,iTo,dTo,Sq,cTo,fTo,mTo,tu,Lie,gTo,hTo,Rq,pTo,_To,uTo,au,xie,bTo,vTo,Pq,FTo,TTo,MTo,nu,ETo,$ie,CTo,wTo,kie,ATo,yTo,su,$qe,xi,lu,Sie,iy,LTo,Rie,xTo,kqe,xo,dy,$To,$i,kTo,Bq,STo,RTo,Iq,PTo,BTo,ITo,cy,NTo,Pie,qTo,jTo,DTo,at,fy,GTo,Bie,OTo,VTo,ki,XTo,Iie,zTo,WTo,Nq,QTo,HTo,UTo,iu,JTo,Ye,my,YTo,Nie,KTo,ZTo,xa,e7o,qie,o7o,r7o,jie,t7o,a7o,Die,n7o,s7o,l7o,G,du,Gie,i7o,d7o,qq,c7o,f7o,m7o,cu,Oie,g7o,h7o,jq,p7o,_7o,u7o,fu,Vie,b7o,v7o,Dq,F7o,T7o,M7o,mu,Xie,E7o,C7o,Gq,w7o,A7o,y7o,gu,zie,L7o,x7o,Oq,$7o,k7o,S7o,hu,Wie,R7o,P7o,Vq,B7o,I7o,N7o,pu,Qie,q7o,j7o,Xq,D7o,G7o,O7o,_u,Hie,V7o,X7o,zq,z7o,W7o,Q7o,uu,Uie,H7o,U7o,Wq,J7o,Y7o,K7o,bu,Jie,Z7o,eMo,Qq,oMo,rMo,tMo,vu,Yie,aMo,nMo,Hq,sMo,lMo,iMo,Fu,Kie,dMo,cMo,Uq,fMo,mMo,gMo,Tu,Zie,hMo,pMo,Jq,_Mo,uMo,bMo,Mu,ede,vMo,FMo,Yq,TMo,MMo,EMo,Eu,ode,CMo,wMo,Kq,AMo,yMo,LMo,Cu,rde,xMo,$Mo,Zq,kMo,SMo,RMo,wu,tde,PMo,BMo,ej,IMo,NMo,qMo,Au,ade,jMo,DMo,oj,GMo,OMo,VMo,yu,nde,XMo,zMo,rj,WMo,QMo,HMo,Lu,sde,UMo,JMo,tj,YMo,KMo,ZMo,xu,lde,eEo,oEo,aj,rEo,tEo,aEo,$u,ide,nEo,sEo,nj,lEo,iEo,dEo,ku,dde,cEo,fEo,sj,mEo,gEo,hEo,Su,cde,pEo,_Eo,lj,uEo,bEo,vEo,Ru,fde,FEo,TEo,ij,MEo,EEo,CEo,Pu,mde,wEo,AEo,dj,yEo,LEo,xEo,Bu,gde,$Eo,kEo,cj,SEo,REo,PEo,Iu,hde,BEo,IEo,fj,NEo,qEo,jEo,Nu,pde,DEo,GEo,mj,OEo,VEo,XEo,qu,_de,zEo,WEo,gj,QEo,HEo,UEo,ju,ude,JEo,YEo,hj,KEo,ZEo,eCo,Du,bde,oCo,rCo,pj,tCo,aCo,nCo,Gu,vde,sCo,lCo,_j,iCo,dCo,cCo,Ou,Fde,fCo,mCo,uj,gCo,hCo,pCo,Vu,Tde,_Co,uCo,bj,bCo,vCo,FCo,Xu,Mde,TCo,MCo,vj,ECo,CCo,wCo,zu,Ede,ACo,yCo,Fj,LCo,xCo,$Co,Wu,Cde,kCo,SCo,Tj,RCo,PCo,BCo,Qu,wde,ICo,NCo,Mj,qCo,jCo,DCo,Hu,Ade,GCo,OCo,Ej,VCo,XCo,zCo,Uu,yde,WCo,QCo,Cj,HCo,UCo,JCo,Ju,Lde,YCo,KCo,wj,ZCo,e5o,o5o,Yu,r5o,xde,t5o,a5o,$de,n5o,s5o,Ku,Sqe,Si,Zu,kde,gy,l5o,Sde,i5o,Rqe,$o,hy,d5o,Ri,c5o,Aj,f5o,m5o,yj,g5o,h5o,p5o,py,_5o,Rde,u5o,b5o,v5o,nt,_y,F5o,Pde,T5o,M5o,Pi,E5o,Bde,C5o,w5o,Lj,A5o,y5o,L5o,e6,x5o,Ke,uy,$5o,Ide,k5o,S5o,$a,R5o,Nde,P5o,B5o,qde,I5o,N5o,jde,q5o,j5o,D5o,z,o6,Dde,G5o,O5o,xj,V5o,X5o,z5o,r6,Gde,W5o,Q5o,$j,H5o,U5o,J5o,t6,Ode,Y5o,K5o,kj,Z5o,e3o,o3o,a6,Vde,r3o,t3o,Sj,a3o,n3o,s3o,n6,Xde,l3o,i3o,Rj,d3o,c3o,f3o,s6,zde,m3o,g3o,Pj,h3o,p3o,_3o,l6,Wde,u3o,b3o,Bj,v3o,F3o,T3o,i6,Qde,M3o,E3o,Ij,C3o,w3o,A3o,d6,Hde,y3o,L3o,Nj,x3o,$3o,k3o,c6,Ude,S3o,R3o,qj,P3o,B3o,I3o,f6,Jde,N3o,q3o,jj,j3o,D3o,G3o,m6,Yde,O3o,V3o,Dj,X3o,z3o,W3o,g6,Kde,Q3o,H3o,Gj,U3o,J3o,Y3o,h6,Zde,K3o,Z3o,Oj,ewo,owo,rwo,p6,ece,two,awo,Vj,nwo,swo,lwo,_6,oce,iwo,dwo,Xj,cwo,fwo,mwo,u6,rce,gwo,hwo,zj,pwo,_wo,uwo,b6,tce,bwo,vwo,Wj,Fwo,Two,Mwo,v6,ace,Ewo,Cwo,Qj,wwo,Awo,ywo,F6,nce,Lwo,xwo,Hj,$wo,kwo,Swo,T6,sce,Rwo,Pwo,Uj,Bwo,Iwo,Nwo,M6,lce,qwo,jwo,Jj,Dwo,Gwo,Owo,E6,ice,Vwo,Xwo,Yj,zwo,Wwo,Qwo,C6,dce,Hwo,Uwo,Kj,Jwo,Ywo,Kwo,w6,cce,Zwo,e0o,Zj,o0o,r0o,t0o,A6,fce,a0o,n0o,eD,s0o,l0o,i0o,y6,mce,d0o,c0o,oD,f0o,m0o,g0o,L6,gce,h0o,p0o,rD,_0o,u0o,b0o,x6,hce,v0o,F0o,tD,T0o,M0o,E0o,$6,pce,C0o,w0o,aD,A0o,y0o,L0o,k6,_ce,x0o,$0o,nD,k0o,S0o,R0o,S6,uce,P0o,B0o,sD,I0o,N0o,q0o,R6,bce,j0o,D0o,lD,G0o,O0o,V0o,P6,vce,X0o,z0o,iD,W0o,Q0o,H0o,B6,Fce,U0o,J0o,dD,Y0o,K0o,Z0o,I6,Tce,eAo,oAo,cD,rAo,tAo,aAo,N6,Mce,nAo,sAo,fD,lAo,iAo,dAo,q6,cAo,Ece,fAo,mAo,Cce,gAo,hAo,j6,Pqe,Bi,D6,wce,by,pAo,Ace,_Ao,Bqe,ko,vy,uAo,Ii,bAo,mD,vAo,FAo,gD,TAo,MAo,EAo,Fy,CAo,yce,wAo,AAo,yAo,st,Ty,LAo,Lce,xAo,$Ao,Ni,kAo,xce,SAo,RAo,hD,PAo,BAo,IAo,G6,NAo,Ze,My,qAo,$ce,jAo,DAo,ka,GAo,kce,OAo,VAo,Sce,XAo,zAo,Rce,WAo,QAo,HAo,Q,O6,Pce,UAo,JAo,pD,YAo,KAo,ZAo,V6,Bce,eyo,oyo,_D,ryo,tyo,ayo,X6,Ice,nyo,syo,uD,lyo,iyo,dyo,z6,Nce,cyo,fyo,bD,myo,gyo,hyo,W6,qce,pyo,_yo,vD,uyo,byo,vyo,Q6,jce,Fyo,Tyo,FD,Myo,Eyo,Cyo,H6,Dce,wyo,Ayo,TD,yyo,Lyo,xyo,U6,Gce,$yo,kyo,MD,Syo,Ryo,Pyo,J6,Oce,Byo,Iyo,ED,Nyo,qyo,jyo,Y6,Vce,Dyo,Gyo,CD,Oyo,Vyo,Xyo,K6,Xce,zyo,Wyo,wD,Qyo,Hyo,Uyo,Z6,zce,Jyo,Yyo,AD,Kyo,Zyo,eLo,e1,Wce,oLo,rLo,yD,tLo,aLo,nLo,o1,Qce,sLo,lLo,LD,iLo,dLo,cLo,r1,Hce,fLo,mLo,xD,gLo,hLo,pLo,t1,Uce,_Lo,uLo,$D,bLo,vLo,FLo,a1,Jce,TLo,MLo,kD,ELo,CLo,wLo,n1,Yce,ALo,yLo,SD,LLo,xLo,$Lo,s1,Kce,kLo,SLo,RD,RLo,PLo,BLo,l1,Zce,ILo,NLo,PD,qLo,jLo,DLo,i1,efe,GLo,OLo,BD,VLo,XLo,zLo,d1,ofe,WLo,QLo,ID,HLo,ULo,JLo,c1,rfe,YLo,KLo,ND,ZLo,e8o,o8o,f1,tfe,r8o,t8o,qD,a8o,n8o,s8o,m1,afe,l8o,i8o,jD,d8o,c8o,f8o,g1,nfe,m8o,g8o,DD,h8o,p8o,_8o,h1,sfe,u8o,b8o,GD,v8o,F8o,T8o,p1,lfe,M8o,E8o,OD,C8o,w8o,A8o,_1,ife,y8o,L8o,VD,x8o,$8o,k8o,u1,dfe,S8o,R8o,XD,P8o,B8o,I8o,b1,cfe,N8o,q8o,ffe,j8o,D8o,G8o,v1,mfe,O8o,V8o,zD,X8o,z8o,W8o,F1,gfe,Q8o,H8o,WD,U8o,J8o,Y8o,T1,hfe,K8o,Z8o,QD,e9o,o9o,r9o,M1,pfe,t9o,a9o,HD,n9o,s9o,l9o,E1,i9o,_fe,d9o,c9o,ufe,f9o,m9o,C1,Iqe,qi,w1,bfe,Ey,g9o,vfe,h9o,Nqe,So,Cy,p9o,ji,_9o,UD,u9o,b9o,JD,v9o,F9o,T9o,wy,M9o,Ffe,E9o,C9o,w9o,lt,Ay,A9o,Tfe,y9o,L9o,Di,x9o,Mfe,$9o,k9o,YD,S9o,R9o,P9o,A1,B9o,eo,yy,I9o,Efe,N9o,q9o,Sa,j9o,Cfe,D9o,G9o,wfe,O9o,V9o,Afe,X9o,z9o,W9o,_e,y1,yfe,Q9o,H9o,KD,U9o,J9o,Y9o,L1,Lfe,K9o,Z9o,ZD,exo,oxo,rxo,x1,xfe,txo,axo,eG,nxo,sxo,lxo,$1,$fe,ixo,dxo,oG,cxo,fxo,mxo,k1,kfe,gxo,hxo,rG,pxo,_xo,uxo,S1,Sfe,bxo,vxo,tG,Fxo,Txo,Mxo,R1,Rfe,Exo,Cxo,aG,wxo,Axo,yxo,P1,Pfe,Lxo,xxo,nG,$xo,kxo,Sxo,B1,Bfe,Rxo,Pxo,sG,Bxo,Ixo,Nxo,I1,Ife,qxo,jxo,lG,Dxo,Gxo,Oxo,N1,Nfe,Vxo,Xxo,iG,zxo,Wxo,Qxo,q1,qfe,Hxo,Uxo,dG,Jxo,Yxo,Kxo,j1,jfe,Zxo,e$o,cG,o$o,r$o,t$o,D1,Dfe,a$o,n$o,fG,s$o,l$o,i$o,G1,Gfe,d$o,c$o,mG,f$o,m$o,g$o,O1,Ofe,h$o,p$o,gG,_$o,u$o,b$o,V1,v$o,Vfe,F$o,T$o,Xfe,M$o,E$o,X1,qqe,Gi,z1,zfe,Ly,C$o,Wfe,w$o,jqe,Ro,xy,A$o,Oi,y$o,hG,L$o,x$o,pG,$$o,k$o,S$o,$y,R$o,Qfe,P$o,B$o,I$o,it,ky,N$o,Hfe,q$o,j$o,Vi,D$o,Ufe,G$o,O$o,_G,V$o,X$o,z$o,W1,W$o,oo,Sy,Q$o,Jfe,H$o,U$o,Ra,J$o,Yfe,Y$o,K$o,Kfe,Z$o,eko,Zfe,oko,rko,tko,N,Q1,eme,ako,nko,uG,sko,lko,iko,H1,ome,dko,cko,bG,fko,mko,gko,U1,rme,hko,pko,vG,_ko,uko,bko,J1,tme,vko,Fko,FG,Tko,Mko,Eko,Y1,ame,Cko,wko,TG,Ako,yko,Lko,K1,nme,xko,$ko,MG,kko,Sko,Rko,Z1,sme,Pko,Bko,EG,Iko,Nko,qko,eb,lme,jko,Dko,CG,Gko,Oko,Vko,ob,ime,Xko,zko,wG,Wko,Qko,Hko,rb,dme,Uko,Jko,AG,Yko,Kko,Zko,tb,cme,eSo,oSo,yG,rSo,tSo,aSo,ab,fme,nSo,sSo,LG,lSo,iSo,dSo,nb,mme,cSo,fSo,xG,mSo,gSo,hSo,sb,gme,pSo,_So,$G,uSo,bSo,vSo,lb,hme,FSo,TSo,kG,MSo,ESo,CSo,ib,pme,wSo,ASo,SG,ySo,LSo,xSo,db,_me,$So,kSo,RG,SSo,RSo,PSo,cb,ume,BSo,ISo,PG,NSo,qSo,jSo,fb,bme,DSo,GSo,BG,OSo,VSo,XSo,mb,vme,zSo,WSo,IG,QSo,HSo,USo,gb,Fme,JSo,YSo,NG,KSo,ZSo,eRo,hb,Tme,oRo,rRo,qG,tRo,aRo,nRo,pb,Mme,sRo,lRo,jG,iRo,dRo,cRo,_b,Eme,fRo,mRo,DG,gRo,hRo,pRo,ub,Cme,_Ro,uRo,GG,bRo,vRo,FRo,bb,wme,TRo,MRo,OG,ERo,CRo,wRo,vb,Ame,ARo,yRo,VG,LRo,xRo,$Ro,Fb,yme,kRo,SRo,XG,RRo,PRo,BRo,Tb,Lme,IRo,NRo,zG,qRo,jRo,DRo,Mb,xme,GRo,ORo,WG,VRo,XRo,zRo,Eb,$me,WRo,QRo,QG,HRo,URo,JRo,Cb,kme,YRo,KRo,HG,ZRo,ePo,oPo,wb,Sme,rPo,tPo,UG,aPo,nPo,sPo,Ab,Rme,lPo,iPo,JG,dPo,cPo,fPo,yb,Pme,mPo,gPo,YG,hPo,pPo,_Po,Lb,Bme,uPo,bPo,KG,vPo,FPo,TPo,xb,Ime,MPo,EPo,ZG,CPo,wPo,APo,$b,Nme,yPo,LPo,eO,xPo,$Po,kPo,kb,qme,SPo,RPo,oO,PPo,BPo,IPo,Sb,jme,NPo,qPo,rO,jPo,DPo,GPo,Rb,Dme,OPo,VPo,tO,XPo,zPo,WPo,Pb,Gme,QPo,HPo,aO,UPo,JPo,YPo,Bb,Ome,KPo,ZPo,nO,eBo,oBo,rBo,Ib,Vme,tBo,aBo,sO,nBo,sBo,lBo,Nb,Xme,iBo,dBo,lO,cBo,fBo,mBo,qb,zme,gBo,hBo,iO,pBo,_Bo,uBo,jb,Wme,bBo,vBo,dO,FBo,TBo,MBo,Db,EBo,Qme,CBo,wBo,Hme,ABo,yBo,Gb,Dqe,Xi,Ob,Ume,Ry,LBo,Jme,xBo,Gqe,Po,Py,$Bo,zi,kBo,cO,SBo,RBo,fO,PBo,BBo,IBo,By,NBo,Yme,qBo,jBo,DBo,dt,Iy,GBo,Kme,OBo,VBo,Wi,XBo,Zme,zBo,WBo,mO,QBo,HBo,UBo,Vb,JBo,ro,Ny,YBo,ege,KBo,ZBo,Pa,eIo,oge,oIo,rIo,rge,tIo,aIo,tge,nIo,sIo,lIo,K,Xb,age,iIo,dIo,gO,cIo,fIo,mIo,zb,nge,gIo,hIo,hO,pIo,_Io,uIo,Wb,sge,bIo,vIo,pO,FIo,TIo,MIo,Qb,lge,EIo,CIo,_O,wIo,AIo,yIo,Hb,ige,LIo,xIo,uO,$Io,kIo,SIo,Ub,dge,RIo,PIo,bO,BIo,IIo,NIo,Jb,cge,qIo,jIo,vO,DIo,GIo,OIo,Yb,fge,VIo,XIo,FO,zIo,WIo,QIo,Kb,mge,HIo,UIo,TO,JIo,YIo,KIo,Zb,gge,ZIo,eNo,MO,oNo,rNo,tNo,e2,hge,aNo,nNo,EO,sNo,lNo,iNo,o2,pge,dNo,cNo,CO,fNo,mNo,gNo,r2,_ge,hNo,pNo,wO,_No,uNo,bNo,t2,uge,vNo,FNo,AO,TNo,MNo,ENo,a2,bge,CNo,wNo,yO,ANo,yNo,LNo,n2,vge,xNo,$No,LO,kNo,SNo,RNo,s2,Fge,PNo,BNo,xO,INo,NNo,qNo,l2,Tge,jNo,DNo,$O,GNo,ONo,VNo,i2,Mge,XNo,zNo,kO,WNo,QNo,HNo,d2,Ege,UNo,JNo,SO,YNo,KNo,ZNo,c2,Cge,eqo,oqo,RO,rqo,tqo,aqo,f2,wge,nqo,sqo,PO,lqo,iqo,dqo,m2,Age,cqo,fqo,BO,mqo,gqo,hqo,g2,yge,pqo,_qo,IO,uqo,bqo,vqo,h2,Lge,Fqo,Tqo,NO,Mqo,Eqo,Cqo,p2,xge,wqo,Aqo,qO,yqo,Lqo,xqo,_2,$ge,$qo,kqo,jO,Sqo,Rqo,Pqo,u2,kge,Bqo,Iqo,DO,Nqo,qqo,jqo,b2,Sge,Dqo,Gqo,GO,Oqo,Vqo,Xqo,v2,zqo,Rge,Wqo,Qqo,Pge,Hqo,Uqo,F2,Oqe,Qi,T2,Bge,qy,Jqo,Ige,Yqo,Vqe,Bo,jy,Kqo,Hi,Zqo,OO,ejo,ojo,VO,rjo,tjo,ajo,Dy,njo,Nge,sjo,ljo,ijo,ct,Gy,djo,qge,cjo,fjo,Ui,mjo,jge,gjo,hjo,XO,pjo,_jo,ujo,M2,bjo,to,Oy,vjo,Dge,Fjo,Tjo,Ba,Mjo,Gge,Ejo,Cjo,Oge,wjo,Ajo,Vge,yjo,Ljo,xjo,Yr,E2,Xge,$jo,kjo,zO,Sjo,Rjo,Pjo,C2,zge,Bjo,Ijo,WO,Njo,qjo,jjo,w2,Wge,Djo,Gjo,QO,Ojo,Vjo,Xjo,A2,Qge,zjo,Wjo,HO,Qjo,Hjo,Ujo,y2,Hge,Jjo,Yjo,UO,Kjo,Zjo,eDo,L2,oDo,Uge,rDo,tDo,Jge,aDo,nDo,x2,Xqe,Ji,$2,Yge,Vy,sDo,Kge,lDo,zqe,Io,Xy,iDo,Yi,dDo,JO,cDo,fDo,YO,mDo,gDo,hDo,zy,pDo,Zge,_Do,uDo,bDo,ft,Wy,vDo,ehe,FDo,TDo,Ki,MDo,ohe,EDo,CDo,KO,wDo,ADo,yDo,k2,LDo,ao,Qy,xDo,rhe,$Do,kDo,Ia,SDo,the,RDo,PDo,ahe,BDo,IDo,nhe,NDo,qDo,jDo,H,S2,she,DDo,GDo,ZO,ODo,VDo,XDo,R2,lhe,zDo,WDo,eV,QDo,HDo,UDo,P2,ihe,JDo,YDo,oV,KDo,ZDo,eGo,B2,dhe,oGo,rGo,rV,tGo,aGo,nGo,I2,che,sGo,lGo,tV,iGo,dGo,cGo,N2,fhe,fGo,mGo,aV,gGo,hGo,pGo,q2,mhe,_Go,uGo,nV,bGo,vGo,FGo,j2,ghe,TGo,MGo,sV,EGo,CGo,wGo,D2,hhe,AGo,yGo,lV,LGo,xGo,$Go,G2,phe,kGo,SGo,iV,RGo,PGo,BGo,O2,_he,IGo,NGo,dV,qGo,jGo,DGo,V2,uhe,GGo,OGo,cV,VGo,XGo,zGo,X2,bhe,WGo,QGo,fV,HGo,UGo,JGo,z2,vhe,YGo,KGo,mV,ZGo,eOo,oOo,W2,Fhe,rOo,tOo,gV,aOo,nOo,sOo,Q2,The,lOo,iOo,hV,dOo,cOo,fOo,H2,Mhe,mOo,gOo,pV,hOo,pOo,_Oo,U2,Ehe,uOo,bOo,_V,vOo,FOo,TOo,J2,Che,MOo,EOo,uV,COo,wOo,AOo,Y2,whe,yOo,LOo,bV,xOo,$Oo,kOo,K2,Ahe,SOo,ROo,vV,POo,BOo,IOo,Z2,yhe,NOo,qOo,FV,jOo,DOo,GOo,e4,Lhe,OOo,VOo,TV,XOo,zOo,WOo,o4,xhe,QOo,HOo,MV,UOo,JOo,YOo,r4,$he,KOo,ZOo,EV,eVo,oVo,rVo,t4,khe,tVo,aVo,CV,nVo,sVo,lVo,a4,She,iVo,dVo,wV,cVo,fVo,mVo,n4,Rhe,gVo,hVo,AV,pVo,_Vo,uVo,s4,Phe,bVo,vVo,yV,FVo,TVo,MVo,l4,Bhe,EVo,CVo,LV,wVo,AVo,yVo,i4,Ihe,LVo,xVo,xV,$Vo,kVo,SVo,d4,Nhe,RVo,PVo,$V,BVo,IVo,NVo,c4,qhe,qVo,jVo,kV,DVo,GVo,OVo,f4,jhe,VVo,XVo,SV,zVo,WVo,QVo,m4,HVo,Dhe,UVo,JVo,Ghe,YVo,KVo,g4,Wqe,Zi,h4,Ohe,Hy,ZVo,Vhe,eXo,Qqe,No,Uy,oXo,ed,rXo,RV,tXo,aXo,PV,nXo,sXo,lXo,Jy,iXo,Xhe,dXo,cXo,fXo,mt,Yy,mXo,zhe,gXo,hXo,od,pXo,Whe,_Xo,uXo,BV,bXo,vXo,FXo,p4,TXo,no,Ky,MXo,Qhe,EXo,CXo,Na,wXo,Hhe,AXo,yXo,Uhe,LXo,xXo,Jhe,$Xo,kXo,SXo,V,_4,Yhe,RXo,PXo,IV,BXo,IXo,NXo,u4,Khe,qXo,jXo,NV,DXo,GXo,OXo,b4,Zhe,VXo,XXo,qV,zXo,WXo,QXo,v4,epe,HXo,UXo,jV,JXo,YXo,KXo,F4,ope,ZXo,ezo,DV,ozo,rzo,tzo,T4,rpe,azo,nzo,GV,szo,lzo,izo,M4,tpe,dzo,czo,OV,fzo,mzo,gzo,E4,ape,hzo,pzo,VV,_zo,uzo,bzo,C4,npe,vzo,Fzo,XV,Tzo,Mzo,Ezo,w4,spe,Czo,wzo,zV,Azo,yzo,Lzo,A4,lpe,xzo,$zo,WV,kzo,Szo,Rzo,y4,ipe,Pzo,Bzo,QV,Izo,Nzo,qzo,L4,dpe,jzo,Dzo,HV,Gzo,Ozo,Vzo,x4,cpe,Xzo,zzo,UV,Wzo,Qzo,Hzo,$4,fpe,Uzo,Jzo,JV,Yzo,Kzo,Zzo,k4,mpe,eWo,oWo,YV,rWo,tWo,aWo,S4,gpe,nWo,sWo,KV,lWo,iWo,dWo,R4,hpe,cWo,fWo,ZV,mWo,gWo,hWo,P4,ppe,pWo,_Wo,eX,uWo,bWo,vWo,B4,_pe,FWo,TWo,oX,MWo,EWo,CWo,I4,upe,wWo,AWo,rX,yWo,LWo,xWo,N4,bpe,$Wo,kWo,tX,SWo,RWo,PWo,q4,vpe,BWo,IWo,aX,NWo,qWo,jWo,j4,Fpe,DWo,GWo,nX,OWo,VWo,XWo,D4,Tpe,zWo,WWo,sX,QWo,HWo,UWo,G4,Mpe,JWo,YWo,lX,KWo,ZWo,eQo,O4,Epe,oQo,rQo,iX,tQo,aQo,nQo,V4,Cpe,sQo,lQo,dX,iQo,dQo,cQo,X4,wpe,fQo,mQo,cX,gQo,hQo,pQo,z4,Ape,_Qo,uQo,fX,bQo,vQo,FQo,W4,ype,TQo,MQo,mX,EQo,CQo,wQo,Q4,Lpe,AQo,yQo,gX,LQo,xQo,$Qo,H4,xpe,kQo,SQo,hX,RQo,PQo,BQo,U4,$pe,IQo,NQo,pX,qQo,jQo,DQo,J4,kpe,GQo,OQo,_X,VQo,XQo,zQo,Y4,Spe,WQo,QQo,uX,HQo,UQo,JQo,K4,Rpe,YQo,KQo,bX,ZQo,eHo,oHo,Z4,Ppe,rHo,tHo,vX,aHo,nHo,sHo,ev,Bpe,lHo,iHo,FX,dHo,cHo,fHo,ov,Ipe,mHo,gHo,TX,hHo,pHo,_Ho,rv,uHo,Npe,bHo,vHo,qpe,FHo,THo,tv,Hqe,rd,av,jpe,Zy,MHo,Dpe,EHo,Uqe,qo,eL,CHo,td,wHo,MX,AHo,yHo,EX,LHo,xHo,$Ho,oL,kHo,Gpe,SHo,RHo,PHo,gt,rL,BHo,Ope,IHo,NHo,ad,qHo,Vpe,jHo,DHo,CX,GHo,OHo,VHo,nv,XHo,so,tL,zHo,Xpe,WHo,QHo,qa,HHo,zpe,UHo,JHo,Wpe,YHo,KHo,Qpe,ZHo,eUo,oUo,Hpe,sv,Upe,rUo,tUo,wX,aUo,nUo,sUo,lv,lUo,Jpe,iUo,dUo,Ype,cUo,fUo,iv,Jqe,nd,dv,Kpe,aL,mUo,Zpe,gUo,Yqe,jo,nL,hUo,sd,pUo,AX,_Uo,uUo,yX,bUo,vUo,FUo,sL,TUo,e_e,MUo,EUo,CUo,ht,lL,wUo,o_e,AUo,yUo,ld,LUo,r_e,xUo,$Uo,LX,kUo,SUo,RUo,cv,PUo,lo,iL,BUo,t_e,IUo,NUo,ja,qUo,a_e,jUo,DUo,n_e,GUo,OUo,s_e,VUo,XUo,zUo,ve,fv,l_e,WUo,QUo,xX,HUo,UUo,JUo,mv,i_e,YUo,KUo,$X,ZUo,eJo,oJo,gv,d_e,rJo,tJo,kX,aJo,nJo,sJo,hv,c_e,lJo,iJo,SX,dJo,cJo,fJo,Bs,f_e,mJo,gJo,RX,hJo,pJo,PX,_Jo,uJo,bJo,pv,m_e,vJo,FJo,BX,TJo,MJo,EJo,Is,g_e,CJo,wJo,IX,AJo,yJo,NX,LJo,xJo,$Jo,pt,h_e,kJo,SJo,qX,RJo,PJo,jX,BJo,IJo,DX,NJo,qJo,jJo,_v,p_e,DJo,GJo,GX,OJo,VJo,XJo,uv,__e,zJo,WJo,OX,QJo,HJo,UJo,bv,u_e,JJo,YJo,VX,KJo,ZJo,eYo,vv,b_e,oYo,rYo,XX,tYo,aYo,nYo,Fv,v_e,sYo,lYo,zX,iYo,dYo,cYo,Tv,F_e,fYo,mYo,WX,gYo,hYo,pYo,Mv,T_e,_Yo,uYo,QX,bYo,vYo,FYo,Ev,TYo,M_e,MYo,EYo,E_e,CYo,wYo,Cv,Kqe,id,wv,C_e,dL,AYo,w_e,yYo,Zqe,Do,cL,LYo,dd,xYo,HX,$Yo,kYo,UX,SYo,RYo,PYo,fL,BYo,A_e,IYo,NYo,qYo,_t,mL,jYo,y_e,DYo,GYo,cd,OYo,L_e,VYo,XYo,JX,zYo,WYo,QYo,Av,HYo,io,gL,UYo,x_e,JYo,YYo,Da,KYo,$_e,ZYo,eKo,k_e,oKo,rKo,S_e,tKo,aKo,nKo,R_e,yv,P_e,sKo,lKo,YX,iKo,dKo,cKo,Lv,fKo,B_e,mKo,gKo,I_e,hKo,pKo,xv,eje,fd,$v,N_e,hL,_Ko,q_e,uKo,oje,Go,pL,bKo,md,vKo,KX,FKo,TKo,ZX,MKo,EKo,CKo,_L,wKo,j_e,AKo,yKo,LKo,ut,uL,xKo,D_e,$Ko,kKo,gd,SKo,G_e,RKo,PKo,ez,BKo,IKo,NKo,kv,qKo,co,bL,jKo,O_e,DKo,GKo,Ga,OKo,V_e,VKo,XKo,X_e,zKo,WKo,z_e,QKo,HKo,UKo,ke,Sv,W_e,JKo,YKo,oz,KKo,ZKo,eZo,Rv,Q_e,oZo,rZo,rz,tZo,aZo,nZo,Pv,H_e,sZo,lZo,tz,iZo,dZo,cZo,Bv,U_e,fZo,mZo,az,gZo,hZo,pZo,Iv,J_e,_Zo,uZo,nz,bZo,vZo,FZo,Nv,Y_e,TZo,MZo,sz,EZo,CZo,wZo,qv,K_e,AZo,yZo,lz,LZo,xZo,$Zo,jv,Z_e,kZo,SZo,iz,RZo,PZo,BZo,Dv,eue,IZo,NZo,dz,qZo,jZo,DZo,Gv,GZo,oue,OZo,VZo,rue,XZo,zZo,Ov,rje,hd,Vv,tue,vL,WZo,aue,QZo,tje,Oo,FL,HZo,pd,UZo,cz,JZo,YZo,fz,KZo,ZZo,eer,TL,oer,nue,rer,ter,aer,bt,ML,ner,sue,ser,ler,_d,ier,lue,der,cer,mz,fer,mer,ger,Xv,her,fo,EL,per,iue,_er,uer,Oa,ber,due,ver,Fer,cue,Ter,Mer,fue,Eer,Cer,wer,Kr,zv,mue,Aer,yer,gz,Ler,xer,$er,Wv,gue,ker,Ser,hz,Rer,Per,Ber,Qv,hue,Ier,Ner,pz,qer,jer,Der,Hv,pue,Ger,Oer,_z,Ver,Xer,zer,Uv,_ue,Wer,Qer,uz,Her,Uer,Jer,Jv,Yer,uue,Ker,Zer,bue,eor,oor,Yv,aje,ud,Kv,vue,CL,ror,Fue,tor,nje,Vo,wL,aor,bd,nor,bz,sor,lor,vz,ior,dor,cor,AL,mor,Tue,gor,hor,por,vt,yL,_or,Mue,uor,bor,vd,vor,Eue,For,Tor,Fz,Mor,Eor,Cor,Zv,wor,mo,LL,Aor,Cue,yor,Lor,Va,xor,wue,$or,kor,Aue,Sor,Ror,yue,Por,Bor,Ior,Se,eF,Lue,Nor,qor,Tz,jor,Dor,Gor,oF,xue,Oor,Vor,Mz,Xor,zor,Wor,rF,$ue,Qor,Hor,Ez,Uor,Jor,Yor,tF,kue,Kor,Zor,Cz,err,orr,rrr,aF,Sue,trr,arr,wz,nrr,srr,lrr,nF,Rue,irr,drr,Az,crr,frr,mrr,sF,Pue,grr,hrr,yz,prr,_rr,urr,lF,Bue,brr,vrr,Lz,Frr,Trr,Mrr,iF,Iue,Err,Crr,xz,wrr,Arr,yrr,dF,Lrr,Nue,xrr,$rr,que,krr,Srr,cF,sje,Fd,fF,jue,xL,Rrr,Due,Prr,lje,Xo,$L,Brr,Td,Irr,$z,Nrr,qrr,kz,jrr,Drr,Grr,kL,Orr,Gue,Vrr,Xrr,zrr,Ft,SL,Wrr,Oue,Qrr,Hrr,Md,Urr,Vue,Jrr,Yrr,Sz,Krr,Zrr,etr,mF,otr,go,RL,rtr,Xue,ttr,atr,Xa,ntr,zue,str,ltr,Wue,itr,dtr,Que,ctr,ftr,mtr,PL,gF,Hue,gtr,htr,Rz,ptr,_tr,utr,hF,Uue,btr,vtr,Pz,Ftr,Ttr,Mtr,pF,Etr,Jue,Ctr,wtr,Yue,Atr,ytr,_F,ije,Ed,uF,Kue,BL,Ltr,Zue,xtr,dje,zo,IL,$tr,Cd,ktr,Bz,Str,Rtr,Iz,Ptr,Btr,Itr,NL,Ntr,e6e,qtr,jtr,Dtr,Tt,qL,Gtr,o6e,Otr,Vtr,wd,Xtr,r6e,ztr,Wtr,Nz,Qtr,Htr,Utr,bF,Jtr,ho,jL,Ytr,t6e,Ktr,Ztr,za,ear,a6e,oar,rar,n6e,tar,aar,s6e,nar,sar,lar,Zr,vF,l6e,iar,dar,qz,car,far,mar,FF,i6e,gar,har,jz,par,_ar,uar,TF,d6e,bar,Far,Dz,Tar,Mar,Ear,MF,c6e,Car,war,Gz,Aar,yar,Lar,EF,f6e,xar,$ar,Oz,kar,Sar,Rar,CF,Par,m6e,Bar,Iar,g6e,Nar,qar,wF,cje,Ad,AF,h6e,DL,jar,p6e,Dar,fje,Wo,GL,Gar,yd,Oar,Vz,Var,Xar,Xz,zar,War,Qar,OL,Har,_6e,Uar,Jar,Yar,Mt,VL,Kar,u6e,Zar,enr,Ld,onr,b6e,rnr,tnr,zz,anr,nnr,snr,yF,lnr,po,XL,inr,v6e,dnr,cnr,Wa,fnr,F6e,mnr,gnr,T6e,hnr,pnr,M6e,_nr,unr,bnr,xd,LF,E6e,vnr,Fnr,Wz,Tnr,Mnr,Enr,xF,C6e,Cnr,wnr,Qz,Anr,ynr,Lnr,$F,w6e,xnr,$nr,Hz,knr,Snr,Rnr,kF,Pnr,A6e,Bnr,Inr,y6e,Nnr,qnr,SF,mje,$d,RF,L6e,zL,jnr,x6e,Dnr,gje,Qo,WL,Gnr,kd,Onr,Uz,Vnr,Xnr,Jz,znr,Wnr,Qnr,QL,Hnr,$6e,Unr,Jnr,Ynr,Et,HL,Knr,k6e,Znr,esr,Sd,osr,S6e,rsr,tsr,Yz,asr,nsr,ssr,PF,lsr,_o,UL,isr,R6e,dsr,csr,Qa,fsr,P6e,msr,gsr,B6e,hsr,psr,I6e,_sr,usr,bsr,JL,BF,N6e,vsr,Fsr,Kz,Tsr,Msr,Esr,IF,q6e,Csr,wsr,Zz,Asr,ysr,Lsr,NF,xsr,j6e,$sr,ksr,D6e,Ssr,Rsr,qF,hje,Rd,jF,G6e,YL,Psr,O6e,Bsr,pje,Ho,KL,Isr,Pd,Nsr,eW,qsr,jsr,oW,Dsr,Gsr,Osr,ZL,Vsr,V6e,Xsr,zsr,Wsr,Ct,e8,Qsr,X6e,Hsr,Usr,Bd,Jsr,z6e,Ysr,Ksr,rW,Zsr,elr,olr,DF,rlr,uo,o8,tlr,W6e,alr,nlr,Ha,slr,Q6e,llr,ilr,H6e,dlr,clr,U6e,flr,mlr,glr,J6e,GF,Y6e,hlr,plr,tW,_lr,ulr,blr,OF,vlr,K6e,Flr,Tlr,Z6e,Mlr,Elr,VF,_je,Id,XF,e1e,r8,Clr,o1e,wlr,uje,Uo,t8,Alr,Nd,ylr,aW,Llr,xlr,nW,$lr,klr,Slr,a8,Rlr,r1e,Plr,Blr,Ilr,wt,n8,Nlr,t1e,qlr,jlr,qd,Dlr,a1e,Glr,Olr,sW,Vlr,Xlr,zlr,zF,Wlr,bo,s8,Qlr,n1e,Hlr,Ulr,Ua,Jlr,s1e,Ylr,Klr,l1e,Zlr,eir,i1e,oir,rir,tir,Ja,WF,d1e,air,nir,lW,sir,lir,iir,QF,c1e,dir,cir,iW,fir,mir,gir,HF,f1e,hir,pir,dW,_ir,uir,bir,UF,m1e,vir,Fir,cW,Tir,Mir,Eir,JF,Cir,g1e,wir,Air,h1e,yir,Lir,YF,bje,jd,KF,p1e,l8,xir,_1e,$ir,vje,Jo,i8,kir,Dd,Sir,fW,Rir,Pir,mW,Bir,Iir,Nir,d8,qir,u1e,jir,Dir,Gir,At,c8,Oir,b1e,Vir,Xir,Gd,zir,v1e,Wir,Qir,gW,Hir,Uir,Jir,ZF,Yir,vo,f8,Kir,F1e,Zir,edr,Ya,odr,T1e,rdr,tdr,M1e,adr,ndr,E1e,sdr,ldr,idr,C1e,eT,w1e,ddr,cdr,hW,fdr,mdr,gdr,oT,hdr,A1e,pdr,_dr,y1e,udr,bdr,rT,Fje,Od,tT,L1e,m8,vdr,x1e,Fdr,Tje,Yo,g8,Tdr,Vd,Mdr,pW,Edr,Cdr,_W,wdr,Adr,ydr,h8,Ldr,$1e,xdr,$dr,kdr,yt,p8,Sdr,k1e,Rdr,Pdr,Xd,Bdr,S1e,Idr,Ndr,uW,qdr,jdr,Ddr,aT,Gdr,wr,_8,Odr,R1e,Vdr,Xdr,Ka,zdr,P1e,Wdr,Qdr,B1e,Hdr,Udr,I1e,Jdr,Ydr,Kdr,q,nT,N1e,Zdr,ecr,bW,ocr,rcr,tcr,sT,q1e,acr,ncr,vW,scr,lcr,icr,lT,j1e,dcr,ccr,FW,fcr,mcr,gcr,iT,D1e,hcr,pcr,TW,_cr,ucr,bcr,dT,G1e,vcr,Fcr,MW,Tcr,Mcr,Ecr,cT,O1e,Ccr,wcr,EW,Acr,ycr,Lcr,fT,V1e,xcr,$cr,CW,kcr,Scr,Rcr,mT,X1e,Pcr,Bcr,wW,Icr,Ncr,qcr,gT,z1e,jcr,Dcr,AW,Gcr,Ocr,Vcr,hT,W1e,Xcr,zcr,yW,Wcr,Qcr,Hcr,pT,Q1e,Ucr,Jcr,LW,Ycr,Kcr,Zcr,_T,H1e,efr,ofr,xW,rfr,tfr,afr,uT,U1e,nfr,sfr,$W,lfr,ifr,dfr,bT,J1e,cfr,ffr,kW,mfr,gfr,hfr,vT,Y1e,pfr,_fr,SW,ufr,bfr,vfr,FT,K1e,Ffr,Tfr,RW,Mfr,Efr,Cfr,TT,Z1e,wfr,Afr,PW,yfr,Lfr,xfr,Ns,ebe,$fr,kfr,BW,Sfr,Rfr,IW,Pfr,Bfr,Ifr,MT,obe,Nfr,qfr,NW,jfr,Dfr,Gfr,ET,rbe,Ofr,Vfr,qW,Xfr,zfr,Wfr,CT,tbe,Qfr,Hfr,jW,Ufr,Jfr,Yfr,wT,abe,Kfr,Zfr,DW,emr,omr,rmr,AT,nbe,tmr,amr,GW,nmr,smr,lmr,yT,sbe,imr,dmr,OW,cmr,fmr,mmr,LT,lbe,gmr,hmr,VW,pmr,_mr,umr,xT,ibe,bmr,vmr,XW,Fmr,Tmr,Mmr,$T,dbe,Emr,Cmr,zW,wmr,Amr,ymr,kT,cbe,Lmr,xmr,WW,$mr,kmr,Smr,ST,fbe,Rmr,Pmr,QW,Bmr,Imr,Nmr,RT,mbe,qmr,jmr,HW,Dmr,Gmr,Omr,PT,gbe,Vmr,Xmr,UW,zmr,Wmr,Qmr,BT,hbe,Hmr,Umr,JW,Jmr,Ymr,Kmr,IT,pbe,Zmr,egr,YW,ogr,rgr,tgr,NT,_be,agr,ngr,KW,sgr,lgr,igr,qT,ube,dgr,cgr,ZW,fgr,mgr,ggr,jT,bbe,hgr,pgr,eQ,_gr,ugr,bgr,DT,vbe,vgr,Fgr,oQ,Tgr,Mgr,Egr,GT,Fbe,Cgr,wgr,rQ,Agr,ygr,Lgr,OT,Tbe,xgr,$gr,tQ,kgr,Sgr,Rgr,VT,Mbe,Pgr,Bgr,aQ,Igr,Ngr,qgr,XT,Ebe,jgr,Dgr,nQ,Ggr,Ogr,Vgr,zT,Cbe,Xgr,zgr,sQ,Wgr,Qgr,Hgr,WT,wbe,Ugr,Jgr,lQ,Ygr,Kgr,Zgr,QT,Abe,ehr,ohr,iQ,rhr,thr,ahr,HT,ybe,nhr,shr,dQ,lhr,ihr,dhr,UT,Lbe,chr,fhr,cQ,mhr,ghr,hhr,JT,Mje,zd,YT,xbe,u8,phr,$be,_hr,Eje,Ko,b8,uhr,Wd,bhr,fQ,vhr,Fhr,mQ,Thr,Mhr,Ehr,v8,Chr,kbe,whr,Ahr,yhr,Lt,F8,Lhr,Sbe,xhr,$hr,Qd,khr,Rbe,Shr,Rhr,gQ,Phr,Bhr,Ihr,KT,Nhr,Ar,T8,qhr,Pbe,jhr,Dhr,Za,Ghr,Bbe,Ohr,Vhr,Ibe,Xhr,zhr,Nbe,Whr,Qhr,Hhr,se,ZT,qbe,Uhr,Jhr,hQ,Yhr,Khr,Zhr,e7,jbe,epr,opr,pQ,rpr,tpr,apr,o7,Dbe,npr,spr,_Q,lpr,ipr,dpr,r7,Gbe,cpr,fpr,uQ,mpr,gpr,hpr,t7,Obe,ppr,_pr,bQ,upr,bpr,vpr,a7,Vbe,Fpr,Tpr,vQ,Mpr,Epr,Cpr,n7,Xbe,wpr,Apr,FQ,ypr,Lpr,xpr,s7,zbe,$pr,kpr,TQ,Spr,Rpr,Ppr,l7,Wbe,Bpr,Ipr,MQ,Npr,qpr,jpr,i7,Qbe,Dpr,Gpr,EQ,Opr,Vpr,Xpr,d7,Hbe,zpr,Wpr,CQ,Qpr,Hpr,Upr,c7,Ube,Jpr,Ypr,wQ,Kpr,Zpr,e_r,f7,Jbe,o_r,r_r,AQ,t_r,a_r,n_r,m7,Ybe,s_r,l_r,yQ,i_r,d_r,c_r,g7,Kbe,f_r,m_r,LQ,g_r,h_r,p_r,h7,Zbe,__r,u_r,xQ,b_r,v_r,F_r,p7,e2e,T_r,M_r,$Q,E_r,C_r,w_r,_7,o2e,A_r,y_r,kQ,L_r,x_r,$_r,u7,r2e,k_r,S_r,SQ,R_r,P_r,B_r,b7,t2e,I_r,N_r,RQ,q_r,j_r,D_r,v7,a2e,G_r,O_r,PQ,V_r,X_r,z_r,F7,n2e,W_r,Q_r,BQ,H_r,U_r,J_r,T7,s2e,Y_r,K_r,IQ,Z_r,eur,our,M7,Cje,Hd,E7,l2e,M8,rur,i2e,tur,wje,Zo,E8,aur,Ud,nur,NQ,sur,lur,qQ,iur,dur,cur,C8,fur,d2e,mur,gur,hur,xt,w8,pur,c2e,_ur,uur,Jd,bur,f2e,vur,Fur,jQ,Tur,Mur,Eur,C7,Cur,yr,A8,wur,m2e,Aur,yur,en,Lur,g2e,xur,$ur,h2e,kur,Sur,p2e,Rur,Pur,Bur,Me,w7,_2e,Iur,Nur,DQ,qur,jur,Dur,A7,u2e,Gur,Our,GQ,Vur,Xur,zur,y7,b2e,Wur,Qur,OQ,Hur,Uur,Jur,L7,v2e,Yur,Kur,VQ,Zur,e6r,o6r,x7,F2e,r6r,t6r,XQ,a6r,n6r,s6r,$7,T2e,l6r,i6r,zQ,d6r,c6r,f6r,k7,M2e,m6r,g6r,WQ,h6r,p6r,_6r,S7,E2e,u6r,b6r,QQ,v6r,F6r,T6r,R7,C2e,M6r,E6r,HQ,C6r,w6r,A6r,P7,w2e,y6r,L6r,UQ,x6r,$6r,k6r,B7,A2e,S6r,R6r,JQ,P6r,B6r,I6r,I7,y2e,N6r,q6r,YQ,j6r,D6r,G6r,N7,Aje,Yd,q7,L2e,y8,O6r,x2e,V6r,yje,er,L8,X6r,Kd,z6r,KQ,W6r,Q6r,ZQ,H6r,U6r,J6r,x8,Y6r,$2e,K6r,Z6r,e1r,$t,$8,o1r,k2e,r1r,t1r,Zd,a1r,S2e,n1r,s1r,eH,l1r,i1r,d1r,j7,c1r,Lr,k8,f1r,R2e,m1r,g1r,on,h1r,P2e,p1r,_1r,B2e,u1r,b1r,I2e,v1r,F1r,T1r,rn,D7,N2e,M1r,E1r,oH,C1r,w1r,A1r,G7,q2e,y1r,L1r,rH,x1r,$1r,k1r,O7,j2e,S1r,R1r,tH,P1r,B1r,I1r,V7,D2e,N1r,q1r,aH,j1r,D1r,G1r,X7,Lje,ec,z7,G2e,S8,O1r,O2e,V1r,xje,or,R8,X1r,oc,z1r,nH,W1r,Q1r,sH,H1r,U1r,J1r,P8,Y1r,V2e,K1r,Z1r,ebr,kt,B8,obr,X2e,rbr,tbr,rc,abr,z2e,nbr,sbr,lH,lbr,ibr,dbr,W7,cbr,xr,I8,fbr,W2e,mbr,gbr,tn,hbr,Q2e,pbr,_br,H2e,ubr,bbr,U2e,vbr,Fbr,Tbr,ie,Q7,J2e,Mbr,Ebr,iH,Cbr,wbr,Abr,H7,Y2e,ybr,Lbr,dH,xbr,$br,kbr,U7,K2e,Sbr,Rbr,cH,Pbr,Bbr,Ibr,J7,Z2e,Nbr,qbr,fH,jbr,Dbr,Gbr,Y7,e4e,Obr,Vbr,mH,Xbr,zbr,Wbr,K7,o4e,Qbr,Hbr,gH,Ubr,Jbr,Ybr,Z7,r4e,Kbr,Zbr,hH,e2r,o2r,r2r,eM,t4e,t2r,a2r,pH,n2r,s2r,l2r,oM,a4e,i2r,d2r,_H,c2r,f2r,m2r,rM,n4e,g2r,h2r,uH,p2r,_2r,u2r,tM,s4e,b2r,v2r,bH,F2r,T2r,M2r,aM,l4e,E2r,C2r,vH,w2r,A2r,y2r,nM,i4e,L2r,x2r,FH,$2r,k2r,S2r,sM,d4e,R2r,P2r,TH,B2r,I2r,N2r,lM,c4e,q2r,j2r,MH,D2r,G2r,O2r,iM,f4e,V2r,X2r,EH,z2r,W2r,Q2r,dM,m4e,H2r,U2r,CH,J2r,Y2r,K2r,cM,g4e,Z2r,e4r,wH,o4r,r4r,t4r,fM,h4e,a4r,n4r,AH,s4r,l4r,i4r,mM,p4e,d4r,c4r,yH,f4r,m4r,g4r,gM,$je,tc,hM,_4e,N8,h4r,u4e,p4r,kje,rr,q8,_4r,ac,u4r,LH,b4r,v4r,xH,F4r,T4r,M4r,j8,E4r,b4e,C4r,w4r,A4r,St,D8,y4r,v4e,L4r,x4r,nc,$4r,F4e,k4r,S4r,$H,R4r,P4r,B4r,pM,I4r,$r,G8,N4r,T4e,q4r,j4r,an,D4r,M4e,G4r,O4r,E4e,V4r,X4r,C4e,z4r,W4r,Q4r,ye,_M,w4e,H4r,U4r,kH,J4r,Y4r,K4r,uM,A4e,Z4r,evr,SH,ovr,rvr,tvr,bM,y4e,avr,nvr,RH,svr,lvr,ivr,vM,L4e,dvr,cvr,PH,fvr,mvr,gvr,FM,x4e,hvr,pvr,BH,_vr,uvr,bvr,TM,$4e,vvr,Fvr,IH,Tvr,Mvr,Evr,MM,k4e,Cvr,wvr,NH,Avr,yvr,Lvr,EM,S4e,xvr,$vr,qH,kvr,Svr,Rvr,CM,R4e,Pvr,Bvr,jH,Ivr,Nvr,qvr,wM,P4e,jvr,Dvr,DH,Gvr,Ovr,Vvr,AM,Sje,sc,yM,B4e,O8,Xvr,I4e,zvr,Rje,tr,V8,Wvr,lc,Qvr,GH,Hvr,Uvr,OH,Jvr,Yvr,Kvr,X8,Zvr,N4e,eFr,oFr,rFr,Rt,z8,tFr,q4e,aFr,nFr,ic,sFr,j4e,lFr,iFr,VH,dFr,cFr,fFr,LM,mFr,kr,W8,gFr,D4e,hFr,pFr,nn,_Fr,G4e,uFr,bFr,O4e,vFr,FFr,V4e,TFr,MFr,EFr,oe,xM,X4e,CFr,wFr,XH,AFr,yFr,LFr,$M,z4e,xFr,$Fr,zH,kFr,SFr,RFr,kM,W4e,PFr,BFr,WH,IFr,NFr,qFr,SM,Q4e,jFr,DFr,QH,GFr,OFr,VFr,RM,H4e,XFr,zFr,HH,WFr,QFr,HFr,PM,U4e,UFr,JFr,UH,YFr,KFr,ZFr,BM,J4e,eTr,oTr,JH,rTr,tTr,aTr,IM,Y4e,nTr,sTr,YH,lTr,iTr,dTr,NM,K4e,cTr,fTr,KH,mTr,gTr,hTr,qM,Z4e,pTr,_Tr,ZH,uTr,bTr,vTr,jM,eve,FTr,TTr,eU,MTr,ETr,CTr,DM,ove,wTr,ATr,oU,yTr,LTr,xTr,GM,rve,$Tr,kTr,rU,STr,RTr,PTr,OM,tve,BTr,ITr,tU,NTr,qTr,jTr,VM,ave,DTr,GTr,aU,OTr,VTr,XTr,XM,nve,zTr,WTr,nU,QTr,HTr,UTr,zM,sve,JTr,YTr,sU,KTr,ZTr,e7r,WM,lve,o7r,r7r,lU,t7r,a7r,n7r,QM,ive,s7r,l7r,iU,i7r,d7r,c7r,HM,dve,f7r,m7r,dU,g7r,h7r,p7r,UM,cve,_7r,u7r,cU,b7r,v7r,F7r,JM,fve,T7r,M7r,fU,E7r,C7r,w7r,YM,mve,A7r,y7r,mU,L7r,x7r,$7r,KM,gve,k7r,S7r,gU,R7r,P7r,B7r,ZM,hve,I7r,N7r,hU,q7r,j7r,D7r,eE,pve,G7r,O7r,pU,V7r,X7r,z7r,oE,Pje,dc,rE,_ve,Q8,W7r,uve,Q7r,Bje,ar,H8,H7r,cc,U7r,_U,J7r,Y7r,uU,K7r,Z7r,eMr,U8,oMr,bve,rMr,tMr,aMr,Pt,J8,nMr,vve,sMr,lMr,fc,iMr,Fve,dMr,cMr,bU,fMr,mMr,gMr,tE,hMr,Sr,Y8,pMr,Tve,_Mr,uMr,sn,bMr,Mve,vMr,FMr,Eve,TMr,MMr,Cve,EMr,CMr,wMr,pe,aE,wve,AMr,yMr,vU,LMr,xMr,$Mr,nE,Ave,kMr,SMr,FU,RMr,PMr,BMr,sE,yve,IMr,NMr,TU,qMr,jMr,DMr,lE,Lve,GMr,OMr,MU,VMr,XMr,zMr,iE,xve,WMr,QMr,EU,HMr,UMr,JMr,dE,$ve,YMr,KMr,CU,ZMr,eEr,oEr,cE,kve,rEr,tEr,wU,aEr,nEr,sEr,fE,Sve,lEr,iEr,AU,dEr,cEr,fEr,mE,Rve,mEr,gEr,yU,hEr,pEr,_Er,gE,Pve,uEr,bEr,LU,vEr,FEr,TEr,hE,Bve,MEr,EEr,xU,CEr,wEr,AEr,pE,Ive,yEr,LEr,$U,xEr,$Er,kEr,_E,Nve,SEr,REr,kU,PEr,BEr,IEr,uE,qve,NEr,qEr,SU,jEr,DEr,GEr,bE,jve,OEr,VEr,RU,XEr,zEr,WEr,vE,Dve,QEr,HEr,PU,UEr,JEr,YEr,FE,Gve,KEr,ZEr,BU,eCr,oCr,rCr,TE,Ije,mc,ME,Ove,K8,tCr,Vve,aCr,Nje,nr,Z8,nCr,gc,sCr,IU,lCr,iCr,NU,dCr,cCr,fCr,e9,mCr,Xve,gCr,hCr,pCr,Bt,o9,_Cr,zve,uCr,bCr,hc,vCr,Wve,FCr,TCr,qU,MCr,ECr,CCr,EE,wCr,Rr,r9,ACr,Qve,yCr,LCr,ln,xCr,Hve,$Cr,kCr,Uve,SCr,RCr,Jve,PCr,BCr,ICr,t9,CE,Yve,NCr,qCr,jU,jCr,DCr,GCr,wE,Kve,OCr,VCr,DU,XCr,zCr,WCr,AE,qje,pc,yE,Zve,a9,QCr,eFe,HCr,jje,sr,n9,UCr,_c,JCr,GU,YCr,KCr,OU,ZCr,e5r,o5r,s9,r5r,oFe,t5r,a5r,n5r,It,l9,s5r,rFe,l5r,i5r,uc,d5r,tFe,c5r,f5r,VU,m5r,g5r,h5r,LE,p5r,Pr,i9,_5r,aFe,u5r,b5r,dn,v5r,nFe,F5r,T5r,sFe,M5r,E5r,lFe,C5r,w5r,A5r,iFe,xE,dFe,y5r,L5r,XU,x5r,$5r,k5r,$E,Dje,bc,kE,cFe,d9,S5r,fFe,R5r,Gje,lr,c9,P5r,vc,B5r,zU,I5r,N5r,WU,q5r,j5r,D5r,f9,G5r,mFe,O5r,V5r,X5r,Nt,m9,z5r,gFe,W5r,Q5r,Fc,H5r,hFe,U5r,J5r,QU,Y5r,K5r,Z5r,SE,e3r,Br,g9,o3r,pFe,r3r,t3r,cn,a3r,_Fe,n3r,s3r,uFe,l3r,i3r,bFe,d3r,c3r,f3r,de,RE,vFe,m3r,g3r,HU,h3r,p3r,_3r,PE,FFe,u3r,b3r,UU,v3r,F3r,T3r,BE,TFe,M3r,E3r,JU,C3r,w3r,A3r,IE,MFe,y3r,L3r,YU,x3r,$3r,k3r,NE,EFe,S3r,R3r,KU,P3r,B3r,I3r,qE,CFe,N3r,q3r,ZU,j3r,D3r,G3r,jE,wFe,O3r,V3r,eJ,X3r,z3r,W3r,DE,AFe,Q3r,H3r,oJ,U3r,J3r,Y3r,GE,yFe,K3r,Z3r,rJ,ewr,owr,rwr,OE,LFe,twr,awr,tJ,nwr,swr,lwr,VE,xFe,iwr,dwr,aJ,cwr,fwr,mwr,XE,$Fe,gwr,hwr,nJ,pwr,_wr,uwr,zE,kFe,bwr,vwr,sJ,Fwr,Twr,Mwr,WE,SFe,Ewr,Cwr,lJ,wwr,Awr,ywr,QE,RFe,Lwr,xwr,iJ,$wr,kwr,Swr,HE,PFe,Rwr,Pwr,dJ,Bwr,Iwr,Nwr,UE,BFe,qwr,jwr,cJ,Dwr,Gwr,Owr,JE,IFe,Vwr,Xwr,fJ,zwr,Wwr,Qwr,YE,NFe,Hwr,Uwr,mJ,Jwr,Ywr,Kwr,KE,qFe,Zwr,e0r,gJ,o0r,r0r,t0r,ZE,Oje,Tc,eC,jFe,h9,a0r,DFe,n0r,Vje,ir,p9,s0r,Mc,l0r,hJ,i0r,d0r,pJ,c0r,f0r,m0r,_9,g0r,GFe,h0r,p0r,_0r,qt,u9,u0r,OFe,b0r,v0r,Ec,F0r,VFe,T0r,M0r,_J,E0r,C0r,w0r,oC,A0r,Ir,b9,y0r,XFe,L0r,x0r,fn,$0r,zFe,k0r,S0r,WFe,R0r,P0r,QFe,B0r,I0r,N0r,ce,rC,HFe,q0r,j0r,uJ,D0r,G0r,O0r,tC,UFe,V0r,X0r,bJ,z0r,W0r,Q0r,aC,JFe,H0r,U0r,vJ,J0r,Y0r,K0r,nC,YFe,Z0r,eAr,FJ,oAr,rAr,tAr,sC,KFe,aAr,nAr,TJ,sAr,lAr,iAr,lC,ZFe,dAr,cAr,MJ,fAr,mAr,gAr,iC,eTe,hAr,pAr,EJ,_Ar,uAr,bAr,dC,oTe,vAr,FAr,CJ,TAr,MAr,EAr,cC,rTe,CAr,wAr,wJ,AAr,yAr,LAr,fC,tTe,xAr,$Ar,AJ,kAr,SAr,RAr,mC,aTe,PAr,BAr,yJ,IAr,NAr,qAr,gC,nTe,jAr,DAr,LJ,GAr,OAr,VAr,hC,sTe,XAr,zAr,xJ,WAr,QAr,HAr,pC,lTe,UAr,JAr,$J,YAr,KAr,ZAr,_C,iTe,eyr,oyr,kJ,ryr,tyr,ayr,uC,dTe,nyr,syr,SJ,lyr,iyr,dyr,bC,cTe,cyr,fyr,RJ,myr,gyr,hyr,vC,fTe,pyr,_yr,PJ,uyr,byr,vyr,FC,mTe,Fyr,Tyr,BJ,Myr,Eyr,Cyr,TC,gTe,wyr,Ayr,IJ,yyr,Lyr,xyr,MC,Xje,Cc,EC,hTe,v9,$yr,pTe,kyr,zje,dr,F9,Syr,wc,Ryr,NJ,Pyr,Byr,qJ,Iyr,Nyr,qyr,T9,jyr,_Te,Dyr,Gyr,Oyr,jt,M9,Vyr,uTe,Xyr,zyr,Ac,Wyr,bTe,Qyr,Hyr,jJ,Uyr,Jyr,Yyr,CC,Kyr,Nr,E9,Zyr,vTe,eLr,oLr,mn,rLr,FTe,tLr,aLr,TTe,nLr,sLr,MTe,lLr,iLr,dLr,ETe,wC,CTe,cLr,fLr,DJ,mLr,gLr,hLr,AC,Wje,yc,yC,wTe,C9,pLr,ATe,_Lr,Qje,cr,w9,uLr,Lc,bLr,GJ,vLr,FLr,OJ,TLr,MLr,ELr,A9,CLr,yTe,wLr,ALr,yLr,Dt,y9,LLr,LTe,xLr,$Lr,xc,kLr,xTe,SLr,RLr,VJ,PLr,BLr,ILr,LC,NLr,qr,L9,qLr,$Te,jLr,DLr,gn,GLr,kTe,OLr,VLr,STe,XLr,zLr,RTe,WLr,QLr,HLr,PTe,xC,BTe,ULr,JLr,XJ,YLr,KLr,ZLr,$C,Hje,$c,kC,ITe,x9,e8r,NTe,o8r,Uje,fr,$9,r8r,kc,t8r,zJ,a8r,n8r,WJ,s8r,l8r,i8r,k9,d8r,qTe,c8r,f8r,m8r,Gt,S9,g8r,jTe,h8r,p8r,Sc,_8r,DTe,u8r,b8r,QJ,v8r,F8r,T8r,SC,M8r,jr,R9,E8r,GTe,C8r,w8r,hn,A8r,OTe,y8r,L8r,VTe,x8r,$8r,XTe,k8r,S8r,R8r,te,RC,zTe,P8r,B8r,HJ,I8r,N8r,q8r,PC,WTe,j8r,D8r,UJ,G8r,O8r,V8r,BC,QTe,X8r,z8r,JJ,W8r,Q8r,H8r,IC,HTe,U8r,J8r,YJ,Y8r,K8r,Z8r,NC,UTe,e9r,o9r,KJ,r9r,t9r,a9r,qC,JTe,n9r,s9r,ZJ,l9r,i9r,d9r,jC,YTe,c9r,f9r,eY,m9r,g9r,h9r,DC,KTe,p9r,_9r,oY,u9r,b9r,v9r,GC,ZTe,F9r,T9r,rY,M9r,E9r,C9r,OC,e7e,w9r,A9r,tY,y9r,L9r,x9r,VC,o7e,$9r,k9r,aY,S9r,R9r,P9r,XC,r7e,B9r,I9r,nY,N9r,q9r,j9r,zC,t7e,D9r,G9r,sY,O9r,V9r,X9r,WC,a7e,z9r,W9r,lY,Q9r,H9r,U9r,QC,n7e,J9r,Y9r,iY,K9r,Z9r,exr,HC,s7e,oxr,rxr,dY,txr,axr,nxr,UC,l7e,sxr,lxr,cY,ixr,dxr,cxr,JC,i7e,fxr,mxr,fY,gxr,hxr,pxr,YC,d7e,_xr,uxr,mY,bxr,vxr,Fxr,KC,c7e,Txr,Mxr,gY,Exr,Cxr,wxr,ZC,f7e,Axr,yxr,hY,Lxr,xxr,$xr,e5,m7e,kxr,Sxr,pY,Rxr,Pxr,Bxr,o5,g7e,Ixr,Nxr,_Y,qxr,jxr,Dxr,r5,h7e,Gxr,Oxr,uY,Vxr,Xxr,zxr,t5,p7e,Wxr,Qxr,bY,Hxr,Uxr,Jxr,a5,Jje,Rc,n5,_7e,P9,Yxr,u7e,Kxr,Yje,mr,B9,Zxr,Pc,e$r,vY,o$r,r$r,FY,t$r,a$r,n$r,I9,s$r,b7e,l$r,i$r,d$r,Ot,N9,c$r,v7e,f$r,m$r,Bc,g$r,F7e,h$r,p$r,TY,_$r,u$r,b$r,s5,v$r,Dr,q9,F$r,T7e,T$r,M$r,pn,E$r,M7e,C$r,w$r,E7e,A$r,y$r,C7e,L$r,x$r,$$r,Re,l5,w7e,k$r,S$r,MY,R$r,P$r,B$r,i5,A7e,I$r,N$r,EY,q$r,j$r,D$r,d5,y7e,G$r,O$r,CY,V$r,X$r,z$r,c5,L7e,W$r,Q$r,wY,H$r,U$r,J$r,f5,x7e,Y$r,K$r,AY,Z$r,ekr,okr,m5,$7e,rkr,tkr,yY,akr,nkr,skr,g5,k7e,lkr,ikr,LY,dkr,ckr,fkr,h5,S7e,mkr,gkr,xY,hkr,pkr,_kr,p5,R7e,ukr,bkr,$Y,vkr,Fkr,Tkr,_5,Kje,Ic,u5,P7e,j9,Mkr,B7e,Ekr,Zje,gr,D9,Ckr,Nc,wkr,kY,Akr,ykr,SY,Lkr,xkr,$kr,G9,kkr,I7e,Skr,Rkr,Pkr,Vt,O9,Bkr,N7e,Ikr,Nkr,qc,qkr,q7e,jkr,Dkr,RY,Gkr,Okr,Vkr,b5,Xkr,Gr,V9,zkr,j7e,Wkr,Qkr,_n,Hkr,D7e,Ukr,Jkr,G7e,Ykr,Kkr,O7e,Zkr,eSr,oSr,Ee,v5,V7e,rSr,tSr,PY,aSr,nSr,sSr,F5,X7e,lSr,iSr,BY,dSr,cSr,fSr,T5,z7e,mSr,gSr,IY,hSr,pSr,_Sr,M5,W7e,uSr,bSr,NY,vSr,FSr,TSr,E5,Q7e,MSr,ESr,qY,CSr,wSr,ASr,C5,H7e,ySr,LSr,jY,xSr,$Sr,kSr,w5,U7e,SSr,RSr,DY,PSr,BSr,ISr,A5,J7e,NSr,qSr,GY,jSr,DSr,GSr,y5,Y7e,OSr,VSr,OY,XSr,zSr,WSr,L5,K7e,QSr,HSr,VY,USr,JSr,YSr,x5,Z7e,KSr,ZSr,XY,eRr,oRr,rRr,$5,eMe,tRr,aRr,zY,nRr,sRr,lRr,k5,eDe,jc,S5,oMe,X9,iRr,rMe,dRr,oDe,hr,z9,cRr,Dc,fRr,WY,mRr,gRr,QY,hRr,pRr,_Rr,W9,uRr,tMe,bRr,vRr,FRr,Xt,Q9,TRr,aMe,MRr,ERr,Gc,CRr,nMe,wRr,ARr,HY,yRr,LRr,xRr,R5,$Rr,Or,H9,kRr,sMe,SRr,RRr,un,PRr,lMe,BRr,IRr,iMe,NRr,qRr,dMe,jRr,DRr,GRr,Le,P5,cMe,ORr,VRr,UY,XRr,zRr,WRr,B5,fMe,QRr,HRr,JY,URr,JRr,YRr,I5,mMe,KRr,ZRr,YY,ePr,oPr,rPr,N5,gMe,tPr,aPr,KY,nPr,sPr,lPr,q5,hMe,iPr,dPr,ZY,cPr,fPr,mPr,j5,pMe,gPr,hPr,eK,pPr,_Pr,uPr,D5,_Me,bPr,vPr,oK,FPr,TPr,MPr,G5,uMe,EPr,CPr,rK,wPr,APr,yPr,O5,bMe,LPr,xPr,tK,$Pr,kPr,SPr,V5,vMe,RPr,PPr,aK,BPr,IPr,NPr,X5,rDe,Oc,z5,FMe,U9,qPr,TMe,jPr,tDe,pr,J9,DPr,Vc,GPr,nK,OPr,VPr,sK,XPr,zPr,WPr,Y9,QPr,MMe,HPr,UPr,JPr,zt,K9,YPr,EMe,KPr,ZPr,Xc,eBr,CMe,oBr,rBr,lK,tBr,aBr,nBr,W5,sBr,Vr,Z9,lBr,wMe,iBr,dBr,bn,cBr,AMe,fBr,mBr,yMe,gBr,hBr,LMe,pBr,_Br,uBr,Pe,Q5,xMe,bBr,vBr,iK,FBr,TBr,MBr,H5,$Me,EBr,CBr,dK,wBr,ABr,yBr,U5,kMe,LBr,xBr,cK,$Br,kBr,SBr,J5,SMe,RBr,PBr,fK,BBr,IBr,NBr,Y5,RMe,qBr,jBr,mK,DBr,GBr,OBr,K5,PMe,VBr,XBr,gK,zBr,WBr,QBr,Z5,BMe,HBr,UBr,hK,JBr,YBr,KBr,e3,IMe,ZBr,eIr,pK,oIr,rIr,tIr,o3,NMe,aIr,nIr,_K,sIr,lIr,iIr,r3,aDe,zc,t3,qMe,ex,dIr,jMe,cIr,nDe,_r,ox,fIr,Wc,mIr,uK,gIr,hIr,bK,pIr,_Ir,uIr,rx,bIr,DMe,vIr,FIr,TIr,Wt,tx,MIr,GMe,EIr,CIr,Qc,wIr,OMe,AIr,yIr,vK,LIr,xIr,$Ir,a3,kIr,Xr,ax,SIr,VMe,RIr,PIr,vn,BIr,XMe,IIr,NIr,zMe,qIr,jIr,WMe,DIr,GIr,OIr,xe,n3,QMe,VIr,XIr,FK,zIr,WIr,QIr,s3,HMe,HIr,UIr,TK,JIr,YIr,KIr,l3,UMe,ZIr,eNr,MK,oNr,rNr,tNr,i3,JMe,aNr,nNr,EK,sNr,lNr,iNr,d3,YMe,dNr,cNr,CK,fNr,mNr,gNr,c3,KMe,hNr,pNr,wK,_Nr,uNr,bNr,f3,ZMe,vNr,FNr,AK,TNr,MNr,ENr,m3,eEe,CNr,wNr,yK,ANr,yNr,LNr,g3,oEe,xNr,$Nr,LK,kNr,SNr,RNr,h3,rEe,PNr,BNr,xK,INr,NNr,qNr,p3,sDe,Hc,_3,tEe,nx,jNr,aEe,DNr,lDe,ur,sx,GNr,Uc,ONr,$K,VNr,XNr,kK,zNr,WNr,QNr,lx,HNr,nEe,UNr,JNr,YNr,Qt,ix,KNr,sEe,ZNr,eqr,Jc,oqr,lEe,rqr,tqr,SK,aqr,nqr,sqr,u3,lqr,zr,dx,iqr,iEe,dqr,cqr,Fn,fqr,dEe,mqr,gqr,cEe,hqr,pqr,fEe,_qr,uqr,bqr,$e,b3,mEe,vqr,Fqr,RK,Tqr,Mqr,Eqr,v3,gEe,Cqr,wqr,PK,Aqr,yqr,Lqr,F3,hEe,xqr,$qr,BK,kqr,Sqr,Rqr,T3,pEe,Pqr,Bqr,IK,Iqr,Nqr,qqr,M3,_Ee,jqr,Dqr,NK,Gqr,Oqr,Vqr,E3,uEe,Xqr,zqr,qK,Wqr,Qqr,Hqr,C3,bEe,Uqr,Jqr,jK,Yqr,Kqr,Zqr,w3,vEe,ejr,ojr,DK,rjr,tjr,ajr,A3,FEe,njr,sjr,GK,ljr,ijr,djr,y3,TEe,cjr,fjr,OK,mjr,gjr,hjr,L3,iDe,Yc,x3,MEe,cx,pjr,EEe,_jr,dDe,br,fx,ujr,Kc,bjr,VK,vjr,Fjr,XK,Tjr,Mjr,Ejr,mx,Cjr,CEe,wjr,Ajr,yjr,Ht,gx,Ljr,wEe,xjr,$jr,Zc,kjr,AEe,Sjr,Rjr,zK,Pjr,Bjr,Ijr,$3,Njr,Wr,hx,qjr,yEe,jjr,Djr,Tn,Gjr,LEe,Ojr,Vjr,xEe,Xjr,zjr,$Ee,Wjr,Qjr,Hjr,De,k3,kEe,Ujr,Jjr,WK,Yjr,Kjr,Zjr,S3,SEe,eDr,oDr,QK,rDr,tDr,aDr,R3,REe,nDr,sDr,HK,lDr,iDr,dDr,P3,PEe,cDr,fDr,UK,mDr,gDr,hDr,B3,BEe,pDr,_Dr,JK,uDr,bDr,vDr,I3,IEe,FDr,TDr,YK,MDr,EDr,CDr,N3,NEe,wDr,ADr,KK,yDr,LDr,xDr,q3,qEe,$Dr,kDr,ZK,SDr,RDr,PDr,j3,cDe,ef,D3,jEe,px,BDr,DEe,IDr,fDe,vr,_x,NDr,of,qDr,eZ,jDr,DDr,oZ,GDr,ODr,VDr,ux,XDr,GEe,zDr,WDr,QDr,Ut,bx,HDr,OEe,UDr,JDr,rf,YDr,VEe,KDr,ZDr,rZ,eGr,oGr,rGr,G3,tGr,Qr,vx,aGr,XEe,nGr,sGr,Mn,lGr,zEe,iGr,dGr,WEe,cGr,fGr,QEe,mGr,gGr,hGr,Ge,O3,HEe,pGr,_Gr,tZ,uGr,bGr,vGr,V3,UEe,FGr,TGr,aZ,MGr,EGr,CGr,X3,JEe,wGr,AGr,nZ,yGr,LGr,xGr,z3,YEe,$Gr,kGr,sZ,SGr,RGr,PGr,W3,KEe,BGr,IGr,lZ,NGr,qGr,jGr,Q3,ZEe,DGr,GGr,iZ,OGr,VGr,XGr,H3,eCe,zGr,WGr,dZ,QGr,HGr,UGr,U3,oCe,JGr,YGr,cZ,KGr,ZGr,eOr,J3,mDe,tf,Y3,rCe,Fx,oOr,tCe,rOr,gDe,Fr,Tx,tOr,af,aOr,fZ,nOr,sOr,mZ,lOr,iOr,dOr,Mx,cOr,aCe,fOr,mOr,gOr,Jt,Ex,hOr,nCe,pOr,_Or,nf,uOr,sCe,bOr,vOr,gZ,FOr,TOr,MOr,K3,EOr,Hr,Cx,COr,lCe,wOr,AOr,En,yOr,iCe,LOr,xOr,dCe,$Or,kOr,cCe,SOr,ROr,POr,fCe,Z3,mCe,BOr,IOr,hZ,NOr,qOr,jOr,ew,hDe,sf,ow,gCe,wx,DOr,hCe,GOr,pDe,Tr,Ax,OOr,lf,VOr,pZ,XOr,zOr,_Z,WOr,QOr,HOr,yx,UOr,pCe,JOr,YOr,KOr,Yt,Lx,ZOr,_Ce,eVr,oVr,df,rVr,uCe,tVr,aVr,uZ,nVr,sVr,lVr,rw,iVr,Ur,xx,dVr,bCe,cVr,fVr,Cn,mVr,vCe,gVr,hVr,FCe,pVr,_Vr,TCe,uVr,bVr,vVr,$x,tw,MCe,FVr,TVr,bZ,MVr,EVr,CVr,aw,ECe,wVr,AVr,vZ,yVr,LVr,xVr,nw,_De,cf,sw,CCe,kx,$Vr,wCe,kVr,uDe,Mr,Sx,SVr,ff,RVr,FZ,PVr,BVr,TZ,IVr,NVr,qVr,Rx,jVr,ACe,DVr,GVr,OVr,Kt,Px,VVr,yCe,XVr,zVr,mf,WVr,LCe,QVr,HVr,MZ,UVr,JVr,YVr,lw,KVr,Jr,Bx,ZVr,xCe,eXr,oXr,wn,rXr,$Ce,tXr,aXr,kCe,nXr,sXr,SCe,lXr,iXr,dXr,RCe,iw,PCe,cXr,fXr,EZ,mXr,gXr,hXr,dw,bDe;return d=new re({}),Ca=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),kA=new re({}),SA=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Tf=new pXr({props:{warning:!0,$$slots:{default:[nkt]},$$scope:{ctx:L}}}),RA=new re({}),PA=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/configuration_auto.py#L587"}}),NA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/configuration_auto.py#L610"}}),wg=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[skt]},$$scope:{ctx:L}}}),qA=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/configuration_auto.py#L733"}}),jA=new re({}),DA=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/tokenization_auto.py#L390"}}),VA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17466/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/tokenization_auto.py#L404"}}),sh=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[lkt]},$$scope:{ctx:L}}}),XA=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/tokenization_auto.py#L603"}}),zA=new re({}),WA=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/feature_extraction_auto.py#L191"}}),UA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17466/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/feature_extraction_auto.py#L205"}}),jh=new pXr({props:{$$slots:{default:[ikt]},$$scope:{ctx:L}}}),Dh=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[dkt]},$$scope:{ctx:L}}}),JA=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/feature_extraction_auto.py#L332"}}),YA=new re({}),KA=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/processing_auto.py#L88"}}),oy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/processing_auto.py#L102"}}),sp=new pXr({props:{$$slots:{default:[ckt]},$$scope:{ctx:L}}}),lp=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[fkt]},$$scope:{ctx:L}}}),ry=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/processing_auto.py#L255"}}),ty=new re({}),ay=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L738"}}),sy=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (Flava model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),cp=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[mkt]},$$scope:{ctx:L}}}),ly=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),su=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[gkt]},$$scope:{ctx:L}}}),iy=new re({}),dy=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L745"}}),fy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (Flava model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),iu=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[hkt]},$$scope:{ctx:L}}}),my=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),Ku=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[pkt]},$$scope:{ctx:L}}}),gy=new re({}),hy=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L760"}}),_y=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),e6=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[_kt]},$$scope:{ctx:L}}}),uy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),j6=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[ukt]},$$scope:{ctx:L}}}),by=new re({}),vy=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L767"}}),Ty=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),G6=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[bkt]},$$scope:{ctx:L}}}),My=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),C1=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[vkt]},$$scope:{ctx:L}}}),Ey=new re({}),Cy=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L774"}}),Ay=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLMProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),A1=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Fkt]},$$scope:{ctx:L}}}),yy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),X1=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Tkt]},$$scope:{ctx:L}}}),Ly=new re({}),xy=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L783"}}),ky=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),W1=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[Mkt]},$$scope:{ctx:L}}}),Sy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),Gb=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Ekt]},$$scope:{ctx:L}}}),Ry=new re({}),Py=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L817"}}),Iy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),Vb=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[Ckt]},$$scope:{ctx:L}}}),Ny=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),F2=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[wkt]},$$scope:{ctx:L}}}),qy=new re({}),jy=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L824"}}),Gy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),M2=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Akt]},$$scope:{ctx:L}}}),Oy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),x2=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[ykt]},$$scope:{ctx:L}}}),Vy=new re({}),Xy=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L810"}}),Wy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),k2=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[Lkt]},$$scope:{ctx:L}}}),Qy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),g4=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[xkt]},$$scope:{ctx:L}}}),Hy=new re({}),Uy=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L792"}}),Yy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),p4=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[$kt]},$$scope:{ctx:L}}}),Ky=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),tv=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[kkt]},$$scope:{ctx:L}}}),Zy=new re({}),eL=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L799"}}),rL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),nv=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[Skt]},$$scope:{ctx:L}}}),tL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),iv=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[Rkt]},$$scope:{ctx:L}}}),aL=new re({}),nL=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L833"}}),lL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17466/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/pr_17466/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17466/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17466/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),cv=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[Pkt]},$$scope:{ctx:L}}}),iL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),Cv=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Bkt]},$$scope:{ctx:L}}}),dL=new re({}),cL=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L872"}}),mL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),Av=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[Ikt]},$$scope:{ctx:L}}}),gL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),xv=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Nkt]},$$scope:{ctx:L}}}),hL=new re({}),pL=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L879"}}),uL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),kv=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[qkt]},$$scope:{ctx:L}}}),bL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),Ov=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[jkt]},$$scope:{ctx:L}}}),vL=new re({}),FL=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L902"}}),ML=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),Xv=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[Dkt]},$$scope:{ctx:L}}}),EL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),Yv=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[Gkt]},$$scope:{ctx:L}}}),CL=new re({}),wL=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L886"}}),yL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),Zv=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[Okt]},$$scope:{ctx:L}}}),LL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),cF=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[Vkt]},$$scope:{ctx:L}}}),xL=new re({}),$L=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L893"}}),SL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),mF=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Xkt]},$$scope:{ctx:L}}}),RL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),_F=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[zkt]},$$scope:{ctx:L}}}),BL=new re({}),IL=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L911"}}),qL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),bF=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[Wkt]},$$scope:{ctx:L}}}),jL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),wF=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[Qkt]},$$scope:{ctx:L}}}),DL=new re({}),GL=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L918"}}),VL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),yF=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[Hkt]},$$scope:{ctx:L}}}),XL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),SF=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[Ukt]},$$scope:{ctx:L}}}),zL=new re({}),WL=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L865"}}),HL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),PF=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[Jkt]},$$scope:{ctx:L}}}),UL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),qF=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[Ykt]},$$scope:{ctx:L}}}),YL=new re({}),KL=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L840"}}),e8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),DF=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[Kkt]},$$scope:{ctx:L}}}),o8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),VF=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[Zkt]},$$scope:{ctx:L}}}),r8=new re({}),t8=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L847"}}),n8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),zF=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[eSt]},$$scope:{ctx:L}}}),s8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),YF=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[oSt]},$$scope:{ctx:L}}}),l8=new re({}),i8=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_auto.py#L856"}}),c8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),ZF=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[rSt]},$$scope:{ctx:L}}}),f8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),rT=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[tSt]},$$scope:{ctx:L}}}),m8=new re({}),g8=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_tf_auto.py#L394"}}),p8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),aT=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[aSt]},$$scope:{ctx:L}}}),_8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),JT=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[nSt]},$$scope:{ctx:L}}}),u8=new re({}),b8=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_tf_auto.py#L401"}}),F8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),KT=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[sSt]},$$scope:{ctx:L}}}),T8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),M7=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[lSt]},$$scope:{ctx:L}}}),M8=new re({}),E8=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_tf_auto.py#L416"}}),w8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),C7=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[iSt]},$$scope:{ctx:L}}}),A8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),N7=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[dSt]},$$scope:{ctx:L}}}),y8=new re({}),L8=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_tf_auto.py#L432"}}),$8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),j7=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[cSt]},$$scope:{ctx:L}}}),k8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),X7=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[fSt]},$$scope:{ctx:L}}}),S8=new re({}),R8=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_tf_auto.py#L448"}}),B8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),W7=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[mSt]},$$scope:{ctx:L}}}),I8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),gM=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[gSt]},$$scope:{ctx:L}}}),N8=new re({}),q8=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_tf_auto.py#L455"}}),D8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),pM=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[hSt]},$$scope:{ctx:L}}}),G8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),AM=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[pSt]},$$scope:{ctx:L}}}),O8=new re({}),V8=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_tf_auto.py#L464"}}),z8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),LM=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[_St]},$$scope:{ctx:L}}}),W8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),oE=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[uSt]},$$scope:{ctx:L}}}),Q8=new re({}),H8=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_tf_auto.py#L500"}}),J8=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),tE=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[bSt]},$$scope:{ctx:L}}}),Y8=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),TE=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[vSt]},$$scope:{ctx:L}}}),K8=new re({}),Z8=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_tf_auto.py#L507"}}),o9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),EE=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[FSt]},$$scope:{ctx:L}}}),r9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),AE=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[TSt]},$$scope:{ctx:L}}}),a9=new re({}),n9=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_tf_auto.py#L480"}}),l9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),LE=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[MSt]},$$scope:{ctx:L}}}),i9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),$E=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[ESt]},$$scope:{ctx:L}}}),d9=new re({}),c9=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_tf_auto.py#L491"}}),m9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),SE=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[CSt]},$$scope:{ctx:L}}}),g9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),ZE=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[wSt]},$$scope:{ctx:L}}}),h9=new re({}),p9=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_tf_auto.py#L473"}}),u9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),oC=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[ASt]},$$scope:{ctx:L}}}),b9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),MC=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[ySt]},$$scope:{ctx:L}}}),v9=new re({}),F9=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_tf_auto.py#L441"}}),M9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),CC=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[LSt]},$$scope:{ctx:L}}}),E9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),AC=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[xSt]},$$scope:{ctx:L}}}),C9=new re({}),w9=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_tf_auto.py#L516"}}),y9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),LC=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[$St]},$$scope:{ctx:L}}}),L9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),$C=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[kSt]},$$scope:{ctx:L}}}),x9=new re({}),$9=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_flax_auto.py#L241"}}),S9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),SC=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[SSt]},$$scope:{ctx:L}}}),R9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),a5=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[RSt]},$$scope:{ctx:L}}}),P9=new re({}),B9=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_flax_auto.py#L255"}}),N9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),s5=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[PSt]},$$scope:{ctx:L}}}),q9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),_5=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[BSt]},$$scope:{ctx:L}}}),j9=new re({}),D9=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_flax_auto.py#L248"}}),O9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),b5=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[ISt]},$$scope:{ctx:L}}}),V9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),k5=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[NSt]},$$scope:{ctx:L}}}),X9=new re({}),z9=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_flax_auto.py#L262"}}),Q9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),R5=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[qSt]},$$scope:{ctx:L}}}),H9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),X5=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[jSt]},$$scope:{ctx:L}}}),U9=new re({}),J9=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_flax_auto.py#L269"}}),K9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),W5=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[DSt]},$$scope:{ctx:L}}}),Z9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),r3=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[GSt]},$$scope:{ctx:L}}}),ex=new re({}),ox=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_flax_auto.py#L278"}}),tx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),a3=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[OSt]},$$scope:{ctx:L}}}),ax=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),p3=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[VSt]},$$scope:{ctx:L}}}),nx=new re({}),sx=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_flax_auto.py#L287"}}),ix=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),u3=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[XSt]},$$scope:{ctx:L}}}),dx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),L3=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[zSt]},$$scope:{ctx:L}}}),cx=new re({}),fx=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_flax_auto.py#L294"}}),gx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),$3=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[WSt]},$$scope:{ctx:L}}}),hx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),j3=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[QSt]},$$scope:{ctx:L}}}),px=new re({}),_x=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_flax_auto.py#L303"}}),bx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),G3=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[HSt]},$$scope:{ctx:L}}}),vx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),J3=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[USt]},$$scope:{ctx:L}}}),Fx=new re({}),Tx=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_flax_auto.py#L310"}}),Ex=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),K3=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[JSt]},$$scope:{ctx:L}}}),Cx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),ew=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[YSt]},$$scope:{ctx:L}}}),wx=new re({}),Ax=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_flax_auto.py#L319"}}),Lx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17466/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),rw=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[KSt]},$$scope:{ctx:L}}}),xx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),nw=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[ZSt]},$$scope:{ctx:L}}}),kx=new re({}),Sx=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/modeling_flax_auto.py#L328"}}),Px=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17466/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17466/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L389"}}),lw=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[eRt]},$$scope:{ctx:L}}}),Bx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17466/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17466/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17466/src/transformers/models/auto/auto_factory.py#L417"}}),dw=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[oRt]},$$scope:{ctx:L}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),_=a("span"),F(d.$$.fragment),h=l(),Mo=a("span"),mi=o("Auto Classes"),_f=l(),rt=a("p"),gi=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),hi=a("code"),yA=o("from_pretrained()"),uf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),je=l(),We=a("p"),pi=o("Instantiating one of "),yn=a("a"),LA=o("AutoConfig"),Ln=o(", "),xn=a("a"),xA=o("AutoModel"),_i=o(`, and
`),$n=a("a"),$A=o("AutoTokenizer"),ui=o(" will directly create a class of the relevant architecture. For instance"),bf=l(),F(Ca.$$.fragment),Qe=l(),Ae=a("p"),J$=o("will create a model that is an instance of "),bi=a("a"),Y$=o("BertModel"),K$=o("."),Eo=l(),wa=a("p"),Z$=o("There is one class of "),vf=a("code"),ek=o("AutoModel"),AOe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),pqe=l(),vi=a("h2"),Ff=a("a"),_oe=a("span"),F(kA.$$.fragment),yOe=l(),uoe=a("span"),LOe=o("Extending the Auto Classes"),_qe=l(),kn=a("p"),xOe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),boe=a("code"),$Oe=o("NewModel"),kOe=o(", make sure you have a "),voe=a("code"),SOe=o("NewModelConfig"),ROe=o(` then you can add those to the auto
classes like this:`),uqe=l(),F(SA.$$.fragment),bqe=l(),ok=a("p"),POe=o("You will then be able to use the auto classes like you would usually do!"),vqe=l(),F(Tf.$$.fragment),Fqe=l(),Fi=a("h2"),Mf=a("a"),Foe=a("span"),F(RA.$$.fragment),BOe=l(),Toe=a("span"),IOe=o("AutoConfig"),Tqe=l(),Co=a("div"),F(PA.$$.fragment),NOe=l(),BA=a("p"),qOe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),rk=a("a"),jOe=o("from_pretrained()"),DOe=o(" class method."),GOe=l(),IA=a("p"),OOe=o("This class cannot be instantiated directly using "),Moe=a("code"),VOe=o("__init__()"),XOe=o(" (throws an error)."),zOe=l(),Er=a("div"),F(NA.$$.fragment),WOe=l(),Eoe=a("p"),QOe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),HOe=l(),Ti=a("p"),UOe=o("The configuration class to instantiate is selected based on the "),Coe=a("code"),JOe=o("model_type"),YOe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),woe=a("code"),KOe=o("pretrained_model_name_or_path"),ZOe=o(":"),eVe=l(),A=a("ul"),Ef=a("li"),Aoe=a("strong"),oVe=o("albert"),rVe=o(" \u2014 "),tk=a("a"),tVe=o("AlbertConfig"),aVe=o(" (ALBERT model)"),nVe=l(),Cf=a("li"),yoe=a("strong"),sVe=o("bart"),lVe=o(" \u2014 "),ak=a("a"),iVe=o("BartConfig"),dVe=o(" (BART model)"),cVe=l(),wf=a("li"),Loe=a("strong"),fVe=o("beit"),mVe=o(" \u2014 "),nk=a("a"),gVe=o("BeitConfig"),hVe=o(" (BEiT model)"),pVe=l(),Af=a("li"),xoe=a("strong"),_Ve=o("bert"),uVe=o(" \u2014 "),sk=a("a"),bVe=o("BertConfig"),vVe=o(" (BERT model)"),FVe=l(),yf=a("li"),$oe=a("strong"),TVe=o("bert-generation"),MVe=o(" \u2014 "),lk=a("a"),EVe=o("BertGenerationConfig"),CVe=o(" (Bert Generation model)"),wVe=l(),Lf=a("li"),koe=a("strong"),AVe=o("big_bird"),yVe=o(" \u2014 "),ik=a("a"),LVe=o("BigBirdConfig"),xVe=o(" (BigBird model)"),$Ve=l(),xf=a("li"),Soe=a("strong"),kVe=o("bigbird_pegasus"),SVe=o(" \u2014 "),dk=a("a"),RVe=o("BigBirdPegasusConfig"),PVe=o(" (BigBirdPegasus model)"),BVe=l(),$f=a("li"),Roe=a("strong"),IVe=o("blenderbot"),NVe=o(" \u2014 "),ck=a("a"),qVe=o("BlenderbotConfig"),jVe=o(" (Blenderbot model)"),DVe=l(),kf=a("li"),Poe=a("strong"),GVe=o("blenderbot-small"),OVe=o(" \u2014 "),fk=a("a"),VVe=o("BlenderbotSmallConfig"),XVe=o(" (BlenderbotSmall model)"),zVe=l(),Sf=a("li"),Boe=a("strong"),WVe=o("camembert"),QVe=o(" \u2014 "),mk=a("a"),HVe=o("CamembertConfig"),UVe=o(" (CamemBERT model)"),JVe=l(),Rf=a("li"),Ioe=a("strong"),YVe=o("canine"),KVe=o(" \u2014 "),gk=a("a"),ZVe=o("CanineConfig"),eXe=o(" (Canine model)"),oXe=l(),Pf=a("li"),Noe=a("strong"),rXe=o("clip"),tXe=o(" \u2014 "),hk=a("a"),aXe=o("CLIPConfig"),nXe=o(" (CLIP model)"),sXe=l(),Bf=a("li"),qoe=a("strong"),lXe=o("convbert"),iXe=o(" \u2014 "),pk=a("a"),dXe=o("ConvBertConfig"),cXe=o(" (ConvBERT model)"),fXe=l(),If=a("li"),joe=a("strong"),mXe=o("convnext"),gXe=o(" \u2014 "),_k=a("a"),hXe=o("ConvNextConfig"),pXe=o(" (ConvNext model)"),_Xe=l(),Nf=a("li"),Doe=a("strong"),uXe=o("ctrl"),bXe=o(" \u2014 "),uk=a("a"),vXe=o("CTRLConfig"),FXe=o(" (CTRL model)"),TXe=l(),qf=a("li"),Goe=a("strong"),MXe=o("cvt"),EXe=o(" \u2014 "),bk=a("a"),CXe=o("CvtConfig"),wXe=o(" (CvT model)"),AXe=l(),jf=a("li"),Ooe=a("strong"),yXe=o("data2vec-audio"),LXe=o(" \u2014 "),vk=a("a"),xXe=o("Data2VecAudioConfig"),$Xe=o(" (Data2VecAudio model)"),kXe=l(),Df=a("li"),Voe=a("strong"),SXe=o("data2vec-text"),RXe=o(" \u2014 "),Fk=a("a"),PXe=o("Data2VecTextConfig"),BXe=o(" (Data2VecText model)"),IXe=l(),Gf=a("li"),Xoe=a("strong"),NXe=o("data2vec-vision"),qXe=o(" \u2014 "),Tk=a("a"),jXe=o("Data2VecVisionConfig"),DXe=o(" (Data2VecVision model)"),GXe=l(),Of=a("li"),zoe=a("strong"),OXe=o("deberta"),VXe=o(" \u2014 "),Mk=a("a"),XXe=o("DebertaConfig"),zXe=o(" (DeBERTa model)"),WXe=l(),Vf=a("li"),Woe=a("strong"),QXe=o("deberta-v2"),HXe=o(" \u2014 "),Ek=a("a"),UXe=o("DebertaV2Config"),JXe=o(" (DeBERTa-v2 model)"),YXe=l(),Xf=a("li"),Qoe=a("strong"),KXe=o("decision_transformer"),ZXe=o(" \u2014 "),Ck=a("a"),eze=o("DecisionTransformerConfig"),oze=o(" (Decision Transformer model)"),rze=l(),zf=a("li"),Hoe=a("strong"),tze=o("deit"),aze=o(" \u2014 "),wk=a("a"),nze=o("DeiTConfig"),sze=o(" (DeiT model)"),lze=l(),Wf=a("li"),Uoe=a("strong"),ize=o("detr"),dze=o(" \u2014 "),Ak=a("a"),cze=o("DetrConfig"),fze=o(" (DETR model)"),mze=l(),Qf=a("li"),Joe=a("strong"),gze=o("distilbert"),hze=o(" \u2014 "),yk=a("a"),pze=o("DistilBertConfig"),_ze=o(" (DistilBERT model)"),uze=l(),Hf=a("li"),Yoe=a("strong"),bze=o("dpr"),vze=o(" \u2014 "),Lk=a("a"),Fze=o("DPRConfig"),Tze=o(" (DPR model)"),Mze=l(),Uf=a("li"),Koe=a("strong"),Eze=o("dpt"),Cze=o(" \u2014 "),xk=a("a"),wze=o("DPTConfig"),Aze=o(" (DPT model)"),yze=l(),Jf=a("li"),Zoe=a("strong"),Lze=o("electra"),xze=o(" \u2014 "),$k=a("a"),$ze=o("ElectraConfig"),kze=o(" (ELECTRA model)"),Sze=l(),Yf=a("li"),ere=a("strong"),Rze=o("encoder-decoder"),Pze=o(" \u2014 "),kk=a("a"),Bze=o("EncoderDecoderConfig"),Ize=o(" (Encoder decoder model)"),Nze=l(),Kf=a("li"),ore=a("strong"),qze=o("flaubert"),jze=o(" \u2014 "),Sk=a("a"),Dze=o("FlaubertConfig"),Gze=o(" (FlauBERT model)"),Oze=l(),Zf=a("li"),rre=a("strong"),Vze=o("flava"),Xze=o(" \u2014 "),Rk=a("a"),zze=o("FlavaConfig"),Wze=o(" (Flava model)"),Qze=l(),em=a("li"),tre=a("strong"),Hze=o("fnet"),Uze=o(" \u2014 "),Pk=a("a"),Jze=o("FNetConfig"),Yze=o(" (FNet model)"),Kze=l(),om=a("li"),are=a("strong"),Zze=o("fsmt"),eWe=o(" \u2014 "),Bk=a("a"),oWe=o("FSMTConfig"),rWe=o(" (FairSeq Machine-Translation model)"),tWe=l(),rm=a("li"),nre=a("strong"),aWe=o("funnel"),nWe=o(" \u2014 "),Ik=a("a"),sWe=o("FunnelConfig"),lWe=o(" (Funnel Transformer model)"),iWe=l(),tm=a("li"),sre=a("strong"),dWe=o("glpn"),cWe=o(" \u2014 "),Nk=a("a"),fWe=o("GLPNConfig"),mWe=o(" (GLPN model)"),gWe=l(),am=a("li"),lre=a("strong"),hWe=o("gpt2"),pWe=o(" \u2014 "),qk=a("a"),_We=o("GPT2Config"),uWe=o(" (OpenAI GPT-2 model)"),bWe=l(),nm=a("li"),ire=a("strong"),vWe=o("gpt_neo"),FWe=o(" \u2014 "),jk=a("a"),TWe=o("GPTNeoConfig"),MWe=o(" (GPT Neo model)"),EWe=l(),sm=a("li"),dre=a("strong"),CWe=o("gpt_neox"),wWe=o(" \u2014 "),Dk=a("a"),AWe=o("GPTNeoXConfig"),yWe=o(" (GPT NeoX model)"),LWe=l(),lm=a("li"),cre=a("strong"),xWe=o("gptj"),$We=o(" \u2014 "),Gk=a("a"),kWe=o("GPTJConfig"),SWe=o(" (GPT-J model)"),RWe=l(),im=a("li"),fre=a("strong"),PWe=o("hubert"),BWe=o(" \u2014 "),Ok=a("a"),IWe=o("HubertConfig"),NWe=o(" (Hubert model)"),qWe=l(),dm=a("li"),mre=a("strong"),jWe=o("ibert"),DWe=o(" \u2014 "),Vk=a("a"),GWe=o("IBertConfig"),OWe=o(" (I-BERT model)"),VWe=l(),cm=a("li"),gre=a("strong"),XWe=o("imagegpt"),zWe=o(" \u2014 "),Xk=a("a"),WWe=o("ImageGPTConfig"),QWe=o(" (ImageGPT model)"),HWe=l(),fm=a("li"),hre=a("strong"),UWe=o("layoutlm"),JWe=o(" \u2014 "),zk=a("a"),YWe=o("LayoutLMConfig"),KWe=o(" (LayoutLM model)"),ZWe=l(),mm=a("li"),pre=a("strong"),eQe=o("layoutlmv2"),oQe=o(" \u2014 "),Wk=a("a"),rQe=o("LayoutLMv2Config"),tQe=o(" (LayoutLMv2 model)"),aQe=l(),gm=a("li"),_re=a("strong"),nQe=o("layoutlmv3"),sQe=o(" \u2014 "),Qk=a("a"),lQe=o("LayoutLMv3Config"),iQe=o(" (LayoutLMv3 model)"),dQe=l(),hm=a("li"),ure=a("strong"),cQe=o("led"),fQe=o(" \u2014 "),Hk=a("a"),mQe=o("LEDConfig"),gQe=o(" (LED model)"),hQe=l(),pm=a("li"),bre=a("strong"),pQe=o("levit"),_Qe=o(" \u2014 "),Uk=a("a"),uQe=o("LevitConfig"),bQe=o(" (LeViT model)"),vQe=l(),_m=a("li"),vre=a("strong"),FQe=o("longformer"),TQe=o(" \u2014 "),Jk=a("a"),MQe=o("LongformerConfig"),EQe=o(" (Longformer model)"),CQe=l(),um=a("li"),Fre=a("strong"),wQe=o("luke"),AQe=o(" \u2014 "),Yk=a("a"),yQe=o("LukeConfig"),LQe=o(" (LUKE model)"),xQe=l(),bm=a("li"),Tre=a("strong"),$Qe=o("lxmert"),kQe=o(" \u2014 "),Kk=a("a"),SQe=o("LxmertConfig"),RQe=o(" (LXMERT model)"),PQe=l(),vm=a("li"),Mre=a("strong"),BQe=o("m2m_100"),IQe=o(" \u2014 "),Zk=a("a"),NQe=o("M2M100Config"),qQe=o(" (M2M100 model)"),jQe=l(),Fm=a("li"),Ere=a("strong"),DQe=o("marian"),GQe=o(" \u2014 "),eS=a("a"),OQe=o("MarianConfig"),VQe=o(" (Marian model)"),XQe=l(),Tm=a("li"),Cre=a("strong"),zQe=o("maskformer"),WQe=o(" \u2014 "),oS=a("a"),QQe=o("MaskFormerConfig"),HQe=o(" (MaskFormer model)"),UQe=l(),Mm=a("li"),wre=a("strong"),JQe=o("mbart"),YQe=o(" \u2014 "),rS=a("a"),KQe=o("MBartConfig"),ZQe=o(" (mBART model)"),eHe=l(),Em=a("li"),Are=a("strong"),oHe=o("megatron-bert"),rHe=o(" \u2014 "),tS=a("a"),tHe=o("MegatronBertConfig"),aHe=o(" (MegatronBert model)"),nHe=l(),Cm=a("li"),yre=a("strong"),sHe=o("mobilebert"),lHe=o(" \u2014 "),aS=a("a"),iHe=o("MobileBertConfig"),dHe=o(" (MobileBERT model)"),cHe=l(),wm=a("li"),Lre=a("strong"),fHe=o("mpnet"),mHe=o(" \u2014 "),nS=a("a"),gHe=o("MPNetConfig"),hHe=o(" (MPNet model)"),pHe=l(),Am=a("li"),xre=a("strong"),_He=o("mt5"),uHe=o(" \u2014 "),sS=a("a"),bHe=o("MT5Config"),vHe=o(" (mT5 model)"),FHe=l(),ym=a("li"),$re=a("strong"),THe=o("nystromformer"),MHe=o(" \u2014 "),lS=a("a"),EHe=o("NystromformerConfig"),CHe=o(" (Nystromformer model)"),wHe=l(),Lm=a("li"),kre=a("strong"),AHe=o("openai-gpt"),yHe=o(" \u2014 "),iS=a("a"),LHe=o("OpenAIGPTConfig"),xHe=o(" (OpenAI GPT model)"),$He=l(),xm=a("li"),Sre=a("strong"),kHe=o("opt"),SHe=o(" \u2014 "),dS=a("a"),RHe=o("OPTConfig"),PHe=o(" (OPT model)"),BHe=l(),$m=a("li"),Rre=a("strong"),IHe=o("pegasus"),NHe=o(" \u2014 "),cS=a("a"),qHe=o("PegasusConfig"),jHe=o(" (Pegasus model)"),DHe=l(),km=a("li"),Pre=a("strong"),GHe=o("perceiver"),OHe=o(" \u2014 "),fS=a("a"),VHe=o("PerceiverConfig"),XHe=o(" (Perceiver model)"),zHe=l(),Sm=a("li"),Bre=a("strong"),WHe=o("plbart"),QHe=o(" \u2014 "),mS=a("a"),HHe=o("PLBartConfig"),UHe=o(" (PLBart model)"),JHe=l(),Rm=a("li"),Ire=a("strong"),YHe=o("poolformer"),KHe=o(" \u2014 "),gS=a("a"),ZHe=o("PoolFormerConfig"),eUe=o(" (PoolFormer model)"),oUe=l(),Pm=a("li"),Nre=a("strong"),rUe=o("prophetnet"),tUe=o(" \u2014 "),hS=a("a"),aUe=o("ProphetNetConfig"),nUe=o(" (ProphetNet model)"),sUe=l(),Bm=a("li"),qre=a("strong"),lUe=o("qdqbert"),iUe=o(" \u2014 "),pS=a("a"),dUe=o("QDQBertConfig"),cUe=o(" (QDQBert model)"),fUe=l(),Im=a("li"),jre=a("strong"),mUe=o("rag"),gUe=o(" \u2014 "),_S=a("a"),hUe=o("RagConfig"),pUe=o(" (RAG model)"),_Ue=l(),Nm=a("li"),Dre=a("strong"),uUe=o("realm"),bUe=o(" \u2014 "),uS=a("a"),vUe=o("RealmConfig"),FUe=o(" (Realm model)"),TUe=l(),qm=a("li"),Gre=a("strong"),MUe=o("reformer"),EUe=o(" \u2014 "),bS=a("a"),CUe=o("ReformerConfig"),wUe=o(" (Reformer model)"),AUe=l(),jm=a("li"),Ore=a("strong"),yUe=o("regnet"),LUe=o(" \u2014 "),vS=a("a"),xUe=o("RegNetConfig"),$Ue=o(" (RegNet model)"),kUe=l(),Dm=a("li"),Vre=a("strong"),SUe=o("rembert"),RUe=o(" \u2014 "),FS=a("a"),PUe=o("RemBertConfig"),BUe=o(" (RemBERT model)"),IUe=l(),Gm=a("li"),Xre=a("strong"),NUe=o("resnet"),qUe=o(" \u2014 "),TS=a("a"),jUe=o("ResNetConfig"),DUe=o(" (ResNet model)"),GUe=l(),Om=a("li"),zre=a("strong"),OUe=o("retribert"),VUe=o(" \u2014 "),MS=a("a"),XUe=o("RetriBertConfig"),zUe=o(" (RetriBERT model)"),WUe=l(),Vm=a("li"),Wre=a("strong"),QUe=o("roberta"),HUe=o(" \u2014 "),ES=a("a"),UUe=o("RobertaConfig"),JUe=o(" (RoBERTa model)"),YUe=l(),Xm=a("li"),Qre=a("strong"),KUe=o("roformer"),ZUe=o(" \u2014 "),CS=a("a"),eJe=o("RoFormerConfig"),oJe=o(" (RoFormer model)"),rJe=l(),zm=a("li"),Hre=a("strong"),tJe=o("segformer"),aJe=o(" \u2014 "),wS=a("a"),nJe=o("SegformerConfig"),sJe=o(" (SegFormer model)"),lJe=l(),Wm=a("li"),Ure=a("strong"),iJe=o("sew"),dJe=o(" \u2014 "),AS=a("a"),cJe=o("SEWConfig"),fJe=o(" (SEW model)"),mJe=l(),Qm=a("li"),Jre=a("strong"),gJe=o("sew-d"),hJe=o(" \u2014 "),yS=a("a"),pJe=o("SEWDConfig"),_Je=o(" (SEW-D model)"),uJe=l(),Hm=a("li"),Yre=a("strong"),bJe=o("speech-encoder-decoder"),vJe=o(" \u2014 "),LS=a("a"),FJe=o("SpeechEncoderDecoderConfig"),TJe=o(" (Speech Encoder decoder model)"),MJe=l(),Um=a("li"),Kre=a("strong"),EJe=o("speech_to_text"),CJe=o(" \u2014 "),xS=a("a"),wJe=o("Speech2TextConfig"),AJe=o(" (Speech2Text model)"),yJe=l(),Jm=a("li"),Zre=a("strong"),LJe=o("speech_to_text_2"),xJe=o(" \u2014 "),$S=a("a"),$Je=o("Speech2Text2Config"),kJe=o(" (Speech2Text2 model)"),SJe=l(),Ym=a("li"),ete=a("strong"),RJe=o("splinter"),PJe=o(" \u2014 "),kS=a("a"),BJe=o("SplinterConfig"),IJe=o(" (Splinter model)"),NJe=l(),Km=a("li"),ote=a("strong"),qJe=o("squeezebert"),jJe=o(" \u2014 "),SS=a("a"),DJe=o("SqueezeBertConfig"),GJe=o(" (SqueezeBERT model)"),OJe=l(),Zm=a("li"),rte=a("strong"),VJe=o("swin"),XJe=o(" \u2014 "),RS=a("a"),zJe=o("SwinConfig"),WJe=o(" (Swin model)"),QJe=l(),eg=a("li"),tte=a("strong"),HJe=o("t5"),UJe=o(" \u2014 "),PS=a("a"),JJe=o("T5Config"),YJe=o(" (T5 model)"),KJe=l(),og=a("li"),ate=a("strong"),ZJe=o("tapas"),eYe=o(" \u2014 "),BS=a("a"),oYe=o("TapasConfig"),rYe=o(" (TAPAS model)"),tYe=l(),rg=a("li"),nte=a("strong"),aYe=o("trajectory_transformer"),nYe=o(" \u2014 "),IS=a("a"),sYe=o("TrajectoryTransformerConfig"),lYe=o(" (Trajectory Transformer model)"),iYe=l(),tg=a("li"),ste=a("strong"),dYe=o("transfo-xl"),cYe=o(" \u2014 "),NS=a("a"),fYe=o("TransfoXLConfig"),mYe=o(" (Transformer-XL model)"),gYe=l(),ag=a("li"),lte=a("strong"),hYe=o("trocr"),pYe=o(" \u2014 "),qS=a("a"),_Ye=o("TrOCRConfig"),uYe=o(" (TrOCR model)"),bYe=l(),ng=a("li"),ite=a("strong"),vYe=o("unispeech"),FYe=o(" \u2014 "),jS=a("a"),TYe=o("UniSpeechConfig"),MYe=o(" (UniSpeech model)"),EYe=l(),sg=a("li"),dte=a("strong"),CYe=o("unispeech-sat"),wYe=o(" \u2014 "),DS=a("a"),AYe=o("UniSpeechSatConfig"),yYe=o(" (UniSpeechSat model)"),LYe=l(),lg=a("li"),cte=a("strong"),xYe=o("van"),$Ye=o(" \u2014 "),GS=a("a"),kYe=o("VanConfig"),SYe=o(" (VAN model)"),RYe=l(),ig=a("li"),fte=a("strong"),PYe=o("vilt"),BYe=o(" \u2014 "),OS=a("a"),IYe=o("ViltConfig"),NYe=o(" (ViLT model)"),qYe=l(),dg=a("li"),mte=a("strong"),jYe=o("vision-encoder-decoder"),DYe=o(" \u2014 "),VS=a("a"),GYe=o("VisionEncoderDecoderConfig"),OYe=o(" (Vision Encoder decoder model)"),VYe=l(),cg=a("li"),gte=a("strong"),XYe=o("vision-text-dual-encoder"),zYe=o(" \u2014 "),XS=a("a"),WYe=o("VisionTextDualEncoderConfig"),QYe=o(" (VisionTextDualEncoder model)"),HYe=l(),fg=a("li"),hte=a("strong"),UYe=o("visual_bert"),JYe=o(" \u2014 "),zS=a("a"),YYe=o("VisualBertConfig"),KYe=o(" (VisualBert model)"),ZYe=l(),mg=a("li"),pte=a("strong"),eKe=o("vit"),oKe=o(" \u2014 "),WS=a("a"),rKe=o("ViTConfig"),tKe=o(" (ViT model)"),aKe=l(),gg=a("li"),_te=a("strong"),nKe=o("vit_mae"),sKe=o(" \u2014 "),QS=a("a"),lKe=o("ViTMAEConfig"),iKe=o(" (ViTMAE model)"),dKe=l(),hg=a("li"),ute=a("strong"),cKe=o("wav2vec2"),fKe=o(" \u2014 "),HS=a("a"),mKe=o("Wav2Vec2Config"),gKe=o(" (Wav2Vec2 model)"),hKe=l(),pg=a("li"),bte=a("strong"),pKe=o("wav2vec2-conformer"),_Ke=o(" \u2014 "),US=a("a"),uKe=o("Wav2Vec2ConformerConfig"),bKe=o(" (Wav2Vec2-Conformer model)"),vKe=l(),_g=a("li"),vte=a("strong"),FKe=o("wavlm"),TKe=o(" \u2014 "),JS=a("a"),MKe=o("WavLMConfig"),EKe=o(" (WavLM model)"),CKe=l(),ug=a("li"),Fte=a("strong"),wKe=o("xglm"),AKe=o(" \u2014 "),YS=a("a"),yKe=o("XGLMConfig"),LKe=o(" (XGLM model)"),xKe=l(),bg=a("li"),Tte=a("strong"),$Ke=o("xlm"),kKe=o(" \u2014 "),KS=a("a"),SKe=o("XLMConfig"),RKe=o(" (XLM model)"),PKe=l(),vg=a("li"),Mte=a("strong"),BKe=o("xlm-prophetnet"),IKe=o(" \u2014 "),ZS=a("a"),NKe=o("XLMProphetNetConfig"),qKe=o(" (XLMProphetNet model)"),jKe=l(),Fg=a("li"),Ete=a("strong"),DKe=o("xlm-roberta"),GKe=o(" \u2014 "),eR=a("a"),OKe=o("XLMRobertaConfig"),VKe=o(" (XLM-RoBERTa model)"),XKe=l(),Tg=a("li"),Cte=a("strong"),zKe=o("xlm-roberta-xl"),WKe=o(" \u2014 "),oR=a("a"),QKe=o("XLMRobertaXLConfig"),HKe=o(" (XLM-RoBERTa-XL model)"),UKe=l(),Mg=a("li"),wte=a("strong"),JKe=o("xlnet"),YKe=o(" \u2014 "),rR=a("a"),KKe=o("XLNetConfig"),ZKe=o(" (XLNet model)"),eZe=l(),Eg=a("li"),Ate=a("strong"),oZe=o("yolos"),rZe=o(" \u2014 "),tR=a("a"),tZe=o("YolosConfig"),aZe=o(" (YOLOS model)"),nZe=l(),Cg=a("li"),yte=a("strong"),sZe=o("yoso"),lZe=o(" \u2014 "),aR=a("a"),iZe=o("YosoConfig"),dZe=o(" (YOSO model)"),cZe=l(),F(wg.$$.fragment),fZe=l(),Ag=a("div"),F(qA.$$.fragment),mZe=l(),Lte=a("p"),gZe=o("Register a new configuration for this class."),Mqe=l(),Mi=a("h2"),yg=a("a"),xte=a("span"),F(jA.$$.fragment),hZe=l(),$te=a("span"),pZe=o("AutoTokenizer"),Eqe=l(),wo=a("div"),F(DA.$$.fragment),_Ze=l(),GA=a("p"),uZe=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),nR=a("a"),bZe=o("AutoTokenizer.from_pretrained()"),vZe=o(" class method."),FZe=l(),OA=a("p"),TZe=o("This class cannot be instantiated directly using "),kte=a("code"),MZe=o("__init__()"),EZe=o(" (throws an error)."),CZe=l(),Cr=a("div"),F(VA.$$.fragment),wZe=l(),Ste=a("p"),AZe=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),yZe=l(),Aa=a("p"),LZe=o("The tokenizer class to instantiate is selected based on the "),Rte=a("code"),xZe=o("model_type"),$Ze=o(` property of the config object (either
passed as an argument or loaded from `),Pte=a("code"),kZe=o("pretrained_model_name_or_path"),SZe=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bte=a("code"),RZe=o("pretrained_model_name_or_path"),PZe=o(":"),BZe=l(),k=a("ul"),Sn=a("li"),Ite=a("strong"),IZe=o("albert"),NZe=o(" \u2014 "),sR=a("a"),qZe=o("AlbertTokenizer"),jZe=o(" or "),lR=a("a"),DZe=o("AlbertTokenizerFast"),GZe=o(" (ALBERT model)"),OZe=l(),Rn=a("li"),Nte=a("strong"),VZe=o("bart"),XZe=o(" \u2014 "),iR=a("a"),zZe=o("BartTokenizer"),WZe=o(" or "),dR=a("a"),QZe=o("BartTokenizerFast"),HZe=o(" (BART model)"),UZe=l(),Pn=a("li"),qte=a("strong"),JZe=o("barthez"),YZe=o(" \u2014 "),cR=a("a"),KZe=o("BarthezTokenizer"),ZZe=o(" or "),fR=a("a"),eeo=o("BarthezTokenizerFast"),oeo=o(" (BARThez model)"),reo=l(),Lg=a("li"),jte=a("strong"),teo=o("bartpho"),aeo=o(" \u2014 "),mR=a("a"),neo=o("BartphoTokenizer"),seo=o(" (BARTpho model)"),leo=l(),Bn=a("li"),Dte=a("strong"),ieo=o("bert"),deo=o(" \u2014 "),gR=a("a"),ceo=o("BertTokenizer"),feo=o(" or "),hR=a("a"),meo=o("BertTokenizerFast"),geo=o(" (BERT model)"),heo=l(),xg=a("li"),Gte=a("strong"),peo=o("bert-generation"),_eo=o(" \u2014 "),pR=a("a"),ueo=o("BertGenerationTokenizer"),beo=o(" (Bert Generation model)"),veo=l(),$g=a("li"),Ote=a("strong"),Feo=o("bert-japanese"),Teo=o(" \u2014 "),_R=a("a"),Meo=o("BertJapaneseTokenizer"),Eeo=o(" (BertJapanese model)"),Ceo=l(),kg=a("li"),Vte=a("strong"),weo=o("bertweet"),Aeo=o(" \u2014 "),uR=a("a"),yeo=o("BertweetTokenizer"),Leo=o(" (Bertweet model)"),xeo=l(),In=a("li"),Xte=a("strong"),$eo=o("big_bird"),keo=o(" \u2014 "),bR=a("a"),Seo=o("BigBirdTokenizer"),Reo=o(" or "),vR=a("a"),Peo=o("BigBirdTokenizerFast"),Beo=o(" (BigBird model)"),Ieo=l(),Nn=a("li"),zte=a("strong"),Neo=o("bigbird_pegasus"),qeo=o(" \u2014 "),FR=a("a"),jeo=o("PegasusTokenizer"),Deo=o(" or "),TR=a("a"),Geo=o("PegasusTokenizerFast"),Oeo=o(" (BigBirdPegasus model)"),Veo=l(),qn=a("li"),Wte=a("strong"),Xeo=o("blenderbot"),zeo=o(" \u2014 "),MR=a("a"),Weo=o("BlenderbotTokenizer"),Qeo=o(" or "),ER=a("a"),Heo=o("BlenderbotTokenizerFast"),Ueo=o(" (Blenderbot model)"),Jeo=l(),Sg=a("li"),Qte=a("strong"),Yeo=o("blenderbot-small"),Keo=o(" \u2014 "),CR=a("a"),Zeo=o("BlenderbotSmallTokenizer"),eoo=o(" (BlenderbotSmall model)"),ooo=l(),Rg=a("li"),Hte=a("strong"),roo=o("byt5"),too=o(" \u2014 "),wR=a("a"),aoo=o("ByT5Tokenizer"),noo=o(" (ByT5 model)"),soo=l(),jn=a("li"),Ute=a("strong"),loo=o("camembert"),ioo=o(" \u2014 "),AR=a("a"),doo=o("CamembertTokenizer"),coo=o(" or "),yR=a("a"),foo=o("CamembertTokenizerFast"),moo=o(" (CamemBERT model)"),goo=l(),Pg=a("li"),Jte=a("strong"),hoo=o("canine"),poo=o(" \u2014 "),LR=a("a"),_oo=o("CanineTokenizer"),uoo=o(" (Canine model)"),boo=l(),Dn=a("li"),Yte=a("strong"),voo=o("clip"),Foo=o(" \u2014 "),xR=a("a"),Too=o("CLIPTokenizer"),Moo=o(" or "),$R=a("a"),Eoo=o("CLIPTokenizerFast"),Coo=o(" (CLIP model)"),woo=l(),Gn=a("li"),Kte=a("strong"),Aoo=o("convbert"),yoo=o(" \u2014 "),kR=a("a"),Loo=o("ConvBertTokenizer"),xoo=o(" or "),SR=a("a"),$oo=o("ConvBertTokenizerFast"),koo=o(" (ConvBERT model)"),Soo=l(),On=a("li"),Zte=a("strong"),Roo=o("cpm"),Poo=o(" \u2014 "),RR=a("a"),Boo=o("CpmTokenizer"),Ioo=o(" or "),PR=a("a"),Noo=o("CpmTokenizerFast"),qoo=o(" (CPM model)"),joo=l(),Bg=a("li"),eae=a("strong"),Doo=o("ctrl"),Goo=o(" \u2014 "),BR=a("a"),Ooo=o("CTRLTokenizer"),Voo=o(" (CTRL model)"),Xoo=l(),Vn=a("li"),oae=a("strong"),zoo=o("data2vec-text"),Woo=o(" \u2014 "),IR=a("a"),Qoo=o("RobertaTokenizer"),Hoo=o(" or "),NR=a("a"),Uoo=o("RobertaTokenizerFast"),Joo=o(" (Data2VecText model)"),Yoo=l(),Xn=a("li"),rae=a("strong"),Koo=o("deberta"),Zoo=o(" \u2014 "),qR=a("a"),ero=o("DebertaTokenizer"),oro=o(" or "),jR=a("a"),rro=o("DebertaTokenizerFast"),tro=o(" (DeBERTa model)"),aro=l(),zn=a("li"),tae=a("strong"),nro=o("deberta-v2"),sro=o(" \u2014 "),DR=a("a"),lro=o("DebertaV2Tokenizer"),iro=o(" or "),GR=a("a"),dro=o("DebertaV2TokenizerFast"),cro=o(" (DeBERTa-v2 model)"),fro=l(),Wn=a("li"),aae=a("strong"),mro=o("distilbert"),gro=o(" \u2014 "),OR=a("a"),hro=o("DistilBertTokenizer"),pro=o(" or "),VR=a("a"),_ro=o("DistilBertTokenizerFast"),uro=o(" (DistilBERT model)"),bro=l(),Qn=a("li"),nae=a("strong"),vro=o("dpr"),Fro=o(" \u2014 "),XR=a("a"),Tro=o("DPRQuestionEncoderTokenizer"),Mro=o(" or "),zR=a("a"),Ero=o("DPRQuestionEncoderTokenizerFast"),Cro=o(" (DPR model)"),wro=l(),Hn=a("li"),sae=a("strong"),Aro=o("electra"),yro=o(" \u2014 "),WR=a("a"),Lro=o("ElectraTokenizer"),xro=o(" or "),QR=a("a"),$ro=o("ElectraTokenizerFast"),kro=o(" (ELECTRA model)"),Sro=l(),Ig=a("li"),lae=a("strong"),Rro=o("flaubert"),Pro=o(" \u2014 "),HR=a("a"),Bro=o("FlaubertTokenizer"),Iro=o(" (FlauBERT model)"),Nro=l(),Un=a("li"),iae=a("strong"),qro=o("fnet"),jro=o(" \u2014 "),UR=a("a"),Dro=o("FNetTokenizer"),Gro=o(" or "),JR=a("a"),Oro=o("FNetTokenizerFast"),Vro=o(" (FNet model)"),Xro=l(),Ng=a("li"),dae=a("strong"),zro=o("fsmt"),Wro=o(" \u2014 "),YR=a("a"),Qro=o("FSMTTokenizer"),Hro=o(" (FairSeq Machine-Translation model)"),Uro=l(),Jn=a("li"),cae=a("strong"),Jro=o("funnel"),Yro=o(" \u2014 "),KR=a("a"),Kro=o("FunnelTokenizer"),Zro=o(" or "),ZR=a("a"),eto=o("FunnelTokenizerFast"),oto=o(" (Funnel Transformer model)"),rto=l(),Yn=a("li"),fae=a("strong"),tto=o("gpt2"),ato=o(" \u2014 "),eP=a("a"),nto=o("GPT2Tokenizer"),sto=o(" or "),oP=a("a"),lto=o("GPT2TokenizerFast"),ito=o(" (OpenAI GPT-2 model)"),dto=l(),Kn=a("li"),mae=a("strong"),cto=o("gpt_neo"),fto=o(" \u2014 "),rP=a("a"),mto=o("GPT2Tokenizer"),gto=o(" or "),tP=a("a"),hto=o("GPT2TokenizerFast"),pto=o(" (GPT Neo model)"),_to=l(),qg=a("li"),gae=a("strong"),uto=o("gpt_neox"),bto=o(" \u2014 "),aP=a("a"),vto=o("GPTNeoXTokenizerFast"),Fto=o(" (GPT NeoX model)"),Tto=l(),Zn=a("li"),hae=a("strong"),Mto=o("gptj"),Eto=o(" \u2014 "),nP=a("a"),Cto=o("GPT2Tokenizer"),wto=o(" or "),sP=a("a"),Ato=o("GPT2TokenizerFast"),yto=o(" (GPT-J model)"),Lto=l(),es=a("li"),pae=a("strong"),xto=o("herbert"),$to=o(" \u2014 "),lP=a("a"),kto=o("HerbertTokenizer"),Sto=o(" or "),iP=a("a"),Rto=o("HerbertTokenizerFast"),Pto=o(" (HerBERT model)"),Bto=l(),jg=a("li"),_ae=a("strong"),Ito=o("hubert"),Nto=o(" \u2014 "),dP=a("a"),qto=o("Wav2Vec2CTCTokenizer"),jto=o(" (Hubert model)"),Dto=l(),os=a("li"),uae=a("strong"),Gto=o("ibert"),Oto=o(" \u2014 "),cP=a("a"),Vto=o("RobertaTokenizer"),Xto=o(" or "),fP=a("a"),zto=o("RobertaTokenizerFast"),Wto=o(" (I-BERT model)"),Qto=l(),rs=a("li"),bae=a("strong"),Hto=o("layoutlm"),Uto=o(" \u2014 "),mP=a("a"),Jto=o("LayoutLMTokenizer"),Yto=o(" or "),gP=a("a"),Kto=o("LayoutLMTokenizerFast"),Zto=o(" (LayoutLM model)"),eao=l(),ts=a("li"),vae=a("strong"),oao=o("layoutlmv2"),rao=o(" \u2014 "),hP=a("a"),tao=o("LayoutLMv2Tokenizer"),aao=o(" or "),pP=a("a"),nao=o("LayoutLMv2TokenizerFast"),sao=o(" (LayoutLMv2 model)"),lao=l(),as=a("li"),Fae=a("strong"),iao=o("layoutlmv3"),dao=o(" \u2014 "),_P=a("a"),cao=o("LayoutLMv3Tokenizer"),fao=o(" or "),uP=a("a"),mao=o("LayoutLMv3TokenizerFast"),gao=o(" (LayoutLMv3 model)"),hao=l(),ns=a("li"),Tae=a("strong"),pao=o("layoutxlm"),_ao=o(" \u2014 "),bP=a("a"),uao=o("LayoutXLMTokenizer"),bao=o(" or "),vP=a("a"),vao=o("LayoutXLMTokenizerFast"),Fao=o(" (LayoutXLM model)"),Tao=l(),ss=a("li"),Mae=a("strong"),Mao=o("led"),Eao=o(" \u2014 "),FP=a("a"),Cao=o("LEDTokenizer"),wao=o(" or "),TP=a("a"),Aao=o("LEDTokenizerFast"),yao=o(" (LED model)"),Lao=l(),ls=a("li"),Eae=a("strong"),xao=o("longformer"),$ao=o(" \u2014 "),MP=a("a"),kao=o("LongformerTokenizer"),Sao=o(" or "),EP=a("a"),Rao=o("LongformerTokenizerFast"),Pao=o(" (Longformer model)"),Bao=l(),Dg=a("li"),Cae=a("strong"),Iao=o("luke"),Nao=o(" \u2014 "),CP=a("a"),qao=o("LukeTokenizer"),jao=o(" (LUKE model)"),Dao=l(),is=a("li"),wae=a("strong"),Gao=o("lxmert"),Oao=o(" \u2014 "),wP=a("a"),Vao=o("LxmertTokenizer"),Xao=o(" or "),AP=a("a"),zao=o("LxmertTokenizerFast"),Wao=o(" (LXMERT model)"),Qao=l(),Gg=a("li"),Aae=a("strong"),Hao=o("m2m_100"),Uao=o(" \u2014 "),yP=a("a"),Jao=o("M2M100Tokenizer"),Yao=o(" (M2M100 model)"),Kao=l(),Og=a("li"),yae=a("strong"),Zao=o("marian"),eno=o(" \u2014 "),LP=a("a"),ono=o("MarianTokenizer"),rno=o(" (Marian model)"),tno=l(),ds=a("li"),Lae=a("strong"),ano=o("mbart"),nno=o(" \u2014 "),xP=a("a"),sno=o("MBartTokenizer"),lno=o(" or "),$P=a("a"),ino=o("MBartTokenizerFast"),dno=o(" (mBART model)"),cno=l(),cs=a("li"),xae=a("strong"),fno=o("mbart50"),mno=o(" \u2014 "),kP=a("a"),gno=o("MBart50Tokenizer"),hno=o(" or "),SP=a("a"),pno=o("MBart50TokenizerFast"),_no=o(" (mBART-50 model)"),uno=l(),fs=a("li"),$ae=a("strong"),bno=o("megatron-bert"),vno=o(" \u2014 "),RP=a("a"),Fno=o("BertTokenizer"),Tno=o(" or "),PP=a("a"),Mno=o("BertTokenizerFast"),Eno=o(" (MegatronBert model)"),Cno=l(),Vg=a("li"),kae=a("strong"),wno=o("mluke"),Ano=o(" \u2014 "),BP=a("a"),yno=o("MLukeTokenizer"),Lno=o(" (mLUKE model)"),xno=l(),ms=a("li"),Sae=a("strong"),$no=o("mobilebert"),kno=o(" \u2014 "),IP=a("a"),Sno=o("MobileBertTokenizer"),Rno=o(" or "),NP=a("a"),Pno=o("MobileBertTokenizerFast"),Bno=o(" (MobileBERT model)"),Ino=l(),gs=a("li"),Rae=a("strong"),Nno=o("mpnet"),qno=o(" \u2014 "),qP=a("a"),jno=o("MPNetTokenizer"),Dno=o(" or "),jP=a("a"),Gno=o("MPNetTokenizerFast"),Ono=o(" (MPNet model)"),Vno=l(),hs=a("li"),Pae=a("strong"),Xno=o("mt5"),zno=o(" \u2014 "),DP=a("a"),Wno=o("MT5Tokenizer"),Qno=o(" or "),GP=a("a"),Hno=o("MT5TokenizerFast"),Uno=o(" (mT5 model)"),Jno=l(),ps=a("li"),Bae=a("strong"),Yno=o("nystromformer"),Kno=o(" \u2014 "),OP=a("a"),Zno=o("AlbertTokenizer"),eso=o(" or "),VP=a("a"),oso=o("AlbertTokenizerFast"),rso=o(" (Nystromformer model)"),tso=l(),_s=a("li"),Iae=a("strong"),aso=o("openai-gpt"),nso=o(" \u2014 "),XP=a("a"),sso=o("OpenAIGPTTokenizer"),lso=o(" or "),zP=a("a"),iso=o("OpenAIGPTTokenizerFast"),dso=o(" (OpenAI GPT model)"),cso=l(),Xg=a("li"),Nae=a("strong"),fso=o("opt"),mso=o(" \u2014 "),WP=a("a"),gso=o("GPT2Tokenizer"),hso=o(" (OPT model)"),pso=l(),us=a("li"),qae=a("strong"),_so=o("pegasus"),uso=o(" \u2014 "),QP=a("a"),bso=o("PegasusTokenizer"),vso=o(" or "),HP=a("a"),Fso=o("PegasusTokenizerFast"),Tso=o(" (Pegasus model)"),Mso=l(),zg=a("li"),jae=a("strong"),Eso=o("perceiver"),Cso=o(" \u2014 "),UP=a("a"),wso=o("PerceiverTokenizer"),Aso=o(" (Perceiver model)"),yso=l(),Wg=a("li"),Dae=a("strong"),Lso=o("phobert"),xso=o(" \u2014 "),JP=a("a"),$so=o("PhobertTokenizer"),kso=o(" (PhoBERT model)"),Sso=l(),Qg=a("li"),Gae=a("strong"),Rso=o("plbart"),Pso=o(" \u2014 "),YP=a("a"),Bso=o("PLBartTokenizer"),Iso=o(" (PLBart model)"),Nso=l(),Hg=a("li"),Oae=a("strong"),qso=o("prophetnet"),jso=o(" \u2014 "),KP=a("a"),Dso=o("ProphetNetTokenizer"),Gso=o(" (ProphetNet model)"),Oso=l(),bs=a("li"),Vae=a("strong"),Vso=o("qdqbert"),Xso=o(" \u2014 "),ZP=a("a"),zso=o("BertTokenizer"),Wso=o(" or "),eB=a("a"),Qso=o("BertTokenizerFast"),Hso=o(" (QDQBert model)"),Uso=l(),Ug=a("li"),Xae=a("strong"),Jso=o("rag"),Yso=o(" \u2014 "),oB=a("a"),Kso=o("RagTokenizer"),Zso=o(" (RAG model)"),elo=l(),vs=a("li"),zae=a("strong"),olo=o("realm"),rlo=o(" \u2014 "),rB=a("a"),tlo=o("RealmTokenizer"),alo=o(" or "),tB=a("a"),nlo=o("RealmTokenizerFast"),slo=o(" (Realm model)"),llo=l(),Fs=a("li"),Wae=a("strong"),ilo=o("reformer"),dlo=o(" \u2014 "),aB=a("a"),clo=o("ReformerTokenizer"),flo=o(" or "),nB=a("a"),mlo=o("ReformerTokenizerFast"),glo=o(" (Reformer model)"),hlo=l(),Ts=a("li"),Qae=a("strong"),plo=o("rembert"),_lo=o(" \u2014 "),sB=a("a"),ulo=o("RemBertTokenizer"),blo=o(" or "),lB=a("a"),vlo=o("RemBertTokenizerFast"),Flo=o(" (RemBERT model)"),Tlo=l(),Ms=a("li"),Hae=a("strong"),Mlo=o("retribert"),Elo=o(" \u2014 "),iB=a("a"),Clo=o("RetriBertTokenizer"),wlo=o(" or "),dB=a("a"),Alo=o("RetriBertTokenizerFast"),ylo=o(" (RetriBERT model)"),Llo=l(),Es=a("li"),Uae=a("strong"),xlo=o("roberta"),$lo=o(" \u2014 "),cB=a("a"),klo=o("RobertaTokenizer"),Slo=o(" or "),fB=a("a"),Rlo=o("RobertaTokenizerFast"),Plo=o(" (RoBERTa model)"),Blo=l(),Cs=a("li"),Jae=a("strong"),Ilo=o("roformer"),Nlo=o(" \u2014 "),mB=a("a"),qlo=o("RoFormerTokenizer"),jlo=o(" or "),gB=a("a"),Dlo=o("RoFormerTokenizerFast"),Glo=o(" (RoFormer model)"),Olo=l(),Jg=a("li"),Yae=a("strong"),Vlo=o("speech_to_text"),Xlo=o(" \u2014 "),hB=a("a"),zlo=o("Speech2TextTokenizer"),Wlo=o(" (Speech2Text model)"),Qlo=l(),Yg=a("li"),Kae=a("strong"),Hlo=o("speech_to_text_2"),Ulo=o(" \u2014 "),pB=a("a"),Jlo=o("Speech2Text2Tokenizer"),Ylo=o(" (Speech2Text2 model)"),Klo=l(),ws=a("li"),Zae=a("strong"),Zlo=o("splinter"),eio=o(" \u2014 "),_B=a("a"),oio=o("SplinterTokenizer"),rio=o(" or "),uB=a("a"),tio=o("SplinterTokenizerFast"),aio=o(" (Splinter model)"),nio=l(),As=a("li"),ene=a("strong"),sio=o("squeezebert"),lio=o(" \u2014 "),bB=a("a"),iio=o("SqueezeBertTokenizer"),dio=o(" or "),vB=a("a"),cio=o("SqueezeBertTokenizerFast"),fio=o(" (SqueezeBERT model)"),mio=l(),ys=a("li"),one=a("strong"),gio=o("t5"),hio=o(" \u2014 "),FB=a("a"),pio=o("T5Tokenizer"),_io=o(" or "),TB=a("a"),uio=o("T5TokenizerFast"),bio=o(" (T5 model)"),vio=l(),Kg=a("li"),rne=a("strong"),Fio=o("tapas"),Tio=o(" \u2014 "),MB=a("a"),Mio=o("TapasTokenizer"),Eio=o(" (TAPAS model)"),Cio=l(),Zg=a("li"),tne=a("strong"),wio=o("tapex"),Aio=o(" \u2014 "),EB=a("a"),yio=o("TapexTokenizer"),Lio=o(" (TAPEX model)"),xio=l(),eh=a("li"),ane=a("strong"),$io=o("transfo-xl"),kio=o(" \u2014 "),CB=a("a"),Sio=o("TransfoXLTokenizer"),Rio=o(" (Transformer-XL model)"),Pio=l(),Ls=a("li"),nne=a("strong"),Bio=o("visual_bert"),Iio=o(" \u2014 "),wB=a("a"),Nio=o("BertTokenizer"),qio=o(" or "),AB=a("a"),jio=o("BertTokenizerFast"),Dio=o(" (VisualBert model)"),Gio=l(),oh=a("li"),sne=a("strong"),Oio=o("wav2vec2"),Vio=o(" \u2014 "),yB=a("a"),Xio=o("Wav2Vec2CTCTokenizer"),zio=o(" (Wav2Vec2 model)"),Wio=l(),rh=a("li"),lne=a("strong"),Qio=o("wav2vec2-conformer"),Hio=o(" \u2014 "),LB=a("a"),Uio=o("Wav2Vec2CTCTokenizer"),Jio=o(" (Wav2Vec2-Conformer model)"),Yio=l(),th=a("li"),ine=a("strong"),Kio=o("wav2vec2_phoneme"),Zio=o(" \u2014 "),xB=a("a"),edo=o("Wav2Vec2PhonemeCTCTokenizer"),odo=o(" (Wav2Vec2Phoneme model)"),rdo=l(),xs=a("li"),dne=a("strong"),tdo=o("xglm"),ado=o(" \u2014 "),$B=a("a"),ndo=o("XGLMTokenizer"),sdo=o(" or "),kB=a("a"),ldo=o("XGLMTokenizerFast"),ido=o(" (XGLM model)"),ddo=l(),ah=a("li"),cne=a("strong"),cdo=o("xlm"),fdo=o(" \u2014 "),SB=a("a"),mdo=o("XLMTokenizer"),gdo=o(" (XLM model)"),hdo=l(),nh=a("li"),fne=a("strong"),pdo=o("xlm-prophetnet"),_do=o(" \u2014 "),RB=a("a"),udo=o("XLMProphetNetTokenizer"),bdo=o(" (XLMProphetNet model)"),vdo=l(),$s=a("li"),mne=a("strong"),Fdo=o("xlm-roberta"),Tdo=o(" \u2014 "),PB=a("a"),Mdo=o("XLMRobertaTokenizer"),Edo=o(" or "),BB=a("a"),Cdo=o("XLMRobertaTokenizerFast"),wdo=o(" (XLM-RoBERTa model)"),Ado=l(),ks=a("li"),gne=a("strong"),ydo=o("xlm-roberta-xl"),Ldo=o(" \u2014 "),IB=a("a"),xdo=o("RobertaTokenizer"),$do=o(" or "),NB=a("a"),kdo=o("RobertaTokenizerFast"),Sdo=o(" (XLM-RoBERTa-XL model)"),Rdo=l(),Ss=a("li"),hne=a("strong"),Pdo=o("xlnet"),Bdo=o(" \u2014 "),qB=a("a"),Ido=o("XLNetTokenizer"),Ndo=o(" or "),jB=a("a"),qdo=o("XLNetTokenizerFast"),jdo=o(" (XLNet model)"),Ddo=l(),Rs=a("li"),pne=a("strong"),Gdo=o("yoso"),Odo=o(" \u2014 "),DB=a("a"),Vdo=o("AlbertTokenizer"),Xdo=o(" or "),GB=a("a"),zdo=o("AlbertTokenizerFast"),Wdo=o(" (YOSO model)"),Qdo=l(),F(sh.$$.fragment),Hdo=l(),lh=a("div"),F(XA.$$.fragment),Udo=l(),_ne=a("p"),Jdo=o("Register a new tokenizer in this mapping."),Cqe=l(),Ei=a("h2"),ih=a("a"),une=a("span"),F(zA.$$.fragment),Ydo=l(),bne=a("span"),Kdo=o("AutoFeatureExtractor"),wqe=l(),Ao=a("div"),F(WA.$$.fragment),Zdo=l(),QA=a("p"),eco=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),OB=a("a"),oco=o("AutoFeatureExtractor.from_pretrained()"),rco=o(" class method."),tco=l(),HA=a("p"),aco=o("This class cannot be instantiated directly using "),vne=a("code"),nco=o("__init__()"),sco=o(" (throws an error)."),lco=l(),He=a("div"),F(UA.$$.fragment),ico=l(),Fne=a("p"),dco=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),cco=l(),ya=a("p"),fco=o("The feature extractor class to instantiate is selected based on the "),Tne=a("code"),mco=o("model_type"),gco=o(` property of the config object
(either passed as an argument or loaded from `),Mne=a("code"),hco=o("pretrained_model_name_or_path"),pco=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Ene=a("code"),_co=o("pretrained_model_name_or_path"),uco=o(":"),bco=l(),Y=a("ul"),dh=a("li"),Cne=a("strong"),vco=o("beit"),Fco=o(" \u2014 "),VB=a("a"),Tco=o("BeitFeatureExtractor"),Mco=o(" (BEiT model)"),Eco=l(),ch=a("li"),wne=a("strong"),Cco=o("clip"),wco=o(" \u2014 "),XB=a("a"),Aco=o("CLIPFeatureExtractor"),yco=o(" (CLIP model)"),Lco=l(),fh=a("li"),Ane=a("strong"),xco=o("convnext"),$co=o(" \u2014 "),zB=a("a"),kco=o("ConvNextFeatureExtractor"),Sco=o(" (ConvNext model)"),Rco=l(),mh=a("li"),yne=a("strong"),Pco=o("cvt"),Bco=o(" \u2014 "),WB=a("a"),Ico=o("ConvNextFeatureExtractor"),Nco=o(" (CvT model)"),qco=l(),gh=a("li"),Lne=a("strong"),jco=o("data2vec-audio"),Dco=o(" \u2014 "),QB=a("a"),Gco=o("Wav2Vec2FeatureExtractor"),Oco=o(" (Data2VecAudio model)"),Vco=l(),hh=a("li"),xne=a("strong"),Xco=o("data2vec-vision"),zco=o(" \u2014 "),HB=a("a"),Wco=o("BeitFeatureExtractor"),Qco=o(" (Data2VecVision model)"),Hco=l(),ph=a("li"),$ne=a("strong"),Uco=o("deit"),Jco=o(" \u2014 "),UB=a("a"),Yco=o("DeiTFeatureExtractor"),Kco=o(" (DeiT model)"),Zco=l(),_h=a("li"),kne=a("strong"),efo=o("detr"),ofo=o(" \u2014 "),JB=a("a"),rfo=o("DetrFeatureExtractor"),tfo=o(" (DETR model)"),afo=l(),uh=a("li"),Sne=a("strong"),nfo=o("dpt"),sfo=o(" \u2014 "),YB=a("a"),lfo=o("DPTFeatureExtractor"),ifo=o(" (DPT model)"),dfo=l(),bh=a("li"),Rne=a("strong"),cfo=o("flava"),ffo=o(" \u2014 "),KB=a("a"),mfo=o("FlavaFeatureExtractor"),gfo=o(" (Flava model)"),hfo=l(),vh=a("li"),Pne=a("strong"),pfo=o("glpn"),_fo=o(" \u2014 "),ZB=a("a"),ufo=o("GLPNFeatureExtractor"),bfo=o(" (GLPN model)"),vfo=l(),Fh=a("li"),Bne=a("strong"),Ffo=o("hubert"),Tfo=o(" \u2014 "),eI=a("a"),Mfo=o("Wav2Vec2FeatureExtractor"),Efo=o(" (Hubert model)"),Cfo=l(),Th=a("li"),Ine=a("strong"),wfo=o("imagegpt"),Afo=o(" \u2014 "),oI=a("a"),yfo=o("ImageGPTFeatureExtractor"),Lfo=o(" (ImageGPT model)"),xfo=l(),Mh=a("li"),Nne=a("strong"),$fo=o("layoutlmv2"),kfo=o(" \u2014 "),rI=a("a"),Sfo=o("LayoutLMv2FeatureExtractor"),Rfo=o(" (LayoutLMv2 model)"),Pfo=l(),Eh=a("li"),qne=a("strong"),Bfo=o("layoutlmv3"),Ifo=o(" \u2014 "),tI=a("a"),Nfo=o("LayoutLMv3FeatureExtractor"),qfo=o(" (LayoutLMv3 model)"),jfo=l(),Ch=a("li"),jne=a("strong"),Dfo=o("levit"),Gfo=o(" \u2014 "),aI=a("a"),Ofo=o("LevitFeatureExtractor"),Vfo=o(" (LeViT model)"),Xfo=l(),wh=a("li"),Dne=a("strong"),zfo=o("maskformer"),Wfo=o(" \u2014 "),nI=a("a"),Qfo=o("MaskFormerFeatureExtractor"),Hfo=o(" (MaskFormer model)"),Ufo=l(),Ah=a("li"),Gne=a("strong"),Jfo=o("perceiver"),Yfo=o(" \u2014 "),sI=a("a"),Kfo=o("PerceiverFeatureExtractor"),Zfo=o(" (Perceiver model)"),emo=l(),yh=a("li"),One=a("strong"),omo=o("poolformer"),rmo=o(" \u2014 "),lI=a("a"),tmo=o("PoolFormerFeatureExtractor"),amo=o(" (PoolFormer model)"),nmo=l(),Lh=a("li"),Vne=a("strong"),smo=o("regnet"),lmo=o(" \u2014 "),iI=a("a"),imo=o("ConvNextFeatureExtractor"),dmo=o(" (RegNet model)"),cmo=l(),xh=a("li"),Xne=a("strong"),fmo=o("resnet"),mmo=o(" \u2014 "),dI=a("a"),gmo=o("ConvNextFeatureExtractor"),hmo=o(" (ResNet model)"),pmo=l(),$h=a("li"),zne=a("strong"),_mo=o("segformer"),umo=o(" \u2014 "),cI=a("a"),bmo=o("SegformerFeatureExtractor"),vmo=o(" (SegFormer model)"),Fmo=l(),kh=a("li"),Wne=a("strong"),Tmo=o("speech_to_text"),Mmo=o(" \u2014 "),fI=a("a"),Emo=o("Speech2TextFeatureExtractor"),Cmo=o(" (Speech2Text model)"),wmo=l(),Sh=a("li"),Qne=a("strong"),Amo=o("swin"),ymo=o(" \u2014 "),mI=a("a"),Lmo=o("ViTFeatureExtractor"),xmo=o(" (Swin model)"),$mo=l(),Rh=a("li"),Hne=a("strong"),kmo=o("van"),Smo=o(" \u2014 "),gI=a("a"),Rmo=o("ConvNextFeatureExtractor"),Pmo=o(" (VAN model)"),Bmo=l(),Ph=a("li"),Une=a("strong"),Imo=o("vit"),Nmo=o(" \u2014 "),hI=a("a"),qmo=o("ViTFeatureExtractor"),jmo=o(" (ViT model)"),Dmo=l(),Bh=a("li"),Jne=a("strong"),Gmo=o("vit_mae"),Omo=o(" \u2014 "),pI=a("a"),Vmo=o("ViTFeatureExtractor"),Xmo=o(" (ViTMAE model)"),zmo=l(),Ih=a("li"),Yne=a("strong"),Wmo=o("wav2vec2"),Qmo=o(" \u2014 "),_I=a("a"),Hmo=o("Wav2Vec2FeatureExtractor"),Umo=o(" (Wav2Vec2 model)"),Jmo=l(),Nh=a("li"),Kne=a("strong"),Ymo=o("wav2vec2-conformer"),Kmo=o(" \u2014 "),uI=a("a"),Zmo=o("Wav2Vec2FeatureExtractor"),ego=o(" (Wav2Vec2-Conformer model)"),ogo=l(),qh=a("li"),Zne=a("strong"),rgo=o("yolos"),tgo=o(" \u2014 "),bI=a("a"),ago=o("YolosFeatureExtractor"),ngo=o(" (YOLOS model)"),sgo=l(),F(jh.$$.fragment),lgo=l(),F(Dh.$$.fragment),igo=l(),Gh=a("div"),F(JA.$$.fragment),dgo=l(),ese=a("p"),cgo=o("Register a new feature extractor for this class."),Aqe=l(),Ci=a("h2"),Oh=a("a"),ose=a("span"),F(YA.$$.fragment),fgo=l(),rse=a("span"),mgo=o("AutoProcessor"),yqe=l(),yo=a("div"),F(KA.$$.fragment),ggo=l(),ZA=a("p"),hgo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),vI=a("a"),pgo=o("AutoProcessor.from_pretrained()"),_go=o(" class method."),ugo=l(),ey=a("p"),bgo=o("This class cannot be instantiated directly using "),tse=a("code"),vgo=o("__init__()"),Fgo=o(" (throws an error)."),Tgo=l(),Ue=a("div"),F(oy.$$.fragment),Mgo=l(),ase=a("p"),Ego=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),Cgo=l(),wi=a("p"),wgo=o("The processor class to instantiate is selected based on the "),nse=a("code"),Ago=o("model_type"),ygo=o(` property of the config object (either
passed as an argument or loaded from `),sse=a("code"),Lgo=o("pretrained_model_name_or_path"),xgo=o(" if possible):"),$go=l(),he=a("ul"),Vh=a("li"),lse=a("strong"),kgo=o("clip"),Sgo=o(" \u2014 "),FI=a("a"),Rgo=o("CLIPProcessor"),Pgo=o(" (CLIP model)"),Bgo=l(),Xh=a("li"),ise=a("strong"),Igo=o("flava"),Ngo=o(" \u2014 "),dse=a("code"),qgo=o("FLAVAProcessor"),jgo=o(" (Flava model)"),Dgo=l(),zh=a("li"),cse=a("strong"),Ggo=o("layoutlmv2"),Ogo=o(" \u2014 "),TI=a("a"),Vgo=o("LayoutLMv2Processor"),Xgo=o(" (LayoutLMv2 model)"),zgo=l(),Wh=a("li"),fse=a("strong"),Wgo=o("layoutlmv3"),Qgo=o(" \u2014 "),MI=a("a"),Hgo=o("LayoutLMv3Processor"),Ugo=o(" (LayoutLMv3 model)"),Jgo=l(),Qh=a("li"),mse=a("strong"),Ygo=o("layoutxlm"),Kgo=o(" \u2014 "),EI=a("a"),Zgo=o("LayoutXLMProcessor"),eho=o(" (LayoutXLM model)"),oho=l(),Hh=a("li"),gse=a("strong"),rho=o("sew"),tho=o(" \u2014 "),CI=a("a"),aho=o("Wav2Vec2Processor"),nho=o(" (SEW model)"),sho=l(),Uh=a("li"),hse=a("strong"),lho=o("sew-d"),iho=o(" \u2014 "),wI=a("a"),dho=o("Wav2Vec2Processor"),cho=o(" (SEW-D model)"),fho=l(),Jh=a("li"),pse=a("strong"),mho=o("speech_to_text"),gho=o(" \u2014 "),AI=a("a"),hho=o("Speech2TextProcessor"),pho=o(" (Speech2Text model)"),_ho=l(),Yh=a("li"),_se=a("strong"),uho=o("speech_to_text_2"),bho=o(" \u2014 "),yI=a("a"),vho=o("Speech2Text2Processor"),Fho=o(" (Speech2Text2 model)"),Tho=l(),Kh=a("li"),use=a("strong"),Mho=o("trocr"),Eho=o(" \u2014 "),LI=a("a"),Cho=o("TrOCRProcessor"),who=o(" (TrOCR model)"),Aho=l(),Zh=a("li"),bse=a("strong"),yho=o("unispeech"),Lho=o(" \u2014 "),xI=a("a"),xho=o("Wav2Vec2Processor"),$ho=o(" (UniSpeech model)"),kho=l(),ep=a("li"),vse=a("strong"),Sho=o("unispeech-sat"),Rho=o(" \u2014 "),$I=a("a"),Pho=o("Wav2Vec2Processor"),Bho=o(" (UniSpeechSat model)"),Iho=l(),op=a("li"),Fse=a("strong"),Nho=o("vilt"),qho=o(" \u2014 "),kI=a("a"),jho=o("ViltProcessor"),Dho=o(" (ViLT model)"),Gho=l(),rp=a("li"),Tse=a("strong"),Oho=o("vision-text-dual-encoder"),Vho=o(" \u2014 "),SI=a("a"),Xho=o("VisionTextDualEncoderProcessor"),zho=o(" (VisionTextDualEncoder model)"),Who=l(),tp=a("li"),Mse=a("strong"),Qho=o("wav2vec2"),Hho=o(" \u2014 "),RI=a("a"),Uho=o("Wav2Vec2Processor"),Jho=o(" (Wav2Vec2 model)"),Yho=l(),ap=a("li"),Ese=a("strong"),Kho=o("wav2vec2-conformer"),Zho=o(" \u2014 "),PI=a("a"),epo=o("Wav2Vec2Processor"),opo=o(" (Wav2Vec2-Conformer model)"),rpo=l(),np=a("li"),Cse=a("strong"),tpo=o("wavlm"),apo=o(" \u2014 "),BI=a("a"),npo=o("Wav2Vec2Processor"),spo=o(" (WavLM model)"),lpo=l(),F(sp.$$.fragment),ipo=l(),F(lp.$$.fragment),dpo=l(),ip=a("div"),F(ry.$$.fragment),cpo=l(),wse=a("p"),fpo=o("Register a new processor for this class."),Lqe=l(),Ai=a("h2"),dp=a("a"),Ase=a("span"),F(ty.$$.fragment),mpo=l(),yse=a("span"),gpo=o("AutoModel"),xqe=l(),Lo=a("div"),F(ay.$$.fragment),hpo=l(),yi=a("p"),ppo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),II=a("a"),_po=o("from_pretrained()"),upo=o(" class method or the "),NI=a("a"),bpo=o("from_config()"),vpo=o(` class
method.`),Fpo=l(),ny=a("p"),Tpo=o("This class cannot be instantiated directly using "),Lse=a("code"),Mpo=o("__init__()"),Epo=o(" (throws an error)."),Cpo=l(),tt=a("div"),F(sy.$$.fragment),wpo=l(),xse=a("p"),Apo=o("Instantiates one of the base model classes of the library from a configuration."),ypo=l(),Li=a("p"),Lpo=o(`Note:
Loading a model from its configuration file does `),$se=a("strong"),xpo=o("not"),$po=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qI=a("a"),kpo=o("from_pretrained()"),Spo=o(" to load the model weights."),Rpo=l(),F(cp.$$.fragment),Ppo=l(),Je=a("div"),F(ly.$$.fragment),Bpo=l(),kse=a("p"),Ipo=o("Instantiate one of the base model classes of the library from a pretrained model."),Npo=l(),La=a("p"),qpo=o("The model class to instantiate is selected based on the "),Sse=a("code"),jpo=o("model_type"),Dpo=o(` property of the config object (either
passed as an argument or loaded from `),Rse=a("code"),Gpo=o("pretrained_model_name_or_path"),Opo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Pse=a("code"),Vpo=o("pretrained_model_name_or_path"),Xpo=o(":"),zpo=l(),x=a("ul"),fp=a("li"),Bse=a("strong"),Wpo=o("albert"),Qpo=o(" \u2014 "),jI=a("a"),Hpo=o("AlbertModel"),Upo=o(" (ALBERT model)"),Jpo=l(),mp=a("li"),Ise=a("strong"),Ypo=o("bart"),Kpo=o(" \u2014 "),DI=a("a"),Zpo=o("BartModel"),e_o=o(" (BART model)"),o_o=l(),gp=a("li"),Nse=a("strong"),r_o=o("beit"),t_o=o(" \u2014 "),GI=a("a"),a_o=o("BeitModel"),n_o=o(" (BEiT model)"),s_o=l(),hp=a("li"),qse=a("strong"),l_o=o("bert"),i_o=o(" \u2014 "),OI=a("a"),d_o=o("BertModel"),c_o=o(" (BERT model)"),f_o=l(),pp=a("li"),jse=a("strong"),m_o=o("bert-generation"),g_o=o(" \u2014 "),VI=a("a"),h_o=o("BertGenerationEncoder"),p_o=o(" (Bert Generation model)"),__o=l(),_p=a("li"),Dse=a("strong"),u_o=o("big_bird"),b_o=o(" \u2014 "),XI=a("a"),v_o=o("BigBirdModel"),F_o=o(" (BigBird model)"),T_o=l(),up=a("li"),Gse=a("strong"),M_o=o("bigbird_pegasus"),E_o=o(" \u2014 "),zI=a("a"),C_o=o("BigBirdPegasusModel"),w_o=o(" (BigBirdPegasus model)"),A_o=l(),bp=a("li"),Ose=a("strong"),y_o=o("blenderbot"),L_o=o(" \u2014 "),WI=a("a"),x_o=o("BlenderbotModel"),$_o=o(" (Blenderbot model)"),k_o=l(),vp=a("li"),Vse=a("strong"),S_o=o("blenderbot-small"),R_o=o(" \u2014 "),QI=a("a"),P_o=o("BlenderbotSmallModel"),B_o=o(" (BlenderbotSmall model)"),I_o=l(),Fp=a("li"),Xse=a("strong"),N_o=o("camembert"),q_o=o(" \u2014 "),HI=a("a"),j_o=o("CamembertModel"),D_o=o(" (CamemBERT model)"),G_o=l(),Tp=a("li"),zse=a("strong"),O_o=o("canine"),V_o=o(" \u2014 "),UI=a("a"),X_o=o("CanineModel"),z_o=o(" (Canine model)"),W_o=l(),Mp=a("li"),Wse=a("strong"),Q_o=o("clip"),H_o=o(" \u2014 "),JI=a("a"),U_o=o("CLIPModel"),J_o=o(" (CLIP model)"),Y_o=l(),Ep=a("li"),Qse=a("strong"),K_o=o("convbert"),Z_o=o(" \u2014 "),YI=a("a"),euo=o("ConvBertModel"),ouo=o(" (ConvBERT model)"),ruo=l(),Cp=a("li"),Hse=a("strong"),tuo=o("convnext"),auo=o(" \u2014 "),KI=a("a"),nuo=o("ConvNextModel"),suo=o(" (ConvNext model)"),luo=l(),wp=a("li"),Use=a("strong"),iuo=o("ctrl"),duo=o(" \u2014 "),ZI=a("a"),cuo=o("CTRLModel"),fuo=o(" (CTRL model)"),muo=l(),Ap=a("li"),Jse=a("strong"),guo=o("cvt"),huo=o(" \u2014 "),eN=a("a"),puo=o("CvtModel"),_uo=o(" (CvT model)"),uuo=l(),yp=a("li"),Yse=a("strong"),buo=o("data2vec-audio"),vuo=o(" \u2014 "),oN=a("a"),Fuo=o("Data2VecAudioModel"),Tuo=o(" (Data2VecAudio model)"),Muo=l(),Lp=a("li"),Kse=a("strong"),Euo=o("data2vec-text"),Cuo=o(" \u2014 "),rN=a("a"),wuo=o("Data2VecTextModel"),Auo=o(" (Data2VecText model)"),yuo=l(),xp=a("li"),Zse=a("strong"),Luo=o("data2vec-vision"),xuo=o(" \u2014 "),tN=a("a"),$uo=o("Data2VecVisionModel"),kuo=o(" (Data2VecVision model)"),Suo=l(),$p=a("li"),ele=a("strong"),Ruo=o("deberta"),Puo=o(" \u2014 "),aN=a("a"),Buo=o("DebertaModel"),Iuo=o(" (DeBERTa model)"),Nuo=l(),kp=a("li"),ole=a("strong"),quo=o("deberta-v2"),juo=o(" \u2014 "),nN=a("a"),Duo=o("DebertaV2Model"),Guo=o(" (DeBERTa-v2 model)"),Ouo=l(),Sp=a("li"),rle=a("strong"),Vuo=o("decision_transformer"),Xuo=o(" \u2014 "),sN=a("a"),zuo=o("DecisionTransformerModel"),Wuo=o(" (Decision Transformer model)"),Quo=l(),Rp=a("li"),tle=a("strong"),Huo=o("deit"),Uuo=o(" \u2014 "),lN=a("a"),Juo=o("DeiTModel"),Yuo=o(" (DeiT model)"),Kuo=l(),Pp=a("li"),ale=a("strong"),Zuo=o("detr"),e6o=o(" \u2014 "),iN=a("a"),o6o=o("DetrModel"),r6o=o(" (DETR model)"),t6o=l(),Bp=a("li"),nle=a("strong"),a6o=o("distilbert"),n6o=o(" \u2014 "),dN=a("a"),s6o=o("DistilBertModel"),l6o=o(" (DistilBERT model)"),i6o=l(),Ip=a("li"),sle=a("strong"),d6o=o("dpr"),c6o=o(" \u2014 "),cN=a("a"),f6o=o("DPRQuestionEncoder"),m6o=o(" (DPR model)"),g6o=l(),Np=a("li"),lle=a("strong"),h6o=o("dpt"),p6o=o(" \u2014 "),fN=a("a"),_6o=o("DPTModel"),u6o=o(" (DPT model)"),b6o=l(),qp=a("li"),ile=a("strong"),v6o=o("electra"),F6o=o(" \u2014 "),mN=a("a"),T6o=o("ElectraModel"),M6o=o(" (ELECTRA model)"),E6o=l(),jp=a("li"),dle=a("strong"),C6o=o("flaubert"),w6o=o(" \u2014 "),gN=a("a"),A6o=o("FlaubertModel"),y6o=o(" (FlauBERT model)"),L6o=l(),Dp=a("li"),cle=a("strong"),x6o=o("flava"),$6o=o(" \u2014 "),hN=a("a"),k6o=o("FlavaModel"),S6o=o(" (Flava model)"),R6o=l(),Gp=a("li"),fle=a("strong"),P6o=o("fnet"),B6o=o(" \u2014 "),pN=a("a"),I6o=o("FNetModel"),N6o=o(" (FNet model)"),q6o=l(),Op=a("li"),mle=a("strong"),j6o=o("fsmt"),D6o=o(" \u2014 "),_N=a("a"),G6o=o("FSMTModel"),O6o=o(" (FairSeq Machine-Translation model)"),V6o=l(),Ps=a("li"),gle=a("strong"),X6o=o("funnel"),z6o=o(" \u2014 "),uN=a("a"),W6o=o("FunnelModel"),Q6o=o(" or "),bN=a("a"),H6o=o("FunnelBaseModel"),U6o=o(" (Funnel Transformer model)"),J6o=l(),Vp=a("li"),hle=a("strong"),Y6o=o("glpn"),K6o=o(" \u2014 "),vN=a("a"),Z6o=o("GLPNModel"),e1o=o(" (GLPN model)"),o1o=l(),Xp=a("li"),ple=a("strong"),r1o=o("gpt2"),t1o=o(" \u2014 "),FN=a("a"),a1o=o("GPT2Model"),n1o=o(" (OpenAI GPT-2 model)"),s1o=l(),zp=a("li"),_le=a("strong"),l1o=o("gpt_neo"),i1o=o(" \u2014 "),TN=a("a"),d1o=o("GPTNeoModel"),c1o=o(" (GPT Neo model)"),f1o=l(),Wp=a("li"),ule=a("strong"),m1o=o("gpt_neox"),g1o=o(" \u2014 "),MN=a("a"),h1o=o("GPTNeoXModel"),p1o=o(" (GPT NeoX model)"),_1o=l(),Qp=a("li"),ble=a("strong"),u1o=o("gptj"),b1o=o(" \u2014 "),EN=a("a"),v1o=o("GPTJModel"),F1o=o(" (GPT-J model)"),T1o=l(),Hp=a("li"),vle=a("strong"),M1o=o("hubert"),E1o=o(" \u2014 "),CN=a("a"),C1o=o("HubertModel"),w1o=o(" (Hubert model)"),A1o=l(),Up=a("li"),Fle=a("strong"),y1o=o("ibert"),L1o=o(" \u2014 "),wN=a("a"),x1o=o("IBertModel"),$1o=o(" (I-BERT model)"),k1o=l(),Jp=a("li"),Tle=a("strong"),S1o=o("imagegpt"),R1o=o(" \u2014 "),AN=a("a"),P1o=o("ImageGPTModel"),B1o=o(" (ImageGPT model)"),I1o=l(),Yp=a("li"),Mle=a("strong"),N1o=o("layoutlm"),q1o=o(" \u2014 "),yN=a("a"),j1o=o("LayoutLMModel"),D1o=o(" (LayoutLM model)"),G1o=l(),Kp=a("li"),Ele=a("strong"),O1o=o("layoutlmv2"),V1o=o(" \u2014 "),LN=a("a"),X1o=o("LayoutLMv2Model"),z1o=o(" (LayoutLMv2 model)"),W1o=l(),Zp=a("li"),Cle=a("strong"),Q1o=o("layoutlmv3"),H1o=o(" \u2014 "),xN=a("a"),U1o=o("LayoutLMv3Model"),J1o=o(" (LayoutLMv3 model)"),Y1o=l(),e_=a("li"),wle=a("strong"),K1o=o("led"),Z1o=o(" \u2014 "),$N=a("a"),ebo=o("LEDModel"),obo=o(" (LED model)"),rbo=l(),o_=a("li"),Ale=a("strong"),tbo=o("levit"),abo=o(" \u2014 "),kN=a("a"),nbo=o("LevitModel"),sbo=o(" (LeViT model)"),lbo=l(),r_=a("li"),yle=a("strong"),ibo=o("longformer"),dbo=o(" \u2014 "),SN=a("a"),cbo=o("LongformerModel"),fbo=o(" (Longformer model)"),mbo=l(),t_=a("li"),Lle=a("strong"),gbo=o("luke"),hbo=o(" \u2014 "),RN=a("a"),pbo=o("LukeModel"),_bo=o(" (LUKE model)"),ubo=l(),a_=a("li"),xle=a("strong"),bbo=o("lxmert"),vbo=o(" \u2014 "),PN=a("a"),Fbo=o("LxmertModel"),Tbo=o(" (LXMERT model)"),Mbo=l(),n_=a("li"),$le=a("strong"),Ebo=o("m2m_100"),Cbo=o(" \u2014 "),BN=a("a"),wbo=o("M2M100Model"),Abo=o(" (M2M100 model)"),ybo=l(),s_=a("li"),kle=a("strong"),Lbo=o("marian"),xbo=o(" \u2014 "),IN=a("a"),$bo=o("MarianModel"),kbo=o(" (Marian model)"),Sbo=l(),l_=a("li"),Sle=a("strong"),Rbo=o("maskformer"),Pbo=o(" \u2014 "),NN=a("a"),Bbo=o("MaskFormerModel"),Ibo=o(" (MaskFormer model)"),Nbo=l(),i_=a("li"),Rle=a("strong"),qbo=o("mbart"),jbo=o(" \u2014 "),qN=a("a"),Dbo=o("MBartModel"),Gbo=o(" (mBART model)"),Obo=l(),d_=a("li"),Ple=a("strong"),Vbo=o("megatron-bert"),Xbo=o(" \u2014 "),jN=a("a"),zbo=o("MegatronBertModel"),Wbo=o(" (MegatronBert model)"),Qbo=l(),c_=a("li"),Ble=a("strong"),Hbo=o("mobilebert"),Ubo=o(" \u2014 "),DN=a("a"),Jbo=o("MobileBertModel"),Ybo=o(" (MobileBERT model)"),Kbo=l(),f_=a("li"),Ile=a("strong"),Zbo=o("mpnet"),e2o=o(" \u2014 "),GN=a("a"),o2o=o("MPNetModel"),r2o=o(" (MPNet model)"),t2o=l(),m_=a("li"),Nle=a("strong"),a2o=o("mt5"),n2o=o(" \u2014 "),ON=a("a"),s2o=o("MT5Model"),l2o=o(" (mT5 model)"),i2o=l(),g_=a("li"),qle=a("strong"),d2o=o("nystromformer"),c2o=o(" \u2014 "),VN=a("a"),f2o=o("NystromformerModel"),m2o=o(" (Nystromformer model)"),g2o=l(),h_=a("li"),jle=a("strong"),h2o=o("openai-gpt"),p2o=o(" \u2014 "),XN=a("a"),_2o=o("OpenAIGPTModel"),u2o=o(" (OpenAI GPT model)"),b2o=l(),p_=a("li"),Dle=a("strong"),v2o=o("opt"),F2o=o(" \u2014 "),zN=a("a"),T2o=o("OPTModel"),M2o=o(" (OPT model)"),E2o=l(),__=a("li"),Gle=a("strong"),C2o=o("pegasus"),w2o=o(" \u2014 "),WN=a("a"),A2o=o("PegasusModel"),y2o=o(" (Pegasus model)"),L2o=l(),u_=a("li"),Ole=a("strong"),x2o=o("perceiver"),$2o=o(" \u2014 "),QN=a("a"),k2o=o("PerceiverModel"),S2o=o(" (Perceiver model)"),R2o=l(),b_=a("li"),Vle=a("strong"),P2o=o("plbart"),B2o=o(" \u2014 "),HN=a("a"),I2o=o("PLBartModel"),N2o=o(" (PLBart model)"),q2o=l(),v_=a("li"),Xle=a("strong"),j2o=o("poolformer"),D2o=o(" \u2014 "),UN=a("a"),G2o=o("PoolFormerModel"),O2o=o(" (PoolFormer model)"),V2o=l(),F_=a("li"),zle=a("strong"),X2o=o("prophetnet"),z2o=o(" \u2014 "),JN=a("a"),W2o=o("ProphetNetModel"),Q2o=o(" (ProphetNet model)"),H2o=l(),T_=a("li"),Wle=a("strong"),U2o=o("qdqbert"),J2o=o(" \u2014 "),YN=a("a"),Y2o=o("QDQBertModel"),K2o=o(" (QDQBert model)"),Z2o=l(),M_=a("li"),Qle=a("strong"),e4o=o("reformer"),o4o=o(" \u2014 "),KN=a("a"),r4o=o("ReformerModel"),t4o=o(" (Reformer model)"),a4o=l(),E_=a("li"),Hle=a("strong"),n4o=o("regnet"),s4o=o(" \u2014 "),ZN=a("a"),l4o=o("RegNetModel"),i4o=o(" (RegNet model)"),d4o=l(),C_=a("li"),Ule=a("strong"),c4o=o("rembert"),f4o=o(" \u2014 "),eq=a("a"),m4o=o("RemBertModel"),g4o=o(" (RemBERT model)"),h4o=l(),w_=a("li"),Jle=a("strong"),p4o=o("resnet"),_4o=o(" \u2014 "),oq=a("a"),u4o=o("ResNetModel"),b4o=o(" (ResNet model)"),v4o=l(),A_=a("li"),Yle=a("strong"),F4o=o("retribert"),T4o=o(" \u2014 "),rq=a("a"),M4o=o("RetriBertModel"),E4o=o(" (RetriBERT model)"),C4o=l(),y_=a("li"),Kle=a("strong"),w4o=o("roberta"),A4o=o(" \u2014 "),tq=a("a"),y4o=o("RobertaModel"),L4o=o(" (RoBERTa model)"),x4o=l(),L_=a("li"),Zle=a("strong"),$4o=o("roformer"),k4o=o(" \u2014 "),aq=a("a"),S4o=o("RoFormerModel"),R4o=o(" (RoFormer model)"),P4o=l(),x_=a("li"),eie=a("strong"),B4o=o("segformer"),I4o=o(" \u2014 "),nq=a("a"),N4o=o("SegformerModel"),q4o=o(" (SegFormer model)"),j4o=l(),$_=a("li"),oie=a("strong"),D4o=o("sew"),G4o=o(" \u2014 "),sq=a("a"),O4o=o("SEWModel"),V4o=o(" (SEW model)"),X4o=l(),k_=a("li"),rie=a("strong"),z4o=o("sew-d"),W4o=o(" \u2014 "),lq=a("a"),Q4o=o("SEWDModel"),H4o=o(" (SEW-D model)"),U4o=l(),S_=a("li"),tie=a("strong"),J4o=o("speech_to_text"),Y4o=o(" \u2014 "),iq=a("a"),K4o=o("Speech2TextModel"),Z4o=o(" (Speech2Text model)"),evo=l(),R_=a("li"),aie=a("strong"),ovo=o("splinter"),rvo=o(" \u2014 "),dq=a("a"),tvo=o("SplinterModel"),avo=o(" (Splinter model)"),nvo=l(),P_=a("li"),nie=a("strong"),svo=o("squeezebert"),lvo=o(" \u2014 "),cq=a("a"),ivo=o("SqueezeBertModel"),dvo=o(" (SqueezeBERT model)"),cvo=l(),B_=a("li"),sie=a("strong"),fvo=o("swin"),mvo=o(" \u2014 "),fq=a("a"),gvo=o("SwinModel"),hvo=o(" (Swin model)"),pvo=l(),I_=a("li"),lie=a("strong"),_vo=o("t5"),uvo=o(" \u2014 "),mq=a("a"),bvo=o("T5Model"),vvo=o(" (T5 model)"),Fvo=l(),N_=a("li"),iie=a("strong"),Tvo=o("tapas"),Mvo=o(" \u2014 "),gq=a("a"),Evo=o("TapasModel"),Cvo=o(" (TAPAS model)"),wvo=l(),q_=a("li"),die=a("strong"),Avo=o("trajectory_transformer"),yvo=o(" \u2014 "),hq=a("a"),Lvo=o("TrajectoryTransformerModel"),xvo=o(" (Trajectory Transformer model)"),$vo=l(),j_=a("li"),cie=a("strong"),kvo=o("transfo-xl"),Svo=o(" \u2014 "),pq=a("a"),Rvo=o("TransfoXLModel"),Pvo=o(" (Transformer-XL model)"),Bvo=l(),D_=a("li"),fie=a("strong"),Ivo=o("unispeech"),Nvo=o(" \u2014 "),_q=a("a"),qvo=o("UniSpeechModel"),jvo=o(" (UniSpeech model)"),Dvo=l(),G_=a("li"),mie=a("strong"),Gvo=o("unispeech-sat"),Ovo=o(" \u2014 "),uq=a("a"),Vvo=o("UniSpeechSatModel"),Xvo=o(" (UniSpeechSat model)"),zvo=l(),O_=a("li"),gie=a("strong"),Wvo=o("van"),Qvo=o(" \u2014 "),bq=a("a"),Hvo=o("VanModel"),Uvo=o(" (VAN model)"),Jvo=l(),V_=a("li"),hie=a("strong"),Yvo=o("vilt"),Kvo=o(" \u2014 "),vq=a("a"),Zvo=o("ViltModel"),eFo=o(" (ViLT model)"),oFo=l(),X_=a("li"),pie=a("strong"),rFo=o("vision-text-dual-encoder"),tFo=o(" \u2014 "),Fq=a("a"),aFo=o("VisionTextDualEncoderModel"),nFo=o(" (VisionTextDualEncoder model)"),sFo=l(),z_=a("li"),_ie=a("strong"),lFo=o("visual_bert"),iFo=o(" \u2014 "),Tq=a("a"),dFo=o("VisualBertModel"),cFo=o(" (VisualBert model)"),fFo=l(),W_=a("li"),uie=a("strong"),mFo=o("vit"),gFo=o(" \u2014 "),Mq=a("a"),hFo=o("ViTModel"),pFo=o(" (ViT model)"),_Fo=l(),Q_=a("li"),bie=a("strong"),uFo=o("vit_mae"),bFo=o(" \u2014 "),Eq=a("a"),vFo=o("ViTMAEModel"),FFo=o(" (ViTMAE model)"),TFo=l(),H_=a("li"),vie=a("strong"),MFo=o("wav2vec2"),EFo=o(" \u2014 "),Cq=a("a"),CFo=o("Wav2Vec2Model"),wFo=o(" (Wav2Vec2 model)"),AFo=l(),U_=a("li"),Fie=a("strong"),yFo=o("wav2vec2-conformer"),LFo=o(" \u2014 "),wq=a("a"),xFo=o("Wav2Vec2ConformerModel"),$Fo=o(" (Wav2Vec2-Conformer model)"),kFo=l(),J_=a("li"),Tie=a("strong"),SFo=o("wavlm"),RFo=o(" \u2014 "),Aq=a("a"),PFo=o("WavLMModel"),BFo=o(" (WavLM model)"),IFo=l(),Y_=a("li"),Mie=a("strong"),NFo=o("xglm"),qFo=o(" \u2014 "),yq=a("a"),jFo=o("XGLMModel"),DFo=o(" (XGLM model)"),GFo=l(),K_=a("li"),Eie=a("strong"),OFo=o("xlm"),VFo=o(" \u2014 "),Lq=a("a"),XFo=o("XLMModel"),zFo=o(" (XLM model)"),WFo=l(),Z_=a("li"),Cie=a("strong"),QFo=o("xlm-prophetnet"),HFo=o(" \u2014 "),xq=a("a"),UFo=o("XLMProphetNetModel"),JFo=o(" (XLMProphetNet model)"),YFo=l(),eu=a("li"),wie=a("strong"),KFo=o("xlm-roberta"),ZFo=o(" \u2014 "),$q=a("a"),eTo=o("XLMRobertaModel"),oTo=o(" (XLM-RoBERTa model)"),rTo=l(),ou=a("li"),Aie=a("strong"),tTo=o("xlm-roberta-xl"),aTo=o(" \u2014 "),kq=a("a"),nTo=o("XLMRobertaXLModel"),sTo=o(" (XLM-RoBERTa-XL model)"),lTo=l(),ru=a("li"),yie=a("strong"),iTo=o("xlnet"),dTo=o(" \u2014 "),Sq=a("a"),cTo=o("XLNetModel"),fTo=o(" (XLNet model)"),mTo=l(),tu=a("li"),Lie=a("strong"),gTo=o("yolos"),hTo=o(" \u2014 "),Rq=a("a"),pTo=o("YolosModel"),_To=o(" (YOLOS model)"),uTo=l(),au=a("li"),xie=a("strong"),bTo=o("yoso"),vTo=o(" \u2014 "),Pq=a("a"),FTo=o("YosoModel"),TTo=o(" (YOSO model)"),MTo=l(),nu=a("p"),ETo=o("The model is set in evaluation mode by default using "),$ie=a("code"),CTo=o("model.eval()"),wTo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kie=a("code"),ATo=o("model.train()"),yTo=l(),F(su.$$.fragment),$qe=l(),xi=a("h2"),lu=a("a"),Sie=a("span"),F(iy.$$.fragment),LTo=l(),Rie=a("span"),xTo=o("AutoModelForPreTraining"),kqe=l(),xo=a("div"),F(dy.$$.fragment),$To=l(),$i=a("p"),kTo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Bq=a("a"),STo=o("from_pretrained()"),RTo=o(" class method or the "),Iq=a("a"),PTo=o("from_config()"),BTo=o(` class
method.`),ITo=l(),cy=a("p"),NTo=o("This class cannot be instantiated directly using "),Pie=a("code"),qTo=o("__init__()"),jTo=o(" (throws an error)."),DTo=l(),at=a("div"),F(fy.$$.fragment),GTo=l(),Bie=a("p"),OTo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),VTo=l(),ki=a("p"),XTo=o(`Note:
Loading a model from its configuration file does `),Iie=a("strong"),zTo=o("not"),WTo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Nq=a("a"),QTo=o("from_pretrained()"),HTo=o(" to load the model weights."),UTo=l(),F(iu.$$.fragment),JTo=l(),Ye=a("div"),F(my.$$.fragment),YTo=l(),Nie=a("p"),KTo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),ZTo=l(),xa=a("p"),e7o=o("The model class to instantiate is selected based on the "),qie=a("code"),o7o=o("model_type"),r7o=o(` property of the config object (either
passed as an argument or loaded from `),jie=a("code"),t7o=o("pretrained_model_name_or_path"),a7o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Die=a("code"),n7o=o("pretrained_model_name_or_path"),s7o=o(":"),l7o=l(),G=a("ul"),du=a("li"),Gie=a("strong"),i7o=o("albert"),d7o=o(" \u2014 "),qq=a("a"),c7o=o("AlbertForPreTraining"),f7o=o(" (ALBERT model)"),m7o=l(),cu=a("li"),Oie=a("strong"),g7o=o("bart"),h7o=o(" \u2014 "),jq=a("a"),p7o=o("BartForConditionalGeneration"),_7o=o(" (BART model)"),u7o=l(),fu=a("li"),Vie=a("strong"),b7o=o("bert"),v7o=o(" \u2014 "),Dq=a("a"),F7o=o("BertForPreTraining"),T7o=o(" (BERT model)"),M7o=l(),mu=a("li"),Xie=a("strong"),E7o=o("big_bird"),C7o=o(" \u2014 "),Gq=a("a"),w7o=o("BigBirdForPreTraining"),A7o=o(" (BigBird model)"),y7o=l(),gu=a("li"),zie=a("strong"),L7o=o("camembert"),x7o=o(" \u2014 "),Oq=a("a"),$7o=o("CamembertForMaskedLM"),k7o=o(" (CamemBERT model)"),S7o=l(),hu=a("li"),Wie=a("strong"),R7o=o("ctrl"),P7o=o(" \u2014 "),Vq=a("a"),B7o=o("CTRLLMHeadModel"),I7o=o(" (CTRL model)"),N7o=l(),pu=a("li"),Qie=a("strong"),q7o=o("data2vec-text"),j7o=o(" \u2014 "),Xq=a("a"),D7o=o("Data2VecTextForMaskedLM"),G7o=o(" (Data2VecText model)"),O7o=l(),_u=a("li"),Hie=a("strong"),V7o=o("deberta"),X7o=o(" \u2014 "),zq=a("a"),z7o=o("DebertaForMaskedLM"),W7o=o(" (DeBERTa model)"),Q7o=l(),uu=a("li"),Uie=a("strong"),H7o=o("deberta-v2"),U7o=o(" \u2014 "),Wq=a("a"),J7o=o("DebertaV2ForMaskedLM"),Y7o=o(" (DeBERTa-v2 model)"),K7o=l(),bu=a("li"),Jie=a("strong"),Z7o=o("distilbert"),eMo=o(" \u2014 "),Qq=a("a"),oMo=o("DistilBertForMaskedLM"),rMo=o(" (DistilBERT model)"),tMo=l(),vu=a("li"),Yie=a("strong"),aMo=o("electra"),nMo=o(" \u2014 "),Hq=a("a"),sMo=o("ElectraForPreTraining"),lMo=o(" (ELECTRA model)"),iMo=l(),Fu=a("li"),Kie=a("strong"),dMo=o("flaubert"),cMo=o(" \u2014 "),Uq=a("a"),fMo=o("FlaubertWithLMHeadModel"),mMo=o(" (FlauBERT model)"),gMo=l(),Tu=a("li"),Zie=a("strong"),hMo=o("flava"),pMo=o(" \u2014 "),Jq=a("a"),_Mo=o("FlavaForPreTraining"),uMo=o(" (Flava model)"),bMo=l(),Mu=a("li"),ede=a("strong"),vMo=o("fnet"),FMo=o(" \u2014 "),Yq=a("a"),TMo=o("FNetForPreTraining"),MMo=o(" (FNet model)"),EMo=l(),Eu=a("li"),ode=a("strong"),CMo=o("fsmt"),wMo=o(" \u2014 "),Kq=a("a"),AMo=o("FSMTForConditionalGeneration"),yMo=o(" (FairSeq Machine-Translation model)"),LMo=l(),Cu=a("li"),rde=a("strong"),xMo=o("funnel"),$Mo=o(" \u2014 "),Zq=a("a"),kMo=o("FunnelForPreTraining"),SMo=o(" (Funnel Transformer model)"),RMo=l(),wu=a("li"),tde=a("strong"),PMo=o("gpt2"),BMo=o(" \u2014 "),ej=a("a"),IMo=o("GPT2LMHeadModel"),NMo=o(" (OpenAI GPT-2 model)"),qMo=l(),Au=a("li"),ade=a("strong"),jMo=o("ibert"),DMo=o(" \u2014 "),oj=a("a"),GMo=o("IBertForMaskedLM"),OMo=o(" (I-BERT model)"),VMo=l(),yu=a("li"),nde=a("strong"),XMo=o("layoutlm"),zMo=o(" \u2014 "),rj=a("a"),WMo=o("LayoutLMForMaskedLM"),QMo=o(" (LayoutLM model)"),HMo=l(),Lu=a("li"),sde=a("strong"),UMo=o("longformer"),JMo=o(" \u2014 "),tj=a("a"),YMo=o("LongformerForMaskedLM"),KMo=o(" (Longformer model)"),ZMo=l(),xu=a("li"),lde=a("strong"),eEo=o("lxmert"),oEo=o(" \u2014 "),aj=a("a"),rEo=o("LxmertForPreTraining"),tEo=o(" (LXMERT model)"),aEo=l(),$u=a("li"),ide=a("strong"),nEo=o("megatron-bert"),sEo=o(" \u2014 "),nj=a("a"),lEo=o("MegatronBertForPreTraining"),iEo=o(" (MegatronBert model)"),dEo=l(),ku=a("li"),dde=a("strong"),cEo=o("mobilebert"),fEo=o(" \u2014 "),sj=a("a"),mEo=o("MobileBertForPreTraining"),gEo=o(" (MobileBERT model)"),hEo=l(),Su=a("li"),cde=a("strong"),pEo=o("mpnet"),_Eo=o(" \u2014 "),lj=a("a"),uEo=o("MPNetForMaskedLM"),bEo=o(" (MPNet model)"),vEo=l(),Ru=a("li"),fde=a("strong"),FEo=o("openai-gpt"),TEo=o(" \u2014 "),ij=a("a"),MEo=o("OpenAIGPTLMHeadModel"),EEo=o(" (OpenAI GPT model)"),CEo=l(),Pu=a("li"),mde=a("strong"),wEo=o("retribert"),AEo=o(" \u2014 "),dj=a("a"),yEo=o("RetriBertModel"),LEo=o(" (RetriBERT model)"),xEo=l(),Bu=a("li"),gde=a("strong"),$Eo=o("roberta"),kEo=o(" \u2014 "),cj=a("a"),SEo=o("RobertaForMaskedLM"),REo=o(" (RoBERTa model)"),PEo=l(),Iu=a("li"),hde=a("strong"),BEo=o("splinter"),IEo=o(" \u2014 "),fj=a("a"),NEo=o("SplinterForPreTraining"),qEo=o(" (Splinter model)"),jEo=l(),Nu=a("li"),pde=a("strong"),DEo=o("squeezebert"),GEo=o(" \u2014 "),mj=a("a"),OEo=o("SqueezeBertForMaskedLM"),VEo=o(" (SqueezeBERT model)"),XEo=l(),qu=a("li"),_de=a("strong"),zEo=o("t5"),WEo=o(" \u2014 "),gj=a("a"),QEo=o("T5ForConditionalGeneration"),HEo=o(" (T5 model)"),UEo=l(),ju=a("li"),ude=a("strong"),JEo=o("tapas"),YEo=o(" \u2014 "),hj=a("a"),KEo=o("TapasForMaskedLM"),ZEo=o(" (TAPAS model)"),eCo=l(),Du=a("li"),bde=a("strong"),oCo=o("transfo-xl"),rCo=o(" \u2014 "),pj=a("a"),tCo=o("TransfoXLLMHeadModel"),aCo=o(" (Transformer-XL model)"),nCo=l(),Gu=a("li"),vde=a("strong"),sCo=o("unispeech"),lCo=o(" \u2014 "),_j=a("a"),iCo=o("UniSpeechForPreTraining"),dCo=o(" (UniSpeech model)"),cCo=l(),Ou=a("li"),Fde=a("strong"),fCo=o("unispeech-sat"),mCo=o(" \u2014 "),uj=a("a"),gCo=o("UniSpeechSatForPreTraining"),hCo=o(" (UniSpeechSat model)"),pCo=l(),Vu=a("li"),Tde=a("strong"),_Co=o("visual_bert"),uCo=o(" \u2014 "),bj=a("a"),bCo=o("VisualBertForPreTraining"),vCo=o(" (VisualBert model)"),FCo=l(),Xu=a("li"),Mde=a("strong"),TCo=o("vit_mae"),MCo=o(" \u2014 "),vj=a("a"),ECo=o("ViTMAEForPreTraining"),CCo=o(" (ViTMAE model)"),wCo=l(),zu=a("li"),Ede=a("strong"),ACo=o("wav2vec2"),yCo=o(" \u2014 "),Fj=a("a"),LCo=o("Wav2Vec2ForPreTraining"),xCo=o(" (Wav2Vec2 model)"),$Co=l(),Wu=a("li"),Cde=a("strong"),kCo=o("wav2vec2-conformer"),SCo=o(" \u2014 "),Tj=a("a"),RCo=o("Wav2Vec2ConformerForPreTraining"),PCo=o(" (Wav2Vec2-Conformer model)"),BCo=l(),Qu=a("li"),wde=a("strong"),ICo=o("xlm"),NCo=o(" \u2014 "),Mj=a("a"),qCo=o("XLMWithLMHeadModel"),jCo=o(" (XLM model)"),DCo=l(),Hu=a("li"),Ade=a("strong"),GCo=o("xlm-roberta"),OCo=o(" \u2014 "),Ej=a("a"),VCo=o("XLMRobertaForMaskedLM"),XCo=o(" (XLM-RoBERTa model)"),zCo=l(),Uu=a("li"),yde=a("strong"),WCo=o("xlm-roberta-xl"),QCo=o(" \u2014 "),Cj=a("a"),HCo=o("XLMRobertaXLForMaskedLM"),UCo=o(" (XLM-RoBERTa-XL model)"),JCo=l(),Ju=a("li"),Lde=a("strong"),YCo=o("xlnet"),KCo=o(" \u2014 "),wj=a("a"),ZCo=o("XLNetLMHeadModel"),e5o=o(" (XLNet model)"),o5o=l(),Yu=a("p"),r5o=o("The model is set in evaluation mode by default using "),xde=a("code"),t5o=o("model.eval()"),a5o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$de=a("code"),n5o=o("model.train()"),s5o=l(),F(Ku.$$.fragment),Sqe=l(),Si=a("h2"),Zu=a("a"),kde=a("span"),F(gy.$$.fragment),l5o=l(),Sde=a("span"),i5o=o("AutoModelForCausalLM"),Rqe=l(),$o=a("div"),F(hy.$$.fragment),d5o=l(),Ri=a("p"),c5o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Aj=a("a"),f5o=o("from_pretrained()"),m5o=o(" class method or the "),yj=a("a"),g5o=o("from_config()"),h5o=o(` class
method.`),p5o=l(),py=a("p"),_5o=o("This class cannot be instantiated directly using "),Rde=a("code"),u5o=o("__init__()"),b5o=o(" (throws an error)."),v5o=l(),nt=a("div"),F(_y.$$.fragment),F5o=l(),Pde=a("p"),T5o=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),M5o=l(),Pi=a("p"),E5o=o(`Note:
Loading a model from its configuration file does `),Bde=a("strong"),C5o=o("not"),w5o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Lj=a("a"),A5o=o("from_pretrained()"),y5o=o(" to load the model weights."),L5o=l(),F(e6.$$.fragment),x5o=l(),Ke=a("div"),F(uy.$$.fragment),$5o=l(),Ide=a("p"),k5o=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),S5o=l(),$a=a("p"),R5o=o("The model class to instantiate is selected based on the "),Nde=a("code"),P5o=o("model_type"),B5o=o(` property of the config object (either
passed as an argument or loaded from `),qde=a("code"),I5o=o("pretrained_model_name_or_path"),N5o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jde=a("code"),q5o=o("pretrained_model_name_or_path"),j5o=o(":"),D5o=l(),z=a("ul"),o6=a("li"),Dde=a("strong"),G5o=o("bart"),O5o=o(" \u2014 "),xj=a("a"),V5o=o("BartForCausalLM"),X5o=o(" (BART model)"),z5o=l(),r6=a("li"),Gde=a("strong"),W5o=o("bert"),Q5o=o(" \u2014 "),$j=a("a"),H5o=o("BertLMHeadModel"),U5o=o(" (BERT model)"),J5o=l(),t6=a("li"),Ode=a("strong"),Y5o=o("bert-generation"),K5o=o(" \u2014 "),kj=a("a"),Z5o=o("BertGenerationDecoder"),e3o=o(" (Bert Generation model)"),o3o=l(),a6=a("li"),Vde=a("strong"),r3o=o("big_bird"),t3o=o(" \u2014 "),Sj=a("a"),a3o=o("BigBirdForCausalLM"),n3o=o(" (BigBird model)"),s3o=l(),n6=a("li"),Xde=a("strong"),l3o=o("bigbird_pegasus"),i3o=o(" \u2014 "),Rj=a("a"),d3o=o("BigBirdPegasusForCausalLM"),c3o=o(" (BigBirdPegasus model)"),f3o=l(),s6=a("li"),zde=a("strong"),m3o=o("blenderbot"),g3o=o(" \u2014 "),Pj=a("a"),h3o=o("BlenderbotForCausalLM"),p3o=o(" (Blenderbot model)"),_3o=l(),l6=a("li"),Wde=a("strong"),u3o=o("blenderbot-small"),b3o=o(" \u2014 "),Bj=a("a"),v3o=o("BlenderbotSmallForCausalLM"),F3o=o(" (BlenderbotSmall model)"),T3o=l(),i6=a("li"),Qde=a("strong"),M3o=o("camembert"),E3o=o(" \u2014 "),Ij=a("a"),C3o=o("CamembertForCausalLM"),w3o=o(" (CamemBERT model)"),A3o=l(),d6=a("li"),Hde=a("strong"),y3o=o("ctrl"),L3o=o(" \u2014 "),Nj=a("a"),x3o=o("CTRLLMHeadModel"),$3o=o(" (CTRL model)"),k3o=l(),c6=a("li"),Ude=a("strong"),S3o=o("data2vec-text"),R3o=o(" \u2014 "),qj=a("a"),P3o=o("Data2VecTextForCausalLM"),B3o=o(" (Data2VecText model)"),I3o=l(),f6=a("li"),Jde=a("strong"),N3o=o("electra"),q3o=o(" \u2014 "),jj=a("a"),j3o=o("ElectraForCausalLM"),D3o=o(" (ELECTRA model)"),G3o=l(),m6=a("li"),Yde=a("strong"),O3o=o("gpt2"),V3o=o(" \u2014 "),Dj=a("a"),X3o=o("GPT2LMHeadModel"),z3o=o(" (OpenAI GPT-2 model)"),W3o=l(),g6=a("li"),Kde=a("strong"),Q3o=o("gpt_neo"),H3o=o(" \u2014 "),Gj=a("a"),U3o=o("GPTNeoForCausalLM"),J3o=o(" (GPT Neo model)"),Y3o=l(),h6=a("li"),Zde=a("strong"),K3o=o("gpt_neox"),Z3o=o(" \u2014 "),Oj=a("a"),ewo=o("GPTNeoXForCausalLM"),owo=o(" (GPT NeoX model)"),rwo=l(),p6=a("li"),ece=a("strong"),two=o("gptj"),awo=o(" \u2014 "),Vj=a("a"),nwo=o("GPTJForCausalLM"),swo=o(" (GPT-J model)"),lwo=l(),_6=a("li"),oce=a("strong"),iwo=o("marian"),dwo=o(" \u2014 "),Xj=a("a"),cwo=o("MarianForCausalLM"),fwo=o(" (Marian model)"),mwo=l(),u6=a("li"),rce=a("strong"),gwo=o("mbart"),hwo=o(" \u2014 "),zj=a("a"),pwo=o("MBartForCausalLM"),_wo=o(" (mBART model)"),uwo=l(),b6=a("li"),tce=a("strong"),bwo=o("megatron-bert"),vwo=o(" \u2014 "),Wj=a("a"),Fwo=o("MegatronBertForCausalLM"),Two=o(" (MegatronBert model)"),Mwo=l(),v6=a("li"),ace=a("strong"),Ewo=o("openai-gpt"),Cwo=o(" \u2014 "),Qj=a("a"),wwo=o("OpenAIGPTLMHeadModel"),Awo=o(" (OpenAI GPT model)"),ywo=l(),F6=a("li"),nce=a("strong"),Lwo=o("opt"),xwo=o(" \u2014 "),Hj=a("a"),$wo=o("OPTForCausalLM"),kwo=o(" (OPT model)"),Swo=l(),T6=a("li"),sce=a("strong"),Rwo=o("pegasus"),Pwo=o(" \u2014 "),Uj=a("a"),Bwo=o("PegasusForCausalLM"),Iwo=o(" (Pegasus model)"),Nwo=l(),M6=a("li"),lce=a("strong"),qwo=o("plbart"),jwo=o(" \u2014 "),Jj=a("a"),Dwo=o("PLBartForCausalLM"),Gwo=o(" (PLBart model)"),Owo=l(),E6=a("li"),ice=a("strong"),Vwo=o("prophetnet"),Xwo=o(" \u2014 "),Yj=a("a"),zwo=o("ProphetNetForCausalLM"),Wwo=o(" (ProphetNet model)"),Qwo=l(),C6=a("li"),dce=a("strong"),Hwo=o("qdqbert"),Uwo=o(" \u2014 "),Kj=a("a"),Jwo=o("QDQBertLMHeadModel"),Ywo=o(" (QDQBert model)"),Kwo=l(),w6=a("li"),cce=a("strong"),Zwo=o("reformer"),e0o=o(" \u2014 "),Zj=a("a"),o0o=o("ReformerModelWithLMHead"),r0o=o(" (Reformer model)"),t0o=l(),A6=a("li"),fce=a("strong"),a0o=o("rembert"),n0o=o(" \u2014 "),eD=a("a"),s0o=o("RemBertForCausalLM"),l0o=o(" (RemBERT model)"),i0o=l(),y6=a("li"),mce=a("strong"),d0o=o("roberta"),c0o=o(" \u2014 "),oD=a("a"),f0o=o("RobertaForCausalLM"),m0o=o(" (RoBERTa model)"),g0o=l(),L6=a("li"),gce=a("strong"),h0o=o("roformer"),p0o=o(" \u2014 "),rD=a("a"),_0o=o("RoFormerForCausalLM"),u0o=o(" (RoFormer model)"),b0o=l(),x6=a("li"),hce=a("strong"),v0o=o("speech_to_text_2"),F0o=o(" \u2014 "),tD=a("a"),T0o=o("Speech2Text2ForCausalLM"),M0o=o(" (Speech2Text2 model)"),E0o=l(),$6=a("li"),pce=a("strong"),C0o=o("transfo-xl"),w0o=o(" \u2014 "),aD=a("a"),A0o=o("TransfoXLLMHeadModel"),y0o=o(" (Transformer-XL model)"),L0o=l(),k6=a("li"),_ce=a("strong"),x0o=o("trocr"),$0o=o(" \u2014 "),nD=a("a"),k0o=o("TrOCRForCausalLM"),S0o=o(" (TrOCR model)"),R0o=l(),S6=a("li"),uce=a("strong"),P0o=o("xglm"),B0o=o(" \u2014 "),sD=a("a"),I0o=o("XGLMForCausalLM"),N0o=o(" (XGLM model)"),q0o=l(),R6=a("li"),bce=a("strong"),j0o=o("xlm"),D0o=o(" \u2014 "),lD=a("a"),G0o=o("XLMWithLMHeadModel"),O0o=o(" (XLM model)"),V0o=l(),P6=a("li"),vce=a("strong"),X0o=o("xlm-prophetnet"),z0o=o(" \u2014 "),iD=a("a"),W0o=o("XLMProphetNetForCausalLM"),Q0o=o(" (XLMProphetNet model)"),H0o=l(),B6=a("li"),Fce=a("strong"),U0o=o("xlm-roberta"),J0o=o(" \u2014 "),dD=a("a"),Y0o=o("XLMRobertaForCausalLM"),K0o=o(" (XLM-RoBERTa model)"),Z0o=l(),I6=a("li"),Tce=a("strong"),eAo=o("xlm-roberta-xl"),oAo=o(" \u2014 "),cD=a("a"),rAo=o("XLMRobertaXLForCausalLM"),tAo=o(" (XLM-RoBERTa-XL model)"),aAo=l(),N6=a("li"),Mce=a("strong"),nAo=o("xlnet"),sAo=o(" \u2014 "),fD=a("a"),lAo=o("XLNetLMHeadModel"),iAo=o(" (XLNet model)"),dAo=l(),q6=a("p"),cAo=o("The model is set in evaluation mode by default using "),Ece=a("code"),fAo=o("model.eval()"),mAo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cce=a("code"),gAo=o("model.train()"),hAo=l(),F(j6.$$.fragment),Pqe=l(),Bi=a("h2"),D6=a("a"),wce=a("span"),F(by.$$.fragment),pAo=l(),Ace=a("span"),_Ao=o("AutoModelForMaskedLM"),Bqe=l(),ko=a("div"),F(vy.$$.fragment),uAo=l(),Ii=a("p"),bAo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),mD=a("a"),vAo=o("from_pretrained()"),FAo=o(" class method or the "),gD=a("a"),TAo=o("from_config()"),MAo=o(` class
method.`),EAo=l(),Fy=a("p"),CAo=o("This class cannot be instantiated directly using "),yce=a("code"),wAo=o("__init__()"),AAo=o(" (throws an error)."),yAo=l(),st=a("div"),F(Ty.$$.fragment),LAo=l(),Lce=a("p"),xAo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),$Ao=l(),Ni=a("p"),kAo=o(`Note:
Loading a model from its configuration file does `),xce=a("strong"),SAo=o("not"),RAo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hD=a("a"),PAo=o("from_pretrained()"),BAo=o(" to load the model weights."),IAo=l(),F(G6.$$.fragment),NAo=l(),Ze=a("div"),F(My.$$.fragment),qAo=l(),$ce=a("p"),jAo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),DAo=l(),ka=a("p"),GAo=o("The model class to instantiate is selected based on the "),kce=a("code"),OAo=o("model_type"),VAo=o(` property of the config object (either
passed as an argument or loaded from `),Sce=a("code"),XAo=o("pretrained_model_name_or_path"),zAo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rce=a("code"),WAo=o("pretrained_model_name_or_path"),QAo=o(":"),HAo=l(),Q=a("ul"),O6=a("li"),Pce=a("strong"),UAo=o("albert"),JAo=o(" \u2014 "),pD=a("a"),YAo=o("AlbertForMaskedLM"),KAo=o(" (ALBERT model)"),ZAo=l(),V6=a("li"),Bce=a("strong"),eyo=o("bart"),oyo=o(" \u2014 "),_D=a("a"),ryo=o("BartForConditionalGeneration"),tyo=o(" (BART model)"),ayo=l(),X6=a("li"),Ice=a("strong"),nyo=o("bert"),syo=o(" \u2014 "),uD=a("a"),lyo=o("BertForMaskedLM"),iyo=o(" (BERT model)"),dyo=l(),z6=a("li"),Nce=a("strong"),cyo=o("big_bird"),fyo=o(" \u2014 "),bD=a("a"),myo=o("BigBirdForMaskedLM"),gyo=o(" (BigBird model)"),hyo=l(),W6=a("li"),qce=a("strong"),pyo=o("camembert"),_yo=o(" \u2014 "),vD=a("a"),uyo=o("CamembertForMaskedLM"),byo=o(" (CamemBERT model)"),vyo=l(),Q6=a("li"),jce=a("strong"),Fyo=o("convbert"),Tyo=o(" \u2014 "),FD=a("a"),Myo=o("ConvBertForMaskedLM"),Eyo=o(" (ConvBERT model)"),Cyo=l(),H6=a("li"),Dce=a("strong"),wyo=o("data2vec-text"),Ayo=o(" \u2014 "),TD=a("a"),yyo=o("Data2VecTextForMaskedLM"),Lyo=o(" (Data2VecText model)"),xyo=l(),U6=a("li"),Gce=a("strong"),$yo=o("deberta"),kyo=o(" \u2014 "),MD=a("a"),Syo=o("DebertaForMaskedLM"),Ryo=o(" (DeBERTa model)"),Pyo=l(),J6=a("li"),Oce=a("strong"),Byo=o("deberta-v2"),Iyo=o(" \u2014 "),ED=a("a"),Nyo=o("DebertaV2ForMaskedLM"),qyo=o(" (DeBERTa-v2 model)"),jyo=l(),Y6=a("li"),Vce=a("strong"),Dyo=o("distilbert"),Gyo=o(" \u2014 "),CD=a("a"),Oyo=o("DistilBertForMaskedLM"),Vyo=o(" (DistilBERT model)"),Xyo=l(),K6=a("li"),Xce=a("strong"),zyo=o("electra"),Wyo=o(" \u2014 "),wD=a("a"),Qyo=o("ElectraForMaskedLM"),Hyo=o(" (ELECTRA model)"),Uyo=l(),Z6=a("li"),zce=a("strong"),Jyo=o("flaubert"),Yyo=o(" \u2014 "),AD=a("a"),Kyo=o("FlaubertWithLMHeadModel"),Zyo=o(" (FlauBERT model)"),eLo=l(),e1=a("li"),Wce=a("strong"),oLo=o("fnet"),rLo=o(" \u2014 "),yD=a("a"),tLo=o("FNetForMaskedLM"),aLo=o(" (FNet model)"),nLo=l(),o1=a("li"),Qce=a("strong"),sLo=o("funnel"),lLo=o(" \u2014 "),LD=a("a"),iLo=o("FunnelForMaskedLM"),dLo=o(" (Funnel Transformer model)"),cLo=l(),r1=a("li"),Hce=a("strong"),fLo=o("ibert"),mLo=o(" \u2014 "),xD=a("a"),gLo=o("IBertForMaskedLM"),hLo=o(" (I-BERT model)"),pLo=l(),t1=a("li"),Uce=a("strong"),_Lo=o("layoutlm"),uLo=o(" \u2014 "),$D=a("a"),bLo=o("LayoutLMForMaskedLM"),vLo=o(" (LayoutLM model)"),FLo=l(),a1=a("li"),Jce=a("strong"),TLo=o("longformer"),MLo=o(" \u2014 "),kD=a("a"),ELo=o("LongformerForMaskedLM"),CLo=o(" (Longformer model)"),wLo=l(),n1=a("li"),Yce=a("strong"),ALo=o("mbart"),yLo=o(" \u2014 "),SD=a("a"),LLo=o("MBartForConditionalGeneration"),xLo=o(" (mBART model)"),$Lo=l(),s1=a("li"),Kce=a("strong"),kLo=o("megatron-bert"),SLo=o(" \u2014 "),RD=a("a"),RLo=o("MegatronBertForMaskedLM"),PLo=o(" (MegatronBert model)"),BLo=l(),l1=a("li"),Zce=a("strong"),ILo=o("mobilebert"),NLo=o(" \u2014 "),PD=a("a"),qLo=o("MobileBertForMaskedLM"),jLo=o(" (MobileBERT model)"),DLo=l(),i1=a("li"),efe=a("strong"),GLo=o("mpnet"),OLo=o(" \u2014 "),BD=a("a"),VLo=o("MPNetForMaskedLM"),XLo=o(" (MPNet model)"),zLo=l(),d1=a("li"),ofe=a("strong"),WLo=o("nystromformer"),QLo=o(" \u2014 "),ID=a("a"),HLo=o("NystromformerForMaskedLM"),ULo=o(" (Nystromformer model)"),JLo=l(),c1=a("li"),rfe=a("strong"),YLo=o("perceiver"),KLo=o(" \u2014 "),ND=a("a"),ZLo=o("PerceiverForMaskedLM"),e8o=o(" (Perceiver model)"),o8o=l(),f1=a("li"),tfe=a("strong"),r8o=o("qdqbert"),t8o=o(" \u2014 "),qD=a("a"),a8o=o("QDQBertForMaskedLM"),n8o=o(" (QDQBert model)"),s8o=l(),m1=a("li"),afe=a("strong"),l8o=o("reformer"),i8o=o(" \u2014 "),jD=a("a"),d8o=o("ReformerForMaskedLM"),c8o=o(" (Reformer model)"),f8o=l(),g1=a("li"),nfe=a("strong"),m8o=o("rembert"),g8o=o(" \u2014 "),DD=a("a"),h8o=o("RemBertForMaskedLM"),p8o=o(" (RemBERT model)"),_8o=l(),h1=a("li"),sfe=a("strong"),u8o=o("roberta"),b8o=o(" \u2014 "),GD=a("a"),v8o=o("RobertaForMaskedLM"),F8o=o(" (RoBERTa model)"),T8o=l(),p1=a("li"),lfe=a("strong"),M8o=o("roformer"),E8o=o(" \u2014 "),OD=a("a"),C8o=o("RoFormerForMaskedLM"),w8o=o(" (RoFormer model)"),A8o=l(),_1=a("li"),ife=a("strong"),y8o=o("squeezebert"),L8o=o(" \u2014 "),VD=a("a"),x8o=o("SqueezeBertForMaskedLM"),$8o=o(" (SqueezeBERT model)"),k8o=l(),u1=a("li"),dfe=a("strong"),S8o=o("tapas"),R8o=o(" \u2014 "),XD=a("a"),P8o=o("TapasForMaskedLM"),B8o=o(" (TAPAS model)"),I8o=l(),b1=a("li"),cfe=a("strong"),N8o=o("wav2vec2"),q8o=o(" \u2014 "),ffe=a("code"),j8o=o("Wav2Vec2ForMaskedLM"),D8o=o(" (Wav2Vec2 model)"),G8o=l(),v1=a("li"),mfe=a("strong"),O8o=o("xlm"),V8o=o(" \u2014 "),zD=a("a"),X8o=o("XLMWithLMHeadModel"),z8o=o(" (XLM model)"),W8o=l(),F1=a("li"),gfe=a("strong"),Q8o=o("xlm-roberta"),H8o=o(" \u2014 "),WD=a("a"),U8o=o("XLMRobertaForMaskedLM"),J8o=o(" (XLM-RoBERTa model)"),Y8o=l(),T1=a("li"),hfe=a("strong"),K8o=o("xlm-roberta-xl"),Z8o=o(" \u2014 "),QD=a("a"),e9o=o("XLMRobertaXLForMaskedLM"),o9o=o(" (XLM-RoBERTa-XL model)"),r9o=l(),M1=a("li"),pfe=a("strong"),t9o=o("yoso"),a9o=o(" \u2014 "),HD=a("a"),n9o=o("YosoForMaskedLM"),s9o=o(" (YOSO model)"),l9o=l(),E1=a("p"),i9o=o("The model is set in evaluation mode by default using "),_fe=a("code"),d9o=o("model.eval()"),c9o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ufe=a("code"),f9o=o("model.train()"),m9o=l(),F(C1.$$.fragment),Iqe=l(),qi=a("h2"),w1=a("a"),bfe=a("span"),F(Ey.$$.fragment),g9o=l(),vfe=a("span"),h9o=o("AutoModelForSeq2SeqLM"),Nqe=l(),So=a("div"),F(Cy.$$.fragment),p9o=l(),ji=a("p"),_9o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),UD=a("a"),u9o=o("from_pretrained()"),b9o=o(" class method or the "),JD=a("a"),v9o=o("from_config()"),F9o=o(` class
method.`),T9o=l(),wy=a("p"),M9o=o("This class cannot be instantiated directly using "),Ffe=a("code"),E9o=o("__init__()"),C9o=o(" (throws an error)."),w9o=l(),lt=a("div"),F(Ay.$$.fragment),A9o=l(),Tfe=a("p"),y9o=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),L9o=l(),Di=a("p"),x9o=o(`Note:
Loading a model from its configuration file does `),Mfe=a("strong"),$9o=o("not"),k9o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YD=a("a"),S9o=o("from_pretrained()"),R9o=o(" to load the model weights."),P9o=l(),F(A1.$$.fragment),B9o=l(),eo=a("div"),F(yy.$$.fragment),I9o=l(),Efe=a("p"),N9o=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),q9o=l(),Sa=a("p"),j9o=o("The model class to instantiate is selected based on the "),Cfe=a("code"),D9o=o("model_type"),G9o=o(` property of the config object (either
passed as an argument or loaded from `),wfe=a("code"),O9o=o("pretrained_model_name_or_path"),V9o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Afe=a("code"),X9o=o("pretrained_model_name_or_path"),z9o=o(":"),W9o=l(),_e=a("ul"),y1=a("li"),yfe=a("strong"),Q9o=o("bart"),H9o=o(" \u2014 "),KD=a("a"),U9o=o("BartForConditionalGeneration"),J9o=o(" (BART model)"),Y9o=l(),L1=a("li"),Lfe=a("strong"),K9o=o("bigbird_pegasus"),Z9o=o(" \u2014 "),ZD=a("a"),exo=o("BigBirdPegasusForConditionalGeneration"),oxo=o(" (BigBirdPegasus model)"),rxo=l(),x1=a("li"),xfe=a("strong"),txo=o("blenderbot"),axo=o(" \u2014 "),eG=a("a"),nxo=o("BlenderbotForConditionalGeneration"),sxo=o(" (Blenderbot model)"),lxo=l(),$1=a("li"),$fe=a("strong"),ixo=o("blenderbot-small"),dxo=o(" \u2014 "),oG=a("a"),cxo=o("BlenderbotSmallForConditionalGeneration"),fxo=o(" (BlenderbotSmall model)"),mxo=l(),k1=a("li"),kfe=a("strong"),gxo=o("encoder-decoder"),hxo=o(" \u2014 "),rG=a("a"),pxo=o("EncoderDecoderModel"),_xo=o(" (Encoder decoder model)"),uxo=l(),S1=a("li"),Sfe=a("strong"),bxo=o("fsmt"),vxo=o(" \u2014 "),tG=a("a"),Fxo=o("FSMTForConditionalGeneration"),Txo=o(" (FairSeq Machine-Translation model)"),Mxo=l(),R1=a("li"),Rfe=a("strong"),Exo=o("led"),Cxo=o(" \u2014 "),aG=a("a"),wxo=o("LEDForConditionalGeneration"),Axo=o(" (LED model)"),yxo=l(),P1=a("li"),Pfe=a("strong"),Lxo=o("m2m_100"),xxo=o(" \u2014 "),nG=a("a"),$xo=o("M2M100ForConditionalGeneration"),kxo=o(" (M2M100 model)"),Sxo=l(),B1=a("li"),Bfe=a("strong"),Rxo=o("marian"),Pxo=o(" \u2014 "),sG=a("a"),Bxo=o("MarianMTModel"),Ixo=o(" (Marian model)"),Nxo=l(),I1=a("li"),Ife=a("strong"),qxo=o("mbart"),jxo=o(" \u2014 "),lG=a("a"),Dxo=o("MBartForConditionalGeneration"),Gxo=o(" (mBART model)"),Oxo=l(),N1=a("li"),Nfe=a("strong"),Vxo=o("mt5"),Xxo=o(" \u2014 "),iG=a("a"),zxo=o("MT5ForConditionalGeneration"),Wxo=o(" (mT5 model)"),Qxo=l(),q1=a("li"),qfe=a("strong"),Hxo=o("pegasus"),Uxo=o(" \u2014 "),dG=a("a"),Jxo=o("PegasusForConditionalGeneration"),Yxo=o(" (Pegasus model)"),Kxo=l(),j1=a("li"),jfe=a("strong"),Zxo=o("plbart"),e$o=o(" \u2014 "),cG=a("a"),o$o=o("PLBartForConditionalGeneration"),r$o=o(" (PLBart model)"),t$o=l(),D1=a("li"),Dfe=a("strong"),a$o=o("prophetnet"),n$o=o(" \u2014 "),fG=a("a"),s$o=o("ProphetNetForConditionalGeneration"),l$o=o(" (ProphetNet model)"),i$o=l(),G1=a("li"),Gfe=a("strong"),d$o=o("t5"),c$o=o(" \u2014 "),mG=a("a"),f$o=o("T5ForConditionalGeneration"),m$o=o(" (T5 model)"),g$o=l(),O1=a("li"),Ofe=a("strong"),h$o=o("xlm-prophetnet"),p$o=o(" \u2014 "),gG=a("a"),_$o=o("XLMProphetNetForConditionalGeneration"),u$o=o(" (XLMProphetNet model)"),b$o=l(),V1=a("p"),v$o=o("The model is set in evaluation mode by default using "),Vfe=a("code"),F$o=o("model.eval()"),T$o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Xfe=a("code"),M$o=o("model.train()"),E$o=l(),F(X1.$$.fragment),qqe=l(),Gi=a("h2"),z1=a("a"),zfe=a("span"),F(Ly.$$.fragment),C$o=l(),Wfe=a("span"),w$o=o("AutoModelForSequenceClassification"),jqe=l(),Ro=a("div"),F(xy.$$.fragment),A$o=l(),Oi=a("p"),y$o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),hG=a("a"),L$o=o("from_pretrained()"),x$o=o(" class method or the "),pG=a("a"),$$o=o("from_config()"),k$o=o(` class
method.`),S$o=l(),$y=a("p"),R$o=o("This class cannot be instantiated directly using "),Qfe=a("code"),P$o=o("__init__()"),B$o=o(" (throws an error)."),I$o=l(),it=a("div"),F(ky.$$.fragment),N$o=l(),Hfe=a("p"),q$o=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),j$o=l(),Vi=a("p"),D$o=o(`Note:
Loading a model from its configuration file does `),Ufe=a("strong"),G$o=o("not"),O$o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_G=a("a"),V$o=o("from_pretrained()"),X$o=o(" to load the model weights."),z$o=l(),F(W1.$$.fragment),W$o=l(),oo=a("div"),F(Sy.$$.fragment),Q$o=l(),Jfe=a("p"),H$o=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),U$o=l(),Ra=a("p"),J$o=o("The model class to instantiate is selected based on the "),Yfe=a("code"),Y$o=o("model_type"),K$o=o(` property of the config object (either
passed as an argument or loaded from `),Kfe=a("code"),Z$o=o("pretrained_model_name_or_path"),eko=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zfe=a("code"),oko=o("pretrained_model_name_or_path"),rko=o(":"),tko=l(),N=a("ul"),Q1=a("li"),eme=a("strong"),ako=o("albert"),nko=o(" \u2014 "),uG=a("a"),sko=o("AlbertForSequenceClassification"),lko=o(" (ALBERT model)"),iko=l(),H1=a("li"),ome=a("strong"),dko=o("bart"),cko=o(" \u2014 "),bG=a("a"),fko=o("BartForSequenceClassification"),mko=o(" (BART model)"),gko=l(),U1=a("li"),rme=a("strong"),hko=o("bert"),pko=o(" \u2014 "),vG=a("a"),_ko=o("BertForSequenceClassification"),uko=o(" (BERT model)"),bko=l(),J1=a("li"),tme=a("strong"),vko=o("big_bird"),Fko=o(" \u2014 "),FG=a("a"),Tko=o("BigBirdForSequenceClassification"),Mko=o(" (BigBird model)"),Eko=l(),Y1=a("li"),ame=a("strong"),Cko=o("bigbird_pegasus"),wko=o(" \u2014 "),TG=a("a"),Ako=o("BigBirdPegasusForSequenceClassification"),yko=o(" (BigBirdPegasus model)"),Lko=l(),K1=a("li"),nme=a("strong"),xko=o("camembert"),$ko=o(" \u2014 "),MG=a("a"),kko=o("CamembertForSequenceClassification"),Sko=o(" (CamemBERT model)"),Rko=l(),Z1=a("li"),sme=a("strong"),Pko=o("canine"),Bko=o(" \u2014 "),EG=a("a"),Iko=o("CanineForSequenceClassification"),Nko=o(" (Canine model)"),qko=l(),eb=a("li"),lme=a("strong"),jko=o("convbert"),Dko=o(" \u2014 "),CG=a("a"),Gko=o("ConvBertForSequenceClassification"),Oko=o(" (ConvBERT model)"),Vko=l(),ob=a("li"),ime=a("strong"),Xko=o("ctrl"),zko=o(" \u2014 "),wG=a("a"),Wko=o("CTRLForSequenceClassification"),Qko=o(" (CTRL model)"),Hko=l(),rb=a("li"),dme=a("strong"),Uko=o("data2vec-text"),Jko=o(" \u2014 "),AG=a("a"),Yko=o("Data2VecTextForSequenceClassification"),Kko=o(" (Data2VecText model)"),Zko=l(),tb=a("li"),cme=a("strong"),eSo=o("deberta"),oSo=o(" \u2014 "),yG=a("a"),rSo=o("DebertaForSequenceClassification"),tSo=o(" (DeBERTa model)"),aSo=l(),ab=a("li"),fme=a("strong"),nSo=o("deberta-v2"),sSo=o(" \u2014 "),LG=a("a"),lSo=o("DebertaV2ForSequenceClassification"),iSo=o(" (DeBERTa-v2 model)"),dSo=l(),nb=a("li"),mme=a("strong"),cSo=o("distilbert"),fSo=o(" \u2014 "),xG=a("a"),mSo=o("DistilBertForSequenceClassification"),gSo=o(" (DistilBERT model)"),hSo=l(),sb=a("li"),gme=a("strong"),pSo=o("electra"),_So=o(" \u2014 "),$G=a("a"),uSo=o("ElectraForSequenceClassification"),bSo=o(" (ELECTRA model)"),vSo=l(),lb=a("li"),hme=a("strong"),FSo=o("flaubert"),TSo=o(" \u2014 "),kG=a("a"),MSo=o("FlaubertForSequenceClassification"),ESo=o(" (FlauBERT model)"),CSo=l(),ib=a("li"),pme=a("strong"),wSo=o("fnet"),ASo=o(" \u2014 "),SG=a("a"),ySo=o("FNetForSequenceClassification"),LSo=o(" (FNet model)"),xSo=l(),db=a("li"),_me=a("strong"),$So=o("funnel"),kSo=o(" \u2014 "),RG=a("a"),SSo=o("FunnelForSequenceClassification"),RSo=o(" (Funnel Transformer model)"),PSo=l(),cb=a("li"),ume=a("strong"),BSo=o("gpt2"),ISo=o(" \u2014 "),PG=a("a"),NSo=o("GPT2ForSequenceClassification"),qSo=o(" (OpenAI GPT-2 model)"),jSo=l(),fb=a("li"),bme=a("strong"),DSo=o("gpt_neo"),GSo=o(" \u2014 "),BG=a("a"),OSo=o("GPTNeoForSequenceClassification"),VSo=o(" (GPT Neo model)"),XSo=l(),mb=a("li"),vme=a("strong"),zSo=o("gptj"),WSo=o(" \u2014 "),IG=a("a"),QSo=o("GPTJForSequenceClassification"),HSo=o(" (GPT-J model)"),USo=l(),gb=a("li"),Fme=a("strong"),JSo=o("ibert"),YSo=o(" \u2014 "),NG=a("a"),KSo=o("IBertForSequenceClassification"),ZSo=o(" (I-BERT model)"),eRo=l(),hb=a("li"),Tme=a("strong"),oRo=o("layoutlm"),rRo=o(" \u2014 "),qG=a("a"),tRo=o("LayoutLMForSequenceClassification"),aRo=o(" (LayoutLM model)"),nRo=l(),pb=a("li"),Mme=a("strong"),sRo=o("layoutlmv2"),lRo=o(" \u2014 "),jG=a("a"),iRo=o("LayoutLMv2ForSequenceClassification"),dRo=o(" (LayoutLMv2 model)"),cRo=l(),_b=a("li"),Eme=a("strong"),fRo=o("layoutlmv3"),mRo=o(" \u2014 "),DG=a("a"),gRo=o("LayoutLMv3ForSequenceClassification"),hRo=o(" (LayoutLMv3 model)"),pRo=l(),ub=a("li"),Cme=a("strong"),_Ro=o("led"),uRo=o(" \u2014 "),GG=a("a"),bRo=o("LEDForSequenceClassification"),vRo=o(" (LED model)"),FRo=l(),bb=a("li"),wme=a("strong"),TRo=o("longformer"),MRo=o(" \u2014 "),OG=a("a"),ERo=o("LongformerForSequenceClassification"),CRo=o(" (Longformer model)"),wRo=l(),vb=a("li"),Ame=a("strong"),ARo=o("mbart"),yRo=o(" \u2014 "),VG=a("a"),LRo=o("MBartForSequenceClassification"),xRo=o(" (mBART model)"),$Ro=l(),Fb=a("li"),yme=a("strong"),kRo=o("megatron-bert"),SRo=o(" \u2014 "),XG=a("a"),RRo=o("MegatronBertForSequenceClassification"),PRo=o(" (MegatronBert model)"),BRo=l(),Tb=a("li"),Lme=a("strong"),IRo=o("mobilebert"),NRo=o(" \u2014 "),zG=a("a"),qRo=o("MobileBertForSequenceClassification"),jRo=o(" (MobileBERT model)"),DRo=l(),Mb=a("li"),xme=a("strong"),GRo=o("mpnet"),ORo=o(" \u2014 "),WG=a("a"),VRo=o("MPNetForSequenceClassification"),XRo=o(" (MPNet model)"),zRo=l(),Eb=a("li"),$me=a("strong"),WRo=o("nystromformer"),QRo=o(" \u2014 "),QG=a("a"),HRo=o("NystromformerForSequenceClassification"),URo=o(" (Nystromformer model)"),JRo=l(),Cb=a("li"),kme=a("strong"),YRo=o("openai-gpt"),KRo=o(" \u2014 "),HG=a("a"),ZRo=o("OpenAIGPTForSequenceClassification"),ePo=o(" (OpenAI GPT model)"),oPo=l(),wb=a("li"),Sme=a("strong"),rPo=o("perceiver"),tPo=o(" \u2014 "),UG=a("a"),aPo=o("PerceiverForSequenceClassification"),nPo=o(" (Perceiver model)"),sPo=l(),Ab=a("li"),Rme=a("strong"),lPo=o("plbart"),iPo=o(" \u2014 "),JG=a("a"),dPo=o("PLBartForSequenceClassification"),cPo=o(" (PLBart model)"),fPo=l(),yb=a("li"),Pme=a("strong"),mPo=o("qdqbert"),gPo=o(" \u2014 "),YG=a("a"),hPo=o("QDQBertForSequenceClassification"),pPo=o(" (QDQBert model)"),_Po=l(),Lb=a("li"),Bme=a("strong"),uPo=o("reformer"),bPo=o(" \u2014 "),KG=a("a"),vPo=o("ReformerForSequenceClassification"),FPo=o(" (Reformer model)"),TPo=l(),xb=a("li"),Ime=a("strong"),MPo=o("rembert"),EPo=o(" \u2014 "),ZG=a("a"),CPo=o("RemBertForSequenceClassification"),wPo=o(" (RemBERT model)"),APo=l(),$b=a("li"),Nme=a("strong"),yPo=o("roberta"),LPo=o(" \u2014 "),eO=a("a"),xPo=o("RobertaForSequenceClassification"),$Po=o(" (RoBERTa model)"),kPo=l(),kb=a("li"),qme=a("strong"),SPo=o("roformer"),RPo=o(" \u2014 "),oO=a("a"),PPo=o("RoFormerForSequenceClassification"),BPo=o(" (RoFormer model)"),IPo=l(),Sb=a("li"),jme=a("strong"),NPo=o("squeezebert"),qPo=o(" \u2014 "),rO=a("a"),jPo=o("SqueezeBertForSequenceClassification"),DPo=o(" (SqueezeBERT model)"),GPo=l(),Rb=a("li"),Dme=a("strong"),OPo=o("tapas"),VPo=o(" \u2014 "),tO=a("a"),XPo=o("TapasForSequenceClassification"),zPo=o(" (TAPAS model)"),WPo=l(),Pb=a("li"),Gme=a("strong"),QPo=o("transfo-xl"),HPo=o(" \u2014 "),aO=a("a"),UPo=o("TransfoXLForSequenceClassification"),JPo=o(" (Transformer-XL model)"),YPo=l(),Bb=a("li"),Ome=a("strong"),KPo=o("xlm"),ZPo=o(" \u2014 "),nO=a("a"),eBo=o("XLMForSequenceClassification"),oBo=o(" (XLM model)"),rBo=l(),Ib=a("li"),Vme=a("strong"),tBo=o("xlm-roberta"),aBo=o(" \u2014 "),sO=a("a"),nBo=o("XLMRobertaForSequenceClassification"),sBo=o(" (XLM-RoBERTa model)"),lBo=l(),Nb=a("li"),Xme=a("strong"),iBo=o("xlm-roberta-xl"),dBo=o(" \u2014 "),lO=a("a"),cBo=o("XLMRobertaXLForSequenceClassification"),fBo=o(" (XLM-RoBERTa-XL model)"),mBo=l(),qb=a("li"),zme=a("strong"),gBo=o("xlnet"),hBo=o(" \u2014 "),iO=a("a"),pBo=o("XLNetForSequenceClassification"),_Bo=o(" (XLNet model)"),uBo=l(),jb=a("li"),Wme=a("strong"),bBo=o("yoso"),vBo=o(" \u2014 "),dO=a("a"),FBo=o("YosoForSequenceClassification"),TBo=o(" (YOSO model)"),MBo=l(),Db=a("p"),EBo=o("The model is set in evaluation mode by default using "),Qme=a("code"),CBo=o("model.eval()"),wBo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Hme=a("code"),ABo=o("model.train()"),yBo=l(),F(Gb.$$.fragment),Dqe=l(),Xi=a("h2"),Ob=a("a"),Ume=a("span"),F(Ry.$$.fragment),LBo=l(),Jme=a("span"),xBo=o("AutoModelForMultipleChoice"),Gqe=l(),Po=a("div"),F(Py.$$.fragment),$Bo=l(),zi=a("p"),kBo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),cO=a("a"),SBo=o("from_pretrained()"),RBo=o(" class method or the "),fO=a("a"),PBo=o("from_config()"),BBo=o(` class
method.`),IBo=l(),By=a("p"),NBo=o("This class cannot be instantiated directly using "),Yme=a("code"),qBo=o("__init__()"),jBo=o(" (throws an error)."),DBo=l(),dt=a("div"),F(Iy.$$.fragment),GBo=l(),Kme=a("p"),OBo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),VBo=l(),Wi=a("p"),XBo=o(`Note:
Loading a model from its configuration file does `),Zme=a("strong"),zBo=o("not"),WBo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mO=a("a"),QBo=o("from_pretrained()"),HBo=o(" to load the model weights."),UBo=l(),F(Vb.$$.fragment),JBo=l(),ro=a("div"),F(Ny.$$.fragment),YBo=l(),ege=a("p"),KBo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),ZBo=l(),Pa=a("p"),eIo=o("The model class to instantiate is selected based on the "),oge=a("code"),oIo=o("model_type"),rIo=o(` property of the config object (either
passed as an argument or loaded from `),rge=a("code"),tIo=o("pretrained_model_name_or_path"),aIo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tge=a("code"),nIo=o("pretrained_model_name_or_path"),sIo=o(":"),lIo=l(),K=a("ul"),Xb=a("li"),age=a("strong"),iIo=o("albert"),dIo=o(" \u2014 "),gO=a("a"),cIo=o("AlbertForMultipleChoice"),fIo=o(" (ALBERT model)"),mIo=l(),zb=a("li"),nge=a("strong"),gIo=o("bert"),hIo=o(" \u2014 "),hO=a("a"),pIo=o("BertForMultipleChoice"),_Io=o(" (BERT model)"),uIo=l(),Wb=a("li"),sge=a("strong"),bIo=o("big_bird"),vIo=o(" \u2014 "),pO=a("a"),FIo=o("BigBirdForMultipleChoice"),TIo=o(" (BigBird model)"),MIo=l(),Qb=a("li"),lge=a("strong"),EIo=o("camembert"),CIo=o(" \u2014 "),_O=a("a"),wIo=o("CamembertForMultipleChoice"),AIo=o(" (CamemBERT model)"),yIo=l(),Hb=a("li"),ige=a("strong"),LIo=o("canine"),xIo=o(" \u2014 "),uO=a("a"),$Io=o("CanineForMultipleChoice"),kIo=o(" (Canine model)"),SIo=l(),Ub=a("li"),dge=a("strong"),RIo=o("convbert"),PIo=o(" \u2014 "),bO=a("a"),BIo=o("ConvBertForMultipleChoice"),IIo=o(" (ConvBERT model)"),NIo=l(),Jb=a("li"),cge=a("strong"),qIo=o("data2vec-text"),jIo=o(" \u2014 "),vO=a("a"),DIo=o("Data2VecTextForMultipleChoice"),GIo=o(" (Data2VecText model)"),OIo=l(),Yb=a("li"),fge=a("strong"),VIo=o("deberta-v2"),XIo=o(" \u2014 "),FO=a("a"),zIo=o("DebertaV2ForMultipleChoice"),WIo=o(" (DeBERTa-v2 model)"),QIo=l(),Kb=a("li"),mge=a("strong"),HIo=o("distilbert"),UIo=o(" \u2014 "),TO=a("a"),JIo=o("DistilBertForMultipleChoice"),YIo=o(" (DistilBERT model)"),KIo=l(),Zb=a("li"),gge=a("strong"),ZIo=o("electra"),eNo=o(" \u2014 "),MO=a("a"),oNo=o("ElectraForMultipleChoice"),rNo=o(" (ELECTRA model)"),tNo=l(),e2=a("li"),hge=a("strong"),aNo=o("flaubert"),nNo=o(" \u2014 "),EO=a("a"),sNo=o("FlaubertForMultipleChoice"),lNo=o(" (FlauBERT model)"),iNo=l(),o2=a("li"),pge=a("strong"),dNo=o("fnet"),cNo=o(" \u2014 "),CO=a("a"),fNo=o("FNetForMultipleChoice"),mNo=o(" (FNet model)"),gNo=l(),r2=a("li"),_ge=a("strong"),hNo=o("funnel"),pNo=o(" \u2014 "),wO=a("a"),_No=o("FunnelForMultipleChoice"),uNo=o(" (Funnel Transformer model)"),bNo=l(),t2=a("li"),uge=a("strong"),vNo=o("ibert"),FNo=o(" \u2014 "),AO=a("a"),TNo=o("IBertForMultipleChoice"),MNo=o(" (I-BERT model)"),ENo=l(),a2=a("li"),bge=a("strong"),CNo=o("longformer"),wNo=o(" \u2014 "),yO=a("a"),ANo=o("LongformerForMultipleChoice"),yNo=o(" (Longformer model)"),LNo=l(),n2=a("li"),vge=a("strong"),xNo=o("megatron-bert"),$No=o(" \u2014 "),LO=a("a"),kNo=o("MegatronBertForMultipleChoice"),SNo=o(" (MegatronBert model)"),RNo=l(),s2=a("li"),Fge=a("strong"),PNo=o("mobilebert"),BNo=o(" \u2014 "),xO=a("a"),INo=o("MobileBertForMultipleChoice"),NNo=o(" (MobileBERT model)"),qNo=l(),l2=a("li"),Tge=a("strong"),jNo=o("mpnet"),DNo=o(" \u2014 "),$O=a("a"),GNo=o("MPNetForMultipleChoice"),ONo=o(" (MPNet model)"),VNo=l(),i2=a("li"),Mge=a("strong"),XNo=o("nystromformer"),zNo=o(" \u2014 "),kO=a("a"),WNo=o("NystromformerForMultipleChoice"),QNo=o(" (Nystromformer model)"),HNo=l(),d2=a("li"),Ege=a("strong"),UNo=o("qdqbert"),JNo=o(" \u2014 "),SO=a("a"),YNo=o("QDQBertForMultipleChoice"),KNo=o(" (QDQBert model)"),ZNo=l(),c2=a("li"),Cge=a("strong"),eqo=o("rembert"),oqo=o(" \u2014 "),RO=a("a"),rqo=o("RemBertForMultipleChoice"),tqo=o(" (RemBERT model)"),aqo=l(),f2=a("li"),wge=a("strong"),nqo=o("roberta"),sqo=o(" \u2014 "),PO=a("a"),lqo=o("RobertaForMultipleChoice"),iqo=o(" (RoBERTa model)"),dqo=l(),m2=a("li"),Age=a("strong"),cqo=o("roformer"),fqo=o(" \u2014 "),BO=a("a"),mqo=o("RoFormerForMultipleChoice"),gqo=o(" (RoFormer model)"),hqo=l(),g2=a("li"),yge=a("strong"),pqo=o("squeezebert"),_qo=o(" \u2014 "),IO=a("a"),uqo=o("SqueezeBertForMultipleChoice"),bqo=o(" (SqueezeBERT model)"),vqo=l(),h2=a("li"),Lge=a("strong"),Fqo=o("xlm"),Tqo=o(" \u2014 "),NO=a("a"),Mqo=o("XLMForMultipleChoice"),Eqo=o(" (XLM model)"),Cqo=l(),p2=a("li"),xge=a("strong"),wqo=o("xlm-roberta"),Aqo=o(" \u2014 "),qO=a("a"),yqo=o("XLMRobertaForMultipleChoice"),Lqo=o(" (XLM-RoBERTa model)"),xqo=l(),_2=a("li"),$ge=a("strong"),$qo=o("xlm-roberta-xl"),kqo=o(" \u2014 "),jO=a("a"),Sqo=o("XLMRobertaXLForMultipleChoice"),Rqo=o(" (XLM-RoBERTa-XL model)"),Pqo=l(),u2=a("li"),kge=a("strong"),Bqo=o("xlnet"),Iqo=o(" \u2014 "),DO=a("a"),Nqo=o("XLNetForMultipleChoice"),qqo=o(" (XLNet model)"),jqo=l(),b2=a("li"),Sge=a("strong"),Dqo=o("yoso"),Gqo=o(" \u2014 "),GO=a("a"),Oqo=o("YosoForMultipleChoice"),Vqo=o(" (YOSO model)"),Xqo=l(),v2=a("p"),zqo=o("The model is set in evaluation mode by default using "),Rge=a("code"),Wqo=o("model.eval()"),Qqo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Pge=a("code"),Hqo=o("model.train()"),Uqo=l(),F(F2.$$.fragment),Oqe=l(),Qi=a("h2"),T2=a("a"),Bge=a("span"),F(qy.$$.fragment),Jqo=l(),Ige=a("span"),Yqo=o("AutoModelForNextSentencePrediction"),Vqe=l(),Bo=a("div"),F(jy.$$.fragment),Kqo=l(),Hi=a("p"),Zqo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),OO=a("a"),ejo=o("from_pretrained()"),ojo=o(" class method or the "),VO=a("a"),rjo=o("from_config()"),tjo=o(` class
method.`),ajo=l(),Dy=a("p"),njo=o("This class cannot be instantiated directly using "),Nge=a("code"),sjo=o("__init__()"),ljo=o(" (throws an error)."),ijo=l(),ct=a("div"),F(Gy.$$.fragment),djo=l(),qge=a("p"),cjo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),fjo=l(),Ui=a("p"),mjo=o(`Note:
Loading a model from its configuration file does `),jge=a("strong"),gjo=o("not"),hjo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XO=a("a"),pjo=o("from_pretrained()"),_jo=o(" to load the model weights."),ujo=l(),F(M2.$$.fragment),bjo=l(),to=a("div"),F(Oy.$$.fragment),vjo=l(),Dge=a("p"),Fjo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Tjo=l(),Ba=a("p"),Mjo=o("The model class to instantiate is selected based on the "),Gge=a("code"),Ejo=o("model_type"),Cjo=o(` property of the config object (either
passed as an argument or loaded from `),Oge=a("code"),wjo=o("pretrained_model_name_or_path"),Ajo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vge=a("code"),yjo=o("pretrained_model_name_or_path"),Ljo=o(":"),xjo=l(),Yr=a("ul"),E2=a("li"),Xge=a("strong"),$jo=o("bert"),kjo=o(" \u2014 "),zO=a("a"),Sjo=o("BertForNextSentencePrediction"),Rjo=o(" (BERT model)"),Pjo=l(),C2=a("li"),zge=a("strong"),Bjo=o("fnet"),Ijo=o(" \u2014 "),WO=a("a"),Njo=o("FNetForNextSentencePrediction"),qjo=o(" (FNet model)"),jjo=l(),w2=a("li"),Wge=a("strong"),Djo=o("megatron-bert"),Gjo=o(" \u2014 "),QO=a("a"),Ojo=o("MegatronBertForNextSentencePrediction"),Vjo=o(" (MegatronBert model)"),Xjo=l(),A2=a("li"),Qge=a("strong"),zjo=o("mobilebert"),Wjo=o(" \u2014 "),HO=a("a"),Qjo=o("MobileBertForNextSentencePrediction"),Hjo=o(" (MobileBERT model)"),Ujo=l(),y2=a("li"),Hge=a("strong"),Jjo=o("qdqbert"),Yjo=o(" \u2014 "),UO=a("a"),Kjo=o("QDQBertForNextSentencePrediction"),Zjo=o(" (QDQBert model)"),eDo=l(),L2=a("p"),oDo=o("The model is set in evaluation mode by default using "),Uge=a("code"),rDo=o("model.eval()"),tDo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jge=a("code"),aDo=o("model.train()"),nDo=l(),F(x2.$$.fragment),Xqe=l(),Ji=a("h2"),$2=a("a"),Yge=a("span"),F(Vy.$$.fragment),sDo=l(),Kge=a("span"),lDo=o("AutoModelForTokenClassification"),zqe=l(),Io=a("div"),F(Xy.$$.fragment),iDo=l(),Yi=a("p"),dDo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),JO=a("a"),cDo=o("from_pretrained()"),fDo=o(" class method or the "),YO=a("a"),mDo=o("from_config()"),gDo=o(` class
method.`),hDo=l(),zy=a("p"),pDo=o("This class cannot be instantiated directly using "),Zge=a("code"),_Do=o("__init__()"),uDo=o(" (throws an error)."),bDo=l(),ft=a("div"),F(Wy.$$.fragment),vDo=l(),ehe=a("p"),FDo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),TDo=l(),Ki=a("p"),MDo=o(`Note:
Loading a model from its configuration file does `),ohe=a("strong"),EDo=o("not"),CDo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KO=a("a"),wDo=o("from_pretrained()"),ADo=o(" to load the model weights."),yDo=l(),F(k2.$$.fragment),LDo=l(),ao=a("div"),F(Qy.$$.fragment),xDo=l(),rhe=a("p"),$Do=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),kDo=l(),Ia=a("p"),SDo=o("The model class to instantiate is selected based on the "),the=a("code"),RDo=o("model_type"),PDo=o(` property of the config object (either
passed as an argument or loaded from `),ahe=a("code"),BDo=o("pretrained_model_name_or_path"),IDo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nhe=a("code"),NDo=o("pretrained_model_name_or_path"),qDo=o(":"),jDo=l(),H=a("ul"),S2=a("li"),she=a("strong"),DDo=o("albert"),GDo=o(" \u2014 "),ZO=a("a"),ODo=o("AlbertForTokenClassification"),VDo=o(" (ALBERT model)"),XDo=l(),R2=a("li"),lhe=a("strong"),zDo=o("bert"),WDo=o(" \u2014 "),eV=a("a"),QDo=o("BertForTokenClassification"),HDo=o(" (BERT model)"),UDo=l(),P2=a("li"),ihe=a("strong"),JDo=o("big_bird"),YDo=o(" \u2014 "),oV=a("a"),KDo=o("BigBirdForTokenClassification"),ZDo=o(" (BigBird model)"),eGo=l(),B2=a("li"),dhe=a("strong"),oGo=o("camembert"),rGo=o(" \u2014 "),rV=a("a"),tGo=o("CamembertForTokenClassification"),aGo=o(" (CamemBERT model)"),nGo=l(),I2=a("li"),che=a("strong"),sGo=o("canine"),lGo=o(" \u2014 "),tV=a("a"),iGo=o("CanineForTokenClassification"),dGo=o(" (Canine model)"),cGo=l(),N2=a("li"),fhe=a("strong"),fGo=o("convbert"),mGo=o(" \u2014 "),aV=a("a"),gGo=o("ConvBertForTokenClassification"),hGo=o(" (ConvBERT model)"),pGo=l(),q2=a("li"),mhe=a("strong"),_Go=o("data2vec-text"),uGo=o(" \u2014 "),nV=a("a"),bGo=o("Data2VecTextForTokenClassification"),vGo=o(" (Data2VecText model)"),FGo=l(),j2=a("li"),ghe=a("strong"),TGo=o("deberta"),MGo=o(" \u2014 "),sV=a("a"),EGo=o("DebertaForTokenClassification"),CGo=o(" (DeBERTa model)"),wGo=l(),D2=a("li"),hhe=a("strong"),AGo=o("deberta-v2"),yGo=o(" \u2014 "),lV=a("a"),LGo=o("DebertaV2ForTokenClassification"),xGo=o(" (DeBERTa-v2 model)"),$Go=l(),G2=a("li"),phe=a("strong"),kGo=o("distilbert"),SGo=o(" \u2014 "),iV=a("a"),RGo=o("DistilBertForTokenClassification"),PGo=o(" (DistilBERT model)"),BGo=l(),O2=a("li"),_he=a("strong"),IGo=o("electra"),NGo=o(" \u2014 "),dV=a("a"),qGo=o("ElectraForTokenClassification"),jGo=o(" (ELECTRA model)"),DGo=l(),V2=a("li"),uhe=a("strong"),GGo=o("flaubert"),OGo=o(" \u2014 "),cV=a("a"),VGo=o("FlaubertForTokenClassification"),XGo=o(" (FlauBERT model)"),zGo=l(),X2=a("li"),bhe=a("strong"),WGo=o("fnet"),QGo=o(" \u2014 "),fV=a("a"),HGo=o("FNetForTokenClassification"),UGo=o(" (FNet model)"),JGo=l(),z2=a("li"),vhe=a("strong"),YGo=o("funnel"),KGo=o(" \u2014 "),mV=a("a"),ZGo=o("FunnelForTokenClassification"),eOo=o(" (Funnel Transformer model)"),oOo=l(),W2=a("li"),Fhe=a("strong"),rOo=o("gpt2"),tOo=o(" \u2014 "),gV=a("a"),aOo=o("GPT2ForTokenClassification"),nOo=o(" (OpenAI GPT-2 model)"),sOo=l(),Q2=a("li"),The=a("strong"),lOo=o("ibert"),iOo=o(" \u2014 "),hV=a("a"),dOo=o("IBertForTokenClassification"),cOo=o(" (I-BERT model)"),fOo=l(),H2=a("li"),Mhe=a("strong"),mOo=o("layoutlm"),gOo=o(" \u2014 "),pV=a("a"),hOo=o("LayoutLMForTokenClassification"),pOo=o(" (LayoutLM model)"),_Oo=l(),U2=a("li"),Ehe=a("strong"),uOo=o("layoutlmv2"),bOo=o(" \u2014 "),_V=a("a"),vOo=o("LayoutLMv2ForTokenClassification"),FOo=o(" (LayoutLMv2 model)"),TOo=l(),J2=a("li"),Che=a("strong"),MOo=o("layoutlmv3"),EOo=o(" \u2014 "),uV=a("a"),COo=o("LayoutLMv3ForTokenClassification"),wOo=o(" (LayoutLMv3 model)"),AOo=l(),Y2=a("li"),whe=a("strong"),yOo=o("longformer"),LOo=o(" \u2014 "),bV=a("a"),xOo=o("LongformerForTokenClassification"),$Oo=o(" (Longformer model)"),kOo=l(),K2=a("li"),Ahe=a("strong"),SOo=o("megatron-bert"),ROo=o(" \u2014 "),vV=a("a"),POo=o("MegatronBertForTokenClassification"),BOo=o(" (MegatronBert model)"),IOo=l(),Z2=a("li"),yhe=a("strong"),NOo=o("mobilebert"),qOo=o(" \u2014 "),FV=a("a"),jOo=o("MobileBertForTokenClassification"),DOo=o(" (MobileBERT model)"),GOo=l(),e4=a("li"),Lhe=a("strong"),OOo=o("mpnet"),VOo=o(" \u2014 "),TV=a("a"),XOo=o("MPNetForTokenClassification"),zOo=o(" (MPNet model)"),WOo=l(),o4=a("li"),xhe=a("strong"),QOo=o("nystromformer"),HOo=o(" \u2014 "),MV=a("a"),UOo=o("NystromformerForTokenClassification"),JOo=o(" (Nystromformer model)"),YOo=l(),r4=a("li"),$he=a("strong"),KOo=o("qdqbert"),ZOo=o(" \u2014 "),EV=a("a"),eVo=o("QDQBertForTokenClassification"),oVo=o(" (QDQBert model)"),rVo=l(),t4=a("li"),khe=a("strong"),tVo=o("rembert"),aVo=o(" \u2014 "),CV=a("a"),nVo=o("RemBertForTokenClassification"),sVo=o(" (RemBERT model)"),lVo=l(),a4=a("li"),She=a("strong"),iVo=o("roberta"),dVo=o(" \u2014 "),wV=a("a"),cVo=o("RobertaForTokenClassification"),fVo=o(" (RoBERTa model)"),mVo=l(),n4=a("li"),Rhe=a("strong"),gVo=o("roformer"),hVo=o(" \u2014 "),AV=a("a"),pVo=o("RoFormerForTokenClassification"),_Vo=o(" (RoFormer model)"),uVo=l(),s4=a("li"),Phe=a("strong"),bVo=o("squeezebert"),vVo=o(" \u2014 "),yV=a("a"),FVo=o("SqueezeBertForTokenClassification"),TVo=o(" (SqueezeBERT model)"),MVo=l(),l4=a("li"),Bhe=a("strong"),EVo=o("xlm"),CVo=o(" \u2014 "),LV=a("a"),wVo=o("XLMForTokenClassification"),AVo=o(" (XLM model)"),yVo=l(),i4=a("li"),Ihe=a("strong"),LVo=o("xlm-roberta"),xVo=o(" \u2014 "),xV=a("a"),$Vo=o("XLMRobertaForTokenClassification"),kVo=o(" (XLM-RoBERTa model)"),SVo=l(),d4=a("li"),Nhe=a("strong"),RVo=o("xlm-roberta-xl"),PVo=o(" \u2014 "),$V=a("a"),BVo=o("XLMRobertaXLForTokenClassification"),IVo=o(" (XLM-RoBERTa-XL model)"),NVo=l(),c4=a("li"),qhe=a("strong"),qVo=o("xlnet"),jVo=o(" \u2014 "),kV=a("a"),DVo=o("XLNetForTokenClassification"),GVo=o(" (XLNet model)"),OVo=l(),f4=a("li"),jhe=a("strong"),VVo=o("yoso"),XVo=o(" \u2014 "),SV=a("a"),zVo=o("YosoForTokenClassification"),WVo=o(" (YOSO model)"),QVo=l(),m4=a("p"),HVo=o("The model is set in evaluation mode by default using "),Dhe=a("code"),UVo=o("model.eval()"),JVo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ghe=a("code"),YVo=o("model.train()"),KVo=l(),F(g4.$$.fragment),Wqe=l(),Zi=a("h2"),h4=a("a"),Ohe=a("span"),F(Hy.$$.fragment),ZVo=l(),Vhe=a("span"),eXo=o("AutoModelForQuestionAnswering"),Qqe=l(),No=a("div"),F(Uy.$$.fragment),oXo=l(),ed=a("p"),rXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),RV=a("a"),tXo=o("from_pretrained()"),aXo=o(" class method or the "),PV=a("a"),nXo=o("from_config()"),sXo=o(` class
method.`),lXo=l(),Jy=a("p"),iXo=o("This class cannot be instantiated directly using "),Xhe=a("code"),dXo=o("__init__()"),cXo=o(" (throws an error)."),fXo=l(),mt=a("div"),F(Yy.$$.fragment),mXo=l(),zhe=a("p"),gXo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),hXo=l(),od=a("p"),pXo=o(`Note:
Loading a model from its configuration file does `),Whe=a("strong"),_Xo=o("not"),uXo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BV=a("a"),bXo=o("from_pretrained()"),vXo=o(" to load the model weights."),FXo=l(),F(p4.$$.fragment),TXo=l(),no=a("div"),F(Ky.$$.fragment),MXo=l(),Qhe=a("p"),EXo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),CXo=l(),Na=a("p"),wXo=o("The model class to instantiate is selected based on the "),Hhe=a("code"),AXo=o("model_type"),yXo=o(` property of the config object (either
passed as an argument or loaded from `),Uhe=a("code"),LXo=o("pretrained_model_name_or_path"),xXo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jhe=a("code"),$Xo=o("pretrained_model_name_or_path"),kXo=o(":"),SXo=l(),V=a("ul"),_4=a("li"),Yhe=a("strong"),RXo=o("albert"),PXo=o(" \u2014 "),IV=a("a"),BXo=o("AlbertForQuestionAnswering"),IXo=o(" (ALBERT model)"),NXo=l(),u4=a("li"),Khe=a("strong"),qXo=o("bart"),jXo=o(" \u2014 "),NV=a("a"),DXo=o("BartForQuestionAnswering"),GXo=o(" (BART model)"),OXo=l(),b4=a("li"),Zhe=a("strong"),VXo=o("bert"),XXo=o(" \u2014 "),qV=a("a"),zXo=o("BertForQuestionAnswering"),WXo=o(" (BERT model)"),QXo=l(),v4=a("li"),epe=a("strong"),HXo=o("big_bird"),UXo=o(" \u2014 "),jV=a("a"),JXo=o("BigBirdForQuestionAnswering"),YXo=o(" (BigBird model)"),KXo=l(),F4=a("li"),ope=a("strong"),ZXo=o("bigbird_pegasus"),ezo=o(" \u2014 "),DV=a("a"),ozo=o("BigBirdPegasusForQuestionAnswering"),rzo=o(" (BigBirdPegasus model)"),tzo=l(),T4=a("li"),rpe=a("strong"),azo=o("camembert"),nzo=o(" \u2014 "),GV=a("a"),szo=o("CamembertForQuestionAnswering"),lzo=o(" (CamemBERT model)"),izo=l(),M4=a("li"),tpe=a("strong"),dzo=o("canine"),czo=o(" \u2014 "),OV=a("a"),fzo=o("CanineForQuestionAnswering"),mzo=o(" (Canine model)"),gzo=l(),E4=a("li"),ape=a("strong"),hzo=o("convbert"),pzo=o(" \u2014 "),VV=a("a"),_zo=o("ConvBertForQuestionAnswering"),uzo=o(" (ConvBERT model)"),bzo=l(),C4=a("li"),npe=a("strong"),vzo=o("data2vec-text"),Fzo=o(" \u2014 "),XV=a("a"),Tzo=o("Data2VecTextForQuestionAnswering"),Mzo=o(" (Data2VecText model)"),Ezo=l(),w4=a("li"),spe=a("strong"),Czo=o("deberta"),wzo=o(" \u2014 "),zV=a("a"),Azo=o("DebertaForQuestionAnswering"),yzo=o(" (DeBERTa model)"),Lzo=l(),A4=a("li"),lpe=a("strong"),xzo=o("deberta-v2"),$zo=o(" \u2014 "),WV=a("a"),kzo=o("DebertaV2ForQuestionAnswering"),Szo=o(" (DeBERTa-v2 model)"),Rzo=l(),y4=a("li"),ipe=a("strong"),Pzo=o("distilbert"),Bzo=o(" \u2014 "),QV=a("a"),Izo=o("DistilBertForQuestionAnswering"),Nzo=o(" (DistilBERT model)"),qzo=l(),L4=a("li"),dpe=a("strong"),jzo=o("electra"),Dzo=o(" \u2014 "),HV=a("a"),Gzo=o("ElectraForQuestionAnswering"),Ozo=o(" (ELECTRA model)"),Vzo=l(),x4=a("li"),cpe=a("strong"),Xzo=o("flaubert"),zzo=o(" \u2014 "),UV=a("a"),Wzo=o("FlaubertForQuestionAnsweringSimple"),Qzo=o(" (FlauBERT model)"),Hzo=l(),$4=a("li"),fpe=a("strong"),Uzo=o("fnet"),Jzo=o(" \u2014 "),JV=a("a"),Yzo=o("FNetForQuestionAnswering"),Kzo=o(" (FNet model)"),Zzo=l(),k4=a("li"),mpe=a("strong"),eWo=o("funnel"),oWo=o(" \u2014 "),YV=a("a"),rWo=o("FunnelForQuestionAnswering"),tWo=o(" (Funnel Transformer model)"),aWo=l(),S4=a("li"),gpe=a("strong"),nWo=o("gptj"),sWo=o(" \u2014 "),KV=a("a"),lWo=o("GPTJForQuestionAnswering"),iWo=o(" (GPT-J model)"),dWo=l(),R4=a("li"),hpe=a("strong"),cWo=o("ibert"),fWo=o(" \u2014 "),ZV=a("a"),mWo=o("IBertForQuestionAnswering"),gWo=o(" (I-BERT model)"),hWo=l(),P4=a("li"),ppe=a("strong"),pWo=o("layoutlmv2"),_Wo=o(" \u2014 "),eX=a("a"),uWo=o("LayoutLMv2ForQuestionAnswering"),bWo=o(" (LayoutLMv2 model)"),vWo=l(),B4=a("li"),_pe=a("strong"),FWo=o("layoutlmv3"),TWo=o(" \u2014 "),oX=a("a"),MWo=o("LayoutLMv3ForQuestionAnswering"),EWo=o(" (LayoutLMv3 model)"),CWo=l(),I4=a("li"),upe=a("strong"),wWo=o("led"),AWo=o(" \u2014 "),rX=a("a"),yWo=o("LEDForQuestionAnswering"),LWo=o(" (LED model)"),xWo=l(),N4=a("li"),bpe=a("strong"),$Wo=o("longformer"),kWo=o(" \u2014 "),tX=a("a"),SWo=o("LongformerForQuestionAnswering"),RWo=o(" (Longformer model)"),PWo=l(),q4=a("li"),vpe=a("strong"),BWo=o("lxmert"),IWo=o(" \u2014 "),aX=a("a"),NWo=o("LxmertForQuestionAnswering"),qWo=o(" (LXMERT model)"),jWo=l(),j4=a("li"),Fpe=a("strong"),DWo=o("mbart"),GWo=o(" \u2014 "),nX=a("a"),OWo=o("MBartForQuestionAnswering"),VWo=o(" (mBART model)"),XWo=l(),D4=a("li"),Tpe=a("strong"),zWo=o("megatron-bert"),WWo=o(" \u2014 "),sX=a("a"),QWo=o("MegatronBertForQuestionAnswering"),HWo=o(" (MegatronBert model)"),UWo=l(),G4=a("li"),Mpe=a("strong"),JWo=o("mobilebert"),YWo=o(" \u2014 "),lX=a("a"),KWo=o("MobileBertForQuestionAnswering"),ZWo=o(" (MobileBERT model)"),eQo=l(),O4=a("li"),Epe=a("strong"),oQo=o("mpnet"),rQo=o(" \u2014 "),iX=a("a"),tQo=o("MPNetForQuestionAnswering"),aQo=o(" (MPNet model)"),nQo=l(),V4=a("li"),Cpe=a("strong"),sQo=o("nystromformer"),lQo=o(" \u2014 "),dX=a("a"),iQo=o("NystromformerForQuestionAnswering"),dQo=o(" (Nystromformer model)"),cQo=l(),X4=a("li"),wpe=a("strong"),fQo=o("qdqbert"),mQo=o(" \u2014 "),cX=a("a"),gQo=o("QDQBertForQuestionAnswering"),hQo=o(" (QDQBert model)"),pQo=l(),z4=a("li"),Ape=a("strong"),_Qo=o("reformer"),uQo=o(" \u2014 "),fX=a("a"),bQo=o("ReformerForQuestionAnswering"),vQo=o(" (Reformer model)"),FQo=l(),W4=a("li"),ype=a("strong"),TQo=o("rembert"),MQo=o(" \u2014 "),mX=a("a"),EQo=o("RemBertForQuestionAnswering"),CQo=o(" (RemBERT model)"),wQo=l(),Q4=a("li"),Lpe=a("strong"),AQo=o("roberta"),yQo=o(" \u2014 "),gX=a("a"),LQo=o("RobertaForQuestionAnswering"),xQo=o(" (RoBERTa model)"),$Qo=l(),H4=a("li"),xpe=a("strong"),kQo=o("roformer"),SQo=o(" \u2014 "),hX=a("a"),RQo=o("RoFormerForQuestionAnswering"),PQo=o(" (RoFormer model)"),BQo=l(),U4=a("li"),$pe=a("strong"),IQo=o("splinter"),NQo=o(" \u2014 "),pX=a("a"),qQo=o("SplinterForQuestionAnswering"),jQo=o(" (Splinter model)"),DQo=l(),J4=a("li"),kpe=a("strong"),GQo=o("squeezebert"),OQo=o(" \u2014 "),_X=a("a"),VQo=o("SqueezeBertForQuestionAnswering"),XQo=o(" (SqueezeBERT model)"),zQo=l(),Y4=a("li"),Spe=a("strong"),WQo=o("xlm"),QQo=o(" \u2014 "),uX=a("a"),HQo=o("XLMForQuestionAnsweringSimple"),UQo=o(" (XLM model)"),JQo=l(),K4=a("li"),Rpe=a("strong"),YQo=o("xlm-roberta"),KQo=o(" \u2014 "),bX=a("a"),ZQo=o("XLMRobertaForQuestionAnswering"),eHo=o(" (XLM-RoBERTa model)"),oHo=l(),Z4=a("li"),Ppe=a("strong"),rHo=o("xlm-roberta-xl"),tHo=o(" \u2014 "),vX=a("a"),aHo=o("XLMRobertaXLForQuestionAnswering"),nHo=o(" (XLM-RoBERTa-XL model)"),sHo=l(),ev=a("li"),Bpe=a("strong"),lHo=o("xlnet"),iHo=o(" \u2014 "),FX=a("a"),dHo=o("XLNetForQuestionAnsweringSimple"),cHo=o(" (XLNet model)"),fHo=l(),ov=a("li"),Ipe=a("strong"),mHo=o("yoso"),gHo=o(" \u2014 "),TX=a("a"),hHo=o("YosoForQuestionAnswering"),pHo=o(" (YOSO model)"),_Ho=l(),rv=a("p"),uHo=o("The model is set in evaluation mode by default using "),Npe=a("code"),bHo=o("model.eval()"),vHo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qpe=a("code"),FHo=o("model.train()"),THo=l(),F(tv.$$.fragment),Hqe=l(),rd=a("h2"),av=a("a"),jpe=a("span"),F(Zy.$$.fragment),MHo=l(),Dpe=a("span"),EHo=o("AutoModelForTableQuestionAnswering"),Uqe=l(),qo=a("div"),F(eL.$$.fragment),CHo=l(),td=a("p"),wHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),MX=a("a"),AHo=o("from_pretrained()"),yHo=o(" class method or the "),EX=a("a"),LHo=o("from_config()"),xHo=o(` class
method.`),$Ho=l(),oL=a("p"),kHo=o("This class cannot be instantiated directly using "),Gpe=a("code"),SHo=o("__init__()"),RHo=o(" (throws an error)."),PHo=l(),gt=a("div"),F(rL.$$.fragment),BHo=l(),Ope=a("p"),IHo=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),NHo=l(),ad=a("p"),qHo=o(`Note:
Loading a model from its configuration file does `),Vpe=a("strong"),jHo=o("not"),DHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CX=a("a"),GHo=o("from_pretrained()"),OHo=o(" to load the model weights."),VHo=l(),F(nv.$$.fragment),XHo=l(),so=a("div"),F(tL.$$.fragment),zHo=l(),Xpe=a("p"),WHo=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),QHo=l(),qa=a("p"),HHo=o("The model class to instantiate is selected based on the "),zpe=a("code"),UHo=o("model_type"),JHo=o(` property of the config object (either
passed as an argument or loaded from `),Wpe=a("code"),YHo=o("pretrained_model_name_or_path"),KHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qpe=a("code"),ZHo=o("pretrained_model_name_or_path"),eUo=o(":"),oUo=l(),Hpe=a("ul"),sv=a("li"),Upe=a("strong"),rUo=o("tapas"),tUo=o(" \u2014 "),wX=a("a"),aUo=o("TapasForQuestionAnswering"),nUo=o(" (TAPAS model)"),sUo=l(),lv=a("p"),lUo=o("The model is set in evaluation mode by default using "),Jpe=a("code"),iUo=o("model.eval()"),dUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ype=a("code"),cUo=o("model.train()"),fUo=l(),F(iv.$$.fragment),Jqe=l(),nd=a("h2"),dv=a("a"),Kpe=a("span"),F(aL.$$.fragment),mUo=l(),Zpe=a("span"),gUo=o("AutoModelForImageClassification"),Yqe=l(),jo=a("div"),F(nL.$$.fragment),hUo=l(),sd=a("p"),pUo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),AX=a("a"),_Uo=o("from_pretrained()"),uUo=o(" class method or the "),yX=a("a"),bUo=o("from_config()"),vUo=o(` class
method.`),FUo=l(),sL=a("p"),TUo=o("This class cannot be instantiated directly using "),e_e=a("code"),MUo=o("__init__()"),EUo=o(" (throws an error)."),CUo=l(),ht=a("div"),F(lL.$$.fragment),wUo=l(),o_e=a("p"),AUo=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),yUo=l(),ld=a("p"),LUo=o(`Note:
Loading a model from its configuration file does `),r_e=a("strong"),xUo=o("not"),$Uo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LX=a("a"),kUo=o("from_pretrained()"),SUo=o(" to load the model weights."),RUo=l(),F(cv.$$.fragment),PUo=l(),lo=a("div"),F(iL.$$.fragment),BUo=l(),t_e=a("p"),IUo=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),NUo=l(),ja=a("p"),qUo=o("The model class to instantiate is selected based on the "),a_e=a("code"),jUo=o("model_type"),DUo=o(` property of the config object (either
passed as an argument or loaded from `),n_e=a("code"),GUo=o("pretrained_model_name_or_path"),OUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s_e=a("code"),VUo=o("pretrained_model_name_or_path"),XUo=o(":"),zUo=l(),ve=a("ul"),fv=a("li"),l_e=a("strong"),WUo=o("beit"),QUo=o(" \u2014 "),xX=a("a"),HUo=o("BeitForImageClassification"),UUo=o(" (BEiT model)"),JUo=l(),mv=a("li"),i_e=a("strong"),YUo=o("convnext"),KUo=o(" \u2014 "),$X=a("a"),ZUo=o("ConvNextForImageClassification"),eJo=o(" (ConvNext model)"),oJo=l(),gv=a("li"),d_e=a("strong"),rJo=o("cvt"),tJo=o(" \u2014 "),kX=a("a"),aJo=o("CvtForImageClassification"),nJo=o(" (CvT model)"),sJo=l(),hv=a("li"),c_e=a("strong"),lJo=o("data2vec-vision"),iJo=o(" \u2014 "),SX=a("a"),dJo=o("Data2VecVisionForImageClassification"),cJo=o(" (Data2VecVision model)"),fJo=l(),Bs=a("li"),f_e=a("strong"),mJo=o("deit"),gJo=o(" \u2014 "),RX=a("a"),hJo=o("DeiTForImageClassification"),pJo=o(" or "),PX=a("a"),_Jo=o("DeiTForImageClassificationWithTeacher"),uJo=o(" (DeiT model)"),bJo=l(),pv=a("li"),m_e=a("strong"),vJo=o("imagegpt"),FJo=o(" \u2014 "),BX=a("a"),TJo=o("ImageGPTForImageClassification"),MJo=o(" (ImageGPT model)"),EJo=l(),Is=a("li"),g_e=a("strong"),CJo=o("levit"),wJo=o(" \u2014 "),IX=a("a"),AJo=o("LevitForImageClassification"),yJo=o(" or "),NX=a("a"),LJo=o("LevitForImageClassificationWithTeacher"),xJo=o(" (LeViT model)"),$Jo=l(),pt=a("li"),h_e=a("strong"),kJo=o("perceiver"),SJo=o(" \u2014 "),qX=a("a"),RJo=o("PerceiverForImageClassificationLearned"),PJo=o(" or "),jX=a("a"),BJo=o("PerceiverForImageClassificationFourier"),IJo=o(" or "),DX=a("a"),NJo=o("PerceiverForImageClassificationConvProcessing"),qJo=o(" (Perceiver model)"),jJo=l(),_v=a("li"),p_e=a("strong"),DJo=o("poolformer"),GJo=o(" \u2014 "),GX=a("a"),OJo=o("PoolFormerForImageClassification"),VJo=o(" (PoolFormer model)"),XJo=l(),uv=a("li"),__e=a("strong"),zJo=o("regnet"),WJo=o(" \u2014 "),OX=a("a"),QJo=o("RegNetForImageClassification"),HJo=o(" (RegNet model)"),UJo=l(),bv=a("li"),u_e=a("strong"),JJo=o("resnet"),YJo=o(" \u2014 "),VX=a("a"),KJo=o("ResNetForImageClassification"),ZJo=o(" (ResNet model)"),eYo=l(),vv=a("li"),b_e=a("strong"),oYo=o("segformer"),rYo=o(" \u2014 "),XX=a("a"),tYo=o("SegformerForImageClassification"),aYo=o(" (SegFormer model)"),nYo=l(),Fv=a("li"),v_e=a("strong"),sYo=o("swin"),lYo=o(" \u2014 "),zX=a("a"),iYo=o("SwinForImageClassification"),dYo=o(" (Swin model)"),cYo=l(),Tv=a("li"),F_e=a("strong"),fYo=o("van"),mYo=o(" \u2014 "),WX=a("a"),gYo=o("VanForImageClassification"),hYo=o(" (VAN model)"),pYo=l(),Mv=a("li"),T_e=a("strong"),_Yo=o("vit"),uYo=o(" \u2014 "),QX=a("a"),bYo=o("ViTForImageClassification"),vYo=o(" (ViT model)"),FYo=l(),Ev=a("p"),TYo=o("The model is set in evaluation mode by default using "),M_e=a("code"),MYo=o("model.eval()"),EYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),E_e=a("code"),CYo=o("model.train()"),wYo=l(),F(Cv.$$.fragment),Kqe=l(),id=a("h2"),wv=a("a"),C_e=a("span"),F(dL.$$.fragment),AYo=l(),w_e=a("span"),yYo=o("AutoModelForVision2Seq"),Zqe=l(),Do=a("div"),F(cL.$$.fragment),LYo=l(),dd=a("p"),xYo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),HX=a("a"),$Yo=o("from_pretrained()"),kYo=o(" class method or the "),UX=a("a"),SYo=o("from_config()"),RYo=o(` class
method.`),PYo=l(),fL=a("p"),BYo=o("This class cannot be instantiated directly using "),A_e=a("code"),IYo=o("__init__()"),NYo=o(" (throws an error)."),qYo=l(),_t=a("div"),F(mL.$$.fragment),jYo=l(),y_e=a("p"),DYo=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),GYo=l(),cd=a("p"),OYo=o(`Note:
Loading a model from its configuration file does `),L_e=a("strong"),VYo=o("not"),XYo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JX=a("a"),zYo=o("from_pretrained()"),WYo=o(" to load the model weights."),QYo=l(),F(Av.$$.fragment),HYo=l(),io=a("div"),F(gL.$$.fragment),UYo=l(),x_e=a("p"),JYo=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),YYo=l(),Da=a("p"),KYo=o("The model class to instantiate is selected based on the "),$_e=a("code"),ZYo=o("model_type"),eKo=o(` property of the config object (either
passed as an argument or loaded from `),k_e=a("code"),oKo=o("pretrained_model_name_or_path"),rKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S_e=a("code"),tKo=o("pretrained_model_name_or_path"),aKo=o(":"),nKo=l(),R_e=a("ul"),yv=a("li"),P_e=a("strong"),sKo=o("vision-encoder-decoder"),lKo=o(" \u2014 "),YX=a("a"),iKo=o("VisionEncoderDecoderModel"),dKo=o(" (Vision Encoder decoder model)"),cKo=l(),Lv=a("p"),fKo=o("The model is set in evaluation mode by default using "),B_e=a("code"),mKo=o("model.eval()"),gKo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),I_e=a("code"),hKo=o("model.train()"),pKo=l(),F(xv.$$.fragment),eje=l(),fd=a("h2"),$v=a("a"),N_e=a("span"),F(hL.$$.fragment),_Ko=l(),q_e=a("span"),uKo=o("AutoModelForAudioClassification"),oje=l(),Go=a("div"),F(pL.$$.fragment),bKo=l(),md=a("p"),vKo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),KX=a("a"),FKo=o("from_pretrained()"),TKo=o(" class method or the "),ZX=a("a"),MKo=o("from_config()"),EKo=o(` class
method.`),CKo=l(),_L=a("p"),wKo=o("This class cannot be instantiated directly using "),j_e=a("code"),AKo=o("__init__()"),yKo=o(" (throws an error)."),LKo=l(),ut=a("div"),F(uL.$$.fragment),xKo=l(),D_e=a("p"),$Ko=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),kKo=l(),gd=a("p"),SKo=o(`Note:
Loading a model from its configuration file does `),G_e=a("strong"),RKo=o("not"),PKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ez=a("a"),BKo=o("from_pretrained()"),IKo=o(" to load the model weights."),NKo=l(),F(kv.$$.fragment),qKo=l(),co=a("div"),F(bL.$$.fragment),jKo=l(),O_e=a("p"),DKo=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),GKo=l(),Ga=a("p"),OKo=o("The model class to instantiate is selected based on the "),V_e=a("code"),VKo=o("model_type"),XKo=o(` property of the config object (either
passed as an argument or loaded from `),X_e=a("code"),zKo=o("pretrained_model_name_or_path"),WKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z_e=a("code"),QKo=o("pretrained_model_name_or_path"),HKo=o(":"),UKo=l(),ke=a("ul"),Sv=a("li"),W_e=a("strong"),JKo=o("data2vec-audio"),YKo=o(" \u2014 "),oz=a("a"),KKo=o("Data2VecAudioForSequenceClassification"),ZKo=o(" (Data2VecAudio model)"),eZo=l(),Rv=a("li"),Q_e=a("strong"),oZo=o("hubert"),rZo=o(" \u2014 "),rz=a("a"),tZo=o("HubertForSequenceClassification"),aZo=o(" (Hubert model)"),nZo=l(),Pv=a("li"),H_e=a("strong"),sZo=o("sew"),lZo=o(" \u2014 "),tz=a("a"),iZo=o("SEWForSequenceClassification"),dZo=o(" (SEW model)"),cZo=l(),Bv=a("li"),U_e=a("strong"),fZo=o("sew-d"),mZo=o(" \u2014 "),az=a("a"),gZo=o("SEWDForSequenceClassification"),hZo=o(" (SEW-D model)"),pZo=l(),Iv=a("li"),J_e=a("strong"),_Zo=o("unispeech"),uZo=o(" \u2014 "),nz=a("a"),bZo=o("UniSpeechForSequenceClassification"),vZo=o(" (UniSpeech model)"),FZo=l(),Nv=a("li"),Y_e=a("strong"),TZo=o("unispeech-sat"),MZo=o(" \u2014 "),sz=a("a"),EZo=o("UniSpeechSatForSequenceClassification"),CZo=o(" (UniSpeechSat model)"),wZo=l(),qv=a("li"),K_e=a("strong"),AZo=o("wav2vec2"),yZo=o(" \u2014 "),lz=a("a"),LZo=o("Wav2Vec2ForSequenceClassification"),xZo=o(" (Wav2Vec2 model)"),$Zo=l(),jv=a("li"),Z_e=a("strong"),kZo=o("wav2vec2-conformer"),SZo=o(" \u2014 "),iz=a("a"),RZo=o("Wav2Vec2ConformerForSequenceClassification"),PZo=o(" (Wav2Vec2-Conformer model)"),BZo=l(),Dv=a("li"),eue=a("strong"),IZo=o("wavlm"),NZo=o(" \u2014 "),dz=a("a"),qZo=o("WavLMForSequenceClassification"),jZo=o(" (WavLM model)"),DZo=l(),Gv=a("p"),GZo=o("The model is set in evaluation mode by default using "),oue=a("code"),OZo=o("model.eval()"),VZo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rue=a("code"),XZo=o("model.train()"),zZo=l(),F(Ov.$$.fragment),rje=l(),hd=a("h2"),Vv=a("a"),tue=a("span"),F(vL.$$.fragment),WZo=l(),aue=a("span"),QZo=o("AutoModelForAudioFrameClassification"),tje=l(),Oo=a("div"),F(FL.$$.fragment),HZo=l(),pd=a("p"),UZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),cz=a("a"),JZo=o("from_pretrained()"),YZo=o(" class method or the "),fz=a("a"),KZo=o("from_config()"),ZZo=o(` class
method.`),eer=l(),TL=a("p"),oer=o("This class cannot be instantiated directly using "),nue=a("code"),rer=o("__init__()"),ter=o(" (throws an error)."),aer=l(),bt=a("div"),F(ML.$$.fragment),ner=l(),sue=a("p"),ser=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),ler=l(),_d=a("p"),ier=o(`Note:
Loading a model from its configuration file does `),lue=a("strong"),der=o("not"),cer=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mz=a("a"),fer=o("from_pretrained()"),mer=o(" to load the model weights."),ger=l(),F(Xv.$$.fragment),her=l(),fo=a("div"),F(EL.$$.fragment),per=l(),iue=a("p"),_er=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),uer=l(),Oa=a("p"),ber=o("The model class to instantiate is selected based on the "),due=a("code"),ver=o("model_type"),Fer=o(` property of the config object (either
passed as an argument or loaded from `),cue=a("code"),Ter=o("pretrained_model_name_or_path"),Mer=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fue=a("code"),Eer=o("pretrained_model_name_or_path"),Cer=o(":"),wer=l(),Kr=a("ul"),zv=a("li"),mue=a("strong"),Aer=o("data2vec-audio"),yer=o(" \u2014 "),gz=a("a"),Ler=o("Data2VecAudioForAudioFrameClassification"),xer=o(" (Data2VecAudio model)"),$er=l(),Wv=a("li"),gue=a("strong"),ker=o("unispeech-sat"),Ser=o(" \u2014 "),hz=a("a"),Rer=o("UniSpeechSatForAudioFrameClassification"),Per=o(" (UniSpeechSat model)"),Ber=l(),Qv=a("li"),hue=a("strong"),Ier=o("wav2vec2"),Ner=o(" \u2014 "),pz=a("a"),qer=o("Wav2Vec2ForAudioFrameClassification"),jer=o(" (Wav2Vec2 model)"),Der=l(),Hv=a("li"),pue=a("strong"),Ger=o("wav2vec2-conformer"),Oer=o(" \u2014 "),_z=a("a"),Ver=o("Wav2Vec2ConformerForAudioFrameClassification"),Xer=o(" (Wav2Vec2-Conformer model)"),zer=l(),Uv=a("li"),_ue=a("strong"),Wer=o("wavlm"),Qer=o(" \u2014 "),uz=a("a"),Her=o("WavLMForAudioFrameClassification"),Uer=o(" (WavLM model)"),Jer=l(),Jv=a("p"),Yer=o("The model is set in evaluation mode by default using "),uue=a("code"),Ker=o("model.eval()"),Zer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bue=a("code"),eor=o("model.train()"),oor=l(),F(Yv.$$.fragment),aje=l(),ud=a("h2"),Kv=a("a"),vue=a("span"),F(CL.$$.fragment),ror=l(),Fue=a("span"),tor=o("AutoModelForCTC"),nje=l(),Vo=a("div"),F(wL.$$.fragment),aor=l(),bd=a("p"),nor=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),bz=a("a"),sor=o("from_pretrained()"),lor=o(" class method or the "),vz=a("a"),ior=o("from_config()"),dor=o(` class
method.`),cor=l(),AL=a("p"),mor=o("This class cannot be instantiated directly using "),Tue=a("code"),gor=o("__init__()"),hor=o(" (throws an error)."),por=l(),vt=a("div"),F(yL.$$.fragment),_or=l(),Mue=a("p"),uor=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),bor=l(),vd=a("p"),vor=o(`Note:
Loading a model from its configuration file does `),Eue=a("strong"),For=o("not"),Tor=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fz=a("a"),Mor=o("from_pretrained()"),Eor=o(" to load the model weights."),Cor=l(),F(Zv.$$.fragment),wor=l(),mo=a("div"),F(LL.$$.fragment),Aor=l(),Cue=a("p"),yor=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Lor=l(),Va=a("p"),xor=o("The model class to instantiate is selected based on the "),wue=a("code"),$or=o("model_type"),kor=o(` property of the config object (either
passed as an argument or loaded from `),Aue=a("code"),Sor=o("pretrained_model_name_or_path"),Ror=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yue=a("code"),Por=o("pretrained_model_name_or_path"),Bor=o(":"),Ior=l(),Se=a("ul"),eF=a("li"),Lue=a("strong"),Nor=o("data2vec-audio"),qor=o(" \u2014 "),Tz=a("a"),jor=o("Data2VecAudioForCTC"),Dor=o(" (Data2VecAudio model)"),Gor=l(),oF=a("li"),xue=a("strong"),Oor=o("hubert"),Vor=o(" \u2014 "),Mz=a("a"),Xor=o("HubertForCTC"),zor=o(" (Hubert model)"),Wor=l(),rF=a("li"),$ue=a("strong"),Qor=o("sew"),Hor=o(" \u2014 "),Ez=a("a"),Uor=o("SEWForCTC"),Jor=o(" (SEW model)"),Yor=l(),tF=a("li"),kue=a("strong"),Kor=o("sew-d"),Zor=o(" \u2014 "),Cz=a("a"),err=o("SEWDForCTC"),orr=o(" (SEW-D model)"),rrr=l(),aF=a("li"),Sue=a("strong"),trr=o("unispeech"),arr=o(" \u2014 "),wz=a("a"),nrr=o("UniSpeechForCTC"),srr=o(" (UniSpeech model)"),lrr=l(),nF=a("li"),Rue=a("strong"),irr=o("unispeech-sat"),drr=o(" \u2014 "),Az=a("a"),crr=o("UniSpeechSatForCTC"),frr=o(" (UniSpeechSat model)"),mrr=l(),sF=a("li"),Pue=a("strong"),grr=o("wav2vec2"),hrr=o(" \u2014 "),yz=a("a"),prr=o("Wav2Vec2ForCTC"),_rr=o(" (Wav2Vec2 model)"),urr=l(),lF=a("li"),Bue=a("strong"),brr=o("wav2vec2-conformer"),vrr=o(" \u2014 "),Lz=a("a"),Frr=o("Wav2Vec2ConformerForCTC"),Trr=o(" (Wav2Vec2-Conformer model)"),Mrr=l(),iF=a("li"),Iue=a("strong"),Err=o("wavlm"),Crr=o(" \u2014 "),xz=a("a"),wrr=o("WavLMForCTC"),Arr=o(" (WavLM model)"),yrr=l(),dF=a("p"),Lrr=o("The model is set in evaluation mode by default using "),Nue=a("code"),xrr=o("model.eval()"),$rr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),que=a("code"),krr=o("model.train()"),Srr=l(),F(cF.$$.fragment),sje=l(),Fd=a("h2"),fF=a("a"),jue=a("span"),F(xL.$$.fragment),Rrr=l(),Due=a("span"),Prr=o("AutoModelForSpeechSeq2Seq"),lje=l(),Xo=a("div"),F($L.$$.fragment),Brr=l(),Td=a("p"),Irr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),$z=a("a"),Nrr=o("from_pretrained()"),qrr=o(" class method or the "),kz=a("a"),jrr=o("from_config()"),Drr=o(` class
method.`),Grr=l(),kL=a("p"),Orr=o("This class cannot be instantiated directly using "),Gue=a("code"),Vrr=o("__init__()"),Xrr=o(" (throws an error)."),zrr=l(),Ft=a("div"),F(SL.$$.fragment),Wrr=l(),Oue=a("p"),Qrr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Hrr=l(),Md=a("p"),Urr=o(`Note:
Loading a model from its configuration file does `),Vue=a("strong"),Jrr=o("not"),Yrr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Sz=a("a"),Krr=o("from_pretrained()"),Zrr=o(" to load the model weights."),etr=l(),F(mF.$$.fragment),otr=l(),go=a("div"),F(RL.$$.fragment),rtr=l(),Xue=a("p"),ttr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),atr=l(),Xa=a("p"),ntr=o("The model class to instantiate is selected based on the "),zue=a("code"),str=o("model_type"),ltr=o(` property of the config object (either
passed as an argument or loaded from `),Wue=a("code"),itr=o("pretrained_model_name_or_path"),dtr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Que=a("code"),ctr=o("pretrained_model_name_or_path"),ftr=o(":"),mtr=l(),PL=a("ul"),gF=a("li"),Hue=a("strong"),gtr=o("speech-encoder-decoder"),htr=o(" \u2014 "),Rz=a("a"),ptr=o("SpeechEncoderDecoderModel"),_tr=o(" (Speech Encoder decoder model)"),utr=l(),hF=a("li"),Uue=a("strong"),btr=o("speech_to_text"),vtr=o(" \u2014 "),Pz=a("a"),Ftr=o("Speech2TextForConditionalGeneration"),Ttr=o(" (Speech2Text model)"),Mtr=l(),pF=a("p"),Etr=o("The model is set in evaluation mode by default using "),Jue=a("code"),Ctr=o("model.eval()"),wtr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yue=a("code"),Atr=o("model.train()"),ytr=l(),F(_F.$$.fragment),ije=l(),Ed=a("h2"),uF=a("a"),Kue=a("span"),F(BL.$$.fragment),Ltr=l(),Zue=a("span"),xtr=o("AutoModelForAudioXVector"),dje=l(),zo=a("div"),F(IL.$$.fragment),$tr=l(),Cd=a("p"),ktr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),Bz=a("a"),Str=o("from_pretrained()"),Rtr=o(" class method or the "),Iz=a("a"),Ptr=o("from_config()"),Btr=o(` class
method.`),Itr=l(),NL=a("p"),Ntr=o("This class cannot be instantiated directly using "),e6e=a("code"),qtr=o("__init__()"),jtr=o(" (throws an error)."),Dtr=l(),Tt=a("div"),F(qL.$$.fragment),Gtr=l(),o6e=a("p"),Otr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Vtr=l(),wd=a("p"),Xtr=o(`Note:
Loading a model from its configuration file does `),r6e=a("strong"),ztr=o("not"),Wtr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Nz=a("a"),Qtr=o("from_pretrained()"),Htr=o(" to load the model weights."),Utr=l(),F(bF.$$.fragment),Jtr=l(),ho=a("div"),F(jL.$$.fragment),Ytr=l(),t6e=a("p"),Ktr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Ztr=l(),za=a("p"),ear=o("The model class to instantiate is selected based on the "),a6e=a("code"),oar=o("model_type"),rar=o(` property of the config object (either
passed as an argument or loaded from `),n6e=a("code"),tar=o("pretrained_model_name_or_path"),aar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s6e=a("code"),nar=o("pretrained_model_name_or_path"),sar=o(":"),lar=l(),Zr=a("ul"),vF=a("li"),l6e=a("strong"),iar=o("data2vec-audio"),dar=o(" \u2014 "),qz=a("a"),car=o("Data2VecAudioForXVector"),far=o(" (Data2VecAudio model)"),mar=l(),FF=a("li"),i6e=a("strong"),gar=o("unispeech-sat"),har=o(" \u2014 "),jz=a("a"),par=o("UniSpeechSatForXVector"),_ar=o(" (UniSpeechSat model)"),uar=l(),TF=a("li"),d6e=a("strong"),bar=o("wav2vec2"),Far=o(" \u2014 "),Dz=a("a"),Tar=o("Wav2Vec2ForXVector"),Mar=o(" (Wav2Vec2 model)"),Ear=l(),MF=a("li"),c6e=a("strong"),Car=o("wav2vec2-conformer"),war=o(" \u2014 "),Gz=a("a"),Aar=o("Wav2Vec2ConformerForXVector"),yar=o(" (Wav2Vec2-Conformer model)"),Lar=l(),EF=a("li"),f6e=a("strong"),xar=o("wavlm"),$ar=o(" \u2014 "),Oz=a("a"),kar=o("WavLMForXVector"),Sar=o(" (WavLM model)"),Rar=l(),CF=a("p"),Par=o("The model is set in evaluation mode by default using "),m6e=a("code"),Bar=o("model.eval()"),Iar=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),g6e=a("code"),Nar=o("model.train()"),qar=l(),F(wF.$$.fragment),cje=l(),Ad=a("h2"),AF=a("a"),h6e=a("span"),F(DL.$$.fragment),jar=l(),p6e=a("span"),Dar=o("AutoModelForMaskedImageModeling"),fje=l(),Wo=a("div"),F(GL.$$.fragment),Gar=l(),yd=a("p"),Oar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Vz=a("a"),Var=o("from_pretrained()"),Xar=o(" class method or the "),Xz=a("a"),zar=o("from_config()"),War=o(` class
method.`),Qar=l(),OL=a("p"),Har=o("This class cannot be instantiated directly using "),_6e=a("code"),Uar=o("__init__()"),Jar=o(" (throws an error)."),Yar=l(),Mt=a("div"),F(VL.$$.fragment),Kar=l(),u6e=a("p"),Zar=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),enr=l(),Ld=a("p"),onr=o(`Note:
Loading a model from its configuration file does `),b6e=a("strong"),rnr=o("not"),tnr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zz=a("a"),anr=o("from_pretrained()"),nnr=o(" to load the model weights."),snr=l(),F(yF.$$.fragment),lnr=l(),po=a("div"),F(XL.$$.fragment),inr=l(),v6e=a("p"),dnr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),cnr=l(),Wa=a("p"),fnr=o("The model class to instantiate is selected based on the "),F6e=a("code"),mnr=o("model_type"),gnr=o(` property of the config object (either
passed as an argument or loaded from `),T6e=a("code"),hnr=o("pretrained_model_name_or_path"),pnr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M6e=a("code"),_nr=o("pretrained_model_name_or_path"),unr=o(":"),bnr=l(),xd=a("ul"),LF=a("li"),E6e=a("strong"),vnr=o("deit"),Fnr=o(" \u2014 "),Wz=a("a"),Tnr=o("DeiTForMaskedImageModeling"),Mnr=o(" (DeiT model)"),Enr=l(),xF=a("li"),C6e=a("strong"),Cnr=o("swin"),wnr=o(" \u2014 "),Qz=a("a"),Anr=o("SwinForMaskedImageModeling"),ynr=o(" (Swin model)"),Lnr=l(),$F=a("li"),w6e=a("strong"),xnr=o("vit"),$nr=o(" \u2014 "),Hz=a("a"),knr=o("ViTForMaskedImageModeling"),Snr=o(" (ViT model)"),Rnr=l(),kF=a("p"),Pnr=o("The model is set in evaluation mode by default using "),A6e=a("code"),Bnr=o("model.eval()"),Inr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),y6e=a("code"),Nnr=o("model.train()"),qnr=l(),F(SF.$$.fragment),mje=l(),$d=a("h2"),RF=a("a"),L6e=a("span"),F(zL.$$.fragment),jnr=l(),x6e=a("span"),Dnr=o("AutoModelForObjectDetection"),gje=l(),Qo=a("div"),F(WL.$$.fragment),Gnr=l(),kd=a("p"),Onr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Uz=a("a"),Vnr=o("from_pretrained()"),Xnr=o(" class method or the "),Jz=a("a"),znr=o("from_config()"),Wnr=o(` class
method.`),Qnr=l(),QL=a("p"),Hnr=o("This class cannot be instantiated directly using "),$6e=a("code"),Unr=o("__init__()"),Jnr=o(" (throws an error)."),Ynr=l(),Et=a("div"),F(HL.$$.fragment),Knr=l(),k6e=a("p"),Znr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),esr=l(),Sd=a("p"),osr=o(`Note:
Loading a model from its configuration file does `),S6e=a("strong"),rsr=o("not"),tsr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yz=a("a"),asr=o("from_pretrained()"),nsr=o(" to load the model weights."),ssr=l(),F(PF.$$.fragment),lsr=l(),_o=a("div"),F(UL.$$.fragment),isr=l(),R6e=a("p"),dsr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),csr=l(),Qa=a("p"),fsr=o("The model class to instantiate is selected based on the "),P6e=a("code"),msr=o("model_type"),gsr=o(` property of the config object (either
passed as an argument or loaded from `),B6e=a("code"),hsr=o("pretrained_model_name_or_path"),psr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I6e=a("code"),_sr=o("pretrained_model_name_or_path"),usr=o(":"),bsr=l(),JL=a("ul"),BF=a("li"),N6e=a("strong"),vsr=o("detr"),Fsr=o(" \u2014 "),Kz=a("a"),Tsr=o("DetrForObjectDetection"),Msr=o(" (DETR model)"),Esr=l(),IF=a("li"),q6e=a("strong"),Csr=o("yolos"),wsr=o(" \u2014 "),Zz=a("a"),Asr=o("YolosForObjectDetection"),ysr=o(" (YOLOS model)"),Lsr=l(),NF=a("p"),xsr=o("The model is set in evaluation mode by default using "),j6e=a("code"),$sr=o("model.eval()"),ksr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),D6e=a("code"),Ssr=o("model.train()"),Rsr=l(),F(qF.$$.fragment),hje=l(),Rd=a("h2"),jF=a("a"),G6e=a("span"),F(YL.$$.fragment),Psr=l(),O6e=a("span"),Bsr=o("AutoModelForImageSegmentation"),pje=l(),Ho=a("div"),F(KL.$$.fragment),Isr=l(),Pd=a("p"),Nsr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),eW=a("a"),qsr=o("from_pretrained()"),jsr=o(" class method or the "),oW=a("a"),Dsr=o("from_config()"),Gsr=o(` class
method.`),Osr=l(),ZL=a("p"),Vsr=o("This class cannot be instantiated directly using "),V6e=a("code"),Xsr=o("__init__()"),zsr=o(" (throws an error)."),Wsr=l(),Ct=a("div"),F(e8.$$.fragment),Qsr=l(),X6e=a("p"),Hsr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Usr=l(),Bd=a("p"),Jsr=o(`Note:
Loading a model from its configuration file does `),z6e=a("strong"),Ysr=o("not"),Ksr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rW=a("a"),Zsr=o("from_pretrained()"),elr=o(" to load the model weights."),olr=l(),F(DF.$$.fragment),rlr=l(),uo=a("div"),F(o8.$$.fragment),tlr=l(),W6e=a("p"),alr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),nlr=l(),Ha=a("p"),slr=o("The model class to instantiate is selected based on the "),Q6e=a("code"),llr=o("model_type"),ilr=o(` property of the config object (either
passed as an argument or loaded from `),H6e=a("code"),dlr=o("pretrained_model_name_or_path"),clr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U6e=a("code"),flr=o("pretrained_model_name_or_path"),mlr=o(":"),glr=l(),J6e=a("ul"),GF=a("li"),Y6e=a("strong"),hlr=o("detr"),plr=o(" \u2014 "),tW=a("a"),_lr=o("DetrForSegmentation"),ulr=o(" (DETR model)"),blr=l(),OF=a("p"),vlr=o("The model is set in evaluation mode by default using "),K6e=a("code"),Flr=o("model.eval()"),Tlr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z6e=a("code"),Mlr=o("model.train()"),Elr=l(),F(VF.$$.fragment),_je=l(),Id=a("h2"),XF=a("a"),e1e=a("span"),F(r8.$$.fragment),Clr=l(),o1e=a("span"),wlr=o("AutoModelForSemanticSegmentation"),uje=l(),Uo=a("div"),F(t8.$$.fragment),Alr=l(),Nd=a("p"),ylr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),aW=a("a"),Llr=o("from_pretrained()"),xlr=o(" class method or the "),nW=a("a"),$lr=o("from_config()"),klr=o(` class
method.`),Slr=l(),a8=a("p"),Rlr=o("This class cannot be instantiated directly using "),r1e=a("code"),Plr=o("__init__()"),Blr=o(" (throws an error)."),Ilr=l(),wt=a("div"),F(n8.$$.fragment),Nlr=l(),t1e=a("p"),qlr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),jlr=l(),qd=a("p"),Dlr=o(`Note:
Loading a model from its configuration file does `),a1e=a("strong"),Glr=o("not"),Olr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sW=a("a"),Vlr=o("from_pretrained()"),Xlr=o(" to load the model weights."),zlr=l(),F(zF.$$.fragment),Wlr=l(),bo=a("div"),F(s8.$$.fragment),Qlr=l(),n1e=a("p"),Hlr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Ulr=l(),Ua=a("p"),Jlr=o("The model class to instantiate is selected based on the "),s1e=a("code"),Ylr=o("model_type"),Klr=o(` property of the config object (either
passed as an argument or loaded from `),l1e=a("code"),Zlr=o("pretrained_model_name_or_path"),eir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i1e=a("code"),oir=o("pretrained_model_name_or_path"),rir=o(":"),tir=l(),Ja=a("ul"),WF=a("li"),d1e=a("strong"),air=o("beit"),nir=o(" \u2014 "),lW=a("a"),sir=o("BeitForSemanticSegmentation"),lir=o(" (BEiT model)"),iir=l(),QF=a("li"),c1e=a("strong"),dir=o("data2vec-vision"),cir=o(" \u2014 "),iW=a("a"),fir=o("Data2VecVisionForSemanticSegmentation"),mir=o(" (Data2VecVision model)"),gir=l(),HF=a("li"),f1e=a("strong"),hir=o("dpt"),pir=o(" \u2014 "),dW=a("a"),_ir=o("DPTForSemanticSegmentation"),uir=o(" (DPT model)"),bir=l(),UF=a("li"),m1e=a("strong"),vir=o("segformer"),Fir=o(" \u2014 "),cW=a("a"),Tir=o("SegformerForSemanticSegmentation"),Mir=o(" (SegFormer model)"),Eir=l(),JF=a("p"),Cir=o("The model is set in evaluation mode by default using "),g1e=a("code"),wir=o("model.eval()"),Air=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),h1e=a("code"),yir=o("model.train()"),Lir=l(),F(YF.$$.fragment),bje=l(),jd=a("h2"),KF=a("a"),p1e=a("span"),F(l8.$$.fragment),xir=l(),_1e=a("span"),$ir=o("AutoModelForInstanceSegmentation"),vje=l(),Jo=a("div"),F(i8.$$.fragment),kir=l(),Dd=a("p"),Sir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),fW=a("a"),Rir=o("from_pretrained()"),Pir=o(" class method or the "),mW=a("a"),Bir=o("from_config()"),Iir=o(` class
method.`),Nir=l(),d8=a("p"),qir=o("This class cannot be instantiated directly using "),u1e=a("code"),jir=o("__init__()"),Dir=o(" (throws an error)."),Gir=l(),At=a("div"),F(c8.$$.fragment),Oir=l(),b1e=a("p"),Vir=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Xir=l(),Gd=a("p"),zir=o(`Note:
Loading a model from its configuration file does `),v1e=a("strong"),Wir=o("not"),Qir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gW=a("a"),Hir=o("from_pretrained()"),Uir=o(" to load the model weights."),Jir=l(),F(ZF.$$.fragment),Yir=l(),vo=a("div"),F(f8.$$.fragment),Kir=l(),F1e=a("p"),Zir=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),edr=l(),Ya=a("p"),odr=o("The model class to instantiate is selected based on the "),T1e=a("code"),rdr=o("model_type"),tdr=o(` property of the config object (either
passed as an argument or loaded from `),M1e=a("code"),adr=o("pretrained_model_name_or_path"),ndr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E1e=a("code"),sdr=o("pretrained_model_name_or_path"),ldr=o(":"),idr=l(),C1e=a("ul"),eT=a("li"),w1e=a("strong"),ddr=o("maskformer"),cdr=o(" \u2014 "),hW=a("a"),fdr=o("MaskFormerForInstanceSegmentation"),mdr=o(" (MaskFormer model)"),gdr=l(),oT=a("p"),hdr=o("The model is set in evaluation mode by default using "),A1e=a("code"),pdr=o("model.eval()"),_dr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),y1e=a("code"),udr=o("model.train()"),bdr=l(),F(rT.$$.fragment),Fje=l(),Od=a("h2"),tT=a("a"),L1e=a("span"),F(m8.$$.fragment),vdr=l(),x1e=a("span"),Fdr=o("TFAutoModel"),Tje=l(),Yo=a("div"),F(g8.$$.fragment),Tdr=l(),Vd=a("p"),Mdr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),pW=a("a"),Edr=o("from_pretrained()"),Cdr=o(" class method or the "),_W=a("a"),wdr=o("from_config()"),Adr=o(` class
method.`),ydr=l(),h8=a("p"),Ldr=o("This class cannot be instantiated directly using "),$1e=a("code"),xdr=o("__init__()"),$dr=o(" (throws an error)."),kdr=l(),yt=a("div"),F(p8.$$.fragment),Sdr=l(),k1e=a("p"),Rdr=o("Instantiates one of the base model classes of the library from a configuration."),Pdr=l(),Xd=a("p"),Bdr=o(`Note:
Loading a model from its configuration file does `),S1e=a("strong"),Idr=o("not"),Ndr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uW=a("a"),qdr=o("from_pretrained()"),jdr=o(" to load the model weights."),Ddr=l(),F(aT.$$.fragment),Gdr=l(),wr=a("div"),F(_8.$$.fragment),Odr=l(),R1e=a("p"),Vdr=o("Instantiate one of the base model classes of the library from a pretrained model."),Xdr=l(),Ka=a("p"),zdr=o("The model class to instantiate is selected based on the "),P1e=a("code"),Wdr=o("model_type"),Qdr=o(` property of the config object (either
passed as an argument or loaded from `),B1e=a("code"),Hdr=o("pretrained_model_name_or_path"),Udr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I1e=a("code"),Jdr=o("pretrained_model_name_or_path"),Ydr=o(":"),Kdr=l(),q=a("ul"),nT=a("li"),N1e=a("strong"),Zdr=o("albert"),ecr=o(" \u2014 "),bW=a("a"),ocr=o("TFAlbertModel"),rcr=o(" (ALBERT model)"),tcr=l(),sT=a("li"),q1e=a("strong"),acr=o("bart"),ncr=o(" \u2014 "),vW=a("a"),scr=o("TFBartModel"),lcr=o(" (BART model)"),icr=l(),lT=a("li"),j1e=a("strong"),dcr=o("bert"),ccr=o(" \u2014 "),FW=a("a"),fcr=o("TFBertModel"),mcr=o(" (BERT model)"),gcr=l(),iT=a("li"),D1e=a("strong"),hcr=o("blenderbot"),pcr=o(" \u2014 "),TW=a("a"),_cr=o("TFBlenderbotModel"),ucr=o(" (Blenderbot model)"),bcr=l(),dT=a("li"),G1e=a("strong"),vcr=o("blenderbot-small"),Fcr=o(" \u2014 "),MW=a("a"),Tcr=o("TFBlenderbotSmallModel"),Mcr=o(" (BlenderbotSmall model)"),Ecr=l(),cT=a("li"),O1e=a("strong"),Ccr=o("camembert"),wcr=o(" \u2014 "),EW=a("a"),Acr=o("TFCamembertModel"),ycr=o(" (CamemBERT model)"),Lcr=l(),fT=a("li"),V1e=a("strong"),xcr=o("clip"),$cr=o(" \u2014 "),CW=a("a"),kcr=o("TFCLIPModel"),Scr=o(" (CLIP model)"),Rcr=l(),mT=a("li"),X1e=a("strong"),Pcr=o("convbert"),Bcr=o(" \u2014 "),wW=a("a"),Icr=o("TFConvBertModel"),Ncr=o(" (ConvBERT model)"),qcr=l(),gT=a("li"),z1e=a("strong"),jcr=o("convnext"),Dcr=o(" \u2014 "),AW=a("a"),Gcr=o("TFConvNextModel"),Ocr=o(" (ConvNext model)"),Vcr=l(),hT=a("li"),W1e=a("strong"),Xcr=o("ctrl"),zcr=o(" \u2014 "),yW=a("a"),Wcr=o("TFCTRLModel"),Qcr=o(" (CTRL model)"),Hcr=l(),pT=a("li"),Q1e=a("strong"),Ucr=o("data2vec-vision"),Jcr=o(" \u2014 "),LW=a("a"),Ycr=o("TFData2VecVisionModel"),Kcr=o(" (Data2VecVision model)"),Zcr=l(),_T=a("li"),H1e=a("strong"),efr=o("deberta"),ofr=o(" \u2014 "),xW=a("a"),rfr=o("TFDebertaModel"),tfr=o(" (DeBERTa model)"),afr=l(),uT=a("li"),U1e=a("strong"),nfr=o("deberta-v2"),sfr=o(" \u2014 "),$W=a("a"),lfr=o("TFDebertaV2Model"),ifr=o(" (DeBERTa-v2 model)"),dfr=l(),bT=a("li"),J1e=a("strong"),cfr=o("distilbert"),ffr=o(" \u2014 "),kW=a("a"),mfr=o("TFDistilBertModel"),gfr=o(" (DistilBERT model)"),hfr=l(),vT=a("li"),Y1e=a("strong"),pfr=o("dpr"),_fr=o(" \u2014 "),SW=a("a"),ufr=o("TFDPRQuestionEncoder"),bfr=o(" (DPR model)"),vfr=l(),FT=a("li"),K1e=a("strong"),Ffr=o("electra"),Tfr=o(" \u2014 "),RW=a("a"),Mfr=o("TFElectraModel"),Efr=o(" (ELECTRA model)"),Cfr=l(),TT=a("li"),Z1e=a("strong"),wfr=o("flaubert"),Afr=o(" \u2014 "),PW=a("a"),yfr=o("TFFlaubertModel"),Lfr=o(" (FlauBERT model)"),xfr=l(),Ns=a("li"),ebe=a("strong"),$fr=o("funnel"),kfr=o(" \u2014 "),BW=a("a"),Sfr=o("TFFunnelModel"),Rfr=o(" or "),IW=a("a"),Pfr=o("TFFunnelBaseModel"),Bfr=o(" (Funnel Transformer model)"),Ifr=l(),MT=a("li"),obe=a("strong"),Nfr=o("gpt2"),qfr=o(" \u2014 "),NW=a("a"),jfr=o("TFGPT2Model"),Dfr=o(" (OpenAI GPT-2 model)"),Gfr=l(),ET=a("li"),rbe=a("strong"),Ofr=o("gptj"),Vfr=o(" \u2014 "),qW=a("a"),Xfr=o("TFGPTJModel"),zfr=o(" (GPT-J model)"),Wfr=l(),CT=a("li"),tbe=a("strong"),Qfr=o("hubert"),Hfr=o(" \u2014 "),jW=a("a"),Ufr=o("TFHubertModel"),Jfr=o(" (Hubert model)"),Yfr=l(),wT=a("li"),abe=a("strong"),Kfr=o("layoutlm"),Zfr=o(" \u2014 "),DW=a("a"),emr=o("TFLayoutLMModel"),omr=o(" (LayoutLM model)"),rmr=l(),AT=a("li"),nbe=a("strong"),tmr=o("led"),amr=o(" \u2014 "),GW=a("a"),nmr=o("TFLEDModel"),smr=o(" (LED model)"),lmr=l(),yT=a("li"),sbe=a("strong"),imr=o("longformer"),dmr=o(" \u2014 "),OW=a("a"),cmr=o("TFLongformerModel"),fmr=o(" (Longformer model)"),mmr=l(),LT=a("li"),lbe=a("strong"),gmr=o("lxmert"),hmr=o(" \u2014 "),VW=a("a"),pmr=o("TFLxmertModel"),_mr=o(" (LXMERT model)"),umr=l(),xT=a("li"),ibe=a("strong"),bmr=o("marian"),vmr=o(" \u2014 "),XW=a("a"),Fmr=o("TFMarianModel"),Tmr=o(" (Marian model)"),Mmr=l(),$T=a("li"),dbe=a("strong"),Emr=o("mbart"),Cmr=o(" \u2014 "),zW=a("a"),wmr=o("TFMBartModel"),Amr=o(" (mBART model)"),ymr=l(),kT=a("li"),cbe=a("strong"),Lmr=o("mobilebert"),xmr=o(" \u2014 "),WW=a("a"),$mr=o("TFMobileBertModel"),kmr=o(" (MobileBERT model)"),Smr=l(),ST=a("li"),fbe=a("strong"),Rmr=o("mpnet"),Pmr=o(" \u2014 "),QW=a("a"),Bmr=o("TFMPNetModel"),Imr=o(" (MPNet model)"),Nmr=l(),RT=a("li"),mbe=a("strong"),qmr=o("mt5"),jmr=o(" \u2014 "),HW=a("a"),Dmr=o("TFMT5Model"),Gmr=o(" (mT5 model)"),Omr=l(),PT=a("li"),gbe=a("strong"),Vmr=o("openai-gpt"),Xmr=o(" \u2014 "),UW=a("a"),zmr=o("TFOpenAIGPTModel"),Wmr=o(" (OpenAI GPT model)"),Qmr=l(),BT=a("li"),hbe=a("strong"),Hmr=o("pegasus"),Umr=o(" \u2014 "),JW=a("a"),Jmr=o("TFPegasusModel"),Ymr=o(" (Pegasus model)"),Kmr=l(),IT=a("li"),pbe=a("strong"),Zmr=o("rembert"),egr=o(" \u2014 "),YW=a("a"),ogr=o("TFRemBertModel"),rgr=o(" (RemBERT model)"),tgr=l(),NT=a("li"),_be=a("strong"),agr=o("roberta"),ngr=o(" \u2014 "),KW=a("a"),sgr=o("TFRobertaModel"),lgr=o(" (RoBERTa model)"),igr=l(),qT=a("li"),ube=a("strong"),dgr=o("roformer"),cgr=o(" \u2014 "),ZW=a("a"),fgr=o("TFRoFormerModel"),mgr=o(" (RoFormer model)"),ggr=l(),jT=a("li"),bbe=a("strong"),hgr=o("speech_to_text"),pgr=o(" \u2014 "),eQ=a("a"),_gr=o("TFSpeech2TextModel"),ugr=o(" (Speech2Text model)"),bgr=l(),DT=a("li"),vbe=a("strong"),vgr=o("swin"),Fgr=o(" \u2014 "),oQ=a("a"),Tgr=o("TFSwinModel"),Mgr=o(" (Swin model)"),Egr=l(),GT=a("li"),Fbe=a("strong"),Cgr=o("t5"),wgr=o(" \u2014 "),rQ=a("a"),Agr=o("TFT5Model"),ygr=o(" (T5 model)"),Lgr=l(),OT=a("li"),Tbe=a("strong"),xgr=o("tapas"),$gr=o(" \u2014 "),tQ=a("a"),kgr=o("TFTapasModel"),Sgr=o(" (TAPAS model)"),Rgr=l(),VT=a("li"),Mbe=a("strong"),Pgr=o("transfo-xl"),Bgr=o(" \u2014 "),aQ=a("a"),Igr=o("TFTransfoXLModel"),Ngr=o(" (Transformer-XL model)"),qgr=l(),XT=a("li"),Ebe=a("strong"),jgr=o("vit"),Dgr=o(" \u2014 "),nQ=a("a"),Ggr=o("TFViTModel"),Ogr=o(" (ViT model)"),Vgr=l(),zT=a("li"),Cbe=a("strong"),Xgr=o("vit_mae"),zgr=o(" \u2014 "),sQ=a("a"),Wgr=o("TFViTMAEModel"),Qgr=o(" (ViTMAE model)"),Hgr=l(),WT=a("li"),wbe=a("strong"),Ugr=o("wav2vec2"),Jgr=o(" \u2014 "),lQ=a("a"),Ygr=o("TFWav2Vec2Model"),Kgr=o(" (Wav2Vec2 model)"),Zgr=l(),QT=a("li"),Abe=a("strong"),ehr=o("xlm"),ohr=o(" \u2014 "),iQ=a("a"),rhr=o("TFXLMModel"),thr=o(" (XLM model)"),ahr=l(),HT=a("li"),ybe=a("strong"),nhr=o("xlm-roberta"),shr=o(" \u2014 "),dQ=a("a"),lhr=o("TFXLMRobertaModel"),ihr=o(" (XLM-RoBERTa model)"),dhr=l(),UT=a("li"),Lbe=a("strong"),chr=o("xlnet"),fhr=o(" \u2014 "),cQ=a("a"),mhr=o("TFXLNetModel"),ghr=o(" (XLNet model)"),hhr=l(),F(JT.$$.fragment),Mje=l(),zd=a("h2"),YT=a("a"),xbe=a("span"),F(u8.$$.fragment),phr=l(),$be=a("span"),_hr=o("TFAutoModelForPreTraining"),Eje=l(),Ko=a("div"),F(b8.$$.fragment),uhr=l(),Wd=a("p"),bhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),fQ=a("a"),vhr=o("from_pretrained()"),Fhr=o(" class method or the "),mQ=a("a"),Thr=o("from_config()"),Mhr=o(` class
method.`),Ehr=l(),v8=a("p"),Chr=o("This class cannot be instantiated directly using "),kbe=a("code"),whr=o("__init__()"),Ahr=o(" (throws an error)."),yhr=l(),Lt=a("div"),F(F8.$$.fragment),Lhr=l(),Sbe=a("p"),xhr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),$hr=l(),Qd=a("p"),khr=o(`Note:
Loading a model from its configuration file does `),Rbe=a("strong"),Shr=o("not"),Rhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gQ=a("a"),Phr=o("from_pretrained()"),Bhr=o(" to load the model weights."),Ihr=l(),F(KT.$$.fragment),Nhr=l(),Ar=a("div"),F(T8.$$.fragment),qhr=l(),Pbe=a("p"),jhr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Dhr=l(),Za=a("p"),Ghr=o("The model class to instantiate is selected based on the "),Bbe=a("code"),Ohr=o("model_type"),Vhr=o(` property of the config object (either
passed as an argument or loaded from `),Ibe=a("code"),Xhr=o("pretrained_model_name_or_path"),zhr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nbe=a("code"),Whr=o("pretrained_model_name_or_path"),Qhr=o(":"),Hhr=l(),se=a("ul"),ZT=a("li"),qbe=a("strong"),Uhr=o("albert"),Jhr=o(" \u2014 "),hQ=a("a"),Yhr=o("TFAlbertForPreTraining"),Khr=o(" (ALBERT model)"),Zhr=l(),e7=a("li"),jbe=a("strong"),epr=o("bart"),opr=o(" \u2014 "),pQ=a("a"),rpr=o("TFBartForConditionalGeneration"),tpr=o(" (BART model)"),apr=l(),o7=a("li"),Dbe=a("strong"),npr=o("bert"),spr=o(" \u2014 "),_Q=a("a"),lpr=o("TFBertForPreTraining"),ipr=o(" (BERT model)"),dpr=l(),r7=a("li"),Gbe=a("strong"),cpr=o("camembert"),fpr=o(" \u2014 "),uQ=a("a"),mpr=o("TFCamembertForMaskedLM"),gpr=o(" (CamemBERT model)"),hpr=l(),t7=a("li"),Obe=a("strong"),ppr=o("ctrl"),_pr=o(" \u2014 "),bQ=a("a"),upr=o("TFCTRLLMHeadModel"),bpr=o(" (CTRL model)"),vpr=l(),a7=a("li"),Vbe=a("strong"),Fpr=o("distilbert"),Tpr=o(" \u2014 "),vQ=a("a"),Mpr=o("TFDistilBertForMaskedLM"),Epr=o(" (DistilBERT model)"),Cpr=l(),n7=a("li"),Xbe=a("strong"),wpr=o("electra"),Apr=o(" \u2014 "),FQ=a("a"),ypr=o("TFElectraForPreTraining"),Lpr=o(" (ELECTRA model)"),xpr=l(),s7=a("li"),zbe=a("strong"),$pr=o("flaubert"),kpr=o(" \u2014 "),TQ=a("a"),Spr=o("TFFlaubertWithLMHeadModel"),Rpr=o(" (FlauBERT model)"),Ppr=l(),l7=a("li"),Wbe=a("strong"),Bpr=o("funnel"),Ipr=o(" \u2014 "),MQ=a("a"),Npr=o("TFFunnelForPreTraining"),qpr=o(" (Funnel Transformer model)"),jpr=l(),i7=a("li"),Qbe=a("strong"),Dpr=o("gpt2"),Gpr=o(" \u2014 "),EQ=a("a"),Opr=o("TFGPT2LMHeadModel"),Vpr=o(" (OpenAI GPT-2 model)"),Xpr=l(),d7=a("li"),Hbe=a("strong"),zpr=o("layoutlm"),Wpr=o(" \u2014 "),CQ=a("a"),Qpr=o("TFLayoutLMForMaskedLM"),Hpr=o(" (LayoutLM model)"),Upr=l(),c7=a("li"),Ube=a("strong"),Jpr=o("lxmert"),Ypr=o(" \u2014 "),wQ=a("a"),Kpr=o("TFLxmertForPreTraining"),Zpr=o(" (LXMERT model)"),e_r=l(),f7=a("li"),Jbe=a("strong"),o_r=o("mobilebert"),r_r=o(" \u2014 "),AQ=a("a"),t_r=o("TFMobileBertForPreTraining"),a_r=o(" (MobileBERT model)"),n_r=l(),m7=a("li"),Ybe=a("strong"),s_r=o("mpnet"),l_r=o(" \u2014 "),yQ=a("a"),i_r=o("TFMPNetForMaskedLM"),d_r=o(" (MPNet model)"),c_r=l(),g7=a("li"),Kbe=a("strong"),f_r=o("openai-gpt"),m_r=o(" \u2014 "),LQ=a("a"),g_r=o("TFOpenAIGPTLMHeadModel"),h_r=o(" (OpenAI GPT model)"),p_r=l(),h7=a("li"),Zbe=a("strong"),__r=o("roberta"),u_r=o(" \u2014 "),xQ=a("a"),b_r=o("TFRobertaForMaskedLM"),v_r=o(" (RoBERTa model)"),F_r=l(),p7=a("li"),e2e=a("strong"),T_r=o("t5"),M_r=o(" \u2014 "),$Q=a("a"),E_r=o("TFT5ForConditionalGeneration"),C_r=o(" (T5 model)"),w_r=l(),_7=a("li"),o2e=a("strong"),A_r=o("tapas"),y_r=o(" \u2014 "),kQ=a("a"),L_r=o("TFTapasForMaskedLM"),x_r=o(" (TAPAS model)"),$_r=l(),u7=a("li"),r2e=a("strong"),k_r=o("transfo-xl"),S_r=o(" \u2014 "),SQ=a("a"),R_r=o("TFTransfoXLLMHeadModel"),P_r=o(" (Transformer-XL model)"),B_r=l(),b7=a("li"),t2e=a("strong"),I_r=o("vit_mae"),N_r=o(" \u2014 "),RQ=a("a"),q_r=o("TFViTMAEForPreTraining"),j_r=o(" (ViTMAE model)"),D_r=l(),v7=a("li"),a2e=a("strong"),G_r=o("xlm"),O_r=o(" \u2014 "),PQ=a("a"),V_r=o("TFXLMWithLMHeadModel"),X_r=o(" (XLM model)"),z_r=l(),F7=a("li"),n2e=a("strong"),W_r=o("xlm-roberta"),Q_r=o(" \u2014 "),BQ=a("a"),H_r=o("TFXLMRobertaForMaskedLM"),U_r=o(" (XLM-RoBERTa model)"),J_r=l(),T7=a("li"),s2e=a("strong"),Y_r=o("xlnet"),K_r=o(" \u2014 "),IQ=a("a"),Z_r=o("TFXLNetLMHeadModel"),eur=o(" (XLNet model)"),our=l(),F(M7.$$.fragment),Cje=l(),Hd=a("h2"),E7=a("a"),l2e=a("span"),F(M8.$$.fragment),rur=l(),i2e=a("span"),tur=o("TFAutoModelForCausalLM"),wje=l(),Zo=a("div"),F(E8.$$.fragment),aur=l(),Ud=a("p"),nur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),NQ=a("a"),sur=o("from_pretrained()"),lur=o(" class method or the "),qQ=a("a"),iur=o("from_config()"),dur=o(` class
method.`),cur=l(),C8=a("p"),fur=o("This class cannot be instantiated directly using "),d2e=a("code"),mur=o("__init__()"),gur=o(" (throws an error)."),hur=l(),xt=a("div"),F(w8.$$.fragment),pur=l(),c2e=a("p"),_ur=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),uur=l(),Jd=a("p"),bur=o(`Note:
Loading a model from its configuration file does `),f2e=a("strong"),vur=o("not"),Fur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jQ=a("a"),Tur=o("from_pretrained()"),Mur=o(" to load the model weights."),Eur=l(),F(C7.$$.fragment),Cur=l(),yr=a("div"),F(A8.$$.fragment),wur=l(),m2e=a("p"),Aur=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),yur=l(),en=a("p"),Lur=o("The model class to instantiate is selected based on the "),g2e=a("code"),xur=o("model_type"),$ur=o(` property of the config object (either
passed as an argument or loaded from `),h2e=a("code"),kur=o("pretrained_model_name_or_path"),Sur=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p2e=a("code"),Rur=o("pretrained_model_name_or_path"),Pur=o(":"),Bur=l(),Me=a("ul"),w7=a("li"),_2e=a("strong"),Iur=o("bert"),Nur=o(" \u2014 "),DQ=a("a"),qur=o("TFBertLMHeadModel"),jur=o(" (BERT model)"),Dur=l(),A7=a("li"),u2e=a("strong"),Gur=o("camembert"),Our=o(" \u2014 "),GQ=a("a"),Vur=o("TFCamembertForCausalLM"),Xur=o(" (CamemBERT model)"),zur=l(),y7=a("li"),b2e=a("strong"),Wur=o("ctrl"),Qur=o(" \u2014 "),OQ=a("a"),Hur=o("TFCTRLLMHeadModel"),Uur=o(" (CTRL model)"),Jur=l(),L7=a("li"),v2e=a("strong"),Yur=o("gpt2"),Kur=o(" \u2014 "),VQ=a("a"),Zur=o("TFGPT2LMHeadModel"),e6r=o(" (OpenAI GPT-2 model)"),o6r=l(),x7=a("li"),F2e=a("strong"),r6r=o("gptj"),t6r=o(" \u2014 "),XQ=a("a"),a6r=o("TFGPTJForCausalLM"),n6r=o(" (GPT-J model)"),s6r=l(),$7=a("li"),T2e=a("strong"),l6r=o("openai-gpt"),i6r=o(" \u2014 "),zQ=a("a"),d6r=o("TFOpenAIGPTLMHeadModel"),c6r=o(" (OpenAI GPT model)"),f6r=l(),k7=a("li"),M2e=a("strong"),m6r=o("rembert"),g6r=o(" \u2014 "),WQ=a("a"),h6r=o("TFRemBertForCausalLM"),p6r=o(" (RemBERT model)"),_6r=l(),S7=a("li"),E2e=a("strong"),u6r=o("roberta"),b6r=o(" \u2014 "),QQ=a("a"),v6r=o("TFRobertaForCausalLM"),F6r=o(" (RoBERTa model)"),T6r=l(),R7=a("li"),C2e=a("strong"),M6r=o("roformer"),E6r=o(" \u2014 "),HQ=a("a"),C6r=o("TFRoFormerForCausalLM"),w6r=o(" (RoFormer model)"),A6r=l(),P7=a("li"),w2e=a("strong"),y6r=o("transfo-xl"),L6r=o(" \u2014 "),UQ=a("a"),x6r=o("TFTransfoXLLMHeadModel"),$6r=o(" (Transformer-XL model)"),k6r=l(),B7=a("li"),A2e=a("strong"),S6r=o("xlm"),R6r=o(" \u2014 "),JQ=a("a"),P6r=o("TFXLMWithLMHeadModel"),B6r=o(" (XLM model)"),I6r=l(),I7=a("li"),y2e=a("strong"),N6r=o("xlnet"),q6r=o(" \u2014 "),YQ=a("a"),j6r=o("TFXLNetLMHeadModel"),D6r=o(" (XLNet model)"),G6r=l(),F(N7.$$.fragment),Aje=l(),Yd=a("h2"),q7=a("a"),L2e=a("span"),F(y8.$$.fragment),O6r=l(),x2e=a("span"),V6r=o("TFAutoModelForImageClassification"),yje=l(),er=a("div"),F(L8.$$.fragment),X6r=l(),Kd=a("p"),z6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),KQ=a("a"),W6r=o("from_pretrained()"),Q6r=o(" class method or the "),ZQ=a("a"),H6r=o("from_config()"),U6r=o(` class
method.`),J6r=l(),x8=a("p"),Y6r=o("This class cannot be instantiated directly using "),$2e=a("code"),K6r=o("__init__()"),Z6r=o(" (throws an error)."),e1r=l(),$t=a("div"),F($8.$$.fragment),o1r=l(),k2e=a("p"),r1r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),t1r=l(),Zd=a("p"),a1r=o(`Note:
Loading a model from its configuration file does `),S2e=a("strong"),n1r=o("not"),s1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eH=a("a"),l1r=o("from_pretrained()"),i1r=o(" to load the model weights."),d1r=l(),F(j7.$$.fragment),c1r=l(),Lr=a("div"),F(k8.$$.fragment),f1r=l(),R2e=a("p"),m1r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),g1r=l(),on=a("p"),h1r=o("The model class to instantiate is selected based on the "),P2e=a("code"),p1r=o("model_type"),_1r=o(` property of the config object (either
passed as an argument or loaded from `),B2e=a("code"),u1r=o("pretrained_model_name_or_path"),b1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I2e=a("code"),v1r=o("pretrained_model_name_or_path"),F1r=o(":"),T1r=l(),rn=a("ul"),D7=a("li"),N2e=a("strong"),M1r=o("convnext"),E1r=o(" \u2014 "),oH=a("a"),C1r=o("TFConvNextForImageClassification"),w1r=o(" (ConvNext model)"),A1r=l(),G7=a("li"),q2e=a("strong"),y1r=o("data2vec-vision"),L1r=o(" \u2014 "),rH=a("a"),x1r=o("TFData2VecVisionForImageClassification"),$1r=o(" (Data2VecVision model)"),k1r=l(),O7=a("li"),j2e=a("strong"),S1r=o("swin"),R1r=o(" \u2014 "),tH=a("a"),P1r=o("TFSwinForImageClassification"),B1r=o(" (Swin model)"),I1r=l(),V7=a("li"),D2e=a("strong"),N1r=o("vit"),q1r=o(" \u2014 "),aH=a("a"),j1r=o("TFViTForImageClassification"),D1r=o(" (ViT model)"),G1r=l(),F(X7.$$.fragment),Lje=l(),ec=a("h2"),z7=a("a"),G2e=a("span"),F(S8.$$.fragment),O1r=l(),O2e=a("span"),V1r=o("TFAutoModelForMaskedLM"),xje=l(),or=a("div"),F(R8.$$.fragment),X1r=l(),oc=a("p"),z1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),nH=a("a"),W1r=o("from_pretrained()"),Q1r=o(" class method or the "),sH=a("a"),H1r=o("from_config()"),U1r=o(` class
method.`),J1r=l(),P8=a("p"),Y1r=o("This class cannot be instantiated directly using "),V2e=a("code"),K1r=o("__init__()"),Z1r=o(" (throws an error)."),ebr=l(),kt=a("div"),F(B8.$$.fragment),obr=l(),X2e=a("p"),rbr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),tbr=l(),rc=a("p"),abr=o(`Note:
Loading a model from its configuration file does `),z2e=a("strong"),nbr=o("not"),sbr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lH=a("a"),lbr=o("from_pretrained()"),ibr=o(" to load the model weights."),dbr=l(),F(W7.$$.fragment),cbr=l(),xr=a("div"),F(I8.$$.fragment),fbr=l(),W2e=a("p"),mbr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),gbr=l(),tn=a("p"),hbr=o("The model class to instantiate is selected based on the "),Q2e=a("code"),pbr=o("model_type"),_br=o(` property of the config object (either
passed as an argument or loaded from `),H2e=a("code"),ubr=o("pretrained_model_name_or_path"),bbr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U2e=a("code"),vbr=o("pretrained_model_name_or_path"),Fbr=o(":"),Tbr=l(),ie=a("ul"),Q7=a("li"),J2e=a("strong"),Mbr=o("albert"),Ebr=o(" \u2014 "),iH=a("a"),Cbr=o("TFAlbertForMaskedLM"),wbr=o(" (ALBERT model)"),Abr=l(),H7=a("li"),Y2e=a("strong"),ybr=o("bert"),Lbr=o(" \u2014 "),dH=a("a"),xbr=o("TFBertForMaskedLM"),$br=o(" (BERT model)"),kbr=l(),U7=a("li"),K2e=a("strong"),Sbr=o("camembert"),Rbr=o(" \u2014 "),cH=a("a"),Pbr=o("TFCamembertForMaskedLM"),Bbr=o(" (CamemBERT model)"),Ibr=l(),J7=a("li"),Z2e=a("strong"),Nbr=o("convbert"),qbr=o(" \u2014 "),fH=a("a"),jbr=o("TFConvBertForMaskedLM"),Dbr=o(" (ConvBERT model)"),Gbr=l(),Y7=a("li"),e4e=a("strong"),Obr=o("deberta"),Vbr=o(" \u2014 "),mH=a("a"),Xbr=o("TFDebertaForMaskedLM"),zbr=o(" (DeBERTa model)"),Wbr=l(),K7=a("li"),o4e=a("strong"),Qbr=o("deberta-v2"),Hbr=o(" \u2014 "),gH=a("a"),Ubr=o("TFDebertaV2ForMaskedLM"),Jbr=o(" (DeBERTa-v2 model)"),Ybr=l(),Z7=a("li"),r4e=a("strong"),Kbr=o("distilbert"),Zbr=o(" \u2014 "),hH=a("a"),e2r=o("TFDistilBertForMaskedLM"),o2r=o(" (DistilBERT model)"),r2r=l(),eM=a("li"),t4e=a("strong"),t2r=o("electra"),a2r=o(" \u2014 "),pH=a("a"),n2r=o("TFElectraForMaskedLM"),s2r=o(" (ELECTRA model)"),l2r=l(),oM=a("li"),a4e=a("strong"),i2r=o("flaubert"),d2r=o(" \u2014 "),_H=a("a"),c2r=o("TFFlaubertWithLMHeadModel"),f2r=o(" (FlauBERT model)"),m2r=l(),rM=a("li"),n4e=a("strong"),g2r=o("funnel"),h2r=o(" \u2014 "),uH=a("a"),p2r=o("TFFunnelForMaskedLM"),_2r=o(" (Funnel Transformer model)"),u2r=l(),tM=a("li"),s4e=a("strong"),b2r=o("layoutlm"),v2r=o(" \u2014 "),bH=a("a"),F2r=o("TFLayoutLMForMaskedLM"),T2r=o(" (LayoutLM model)"),M2r=l(),aM=a("li"),l4e=a("strong"),E2r=o("longformer"),C2r=o(" \u2014 "),vH=a("a"),w2r=o("TFLongformerForMaskedLM"),A2r=o(" (Longformer model)"),y2r=l(),nM=a("li"),i4e=a("strong"),L2r=o("mobilebert"),x2r=o(" \u2014 "),FH=a("a"),$2r=o("TFMobileBertForMaskedLM"),k2r=o(" (MobileBERT model)"),S2r=l(),sM=a("li"),d4e=a("strong"),R2r=o("mpnet"),P2r=o(" \u2014 "),TH=a("a"),B2r=o("TFMPNetForMaskedLM"),I2r=o(" (MPNet model)"),N2r=l(),lM=a("li"),c4e=a("strong"),q2r=o("rembert"),j2r=o(" \u2014 "),MH=a("a"),D2r=o("TFRemBertForMaskedLM"),G2r=o(" (RemBERT model)"),O2r=l(),iM=a("li"),f4e=a("strong"),V2r=o("roberta"),X2r=o(" \u2014 "),EH=a("a"),z2r=o("TFRobertaForMaskedLM"),W2r=o(" (RoBERTa model)"),Q2r=l(),dM=a("li"),m4e=a("strong"),H2r=o("roformer"),U2r=o(" \u2014 "),CH=a("a"),J2r=o("TFRoFormerForMaskedLM"),Y2r=o(" (RoFormer model)"),K2r=l(),cM=a("li"),g4e=a("strong"),Z2r=o("tapas"),e4r=o(" \u2014 "),wH=a("a"),o4r=o("TFTapasForMaskedLM"),r4r=o(" (TAPAS model)"),t4r=l(),fM=a("li"),h4e=a("strong"),a4r=o("xlm"),n4r=o(" \u2014 "),AH=a("a"),s4r=o("TFXLMWithLMHeadModel"),l4r=o(" (XLM model)"),i4r=l(),mM=a("li"),p4e=a("strong"),d4r=o("xlm-roberta"),c4r=o(" \u2014 "),yH=a("a"),f4r=o("TFXLMRobertaForMaskedLM"),m4r=o(" (XLM-RoBERTa model)"),g4r=l(),F(gM.$$.fragment),$je=l(),tc=a("h2"),hM=a("a"),_4e=a("span"),F(N8.$$.fragment),h4r=l(),u4e=a("span"),p4r=o("TFAutoModelForSeq2SeqLM"),kje=l(),rr=a("div"),F(q8.$$.fragment),_4r=l(),ac=a("p"),u4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),LH=a("a"),b4r=o("from_pretrained()"),v4r=o(" class method or the "),xH=a("a"),F4r=o("from_config()"),T4r=o(` class
method.`),M4r=l(),j8=a("p"),E4r=o("This class cannot be instantiated directly using "),b4e=a("code"),C4r=o("__init__()"),w4r=o(" (throws an error)."),A4r=l(),St=a("div"),F(D8.$$.fragment),y4r=l(),v4e=a("p"),L4r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),x4r=l(),nc=a("p"),$4r=o(`Note:
Loading a model from its configuration file does `),F4e=a("strong"),k4r=o("not"),S4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$H=a("a"),R4r=o("from_pretrained()"),P4r=o(" to load the model weights."),B4r=l(),F(pM.$$.fragment),I4r=l(),$r=a("div"),F(G8.$$.fragment),N4r=l(),T4e=a("p"),q4r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),j4r=l(),an=a("p"),D4r=o("The model class to instantiate is selected based on the "),M4e=a("code"),G4r=o("model_type"),O4r=o(` property of the config object (either
passed as an argument or loaded from `),E4e=a("code"),V4r=o("pretrained_model_name_or_path"),X4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C4e=a("code"),z4r=o("pretrained_model_name_or_path"),W4r=o(":"),Q4r=l(),ye=a("ul"),_M=a("li"),w4e=a("strong"),H4r=o("bart"),U4r=o(" \u2014 "),kH=a("a"),J4r=o("TFBartForConditionalGeneration"),Y4r=o(" (BART model)"),K4r=l(),uM=a("li"),A4e=a("strong"),Z4r=o("blenderbot"),evr=o(" \u2014 "),SH=a("a"),ovr=o("TFBlenderbotForConditionalGeneration"),rvr=o(" (Blenderbot model)"),tvr=l(),bM=a("li"),y4e=a("strong"),avr=o("blenderbot-small"),nvr=o(" \u2014 "),RH=a("a"),svr=o("TFBlenderbotSmallForConditionalGeneration"),lvr=o(" (BlenderbotSmall model)"),ivr=l(),vM=a("li"),L4e=a("strong"),dvr=o("encoder-decoder"),cvr=o(" \u2014 "),PH=a("a"),fvr=o("TFEncoderDecoderModel"),mvr=o(" (Encoder decoder model)"),gvr=l(),FM=a("li"),x4e=a("strong"),hvr=o("led"),pvr=o(" \u2014 "),BH=a("a"),_vr=o("TFLEDForConditionalGeneration"),uvr=o(" (LED model)"),bvr=l(),TM=a("li"),$4e=a("strong"),vvr=o("marian"),Fvr=o(" \u2014 "),IH=a("a"),Tvr=o("TFMarianMTModel"),Mvr=o(" (Marian model)"),Evr=l(),MM=a("li"),k4e=a("strong"),Cvr=o("mbart"),wvr=o(" \u2014 "),NH=a("a"),Avr=o("TFMBartForConditionalGeneration"),yvr=o(" (mBART model)"),Lvr=l(),EM=a("li"),S4e=a("strong"),xvr=o("mt5"),$vr=o(" \u2014 "),qH=a("a"),kvr=o("TFMT5ForConditionalGeneration"),Svr=o(" (mT5 model)"),Rvr=l(),CM=a("li"),R4e=a("strong"),Pvr=o("pegasus"),Bvr=o(" \u2014 "),jH=a("a"),Ivr=o("TFPegasusForConditionalGeneration"),Nvr=o(" (Pegasus model)"),qvr=l(),wM=a("li"),P4e=a("strong"),jvr=o("t5"),Dvr=o(" \u2014 "),DH=a("a"),Gvr=o("TFT5ForConditionalGeneration"),Ovr=o(" (T5 model)"),Vvr=l(),F(AM.$$.fragment),Sje=l(),sc=a("h2"),yM=a("a"),B4e=a("span"),F(O8.$$.fragment),Xvr=l(),I4e=a("span"),zvr=o("TFAutoModelForSequenceClassification"),Rje=l(),tr=a("div"),F(V8.$$.fragment),Wvr=l(),lc=a("p"),Qvr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),GH=a("a"),Hvr=o("from_pretrained()"),Uvr=o(" class method or the "),OH=a("a"),Jvr=o("from_config()"),Yvr=o(` class
method.`),Kvr=l(),X8=a("p"),Zvr=o("This class cannot be instantiated directly using "),N4e=a("code"),eFr=o("__init__()"),oFr=o(" (throws an error)."),rFr=l(),Rt=a("div"),F(z8.$$.fragment),tFr=l(),q4e=a("p"),aFr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),nFr=l(),ic=a("p"),sFr=o(`Note:
Loading a model from its configuration file does `),j4e=a("strong"),lFr=o("not"),iFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VH=a("a"),dFr=o("from_pretrained()"),cFr=o(" to load the model weights."),fFr=l(),F(LM.$$.fragment),mFr=l(),kr=a("div"),F(W8.$$.fragment),gFr=l(),D4e=a("p"),hFr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),pFr=l(),nn=a("p"),_Fr=o("The model class to instantiate is selected based on the "),G4e=a("code"),uFr=o("model_type"),bFr=o(` property of the config object (either
passed as an argument or loaded from `),O4e=a("code"),vFr=o("pretrained_model_name_or_path"),FFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V4e=a("code"),TFr=o("pretrained_model_name_or_path"),MFr=o(":"),EFr=l(),oe=a("ul"),xM=a("li"),X4e=a("strong"),CFr=o("albert"),wFr=o(" \u2014 "),XH=a("a"),AFr=o("TFAlbertForSequenceClassification"),yFr=o(" (ALBERT model)"),LFr=l(),$M=a("li"),z4e=a("strong"),xFr=o("bert"),$Fr=o(" \u2014 "),zH=a("a"),kFr=o("TFBertForSequenceClassification"),SFr=o(" (BERT model)"),RFr=l(),kM=a("li"),W4e=a("strong"),PFr=o("camembert"),BFr=o(" \u2014 "),WH=a("a"),IFr=o("TFCamembertForSequenceClassification"),NFr=o(" (CamemBERT model)"),qFr=l(),SM=a("li"),Q4e=a("strong"),jFr=o("convbert"),DFr=o(" \u2014 "),QH=a("a"),GFr=o("TFConvBertForSequenceClassification"),OFr=o(" (ConvBERT model)"),VFr=l(),RM=a("li"),H4e=a("strong"),XFr=o("ctrl"),zFr=o(" \u2014 "),HH=a("a"),WFr=o("TFCTRLForSequenceClassification"),QFr=o(" (CTRL model)"),HFr=l(),PM=a("li"),U4e=a("strong"),UFr=o("deberta"),JFr=o(" \u2014 "),UH=a("a"),YFr=o("TFDebertaForSequenceClassification"),KFr=o(" (DeBERTa model)"),ZFr=l(),BM=a("li"),J4e=a("strong"),eTr=o("deberta-v2"),oTr=o(" \u2014 "),JH=a("a"),rTr=o("TFDebertaV2ForSequenceClassification"),tTr=o(" (DeBERTa-v2 model)"),aTr=l(),IM=a("li"),Y4e=a("strong"),nTr=o("distilbert"),sTr=o(" \u2014 "),YH=a("a"),lTr=o("TFDistilBertForSequenceClassification"),iTr=o(" (DistilBERT model)"),dTr=l(),NM=a("li"),K4e=a("strong"),cTr=o("electra"),fTr=o(" \u2014 "),KH=a("a"),mTr=o("TFElectraForSequenceClassification"),gTr=o(" (ELECTRA model)"),hTr=l(),qM=a("li"),Z4e=a("strong"),pTr=o("flaubert"),_Tr=o(" \u2014 "),ZH=a("a"),uTr=o("TFFlaubertForSequenceClassification"),bTr=o(" (FlauBERT model)"),vTr=l(),jM=a("li"),eve=a("strong"),FTr=o("funnel"),TTr=o(" \u2014 "),eU=a("a"),MTr=o("TFFunnelForSequenceClassification"),ETr=o(" (Funnel Transformer model)"),CTr=l(),DM=a("li"),ove=a("strong"),wTr=o("gpt2"),ATr=o(" \u2014 "),oU=a("a"),yTr=o("TFGPT2ForSequenceClassification"),LTr=o(" (OpenAI GPT-2 model)"),xTr=l(),GM=a("li"),rve=a("strong"),$Tr=o("gptj"),kTr=o(" \u2014 "),rU=a("a"),STr=o("TFGPTJForSequenceClassification"),RTr=o(" (GPT-J model)"),PTr=l(),OM=a("li"),tve=a("strong"),BTr=o("layoutlm"),ITr=o(" \u2014 "),tU=a("a"),NTr=o("TFLayoutLMForSequenceClassification"),qTr=o(" (LayoutLM model)"),jTr=l(),VM=a("li"),ave=a("strong"),DTr=o("longformer"),GTr=o(" \u2014 "),aU=a("a"),OTr=o("TFLongformerForSequenceClassification"),VTr=o(" (Longformer model)"),XTr=l(),XM=a("li"),nve=a("strong"),zTr=o("mobilebert"),WTr=o(" \u2014 "),nU=a("a"),QTr=o("TFMobileBertForSequenceClassification"),HTr=o(" (MobileBERT model)"),UTr=l(),zM=a("li"),sve=a("strong"),JTr=o("mpnet"),YTr=o(" \u2014 "),sU=a("a"),KTr=o("TFMPNetForSequenceClassification"),ZTr=o(" (MPNet model)"),e7r=l(),WM=a("li"),lve=a("strong"),o7r=o("openai-gpt"),r7r=o(" \u2014 "),lU=a("a"),t7r=o("TFOpenAIGPTForSequenceClassification"),a7r=o(" (OpenAI GPT model)"),n7r=l(),QM=a("li"),ive=a("strong"),s7r=o("rembert"),l7r=o(" \u2014 "),iU=a("a"),i7r=o("TFRemBertForSequenceClassification"),d7r=o(" (RemBERT model)"),c7r=l(),HM=a("li"),dve=a("strong"),f7r=o("roberta"),m7r=o(" \u2014 "),dU=a("a"),g7r=o("TFRobertaForSequenceClassification"),h7r=o(" (RoBERTa model)"),p7r=l(),UM=a("li"),cve=a("strong"),_7r=o("roformer"),u7r=o(" \u2014 "),cU=a("a"),b7r=o("TFRoFormerForSequenceClassification"),v7r=o(" (RoFormer model)"),F7r=l(),JM=a("li"),fve=a("strong"),T7r=o("tapas"),M7r=o(" \u2014 "),fU=a("a"),E7r=o("TFTapasForSequenceClassification"),C7r=o(" (TAPAS model)"),w7r=l(),YM=a("li"),mve=a("strong"),A7r=o("transfo-xl"),y7r=o(" \u2014 "),mU=a("a"),L7r=o("TFTransfoXLForSequenceClassification"),x7r=o(" (Transformer-XL model)"),$7r=l(),KM=a("li"),gve=a("strong"),k7r=o("xlm"),S7r=o(" \u2014 "),gU=a("a"),R7r=o("TFXLMForSequenceClassification"),P7r=o(" (XLM model)"),B7r=l(),ZM=a("li"),hve=a("strong"),I7r=o("xlm-roberta"),N7r=o(" \u2014 "),hU=a("a"),q7r=o("TFXLMRobertaForSequenceClassification"),j7r=o(" (XLM-RoBERTa model)"),D7r=l(),eE=a("li"),pve=a("strong"),G7r=o("xlnet"),O7r=o(" \u2014 "),pU=a("a"),V7r=o("TFXLNetForSequenceClassification"),X7r=o(" (XLNet model)"),z7r=l(),F(oE.$$.fragment),Pje=l(),dc=a("h2"),rE=a("a"),_ve=a("span"),F(Q8.$$.fragment),W7r=l(),uve=a("span"),Q7r=o("TFAutoModelForMultipleChoice"),Bje=l(),ar=a("div"),F(H8.$$.fragment),H7r=l(),cc=a("p"),U7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),_U=a("a"),J7r=o("from_pretrained()"),Y7r=o(" class method or the "),uU=a("a"),K7r=o("from_config()"),Z7r=o(` class
method.`),eMr=l(),U8=a("p"),oMr=o("This class cannot be instantiated directly using "),bve=a("code"),rMr=o("__init__()"),tMr=o(" (throws an error)."),aMr=l(),Pt=a("div"),F(J8.$$.fragment),nMr=l(),vve=a("p"),sMr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),lMr=l(),fc=a("p"),iMr=o(`Note:
Loading a model from its configuration file does `),Fve=a("strong"),dMr=o("not"),cMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bU=a("a"),fMr=o("from_pretrained()"),mMr=o(" to load the model weights."),gMr=l(),F(tE.$$.fragment),hMr=l(),Sr=a("div"),F(Y8.$$.fragment),pMr=l(),Tve=a("p"),_Mr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),uMr=l(),sn=a("p"),bMr=o("The model class to instantiate is selected based on the "),Mve=a("code"),vMr=o("model_type"),FMr=o(` property of the config object (either
passed as an argument or loaded from `),Eve=a("code"),TMr=o("pretrained_model_name_or_path"),MMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cve=a("code"),EMr=o("pretrained_model_name_or_path"),CMr=o(":"),wMr=l(),pe=a("ul"),aE=a("li"),wve=a("strong"),AMr=o("albert"),yMr=o(" \u2014 "),vU=a("a"),LMr=o("TFAlbertForMultipleChoice"),xMr=o(" (ALBERT model)"),$Mr=l(),nE=a("li"),Ave=a("strong"),kMr=o("bert"),SMr=o(" \u2014 "),FU=a("a"),RMr=o("TFBertForMultipleChoice"),PMr=o(" (BERT model)"),BMr=l(),sE=a("li"),yve=a("strong"),IMr=o("camembert"),NMr=o(" \u2014 "),TU=a("a"),qMr=o("TFCamembertForMultipleChoice"),jMr=o(" (CamemBERT model)"),DMr=l(),lE=a("li"),Lve=a("strong"),GMr=o("convbert"),OMr=o(" \u2014 "),MU=a("a"),VMr=o("TFConvBertForMultipleChoice"),XMr=o(" (ConvBERT model)"),zMr=l(),iE=a("li"),xve=a("strong"),WMr=o("distilbert"),QMr=o(" \u2014 "),EU=a("a"),HMr=o("TFDistilBertForMultipleChoice"),UMr=o(" (DistilBERT model)"),JMr=l(),dE=a("li"),$ve=a("strong"),YMr=o("electra"),KMr=o(" \u2014 "),CU=a("a"),ZMr=o("TFElectraForMultipleChoice"),eEr=o(" (ELECTRA model)"),oEr=l(),cE=a("li"),kve=a("strong"),rEr=o("flaubert"),tEr=o(" \u2014 "),wU=a("a"),aEr=o("TFFlaubertForMultipleChoice"),nEr=o(" (FlauBERT model)"),sEr=l(),fE=a("li"),Sve=a("strong"),lEr=o("funnel"),iEr=o(" \u2014 "),AU=a("a"),dEr=o("TFFunnelForMultipleChoice"),cEr=o(" (Funnel Transformer model)"),fEr=l(),mE=a("li"),Rve=a("strong"),mEr=o("longformer"),gEr=o(" \u2014 "),yU=a("a"),hEr=o("TFLongformerForMultipleChoice"),pEr=o(" (Longformer model)"),_Er=l(),gE=a("li"),Pve=a("strong"),uEr=o("mobilebert"),bEr=o(" \u2014 "),LU=a("a"),vEr=o("TFMobileBertForMultipleChoice"),FEr=o(" (MobileBERT model)"),TEr=l(),hE=a("li"),Bve=a("strong"),MEr=o("mpnet"),EEr=o(" \u2014 "),xU=a("a"),CEr=o("TFMPNetForMultipleChoice"),wEr=o(" (MPNet model)"),AEr=l(),pE=a("li"),Ive=a("strong"),yEr=o("rembert"),LEr=o(" \u2014 "),$U=a("a"),xEr=o("TFRemBertForMultipleChoice"),$Er=o(" (RemBERT model)"),kEr=l(),_E=a("li"),Nve=a("strong"),SEr=o("roberta"),REr=o(" \u2014 "),kU=a("a"),PEr=o("TFRobertaForMultipleChoice"),BEr=o(" (RoBERTa model)"),IEr=l(),uE=a("li"),qve=a("strong"),NEr=o("roformer"),qEr=o(" \u2014 "),SU=a("a"),jEr=o("TFRoFormerForMultipleChoice"),DEr=o(" (RoFormer model)"),GEr=l(),bE=a("li"),jve=a("strong"),OEr=o("xlm"),VEr=o(" \u2014 "),RU=a("a"),XEr=o("TFXLMForMultipleChoice"),zEr=o(" (XLM model)"),WEr=l(),vE=a("li"),Dve=a("strong"),QEr=o("xlm-roberta"),HEr=o(" \u2014 "),PU=a("a"),UEr=o("TFXLMRobertaForMultipleChoice"),JEr=o(" (XLM-RoBERTa model)"),YEr=l(),FE=a("li"),Gve=a("strong"),KEr=o("xlnet"),ZEr=o(" \u2014 "),BU=a("a"),eCr=o("TFXLNetForMultipleChoice"),oCr=o(" (XLNet model)"),rCr=l(),F(TE.$$.fragment),Ije=l(),mc=a("h2"),ME=a("a"),Ove=a("span"),F(K8.$$.fragment),tCr=l(),Vve=a("span"),aCr=o("TFAutoModelForNextSentencePrediction"),Nje=l(),nr=a("div"),F(Z8.$$.fragment),nCr=l(),gc=a("p"),sCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),IU=a("a"),lCr=o("from_pretrained()"),iCr=o(" class method or the "),NU=a("a"),dCr=o("from_config()"),cCr=o(` class
method.`),fCr=l(),e9=a("p"),mCr=o("This class cannot be instantiated directly using "),Xve=a("code"),gCr=o("__init__()"),hCr=o(" (throws an error)."),pCr=l(),Bt=a("div"),F(o9.$$.fragment),_Cr=l(),zve=a("p"),uCr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),bCr=l(),hc=a("p"),vCr=o(`Note:
Loading a model from its configuration file does `),Wve=a("strong"),FCr=o("not"),TCr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qU=a("a"),MCr=o("from_pretrained()"),ECr=o(" to load the model weights."),CCr=l(),F(EE.$$.fragment),wCr=l(),Rr=a("div"),F(r9.$$.fragment),ACr=l(),Qve=a("p"),yCr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),LCr=l(),ln=a("p"),xCr=o("The model class to instantiate is selected based on the "),Hve=a("code"),$Cr=o("model_type"),kCr=o(` property of the config object (either
passed as an argument or loaded from `),Uve=a("code"),SCr=o("pretrained_model_name_or_path"),RCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jve=a("code"),PCr=o("pretrained_model_name_or_path"),BCr=o(":"),ICr=l(),t9=a("ul"),CE=a("li"),Yve=a("strong"),NCr=o("bert"),qCr=o(" \u2014 "),jU=a("a"),jCr=o("TFBertForNextSentencePrediction"),DCr=o(" (BERT model)"),GCr=l(),wE=a("li"),Kve=a("strong"),OCr=o("mobilebert"),VCr=o(" \u2014 "),DU=a("a"),XCr=o("TFMobileBertForNextSentencePrediction"),zCr=o(" (MobileBERT model)"),WCr=l(),F(AE.$$.fragment),qje=l(),pc=a("h2"),yE=a("a"),Zve=a("span"),F(a9.$$.fragment),QCr=l(),eFe=a("span"),HCr=o("TFAutoModelForTableQuestionAnswering"),jje=l(),sr=a("div"),F(n9.$$.fragment),UCr=l(),_c=a("p"),JCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),GU=a("a"),YCr=o("from_pretrained()"),KCr=o(" class method or the "),OU=a("a"),ZCr=o("from_config()"),e5r=o(` class
method.`),o5r=l(),s9=a("p"),r5r=o("This class cannot be instantiated directly using "),oFe=a("code"),t5r=o("__init__()"),a5r=o(" (throws an error)."),n5r=l(),It=a("div"),F(l9.$$.fragment),s5r=l(),rFe=a("p"),l5r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),i5r=l(),uc=a("p"),d5r=o(`Note:
Loading a model from its configuration file does `),tFe=a("strong"),c5r=o("not"),f5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VU=a("a"),m5r=o("from_pretrained()"),g5r=o(" to load the model weights."),h5r=l(),F(LE.$$.fragment),p5r=l(),Pr=a("div"),F(i9.$$.fragment),_5r=l(),aFe=a("p"),u5r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),b5r=l(),dn=a("p"),v5r=o("The model class to instantiate is selected based on the "),nFe=a("code"),F5r=o("model_type"),T5r=o(` property of the config object (either
passed as an argument or loaded from `),sFe=a("code"),M5r=o("pretrained_model_name_or_path"),E5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lFe=a("code"),C5r=o("pretrained_model_name_or_path"),w5r=o(":"),A5r=l(),iFe=a("ul"),xE=a("li"),dFe=a("strong"),y5r=o("tapas"),L5r=o(" \u2014 "),XU=a("a"),x5r=o("TFTapasForQuestionAnswering"),$5r=o(" (TAPAS model)"),k5r=l(),F($E.$$.fragment),Dje=l(),bc=a("h2"),kE=a("a"),cFe=a("span"),F(d9.$$.fragment),S5r=l(),fFe=a("span"),R5r=o("TFAutoModelForTokenClassification"),Gje=l(),lr=a("div"),F(c9.$$.fragment),P5r=l(),vc=a("p"),B5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),zU=a("a"),I5r=o("from_pretrained()"),N5r=o(" class method or the "),WU=a("a"),q5r=o("from_config()"),j5r=o(` class
method.`),D5r=l(),f9=a("p"),G5r=o("This class cannot be instantiated directly using "),mFe=a("code"),O5r=o("__init__()"),V5r=o(" (throws an error)."),X5r=l(),Nt=a("div"),F(m9.$$.fragment),z5r=l(),gFe=a("p"),W5r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Q5r=l(),Fc=a("p"),H5r=o(`Note:
Loading a model from its configuration file does `),hFe=a("strong"),U5r=o("not"),J5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QU=a("a"),Y5r=o("from_pretrained()"),K5r=o(" to load the model weights."),Z5r=l(),F(SE.$$.fragment),e3r=l(),Br=a("div"),F(g9.$$.fragment),o3r=l(),pFe=a("p"),r3r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),t3r=l(),cn=a("p"),a3r=o("The model class to instantiate is selected based on the "),_Fe=a("code"),n3r=o("model_type"),s3r=o(` property of the config object (either
passed as an argument or loaded from `),uFe=a("code"),l3r=o("pretrained_model_name_or_path"),i3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bFe=a("code"),d3r=o("pretrained_model_name_or_path"),c3r=o(":"),f3r=l(),de=a("ul"),RE=a("li"),vFe=a("strong"),m3r=o("albert"),g3r=o(" \u2014 "),HU=a("a"),h3r=o("TFAlbertForTokenClassification"),p3r=o(" (ALBERT model)"),_3r=l(),PE=a("li"),FFe=a("strong"),u3r=o("bert"),b3r=o(" \u2014 "),UU=a("a"),v3r=o("TFBertForTokenClassification"),F3r=o(" (BERT model)"),T3r=l(),BE=a("li"),TFe=a("strong"),M3r=o("camembert"),E3r=o(" \u2014 "),JU=a("a"),C3r=o("TFCamembertForTokenClassification"),w3r=o(" (CamemBERT model)"),A3r=l(),IE=a("li"),MFe=a("strong"),y3r=o("convbert"),L3r=o(" \u2014 "),YU=a("a"),x3r=o("TFConvBertForTokenClassification"),$3r=o(" (ConvBERT model)"),k3r=l(),NE=a("li"),EFe=a("strong"),S3r=o("deberta"),R3r=o(" \u2014 "),KU=a("a"),P3r=o("TFDebertaForTokenClassification"),B3r=o(" (DeBERTa model)"),I3r=l(),qE=a("li"),CFe=a("strong"),N3r=o("deberta-v2"),q3r=o(" \u2014 "),ZU=a("a"),j3r=o("TFDebertaV2ForTokenClassification"),D3r=o(" (DeBERTa-v2 model)"),G3r=l(),jE=a("li"),wFe=a("strong"),O3r=o("distilbert"),V3r=o(" \u2014 "),eJ=a("a"),X3r=o("TFDistilBertForTokenClassification"),z3r=o(" (DistilBERT model)"),W3r=l(),DE=a("li"),AFe=a("strong"),Q3r=o("electra"),H3r=o(" \u2014 "),oJ=a("a"),U3r=o("TFElectraForTokenClassification"),J3r=o(" (ELECTRA model)"),Y3r=l(),GE=a("li"),yFe=a("strong"),K3r=o("flaubert"),Z3r=o(" \u2014 "),rJ=a("a"),ewr=o("TFFlaubertForTokenClassification"),owr=o(" (FlauBERT model)"),rwr=l(),OE=a("li"),LFe=a("strong"),twr=o("funnel"),awr=o(" \u2014 "),tJ=a("a"),nwr=o("TFFunnelForTokenClassification"),swr=o(" (Funnel Transformer model)"),lwr=l(),VE=a("li"),xFe=a("strong"),iwr=o("layoutlm"),dwr=o(" \u2014 "),aJ=a("a"),cwr=o("TFLayoutLMForTokenClassification"),fwr=o(" (LayoutLM model)"),mwr=l(),XE=a("li"),$Fe=a("strong"),gwr=o("longformer"),hwr=o(" \u2014 "),nJ=a("a"),pwr=o("TFLongformerForTokenClassification"),_wr=o(" (Longformer model)"),uwr=l(),zE=a("li"),kFe=a("strong"),bwr=o("mobilebert"),vwr=o(" \u2014 "),sJ=a("a"),Fwr=o("TFMobileBertForTokenClassification"),Twr=o(" (MobileBERT model)"),Mwr=l(),WE=a("li"),SFe=a("strong"),Ewr=o("mpnet"),Cwr=o(" \u2014 "),lJ=a("a"),wwr=o("TFMPNetForTokenClassification"),Awr=o(" (MPNet model)"),ywr=l(),QE=a("li"),RFe=a("strong"),Lwr=o("rembert"),xwr=o(" \u2014 "),iJ=a("a"),$wr=o("TFRemBertForTokenClassification"),kwr=o(" (RemBERT model)"),Swr=l(),HE=a("li"),PFe=a("strong"),Rwr=o("roberta"),Pwr=o(" \u2014 "),dJ=a("a"),Bwr=o("TFRobertaForTokenClassification"),Iwr=o(" (RoBERTa model)"),Nwr=l(),UE=a("li"),BFe=a("strong"),qwr=o("roformer"),jwr=o(" \u2014 "),cJ=a("a"),Dwr=o("TFRoFormerForTokenClassification"),Gwr=o(" (RoFormer model)"),Owr=l(),JE=a("li"),IFe=a("strong"),Vwr=o("xlm"),Xwr=o(" \u2014 "),fJ=a("a"),zwr=o("TFXLMForTokenClassification"),Wwr=o(" (XLM model)"),Qwr=l(),YE=a("li"),NFe=a("strong"),Hwr=o("xlm-roberta"),Uwr=o(" \u2014 "),mJ=a("a"),Jwr=o("TFXLMRobertaForTokenClassification"),Ywr=o(" (XLM-RoBERTa model)"),Kwr=l(),KE=a("li"),qFe=a("strong"),Zwr=o("xlnet"),e0r=o(" \u2014 "),gJ=a("a"),o0r=o("TFXLNetForTokenClassification"),r0r=o(" (XLNet model)"),t0r=l(),F(ZE.$$.fragment),Oje=l(),Tc=a("h2"),eC=a("a"),jFe=a("span"),F(h9.$$.fragment),a0r=l(),DFe=a("span"),n0r=o("TFAutoModelForQuestionAnswering"),Vje=l(),ir=a("div"),F(p9.$$.fragment),s0r=l(),Mc=a("p"),l0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),hJ=a("a"),i0r=o("from_pretrained()"),d0r=o(" class method or the "),pJ=a("a"),c0r=o("from_config()"),f0r=o(` class
method.`),m0r=l(),_9=a("p"),g0r=o("This class cannot be instantiated directly using "),GFe=a("code"),h0r=o("__init__()"),p0r=o(" (throws an error)."),_0r=l(),qt=a("div"),F(u9.$$.fragment),u0r=l(),OFe=a("p"),b0r=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),v0r=l(),Ec=a("p"),F0r=o(`Note:
Loading a model from its configuration file does `),VFe=a("strong"),T0r=o("not"),M0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_J=a("a"),E0r=o("from_pretrained()"),C0r=o(" to load the model weights."),w0r=l(),F(oC.$$.fragment),A0r=l(),Ir=a("div"),F(b9.$$.fragment),y0r=l(),XFe=a("p"),L0r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),x0r=l(),fn=a("p"),$0r=o("The model class to instantiate is selected based on the "),zFe=a("code"),k0r=o("model_type"),S0r=o(` property of the config object (either
passed as an argument or loaded from `),WFe=a("code"),R0r=o("pretrained_model_name_or_path"),P0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QFe=a("code"),B0r=o("pretrained_model_name_or_path"),I0r=o(":"),N0r=l(),ce=a("ul"),rC=a("li"),HFe=a("strong"),q0r=o("albert"),j0r=o(" \u2014 "),uJ=a("a"),D0r=o("TFAlbertForQuestionAnswering"),G0r=o(" (ALBERT model)"),O0r=l(),tC=a("li"),UFe=a("strong"),V0r=o("bert"),X0r=o(" \u2014 "),bJ=a("a"),z0r=o("TFBertForQuestionAnswering"),W0r=o(" (BERT model)"),Q0r=l(),aC=a("li"),JFe=a("strong"),H0r=o("camembert"),U0r=o(" \u2014 "),vJ=a("a"),J0r=o("TFCamembertForQuestionAnswering"),Y0r=o(" (CamemBERT model)"),K0r=l(),nC=a("li"),YFe=a("strong"),Z0r=o("convbert"),eAr=o(" \u2014 "),FJ=a("a"),oAr=o("TFConvBertForQuestionAnswering"),rAr=o(" (ConvBERT model)"),tAr=l(),sC=a("li"),KFe=a("strong"),aAr=o("deberta"),nAr=o(" \u2014 "),TJ=a("a"),sAr=o("TFDebertaForQuestionAnswering"),lAr=o(" (DeBERTa model)"),iAr=l(),lC=a("li"),ZFe=a("strong"),dAr=o("deberta-v2"),cAr=o(" \u2014 "),MJ=a("a"),fAr=o("TFDebertaV2ForQuestionAnswering"),mAr=o(" (DeBERTa-v2 model)"),gAr=l(),iC=a("li"),eTe=a("strong"),hAr=o("distilbert"),pAr=o(" \u2014 "),EJ=a("a"),_Ar=o("TFDistilBertForQuestionAnswering"),uAr=o(" (DistilBERT model)"),bAr=l(),dC=a("li"),oTe=a("strong"),vAr=o("electra"),FAr=o(" \u2014 "),CJ=a("a"),TAr=o("TFElectraForQuestionAnswering"),MAr=o(" (ELECTRA model)"),EAr=l(),cC=a("li"),rTe=a("strong"),CAr=o("flaubert"),wAr=o(" \u2014 "),wJ=a("a"),AAr=o("TFFlaubertForQuestionAnsweringSimple"),yAr=o(" (FlauBERT model)"),LAr=l(),fC=a("li"),tTe=a("strong"),xAr=o("funnel"),$Ar=o(" \u2014 "),AJ=a("a"),kAr=o("TFFunnelForQuestionAnswering"),SAr=o(" (Funnel Transformer model)"),RAr=l(),mC=a("li"),aTe=a("strong"),PAr=o("gptj"),BAr=o(" \u2014 "),yJ=a("a"),IAr=o("TFGPTJForQuestionAnswering"),NAr=o(" (GPT-J model)"),qAr=l(),gC=a("li"),nTe=a("strong"),jAr=o("longformer"),DAr=o(" \u2014 "),LJ=a("a"),GAr=o("TFLongformerForQuestionAnswering"),OAr=o(" (Longformer model)"),VAr=l(),hC=a("li"),sTe=a("strong"),XAr=o("mobilebert"),zAr=o(" \u2014 "),xJ=a("a"),WAr=o("TFMobileBertForQuestionAnswering"),QAr=o(" (MobileBERT model)"),HAr=l(),pC=a("li"),lTe=a("strong"),UAr=o("mpnet"),JAr=o(" \u2014 "),$J=a("a"),YAr=o("TFMPNetForQuestionAnswering"),KAr=o(" (MPNet model)"),ZAr=l(),_C=a("li"),iTe=a("strong"),eyr=o("rembert"),oyr=o(" \u2014 "),kJ=a("a"),ryr=o("TFRemBertForQuestionAnswering"),tyr=o(" (RemBERT model)"),ayr=l(),uC=a("li"),dTe=a("strong"),nyr=o("roberta"),syr=o(" \u2014 "),SJ=a("a"),lyr=o("TFRobertaForQuestionAnswering"),iyr=o(" (RoBERTa model)"),dyr=l(),bC=a("li"),cTe=a("strong"),cyr=o("roformer"),fyr=o(" \u2014 "),RJ=a("a"),myr=o("TFRoFormerForQuestionAnswering"),gyr=o(" (RoFormer model)"),hyr=l(),vC=a("li"),fTe=a("strong"),pyr=o("xlm"),_yr=o(" \u2014 "),PJ=a("a"),uyr=o("TFXLMForQuestionAnsweringSimple"),byr=o(" (XLM model)"),vyr=l(),FC=a("li"),mTe=a("strong"),Fyr=o("xlm-roberta"),Tyr=o(" \u2014 "),BJ=a("a"),Myr=o("TFXLMRobertaForQuestionAnswering"),Eyr=o(" (XLM-RoBERTa model)"),Cyr=l(),TC=a("li"),gTe=a("strong"),wyr=o("xlnet"),Ayr=o(" \u2014 "),IJ=a("a"),yyr=o("TFXLNetForQuestionAnsweringSimple"),Lyr=o(" (XLNet model)"),xyr=l(),F(MC.$$.fragment),Xje=l(),Cc=a("h2"),EC=a("a"),hTe=a("span"),F(v9.$$.fragment),$yr=l(),pTe=a("span"),kyr=o("TFAutoModelForVision2Seq"),zje=l(),dr=a("div"),F(F9.$$.fragment),Syr=l(),wc=a("p"),Ryr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),NJ=a("a"),Pyr=o("from_pretrained()"),Byr=o(" class method or the "),qJ=a("a"),Iyr=o("from_config()"),Nyr=o(` class
method.`),qyr=l(),T9=a("p"),jyr=o("This class cannot be instantiated directly using "),_Te=a("code"),Dyr=o("__init__()"),Gyr=o(" (throws an error)."),Oyr=l(),jt=a("div"),F(M9.$$.fragment),Vyr=l(),uTe=a("p"),Xyr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),zyr=l(),Ac=a("p"),Wyr=o(`Note:
Loading a model from its configuration file does `),bTe=a("strong"),Qyr=o("not"),Hyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jJ=a("a"),Uyr=o("from_pretrained()"),Jyr=o(" to load the model weights."),Yyr=l(),F(CC.$$.fragment),Kyr=l(),Nr=a("div"),F(E9.$$.fragment),Zyr=l(),vTe=a("p"),eLr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),oLr=l(),mn=a("p"),rLr=o("The model class to instantiate is selected based on the "),FTe=a("code"),tLr=o("model_type"),aLr=o(` property of the config object (either
passed as an argument or loaded from `),TTe=a("code"),nLr=o("pretrained_model_name_or_path"),sLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MTe=a("code"),lLr=o("pretrained_model_name_or_path"),iLr=o(":"),dLr=l(),ETe=a("ul"),wC=a("li"),CTe=a("strong"),cLr=o("vision-encoder-decoder"),fLr=o(" \u2014 "),DJ=a("a"),mLr=o("TFVisionEncoderDecoderModel"),gLr=o(" (Vision Encoder decoder model)"),hLr=l(),F(AC.$$.fragment),Wje=l(),yc=a("h2"),yC=a("a"),wTe=a("span"),F(C9.$$.fragment),pLr=l(),ATe=a("span"),_Lr=o("TFAutoModelForSpeechSeq2Seq"),Qje=l(),cr=a("div"),F(w9.$$.fragment),uLr=l(),Lc=a("p"),bLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),GJ=a("a"),vLr=o("from_pretrained()"),FLr=o(" class method or the "),OJ=a("a"),TLr=o("from_config()"),MLr=o(` class
method.`),ELr=l(),A9=a("p"),CLr=o("This class cannot be instantiated directly using "),yTe=a("code"),wLr=o("__init__()"),ALr=o(" (throws an error)."),yLr=l(),Dt=a("div"),F(y9.$$.fragment),LLr=l(),LTe=a("p"),xLr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),$Lr=l(),xc=a("p"),kLr=o(`Note:
Loading a model from its configuration file does `),xTe=a("strong"),SLr=o("not"),RLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VJ=a("a"),PLr=o("from_pretrained()"),BLr=o(" to load the model weights."),ILr=l(),F(LC.$$.fragment),NLr=l(),qr=a("div"),F(L9.$$.fragment),qLr=l(),$Te=a("p"),jLr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),DLr=l(),gn=a("p"),GLr=o("The model class to instantiate is selected based on the "),kTe=a("code"),OLr=o("model_type"),VLr=o(` property of the config object (either
passed as an argument or loaded from `),STe=a("code"),XLr=o("pretrained_model_name_or_path"),zLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RTe=a("code"),WLr=o("pretrained_model_name_or_path"),QLr=o(":"),HLr=l(),PTe=a("ul"),xC=a("li"),BTe=a("strong"),ULr=o("speech_to_text"),JLr=o(" \u2014 "),XJ=a("a"),YLr=o("TFSpeech2TextForConditionalGeneration"),KLr=o(" (Speech2Text model)"),ZLr=l(),F($C.$$.fragment),Hje=l(),$c=a("h2"),kC=a("a"),ITe=a("span"),F(x9.$$.fragment),e8r=l(),NTe=a("span"),o8r=o("FlaxAutoModel"),Uje=l(),fr=a("div"),F($9.$$.fragment),r8r=l(),kc=a("p"),t8r=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),zJ=a("a"),a8r=o("from_pretrained()"),n8r=o(" class method or the "),WJ=a("a"),s8r=o("from_config()"),l8r=o(` class
method.`),i8r=l(),k9=a("p"),d8r=o("This class cannot be instantiated directly using "),qTe=a("code"),c8r=o("__init__()"),f8r=o(" (throws an error)."),m8r=l(),Gt=a("div"),F(S9.$$.fragment),g8r=l(),jTe=a("p"),h8r=o("Instantiates one of the base model classes of the library from a configuration."),p8r=l(),Sc=a("p"),_8r=o(`Note:
Loading a model from its configuration file does `),DTe=a("strong"),u8r=o("not"),b8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QJ=a("a"),v8r=o("from_pretrained()"),F8r=o(" to load the model weights."),T8r=l(),F(SC.$$.fragment),M8r=l(),jr=a("div"),F(R9.$$.fragment),E8r=l(),GTe=a("p"),C8r=o("Instantiate one of the base model classes of the library from a pretrained model."),w8r=l(),hn=a("p"),A8r=o("The model class to instantiate is selected based on the "),OTe=a("code"),y8r=o("model_type"),L8r=o(` property of the config object (either
passed as an argument or loaded from `),VTe=a("code"),x8r=o("pretrained_model_name_or_path"),$8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),XTe=a("code"),k8r=o("pretrained_model_name_or_path"),S8r=o(":"),R8r=l(),te=a("ul"),RC=a("li"),zTe=a("strong"),P8r=o("albert"),B8r=o(" \u2014 "),HJ=a("a"),I8r=o("FlaxAlbertModel"),N8r=o(" (ALBERT model)"),q8r=l(),PC=a("li"),WTe=a("strong"),j8r=o("bart"),D8r=o(" \u2014 "),UJ=a("a"),G8r=o("FlaxBartModel"),O8r=o(" (BART model)"),V8r=l(),BC=a("li"),QTe=a("strong"),X8r=o("beit"),z8r=o(" \u2014 "),JJ=a("a"),W8r=o("FlaxBeitModel"),Q8r=o(" (BEiT model)"),H8r=l(),IC=a("li"),HTe=a("strong"),U8r=o("bert"),J8r=o(" \u2014 "),YJ=a("a"),Y8r=o("FlaxBertModel"),K8r=o(" (BERT model)"),Z8r=l(),NC=a("li"),UTe=a("strong"),e9r=o("big_bird"),o9r=o(" \u2014 "),KJ=a("a"),r9r=o("FlaxBigBirdModel"),t9r=o(" (BigBird model)"),a9r=l(),qC=a("li"),JTe=a("strong"),n9r=o("blenderbot"),s9r=o(" \u2014 "),ZJ=a("a"),l9r=o("FlaxBlenderbotModel"),i9r=o(" (Blenderbot model)"),d9r=l(),jC=a("li"),YTe=a("strong"),c9r=o("blenderbot-small"),f9r=o(" \u2014 "),eY=a("a"),m9r=o("FlaxBlenderbotSmallModel"),g9r=o(" (BlenderbotSmall model)"),h9r=l(),DC=a("li"),KTe=a("strong"),p9r=o("clip"),_9r=o(" \u2014 "),oY=a("a"),u9r=o("FlaxCLIPModel"),b9r=o(" (CLIP model)"),v9r=l(),GC=a("li"),ZTe=a("strong"),F9r=o("distilbert"),T9r=o(" \u2014 "),rY=a("a"),M9r=o("FlaxDistilBertModel"),E9r=o(" (DistilBERT model)"),C9r=l(),OC=a("li"),e7e=a("strong"),w9r=o("electra"),A9r=o(" \u2014 "),tY=a("a"),y9r=o("FlaxElectraModel"),L9r=o(" (ELECTRA model)"),x9r=l(),VC=a("li"),o7e=a("strong"),$9r=o("gpt2"),k9r=o(" \u2014 "),aY=a("a"),S9r=o("FlaxGPT2Model"),R9r=o(" (OpenAI GPT-2 model)"),P9r=l(),XC=a("li"),r7e=a("strong"),B9r=o("gpt_neo"),I9r=o(" \u2014 "),nY=a("a"),N9r=o("FlaxGPTNeoModel"),q9r=o(" (GPT Neo model)"),j9r=l(),zC=a("li"),t7e=a("strong"),D9r=o("gptj"),G9r=o(" \u2014 "),sY=a("a"),O9r=o("FlaxGPTJModel"),V9r=o(" (GPT-J model)"),X9r=l(),WC=a("li"),a7e=a("strong"),z9r=o("marian"),W9r=o(" \u2014 "),lY=a("a"),Q9r=o("FlaxMarianModel"),H9r=o(" (Marian model)"),U9r=l(),QC=a("li"),n7e=a("strong"),J9r=o("mbart"),Y9r=o(" \u2014 "),iY=a("a"),K9r=o("FlaxMBartModel"),Z9r=o(" (mBART model)"),exr=l(),HC=a("li"),s7e=a("strong"),oxr=o("mt5"),rxr=o(" \u2014 "),dY=a("a"),txr=o("FlaxMT5Model"),axr=o(" (mT5 model)"),nxr=l(),UC=a("li"),l7e=a("strong"),sxr=o("pegasus"),lxr=o(" \u2014 "),cY=a("a"),ixr=o("FlaxPegasusModel"),dxr=o(" (Pegasus model)"),cxr=l(),JC=a("li"),i7e=a("strong"),fxr=o("roberta"),mxr=o(" \u2014 "),fY=a("a"),gxr=o("FlaxRobertaModel"),hxr=o(" (RoBERTa model)"),pxr=l(),YC=a("li"),d7e=a("strong"),_xr=o("roformer"),uxr=o(" \u2014 "),mY=a("a"),bxr=o("FlaxRoFormerModel"),vxr=o(" (RoFormer model)"),Fxr=l(),KC=a("li"),c7e=a("strong"),Txr=o("t5"),Mxr=o(" \u2014 "),gY=a("a"),Exr=o("FlaxT5Model"),Cxr=o(" (T5 model)"),wxr=l(),ZC=a("li"),f7e=a("strong"),Axr=o("vision-text-dual-encoder"),yxr=o(" \u2014 "),hY=a("a"),Lxr=o("FlaxVisionTextDualEncoderModel"),xxr=o(" (VisionTextDualEncoder model)"),$xr=l(),e5=a("li"),m7e=a("strong"),kxr=o("vit"),Sxr=o(" \u2014 "),pY=a("a"),Rxr=o("FlaxViTModel"),Pxr=o(" (ViT model)"),Bxr=l(),o5=a("li"),g7e=a("strong"),Ixr=o("wav2vec2"),Nxr=o(" \u2014 "),_Y=a("a"),qxr=o("FlaxWav2Vec2Model"),jxr=o(" (Wav2Vec2 model)"),Dxr=l(),r5=a("li"),h7e=a("strong"),Gxr=o("xglm"),Oxr=o(" \u2014 "),uY=a("a"),Vxr=o("FlaxXGLMModel"),Xxr=o(" (XGLM model)"),zxr=l(),t5=a("li"),p7e=a("strong"),Wxr=o("xlm-roberta"),Qxr=o(" \u2014 "),bY=a("a"),Hxr=o("FlaxXLMRobertaModel"),Uxr=o(" (XLM-RoBERTa model)"),Jxr=l(),F(a5.$$.fragment),Jje=l(),Rc=a("h2"),n5=a("a"),_7e=a("span"),F(P9.$$.fragment),Yxr=l(),u7e=a("span"),Kxr=o("FlaxAutoModelForCausalLM"),Yje=l(),mr=a("div"),F(B9.$$.fragment),Zxr=l(),Pc=a("p"),e$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),vY=a("a"),o$r=o("from_pretrained()"),r$r=o(" class method or the "),FY=a("a"),t$r=o("from_config()"),a$r=o(` class
method.`),n$r=l(),I9=a("p"),s$r=o("This class cannot be instantiated directly using "),b7e=a("code"),l$r=o("__init__()"),i$r=o(" (throws an error)."),d$r=l(),Ot=a("div"),F(N9.$$.fragment),c$r=l(),v7e=a("p"),f$r=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),m$r=l(),Bc=a("p"),g$r=o(`Note:
Loading a model from its configuration file does `),F7e=a("strong"),h$r=o("not"),p$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),TY=a("a"),_$r=o("from_pretrained()"),u$r=o(" to load the model weights."),b$r=l(),F(s5.$$.fragment),v$r=l(),Dr=a("div"),F(q9.$$.fragment),F$r=l(),T7e=a("p"),T$r=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),M$r=l(),pn=a("p"),E$r=o("The model class to instantiate is selected based on the "),M7e=a("code"),C$r=o("model_type"),w$r=o(` property of the config object (either
passed as an argument or loaded from `),E7e=a("code"),A$r=o("pretrained_model_name_or_path"),y$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C7e=a("code"),L$r=o("pretrained_model_name_or_path"),x$r=o(":"),$$r=l(),Re=a("ul"),l5=a("li"),w7e=a("strong"),k$r=o("bart"),S$r=o(" \u2014 "),MY=a("a"),R$r=o("FlaxBartForCausalLM"),P$r=o(" (BART model)"),B$r=l(),i5=a("li"),A7e=a("strong"),I$r=o("bert"),N$r=o(" \u2014 "),EY=a("a"),q$r=o("FlaxBertForCausalLM"),j$r=o(" (BERT model)"),D$r=l(),d5=a("li"),y7e=a("strong"),G$r=o("big_bird"),O$r=o(" \u2014 "),CY=a("a"),V$r=o("FlaxBigBirdForCausalLM"),X$r=o(" (BigBird model)"),z$r=l(),c5=a("li"),L7e=a("strong"),W$r=o("electra"),Q$r=o(" \u2014 "),wY=a("a"),H$r=o("FlaxElectraForCausalLM"),U$r=o(" (ELECTRA model)"),J$r=l(),f5=a("li"),x7e=a("strong"),Y$r=o("gpt2"),K$r=o(" \u2014 "),AY=a("a"),Z$r=o("FlaxGPT2LMHeadModel"),ekr=o(" (OpenAI GPT-2 model)"),okr=l(),m5=a("li"),$7e=a("strong"),rkr=o("gpt_neo"),tkr=o(" \u2014 "),yY=a("a"),akr=o("FlaxGPTNeoForCausalLM"),nkr=o(" (GPT Neo model)"),skr=l(),g5=a("li"),k7e=a("strong"),lkr=o("gptj"),ikr=o(" \u2014 "),LY=a("a"),dkr=o("FlaxGPTJForCausalLM"),ckr=o(" (GPT-J model)"),fkr=l(),h5=a("li"),S7e=a("strong"),mkr=o("roberta"),gkr=o(" \u2014 "),xY=a("a"),hkr=o("FlaxRobertaForCausalLM"),pkr=o(" (RoBERTa model)"),_kr=l(),p5=a("li"),R7e=a("strong"),ukr=o("xglm"),bkr=o(" \u2014 "),$Y=a("a"),vkr=o("FlaxXGLMForCausalLM"),Fkr=o(" (XGLM model)"),Tkr=l(),F(_5.$$.fragment),Kje=l(),Ic=a("h2"),u5=a("a"),P7e=a("span"),F(j9.$$.fragment),Mkr=l(),B7e=a("span"),Ekr=o("FlaxAutoModelForPreTraining"),Zje=l(),gr=a("div"),F(D9.$$.fragment),Ckr=l(),Nc=a("p"),wkr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),kY=a("a"),Akr=o("from_pretrained()"),ykr=o(" class method or the "),SY=a("a"),Lkr=o("from_config()"),xkr=o(` class
method.`),$kr=l(),G9=a("p"),kkr=o("This class cannot be instantiated directly using "),I7e=a("code"),Skr=o("__init__()"),Rkr=o(" (throws an error)."),Pkr=l(),Vt=a("div"),F(O9.$$.fragment),Bkr=l(),N7e=a("p"),Ikr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Nkr=l(),qc=a("p"),qkr=o(`Note:
Loading a model from its configuration file does `),q7e=a("strong"),jkr=o("not"),Dkr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RY=a("a"),Gkr=o("from_pretrained()"),Okr=o(" to load the model weights."),Vkr=l(),F(b5.$$.fragment),Xkr=l(),Gr=a("div"),F(V9.$$.fragment),zkr=l(),j7e=a("p"),Wkr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Qkr=l(),_n=a("p"),Hkr=o("The model class to instantiate is selected based on the "),D7e=a("code"),Ukr=o("model_type"),Jkr=o(` property of the config object (either
passed as an argument or loaded from `),G7e=a("code"),Ykr=o("pretrained_model_name_or_path"),Kkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O7e=a("code"),Zkr=o("pretrained_model_name_or_path"),eSr=o(":"),oSr=l(),Ee=a("ul"),v5=a("li"),V7e=a("strong"),rSr=o("albert"),tSr=o(" \u2014 "),PY=a("a"),aSr=o("FlaxAlbertForPreTraining"),nSr=o(" (ALBERT model)"),sSr=l(),F5=a("li"),X7e=a("strong"),lSr=o("bart"),iSr=o(" \u2014 "),BY=a("a"),dSr=o("FlaxBartForConditionalGeneration"),cSr=o(" (BART model)"),fSr=l(),T5=a("li"),z7e=a("strong"),mSr=o("bert"),gSr=o(" \u2014 "),IY=a("a"),hSr=o("FlaxBertForPreTraining"),pSr=o(" (BERT model)"),_Sr=l(),M5=a("li"),W7e=a("strong"),uSr=o("big_bird"),bSr=o(" \u2014 "),NY=a("a"),vSr=o("FlaxBigBirdForPreTraining"),FSr=o(" (BigBird model)"),TSr=l(),E5=a("li"),Q7e=a("strong"),MSr=o("electra"),ESr=o(" \u2014 "),qY=a("a"),CSr=o("FlaxElectraForPreTraining"),wSr=o(" (ELECTRA model)"),ASr=l(),C5=a("li"),H7e=a("strong"),ySr=o("mbart"),LSr=o(" \u2014 "),jY=a("a"),xSr=o("FlaxMBartForConditionalGeneration"),$Sr=o(" (mBART model)"),kSr=l(),w5=a("li"),U7e=a("strong"),SSr=o("mt5"),RSr=o(" \u2014 "),DY=a("a"),PSr=o("FlaxMT5ForConditionalGeneration"),BSr=o(" (mT5 model)"),ISr=l(),A5=a("li"),J7e=a("strong"),NSr=o("roberta"),qSr=o(" \u2014 "),GY=a("a"),jSr=o("FlaxRobertaForMaskedLM"),DSr=o(" (RoBERTa model)"),GSr=l(),y5=a("li"),Y7e=a("strong"),OSr=o("roformer"),VSr=o(" \u2014 "),OY=a("a"),XSr=o("FlaxRoFormerForMaskedLM"),zSr=o(" (RoFormer model)"),WSr=l(),L5=a("li"),K7e=a("strong"),QSr=o("t5"),HSr=o(" \u2014 "),VY=a("a"),USr=o("FlaxT5ForConditionalGeneration"),JSr=o(" (T5 model)"),YSr=l(),x5=a("li"),Z7e=a("strong"),KSr=o("wav2vec2"),ZSr=o(" \u2014 "),XY=a("a"),eRr=o("FlaxWav2Vec2ForPreTraining"),oRr=o(" (Wav2Vec2 model)"),rRr=l(),$5=a("li"),eMe=a("strong"),tRr=o("xlm-roberta"),aRr=o(" \u2014 "),zY=a("a"),nRr=o("FlaxXLMRobertaForMaskedLM"),sRr=o(" (XLM-RoBERTa model)"),lRr=l(),F(k5.$$.fragment),eDe=l(),jc=a("h2"),S5=a("a"),oMe=a("span"),F(X9.$$.fragment),iRr=l(),rMe=a("span"),dRr=o("FlaxAutoModelForMaskedLM"),oDe=l(),hr=a("div"),F(z9.$$.fragment),cRr=l(),Dc=a("p"),fRr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),WY=a("a"),mRr=o("from_pretrained()"),gRr=o(" class method or the "),QY=a("a"),hRr=o("from_config()"),pRr=o(` class
method.`),_Rr=l(),W9=a("p"),uRr=o("This class cannot be instantiated directly using "),tMe=a("code"),bRr=o("__init__()"),vRr=o(" (throws an error)."),FRr=l(),Xt=a("div"),F(Q9.$$.fragment),TRr=l(),aMe=a("p"),MRr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),ERr=l(),Gc=a("p"),CRr=o(`Note:
Loading a model from its configuration file does `),nMe=a("strong"),wRr=o("not"),ARr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HY=a("a"),yRr=o("from_pretrained()"),LRr=o(" to load the model weights."),xRr=l(),F(R5.$$.fragment),$Rr=l(),Or=a("div"),F(H9.$$.fragment),kRr=l(),sMe=a("p"),SRr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),RRr=l(),un=a("p"),PRr=o("The model class to instantiate is selected based on the "),lMe=a("code"),BRr=o("model_type"),IRr=o(` property of the config object (either
passed as an argument or loaded from `),iMe=a("code"),NRr=o("pretrained_model_name_or_path"),qRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dMe=a("code"),jRr=o("pretrained_model_name_or_path"),DRr=o(":"),GRr=l(),Le=a("ul"),P5=a("li"),cMe=a("strong"),ORr=o("albert"),VRr=o(" \u2014 "),UY=a("a"),XRr=o("FlaxAlbertForMaskedLM"),zRr=o(" (ALBERT model)"),WRr=l(),B5=a("li"),fMe=a("strong"),QRr=o("bart"),HRr=o(" \u2014 "),JY=a("a"),URr=o("FlaxBartForConditionalGeneration"),JRr=o(" (BART model)"),YRr=l(),I5=a("li"),mMe=a("strong"),KRr=o("bert"),ZRr=o(" \u2014 "),YY=a("a"),ePr=o("FlaxBertForMaskedLM"),oPr=o(" (BERT model)"),rPr=l(),N5=a("li"),gMe=a("strong"),tPr=o("big_bird"),aPr=o(" \u2014 "),KY=a("a"),nPr=o("FlaxBigBirdForMaskedLM"),sPr=o(" (BigBird model)"),lPr=l(),q5=a("li"),hMe=a("strong"),iPr=o("distilbert"),dPr=o(" \u2014 "),ZY=a("a"),cPr=o("FlaxDistilBertForMaskedLM"),fPr=o(" (DistilBERT model)"),mPr=l(),j5=a("li"),pMe=a("strong"),gPr=o("electra"),hPr=o(" \u2014 "),eK=a("a"),pPr=o("FlaxElectraForMaskedLM"),_Pr=o(" (ELECTRA model)"),uPr=l(),D5=a("li"),_Me=a("strong"),bPr=o("mbart"),vPr=o(" \u2014 "),oK=a("a"),FPr=o("FlaxMBartForConditionalGeneration"),TPr=o(" (mBART model)"),MPr=l(),G5=a("li"),uMe=a("strong"),EPr=o("roberta"),CPr=o(" \u2014 "),rK=a("a"),wPr=o("FlaxRobertaForMaskedLM"),APr=o(" (RoBERTa model)"),yPr=l(),O5=a("li"),bMe=a("strong"),LPr=o("roformer"),xPr=o(" \u2014 "),tK=a("a"),$Pr=o("FlaxRoFormerForMaskedLM"),kPr=o(" (RoFormer model)"),SPr=l(),V5=a("li"),vMe=a("strong"),RPr=o("xlm-roberta"),PPr=o(" \u2014 "),aK=a("a"),BPr=o("FlaxXLMRobertaForMaskedLM"),IPr=o(" (XLM-RoBERTa model)"),NPr=l(),F(X5.$$.fragment),rDe=l(),Oc=a("h2"),z5=a("a"),FMe=a("span"),F(U9.$$.fragment),qPr=l(),TMe=a("span"),jPr=o("FlaxAutoModelForSeq2SeqLM"),tDe=l(),pr=a("div"),F(J9.$$.fragment),DPr=l(),Vc=a("p"),GPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),nK=a("a"),OPr=o("from_pretrained()"),VPr=o(" class method or the "),sK=a("a"),XPr=o("from_config()"),zPr=o(` class
method.`),WPr=l(),Y9=a("p"),QPr=o("This class cannot be instantiated directly using "),MMe=a("code"),HPr=o("__init__()"),UPr=o(" (throws an error)."),JPr=l(),zt=a("div"),F(K9.$$.fragment),YPr=l(),EMe=a("p"),KPr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),ZPr=l(),Xc=a("p"),eBr=o(`Note:
Loading a model from its configuration file does `),CMe=a("strong"),oBr=o("not"),rBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lK=a("a"),tBr=o("from_pretrained()"),aBr=o(" to load the model weights."),nBr=l(),F(W5.$$.fragment),sBr=l(),Vr=a("div"),F(Z9.$$.fragment),lBr=l(),wMe=a("p"),iBr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),dBr=l(),bn=a("p"),cBr=o("The model class to instantiate is selected based on the "),AMe=a("code"),fBr=o("model_type"),mBr=o(` property of the config object (either
passed as an argument or loaded from `),yMe=a("code"),gBr=o("pretrained_model_name_or_path"),hBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LMe=a("code"),pBr=o("pretrained_model_name_or_path"),_Br=o(":"),uBr=l(),Pe=a("ul"),Q5=a("li"),xMe=a("strong"),bBr=o("bart"),vBr=o(" \u2014 "),iK=a("a"),FBr=o("FlaxBartForConditionalGeneration"),TBr=o(" (BART model)"),MBr=l(),H5=a("li"),$Me=a("strong"),EBr=o("blenderbot"),CBr=o(" \u2014 "),dK=a("a"),wBr=o("FlaxBlenderbotForConditionalGeneration"),ABr=o(" (Blenderbot model)"),yBr=l(),U5=a("li"),kMe=a("strong"),LBr=o("blenderbot-small"),xBr=o(" \u2014 "),cK=a("a"),$Br=o("FlaxBlenderbotSmallForConditionalGeneration"),kBr=o(" (BlenderbotSmall model)"),SBr=l(),J5=a("li"),SMe=a("strong"),RBr=o("encoder-decoder"),PBr=o(" \u2014 "),fK=a("a"),BBr=o("FlaxEncoderDecoderModel"),IBr=o(" (Encoder decoder model)"),NBr=l(),Y5=a("li"),RMe=a("strong"),qBr=o("marian"),jBr=o(" \u2014 "),mK=a("a"),DBr=o("FlaxMarianMTModel"),GBr=o(" (Marian model)"),OBr=l(),K5=a("li"),PMe=a("strong"),VBr=o("mbart"),XBr=o(" \u2014 "),gK=a("a"),zBr=o("FlaxMBartForConditionalGeneration"),WBr=o(" (mBART model)"),QBr=l(),Z5=a("li"),BMe=a("strong"),HBr=o("mt5"),UBr=o(" \u2014 "),hK=a("a"),JBr=o("FlaxMT5ForConditionalGeneration"),YBr=o(" (mT5 model)"),KBr=l(),e3=a("li"),IMe=a("strong"),ZBr=o("pegasus"),eIr=o(" \u2014 "),pK=a("a"),oIr=o("FlaxPegasusForConditionalGeneration"),rIr=o(" (Pegasus model)"),tIr=l(),o3=a("li"),NMe=a("strong"),aIr=o("t5"),nIr=o(" \u2014 "),_K=a("a"),sIr=o("FlaxT5ForConditionalGeneration"),lIr=o(" (T5 model)"),iIr=l(),F(r3.$$.fragment),aDe=l(),zc=a("h2"),t3=a("a"),qMe=a("span"),F(ex.$$.fragment),dIr=l(),jMe=a("span"),cIr=o("FlaxAutoModelForSequenceClassification"),nDe=l(),_r=a("div"),F(ox.$$.fragment),fIr=l(),Wc=a("p"),mIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),uK=a("a"),gIr=o("from_pretrained()"),hIr=o(" class method or the "),bK=a("a"),pIr=o("from_config()"),_Ir=o(` class
method.`),uIr=l(),rx=a("p"),bIr=o("This class cannot be instantiated directly using "),DMe=a("code"),vIr=o("__init__()"),FIr=o(" (throws an error)."),TIr=l(),Wt=a("div"),F(tx.$$.fragment),MIr=l(),GMe=a("p"),EIr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),CIr=l(),Qc=a("p"),wIr=o(`Note:
Loading a model from its configuration file does `),OMe=a("strong"),AIr=o("not"),yIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vK=a("a"),LIr=o("from_pretrained()"),xIr=o(" to load the model weights."),$Ir=l(),F(a3.$$.fragment),kIr=l(),Xr=a("div"),F(ax.$$.fragment),SIr=l(),VMe=a("p"),RIr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),PIr=l(),vn=a("p"),BIr=o("The model class to instantiate is selected based on the "),XMe=a("code"),IIr=o("model_type"),NIr=o(` property of the config object (either
passed as an argument or loaded from `),zMe=a("code"),qIr=o("pretrained_model_name_or_path"),jIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WMe=a("code"),DIr=o("pretrained_model_name_or_path"),GIr=o(":"),OIr=l(),xe=a("ul"),n3=a("li"),QMe=a("strong"),VIr=o("albert"),XIr=o(" \u2014 "),FK=a("a"),zIr=o("FlaxAlbertForSequenceClassification"),WIr=o(" (ALBERT model)"),QIr=l(),s3=a("li"),HMe=a("strong"),HIr=o("bart"),UIr=o(" \u2014 "),TK=a("a"),JIr=o("FlaxBartForSequenceClassification"),YIr=o(" (BART model)"),KIr=l(),l3=a("li"),UMe=a("strong"),ZIr=o("bert"),eNr=o(" \u2014 "),MK=a("a"),oNr=o("FlaxBertForSequenceClassification"),rNr=o(" (BERT model)"),tNr=l(),i3=a("li"),JMe=a("strong"),aNr=o("big_bird"),nNr=o(" \u2014 "),EK=a("a"),sNr=o("FlaxBigBirdForSequenceClassification"),lNr=o(" (BigBird model)"),iNr=l(),d3=a("li"),YMe=a("strong"),dNr=o("distilbert"),cNr=o(" \u2014 "),CK=a("a"),fNr=o("FlaxDistilBertForSequenceClassification"),mNr=o(" (DistilBERT model)"),gNr=l(),c3=a("li"),KMe=a("strong"),hNr=o("electra"),pNr=o(" \u2014 "),wK=a("a"),_Nr=o("FlaxElectraForSequenceClassification"),uNr=o(" (ELECTRA model)"),bNr=l(),f3=a("li"),ZMe=a("strong"),vNr=o("mbart"),FNr=o(" \u2014 "),AK=a("a"),TNr=o("FlaxMBartForSequenceClassification"),MNr=o(" (mBART model)"),ENr=l(),m3=a("li"),eEe=a("strong"),CNr=o("roberta"),wNr=o(" \u2014 "),yK=a("a"),ANr=o("FlaxRobertaForSequenceClassification"),yNr=o(" (RoBERTa model)"),LNr=l(),g3=a("li"),oEe=a("strong"),xNr=o("roformer"),$Nr=o(" \u2014 "),LK=a("a"),kNr=o("FlaxRoFormerForSequenceClassification"),SNr=o(" (RoFormer model)"),RNr=l(),h3=a("li"),rEe=a("strong"),PNr=o("xlm-roberta"),BNr=o(" \u2014 "),xK=a("a"),INr=o("FlaxXLMRobertaForSequenceClassification"),NNr=o(" (XLM-RoBERTa model)"),qNr=l(),F(p3.$$.fragment),sDe=l(),Hc=a("h2"),_3=a("a"),tEe=a("span"),F(nx.$$.fragment),jNr=l(),aEe=a("span"),DNr=o("FlaxAutoModelForQuestionAnswering"),lDe=l(),ur=a("div"),F(sx.$$.fragment),GNr=l(),Uc=a("p"),ONr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),$K=a("a"),VNr=o("from_pretrained()"),XNr=o(" class method or the "),kK=a("a"),zNr=o("from_config()"),WNr=o(` class
method.`),QNr=l(),lx=a("p"),HNr=o("This class cannot be instantiated directly using "),nEe=a("code"),UNr=o("__init__()"),JNr=o(" (throws an error)."),YNr=l(),Qt=a("div"),F(ix.$$.fragment),KNr=l(),sEe=a("p"),ZNr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),eqr=l(),Jc=a("p"),oqr=o(`Note:
Loading a model from its configuration file does `),lEe=a("strong"),rqr=o("not"),tqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SK=a("a"),aqr=o("from_pretrained()"),nqr=o(" to load the model weights."),sqr=l(),F(u3.$$.fragment),lqr=l(),zr=a("div"),F(dx.$$.fragment),iqr=l(),iEe=a("p"),dqr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),cqr=l(),Fn=a("p"),fqr=o("The model class to instantiate is selected based on the "),dEe=a("code"),mqr=o("model_type"),gqr=o(` property of the config object (either
passed as an argument or loaded from `),cEe=a("code"),hqr=o("pretrained_model_name_or_path"),pqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fEe=a("code"),_qr=o("pretrained_model_name_or_path"),uqr=o(":"),bqr=l(),$e=a("ul"),b3=a("li"),mEe=a("strong"),vqr=o("albert"),Fqr=o(" \u2014 "),RK=a("a"),Tqr=o("FlaxAlbertForQuestionAnswering"),Mqr=o(" (ALBERT model)"),Eqr=l(),v3=a("li"),gEe=a("strong"),Cqr=o("bart"),wqr=o(" \u2014 "),PK=a("a"),Aqr=o("FlaxBartForQuestionAnswering"),yqr=o(" (BART model)"),Lqr=l(),F3=a("li"),hEe=a("strong"),xqr=o("bert"),$qr=o(" \u2014 "),BK=a("a"),kqr=o("FlaxBertForQuestionAnswering"),Sqr=o(" (BERT model)"),Rqr=l(),T3=a("li"),pEe=a("strong"),Pqr=o("big_bird"),Bqr=o(" \u2014 "),IK=a("a"),Iqr=o("FlaxBigBirdForQuestionAnswering"),Nqr=o(" (BigBird model)"),qqr=l(),M3=a("li"),_Ee=a("strong"),jqr=o("distilbert"),Dqr=o(" \u2014 "),NK=a("a"),Gqr=o("FlaxDistilBertForQuestionAnswering"),Oqr=o(" (DistilBERT model)"),Vqr=l(),E3=a("li"),uEe=a("strong"),Xqr=o("electra"),zqr=o(" \u2014 "),qK=a("a"),Wqr=o("FlaxElectraForQuestionAnswering"),Qqr=o(" (ELECTRA model)"),Hqr=l(),C3=a("li"),bEe=a("strong"),Uqr=o("mbart"),Jqr=o(" \u2014 "),jK=a("a"),Yqr=o("FlaxMBartForQuestionAnswering"),Kqr=o(" (mBART model)"),Zqr=l(),w3=a("li"),vEe=a("strong"),ejr=o("roberta"),ojr=o(" \u2014 "),DK=a("a"),rjr=o("FlaxRobertaForQuestionAnswering"),tjr=o(" (RoBERTa model)"),ajr=l(),A3=a("li"),FEe=a("strong"),njr=o("roformer"),sjr=o(" \u2014 "),GK=a("a"),ljr=o("FlaxRoFormerForQuestionAnswering"),ijr=o(" (RoFormer model)"),djr=l(),y3=a("li"),TEe=a("strong"),cjr=o("xlm-roberta"),fjr=o(" \u2014 "),OK=a("a"),mjr=o("FlaxXLMRobertaForQuestionAnswering"),gjr=o(" (XLM-RoBERTa model)"),hjr=l(),F(L3.$$.fragment),iDe=l(),Yc=a("h2"),x3=a("a"),MEe=a("span"),F(cx.$$.fragment),pjr=l(),EEe=a("span"),_jr=o("FlaxAutoModelForTokenClassification"),dDe=l(),br=a("div"),F(fx.$$.fragment),ujr=l(),Kc=a("p"),bjr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),VK=a("a"),vjr=o("from_pretrained()"),Fjr=o(" class method or the "),XK=a("a"),Tjr=o("from_config()"),Mjr=o(` class
method.`),Ejr=l(),mx=a("p"),Cjr=o("This class cannot be instantiated directly using "),CEe=a("code"),wjr=o("__init__()"),Ajr=o(" (throws an error)."),yjr=l(),Ht=a("div"),F(gx.$$.fragment),Ljr=l(),wEe=a("p"),xjr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),$jr=l(),Zc=a("p"),kjr=o(`Note:
Loading a model from its configuration file does `),AEe=a("strong"),Sjr=o("not"),Rjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zK=a("a"),Pjr=o("from_pretrained()"),Bjr=o(" to load the model weights."),Ijr=l(),F($3.$$.fragment),Njr=l(),Wr=a("div"),F(hx.$$.fragment),qjr=l(),yEe=a("p"),jjr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Djr=l(),Tn=a("p"),Gjr=o("The model class to instantiate is selected based on the "),LEe=a("code"),Ojr=o("model_type"),Vjr=o(` property of the config object (either
passed as an argument or loaded from `),xEe=a("code"),Xjr=o("pretrained_model_name_or_path"),zjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Ee=a("code"),Wjr=o("pretrained_model_name_or_path"),Qjr=o(":"),Hjr=l(),De=a("ul"),k3=a("li"),kEe=a("strong"),Ujr=o("albert"),Jjr=o(" \u2014 "),WK=a("a"),Yjr=o("FlaxAlbertForTokenClassification"),Kjr=o(" (ALBERT model)"),Zjr=l(),S3=a("li"),SEe=a("strong"),eDr=o("bert"),oDr=o(" \u2014 "),QK=a("a"),rDr=o("FlaxBertForTokenClassification"),tDr=o(" (BERT model)"),aDr=l(),R3=a("li"),REe=a("strong"),nDr=o("big_bird"),sDr=o(" \u2014 "),HK=a("a"),lDr=o("FlaxBigBirdForTokenClassification"),iDr=o(" (BigBird model)"),dDr=l(),P3=a("li"),PEe=a("strong"),cDr=o("distilbert"),fDr=o(" \u2014 "),UK=a("a"),mDr=o("FlaxDistilBertForTokenClassification"),gDr=o(" (DistilBERT model)"),hDr=l(),B3=a("li"),BEe=a("strong"),pDr=o("electra"),_Dr=o(" \u2014 "),JK=a("a"),uDr=o("FlaxElectraForTokenClassification"),bDr=o(" (ELECTRA model)"),vDr=l(),I3=a("li"),IEe=a("strong"),FDr=o("roberta"),TDr=o(" \u2014 "),YK=a("a"),MDr=o("FlaxRobertaForTokenClassification"),EDr=o(" (RoBERTa model)"),CDr=l(),N3=a("li"),NEe=a("strong"),wDr=o("roformer"),ADr=o(" \u2014 "),KK=a("a"),yDr=o("FlaxRoFormerForTokenClassification"),LDr=o(" (RoFormer model)"),xDr=l(),q3=a("li"),qEe=a("strong"),$Dr=o("xlm-roberta"),kDr=o(" \u2014 "),ZK=a("a"),SDr=o("FlaxXLMRobertaForTokenClassification"),RDr=o(" (XLM-RoBERTa model)"),PDr=l(),F(j3.$$.fragment),cDe=l(),ef=a("h2"),D3=a("a"),jEe=a("span"),F(px.$$.fragment),BDr=l(),DEe=a("span"),IDr=o("FlaxAutoModelForMultipleChoice"),fDe=l(),vr=a("div"),F(_x.$$.fragment),NDr=l(),of=a("p"),qDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),eZ=a("a"),jDr=o("from_pretrained()"),DDr=o(" class method or the "),oZ=a("a"),GDr=o("from_config()"),ODr=o(` class
method.`),VDr=l(),ux=a("p"),XDr=o("This class cannot be instantiated directly using "),GEe=a("code"),zDr=o("__init__()"),WDr=o(" (throws an error)."),QDr=l(),Ut=a("div"),F(bx.$$.fragment),HDr=l(),OEe=a("p"),UDr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),JDr=l(),rf=a("p"),YDr=o(`Note:
Loading a model from its configuration file does `),VEe=a("strong"),KDr=o("not"),ZDr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rZ=a("a"),eGr=o("from_pretrained()"),oGr=o(" to load the model weights."),rGr=l(),F(G3.$$.fragment),tGr=l(),Qr=a("div"),F(vx.$$.fragment),aGr=l(),XEe=a("p"),nGr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),sGr=l(),Mn=a("p"),lGr=o("The model class to instantiate is selected based on the "),zEe=a("code"),iGr=o("model_type"),dGr=o(` property of the config object (either
passed as an argument or loaded from `),WEe=a("code"),cGr=o("pretrained_model_name_or_path"),fGr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QEe=a("code"),mGr=o("pretrained_model_name_or_path"),gGr=o(":"),hGr=l(),Ge=a("ul"),O3=a("li"),HEe=a("strong"),pGr=o("albert"),_Gr=o(" \u2014 "),tZ=a("a"),uGr=o("FlaxAlbertForMultipleChoice"),bGr=o(" (ALBERT model)"),vGr=l(),V3=a("li"),UEe=a("strong"),FGr=o("bert"),TGr=o(" \u2014 "),aZ=a("a"),MGr=o("FlaxBertForMultipleChoice"),EGr=o(" (BERT model)"),CGr=l(),X3=a("li"),JEe=a("strong"),wGr=o("big_bird"),AGr=o(" \u2014 "),nZ=a("a"),yGr=o("FlaxBigBirdForMultipleChoice"),LGr=o(" (BigBird model)"),xGr=l(),z3=a("li"),YEe=a("strong"),$Gr=o("distilbert"),kGr=o(" \u2014 "),sZ=a("a"),SGr=o("FlaxDistilBertForMultipleChoice"),RGr=o(" (DistilBERT model)"),PGr=l(),W3=a("li"),KEe=a("strong"),BGr=o("electra"),IGr=o(" \u2014 "),lZ=a("a"),NGr=o("FlaxElectraForMultipleChoice"),qGr=o(" (ELECTRA model)"),jGr=l(),Q3=a("li"),ZEe=a("strong"),DGr=o("roberta"),GGr=o(" \u2014 "),iZ=a("a"),OGr=o("FlaxRobertaForMultipleChoice"),VGr=o(" (RoBERTa model)"),XGr=l(),H3=a("li"),eCe=a("strong"),zGr=o("roformer"),WGr=o(" \u2014 "),dZ=a("a"),QGr=o("FlaxRoFormerForMultipleChoice"),HGr=o(" (RoFormer model)"),UGr=l(),U3=a("li"),oCe=a("strong"),JGr=o("xlm-roberta"),YGr=o(" \u2014 "),cZ=a("a"),KGr=o("FlaxXLMRobertaForMultipleChoice"),ZGr=o(" (XLM-RoBERTa model)"),eOr=l(),F(J3.$$.fragment),mDe=l(),tf=a("h2"),Y3=a("a"),rCe=a("span"),F(Fx.$$.fragment),oOr=l(),tCe=a("span"),rOr=o("FlaxAutoModelForNextSentencePrediction"),gDe=l(),Fr=a("div"),F(Tx.$$.fragment),tOr=l(),af=a("p"),aOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),fZ=a("a"),nOr=o("from_pretrained()"),sOr=o(" class method or the "),mZ=a("a"),lOr=o("from_config()"),iOr=o(` class
method.`),dOr=l(),Mx=a("p"),cOr=o("This class cannot be instantiated directly using "),aCe=a("code"),fOr=o("__init__()"),mOr=o(" (throws an error)."),gOr=l(),Jt=a("div"),F(Ex.$$.fragment),hOr=l(),nCe=a("p"),pOr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),_Or=l(),nf=a("p"),uOr=o(`Note:
Loading a model from its configuration file does `),sCe=a("strong"),bOr=o("not"),vOr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gZ=a("a"),FOr=o("from_pretrained()"),TOr=o(" to load the model weights."),MOr=l(),F(K3.$$.fragment),EOr=l(),Hr=a("div"),F(Cx.$$.fragment),COr=l(),lCe=a("p"),wOr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),AOr=l(),En=a("p"),yOr=o("The model class to instantiate is selected based on the "),iCe=a("code"),LOr=o("model_type"),xOr=o(` property of the config object (either
passed as an argument or loaded from `),dCe=a("code"),$Or=o("pretrained_model_name_or_path"),kOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cCe=a("code"),SOr=o("pretrained_model_name_or_path"),ROr=o(":"),POr=l(),fCe=a("ul"),Z3=a("li"),mCe=a("strong"),BOr=o("bert"),IOr=o(" \u2014 "),hZ=a("a"),NOr=o("FlaxBertForNextSentencePrediction"),qOr=o(" (BERT model)"),jOr=l(),F(ew.$$.fragment),hDe=l(),sf=a("h2"),ow=a("a"),gCe=a("span"),F(wx.$$.fragment),DOr=l(),hCe=a("span"),GOr=o("FlaxAutoModelForImageClassification"),pDe=l(),Tr=a("div"),F(Ax.$$.fragment),OOr=l(),lf=a("p"),VOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),pZ=a("a"),XOr=o("from_pretrained()"),zOr=o(" class method or the "),_Z=a("a"),WOr=o("from_config()"),QOr=o(` class
method.`),HOr=l(),yx=a("p"),UOr=o("This class cannot be instantiated directly using "),pCe=a("code"),JOr=o("__init__()"),YOr=o(" (throws an error)."),KOr=l(),Yt=a("div"),F(Lx.$$.fragment),ZOr=l(),_Ce=a("p"),eVr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),oVr=l(),df=a("p"),rVr=o(`Note:
Loading a model from its configuration file does `),uCe=a("strong"),tVr=o("not"),aVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uZ=a("a"),nVr=o("from_pretrained()"),sVr=o(" to load the model weights."),lVr=l(),F(rw.$$.fragment),iVr=l(),Ur=a("div"),F(xx.$$.fragment),dVr=l(),bCe=a("p"),cVr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),fVr=l(),Cn=a("p"),mVr=o("The model class to instantiate is selected based on the "),vCe=a("code"),gVr=o("model_type"),hVr=o(` property of the config object (either
passed as an argument or loaded from `),FCe=a("code"),pVr=o("pretrained_model_name_or_path"),_Vr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TCe=a("code"),uVr=o("pretrained_model_name_or_path"),bVr=o(":"),vVr=l(),$x=a("ul"),tw=a("li"),MCe=a("strong"),FVr=o("beit"),TVr=o(" \u2014 "),bZ=a("a"),MVr=o("FlaxBeitForImageClassification"),EVr=o(" (BEiT model)"),CVr=l(),aw=a("li"),ECe=a("strong"),wVr=o("vit"),AVr=o(" \u2014 "),vZ=a("a"),yVr=o("FlaxViTForImageClassification"),LVr=o(" (ViT model)"),xVr=l(),F(nw.$$.fragment),_De=l(),cf=a("h2"),sw=a("a"),CCe=a("span"),F(kx.$$.fragment),$Vr=l(),wCe=a("span"),kVr=o("FlaxAutoModelForVision2Seq"),uDe=l(),Mr=a("div"),F(Sx.$$.fragment),SVr=l(),ff=a("p"),RVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),FZ=a("a"),PVr=o("from_pretrained()"),BVr=o(" class method or the "),TZ=a("a"),IVr=o("from_config()"),NVr=o(` class
method.`),qVr=l(),Rx=a("p"),jVr=o("This class cannot be instantiated directly using "),ACe=a("code"),DVr=o("__init__()"),GVr=o(" (throws an error)."),OVr=l(),Kt=a("div"),F(Px.$$.fragment),VVr=l(),yCe=a("p"),XVr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),zVr=l(),mf=a("p"),WVr=o(`Note:
Loading a model from its configuration file does `),LCe=a("strong"),QVr=o("not"),HVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MZ=a("a"),UVr=o("from_pretrained()"),JVr=o(" to load the model weights."),YVr=l(),F(lw.$$.fragment),KVr=l(),Jr=a("div"),F(Bx.$$.fragment),ZVr=l(),xCe=a("p"),eXr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),oXr=l(),wn=a("p"),rXr=o("The model class to instantiate is selected based on the "),$Ce=a("code"),tXr=o("model_type"),aXr=o(` property of the config object (either
passed as an argument or loaded from `),kCe=a("code"),nXr=o("pretrained_model_name_or_path"),sXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SCe=a("code"),lXr=o("pretrained_model_name_or_path"),iXr=o(":"),dXr=l(),RCe=a("ul"),iw=a("li"),PCe=a("strong"),cXr=o("vision-encoder-decoder"),fXr=o(" \u2014 "),EZ=a("a"),mXr=o("FlaxVisionEncoderDecoderModel"),gXr=o(" (Vision Encoder decoder model)"),hXr=l(),F(dw.$$.fragment),this.h()},l(f){const u=tkt('[data-svelte="svelte-1phssyn"]',document.head);g=n(u,"META",{name:!0,content:!0}),u.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var Ix=s(p);m=n(Ix,"A",{id:!0,class:!0,href:!0});var BCe=s(m);_=n(BCe,"SPAN",{});var ICe=s(_);T(d.$$.fragment,ICe),ICe.forEach(t),BCe.forEach(t),h=i(Ix),Mo=n(Ix,"SPAN",{});var NCe=s(Mo);mi=r(NCe,"Auto Classes"),NCe.forEach(t),Ix.forEach(t),_f=i(f),rt=n(f,"P",{});var Nx=s(rt);gi=r(Nx,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),hi=n(Nx,"CODE",{});var qCe=s(hi);yA=r(qCe,"from_pretrained()"),qCe.forEach(t),uf=r(Nx,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Nx.forEach(t),je=i(f),We=n(f,"P",{});var An=s(We);pi=r(An,"Instantiating one of "),yn=n(An,"A",{href:!0});var jCe=s(yn);LA=r(jCe,"AutoConfig"),jCe.forEach(t),Ln=r(An,", "),xn=n(An,"A",{href:!0});var DCe=s(xn);xA=r(DCe,"AutoModel"),DCe.forEach(t),_i=r(An,`, and
`),$n=n(An,"A",{href:!0});var GCe=s($n);$A=r(GCe,"AutoTokenizer"),GCe.forEach(t),ui=r(An," will directly create a class of the relevant architecture. For instance"),An.forEach(t),bf=i(f),T(Ca.$$.fragment,f),Qe=i(f),Ae=n(f,"P",{});var qx=s(Ae);J$=r(qx,"will create a model that is an instance of "),bi=n(qx,"A",{href:!0});var OCe=s(bi);Y$=r(OCe,"BertModel"),OCe.forEach(t),K$=r(qx,"."),qx.forEach(t),Eo=i(f),wa=n(f,"P",{});var jx=s(wa);Z$=r(jx,"There is one class of "),vf=n(jx,"CODE",{});var VCe=s(vf);ek=r(VCe,"AutoModel"),VCe.forEach(t),AOe=r(jx," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),jx.forEach(t),pqe=i(f),vi=n(f,"H2",{class:!0});var Dx=s(vi);Ff=n(Dx,"A",{id:!0,class:!0,href:!0});var XCe=s(Ff);_oe=n(XCe,"SPAN",{});var zCe=s(_oe);T(kA.$$.fragment,zCe),zCe.forEach(t),XCe.forEach(t),yOe=i(Dx),uoe=n(Dx,"SPAN",{});var WCe=s(uoe);LOe=r(WCe,"Extending the Auto Classes"),WCe.forEach(t),Dx.forEach(t),_qe=i(f),kn=n(f,"P",{});var gf=s(kn);xOe=r(gf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),boe=n(gf,"CODE",{});var QCe=s(boe);$Oe=r(QCe,"NewModel"),QCe.forEach(t),kOe=r(gf,", make sure you have a "),voe=n(gf,"CODE",{});var HCe=s(voe);SOe=r(HCe,"NewModelConfig"),HCe.forEach(t),ROe=r(gf,` then you can add those to the auto
classes like this:`),gf.forEach(t),uqe=i(f),T(SA.$$.fragment,f),bqe=i(f),ok=n(f,"P",{});var UCe=s(ok);POe=r(UCe,"You will then be able to use the auto classes like you would usually do!"),UCe.forEach(t),vqe=i(f),T(Tf.$$.fragment,f),Fqe=i(f),Fi=n(f,"H2",{class:!0});var Gx=s(Fi);Mf=n(Gx,"A",{id:!0,class:!0,href:!0});var JCe=s(Mf);Foe=n(JCe,"SPAN",{});var YCe=s(Foe);T(RA.$$.fragment,YCe),YCe.forEach(t),JCe.forEach(t),BOe=i(Gx),Toe=n(Gx,"SPAN",{});var KCe=s(Toe);IOe=r(KCe,"AutoConfig"),KCe.forEach(t),Gx.forEach(t),Tqe=i(f),Co=n(f,"DIV",{class:!0});var et=s(Co);T(PA.$$.fragment,et),NOe=i(et),BA=n(et,"P",{});var Ox=s(BA);qOe=r(Ox,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),rk=n(Ox,"A",{href:!0});var ZCe=s(rk);jOe=r(ZCe,"from_pretrained()"),ZCe.forEach(t),DOe=r(Ox," class method."),Ox.forEach(t),GOe=i(et),IA=n(et,"P",{});var Vx=s(IA);OOe=r(Vx,"This class cannot be instantiated directly using "),Moe=n(Vx,"CODE",{});var e5e=s(Moe);VOe=r(e5e,"__init__()"),e5e.forEach(t),XOe=r(Vx," (throws an error)."),Vx.forEach(t),zOe=i(et),Er=n(et,"DIV",{class:!0});var ot=s(Er);T(NA.$$.fragment,ot),WOe=i(ot),Eoe=n(ot,"P",{});var o5e=s(Eoe);QOe=r(o5e,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),o5e.forEach(t),HOe=i(ot),Ti=n(ot,"P",{});var hf=s(Ti);UOe=r(hf,"The configuration class to instantiate is selected based on the "),Coe=n(hf,"CODE",{});var r5e=s(Coe);JOe=r(r5e,"model_type"),r5e.forEach(t),YOe=r(hf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),woe=n(hf,"CODE",{});var t5e=s(woe);KOe=r(t5e,"pretrained_model_name_or_path"),t5e.forEach(t),ZOe=r(hf,":"),hf.forEach(t),eVe=i(ot),A=n(ot,"UL",{});var y=s(A);Ef=n(y,"LI",{});var cw=s(Ef);Aoe=n(cw,"STRONG",{});var a5e=s(Aoe);oVe=r(a5e,"albert"),a5e.forEach(t),rVe=r(cw," \u2014 "),tk=n(cw,"A",{href:!0});var n5e=s(tk);tVe=r(n5e,"AlbertConfig"),n5e.forEach(t),aVe=r(cw," (ALBERT model)"),cw.forEach(t),nVe=i(y),Cf=n(y,"LI",{});var fw=s(Cf);yoe=n(fw,"STRONG",{});var s5e=s(yoe);sVe=r(s5e,"bart"),s5e.forEach(t),lVe=r(fw," \u2014 "),ak=n(fw,"A",{href:!0});var l5e=s(ak);iVe=r(l5e,"BartConfig"),l5e.forEach(t),dVe=r(fw," (BART model)"),fw.forEach(t),cVe=i(y),wf=n(y,"LI",{});var mw=s(wf);Loe=n(mw,"STRONG",{});var i5e=s(Loe);fVe=r(i5e,"beit"),i5e.forEach(t),mVe=r(mw," \u2014 "),nk=n(mw,"A",{href:!0});var d5e=s(nk);gVe=r(d5e,"BeitConfig"),d5e.forEach(t),hVe=r(mw," (BEiT model)"),mw.forEach(t),pVe=i(y),Af=n(y,"LI",{});var gw=s(Af);xoe=n(gw,"STRONG",{});var c5e=s(xoe);_Ve=r(c5e,"bert"),c5e.forEach(t),uVe=r(gw," \u2014 "),sk=n(gw,"A",{href:!0});var f5e=s(sk);bVe=r(f5e,"BertConfig"),f5e.forEach(t),vVe=r(gw," (BERT model)"),gw.forEach(t),FVe=i(y),yf=n(y,"LI",{});var hw=s(yf);$oe=n(hw,"STRONG",{});var m5e=s($oe);TVe=r(m5e,"bert-generation"),m5e.forEach(t),MVe=r(hw," \u2014 "),lk=n(hw,"A",{href:!0});var g5e=s(lk);EVe=r(g5e,"BertGenerationConfig"),g5e.forEach(t),CVe=r(hw," (Bert Generation model)"),hw.forEach(t),wVe=i(y),Lf=n(y,"LI",{});var pw=s(Lf);koe=n(pw,"STRONG",{});var h5e=s(koe);AVe=r(h5e,"big_bird"),h5e.forEach(t),yVe=r(pw," \u2014 "),ik=n(pw,"A",{href:!0});var p5e=s(ik);LVe=r(p5e,"BigBirdConfig"),p5e.forEach(t),xVe=r(pw," (BigBird model)"),pw.forEach(t),$Ve=i(y),xf=n(y,"LI",{});var _w=s(xf);Soe=n(_w,"STRONG",{});var _5e=s(Soe);kVe=r(_5e,"bigbird_pegasus"),_5e.forEach(t),SVe=r(_w," \u2014 "),dk=n(_w,"A",{href:!0});var u5e=s(dk);RVe=r(u5e,"BigBirdPegasusConfig"),u5e.forEach(t),PVe=r(_w," (BigBirdPegasus model)"),_w.forEach(t),BVe=i(y),$f=n(y,"LI",{});var uw=s($f);Roe=n(uw,"STRONG",{});var b5e=s(Roe);IVe=r(b5e,"blenderbot"),b5e.forEach(t),NVe=r(uw," \u2014 "),ck=n(uw,"A",{href:!0});var v5e=s(ck);qVe=r(v5e,"BlenderbotConfig"),v5e.forEach(t),jVe=r(uw," (Blenderbot model)"),uw.forEach(t),DVe=i(y),kf=n(y,"LI",{});var bw=s(kf);Poe=n(bw,"STRONG",{});var F5e=s(Poe);GVe=r(F5e,"blenderbot-small"),F5e.forEach(t),OVe=r(bw," \u2014 "),fk=n(bw,"A",{href:!0});var T5e=s(fk);VVe=r(T5e,"BlenderbotSmallConfig"),T5e.forEach(t),XVe=r(bw," (BlenderbotSmall model)"),bw.forEach(t),zVe=i(y),Sf=n(y,"LI",{});var vw=s(Sf);Boe=n(vw,"STRONG",{});var M5e=s(Boe);WVe=r(M5e,"camembert"),M5e.forEach(t),QVe=r(vw," \u2014 "),mk=n(vw,"A",{href:!0});var E5e=s(mk);HVe=r(E5e,"CamembertConfig"),E5e.forEach(t),UVe=r(vw," (CamemBERT model)"),vw.forEach(t),JVe=i(y),Rf=n(y,"LI",{});var Fw=s(Rf);Ioe=n(Fw,"STRONG",{});var C5e=s(Ioe);YVe=r(C5e,"canine"),C5e.forEach(t),KVe=r(Fw," \u2014 "),gk=n(Fw,"A",{href:!0});var w5e=s(gk);ZVe=r(w5e,"CanineConfig"),w5e.forEach(t),eXe=r(Fw," (Canine model)"),Fw.forEach(t),oXe=i(y),Pf=n(y,"LI",{});var Tw=s(Pf);Noe=n(Tw,"STRONG",{});var A5e=s(Noe);rXe=r(A5e,"clip"),A5e.forEach(t),tXe=r(Tw," \u2014 "),hk=n(Tw,"A",{href:!0});var y5e=s(hk);aXe=r(y5e,"CLIPConfig"),y5e.forEach(t),nXe=r(Tw," (CLIP model)"),Tw.forEach(t),sXe=i(y),Bf=n(y,"LI",{});var Mw=s(Bf);qoe=n(Mw,"STRONG",{});var L5e=s(qoe);lXe=r(L5e,"convbert"),L5e.forEach(t),iXe=r(Mw," \u2014 "),pk=n(Mw,"A",{href:!0});var x5e=s(pk);dXe=r(x5e,"ConvBertConfig"),x5e.forEach(t),cXe=r(Mw," (ConvBERT model)"),Mw.forEach(t),fXe=i(y),If=n(y,"LI",{});var Ew=s(If);joe=n(Ew,"STRONG",{});var $5e=s(joe);mXe=r($5e,"convnext"),$5e.forEach(t),gXe=r(Ew," \u2014 "),_k=n(Ew,"A",{href:!0});var k5e=s(_k);hXe=r(k5e,"ConvNextConfig"),k5e.forEach(t),pXe=r(Ew," (ConvNext model)"),Ew.forEach(t),_Xe=i(y),Nf=n(y,"LI",{});var Cw=s(Nf);Doe=n(Cw,"STRONG",{});var S5e=s(Doe);uXe=r(S5e,"ctrl"),S5e.forEach(t),bXe=r(Cw," \u2014 "),uk=n(Cw,"A",{href:!0});var R5e=s(uk);vXe=r(R5e,"CTRLConfig"),R5e.forEach(t),FXe=r(Cw," (CTRL model)"),Cw.forEach(t),TXe=i(y),qf=n(y,"LI",{});var ww=s(qf);Goe=n(ww,"STRONG",{});var P5e=s(Goe);MXe=r(P5e,"cvt"),P5e.forEach(t),EXe=r(ww," \u2014 "),bk=n(ww,"A",{href:!0});var B5e=s(bk);CXe=r(B5e,"CvtConfig"),B5e.forEach(t),wXe=r(ww," (CvT model)"),ww.forEach(t),AXe=i(y),jf=n(y,"LI",{});var Aw=s(jf);Ooe=n(Aw,"STRONG",{});var I5e=s(Ooe);yXe=r(I5e,"data2vec-audio"),I5e.forEach(t),LXe=r(Aw," \u2014 "),vk=n(Aw,"A",{href:!0});var N5e=s(vk);xXe=r(N5e,"Data2VecAudioConfig"),N5e.forEach(t),$Xe=r(Aw," (Data2VecAudio model)"),Aw.forEach(t),kXe=i(y),Df=n(y,"LI",{});var yw=s(Df);Voe=n(yw,"STRONG",{});var q5e=s(Voe);SXe=r(q5e,"data2vec-text"),q5e.forEach(t),RXe=r(yw," \u2014 "),Fk=n(yw,"A",{href:!0});var j5e=s(Fk);PXe=r(j5e,"Data2VecTextConfig"),j5e.forEach(t),BXe=r(yw," (Data2VecText model)"),yw.forEach(t),IXe=i(y),Gf=n(y,"LI",{});var Lw=s(Gf);Xoe=n(Lw,"STRONG",{});var D5e=s(Xoe);NXe=r(D5e,"data2vec-vision"),D5e.forEach(t),qXe=r(Lw," \u2014 "),Tk=n(Lw,"A",{href:!0});var G5e=s(Tk);jXe=r(G5e,"Data2VecVisionConfig"),G5e.forEach(t),DXe=r(Lw," (Data2VecVision model)"),Lw.forEach(t),GXe=i(y),Of=n(y,"LI",{});var xw=s(Of);zoe=n(xw,"STRONG",{});var O5e=s(zoe);OXe=r(O5e,"deberta"),O5e.forEach(t),VXe=r(xw," \u2014 "),Mk=n(xw,"A",{href:!0});var V5e=s(Mk);XXe=r(V5e,"DebertaConfig"),V5e.forEach(t),zXe=r(xw," (DeBERTa model)"),xw.forEach(t),WXe=i(y),Vf=n(y,"LI",{});var $w=s(Vf);Woe=n($w,"STRONG",{});var X5e=s(Woe);QXe=r(X5e,"deberta-v2"),X5e.forEach(t),HXe=r($w," \u2014 "),Ek=n($w,"A",{href:!0});var z5e=s(Ek);UXe=r(z5e,"DebertaV2Config"),z5e.forEach(t),JXe=r($w," (DeBERTa-v2 model)"),$w.forEach(t),YXe=i(y),Xf=n(y,"LI",{});var kw=s(Xf);Qoe=n(kw,"STRONG",{});var W5e=s(Qoe);KXe=r(W5e,"decision_transformer"),W5e.forEach(t),ZXe=r(kw," \u2014 "),Ck=n(kw,"A",{href:!0});var Q5e=s(Ck);eze=r(Q5e,"DecisionTransformerConfig"),Q5e.forEach(t),oze=r(kw," (Decision Transformer model)"),kw.forEach(t),rze=i(y),zf=n(y,"LI",{});var Sw=s(zf);Hoe=n(Sw,"STRONG",{});var H5e=s(Hoe);tze=r(H5e,"deit"),H5e.forEach(t),aze=r(Sw," \u2014 "),wk=n(Sw,"A",{href:!0});var _Xr=s(wk);nze=r(_Xr,"DeiTConfig"),_Xr.forEach(t),sze=r(Sw," (DeiT model)"),Sw.forEach(t),lze=i(y),Wf=n(y,"LI",{});var U5e=s(Wf);Uoe=n(U5e,"STRONG",{});var uXr=s(Uoe);ize=r(uXr,"detr"),uXr.forEach(t),dze=r(U5e," \u2014 "),Ak=n(U5e,"A",{href:!0});var bXr=s(Ak);cze=r(bXr,"DetrConfig"),bXr.forEach(t),fze=r(U5e," (DETR model)"),U5e.forEach(t),mze=i(y),Qf=n(y,"LI",{});var J5e=s(Qf);Joe=n(J5e,"STRONG",{});var vXr=s(Joe);gze=r(vXr,"distilbert"),vXr.forEach(t),hze=r(J5e," \u2014 "),yk=n(J5e,"A",{href:!0});var FXr=s(yk);pze=r(FXr,"DistilBertConfig"),FXr.forEach(t),_ze=r(J5e," (DistilBERT model)"),J5e.forEach(t),uze=i(y),Hf=n(y,"LI",{});var Y5e=s(Hf);Yoe=n(Y5e,"STRONG",{});var TXr=s(Yoe);bze=r(TXr,"dpr"),TXr.forEach(t),vze=r(Y5e," \u2014 "),Lk=n(Y5e,"A",{href:!0});var MXr=s(Lk);Fze=r(MXr,"DPRConfig"),MXr.forEach(t),Tze=r(Y5e," (DPR model)"),Y5e.forEach(t),Mze=i(y),Uf=n(y,"LI",{});var K5e=s(Uf);Koe=n(K5e,"STRONG",{});var EXr=s(Koe);Eze=r(EXr,"dpt"),EXr.forEach(t),Cze=r(K5e," \u2014 "),xk=n(K5e,"A",{href:!0});var CXr=s(xk);wze=r(CXr,"DPTConfig"),CXr.forEach(t),Aze=r(K5e," (DPT model)"),K5e.forEach(t),yze=i(y),Jf=n(y,"LI",{});var Z5e=s(Jf);Zoe=n(Z5e,"STRONG",{});var wXr=s(Zoe);Lze=r(wXr,"electra"),wXr.forEach(t),xze=r(Z5e," \u2014 "),$k=n(Z5e,"A",{href:!0});var AXr=s($k);$ze=r(AXr,"ElectraConfig"),AXr.forEach(t),kze=r(Z5e," (ELECTRA model)"),Z5e.forEach(t),Sze=i(y),Yf=n(y,"LI",{});var e3e=s(Yf);ere=n(e3e,"STRONG",{});var yXr=s(ere);Rze=r(yXr,"encoder-decoder"),yXr.forEach(t),Pze=r(e3e," \u2014 "),kk=n(e3e,"A",{href:!0});var LXr=s(kk);Bze=r(LXr,"EncoderDecoderConfig"),LXr.forEach(t),Ize=r(e3e," (Encoder decoder model)"),e3e.forEach(t),Nze=i(y),Kf=n(y,"LI",{});var o3e=s(Kf);ore=n(o3e,"STRONG",{});var xXr=s(ore);qze=r(xXr,"flaubert"),xXr.forEach(t),jze=r(o3e," \u2014 "),Sk=n(o3e,"A",{href:!0});var $Xr=s(Sk);Dze=r($Xr,"FlaubertConfig"),$Xr.forEach(t),Gze=r(o3e," (FlauBERT model)"),o3e.forEach(t),Oze=i(y),Zf=n(y,"LI",{});var r3e=s(Zf);rre=n(r3e,"STRONG",{});var kXr=s(rre);Vze=r(kXr,"flava"),kXr.forEach(t),Xze=r(r3e," \u2014 "),Rk=n(r3e,"A",{href:!0});var SXr=s(Rk);zze=r(SXr,"FlavaConfig"),SXr.forEach(t),Wze=r(r3e," (Flava model)"),r3e.forEach(t),Qze=i(y),em=n(y,"LI",{});var t3e=s(em);tre=n(t3e,"STRONG",{});var RXr=s(tre);Hze=r(RXr,"fnet"),RXr.forEach(t),Uze=r(t3e," \u2014 "),Pk=n(t3e,"A",{href:!0});var PXr=s(Pk);Jze=r(PXr,"FNetConfig"),PXr.forEach(t),Yze=r(t3e," (FNet model)"),t3e.forEach(t),Kze=i(y),om=n(y,"LI",{});var a3e=s(om);are=n(a3e,"STRONG",{});var BXr=s(are);Zze=r(BXr,"fsmt"),BXr.forEach(t),eWe=r(a3e," \u2014 "),Bk=n(a3e,"A",{href:!0});var IXr=s(Bk);oWe=r(IXr,"FSMTConfig"),IXr.forEach(t),rWe=r(a3e," (FairSeq Machine-Translation model)"),a3e.forEach(t),tWe=i(y),rm=n(y,"LI",{});var n3e=s(rm);nre=n(n3e,"STRONG",{});var NXr=s(nre);aWe=r(NXr,"funnel"),NXr.forEach(t),nWe=r(n3e," \u2014 "),Ik=n(n3e,"A",{href:!0});var qXr=s(Ik);sWe=r(qXr,"FunnelConfig"),qXr.forEach(t),lWe=r(n3e," (Funnel Transformer model)"),n3e.forEach(t),iWe=i(y),tm=n(y,"LI",{});var s3e=s(tm);sre=n(s3e,"STRONG",{});var jXr=s(sre);dWe=r(jXr,"glpn"),jXr.forEach(t),cWe=r(s3e," \u2014 "),Nk=n(s3e,"A",{href:!0});var DXr=s(Nk);fWe=r(DXr,"GLPNConfig"),DXr.forEach(t),mWe=r(s3e," (GLPN model)"),s3e.forEach(t),gWe=i(y),am=n(y,"LI",{});var l3e=s(am);lre=n(l3e,"STRONG",{});var GXr=s(lre);hWe=r(GXr,"gpt2"),GXr.forEach(t),pWe=r(l3e," \u2014 "),qk=n(l3e,"A",{href:!0});var OXr=s(qk);_We=r(OXr,"GPT2Config"),OXr.forEach(t),uWe=r(l3e," (OpenAI GPT-2 model)"),l3e.forEach(t),bWe=i(y),nm=n(y,"LI",{});var i3e=s(nm);ire=n(i3e,"STRONG",{});var VXr=s(ire);vWe=r(VXr,"gpt_neo"),VXr.forEach(t),FWe=r(i3e," \u2014 "),jk=n(i3e,"A",{href:!0});var XXr=s(jk);TWe=r(XXr,"GPTNeoConfig"),XXr.forEach(t),MWe=r(i3e," (GPT Neo model)"),i3e.forEach(t),EWe=i(y),sm=n(y,"LI",{});var d3e=s(sm);dre=n(d3e,"STRONG",{});var zXr=s(dre);CWe=r(zXr,"gpt_neox"),zXr.forEach(t),wWe=r(d3e," \u2014 "),Dk=n(d3e,"A",{href:!0});var WXr=s(Dk);AWe=r(WXr,"GPTNeoXConfig"),WXr.forEach(t),yWe=r(d3e," (GPT NeoX model)"),d3e.forEach(t),LWe=i(y),lm=n(y,"LI",{});var c3e=s(lm);cre=n(c3e,"STRONG",{});var QXr=s(cre);xWe=r(QXr,"gptj"),QXr.forEach(t),$We=r(c3e," \u2014 "),Gk=n(c3e,"A",{href:!0});var HXr=s(Gk);kWe=r(HXr,"GPTJConfig"),HXr.forEach(t),SWe=r(c3e," (GPT-J model)"),c3e.forEach(t),RWe=i(y),im=n(y,"LI",{});var f3e=s(im);fre=n(f3e,"STRONG",{});var UXr=s(fre);PWe=r(UXr,"hubert"),UXr.forEach(t),BWe=r(f3e," \u2014 "),Ok=n(f3e,"A",{href:!0});var JXr=s(Ok);IWe=r(JXr,"HubertConfig"),JXr.forEach(t),NWe=r(f3e," (Hubert model)"),f3e.forEach(t),qWe=i(y),dm=n(y,"LI",{});var m3e=s(dm);mre=n(m3e,"STRONG",{});var YXr=s(mre);jWe=r(YXr,"ibert"),YXr.forEach(t),DWe=r(m3e," \u2014 "),Vk=n(m3e,"A",{href:!0});var KXr=s(Vk);GWe=r(KXr,"IBertConfig"),KXr.forEach(t),OWe=r(m3e," (I-BERT model)"),m3e.forEach(t),VWe=i(y),cm=n(y,"LI",{});var g3e=s(cm);gre=n(g3e,"STRONG",{});var ZXr=s(gre);XWe=r(ZXr,"imagegpt"),ZXr.forEach(t),zWe=r(g3e," \u2014 "),Xk=n(g3e,"A",{href:!0});var ezr=s(Xk);WWe=r(ezr,"ImageGPTConfig"),ezr.forEach(t),QWe=r(g3e," (ImageGPT model)"),g3e.forEach(t),HWe=i(y),fm=n(y,"LI",{});var h3e=s(fm);hre=n(h3e,"STRONG",{});var ozr=s(hre);UWe=r(ozr,"layoutlm"),ozr.forEach(t),JWe=r(h3e," \u2014 "),zk=n(h3e,"A",{href:!0});var rzr=s(zk);YWe=r(rzr,"LayoutLMConfig"),rzr.forEach(t),KWe=r(h3e," (LayoutLM model)"),h3e.forEach(t),ZWe=i(y),mm=n(y,"LI",{});var p3e=s(mm);pre=n(p3e,"STRONG",{});var tzr=s(pre);eQe=r(tzr,"layoutlmv2"),tzr.forEach(t),oQe=r(p3e," \u2014 "),Wk=n(p3e,"A",{href:!0});var azr=s(Wk);rQe=r(azr,"LayoutLMv2Config"),azr.forEach(t),tQe=r(p3e," (LayoutLMv2 model)"),p3e.forEach(t),aQe=i(y),gm=n(y,"LI",{});var _3e=s(gm);_re=n(_3e,"STRONG",{});var nzr=s(_re);nQe=r(nzr,"layoutlmv3"),nzr.forEach(t),sQe=r(_3e," \u2014 "),Qk=n(_3e,"A",{href:!0});var szr=s(Qk);lQe=r(szr,"LayoutLMv3Config"),szr.forEach(t),iQe=r(_3e," (LayoutLMv3 model)"),_3e.forEach(t),dQe=i(y),hm=n(y,"LI",{});var u3e=s(hm);ure=n(u3e,"STRONG",{});var lzr=s(ure);cQe=r(lzr,"led"),lzr.forEach(t),fQe=r(u3e," \u2014 "),Hk=n(u3e,"A",{href:!0});var izr=s(Hk);mQe=r(izr,"LEDConfig"),izr.forEach(t),gQe=r(u3e," (LED model)"),u3e.forEach(t),hQe=i(y),pm=n(y,"LI",{});var b3e=s(pm);bre=n(b3e,"STRONG",{});var dzr=s(bre);pQe=r(dzr,"levit"),dzr.forEach(t),_Qe=r(b3e," \u2014 "),Uk=n(b3e,"A",{href:!0});var czr=s(Uk);uQe=r(czr,"LevitConfig"),czr.forEach(t),bQe=r(b3e," (LeViT model)"),b3e.forEach(t),vQe=i(y),_m=n(y,"LI",{});var v3e=s(_m);vre=n(v3e,"STRONG",{});var fzr=s(vre);FQe=r(fzr,"longformer"),fzr.forEach(t),TQe=r(v3e," \u2014 "),Jk=n(v3e,"A",{href:!0});var mzr=s(Jk);MQe=r(mzr,"LongformerConfig"),mzr.forEach(t),EQe=r(v3e," (Longformer model)"),v3e.forEach(t),CQe=i(y),um=n(y,"LI",{});var F3e=s(um);Fre=n(F3e,"STRONG",{});var gzr=s(Fre);wQe=r(gzr,"luke"),gzr.forEach(t),AQe=r(F3e," \u2014 "),Yk=n(F3e,"A",{href:!0});var hzr=s(Yk);yQe=r(hzr,"LukeConfig"),hzr.forEach(t),LQe=r(F3e," (LUKE model)"),F3e.forEach(t),xQe=i(y),bm=n(y,"LI",{});var T3e=s(bm);Tre=n(T3e,"STRONG",{});var pzr=s(Tre);$Qe=r(pzr,"lxmert"),pzr.forEach(t),kQe=r(T3e," \u2014 "),Kk=n(T3e,"A",{href:!0});var _zr=s(Kk);SQe=r(_zr,"LxmertConfig"),_zr.forEach(t),RQe=r(T3e," (LXMERT model)"),T3e.forEach(t),PQe=i(y),vm=n(y,"LI",{});var M3e=s(vm);Mre=n(M3e,"STRONG",{});var uzr=s(Mre);BQe=r(uzr,"m2m_100"),uzr.forEach(t),IQe=r(M3e," \u2014 "),Zk=n(M3e,"A",{href:!0});var bzr=s(Zk);NQe=r(bzr,"M2M100Config"),bzr.forEach(t),qQe=r(M3e," (M2M100 model)"),M3e.forEach(t),jQe=i(y),Fm=n(y,"LI",{});var E3e=s(Fm);Ere=n(E3e,"STRONG",{});var vzr=s(Ere);DQe=r(vzr,"marian"),vzr.forEach(t),GQe=r(E3e," \u2014 "),eS=n(E3e,"A",{href:!0});var Fzr=s(eS);OQe=r(Fzr,"MarianConfig"),Fzr.forEach(t),VQe=r(E3e," (Marian model)"),E3e.forEach(t),XQe=i(y),Tm=n(y,"LI",{});var C3e=s(Tm);Cre=n(C3e,"STRONG",{});var Tzr=s(Cre);zQe=r(Tzr,"maskformer"),Tzr.forEach(t),WQe=r(C3e," \u2014 "),oS=n(C3e,"A",{href:!0});var Mzr=s(oS);QQe=r(Mzr,"MaskFormerConfig"),Mzr.forEach(t),HQe=r(C3e," (MaskFormer model)"),C3e.forEach(t),UQe=i(y),Mm=n(y,"LI",{});var w3e=s(Mm);wre=n(w3e,"STRONG",{});var Ezr=s(wre);JQe=r(Ezr,"mbart"),Ezr.forEach(t),YQe=r(w3e," \u2014 "),rS=n(w3e,"A",{href:!0});var Czr=s(rS);KQe=r(Czr,"MBartConfig"),Czr.forEach(t),ZQe=r(w3e," (mBART model)"),w3e.forEach(t),eHe=i(y),Em=n(y,"LI",{});var A3e=s(Em);Are=n(A3e,"STRONG",{});var wzr=s(Are);oHe=r(wzr,"megatron-bert"),wzr.forEach(t),rHe=r(A3e," \u2014 "),tS=n(A3e,"A",{href:!0});var Azr=s(tS);tHe=r(Azr,"MegatronBertConfig"),Azr.forEach(t),aHe=r(A3e," (MegatronBert model)"),A3e.forEach(t),nHe=i(y),Cm=n(y,"LI",{});var y3e=s(Cm);yre=n(y3e,"STRONG",{});var yzr=s(yre);sHe=r(yzr,"mobilebert"),yzr.forEach(t),lHe=r(y3e," \u2014 "),aS=n(y3e,"A",{href:!0});var Lzr=s(aS);iHe=r(Lzr,"MobileBertConfig"),Lzr.forEach(t),dHe=r(y3e," (MobileBERT model)"),y3e.forEach(t),cHe=i(y),wm=n(y,"LI",{});var L3e=s(wm);Lre=n(L3e,"STRONG",{});var xzr=s(Lre);fHe=r(xzr,"mpnet"),xzr.forEach(t),mHe=r(L3e," \u2014 "),nS=n(L3e,"A",{href:!0});var $zr=s(nS);gHe=r($zr,"MPNetConfig"),$zr.forEach(t),hHe=r(L3e," (MPNet model)"),L3e.forEach(t),pHe=i(y),Am=n(y,"LI",{});var x3e=s(Am);xre=n(x3e,"STRONG",{});var kzr=s(xre);_He=r(kzr,"mt5"),kzr.forEach(t),uHe=r(x3e," \u2014 "),sS=n(x3e,"A",{href:!0});var Szr=s(sS);bHe=r(Szr,"MT5Config"),Szr.forEach(t),vHe=r(x3e," (mT5 model)"),x3e.forEach(t),FHe=i(y),ym=n(y,"LI",{});var $3e=s(ym);$re=n($3e,"STRONG",{});var Rzr=s($re);THe=r(Rzr,"nystromformer"),Rzr.forEach(t),MHe=r($3e," \u2014 "),lS=n($3e,"A",{href:!0});var Pzr=s(lS);EHe=r(Pzr,"NystromformerConfig"),Pzr.forEach(t),CHe=r($3e," (Nystromformer model)"),$3e.forEach(t),wHe=i(y),Lm=n(y,"LI",{});var k3e=s(Lm);kre=n(k3e,"STRONG",{});var Bzr=s(kre);AHe=r(Bzr,"openai-gpt"),Bzr.forEach(t),yHe=r(k3e," \u2014 "),iS=n(k3e,"A",{href:!0});var Izr=s(iS);LHe=r(Izr,"OpenAIGPTConfig"),Izr.forEach(t),xHe=r(k3e," (OpenAI GPT model)"),k3e.forEach(t),$He=i(y),xm=n(y,"LI",{});var S3e=s(xm);Sre=n(S3e,"STRONG",{});var Nzr=s(Sre);kHe=r(Nzr,"opt"),Nzr.forEach(t),SHe=r(S3e," \u2014 "),dS=n(S3e,"A",{href:!0});var qzr=s(dS);RHe=r(qzr,"OPTConfig"),qzr.forEach(t),PHe=r(S3e," (OPT model)"),S3e.forEach(t),BHe=i(y),$m=n(y,"LI",{});var R3e=s($m);Rre=n(R3e,"STRONG",{});var jzr=s(Rre);IHe=r(jzr,"pegasus"),jzr.forEach(t),NHe=r(R3e," \u2014 "),cS=n(R3e,"A",{href:!0});var Dzr=s(cS);qHe=r(Dzr,"PegasusConfig"),Dzr.forEach(t),jHe=r(R3e," (Pegasus model)"),R3e.forEach(t),DHe=i(y),km=n(y,"LI",{});var P3e=s(km);Pre=n(P3e,"STRONG",{});var Gzr=s(Pre);GHe=r(Gzr,"perceiver"),Gzr.forEach(t),OHe=r(P3e," \u2014 "),fS=n(P3e,"A",{href:!0});var Ozr=s(fS);VHe=r(Ozr,"PerceiverConfig"),Ozr.forEach(t),XHe=r(P3e," (Perceiver model)"),P3e.forEach(t),zHe=i(y),Sm=n(y,"LI",{});var B3e=s(Sm);Bre=n(B3e,"STRONG",{});var Vzr=s(Bre);WHe=r(Vzr,"plbart"),Vzr.forEach(t),QHe=r(B3e," \u2014 "),mS=n(B3e,"A",{href:!0});var Xzr=s(mS);HHe=r(Xzr,"PLBartConfig"),Xzr.forEach(t),UHe=r(B3e," (PLBart model)"),B3e.forEach(t),JHe=i(y),Rm=n(y,"LI",{});var I3e=s(Rm);Ire=n(I3e,"STRONG",{});var zzr=s(Ire);YHe=r(zzr,"poolformer"),zzr.forEach(t),KHe=r(I3e," \u2014 "),gS=n(I3e,"A",{href:!0});var Wzr=s(gS);ZHe=r(Wzr,"PoolFormerConfig"),Wzr.forEach(t),eUe=r(I3e," (PoolFormer model)"),I3e.forEach(t),oUe=i(y),Pm=n(y,"LI",{});var N3e=s(Pm);Nre=n(N3e,"STRONG",{});var Qzr=s(Nre);rUe=r(Qzr,"prophetnet"),Qzr.forEach(t),tUe=r(N3e," \u2014 "),hS=n(N3e,"A",{href:!0});var Hzr=s(hS);aUe=r(Hzr,"ProphetNetConfig"),Hzr.forEach(t),nUe=r(N3e," (ProphetNet model)"),N3e.forEach(t),sUe=i(y),Bm=n(y,"LI",{});var q3e=s(Bm);qre=n(q3e,"STRONG",{});var Uzr=s(qre);lUe=r(Uzr,"qdqbert"),Uzr.forEach(t),iUe=r(q3e," \u2014 "),pS=n(q3e,"A",{href:!0});var Jzr=s(pS);dUe=r(Jzr,"QDQBertConfig"),Jzr.forEach(t),cUe=r(q3e," (QDQBert model)"),q3e.forEach(t),fUe=i(y),Im=n(y,"LI",{});var j3e=s(Im);jre=n(j3e,"STRONG",{});var Yzr=s(jre);mUe=r(Yzr,"rag"),Yzr.forEach(t),gUe=r(j3e," \u2014 "),_S=n(j3e,"A",{href:!0});var Kzr=s(_S);hUe=r(Kzr,"RagConfig"),Kzr.forEach(t),pUe=r(j3e," (RAG model)"),j3e.forEach(t),_Ue=i(y),Nm=n(y,"LI",{});var D3e=s(Nm);Dre=n(D3e,"STRONG",{});var Zzr=s(Dre);uUe=r(Zzr,"realm"),Zzr.forEach(t),bUe=r(D3e," \u2014 "),uS=n(D3e,"A",{href:!0});var eWr=s(uS);vUe=r(eWr,"RealmConfig"),eWr.forEach(t),FUe=r(D3e," (Realm model)"),D3e.forEach(t),TUe=i(y),qm=n(y,"LI",{});var G3e=s(qm);Gre=n(G3e,"STRONG",{});var oWr=s(Gre);MUe=r(oWr,"reformer"),oWr.forEach(t),EUe=r(G3e," \u2014 "),bS=n(G3e,"A",{href:!0});var rWr=s(bS);CUe=r(rWr,"ReformerConfig"),rWr.forEach(t),wUe=r(G3e," (Reformer model)"),G3e.forEach(t),AUe=i(y),jm=n(y,"LI",{});var O3e=s(jm);Ore=n(O3e,"STRONG",{});var tWr=s(Ore);yUe=r(tWr,"regnet"),tWr.forEach(t),LUe=r(O3e," \u2014 "),vS=n(O3e,"A",{href:!0});var aWr=s(vS);xUe=r(aWr,"RegNetConfig"),aWr.forEach(t),$Ue=r(O3e," (RegNet model)"),O3e.forEach(t),kUe=i(y),Dm=n(y,"LI",{});var V3e=s(Dm);Vre=n(V3e,"STRONG",{});var nWr=s(Vre);SUe=r(nWr,"rembert"),nWr.forEach(t),RUe=r(V3e," \u2014 "),FS=n(V3e,"A",{href:!0});var sWr=s(FS);PUe=r(sWr,"RemBertConfig"),sWr.forEach(t),BUe=r(V3e," (RemBERT model)"),V3e.forEach(t),IUe=i(y),Gm=n(y,"LI",{});var X3e=s(Gm);Xre=n(X3e,"STRONG",{});var lWr=s(Xre);NUe=r(lWr,"resnet"),lWr.forEach(t),qUe=r(X3e," \u2014 "),TS=n(X3e,"A",{href:!0});var iWr=s(TS);jUe=r(iWr,"ResNetConfig"),iWr.forEach(t),DUe=r(X3e," (ResNet model)"),X3e.forEach(t),GUe=i(y),Om=n(y,"LI",{});var z3e=s(Om);zre=n(z3e,"STRONG",{});var dWr=s(zre);OUe=r(dWr,"retribert"),dWr.forEach(t),VUe=r(z3e," \u2014 "),MS=n(z3e,"A",{href:!0});var cWr=s(MS);XUe=r(cWr,"RetriBertConfig"),cWr.forEach(t),zUe=r(z3e," (RetriBERT model)"),z3e.forEach(t),WUe=i(y),Vm=n(y,"LI",{});var W3e=s(Vm);Wre=n(W3e,"STRONG",{});var fWr=s(Wre);QUe=r(fWr,"roberta"),fWr.forEach(t),HUe=r(W3e," \u2014 "),ES=n(W3e,"A",{href:!0});var mWr=s(ES);UUe=r(mWr,"RobertaConfig"),mWr.forEach(t),JUe=r(W3e," (RoBERTa model)"),W3e.forEach(t),YUe=i(y),Xm=n(y,"LI",{});var Q3e=s(Xm);Qre=n(Q3e,"STRONG",{});var gWr=s(Qre);KUe=r(gWr,"roformer"),gWr.forEach(t),ZUe=r(Q3e," \u2014 "),CS=n(Q3e,"A",{href:!0});var hWr=s(CS);eJe=r(hWr,"RoFormerConfig"),hWr.forEach(t),oJe=r(Q3e," (RoFormer model)"),Q3e.forEach(t),rJe=i(y),zm=n(y,"LI",{});var H3e=s(zm);Hre=n(H3e,"STRONG",{});var pWr=s(Hre);tJe=r(pWr,"segformer"),pWr.forEach(t),aJe=r(H3e," \u2014 "),wS=n(H3e,"A",{href:!0});var _Wr=s(wS);nJe=r(_Wr,"SegformerConfig"),_Wr.forEach(t),sJe=r(H3e," (SegFormer model)"),H3e.forEach(t),lJe=i(y),Wm=n(y,"LI",{});var U3e=s(Wm);Ure=n(U3e,"STRONG",{});var uWr=s(Ure);iJe=r(uWr,"sew"),uWr.forEach(t),dJe=r(U3e," \u2014 "),AS=n(U3e,"A",{href:!0});var bWr=s(AS);cJe=r(bWr,"SEWConfig"),bWr.forEach(t),fJe=r(U3e," (SEW model)"),U3e.forEach(t),mJe=i(y),Qm=n(y,"LI",{});var J3e=s(Qm);Jre=n(J3e,"STRONG",{});var vWr=s(Jre);gJe=r(vWr,"sew-d"),vWr.forEach(t),hJe=r(J3e," \u2014 "),yS=n(J3e,"A",{href:!0});var FWr=s(yS);pJe=r(FWr,"SEWDConfig"),FWr.forEach(t),_Je=r(J3e," (SEW-D model)"),J3e.forEach(t),uJe=i(y),Hm=n(y,"LI",{});var Y3e=s(Hm);Yre=n(Y3e,"STRONG",{});var TWr=s(Yre);bJe=r(TWr,"speech-encoder-decoder"),TWr.forEach(t),vJe=r(Y3e," \u2014 "),LS=n(Y3e,"A",{href:!0});var MWr=s(LS);FJe=r(MWr,"SpeechEncoderDecoderConfig"),MWr.forEach(t),TJe=r(Y3e," (Speech Encoder decoder model)"),Y3e.forEach(t),MJe=i(y),Um=n(y,"LI",{});var K3e=s(Um);Kre=n(K3e,"STRONG",{});var EWr=s(Kre);EJe=r(EWr,"speech_to_text"),EWr.forEach(t),CJe=r(K3e," \u2014 "),xS=n(K3e,"A",{href:!0});var CWr=s(xS);wJe=r(CWr,"Speech2TextConfig"),CWr.forEach(t),AJe=r(K3e," (Speech2Text model)"),K3e.forEach(t),yJe=i(y),Jm=n(y,"LI",{});var Z3e=s(Jm);Zre=n(Z3e,"STRONG",{});var wWr=s(Zre);LJe=r(wWr,"speech_to_text_2"),wWr.forEach(t),xJe=r(Z3e," \u2014 "),$S=n(Z3e,"A",{href:!0});var AWr=s($S);$Je=r(AWr,"Speech2Text2Config"),AWr.forEach(t),kJe=r(Z3e," (Speech2Text2 model)"),Z3e.forEach(t),SJe=i(y),Ym=n(y,"LI",{});var ewe=s(Ym);ete=n(ewe,"STRONG",{});var yWr=s(ete);RJe=r(yWr,"splinter"),yWr.forEach(t),PJe=r(ewe," \u2014 "),kS=n(ewe,"A",{href:!0});var LWr=s(kS);BJe=r(LWr,"SplinterConfig"),LWr.forEach(t),IJe=r(ewe," (Splinter model)"),ewe.forEach(t),NJe=i(y),Km=n(y,"LI",{});var owe=s(Km);ote=n(owe,"STRONG",{});var xWr=s(ote);qJe=r(xWr,"squeezebert"),xWr.forEach(t),jJe=r(owe," \u2014 "),SS=n(owe,"A",{href:!0});var $Wr=s(SS);DJe=r($Wr,"SqueezeBertConfig"),$Wr.forEach(t),GJe=r(owe," (SqueezeBERT model)"),owe.forEach(t),OJe=i(y),Zm=n(y,"LI",{});var rwe=s(Zm);rte=n(rwe,"STRONG",{});var kWr=s(rte);VJe=r(kWr,"swin"),kWr.forEach(t),XJe=r(rwe," \u2014 "),RS=n(rwe,"A",{href:!0});var SWr=s(RS);zJe=r(SWr,"SwinConfig"),SWr.forEach(t),WJe=r(rwe," (Swin model)"),rwe.forEach(t),QJe=i(y),eg=n(y,"LI",{});var twe=s(eg);tte=n(twe,"STRONG",{});var RWr=s(tte);HJe=r(RWr,"t5"),RWr.forEach(t),UJe=r(twe," \u2014 "),PS=n(twe,"A",{href:!0});var PWr=s(PS);JJe=r(PWr,"T5Config"),PWr.forEach(t),YJe=r(twe," (T5 model)"),twe.forEach(t),KJe=i(y),og=n(y,"LI",{});var awe=s(og);ate=n(awe,"STRONG",{});var BWr=s(ate);ZJe=r(BWr,"tapas"),BWr.forEach(t),eYe=r(awe," \u2014 "),BS=n(awe,"A",{href:!0});var IWr=s(BS);oYe=r(IWr,"TapasConfig"),IWr.forEach(t),rYe=r(awe," (TAPAS model)"),awe.forEach(t),tYe=i(y),rg=n(y,"LI",{});var nwe=s(rg);nte=n(nwe,"STRONG",{});var NWr=s(nte);aYe=r(NWr,"trajectory_transformer"),NWr.forEach(t),nYe=r(nwe," \u2014 "),IS=n(nwe,"A",{href:!0});var qWr=s(IS);sYe=r(qWr,"TrajectoryTransformerConfig"),qWr.forEach(t),lYe=r(nwe," (Trajectory Transformer model)"),nwe.forEach(t),iYe=i(y),tg=n(y,"LI",{});var swe=s(tg);ste=n(swe,"STRONG",{});var jWr=s(ste);dYe=r(jWr,"transfo-xl"),jWr.forEach(t),cYe=r(swe," \u2014 "),NS=n(swe,"A",{href:!0});var DWr=s(NS);fYe=r(DWr,"TransfoXLConfig"),DWr.forEach(t),mYe=r(swe," (Transformer-XL model)"),swe.forEach(t),gYe=i(y),ag=n(y,"LI",{});var lwe=s(ag);lte=n(lwe,"STRONG",{});var GWr=s(lte);hYe=r(GWr,"trocr"),GWr.forEach(t),pYe=r(lwe," \u2014 "),qS=n(lwe,"A",{href:!0});var OWr=s(qS);_Ye=r(OWr,"TrOCRConfig"),OWr.forEach(t),uYe=r(lwe," (TrOCR model)"),lwe.forEach(t),bYe=i(y),ng=n(y,"LI",{});var iwe=s(ng);ite=n(iwe,"STRONG",{});var VWr=s(ite);vYe=r(VWr,"unispeech"),VWr.forEach(t),FYe=r(iwe," \u2014 "),jS=n(iwe,"A",{href:!0});var XWr=s(jS);TYe=r(XWr,"UniSpeechConfig"),XWr.forEach(t),MYe=r(iwe," (UniSpeech model)"),iwe.forEach(t),EYe=i(y),sg=n(y,"LI",{});var dwe=s(sg);dte=n(dwe,"STRONG",{});var zWr=s(dte);CYe=r(zWr,"unispeech-sat"),zWr.forEach(t),wYe=r(dwe," \u2014 "),DS=n(dwe,"A",{href:!0});var WWr=s(DS);AYe=r(WWr,"UniSpeechSatConfig"),WWr.forEach(t),yYe=r(dwe," (UniSpeechSat model)"),dwe.forEach(t),LYe=i(y),lg=n(y,"LI",{});var cwe=s(lg);cte=n(cwe,"STRONG",{});var QWr=s(cte);xYe=r(QWr,"van"),QWr.forEach(t),$Ye=r(cwe," \u2014 "),GS=n(cwe,"A",{href:!0});var HWr=s(GS);kYe=r(HWr,"VanConfig"),HWr.forEach(t),SYe=r(cwe," (VAN model)"),cwe.forEach(t),RYe=i(y),ig=n(y,"LI",{});var fwe=s(ig);fte=n(fwe,"STRONG",{});var UWr=s(fte);PYe=r(UWr,"vilt"),UWr.forEach(t),BYe=r(fwe," \u2014 "),OS=n(fwe,"A",{href:!0});var JWr=s(OS);IYe=r(JWr,"ViltConfig"),JWr.forEach(t),NYe=r(fwe," (ViLT model)"),fwe.forEach(t),qYe=i(y),dg=n(y,"LI",{});var mwe=s(dg);mte=n(mwe,"STRONG",{});var YWr=s(mte);jYe=r(YWr,"vision-encoder-decoder"),YWr.forEach(t),DYe=r(mwe," \u2014 "),VS=n(mwe,"A",{href:!0});var KWr=s(VS);GYe=r(KWr,"VisionEncoderDecoderConfig"),KWr.forEach(t),OYe=r(mwe," (Vision Encoder decoder model)"),mwe.forEach(t),VYe=i(y),cg=n(y,"LI",{});var gwe=s(cg);gte=n(gwe,"STRONG",{});var ZWr=s(gte);XYe=r(ZWr,"vision-text-dual-encoder"),ZWr.forEach(t),zYe=r(gwe," \u2014 "),XS=n(gwe,"A",{href:!0});var eQr=s(XS);WYe=r(eQr,"VisionTextDualEncoderConfig"),eQr.forEach(t),QYe=r(gwe," (VisionTextDualEncoder model)"),gwe.forEach(t),HYe=i(y),fg=n(y,"LI",{});var hwe=s(fg);hte=n(hwe,"STRONG",{});var oQr=s(hte);UYe=r(oQr,"visual_bert"),oQr.forEach(t),JYe=r(hwe," \u2014 "),zS=n(hwe,"A",{href:!0});var rQr=s(zS);YYe=r(rQr,"VisualBertConfig"),rQr.forEach(t),KYe=r(hwe," (VisualBert model)"),hwe.forEach(t),ZYe=i(y),mg=n(y,"LI",{});var pwe=s(mg);pte=n(pwe,"STRONG",{});var tQr=s(pte);eKe=r(tQr,"vit"),tQr.forEach(t),oKe=r(pwe," \u2014 "),WS=n(pwe,"A",{href:!0});var aQr=s(WS);rKe=r(aQr,"ViTConfig"),aQr.forEach(t),tKe=r(pwe," (ViT model)"),pwe.forEach(t),aKe=i(y),gg=n(y,"LI",{});var _we=s(gg);_te=n(_we,"STRONG",{});var nQr=s(_te);nKe=r(nQr,"vit_mae"),nQr.forEach(t),sKe=r(_we," \u2014 "),QS=n(_we,"A",{href:!0});var sQr=s(QS);lKe=r(sQr,"ViTMAEConfig"),sQr.forEach(t),iKe=r(_we," (ViTMAE model)"),_we.forEach(t),dKe=i(y),hg=n(y,"LI",{});var uwe=s(hg);ute=n(uwe,"STRONG",{});var lQr=s(ute);cKe=r(lQr,"wav2vec2"),lQr.forEach(t),fKe=r(uwe," \u2014 "),HS=n(uwe,"A",{href:!0});var iQr=s(HS);mKe=r(iQr,"Wav2Vec2Config"),iQr.forEach(t),gKe=r(uwe," (Wav2Vec2 model)"),uwe.forEach(t),hKe=i(y),pg=n(y,"LI",{});var bwe=s(pg);bte=n(bwe,"STRONG",{});var dQr=s(bte);pKe=r(dQr,"wav2vec2-conformer"),dQr.forEach(t),_Ke=r(bwe," \u2014 "),US=n(bwe,"A",{href:!0});var cQr=s(US);uKe=r(cQr,"Wav2Vec2ConformerConfig"),cQr.forEach(t),bKe=r(bwe," (Wav2Vec2-Conformer model)"),bwe.forEach(t),vKe=i(y),_g=n(y,"LI",{});var vwe=s(_g);vte=n(vwe,"STRONG",{});var fQr=s(vte);FKe=r(fQr,"wavlm"),fQr.forEach(t),TKe=r(vwe," \u2014 "),JS=n(vwe,"A",{href:!0});var mQr=s(JS);MKe=r(mQr,"WavLMConfig"),mQr.forEach(t),EKe=r(vwe," (WavLM model)"),vwe.forEach(t),CKe=i(y),ug=n(y,"LI",{});var Fwe=s(ug);Fte=n(Fwe,"STRONG",{});var gQr=s(Fte);wKe=r(gQr,"xglm"),gQr.forEach(t),AKe=r(Fwe," \u2014 "),YS=n(Fwe,"A",{href:!0});var hQr=s(YS);yKe=r(hQr,"XGLMConfig"),hQr.forEach(t),LKe=r(Fwe," (XGLM model)"),Fwe.forEach(t),xKe=i(y),bg=n(y,"LI",{});var Twe=s(bg);Tte=n(Twe,"STRONG",{});var pQr=s(Tte);$Ke=r(pQr,"xlm"),pQr.forEach(t),kKe=r(Twe," \u2014 "),KS=n(Twe,"A",{href:!0});var _Qr=s(KS);SKe=r(_Qr,"XLMConfig"),_Qr.forEach(t),RKe=r(Twe," (XLM model)"),Twe.forEach(t),PKe=i(y),vg=n(y,"LI",{});var Mwe=s(vg);Mte=n(Mwe,"STRONG",{});var uQr=s(Mte);BKe=r(uQr,"xlm-prophetnet"),uQr.forEach(t),IKe=r(Mwe," \u2014 "),ZS=n(Mwe,"A",{href:!0});var bQr=s(ZS);NKe=r(bQr,"XLMProphetNetConfig"),bQr.forEach(t),qKe=r(Mwe," (XLMProphetNet model)"),Mwe.forEach(t),jKe=i(y),Fg=n(y,"LI",{});var Ewe=s(Fg);Ete=n(Ewe,"STRONG",{});var vQr=s(Ete);DKe=r(vQr,"xlm-roberta"),vQr.forEach(t),GKe=r(Ewe," \u2014 "),eR=n(Ewe,"A",{href:!0});var FQr=s(eR);OKe=r(FQr,"XLMRobertaConfig"),FQr.forEach(t),VKe=r(Ewe," (XLM-RoBERTa model)"),Ewe.forEach(t),XKe=i(y),Tg=n(y,"LI",{});var Cwe=s(Tg);Cte=n(Cwe,"STRONG",{});var TQr=s(Cte);zKe=r(TQr,"xlm-roberta-xl"),TQr.forEach(t),WKe=r(Cwe," \u2014 "),oR=n(Cwe,"A",{href:!0});var MQr=s(oR);QKe=r(MQr,"XLMRobertaXLConfig"),MQr.forEach(t),HKe=r(Cwe," (XLM-RoBERTa-XL model)"),Cwe.forEach(t),UKe=i(y),Mg=n(y,"LI",{});var wwe=s(Mg);wte=n(wwe,"STRONG",{});var EQr=s(wte);JKe=r(EQr,"xlnet"),EQr.forEach(t),YKe=r(wwe," \u2014 "),rR=n(wwe,"A",{href:!0});var CQr=s(rR);KKe=r(CQr,"XLNetConfig"),CQr.forEach(t),ZKe=r(wwe," (XLNet model)"),wwe.forEach(t),eZe=i(y),Eg=n(y,"LI",{});var Awe=s(Eg);Ate=n(Awe,"STRONG",{});var wQr=s(Ate);oZe=r(wQr,"yolos"),wQr.forEach(t),rZe=r(Awe," \u2014 "),tR=n(Awe,"A",{href:!0});var AQr=s(tR);tZe=r(AQr,"YolosConfig"),AQr.forEach(t),aZe=r(Awe," (YOLOS model)"),Awe.forEach(t),nZe=i(y),Cg=n(y,"LI",{});var ywe=s(Cg);yte=n(ywe,"STRONG",{});var yQr=s(yte);sZe=r(yQr,"yoso"),yQr.forEach(t),lZe=r(ywe," \u2014 "),aR=n(ywe,"A",{href:!0});var LQr=s(aR);iZe=r(LQr,"YosoConfig"),LQr.forEach(t),dZe=r(ywe," (YOSO model)"),ywe.forEach(t),y.forEach(t),cZe=i(ot),T(wg.$$.fragment,ot),ot.forEach(t),fZe=i(et),Ag=n(et,"DIV",{class:!0});var vDe=s(Ag);T(qA.$$.fragment,vDe),mZe=i(vDe),Lte=n(vDe,"P",{});var xQr=s(Lte);gZe=r(xQr,"Register a new configuration for this class."),xQr.forEach(t),vDe.forEach(t),et.forEach(t),Mqe=i(f),Mi=n(f,"H2",{class:!0});var FDe=s(Mi);yg=n(FDe,"A",{id:!0,class:!0,href:!0});var $Qr=s(yg);xte=n($Qr,"SPAN",{});var kQr=s(xte);T(jA.$$.fragment,kQr),kQr.forEach(t),$Qr.forEach(t),hZe=i(FDe),$te=n(FDe,"SPAN",{});var SQr=s($te);pZe=r(SQr,"AutoTokenizer"),SQr.forEach(t),FDe.forEach(t),Eqe=i(f),wo=n(f,"DIV",{class:!0});var qs=s(wo);T(DA.$$.fragment,qs),_Ze=i(qs),GA=n(qs,"P",{});var TDe=s(GA);uZe=r(TDe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),nR=n(TDe,"A",{href:!0});var RQr=s(nR);bZe=r(RQr,"AutoTokenizer.from_pretrained()"),RQr.forEach(t),vZe=r(TDe," class method."),TDe.forEach(t),FZe=i(qs),OA=n(qs,"P",{});var MDe=s(OA);TZe=r(MDe,"This class cannot be instantiated directly using "),kte=n(MDe,"CODE",{});var PQr=s(kte);MZe=r(PQr,"__init__()"),PQr.forEach(t),EZe=r(MDe," (throws an error)."),MDe.forEach(t),CZe=i(qs),Cr=n(qs,"DIV",{class:!0});var js=s(Cr);T(VA.$$.fragment,js),wZe=i(js),Ste=n(js,"P",{});var BQr=s(Ste);AZe=r(BQr,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),BQr.forEach(t),yZe=i(js),Aa=n(js,"P",{});var Rw=s(Aa);LZe=r(Rw,"The tokenizer class to instantiate is selected based on the "),Rte=n(Rw,"CODE",{});var IQr=s(Rte);xZe=r(IQr,"model_type"),IQr.forEach(t),$Ze=r(Rw,` property of the config object (either
passed as an argument or loaded from `),Pte=n(Rw,"CODE",{});var NQr=s(Pte);kZe=r(NQr,"pretrained_model_name_or_path"),NQr.forEach(t),SZe=r(Rw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bte=n(Rw,"CODE",{});var qQr=s(Bte);RZe=r(qQr,"pretrained_model_name_or_path"),qQr.forEach(t),PZe=r(Rw,":"),Rw.forEach(t),BZe=i(js),k=n(js,"UL",{});var S=s(k);Sn=n(S,"LI",{});var Xx=s(Sn);Ite=n(Xx,"STRONG",{});var jQr=s(Ite);IZe=r(jQr,"albert"),jQr.forEach(t),NZe=r(Xx," \u2014 "),sR=n(Xx,"A",{href:!0});var DQr=s(sR);qZe=r(DQr,"AlbertTokenizer"),DQr.forEach(t),jZe=r(Xx," or "),lR=n(Xx,"A",{href:!0});var GQr=s(lR);DZe=r(GQr,"AlbertTokenizerFast"),GQr.forEach(t),GZe=r(Xx," (ALBERT model)"),Xx.forEach(t),OZe=i(S),Rn=n(S,"LI",{});var zx=s(Rn);Nte=n(zx,"STRONG",{});var OQr=s(Nte);VZe=r(OQr,"bart"),OQr.forEach(t),XZe=r(zx," \u2014 "),iR=n(zx,"A",{href:!0});var VQr=s(iR);zZe=r(VQr,"BartTokenizer"),VQr.forEach(t),WZe=r(zx," or "),dR=n(zx,"A",{href:!0});var XQr=s(dR);QZe=r(XQr,"BartTokenizerFast"),XQr.forEach(t),HZe=r(zx," (BART model)"),zx.forEach(t),UZe=i(S),Pn=n(S,"LI",{});var Wx=s(Pn);qte=n(Wx,"STRONG",{});var zQr=s(qte);JZe=r(zQr,"barthez"),zQr.forEach(t),YZe=r(Wx," \u2014 "),cR=n(Wx,"A",{href:!0});var WQr=s(cR);KZe=r(WQr,"BarthezTokenizer"),WQr.forEach(t),ZZe=r(Wx," or "),fR=n(Wx,"A",{href:!0});var QQr=s(fR);eeo=r(QQr,"BarthezTokenizerFast"),QQr.forEach(t),oeo=r(Wx," (BARThez model)"),Wx.forEach(t),reo=i(S),Lg=n(S,"LI",{});var Lwe=s(Lg);jte=n(Lwe,"STRONG",{});var HQr=s(jte);teo=r(HQr,"bartpho"),HQr.forEach(t),aeo=r(Lwe," \u2014 "),mR=n(Lwe,"A",{href:!0});var UQr=s(mR);neo=r(UQr,"BartphoTokenizer"),UQr.forEach(t),seo=r(Lwe," (BARTpho model)"),Lwe.forEach(t),leo=i(S),Bn=n(S,"LI",{});var Qx=s(Bn);Dte=n(Qx,"STRONG",{});var JQr=s(Dte);ieo=r(JQr,"bert"),JQr.forEach(t),deo=r(Qx," \u2014 "),gR=n(Qx,"A",{href:!0});var YQr=s(gR);ceo=r(YQr,"BertTokenizer"),YQr.forEach(t),feo=r(Qx," or "),hR=n(Qx,"A",{href:!0});var KQr=s(hR);meo=r(KQr,"BertTokenizerFast"),KQr.forEach(t),geo=r(Qx," (BERT model)"),Qx.forEach(t),heo=i(S),xg=n(S,"LI",{});var xwe=s(xg);Gte=n(xwe,"STRONG",{});var ZQr=s(Gte);peo=r(ZQr,"bert-generation"),ZQr.forEach(t),_eo=r(xwe," \u2014 "),pR=n(xwe,"A",{href:!0});var eHr=s(pR);ueo=r(eHr,"BertGenerationTokenizer"),eHr.forEach(t),beo=r(xwe," (Bert Generation model)"),xwe.forEach(t),veo=i(S),$g=n(S,"LI",{});var $we=s($g);Ote=n($we,"STRONG",{});var oHr=s(Ote);Feo=r(oHr,"bert-japanese"),oHr.forEach(t),Teo=r($we," \u2014 "),_R=n($we,"A",{href:!0});var rHr=s(_R);Meo=r(rHr,"BertJapaneseTokenizer"),rHr.forEach(t),Eeo=r($we," (BertJapanese model)"),$we.forEach(t),Ceo=i(S),kg=n(S,"LI",{});var kwe=s(kg);Vte=n(kwe,"STRONG",{});var tHr=s(Vte);weo=r(tHr,"bertweet"),tHr.forEach(t),Aeo=r(kwe," \u2014 "),uR=n(kwe,"A",{href:!0});var aHr=s(uR);yeo=r(aHr,"BertweetTokenizer"),aHr.forEach(t),Leo=r(kwe," (Bertweet model)"),kwe.forEach(t),xeo=i(S),In=n(S,"LI",{});var Hx=s(In);Xte=n(Hx,"STRONG",{});var nHr=s(Xte);$eo=r(nHr,"big_bird"),nHr.forEach(t),keo=r(Hx," \u2014 "),bR=n(Hx,"A",{href:!0});var sHr=s(bR);Seo=r(sHr,"BigBirdTokenizer"),sHr.forEach(t),Reo=r(Hx," or "),vR=n(Hx,"A",{href:!0});var lHr=s(vR);Peo=r(lHr,"BigBirdTokenizerFast"),lHr.forEach(t),Beo=r(Hx," (BigBird model)"),Hx.forEach(t),Ieo=i(S),Nn=n(S,"LI",{});var Ux=s(Nn);zte=n(Ux,"STRONG",{});var iHr=s(zte);Neo=r(iHr,"bigbird_pegasus"),iHr.forEach(t),qeo=r(Ux," \u2014 "),FR=n(Ux,"A",{href:!0});var dHr=s(FR);jeo=r(dHr,"PegasusTokenizer"),dHr.forEach(t),Deo=r(Ux," or "),TR=n(Ux,"A",{href:!0});var cHr=s(TR);Geo=r(cHr,"PegasusTokenizerFast"),cHr.forEach(t),Oeo=r(Ux," (BigBirdPegasus model)"),Ux.forEach(t),Veo=i(S),qn=n(S,"LI",{});var Jx=s(qn);Wte=n(Jx,"STRONG",{});var fHr=s(Wte);Xeo=r(fHr,"blenderbot"),fHr.forEach(t),zeo=r(Jx," \u2014 "),MR=n(Jx,"A",{href:!0});var mHr=s(MR);Weo=r(mHr,"BlenderbotTokenizer"),mHr.forEach(t),Qeo=r(Jx," or "),ER=n(Jx,"A",{href:!0});var gHr=s(ER);Heo=r(gHr,"BlenderbotTokenizerFast"),gHr.forEach(t),Ueo=r(Jx," (Blenderbot model)"),Jx.forEach(t),Jeo=i(S),Sg=n(S,"LI",{});var Swe=s(Sg);Qte=n(Swe,"STRONG",{});var hHr=s(Qte);Yeo=r(hHr,"blenderbot-small"),hHr.forEach(t),Keo=r(Swe," \u2014 "),CR=n(Swe,"A",{href:!0});var pHr=s(CR);Zeo=r(pHr,"BlenderbotSmallTokenizer"),pHr.forEach(t),eoo=r(Swe," (BlenderbotSmall model)"),Swe.forEach(t),ooo=i(S),Rg=n(S,"LI",{});var Rwe=s(Rg);Hte=n(Rwe,"STRONG",{});var _Hr=s(Hte);roo=r(_Hr,"byt5"),_Hr.forEach(t),too=r(Rwe," \u2014 "),wR=n(Rwe,"A",{href:!0});var uHr=s(wR);aoo=r(uHr,"ByT5Tokenizer"),uHr.forEach(t),noo=r(Rwe," (ByT5 model)"),Rwe.forEach(t),soo=i(S),jn=n(S,"LI",{});var Yx=s(jn);Ute=n(Yx,"STRONG",{});var bHr=s(Ute);loo=r(bHr,"camembert"),bHr.forEach(t),ioo=r(Yx," \u2014 "),AR=n(Yx,"A",{href:!0});var vHr=s(AR);doo=r(vHr,"CamembertTokenizer"),vHr.forEach(t),coo=r(Yx," or "),yR=n(Yx,"A",{href:!0});var FHr=s(yR);foo=r(FHr,"CamembertTokenizerFast"),FHr.forEach(t),moo=r(Yx," (CamemBERT model)"),Yx.forEach(t),goo=i(S),Pg=n(S,"LI",{});var Pwe=s(Pg);Jte=n(Pwe,"STRONG",{});var THr=s(Jte);hoo=r(THr,"canine"),THr.forEach(t),poo=r(Pwe," \u2014 "),LR=n(Pwe,"A",{href:!0});var MHr=s(LR);_oo=r(MHr,"CanineTokenizer"),MHr.forEach(t),uoo=r(Pwe," (Canine model)"),Pwe.forEach(t),boo=i(S),Dn=n(S,"LI",{});var Kx=s(Dn);Yte=n(Kx,"STRONG",{});var EHr=s(Yte);voo=r(EHr,"clip"),EHr.forEach(t),Foo=r(Kx," \u2014 "),xR=n(Kx,"A",{href:!0});var CHr=s(xR);Too=r(CHr,"CLIPTokenizer"),CHr.forEach(t),Moo=r(Kx," or "),$R=n(Kx,"A",{href:!0});var wHr=s($R);Eoo=r(wHr,"CLIPTokenizerFast"),wHr.forEach(t),Coo=r(Kx," (CLIP model)"),Kx.forEach(t),woo=i(S),Gn=n(S,"LI",{});var Zx=s(Gn);Kte=n(Zx,"STRONG",{});var AHr=s(Kte);Aoo=r(AHr,"convbert"),AHr.forEach(t),yoo=r(Zx," \u2014 "),kR=n(Zx,"A",{href:!0});var yHr=s(kR);Loo=r(yHr,"ConvBertTokenizer"),yHr.forEach(t),xoo=r(Zx," or "),SR=n(Zx,"A",{href:!0});var LHr=s(SR);$oo=r(LHr,"ConvBertTokenizerFast"),LHr.forEach(t),koo=r(Zx," (ConvBERT model)"),Zx.forEach(t),Soo=i(S),On=n(S,"LI",{});var e$=s(On);Zte=n(e$,"STRONG",{});var xHr=s(Zte);Roo=r(xHr,"cpm"),xHr.forEach(t),Poo=r(e$," \u2014 "),RR=n(e$,"A",{href:!0});var $Hr=s(RR);Boo=r($Hr,"CpmTokenizer"),$Hr.forEach(t),Ioo=r(e$," or "),PR=n(e$,"A",{href:!0});var kHr=s(PR);Noo=r(kHr,"CpmTokenizerFast"),kHr.forEach(t),qoo=r(e$," (CPM model)"),e$.forEach(t),joo=i(S),Bg=n(S,"LI",{});var Bwe=s(Bg);eae=n(Bwe,"STRONG",{});var SHr=s(eae);Doo=r(SHr,"ctrl"),SHr.forEach(t),Goo=r(Bwe," \u2014 "),BR=n(Bwe,"A",{href:!0});var RHr=s(BR);Ooo=r(RHr,"CTRLTokenizer"),RHr.forEach(t),Voo=r(Bwe," (CTRL model)"),Bwe.forEach(t),Xoo=i(S),Vn=n(S,"LI",{});var o$=s(Vn);oae=n(o$,"STRONG",{});var PHr=s(oae);zoo=r(PHr,"data2vec-text"),PHr.forEach(t),Woo=r(o$," \u2014 "),IR=n(o$,"A",{href:!0});var BHr=s(IR);Qoo=r(BHr,"RobertaTokenizer"),BHr.forEach(t),Hoo=r(o$," or "),NR=n(o$,"A",{href:!0});var IHr=s(NR);Uoo=r(IHr,"RobertaTokenizerFast"),IHr.forEach(t),Joo=r(o$," (Data2VecText model)"),o$.forEach(t),Yoo=i(S),Xn=n(S,"LI",{});var r$=s(Xn);rae=n(r$,"STRONG",{});var NHr=s(rae);Koo=r(NHr,"deberta"),NHr.forEach(t),Zoo=r(r$," \u2014 "),qR=n(r$,"A",{href:!0});var qHr=s(qR);ero=r(qHr,"DebertaTokenizer"),qHr.forEach(t),oro=r(r$," or "),jR=n(r$,"A",{href:!0});var jHr=s(jR);rro=r(jHr,"DebertaTokenizerFast"),jHr.forEach(t),tro=r(r$," (DeBERTa model)"),r$.forEach(t),aro=i(S),zn=n(S,"LI",{});var t$=s(zn);tae=n(t$,"STRONG",{});var DHr=s(tae);nro=r(DHr,"deberta-v2"),DHr.forEach(t),sro=r(t$," \u2014 "),DR=n(t$,"A",{href:!0});var GHr=s(DR);lro=r(GHr,"DebertaV2Tokenizer"),GHr.forEach(t),iro=r(t$," or "),GR=n(t$,"A",{href:!0});var OHr=s(GR);dro=r(OHr,"DebertaV2TokenizerFast"),OHr.forEach(t),cro=r(t$," (DeBERTa-v2 model)"),t$.forEach(t),fro=i(S),Wn=n(S,"LI",{});var a$=s(Wn);aae=n(a$,"STRONG",{});var VHr=s(aae);mro=r(VHr,"distilbert"),VHr.forEach(t),gro=r(a$," \u2014 "),OR=n(a$,"A",{href:!0});var XHr=s(OR);hro=r(XHr,"DistilBertTokenizer"),XHr.forEach(t),pro=r(a$," or "),VR=n(a$,"A",{href:!0});var zHr=s(VR);_ro=r(zHr,"DistilBertTokenizerFast"),zHr.forEach(t),uro=r(a$," (DistilBERT model)"),a$.forEach(t),bro=i(S),Qn=n(S,"LI",{});var n$=s(Qn);nae=n(n$,"STRONG",{});var WHr=s(nae);vro=r(WHr,"dpr"),WHr.forEach(t),Fro=r(n$," \u2014 "),XR=n(n$,"A",{href:!0});var QHr=s(XR);Tro=r(QHr,"DPRQuestionEncoderTokenizer"),QHr.forEach(t),Mro=r(n$," or "),zR=n(n$,"A",{href:!0});var HHr=s(zR);Ero=r(HHr,"DPRQuestionEncoderTokenizerFast"),HHr.forEach(t),Cro=r(n$," (DPR model)"),n$.forEach(t),wro=i(S),Hn=n(S,"LI",{});var s$=s(Hn);sae=n(s$,"STRONG",{});var UHr=s(sae);Aro=r(UHr,"electra"),UHr.forEach(t),yro=r(s$," \u2014 "),WR=n(s$,"A",{href:!0});var JHr=s(WR);Lro=r(JHr,"ElectraTokenizer"),JHr.forEach(t),xro=r(s$," or "),QR=n(s$,"A",{href:!0});var YHr=s(QR);$ro=r(YHr,"ElectraTokenizerFast"),YHr.forEach(t),kro=r(s$," (ELECTRA model)"),s$.forEach(t),Sro=i(S),Ig=n(S,"LI",{});var Iwe=s(Ig);lae=n(Iwe,"STRONG",{});var KHr=s(lae);Rro=r(KHr,"flaubert"),KHr.forEach(t),Pro=r(Iwe," \u2014 "),HR=n(Iwe,"A",{href:!0});var ZHr=s(HR);Bro=r(ZHr,"FlaubertTokenizer"),ZHr.forEach(t),Iro=r(Iwe," (FlauBERT model)"),Iwe.forEach(t),Nro=i(S),Un=n(S,"LI",{});var l$=s(Un);iae=n(l$,"STRONG",{});var eUr=s(iae);qro=r(eUr,"fnet"),eUr.forEach(t),jro=r(l$," \u2014 "),UR=n(l$,"A",{href:!0});var oUr=s(UR);Dro=r(oUr,"FNetTokenizer"),oUr.forEach(t),Gro=r(l$," or "),JR=n(l$,"A",{href:!0});var rUr=s(JR);Oro=r(rUr,"FNetTokenizerFast"),rUr.forEach(t),Vro=r(l$," (FNet model)"),l$.forEach(t),Xro=i(S),Ng=n(S,"LI",{});var Nwe=s(Ng);dae=n(Nwe,"STRONG",{});var tUr=s(dae);zro=r(tUr,"fsmt"),tUr.forEach(t),Wro=r(Nwe," \u2014 "),YR=n(Nwe,"A",{href:!0});var aUr=s(YR);Qro=r(aUr,"FSMTTokenizer"),aUr.forEach(t),Hro=r(Nwe," (FairSeq Machine-Translation model)"),Nwe.forEach(t),Uro=i(S),Jn=n(S,"LI",{});var i$=s(Jn);cae=n(i$,"STRONG",{});var nUr=s(cae);Jro=r(nUr,"funnel"),nUr.forEach(t),Yro=r(i$," \u2014 "),KR=n(i$,"A",{href:!0});var sUr=s(KR);Kro=r(sUr,"FunnelTokenizer"),sUr.forEach(t),Zro=r(i$," or "),ZR=n(i$,"A",{href:!0});var lUr=s(ZR);eto=r(lUr,"FunnelTokenizerFast"),lUr.forEach(t),oto=r(i$," (Funnel Transformer model)"),i$.forEach(t),rto=i(S),Yn=n(S,"LI",{});var d$=s(Yn);fae=n(d$,"STRONG",{});var iUr=s(fae);tto=r(iUr,"gpt2"),iUr.forEach(t),ato=r(d$," \u2014 "),eP=n(d$,"A",{href:!0});var dUr=s(eP);nto=r(dUr,"GPT2Tokenizer"),dUr.forEach(t),sto=r(d$," or "),oP=n(d$,"A",{href:!0});var cUr=s(oP);lto=r(cUr,"GPT2TokenizerFast"),cUr.forEach(t),ito=r(d$," (OpenAI GPT-2 model)"),d$.forEach(t),dto=i(S),Kn=n(S,"LI",{});var c$=s(Kn);mae=n(c$,"STRONG",{});var fUr=s(mae);cto=r(fUr,"gpt_neo"),fUr.forEach(t),fto=r(c$," \u2014 "),rP=n(c$,"A",{href:!0});var mUr=s(rP);mto=r(mUr,"GPT2Tokenizer"),mUr.forEach(t),gto=r(c$," or "),tP=n(c$,"A",{href:!0});var gUr=s(tP);hto=r(gUr,"GPT2TokenizerFast"),gUr.forEach(t),pto=r(c$," (GPT Neo model)"),c$.forEach(t),_to=i(S),qg=n(S,"LI",{});var qwe=s(qg);gae=n(qwe,"STRONG",{});var hUr=s(gae);uto=r(hUr,"gpt_neox"),hUr.forEach(t),bto=r(qwe," \u2014 "),aP=n(qwe,"A",{href:!0});var pUr=s(aP);vto=r(pUr,"GPTNeoXTokenizerFast"),pUr.forEach(t),Fto=r(qwe," (GPT NeoX model)"),qwe.forEach(t),Tto=i(S),Zn=n(S,"LI",{});var f$=s(Zn);hae=n(f$,"STRONG",{});var _Ur=s(hae);Mto=r(_Ur,"gptj"),_Ur.forEach(t),Eto=r(f$," \u2014 "),nP=n(f$,"A",{href:!0});var uUr=s(nP);Cto=r(uUr,"GPT2Tokenizer"),uUr.forEach(t),wto=r(f$," or "),sP=n(f$,"A",{href:!0});var bUr=s(sP);Ato=r(bUr,"GPT2TokenizerFast"),bUr.forEach(t),yto=r(f$," (GPT-J model)"),f$.forEach(t),Lto=i(S),es=n(S,"LI",{});var m$=s(es);pae=n(m$,"STRONG",{});var vUr=s(pae);xto=r(vUr,"herbert"),vUr.forEach(t),$to=r(m$," \u2014 "),lP=n(m$,"A",{href:!0});var FUr=s(lP);kto=r(FUr,"HerbertTokenizer"),FUr.forEach(t),Sto=r(m$," or "),iP=n(m$,"A",{href:!0});var TUr=s(iP);Rto=r(TUr,"HerbertTokenizerFast"),TUr.forEach(t),Pto=r(m$," (HerBERT model)"),m$.forEach(t),Bto=i(S),jg=n(S,"LI",{});var jwe=s(jg);_ae=n(jwe,"STRONG",{});var MUr=s(_ae);Ito=r(MUr,"hubert"),MUr.forEach(t),Nto=r(jwe," \u2014 "),dP=n(jwe,"A",{href:!0});var EUr=s(dP);qto=r(EUr,"Wav2Vec2CTCTokenizer"),EUr.forEach(t),jto=r(jwe," (Hubert model)"),jwe.forEach(t),Dto=i(S),os=n(S,"LI",{});var g$=s(os);uae=n(g$,"STRONG",{});var CUr=s(uae);Gto=r(CUr,"ibert"),CUr.forEach(t),Oto=r(g$," \u2014 "),cP=n(g$,"A",{href:!0});var wUr=s(cP);Vto=r(wUr,"RobertaTokenizer"),wUr.forEach(t),Xto=r(g$," or "),fP=n(g$,"A",{href:!0});var AUr=s(fP);zto=r(AUr,"RobertaTokenizerFast"),AUr.forEach(t),Wto=r(g$," (I-BERT model)"),g$.forEach(t),Qto=i(S),rs=n(S,"LI",{});var h$=s(rs);bae=n(h$,"STRONG",{});var yUr=s(bae);Hto=r(yUr,"layoutlm"),yUr.forEach(t),Uto=r(h$," \u2014 "),mP=n(h$,"A",{href:!0});var LUr=s(mP);Jto=r(LUr,"LayoutLMTokenizer"),LUr.forEach(t),Yto=r(h$," or "),gP=n(h$,"A",{href:!0});var xUr=s(gP);Kto=r(xUr,"LayoutLMTokenizerFast"),xUr.forEach(t),Zto=r(h$," (LayoutLM model)"),h$.forEach(t),eao=i(S),ts=n(S,"LI",{});var p$=s(ts);vae=n(p$,"STRONG",{});var $Ur=s(vae);oao=r($Ur,"layoutlmv2"),$Ur.forEach(t),rao=r(p$," \u2014 "),hP=n(p$,"A",{href:!0});var kUr=s(hP);tao=r(kUr,"LayoutLMv2Tokenizer"),kUr.forEach(t),aao=r(p$," or "),pP=n(p$,"A",{href:!0});var SUr=s(pP);nao=r(SUr,"LayoutLMv2TokenizerFast"),SUr.forEach(t),sao=r(p$," (LayoutLMv2 model)"),p$.forEach(t),lao=i(S),as=n(S,"LI",{});var _$=s(as);Fae=n(_$,"STRONG",{});var RUr=s(Fae);iao=r(RUr,"layoutlmv3"),RUr.forEach(t),dao=r(_$," \u2014 "),_P=n(_$,"A",{href:!0});var PUr=s(_P);cao=r(PUr,"LayoutLMv3Tokenizer"),PUr.forEach(t),fao=r(_$," or "),uP=n(_$,"A",{href:!0});var BUr=s(uP);mao=r(BUr,"LayoutLMv3TokenizerFast"),BUr.forEach(t),gao=r(_$," (LayoutLMv3 model)"),_$.forEach(t),hao=i(S),ns=n(S,"LI",{});var u$=s(ns);Tae=n(u$,"STRONG",{});var IUr=s(Tae);pao=r(IUr,"layoutxlm"),IUr.forEach(t),_ao=r(u$," \u2014 "),bP=n(u$,"A",{href:!0});var NUr=s(bP);uao=r(NUr,"LayoutXLMTokenizer"),NUr.forEach(t),bao=r(u$," or "),vP=n(u$,"A",{href:!0});var qUr=s(vP);vao=r(qUr,"LayoutXLMTokenizerFast"),qUr.forEach(t),Fao=r(u$," (LayoutXLM model)"),u$.forEach(t),Tao=i(S),ss=n(S,"LI",{});var b$=s(ss);Mae=n(b$,"STRONG",{});var jUr=s(Mae);Mao=r(jUr,"led"),jUr.forEach(t),Eao=r(b$," \u2014 "),FP=n(b$,"A",{href:!0});var DUr=s(FP);Cao=r(DUr,"LEDTokenizer"),DUr.forEach(t),wao=r(b$," or "),TP=n(b$,"A",{href:!0});var GUr=s(TP);Aao=r(GUr,"LEDTokenizerFast"),GUr.forEach(t),yao=r(b$," (LED model)"),b$.forEach(t),Lao=i(S),ls=n(S,"LI",{});var v$=s(ls);Eae=n(v$,"STRONG",{});var OUr=s(Eae);xao=r(OUr,"longformer"),OUr.forEach(t),$ao=r(v$," \u2014 "),MP=n(v$,"A",{href:!0});var VUr=s(MP);kao=r(VUr,"LongformerTokenizer"),VUr.forEach(t),Sao=r(v$," or "),EP=n(v$,"A",{href:!0});var XUr=s(EP);Rao=r(XUr,"LongformerTokenizerFast"),XUr.forEach(t),Pao=r(v$," (Longformer model)"),v$.forEach(t),Bao=i(S),Dg=n(S,"LI",{});var Dwe=s(Dg);Cae=n(Dwe,"STRONG",{});var zUr=s(Cae);Iao=r(zUr,"luke"),zUr.forEach(t),Nao=r(Dwe," \u2014 "),CP=n(Dwe,"A",{href:!0});var WUr=s(CP);qao=r(WUr,"LukeTokenizer"),WUr.forEach(t),jao=r(Dwe," (LUKE model)"),Dwe.forEach(t),Dao=i(S),is=n(S,"LI",{});var F$=s(is);wae=n(F$,"STRONG",{});var QUr=s(wae);Gao=r(QUr,"lxmert"),QUr.forEach(t),Oao=r(F$," \u2014 "),wP=n(F$,"A",{href:!0});var HUr=s(wP);Vao=r(HUr,"LxmertTokenizer"),HUr.forEach(t),Xao=r(F$," or "),AP=n(F$,"A",{href:!0});var UUr=s(AP);zao=r(UUr,"LxmertTokenizerFast"),UUr.forEach(t),Wao=r(F$," (LXMERT model)"),F$.forEach(t),Qao=i(S),Gg=n(S,"LI",{});var Gwe=s(Gg);Aae=n(Gwe,"STRONG",{});var JUr=s(Aae);Hao=r(JUr,"m2m_100"),JUr.forEach(t),Uao=r(Gwe," \u2014 "),yP=n(Gwe,"A",{href:!0});var YUr=s(yP);Jao=r(YUr,"M2M100Tokenizer"),YUr.forEach(t),Yao=r(Gwe," (M2M100 model)"),Gwe.forEach(t),Kao=i(S),Og=n(S,"LI",{});var Owe=s(Og);yae=n(Owe,"STRONG",{});var KUr=s(yae);Zao=r(KUr,"marian"),KUr.forEach(t),eno=r(Owe," \u2014 "),LP=n(Owe,"A",{href:!0});var ZUr=s(LP);ono=r(ZUr,"MarianTokenizer"),ZUr.forEach(t),rno=r(Owe," (Marian model)"),Owe.forEach(t),tno=i(S),ds=n(S,"LI",{});var T$=s(ds);Lae=n(T$,"STRONG",{});var eJr=s(Lae);ano=r(eJr,"mbart"),eJr.forEach(t),nno=r(T$," \u2014 "),xP=n(T$,"A",{href:!0});var oJr=s(xP);sno=r(oJr,"MBartTokenizer"),oJr.forEach(t),lno=r(T$," or "),$P=n(T$,"A",{href:!0});var rJr=s($P);ino=r(rJr,"MBartTokenizerFast"),rJr.forEach(t),dno=r(T$," (mBART model)"),T$.forEach(t),cno=i(S),cs=n(S,"LI",{});var M$=s(cs);xae=n(M$,"STRONG",{});var tJr=s(xae);fno=r(tJr,"mbart50"),tJr.forEach(t),mno=r(M$," \u2014 "),kP=n(M$,"A",{href:!0});var aJr=s(kP);gno=r(aJr,"MBart50Tokenizer"),aJr.forEach(t),hno=r(M$," or "),SP=n(M$,"A",{href:!0});var nJr=s(SP);pno=r(nJr,"MBart50TokenizerFast"),nJr.forEach(t),_no=r(M$," (mBART-50 model)"),M$.forEach(t),uno=i(S),fs=n(S,"LI",{});var E$=s(fs);$ae=n(E$,"STRONG",{});var sJr=s($ae);bno=r(sJr,"megatron-bert"),sJr.forEach(t),vno=r(E$," \u2014 "),RP=n(E$,"A",{href:!0});var lJr=s(RP);Fno=r(lJr,"BertTokenizer"),lJr.forEach(t),Tno=r(E$," or "),PP=n(E$,"A",{href:!0});var iJr=s(PP);Mno=r(iJr,"BertTokenizerFast"),iJr.forEach(t),Eno=r(E$," (MegatronBert model)"),E$.forEach(t),Cno=i(S),Vg=n(S,"LI",{});var Vwe=s(Vg);kae=n(Vwe,"STRONG",{});var dJr=s(kae);wno=r(dJr,"mluke"),dJr.forEach(t),Ano=r(Vwe," \u2014 "),BP=n(Vwe,"A",{href:!0});var cJr=s(BP);yno=r(cJr,"MLukeTokenizer"),cJr.forEach(t),Lno=r(Vwe," (mLUKE model)"),Vwe.forEach(t),xno=i(S),ms=n(S,"LI",{});var C$=s(ms);Sae=n(C$,"STRONG",{});var fJr=s(Sae);$no=r(fJr,"mobilebert"),fJr.forEach(t),kno=r(C$," \u2014 "),IP=n(C$,"A",{href:!0});var mJr=s(IP);Sno=r(mJr,"MobileBertTokenizer"),mJr.forEach(t),Rno=r(C$," or "),NP=n(C$,"A",{href:!0});var gJr=s(NP);Pno=r(gJr,"MobileBertTokenizerFast"),gJr.forEach(t),Bno=r(C$," (MobileBERT model)"),C$.forEach(t),Ino=i(S),gs=n(S,"LI",{});var w$=s(gs);Rae=n(w$,"STRONG",{});var hJr=s(Rae);Nno=r(hJr,"mpnet"),hJr.forEach(t),qno=r(w$," \u2014 "),qP=n(w$,"A",{href:!0});var pJr=s(qP);jno=r(pJr,"MPNetTokenizer"),pJr.forEach(t),Dno=r(w$," or "),jP=n(w$,"A",{href:!0});var _Jr=s(jP);Gno=r(_Jr,"MPNetTokenizerFast"),_Jr.forEach(t),Ono=r(w$," (MPNet model)"),w$.forEach(t),Vno=i(S),hs=n(S,"LI",{});var A$=s(hs);Pae=n(A$,"STRONG",{});var uJr=s(Pae);Xno=r(uJr,"mt5"),uJr.forEach(t),zno=r(A$," \u2014 "),DP=n(A$,"A",{href:!0});var bJr=s(DP);Wno=r(bJr,"MT5Tokenizer"),bJr.forEach(t),Qno=r(A$," or "),GP=n(A$,"A",{href:!0});var vJr=s(GP);Hno=r(vJr,"MT5TokenizerFast"),vJr.forEach(t),Uno=r(A$," (mT5 model)"),A$.forEach(t),Jno=i(S),ps=n(S,"LI",{});var y$=s(ps);Bae=n(y$,"STRONG",{});var FJr=s(Bae);Yno=r(FJr,"nystromformer"),FJr.forEach(t),Kno=r(y$," \u2014 "),OP=n(y$,"A",{href:!0});var TJr=s(OP);Zno=r(TJr,"AlbertTokenizer"),TJr.forEach(t),eso=r(y$," or "),VP=n(y$,"A",{href:!0});var MJr=s(VP);oso=r(MJr,"AlbertTokenizerFast"),MJr.forEach(t),rso=r(y$," (Nystromformer model)"),y$.forEach(t),tso=i(S),_s=n(S,"LI",{});var L$=s(_s);Iae=n(L$,"STRONG",{});var EJr=s(Iae);aso=r(EJr,"openai-gpt"),EJr.forEach(t),nso=r(L$," \u2014 "),XP=n(L$,"A",{href:!0});var CJr=s(XP);sso=r(CJr,"OpenAIGPTTokenizer"),CJr.forEach(t),lso=r(L$," or "),zP=n(L$,"A",{href:!0});var wJr=s(zP);iso=r(wJr,"OpenAIGPTTokenizerFast"),wJr.forEach(t),dso=r(L$," (OpenAI GPT model)"),L$.forEach(t),cso=i(S),Xg=n(S,"LI",{});var Xwe=s(Xg);Nae=n(Xwe,"STRONG",{});var AJr=s(Nae);fso=r(AJr,"opt"),AJr.forEach(t),mso=r(Xwe," \u2014 "),WP=n(Xwe,"A",{href:!0});var yJr=s(WP);gso=r(yJr,"GPT2Tokenizer"),yJr.forEach(t),hso=r(Xwe," (OPT model)"),Xwe.forEach(t),pso=i(S),us=n(S,"LI",{});var x$=s(us);qae=n(x$,"STRONG",{});var LJr=s(qae);_so=r(LJr,"pegasus"),LJr.forEach(t),uso=r(x$," \u2014 "),QP=n(x$,"A",{href:!0});var xJr=s(QP);bso=r(xJr,"PegasusTokenizer"),xJr.forEach(t),vso=r(x$," or "),HP=n(x$,"A",{href:!0});var $Jr=s(HP);Fso=r($Jr,"PegasusTokenizerFast"),$Jr.forEach(t),Tso=r(x$," (Pegasus model)"),x$.forEach(t),Mso=i(S),zg=n(S,"LI",{});var zwe=s(zg);jae=n(zwe,"STRONG",{});var kJr=s(jae);Eso=r(kJr,"perceiver"),kJr.forEach(t),Cso=r(zwe," \u2014 "),UP=n(zwe,"A",{href:!0});var SJr=s(UP);wso=r(SJr,"PerceiverTokenizer"),SJr.forEach(t),Aso=r(zwe," (Perceiver model)"),zwe.forEach(t),yso=i(S),Wg=n(S,"LI",{});var Wwe=s(Wg);Dae=n(Wwe,"STRONG",{});var RJr=s(Dae);Lso=r(RJr,"phobert"),RJr.forEach(t),xso=r(Wwe," \u2014 "),JP=n(Wwe,"A",{href:!0});var PJr=s(JP);$so=r(PJr,"PhobertTokenizer"),PJr.forEach(t),kso=r(Wwe," (PhoBERT model)"),Wwe.forEach(t),Sso=i(S),Qg=n(S,"LI",{});var Qwe=s(Qg);Gae=n(Qwe,"STRONG",{});var BJr=s(Gae);Rso=r(BJr,"plbart"),BJr.forEach(t),Pso=r(Qwe," \u2014 "),YP=n(Qwe,"A",{href:!0});var IJr=s(YP);Bso=r(IJr,"PLBartTokenizer"),IJr.forEach(t),Iso=r(Qwe," (PLBart model)"),Qwe.forEach(t),Nso=i(S),Hg=n(S,"LI",{});var Hwe=s(Hg);Oae=n(Hwe,"STRONG",{});var NJr=s(Oae);qso=r(NJr,"prophetnet"),NJr.forEach(t),jso=r(Hwe," \u2014 "),KP=n(Hwe,"A",{href:!0});var qJr=s(KP);Dso=r(qJr,"ProphetNetTokenizer"),qJr.forEach(t),Gso=r(Hwe," (ProphetNet model)"),Hwe.forEach(t),Oso=i(S),bs=n(S,"LI",{});var $$=s(bs);Vae=n($$,"STRONG",{});var jJr=s(Vae);Vso=r(jJr,"qdqbert"),jJr.forEach(t),Xso=r($$," \u2014 "),ZP=n($$,"A",{href:!0});var DJr=s(ZP);zso=r(DJr,"BertTokenizer"),DJr.forEach(t),Wso=r($$," or "),eB=n($$,"A",{href:!0});var GJr=s(eB);Qso=r(GJr,"BertTokenizerFast"),GJr.forEach(t),Hso=r($$," (QDQBert model)"),$$.forEach(t),Uso=i(S),Ug=n(S,"LI",{});var Uwe=s(Ug);Xae=n(Uwe,"STRONG",{});var OJr=s(Xae);Jso=r(OJr,"rag"),OJr.forEach(t),Yso=r(Uwe," \u2014 "),oB=n(Uwe,"A",{href:!0});var VJr=s(oB);Kso=r(VJr,"RagTokenizer"),VJr.forEach(t),Zso=r(Uwe," (RAG model)"),Uwe.forEach(t),elo=i(S),vs=n(S,"LI",{});var k$=s(vs);zae=n(k$,"STRONG",{});var XJr=s(zae);olo=r(XJr,"realm"),XJr.forEach(t),rlo=r(k$," \u2014 "),rB=n(k$,"A",{href:!0});var zJr=s(rB);tlo=r(zJr,"RealmTokenizer"),zJr.forEach(t),alo=r(k$," or "),tB=n(k$,"A",{href:!0});var WJr=s(tB);nlo=r(WJr,"RealmTokenizerFast"),WJr.forEach(t),slo=r(k$," (Realm model)"),k$.forEach(t),llo=i(S),Fs=n(S,"LI",{});var S$=s(Fs);Wae=n(S$,"STRONG",{});var QJr=s(Wae);ilo=r(QJr,"reformer"),QJr.forEach(t),dlo=r(S$," \u2014 "),aB=n(S$,"A",{href:!0});var HJr=s(aB);clo=r(HJr,"ReformerTokenizer"),HJr.forEach(t),flo=r(S$," or "),nB=n(S$,"A",{href:!0});var UJr=s(nB);mlo=r(UJr,"ReformerTokenizerFast"),UJr.forEach(t),glo=r(S$," (Reformer model)"),S$.forEach(t),hlo=i(S),Ts=n(S,"LI",{});var R$=s(Ts);Qae=n(R$,"STRONG",{});var JJr=s(Qae);plo=r(JJr,"rembert"),JJr.forEach(t),_lo=r(R$," \u2014 "),sB=n(R$,"A",{href:!0});var YJr=s(sB);ulo=r(YJr,"RemBertTokenizer"),YJr.forEach(t),blo=r(R$," or "),lB=n(R$,"A",{href:!0});var KJr=s(lB);vlo=r(KJr,"RemBertTokenizerFast"),KJr.forEach(t),Flo=r(R$," (RemBERT model)"),R$.forEach(t),Tlo=i(S),Ms=n(S,"LI",{});var P$=s(Ms);Hae=n(P$,"STRONG",{});var ZJr=s(Hae);Mlo=r(ZJr,"retribert"),ZJr.forEach(t),Elo=r(P$," \u2014 "),iB=n(P$,"A",{href:!0});var eYr=s(iB);Clo=r(eYr,"RetriBertTokenizer"),eYr.forEach(t),wlo=r(P$," or "),dB=n(P$,"A",{href:!0});var oYr=s(dB);Alo=r(oYr,"RetriBertTokenizerFast"),oYr.forEach(t),ylo=r(P$," (RetriBERT model)"),P$.forEach(t),Llo=i(S),Es=n(S,"LI",{});var B$=s(Es);Uae=n(B$,"STRONG",{});var rYr=s(Uae);xlo=r(rYr,"roberta"),rYr.forEach(t),$lo=r(B$," \u2014 "),cB=n(B$,"A",{href:!0});var tYr=s(cB);klo=r(tYr,"RobertaTokenizer"),tYr.forEach(t),Slo=r(B$," or "),fB=n(B$,"A",{href:!0});var aYr=s(fB);Rlo=r(aYr,"RobertaTokenizerFast"),aYr.forEach(t),Plo=r(B$," (RoBERTa model)"),B$.forEach(t),Blo=i(S),Cs=n(S,"LI",{});var I$=s(Cs);Jae=n(I$,"STRONG",{});var nYr=s(Jae);Ilo=r(nYr,"roformer"),nYr.forEach(t),Nlo=r(I$," \u2014 "),mB=n(I$,"A",{href:!0});var sYr=s(mB);qlo=r(sYr,"RoFormerTokenizer"),sYr.forEach(t),jlo=r(I$," or "),gB=n(I$,"A",{href:!0});var lYr=s(gB);Dlo=r(lYr,"RoFormerTokenizerFast"),lYr.forEach(t),Glo=r(I$," (RoFormer model)"),I$.forEach(t),Olo=i(S),Jg=n(S,"LI",{});var Jwe=s(Jg);Yae=n(Jwe,"STRONG",{});var iYr=s(Yae);Vlo=r(iYr,"speech_to_text"),iYr.forEach(t),Xlo=r(Jwe," \u2014 "),hB=n(Jwe,"A",{href:!0});var dYr=s(hB);zlo=r(dYr,"Speech2TextTokenizer"),dYr.forEach(t),Wlo=r(Jwe," (Speech2Text model)"),Jwe.forEach(t),Qlo=i(S),Yg=n(S,"LI",{});var Ywe=s(Yg);Kae=n(Ywe,"STRONG",{});var cYr=s(Kae);Hlo=r(cYr,"speech_to_text_2"),cYr.forEach(t),Ulo=r(Ywe," \u2014 "),pB=n(Ywe,"A",{href:!0});var fYr=s(pB);Jlo=r(fYr,"Speech2Text2Tokenizer"),fYr.forEach(t),Ylo=r(Ywe," (Speech2Text2 model)"),Ywe.forEach(t),Klo=i(S),ws=n(S,"LI",{});var N$=s(ws);Zae=n(N$,"STRONG",{});var mYr=s(Zae);Zlo=r(mYr,"splinter"),mYr.forEach(t),eio=r(N$," \u2014 "),_B=n(N$,"A",{href:!0});var gYr=s(_B);oio=r(gYr,"SplinterTokenizer"),gYr.forEach(t),rio=r(N$," or "),uB=n(N$,"A",{href:!0});var hYr=s(uB);tio=r(hYr,"SplinterTokenizerFast"),hYr.forEach(t),aio=r(N$," (Splinter model)"),N$.forEach(t),nio=i(S),As=n(S,"LI",{});var q$=s(As);ene=n(q$,"STRONG",{});var pYr=s(ene);sio=r(pYr,"squeezebert"),pYr.forEach(t),lio=r(q$," \u2014 "),bB=n(q$,"A",{href:!0});var _Yr=s(bB);iio=r(_Yr,"SqueezeBertTokenizer"),_Yr.forEach(t),dio=r(q$," or "),vB=n(q$,"A",{href:!0});var uYr=s(vB);cio=r(uYr,"SqueezeBertTokenizerFast"),uYr.forEach(t),fio=r(q$," (SqueezeBERT model)"),q$.forEach(t),mio=i(S),ys=n(S,"LI",{});var j$=s(ys);one=n(j$,"STRONG",{});var bYr=s(one);gio=r(bYr,"t5"),bYr.forEach(t),hio=r(j$," \u2014 "),FB=n(j$,"A",{href:!0});var vYr=s(FB);pio=r(vYr,"T5Tokenizer"),vYr.forEach(t),_io=r(j$," or "),TB=n(j$,"A",{href:!0});var FYr=s(TB);uio=r(FYr,"T5TokenizerFast"),FYr.forEach(t),bio=r(j$," (T5 model)"),j$.forEach(t),vio=i(S),Kg=n(S,"LI",{});var Kwe=s(Kg);rne=n(Kwe,"STRONG",{});var TYr=s(rne);Fio=r(TYr,"tapas"),TYr.forEach(t),Tio=r(Kwe," \u2014 "),MB=n(Kwe,"A",{href:!0});var MYr=s(MB);Mio=r(MYr,"TapasTokenizer"),MYr.forEach(t),Eio=r(Kwe," (TAPAS model)"),Kwe.forEach(t),Cio=i(S),Zg=n(S,"LI",{});var Zwe=s(Zg);tne=n(Zwe,"STRONG",{});var EYr=s(tne);wio=r(EYr,"tapex"),EYr.forEach(t),Aio=r(Zwe," \u2014 "),EB=n(Zwe,"A",{href:!0});var CYr=s(EB);yio=r(CYr,"TapexTokenizer"),CYr.forEach(t),Lio=r(Zwe," (TAPEX model)"),Zwe.forEach(t),xio=i(S),eh=n(S,"LI",{});var e0e=s(eh);ane=n(e0e,"STRONG",{});var wYr=s(ane);$io=r(wYr,"transfo-xl"),wYr.forEach(t),kio=r(e0e," \u2014 "),CB=n(e0e,"A",{href:!0});var AYr=s(CB);Sio=r(AYr,"TransfoXLTokenizer"),AYr.forEach(t),Rio=r(e0e," (Transformer-XL model)"),e0e.forEach(t),Pio=i(S),Ls=n(S,"LI",{});var D$=s(Ls);nne=n(D$,"STRONG",{});var yYr=s(nne);Bio=r(yYr,"visual_bert"),yYr.forEach(t),Iio=r(D$," \u2014 "),wB=n(D$,"A",{href:!0});var LYr=s(wB);Nio=r(LYr,"BertTokenizer"),LYr.forEach(t),qio=r(D$," or "),AB=n(D$,"A",{href:!0});var xYr=s(AB);jio=r(xYr,"BertTokenizerFast"),xYr.forEach(t),Dio=r(D$," (VisualBert model)"),D$.forEach(t),Gio=i(S),oh=n(S,"LI",{});var o0e=s(oh);sne=n(o0e,"STRONG",{});var $Yr=s(sne);Oio=r($Yr,"wav2vec2"),$Yr.forEach(t),Vio=r(o0e," \u2014 "),yB=n(o0e,"A",{href:!0});var kYr=s(yB);Xio=r(kYr,"Wav2Vec2CTCTokenizer"),kYr.forEach(t),zio=r(o0e," (Wav2Vec2 model)"),o0e.forEach(t),Wio=i(S),rh=n(S,"LI",{});var r0e=s(rh);lne=n(r0e,"STRONG",{});var SYr=s(lne);Qio=r(SYr,"wav2vec2-conformer"),SYr.forEach(t),Hio=r(r0e," \u2014 "),LB=n(r0e,"A",{href:!0});var RYr=s(LB);Uio=r(RYr,"Wav2Vec2CTCTokenizer"),RYr.forEach(t),Jio=r(r0e," (Wav2Vec2-Conformer model)"),r0e.forEach(t),Yio=i(S),th=n(S,"LI",{});var t0e=s(th);ine=n(t0e,"STRONG",{});var PYr=s(ine);Kio=r(PYr,"wav2vec2_phoneme"),PYr.forEach(t),Zio=r(t0e," \u2014 "),xB=n(t0e,"A",{href:!0});var BYr=s(xB);edo=r(BYr,"Wav2Vec2PhonemeCTCTokenizer"),BYr.forEach(t),odo=r(t0e," (Wav2Vec2Phoneme model)"),t0e.forEach(t),rdo=i(S),xs=n(S,"LI",{});var G$=s(xs);dne=n(G$,"STRONG",{});var IYr=s(dne);tdo=r(IYr,"xglm"),IYr.forEach(t),ado=r(G$," \u2014 "),$B=n(G$,"A",{href:!0});var NYr=s($B);ndo=r(NYr,"XGLMTokenizer"),NYr.forEach(t),sdo=r(G$," or "),kB=n(G$,"A",{href:!0});var qYr=s(kB);ldo=r(qYr,"XGLMTokenizerFast"),qYr.forEach(t),ido=r(G$," (XGLM model)"),G$.forEach(t),ddo=i(S),ah=n(S,"LI",{});var a0e=s(ah);cne=n(a0e,"STRONG",{});var jYr=s(cne);cdo=r(jYr,"xlm"),jYr.forEach(t),fdo=r(a0e," \u2014 "),SB=n(a0e,"A",{href:!0});var DYr=s(SB);mdo=r(DYr,"XLMTokenizer"),DYr.forEach(t),gdo=r(a0e," (XLM model)"),a0e.forEach(t),hdo=i(S),nh=n(S,"LI",{});var n0e=s(nh);fne=n(n0e,"STRONG",{});var GYr=s(fne);pdo=r(GYr,"xlm-prophetnet"),GYr.forEach(t),_do=r(n0e," \u2014 "),RB=n(n0e,"A",{href:!0});var OYr=s(RB);udo=r(OYr,"XLMProphetNetTokenizer"),OYr.forEach(t),bdo=r(n0e," (XLMProphetNet model)"),n0e.forEach(t),vdo=i(S),$s=n(S,"LI",{});var O$=s($s);mne=n(O$,"STRONG",{});var VYr=s(mne);Fdo=r(VYr,"xlm-roberta"),VYr.forEach(t),Tdo=r(O$," \u2014 "),PB=n(O$,"A",{href:!0});var XYr=s(PB);Mdo=r(XYr,"XLMRobertaTokenizer"),XYr.forEach(t),Edo=r(O$," or "),BB=n(O$,"A",{href:!0});var zYr=s(BB);Cdo=r(zYr,"XLMRobertaTokenizerFast"),zYr.forEach(t),wdo=r(O$," (XLM-RoBERTa model)"),O$.forEach(t),Ado=i(S),ks=n(S,"LI",{});var V$=s(ks);gne=n(V$,"STRONG",{});var WYr=s(gne);ydo=r(WYr,"xlm-roberta-xl"),WYr.forEach(t),Ldo=r(V$," \u2014 "),IB=n(V$,"A",{href:!0});var QYr=s(IB);xdo=r(QYr,"RobertaTokenizer"),QYr.forEach(t),$do=r(V$," or "),NB=n(V$,"A",{href:!0});var HYr=s(NB);kdo=r(HYr,"RobertaTokenizerFast"),HYr.forEach(t),Sdo=r(V$," (XLM-RoBERTa-XL model)"),V$.forEach(t),Rdo=i(S),Ss=n(S,"LI",{});var X$=s(Ss);hne=n(X$,"STRONG",{});var UYr=s(hne);Pdo=r(UYr,"xlnet"),UYr.forEach(t),Bdo=r(X$," \u2014 "),qB=n(X$,"A",{href:!0});var JYr=s(qB);Ido=r(JYr,"XLNetTokenizer"),JYr.forEach(t),Ndo=r(X$," or "),jB=n(X$,"A",{href:!0});var YYr=s(jB);qdo=r(YYr,"XLNetTokenizerFast"),YYr.forEach(t),jdo=r(X$," (XLNet model)"),X$.forEach(t),Ddo=i(S),Rs=n(S,"LI",{});var z$=s(Rs);pne=n(z$,"STRONG",{});var KYr=s(pne);Gdo=r(KYr,"yoso"),KYr.forEach(t),Odo=r(z$," \u2014 "),DB=n(z$,"A",{href:!0});var ZYr=s(DB);Vdo=r(ZYr,"AlbertTokenizer"),ZYr.forEach(t),Xdo=r(z$," or "),GB=n(z$,"A",{href:!0});var eKr=s(GB);zdo=r(eKr,"AlbertTokenizerFast"),eKr.forEach(t),Wdo=r(z$," (YOSO model)"),z$.forEach(t),S.forEach(t),Qdo=i(js),T(sh.$$.fragment,js),js.forEach(t),Hdo=i(qs),lh=n(qs,"DIV",{class:!0});var EDe=s(lh);T(XA.$$.fragment,EDe),Udo=i(EDe),_ne=n(EDe,"P",{});var oKr=s(_ne);Jdo=r(oKr,"Register a new tokenizer in this mapping."),oKr.forEach(t),EDe.forEach(t),qs.forEach(t),Cqe=i(f),Ei=n(f,"H2",{class:!0});var CDe=s(Ei);ih=n(CDe,"A",{id:!0,class:!0,href:!0});var rKr=s(ih);une=n(rKr,"SPAN",{});var tKr=s(une);T(zA.$$.fragment,tKr),tKr.forEach(t),rKr.forEach(t),Ydo=i(CDe),bne=n(CDe,"SPAN",{});var aKr=s(bne);Kdo=r(aKr,"AutoFeatureExtractor"),aKr.forEach(t),CDe.forEach(t),wqe=i(f),Ao=n(f,"DIV",{class:!0});var Ds=s(Ao);T(WA.$$.fragment,Ds),Zdo=i(Ds),QA=n(Ds,"P",{});var wDe=s(QA);eco=r(wDe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),OB=n(wDe,"A",{href:!0});var nKr=s(OB);oco=r(nKr,"AutoFeatureExtractor.from_pretrained()"),nKr.forEach(t),rco=r(wDe," class method."),wDe.forEach(t),tco=i(Ds),HA=n(Ds,"P",{});var ADe=s(HA);aco=r(ADe,"This class cannot be instantiated directly using "),vne=n(ADe,"CODE",{});var sKr=s(vne);nco=r(sKr,"__init__()"),sKr.forEach(t),sco=r(ADe," (throws an error)."),ADe.forEach(t),lco=i(Ds),He=n(Ds,"DIV",{class:!0});var Zt=s(He);T(UA.$$.fragment,Zt),ico=i(Zt),Fne=n(Zt,"P",{});var lKr=s(Fne);dco=r(lKr,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),lKr.forEach(t),cco=i(Zt),ya=n(Zt,"P",{});var Pw=s(ya);fco=r(Pw,"The feature extractor class to instantiate is selected based on the "),Tne=n(Pw,"CODE",{});var iKr=s(Tne);mco=r(iKr,"model_type"),iKr.forEach(t),gco=r(Pw,` property of the config object
(either passed as an argument or loaded from `),Mne=n(Pw,"CODE",{});var dKr=s(Mne);hco=r(dKr,"pretrained_model_name_or_path"),dKr.forEach(t),pco=r(Pw,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Ene=n(Pw,"CODE",{});var cKr=s(Ene);_co=r(cKr,"pretrained_model_name_or_path"),cKr.forEach(t),uco=r(Pw,":"),Pw.forEach(t),bco=i(Zt),Y=n(Zt,"UL",{});var Z=s(Y);dh=n(Z,"LI",{});var s0e=s(dh);Cne=n(s0e,"STRONG",{});var fKr=s(Cne);vco=r(fKr,"beit"),fKr.forEach(t),Fco=r(s0e," \u2014 "),VB=n(s0e,"A",{href:!0});var mKr=s(VB);Tco=r(mKr,"BeitFeatureExtractor"),mKr.forEach(t),Mco=r(s0e," (BEiT model)"),s0e.forEach(t),Eco=i(Z),ch=n(Z,"LI",{});var l0e=s(ch);wne=n(l0e,"STRONG",{});var gKr=s(wne);Cco=r(gKr,"clip"),gKr.forEach(t),wco=r(l0e," \u2014 "),XB=n(l0e,"A",{href:!0});var hKr=s(XB);Aco=r(hKr,"CLIPFeatureExtractor"),hKr.forEach(t),yco=r(l0e," (CLIP model)"),l0e.forEach(t),Lco=i(Z),fh=n(Z,"LI",{});var i0e=s(fh);Ane=n(i0e,"STRONG",{});var pKr=s(Ane);xco=r(pKr,"convnext"),pKr.forEach(t),$co=r(i0e," \u2014 "),zB=n(i0e,"A",{href:!0});var _Kr=s(zB);kco=r(_Kr,"ConvNextFeatureExtractor"),_Kr.forEach(t),Sco=r(i0e," (ConvNext model)"),i0e.forEach(t),Rco=i(Z),mh=n(Z,"LI",{});var d0e=s(mh);yne=n(d0e,"STRONG",{});var uKr=s(yne);Pco=r(uKr,"cvt"),uKr.forEach(t),Bco=r(d0e," \u2014 "),WB=n(d0e,"A",{href:!0});var bKr=s(WB);Ico=r(bKr,"ConvNextFeatureExtractor"),bKr.forEach(t),Nco=r(d0e," (CvT model)"),d0e.forEach(t),qco=i(Z),gh=n(Z,"LI",{});var c0e=s(gh);Lne=n(c0e,"STRONG",{});var vKr=s(Lne);jco=r(vKr,"data2vec-audio"),vKr.forEach(t),Dco=r(c0e," \u2014 "),QB=n(c0e,"A",{href:!0});var FKr=s(QB);Gco=r(FKr,"Wav2Vec2FeatureExtractor"),FKr.forEach(t),Oco=r(c0e," (Data2VecAudio model)"),c0e.forEach(t),Vco=i(Z),hh=n(Z,"LI",{});var f0e=s(hh);xne=n(f0e,"STRONG",{});var TKr=s(xne);Xco=r(TKr,"data2vec-vision"),TKr.forEach(t),zco=r(f0e," \u2014 "),HB=n(f0e,"A",{href:!0});var MKr=s(HB);Wco=r(MKr,"BeitFeatureExtractor"),MKr.forEach(t),Qco=r(f0e," (Data2VecVision model)"),f0e.forEach(t),Hco=i(Z),ph=n(Z,"LI",{});var m0e=s(ph);$ne=n(m0e,"STRONG",{});var EKr=s($ne);Uco=r(EKr,"deit"),EKr.forEach(t),Jco=r(m0e," \u2014 "),UB=n(m0e,"A",{href:!0});var CKr=s(UB);Yco=r(CKr,"DeiTFeatureExtractor"),CKr.forEach(t),Kco=r(m0e," (DeiT model)"),m0e.forEach(t),Zco=i(Z),_h=n(Z,"LI",{});var g0e=s(_h);kne=n(g0e,"STRONG",{});var wKr=s(kne);efo=r(wKr,"detr"),wKr.forEach(t),ofo=r(g0e," \u2014 "),JB=n(g0e,"A",{href:!0});var AKr=s(JB);rfo=r(AKr,"DetrFeatureExtractor"),AKr.forEach(t),tfo=r(g0e," (DETR model)"),g0e.forEach(t),afo=i(Z),uh=n(Z,"LI",{});var h0e=s(uh);Sne=n(h0e,"STRONG",{});var yKr=s(Sne);nfo=r(yKr,"dpt"),yKr.forEach(t),sfo=r(h0e," \u2014 "),YB=n(h0e,"A",{href:!0});var LKr=s(YB);lfo=r(LKr,"DPTFeatureExtractor"),LKr.forEach(t),ifo=r(h0e," (DPT model)"),h0e.forEach(t),dfo=i(Z),bh=n(Z,"LI",{});var p0e=s(bh);Rne=n(p0e,"STRONG",{});var xKr=s(Rne);cfo=r(xKr,"flava"),xKr.forEach(t),ffo=r(p0e," \u2014 "),KB=n(p0e,"A",{href:!0});var $Kr=s(KB);mfo=r($Kr,"FlavaFeatureExtractor"),$Kr.forEach(t),gfo=r(p0e," (Flava model)"),p0e.forEach(t),hfo=i(Z),vh=n(Z,"LI",{});var _0e=s(vh);Pne=n(_0e,"STRONG",{});var kKr=s(Pne);pfo=r(kKr,"glpn"),kKr.forEach(t),_fo=r(_0e," \u2014 "),ZB=n(_0e,"A",{href:!0});var SKr=s(ZB);ufo=r(SKr,"GLPNFeatureExtractor"),SKr.forEach(t),bfo=r(_0e," (GLPN model)"),_0e.forEach(t),vfo=i(Z),Fh=n(Z,"LI",{});var u0e=s(Fh);Bne=n(u0e,"STRONG",{});var RKr=s(Bne);Ffo=r(RKr,"hubert"),RKr.forEach(t),Tfo=r(u0e," \u2014 "),eI=n(u0e,"A",{href:!0});var PKr=s(eI);Mfo=r(PKr,"Wav2Vec2FeatureExtractor"),PKr.forEach(t),Efo=r(u0e," (Hubert model)"),u0e.forEach(t),Cfo=i(Z),Th=n(Z,"LI",{});var b0e=s(Th);Ine=n(b0e,"STRONG",{});var BKr=s(Ine);wfo=r(BKr,"imagegpt"),BKr.forEach(t),Afo=r(b0e," \u2014 "),oI=n(b0e,"A",{href:!0});var IKr=s(oI);yfo=r(IKr,"ImageGPTFeatureExtractor"),IKr.forEach(t),Lfo=r(b0e," (ImageGPT model)"),b0e.forEach(t),xfo=i(Z),Mh=n(Z,"LI",{});var v0e=s(Mh);Nne=n(v0e,"STRONG",{});var NKr=s(Nne);$fo=r(NKr,"layoutlmv2"),NKr.forEach(t),kfo=r(v0e," \u2014 "),rI=n(v0e,"A",{href:!0});var qKr=s(rI);Sfo=r(qKr,"LayoutLMv2FeatureExtractor"),qKr.forEach(t),Rfo=r(v0e," (LayoutLMv2 model)"),v0e.forEach(t),Pfo=i(Z),Eh=n(Z,"LI",{});var F0e=s(Eh);qne=n(F0e,"STRONG",{});var jKr=s(qne);Bfo=r(jKr,"layoutlmv3"),jKr.forEach(t),Ifo=r(F0e," \u2014 "),tI=n(F0e,"A",{href:!0});var DKr=s(tI);Nfo=r(DKr,"LayoutLMv3FeatureExtractor"),DKr.forEach(t),qfo=r(F0e," (LayoutLMv3 model)"),F0e.forEach(t),jfo=i(Z),Ch=n(Z,"LI",{});var T0e=s(Ch);jne=n(T0e,"STRONG",{});var GKr=s(jne);Dfo=r(GKr,"levit"),GKr.forEach(t),Gfo=r(T0e," \u2014 "),aI=n(T0e,"A",{href:!0});var OKr=s(aI);Ofo=r(OKr,"LevitFeatureExtractor"),OKr.forEach(t),Vfo=r(T0e," (LeViT model)"),T0e.forEach(t),Xfo=i(Z),wh=n(Z,"LI",{});var M0e=s(wh);Dne=n(M0e,"STRONG",{});var VKr=s(Dne);zfo=r(VKr,"maskformer"),VKr.forEach(t),Wfo=r(M0e," \u2014 "),nI=n(M0e,"A",{href:!0});var XKr=s(nI);Qfo=r(XKr,"MaskFormerFeatureExtractor"),XKr.forEach(t),Hfo=r(M0e," (MaskFormer model)"),M0e.forEach(t),Ufo=i(Z),Ah=n(Z,"LI",{});var E0e=s(Ah);Gne=n(E0e,"STRONG",{});var zKr=s(Gne);Jfo=r(zKr,"perceiver"),zKr.forEach(t),Yfo=r(E0e," \u2014 "),sI=n(E0e,"A",{href:!0});var WKr=s(sI);Kfo=r(WKr,"PerceiverFeatureExtractor"),WKr.forEach(t),Zfo=r(E0e," (Perceiver model)"),E0e.forEach(t),emo=i(Z),yh=n(Z,"LI",{});var C0e=s(yh);One=n(C0e,"STRONG",{});var QKr=s(One);omo=r(QKr,"poolformer"),QKr.forEach(t),rmo=r(C0e," \u2014 "),lI=n(C0e,"A",{href:!0});var HKr=s(lI);tmo=r(HKr,"PoolFormerFeatureExtractor"),HKr.forEach(t),amo=r(C0e," (PoolFormer model)"),C0e.forEach(t),nmo=i(Z),Lh=n(Z,"LI",{});var w0e=s(Lh);Vne=n(w0e,"STRONG",{});var UKr=s(Vne);smo=r(UKr,"regnet"),UKr.forEach(t),lmo=r(w0e," \u2014 "),iI=n(w0e,"A",{href:!0});var JKr=s(iI);imo=r(JKr,"ConvNextFeatureExtractor"),JKr.forEach(t),dmo=r(w0e," (RegNet model)"),w0e.forEach(t),cmo=i(Z),xh=n(Z,"LI",{});var A0e=s(xh);Xne=n(A0e,"STRONG",{});var YKr=s(Xne);fmo=r(YKr,"resnet"),YKr.forEach(t),mmo=r(A0e," \u2014 "),dI=n(A0e,"A",{href:!0});var KKr=s(dI);gmo=r(KKr,"ConvNextFeatureExtractor"),KKr.forEach(t),hmo=r(A0e," (ResNet model)"),A0e.forEach(t),pmo=i(Z),$h=n(Z,"LI",{});var y0e=s($h);zne=n(y0e,"STRONG",{});var ZKr=s(zne);_mo=r(ZKr,"segformer"),ZKr.forEach(t),umo=r(y0e," \u2014 "),cI=n(y0e,"A",{href:!0});var eZr=s(cI);bmo=r(eZr,"SegformerFeatureExtractor"),eZr.forEach(t),vmo=r(y0e," (SegFormer model)"),y0e.forEach(t),Fmo=i(Z),kh=n(Z,"LI",{});var L0e=s(kh);Wne=n(L0e,"STRONG",{});var oZr=s(Wne);Tmo=r(oZr,"speech_to_text"),oZr.forEach(t),Mmo=r(L0e," \u2014 "),fI=n(L0e,"A",{href:!0});var rZr=s(fI);Emo=r(rZr,"Speech2TextFeatureExtractor"),rZr.forEach(t),Cmo=r(L0e," (Speech2Text model)"),L0e.forEach(t),wmo=i(Z),Sh=n(Z,"LI",{});var x0e=s(Sh);Qne=n(x0e,"STRONG",{});var tZr=s(Qne);Amo=r(tZr,"swin"),tZr.forEach(t),ymo=r(x0e," \u2014 "),mI=n(x0e,"A",{href:!0});var aZr=s(mI);Lmo=r(aZr,"ViTFeatureExtractor"),aZr.forEach(t),xmo=r(x0e," (Swin model)"),x0e.forEach(t),$mo=i(Z),Rh=n(Z,"LI",{});var $0e=s(Rh);Hne=n($0e,"STRONG",{});var nZr=s(Hne);kmo=r(nZr,"van"),nZr.forEach(t),Smo=r($0e," \u2014 "),gI=n($0e,"A",{href:!0});var sZr=s(gI);Rmo=r(sZr,"ConvNextFeatureExtractor"),sZr.forEach(t),Pmo=r($0e," (VAN model)"),$0e.forEach(t),Bmo=i(Z),Ph=n(Z,"LI",{});var k0e=s(Ph);Une=n(k0e,"STRONG",{});var lZr=s(Une);Imo=r(lZr,"vit"),lZr.forEach(t),Nmo=r(k0e," \u2014 "),hI=n(k0e,"A",{href:!0});var iZr=s(hI);qmo=r(iZr,"ViTFeatureExtractor"),iZr.forEach(t),jmo=r(k0e," (ViT model)"),k0e.forEach(t),Dmo=i(Z),Bh=n(Z,"LI",{});var S0e=s(Bh);Jne=n(S0e,"STRONG",{});var dZr=s(Jne);Gmo=r(dZr,"vit_mae"),dZr.forEach(t),Omo=r(S0e," \u2014 "),pI=n(S0e,"A",{href:!0});var cZr=s(pI);Vmo=r(cZr,"ViTFeatureExtractor"),cZr.forEach(t),Xmo=r(S0e," (ViTMAE model)"),S0e.forEach(t),zmo=i(Z),Ih=n(Z,"LI",{});var R0e=s(Ih);Yne=n(R0e,"STRONG",{});var fZr=s(Yne);Wmo=r(fZr,"wav2vec2"),fZr.forEach(t),Qmo=r(R0e," \u2014 "),_I=n(R0e,"A",{href:!0});var mZr=s(_I);Hmo=r(mZr,"Wav2Vec2FeatureExtractor"),mZr.forEach(t),Umo=r(R0e," (Wav2Vec2 model)"),R0e.forEach(t),Jmo=i(Z),Nh=n(Z,"LI",{});var P0e=s(Nh);Kne=n(P0e,"STRONG",{});var gZr=s(Kne);Ymo=r(gZr,"wav2vec2-conformer"),gZr.forEach(t),Kmo=r(P0e," \u2014 "),uI=n(P0e,"A",{href:!0});var hZr=s(uI);Zmo=r(hZr,"Wav2Vec2FeatureExtractor"),hZr.forEach(t),ego=r(P0e," (Wav2Vec2-Conformer model)"),P0e.forEach(t),ogo=i(Z),qh=n(Z,"LI",{});var B0e=s(qh);Zne=n(B0e,"STRONG",{});var pZr=s(Zne);rgo=r(pZr,"yolos"),pZr.forEach(t),tgo=r(B0e," \u2014 "),bI=n(B0e,"A",{href:!0});var _Zr=s(bI);ago=r(_Zr,"YolosFeatureExtractor"),_Zr.forEach(t),ngo=r(B0e," (YOLOS model)"),B0e.forEach(t),Z.forEach(t),sgo=i(Zt),T(jh.$$.fragment,Zt),lgo=i(Zt),T(Dh.$$.fragment,Zt),Zt.forEach(t),igo=i(Ds),Gh=n(Ds,"DIV",{class:!0});var yDe=s(Gh);T(JA.$$.fragment,yDe),dgo=i(yDe),ese=n(yDe,"P",{});var uZr=s(ese);cgo=r(uZr,"Register a new feature extractor for this class."),uZr.forEach(t),yDe.forEach(t),Ds.forEach(t),Aqe=i(f),Ci=n(f,"H2",{class:!0});var LDe=s(Ci);Oh=n(LDe,"A",{id:!0,class:!0,href:!0});var bZr=s(Oh);ose=n(bZr,"SPAN",{});var vZr=s(ose);T(YA.$$.fragment,vZr),vZr.forEach(t),bZr.forEach(t),fgo=i(LDe),rse=n(LDe,"SPAN",{});var FZr=s(rse);mgo=r(FZr,"AutoProcessor"),FZr.forEach(t),LDe.forEach(t),yqe=i(f),yo=n(f,"DIV",{class:!0});var Gs=s(yo);T(KA.$$.fragment,Gs),ggo=i(Gs),ZA=n(Gs,"P",{});var xDe=s(ZA);hgo=r(xDe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),vI=n(xDe,"A",{href:!0});var TZr=s(vI);pgo=r(TZr,"AutoProcessor.from_pretrained()"),TZr.forEach(t),_go=r(xDe," class method."),xDe.forEach(t),ugo=i(Gs),ey=n(Gs,"P",{});var $De=s(ey);bgo=r($De,"This class cannot be instantiated directly using "),tse=n($De,"CODE",{});var MZr=s(tse);vgo=r(MZr,"__init__()"),MZr.forEach(t),Fgo=r($De," (throws an error)."),$De.forEach(t),Tgo=i(Gs),Ue=n(Gs,"DIV",{class:!0});var ea=s(Ue);T(oy.$$.fragment,ea),Mgo=i(ea),ase=n(ea,"P",{});var EZr=s(ase);Ego=r(EZr,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),EZr.forEach(t),Cgo=i(ea),wi=n(ea,"P",{});var CZ=s(wi);wgo=r(CZ,"The processor class to instantiate is selected based on the "),nse=n(CZ,"CODE",{});var CZr=s(nse);Ago=r(CZr,"model_type"),CZr.forEach(t),ygo=r(CZ,` property of the config object (either
passed as an argument or loaded from `),sse=n(CZ,"CODE",{});var wZr=s(sse);Lgo=r(wZr,"pretrained_model_name_or_path"),wZr.forEach(t),xgo=r(CZ," if possible):"),CZ.forEach(t),$go=i(ea),he=n(ea,"UL",{});var ue=s(he);Vh=n(ue,"LI",{});var I0e=s(Vh);lse=n(I0e,"STRONG",{});var AZr=s(lse);kgo=r(AZr,"clip"),AZr.forEach(t),Sgo=r(I0e," \u2014 "),FI=n(I0e,"A",{href:!0});var yZr=s(FI);Rgo=r(yZr,"CLIPProcessor"),yZr.forEach(t),Pgo=r(I0e," (CLIP model)"),I0e.forEach(t),Bgo=i(ue),Xh=n(ue,"LI",{});var N0e=s(Xh);ise=n(N0e,"STRONG",{});var LZr=s(ise);Igo=r(LZr,"flava"),LZr.forEach(t),Ngo=r(N0e," \u2014 "),dse=n(N0e,"CODE",{});var xZr=s(dse);qgo=r(xZr,"FLAVAProcessor"),xZr.forEach(t),jgo=r(N0e," (Flava model)"),N0e.forEach(t),Dgo=i(ue),zh=n(ue,"LI",{});var q0e=s(zh);cse=n(q0e,"STRONG",{});var $Zr=s(cse);Ggo=r($Zr,"layoutlmv2"),$Zr.forEach(t),Ogo=r(q0e," \u2014 "),TI=n(q0e,"A",{href:!0});var kZr=s(TI);Vgo=r(kZr,"LayoutLMv2Processor"),kZr.forEach(t),Xgo=r(q0e," (LayoutLMv2 model)"),q0e.forEach(t),zgo=i(ue),Wh=n(ue,"LI",{});var j0e=s(Wh);fse=n(j0e,"STRONG",{});var SZr=s(fse);Wgo=r(SZr,"layoutlmv3"),SZr.forEach(t),Qgo=r(j0e," \u2014 "),MI=n(j0e,"A",{href:!0});var RZr=s(MI);Hgo=r(RZr,"LayoutLMv3Processor"),RZr.forEach(t),Ugo=r(j0e," (LayoutLMv3 model)"),j0e.forEach(t),Jgo=i(ue),Qh=n(ue,"LI",{});var D0e=s(Qh);mse=n(D0e,"STRONG",{});var PZr=s(mse);Ygo=r(PZr,"layoutxlm"),PZr.forEach(t),Kgo=r(D0e," \u2014 "),EI=n(D0e,"A",{href:!0});var BZr=s(EI);Zgo=r(BZr,"LayoutXLMProcessor"),BZr.forEach(t),eho=r(D0e," (LayoutXLM model)"),D0e.forEach(t),oho=i(ue),Hh=n(ue,"LI",{});var G0e=s(Hh);gse=n(G0e,"STRONG",{});var IZr=s(gse);rho=r(IZr,"sew"),IZr.forEach(t),tho=r(G0e," \u2014 "),CI=n(G0e,"A",{href:!0});var NZr=s(CI);aho=r(NZr,"Wav2Vec2Processor"),NZr.forEach(t),nho=r(G0e," (SEW model)"),G0e.forEach(t),sho=i(ue),Uh=n(ue,"LI",{});var O0e=s(Uh);hse=n(O0e,"STRONG",{});var qZr=s(hse);lho=r(qZr,"sew-d"),qZr.forEach(t),iho=r(O0e," \u2014 "),wI=n(O0e,"A",{href:!0});var jZr=s(wI);dho=r(jZr,"Wav2Vec2Processor"),jZr.forEach(t),cho=r(O0e," (SEW-D model)"),O0e.forEach(t),fho=i(ue),Jh=n(ue,"LI",{});var V0e=s(Jh);pse=n(V0e,"STRONG",{});var DZr=s(pse);mho=r(DZr,"speech_to_text"),DZr.forEach(t),gho=r(V0e," \u2014 "),AI=n(V0e,"A",{href:!0});var GZr=s(AI);hho=r(GZr,"Speech2TextProcessor"),GZr.forEach(t),pho=r(V0e," (Speech2Text model)"),V0e.forEach(t),_ho=i(ue),Yh=n(ue,"LI",{});var X0e=s(Yh);_se=n(X0e,"STRONG",{});var OZr=s(_se);uho=r(OZr,"speech_to_text_2"),OZr.forEach(t),bho=r(X0e," \u2014 "),yI=n(X0e,"A",{href:!0});var VZr=s(yI);vho=r(VZr,"Speech2Text2Processor"),VZr.forEach(t),Fho=r(X0e," (Speech2Text2 model)"),X0e.forEach(t),Tho=i(ue),Kh=n(ue,"LI",{});var z0e=s(Kh);use=n(z0e,"STRONG",{});var XZr=s(use);Mho=r(XZr,"trocr"),XZr.forEach(t),Eho=r(z0e," \u2014 "),LI=n(z0e,"A",{href:!0});var zZr=s(LI);Cho=r(zZr,"TrOCRProcessor"),zZr.forEach(t),who=r(z0e," (TrOCR model)"),z0e.forEach(t),Aho=i(ue),Zh=n(ue,"LI",{});var W0e=s(Zh);bse=n(W0e,"STRONG",{});var WZr=s(bse);yho=r(WZr,"unispeech"),WZr.forEach(t),Lho=r(W0e," \u2014 "),xI=n(W0e,"A",{href:!0});var QZr=s(xI);xho=r(QZr,"Wav2Vec2Processor"),QZr.forEach(t),$ho=r(W0e," (UniSpeech model)"),W0e.forEach(t),kho=i(ue),ep=n(ue,"LI",{});var Q0e=s(ep);vse=n(Q0e,"STRONG",{});var HZr=s(vse);Sho=r(HZr,"unispeech-sat"),HZr.forEach(t),Rho=r(Q0e," \u2014 "),$I=n(Q0e,"A",{href:!0});var UZr=s($I);Pho=r(UZr,"Wav2Vec2Processor"),UZr.forEach(t),Bho=r(Q0e," (UniSpeechSat model)"),Q0e.forEach(t),Iho=i(ue),op=n(ue,"LI",{});var H0e=s(op);Fse=n(H0e,"STRONG",{});var JZr=s(Fse);Nho=r(JZr,"vilt"),JZr.forEach(t),qho=r(H0e," \u2014 "),kI=n(H0e,"A",{href:!0});var YZr=s(kI);jho=r(YZr,"ViltProcessor"),YZr.forEach(t),Dho=r(H0e," (ViLT model)"),H0e.forEach(t),Gho=i(ue),rp=n(ue,"LI",{});var U0e=s(rp);Tse=n(U0e,"STRONG",{});var KZr=s(Tse);Oho=r(KZr,"vision-text-dual-encoder"),KZr.forEach(t),Vho=r(U0e," \u2014 "),SI=n(U0e,"A",{href:!0});var ZZr=s(SI);Xho=r(ZZr,"VisionTextDualEncoderProcessor"),ZZr.forEach(t),zho=r(U0e," (VisionTextDualEncoder model)"),U0e.forEach(t),Who=i(ue),tp=n(ue,"LI",{});var J0e=s(tp);Mse=n(J0e,"STRONG",{});var eet=s(Mse);Qho=r(eet,"wav2vec2"),eet.forEach(t),Hho=r(J0e," \u2014 "),RI=n(J0e,"A",{href:!0});var oet=s(RI);Uho=r(oet,"Wav2Vec2Processor"),oet.forEach(t),Jho=r(J0e," (Wav2Vec2 model)"),J0e.forEach(t),Yho=i(ue),ap=n(ue,"LI",{});var Y0e=s(ap);Ese=n(Y0e,"STRONG",{});var ret=s(Ese);Kho=r(ret,"wav2vec2-conformer"),ret.forEach(t),Zho=r(Y0e," \u2014 "),PI=n(Y0e,"A",{href:!0});var tet=s(PI);epo=r(tet,"Wav2Vec2Processor"),tet.forEach(t),opo=r(Y0e," (Wav2Vec2-Conformer model)"),Y0e.forEach(t),rpo=i(ue),np=n(ue,"LI",{});var K0e=s(np);Cse=n(K0e,"STRONG",{});var aet=s(Cse);tpo=r(aet,"wavlm"),aet.forEach(t),apo=r(K0e," \u2014 "),BI=n(K0e,"A",{href:!0});var net=s(BI);npo=r(net,"Wav2Vec2Processor"),net.forEach(t),spo=r(K0e," (WavLM model)"),K0e.forEach(t),ue.forEach(t),lpo=i(ea),T(sp.$$.fragment,ea),ipo=i(ea),T(lp.$$.fragment,ea),ea.forEach(t),dpo=i(Gs),ip=n(Gs,"DIV",{class:!0});var kDe=s(ip);T(ry.$$.fragment,kDe),cpo=i(kDe),wse=n(kDe,"P",{});var set=s(wse);fpo=r(set,"Register a new processor for this class."),set.forEach(t),kDe.forEach(t),Gs.forEach(t),Lqe=i(f),Ai=n(f,"H2",{class:!0});var SDe=s(Ai);dp=n(SDe,"A",{id:!0,class:!0,href:!0});var iet=s(dp);Ase=n(iet,"SPAN",{});var det=s(Ase);T(ty.$$.fragment,det),det.forEach(t),iet.forEach(t),mpo=i(SDe),yse=n(SDe,"SPAN",{});var cet=s(yse);gpo=r(cet,"AutoModel"),cet.forEach(t),SDe.forEach(t),xqe=i(f),Lo=n(f,"DIV",{class:!0});var Os=s(Lo);T(ay.$$.fragment,Os),hpo=i(Os),yi=n(Os,"P",{});var wZ=s(yi);ppo=r(wZ,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),II=n(wZ,"A",{href:!0});var fet=s(II);_po=r(fet,"from_pretrained()"),fet.forEach(t),upo=r(wZ," class method or the "),NI=n(wZ,"A",{href:!0});var met=s(NI);bpo=r(met,"from_config()"),met.forEach(t),vpo=r(wZ,` class
method.`),wZ.forEach(t),Fpo=i(Os),ny=n(Os,"P",{});var RDe=s(ny);Tpo=r(RDe,"This class cannot be instantiated directly using "),Lse=n(RDe,"CODE",{});var get=s(Lse);Mpo=r(get,"__init__()"),get.forEach(t),Epo=r(RDe," (throws an error)."),RDe.forEach(t),Cpo=i(Os),tt=n(Os,"DIV",{class:!0});var Bw=s(tt);T(sy.$$.fragment,Bw),wpo=i(Bw),xse=n(Bw,"P",{});var het=s(xse);Apo=r(het,"Instantiates one of the base model classes of the library from a configuration."),het.forEach(t),ypo=i(Bw),Li=n(Bw,"P",{});var AZ=s(Li);Lpo=r(AZ,`Note:
Loading a model from its configuration file does `),$se=n(AZ,"STRONG",{});var pet=s($se);xpo=r(pet,"not"),pet.forEach(t),$po=r(AZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),qI=n(AZ,"A",{href:!0});var _et=s(qI);kpo=r(_et,"from_pretrained()"),_et.forEach(t),Spo=r(AZ," to load the model weights."),AZ.forEach(t),Rpo=i(Bw),T(cp.$$.fragment,Bw),Bw.forEach(t),Ppo=i(Os),Je=n(Os,"DIV",{class:!0});var oa=s(Je);T(ly.$$.fragment,oa),Bpo=i(oa),kse=n(oa,"P",{});var uet=s(kse);Ipo=r(uet,"Instantiate one of the base model classes of the library from a pretrained model."),uet.forEach(t),Npo=i(oa),La=n(oa,"P",{});var Iw=s(La);qpo=r(Iw,"The model class to instantiate is selected based on the "),Sse=n(Iw,"CODE",{});var bet=s(Sse);jpo=r(bet,"model_type"),bet.forEach(t),Dpo=r(Iw,` property of the config object (either
passed as an argument or loaded from `),Rse=n(Iw,"CODE",{});var vet=s(Rse);Gpo=r(vet,"pretrained_model_name_or_path"),vet.forEach(t),Opo=r(Iw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Pse=n(Iw,"CODE",{});var Fet=s(Pse);Vpo=r(Fet,"pretrained_model_name_or_path"),Fet.forEach(t),Xpo=r(Iw,":"),Iw.forEach(t),zpo=i(oa),x=n(oa,"UL",{});var $=s(x);fp=n($,"LI",{});var Z0e=s(fp);Bse=n(Z0e,"STRONG",{});var Tet=s(Bse);Wpo=r(Tet,"albert"),Tet.forEach(t),Qpo=r(Z0e," \u2014 "),jI=n(Z0e,"A",{href:!0});var Met=s(jI);Hpo=r(Met,"AlbertModel"),Met.forEach(t),Upo=r(Z0e," (ALBERT model)"),Z0e.forEach(t),Jpo=i($),mp=n($,"LI",{});var eAe=s(mp);Ise=n(eAe,"STRONG",{});var Eet=s(Ise);Ypo=r(Eet,"bart"),Eet.forEach(t),Kpo=r(eAe," \u2014 "),DI=n(eAe,"A",{href:!0});var Cet=s(DI);Zpo=r(Cet,"BartModel"),Cet.forEach(t),e_o=r(eAe," (BART model)"),eAe.forEach(t),o_o=i($),gp=n($,"LI",{});var oAe=s(gp);Nse=n(oAe,"STRONG",{});var wet=s(Nse);r_o=r(wet,"beit"),wet.forEach(t),t_o=r(oAe," \u2014 "),GI=n(oAe,"A",{href:!0});var Aet=s(GI);a_o=r(Aet,"BeitModel"),Aet.forEach(t),n_o=r(oAe," (BEiT model)"),oAe.forEach(t),s_o=i($),hp=n($,"LI",{});var rAe=s(hp);qse=n(rAe,"STRONG",{});var yet=s(qse);l_o=r(yet,"bert"),yet.forEach(t),i_o=r(rAe," \u2014 "),OI=n(rAe,"A",{href:!0});var Let=s(OI);d_o=r(Let,"BertModel"),Let.forEach(t),c_o=r(rAe," (BERT model)"),rAe.forEach(t),f_o=i($),pp=n($,"LI",{});var tAe=s(pp);jse=n(tAe,"STRONG",{});var xet=s(jse);m_o=r(xet,"bert-generation"),xet.forEach(t),g_o=r(tAe," \u2014 "),VI=n(tAe,"A",{href:!0});var $et=s(VI);h_o=r($et,"BertGenerationEncoder"),$et.forEach(t),p_o=r(tAe," (Bert Generation model)"),tAe.forEach(t),__o=i($),_p=n($,"LI",{});var aAe=s(_p);Dse=n(aAe,"STRONG",{});var ket=s(Dse);u_o=r(ket,"big_bird"),ket.forEach(t),b_o=r(aAe," \u2014 "),XI=n(aAe,"A",{href:!0});var Set=s(XI);v_o=r(Set,"BigBirdModel"),Set.forEach(t),F_o=r(aAe," (BigBird model)"),aAe.forEach(t),T_o=i($),up=n($,"LI",{});var nAe=s(up);Gse=n(nAe,"STRONG",{});var Ret=s(Gse);M_o=r(Ret,"bigbird_pegasus"),Ret.forEach(t),E_o=r(nAe," \u2014 "),zI=n(nAe,"A",{href:!0});var Pet=s(zI);C_o=r(Pet,"BigBirdPegasusModel"),Pet.forEach(t),w_o=r(nAe," (BigBirdPegasus model)"),nAe.forEach(t),A_o=i($),bp=n($,"LI",{});var sAe=s(bp);Ose=n(sAe,"STRONG",{});var Bet=s(Ose);y_o=r(Bet,"blenderbot"),Bet.forEach(t),L_o=r(sAe," \u2014 "),WI=n(sAe,"A",{href:!0});var Iet=s(WI);x_o=r(Iet,"BlenderbotModel"),Iet.forEach(t),$_o=r(sAe," (Blenderbot model)"),sAe.forEach(t),k_o=i($),vp=n($,"LI",{});var lAe=s(vp);Vse=n(lAe,"STRONG",{});var Net=s(Vse);S_o=r(Net,"blenderbot-small"),Net.forEach(t),R_o=r(lAe," \u2014 "),QI=n(lAe,"A",{href:!0});var qet=s(QI);P_o=r(qet,"BlenderbotSmallModel"),qet.forEach(t),B_o=r(lAe," (BlenderbotSmall model)"),lAe.forEach(t),I_o=i($),Fp=n($,"LI",{});var iAe=s(Fp);Xse=n(iAe,"STRONG",{});var jet=s(Xse);N_o=r(jet,"camembert"),jet.forEach(t),q_o=r(iAe," \u2014 "),HI=n(iAe,"A",{href:!0});var Det=s(HI);j_o=r(Det,"CamembertModel"),Det.forEach(t),D_o=r(iAe," (CamemBERT model)"),iAe.forEach(t),G_o=i($),Tp=n($,"LI",{});var dAe=s(Tp);zse=n(dAe,"STRONG",{});var Get=s(zse);O_o=r(Get,"canine"),Get.forEach(t),V_o=r(dAe," \u2014 "),UI=n(dAe,"A",{href:!0});var Oet=s(UI);X_o=r(Oet,"CanineModel"),Oet.forEach(t),z_o=r(dAe," (Canine model)"),dAe.forEach(t),W_o=i($),Mp=n($,"LI",{});var cAe=s(Mp);Wse=n(cAe,"STRONG",{});var Vet=s(Wse);Q_o=r(Vet,"clip"),Vet.forEach(t),H_o=r(cAe," \u2014 "),JI=n(cAe,"A",{href:!0});var Xet=s(JI);U_o=r(Xet,"CLIPModel"),Xet.forEach(t),J_o=r(cAe," (CLIP model)"),cAe.forEach(t),Y_o=i($),Ep=n($,"LI",{});var fAe=s(Ep);Qse=n(fAe,"STRONG",{});var zet=s(Qse);K_o=r(zet,"convbert"),zet.forEach(t),Z_o=r(fAe," \u2014 "),YI=n(fAe,"A",{href:!0});var Wet=s(YI);euo=r(Wet,"ConvBertModel"),Wet.forEach(t),ouo=r(fAe," (ConvBERT model)"),fAe.forEach(t),ruo=i($),Cp=n($,"LI",{});var mAe=s(Cp);Hse=n(mAe,"STRONG",{});var Qet=s(Hse);tuo=r(Qet,"convnext"),Qet.forEach(t),auo=r(mAe," \u2014 "),KI=n(mAe,"A",{href:!0});var Het=s(KI);nuo=r(Het,"ConvNextModel"),Het.forEach(t),suo=r(mAe," (ConvNext model)"),mAe.forEach(t),luo=i($),wp=n($,"LI",{});var gAe=s(wp);Use=n(gAe,"STRONG",{});var Uet=s(Use);iuo=r(Uet,"ctrl"),Uet.forEach(t),duo=r(gAe," \u2014 "),ZI=n(gAe,"A",{href:!0});var Jet=s(ZI);cuo=r(Jet,"CTRLModel"),Jet.forEach(t),fuo=r(gAe," (CTRL model)"),gAe.forEach(t),muo=i($),Ap=n($,"LI",{});var hAe=s(Ap);Jse=n(hAe,"STRONG",{});var Yet=s(Jse);guo=r(Yet,"cvt"),Yet.forEach(t),huo=r(hAe," \u2014 "),eN=n(hAe,"A",{href:!0});var Ket=s(eN);puo=r(Ket,"CvtModel"),Ket.forEach(t),_uo=r(hAe," (CvT model)"),hAe.forEach(t),uuo=i($),yp=n($,"LI",{});var pAe=s(yp);Yse=n(pAe,"STRONG",{});var Zet=s(Yse);buo=r(Zet,"data2vec-audio"),Zet.forEach(t),vuo=r(pAe," \u2014 "),oN=n(pAe,"A",{href:!0});var eot=s(oN);Fuo=r(eot,"Data2VecAudioModel"),eot.forEach(t),Tuo=r(pAe," (Data2VecAudio model)"),pAe.forEach(t),Muo=i($),Lp=n($,"LI",{});var _Ae=s(Lp);Kse=n(_Ae,"STRONG",{});var oot=s(Kse);Euo=r(oot,"data2vec-text"),oot.forEach(t),Cuo=r(_Ae," \u2014 "),rN=n(_Ae,"A",{href:!0});var rot=s(rN);wuo=r(rot,"Data2VecTextModel"),rot.forEach(t),Auo=r(_Ae," (Data2VecText model)"),_Ae.forEach(t),yuo=i($),xp=n($,"LI",{});var uAe=s(xp);Zse=n(uAe,"STRONG",{});var tot=s(Zse);Luo=r(tot,"data2vec-vision"),tot.forEach(t),xuo=r(uAe," \u2014 "),tN=n(uAe,"A",{href:!0});var aot=s(tN);$uo=r(aot,"Data2VecVisionModel"),aot.forEach(t),kuo=r(uAe," (Data2VecVision model)"),uAe.forEach(t),Suo=i($),$p=n($,"LI",{});var bAe=s($p);ele=n(bAe,"STRONG",{});var not=s(ele);Ruo=r(not,"deberta"),not.forEach(t),Puo=r(bAe," \u2014 "),aN=n(bAe,"A",{href:!0});var sot=s(aN);Buo=r(sot,"DebertaModel"),sot.forEach(t),Iuo=r(bAe," (DeBERTa model)"),bAe.forEach(t),Nuo=i($),kp=n($,"LI",{});var vAe=s(kp);ole=n(vAe,"STRONG",{});var lot=s(ole);quo=r(lot,"deberta-v2"),lot.forEach(t),juo=r(vAe," \u2014 "),nN=n(vAe,"A",{href:!0});var iot=s(nN);Duo=r(iot,"DebertaV2Model"),iot.forEach(t),Guo=r(vAe," (DeBERTa-v2 model)"),vAe.forEach(t),Ouo=i($),Sp=n($,"LI",{});var FAe=s(Sp);rle=n(FAe,"STRONG",{});var dot=s(rle);Vuo=r(dot,"decision_transformer"),dot.forEach(t),Xuo=r(FAe," \u2014 "),sN=n(FAe,"A",{href:!0});var cot=s(sN);zuo=r(cot,"DecisionTransformerModel"),cot.forEach(t),Wuo=r(FAe," (Decision Transformer model)"),FAe.forEach(t),Quo=i($),Rp=n($,"LI",{});var TAe=s(Rp);tle=n(TAe,"STRONG",{});var fot=s(tle);Huo=r(fot,"deit"),fot.forEach(t),Uuo=r(TAe," \u2014 "),lN=n(TAe,"A",{href:!0});var mot=s(lN);Juo=r(mot,"DeiTModel"),mot.forEach(t),Yuo=r(TAe," (DeiT model)"),TAe.forEach(t),Kuo=i($),Pp=n($,"LI",{});var MAe=s(Pp);ale=n(MAe,"STRONG",{});var got=s(ale);Zuo=r(got,"detr"),got.forEach(t),e6o=r(MAe," \u2014 "),iN=n(MAe,"A",{href:!0});var hot=s(iN);o6o=r(hot,"DetrModel"),hot.forEach(t),r6o=r(MAe," (DETR model)"),MAe.forEach(t),t6o=i($),Bp=n($,"LI",{});var EAe=s(Bp);nle=n(EAe,"STRONG",{});var pot=s(nle);a6o=r(pot,"distilbert"),pot.forEach(t),n6o=r(EAe," \u2014 "),dN=n(EAe,"A",{href:!0});var _ot=s(dN);s6o=r(_ot,"DistilBertModel"),_ot.forEach(t),l6o=r(EAe," (DistilBERT model)"),EAe.forEach(t),i6o=i($),Ip=n($,"LI",{});var CAe=s(Ip);sle=n(CAe,"STRONG",{});var uot=s(sle);d6o=r(uot,"dpr"),uot.forEach(t),c6o=r(CAe," \u2014 "),cN=n(CAe,"A",{href:!0});var bot=s(cN);f6o=r(bot,"DPRQuestionEncoder"),bot.forEach(t),m6o=r(CAe," (DPR model)"),CAe.forEach(t),g6o=i($),Np=n($,"LI",{});var wAe=s(Np);lle=n(wAe,"STRONG",{});var vot=s(lle);h6o=r(vot,"dpt"),vot.forEach(t),p6o=r(wAe," \u2014 "),fN=n(wAe,"A",{href:!0});var Fot=s(fN);_6o=r(Fot,"DPTModel"),Fot.forEach(t),u6o=r(wAe," (DPT model)"),wAe.forEach(t),b6o=i($),qp=n($,"LI",{});var AAe=s(qp);ile=n(AAe,"STRONG",{});var Tot=s(ile);v6o=r(Tot,"electra"),Tot.forEach(t),F6o=r(AAe," \u2014 "),mN=n(AAe,"A",{href:!0});var Mot=s(mN);T6o=r(Mot,"ElectraModel"),Mot.forEach(t),M6o=r(AAe," (ELECTRA model)"),AAe.forEach(t),E6o=i($),jp=n($,"LI",{});var yAe=s(jp);dle=n(yAe,"STRONG",{});var Eot=s(dle);C6o=r(Eot,"flaubert"),Eot.forEach(t),w6o=r(yAe," \u2014 "),gN=n(yAe,"A",{href:!0});var Cot=s(gN);A6o=r(Cot,"FlaubertModel"),Cot.forEach(t),y6o=r(yAe," (FlauBERT model)"),yAe.forEach(t),L6o=i($),Dp=n($,"LI",{});var LAe=s(Dp);cle=n(LAe,"STRONG",{});var wot=s(cle);x6o=r(wot,"flava"),wot.forEach(t),$6o=r(LAe," \u2014 "),hN=n(LAe,"A",{href:!0});var Aot=s(hN);k6o=r(Aot,"FlavaModel"),Aot.forEach(t),S6o=r(LAe," (Flava model)"),LAe.forEach(t),R6o=i($),Gp=n($,"LI",{});var xAe=s(Gp);fle=n(xAe,"STRONG",{});var yot=s(fle);P6o=r(yot,"fnet"),yot.forEach(t),B6o=r(xAe," \u2014 "),pN=n(xAe,"A",{href:!0});var Lot=s(pN);I6o=r(Lot,"FNetModel"),Lot.forEach(t),N6o=r(xAe," (FNet model)"),xAe.forEach(t),q6o=i($),Op=n($,"LI",{});var $Ae=s(Op);mle=n($Ae,"STRONG",{});var xot=s(mle);j6o=r(xot,"fsmt"),xot.forEach(t),D6o=r($Ae," \u2014 "),_N=n($Ae,"A",{href:!0});var $ot=s(_N);G6o=r($ot,"FSMTModel"),$ot.forEach(t),O6o=r($Ae," (FairSeq Machine-Translation model)"),$Ae.forEach(t),V6o=i($),Ps=n($,"LI",{});var W$=s(Ps);gle=n(W$,"STRONG",{});var kot=s(gle);X6o=r(kot,"funnel"),kot.forEach(t),z6o=r(W$," \u2014 "),uN=n(W$,"A",{href:!0});var Sot=s(uN);W6o=r(Sot,"FunnelModel"),Sot.forEach(t),Q6o=r(W$," or "),bN=n(W$,"A",{href:!0});var Rot=s(bN);H6o=r(Rot,"FunnelBaseModel"),Rot.forEach(t),U6o=r(W$," (Funnel Transformer model)"),W$.forEach(t),J6o=i($),Vp=n($,"LI",{});var kAe=s(Vp);hle=n(kAe,"STRONG",{});var Pot=s(hle);Y6o=r(Pot,"glpn"),Pot.forEach(t),K6o=r(kAe," \u2014 "),vN=n(kAe,"A",{href:!0});var Bot=s(vN);Z6o=r(Bot,"GLPNModel"),Bot.forEach(t),e1o=r(kAe," (GLPN model)"),kAe.forEach(t),o1o=i($),Xp=n($,"LI",{});var SAe=s(Xp);ple=n(SAe,"STRONG",{});var Iot=s(ple);r1o=r(Iot,"gpt2"),Iot.forEach(t),t1o=r(SAe," \u2014 "),FN=n(SAe,"A",{href:!0});var Not=s(FN);a1o=r(Not,"GPT2Model"),Not.forEach(t),n1o=r(SAe," (OpenAI GPT-2 model)"),SAe.forEach(t),s1o=i($),zp=n($,"LI",{});var RAe=s(zp);_le=n(RAe,"STRONG",{});var qot=s(_le);l1o=r(qot,"gpt_neo"),qot.forEach(t),i1o=r(RAe," \u2014 "),TN=n(RAe,"A",{href:!0});var jot=s(TN);d1o=r(jot,"GPTNeoModel"),jot.forEach(t),c1o=r(RAe," (GPT Neo model)"),RAe.forEach(t),f1o=i($),Wp=n($,"LI",{});var PAe=s(Wp);ule=n(PAe,"STRONG",{});var Dot=s(ule);m1o=r(Dot,"gpt_neox"),Dot.forEach(t),g1o=r(PAe," \u2014 "),MN=n(PAe,"A",{href:!0});var Got=s(MN);h1o=r(Got,"GPTNeoXModel"),Got.forEach(t),p1o=r(PAe," (GPT NeoX model)"),PAe.forEach(t),_1o=i($),Qp=n($,"LI",{});var BAe=s(Qp);ble=n(BAe,"STRONG",{});var Oot=s(ble);u1o=r(Oot,"gptj"),Oot.forEach(t),b1o=r(BAe," \u2014 "),EN=n(BAe,"A",{href:!0});var Vot=s(EN);v1o=r(Vot,"GPTJModel"),Vot.forEach(t),F1o=r(BAe," (GPT-J model)"),BAe.forEach(t),T1o=i($),Hp=n($,"LI",{});var IAe=s(Hp);vle=n(IAe,"STRONG",{});var Xot=s(vle);M1o=r(Xot,"hubert"),Xot.forEach(t),E1o=r(IAe," \u2014 "),CN=n(IAe,"A",{href:!0});var zot=s(CN);C1o=r(zot,"HubertModel"),zot.forEach(t),w1o=r(IAe," (Hubert model)"),IAe.forEach(t),A1o=i($),Up=n($,"LI",{});var NAe=s(Up);Fle=n(NAe,"STRONG",{});var Wot=s(Fle);y1o=r(Wot,"ibert"),Wot.forEach(t),L1o=r(NAe," \u2014 "),wN=n(NAe,"A",{href:!0});var Qot=s(wN);x1o=r(Qot,"IBertModel"),Qot.forEach(t),$1o=r(NAe," (I-BERT model)"),NAe.forEach(t),k1o=i($),Jp=n($,"LI",{});var qAe=s(Jp);Tle=n(qAe,"STRONG",{});var Hot=s(Tle);S1o=r(Hot,"imagegpt"),Hot.forEach(t),R1o=r(qAe," \u2014 "),AN=n(qAe,"A",{href:!0});var Uot=s(AN);P1o=r(Uot,"ImageGPTModel"),Uot.forEach(t),B1o=r(qAe," (ImageGPT model)"),qAe.forEach(t),I1o=i($),Yp=n($,"LI",{});var jAe=s(Yp);Mle=n(jAe,"STRONG",{});var Jot=s(Mle);N1o=r(Jot,"layoutlm"),Jot.forEach(t),q1o=r(jAe," \u2014 "),yN=n(jAe,"A",{href:!0});var Yot=s(yN);j1o=r(Yot,"LayoutLMModel"),Yot.forEach(t),D1o=r(jAe," (LayoutLM model)"),jAe.forEach(t),G1o=i($),Kp=n($,"LI",{});var DAe=s(Kp);Ele=n(DAe,"STRONG",{});var Kot=s(Ele);O1o=r(Kot,"layoutlmv2"),Kot.forEach(t),V1o=r(DAe," \u2014 "),LN=n(DAe,"A",{href:!0});var Zot=s(LN);X1o=r(Zot,"LayoutLMv2Model"),Zot.forEach(t),z1o=r(DAe," (LayoutLMv2 model)"),DAe.forEach(t),W1o=i($),Zp=n($,"LI",{});var GAe=s(Zp);Cle=n(GAe,"STRONG",{});var ert=s(Cle);Q1o=r(ert,"layoutlmv3"),ert.forEach(t),H1o=r(GAe," \u2014 "),xN=n(GAe,"A",{href:!0});var ort=s(xN);U1o=r(ort,"LayoutLMv3Model"),ort.forEach(t),J1o=r(GAe," (LayoutLMv3 model)"),GAe.forEach(t),Y1o=i($),e_=n($,"LI",{});var OAe=s(e_);wle=n(OAe,"STRONG",{});var rrt=s(wle);K1o=r(rrt,"led"),rrt.forEach(t),Z1o=r(OAe," \u2014 "),$N=n(OAe,"A",{href:!0});var trt=s($N);ebo=r(trt,"LEDModel"),trt.forEach(t),obo=r(OAe," (LED model)"),OAe.forEach(t),rbo=i($),o_=n($,"LI",{});var VAe=s(o_);Ale=n(VAe,"STRONG",{});var art=s(Ale);tbo=r(art,"levit"),art.forEach(t),abo=r(VAe," \u2014 "),kN=n(VAe,"A",{href:!0});var nrt=s(kN);nbo=r(nrt,"LevitModel"),nrt.forEach(t),sbo=r(VAe," (LeViT model)"),VAe.forEach(t),lbo=i($),r_=n($,"LI",{});var XAe=s(r_);yle=n(XAe,"STRONG",{});var srt=s(yle);ibo=r(srt,"longformer"),srt.forEach(t),dbo=r(XAe," \u2014 "),SN=n(XAe,"A",{href:!0});var lrt=s(SN);cbo=r(lrt,"LongformerModel"),lrt.forEach(t),fbo=r(XAe," (Longformer model)"),XAe.forEach(t),mbo=i($),t_=n($,"LI",{});var zAe=s(t_);Lle=n(zAe,"STRONG",{});var irt=s(Lle);gbo=r(irt,"luke"),irt.forEach(t),hbo=r(zAe," \u2014 "),RN=n(zAe,"A",{href:!0});var drt=s(RN);pbo=r(drt,"LukeModel"),drt.forEach(t),_bo=r(zAe," (LUKE model)"),zAe.forEach(t),ubo=i($),a_=n($,"LI",{});var WAe=s(a_);xle=n(WAe,"STRONG",{});var crt=s(xle);bbo=r(crt,"lxmert"),crt.forEach(t),vbo=r(WAe," \u2014 "),PN=n(WAe,"A",{href:!0});var frt=s(PN);Fbo=r(frt,"LxmertModel"),frt.forEach(t),Tbo=r(WAe," (LXMERT model)"),WAe.forEach(t),Mbo=i($),n_=n($,"LI",{});var QAe=s(n_);$le=n(QAe,"STRONG",{});var mrt=s($le);Ebo=r(mrt,"m2m_100"),mrt.forEach(t),Cbo=r(QAe," \u2014 "),BN=n(QAe,"A",{href:!0});var grt=s(BN);wbo=r(grt,"M2M100Model"),grt.forEach(t),Abo=r(QAe," (M2M100 model)"),QAe.forEach(t),ybo=i($),s_=n($,"LI",{});var HAe=s(s_);kle=n(HAe,"STRONG",{});var hrt=s(kle);Lbo=r(hrt,"marian"),hrt.forEach(t),xbo=r(HAe," \u2014 "),IN=n(HAe,"A",{href:!0});var prt=s(IN);$bo=r(prt,"MarianModel"),prt.forEach(t),kbo=r(HAe," (Marian model)"),HAe.forEach(t),Sbo=i($),l_=n($,"LI",{});var UAe=s(l_);Sle=n(UAe,"STRONG",{});var _rt=s(Sle);Rbo=r(_rt,"maskformer"),_rt.forEach(t),Pbo=r(UAe," \u2014 "),NN=n(UAe,"A",{href:!0});var urt=s(NN);Bbo=r(urt,"MaskFormerModel"),urt.forEach(t),Ibo=r(UAe," (MaskFormer model)"),UAe.forEach(t),Nbo=i($),i_=n($,"LI",{});var JAe=s(i_);Rle=n(JAe,"STRONG",{});var brt=s(Rle);qbo=r(brt,"mbart"),brt.forEach(t),jbo=r(JAe," \u2014 "),qN=n(JAe,"A",{href:!0});var vrt=s(qN);Dbo=r(vrt,"MBartModel"),vrt.forEach(t),Gbo=r(JAe," (mBART model)"),JAe.forEach(t),Obo=i($),d_=n($,"LI",{});var YAe=s(d_);Ple=n(YAe,"STRONG",{});var Frt=s(Ple);Vbo=r(Frt,"megatron-bert"),Frt.forEach(t),Xbo=r(YAe," \u2014 "),jN=n(YAe,"A",{href:!0});var Trt=s(jN);zbo=r(Trt,"MegatronBertModel"),Trt.forEach(t),Wbo=r(YAe," (MegatronBert model)"),YAe.forEach(t),Qbo=i($),c_=n($,"LI",{});var KAe=s(c_);Ble=n(KAe,"STRONG",{});var Mrt=s(Ble);Hbo=r(Mrt,"mobilebert"),Mrt.forEach(t),Ubo=r(KAe," \u2014 "),DN=n(KAe,"A",{href:!0});var Ert=s(DN);Jbo=r(Ert,"MobileBertModel"),Ert.forEach(t),Ybo=r(KAe," (MobileBERT model)"),KAe.forEach(t),Kbo=i($),f_=n($,"LI",{});var ZAe=s(f_);Ile=n(ZAe,"STRONG",{});var Crt=s(Ile);Zbo=r(Crt,"mpnet"),Crt.forEach(t),e2o=r(ZAe," \u2014 "),GN=n(ZAe,"A",{href:!0});var wrt=s(GN);o2o=r(wrt,"MPNetModel"),wrt.forEach(t),r2o=r(ZAe," (MPNet model)"),ZAe.forEach(t),t2o=i($),m_=n($,"LI",{});var eye=s(m_);Nle=n(eye,"STRONG",{});var Art=s(Nle);a2o=r(Art,"mt5"),Art.forEach(t),n2o=r(eye," \u2014 "),ON=n(eye,"A",{href:!0});var yrt=s(ON);s2o=r(yrt,"MT5Model"),yrt.forEach(t),l2o=r(eye," (mT5 model)"),eye.forEach(t),i2o=i($),g_=n($,"LI",{});var oye=s(g_);qle=n(oye,"STRONG",{});var Lrt=s(qle);d2o=r(Lrt,"nystromformer"),Lrt.forEach(t),c2o=r(oye," \u2014 "),VN=n(oye,"A",{href:!0});var xrt=s(VN);f2o=r(xrt,"NystromformerModel"),xrt.forEach(t),m2o=r(oye," (Nystromformer model)"),oye.forEach(t),g2o=i($),h_=n($,"LI",{});var rye=s(h_);jle=n(rye,"STRONG",{});var $rt=s(jle);h2o=r($rt,"openai-gpt"),$rt.forEach(t),p2o=r(rye," \u2014 "),XN=n(rye,"A",{href:!0});var krt=s(XN);_2o=r(krt,"OpenAIGPTModel"),krt.forEach(t),u2o=r(rye," (OpenAI GPT model)"),rye.forEach(t),b2o=i($),p_=n($,"LI",{});var tye=s(p_);Dle=n(tye,"STRONG",{});var Srt=s(Dle);v2o=r(Srt,"opt"),Srt.forEach(t),F2o=r(tye," \u2014 "),zN=n(tye,"A",{href:!0});var Rrt=s(zN);T2o=r(Rrt,"OPTModel"),Rrt.forEach(t),M2o=r(tye," (OPT model)"),tye.forEach(t),E2o=i($),__=n($,"LI",{});var aye=s(__);Gle=n(aye,"STRONG",{});var Prt=s(Gle);C2o=r(Prt,"pegasus"),Prt.forEach(t),w2o=r(aye," \u2014 "),WN=n(aye,"A",{href:!0});var Brt=s(WN);A2o=r(Brt,"PegasusModel"),Brt.forEach(t),y2o=r(aye," (Pegasus model)"),aye.forEach(t),L2o=i($),u_=n($,"LI",{});var nye=s(u_);Ole=n(nye,"STRONG",{});var Irt=s(Ole);x2o=r(Irt,"perceiver"),Irt.forEach(t),$2o=r(nye," \u2014 "),QN=n(nye,"A",{href:!0});var Nrt=s(QN);k2o=r(Nrt,"PerceiverModel"),Nrt.forEach(t),S2o=r(nye," (Perceiver model)"),nye.forEach(t),R2o=i($),b_=n($,"LI",{});var sye=s(b_);Vle=n(sye,"STRONG",{});var qrt=s(Vle);P2o=r(qrt,"plbart"),qrt.forEach(t),B2o=r(sye," \u2014 "),HN=n(sye,"A",{href:!0});var jrt=s(HN);I2o=r(jrt,"PLBartModel"),jrt.forEach(t),N2o=r(sye," (PLBart model)"),sye.forEach(t),q2o=i($),v_=n($,"LI",{});var lye=s(v_);Xle=n(lye,"STRONG",{});var Drt=s(Xle);j2o=r(Drt,"poolformer"),Drt.forEach(t),D2o=r(lye," \u2014 "),UN=n(lye,"A",{href:!0});var Grt=s(UN);G2o=r(Grt,"PoolFormerModel"),Grt.forEach(t),O2o=r(lye," (PoolFormer model)"),lye.forEach(t),V2o=i($),F_=n($,"LI",{});var iye=s(F_);zle=n(iye,"STRONG",{});var Ort=s(zle);X2o=r(Ort,"prophetnet"),Ort.forEach(t),z2o=r(iye," \u2014 "),JN=n(iye,"A",{href:!0});var Vrt=s(JN);W2o=r(Vrt,"ProphetNetModel"),Vrt.forEach(t),Q2o=r(iye," (ProphetNet model)"),iye.forEach(t),H2o=i($),T_=n($,"LI",{});var dye=s(T_);Wle=n(dye,"STRONG",{});var Xrt=s(Wle);U2o=r(Xrt,"qdqbert"),Xrt.forEach(t),J2o=r(dye," \u2014 "),YN=n(dye,"A",{href:!0});var zrt=s(YN);Y2o=r(zrt,"QDQBertModel"),zrt.forEach(t),K2o=r(dye," (QDQBert model)"),dye.forEach(t),Z2o=i($),M_=n($,"LI",{});var cye=s(M_);Qle=n(cye,"STRONG",{});var Wrt=s(Qle);e4o=r(Wrt,"reformer"),Wrt.forEach(t),o4o=r(cye," \u2014 "),KN=n(cye,"A",{href:!0});var Qrt=s(KN);r4o=r(Qrt,"ReformerModel"),Qrt.forEach(t),t4o=r(cye," (Reformer model)"),cye.forEach(t),a4o=i($),E_=n($,"LI",{});var fye=s(E_);Hle=n(fye,"STRONG",{});var Hrt=s(Hle);n4o=r(Hrt,"regnet"),Hrt.forEach(t),s4o=r(fye," \u2014 "),ZN=n(fye,"A",{href:!0});var Urt=s(ZN);l4o=r(Urt,"RegNetModel"),Urt.forEach(t),i4o=r(fye," (RegNet model)"),fye.forEach(t),d4o=i($),C_=n($,"LI",{});var mye=s(C_);Ule=n(mye,"STRONG",{});var Jrt=s(Ule);c4o=r(Jrt,"rembert"),Jrt.forEach(t),f4o=r(mye," \u2014 "),eq=n(mye,"A",{href:!0});var Yrt=s(eq);m4o=r(Yrt,"RemBertModel"),Yrt.forEach(t),g4o=r(mye," (RemBERT model)"),mye.forEach(t),h4o=i($),w_=n($,"LI",{});var gye=s(w_);Jle=n(gye,"STRONG",{});var Krt=s(Jle);p4o=r(Krt,"resnet"),Krt.forEach(t),_4o=r(gye," \u2014 "),oq=n(gye,"A",{href:!0});var Zrt=s(oq);u4o=r(Zrt,"ResNetModel"),Zrt.forEach(t),b4o=r(gye," (ResNet model)"),gye.forEach(t),v4o=i($),A_=n($,"LI",{});var hye=s(A_);Yle=n(hye,"STRONG",{});var ett=s(Yle);F4o=r(ett,"retribert"),ett.forEach(t),T4o=r(hye," \u2014 "),rq=n(hye,"A",{href:!0});var ott=s(rq);M4o=r(ott,"RetriBertModel"),ott.forEach(t),E4o=r(hye," (RetriBERT model)"),hye.forEach(t),C4o=i($),y_=n($,"LI",{});var pye=s(y_);Kle=n(pye,"STRONG",{});var rtt=s(Kle);w4o=r(rtt,"roberta"),rtt.forEach(t),A4o=r(pye," \u2014 "),tq=n(pye,"A",{href:!0});var ttt=s(tq);y4o=r(ttt,"RobertaModel"),ttt.forEach(t),L4o=r(pye," (RoBERTa model)"),pye.forEach(t),x4o=i($),L_=n($,"LI",{});var _ye=s(L_);Zle=n(_ye,"STRONG",{});var att=s(Zle);$4o=r(att,"roformer"),att.forEach(t),k4o=r(_ye," \u2014 "),aq=n(_ye,"A",{href:!0});var ntt=s(aq);S4o=r(ntt,"RoFormerModel"),ntt.forEach(t),R4o=r(_ye," (RoFormer model)"),_ye.forEach(t),P4o=i($),x_=n($,"LI",{});var uye=s(x_);eie=n(uye,"STRONG",{});var stt=s(eie);B4o=r(stt,"segformer"),stt.forEach(t),I4o=r(uye," \u2014 "),nq=n(uye,"A",{href:!0});var ltt=s(nq);N4o=r(ltt,"SegformerModel"),ltt.forEach(t),q4o=r(uye," (SegFormer model)"),uye.forEach(t),j4o=i($),$_=n($,"LI",{});var bye=s($_);oie=n(bye,"STRONG",{});var itt=s(oie);D4o=r(itt,"sew"),itt.forEach(t),G4o=r(bye," \u2014 "),sq=n(bye,"A",{href:!0});var dtt=s(sq);O4o=r(dtt,"SEWModel"),dtt.forEach(t),V4o=r(bye," (SEW model)"),bye.forEach(t),X4o=i($),k_=n($,"LI",{});var vye=s(k_);rie=n(vye,"STRONG",{});var ctt=s(rie);z4o=r(ctt,"sew-d"),ctt.forEach(t),W4o=r(vye," \u2014 "),lq=n(vye,"A",{href:!0});var ftt=s(lq);Q4o=r(ftt,"SEWDModel"),ftt.forEach(t),H4o=r(vye," (SEW-D model)"),vye.forEach(t),U4o=i($),S_=n($,"LI",{});var Fye=s(S_);tie=n(Fye,"STRONG",{});var mtt=s(tie);J4o=r(mtt,"speech_to_text"),mtt.forEach(t),Y4o=r(Fye," \u2014 "),iq=n(Fye,"A",{href:!0});var gtt=s(iq);K4o=r(gtt,"Speech2TextModel"),gtt.forEach(t),Z4o=r(Fye," (Speech2Text model)"),Fye.forEach(t),evo=i($),R_=n($,"LI",{});var Tye=s(R_);aie=n(Tye,"STRONG",{});var htt=s(aie);ovo=r(htt,"splinter"),htt.forEach(t),rvo=r(Tye," \u2014 "),dq=n(Tye,"A",{href:!0});var ptt=s(dq);tvo=r(ptt,"SplinterModel"),ptt.forEach(t),avo=r(Tye," (Splinter model)"),Tye.forEach(t),nvo=i($),P_=n($,"LI",{});var Mye=s(P_);nie=n(Mye,"STRONG",{});var _tt=s(nie);svo=r(_tt,"squeezebert"),_tt.forEach(t),lvo=r(Mye," \u2014 "),cq=n(Mye,"A",{href:!0});var utt=s(cq);ivo=r(utt,"SqueezeBertModel"),utt.forEach(t),dvo=r(Mye," (SqueezeBERT model)"),Mye.forEach(t),cvo=i($),B_=n($,"LI",{});var Eye=s(B_);sie=n(Eye,"STRONG",{});var btt=s(sie);fvo=r(btt,"swin"),btt.forEach(t),mvo=r(Eye," \u2014 "),fq=n(Eye,"A",{href:!0});var vtt=s(fq);gvo=r(vtt,"SwinModel"),vtt.forEach(t),hvo=r(Eye," (Swin model)"),Eye.forEach(t),pvo=i($),I_=n($,"LI",{});var Cye=s(I_);lie=n(Cye,"STRONG",{});var Ftt=s(lie);_vo=r(Ftt,"t5"),Ftt.forEach(t),uvo=r(Cye," \u2014 "),mq=n(Cye,"A",{href:!0});var Ttt=s(mq);bvo=r(Ttt,"T5Model"),Ttt.forEach(t),vvo=r(Cye," (T5 model)"),Cye.forEach(t),Fvo=i($),N_=n($,"LI",{});var wye=s(N_);iie=n(wye,"STRONG",{});var Mtt=s(iie);Tvo=r(Mtt,"tapas"),Mtt.forEach(t),Mvo=r(wye," \u2014 "),gq=n(wye,"A",{href:!0});var Ett=s(gq);Evo=r(Ett,"TapasModel"),Ett.forEach(t),Cvo=r(wye," (TAPAS model)"),wye.forEach(t),wvo=i($),q_=n($,"LI",{});var Aye=s(q_);die=n(Aye,"STRONG",{});var Ctt=s(die);Avo=r(Ctt,"trajectory_transformer"),Ctt.forEach(t),yvo=r(Aye," \u2014 "),hq=n(Aye,"A",{href:!0});var wtt=s(hq);Lvo=r(wtt,"TrajectoryTransformerModel"),wtt.forEach(t),xvo=r(Aye," (Trajectory Transformer model)"),Aye.forEach(t),$vo=i($),j_=n($,"LI",{});var yye=s(j_);cie=n(yye,"STRONG",{});var Att=s(cie);kvo=r(Att,"transfo-xl"),Att.forEach(t),Svo=r(yye," \u2014 "),pq=n(yye,"A",{href:!0});var ytt=s(pq);Rvo=r(ytt,"TransfoXLModel"),ytt.forEach(t),Pvo=r(yye," (Transformer-XL model)"),yye.forEach(t),Bvo=i($),D_=n($,"LI",{});var Lye=s(D_);fie=n(Lye,"STRONG",{});var Ltt=s(fie);Ivo=r(Ltt,"unispeech"),Ltt.forEach(t),Nvo=r(Lye," \u2014 "),_q=n(Lye,"A",{href:!0});var xtt=s(_q);qvo=r(xtt,"UniSpeechModel"),xtt.forEach(t),jvo=r(Lye," (UniSpeech model)"),Lye.forEach(t),Dvo=i($),G_=n($,"LI",{});var xye=s(G_);mie=n(xye,"STRONG",{});var $tt=s(mie);Gvo=r($tt,"unispeech-sat"),$tt.forEach(t),Ovo=r(xye," \u2014 "),uq=n(xye,"A",{href:!0});var ktt=s(uq);Vvo=r(ktt,"UniSpeechSatModel"),ktt.forEach(t),Xvo=r(xye," (UniSpeechSat model)"),xye.forEach(t),zvo=i($),O_=n($,"LI",{});var $ye=s(O_);gie=n($ye,"STRONG",{});var Stt=s(gie);Wvo=r(Stt,"van"),Stt.forEach(t),Qvo=r($ye," \u2014 "),bq=n($ye,"A",{href:!0});var Rtt=s(bq);Hvo=r(Rtt,"VanModel"),Rtt.forEach(t),Uvo=r($ye," (VAN model)"),$ye.forEach(t),Jvo=i($),V_=n($,"LI",{});var kye=s(V_);hie=n(kye,"STRONG",{});var Ptt=s(hie);Yvo=r(Ptt,"vilt"),Ptt.forEach(t),Kvo=r(kye," \u2014 "),vq=n(kye,"A",{href:!0});var Btt=s(vq);Zvo=r(Btt,"ViltModel"),Btt.forEach(t),eFo=r(kye," (ViLT model)"),kye.forEach(t),oFo=i($),X_=n($,"LI",{});var Sye=s(X_);pie=n(Sye,"STRONG",{});var Itt=s(pie);rFo=r(Itt,"vision-text-dual-encoder"),Itt.forEach(t),tFo=r(Sye," \u2014 "),Fq=n(Sye,"A",{href:!0});var Ntt=s(Fq);aFo=r(Ntt,"VisionTextDualEncoderModel"),Ntt.forEach(t),nFo=r(Sye," (VisionTextDualEncoder model)"),Sye.forEach(t),sFo=i($),z_=n($,"LI",{});var Rye=s(z_);_ie=n(Rye,"STRONG",{});var qtt=s(_ie);lFo=r(qtt,"visual_bert"),qtt.forEach(t),iFo=r(Rye," \u2014 "),Tq=n(Rye,"A",{href:!0});var jtt=s(Tq);dFo=r(jtt,"VisualBertModel"),jtt.forEach(t),cFo=r(Rye," (VisualBert model)"),Rye.forEach(t),fFo=i($),W_=n($,"LI",{});var Pye=s(W_);uie=n(Pye,"STRONG",{});var Dtt=s(uie);mFo=r(Dtt,"vit"),Dtt.forEach(t),gFo=r(Pye," \u2014 "),Mq=n(Pye,"A",{href:!0});var Gtt=s(Mq);hFo=r(Gtt,"ViTModel"),Gtt.forEach(t),pFo=r(Pye," (ViT model)"),Pye.forEach(t),_Fo=i($),Q_=n($,"LI",{});var Bye=s(Q_);bie=n(Bye,"STRONG",{});var Ott=s(bie);uFo=r(Ott,"vit_mae"),Ott.forEach(t),bFo=r(Bye," \u2014 "),Eq=n(Bye,"A",{href:!0});var Vtt=s(Eq);vFo=r(Vtt,"ViTMAEModel"),Vtt.forEach(t),FFo=r(Bye," (ViTMAE model)"),Bye.forEach(t),TFo=i($),H_=n($,"LI",{});var Iye=s(H_);vie=n(Iye,"STRONG",{});var Xtt=s(vie);MFo=r(Xtt,"wav2vec2"),Xtt.forEach(t),EFo=r(Iye," \u2014 "),Cq=n(Iye,"A",{href:!0});var ztt=s(Cq);CFo=r(ztt,"Wav2Vec2Model"),ztt.forEach(t),wFo=r(Iye," (Wav2Vec2 model)"),Iye.forEach(t),AFo=i($),U_=n($,"LI",{});var Nye=s(U_);Fie=n(Nye,"STRONG",{});var Wtt=s(Fie);yFo=r(Wtt,"wav2vec2-conformer"),Wtt.forEach(t),LFo=r(Nye," \u2014 "),wq=n(Nye,"A",{href:!0});var Qtt=s(wq);xFo=r(Qtt,"Wav2Vec2ConformerModel"),Qtt.forEach(t),$Fo=r(Nye," (Wav2Vec2-Conformer model)"),Nye.forEach(t),kFo=i($),J_=n($,"LI",{});var qye=s(J_);Tie=n(qye,"STRONG",{});var Htt=s(Tie);SFo=r(Htt,"wavlm"),Htt.forEach(t),RFo=r(qye," \u2014 "),Aq=n(qye,"A",{href:!0});var Utt=s(Aq);PFo=r(Utt,"WavLMModel"),Utt.forEach(t),BFo=r(qye," (WavLM model)"),qye.forEach(t),IFo=i($),Y_=n($,"LI",{});var jye=s(Y_);Mie=n(jye,"STRONG",{});var Jtt=s(Mie);NFo=r(Jtt,"xglm"),Jtt.forEach(t),qFo=r(jye," \u2014 "),yq=n(jye,"A",{href:!0});var Ytt=s(yq);jFo=r(Ytt,"XGLMModel"),Ytt.forEach(t),DFo=r(jye," (XGLM model)"),jye.forEach(t),GFo=i($),K_=n($,"LI",{});var Dye=s(K_);Eie=n(Dye,"STRONG",{});var Ktt=s(Eie);OFo=r(Ktt,"xlm"),Ktt.forEach(t),VFo=r(Dye," \u2014 "),Lq=n(Dye,"A",{href:!0});var Ztt=s(Lq);XFo=r(Ztt,"XLMModel"),Ztt.forEach(t),zFo=r(Dye," (XLM model)"),Dye.forEach(t),WFo=i($),Z_=n($,"LI",{});var Gye=s(Z_);Cie=n(Gye,"STRONG",{});var eat=s(Cie);QFo=r(eat,"xlm-prophetnet"),eat.forEach(t),HFo=r(Gye," \u2014 "),xq=n(Gye,"A",{href:!0});var oat=s(xq);UFo=r(oat,"XLMProphetNetModel"),oat.forEach(t),JFo=r(Gye," (XLMProphetNet model)"),Gye.forEach(t),YFo=i($),eu=n($,"LI",{});var Oye=s(eu);wie=n(Oye,"STRONG",{});var rat=s(wie);KFo=r(rat,"xlm-roberta"),rat.forEach(t),ZFo=r(Oye," \u2014 "),$q=n(Oye,"A",{href:!0});var tat=s($q);eTo=r(tat,"XLMRobertaModel"),tat.forEach(t),oTo=r(Oye," (XLM-RoBERTa model)"),Oye.forEach(t),rTo=i($),ou=n($,"LI",{});var Vye=s(ou);Aie=n(Vye,"STRONG",{});var aat=s(Aie);tTo=r(aat,"xlm-roberta-xl"),aat.forEach(t),aTo=r(Vye," \u2014 "),kq=n(Vye,"A",{href:!0});var nat=s(kq);nTo=r(nat,"XLMRobertaXLModel"),nat.forEach(t),sTo=r(Vye," (XLM-RoBERTa-XL model)"),Vye.forEach(t),lTo=i($),ru=n($,"LI",{});var Xye=s(ru);yie=n(Xye,"STRONG",{});var sat=s(yie);iTo=r(sat,"xlnet"),sat.forEach(t),dTo=r(Xye," \u2014 "),Sq=n(Xye,"A",{href:!0});var lat=s(Sq);cTo=r(lat,"XLNetModel"),lat.forEach(t),fTo=r(Xye," (XLNet model)"),Xye.forEach(t),mTo=i($),tu=n($,"LI",{});var zye=s(tu);Lie=n(zye,"STRONG",{});var iat=s(Lie);gTo=r(iat,"yolos"),iat.forEach(t),hTo=r(zye," \u2014 "),Rq=n(zye,"A",{href:!0});var dat=s(Rq);pTo=r(dat,"YolosModel"),dat.forEach(t),_To=r(zye," (YOLOS model)"),zye.forEach(t),uTo=i($),au=n($,"LI",{});var Wye=s(au);xie=n(Wye,"STRONG",{});var cat=s(xie);bTo=r(cat,"yoso"),cat.forEach(t),vTo=r(Wye," \u2014 "),Pq=n(Wye,"A",{href:!0});var fat=s(Pq);FTo=r(fat,"YosoModel"),fat.forEach(t),TTo=r(Wye," (YOSO model)"),Wye.forEach(t),$.forEach(t),MTo=i(oa),nu=n(oa,"P",{});var Qye=s(nu);ETo=r(Qye,"The model is set in evaluation mode by default using "),$ie=n(Qye,"CODE",{});var mat=s($ie);CTo=r(mat,"model.eval()"),mat.forEach(t),wTo=r(Qye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kie=n(Qye,"CODE",{});var gat=s(kie);ATo=r(gat,"model.train()"),gat.forEach(t),Qye.forEach(t),yTo=i(oa),T(su.$$.fragment,oa),oa.forEach(t),Os.forEach(t),$qe=i(f),xi=n(f,"H2",{class:!0});var PDe=s(xi);lu=n(PDe,"A",{id:!0,class:!0,href:!0});var hat=s(lu);Sie=n(hat,"SPAN",{});var pat=s(Sie);T(iy.$$.fragment,pat),pat.forEach(t),hat.forEach(t),LTo=i(PDe),Rie=n(PDe,"SPAN",{});var _at=s(Rie);xTo=r(_at,"AutoModelForPreTraining"),_at.forEach(t),PDe.forEach(t),kqe=i(f),xo=n(f,"DIV",{class:!0});var Vs=s(xo);T(dy.$$.fragment,Vs),$To=i(Vs),$i=n(Vs,"P",{});var yZ=s($i);kTo=r(yZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Bq=n(yZ,"A",{href:!0});var uat=s(Bq);STo=r(uat,"from_pretrained()"),uat.forEach(t),RTo=r(yZ," class method or the "),Iq=n(yZ,"A",{href:!0});var bat=s(Iq);PTo=r(bat,"from_config()"),bat.forEach(t),BTo=r(yZ,` class
method.`),yZ.forEach(t),ITo=i(Vs),cy=n(Vs,"P",{});var BDe=s(cy);NTo=r(BDe,"This class cannot be instantiated directly using "),Pie=n(BDe,"CODE",{});var vat=s(Pie);qTo=r(vat,"__init__()"),vat.forEach(t),jTo=r(BDe," (throws an error)."),BDe.forEach(t),DTo=i(Vs),at=n(Vs,"DIV",{class:!0});var Nw=s(at);T(fy.$$.fragment,Nw),GTo=i(Nw),Bie=n(Nw,"P",{});var Fat=s(Bie);OTo=r(Fat,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Fat.forEach(t),VTo=i(Nw),ki=n(Nw,"P",{});var LZ=s(ki);XTo=r(LZ,`Note:
Loading a model from its configuration file does `),Iie=n(LZ,"STRONG",{});var Tat=s(Iie);zTo=r(Tat,"not"),Tat.forEach(t),WTo=r(LZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Nq=n(LZ,"A",{href:!0});var Mat=s(Nq);QTo=r(Mat,"from_pretrained()"),Mat.forEach(t),HTo=r(LZ," to load the model weights."),LZ.forEach(t),UTo=i(Nw),T(iu.$$.fragment,Nw),Nw.forEach(t),JTo=i(Vs),Ye=n(Vs,"DIV",{class:!0});var ra=s(Ye);T(my.$$.fragment,ra),YTo=i(ra),Nie=n(ra,"P",{});var Eat=s(Nie);KTo=r(Eat,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Eat.forEach(t),ZTo=i(ra),xa=n(ra,"P",{});var qw=s(xa);e7o=r(qw,"The model class to instantiate is selected based on the "),qie=n(qw,"CODE",{});var Cat=s(qie);o7o=r(Cat,"model_type"),Cat.forEach(t),r7o=r(qw,` property of the config object (either
passed as an argument or loaded from `),jie=n(qw,"CODE",{});var wat=s(jie);t7o=r(wat,"pretrained_model_name_or_path"),wat.forEach(t),a7o=r(qw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Die=n(qw,"CODE",{});var Aat=s(Die);n7o=r(Aat,"pretrained_model_name_or_path"),Aat.forEach(t),s7o=r(qw,":"),qw.forEach(t),l7o=i(ra),G=n(ra,"UL",{});var O=s(G);du=n(O,"LI",{});var Hye=s(du);Gie=n(Hye,"STRONG",{});var yat=s(Gie);i7o=r(yat,"albert"),yat.forEach(t),d7o=r(Hye," \u2014 "),qq=n(Hye,"A",{href:!0});var Lat=s(qq);c7o=r(Lat,"AlbertForPreTraining"),Lat.forEach(t),f7o=r(Hye," (ALBERT model)"),Hye.forEach(t),m7o=i(O),cu=n(O,"LI",{});var Uye=s(cu);Oie=n(Uye,"STRONG",{});var xat=s(Oie);g7o=r(xat,"bart"),xat.forEach(t),h7o=r(Uye," \u2014 "),jq=n(Uye,"A",{href:!0});var $at=s(jq);p7o=r($at,"BartForConditionalGeneration"),$at.forEach(t),_7o=r(Uye," (BART model)"),Uye.forEach(t),u7o=i(O),fu=n(O,"LI",{});var Jye=s(fu);Vie=n(Jye,"STRONG",{});var kat=s(Vie);b7o=r(kat,"bert"),kat.forEach(t),v7o=r(Jye," \u2014 "),Dq=n(Jye,"A",{href:!0});var Sat=s(Dq);F7o=r(Sat,"BertForPreTraining"),Sat.forEach(t),T7o=r(Jye," (BERT model)"),Jye.forEach(t),M7o=i(O),mu=n(O,"LI",{});var Yye=s(mu);Xie=n(Yye,"STRONG",{});var Rat=s(Xie);E7o=r(Rat,"big_bird"),Rat.forEach(t),C7o=r(Yye," \u2014 "),Gq=n(Yye,"A",{href:!0});var Pat=s(Gq);w7o=r(Pat,"BigBirdForPreTraining"),Pat.forEach(t),A7o=r(Yye," (BigBird model)"),Yye.forEach(t),y7o=i(O),gu=n(O,"LI",{});var Kye=s(gu);zie=n(Kye,"STRONG",{});var Bat=s(zie);L7o=r(Bat,"camembert"),Bat.forEach(t),x7o=r(Kye," \u2014 "),Oq=n(Kye,"A",{href:!0});var Iat=s(Oq);$7o=r(Iat,"CamembertForMaskedLM"),Iat.forEach(t),k7o=r(Kye," (CamemBERT model)"),Kye.forEach(t),S7o=i(O),hu=n(O,"LI",{});var Zye=s(hu);Wie=n(Zye,"STRONG",{});var Nat=s(Wie);R7o=r(Nat,"ctrl"),Nat.forEach(t),P7o=r(Zye," \u2014 "),Vq=n(Zye,"A",{href:!0});var qat=s(Vq);B7o=r(qat,"CTRLLMHeadModel"),qat.forEach(t),I7o=r(Zye," (CTRL model)"),Zye.forEach(t),N7o=i(O),pu=n(O,"LI",{});var eLe=s(pu);Qie=n(eLe,"STRONG",{});var jat=s(Qie);q7o=r(jat,"data2vec-text"),jat.forEach(t),j7o=r(eLe," \u2014 "),Xq=n(eLe,"A",{href:!0});var Dat=s(Xq);D7o=r(Dat,"Data2VecTextForMaskedLM"),Dat.forEach(t),G7o=r(eLe," (Data2VecText model)"),eLe.forEach(t),O7o=i(O),_u=n(O,"LI",{});var oLe=s(_u);Hie=n(oLe,"STRONG",{});var Gat=s(Hie);V7o=r(Gat,"deberta"),Gat.forEach(t),X7o=r(oLe," \u2014 "),zq=n(oLe,"A",{href:!0});var Oat=s(zq);z7o=r(Oat,"DebertaForMaskedLM"),Oat.forEach(t),W7o=r(oLe," (DeBERTa model)"),oLe.forEach(t),Q7o=i(O),uu=n(O,"LI",{});var rLe=s(uu);Uie=n(rLe,"STRONG",{});var Vat=s(Uie);H7o=r(Vat,"deberta-v2"),Vat.forEach(t),U7o=r(rLe," \u2014 "),Wq=n(rLe,"A",{href:!0});var Xat=s(Wq);J7o=r(Xat,"DebertaV2ForMaskedLM"),Xat.forEach(t),Y7o=r(rLe," (DeBERTa-v2 model)"),rLe.forEach(t),K7o=i(O),bu=n(O,"LI",{});var tLe=s(bu);Jie=n(tLe,"STRONG",{});var zat=s(Jie);Z7o=r(zat,"distilbert"),zat.forEach(t),eMo=r(tLe," \u2014 "),Qq=n(tLe,"A",{href:!0});var Wat=s(Qq);oMo=r(Wat,"DistilBertForMaskedLM"),Wat.forEach(t),rMo=r(tLe," (DistilBERT model)"),tLe.forEach(t),tMo=i(O),vu=n(O,"LI",{});var aLe=s(vu);Yie=n(aLe,"STRONG",{});var Qat=s(Yie);aMo=r(Qat,"electra"),Qat.forEach(t),nMo=r(aLe," \u2014 "),Hq=n(aLe,"A",{href:!0});var Hat=s(Hq);sMo=r(Hat,"ElectraForPreTraining"),Hat.forEach(t),lMo=r(aLe," (ELECTRA model)"),aLe.forEach(t),iMo=i(O),Fu=n(O,"LI",{});var nLe=s(Fu);Kie=n(nLe,"STRONG",{});var Uat=s(Kie);dMo=r(Uat,"flaubert"),Uat.forEach(t),cMo=r(nLe," \u2014 "),Uq=n(nLe,"A",{href:!0});var Jat=s(Uq);fMo=r(Jat,"FlaubertWithLMHeadModel"),Jat.forEach(t),mMo=r(nLe," (FlauBERT model)"),nLe.forEach(t),gMo=i(O),Tu=n(O,"LI",{});var sLe=s(Tu);Zie=n(sLe,"STRONG",{});var Yat=s(Zie);hMo=r(Yat,"flava"),Yat.forEach(t),pMo=r(sLe," \u2014 "),Jq=n(sLe,"A",{href:!0});var Kat=s(Jq);_Mo=r(Kat,"FlavaForPreTraining"),Kat.forEach(t),uMo=r(sLe," (Flava model)"),sLe.forEach(t),bMo=i(O),Mu=n(O,"LI",{});var lLe=s(Mu);ede=n(lLe,"STRONG",{});var Zat=s(ede);vMo=r(Zat,"fnet"),Zat.forEach(t),FMo=r(lLe," \u2014 "),Yq=n(lLe,"A",{href:!0});var ent=s(Yq);TMo=r(ent,"FNetForPreTraining"),ent.forEach(t),MMo=r(lLe," (FNet model)"),lLe.forEach(t),EMo=i(O),Eu=n(O,"LI",{});var iLe=s(Eu);ode=n(iLe,"STRONG",{});var ont=s(ode);CMo=r(ont,"fsmt"),ont.forEach(t),wMo=r(iLe," \u2014 "),Kq=n(iLe,"A",{href:!0});var rnt=s(Kq);AMo=r(rnt,"FSMTForConditionalGeneration"),rnt.forEach(t),yMo=r(iLe," (FairSeq Machine-Translation model)"),iLe.forEach(t),LMo=i(O),Cu=n(O,"LI",{});var dLe=s(Cu);rde=n(dLe,"STRONG",{});var tnt=s(rde);xMo=r(tnt,"funnel"),tnt.forEach(t),$Mo=r(dLe," \u2014 "),Zq=n(dLe,"A",{href:!0});var ant=s(Zq);kMo=r(ant,"FunnelForPreTraining"),ant.forEach(t),SMo=r(dLe," (Funnel Transformer model)"),dLe.forEach(t),RMo=i(O),wu=n(O,"LI",{});var cLe=s(wu);tde=n(cLe,"STRONG",{});var nnt=s(tde);PMo=r(nnt,"gpt2"),nnt.forEach(t),BMo=r(cLe," \u2014 "),ej=n(cLe,"A",{href:!0});var snt=s(ej);IMo=r(snt,"GPT2LMHeadModel"),snt.forEach(t),NMo=r(cLe," (OpenAI GPT-2 model)"),cLe.forEach(t),qMo=i(O),Au=n(O,"LI",{});var fLe=s(Au);ade=n(fLe,"STRONG",{});var lnt=s(ade);jMo=r(lnt,"ibert"),lnt.forEach(t),DMo=r(fLe," \u2014 "),oj=n(fLe,"A",{href:!0});var int=s(oj);GMo=r(int,"IBertForMaskedLM"),int.forEach(t),OMo=r(fLe," (I-BERT model)"),fLe.forEach(t),VMo=i(O),yu=n(O,"LI",{});var mLe=s(yu);nde=n(mLe,"STRONG",{});var dnt=s(nde);XMo=r(dnt,"layoutlm"),dnt.forEach(t),zMo=r(mLe," \u2014 "),rj=n(mLe,"A",{href:!0});var cnt=s(rj);WMo=r(cnt,"LayoutLMForMaskedLM"),cnt.forEach(t),QMo=r(mLe," (LayoutLM model)"),mLe.forEach(t),HMo=i(O),Lu=n(O,"LI",{});var gLe=s(Lu);sde=n(gLe,"STRONG",{});var fnt=s(sde);UMo=r(fnt,"longformer"),fnt.forEach(t),JMo=r(gLe," \u2014 "),tj=n(gLe,"A",{href:!0});var mnt=s(tj);YMo=r(mnt,"LongformerForMaskedLM"),mnt.forEach(t),KMo=r(gLe," (Longformer model)"),gLe.forEach(t),ZMo=i(O),xu=n(O,"LI",{});var hLe=s(xu);lde=n(hLe,"STRONG",{});var gnt=s(lde);eEo=r(gnt,"lxmert"),gnt.forEach(t),oEo=r(hLe," \u2014 "),aj=n(hLe,"A",{href:!0});var hnt=s(aj);rEo=r(hnt,"LxmertForPreTraining"),hnt.forEach(t),tEo=r(hLe," (LXMERT model)"),hLe.forEach(t),aEo=i(O),$u=n(O,"LI",{});var pLe=s($u);ide=n(pLe,"STRONG",{});var pnt=s(ide);nEo=r(pnt,"megatron-bert"),pnt.forEach(t),sEo=r(pLe," \u2014 "),nj=n(pLe,"A",{href:!0});var _nt=s(nj);lEo=r(_nt,"MegatronBertForPreTraining"),_nt.forEach(t),iEo=r(pLe," (MegatronBert model)"),pLe.forEach(t),dEo=i(O),ku=n(O,"LI",{});var _Le=s(ku);dde=n(_Le,"STRONG",{});var unt=s(dde);cEo=r(unt,"mobilebert"),unt.forEach(t),fEo=r(_Le," \u2014 "),sj=n(_Le,"A",{href:!0});var bnt=s(sj);mEo=r(bnt,"MobileBertForPreTraining"),bnt.forEach(t),gEo=r(_Le," (MobileBERT model)"),_Le.forEach(t),hEo=i(O),Su=n(O,"LI",{});var uLe=s(Su);cde=n(uLe,"STRONG",{});var vnt=s(cde);pEo=r(vnt,"mpnet"),vnt.forEach(t),_Eo=r(uLe," \u2014 "),lj=n(uLe,"A",{href:!0});var Fnt=s(lj);uEo=r(Fnt,"MPNetForMaskedLM"),Fnt.forEach(t),bEo=r(uLe," (MPNet model)"),uLe.forEach(t),vEo=i(O),Ru=n(O,"LI",{});var bLe=s(Ru);fde=n(bLe,"STRONG",{});var Tnt=s(fde);FEo=r(Tnt,"openai-gpt"),Tnt.forEach(t),TEo=r(bLe," \u2014 "),ij=n(bLe,"A",{href:!0});var Mnt=s(ij);MEo=r(Mnt,"OpenAIGPTLMHeadModel"),Mnt.forEach(t),EEo=r(bLe," (OpenAI GPT model)"),bLe.forEach(t),CEo=i(O),Pu=n(O,"LI",{});var vLe=s(Pu);mde=n(vLe,"STRONG",{});var Ent=s(mde);wEo=r(Ent,"retribert"),Ent.forEach(t),AEo=r(vLe," \u2014 "),dj=n(vLe,"A",{href:!0});var Cnt=s(dj);yEo=r(Cnt,"RetriBertModel"),Cnt.forEach(t),LEo=r(vLe," (RetriBERT model)"),vLe.forEach(t),xEo=i(O),Bu=n(O,"LI",{});var FLe=s(Bu);gde=n(FLe,"STRONG",{});var wnt=s(gde);$Eo=r(wnt,"roberta"),wnt.forEach(t),kEo=r(FLe," \u2014 "),cj=n(FLe,"A",{href:!0});var Ant=s(cj);SEo=r(Ant,"RobertaForMaskedLM"),Ant.forEach(t),REo=r(FLe," (RoBERTa model)"),FLe.forEach(t),PEo=i(O),Iu=n(O,"LI",{});var TLe=s(Iu);hde=n(TLe,"STRONG",{});var ynt=s(hde);BEo=r(ynt,"splinter"),ynt.forEach(t),IEo=r(TLe," \u2014 "),fj=n(TLe,"A",{href:!0});var Lnt=s(fj);NEo=r(Lnt,"SplinterForPreTraining"),Lnt.forEach(t),qEo=r(TLe," (Splinter model)"),TLe.forEach(t),jEo=i(O),Nu=n(O,"LI",{});var MLe=s(Nu);pde=n(MLe,"STRONG",{});var xnt=s(pde);DEo=r(xnt,"squeezebert"),xnt.forEach(t),GEo=r(MLe," \u2014 "),mj=n(MLe,"A",{href:!0});var $nt=s(mj);OEo=r($nt,"SqueezeBertForMaskedLM"),$nt.forEach(t),VEo=r(MLe," (SqueezeBERT model)"),MLe.forEach(t),XEo=i(O),qu=n(O,"LI",{});var ELe=s(qu);_de=n(ELe,"STRONG",{});var knt=s(_de);zEo=r(knt,"t5"),knt.forEach(t),WEo=r(ELe," \u2014 "),gj=n(ELe,"A",{href:!0});var Snt=s(gj);QEo=r(Snt,"T5ForConditionalGeneration"),Snt.forEach(t),HEo=r(ELe," (T5 model)"),ELe.forEach(t),UEo=i(O),ju=n(O,"LI",{});var CLe=s(ju);ude=n(CLe,"STRONG",{});var Rnt=s(ude);JEo=r(Rnt,"tapas"),Rnt.forEach(t),YEo=r(CLe," \u2014 "),hj=n(CLe,"A",{href:!0});var Pnt=s(hj);KEo=r(Pnt,"TapasForMaskedLM"),Pnt.forEach(t),ZEo=r(CLe," (TAPAS model)"),CLe.forEach(t),eCo=i(O),Du=n(O,"LI",{});var wLe=s(Du);bde=n(wLe,"STRONG",{});var Bnt=s(bde);oCo=r(Bnt,"transfo-xl"),Bnt.forEach(t),rCo=r(wLe," \u2014 "),pj=n(wLe,"A",{href:!0});var Int=s(pj);tCo=r(Int,"TransfoXLLMHeadModel"),Int.forEach(t),aCo=r(wLe," (Transformer-XL model)"),wLe.forEach(t),nCo=i(O),Gu=n(O,"LI",{});var ALe=s(Gu);vde=n(ALe,"STRONG",{});var Nnt=s(vde);sCo=r(Nnt,"unispeech"),Nnt.forEach(t),lCo=r(ALe," \u2014 "),_j=n(ALe,"A",{href:!0});var qnt=s(_j);iCo=r(qnt,"UniSpeechForPreTraining"),qnt.forEach(t),dCo=r(ALe," (UniSpeech model)"),ALe.forEach(t),cCo=i(O),Ou=n(O,"LI",{});var yLe=s(Ou);Fde=n(yLe,"STRONG",{});var jnt=s(Fde);fCo=r(jnt,"unispeech-sat"),jnt.forEach(t),mCo=r(yLe," \u2014 "),uj=n(yLe,"A",{href:!0});var Dnt=s(uj);gCo=r(Dnt,"UniSpeechSatForPreTraining"),Dnt.forEach(t),hCo=r(yLe," (UniSpeechSat model)"),yLe.forEach(t),pCo=i(O),Vu=n(O,"LI",{});var LLe=s(Vu);Tde=n(LLe,"STRONG",{});var Gnt=s(Tde);_Co=r(Gnt,"visual_bert"),Gnt.forEach(t),uCo=r(LLe," \u2014 "),bj=n(LLe,"A",{href:!0});var Ont=s(bj);bCo=r(Ont,"VisualBertForPreTraining"),Ont.forEach(t),vCo=r(LLe," (VisualBert model)"),LLe.forEach(t),FCo=i(O),Xu=n(O,"LI",{});var xLe=s(Xu);Mde=n(xLe,"STRONG",{});var Vnt=s(Mde);TCo=r(Vnt,"vit_mae"),Vnt.forEach(t),MCo=r(xLe," \u2014 "),vj=n(xLe,"A",{href:!0});var Xnt=s(vj);ECo=r(Xnt,"ViTMAEForPreTraining"),Xnt.forEach(t),CCo=r(xLe," (ViTMAE model)"),xLe.forEach(t),wCo=i(O),zu=n(O,"LI",{});var $Le=s(zu);Ede=n($Le,"STRONG",{});var znt=s(Ede);ACo=r(znt,"wav2vec2"),znt.forEach(t),yCo=r($Le," \u2014 "),Fj=n($Le,"A",{href:!0});var Wnt=s(Fj);LCo=r(Wnt,"Wav2Vec2ForPreTraining"),Wnt.forEach(t),xCo=r($Le," (Wav2Vec2 model)"),$Le.forEach(t),$Co=i(O),Wu=n(O,"LI",{});var kLe=s(Wu);Cde=n(kLe,"STRONG",{});var Qnt=s(Cde);kCo=r(Qnt,"wav2vec2-conformer"),Qnt.forEach(t),SCo=r(kLe," \u2014 "),Tj=n(kLe,"A",{href:!0});var Hnt=s(Tj);RCo=r(Hnt,"Wav2Vec2ConformerForPreTraining"),Hnt.forEach(t),PCo=r(kLe," (Wav2Vec2-Conformer model)"),kLe.forEach(t),BCo=i(O),Qu=n(O,"LI",{});var SLe=s(Qu);wde=n(SLe,"STRONG",{});var Unt=s(wde);ICo=r(Unt,"xlm"),Unt.forEach(t),NCo=r(SLe," \u2014 "),Mj=n(SLe,"A",{href:!0});var Jnt=s(Mj);qCo=r(Jnt,"XLMWithLMHeadModel"),Jnt.forEach(t),jCo=r(SLe," (XLM model)"),SLe.forEach(t),DCo=i(O),Hu=n(O,"LI",{});var RLe=s(Hu);Ade=n(RLe,"STRONG",{});var Ynt=s(Ade);GCo=r(Ynt,"xlm-roberta"),Ynt.forEach(t),OCo=r(RLe," \u2014 "),Ej=n(RLe,"A",{href:!0});var Knt=s(Ej);VCo=r(Knt,"XLMRobertaForMaskedLM"),Knt.forEach(t),XCo=r(RLe," (XLM-RoBERTa model)"),RLe.forEach(t),zCo=i(O),Uu=n(O,"LI",{});var PLe=s(Uu);yde=n(PLe,"STRONG",{});var Znt=s(yde);WCo=r(Znt,"xlm-roberta-xl"),Znt.forEach(t),QCo=r(PLe," \u2014 "),Cj=n(PLe,"A",{href:!0});var est=s(Cj);HCo=r(est,"XLMRobertaXLForMaskedLM"),est.forEach(t),UCo=r(PLe," (XLM-RoBERTa-XL model)"),PLe.forEach(t),JCo=i(O),Ju=n(O,"LI",{});var BLe=s(Ju);Lde=n(BLe,"STRONG",{});var ost=s(Lde);YCo=r(ost,"xlnet"),ost.forEach(t),KCo=r(BLe," \u2014 "),wj=n(BLe,"A",{href:!0});var rst=s(wj);ZCo=r(rst,"XLNetLMHeadModel"),rst.forEach(t),e5o=r(BLe," (XLNet model)"),BLe.forEach(t),O.forEach(t),o5o=i(ra),Yu=n(ra,"P",{});var ILe=s(Yu);r5o=r(ILe,"The model is set in evaluation mode by default using "),xde=n(ILe,"CODE",{});var tst=s(xde);t5o=r(tst,"model.eval()"),tst.forEach(t),a5o=r(ILe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$de=n(ILe,"CODE",{});var ast=s($de);n5o=r(ast,"model.train()"),ast.forEach(t),ILe.forEach(t),s5o=i(ra),T(Ku.$$.fragment,ra),ra.forEach(t),Vs.forEach(t),Sqe=i(f),Si=n(f,"H2",{class:!0});var IDe=s(Si);Zu=n(IDe,"A",{id:!0,class:!0,href:!0});var nst=s(Zu);kde=n(nst,"SPAN",{});var sst=s(kde);T(gy.$$.fragment,sst),sst.forEach(t),nst.forEach(t),l5o=i(IDe),Sde=n(IDe,"SPAN",{});var lst=s(Sde);i5o=r(lst,"AutoModelForCausalLM"),lst.forEach(t),IDe.forEach(t),Rqe=i(f),$o=n(f,"DIV",{class:!0});var Xs=s($o);T(hy.$$.fragment,Xs),d5o=i(Xs),Ri=n(Xs,"P",{});var xZ=s(Ri);c5o=r(xZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Aj=n(xZ,"A",{href:!0});var ist=s(Aj);f5o=r(ist,"from_pretrained()"),ist.forEach(t),m5o=r(xZ," class method or the "),yj=n(xZ,"A",{href:!0});var dst=s(yj);g5o=r(dst,"from_config()"),dst.forEach(t),h5o=r(xZ,` class
method.`),xZ.forEach(t),p5o=i(Xs),py=n(Xs,"P",{});var NDe=s(py);_5o=r(NDe,"This class cannot be instantiated directly using "),Rde=n(NDe,"CODE",{});var cst=s(Rde);u5o=r(cst,"__init__()"),cst.forEach(t),b5o=r(NDe," (throws an error)."),NDe.forEach(t),v5o=i(Xs),nt=n(Xs,"DIV",{class:!0});var jw=s(nt);T(_y.$$.fragment,jw),F5o=i(jw),Pde=n(jw,"P",{});var fst=s(Pde);T5o=r(fst,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),fst.forEach(t),M5o=i(jw),Pi=n(jw,"P",{});var $Z=s(Pi);E5o=r($Z,`Note:
Loading a model from its configuration file does `),Bde=n($Z,"STRONG",{});var mst=s(Bde);C5o=r(mst,"not"),mst.forEach(t),w5o=r($Z,` load the model weights. It only affects the
model\u2019s configuration. Use `),Lj=n($Z,"A",{href:!0});var gst=s(Lj);A5o=r(gst,"from_pretrained()"),gst.forEach(t),y5o=r($Z," to load the model weights."),$Z.forEach(t),L5o=i(jw),T(e6.$$.fragment,jw),jw.forEach(t),x5o=i(Xs),Ke=n(Xs,"DIV",{class:!0});var ta=s(Ke);T(uy.$$.fragment,ta),$5o=i(ta),Ide=n(ta,"P",{});var hst=s(Ide);k5o=r(hst,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),hst.forEach(t),S5o=i(ta),$a=n(ta,"P",{});var Dw=s($a);R5o=r(Dw,"The model class to instantiate is selected based on the "),Nde=n(Dw,"CODE",{});var pst=s(Nde);P5o=r(pst,"model_type"),pst.forEach(t),B5o=r(Dw,` property of the config object (either
passed as an argument or loaded from `),qde=n(Dw,"CODE",{});var _st=s(qde);I5o=r(_st,"pretrained_model_name_or_path"),_st.forEach(t),N5o=r(Dw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jde=n(Dw,"CODE",{});var ust=s(jde);q5o=r(ust,"pretrained_model_name_or_path"),ust.forEach(t),j5o=r(Dw,":"),Dw.forEach(t),D5o=i(ta),z=n(ta,"UL",{});var W=s(z);o6=n(W,"LI",{});var NLe=s(o6);Dde=n(NLe,"STRONG",{});var bst=s(Dde);G5o=r(bst,"bart"),bst.forEach(t),O5o=r(NLe," \u2014 "),xj=n(NLe,"A",{href:!0});var vst=s(xj);V5o=r(vst,"BartForCausalLM"),vst.forEach(t),X5o=r(NLe," (BART model)"),NLe.forEach(t),z5o=i(W),r6=n(W,"LI",{});var qLe=s(r6);Gde=n(qLe,"STRONG",{});var Fst=s(Gde);W5o=r(Fst,"bert"),Fst.forEach(t),Q5o=r(qLe," \u2014 "),$j=n(qLe,"A",{href:!0});var Tst=s($j);H5o=r(Tst,"BertLMHeadModel"),Tst.forEach(t),U5o=r(qLe," (BERT model)"),qLe.forEach(t),J5o=i(W),t6=n(W,"LI",{});var jLe=s(t6);Ode=n(jLe,"STRONG",{});var Mst=s(Ode);Y5o=r(Mst,"bert-generation"),Mst.forEach(t),K5o=r(jLe," \u2014 "),kj=n(jLe,"A",{href:!0});var Est=s(kj);Z5o=r(Est,"BertGenerationDecoder"),Est.forEach(t),e3o=r(jLe," (Bert Generation model)"),jLe.forEach(t),o3o=i(W),a6=n(W,"LI",{});var DLe=s(a6);Vde=n(DLe,"STRONG",{});var Cst=s(Vde);r3o=r(Cst,"big_bird"),Cst.forEach(t),t3o=r(DLe," \u2014 "),Sj=n(DLe,"A",{href:!0});var wst=s(Sj);a3o=r(wst,"BigBirdForCausalLM"),wst.forEach(t),n3o=r(DLe," (BigBird model)"),DLe.forEach(t),s3o=i(W),n6=n(W,"LI",{});var GLe=s(n6);Xde=n(GLe,"STRONG",{});var Ast=s(Xde);l3o=r(Ast,"bigbird_pegasus"),Ast.forEach(t),i3o=r(GLe," \u2014 "),Rj=n(GLe,"A",{href:!0});var yst=s(Rj);d3o=r(yst,"BigBirdPegasusForCausalLM"),yst.forEach(t),c3o=r(GLe," (BigBirdPegasus model)"),GLe.forEach(t),f3o=i(W),s6=n(W,"LI",{});var OLe=s(s6);zde=n(OLe,"STRONG",{});var Lst=s(zde);m3o=r(Lst,"blenderbot"),Lst.forEach(t),g3o=r(OLe," \u2014 "),Pj=n(OLe,"A",{href:!0});var xst=s(Pj);h3o=r(xst,"BlenderbotForCausalLM"),xst.forEach(t),p3o=r(OLe," (Blenderbot model)"),OLe.forEach(t),_3o=i(W),l6=n(W,"LI",{});var VLe=s(l6);Wde=n(VLe,"STRONG",{});var $st=s(Wde);u3o=r($st,"blenderbot-small"),$st.forEach(t),b3o=r(VLe," \u2014 "),Bj=n(VLe,"A",{href:!0});var kst=s(Bj);v3o=r(kst,"BlenderbotSmallForCausalLM"),kst.forEach(t),F3o=r(VLe," (BlenderbotSmall model)"),VLe.forEach(t),T3o=i(W),i6=n(W,"LI",{});var XLe=s(i6);Qde=n(XLe,"STRONG",{});var Sst=s(Qde);M3o=r(Sst,"camembert"),Sst.forEach(t),E3o=r(XLe," \u2014 "),Ij=n(XLe,"A",{href:!0});var Rst=s(Ij);C3o=r(Rst,"CamembertForCausalLM"),Rst.forEach(t),w3o=r(XLe," (CamemBERT model)"),XLe.forEach(t),A3o=i(W),d6=n(W,"LI",{});var zLe=s(d6);Hde=n(zLe,"STRONG",{});var Pst=s(Hde);y3o=r(Pst,"ctrl"),Pst.forEach(t),L3o=r(zLe," \u2014 "),Nj=n(zLe,"A",{href:!0});var Bst=s(Nj);x3o=r(Bst,"CTRLLMHeadModel"),Bst.forEach(t),$3o=r(zLe," (CTRL model)"),zLe.forEach(t),k3o=i(W),c6=n(W,"LI",{});var WLe=s(c6);Ude=n(WLe,"STRONG",{});var Ist=s(Ude);S3o=r(Ist,"data2vec-text"),Ist.forEach(t),R3o=r(WLe," \u2014 "),qj=n(WLe,"A",{href:!0});var Nst=s(qj);P3o=r(Nst,"Data2VecTextForCausalLM"),Nst.forEach(t),B3o=r(WLe," (Data2VecText model)"),WLe.forEach(t),I3o=i(W),f6=n(W,"LI",{});var QLe=s(f6);Jde=n(QLe,"STRONG",{});var qst=s(Jde);N3o=r(qst,"electra"),qst.forEach(t),q3o=r(QLe," \u2014 "),jj=n(QLe,"A",{href:!0});var jst=s(jj);j3o=r(jst,"ElectraForCausalLM"),jst.forEach(t),D3o=r(QLe," (ELECTRA model)"),QLe.forEach(t),G3o=i(W),m6=n(W,"LI",{});var HLe=s(m6);Yde=n(HLe,"STRONG",{});var Dst=s(Yde);O3o=r(Dst,"gpt2"),Dst.forEach(t),V3o=r(HLe," \u2014 "),Dj=n(HLe,"A",{href:!0});var Gst=s(Dj);X3o=r(Gst,"GPT2LMHeadModel"),Gst.forEach(t),z3o=r(HLe," (OpenAI GPT-2 model)"),HLe.forEach(t),W3o=i(W),g6=n(W,"LI",{});var ULe=s(g6);Kde=n(ULe,"STRONG",{});var Ost=s(Kde);Q3o=r(Ost,"gpt_neo"),Ost.forEach(t),H3o=r(ULe," \u2014 "),Gj=n(ULe,"A",{href:!0});var Vst=s(Gj);U3o=r(Vst,"GPTNeoForCausalLM"),Vst.forEach(t),J3o=r(ULe," (GPT Neo model)"),ULe.forEach(t),Y3o=i(W),h6=n(W,"LI",{});var JLe=s(h6);Zde=n(JLe,"STRONG",{});var Xst=s(Zde);K3o=r(Xst,"gpt_neox"),Xst.forEach(t),Z3o=r(JLe," \u2014 "),Oj=n(JLe,"A",{href:!0});var zst=s(Oj);ewo=r(zst,"GPTNeoXForCausalLM"),zst.forEach(t),owo=r(JLe," (GPT NeoX model)"),JLe.forEach(t),rwo=i(W),p6=n(W,"LI",{});var YLe=s(p6);ece=n(YLe,"STRONG",{});var Wst=s(ece);two=r(Wst,"gptj"),Wst.forEach(t),awo=r(YLe," \u2014 "),Vj=n(YLe,"A",{href:!0});var Qst=s(Vj);nwo=r(Qst,"GPTJForCausalLM"),Qst.forEach(t),swo=r(YLe," (GPT-J model)"),YLe.forEach(t),lwo=i(W),_6=n(W,"LI",{});var KLe=s(_6);oce=n(KLe,"STRONG",{});var Hst=s(oce);iwo=r(Hst,"marian"),Hst.forEach(t),dwo=r(KLe," \u2014 "),Xj=n(KLe,"A",{href:!0});var Ust=s(Xj);cwo=r(Ust,"MarianForCausalLM"),Ust.forEach(t),fwo=r(KLe," (Marian model)"),KLe.forEach(t),mwo=i(W),u6=n(W,"LI",{});var ZLe=s(u6);rce=n(ZLe,"STRONG",{});var Jst=s(rce);gwo=r(Jst,"mbart"),Jst.forEach(t),hwo=r(ZLe," \u2014 "),zj=n(ZLe,"A",{href:!0});var Yst=s(zj);pwo=r(Yst,"MBartForCausalLM"),Yst.forEach(t),_wo=r(ZLe," (mBART model)"),ZLe.forEach(t),uwo=i(W),b6=n(W,"LI",{});var e8e=s(b6);tce=n(e8e,"STRONG",{});var Kst=s(tce);bwo=r(Kst,"megatron-bert"),Kst.forEach(t),vwo=r(e8e," \u2014 "),Wj=n(e8e,"A",{href:!0});var Zst=s(Wj);Fwo=r(Zst,"MegatronBertForCausalLM"),Zst.forEach(t),Two=r(e8e," (MegatronBert model)"),e8e.forEach(t),Mwo=i(W),v6=n(W,"LI",{});var o8e=s(v6);ace=n(o8e,"STRONG",{});var elt=s(ace);Ewo=r(elt,"openai-gpt"),elt.forEach(t),Cwo=r(o8e," \u2014 "),Qj=n(o8e,"A",{href:!0});var olt=s(Qj);wwo=r(olt,"OpenAIGPTLMHeadModel"),olt.forEach(t),Awo=r(o8e," (OpenAI GPT model)"),o8e.forEach(t),ywo=i(W),F6=n(W,"LI",{});var r8e=s(F6);nce=n(r8e,"STRONG",{});var rlt=s(nce);Lwo=r(rlt,"opt"),rlt.forEach(t),xwo=r(r8e," \u2014 "),Hj=n(r8e,"A",{href:!0});var tlt=s(Hj);$wo=r(tlt,"OPTForCausalLM"),tlt.forEach(t),kwo=r(r8e," (OPT model)"),r8e.forEach(t),Swo=i(W),T6=n(W,"LI",{});var t8e=s(T6);sce=n(t8e,"STRONG",{});var alt=s(sce);Rwo=r(alt,"pegasus"),alt.forEach(t),Pwo=r(t8e," \u2014 "),Uj=n(t8e,"A",{href:!0});var nlt=s(Uj);Bwo=r(nlt,"PegasusForCausalLM"),nlt.forEach(t),Iwo=r(t8e," (Pegasus model)"),t8e.forEach(t),Nwo=i(W),M6=n(W,"LI",{});var a8e=s(M6);lce=n(a8e,"STRONG",{});var slt=s(lce);qwo=r(slt,"plbart"),slt.forEach(t),jwo=r(a8e," \u2014 "),Jj=n(a8e,"A",{href:!0});var llt=s(Jj);Dwo=r(llt,"PLBartForCausalLM"),llt.forEach(t),Gwo=r(a8e," (PLBart model)"),a8e.forEach(t),Owo=i(W),E6=n(W,"LI",{});var n8e=s(E6);ice=n(n8e,"STRONG",{});var ilt=s(ice);Vwo=r(ilt,"prophetnet"),ilt.forEach(t),Xwo=r(n8e," \u2014 "),Yj=n(n8e,"A",{href:!0});var dlt=s(Yj);zwo=r(dlt,"ProphetNetForCausalLM"),dlt.forEach(t),Wwo=r(n8e," (ProphetNet model)"),n8e.forEach(t),Qwo=i(W),C6=n(W,"LI",{});var s8e=s(C6);dce=n(s8e,"STRONG",{});var clt=s(dce);Hwo=r(clt,"qdqbert"),clt.forEach(t),Uwo=r(s8e," \u2014 "),Kj=n(s8e,"A",{href:!0});var flt=s(Kj);Jwo=r(flt,"QDQBertLMHeadModel"),flt.forEach(t),Ywo=r(s8e," (QDQBert model)"),s8e.forEach(t),Kwo=i(W),w6=n(W,"LI",{});var l8e=s(w6);cce=n(l8e,"STRONG",{});var mlt=s(cce);Zwo=r(mlt,"reformer"),mlt.forEach(t),e0o=r(l8e," \u2014 "),Zj=n(l8e,"A",{href:!0});var glt=s(Zj);o0o=r(glt,"ReformerModelWithLMHead"),glt.forEach(t),r0o=r(l8e," (Reformer model)"),l8e.forEach(t),t0o=i(W),A6=n(W,"LI",{});var i8e=s(A6);fce=n(i8e,"STRONG",{});var hlt=s(fce);a0o=r(hlt,"rembert"),hlt.forEach(t),n0o=r(i8e," \u2014 "),eD=n(i8e,"A",{href:!0});var plt=s(eD);s0o=r(plt,"RemBertForCausalLM"),plt.forEach(t),l0o=r(i8e," (RemBERT model)"),i8e.forEach(t),i0o=i(W),y6=n(W,"LI",{});var d8e=s(y6);mce=n(d8e,"STRONG",{});var _lt=s(mce);d0o=r(_lt,"roberta"),_lt.forEach(t),c0o=r(d8e," \u2014 "),oD=n(d8e,"A",{href:!0});var ult=s(oD);f0o=r(ult,"RobertaForCausalLM"),ult.forEach(t),m0o=r(d8e," (RoBERTa model)"),d8e.forEach(t),g0o=i(W),L6=n(W,"LI",{});var c8e=s(L6);gce=n(c8e,"STRONG",{});var blt=s(gce);h0o=r(blt,"roformer"),blt.forEach(t),p0o=r(c8e," \u2014 "),rD=n(c8e,"A",{href:!0});var vlt=s(rD);_0o=r(vlt,"RoFormerForCausalLM"),vlt.forEach(t),u0o=r(c8e," (RoFormer model)"),c8e.forEach(t),b0o=i(W),x6=n(W,"LI",{});var f8e=s(x6);hce=n(f8e,"STRONG",{});var Flt=s(hce);v0o=r(Flt,"speech_to_text_2"),Flt.forEach(t),F0o=r(f8e," \u2014 "),tD=n(f8e,"A",{href:!0});var Tlt=s(tD);T0o=r(Tlt,"Speech2Text2ForCausalLM"),Tlt.forEach(t),M0o=r(f8e," (Speech2Text2 model)"),f8e.forEach(t),E0o=i(W),$6=n(W,"LI",{});var m8e=s($6);pce=n(m8e,"STRONG",{});var Mlt=s(pce);C0o=r(Mlt,"transfo-xl"),Mlt.forEach(t),w0o=r(m8e," \u2014 "),aD=n(m8e,"A",{href:!0});var Elt=s(aD);A0o=r(Elt,"TransfoXLLMHeadModel"),Elt.forEach(t),y0o=r(m8e," (Transformer-XL model)"),m8e.forEach(t),L0o=i(W),k6=n(W,"LI",{});var g8e=s(k6);_ce=n(g8e,"STRONG",{});var Clt=s(_ce);x0o=r(Clt,"trocr"),Clt.forEach(t),$0o=r(g8e," \u2014 "),nD=n(g8e,"A",{href:!0});var wlt=s(nD);k0o=r(wlt,"TrOCRForCausalLM"),wlt.forEach(t),S0o=r(g8e," (TrOCR model)"),g8e.forEach(t),R0o=i(W),S6=n(W,"LI",{});var h8e=s(S6);uce=n(h8e,"STRONG",{});var Alt=s(uce);P0o=r(Alt,"xglm"),Alt.forEach(t),B0o=r(h8e," \u2014 "),sD=n(h8e,"A",{href:!0});var ylt=s(sD);I0o=r(ylt,"XGLMForCausalLM"),ylt.forEach(t),N0o=r(h8e," (XGLM model)"),h8e.forEach(t),q0o=i(W),R6=n(W,"LI",{});var p8e=s(R6);bce=n(p8e,"STRONG",{});var Llt=s(bce);j0o=r(Llt,"xlm"),Llt.forEach(t),D0o=r(p8e," \u2014 "),lD=n(p8e,"A",{href:!0});var xlt=s(lD);G0o=r(xlt,"XLMWithLMHeadModel"),xlt.forEach(t),O0o=r(p8e," (XLM model)"),p8e.forEach(t),V0o=i(W),P6=n(W,"LI",{});var _8e=s(P6);vce=n(_8e,"STRONG",{});var $lt=s(vce);X0o=r($lt,"xlm-prophetnet"),$lt.forEach(t),z0o=r(_8e," \u2014 "),iD=n(_8e,"A",{href:!0});var klt=s(iD);W0o=r(klt,"XLMProphetNetForCausalLM"),klt.forEach(t),Q0o=r(_8e," (XLMProphetNet model)"),_8e.forEach(t),H0o=i(W),B6=n(W,"LI",{});var u8e=s(B6);Fce=n(u8e,"STRONG",{});var Slt=s(Fce);U0o=r(Slt,"xlm-roberta"),Slt.forEach(t),J0o=r(u8e," \u2014 "),dD=n(u8e,"A",{href:!0});var Rlt=s(dD);Y0o=r(Rlt,"XLMRobertaForCausalLM"),Rlt.forEach(t),K0o=r(u8e," (XLM-RoBERTa model)"),u8e.forEach(t),Z0o=i(W),I6=n(W,"LI",{});var b8e=s(I6);Tce=n(b8e,"STRONG",{});var Plt=s(Tce);eAo=r(Plt,"xlm-roberta-xl"),Plt.forEach(t),oAo=r(b8e," \u2014 "),cD=n(b8e,"A",{href:!0});var Blt=s(cD);rAo=r(Blt,"XLMRobertaXLForCausalLM"),Blt.forEach(t),tAo=r(b8e," (XLM-RoBERTa-XL model)"),b8e.forEach(t),aAo=i(W),N6=n(W,"LI",{});var v8e=s(N6);Mce=n(v8e,"STRONG",{});var Ilt=s(Mce);nAo=r(Ilt,"xlnet"),Ilt.forEach(t),sAo=r(v8e," \u2014 "),fD=n(v8e,"A",{href:!0});var Nlt=s(fD);lAo=r(Nlt,"XLNetLMHeadModel"),Nlt.forEach(t),iAo=r(v8e," (XLNet model)"),v8e.forEach(t),W.forEach(t),dAo=i(ta),q6=n(ta,"P",{});var F8e=s(q6);cAo=r(F8e,"The model is set in evaluation mode by default using "),Ece=n(F8e,"CODE",{});var qlt=s(Ece);fAo=r(qlt,"model.eval()"),qlt.forEach(t),mAo=r(F8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cce=n(F8e,"CODE",{});var jlt=s(Cce);gAo=r(jlt,"model.train()"),jlt.forEach(t),F8e.forEach(t),hAo=i(ta),T(j6.$$.fragment,ta),ta.forEach(t),Xs.forEach(t),Pqe=i(f),Bi=n(f,"H2",{class:!0});var qDe=s(Bi);D6=n(qDe,"A",{id:!0,class:!0,href:!0});var Dlt=s(D6);wce=n(Dlt,"SPAN",{});var Glt=s(wce);T(by.$$.fragment,Glt),Glt.forEach(t),Dlt.forEach(t),pAo=i(qDe),Ace=n(qDe,"SPAN",{});var Olt=s(Ace);_Ao=r(Olt,"AutoModelForMaskedLM"),Olt.forEach(t),qDe.forEach(t),Bqe=i(f),ko=n(f,"DIV",{class:!0});var zs=s(ko);T(vy.$$.fragment,zs),uAo=i(zs),Ii=n(zs,"P",{});var kZ=s(Ii);bAo=r(kZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),mD=n(kZ,"A",{href:!0});var Vlt=s(mD);vAo=r(Vlt,"from_pretrained()"),Vlt.forEach(t),FAo=r(kZ," class method or the "),gD=n(kZ,"A",{href:!0});var Xlt=s(gD);TAo=r(Xlt,"from_config()"),Xlt.forEach(t),MAo=r(kZ,` class
method.`),kZ.forEach(t),EAo=i(zs),Fy=n(zs,"P",{});var jDe=s(Fy);CAo=r(jDe,"This class cannot be instantiated directly using "),yce=n(jDe,"CODE",{});var zlt=s(yce);wAo=r(zlt,"__init__()"),zlt.forEach(t),AAo=r(jDe," (throws an error)."),jDe.forEach(t),yAo=i(zs),st=n(zs,"DIV",{class:!0});var Gw=s(st);T(Ty.$$.fragment,Gw),LAo=i(Gw),Lce=n(Gw,"P",{});var Wlt=s(Lce);xAo=r(Wlt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Wlt.forEach(t),$Ao=i(Gw),Ni=n(Gw,"P",{});var SZ=s(Ni);kAo=r(SZ,`Note:
Loading a model from its configuration file does `),xce=n(SZ,"STRONG",{});var Qlt=s(xce);SAo=r(Qlt,"not"),Qlt.forEach(t),RAo=r(SZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),hD=n(SZ,"A",{href:!0});var Hlt=s(hD);PAo=r(Hlt,"from_pretrained()"),Hlt.forEach(t),BAo=r(SZ," to load the model weights."),SZ.forEach(t),IAo=i(Gw),T(G6.$$.fragment,Gw),Gw.forEach(t),NAo=i(zs),Ze=n(zs,"DIV",{class:!0});var aa=s(Ze);T(My.$$.fragment,aa),qAo=i(aa),$ce=n(aa,"P",{});var Ult=s($ce);jAo=r(Ult,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Ult.forEach(t),DAo=i(aa),ka=n(aa,"P",{});var Ow=s(ka);GAo=r(Ow,"The model class to instantiate is selected based on the "),kce=n(Ow,"CODE",{});var Jlt=s(kce);OAo=r(Jlt,"model_type"),Jlt.forEach(t),VAo=r(Ow,` property of the config object (either
passed as an argument or loaded from `),Sce=n(Ow,"CODE",{});var Ylt=s(Sce);XAo=r(Ylt,"pretrained_model_name_or_path"),Ylt.forEach(t),zAo=r(Ow,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rce=n(Ow,"CODE",{});var Klt=s(Rce);WAo=r(Klt,"pretrained_model_name_or_path"),Klt.forEach(t),QAo=r(Ow,":"),Ow.forEach(t),HAo=i(aa),Q=n(aa,"UL",{});var U=s(Q);O6=n(U,"LI",{});var T8e=s(O6);Pce=n(T8e,"STRONG",{});var Zlt=s(Pce);UAo=r(Zlt,"albert"),Zlt.forEach(t),JAo=r(T8e," \u2014 "),pD=n(T8e,"A",{href:!0});var eit=s(pD);YAo=r(eit,"AlbertForMaskedLM"),eit.forEach(t),KAo=r(T8e," (ALBERT model)"),T8e.forEach(t),ZAo=i(U),V6=n(U,"LI",{});var M8e=s(V6);Bce=n(M8e,"STRONG",{});var oit=s(Bce);eyo=r(oit,"bart"),oit.forEach(t),oyo=r(M8e," \u2014 "),_D=n(M8e,"A",{href:!0});var rit=s(_D);ryo=r(rit,"BartForConditionalGeneration"),rit.forEach(t),tyo=r(M8e," (BART model)"),M8e.forEach(t),ayo=i(U),X6=n(U,"LI",{});var E8e=s(X6);Ice=n(E8e,"STRONG",{});var tit=s(Ice);nyo=r(tit,"bert"),tit.forEach(t),syo=r(E8e," \u2014 "),uD=n(E8e,"A",{href:!0});var ait=s(uD);lyo=r(ait,"BertForMaskedLM"),ait.forEach(t),iyo=r(E8e," (BERT model)"),E8e.forEach(t),dyo=i(U),z6=n(U,"LI",{});var C8e=s(z6);Nce=n(C8e,"STRONG",{});var nit=s(Nce);cyo=r(nit,"big_bird"),nit.forEach(t),fyo=r(C8e," \u2014 "),bD=n(C8e,"A",{href:!0});var sit=s(bD);myo=r(sit,"BigBirdForMaskedLM"),sit.forEach(t),gyo=r(C8e," (BigBird model)"),C8e.forEach(t),hyo=i(U),W6=n(U,"LI",{});var w8e=s(W6);qce=n(w8e,"STRONG",{});var lit=s(qce);pyo=r(lit,"camembert"),lit.forEach(t),_yo=r(w8e," \u2014 "),vD=n(w8e,"A",{href:!0});var iit=s(vD);uyo=r(iit,"CamembertForMaskedLM"),iit.forEach(t),byo=r(w8e," (CamemBERT model)"),w8e.forEach(t),vyo=i(U),Q6=n(U,"LI",{});var A8e=s(Q6);jce=n(A8e,"STRONG",{});var dit=s(jce);Fyo=r(dit,"convbert"),dit.forEach(t),Tyo=r(A8e," \u2014 "),FD=n(A8e,"A",{href:!0});var cit=s(FD);Myo=r(cit,"ConvBertForMaskedLM"),cit.forEach(t),Eyo=r(A8e," (ConvBERT model)"),A8e.forEach(t),Cyo=i(U),H6=n(U,"LI",{});var y8e=s(H6);Dce=n(y8e,"STRONG",{});var fit=s(Dce);wyo=r(fit,"data2vec-text"),fit.forEach(t),Ayo=r(y8e," \u2014 "),TD=n(y8e,"A",{href:!0});var mit=s(TD);yyo=r(mit,"Data2VecTextForMaskedLM"),mit.forEach(t),Lyo=r(y8e," (Data2VecText model)"),y8e.forEach(t),xyo=i(U),U6=n(U,"LI",{});var L8e=s(U6);Gce=n(L8e,"STRONG",{});var git=s(Gce);$yo=r(git,"deberta"),git.forEach(t),kyo=r(L8e," \u2014 "),MD=n(L8e,"A",{href:!0});var hit=s(MD);Syo=r(hit,"DebertaForMaskedLM"),hit.forEach(t),Ryo=r(L8e," (DeBERTa model)"),L8e.forEach(t),Pyo=i(U),J6=n(U,"LI",{});var x8e=s(J6);Oce=n(x8e,"STRONG",{});var pit=s(Oce);Byo=r(pit,"deberta-v2"),pit.forEach(t),Iyo=r(x8e," \u2014 "),ED=n(x8e,"A",{href:!0});var _it=s(ED);Nyo=r(_it,"DebertaV2ForMaskedLM"),_it.forEach(t),qyo=r(x8e," (DeBERTa-v2 model)"),x8e.forEach(t),jyo=i(U),Y6=n(U,"LI",{});var $8e=s(Y6);Vce=n($8e,"STRONG",{});var uit=s(Vce);Dyo=r(uit,"distilbert"),uit.forEach(t),Gyo=r($8e," \u2014 "),CD=n($8e,"A",{href:!0});var bit=s(CD);Oyo=r(bit,"DistilBertForMaskedLM"),bit.forEach(t),Vyo=r($8e," (DistilBERT model)"),$8e.forEach(t),Xyo=i(U),K6=n(U,"LI",{});var k8e=s(K6);Xce=n(k8e,"STRONG",{});var vit=s(Xce);zyo=r(vit,"electra"),vit.forEach(t),Wyo=r(k8e," \u2014 "),wD=n(k8e,"A",{href:!0});var Fit=s(wD);Qyo=r(Fit,"ElectraForMaskedLM"),Fit.forEach(t),Hyo=r(k8e," (ELECTRA model)"),k8e.forEach(t),Uyo=i(U),Z6=n(U,"LI",{});var S8e=s(Z6);zce=n(S8e,"STRONG",{});var Tit=s(zce);Jyo=r(Tit,"flaubert"),Tit.forEach(t),Yyo=r(S8e," \u2014 "),AD=n(S8e,"A",{href:!0});var Mit=s(AD);Kyo=r(Mit,"FlaubertWithLMHeadModel"),Mit.forEach(t),Zyo=r(S8e," (FlauBERT model)"),S8e.forEach(t),eLo=i(U),e1=n(U,"LI",{});var R8e=s(e1);Wce=n(R8e,"STRONG",{});var Eit=s(Wce);oLo=r(Eit,"fnet"),Eit.forEach(t),rLo=r(R8e," \u2014 "),yD=n(R8e,"A",{href:!0});var Cit=s(yD);tLo=r(Cit,"FNetForMaskedLM"),Cit.forEach(t),aLo=r(R8e," (FNet model)"),R8e.forEach(t),nLo=i(U),o1=n(U,"LI",{});var P8e=s(o1);Qce=n(P8e,"STRONG",{});var wit=s(Qce);sLo=r(wit,"funnel"),wit.forEach(t),lLo=r(P8e," \u2014 "),LD=n(P8e,"A",{href:!0});var Ait=s(LD);iLo=r(Ait,"FunnelForMaskedLM"),Ait.forEach(t),dLo=r(P8e," (Funnel Transformer model)"),P8e.forEach(t),cLo=i(U),r1=n(U,"LI",{});var B8e=s(r1);Hce=n(B8e,"STRONG",{});var yit=s(Hce);fLo=r(yit,"ibert"),yit.forEach(t),mLo=r(B8e," \u2014 "),xD=n(B8e,"A",{href:!0});var Lit=s(xD);gLo=r(Lit,"IBertForMaskedLM"),Lit.forEach(t),hLo=r(B8e," (I-BERT model)"),B8e.forEach(t),pLo=i(U),t1=n(U,"LI",{});var I8e=s(t1);Uce=n(I8e,"STRONG",{});var xit=s(Uce);_Lo=r(xit,"layoutlm"),xit.forEach(t),uLo=r(I8e," \u2014 "),$D=n(I8e,"A",{href:!0});var $it=s($D);bLo=r($it,"LayoutLMForMaskedLM"),$it.forEach(t),vLo=r(I8e," (LayoutLM model)"),I8e.forEach(t),FLo=i(U),a1=n(U,"LI",{});var N8e=s(a1);Jce=n(N8e,"STRONG",{});var kit=s(Jce);TLo=r(kit,"longformer"),kit.forEach(t),MLo=r(N8e," \u2014 "),kD=n(N8e,"A",{href:!0});var Sit=s(kD);ELo=r(Sit,"LongformerForMaskedLM"),Sit.forEach(t),CLo=r(N8e," (Longformer model)"),N8e.forEach(t),wLo=i(U),n1=n(U,"LI",{});var q8e=s(n1);Yce=n(q8e,"STRONG",{});var Rit=s(Yce);ALo=r(Rit,"mbart"),Rit.forEach(t),yLo=r(q8e," \u2014 "),SD=n(q8e,"A",{href:!0});var Pit=s(SD);LLo=r(Pit,"MBartForConditionalGeneration"),Pit.forEach(t),xLo=r(q8e," (mBART model)"),q8e.forEach(t),$Lo=i(U),s1=n(U,"LI",{});var j8e=s(s1);Kce=n(j8e,"STRONG",{});var Bit=s(Kce);kLo=r(Bit,"megatron-bert"),Bit.forEach(t),SLo=r(j8e," \u2014 "),RD=n(j8e,"A",{href:!0});var Iit=s(RD);RLo=r(Iit,"MegatronBertForMaskedLM"),Iit.forEach(t),PLo=r(j8e," (MegatronBert model)"),j8e.forEach(t),BLo=i(U),l1=n(U,"LI",{});var D8e=s(l1);Zce=n(D8e,"STRONG",{});var Nit=s(Zce);ILo=r(Nit,"mobilebert"),Nit.forEach(t),NLo=r(D8e," \u2014 "),PD=n(D8e,"A",{href:!0});var qit=s(PD);qLo=r(qit,"MobileBertForMaskedLM"),qit.forEach(t),jLo=r(D8e," (MobileBERT model)"),D8e.forEach(t),DLo=i(U),i1=n(U,"LI",{});var G8e=s(i1);efe=n(G8e,"STRONG",{});var jit=s(efe);GLo=r(jit,"mpnet"),jit.forEach(t),OLo=r(G8e," \u2014 "),BD=n(G8e,"A",{href:!0});var Dit=s(BD);VLo=r(Dit,"MPNetForMaskedLM"),Dit.forEach(t),XLo=r(G8e," (MPNet model)"),G8e.forEach(t),zLo=i(U),d1=n(U,"LI",{});var O8e=s(d1);ofe=n(O8e,"STRONG",{});var Git=s(ofe);WLo=r(Git,"nystromformer"),Git.forEach(t),QLo=r(O8e," \u2014 "),ID=n(O8e,"A",{href:!0});var Oit=s(ID);HLo=r(Oit,"NystromformerForMaskedLM"),Oit.forEach(t),ULo=r(O8e," (Nystromformer model)"),O8e.forEach(t),JLo=i(U),c1=n(U,"LI",{});var V8e=s(c1);rfe=n(V8e,"STRONG",{});var Vit=s(rfe);YLo=r(Vit,"perceiver"),Vit.forEach(t),KLo=r(V8e," \u2014 "),ND=n(V8e,"A",{href:!0});var Xit=s(ND);ZLo=r(Xit,"PerceiverForMaskedLM"),Xit.forEach(t),e8o=r(V8e," (Perceiver model)"),V8e.forEach(t),o8o=i(U),f1=n(U,"LI",{});var X8e=s(f1);tfe=n(X8e,"STRONG",{});var zit=s(tfe);r8o=r(zit,"qdqbert"),zit.forEach(t),t8o=r(X8e," \u2014 "),qD=n(X8e,"A",{href:!0});var Wit=s(qD);a8o=r(Wit,"QDQBertForMaskedLM"),Wit.forEach(t),n8o=r(X8e," (QDQBert model)"),X8e.forEach(t),s8o=i(U),m1=n(U,"LI",{});var z8e=s(m1);afe=n(z8e,"STRONG",{});var Qit=s(afe);l8o=r(Qit,"reformer"),Qit.forEach(t),i8o=r(z8e," \u2014 "),jD=n(z8e,"A",{href:!0});var Hit=s(jD);d8o=r(Hit,"ReformerForMaskedLM"),Hit.forEach(t),c8o=r(z8e," (Reformer model)"),z8e.forEach(t),f8o=i(U),g1=n(U,"LI",{});var W8e=s(g1);nfe=n(W8e,"STRONG",{});var Uit=s(nfe);m8o=r(Uit,"rembert"),Uit.forEach(t),g8o=r(W8e," \u2014 "),DD=n(W8e,"A",{href:!0});var Jit=s(DD);h8o=r(Jit,"RemBertForMaskedLM"),Jit.forEach(t),p8o=r(W8e," (RemBERT model)"),W8e.forEach(t),_8o=i(U),h1=n(U,"LI",{});var Q8e=s(h1);sfe=n(Q8e,"STRONG",{});var Yit=s(sfe);u8o=r(Yit,"roberta"),Yit.forEach(t),b8o=r(Q8e," \u2014 "),GD=n(Q8e,"A",{href:!0});var Kit=s(GD);v8o=r(Kit,"RobertaForMaskedLM"),Kit.forEach(t),F8o=r(Q8e," (RoBERTa model)"),Q8e.forEach(t),T8o=i(U),p1=n(U,"LI",{});var H8e=s(p1);lfe=n(H8e,"STRONG",{});var Zit=s(lfe);M8o=r(Zit,"roformer"),Zit.forEach(t),E8o=r(H8e," \u2014 "),OD=n(H8e,"A",{href:!0});var edt=s(OD);C8o=r(edt,"RoFormerForMaskedLM"),edt.forEach(t),w8o=r(H8e," (RoFormer model)"),H8e.forEach(t),A8o=i(U),_1=n(U,"LI",{});var U8e=s(_1);ife=n(U8e,"STRONG",{});var odt=s(ife);y8o=r(odt,"squeezebert"),odt.forEach(t),L8o=r(U8e," \u2014 "),VD=n(U8e,"A",{href:!0});var rdt=s(VD);x8o=r(rdt,"SqueezeBertForMaskedLM"),rdt.forEach(t),$8o=r(U8e," (SqueezeBERT model)"),U8e.forEach(t),k8o=i(U),u1=n(U,"LI",{});var J8e=s(u1);dfe=n(J8e,"STRONG",{});var tdt=s(dfe);S8o=r(tdt,"tapas"),tdt.forEach(t),R8o=r(J8e," \u2014 "),XD=n(J8e,"A",{href:!0});var adt=s(XD);P8o=r(adt,"TapasForMaskedLM"),adt.forEach(t),B8o=r(J8e," (TAPAS model)"),J8e.forEach(t),I8o=i(U),b1=n(U,"LI",{});var Y8e=s(b1);cfe=n(Y8e,"STRONG",{});var ndt=s(cfe);N8o=r(ndt,"wav2vec2"),ndt.forEach(t),q8o=r(Y8e," \u2014 "),ffe=n(Y8e,"CODE",{});var sdt=s(ffe);j8o=r(sdt,"Wav2Vec2ForMaskedLM"),sdt.forEach(t),D8o=r(Y8e," (Wav2Vec2 model)"),Y8e.forEach(t),G8o=i(U),v1=n(U,"LI",{});var K8e=s(v1);mfe=n(K8e,"STRONG",{});var ldt=s(mfe);O8o=r(ldt,"xlm"),ldt.forEach(t),V8o=r(K8e," \u2014 "),zD=n(K8e,"A",{href:!0});var idt=s(zD);X8o=r(idt,"XLMWithLMHeadModel"),idt.forEach(t),z8o=r(K8e," (XLM model)"),K8e.forEach(t),W8o=i(U),F1=n(U,"LI",{});var Z8e=s(F1);gfe=n(Z8e,"STRONG",{});var ddt=s(gfe);Q8o=r(ddt,"xlm-roberta"),ddt.forEach(t),H8o=r(Z8e," \u2014 "),WD=n(Z8e,"A",{href:!0});var cdt=s(WD);U8o=r(cdt,"XLMRobertaForMaskedLM"),cdt.forEach(t),J8o=r(Z8e," (XLM-RoBERTa model)"),Z8e.forEach(t),Y8o=i(U),T1=n(U,"LI",{});var e9e=s(T1);hfe=n(e9e,"STRONG",{});var fdt=s(hfe);K8o=r(fdt,"xlm-roberta-xl"),fdt.forEach(t),Z8o=r(e9e," \u2014 "),QD=n(e9e,"A",{href:!0});var mdt=s(QD);e9o=r(mdt,"XLMRobertaXLForMaskedLM"),mdt.forEach(t),o9o=r(e9e," (XLM-RoBERTa-XL model)"),e9e.forEach(t),r9o=i(U),M1=n(U,"LI",{});var o9e=s(M1);pfe=n(o9e,"STRONG",{});var gdt=s(pfe);t9o=r(gdt,"yoso"),gdt.forEach(t),a9o=r(o9e," \u2014 "),HD=n(o9e,"A",{href:!0});var hdt=s(HD);n9o=r(hdt,"YosoForMaskedLM"),hdt.forEach(t),s9o=r(o9e," (YOSO model)"),o9e.forEach(t),U.forEach(t),l9o=i(aa),E1=n(aa,"P",{});var r9e=s(E1);i9o=r(r9e,"The model is set in evaluation mode by default using "),_fe=n(r9e,"CODE",{});var pdt=s(_fe);d9o=r(pdt,"model.eval()"),pdt.forEach(t),c9o=r(r9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ufe=n(r9e,"CODE",{});var _dt=s(ufe);f9o=r(_dt,"model.train()"),_dt.forEach(t),r9e.forEach(t),m9o=i(aa),T(C1.$$.fragment,aa),aa.forEach(t),zs.forEach(t),Iqe=i(f),qi=n(f,"H2",{class:!0});var DDe=s(qi);w1=n(DDe,"A",{id:!0,class:!0,href:!0});var udt=s(w1);bfe=n(udt,"SPAN",{});var bdt=s(bfe);T(Ey.$$.fragment,bdt),bdt.forEach(t),udt.forEach(t),g9o=i(DDe),vfe=n(DDe,"SPAN",{});var vdt=s(vfe);h9o=r(vdt,"AutoModelForSeq2SeqLM"),vdt.forEach(t),DDe.forEach(t),Nqe=i(f),So=n(f,"DIV",{class:!0});var Ws=s(So);T(Cy.$$.fragment,Ws),p9o=i(Ws),ji=n(Ws,"P",{});var RZ=s(ji);_9o=r(RZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),UD=n(RZ,"A",{href:!0});var Fdt=s(UD);u9o=r(Fdt,"from_pretrained()"),Fdt.forEach(t),b9o=r(RZ," class method or the "),JD=n(RZ,"A",{href:!0});var Tdt=s(JD);v9o=r(Tdt,"from_config()"),Tdt.forEach(t),F9o=r(RZ,` class
method.`),RZ.forEach(t),T9o=i(Ws),wy=n(Ws,"P",{});var GDe=s(wy);M9o=r(GDe,"This class cannot be instantiated directly using "),Ffe=n(GDe,"CODE",{});var Mdt=s(Ffe);E9o=r(Mdt,"__init__()"),Mdt.forEach(t),C9o=r(GDe," (throws an error)."),GDe.forEach(t),w9o=i(Ws),lt=n(Ws,"DIV",{class:!0});var Vw=s(lt);T(Ay.$$.fragment,Vw),A9o=i(Vw),Tfe=n(Vw,"P",{});var Edt=s(Tfe);y9o=r(Edt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Edt.forEach(t),L9o=i(Vw),Di=n(Vw,"P",{});var PZ=s(Di);x9o=r(PZ,`Note:
Loading a model from its configuration file does `),Mfe=n(PZ,"STRONG",{});var Cdt=s(Mfe);$9o=r(Cdt,"not"),Cdt.forEach(t),k9o=r(PZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),YD=n(PZ,"A",{href:!0});var wdt=s(YD);S9o=r(wdt,"from_pretrained()"),wdt.forEach(t),R9o=r(PZ," to load the model weights."),PZ.forEach(t),P9o=i(Vw),T(A1.$$.fragment,Vw),Vw.forEach(t),B9o=i(Ws),eo=n(Ws,"DIV",{class:!0});var na=s(eo);T(yy.$$.fragment,na),I9o=i(na),Efe=n(na,"P",{});var Adt=s(Efe);N9o=r(Adt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Adt.forEach(t),q9o=i(na),Sa=n(na,"P",{});var Xw=s(Sa);j9o=r(Xw,"The model class to instantiate is selected based on the "),Cfe=n(Xw,"CODE",{});var ydt=s(Cfe);D9o=r(ydt,"model_type"),ydt.forEach(t),G9o=r(Xw,` property of the config object (either
passed as an argument or loaded from `),wfe=n(Xw,"CODE",{});var Ldt=s(wfe);O9o=r(Ldt,"pretrained_model_name_or_path"),Ldt.forEach(t),V9o=r(Xw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Afe=n(Xw,"CODE",{});var xdt=s(Afe);X9o=r(xdt,"pretrained_model_name_or_path"),xdt.forEach(t),z9o=r(Xw,":"),Xw.forEach(t),W9o=i(na),_e=n(na,"UL",{});var Fe=s(_e);y1=n(Fe,"LI",{});var t9e=s(y1);yfe=n(t9e,"STRONG",{});var $dt=s(yfe);Q9o=r($dt,"bart"),$dt.forEach(t),H9o=r(t9e," \u2014 "),KD=n(t9e,"A",{href:!0});var kdt=s(KD);U9o=r(kdt,"BartForConditionalGeneration"),kdt.forEach(t),J9o=r(t9e," (BART model)"),t9e.forEach(t),Y9o=i(Fe),L1=n(Fe,"LI",{});var a9e=s(L1);Lfe=n(a9e,"STRONG",{});var Sdt=s(Lfe);K9o=r(Sdt,"bigbird_pegasus"),Sdt.forEach(t),Z9o=r(a9e," \u2014 "),ZD=n(a9e,"A",{href:!0});var Rdt=s(ZD);exo=r(Rdt,"BigBirdPegasusForConditionalGeneration"),Rdt.forEach(t),oxo=r(a9e," (BigBirdPegasus model)"),a9e.forEach(t),rxo=i(Fe),x1=n(Fe,"LI",{});var n9e=s(x1);xfe=n(n9e,"STRONG",{});var Pdt=s(xfe);txo=r(Pdt,"blenderbot"),Pdt.forEach(t),axo=r(n9e," \u2014 "),eG=n(n9e,"A",{href:!0});var Bdt=s(eG);nxo=r(Bdt,"BlenderbotForConditionalGeneration"),Bdt.forEach(t),sxo=r(n9e," (Blenderbot model)"),n9e.forEach(t),lxo=i(Fe),$1=n(Fe,"LI",{});var s9e=s($1);$fe=n(s9e,"STRONG",{});var Idt=s($fe);ixo=r(Idt,"blenderbot-small"),Idt.forEach(t),dxo=r(s9e," \u2014 "),oG=n(s9e,"A",{href:!0});var Ndt=s(oG);cxo=r(Ndt,"BlenderbotSmallForConditionalGeneration"),Ndt.forEach(t),fxo=r(s9e," (BlenderbotSmall model)"),s9e.forEach(t),mxo=i(Fe),k1=n(Fe,"LI",{});var l9e=s(k1);kfe=n(l9e,"STRONG",{});var qdt=s(kfe);gxo=r(qdt,"encoder-decoder"),qdt.forEach(t),hxo=r(l9e," \u2014 "),rG=n(l9e,"A",{href:!0});var jdt=s(rG);pxo=r(jdt,"EncoderDecoderModel"),jdt.forEach(t),_xo=r(l9e," (Encoder decoder model)"),l9e.forEach(t),uxo=i(Fe),S1=n(Fe,"LI",{});var i9e=s(S1);Sfe=n(i9e,"STRONG",{});var Ddt=s(Sfe);bxo=r(Ddt,"fsmt"),Ddt.forEach(t),vxo=r(i9e," \u2014 "),tG=n(i9e,"A",{href:!0});var Gdt=s(tG);Fxo=r(Gdt,"FSMTForConditionalGeneration"),Gdt.forEach(t),Txo=r(i9e," (FairSeq Machine-Translation model)"),i9e.forEach(t),Mxo=i(Fe),R1=n(Fe,"LI",{});var d9e=s(R1);Rfe=n(d9e,"STRONG",{});var Odt=s(Rfe);Exo=r(Odt,"led"),Odt.forEach(t),Cxo=r(d9e," \u2014 "),aG=n(d9e,"A",{href:!0});var Vdt=s(aG);wxo=r(Vdt,"LEDForConditionalGeneration"),Vdt.forEach(t),Axo=r(d9e," (LED model)"),d9e.forEach(t),yxo=i(Fe),P1=n(Fe,"LI",{});var c9e=s(P1);Pfe=n(c9e,"STRONG",{});var Xdt=s(Pfe);Lxo=r(Xdt,"m2m_100"),Xdt.forEach(t),xxo=r(c9e," \u2014 "),nG=n(c9e,"A",{href:!0});var zdt=s(nG);$xo=r(zdt,"M2M100ForConditionalGeneration"),zdt.forEach(t),kxo=r(c9e," (M2M100 model)"),c9e.forEach(t),Sxo=i(Fe),B1=n(Fe,"LI",{});var f9e=s(B1);Bfe=n(f9e,"STRONG",{});var Wdt=s(Bfe);Rxo=r(Wdt,"marian"),Wdt.forEach(t),Pxo=r(f9e," \u2014 "),sG=n(f9e,"A",{href:!0});var Qdt=s(sG);Bxo=r(Qdt,"MarianMTModel"),Qdt.forEach(t),Ixo=r(f9e," (Marian model)"),f9e.forEach(t),Nxo=i(Fe),I1=n(Fe,"LI",{});var m9e=s(I1);Ife=n(m9e,"STRONG",{});var Hdt=s(Ife);qxo=r(Hdt,"mbart"),Hdt.forEach(t),jxo=r(m9e," \u2014 "),lG=n(m9e,"A",{href:!0});var Udt=s(lG);Dxo=r(Udt,"MBartForConditionalGeneration"),Udt.forEach(t),Gxo=r(m9e," (mBART model)"),m9e.forEach(t),Oxo=i(Fe),N1=n(Fe,"LI",{});var g9e=s(N1);Nfe=n(g9e,"STRONG",{});var Jdt=s(Nfe);Vxo=r(Jdt,"mt5"),Jdt.forEach(t),Xxo=r(g9e," \u2014 "),iG=n(g9e,"A",{href:!0});var Ydt=s(iG);zxo=r(Ydt,"MT5ForConditionalGeneration"),Ydt.forEach(t),Wxo=r(g9e," (mT5 model)"),g9e.forEach(t),Qxo=i(Fe),q1=n(Fe,"LI",{});var h9e=s(q1);qfe=n(h9e,"STRONG",{});var Kdt=s(qfe);Hxo=r(Kdt,"pegasus"),Kdt.forEach(t),Uxo=r(h9e," \u2014 "),dG=n(h9e,"A",{href:!0});var Zdt=s(dG);Jxo=r(Zdt,"PegasusForConditionalGeneration"),Zdt.forEach(t),Yxo=r(h9e," (Pegasus model)"),h9e.forEach(t),Kxo=i(Fe),j1=n(Fe,"LI",{});var p9e=s(j1);jfe=n(p9e,"STRONG",{});var ect=s(jfe);Zxo=r(ect,"plbart"),ect.forEach(t),e$o=r(p9e," \u2014 "),cG=n(p9e,"A",{href:!0});var oct=s(cG);o$o=r(oct,"PLBartForConditionalGeneration"),oct.forEach(t),r$o=r(p9e," (PLBart model)"),p9e.forEach(t),t$o=i(Fe),D1=n(Fe,"LI",{});var _9e=s(D1);Dfe=n(_9e,"STRONG",{});var rct=s(Dfe);a$o=r(rct,"prophetnet"),rct.forEach(t),n$o=r(_9e," \u2014 "),fG=n(_9e,"A",{href:!0});var tct=s(fG);s$o=r(tct,"ProphetNetForConditionalGeneration"),tct.forEach(t),l$o=r(_9e," (ProphetNet model)"),_9e.forEach(t),i$o=i(Fe),G1=n(Fe,"LI",{});var u9e=s(G1);Gfe=n(u9e,"STRONG",{});var act=s(Gfe);d$o=r(act,"t5"),act.forEach(t),c$o=r(u9e," \u2014 "),mG=n(u9e,"A",{href:!0});var nct=s(mG);f$o=r(nct,"T5ForConditionalGeneration"),nct.forEach(t),m$o=r(u9e," (T5 model)"),u9e.forEach(t),g$o=i(Fe),O1=n(Fe,"LI",{});var b9e=s(O1);Ofe=n(b9e,"STRONG",{});var sct=s(Ofe);h$o=r(sct,"xlm-prophetnet"),sct.forEach(t),p$o=r(b9e," \u2014 "),gG=n(b9e,"A",{href:!0});var lct=s(gG);_$o=r(lct,"XLMProphetNetForConditionalGeneration"),lct.forEach(t),u$o=r(b9e," (XLMProphetNet model)"),b9e.forEach(t),Fe.forEach(t),b$o=i(na),V1=n(na,"P",{});var v9e=s(V1);v$o=r(v9e,"The model is set in evaluation mode by default using "),Vfe=n(v9e,"CODE",{});var ict=s(Vfe);F$o=r(ict,"model.eval()"),ict.forEach(t),T$o=r(v9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Xfe=n(v9e,"CODE",{});var dct=s(Xfe);M$o=r(dct,"model.train()"),dct.forEach(t),v9e.forEach(t),E$o=i(na),T(X1.$$.fragment,na),na.forEach(t),Ws.forEach(t),qqe=i(f),Gi=n(f,"H2",{class:!0});var ODe=s(Gi);z1=n(ODe,"A",{id:!0,class:!0,href:!0});var cct=s(z1);zfe=n(cct,"SPAN",{});var fct=s(zfe);T(Ly.$$.fragment,fct),fct.forEach(t),cct.forEach(t),C$o=i(ODe),Wfe=n(ODe,"SPAN",{});var mct=s(Wfe);w$o=r(mct,"AutoModelForSequenceClassification"),mct.forEach(t),ODe.forEach(t),jqe=i(f),Ro=n(f,"DIV",{class:!0});var Qs=s(Ro);T(xy.$$.fragment,Qs),A$o=i(Qs),Oi=n(Qs,"P",{});var BZ=s(Oi);y$o=r(BZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),hG=n(BZ,"A",{href:!0});var gct=s(hG);L$o=r(gct,"from_pretrained()"),gct.forEach(t),x$o=r(BZ," class method or the "),pG=n(BZ,"A",{href:!0});var hct=s(pG);$$o=r(hct,"from_config()"),hct.forEach(t),k$o=r(BZ,` class
method.`),BZ.forEach(t),S$o=i(Qs),$y=n(Qs,"P",{});var VDe=s($y);R$o=r(VDe,"This class cannot be instantiated directly using "),Qfe=n(VDe,"CODE",{});var pct=s(Qfe);P$o=r(pct,"__init__()"),pct.forEach(t),B$o=r(VDe," (throws an error)."),VDe.forEach(t),I$o=i(Qs),it=n(Qs,"DIV",{class:!0});var zw=s(it);T(ky.$$.fragment,zw),N$o=i(zw),Hfe=n(zw,"P",{});var _ct=s(Hfe);q$o=r(_ct,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),_ct.forEach(t),j$o=i(zw),Vi=n(zw,"P",{});var IZ=s(Vi);D$o=r(IZ,`Note:
Loading a model from its configuration file does `),Ufe=n(IZ,"STRONG",{});var uct=s(Ufe);G$o=r(uct,"not"),uct.forEach(t),O$o=r(IZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),_G=n(IZ,"A",{href:!0});var bct=s(_G);V$o=r(bct,"from_pretrained()"),bct.forEach(t),X$o=r(IZ," to load the model weights."),IZ.forEach(t),z$o=i(zw),T(W1.$$.fragment,zw),zw.forEach(t),W$o=i(Qs),oo=n(Qs,"DIV",{class:!0});var sa=s(oo);T(Sy.$$.fragment,sa),Q$o=i(sa),Jfe=n(sa,"P",{});var vct=s(Jfe);H$o=r(vct,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),vct.forEach(t),U$o=i(sa),Ra=n(sa,"P",{});var Ww=s(Ra);J$o=r(Ww,"The model class to instantiate is selected based on the "),Yfe=n(Ww,"CODE",{});var Fct=s(Yfe);Y$o=r(Fct,"model_type"),Fct.forEach(t),K$o=r(Ww,` property of the config object (either
passed as an argument or loaded from `),Kfe=n(Ww,"CODE",{});var Tct=s(Kfe);Z$o=r(Tct,"pretrained_model_name_or_path"),Tct.forEach(t),eko=r(Ww,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zfe=n(Ww,"CODE",{});var Mct=s(Zfe);oko=r(Mct,"pretrained_model_name_or_path"),Mct.forEach(t),rko=r(Ww,":"),Ww.forEach(t),tko=i(sa),N=n(sa,"UL",{});var j=s(N);Q1=n(j,"LI",{});var F9e=s(Q1);eme=n(F9e,"STRONG",{});var Ect=s(eme);ako=r(Ect,"albert"),Ect.forEach(t),nko=r(F9e," \u2014 "),uG=n(F9e,"A",{href:!0});var Cct=s(uG);sko=r(Cct,"AlbertForSequenceClassification"),Cct.forEach(t),lko=r(F9e," (ALBERT model)"),F9e.forEach(t),iko=i(j),H1=n(j,"LI",{});var T9e=s(H1);ome=n(T9e,"STRONG",{});var wct=s(ome);dko=r(wct,"bart"),wct.forEach(t),cko=r(T9e," \u2014 "),bG=n(T9e,"A",{href:!0});var Act=s(bG);fko=r(Act,"BartForSequenceClassification"),Act.forEach(t),mko=r(T9e," (BART model)"),T9e.forEach(t),gko=i(j),U1=n(j,"LI",{});var M9e=s(U1);rme=n(M9e,"STRONG",{});var yct=s(rme);hko=r(yct,"bert"),yct.forEach(t),pko=r(M9e," \u2014 "),vG=n(M9e,"A",{href:!0});var Lct=s(vG);_ko=r(Lct,"BertForSequenceClassification"),Lct.forEach(t),uko=r(M9e," (BERT model)"),M9e.forEach(t),bko=i(j),J1=n(j,"LI",{});var E9e=s(J1);tme=n(E9e,"STRONG",{});var xct=s(tme);vko=r(xct,"big_bird"),xct.forEach(t),Fko=r(E9e," \u2014 "),FG=n(E9e,"A",{href:!0});var $ct=s(FG);Tko=r($ct,"BigBirdForSequenceClassification"),$ct.forEach(t),Mko=r(E9e," (BigBird model)"),E9e.forEach(t),Eko=i(j),Y1=n(j,"LI",{});var C9e=s(Y1);ame=n(C9e,"STRONG",{});var kct=s(ame);Cko=r(kct,"bigbird_pegasus"),kct.forEach(t),wko=r(C9e," \u2014 "),TG=n(C9e,"A",{href:!0});var Sct=s(TG);Ako=r(Sct,"BigBirdPegasusForSequenceClassification"),Sct.forEach(t),yko=r(C9e," (BigBirdPegasus model)"),C9e.forEach(t),Lko=i(j),K1=n(j,"LI",{});var w9e=s(K1);nme=n(w9e,"STRONG",{});var Rct=s(nme);xko=r(Rct,"camembert"),Rct.forEach(t),$ko=r(w9e," \u2014 "),MG=n(w9e,"A",{href:!0});var Pct=s(MG);kko=r(Pct,"CamembertForSequenceClassification"),Pct.forEach(t),Sko=r(w9e," (CamemBERT model)"),w9e.forEach(t),Rko=i(j),Z1=n(j,"LI",{});var A9e=s(Z1);sme=n(A9e,"STRONG",{});var Bct=s(sme);Pko=r(Bct,"canine"),Bct.forEach(t),Bko=r(A9e," \u2014 "),EG=n(A9e,"A",{href:!0});var Ict=s(EG);Iko=r(Ict,"CanineForSequenceClassification"),Ict.forEach(t),Nko=r(A9e," (Canine model)"),A9e.forEach(t),qko=i(j),eb=n(j,"LI",{});var y9e=s(eb);lme=n(y9e,"STRONG",{});var Nct=s(lme);jko=r(Nct,"convbert"),Nct.forEach(t),Dko=r(y9e," \u2014 "),CG=n(y9e,"A",{href:!0});var qct=s(CG);Gko=r(qct,"ConvBertForSequenceClassification"),qct.forEach(t),Oko=r(y9e," (ConvBERT model)"),y9e.forEach(t),Vko=i(j),ob=n(j,"LI",{});var L9e=s(ob);ime=n(L9e,"STRONG",{});var jct=s(ime);Xko=r(jct,"ctrl"),jct.forEach(t),zko=r(L9e," \u2014 "),wG=n(L9e,"A",{href:!0});var Dct=s(wG);Wko=r(Dct,"CTRLForSequenceClassification"),Dct.forEach(t),Qko=r(L9e," (CTRL model)"),L9e.forEach(t),Hko=i(j),rb=n(j,"LI",{});var x9e=s(rb);dme=n(x9e,"STRONG",{});var Gct=s(dme);Uko=r(Gct,"data2vec-text"),Gct.forEach(t),Jko=r(x9e," \u2014 "),AG=n(x9e,"A",{href:!0});var Oct=s(AG);Yko=r(Oct,"Data2VecTextForSequenceClassification"),Oct.forEach(t),Kko=r(x9e," (Data2VecText model)"),x9e.forEach(t),Zko=i(j),tb=n(j,"LI",{});var $9e=s(tb);cme=n($9e,"STRONG",{});var Vct=s(cme);eSo=r(Vct,"deberta"),Vct.forEach(t),oSo=r($9e," \u2014 "),yG=n($9e,"A",{href:!0});var Xct=s(yG);rSo=r(Xct,"DebertaForSequenceClassification"),Xct.forEach(t),tSo=r($9e," (DeBERTa model)"),$9e.forEach(t),aSo=i(j),ab=n(j,"LI",{});var k9e=s(ab);fme=n(k9e,"STRONG",{});var zct=s(fme);nSo=r(zct,"deberta-v2"),zct.forEach(t),sSo=r(k9e," \u2014 "),LG=n(k9e,"A",{href:!0});var Wct=s(LG);lSo=r(Wct,"DebertaV2ForSequenceClassification"),Wct.forEach(t),iSo=r(k9e," (DeBERTa-v2 model)"),k9e.forEach(t),dSo=i(j),nb=n(j,"LI",{});var S9e=s(nb);mme=n(S9e,"STRONG",{});var Qct=s(mme);cSo=r(Qct,"distilbert"),Qct.forEach(t),fSo=r(S9e," \u2014 "),xG=n(S9e,"A",{href:!0});var Hct=s(xG);mSo=r(Hct,"DistilBertForSequenceClassification"),Hct.forEach(t),gSo=r(S9e," (DistilBERT model)"),S9e.forEach(t),hSo=i(j),sb=n(j,"LI",{});var R9e=s(sb);gme=n(R9e,"STRONG",{});var Uct=s(gme);pSo=r(Uct,"electra"),Uct.forEach(t),_So=r(R9e," \u2014 "),$G=n(R9e,"A",{href:!0});var Jct=s($G);uSo=r(Jct,"ElectraForSequenceClassification"),Jct.forEach(t),bSo=r(R9e," (ELECTRA model)"),R9e.forEach(t),vSo=i(j),lb=n(j,"LI",{});var P9e=s(lb);hme=n(P9e,"STRONG",{});var Yct=s(hme);FSo=r(Yct,"flaubert"),Yct.forEach(t),TSo=r(P9e," \u2014 "),kG=n(P9e,"A",{href:!0});var Kct=s(kG);MSo=r(Kct,"FlaubertForSequenceClassification"),Kct.forEach(t),ESo=r(P9e," (FlauBERT model)"),P9e.forEach(t),CSo=i(j),ib=n(j,"LI",{});var B9e=s(ib);pme=n(B9e,"STRONG",{});var Zct=s(pme);wSo=r(Zct,"fnet"),Zct.forEach(t),ASo=r(B9e," \u2014 "),SG=n(B9e,"A",{href:!0});var eft=s(SG);ySo=r(eft,"FNetForSequenceClassification"),eft.forEach(t),LSo=r(B9e," (FNet model)"),B9e.forEach(t),xSo=i(j),db=n(j,"LI",{});var I9e=s(db);_me=n(I9e,"STRONG",{});var oft=s(_me);$So=r(oft,"funnel"),oft.forEach(t),kSo=r(I9e," \u2014 "),RG=n(I9e,"A",{href:!0});var rft=s(RG);SSo=r(rft,"FunnelForSequenceClassification"),rft.forEach(t),RSo=r(I9e," (Funnel Transformer model)"),I9e.forEach(t),PSo=i(j),cb=n(j,"LI",{});var N9e=s(cb);ume=n(N9e,"STRONG",{});var tft=s(ume);BSo=r(tft,"gpt2"),tft.forEach(t),ISo=r(N9e," \u2014 "),PG=n(N9e,"A",{href:!0});var aft=s(PG);NSo=r(aft,"GPT2ForSequenceClassification"),aft.forEach(t),qSo=r(N9e," (OpenAI GPT-2 model)"),N9e.forEach(t),jSo=i(j),fb=n(j,"LI",{});var q9e=s(fb);bme=n(q9e,"STRONG",{});var nft=s(bme);DSo=r(nft,"gpt_neo"),nft.forEach(t),GSo=r(q9e," \u2014 "),BG=n(q9e,"A",{href:!0});var sft=s(BG);OSo=r(sft,"GPTNeoForSequenceClassification"),sft.forEach(t),VSo=r(q9e," (GPT Neo model)"),q9e.forEach(t),XSo=i(j),mb=n(j,"LI",{});var j9e=s(mb);vme=n(j9e,"STRONG",{});var lft=s(vme);zSo=r(lft,"gptj"),lft.forEach(t),WSo=r(j9e," \u2014 "),IG=n(j9e,"A",{href:!0});var ift=s(IG);QSo=r(ift,"GPTJForSequenceClassification"),ift.forEach(t),HSo=r(j9e," (GPT-J model)"),j9e.forEach(t),USo=i(j),gb=n(j,"LI",{});var D9e=s(gb);Fme=n(D9e,"STRONG",{});var dft=s(Fme);JSo=r(dft,"ibert"),dft.forEach(t),YSo=r(D9e," \u2014 "),NG=n(D9e,"A",{href:!0});var cft=s(NG);KSo=r(cft,"IBertForSequenceClassification"),cft.forEach(t),ZSo=r(D9e," (I-BERT model)"),D9e.forEach(t),eRo=i(j),hb=n(j,"LI",{});var G9e=s(hb);Tme=n(G9e,"STRONG",{});var fft=s(Tme);oRo=r(fft,"layoutlm"),fft.forEach(t),rRo=r(G9e," \u2014 "),qG=n(G9e,"A",{href:!0});var mft=s(qG);tRo=r(mft,"LayoutLMForSequenceClassification"),mft.forEach(t),aRo=r(G9e," (LayoutLM model)"),G9e.forEach(t),nRo=i(j),pb=n(j,"LI",{});var O9e=s(pb);Mme=n(O9e,"STRONG",{});var gft=s(Mme);sRo=r(gft,"layoutlmv2"),gft.forEach(t),lRo=r(O9e," \u2014 "),jG=n(O9e,"A",{href:!0});var hft=s(jG);iRo=r(hft,"LayoutLMv2ForSequenceClassification"),hft.forEach(t),dRo=r(O9e," (LayoutLMv2 model)"),O9e.forEach(t),cRo=i(j),_b=n(j,"LI",{});var V9e=s(_b);Eme=n(V9e,"STRONG",{});var pft=s(Eme);fRo=r(pft,"layoutlmv3"),pft.forEach(t),mRo=r(V9e," \u2014 "),DG=n(V9e,"A",{href:!0});var _ft=s(DG);gRo=r(_ft,"LayoutLMv3ForSequenceClassification"),_ft.forEach(t),hRo=r(V9e," (LayoutLMv3 model)"),V9e.forEach(t),pRo=i(j),ub=n(j,"LI",{});var X9e=s(ub);Cme=n(X9e,"STRONG",{});var uft=s(Cme);_Ro=r(uft,"led"),uft.forEach(t),uRo=r(X9e," \u2014 "),GG=n(X9e,"A",{href:!0});var bft=s(GG);bRo=r(bft,"LEDForSequenceClassification"),bft.forEach(t),vRo=r(X9e," (LED model)"),X9e.forEach(t),FRo=i(j),bb=n(j,"LI",{});var z9e=s(bb);wme=n(z9e,"STRONG",{});var vft=s(wme);TRo=r(vft,"longformer"),vft.forEach(t),MRo=r(z9e," \u2014 "),OG=n(z9e,"A",{href:!0});var Fft=s(OG);ERo=r(Fft,"LongformerForSequenceClassification"),Fft.forEach(t),CRo=r(z9e," (Longformer model)"),z9e.forEach(t),wRo=i(j),vb=n(j,"LI",{});var W9e=s(vb);Ame=n(W9e,"STRONG",{});var Tft=s(Ame);ARo=r(Tft,"mbart"),Tft.forEach(t),yRo=r(W9e," \u2014 "),VG=n(W9e,"A",{href:!0});var Mft=s(VG);LRo=r(Mft,"MBartForSequenceClassification"),Mft.forEach(t),xRo=r(W9e," (mBART model)"),W9e.forEach(t),$Ro=i(j),Fb=n(j,"LI",{});var Q9e=s(Fb);yme=n(Q9e,"STRONG",{});var Eft=s(yme);kRo=r(Eft,"megatron-bert"),Eft.forEach(t),SRo=r(Q9e," \u2014 "),XG=n(Q9e,"A",{href:!0});var Cft=s(XG);RRo=r(Cft,"MegatronBertForSequenceClassification"),Cft.forEach(t),PRo=r(Q9e," (MegatronBert model)"),Q9e.forEach(t),BRo=i(j),Tb=n(j,"LI",{});var H9e=s(Tb);Lme=n(H9e,"STRONG",{});var wft=s(Lme);IRo=r(wft,"mobilebert"),wft.forEach(t),NRo=r(H9e," \u2014 "),zG=n(H9e,"A",{href:!0});var Aft=s(zG);qRo=r(Aft,"MobileBertForSequenceClassification"),Aft.forEach(t),jRo=r(H9e," (MobileBERT model)"),H9e.forEach(t),DRo=i(j),Mb=n(j,"LI",{});var U9e=s(Mb);xme=n(U9e,"STRONG",{});var yft=s(xme);GRo=r(yft,"mpnet"),yft.forEach(t),ORo=r(U9e," \u2014 "),WG=n(U9e,"A",{href:!0});var Lft=s(WG);VRo=r(Lft,"MPNetForSequenceClassification"),Lft.forEach(t),XRo=r(U9e," (MPNet model)"),U9e.forEach(t),zRo=i(j),Eb=n(j,"LI",{});var J9e=s(Eb);$me=n(J9e,"STRONG",{});var xft=s($me);WRo=r(xft,"nystromformer"),xft.forEach(t),QRo=r(J9e," \u2014 "),QG=n(J9e,"A",{href:!0});var $ft=s(QG);HRo=r($ft,"NystromformerForSequenceClassification"),$ft.forEach(t),URo=r(J9e," (Nystromformer model)"),J9e.forEach(t),JRo=i(j),Cb=n(j,"LI",{});var Y9e=s(Cb);kme=n(Y9e,"STRONG",{});var kft=s(kme);YRo=r(kft,"openai-gpt"),kft.forEach(t),KRo=r(Y9e," \u2014 "),HG=n(Y9e,"A",{href:!0});var Sft=s(HG);ZRo=r(Sft,"OpenAIGPTForSequenceClassification"),Sft.forEach(t),ePo=r(Y9e," (OpenAI GPT model)"),Y9e.forEach(t),oPo=i(j),wb=n(j,"LI",{});var K9e=s(wb);Sme=n(K9e,"STRONG",{});var Rft=s(Sme);rPo=r(Rft,"perceiver"),Rft.forEach(t),tPo=r(K9e," \u2014 "),UG=n(K9e,"A",{href:!0});var Pft=s(UG);aPo=r(Pft,"PerceiverForSequenceClassification"),Pft.forEach(t),nPo=r(K9e," (Perceiver model)"),K9e.forEach(t),sPo=i(j),Ab=n(j,"LI",{});var Z9e=s(Ab);Rme=n(Z9e,"STRONG",{});var Bft=s(Rme);lPo=r(Bft,"plbart"),Bft.forEach(t),iPo=r(Z9e," \u2014 "),JG=n(Z9e,"A",{href:!0});var Ift=s(JG);dPo=r(Ift,"PLBartForSequenceClassification"),Ift.forEach(t),cPo=r(Z9e," (PLBart model)"),Z9e.forEach(t),fPo=i(j),yb=n(j,"LI",{});var exe=s(yb);Pme=n(exe,"STRONG",{});var Nft=s(Pme);mPo=r(Nft,"qdqbert"),Nft.forEach(t),gPo=r(exe," \u2014 "),YG=n(exe,"A",{href:!0});var qft=s(YG);hPo=r(qft,"QDQBertForSequenceClassification"),qft.forEach(t),pPo=r(exe," (QDQBert model)"),exe.forEach(t),_Po=i(j),Lb=n(j,"LI",{});var oxe=s(Lb);Bme=n(oxe,"STRONG",{});var jft=s(Bme);uPo=r(jft,"reformer"),jft.forEach(t),bPo=r(oxe," \u2014 "),KG=n(oxe,"A",{href:!0});var Dft=s(KG);vPo=r(Dft,"ReformerForSequenceClassification"),Dft.forEach(t),FPo=r(oxe," (Reformer model)"),oxe.forEach(t),TPo=i(j),xb=n(j,"LI",{});var rxe=s(xb);Ime=n(rxe,"STRONG",{});var Gft=s(Ime);MPo=r(Gft,"rembert"),Gft.forEach(t),EPo=r(rxe," \u2014 "),ZG=n(rxe,"A",{href:!0});var Oft=s(ZG);CPo=r(Oft,"RemBertForSequenceClassification"),Oft.forEach(t),wPo=r(rxe," (RemBERT model)"),rxe.forEach(t),APo=i(j),$b=n(j,"LI",{});var txe=s($b);Nme=n(txe,"STRONG",{});var Vft=s(Nme);yPo=r(Vft,"roberta"),Vft.forEach(t),LPo=r(txe," \u2014 "),eO=n(txe,"A",{href:!0});var Xft=s(eO);xPo=r(Xft,"RobertaForSequenceClassification"),Xft.forEach(t),$Po=r(txe," (RoBERTa model)"),txe.forEach(t),kPo=i(j),kb=n(j,"LI",{});var axe=s(kb);qme=n(axe,"STRONG",{});var zft=s(qme);SPo=r(zft,"roformer"),zft.forEach(t),RPo=r(axe," \u2014 "),oO=n(axe,"A",{href:!0});var Wft=s(oO);PPo=r(Wft,"RoFormerForSequenceClassification"),Wft.forEach(t),BPo=r(axe," (RoFormer model)"),axe.forEach(t),IPo=i(j),Sb=n(j,"LI",{});var nxe=s(Sb);jme=n(nxe,"STRONG",{});var Qft=s(jme);NPo=r(Qft,"squeezebert"),Qft.forEach(t),qPo=r(nxe," \u2014 "),rO=n(nxe,"A",{href:!0});var Hft=s(rO);jPo=r(Hft,"SqueezeBertForSequenceClassification"),Hft.forEach(t),DPo=r(nxe," (SqueezeBERT model)"),nxe.forEach(t),GPo=i(j),Rb=n(j,"LI",{});var sxe=s(Rb);Dme=n(sxe,"STRONG",{});var Uft=s(Dme);OPo=r(Uft,"tapas"),Uft.forEach(t),VPo=r(sxe," \u2014 "),tO=n(sxe,"A",{href:!0});var Jft=s(tO);XPo=r(Jft,"TapasForSequenceClassification"),Jft.forEach(t),zPo=r(sxe," (TAPAS model)"),sxe.forEach(t),WPo=i(j),Pb=n(j,"LI",{});var lxe=s(Pb);Gme=n(lxe,"STRONG",{});var Yft=s(Gme);QPo=r(Yft,"transfo-xl"),Yft.forEach(t),HPo=r(lxe," \u2014 "),aO=n(lxe,"A",{href:!0});var Kft=s(aO);UPo=r(Kft,"TransfoXLForSequenceClassification"),Kft.forEach(t),JPo=r(lxe," (Transformer-XL model)"),lxe.forEach(t),YPo=i(j),Bb=n(j,"LI",{});var ixe=s(Bb);Ome=n(ixe,"STRONG",{});var Zft=s(Ome);KPo=r(Zft,"xlm"),Zft.forEach(t),ZPo=r(ixe," \u2014 "),nO=n(ixe,"A",{href:!0});var emt=s(nO);eBo=r(emt,"XLMForSequenceClassification"),emt.forEach(t),oBo=r(ixe," (XLM model)"),ixe.forEach(t),rBo=i(j),Ib=n(j,"LI",{});var dxe=s(Ib);Vme=n(dxe,"STRONG",{});var omt=s(Vme);tBo=r(omt,"xlm-roberta"),omt.forEach(t),aBo=r(dxe," \u2014 "),sO=n(dxe,"A",{href:!0});var rmt=s(sO);nBo=r(rmt,"XLMRobertaForSequenceClassification"),rmt.forEach(t),sBo=r(dxe," (XLM-RoBERTa model)"),dxe.forEach(t),lBo=i(j),Nb=n(j,"LI",{});var cxe=s(Nb);Xme=n(cxe,"STRONG",{});var tmt=s(Xme);iBo=r(tmt,"xlm-roberta-xl"),tmt.forEach(t),dBo=r(cxe," \u2014 "),lO=n(cxe,"A",{href:!0});var amt=s(lO);cBo=r(amt,"XLMRobertaXLForSequenceClassification"),amt.forEach(t),fBo=r(cxe," (XLM-RoBERTa-XL model)"),cxe.forEach(t),mBo=i(j),qb=n(j,"LI",{});var fxe=s(qb);zme=n(fxe,"STRONG",{});var nmt=s(zme);gBo=r(nmt,"xlnet"),nmt.forEach(t),hBo=r(fxe," \u2014 "),iO=n(fxe,"A",{href:!0});var smt=s(iO);pBo=r(smt,"XLNetForSequenceClassification"),smt.forEach(t),_Bo=r(fxe," (XLNet model)"),fxe.forEach(t),uBo=i(j),jb=n(j,"LI",{});var mxe=s(jb);Wme=n(mxe,"STRONG",{});var lmt=s(Wme);bBo=r(lmt,"yoso"),lmt.forEach(t),vBo=r(mxe," \u2014 "),dO=n(mxe,"A",{href:!0});var imt=s(dO);FBo=r(imt,"YosoForSequenceClassification"),imt.forEach(t),TBo=r(mxe," (YOSO model)"),mxe.forEach(t),j.forEach(t),MBo=i(sa),Db=n(sa,"P",{});var gxe=s(Db);EBo=r(gxe,"The model is set in evaluation mode by default using "),Qme=n(gxe,"CODE",{});var dmt=s(Qme);CBo=r(dmt,"model.eval()"),dmt.forEach(t),wBo=r(gxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Hme=n(gxe,"CODE",{});var cmt=s(Hme);ABo=r(cmt,"model.train()"),cmt.forEach(t),gxe.forEach(t),yBo=i(sa),T(Gb.$$.fragment,sa),sa.forEach(t),Qs.forEach(t),Dqe=i(f),Xi=n(f,"H2",{class:!0});var XDe=s(Xi);Ob=n(XDe,"A",{id:!0,class:!0,href:!0});var fmt=s(Ob);Ume=n(fmt,"SPAN",{});var mmt=s(Ume);T(Ry.$$.fragment,mmt),mmt.forEach(t),fmt.forEach(t),LBo=i(XDe),Jme=n(XDe,"SPAN",{});var gmt=s(Jme);xBo=r(gmt,"AutoModelForMultipleChoice"),gmt.forEach(t),XDe.forEach(t),Gqe=i(f),Po=n(f,"DIV",{class:!0});var Hs=s(Po);T(Py.$$.fragment,Hs),$Bo=i(Hs),zi=n(Hs,"P",{});var NZ=s(zi);kBo=r(NZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),cO=n(NZ,"A",{href:!0});var hmt=s(cO);SBo=r(hmt,"from_pretrained()"),hmt.forEach(t),RBo=r(NZ," class method or the "),fO=n(NZ,"A",{href:!0});var pmt=s(fO);PBo=r(pmt,"from_config()"),pmt.forEach(t),BBo=r(NZ,` class
method.`),NZ.forEach(t),IBo=i(Hs),By=n(Hs,"P",{});var zDe=s(By);NBo=r(zDe,"This class cannot be instantiated directly using "),Yme=n(zDe,"CODE",{});var _mt=s(Yme);qBo=r(_mt,"__init__()"),_mt.forEach(t),jBo=r(zDe," (throws an error)."),zDe.forEach(t),DBo=i(Hs),dt=n(Hs,"DIV",{class:!0});var Qw=s(dt);T(Iy.$$.fragment,Qw),GBo=i(Qw),Kme=n(Qw,"P",{});var umt=s(Kme);OBo=r(umt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),umt.forEach(t),VBo=i(Qw),Wi=n(Qw,"P",{});var qZ=s(Wi);XBo=r(qZ,`Note:
Loading a model from its configuration file does `),Zme=n(qZ,"STRONG",{});var bmt=s(Zme);zBo=r(bmt,"not"),bmt.forEach(t),WBo=r(qZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),mO=n(qZ,"A",{href:!0});var vmt=s(mO);QBo=r(vmt,"from_pretrained()"),vmt.forEach(t),HBo=r(qZ," to load the model weights."),qZ.forEach(t),UBo=i(Qw),T(Vb.$$.fragment,Qw),Qw.forEach(t),JBo=i(Hs),ro=n(Hs,"DIV",{class:!0});var la=s(ro);T(Ny.$$.fragment,la),YBo=i(la),ege=n(la,"P",{});var Fmt=s(ege);KBo=r(Fmt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Fmt.forEach(t),ZBo=i(la),Pa=n(la,"P",{});var Hw=s(Pa);eIo=r(Hw,"The model class to instantiate is selected based on the "),oge=n(Hw,"CODE",{});var Tmt=s(oge);oIo=r(Tmt,"model_type"),Tmt.forEach(t),rIo=r(Hw,` property of the config object (either
passed as an argument or loaded from `),rge=n(Hw,"CODE",{});var Mmt=s(rge);tIo=r(Mmt,"pretrained_model_name_or_path"),Mmt.forEach(t),aIo=r(Hw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tge=n(Hw,"CODE",{});var Emt=s(tge);nIo=r(Emt,"pretrained_model_name_or_path"),Emt.forEach(t),sIo=r(Hw,":"),Hw.forEach(t),lIo=i(la),K=n(la,"UL",{});var ee=s(K);Xb=n(ee,"LI",{});var hxe=s(Xb);age=n(hxe,"STRONG",{});var Cmt=s(age);iIo=r(Cmt,"albert"),Cmt.forEach(t),dIo=r(hxe," \u2014 "),gO=n(hxe,"A",{href:!0});var wmt=s(gO);cIo=r(wmt,"AlbertForMultipleChoice"),wmt.forEach(t),fIo=r(hxe," (ALBERT model)"),hxe.forEach(t),mIo=i(ee),zb=n(ee,"LI",{});var pxe=s(zb);nge=n(pxe,"STRONG",{});var Amt=s(nge);gIo=r(Amt,"bert"),Amt.forEach(t),hIo=r(pxe," \u2014 "),hO=n(pxe,"A",{href:!0});var ymt=s(hO);pIo=r(ymt,"BertForMultipleChoice"),ymt.forEach(t),_Io=r(pxe," (BERT model)"),pxe.forEach(t),uIo=i(ee),Wb=n(ee,"LI",{});var _xe=s(Wb);sge=n(_xe,"STRONG",{});var Lmt=s(sge);bIo=r(Lmt,"big_bird"),Lmt.forEach(t),vIo=r(_xe," \u2014 "),pO=n(_xe,"A",{href:!0});var xmt=s(pO);FIo=r(xmt,"BigBirdForMultipleChoice"),xmt.forEach(t),TIo=r(_xe," (BigBird model)"),_xe.forEach(t),MIo=i(ee),Qb=n(ee,"LI",{});var uxe=s(Qb);lge=n(uxe,"STRONG",{});var $mt=s(lge);EIo=r($mt,"camembert"),$mt.forEach(t),CIo=r(uxe," \u2014 "),_O=n(uxe,"A",{href:!0});var kmt=s(_O);wIo=r(kmt,"CamembertForMultipleChoice"),kmt.forEach(t),AIo=r(uxe," (CamemBERT model)"),uxe.forEach(t),yIo=i(ee),Hb=n(ee,"LI",{});var bxe=s(Hb);ige=n(bxe,"STRONG",{});var Smt=s(ige);LIo=r(Smt,"canine"),Smt.forEach(t),xIo=r(bxe," \u2014 "),uO=n(bxe,"A",{href:!0});var Rmt=s(uO);$Io=r(Rmt,"CanineForMultipleChoice"),Rmt.forEach(t),kIo=r(bxe," (Canine model)"),bxe.forEach(t),SIo=i(ee),Ub=n(ee,"LI",{});var vxe=s(Ub);dge=n(vxe,"STRONG",{});var Pmt=s(dge);RIo=r(Pmt,"convbert"),Pmt.forEach(t),PIo=r(vxe," \u2014 "),bO=n(vxe,"A",{href:!0});var Bmt=s(bO);BIo=r(Bmt,"ConvBertForMultipleChoice"),Bmt.forEach(t),IIo=r(vxe," (ConvBERT model)"),vxe.forEach(t),NIo=i(ee),Jb=n(ee,"LI",{});var Fxe=s(Jb);cge=n(Fxe,"STRONG",{});var Imt=s(cge);qIo=r(Imt,"data2vec-text"),Imt.forEach(t),jIo=r(Fxe," \u2014 "),vO=n(Fxe,"A",{href:!0});var Nmt=s(vO);DIo=r(Nmt,"Data2VecTextForMultipleChoice"),Nmt.forEach(t),GIo=r(Fxe," (Data2VecText model)"),Fxe.forEach(t),OIo=i(ee),Yb=n(ee,"LI",{});var Txe=s(Yb);fge=n(Txe,"STRONG",{});var qmt=s(fge);VIo=r(qmt,"deberta-v2"),qmt.forEach(t),XIo=r(Txe," \u2014 "),FO=n(Txe,"A",{href:!0});var jmt=s(FO);zIo=r(jmt,"DebertaV2ForMultipleChoice"),jmt.forEach(t),WIo=r(Txe," (DeBERTa-v2 model)"),Txe.forEach(t),QIo=i(ee),Kb=n(ee,"LI",{});var Mxe=s(Kb);mge=n(Mxe,"STRONG",{});var Dmt=s(mge);HIo=r(Dmt,"distilbert"),Dmt.forEach(t),UIo=r(Mxe," \u2014 "),TO=n(Mxe,"A",{href:!0});var Gmt=s(TO);JIo=r(Gmt,"DistilBertForMultipleChoice"),Gmt.forEach(t),YIo=r(Mxe," (DistilBERT model)"),Mxe.forEach(t),KIo=i(ee),Zb=n(ee,"LI",{});var Exe=s(Zb);gge=n(Exe,"STRONG",{});var Omt=s(gge);ZIo=r(Omt,"electra"),Omt.forEach(t),eNo=r(Exe," \u2014 "),MO=n(Exe,"A",{href:!0});var Vmt=s(MO);oNo=r(Vmt,"ElectraForMultipleChoice"),Vmt.forEach(t),rNo=r(Exe," (ELECTRA model)"),Exe.forEach(t),tNo=i(ee),e2=n(ee,"LI",{});var Cxe=s(e2);hge=n(Cxe,"STRONG",{});var Xmt=s(hge);aNo=r(Xmt,"flaubert"),Xmt.forEach(t),nNo=r(Cxe," \u2014 "),EO=n(Cxe,"A",{href:!0});var zmt=s(EO);sNo=r(zmt,"FlaubertForMultipleChoice"),zmt.forEach(t),lNo=r(Cxe," (FlauBERT model)"),Cxe.forEach(t),iNo=i(ee),o2=n(ee,"LI",{});var wxe=s(o2);pge=n(wxe,"STRONG",{});var Wmt=s(pge);dNo=r(Wmt,"fnet"),Wmt.forEach(t),cNo=r(wxe," \u2014 "),CO=n(wxe,"A",{href:!0});var Qmt=s(CO);fNo=r(Qmt,"FNetForMultipleChoice"),Qmt.forEach(t),mNo=r(wxe," (FNet model)"),wxe.forEach(t),gNo=i(ee),r2=n(ee,"LI",{});var Axe=s(r2);_ge=n(Axe,"STRONG",{});var Hmt=s(_ge);hNo=r(Hmt,"funnel"),Hmt.forEach(t),pNo=r(Axe," \u2014 "),wO=n(Axe,"A",{href:!0});var Umt=s(wO);_No=r(Umt,"FunnelForMultipleChoice"),Umt.forEach(t),uNo=r(Axe," (Funnel Transformer model)"),Axe.forEach(t),bNo=i(ee),t2=n(ee,"LI",{});var yxe=s(t2);uge=n(yxe,"STRONG",{});var Jmt=s(uge);vNo=r(Jmt,"ibert"),Jmt.forEach(t),FNo=r(yxe," \u2014 "),AO=n(yxe,"A",{href:!0});var Ymt=s(AO);TNo=r(Ymt,"IBertForMultipleChoice"),Ymt.forEach(t),MNo=r(yxe," (I-BERT model)"),yxe.forEach(t),ENo=i(ee),a2=n(ee,"LI",{});var Lxe=s(a2);bge=n(Lxe,"STRONG",{});var Kmt=s(bge);CNo=r(Kmt,"longformer"),Kmt.forEach(t),wNo=r(Lxe," \u2014 "),yO=n(Lxe,"A",{href:!0});var Zmt=s(yO);ANo=r(Zmt,"LongformerForMultipleChoice"),Zmt.forEach(t),yNo=r(Lxe," (Longformer model)"),Lxe.forEach(t),LNo=i(ee),n2=n(ee,"LI",{});var xxe=s(n2);vge=n(xxe,"STRONG",{});var egt=s(vge);xNo=r(egt,"megatron-bert"),egt.forEach(t),$No=r(xxe," \u2014 "),LO=n(xxe,"A",{href:!0});var ogt=s(LO);kNo=r(ogt,"MegatronBertForMultipleChoice"),ogt.forEach(t),SNo=r(xxe," (MegatronBert model)"),xxe.forEach(t),RNo=i(ee),s2=n(ee,"LI",{});var $xe=s(s2);Fge=n($xe,"STRONG",{});var rgt=s(Fge);PNo=r(rgt,"mobilebert"),rgt.forEach(t),BNo=r($xe," \u2014 "),xO=n($xe,"A",{href:!0});var tgt=s(xO);INo=r(tgt,"MobileBertForMultipleChoice"),tgt.forEach(t),NNo=r($xe," (MobileBERT model)"),$xe.forEach(t),qNo=i(ee),l2=n(ee,"LI",{});var kxe=s(l2);Tge=n(kxe,"STRONG",{});var agt=s(Tge);jNo=r(agt,"mpnet"),agt.forEach(t),DNo=r(kxe," \u2014 "),$O=n(kxe,"A",{href:!0});var ngt=s($O);GNo=r(ngt,"MPNetForMultipleChoice"),ngt.forEach(t),ONo=r(kxe," (MPNet model)"),kxe.forEach(t),VNo=i(ee),i2=n(ee,"LI",{});var Sxe=s(i2);Mge=n(Sxe,"STRONG",{});var sgt=s(Mge);XNo=r(sgt,"nystromformer"),sgt.forEach(t),zNo=r(Sxe," \u2014 "),kO=n(Sxe,"A",{href:!0});var lgt=s(kO);WNo=r(lgt,"NystromformerForMultipleChoice"),lgt.forEach(t),QNo=r(Sxe," (Nystromformer model)"),Sxe.forEach(t),HNo=i(ee),d2=n(ee,"LI",{});var Rxe=s(d2);Ege=n(Rxe,"STRONG",{});var igt=s(Ege);UNo=r(igt,"qdqbert"),igt.forEach(t),JNo=r(Rxe," \u2014 "),SO=n(Rxe,"A",{href:!0});var dgt=s(SO);YNo=r(dgt,"QDQBertForMultipleChoice"),dgt.forEach(t),KNo=r(Rxe," (QDQBert model)"),Rxe.forEach(t),ZNo=i(ee),c2=n(ee,"LI",{});var Pxe=s(c2);Cge=n(Pxe,"STRONG",{});var cgt=s(Cge);eqo=r(cgt,"rembert"),cgt.forEach(t),oqo=r(Pxe," \u2014 "),RO=n(Pxe,"A",{href:!0});var fgt=s(RO);rqo=r(fgt,"RemBertForMultipleChoice"),fgt.forEach(t),tqo=r(Pxe," (RemBERT model)"),Pxe.forEach(t),aqo=i(ee),f2=n(ee,"LI",{});var Bxe=s(f2);wge=n(Bxe,"STRONG",{});var mgt=s(wge);nqo=r(mgt,"roberta"),mgt.forEach(t),sqo=r(Bxe," \u2014 "),PO=n(Bxe,"A",{href:!0});var ggt=s(PO);lqo=r(ggt,"RobertaForMultipleChoice"),ggt.forEach(t),iqo=r(Bxe," (RoBERTa model)"),Bxe.forEach(t),dqo=i(ee),m2=n(ee,"LI",{});var Ixe=s(m2);Age=n(Ixe,"STRONG",{});var hgt=s(Age);cqo=r(hgt,"roformer"),hgt.forEach(t),fqo=r(Ixe," \u2014 "),BO=n(Ixe,"A",{href:!0});var pgt=s(BO);mqo=r(pgt,"RoFormerForMultipleChoice"),pgt.forEach(t),gqo=r(Ixe," (RoFormer model)"),Ixe.forEach(t),hqo=i(ee),g2=n(ee,"LI",{});var Nxe=s(g2);yge=n(Nxe,"STRONG",{});var _gt=s(yge);pqo=r(_gt,"squeezebert"),_gt.forEach(t),_qo=r(Nxe," \u2014 "),IO=n(Nxe,"A",{href:!0});var ugt=s(IO);uqo=r(ugt,"SqueezeBertForMultipleChoice"),ugt.forEach(t),bqo=r(Nxe," (SqueezeBERT model)"),Nxe.forEach(t),vqo=i(ee),h2=n(ee,"LI",{});var qxe=s(h2);Lge=n(qxe,"STRONG",{});var bgt=s(Lge);Fqo=r(bgt,"xlm"),bgt.forEach(t),Tqo=r(qxe," \u2014 "),NO=n(qxe,"A",{href:!0});var vgt=s(NO);Mqo=r(vgt,"XLMForMultipleChoice"),vgt.forEach(t),Eqo=r(qxe," (XLM model)"),qxe.forEach(t),Cqo=i(ee),p2=n(ee,"LI",{});var jxe=s(p2);xge=n(jxe,"STRONG",{});var Fgt=s(xge);wqo=r(Fgt,"xlm-roberta"),Fgt.forEach(t),Aqo=r(jxe," \u2014 "),qO=n(jxe,"A",{href:!0});var Tgt=s(qO);yqo=r(Tgt,"XLMRobertaForMultipleChoice"),Tgt.forEach(t),Lqo=r(jxe," (XLM-RoBERTa model)"),jxe.forEach(t),xqo=i(ee),_2=n(ee,"LI",{});var Dxe=s(_2);$ge=n(Dxe,"STRONG",{});var Mgt=s($ge);$qo=r(Mgt,"xlm-roberta-xl"),Mgt.forEach(t),kqo=r(Dxe," \u2014 "),jO=n(Dxe,"A",{href:!0});var Egt=s(jO);Sqo=r(Egt,"XLMRobertaXLForMultipleChoice"),Egt.forEach(t),Rqo=r(Dxe," (XLM-RoBERTa-XL model)"),Dxe.forEach(t),Pqo=i(ee),u2=n(ee,"LI",{});var Gxe=s(u2);kge=n(Gxe,"STRONG",{});var Cgt=s(kge);Bqo=r(Cgt,"xlnet"),Cgt.forEach(t),Iqo=r(Gxe," \u2014 "),DO=n(Gxe,"A",{href:!0});var wgt=s(DO);Nqo=r(wgt,"XLNetForMultipleChoice"),wgt.forEach(t),qqo=r(Gxe," (XLNet model)"),Gxe.forEach(t),jqo=i(ee),b2=n(ee,"LI",{});var Oxe=s(b2);Sge=n(Oxe,"STRONG",{});var Agt=s(Sge);Dqo=r(Agt,"yoso"),Agt.forEach(t),Gqo=r(Oxe," \u2014 "),GO=n(Oxe,"A",{href:!0});var ygt=s(GO);Oqo=r(ygt,"YosoForMultipleChoice"),ygt.forEach(t),Vqo=r(Oxe," (YOSO model)"),Oxe.forEach(t),ee.forEach(t),Xqo=i(la),v2=n(la,"P",{});var Vxe=s(v2);zqo=r(Vxe,"The model is set in evaluation mode by default using "),Rge=n(Vxe,"CODE",{});var Lgt=s(Rge);Wqo=r(Lgt,"model.eval()"),Lgt.forEach(t),Qqo=r(Vxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Pge=n(Vxe,"CODE",{});var xgt=s(Pge);Hqo=r(xgt,"model.train()"),xgt.forEach(t),Vxe.forEach(t),Uqo=i(la),T(F2.$$.fragment,la),la.forEach(t),Hs.forEach(t),Oqe=i(f),Qi=n(f,"H2",{class:!0});var WDe=s(Qi);T2=n(WDe,"A",{id:!0,class:!0,href:!0});var $gt=s(T2);Bge=n($gt,"SPAN",{});var kgt=s(Bge);T(qy.$$.fragment,kgt),kgt.forEach(t),$gt.forEach(t),Jqo=i(WDe),Ige=n(WDe,"SPAN",{});var Sgt=s(Ige);Yqo=r(Sgt,"AutoModelForNextSentencePrediction"),Sgt.forEach(t),WDe.forEach(t),Vqe=i(f),Bo=n(f,"DIV",{class:!0});var Us=s(Bo);T(jy.$$.fragment,Us),Kqo=i(Us),Hi=n(Us,"P",{});var jZ=s(Hi);Zqo=r(jZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),OO=n(jZ,"A",{href:!0});var Rgt=s(OO);ejo=r(Rgt,"from_pretrained()"),Rgt.forEach(t),ojo=r(jZ," class method or the "),VO=n(jZ,"A",{href:!0});var Pgt=s(VO);rjo=r(Pgt,"from_config()"),Pgt.forEach(t),tjo=r(jZ,` class
method.`),jZ.forEach(t),ajo=i(Us),Dy=n(Us,"P",{});var QDe=s(Dy);njo=r(QDe,"This class cannot be instantiated directly using "),Nge=n(QDe,"CODE",{});var Bgt=s(Nge);sjo=r(Bgt,"__init__()"),Bgt.forEach(t),ljo=r(QDe," (throws an error)."),QDe.forEach(t),ijo=i(Us),ct=n(Us,"DIV",{class:!0});var Uw=s(ct);T(Gy.$$.fragment,Uw),djo=i(Uw),qge=n(Uw,"P",{});var Igt=s(qge);cjo=r(Igt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Igt.forEach(t),fjo=i(Uw),Ui=n(Uw,"P",{});var DZ=s(Ui);mjo=r(DZ,`Note:
Loading a model from its configuration file does `),jge=n(DZ,"STRONG",{});var Ngt=s(jge);gjo=r(Ngt,"not"),Ngt.forEach(t),hjo=r(DZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),XO=n(DZ,"A",{href:!0});var qgt=s(XO);pjo=r(qgt,"from_pretrained()"),qgt.forEach(t),_jo=r(DZ," to load the model weights."),DZ.forEach(t),ujo=i(Uw),T(M2.$$.fragment,Uw),Uw.forEach(t),bjo=i(Us),to=n(Us,"DIV",{class:!0});var ia=s(to);T(Oy.$$.fragment,ia),vjo=i(ia),Dge=n(ia,"P",{});var jgt=s(Dge);Fjo=r(jgt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),jgt.forEach(t),Tjo=i(ia),Ba=n(ia,"P",{});var Jw=s(Ba);Mjo=r(Jw,"The model class to instantiate is selected based on the "),Gge=n(Jw,"CODE",{});var Dgt=s(Gge);Ejo=r(Dgt,"model_type"),Dgt.forEach(t),Cjo=r(Jw,` property of the config object (either
passed as an argument or loaded from `),Oge=n(Jw,"CODE",{});var Ggt=s(Oge);wjo=r(Ggt,"pretrained_model_name_or_path"),Ggt.forEach(t),Ajo=r(Jw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vge=n(Jw,"CODE",{});var Ogt=s(Vge);yjo=r(Ogt,"pretrained_model_name_or_path"),Ogt.forEach(t),Ljo=r(Jw,":"),Jw.forEach(t),xjo=i(ia),Yr=n(ia,"UL",{});var Js=s(Yr);E2=n(Js,"LI",{});var Xxe=s(E2);Xge=n(Xxe,"STRONG",{});var Vgt=s(Xge);$jo=r(Vgt,"bert"),Vgt.forEach(t),kjo=r(Xxe," \u2014 "),zO=n(Xxe,"A",{href:!0});var Xgt=s(zO);Sjo=r(Xgt,"BertForNextSentencePrediction"),Xgt.forEach(t),Rjo=r(Xxe," (BERT model)"),Xxe.forEach(t),Pjo=i(Js),C2=n(Js,"LI",{});var zxe=s(C2);zge=n(zxe,"STRONG",{});var zgt=s(zge);Bjo=r(zgt,"fnet"),zgt.forEach(t),Ijo=r(zxe," \u2014 "),WO=n(zxe,"A",{href:!0});var Wgt=s(WO);Njo=r(Wgt,"FNetForNextSentencePrediction"),Wgt.forEach(t),qjo=r(zxe," (FNet model)"),zxe.forEach(t),jjo=i(Js),w2=n(Js,"LI",{});var Wxe=s(w2);Wge=n(Wxe,"STRONG",{});var Qgt=s(Wge);Djo=r(Qgt,"megatron-bert"),Qgt.forEach(t),Gjo=r(Wxe," \u2014 "),QO=n(Wxe,"A",{href:!0});var Hgt=s(QO);Ojo=r(Hgt,"MegatronBertForNextSentencePrediction"),Hgt.forEach(t),Vjo=r(Wxe," (MegatronBert model)"),Wxe.forEach(t),Xjo=i(Js),A2=n(Js,"LI",{});var Qxe=s(A2);Qge=n(Qxe,"STRONG",{});var Ugt=s(Qge);zjo=r(Ugt,"mobilebert"),Ugt.forEach(t),Wjo=r(Qxe," \u2014 "),HO=n(Qxe,"A",{href:!0});var Jgt=s(HO);Qjo=r(Jgt,"MobileBertForNextSentencePrediction"),Jgt.forEach(t),Hjo=r(Qxe," (MobileBERT model)"),Qxe.forEach(t),Ujo=i(Js),y2=n(Js,"LI",{});var Hxe=s(y2);Hge=n(Hxe,"STRONG",{});var Ygt=s(Hge);Jjo=r(Ygt,"qdqbert"),Ygt.forEach(t),Yjo=r(Hxe," \u2014 "),UO=n(Hxe,"A",{href:!0});var Kgt=s(UO);Kjo=r(Kgt,"QDQBertForNextSentencePrediction"),Kgt.forEach(t),Zjo=r(Hxe," (QDQBert model)"),Hxe.forEach(t),Js.forEach(t),eDo=i(ia),L2=n(ia,"P",{});var Uxe=s(L2);oDo=r(Uxe,"The model is set in evaluation mode by default using "),Uge=n(Uxe,"CODE",{});var Zgt=s(Uge);rDo=r(Zgt,"model.eval()"),Zgt.forEach(t),tDo=r(Uxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jge=n(Uxe,"CODE",{});var eht=s(Jge);aDo=r(eht,"model.train()"),eht.forEach(t),Uxe.forEach(t),nDo=i(ia),T(x2.$$.fragment,ia),ia.forEach(t),Us.forEach(t),Xqe=i(f),Ji=n(f,"H2",{class:!0});var HDe=s(Ji);$2=n(HDe,"A",{id:!0,class:!0,href:!0});var oht=s($2);Yge=n(oht,"SPAN",{});var rht=s(Yge);T(Vy.$$.fragment,rht),rht.forEach(t),oht.forEach(t),sDo=i(HDe),Kge=n(HDe,"SPAN",{});var tht=s(Kge);lDo=r(tht,"AutoModelForTokenClassification"),tht.forEach(t),HDe.forEach(t),zqe=i(f),Io=n(f,"DIV",{class:!0});var Ys=s(Io);T(Xy.$$.fragment,Ys),iDo=i(Ys),Yi=n(Ys,"P",{});var GZ=s(Yi);dDo=r(GZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),JO=n(GZ,"A",{href:!0});var aht=s(JO);cDo=r(aht,"from_pretrained()"),aht.forEach(t),fDo=r(GZ," class method or the "),YO=n(GZ,"A",{href:!0});var nht=s(YO);mDo=r(nht,"from_config()"),nht.forEach(t),gDo=r(GZ,` class
method.`),GZ.forEach(t),hDo=i(Ys),zy=n(Ys,"P",{});var UDe=s(zy);pDo=r(UDe,"This class cannot be instantiated directly using "),Zge=n(UDe,"CODE",{});var sht=s(Zge);_Do=r(sht,"__init__()"),sht.forEach(t),uDo=r(UDe," (throws an error)."),UDe.forEach(t),bDo=i(Ys),ft=n(Ys,"DIV",{class:!0});var Yw=s(ft);T(Wy.$$.fragment,Yw),vDo=i(Yw),ehe=n(Yw,"P",{});var lht=s(ehe);FDo=r(lht,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),lht.forEach(t),TDo=i(Yw),Ki=n(Yw,"P",{});var OZ=s(Ki);MDo=r(OZ,`Note:
Loading a model from its configuration file does `),ohe=n(OZ,"STRONG",{});var iht=s(ohe);EDo=r(iht,"not"),iht.forEach(t),CDo=r(OZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),KO=n(OZ,"A",{href:!0});var dht=s(KO);wDo=r(dht,"from_pretrained()"),dht.forEach(t),ADo=r(OZ," to load the model weights."),OZ.forEach(t),yDo=i(Yw),T(k2.$$.fragment,Yw),Yw.forEach(t),LDo=i(Ys),ao=n(Ys,"DIV",{class:!0});var da=s(ao);T(Qy.$$.fragment,da),xDo=i(da),rhe=n(da,"P",{});var cht=s(rhe);$Do=r(cht,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),cht.forEach(t),kDo=i(da),Ia=n(da,"P",{});var Kw=s(Ia);SDo=r(Kw,"The model class to instantiate is selected based on the "),the=n(Kw,"CODE",{});var fht=s(the);RDo=r(fht,"model_type"),fht.forEach(t),PDo=r(Kw,` property of the config object (either
passed as an argument or loaded from `),ahe=n(Kw,"CODE",{});var mht=s(ahe);BDo=r(mht,"pretrained_model_name_or_path"),mht.forEach(t),IDo=r(Kw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nhe=n(Kw,"CODE",{});var ght=s(nhe);NDo=r(ght,"pretrained_model_name_or_path"),ght.forEach(t),qDo=r(Kw,":"),Kw.forEach(t),jDo=i(da),H=n(da,"UL",{});var J=s(H);S2=n(J,"LI",{});var Jxe=s(S2);she=n(Jxe,"STRONG",{});var hht=s(she);DDo=r(hht,"albert"),hht.forEach(t),GDo=r(Jxe," \u2014 "),ZO=n(Jxe,"A",{href:!0});var pht=s(ZO);ODo=r(pht,"AlbertForTokenClassification"),pht.forEach(t),VDo=r(Jxe," (ALBERT model)"),Jxe.forEach(t),XDo=i(J),R2=n(J,"LI",{});var Yxe=s(R2);lhe=n(Yxe,"STRONG",{});var _ht=s(lhe);zDo=r(_ht,"bert"),_ht.forEach(t),WDo=r(Yxe," \u2014 "),eV=n(Yxe,"A",{href:!0});var uht=s(eV);QDo=r(uht,"BertForTokenClassification"),uht.forEach(t),HDo=r(Yxe," (BERT model)"),Yxe.forEach(t),UDo=i(J),P2=n(J,"LI",{});var Kxe=s(P2);ihe=n(Kxe,"STRONG",{});var bht=s(ihe);JDo=r(bht,"big_bird"),bht.forEach(t),YDo=r(Kxe," \u2014 "),oV=n(Kxe,"A",{href:!0});var vht=s(oV);KDo=r(vht,"BigBirdForTokenClassification"),vht.forEach(t),ZDo=r(Kxe," (BigBird model)"),Kxe.forEach(t),eGo=i(J),B2=n(J,"LI",{});var Zxe=s(B2);dhe=n(Zxe,"STRONG",{});var Fht=s(dhe);oGo=r(Fht,"camembert"),Fht.forEach(t),rGo=r(Zxe," \u2014 "),rV=n(Zxe,"A",{href:!0});var Tht=s(rV);tGo=r(Tht,"CamembertForTokenClassification"),Tht.forEach(t),aGo=r(Zxe," (CamemBERT model)"),Zxe.forEach(t),nGo=i(J),I2=n(J,"LI",{});var e$e=s(I2);che=n(e$e,"STRONG",{});var Mht=s(che);sGo=r(Mht,"canine"),Mht.forEach(t),lGo=r(e$e," \u2014 "),tV=n(e$e,"A",{href:!0});var Eht=s(tV);iGo=r(Eht,"CanineForTokenClassification"),Eht.forEach(t),dGo=r(e$e," (Canine model)"),e$e.forEach(t),cGo=i(J),N2=n(J,"LI",{});var o$e=s(N2);fhe=n(o$e,"STRONG",{});var Cht=s(fhe);fGo=r(Cht,"convbert"),Cht.forEach(t),mGo=r(o$e," \u2014 "),aV=n(o$e,"A",{href:!0});var wht=s(aV);gGo=r(wht,"ConvBertForTokenClassification"),wht.forEach(t),hGo=r(o$e," (ConvBERT model)"),o$e.forEach(t),pGo=i(J),q2=n(J,"LI",{});var r$e=s(q2);mhe=n(r$e,"STRONG",{});var Aht=s(mhe);_Go=r(Aht,"data2vec-text"),Aht.forEach(t),uGo=r(r$e," \u2014 "),nV=n(r$e,"A",{href:!0});var yht=s(nV);bGo=r(yht,"Data2VecTextForTokenClassification"),yht.forEach(t),vGo=r(r$e," (Data2VecText model)"),r$e.forEach(t),FGo=i(J),j2=n(J,"LI",{});var t$e=s(j2);ghe=n(t$e,"STRONG",{});var Lht=s(ghe);TGo=r(Lht,"deberta"),Lht.forEach(t),MGo=r(t$e," \u2014 "),sV=n(t$e,"A",{href:!0});var xht=s(sV);EGo=r(xht,"DebertaForTokenClassification"),xht.forEach(t),CGo=r(t$e," (DeBERTa model)"),t$e.forEach(t),wGo=i(J),D2=n(J,"LI",{});var a$e=s(D2);hhe=n(a$e,"STRONG",{});var $ht=s(hhe);AGo=r($ht,"deberta-v2"),$ht.forEach(t),yGo=r(a$e," \u2014 "),lV=n(a$e,"A",{href:!0});var kht=s(lV);LGo=r(kht,"DebertaV2ForTokenClassification"),kht.forEach(t),xGo=r(a$e," (DeBERTa-v2 model)"),a$e.forEach(t),$Go=i(J),G2=n(J,"LI",{});var n$e=s(G2);phe=n(n$e,"STRONG",{});var Sht=s(phe);kGo=r(Sht,"distilbert"),Sht.forEach(t),SGo=r(n$e," \u2014 "),iV=n(n$e,"A",{href:!0});var Rht=s(iV);RGo=r(Rht,"DistilBertForTokenClassification"),Rht.forEach(t),PGo=r(n$e," (DistilBERT model)"),n$e.forEach(t),BGo=i(J),O2=n(J,"LI",{});var s$e=s(O2);_he=n(s$e,"STRONG",{});var Pht=s(_he);IGo=r(Pht,"electra"),Pht.forEach(t),NGo=r(s$e," \u2014 "),dV=n(s$e,"A",{href:!0});var Bht=s(dV);qGo=r(Bht,"ElectraForTokenClassification"),Bht.forEach(t),jGo=r(s$e," (ELECTRA model)"),s$e.forEach(t),DGo=i(J),V2=n(J,"LI",{});var l$e=s(V2);uhe=n(l$e,"STRONG",{});var Iht=s(uhe);GGo=r(Iht,"flaubert"),Iht.forEach(t),OGo=r(l$e," \u2014 "),cV=n(l$e,"A",{href:!0});var Nht=s(cV);VGo=r(Nht,"FlaubertForTokenClassification"),Nht.forEach(t),XGo=r(l$e," (FlauBERT model)"),l$e.forEach(t),zGo=i(J),X2=n(J,"LI",{});var i$e=s(X2);bhe=n(i$e,"STRONG",{});var qht=s(bhe);WGo=r(qht,"fnet"),qht.forEach(t),QGo=r(i$e," \u2014 "),fV=n(i$e,"A",{href:!0});var jht=s(fV);HGo=r(jht,"FNetForTokenClassification"),jht.forEach(t),UGo=r(i$e," (FNet model)"),i$e.forEach(t),JGo=i(J),z2=n(J,"LI",{});var d$e=s(z2);vhe=n(d$e,"STRONG",{});var Dht=s(vhe);YGo=r(Dht,"funnel"),Dht.forEach(t),KGo=r(d$e," \u2014 "),mV=n(d$e,"A",{href:!0});var Ght=s(mV);ZGo=r(Ght,"FunnelForTokenClassification"),Ght.forEach(t),eOo=r(d$e," (Funnel Transformer model)"),d$e.forEach(t),oOo=i(J),W2=n(J,"LI",{});var c$e=s(W2);Fhe=n(c$e,"STRONG",{});var Oht=s(Fhe);rOo=r(Oht,"gpt2"),Oht.forEach(t),tOo=r(c$e," \u2014 "),gV=n(c$e,"A",{href:!0});var Vht=s(gV);aOo=r(Vht,"GPT2ForTokenClassification"),Vht.forEach(t),nOo=r(c$e," (OpenAI GPT-2 model)"),c$e.forEach(t),sOo=i(J),Q2=n(J,"LI",{});var f$e=s(Q2);The=n(f$e,"STRONG",{});var Xht=s(The);lOo=r(Xht,"ibert"),Xht.forEach(t),iOo=r(f$e," \u2014 "),hV=n(f$e,"A",{href:!0});var zht=s(hV);dOo=r(zht,"IBertForTokenClassification"),zht.forEach(t),cOo=r(f$e," (I-BERT model)"),f$e.forEach(t),fOo=i(J),H2=n(J,"LI",{});var m$e=s(H2);Mhe=n(m$e,"STRONG",{});var Wht=s(Mhe);mOo=r(Wht,"layoutlm"),Wht.forEach(t),gOo=r(m$e," \u2014 "),pV=n(m$e,"A",{href:!0});var Qht=s(pV);hOo=r(Qht,"LayoutLMForTokenClassification"),Qht.forEach(t),pOo=r(m$e," (LayoutLM model)"),m$e.forEach(t),_Oo=i(J),U2=n(J,"LI",{});var g$e=s(U2);Ehe=n(g$e,"STRONG",{});var Hht=s(Ehe);uOo=r(Hht,"layoutlmv2"),Hht.forEach(t),bOo=r(g$e," \u2014 "),_V=n(g$e,"A",{href:!0});var Uht=s(_V);vOo=r(Uht,"LayoutLMv2ForTokenClassification"),Uht.forEach(t),FOo=r(g$e," (LayoutLMv2 model)"),g$e.forEach(t),TOo=i(J),J2=n(J,"LI",{});var h$e=s(J2);Che=n(h$e,"STRONG",{});var Jht=s(Che);MOo=r(Jht,"layoutlmv3"),Jht.forEach(t),EOo=r(h$e," \u2014 "),uV=n(h$e,"A",{href:!0});var Yht=s(uV);COo=r(Yht,"LayoutLMv3ForTokenClassification"),Yht.forEach(t),wOo=r(h$e," (LayoutLMv3 model)"),h$e.forEach(t),AOo=i(J),Y2=n(J,"LI",{});var p$e=s(Y2);whe=n(p$e,"STRONG",{});var Kht=s(whe);yOo=r(Kht,"longformer"),Kht.forEach(t),LOo=r(p$e," \u2014 "),bV=n(p$e,"A",{href:!0});var Zht=s(bV);xOo=r(Zht,"LongformerForTokenClassification"),Zht.forEach(t),$Oo=r(p$e," (Longformer model)"),p$e.forEach(t),kOo=i(J),K2=n(J,"LI",{});var _$e=s(K2);Ahe=n(_$e,"STRONG",{});var ept=s(Ahe);SOo=r(ept,"megatron-bert"),ept.forEach(t),ROo=r(_$e," \u2014 "),vV=n(_$e,"A",{href:!0});var opt=s(vV);POo=r(opt,"MegatronBertForTokenClassification"),opt.forEach(t),BOo=r(_$e," (MegatronBert model)"),_$e.forEach(t),IOo=i(J),Z2=n(J,"LI",{});var u$e=s(Z2);yhe=n(u$e,"STRONG",{});var rpt=s(yhe);NOo=r(rpt,"mobilebert"),rpt.forEach(t),qOo=r(u$e," \u2014 "),FV=n(u$e,"A",{href:!0});var tpt=s(FV);jOo=r(tpt,"MobileBertForTokenClassification"),tpt.forEach(t),DOo=r(u$e," (MobileBERT model)"),u$e.forEach(t),GOo=i(J),e4=n(J,"LI",{});var b$e=s(e4);Lhe=n(b$e,"STRONG",{});var apt=s(Lhe);OOo=r(apt,"mpnet"),apt.forEach(t),VOo=r(b$e," \u2014 "),TV=n(b$e,"A",{href:!0});var npt=s(TV);XOo=r(npt,"MPNetForTokenClassification"),npt.forEach(t),zOo=r(b$e," (MPNet model)"),b$e.forEach(t),WOo=i(J),o4=n(J,"LI",{});var v$e=s(o4);xhe=n(v$e,"STRONG",{});var spt=s(xhe);QOo=r(spt,"nystromformer"),spt.forEach(t),HOo=r(v$e," \u2014 "),MV=n(v$e,"A",{href:!0});var lpt=s(MV);UOo=r(lpt,"NystromformerForTokenClassification"),lpt.forEach(t),JOo=r(v$e," (Nystromformer model)"),v$e.forEach(t),YOo=i(J),r4=n(J,"LI",{});var F$e=s(r4);$he=n(F$e,"STRONG",{});var ipt=s($he);KOo=r(ipt,"qdqbert"),ipt.forEach(t),ZOo=r(F$e," \u2014 "),EV=n(F$e,"A",{href:!0});var dpt=s(EV);eVo=r(dpt,"QDQBertForTokenClassification"),dpt.forEach(t),oVo=r(F$e," (QDQBert model)"),F$e.forEach(t),rVo=i(J),t4=n(J,"LI",{});var T$e=s(t4);khe=n(T$e,"STRONG",{});var cpt=s(khe);tVo=r(cpt,"rembert"),cpt.forEach(t),aVo=r(T$e," \u2014 "),CV=n(T$e,"A",{href:!0});var fpt=s(CV);nVo=r(fpt,"RemBertForTokenClassification"),fpt.forEach(t),sVo=r(T$e," (RemBERT model)"),T$e.forEach(t),lVo=i(J),a4=n(J,"LI",{});var M$e=s(a4);She=n(M$e,"STRONG",{});var mpt=s(She);iVo=r(mpt,"roberta"),mpt.forEach(t),dVo=r(M$e," \u2014 "),wV=n(M$e,"A",{href:!0});var gpt=s(wV);cVo=r(gpt,"RobertaForTokenClassification"),gpt.forEach(t),fVo=r(M$e," (RoBERTa model)"),M$e.forEach(t),mVo=i(J),n4=n(J,"LI",{});var E$e=s(n4);Rhe=n(E$e,"STRONG",{});var hpt=s(Rhe);gVo=r(hpt,"roformer"),hpt.forEach(t),hVo=r(E$e," \u2014 "),AV=n(E$e,"A",{href:!0});var ppt=s(AV);pVo=r(ppt,"RoFormerForTokenClassification"),ppt.forEach(t),_Vo=r(E$e," (RoFormer model)"),E$e.forEach(t),uVo=i(J),s4=n(J,"LI",{});var C$e=s(s4);Phe=n(C$e,"STRONG",{});var _pt=s(Phe);bVo=r(_pt,"squeezebert"),_pt.forEach(t),vVo=r(C$e," \u2014 "),yV=n(C$e,"A",{href:!0});var upt=s(yV);FVo=r(upt,"SqueezeBertForTokenClassification"),upt.forEach(t),TVo=r(C$e," (SqueezeBERT model)"),C$e.forEach(t),MVo=i(J),l4=n(J,"LI",{});var w$e=s(l4);Bhe=n(w$e,"STRONG",{});var bpt=s(Bhe);EVo=r(bpt,"xlm"),bpt.forEach(t),CVo=r(w$e," \u2014 "),LV=n(w$e,"A",{href:!0});var vpt=s(LV);wVo=r(vpt,"XLMForTokenClassification"),vpt.forEach(t),AVo=r(w$e," (XLM model)"),w$e.forEach(t),yVo=i(J),i4=n(J,"LI",{});var A$e=s(i4);Ihe=n(A$e,"STRONG",{});var Fpt=s(Ihe);LVo=r(Fpt,"xlm-roberta"),Fpt.forEach(t),xVo=r(A$e," \u2014 "),xV=n(A$e,"A",{href:!0});var Tpt=s(xV);$Vo=r(Tpt,"XLMRobertaForTokenClassification"),Tpt.forEach(t),kVo=r(A$e," (XLM-RoBERTa model)"),A$e.forEach(t),SVo=i(J),d4=n(J,"LI",{});var y$e=s(d4);Nhe=n(y$e,"STRONG",{});var Mpt=s(Nhe);RVo=r(Mpt,"xlm-roberta-xl"),Mpt.forEach(t),PVo=r(y$e," \u2014 "),$V=n(y$e,"A",{href:!0});var Ept=s($V);BVo=r(Ept,"XLMRobertaXLForTokenClassification"),Ept.forEach(t),IVo=r(y$e," (XLM-RoBERTa-XL model)"),y$e.forEach(t),NVo=i(J),c4=n(J,"LI",{});var L$e=s(c4);qhe=n(L$e,"STRONG",{});var Cpt=s(qhe);qVo=r(Cpt,"xlnet"),Cpt.forEach(t),jVo=r(L$e," \u2014 "),kV=n(L$e,"A",{href:!0});var wpt=s(kV);DVo=r(wpt,"XLNetForTokenClassification"),wpt.forEach(t),GVo=r(L$e," (XLNet model)"),L$e.forEach(t),OVo=i(J),f4=n(J,"LI",{});var x$e=s(f4);jhe=n(x$e,"STRONG",{});var Apt=s(jhe);VVo=r(Apt,"yoso"),Apt.forEach(t),XVo=r(x$e," \u2014 "),SV=n(x$e,"A",{href:!0});var ypt=s(SV);zVo=r(ypt,"YosoForTokenClassification"),ypt.forEach(t),WVo=r(x$e," (YOSO model)"),x$e.forEach(t),J.forEach(t),QVo=i(da),m4=n(da,"P",{});var $$e=s(m4);HVo=r($$e,"The model is set in evaluation mode by default using "),Dhe=n($$e,"CODE",{});var Lpt=s(Dhe);UVo=r(Lpt,"model.eval()"),Lpt.forEach(t),JVo=r($$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ghe=n($$e,"CODE",{});var xpt=s(Ghe);YVo=r(xpt,"model.train()"),xpt.forEach(t),$$e.forEach(t),KVo=i(da),T(g4.$$.fragment,da),da.forEach(t),Ys.forEach(t),Wqe=i(f),Zi=n(f,"H2",{class:!0});var JDe=s(Zi);h4=n(JDe,"A",{id:!0,class:!0,href:!0});var $pt=s(h4);Ohe=n($pt,"SPAN",{});var kpt=s(Ohe);T(Hy.$$.fragment,kpt),kpt.forEach(t),$pt.forEach(t),ZVo=i(JDe),Vhe=n(JDe,"SPAN",{});var Spt=s(Vhe);eXo=r(Spt,"AutoModelForQuestionAnswering"),Spt.forEach(t),JDe.forEach(t),Qqe=i(f),No=n(f,"DIV",{class:!0});var Ks=s(No);T(Uy.$$.fragment,Ks),oXo=i(Ks),ed=n(Ks,"P",{});var VZ=s(ed);rXo=r(VZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),RV=n(VZ,"A",{href:!0});var Rpt=s(RV);tXo=r(Rpt,"from_pretrained()"),Rpt.forEach(t),aXo=r(VZ," class method or the "),PV=n(VZ,"A",{href:!0});var Ppt=s(PV);nXo=r(Ppt,"from_config()"),Ppt.forEach(t),sXo=r(VZ,` class
method.`),VZ.forEach(t),lXo=i(Ks),Jy=n(Ks,"P",{});var YDe=s(Jy);iXo=r(YDe,"This class cannot be instantiated directly using "),Xhe=n(YDe,"CODE",{});var Bpt=s(Xhe);dXo=r(Bpt,"__init__()"),Bpt.forEach(t),cXo=r(YDe," (throws an error)."),YDe.forEach(t),fXo=i(Ks),mt=n(Ks,"DIV",{class:!0});var Zw=s(mt);T(Yy.$$.fragment,Zw),mXo=i(Zw),zhe=n(Zw,"P",{});var Ipt=s(zhe);gXo=r(Ipt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Ipt.forEach(t),hXo=i(Zw),od=n(Zw,"P",{});var XZ=s(od);pXo=r(XZ,`Note:
Loading a model from its configuration file does `),Whe=n(XZ,"STRONG",{});var Npt=s(Whe);_Xo=r(Npt,"not"),Npt.forEach(t),uXo=r(XZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),BV=n(XZ,"A",{href:!0});var qpt=s(BV);bXo=r(qpt,"from_pretrained()"),qpt.forEach(t),vXo=r(XZ," to load the model weights."),XZ.forEach(t),FXo=i(Zw),T(p4.$$.fragment,Zw),Zw.forEach(t),TXo=i(Ks),no=n(Ks,"DIV",{class:!0});var ca=s(no);T(Ky.$$.fragment,ca),MXo=i(ca),Qhe=n(ca,"P",{});var jpt=s(Qhe);EXo=r(jpt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),jpt.forEach(t),CXo=i(ca),Na=n(ca,"P",{});var e0=s(Na);wXo=r(e0,"The model class to instantiate is selected based on the "),Hhe=n(e0,"CODE",{});var Dpt=s(Hhe);AXo=r(Dpt,"model_type"),Dpt.forEach(t),yXo=r(e0,` property of the config object (either
passed as an argument or loaded from `),Uhe=n(e0,"CODE",{});var Gpt=s(Uhe);LXo=r(Gpt,"pretrained_model_name_or_path"),Gpt.forEach(t),xXo=r(e0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jhe=n(e0,"CODE",{});var Opt=s(Jhe);$Xo=r(Opt,"pretrained_model_name_or_path"),Opt.forEach(t),kXo=r(e0,":"),e0.forEach(t),SXo=i(ca),V=n(ca,"UL",{});var X=s(V);_4=n(X,"LI",{});var k$e=s(_4);Yhe=n(k$e,"STRONG",{});var Vpt=s(Yhe);RXo=r(Vpt,"albert"),Vpt.forEach(t),PXo=r(k$e," \u2014 "),IV=n(k$e,"A",{href:!0});var Xpt=s(IV);BXo=r(Xpt,"AlbertForQuestionAnswering"),Xpt.forEach(t),IXo=r(k$e," (ALBERT model)"),k$e.forEach(t),NXo=i(X),u4=n(X,"LI",{});var S$e=s(u4);Khe=n(S$e,"STRONG",{});var zpt=s(Khe);qXo=r(zpt,"bart"),zpt.forEach(t),jXo=r(S$e," \u2014 "),NV=n(S$e,"A",{href:!0});var Wpt=s(NV);DXo=r(Wpt,"BartForQuestionAnswering"),Wpt.forEach(t),GXo=r(S$e," (BART model)"),S$e.forEach(t),OXo=i(X),b4=n(X,"LI",{});var R$e=s(b4);Zhe=n(R$e,"STRONG",{});var Qpt=s(Zhe);VXo=r(Qpt,"bert"),Qpt.forEach(t),XXo=r(R$e," \u2014 "),qV=n(R$e,"A",{href:!0});var Hpt=s(qV);zXo=r(Hpt,"BertForQuestionAnswering"),Hpt.forEach(t),WXo=r(R$e," (BERT model)"),R$e.forEach(t),QXo=i(X),v4=n(X,"LI",{});var P$e=s(v4);epe=n(P$e,"STRONG",{});var Upt=s(epe);HXo=r(Upt,"big_bird"),Upt.forEach(t),UXo=r(P$e," \u2014 "),jV=n(P$e,"A",{href:!0});var Jpt=s(jV);JXo=r(Jpt,"BigBirdForQuestionAnswering"),Jpt.forEach(t),YXo=r(P$e," (BigBird model)"),P$e.forEach(t),KXo=i(X),F4=n(X,"LI",{});var B$e=s(F4);ope=n(B$e,"STRONG",{});var Ypt=s(ope);ZXo=r(Ypt,"bigbird_pegasus"),Ypt.forEach(t),ezo=r(B$e," \u2014 "),DV=n(B$e,"A",{href:!0});var Kpt=s(DV);ozo=r(Kpt,"BigBirdPegasusForQuestionAnswering"),Kpt.forEach(t),rzo=r(B$e," (BigBirdPegasus model)"),B$e.forEach(t),tzo=i(X),T4=n(X,"LI",{});var I$e=s(T4);rpe=n(I$e,"STRONG",{});var Zpt=s(rpe);azo=r(Zpt,"camembert"),Zpt.forEach(t),nzo=r(I$e," \u2014 "),GV=n(I$e,"A",{href:!0});var e_t=s(GV);szo=r(e_t,"CamembertForQuestionAnswering"),e_t.forEach(t),lzo=r(I$e," (CamemBERT model)"),I$e.forEach(t),izo=i(X),M4=n(X,"LI",{});var N$e=s(M4);tpe=n(N$e,"STRONG",{});var o_t=s(tpe);dzo=r(o_t,"canine"),o_t.forEach(t),czo=r(N$e," \u2014 "),OV=n(N$e,"A",{href:!0});var r_t=s(OV);fzo=r(r_t,"CanineForQuestionAnswering"),r_t.forEach(t),mzo=r(N$e," (Canine model)"),N$e.forEach(t),gzo=i(X),E4=n(X,"LI",{});var q$e=s(E4);ape=n(q$e,"STRONG",{});var t_t=s(ape);hzo=r(t_t,"convbert"),t_t.forEach(t),pzo=r(q$e," \u2014 "),VV=n(q$e,"A",{href:!0});var a_t=s(VV);_zo=r(a_t,"ConvBertForQuestionAnswering"),a_t.forEach(t),uzo=r(q$e," (ConvBERT model)"),q$e.forEach(t),bzo=i(X),C4=n(X,"LI",{});var j$e=s(C4);npe=n(j$e,"STRONG",{});var n_t=s(npe);vzo=r(n_t,"data2vec-text"),n_t.forEach(t),Fzo=r(j$e," \u2014 "),XV=n(j$e,"A",{href:!0});var s_t=s(XV);Tzo=r(s_t,"Data2VecTextForQuestionAnswering"),s_t.forEach(t),Mzo=r(j$e," (Data2VecText model)"),j$e.forEach(t),Ezo=i(X),w4=n(X,"LI",{});var D$e=s(w4);spe=n(D$e,"STRONG",{});var l_t=s(spe);Czo=r(l_t,"deberta"),l_t.forEach(t),wzo=r(D$e," \u2014 "),zV=n(D$e,"A",{href:!0});var i_t=s(zV);Azo=r(i_t,"DebertaForQuestionAnswering"),i_t.forEach(t),yzo=r(D$e," (DeBERTa model)"),D$e.forEach(t),Lzo=i(X),A4=n(X,"LI",{});var G$e=s(A4);lpe=n(G$e,"STRONG",{});var d_t=s(lpe);xzo=r(d_t,"deberta-v2"),d_t.forEach(t),$zo=r(G$e," \u2014 "),WV=n(G$e,"A",{href:!0});var c_t=s(WV);kzo=r(c_t,"DebertaV2ForQuestionAnswering"),c_t.forEach(t),Szo=r(G$e," (DeBERTa-v2 model)"),G$e.forEach(t),Rzo=i(X),y4=n(X,"LI",{});var O$e=s(y4);ipe=n(O$e,"STRONG",{});var f_t=s(ipe);Pzo=r(f_t,"distilbert"),f_t.forEach(t),Bzo=r(O$e," \u2014 "),QV=n(O$e,"A",{href:!0});var m_t=s(QV);Izo=r(m_t,"DistilBertForQuestionAnswering"),m_t.forEach(t),Nzo=r(O$e," (DistilBERT model)"),O$e.forEach(t),qzo=i(X),L4=n(X,"LI",{});var V$e=s(L4);dpe=n(V$e,"STRONG",{});var g_t=s(dpe);jzo=r(g_t,"electra"),g_t.forEach(t),Dzo=r(V$e," \u2014 "),HV=n(V$e,"A",{href:!0});var h_t=s(HV);Gzo=r(h_t,"ElectraForQuestionAnswering"),h_t.forEach(t),Ozo=r(V$e," (ELECTRA model)"),V$e.forEach(t),Vzo=i(X),x4=n(X,"LI",{});var X$e=s(x4);cpe=n(X$e,"STRONG",{});var p_t=s(cpe);Xzo=r(p_t,"flaubert"),p_t.forEach(t),zzo=r(X$e," \u2014 "),UV=n(X$e,"A",{href:!0});var __t=s(UV);Wzo=r(__t,"FlaubertForQuestionAnsweringSimple"),__t.forEach(t),Qzo=r(X$e," (FlauBERT model)"),X$e.forEach(t),Hzo=i(X),$4=n(X,"LI",{});var z$e=s($4);fpe=n(z$e,"STRONG",{});var u_t=s(fpe);Uzo=r(u_t,"fnet"),u_t.forEach(t),Jzo=r(z$e," \u2014 "),JV=n(z$e,"A",{href:!0});var b_t=s(JV);Yzo=r(b_t,"FNetForQuestionAnswering"),b_t.forEach(t),Kzo=r(z$e," (FNet model)"),z$e.forEach(t),Zzo=i(X),k4=n(X,"LI",{});var W$e=s(k4);mpe=n(W$e,"STRONG",{});var v_t=s(mpe);eWo=r(v_t,"funnel"),v_t.forEach(t),oWo=r(W$e," \u2014 "),YV=n(W$e,"A",{href:!0});var F_t=s(YV);rWo=r(F_t,"FunnelForQuestionAnswering"),F_t.forEach(t),tWo=r(W$e," (Funnel Transformer model)"),W$e.forEach(t),aWo=i(X),S4=n(X,"LI",{});var Q$e=s(S4);gpe=n(Q$e,"STRONG",{});var T_t=s(gpe);nWo=r(T_t,"gptj"),T_t.forEach(t),sWo=r(Q$e," \u2014 "),KV=n(Q$e,"A",{href:!0});var M_t=s(KV);lWo=r(M_t,"GPTJForQuestionAnswering"),M_t.forEach(t),iWo=r(Q$e," (GPT-J model)"),Q$e.forEach(t),dWo=i(X),R4=n(X,"LI",{});var H$e=s(R4);hpe=n(H$e,"STRONG",{});var E_t=s(hpe);cWo=r(E_t,"ibert"),E_t.forEach(t),fWo=r(H$e," \u2014 "),ZV=n(H$e,"A",{href:!0});var C_t=s(ZV);mWo=r(C_t,"IBertForQuestionAnswering"),C_t.forEach(t),gWo=r(H$e," (I-BERT model)"),H$e.forEach(t),hWo=i(X),P4=n(X,"LI",{});var U$e=s(P4);ppe=n(U$e,"STRONG",{});var w_t=s(ppe);pWo=r(w_t,"layoutlmv2"),w_t.forEach(t),_Wo=r(U$e," \u2014 "),eX=n(U$e,"A",{href:!0});var A_t=s(eX);uWo=r(A_t,"LayoutLMv2ForQuestionAnswering"),A_t.forEach(t),bWo=r(U$e," (LayoutLMv2 model)"),U$e.forEach(t),vWo=i(X),B4=n(X,"LI",{});var J$e=s(B4);_pe=n(J$e,"STRONG",{});var y_t=s(_pe);FWo=r(y_t,"layoutlmv3"),y_t.forEach(t),TWo=r(J$e," \u2014 "),oX=n(J$e,"A",{href:!0});var L_t=s(oX);MWo=r(L_t,"LayoutLMv3ForQuestionAnswering"),L_t.forEach(t),EWo=r(J$e," (LayoutLMv3 model)"),J$e.forEach(t),CWo=i(X),I4=n(X,"LI",{});var Y$e=s(I4);upe=n(Y$e,"STRONG",{});var x_t=s(upe);wWo=r(x_t,"led"),x_t.forEach(t),AWo=r(Y$e," \u2014 "),rX=n(Y$e,"A",{href:!0});var $_t=s(rX);yWo=r($_t,"LEDForQuestionAnswering"),$_t.forEach(t),LWo=r(Y$e," (LED model)"),Y$e.forEach(t),xWo=i(X),N4=n(X,"LI",{});var K$e=s(N4);bpe=n(K$e,"STRONG",{});var k_t=s(bpe);$Wo=r(k_t,"longformer"),k_t.forEach(t),kWo=r(K$e," \u2014 "),tX=n(K$e,"A",{href:!0});var S_t=s(tX);SWo=r(S_t,"LongformerForQuestionAnswering"),S_t.forEach(t),RWo=r(K$e," (Longformer model)"),K$e.forEach(t),PWo=i(X),q4=n(X,"LI",{});var Z$e=s(q4);vpe=n(Z$e,"STRONG",{});var R_t=s(vpe);BWo=r(R_t,"lxmert"),R_t.forEach(t),IWo=r(Z$e," \u2014 "),aX=n(Z$e,"A",{href:!0});var P_t=s(aX);NWo=r(P_t,"LxmertForQuestionAnswering"),P_t.forEach(t),qWo=r(Z$e," (LXMERT model)"),Z$e.forEach(t),jWo=i(X),j4=n(X,"LI",{});var eke=s(j4);Fpe=n(eke,"STRONG",{});var B_t=s(Fpe);DWo=r(B_t,"mbart"),B_t.forEach(t),GWo=r(eke," \u2014 "),nX=n(eke,"A",{href:!0});var I_t=s(nX);OWo=r(I_t,"MBartForQuestionAnswering"),I_t.forEach(t),VWo=r(eke," (mBART model)"),eke.forEach(t),XWo=i(X),D4=n(X,"LI",{});var oke=s(D4);Tpe=n(oke,"STRONG",{});var N_t=s(Tpe);zWo=r(N_t,"megatron-bert"),N_t.forEach(t),WWo=r(oke," \u2014 "),sX=n(oke,"A",{href:!0});var q_t=s(sX);QWo=r(q_t,"MegatronBertForQuestionAnswering"),q_t.forEach(t),HWo=r(oke," (MegatronBert model)"),oke.forEach(t),UWo=i(X),G4=n(X,"LI",{});var rke=s(G4);Mpe=n(rke,"STRONG",{});var j_t=s(Mpe);JWo=r(j_t,"mobilebert"),j_t.forEach(t),YWo=r(rke," \u2014 "),lX=n(rke,"A",{href:!0});var D_t=s(lX);KWo=r(D_t,"MobileBertForQuestionAnswering"),D_t.forEach(t),ZWo=r(rke," (MobileBERT model)"),rke.forEach(t),eQo=i(X),O4=n(X,"LI",{});var tke=s(O4);Epe=n(tke,"STRONG",{});var G_t=s(Epe);oQo=r(G_t,"mpnet"),G_t.forEach(t),rQo=r(tke," \u2014 "),iX=n(tke,"A",{href:!0});var O_t=s(iX);tQo=r(O_t,"MPNetForQuestionAnswering"),O_t.forEach(t),aQo=r(tke," (MPNet model)"),tke.forEach(t),nQo=i(X),V4=n(X,"LI",{});var ake=s(V4);Cpe=n(ake,"STRONG",{});var V_t=s(Cpe);sQo=r(V_t,"nystromformer"),V_t.forEach(t),lQo=r(ake," \u2014 "),dX=n(ake,"A",{href:!0});var X_t=s(dX);iQo=r(X_t,"NystromformerForQuestionAnswering"),X_t.forEach(t),dQo=r(ake," (Nystromformer model)"),ake.forEach(t),cQo=i(X),X4=n(X,"LI",{});var nke=s(X4);wpe=n(nke,"STRONG",{});var z_t=s(wpe);fQo=r(z_t,"qdqbert"),z_t.forEach(t),mQo=r(nke," \u2014 "),cX=n(nke,"A",{href:!0});var W_t=s(cX);gQo=r(W_t,"QDQBertForQuestionAnswering"),W_t.forEach(t),hQo=r(nke," (QDQBert model)"),nke.forEach(t),pQo=i(X),z4=n(X,"LI",{});var ske=s(z4);Ape=n(ske,"STRONG",{});var Q_t=s(Ape);_Qo=r(Q_t,"reformer"),Q_t.forEach(t),uQo=r(ske," \u2014 "),fX=n(ske,"A",{href:!0});var H_t=s(fX);bQo=r(H_t,"ReformerForQuestionAnswering"),H_t.forEach(t),vQo=r(ske," (Reformer model)"),ske.forEach(t),FQo=i(X),W4=n(X,"LI",{});var lke=s(W4);ype=n(lke,"STRONG",{});var U_t=s(ype);TQo=r(U_t,"rembert"),U_t.forEach(t),MQo=r(lke," \u2014 "),mX=n(lke,"A",{href:!0});var J_t=s(mX);EQo=r(J_t,"RemBertForQuestionAnswering"),J_t.forEach(t),CQo=r(lke," (RemBERT model)"),lke.forEach(t),wQo=i(X),Q4=n(X,"LI",{});var ike=s(Q4);Lpe=n(ike,"STRONG",{});var Y_t=s(Lpe);AQo=r(Y_t,"roberta"),Y_t.forEach(t),yQo=r(ike," \u2014 "),gX=n(ike,"A",{href:!0});var K_t=s(gX);LQo=r(K_t,"RobertaForQuestionAnswering"),K_t.forEach(t),xQo=r(ike," (RoBERTa model)"),ike.forEach(t),$Qo=i(X),H4=n(X,"LI",{});var dke=s(H4);xpe=n(dke,"STRONG",{});var Z_t=s(xpe);kQo=r(Z_t,"roformer"),Z_t.forEach(t),SQo=r(dke," \u2014 "),hX=n(dke,"A",{href:!0});var eut=s(hX);RQo=r(eut,"RoFormerForQuestionAnswering"),eut.forEach(t),PQo=r(dke," (RoFormer model)"),dke.forEach(t),BQo=i(X),U4=n(X,"LI",{});var cke=s(U4);$pe=n(cke,"STRONG",{});var out=s($pe);IQo=r(out,"splinter"),out.forEach(t),NQo=r(cke," \u2014 "),pX=n(cke,"A",{href:!0});var rut=s(pX);qQo=r(rut,"SplinterForQuestionAnswering"),rut.forEach(t),jQo=r(cke," (Splinter model)"),cke.forEach(t),DQo=i(X),J4=n(X,"LI",{});var fke=s(J4);kpe=n(fke,"STRONG",{});var tut=s(kpe);GQo=r(tut,"squeezebert"),tut.forEach(t),OQo=r(fke," \u2014 "),_X=n(fke,"A",{href:!0});var aut=s(_X);VQo=r(aut,"SqueezeBertForQuestionAnswering"),aut.forEach(t),XQo=r(fke," (SqueezeBERT model)"),fke.forEach(t),zQo=i(X),Y4=n(X,"LI",{});var mke=s(Y4);Spe=n(mke,"STRONG",{});var nut=s(Spe);WQo=r(nut,"xlm"),nut.forEach(t),QQo=r(mke," \u2014 "),uX=n(mke,"A",{href:!0});var sut=s(uX);HQo=r(sut,"XLMForQuestionAnsweringSimple"),sut.forEach(t),UQo=r(mke," (XLM model)"),mke.forEach(t),JQo=i(X),K4=n(X,"LI",{});var gke=s(K4);Rpe=n(gke,"STRONG",{});var lut=s(Rpe);YQo=r(lut,"xlm-roberta"),lut.forEach(t),KQo=r(gke," \u2014 "),bX=n(gke,"A",{href:!0});var iut=s(bX);ZQo=r(iut,"XLMRobertaForQuestionAnswering"),iut.forEach(t),eHo=r(gke," (XLM-RoBERTa model)"),gke.forEach(t),oHo=i(X),Z4=n(X,"LI",{});var hke=s(Z4);Ppe=n(hke,"STRONG",{});var dut=s(Ppe);rHo=r(dut,"xlm-roberta-xl"),dut.forEach(t),tHo=r(hke," \u2014 "),vX=n(hke,"A",{href:!0});var cut=s(vX);aHo=r(cut,"XLMRobertaXLForQuestionAnswering"),cut.forEach(t),nHo=r(hke," (XLM-RoBERTa-XL model)"),hke.forEach(t),sHo=i(X),ev=n(X,"LI",{});var pke=s(ev);Bpe=n(pke,"STRONG",{});var fut=s(Bpe);lHo=r(fut,"xlnet"),fut.forEach(t),iHo=r(pke," \u2014 "),FX=n(pke,"A",{href:!0});var mut=s(FX);dHo=r(mut,"XLNetForQuestionAnsweringSimple"),mut.forEach(t),cHo=r(pke," (XLNet model)"),pke.forEach(t),fHo=i(X),ov=n(X,"LI",{});var _ke=s(ov);Ipe=n(_ke,"STRONG",{});var gut=s(Ipe);mHo=r(gut,"yoso"),gut.forEach(t),gHo=r(_ke," \u2014 "),TX=n(_ke,"A",{href:!0});var hut=s(TX);hHo=r(hut,"YosoForQuestionAnswering"),hut.forEach(t),pHo=r(_ke," (YOSO model)"),_ke.forEach(t),X.forEach(t),_Ho=i(ca),rv=n(ca,"P",{});var uke=s(rv);uHo=r(uke,"The model is set in evaluation mode by default using "),Npe=n(uke,"CODE",{});var put=s(Npe);bHo=r(put,"model.eval()"),put.forEach(t),vHo=r(uke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qpe=n(uke,"CODE",{});var _ut=s(qpe);FHo=r(_ut,"model.train()"),_ut.forEach(t),uke.forEach(t),THo=i(ca),T(tv.$$.fragment,ca),ca.forEach(t),Ks.forEach(t),Hqe=i(f),rd=n(f,"H2",{class:!0});var KDe=s(rd);av=n(KDe,"A",{id:!0,class:!0,href:!0});var uut=s(av);jpe=n(uut,"SPAN",{});var but=s(jpe);T(Zy.$$.fragment,but),but.forEach(t),uut.forEach(t),MHo=i(KDe),Dpe=n(KDe,"SPAN",{});var vut=s(Dpe);EHo=r(vut,"AutoModelForTableQuestionAnswering"),vut.forEach(t),KDe.forEach(t),Uqe=i(f),qo=n(f,"DIV",{class:!0});var Zs=s(qo);T(eL.$$.fragment,Zs),CHo=i(Zs),td=n(Zs,"P",{});var zZ=s(td);wHo=r(zZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),MX=n(zZ,"A",{href:!0});var Fut=s(MX);AHo=r(Fut,"from_pretrained()"),Fut.forEach(t),yHo=r(zZ," class method or the "),EX=n(zZ,"A",{href:!0});var Tut=s(EX);LHo=r(Tut,"from_config()"),Tut.forEach(t),xHo=r(zZ,` class
method.`),zZ.forEach(t),$Ho=i(Zs),oL=n(Zs,"P",{});var ZDe=s(oL);kHo=r(ZDe,"This class cannot be instantiated directly using "),Gpe=n(ZDe,"CODE",{});var Mut=s(Gpe);SHo=r(Mut,"__init__()"),Mut.forEach(t),RHo=r(ZDe," (throws an error)."),ZDe.forEach(t),PHo=i(Zs),gt=n(Zs,"DIV",{class:!0});var o0=s(gt);T(rL.$$.fragment,o0),BHo=i(o0),Ope=n(o0,"P",{});var Eut=s(Ope);IHo=r(Eut,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Eut.forEach(t),NHo=i(o0),ad=n(o0,"P",{});var WZ=s(ad);qHo=r(WZ,`Note:
Loading a model from its configuration file does `),Vpe=n(WZ,"STRONG",{});var Cut=s(Vpe);jHo=r(Cut,"not"),Cut.forEach(t),DHo=r(WZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),CX=n(WZ,"A",{href:!0});var wut=s(CX);GHo=r(wut,"from_pretrained()"),wut.forEach(t),OHo=r(WZ," to load the model weights."),WZ.forEach(t),VHo=i(o0),T(nv.$$.fragment,o0),o0.forEach(t),XHo=i(Zs),so=n(Zs,"DIV",{class:!0});var fa=s(so);T(tL.$$.fragment,fa),zHo=i(fa),Xpe=n(fa,"P",{});var Aut=s(Xpe);WHo=r(Aut,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Aut.forEach(t),QHo=i(fa),qa=n(fa,"P",{});var r0=s(qa);HHo=r(r0,"The model class to instantiate is selected based on the "),zpe=n(r0,"CODE",{});var yut=s(zpe);UHo=r(yut,"model_type"),yut.forEach(t),JHo=r(r0,` property of the config object (either
passed as an argument or loaded from `),Wpe=n(r0,"CODE",{});var Lut=s(Wpe);YHo=r(Lut,"pretrained_model_name_or_path"),Lut.forEach(t),KHo=r(r0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qpe=n(r0,"CODE",{});var xut=s(Qpe);ZHo=r(xut,"pretrained_model_name_or_path"),xut.forEach(t),eUo=r(r0,":"),r0.forEach(t),oUo=i(fa),Hpe=n(fa,"UL",{});var $ut=s(Hpe);sv=n($ut,"LI",{});var bke=s(sv);Upe=n(bke,"STRONG",{});var kut=s(Upe);rUo=r(kut,"tapas"),kut.forEach(t),tUo=r(bke," \u2014 "),wX=n(bke,"A",{href:!0});var Sut=s(wX);aUo=r(Sut,"TapasForQuestionAnswering"),Sut.forEach(t),nUo=r(bke," (TAPAS model)"),bke.forEach(t),$ut.forEach(t),sUo=i(fa),lv=n(fa,"P",{});var vke=s(lv);lUo=r(vke,"The model is set in evaluation mode by default using "),Jpe=n(vke,"CODE",{});var Rut=s(Jpe);iUo=r(Rut,"model.eval()"),Rut.forEach(t),dUo=r(vke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ype=n(vke,"CODE",{});var Put=s(Ype);cUo=r(Put,"model.train()"),Put.forEach(t),vke.forEach(t),fUo=i(fa),T(iv.$$.fragment,fa),fa.forEach(t),Zs.forEach(t),Jqe=i(f),nd=n(f,"H2",{class:!0});var eGe=s(nd);dv=n(eGe,"A",{id:!0,class:!0,href:!0});var But=s(dv);Kpe=n(But,"SPAN",{});var Iut=s(Kpe);T(aL.$$.fragment,Iut),Iut.forEach(t),But.forEach(t),mUo=i(eGe),Zpe=n(eGe,"SPAN",{});var Nut=s(Zpe);gUo=r(Nut,"AutoModelForImageClassification"),Nut.forEach(t),eGe.forEach(t),Yqe=i(f),jo=n(f,"DIV",{class:!0});var el=s(jo);T(nL.$$.fragment,el),hUo=i(el),sd=n(el,"P",{});var QZ=s(sd);pUo=r(QZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),AX=n(QZ,"A",{href:!0});var qut=s(AX);_Uo=r(qut,"from_pretrained()"),qut.forEach(t),uUo=r(QZ," class method or the "),yX=n(QZ,"A",{href:!0});var jut=s(yX);bUo=r(jut,"from_config()"),jut.forEach(t),vUo=r(QZ,` class
method.`),QZ.forEach(t),FUo=i(el),sL=n(el,"P",{});var oGe=s(sL);TUo=r(oGe,"This class cannot be instantiated directly using "),e_e=n(oGe,"CODE",{});var Dut=s(e_e);MUo=r(Dut,"__init__()"),Dut.forEach(t),EUo=r(oGe," (throws an error)."),oGe.forEach(t),CUo=i(el),ht=n(el,"DIV",{class:!0});var t0=s(ht);T(lL.$$.fragment,t0),wUo=i(t0),o_e=n(t0,"P",{});var Gut=s(o_e);AUo=r(Gut,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Gut.forEach(t),yUo=i(t0),ld=n(t0,"P",{});var HZ=s(ld);LUo=r(HZ,`Note:
Loading a model from its configuration file does `),r_e=n(HZ,"STRONG",{});var Out=s(r_e);xUo=r(Out,"not"),Out.forEach(t),$Uo=r(HZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),LX=n(HZ,"A",{href:!0});var Vut=s(LX);kUo=r(Vut,"from_pretrained()"),Vut.forEach(t),SUo=r(HZ," to load the model weights."),HZ.forEach(t),RUo=i(t0),T(cv.$$.fragment,t0),t0.forEach(t),PUo=i(el),lo=n(el,"DIV",{class:!0});var ma=s(lo);T(iL.$$.fragment,ma),BUo=i(ma),t_e=n(ma,"P",{});var Xut=s(t_e);IUo=r(Xut,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Xut.forEach(t),NUo=i(ma),ja=n(ma,"P",{});var a0=s(ja);qUo=r(a0,"The model class to instantiate is selected based on the "),a_e=n(a0,"CODE",{});var zut=s(a_e);jUo=r(zut,"model_type"),zut.forEach(t),DUo=r(a0,` property of the config object (either
passed as an argument or loaded from `),n_e=n(a0,"CODE",{});var Wut=s(n_e);GUo=r(Wut,"pretrained_model_name_or_path"),Wut.forEach(t),OUo=r(a0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s_e=n(a0,"CODE",{});var Qut=s(s_e);VUo=r(Qut,"pretrained_model_name_or_path"),Qut.forEach(t),XUo=r(a0,":"),a0.forEach(t),zUo=i(ma),ve=n(ma,"UL",{});var Te=s(ve);fv=n(Te,"LI",{});var Fke=s(fv);l_e=n(Fke,"STRONG",{});var Hut=s(l_e);WUo=r(Hut,"beit"),Hut.forEach(t),QUo=r(Fke," \u2014 "),xX=n(Fke,"A",{href:!0});var Uut=s(xX);HUo=r(Uut,"BeitForImageClassification"),Uut.forEach(t),UUo=r(Fke," (BEiT model)"),Fke.forEach(t),JUo=i(Te),mv=n(Te,"LI",{});var Tke=s(mv);i_e=n(Tke,"STRONG",{});var Jut=s(i_e);YUo=r(Jut,"convnext"),Jut.forEach(t),KUo=r(Tke," \u2014 "),$X=n(Tke,"A",{href:!0});var Yut=s($X);ZUo=r(Yut,"ConvNextForImageClassification"),Yut.forEach(t),eJo=r(Tke," (ConvNext model)"),Tke.forEach(t),oJo=i(Te),gv=n(Te,"LI",{});var Mke=s(gv);d_e=n(Mke,"STRONG",{});var Kut=s(d_e);rJo=r(Kut,"cvt"),Kut.forEach(t),tJo=r(Mke," \u2014 "),kX=n(Mke,"A",{href:!0});var Zut=s(kX);aJo=r(Zut,"CvtForImageClassification"),Zut.forEach(t),nJo=r(Mke," (CvT model)"),Mke.forEach(t),sJo=i(Te),hv=n(Te,"LI",{});var Eke=s(hv);c_e=n(Eke,"STRONG",{});var e6t=s(c_e);lJo=r(e6t,"data2vec-vision"),e6t.forEach(t),iJo=r(Eke," \u2014 "),SX=n(Eke,"A",{href:!0});var o6t=s(SX);dJo=r(o6t,"Data2VecVisionForImageClassification"),o6t.forEach(t),cJo=r(Eke," (Data2VecVision model)"),Eke.forEach(t),fJo=i(Te),Bs=n(Te,"LI",{});var Q$=s(Bs);f_e=n(Q$,"STRONG",{});var r6t=s(f_e);mJo=r(r6t,"deit"),r6t.forEach(t),gJo=r(Q$," \u2014 "),RX=n(Q$,"A",{href:!0});var t6t=s(RX);hJo=r(t6t,"DeiTForImageClassification"),t6t.forEach(t),pJo=r(Q$," or "),PX=n(Q$,"A",{href:!0});var a6t=s(PX);_Jo=r(a6t,"DeiTForImageClassificationWithTeacher"),a6t.forEach(t),uJo=r(Q$," (DeiT model)"),Q$.forEach(t),bJo=i(Te),pv=n(Te,"LI",{});var Cke=s(pv);m_e=n(Cke,"STRONG",{});var n6t=s(m_e);vJo=r(n6t,"imagegpt"),n6t.forEach(t),FJo=r(Cke," \u2014 "),BX=n(Cke,"A",{href:!0});var s6t=s(BX);TJo=r(s6t,"ImageGPTForImageClassification"),s6t.forEach(t),MJo=r(Cke," (ImageGPT model)"),Cke.forEach(t),EJo=i(Te),Is=n(Te,"LI",{});var H$=s(Is);g_e=n(H$,"STRONG",{});var l6t=s(g_e);CJo=r(l6t,"levit"),l6t.forEach(t),wJo=r(H$," \u2014 "),IX=n(H$,"A",{href:!0});var i6t=s(IX);AJo=r(i6t,"LevitForImageClassification"),i6t.forEach(t),yJo=r(H$," or "),NX=n(H$,"A",{href:!0});var d6t=s(NX);LJo=r(d6t,"LevitForImageClassificationWithTeacher"),d6t.forEach(t),xJo=r(H$," (LeViT model)"),H$.forEach(t),$Jo=i(Te),pt=n(Te,"LI",{});var pf=s(pt);h_e=n(pf,"STRONG",{});var c6t=s(h_e);kJo=r(c6t,"perceiver"),c6t.forEach(t),SJo=r(pf," \u2014 "),qX=n(pf,"A",{href:!0});var f6t=s(qX);RJo=r(f6t,"PerceiverForImageClassificationLearned"),f6t.forEach(t),PJo=r(pf," or "),jX=n(pf,"A",{href:!0});var m6t=s(jX);BJo=r(m6t,"PerceiverForImageClassificationFourier"),m6t.forEach(t),IJo=r(pf," or "),DX=n(pf,"A",{href:!0});var g6t=s(DX);NJo=r(g6t,"PerceiverForImageClassificationConvProcessing"),g6t.forEach(t),qJo=r(pf," (Perceiver model)"),pf.forEach(t),jJo=i(Te),_v=n(Te,"LI",{});var wke=s(_v);p_e=n(wke,"STRONG",{});var h6t=s(p_e);DJo=r(h6t,"poolformer"),h6t.forEach(t),GJo=r(wke," \u2014 "),GX=n(wke,"A",{href:!0});var p6t=s(GX);OJo=r(p6t,"PoolFormerForImageClassification"),p6t.forEach(t),VJo=r(wke," (PoolFormer model)"),wke.forEach(t),XJo=i(Te),uv=n(Te,"LI",{});var Ake=s(uv);__e=n(Ake,"STRONG",{});var _6t=s(__e);zJo=r(_6t,"regnet"),_6t.forEach(t),WJo=r(Ake," \u2014 "),OX=n(Ake,"A",{href:!0});var u6t=s(OX);QJo=r(u6t,"RegNetForImageClassification"),u6t.forEach(t),HJo=r(Ake," (RegNet model)"),Ake.forEach(t),UJo=i(Te),bv=n(Te,"LI",{});var yke=s(bv);u_e=n(yke,"STRONG",{});var b6t=s(u_e);JJo=r(b6t,"resnet"),b6t.forEach(t),YJo=r(yke," \u2014 "),VX=n(yke,"A",{href:!0});var v6t=s(VX);KJo=r(v6t,"ResNetForImageClassification"),v6t.forEach(t),ZJo=r(yke," (ResNet model)"),yke.forEach(t),eYo=i(Te),vv=n(Te,"LI",{});var Lke=s(vv);b_e=n(Lke,"STRONG",{});var F6t=s(b_e);oYo=r(F6t,"segformer"),F6t.forEach(t),rYo=r(Lke," \u2014 "),XX=n(Lke,"A",{href:!0});var T6t=s(XX);tYo=r(T6t,"SegformerForImageClassification"),T6t.forEach(t),aYo=r(Lke," (SegFormer model)"),Lke.forEach(t),nYo=i(Te),Fv=n(Te,"LI",{});var xke=s(Fv);v_e=n(xke,"STRONG",{});var M6t=s(v_e);sYo=r(M6t,"swin"),M6t.forEach(t),lYo=r(xke," \u2014 "),zX=n(xke,"A",{href:!0});var E6t=s(zX);iYo=r(E6t,"SwinForImageClassification"),E6t.forEach(t),dYo=r(xke," (Swin model)"),xke.forEach(t),cYo=i(Te),Tv=n(Te,"LI",{});var $ke=s(Tv);F_e=n($ke,"STRONG",{});var C6t=s(F_e);fYo=r(C6t,"van"),C6t.forEach(t),mYo=r($ke," \u2014 "),WX=n($ke,"A",{href:!0});var w6t=s(WX);gYo=r(w6t,"VanForImageClassification"),w6t.forEach(t),hYo=r($ke," (VAN model)"),$ke.forEach(t),pYo=i(Te),Mv=n(Te,"LI",{});var kke=s(Mv);T_e=n(kke,"STRONG",{});var A6t=s(T_e);_Yo=r(A6t,"vit"),A6t.forEach(t),uYo=r(kke," \u2014 "),QX=n(kke,"A",{href:!0});var y6t=s(QX);bYo=r(y6t,"ViTForImageClassification"),y6t.forEach(t),vYo=r(kke," (ViT model)"),kke.forEach(t),Te.forEach(t),FYo=i(ma),Ev=n(ma,"P",{});var Ske=s(Ev);TYo=r(Ske,"The model is set in evaluation mode by default using "),M_e=n(Ske,"CODE",{});var L6t=s(M_e);MYo=r(L6t,"model.eval()"),L6t.forEach(t),EYo=r(Ske,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),E_e=n(Ske,"CODE",{});var x6t=s(E_e);CYo=r(x6t,"model.train()"),x6t.forEach(t),Ske.forEach(t),wYo=i(ma),T(Cv.$$.fragment,ma),ma.forEach(t),el.forEach(t),Kqe=i(f),id=n(f,"H2",{class:!0});var rGe=s(id);wv=n(rGe,"A",{id:!0,class:!0,href:!0});var $6t=s(wv);C_e=n($6t,"SPAN",{});var k6t=s(C_e);T(dL.$$.fragment,k6t),k6t.forEach(t),$6t.forEach(t),AYo=i(rGe),w_e=n(rGe,"SPAN",{});var S6t=s(w_e);yYo=r(S6t,"AutoModelForVision2Seq"),S6t.forEach(t),rGe.forEach(t),Zqe=i(f),Do=n(f,"DIV",{class:!0});var ol=s(Do);T(cL.$$.fragment,ol),LYo=i(ol),dd=n(ol,"P",{});var UZ=s(dd);xYo=r(UZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),HX=n(UZ,"A",{href:!0});var R6t=s(HX);$Yo=r(R6t,"from_pretrained()"),R6t.forEach(t),kYo=r(UZ," class method or the "),UX=n(UZ,"A",{href:!0});var P6t=s(UX);SYo=r(P6t,"from_config()"),P6t.forEach(t),RYo=r(UZ,` class
method.`),UZ.forEach(t),PYo=i(ol),fL=n(ol,"P",{});var tGe=s(fL);BYo=r(tGe,"This class cannot be instantiated directly using "),A_e=n(tGe,"CODE",{});var B6t=s(A_e);IYo=r(B6t,"__init__()"),B6t.forEach(t),NYo=r(tGe," (throws an error)."),tGe.forEach(t),qYo=i(ol),_t=n(ol,"DIV",{class:!0});var n0=s(_t);T(mL.$$.fragment,n0),jYo=i(n0),y_e=n(n0,"P",{});var I6t=s(y_e);DYo=r(I6t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),I6t.forEach(t),GYo=i(n0),cd=n(n0,"P",{});var JZ=s(cd);OYo=r(JZ,`Note:
Loading a model from its configuration file does `),L_e=n(JZ,"STRONG",{});var N6t=s(L_e);VYo=r(N6t,"not"),N6t.forEach(t),XYo=r(JZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),JX=n(JZ,"A",{href:!0});var q6t=s(JX);zYo=r(q6t,"from_pretrained()"),q6t.forEach(t),WYo=r(JZ," to load the model weights."),JZ.forEach(t),QYo=i(n0),T(Av.$$.fragment,n0),n0.forEach(t),HYo=i(ol),io=n(ol,"DIV",{class:!0});var ga=s(io);T(gL.$$.fragment,ga),UYo=i(ga),x_e=n(ga,"P",{});var j6t=s(x_e);JYo=r(j6t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),j6t.forEach(t),YYo=i(ga),Da=n(ga,"P",{});var s0=s(Da);KYo=r(s0,"The model class to instantiate is selected based on the "),$_e=n(s0,"CODE",{});var D6t=s($_e);ZYo=r(D6t,"model_type"),D6t.forEach(t),eKo=r(s0,` property of the config object (either
passed as an argument or loaded from `),k_e=n(s0,"CODE",{});var G6t=s(k_e);oKo=r(G6t,"pretrained_model_name_or_path"),G6t.forEach(t),rKo=r(s0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S_e=n(s0,"CODE",{});var O6t=s(S_e);tKo=r(O6t,"pretrained_model_name_or_path"),O6t.forEach(t),aKo=r(s0,":"),s0.forEach(t),nKo=i(ga),R_e=n(ga,"UL",{});var V6t=s(R_e);yv=n(V6t,"LI",{});var Rke=s(yv);P_e=n(Rke,"STRONG",{});var X6t=s(P_e);sKo=r(X6t,"vision-encoder-decoder"),X6t.forEach(t),lKo=r(Rke," \u2014 "),YX=n(Rke,"A",{href:!0});var z6t=s(YX);iKo=r(z6t,"VisionEncoderDecoderModel"),z6t.forEach(t),dKo=r(Rke," (Vision Encoder decoder model)"),Rke.forEach(t),V6t.forEach(t),cKo=i(ga),Lv=n(ga,"P",{});var Pke=s(Lv);fKo=r(Pke,"The model is set in evaluation mode by default using "),B_e=n(Pke,"CODE",{});var W6t=s(B_e);mKo=r(W6t,"model.eval()"),W6t.forEach(t),gKo=r(Pke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),I_e=n(Pke,"CODE",{});var Q6t=s(I_e);hKo=r(Q6t,"model.train()"),Q6t.forEach(t),Pke.forEach(t),pKo=i(ga),T(xv.$$.fragment,ga),ga.forEach(t),ol.forEach(t),eje=i(f),fd=n(f,"H2",{class:!0});var aGe=s(fd);$v=n(aGe,"A",{id:!0,class:!0,href:!0});var H6t=s($v);N_e=n(H6t,"SPAN",{});var U6t=s(N_e);T(hL.$$.fragment,U6t),U6t.forEach(t),H6t.forEach(t),_Ko=i(aGe),q_e=n(aGe,"SPAN",{});var J6t=s(q_e);uKo=r(J6t,"AutoModelForAudioClassification"),J6t.forEach(t),aGe.forEach(t),oje=i(f),Go=n(f,"DIV",{class:!0});var rl=s(Go);T(pL.$$.fragment,rl),bKo=i(rl),md=n(rl,"P",{});var YZ=s(md);vKo=r(YZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),KX=n(YZ,"A",{href:!0});var Y6t=s(KX);FKo=r(Y6t,"from_pretrained()"),Y6t.forEach(t),TKo=r(YZ," class method or the "),ZX=n(YZ,"A",{href:!0});var K6t=s(ZX);MKo=r(K6t,"from_config()"),K6t.forEach(t),EKo=r(YZ,` class
method.`),YZ.forEach(t),CKo=i(rl),_L=n(rl,"P",{});var nGe=s(_L);wKo=r(nGe,"This class cannot be instantiated directly using "),j_e=n(nGe,"CODE",{});var Z6t=s(j_e);AKo=r(Z6t,"__init__()"),Z6t.forEach(t),yKo=r(nGe," (throws an error)."),nGe.forEach(t),LKo=i(rl),ut=n(rl,"DIV",{class:!0});var l0=s(ut);T(uL.$$.fragment,l0),xKo=i(l0),D_e=n(l0,"P",{});var e1t=s(D_e);$Ko=r(e1t,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),e1t.forEach(t),kKo=i(l0),gd=n(l0,"P",{});var KZ=s(gd);SKo=r(KZ,`Note:
Loading a model from its configuration file does `),G_e=n(KZ,"STRONG",{});var o1t=s(G_e);RKo=r(o1t,"not"),o1t.forEach(t),PKo=r(KZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),ez=n(KZ,"A",{href:!0});var r1t=s(ez);BKo=r(r1t,"from_pretrained()"),r1t.forEach(t),IKo=r(KZ," to load the model weights."),KZ.forEach(t),NKo=i(l0),T(kv.$$.fragment,l0),l0.forEach(t),qKo=i(rl),co=n(rl,"DIV",{class:!0});var ha=s(co);T(bL.$$.fragment,ha),jKo=i(ha),O_e=n(ha,"P",{});var t1t=s(O_e);DKo=r(t1t,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),t1t.forEach(t),GKo=i(ha),Ga=n(ha,"P",{});var i0=s(Ga);OKo=r(i0,"The model class to instantiate is selected based on the "),V_e=n(i0,"CODE",{});var a1t=s(V_e);VKo=r(a1t,"model_type"),a1t.forEach(t),XKo=r(i0,` property of the config object (either
passed as an argument or loaded from `),X_e=n(i0,"CODE",{});var n1t=s(X_e);zKo=r(n1t,"pretrained_model_name_or_path"),n1t.forEach(t),WKo=r(i0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z_e=n(i0,"CODE",{});var s1t=s(z_e);QKo=r(s1t,"pretrained_model_name_or_path"),s1t.forEach(t),HKo=r(i0,":"),i0.forEach(t),UKo=i(ha),ke=n(ha,"UL",{});var Oe=s(ke);Sv=n(Oe,"LI",{});var Bke=s(Sv);W_e=n(Bke,"STRONG",{});var l1t=s(W_e);JKo=r(l1t,"data2vec-audio"),l1t.forEach(t),YKo=r(Bke," \u2014 "),oz=n(Bke,"A",{href:!0});var i1t=s(oz);KKo=r(i1t,"Data2VecAudioForSequenceClassification"),i1t.forEach(t),ZKo=r(Bke," (Data2VecAudio model)"),Bke.forEach(t),eZo=i(Oe),Rv=n(Oe,"LI",{});var Ike=s(Rv);Q_e=n(Ike,"STRONG",{});var d1t=s(Q_e);oZo=r(d1t,"hubert"),d1t.forEach(t),rZo=r(Ike," \u2014 "),rz=n(Ike,"A",{href:!0});var c1t=s(rz);tZo=r(c1t,"HubertForSequenceClassification"),c1t.forEach(t),aZo=r(Ike," (Hubert model)"),Ike.forEach(t),nZo=i(Oe),Pv=n(Oe,"LI",{});var Nke=s(Pv);H_e=n(Nke,"STRONG",{});var f1t=s(H_e);sZo=r(f1t,"sew"),f1t.forEach(t),lZo=r(Nke," \u2014 "),tz=n(Nke,"A",{href:!0});var m1t=s(tz);iZo=r(m1t,"SEWForSequenceClassification"),m1t.forEach(t),dZo=r(Nke," (SEW model)"),Nke.forEach(t),cZo=i(Oe),Bv=n(Oe,"LI",{});var qke=s(Bv);U_e=n(qke,"STRONG",{});var g1t=s(U_e);fZo=r(g1t,"sew-d"),g1t.forEach(t),mZo=r(qke," \u2014 "),az=n(qke,"A",{href:!0});var h1t=s(az);gZo=r(h1t,"SEWDForSequenceClassification"),h1t.forEach(t),hZo=r(qke," (SEW-D model)"),qke.forEach(t),pZo=i(Oe),Iv=n(Oe,"LI",{});var jke=s(Iv);J_e=n(jke,"STRONG",{});var p1t=s(J_e);_Zo=r(p1t,"unispeech"),p1t.forEach(t),uZo=r(jke," \u2014 "),nz=n(jke,"A",{href:!0});var _1t=s(nz);bZo=r(_1t,"UniSpeechForSequenceClassification"),_1t.forEach(t),vZo=r(jke," (UniSpeech model)"),jke.forEach(t),FZo=i(Oe),Nv=n(Oe,"LI",{});var Dke=s(Nv);Y_e=n(Dke,"STRONG",{});var u1t=s(Y_e);TZo=r(u1t,"unispeech-sat"),u1t.forEach(t),MZo=r(Dke," \u2014 "),sz=n(Dke,"A",{href:!0});var b1t=s(sz);EZo=r(b1t,"UniSpeechSatForSequenceClassification"),b1t.forEach(t),CZo=r(Dke," (UniSpeechSat model)"),Dke.forEach(t),wZo=i(Oe),qv=n(Oe,"LI",{});var Gke=s(qv);K_e=n(Gke,"STRONG",{});var v1t=s(K_e);AZo=r(v1t,"wav2vec2"),v1t.forEach(t),yZo=r(Gke," \u2014 "),lz=n(Gke,"A",{href:!0});var F1t=s(lz);LZo=r(F1t,"Wav2Vec2ForSequenceClassification"),F1t.forEach(t),xZo=r(Gke," (Wav2Vec2 model)"),Gke.forEach(t),$Zo=i(Oe),jv=n(Oe,"LI",{});var Oke=s(jv);Z_e=n(Oke,"STRONG",{});var T1t=s(Z_e);kZo=r(T1t,"wav2vec2-conformer"),T1t.forEach(t),SZo=r(Oke," \u2014 "),iz=n(Oke,"A",{href:!0});var M1t=s(iz);RZo=r(M1t,"Wav2Vec2ConformerForSequenceClassification"),M1t.forEach(t),PZo=r(Oke," (Wav2Vec2-Conformer model)"),Oke.forEach(t),BZo=i(Oe),Dv=n(Oe,"LI",{});var Vke=s(Dv);eue=n(Vke,"STRONG",{});var E1t=s(eue);IZo=r(E1t,"wavlm"),E1t.forEach(t),NZo=r(Vke," \u2014 "),dz=n(Vke,"A",{href:!0});var C1t=s(dz);qZo=r(C1t,"WavLMForSequenceClassification"),C1t.forEach(t),jZo=r(Vke," (WavLM model)"),Vke.forEach(t),Oe.forEach(t),DZo=i(ha),Gv=n(ha,"P",{});var Xke=s(Gv);GZo=r(Xke,"The model is set in evaluation mode by default using "),oue=n(Xke,"CODE",{});var w1t=s(oue);OZo=r(w1t,"model.eval()"),w1t.forEach(t),VZo=r(Xke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rue=n(Xke,"CODE",{});var A1t=s(rue);XZo=r(A1t,"model.train()"),A1t.forEach(t),Xke.forEach(t),zZo=i(ha),T(Ov.$$.fragment,ha),ha.forEach(t),rl.forEach(t),rje=i(f),hd=n(f,"H2",{class:!0});var sGe=s(hd);Vv=n(sGe,"A",{id:!0,class:!0,href:!0});var y1t=s(Vv);tue=n(y1t,"SPAN",{});var L1t=s(tue);T(vL.$$.fragment,L1t),L1t.forEach(t),y1t.forEach(t),WZo=i(sGe),aue=n(sGe,"SPAN",{});var x1t=s(aue);QZo=r(x1t,"AutoModelForAudioFrameClassification"),x1t.forEach(t),sGe.forEach(t),tje=i(f),Oo=n(f,"DIV",{class:!0});var tl=s(Oo);T(FL.$$.fragment,tl),HZo=i(tl),pd=n(tl,"P",{});var ZZ=s(pd);UZo=r(ZZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),cz=n(ZZ,"A",{href:!0});var $1t=s(cz);JZo=r($1t,"from_pretrained()"),$1t.forEach(t),YZo=r(ZZ," class method or the "),fz=n(ZZ,"A",{href:!0});var k1t=s(fz);KZo=r(k1t,"from_config()"),k1t.forEach(t),ZZo=r(ZZ,` class
method.`),ZZ.forEach(t),eer=i(tl),TL=n(tl,"P",{});var lGe=s(TL);oer=r(lGe,"This class cannot be instantiated directly using "),nue=n(lGe,"CODE",{});var S1t=s(nue);rer=r(S1t,"__init__()"),S1t.forEach(t),ter=r(lGe," (throws an error)."),lGe.forEach(t),aer=i(tl),bt=n(tl,"DIV",{class:!0});var d0=s(bt);T(ML.$$.fragment,d0),ner=i(d0),sue=n(d0,"P",{});var R1t=s(sue);ser=r(R1t,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),R1t.forEach(t),ler=i(d0),_d=n(d0,"P",{});var eee=s(_d);ier=r(eee,`Note:
Loading a model from its configuration file does `),lue=n(eee,"STRONG",{});var P1t=s(lue);der=r(P1t,"not"),P1t.forEach(t),cer=r(eee,` load the model weights. It only affects the
model\u2019s configuration. Use `),mz=n(eee,"A",{href:!0});var B1t=s(mz);fer=r(B1t,"from_pretrained()"),B1t.forEach(t),mer=r(eee," to load the model weights."),eee.forEach(t),ger=i(d0),T(Xv.$$.fragment,d0),d0.forEach(t),her=i(tl),fo=n(tl,"DIV",{class:!0});var pa=s(fo);T(EL.$$.fragment,pa),per=i(pa),iue=n(pa,"P",{});var I1t=s(iue);_er=r(I1t,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),I1t.forEach(t),uer=i(pa),Oa=n(pa,"P",{});var c0=s(Oa);ber=r(c0,"The model class to instantiate is selected based on the "),due=n(c0,"CODE",{});var N1t=s(due);ver=r(N1t,"model_type"),N1t.forEach(t),Fer=r(c0,` property of the config object (either
passed as an argument or loaded from `),cue=n(c0,"CODE",{});var q1t=s(cue);Ter=r(q1t,"pretrained_model_name_or_path"),q1t.forEach(t),Mer=r(c0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fue=n(c0,"CODE",{});var j1t=s(fue);Eer=r(j1t,"pretrained_model_name_or_path"),j1t.forEach(t),Cer=r(c0,":"),c0.forEach(t),wer=i(pa),Kr=n(pa,"UL",{});var al=s(Kr);zv=n(al,"LI",{});var zke=s(zv);mue=n(zke,"STRONG",{});var D1t=s(mue);Aer=r(D1t,"data2vec-audio"),D1t.forEach(t),yer=r(zke," \u2014 "),gz=n(zke,"A",{href:!0});var G1t=s(gz);Ler=r(G1t,"Data2VecAudioForAudioFrameClassification"),G1t.forEach(t),xer=r(zke," (Data2VecAudio model)"),zke.forEach(t),$er=i(al),Wv=n(al,"LI",{});var Wke=s(Wv);gue=n(Wke,"STRONG",{});var O1t=s(gue);ker=r(O1t,"unispeech-sat"),O1t.forEach(t),Ser=r(Wke," \u2014 "),hz=n(Wke,"A",{href:!0});var V1t=s(hz);Rer=r(V1t,"UniSpeechSatForAudioFrameClassification"),V1t.forEach(t),Per=r(Wke," (UniSpeechSat model)"),Wke.forEach(t),Ber=i(al),Qv=n(al,"LI",{});var Qke=s(Qv);hue=n(Qke,"STRONG",{});var X1t=s(hue);Ier=r(X1t,"wav2vec2"),X1t.forEach(t),Ner=r(Qke," \u2014 "),pz=n(Qke,"A",{href:!0});var z1t=s(pz);qer=r(z1t,"Wav2Vec2ForAudioFrameClassification"),z1t.forEach(t),jer=r(Qke," (Wav2Vec2 model)"),Qke.forEach(t),Der=i(al),Hv=n(al,"LI",{});var Hke=s(Hv);pue=n(Hke,"STRONG",{});var W1t=s(pue);Ger=r(W1t,"wav2vec2-conformer"),W1t.forEach(t),Oer=r(Hke," \u2014 "),_z=n(Hke,"A",{href:!0});var Q1t=s(_z);Ver=r(Q1t,"Wav2Vec2ConformerForAudioFrameClassification"),Q1t.forEach(t),Xer=r(Hke," (Wav2Vec2-Conformer model)"),Hke.forEach(t),zer=i(al),Uv=n(al,"LI",{});var Uke=s(Uv);_ue=n(Uke,"STRONG",{});var H1t=s(_ue);Wer=r(H1t,"wavlm"),H1t.forEach(t),Qer=r(Uke," \u2014 "),uz=n(Uke,"A",{href:!0});var U1t=s(uz);Her=r(U1t,"WavLMForAudioFrameClassification"),U1t.forEach(t),Uer=r(Uke," (WavLM model)"),Uke.forEach(t),al.forEach(t),Jer=i(pa),Jv=n(pa,"P",{});var Jke=s(Jv);Yer=r(Jke,"The model is set in evaluation mode by default using "),uue=n(Jke,"CODE",{});var J1t=s(uue);Ker=r(J1t,"model.eval()"),J1t.forEach(t),Zer=r(Jke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bue=n(Jke,"CODE",{});var Y1t=s(bue);eor=r(Y1t,"model.train()"),Y1t.forEach(t),Jke.forEach(t),oor=i(pa),T(Yv.$$.fragment,pa),pa.forEach(t),tl.forEach(t),aje=i(f),ud=n(f,"H2",{class:!0});var iGe=s(ud);Kv=n(iGe,"A",{id:!0,class:!0,href:!0});var K1t=s(Kv);vue=n(K1t,"SPAN",{});var Z1t=s(vue);T(CL.$$.fragment,Z1t),Z1t.forEach(t),K1t.forEach(t),ror=i(iGe),Fue=n(iGe,"SPAN",{});var ebt=s(Fue);tor=r(ebt,"AutoModelForCTC"),ebt.forEach(t),iGe.forEach(t),nje=i(f),Vo=n(f,"DIV",{class:!0});var nl=s(Vo);T(wL.$$.fragment,nl),aor=i(nl),bd=n(nl,"P",{});var oee=s(bd);nor=r(oee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),bz=n(oee,"A",{href:!0});var obt=s(bz);sor=r(obt,"from_pretrained()"),obt.forEach(t),lor=r(oee," class method or the "),vz=n(oee,"A",{href:!0});var rbt=s(vz);ior=r(rbt,"from_config()"),rbt.forEach(t),dor=r(oee,` class
method.`),oee.forEach(t),cor=i(nl),AL=n(nl,"P",{});var dGe=s(AL);mor=r(dGe,"This class cannot be instantiated directly using "),Tue=n(dGe,"CODE",{});var tbt=s(Tue);gor=r(tbt,"__init__()"),tbt.forEach(t),hor=r(dGe," (throws an error)."),dGe.forEach(t),por=i(nl),vt=n(nl,"DIV",{class:!0});var f0=s(vt);T(yL.$$.fragment,f0),_or=i(f0),Mue=n(f0,"P",{});var abt=s(Mue);uor=r(abt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),abt.forEach(t),bor=i(f0),vd=n(f0,"P",{});var ree=s(vd);vor=r(ree,`Note:
Loading a model from its configuration file does `),Eue=n(ree,"STRONG",{});var nbt=s(Eue);For=r(nbt,"not"),nbt.forEach(t),Tor=r(ree,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fz=n(ree,"A",{href:!0});var sbt=s(Fz);Mor=r(sbt,"from_pretrained()"),sbt.forEach(t),Eor=r(ree," to load the model weights."),ree.forEach(t),Cor=i(f0),T(Zv.$$.fragment,f0),f0.forEach(t),wor=i(nl),mo=n(nl,"DIV",{class:!0});var _a=s(mo);T(LL.$$.fragment,_a),Aor=i(_a),Cue=n(_a,"P",{});var lbt=s(Cue);yor=r(lbt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),lbt.forEach(t),Lor=i(_a),Va=n(_a,"P",{});var m0=s(Va);xor=r(m0,"The model class to instantiate is selected based on the "),wue=n(m0,"CODE",{});var ibt=s(wue);$or=r(ibt,"model_type"),ibt.forEach(t),kor=r(m0,` property of the config object (either
passed as an argument or loaded from `),Aue=n(m0,"CODE",{});var dbt=s(Aue);Sor=r(dbt,"pretrained_model_name_or_path"),dbt.forEach(t),Ror=r(m0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yue=n(m0,"CODE",{});var cbt=s(yue);Por=r(cbt,"pretrained_model_name_or_path"),cbt.forEach(t),Bor=r(m0,":"),m0.forEach(t),Ior=i(_a),Se=n(_a,"UL",{});var Ve=s(Se);eF=n(Ve,"LI",{});var Yke=s(eF);Lue=n(Yke,"STRONG",{});var fbt=s(Lue);Nor=r(fbt,"data2vec-audio"),fbt.forEach(t),qor=r(Yke," \u2014 "),Tz=n(Yke,"A",{href:!0});var mbt=s(Tz);jor=r(mbt,"Data2VecAudioForCTC"),mbt.forEach(t),Dor=r(Yke," (Data2VecAudio model)"),Yke.forEach(t),Gor=i(Ve),oF=n(Ve,"LI",{});var Kke=s(oF);xue=n(Kke,"STRONG",{});var gbt=s(xue);Oor=r(gbt,"hubert"),gbt.forEach(t),Vor=r(Kke," \u2014 "),Mz=n(Kke,"A",{href:!0});var hbt=s(Mz);Xor=r(hbt,"HubertForCTC"),hbt.forEach(t),zor=r(Kke," (Hubert model)"),Kke.forEach(t),Wor=i(Ve),rF=n(Ve,"LI",{});var Zke=s(rF);$ue=n(Zke,"STRONG",{});var pbt=s($ue);Qor=r(pbt,"sew"),pbt.forEach(t),Hor=r(Zke," \u2014 "),Ez=n(Zke,"A",{href:!0});var _bt=s(Ez);Uor=r(_bt,"SEWForCTC"),_bt.forEach(t),Jor=r(Zke," (SEW model)"),Zke.forEach(t),Yor=i(Ve),tF=n(Ve,"LI",{});var eSe=s(tF);kue=n(eSe,"STRONG",{});var ubt=s(kue);Kor=r(ubt,"sew-d"),ubt.forEach(t),Zor=r(eSe," \u2014 "),Cz=n(eSe,"A",{href:!0});var bbt=s(Cz);err=r(bbt,"SEWDForCTC"),bbt.forEach(t),orr=r(eSe," (SEW-D model)"),eSe.forEach(t),rrr=i(Ve),aF=n(Ve,"LI",{});var oSe=s(aF);Sue=n(oSe,"STRONG",{});var vbt=s(Sue);trr=r(vbt,"unispeech"),vbt.forEach(t),arr=r(oSe," \u2014 "),wz=n(oSe,"A",{href:!0});var Fbt=s(wz);nrr=r(Fbt,"UniSpeechForCTC"),Fbt.forEach(t),srr=r(oSe," (UniSpeech model)"),oSe.forEach(t),lrr=i(Ve),nF=n(Ve,"LI",{});var rSe=s(nF);Rue=n(rSe,"STRONG",{});var Tbt=s(Rue);irr=r(Tbt,"unispeech-sat"),Tbt.forEach(t),drr=r(rSe," \u2014 "),Az=n(rSe,"A",{href:!0});var Mbt=s(Az);crr=r(Mbt,"UniSpeechSatForCTC"),Mbt.forEach(t),frr=r(rSe," (UniSpeechSat model)"),rSe.forEach(t),mrr=i(Ve),sF=n(Ve,"LI",{});var tSe=s(sF);Pue=n(tSe,"STRONG",{});var Ebt=s(Pue);grr=r(Ebt,"wav2vec2"),Ebt.forEach(t),hrr=r(tSe," \u2014 "),yz=n(tSe,"A",{href:!0});var Cbt=s(yz);prr=r(Cbt,"Wav2Vec2ForCTC"),Cbt.forEach(t),_rr=r(tSe," (Wav2Vec2 model)"),tSe.forEach(t),urr=i(Ve),lF=n(Ve,"LI",{});var aSe=s(lF);Bue=n(aSe,"STRONG",{});var wbt=s(Bue);brr=r(wbt,"wav2vec2-conformer"),wbt.forEach(t),vrr=r(aSe," \u2014 "),Lz=n(aSe,"A",{href:!0});var Abt=s(Lz);Frr=r(Abt,"Wav2Vec2ConformerForCTC"),Abt.forEach(t),Trr=r(aSe," (Wav2Vec2-Conformer model)"),aSe.forEach(t),Mrr=i(Ve),iF=n(Ve,"LI",{});var nSe=s(iF);Iue=n(nSe,"STRONG",{});var ybt=s(Iue);Err=r(ybt,"wavlm"),ybt.forEach(t),Crr=r(nSe," \u2014 "),xz=n(nSe,"A",{href:!0});var Lbt=s(xz);wrr=r(Lbt,"WavLMForCTC"),Lbt.forEach(t),Arr=r(nSe," (WavLM model)"),nSe.forEach(t),Ve.forEach(t),yrr=i(_a),dF=n(_a,"P",{});var sSe=s(dF);Lrr=r(sSe,"The model is set in evaluation mode by default using "),Nue=n(sSe,"CODE",{});var xbt=s(Nue);xrr=r(xbt,"model.eval()"),xbt.forEach(t),$rr=r(sSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),que=n(sSe,"CODE",{});var $bt=s(que);krr=r($bt,"model.train()"),$bt.forEach(t),sSe.forEach(t),Srr=i(_a),T(cF.$$.fragment,_a),_a.forEach(t),nl.forEach(t),sje=i(f),Fd=n(f,"H2",{class:!0});var cGe=s(Fd);fF=n(cGe,"A",{id:!0,class:!0,href:!0});var kbt=s(fF);jue=n(kbt,"SPAN",{});var Sbt=s(jue);T(xL.$$.fragment,Sbt),Sbt.forEach(t),kbt.forEach(t),Rrr=i(cGe),Due=n(cGe,"SPAN",{});var Rbt=s(Due);Prr=r(Rbt,"AutoModelForSpeechSeq2Seq"),Rbt.forEach(t),cGe.forEach(t),lje=i(f),Xo=n(f,"DIV",{class:!0});var sl=s(Xo);T($L.$$.fragment,sl),Brr=i(sl),Td=n(sl,"P",{});var tee=s(Td);Irr=r(tee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),$z=n(tee,"A",{href:!0});var Pbt=s($z);Nrr=r(Pbt,"from_pretrained()"),Pbt.forEach(t),qrr=r(tee," class method or the "),kz=n(tee,"A",{href:!0});var Bbt=s(kz);jrr=r(Bbt,"from_config()"),Bbt.forEach(t),Drr=r(tee,` class
method.`),tee.forEach(t),Grr=i(sl),kL=n(sl,"P",{});var fGe=s(kL);Orr=r(fGe,"This class cannot be instantiated directly using "),Gue=n(fGe,"CODE",{});var Ibt=s(Gue);Vrr=r(Ibt,"__init__()"),Ibt.forEach(t),Xrr=r(fGe," (throws an error)."),fGe.forEach(t),zrr=i(sl),Ft=n(sl,"DIV",{class:!0});var g0=s(Ft);T(SL.$$.fragment,g0),Wrr=i(g0),Oue=n(g0,"P",{});var Nbt=s(Oue);Qrr=r(Nbt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Nbt.forEach(t),Hrr=i(g0),Md=n(g0,"P",{});var aee=s(Md);Urr=r(aee,`Note:
Loading a model from its configuration file does `),Vue=n(aee,"STRONG",{});var qbt=s(Vue);Jrr=r(qbt,"not"),qbt.forEach(t),Yrr=r(aee,` load the model weights. It only affects the
model\u2019s configuration. Use `),Sz=n(aee,"A",{href:!0});var jbt=s(Sz);Krr=r(jbt,"from_pretrained()"),jbt.forEach(t),Zrr=r(aee," to load the model weights."),aee.forEach(t),etr=i(g0),T(mF.$$.fragment,g0),g0.forEach(t),otr=i(sl),go=n(sl,"DIV",{class:!0});var ua=s(go);T(RL.$$.fragment,ua),rtr=i(ua),Xue=n(ua,"P",{});var Dbt=s(Xue);ttr=r(Dbt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Dbt.forEach(t),atr=i(ua),Xa=n(ua,"P",{});var h0=s(Xa);ntr=r(h0,"The model class to instantiate is selected based on the "),zue=n(h0,"CODE",{});var Gbt=s(zue);str=r(Gbt,"model_type"),Gbt.forEach(t),ltr=r(h0,` property of the config object (either
passed as an argument or loaded from `),Wue=n(h0,"CODE",{});var Obt=s(Wue);itr=r(Obt,"pretrained_model_name_or_path"),Obt.forEach(t),dtr=r(h0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Que=n(h0,"CODE",{});var Vbt=s(Que);ctr=r(Vbt,"pretrained_model_name_or_path"),Vbt.forEach(t),ftr=r(h0,":"),h0.forEach(t),mtr=i(ua),PL=n(ua,"UL",{});var mGe=s(PL);gF=n(mGe,"LI",{});var lSe=s(gF);Hue=n(lSe,"STRONG",{});var Xbt=s(Hue);gtr=r(Xbt,"speech-encoder-decoder"),Xbt.forEach(t),htr=r(lSe," \u2014 "),Rz=n(lSe,"A",{href:!0});var zbt=s(Rz);ptr=r(zbt,"SpeechEncoderDecoderModel"),zbt.forEach(t),_tr=r(lSe," (Speech Encoder decoder model)"),lSe.forEach(t),utr=i(mGe),hF=n(mGe,"LI",{});var iSe=s(hF);Uue=n(iSe,"STRONG",{});var Wbt=s(Uue);btr=r(Wbt,"speech_to_text"),Wbt.forEach(t),vtr=r(iSe," \u2014 "),Pz=n(iSe,"A",{href:!0});var Qbt=s(Pz);Ftr=r(Qbt,"Speech2TextForConditionalGeneration"),Qbt.forEach(t),Ttr=r(iSe," (Speech2Text model)"),iSe.forEach(t),mGe.forEach(t),Mtr=i(ua),pF=n(ua,"P",{});var dSe=s(pF);Etr=r(dSe,"The model is set in evaluation mode by default using "),Jue=n(dSe,"CODE",{});var Hbt=s(Jue);Ctr=r(Hbt,"model.eval()"),Hbt.forEach(t),wtr=r(dSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yue=n(dSe,"CODE",{});var Ubt=s(Yue);Atr=r(Ubt,"model.train()"),Ubt.forEach(t),dSe.forEach(t),ytr=i(ua),T(_F.$$.fragment,ua),ua.forEach(t),sl.forEach(t),ije=i(f),Ed=n(f,"H2",{class:!0});var gGe=s(Ed);uF=n(gGe,"A",{id:!0,class:!0,href:!0});var Jbt=s(uF);Kue=n(Jbt,"SPAN",{});var Ybt=s(Kue);T(BL.$$.fragment,Ybt),Ybt.forEach(t),Jbt.forEach(t),Ltr=i(gGe),Zue=n(gGe,"SPAN",{});var Kbt=s(Zue);xtr=r(Kbt,"AutoModelForAudioXVector"),Kbt.forEach(t),gGe.forEach(t),dje=i(f),zo=n(f,"DIV",{class:!0});var ll=s(zo);T(IL.$$.fragment,ll),$tr=i(ll),Cd=n(ll,"P",{});var nee=s(Cd);ktr=r(nee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),Bz=n(nee,"A",{href:!0});var Zbt=s(Bz);Str=r(Zbt,"from_pretrained()"),Zbt.forEach(t),Rtr=r(nee," class method or the "),Iz=n(nee,"A",{href:!0});var e2t=s(Iz);Ptr=r(e2t,"from_config()"),e2t.forEach(t),Btr=r(nee,` class
method.`),nee.forEach(t),Itr=i(ll),NL=n(ll,"P",{});var hGe=s(NL);Ntr=r(hGe,"This class cannot be instantiated directly using "),e6e=n(hGe,"CODE",{});var o2t=s(e6e);qtr=r(o2t,"__init__()"),o2t.forEach(t),jtr=r(hGe," (throws an error)."),hGe.forEach(t),Dtr=i(ll),Tt=n(ll,"DIV",{class:!0});var p0=s(Tt);T(qL.$$.fragment,p0),Gtr=i(p0),o6e=n(p0,"P",{});var r2t=s(o6e);Otr=r(r2t,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),r2t.forEach(t),Vtr=i(p0),wd=n(p0,"P",{});var see=s(wd);Xtr=r(see,`Note:
Loading a model from its configuration file does `),r6e=n(see,"STRONG",{});var t2t=s(r6e);ztr=r(t2t,"not"),t2t.forEach(t),Wtr=r(see,` load the model weights. It only affects the
model\u2019s configuration. Use `),Nz=n(see,"A",{href:!0});var a2t=s(Nz);Qtr=r(a2t,"from_pretrained()"),a2t.forEach(t),Htr=r(see," to load the model weights."),see.forEach(t),Utr=i(p0),T(bF.$$.fragment,p0),p0.forEach(t),Jtr=i(ll),ho=n(ll,"DIV",{class:!0});var ba=s(ho);T(jL.$$.fragment,ba),Ytr=i(ba),t6e=n(ba,"P",{});var n2t=s(t6e);Ktr=r(n2t,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),n2t.forEach(t),Ztr=i(ba),za=n(ba,"P",{});var _0=s(za);ear=r(_0,"The model class to instantiate is selected based on the "),a6e=n(_0,"CODE",{});var s2t=s(a6e);oar=r(s2t,"model_type"),s2t.forEach(t),rar=r(_0,` property of the config object (either
passed as an argument or loaded from `),n6e=n(_0,"CODE",{});var l2t=s(n6e);tar=r(l2t,"pretrained_model_name_or_path"),l2t.forEach(t),aar=r(_0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s6e=n(_0,"CODE",{});var i2t=s(s6e);nar=r(i2t,"pretrained_model_name_or_path"),i2t.forEach(t),sar=r(_0,":"),_0.forEach(t),lar=i(ba),Zr=n(ba,"UL",{});var il=s(Zr);vF=n(il,"LI",{});var cSe=s(vF);l6e=n(cSe,"STRONG",{});var d2t=s(l6e);iar=r(d2t,"data2vec-audio"),d2t.forEach(t),dar=r(cSe," \u2014 "),qz=n(cSe,"A",{href:!0});var c2t=s(qz);car=r(c2t,"Data2VecAudioForXVector"),c2t.forEach(t),far=r(cSe," (Data2VecAudio model)"),cSe.forEach(t),mar=i(il),FF=n(il,"LI",{});var fSe=s(FF);i6e=n(fSe,"STRONG",{});var f2t=s(i6e);gar=r(f2t,"unispeech-sat"),f2t.forEach(t),har=r(fSe," \u2014 "),jz=n(fSe,"A",{href:!0});var m2t=s(jz);par=r(m2t,"UniSpeechSatForXVector"),m2t.forEach(t),_ar=r(fSe," (UniSpeechSat model)"),fSe.forEach(t),uar=i(il),TF=n(il,"LI",{});var mSe=s(TF);d6e=n(mSe,"STRONG",{});var g2t=s(d6e);bar=r(g2t,"wav2vec2"),g2t.forEach(t),Far=r(mSe," \u2014 "),Dz=n(mSe,"A",{href:!0});var h2t=s(Dz);Tar=r(h2t,"Wav2Vec2ForXVector"),h2t.forEach(t),Mar=r(mSe," (Wav2Vec2 model)"),mSe.forEach(t),Ear=i(il),MF=n(il,"LI",{});var gSe=s(MF);c6e=n(gSe,"STRONG",{});var p2t=s(c6e);Car=r(p2t,"wav2vec2-conformer"),p2t.forEach(t),war=r(gSe," \u2014 "),Gz=n(gSe,"A",{href:!0});var _2t=s(Gz);Aar=r(_2t,"Wav2Vec2ConformerForXVector"),_2t.forEach(t),yar=r(gSe," (Wav2Vec2-Conformer model)"),gSe.forEach(t),Lar=i(il),EF=n(il,"LI",{});var hSe=s(EF);f6e=n(hSe,"STRONG",{});var u2t=s(f6e);xar=r(u2t,"wavlm"),u2t.forEach(t),$ar=r(hSe," \u2014 "),Oz=n(hSe,"A",{href:!0});var b2t=s(Oz);kar=r(b2t,"WavLMForXVector"),b2t.forEach(t),Sar=r(hSe," (WavLM model)"),hSe.forEach(t),il.forEach(t),Rar=i(ba),CF=n(ba,"P",{});var pSe=s(CF);Par=r(pSe,"The model is set in evaluation mode by default using "),m6e=n(pSe,"CODE",{});var v2t=s(m6e);Bar=r(v2t,"model.eval()"),v2t.forEach(t),Iar=r(pSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),g6e=n(pSe,"CODE",{});var F2t=s(g6e);Nar=r(F2t,"model.train()"),F2t.forEach(t),pSe.forEach(t),qar=i(ba),T(wF.$$.fragment,ba),ba.forEach(t),ll.forEach(t),cje=i(f),Ad=n(f,"H2",{class:!0});var pGe=s(Ad);AF=n(pGe,"A",{id:!0,class:!0,href:!0});var T2t=s(AF);h6e=n(T2t,"SPAN",{});var M2t=s(h6e);T(DL.$$.fragment,M2t),M2t.forEach(t),T2t.forEach(t),jar=i(pGe),p6e=n(pGe,"SPAN",{});var E2t=s(p6e);Dar=r(E2t,"AutoModelForMaskedImageModeling"),E2t.forEach(t),pGe.forEach(t),fje=i(f),Wo=n(f,"DIV",{class:!0});var dl=s(Wo);T(GL.$$.fragment,dl),Gar=i(dl),yd=n(dl,"P",{});var lee=s(yd);Oar=r(lee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Vz=n(lee,"A",{href:!0});var C2t=s(Vz);Var=r(C2t,"from_pretrained()"),C2t.forEach(t),Xar=r(lee," class method or the "),Xz=n(lee,"A",{href:!0});var w2t=s(Xz);zar=r(w2t,"from_config()"),w2t.forEach(t),War=r(lee,` class
method.`),lee.forEach(t),Qar=i(dl),OL=n(dl,"P",{});var _Ge=s(OL);Har=r(_Ge,"This class cannot be instantiated directly using "),_6e=n(_Ge,"CODE",{});var A2t=s(_6e);Uar=r(A2t,"__init__()"),A2t.forEach(t),Jar=r(_Ge," (throws an error)."),_Ge.forEach(t),Yar=i(dl),Mt=n(dl,"DIV",{class:!0});var u0=s(Mt);T(VL.$$.fragment,u0),Kar=i(u0),u6e=n(u0,"P",{});var y2t=s(u6e);Zar=r(y2t,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),y2t.forEach(t),enr=i(u0),Ld=n(u0,"P",{});var iee=s(Ld);onr=r(iee,`Note:
Loading a model from its configuration file does `),b6e=n(iee,"STRONG",{});var L2t=s(b6e);rnr=r(L2t,"not"),L2t.forEach(t),tnr=r(iee,` load the model weights. It only affects the
model\u2019s configuration. Use `),zz=n(iee,"A",{href:!0});var x2t=s(zz);anr=r(x2t,"from_pretrained()"),x2t.forEach(t),nnr=r(iee," to load the model weights."),iee.forEach(t),snr=i(u0),T(yF.$$.fragment,u0),u0.forEach(t),lnr=i(dl),po=n(dl,"DIV",{class:!0});var va=s(po);T(XL.$$.fragment,va),inr=i(va),v6e=n(va,"P",{});var $2t=s(v6e);dnr=r($2t,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),$2t.forEach(t),cnr=i(va),Wa=n(va,"P",{});var b0=s(Wa);fnr=r(b0,"The model class to instantiate is selected based on the "),F6e=n(b0,"CODE",{});var k2t=s(F6e);mnr=r(k2t,"model_type"),k2t.forEach(t),gnr=r(b0,` property of the config object (either
passed as an argument or loaded from `),T6e=n(b0,"CODE",{});var S2t=s(T6e);hnr=r(S2t,"pretrained_model_name_or_path"),S2t.forEach(t),pnr=r(b0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M6e=n(b0,"CODE",{});var R2t=s(M6e);_nr=r(R2t,"pretrained_model_name_or_path"),R2t.forEach(t),unr=r(b0,":"),b0.forEach(t),bnr=i(va),xd=n(va,"UL",{});var dee=s(xd);LF=n(dee,"LI",{});var _Se=s(LF);E6e=n(_Se,"STRONG",{});var P2t=s(E6e);vnr=r(P2t,"deit"),P2t.forEach(t),Fnr=r(_Se," \u2014 "),Wz=n(_Se,"A",{href:!0});var B2t=s(Wz);Tnr=r(B2t,"DeiTForMaskedImageModeling"),B2t.forEach(t),Mnr=r(_Se," (DeiT model)"),_Se.forEach(t),Enr=i(dee),xF=n(dee,"LI",{});var uSe=s(xF);C6e=n(uSe,"STRONG",{});var I2t=s(C6e);Cnr=r(I2t,"swin"),I2t.forEach(t),wnr=r(uSe," \u2014 "),Qz=n(uSe,"A",{href:!0});var N2t=s(Qz);Anr=r(N2t,"SwinForMaskedImageModeling"),N2t.forEach(t),ynr=r(uSe," (Swin model)"),uSe.forEach(t),Lnr=i(dee),$F=n(dee,"LI",{});var bSe=s($F);w6e=n(bSe,"STRONG",{});var q2t=s(w6e);xnr=r(q2t,"vit"),q2t.forEach(t),$nr=r(bSe," \u2014 "),Hz=n(bSe,"A",{href:!0});var j2t=s(Hz);knr=r(j2t,"ViTForMaskedImageModeling"),j2t.forEach(t),Snr=r(bSe," (ViT model)"),bSe.forEach(t),dee.forEach(t),Rnr=i(va),kF=n(va,"P",{});var vSe=s(kF);Pnr=r(vSe,"The model is set in evaluation mode by default using "),A6e=n(vSe,"CODE",{});var D2t=s(A6e);Bnr=r(D2t,"model.eval()"),D2t.forEach(t),Inr=r(vSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),y6e=n(vSe,"CODE",{});var G2t=s(y6e);Nnr=r(G2t,"model.train()"),G2t.forEach(t),vSe.forEach(t),qnr=i(va),T(SF.$$.fragment,va),va.forEach(t),dl.forEach(t),mje=i(f),$d=n(f,"H2",{class:!0});var uGe=s($d);RF=n(uGe,"A",{id:!0,class:!0,href:!0});var O2t=s(RF);L6e=n(O2t,"SPAN",{});var V2t=s(L6e);T(zL.$$.fragment,V2t),V2t.forEach(t),O2t.forEach(t),jnr=i(uGe),x6e=n(uGe,"SPAN",{});var X2t=s(x6e);Dnr=r(X2t,"AutoModelForObjectDetection"),X2t.forEach(t),uGe.forEach(t),gje=i(f),Qo=n(f,"DIV",{class:!0});var cl=s(Qo);T(WL.$$.fragment,cl),Gnr=i(cl),kd=n(cl,"P",{});var cee=s(kd);Onr=r(cee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Uz=n(cee,"A",{href:!0});var z2t=s(Uz);Vnr=r(z2t,"from_pretrained()"),z2t.forEach(t),Xnr=r(cee," class method or the "),Jz=n(cee,"A",{href:!0});var W2t=s(Jz);znr=r(W2t,"from_config()"),W2t.forEach(t),Wnr=r(cee,` class
method.`),cee.forEach(t),Qnr=i(cl),QL=n(cl,"P",{});var bGe=s(QL);Hnr=r(bGe,"This class cannot be instantiated directly using "),$6e=n(bGe,"CODE",{});var Q2t=s($6e);Unr=r(Q2t,"__init__()"),Q2t.forEach(t),Jnr=r(bGe," (throws an error)."),bGe.forEach(t),Ynr=i(cl),Et=n(cl,"DIV",{class:!0});var v0=s(Et);T(HL.$$.fragment,v0),Knr=i(v0),k6e=n(v0,"P",{});var H2t=s(k6e);Znr=r(H2t,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),H2t.forEach(t),esr=i(v0),Sd=n(v0,"P",{});var fee=s(Sd);osr=r(fee,`Note:
Loading a model from its configuration file does `),S6e=n(fee,"STRONG",{});var U2t=s(S6e);rsr=r(U2t,"not"),U2t.forEach(t),tsr=r(fee,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yz=n(fee,"A",{href:!0});var J2t=s(Yz);asr=r(J2t,"from_pretrained()"),J2t.forEach(t),nsr=r(fee," to load the model weights."),fee.forEach(t),ssr=i(v0),T(PF.$$.fragment,v0),v0.forEach(t),lsr=i(cl),_o=n(cl,"DIV",{class:!0});var Fa=s(_o);T(UL.$$.fragment,Fa),isr=i(Fa),R6e=n(Fa,"P",{});var Y2t=s(R6e);dsr=r(Y2t,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),Y2t.forEach(t),csr=i(Fa),Qa=n(Fa,"P",{});var F0=s(Qa);fsr=r(F0,"The model class to instantiate is selected based on the "),P6e=n(F0,"CODE",{});var K2t=s(P6e);msr=r(K2t,"model_type"),K2t.forEach(t),gsr=r(F0,` property of the config object (either
passed as an argument or loaded from `),B6e=n(F0,"CODE",{});var Z2t=s(B6e);hsr=r(Z2t,"pretrained_model_name_or_path"),Z2t.forEach(t),psr=r(F0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I6e=n(F0,"CODE",{});var e4t=s(I6e);_sr=r(e4t,"pretrained_model_name_or_path"),e4t.forEach(t),usr=r(F0,":"),F0.forEach(t),bsr=i(Fa),JL=n(Fa,"UL",{});var vGe=s(JL);BF=n(vGe,"LI",{});var FSe=s(BF);N6e=n(FSe,"STRONG",{});var o4t=s(N6e);vsr=r(o4t,"detr"),o4t.forEach(t),Fsr=r(FSe," \u2014 "),Kz=n(FSe,"A",{href:!0});var r4t=s(Kz);Tsr=r(r4t,"DetrForObjectDetection"),r4t.forEach(t),Msr=r(FSe," (DETR model)"),FSe.forEach(t),Esr=i(vGe),IF=n(vGe,"LI",{});var TSe=s(IF);q6e=n(TSe,"STRONG",{});var t4t=s(q6e);Csr=r(t4t,"yolos"),t4t.forEach(t),wsr=r(TSe," \u2014 "),Zz=n(TSe,"A",{href:!0});var a4t=s(Zz);Asr=r(a4t,"YolosForObjectDetection"),a4t.forEach(t),ysr=r(TSe," (YOLOS model)"),TSe.forEach(t),vGe.forEach(t),Lsr=i(Fa),NF=n(Fa,"P",{});var MSe=s(NF);xsr=r(MSe,"The model is set in evaluation mode by default using "),j6e=n(MSe,"CODE",{});var n4t=s(j6e);$sr=r(n4t,"model.eval()"),n4t.forEach(t),ksr=r(MSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),D6e=n(MSe,"CODE",{});var s4t=s(D6e);Ssr=r(s4t,"model.train()"),s4t.forEach(t),MSe.forEach(t),Rsr=i(Fa),T(qF.$$.fragment,Fa),Fa.forEach(t),cl.forEach(t),hje=i(f),Rd=n(f,"H2",{class:!0});var FGe=s(Rd);jF=n(FGe,"A",{id:!0,class:!0,href:!0});var l4t=s(jF);G6e=n(l4t,"SPAN",{});var i4t=s(G6e);T(YL.$$.fragment,i4t),i4t.forEach(t),l4t.forEach(t),Psr=i(FGe),O6e=n(FGe,"SPAN",{});var d4t=s(O6e);Bsr=r(d4t,"AutoModelForImageSegmentation"),d4t.forEach(t),FGe.forEach(t),pje=i(f),Ho=n(f,"DIV",{class:!0});var fl=s(Ho);T(KL.$$.fragment,fl),Isr=i(fl),Pd=n(fl,"P",{});var mee=s(Pd);Nsr=r(mee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),eW=n(mee,"A",{href:!0});var c4t=s(eW);qsr=r(c4t,"from_pretrained()"),c4t.forEach(t),jsr=r(mee," class method or the "),oW=n(mee,"A",{href:!0});var f4t=s(oW);Dsr=r(f4t,"from_config()"),f4t.forEach(t),Gsr=r(mee,` class
method.`),mee.forEach(t),Osr=i(fl),ZL=n(fl,"P",{});var TGe=s(ZL);Vsr=r(TGe,"This class cannot be instantiated directly using "),V6e=n(TGe,"CODE",{});var m4t=s(V6e);Xsr=r(m4t,"__init__()"),m4t.forEach(t),zsr=r(TGe," (throws an error)."),TGe.forEach(t),Wsr=i(fl),Ct=n(fl,"DIV",{class:!0});var T0=s(Ct);T(e8.$$.fragment,T0),Qsr=i(T0),X6e=n(T0,"P",{});var g4t=s(X6e);Hsr=r(g4t,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),g4t.forEach(t),Usr=i(T0),Bd=n(T0,"P",{});var gee=s(Bd);Jsr=r(gee,`Note:
Loading a model from its configuration file does `),z6e=n(gee,"STRONG",{});var h4t=s(z6e);Ysr=r(h4t,"not"),h4t.forEach(t),Ksr=r(gee,` load the model weights. It only affects the
model\u2019s configuration. Use `),rW=n(gee,"A",{href:!0});var p4t=s(rW);Zsr=r(p4t,"from_pretrained()"),p4t.forEach(t),elr=r(gee," to load the model weights."),gee.forEach(t),olr=i(T0),T(DF.$$.fragment,T0),T0.forEach(t),rlr=i(fl),uo=n(fl,"DIV",{class:!0});var Ta=s(uo);T(o8.$$.fragment,Ta),tlr=i(Ta),W6e=n(Ta,"P",{});var _4t=s(W6e);alr=r(_4t,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),_4t.forEach(t),nlr=i(Ta),Ha=n(Ta,"P",{});var M0=s(Ha);slr=r(M0,"The model class to instantiate is selected based on the "),Q6e=n(M0,"CODE",{});var u4t=s(Q6e);llr=r(u4t,"model_type"),u4t.forEach(t),ilr=r(M0,` property of the config object (either
passed as an argument or loaded from `),H6e=n(M0,"CODE",{});var b4t=s(H6e);dlr=r(b4t,"pretrained_model_name_or_path"),b4t.forEach(t),clr=r(M0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U6e=n(M0,"CODE",{});var v4t=s(U6e);flr=r(v4t,"pretrained_model_name_or_path"),v4t.forEach(t),mlr=r(M0,":"),M0.forEach(t),glr=i(Ta),J6e=n(Ta,"UL",{});var F4t=s(J6e);GF=n(F4t,"LI",{});var ESe=s(GF);Y6e=n(ESe,"STRONG",{});var T4t=s(Y6e);hlr=r(T4t,"detr"),T4t.forEach(t),plr=r(ESe," \u2014 "),tW=n(ESe,"A",{href:!0});var M4t=s(tW);_lr=r(M4t,"DetrForSegmentation"),M4t.forEach(t),ulr=r(ESe," (DETR model)"),ESe.forEach(t),F4t.forEach(t),blr=i(Ta),OF=n(Ta,"P",{});var CSe=s(OF);vlr=r(CSe,"The model is set in evaluation mode by default using "),K6e=n(CSe,"CODE",{});var E4t=s(K6e);Flr=r(E4t,"model.eval()"),E4t.forEach(t),Tlr=r(CSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z6e=n(CSe,"CODE",{});var C4t=s(Z6e);Mlr=r(C4t,"model.train()"),C4t.forEach(t),CSe.forEach(t),Elr=i(Ta),T(VF.$$.fragment,Ta),Ta.forEach(t),fl.forEach(t),_je=i(f),Id=n(f,"H2",{class:!0});var MGe=s(Id);XF=n(MGe,"A",{id:!0,class:!0,href:!0});var w4t=s(XF);e1e=n(w4t,"SPAN",{});var A4t=s(e1e);T(r8.$$.fragment,A4t),A4t.forEach(t),w4t.forEach(t),Clr=i(MGe),o1e=n(MGe,"SPAN",{});var y4t=s(o1e);wlr=r(y4t,"AutoModelForSemanticSegmentation"),y4t.forEach(t),MGe.forEach(t),uje=i(f),Uo=n(f,"DIV",{class:!0});var ml=s(Uo);T(t8.$$.fragment,ml),Alr=i(ml),Nd=n(ml,"P",{});var hee=s(Nd);ylr=r(hee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),aW=n(hee,"A",{href:!0});var L4t=s(aW);Llr=r(L4t,"from_pretrained()"),L4t.forEach(t),xlr=r(hee," class method or the "),nW=n(hee,"A",{href:!0});var x4t=s(nW);$lr=r(x4t,"from_config()"),x4t.forEach(t),klr=r(hee,` class
method.`),hee.forEach(t),Slr=i(ml),a8=n(ml,"P",{});var EGe=s(a8);Rlr=r(EGe,"This class cannot be instantiated directly using "),r1e=n(EGe,"CODE",{});var $4t=s(r1e);Plr=r($4t,"__init__()"),$4t.forEach(t),Blr=r(EGe," (throws an error)."),EGe.forEach(t),Ilr=i(ml),wt=n(ml,"DIV",{class:!0});var E0=s(wt);T(n8.$$.fragment,E0),Nlr=i(E0),t1e=n(E0,"P",{});var k4t=s(t1e);qlr=r(k4t,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),k4t.forEach(t),jlr=i(E0),qd=n(E0,"P",{});var pee=s(qd);Dlr=r(pee,`Note:
Loading a model from its configuration file does `),a1e=n(pee,"STRONG",{});var S4t=s(a1e);Glr=r(S4t,"not"),S4t.forEach(t),Olr=r(pee,` load the model weights. It only affects the
model\u2019s configuration. Use `),sW=n(pee,"A",{href:!0});var R4t=s(sW);Vlr=r(R4t,"from_pretrained()"),R4t.forEach(t),Xlr=r(pee," to load the model weights."),pee.forEach(t),zlr=i(E0),T(zF.$$.fragment,E0),E0.forEach(t),Wlr=i(ml),bo=n(ml,"DIV",{class:!0});var Ma=s(bo);T(s8.$$.fragment,Ma),Qlr=i(Ma),n1e=n(Ma,"P",{});var P4t=s(n1e);Hlr=r(P4t,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),P4t.forEach(t),Ulr=i(Ma),Ua=n(Ma,"P",{});var C0=s(Ua);Jlr=r(C0,"The model class to instantiate is selected based on the "),s1e=n(C0,"CODE",{});var B4t=s(s1e);Ylr=r(B4t,"model_type"),B4t.forEach(t),Klr=r(C0,` property of the config object (either
passed as an argument or loaded from `),l1e=n(C0,"CODE",{});var I4t=s(l1e);Zlr=r(I4t,"pretrained_model_name_or_path"),I4t.forEach(t),eir=r(C0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i1e=n(C0,"CODE",{});var N4t=s(i1e);oir=r(N4t,"pretrained_model_name_or_path"),N4t.forEach(t),rir=r(C0,":"),C0.forEach(t),tir=i(Ma),Ja=n(Ma,"UL",{});var w0=s(Ja);WF=n(w0,"LI",{});var wSe=s(WF);d1e=n(wSe,"STRONG",{});var q4t=s(d1e);air=r(q4t,"beit"),q4t.forEach(t),nir=r(wSe," \u2014 "),lW=n(wSe,"A",{href:!0});var j4t=s(lW);sir=r(j4t,"BeitForSemanticSegmentation"),j4t.forEach(t),lir=r(wSe," (BEiT model)"),wSe.forEach(t),iir=i(w0),QF=n(w0,"LI",{});var ASe=s(QF);c1e=n(ASe,"STRONG",{});var D4t=s(c1e);dir=r(D4t,"data2vec-vision"),D4t.forEach(t),cir=r(ASe," \u2014 "),iW=n(ASe,"A",{href:!0});var G4t=s(iW);fir=r(G4t,"Data2VecVisionForSemanticSegmentation"),G4t.forEach(t),mir=r(ASe," (Data2VecVision model)"),ASe.forEach(t),gir=i(w0),HF=n(w0,"LI",{});var ySe=s(HF);f1e=n(ySe,"STRONG",{});var O4t=s(f1e);hir=r(O4t,"dpt"),O4t.forEach(t),pir=r(ySe," \u2014 "),dW=n(ySe,"A",{href:!0});var V4t=s(dW);_ir=r(V4t,"DPTForSemanticSegmentation"),V4t.forEach(t),uir=r(ySe," (DPT model)"),ySe.forEach(t),bir=i(w0),UF=n(w0,"LI",{});var LSe=s(UF);m1e=n(LSe,"STRONG",{});var X4t=s(m1e);vir=r(X4t,"segformer"),X4t.forEach(t),Fir=r(LSe," \u2014 "),cW=n(LSe,"A",{href:!0});var z4t=s(cW);Tir=r(z4t,"SegformerForSemanticSegmentation"),z4t.forEach(t),Mir=r(LSe," (SegFormer model)"),LSe.forEach(t),w0.forEach(t),Eir=i(Ma),JF=n(Ma,"P",{});var xSe=s(JF);Cir=r(xSe,"The model is set in evaluation mode by default using "),g1e=n(xSe,"CODE",{});var W4t=s(g1e);wir=r(W4t,"model.eval()"),W4t.forEach(t),Air=r(xSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),h1e=n(xSe,"CODE",{});var Q4t=s(h1e);yir=r(Q4t,"model.train()"),Q4t.forEach(t),xSe.forEach(t),Lir=i(Ma),T(YF.$$.fragment,Ma),Ma.forEach(t),ml.forEach(t),bje=i(f),jd=n(f,"H2",{class:!0});var CGe=s(jd);KF=n(CGe,"A",{id:!0,class:!0,href:!0});var H4t=s(KF);p1e=n(H4t,"SPAN",{});var U4t=s(p1e);T(l8.$$.fragment,U4t),U4t.forEach(t),H4t.forEach(t),xir=i(CGe),_1e=n(CGe,"SPAN",{});var J4t=s(_1e);$ir=r(J4t,"AutoModelForInstanceSegmentation"),J4t.forEach(t),CGe.forEach(t),vje=i(f),Jo=n(f,"DIV",{class:!0});var gl=s(Jo);T(i8.$$.fragment,gl),kir=i(gl),Dd=n(gl,"P",{});var _ee=s(Dd);Sir=r(_ee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),fW=n(_ee,"A",{href:!0});var Y4t=s(fW);Rir=r(Y4t,"from_pretrained()"),Y4t.forEach(t),Pir=r(_ee," class method or the "),mW=n(_ee,"A",{href:!0});var K4t=s(mW);Bir=r(K4t,"from_config()"),K4t.forEach(t),Iir=r(_ee,` class
method.`),_ee.forEach(t),Nir=i(gl),d8=n(gl,"P",{});var wGe=s(d8);qir=r(wGe,"This class cannot be instantiated directly using "),u1e=n(wGe,"CODE",{});var Z4t=s(u1e);jir=r(Z4t,"__init__()"),Z4t.forEach(t),Dir=r(wGe," (throws an error)."),wGe.forEach(t),Gir=i(gl),At=n(gl,"DIV",{class:!0});var A0=s(At);T(c8.$$.fragment,A0),Oir=i(A0),b1e=n(A0,"P",{});var evt=s(b1e);Vir=r(evt,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),evt.forEach(t),Xir=i(A0),Gd=n(A0,"P",{});var uee=s(Gd);zir=r(uee,`Note:
Loading a model from its configuration file does `),v1e=n(uee,"STRONG",{});var ovt=s(v1e);Wir=r(ovt,"not"),ovt.forEach(t),Qir=r(uee,` load the model weights. It only affects the
model\u2019s configuration. Use `),gW=n(uee,"A",{href:!0});var rvt=s(gW);Hir=r(rvt,"from_pretrained()"),rvt.forEach(t),Uir=r(uee," to load the model weights."),uee.forEach(t),Jir=i(A0),T(ZF.$$.fragment,A0),A0.forEach(t),Yir=i(gl),vo=n(gl,"DIV",{class:!0});var Ea=s(vo);T(f8.$$.fragment,Ea),Kir=i(Ea),F1e=n(Ea,"P",{});var tvt=s(F1e);Zir=r(tvt,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),tvt.forEach(t),edr=i(Ea),Ya=n(Ea,"P",{});var y0=s(Ya);odr=r(y0,"The model class to instantiate is selected based on the "),T1e=n(y0,"CODE",{});var avt=s(T1e);rdr=r(avt,"model_type"),avt.forEach(t),tdr=r(y0,` property of the config object (either
passed as an argument or loaded from `),M1e=n(y0,"CODE",{});var nvt=s(M1e);adr=r(nvt,"pretrained_model_name_or_path"),nvt.forEach(t),ndr=r(y0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E1e=n(y0,"CODE",{});var svt=s(E1e);sdr=r(svt,"pretrained_model_name_or_path"),svt.forEach(t),ldr=r(y0,":"),y0.forEach(t),idr=i(Ea),C1e=n(Ea,"UL",{});var lvt=s(C1e);eT=n(lvt,"LI",{});var $Se=s(eT);w1e=n($Se,"STRONG",{});var ivt=s(w1e);ddr=r(ivt,"maskformer"),ivt.forEach(t),cdr=r($Se," \u2014 "),hW=n($Se,"A",{href:!0});var dvt=s(hW);fdr=r(dvt,"MaskFormerForInstanceSegmentation"),dvt.forEach(t),mdr=r($Se," (MaskFormer model)"),$Se.forEach(t),lvt.forEach(t),gdr=i(Ea),oT=n(Ea,"P",{});var kSe=s(oT);hdr=r(kSe,"The model is set in evaluation mode by default using "),A1e=n(kSe,"CODE",{});var cvt=s(A1e);pdr=r(cvt,"model.eval()"),cvt.forEach(t),_dr=r(kSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),y1e=n(kSe,"CODE",{});var fvt=s(y1e);udr=r(fvt,"model.train()"),fvt.forEach(t),kSe.forEach(t),bdr=i(Ea),T(rT.$$.fragment,Ea),Ea.forEach(t),gl.forEach(t),Fje=i(f),Od=n(f,"H2",{class:!0});var AGe=s(Od);tT=n(AGe,"A",{id:!0,class:!0,href:!0});var mvt=s(tT);L1e=n(mvt,"SPAN",{});var gvt=s(L1e);T(m8.$$.fragment,gvt),gvt.forEach(t),mvt.forEach(t),vdr=i(AGe),x1e=n(AGe,"SPAN",{});var hvt=s(x1e);Fdr=r(hvt,"TFAutoModel"),hvt.forEach(t),AGe.forEach(t),Tje=i(f),Yo=n(f,"DIV",{class:!0});var hl=s(Yo);T(g8.$$.fragment,hl),Tdr=i(hl),Vd=n(hl,"P",{});var bee=s(Vd);Mdr=r(bee,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),pW=n(bee,"A",{href:!0});var pvt=s(pW);Edr=r(pvt,"from_pretrained()"),pvt.forEach(t),Cdr=r(bee," class method or the "),_W=n(bee,"A",{href:!0});var _vt=s(_W);wdr=r(_vt,"from_config()"),_vt.forEach(t),Adr=r(bee,` class
method.`),bee.forEach(t),ydr=i(hl),h8=n(hl,"P",{});var yGe=s(h8);Ldr=r(yGe,"This class cannot be instantiated directly using "),$1e=n(yGe,"CODE",{});var uvt=s($1e);xdr=r(uvt,"__init__()"),uvt.forEach(t),$dr=r(yGe," (throws an error)."),yGe.forEach(t),kdr=i(hl),yt=n(hl,"DIV",{class:!0});var L0=s(yt);T(p8.$$.fragment,L0),Sdr=i(L0),k1e=n(L0,"P",{});var bvt=s(k1e);Rdr=r(bvt,"Instantiates one of the base model classes of the library from a configuration."),bvt.forEach(t),Pdr=i(L0),Xd=n(L0,"P",{});var vee=s(Xd);Bdr=r(vee,`Note:
Loading a model from its configuration file does `),S1e=n(vee,"STRONG",{});var vvt=s(S1e);Idr=r(vvt,"not"),vvt.forEach(t),Ndr=r(vee,` load the model weights. It only affects the
model\u2019s configuration. Use `),uW=n(vee,"A",{href:!0});var Fvt=s(uW);qdr=r(Fvt,"from_pretrained()"),Fvt.forEach(t),jdr=r(vee," to load the model weights."),vee.forEach(t),Ddr=i(L0),T(aT.$$.fragment,L0),L0.forEach(t),Gdr=i(hl),wr=n(hl,"DIV",{class:!0});var pl=s(wr);T(_8.$$.fragment,pl),Odr=i(pl),R1e=n(pl,"P",{});var Tvt=s(R1e);Vdr=r(Tvt,"Instantiate one of the base model classes of the library from a pretrained model."),Tvt.forEach(t),Xdr=i(pl),Ka=n(pl,"P",{});var x0=s(Ka);zdr=r(x0,"The model class to instantiate is selected based on the "),P1e=n(x0,"CODE",{});var Mvt=s(P1e);Wdr=r(Mvt,"model_type"),Mvt.forEach(t),Qdr=r(x0,` property of the config object (either
passed as an argument or loaded from `),B1e=n(x0,"CODE",{});var Evt=s(B1e);Hdr=r(Evt,"pretrained_model_name_or_path"),Evt.forEach(t),Udr=r(x0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I1e=n(x0,"CODE",{});var Cvt=s(I1e);Jdr=r(Cvt,"pretrained_model_name_or_path"),Cvt.forEach(t),Ydr=r(x0,":"),x0.forEach(t),Kdr=i(pl),q=n(pl,"UL",{});var D=s(q);nT=n(D,"LI",{});var SSe=s(nT);N1e=n(SSe,"STRONG",{});var wvt=s(N1e);Zdr=r(wvt,"albert"),wvt.forEach(t),ecr=r(SSe," \u2014 "),bW=n(SSe,"A",{href:!0});var Avt=s(bW);ocr=r(Avt,"TFAlbertModel"),Avt.forEach(t),rcr=r(SSe," (ALBERT model)"),SSe.forEach(t),tcr=i(D),sT=n(D,"LI",{});var RSe=s(sT);q1e=n(RSe,"STRONG",{});var yvt=s(q1e);acr=r(yvt,"bart"),yvt.forEach(t),ncr=r(RSe," \u2014 "),vW=n(RSe,"A",{href:!0});var Lvt=s(vW);scr=r(Lvt,"TFBartModel"),Lvt.forEach(t),lcr=r(RSe," (BART model)"),RSe.forEach(t),icr=i(D),lT=n(D,"LI",{});var PSe=s(lT);j1e=n(PSe,"STRONG",{});var xvt=s(j1e);dcr=r(xvt,"bert"),xvt.forEach(t),ccr=r(PSe," \u2014 "),FW=n(PSe,"A",{href:!0});var $vt=s(FW);fcr=r($vt,"TFBertModel"),$vt.forEach(t),mcr=r(PSe," (BERT model)"),PSe.forEach(t),gcr=i(D),iT=n(D,"LI",{});var BSe=s(iT);D1e=n(BSe,"STRONG",{});var kvt=s(D1e);hcr=r(kvt,"blenderbot"),kvt.forEach(t),pcr=r(BSe," \u2014 "),TW=n(BSe,"A",{href:!0});var Svt=s(TW);_cr=r(Svt,"TFBlenderbotModel"),Svt.forEach(t),ucr=r(BSe," (Blenderbot model)"),BSe.forEach(t),bcr=i(D),dT=n(D,"LI",{});var ISe=s(dT);G1e=n(ISe,"STRONG",{});var Rvt=s(G1e);vcr=r(Rvt,"blenderbot-small"),Rvt.forEach(t),Fcr=r(ISe," \u2014 "),MW=n(ISe,"A",{href:!0});var Pvt=s(MW);Tcr=r(Pvt,"TFBlenderbotSmallModel"),Pvt.forEach(t),Mcr=r(ISe," (BlenderbotSmall model)"),ISe.forEach(t),Ecr=i(D),cT=n(D,"LI",{});var NSe=s(cT);O1e=n(NSe,"STRONG",{});var Bvt=s(O1e);Ccr=r(Bvt,"camembert"),Bvt.forEach(t),wcr=r(NSe," \u2014 "),EW=n(NSe,"A",{href:!0});var Ivt=s(EW);Acr=r(Ivt,"TFCamembertModel"),Ivt.forEach(t),ycr=r(NSe," (CamemBERT model)"),NSe.forEach(t),Lcr=i(D),fT=n(D,"LI",{});var qSe=s(fT);V1e=n(qSe,"STRONG",{});var Nvt=s(V1e);xcr=r(Nvt,"clip"),Nvt.forEach(t),$cr=r(qSe," \u2014 "),CW=n(qSe,"A",{href:!0});var qvt=s(CW);kcr=r(qvt,"TFCLIPModel"),qvt.forEach(t),Scr=r(qSe," (CLIP model)"),qSe.forEach(t),Rcr=i(D),mT=n(D,"LI",{});var jSe=s(mT);X1e=n(jSe,"STRONG",{});var jvt=s(X1e);Pcr=r(jvt,"convbert"),jvt.forEach(t),Bcr=r(jSe," \u2014 "),wW=n(jSe,"A",{href:!0});var Dvt=s(wW);Icr=r(Dvt,"TFConvBertModel"),Dvt.forEach(t),Ncr=r(jSe," (ConvBERT model)"),jSe.forEach(t),qcr=i(D),gT=n(D,"LI",{});var DSe=s(gT);z1e=n(DSe,"STRONG",{});var Gvt=s(z1e);jcr=r(Gvt,"convnext"),Gvt.forEach(t),Dcr=r(DSe," \u2014 "),AW=n(DSe,"A",{href:!0});var Ovt=s(AW);Gcr=r(Ovt,"TFConvNextModel"),Ovt.forEach(t),Ocr=r(DSe," (ConvNext model)"),DSe.forEach(t),Vcr=i(D),hT=n(D,"LI",{});var GSe=s(hT);W1e=n(GSe,"STRONG",{});var Vvt=s(W1e);Xcr=r(Vvt,"ctrl"),Vvt.forEach(t),zcr=r(GSe," \u2014 "),yW=n(GSe,"A",{href:!0});var Xvt=s(yW);Wcr=r(Xvt,"TFCTRLModel"),Xvt.forEach(t),Qcr=r(GSe," (CTRL model)"),GSe.forEach(t),Hcr=i(D),pT=n(D,"LI",{});var OSe=s(pT);Q1e=n(OSe,"STRONG",{});var zvt=s(Q1e);Ucr=r(zvt,"data2vec-vision"),zvt.forEach(t),Jcr=r(OSe," \u2014 "),LW=n(OSe,"A",{href:!0});var Wvt=s(LW);Ycr=r(Wvt,"TFData2VecVisionModel"),Wvt.forEach(t),Kcr=r(OSe," (Data2VecVision model)"),OSe.forEach(t),Zcr=i(D),_T=n(D,"LI",{});var VSe=s(_T);H1e=n(VSe,"STRONG",{});var Qvt=s(H1e);efr=r(Qvt,"deberta"),Qvt.forEach(t),ofr=r(VSe," \u2014 "),xW=n(VSe,"A",{href:!0});var Hvt=s(xW);rfr=r(Hvt,"TFDebertaModel"),Hvt.forEach(t),tfr=r(VSe," (DeBERTa model)"),VSe.forEach(t),afr=i(D),uT=n(D,"LI",{});var XSe=s(uT);U1e=n(XSe,"STRONG",{});var Uvt=s(U1e);nfr=r(Uvt,"deberta-v2"),Uvt.forEach(t),sfr=r(XSe," \u2014 "),$W=n(XSe,"A",{href:!0});var Jvt=s($W);lfr=r(Jvt,"TFDebertaV2Model"),Jvt.forEach(t),ifr=r(XSe," (DeBERTa-v2 model)"),XSe.forEach(t),dfr=i(D),bT=n(D,"LI",{});var zSe=s(bT);J1e=n(zSe,"STRONG",{});var Yvt=s(J1e);cfr=r(Yvt,"distilbert"),Yvt.forEach(t),ffr=r(zSe," \u2014 "),kW=n(zSe,"A",{href:!0});var Kvt=s(kW);mfr=r(Kvt,"TFDistilBertModel"),Kvt.forEach(t),gfr=r(zSe," (DistilBERT model)"),zSe.forEach(t),hfr=i(D),vT=n(D,"LI",{});var WSe=s(vT);Y1e=n(WSe,"STRONG",{});var Zvt=s(Y1e);pfr=r(Zvt,"dpr"),Zvt.forEach(t),_fr=r(WSe," \u2014 "),SW=n(WSe,"A",{href:!0});var eFt=s(SW);ufr=r(eFt,"TFDPRQuestionEncoder"),eFt.forEach(t),bfr=r(WSe," (DPR model)"),WSe.forEach(t),vfr=i(D),FT=n(D,"LI",{});var QSe=s(FT);K1e=n(QSe,"STRONG",{});var oFt=s(K1e);Ffr=r(oFt,"electra"),oFt.forEach(t),Tfr=r(QSe," \u2014 "),RW=n(QSe,"A",{href:!0});var rFt=s(RW);Mfr=r(rFt,"TFElectraModel"),rFt.forEach(t),Efr=r(QSe," (ELECTRA model)"),QSe.forEach(t),Cfr=i(D),TT=n(D,"LI",{});var HSe=s(TT);Z1e=n(HSe,"STRONG",{});var tFt=s(Z1e);wfr=r(tFt,"flaubert"),tFt.forEach(t),Afr=r(HSe," \u2014 "),PW=n(HSe,"A",{href:!0});var aFt=s(PW);yfr=r(aFt,"TFFlaubertModel"),aFt.forEach(t),Lfr=r(HSe," (FlauBERT model)"),HSe.forEach(t),xfr=i(D),Ns=n(D,"LI",{});var U$=s(Ns);ebe=n(U$,"STRONG",{});var nFt=s(ebe);$fr=r(nFt,"funnel"),nFt.forEach(t),kfr=r(U$," \u2014 "),BW=n(U$,"A",{href:!0});var sFt=s(BW);Sfr=r(sFt,"TFFunnelModel"),sFt.forEach(t),Rfr=r(U$," or "),IW=n(U$,"A",{href:!0});var lFt=s(IW);Pfr=r(lFt,"TFFunnelBaseModel"),lFt.forEach(t),Bfr=r(U$," (Funnel Transformer model)"),U$.forEach(t),Ifr=i(D),MT=n(D,"LI",{});var USe=s(MT);obe=n(USe,"STRONG",{});var iFt=s(obe);Nfr=r(iFt,"gpt2"),iFt.forEach(t),qfr=r(USe," \u2014 "),NW=n(USe,"A",{href:!0});var dFt=s(NW);jfr=r(dFt,"TFGPT2Model"),dFt.forEach(t),Dfr=r(USe," (OpenAI GPT-2 model)"),USe.forEach(t),Gfr=i(D),ET=n(D,"LI",{});var JSe=s(ET);rbe=n(JSe,"STRONG",{});var cFt=s(rbe);Ofr=r(cFt,"gptj"),cFt.forEach(t),Vfr=r(JSe," \u2014 "),qW=n(JSe,"A",{href:!0});var fFt=s(qW);Xfr=r(fFt,"TFGPTJModel"),fFt.forEach(t),zfr=r(JSe," (GPT-J model)"),JSe.forEach(t),Wfr=i(D),CT=n(D,"LI",{});var YSe=s(CT);tbe=n(YSe,"STRONG",{});var mFt=s(tbe);Qfr=r(mFt,"hubert"),mFt.forEach(t),Hfr=r(YSe," \u2014 "),jW=n(YSe,"A",{href:!0});var gFt=s(jW);Ufr=r(gFt,"TFHubertModel"),gFt.forEach(t),Jfr=r(YSe," (Hubert model)"),YSe.forEach(t),Yfr=i(D),wT=n(D,"LI",{});var KSe=s(wT);abe=n(KSe,"STRONG",{});var hFt=s(abe);Kfr=r(hFt,"layoutlm"),hFt.forEach(t),Zfr=r(KSe," \u2014 "),DW=n(KSe,"A",{href:!0});var pFt=s(DW);emr=r(pFt,"TFLayoutLMModel"),pFt.forEach(t),omr=r(KSe," (LayoutLM model)"),KSe.forEach(t),rmr=i(D),AT=n(D,"LI",{});var ZSe=s(AT);nbe=n(ZSe,"STRONG",{});var _Ft=s(nbe);tmr=r(_Ft,"led"),_Ft.forEach(t),amr=r(ZSe," \u2014 "),GW=n(ZSe,"A",{href:!0});var uFt=s(GW);nmr=r(uFt,"TFLEDModel"),uFt.forEach(t),smr=r(ZSe," (LED model)"),ZSe.forEach(t),lmr=i(D),yT=n(D,"LI",{});var eRe=s(yT);sbe=n(eRe,"STRONG",{});var bFt=s(sbe);imr=r(bFt,"longformer"),bFt.forEach(t),dmr=r(eRe," \u2014 "),OW=n(eRe,"A",{href:!0});var vFt=s(OW);cmr=r(vFt,"TFLongformerModel"),vFt.forEach(t),fmr=r(eRe," (Longformer model)"),eRe.forEach(t),mmr=i(D),LT=n(D,"LI",{});var oRe=s(LT);lbe=n(oRe,"STRONG",{});var FFt=s(lbe);gmr=r(FFt,"lxmert"),FFt.forEach(t),hmr=r(oRe," \u2014 "),VW=n(oRe,"A",{href:!0});var TFt=s(VW);pmr=r(TFt,"TFLxmertModel"),TFt.forEach(t),_mr=r(oRe," (LXMERT model)"),oRe.forEach(t),umr=i(D),xT=n(D,"LI",{});var rRe=s(xT);ibe=n(rRe,"STRONG",{});var MFt=s(ibe);bmr=r(MFt,"marian"),MFt.forEach(t),vmr=r(rRe," \u2014 "),XW=n(rRe,"A",{href:!0});var EFt=s(XW);Fmr=r(EFt,"TFMarianModel"),EFt.forEach(t),Tmr=r(rRe," (Marian model)"),rRe.forEach(t),Mmr=i(D),$T=n(D,"LI",{});var tRe=s($T);dbe=n(tRe,"STRONG",{});var CFt=s(dbe);Emr=r(CFt,"mbart"),CFt.forEach(t),Cmr=r(tRe," \u2014 "),zW=n(tRe,"A",{href:!0});var wFt=s(zW);wmr=r(wFt,"TFMBartModel"),wFt.forEach(t),Amr=r(tRe," (mBART model)"),tRe.forEach(t),ymr=i(D),kT=n(D,"LI",{});var aRe=s(kT);cbe=n(aRe,"STRONG",{});var AFt=s(cbe);Lmr=r(AFt,"mobilebert"),AFt.forEach(t),xmr=r(aRe," \u2014 "),WW=n(aRe,"A",{href:!0});var yFt=s(WW);$mr=r(yFt,"TFMobileBertModel"),yFt.forEach(t),kmr=r(aRe," (MobileBERT model)"),aRe.forEach(t),Smr=i(D),ST=n(D,"LI",{});var nRe=s(ST);fbe=n(nRe,"STRONG",{});var LFt=s(fbe);Rmr=r(LFt,"mpnet"),LFt.forEach(t),Pmr=r(nRe," \u2014 "),QW=n(nRe,"A",{href:!0});var xFt=s(QW);Bmr=r(xFt,"TFMPNetModel"),xFt.forEach(t),Imr=r(nRe," (MPNet model)"),nRe.forEach(t),Nmr=i(D),RT=n(D,"LI",{});var sRe=s(RT);mbe=n(sRe,"STRONG",{});var $Ft=s(mbe);qmr=r($Ft,"mt5"),$Ft.forEach(t),jmr=r(sRe," \u2014 "),HW=n(sRe,"A",{href:!0});var kFt=s(HW);Dmr=r(kFt,"TFMT5Model"),kFt.forEach(t),Gmr=r(sRe," (mT5 model)"),sRe.forEach(t),Omr=i(D),PT=n(D,"LI",{});var lRe=s(PT);gbe=n(lRe,"STRONG",{});var SFt=s(gbe);Vmr=r(SFt,"openai-gpt"),SFt.forEach(t),Xmr=r(lRe," \u2014 "),UW=n(lRe,"A",{href:!0});var RFt=s(UW);zmr=r(RFt,"TFOpenAIGPTModel"),RFt.forEach(t),Wmr=r(lRe," (OpenAI GPT model)"),lRe.forEach(t),Qmr=i(D),BT=n(D,"LI",{});var iRe=s(BT);hbe=n(iRe,"STRONG",{});var PFt=s(hbe);Hmr=r(PFt,"pegasus"),PFt.forEach(t),Umr=r(iRe," \u2014 "),JW=n(iRe,"A",{href:!0});var BFt=s(JW);Jmr=r(BFt,"TFPegasusModel"),BFt.forEach(t),Ymr=r(iRe," (Pegasus model)"),iRe.forEach(t),Kmr=i(D),IT=n(D,"LI",{});var dRe=s(IT);pbe=n(dRe,"STRONG",{});var IFt=s(pbe);Zmr=r(IFt,"rembert"),IFt.forEach(t),egr=r(dRe," \u2014 "),YW=n(dRe,"A",{href:!0});var NFt=s(YW);ogr=r(NFt,"TFRemBertModel"),NFt.forEach(t),rgr=r(dRe," (RemBERT model)"),dRe.forEach(t),tgr=i(D),NT=n(D,"LI",{});var cRe=s(NT);_be=n(cRe,"STRONG",{});var qFt=s(_be);agr=r(qFt,"roberta"),qFt.forEach(t),ngr=r(cRe," \u2014 "),KW=n(cRe,"A",{href:!0});var jFt=s(KW);sgr=r(jFt,"TFRobertaModel"),jFt.forEach(t),lgr=r(cRe," (RoBERTa model)"),cRe.forEach(t),igr=i(D),qT=n(D,"LI",{});var fRe=s(qT);ube=n(fRe,"STRONG",{});var DFt=s(ube);dgr=r(DFt,"roformer"),DFt.forEach(t),cgr=r(fRe," \u2014 "),ZW=n(fRe,"A",{href:!0});var GFt=s(ZW);fgr=r(GFt,"TFRoFormerModel"),GFt.forEach(t),mgr=r(fRe," (RoFormer model)"),fRe.forEach(t),ggr=i(D),jT=n(D,"LI",{});var mRe=s(jT);bbe=n(mRe,"STRONG",{});var OFt=s(bbe);hgr=r(OFt,"speech_to_text"),OFt.forEach(t),pgr=r(mRe," \u2014 "),eQ=n(mRe,"A",{href:!0});var VFt=s(eQ);_gr=r(VFt,"TFSpeech2TextModel"),VFt.forEach(t),ugr=r(mRe," (Speech2Text model)"),mRe.forEach(t),bgr=i(D),DT=n(D,"LI",{});var gRe=s(DT);vbe=n(gRe,"STRONG",{});var XFt=s(vbe);vgr=r(XFt,"swin"),XFt.forEach(t),Fgr=r(gRe," \u2014 "),oQ=n(gRe,"A",{href:!0});var zFt=s(oQ);Tgr=r(zFt,"TFSwinModel"),zFt.forEach(t),Mgr=r(gRe," (Swin model)"),gRe.forEach(t),Egr=i(D),GT=n(D,"LI",{});var hRe=s(GT);Fbe=n(hRe,"STRONG",{});var WFt=s(Fbe);Cgr=r(WFt,"t5"),WFt.forEach(t),wgr=r(hRe," \u2014 "),rQ=n(hRe,"A",{href:!0});var QFt=s(rQ);Agr=r(QFt,"TFT5Model"),QFt.forEach(t),ygr=r(hRe," (T5 model)"),hRe.forEach(t),Lgr=i(D),OT=n(D,"LI",{});var pRe=s(OT);Tbe=n(pRe,"STRONG",{});var HFt=s(Tbe);xgr=r(HFt,"tapas"),HFt.forEach(t),$gr=r(pRe," \u2014 "),tQ=n(pRe,"A",{href:!0});var UFt=s(tQ);kgr=r(UFt,"TFTapasModel"),UFt.forEach(t),Sgr=r(pRe," (TAPAS model)"),pRe.forEach(t),Rgr=i(D),VT=n(D,"LI",{});var _Re=s(VT);Mbe=n(_Re,"STRONG",{});var JFt=s(Mbe);Pgr=r(JFt,"transfo-xl"),JFt.forEach(t),Bgr=r(_Re," \u2014 "),aQ=n(_Re,"A",{href:!0});var YFt=s(aQ);Igr=r(YFt,"TFTransfoXLModel"),YFt.forEach(t),Ngr=r(_Re," (Transformer-XL model)"),_Re.forEach(t),qgr=i(D),XT=n(D,"LI",{});var uRe=s(XT);Ebe=n(uRe,"STRONG",{});var KFt=s(Ebe);jgr=r(KFt,"vit"),KFt.forEach(t),Dgr=r(uRe," \u2014 "),nQ=n(uRe,"A",{href:!0});var ZFt=s(nQ);Ggr=r(ZFt,"TFViTModel"),ZFt.forEach(t),Ogr=r(uRe," (ViT model)"),uRe.forEach(t),Vgr=i(D),zT=n(D,"LI",{});var bRe=s(zT);Cbe=n(bRe,"STRONG",{});var eTt=s(Cbe);Xgr=r(eTt,"vit_mae"),eTt.forEach(t),zgr=r(bRe," \u2014 "),sQ=n(bRe,"A",{href:!0});var oTt=s(sQ);Wgr=r(oTt,"TFViTMAEModel"),oTt.forEach(t),Qgr=r(bRe," (ViTMAE model)"),bRe.forEach(t),Hgr=i(D),WT=n(D,"LI",{});var vRe=s(WT);wbe=n(vRe,"STRONG",{});var rTt=s(wbe);Ugr=r(rTt,"wav2vec2"),rTt.forEach(t),Jgr=r(vRe," \u2014 "),lQ=n(vRe,"A",{href:!0});var tTt=s(lQ);Ygr=r(tTt,"TFWav2Vec2Model"),tTt.forEach(t),Kgr=r(vRe," (Wav2Vec2 model)"),vRe.forEach(t),Zgr=i(D),QT=n(D,"LI",{});var FRe=s(QT);Abe=n(FRe,"STRONG",{});var aTt=s(Abe);ehr=r(aTt,"xlm"),aTt.forEach(t),ohr=r(FRe," \u2014 "),iQ=n(FRe,"A",{href:!0});var nTt=s(iQ);rhr=r(nTt,"TFXLMModel"),nTt.forEach(t),thr=r(FRe," (XLM model)"),FRe.forEach(t),ahr=i(D),HT=n(D,"LI",{});var TRe=s(HT);ybe=n(TRe,"STRONG",{});var sTt=s(ybe);nhr=r(sTt,"xlm-roberta"),sTt.forEach(t),shr=r(TRe," \u2014 "),dQ=n(TRe,"A",{href:!0});var lTt=s(dQ);lhr=r(lTt,"TFXLMRobertaModel"),lTt.forEach(t),ihr=r(TRe," (XLM-RoBERTa model)"),TRe.forEach(t),dhr=i(D),UT=n(D,"LI",{});var MRe=s(UT);Lbe=n(MRe,"STRONG",{});var iTt=s(Lbe);chr=r(iTt,"xlnet"),iTt.forEach(t),fhr=r(MRe," \u2014 "),cQ=n(MRe,"A",{href:!0});var dTt=s(cQ);mhr=r(dTt,"TFXLNetModel"),dTt.forEach(t),ghr=r(MRe," (XLNet model)"),MRe.forEach(t),D.forEach(t),hhr=i(pl),T(JT.$$.fragment,pl),pl.forEach(t),hl.forEach(t),Mje=i(f),zd=n(f,"H2",{class:!0});var LGe=s(zd);YT=n(LGe,"A",{id:!0,class:!0,href:!0});var cTt=s(YT);xbe=n(cTt,"SPAN",{});var fTt=s(xbe);T(u8.$$.fragment,fTt),fTt.forEach(t),cTt.forEach(t),phr=i(LGe),$be=n(LGe,"SPAN",{});var mTt=s($be);_hr=r(mTt,"TFAutoModelForPreTraining"),mTt.forEach(t),LGe.forEach(t),Eje=i(f),Ko=n(f,"DIV",{class:!0});var _l=s(Ko);T(b8.$$.fragment,_l),uhr=i(_l),Wd=n(_l,"P",{});var Fee=s(Wd);bhr=r(Fee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),fQ=n(Fee,"A",{href:!0});var gTt=s(fQ);vhr=r(gTt,"from_pretrained()"),gTt.forEach(t),Fhr=r(Fee," class method or the "),mQ=n(Fee,"A",{href:!0});var hTt=s(mQ);Thr=r(hTt,"from_config()"),hTt.forEach(t),Mhr=r(Fee,` class
method.`),Fee.forEach(t),Ehr=i(_l),v8=n(_l,"P",{});var xGe=s(v8);Chr=r(xGe,"This class cannot be instantiated directly using "),kbe=n(xGe,"CODE",{});var pTt=s(kbe);whr=r(pTt,"__init__()"),pTt.forEach(t),Ahr=r(xGe," (throws an error)."),xGe.forEach(t),yhr=i(_l),Lt=n(_l,"DIV",{class:!0});var $0=s(Lt);T(F8.$$.fragment,$0),Lhr=i($0),Sbe=n($0,"P",{});var _Tt=s(Sbe);xhr=r(_Tt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),_Tt.forEach(t),$hr=i($0),Qd=n($0,"P",{});var Tee=s(Qd);khr=r(Tee,`Note:
Loading a model from its configuration file does `),Rbe=n(Tee,"STRONG",{});var uTt=s(Rbe);Shr=r(uTt,"not"),uTt.forEach(t),Rhr=r(Tee,` load the model weights. It only affects the
model\u2019s configuration. Use `),gQ=n(Tee,"A",{href:!0});var bTt=s(gQ);Phr=r(bTt,"from_pretrained()"),bTt.forEach(t),Bhr=r(Tee," to load the model weights."),Tee.forEach(t),Ihr=i($0),T(KT.$$.fragment,$0),$0.forEach(t),Nhr=i(_l),Ar=n(_l,"DIV",{class:!0});var ul=s(Ar);T(T8.$$.fragment,ul),qhr=i(ul),Pbe=n(ul,"P",{});var vTt=s(Pbe);jhr=r(vTt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),vTt.forEach(t),Dhr=i(ul),Za=n(ul,"P",{});var k0=s(Za);Ghr=r(k0,"The model class to instantiate is selected based on the "),Bbe=n(k0,"CODE",{});var FTt=s(Bbe);Ohr=r(FTt,"model_type"),FTt.forEach(t),Vhr=r(k0,` property of the config object (either
passed as an argument or loaded from `),Ibe=n(k0,"CODE",{});var TTt=s(Ibe);Xhr=r(TTt,"pretrained_model_name_or_path"),TTt.forEach(t),zhr=r(k0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nbe=n(k0,"CODE",{});var MTt=s(Nbe);Whr=r(MTt,"pretrained_model_name_or_path"),MTt.forEach(t),Qhr=r(k0,":"),k0.forEach(t),Hhr=i(ul),se=n(ul,"UL",{});var le=s(se);ZT=n(le,"LI",{});var ERe=s(ZT);qbe=n(ERe,"STRONG",{});var ETt=s(qbe);Uhr=r(ETt,"albert"),ETt.forEach(t),Jhr=r(ERe," \u2014 "),hQ=n(ERe,"A",{href:!0});var CTt=s(hQ);Yhr=r(CTt,"TFAlbertForPreTraining"),CTt.forEach(t),Khr=r(ERe," (ALBERT model)"),ERe.forEach(t),Zhr=i(le),e7=n(le,"LI",{});var CRe=s(e7);jbe=n(CRe,"STRONG",{});var wTt=s(jbe);epr=r(wTt,"bart"),wTt.forEach(t),opr=r(CRe," \u2014 "),pQ=n(CRe,"A",{href:!0});var ATt=s(pQ);rpr=r(ATt,"TFBartForConditionalGeneration"),ATt.forEach(t),tpr=r(CRe," (BART model)"),CRe.forEach(t),apr=i(le),o7=n(le,"LI",{});var wRe=s(o7);Dbe=n(wRe,"STRONG",{});var yTt=s(Dbe);npr=r(yTt,"bert"),yTt.forEach(t),spr=r(wRe," \u2014 "),_Q=n(wRe,"A",{href:!0});var LTt=s(_Q);lpr=r(LTt,"TFBertForPreTraining"),LTt.forEach(t),ipr=r(wRe," (BERT model)"),wRe.forEach(t),dpr=i(le),r7=n(le,"LI",{});var ARe=s(r7);Gbe=n(ARe,"STRONG",{});var xTt=s(Gbe);cpr=r(xTt,"camembert"),xTt.forEach(t),fpr=r(ARe," \u2014 "),uQ=n(ARe,"A",{href:!0});var $Tt=s(uQ);mpr=r($Tt,"TFCamembertForMaskedLM"),$Tt.forEach(t),gpr=r(ARe," (CamemBERT model)"),ARe.forEach(t),hpr=i(le),t7=n(le,"LI",{});var yRe=s(t7);Obe=n(yRe,"STRONG",{});var kTt=s(Obe);ppr=r(kTt,"ctrl"),kTt.forEach(t),_pr=r(yRe," \u2014 "),bQ=n(yRe,"A",{href:!0});var STt=s(bQ);upr=r(STt,"TFCTRLLMHeadModel"),STt.forEach(t),bpr=r(yRe," (CTRL model)"),yRe.forEach(t),vpr=i(le),a7=n(le,"LI",{});var LRe=s(a7);Vbe=n(LRe,"STRONG",{});var RTt=s(Vbe);Fpr=r(RTt,"distilbert"),RTt.forEach(t),Tpr=r(LRe," \u2014 "),vQ=n(LRe,"A",{href:!0});var PTt=s(vQ);Mpr=r(PTt,"TFDistilBertForMaskedLM"),PTt.forEach(t),Epr=r(LRe," (DistilBERT model)"),LRe.forEach(t),Cpr=i(le),n7=n(le,"LI",{});var xRe=s(n7);Xbe=n(xRe,"STRONG",{});var BTt=s(Xbe);wpr=r(BTt,"electra"),BTt.forEach(t),Apr=r(xRe," \u2014 "),FQ=n(xRe,"A",{href:!0});var ITt=s(FQ);ypr=r(ITt,"TFElectraForPreTraining"),ITt.forEach(t),Lpr=r(xRe," (ELECTRA model)"),xRe.forEach(t),xpr=i(le),s7=n(le,"LI",{});var $Re=s(s7);zbe=n($Re,"STRONG",{});var NTt=s(zbe);$pr=r(NTt,"flaubert"),NTt.forEach(t),kpr=r($Re," \u2014 "),TQ=n($Re,"A",{href:!0});var qTt=s(TQ);Spr=r(qTt,"TFFlaubertWithLMHeadModel"),qTt.forEach(t),Rpr=r($Re," (FlauBERT model)"),$Re.forEach(t),Ppr=i(le),l7=n(le,"LI",{});var kRe=s(l7);Wbe=n(kRe,"STRONG",{});var jTt=s(Wbe);Bpr=r(jTt,"funnel"),jTt.forEach(t),Ipr=r(kRe," \u2014 "),MQ=n(kRe,"A",{href:!0});var DTt=s(MQ);Npr=r(DTt,"TFFunnelForPreTraining"),DTt.forEach(t),qpr=r(kRe," (Funnel Transformer model)"),kRe.forEach(t),jpr=i(le),i7=n(le,"LI",{});var SRe=s(i7);Qbe=n(SRe,"STRONG",{});var GTt=s(Qbe);Dpr=r(GTt,"gpt2"),GTt.forEach(t),Gpr=r(SRe," \u2014 "),EQ=n(SRe,"A",{href:!0});var OTt=s(EQ);Opr=r(OTt,"TFGPT2LMHeadModel"),OTt.forEach(t),Vpr=r(SRe," (OpenAI GPT-2 model)"),SRe.forEach(t),Xpr=i(le),d7=n(le,"LI",{});var RRe=s(d7);Hbe=n(RRe,"STRONG",{});var VTt=s(Hbe);zpr=r(VTt,"layoutlm"),VTt.forEach(t),Wpr=r(RRe," \u2014 "),CQ=n(RRe,"A",{href:!0});var XTt=s(CQ);Qpr=r(XTt,"TFLayoutLMForMaskedLM"),XTt.forEach(t),Hpr=r(RRe," (LayoutLM model)"),RRe.forEach(t),Upr=i(le),c7=n(le,"LI",{});var PRe=s(c7);Ube=n(PRe,"STRONG",{});var zTt=s(Ube);Jpr=r(zTt,"lxmert"),zTt.forEach(t),Ypr=r(PRe," \u2014 "),wQ=n(PRe,"A",{href:!0});var WTt=s(wQ);Kpr=r(WTt,"TFLxmertForPreTraining"),WTt.forEach(t),Zpr=r(PRe," (LXMERT model)"),PRe.forEach(t),e_r=i(le),f7=n(le,"LI",{});var BRe=s(f7);Jbe=n(BRe,"STRONG",{});var QTt=s(Jbe);o_r=r(QTt,"mobilebert"),QTt.forEach(t),r_r=r(BRe," \u2014 "),AQ=n(BRe,"A",{href:!0});var HTt=s(AQ);t_r=r(HTt,"TFMobileBertForPreTraining"),HTt.forEach(t),a_r=r(BRe," (MobileBERT model)"),BRe.forEach(t),n_r=i(le),m7=n(le,"LI",{});var IRe=s(m7);Ybe=n(IRe,"STRONG",{});var UTt=s(Ybe);s_r=r(UTt,"mpnet"),UTt.forEach(t),l_r=r(IRe," \u2014 "),yQ=n(IRe,"A",{href:!0});var JTt=s(yQ);i_r=r(JTt,"TFMPNetForMaskedLM"),JTt.forEach(t),d_r=r(IRe," (MPNet model)"),IRe.forEach(t),c_r=i(le),g7=n(le,"LI",{});var NRe=s(g7);Kbe=n(NRe,"STRONG",{});var YTt=s(Kbe);f_r=r(YTt,"openai-gpt"),YTt.forEach(t),m_r=r(NRe," \u2014 "),LQ=n(NRe,"A",{href:!0});var KTt=s(LQ);g_r=r(KTt,"TFOpenAIGPTLMHeadModel"),KTt.forEach(t),h_r=r(NRe," (OpenAI GPT model)"),NRe.forEach(t),p_r=i(le),h7=n(le,"LI",{});var qRe=s(h7);Zbe=n(qRe,"STRONG",{});var ZTt=s(Zbe);__r=r(ZTt,"roberta"),ZTt.forEach(t),u_r=r(qRe," \u2014 "),xQ=n(qRe,"A",{href:!0});var e7t=s(xQ);b_r=r(e7t,"TFRobertaForMaskedLM"),e7t.forEach(t),v_r=r(qRe," (RoBERTa model)"),qRe.forEach(t),F_r=i(le),p7=n(le,"LI",{});var jRe=s(p7);e2e=n(jRe,"STRONG",{});var o7t=s(e2e);T_r=r(o7t,"t5"),o7t.forEach(t),M_r=r(jRe," \u2014 "),$Q=n(jRe,"A",{href:!0});var r7t=s($Q);E_r=r(r7t,"TFT5ForConditionalGeneration"),r7t.forEach(t),C_r=r(jRe," (T5 model)"),jRe.forEach(t),w_r=i(le),_7=n(le,"LI",{});var DRe=s(_7);o2e=n(DRe,"STRONG",{});var t7t=s(o2e);A_r=r(t7t,"tapas"),t7t.forEach(t),y_r=r(DRe," \u2014 "),kQ=n(DRe,"A",{href:!0});var a7t=s(kQ);L_r=r(a7t,"TFTapasForMaskedLM"),a7t.forEach(t),x_r=r(DRe," (TAPAS model)"),DRe.forEach(t),$_r=i(le),u7=n(le,"LI",{});var GRe=s(u7);r2e=n(GRe,"STRONG",{});var n7t=s(r2e);k_r=r(n7t,"transfo-xl"),n7t.forEach(t),S_r=r(GRe," \u2014 "),SQ=n(GRe,"A",{href:!0});var s7t=s(SQ);R_r=r(s7t,"TFTransfoXLLMHeadModel"),s7t.forEach(t),P_r=r(GRe," (Transformer-XL model)"),GRe.forEach(t),B_r=i(le),b7=n(le,"LI",{});var ORe=s(b7);t2e=n(ORe,"STRONG",{});var l7t=s(t2e);I_r=r(l7t,"vit_mae"),l7t.forEach(t),N_r=r(ORe," \u2014 "),RQ=n(ORe,"A",{href:!0});var i7t=s(RQ);q_r=r(i7t,"TFViTMAEForPreTraining"),i7t.forEach(t),j_r=r(ORe," (ViTMAE model)"),ORe.forEach(t),D_r=i(le),v7=n(le,"LI",{});var VRe=s(v7);a2e=n(VRe,"STRONG",{});var d7t=s(a2e);G_r=r(d7t,"xlm"),d7t.forEach(t),O_r=r(VRe," \u2014 "),PQ=n(VRe,"A",{href:!0});var c7t=s(PQ);V_r=r(c7t,"TFXLMWithLMHeadModel"),c7t.forEach(t),X_r=r(VRe," (XLM model)"),VRe.forEach(t),z_r=i(le),F7=n(le,"LI",{});var XRe=s(F7);n2e=n(XRe,"STRONG",{});var f7t=s(n2e);W_r=r(f7t,"xlm-roberta"),f7t.forEach(t),Q_r=r(XRe," \u2014 "),BQ=n(XRe,"A",{href:!0});var m7t=s(BQ);H_r=r(m7t,"TFXLMRobertaForMaskedLM"),m7t.forEach(t),U_r=r(XRe," (XLM-RoBERTa model)"),XRe.forEach(t),J_r=i(le),T7=n(le,"LI",{});var zRe=s(T7);s2e=n(zRe,"STRONG",{});var g7t=s(s2e);Y_r=r(g7t,"xlnet"),g7t.forEach(t),K_r=r(zRe," \u2014 "),IQ=n(zRe,"A",{href:!0});var h7t=s(IQ);Z_r=r(h7t,"TFXLNetLMHeadModel"),h7t.forEach(t),eur=r(zRe," (XLNet model)"),zRe.forEach(t),le.forEach(t),our=i(ul),T(M7.$$.fragment,ul),ul.forEach(t),_l.forEach(t),Cje=i(f),Hd=n(f,"H2",{class:!0});var $Ge=s(Hd);E7=n($Ge,"A",{id:!0,class:!0,href:!0});var p7t=s(E7);l2e=n(p7t,"SPAN",{});var _7t=s(l2e);T(M8.$$.fragment,_7t),_7t.forEach(t),p7t.forEach(t),rur=i($Ge),i2e=n($Ge,"SPAN",{});var u7t=s(i2e);tur=r(u7t,"TFAutoModelForCausalLM"),u7t.forEach(t),$Ge.forEach(t),wje=i(f),Zo=n(f,"DIV",{class:!0});var bl=s(Zo);T(E8.$$.fragment,bl),aur=i(bl),Ud=n(bl,"P",{});var Mee=s(Ud);nur=r(Mee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),NQ=n(Mee,"A",{href:!0});var b7t=s(NQ);sur=r(b7t,"from_pretrained()"),b7t.forEach(t),lur=r(Mee," class method or the "),qQ=n(Mee,"A",{href:!0});var v7t=s(qQ);iur=r(v7t,"from_config()"),v7t.forEach(t),dur=r(Mee,` class
method.`),Mee.forEach(t),cur=i(bl),C8=n(bl,"P",{});var kGe=s(C8);fur=r(kGe,"This class cannot be instantiated directly using "),d2e=n(kGe,"CODE",{});var F7t=s(d2e);mur=r(F7t,"__init__()"),F7t.forEach(t),gur=r(kGe," (throws an error)."),kGe.forEach(t),hur=i(bl),xt=n(bl,"DIV",{class:!0});var S0=s(xt);T(w8.$$.fragment,S0),pur=i(S0),c2e=n(S0,"P",{});var T7t=s(c2e);_ur=r(T7t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),T7t.forEach(t),uur=i(S0),Jd=n(S0,"P",{});var Eee=s(Jd);bur=r(Eee,`Note:
Loading a model from its configuration file does `),f2e=n(Eee,"STRONG",{});var M7t=s(f2e);vur=r(M7t,"not"),M7t.forEach(t),Fur=r(Eee,` load the model weights. It only affects the
model\u2019s configuration. Use `),jQ=n(Eee,"A",{href:!0});var E7t=s(jQ);Tur=r(E7t,"from_pretrained()"),E7t.forEach(t),Mur=r(Eee," to load the model weights."),Eee.forEach(t),Eur=i(S0),T(C7.$$.fragment,S0),S0.forEach(t),Cur=i(bl),yr=n(bl,"DIV",{class:!0});var vl=s(yr);T(A8.$$.fragment,vl),wur=i(vl),m2e=n(vl,"P",{});var C7t=s(m2e);Aur=r(C7t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),C7t.forEach(t),yur=i(vl),en=n(vl,"P",{});var R0=s(en);Lur=r(R0,"The model class to instantiate is selected based on the "),g2e=n(R0,"CODE",{});var w7t=s(g2e);xur=r(w7t,"model_type"),w7t.forEach(t),$ur=r(R0,` property of the config object (either
passed as an argument or loaded from `),h2e=n(R0,"CODE",{});var A7t=s(h2e);kur=r(A7t,"pretrained_model_name_or_path"),A7t.forEach(t),Sur=r(R0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p2e=n(R0,"CODE",{});var y7t=s(p2e);Rur=r(y7t,"pretrained_model_name_or_path"),y7t.forEach(t),Pur=r(R0,":"),R0.forEach(t),Bur=i(vl),Me=n(vl,"UL",{});var Ce=s(Me);w7=n(Ce,"LI",{});var WRe=s(w7);_2e=n(WRe,"STRONG",{});var L7t=s(_2e);Iur=r(L7t,"bert"),L7t.forEach(t),Nur=r(WRe," \u2014 "),DQ=n(WRe,"A",{href:!0});var x7t=s(DQ);qur=r(x7t,"TFBertLMHeadModel"),x7t.forEach(t),jur=r(WRe," (BERT model)"),WRe.forEach(t),Dur=i(Ce),A7=n(Ce,"LI",{});var QRe=s(A7);u2e=n(QRe,"STRONG",{});var $7t=s(u2e);Gur=r($7t,"camembert"),$7t.forEach(t),Our=r(QRe," \u2014 "),GQ=n(QRe,"A",{href:!0});var k7t=s(GQ);Vur=r(k7t,"TFCamembertForCausalLM"),k7t.forEach(t),Xur=r(QRe," (CamemBERT model)"),QRe.forEach(t),zur=i(Ce),y7=n(Ce,"LI",{});var HRe=s(y7);b2e=n(HRe,"STRONG",{});var S7t=s(b2e);Wur=r(S7t,"ctrl"),S7t.forEach(t),Qur=r(HRe," \u2014 "),OQ=n(HRe,"A",{href:!0});var R7t=s(OQ);Hur=r(R7t,"TFCTRLLMHeadModel"),R7t.forEach(t),Uur=r(HRe," (CTRL model)"),HRe.forEach(t),Jur=i(Ce),L7=n(Ce,"LI",{});var URe=s(L7);v2e=n(URe,"STRONG",{});var P7t=s(v2e);Yur=r(P7t,"gpt2"),P7t.forEach(t),Kur=r(URe," \u2014 "),VQ=n(URe,"A",{href:!0});var B7t=s(VQ);Zur=r(B7t,"TFGPT2LMHeadModel"),B7t.forEach(t),e6r=r(URe," (OpenAI GPT-2 model)"),URe.forEach(t),o6r=i(Ce),x7=n(Ce,"LI",{});var JRe=s(x7);F2e=n(JRe,"STRONG",{});var I7t=s(F2e);r6r=r(I7t,"gptj"),I7t.forEach(t),t6r=r(JRe," \u2014 "),XQ=n(JRe,"A",{href:!0});var N7t=s(XQ);a6r=r(N7t,"TFGPTJForCausalLM"),N7t.forEach(t),n6r=r(JRe," (GPT-J model)"),JRe.forEach(t),s6r=i(Ce),$7=n(Ce,"LI",{});var YRe=s($7);T2e=n(YRe,"STRONG",{});var q7t=s(T2e);l6r=r(q7t,"openai-gpt"),q7t.forEach(t),i6r=r(YRe," \u2014 "),zQ=n(YRe,"A",{href:!0});var j7t=s(zQ);d6r=r(j7t,"TFOpenAIGPTLMHeadModel"),j7t.forEach(t),c6r=r(YRe," (OpenAI GPT model)"),YRe.forEach(t),f6r=i(Ce),k7=n(Ce,"LI",{});var KRe=s(k7);M2e=n(KRe,"STRONG",{});var D7t=s(M2e);m6r=r(D7t,"rembert"),D7t.forEach(t),g6r=r(KRe," \u2014 "),WQ=n(KRe,"A",{href:!0});var G7t=s(WQ);h6r=r(G7t,"TFRemBertForCausalLM"),G7t.forEach(t),p6r=r(KRe," (RemBERT model)"),KRe.forEach(t),_6r=i(Ce),S7=n(Ce,"LI",{});var ZRe=s(S7);E2e=n(ZRe,"STRONG",{});var O7t=s(E2e);u6r=r(O7t,"roberta"),O7t.forEach(t),b6r=r(ZRe," \u2014 "),QQ=n(ZRe,"A",{href:!0});var V7t=s(QQ);v6r=r(V7t,"TFRobertaForCausalLM"),V7t.forEach(t),F6r=r(ZRe," (RoBERTa model)"),ZRe.forEach(t),T6r=i(Ce),R7=n(Ce,"LI",{});var ePe=s(R7);C2e=n(ePe,"STRONG",{});var X7t=s(C2e);M6r=r(X7t,"roformer"),X7t.forEach(t),E6r=r(ePe," \u2014 "),HQ=n(ePe,"A",{href:!0});var z7t=s(HQ);C6r=r(z7t,"TFRoFormerForCausalLM"),z7t.forEach(t),w6r=r(ePe," (RoFormer model)"),ePe.forEach(t),A6r=i(Ce),P7=n(Ce,"LI",{});var oPe=s(P7);w2e=n(oPe,"STRONG",{});var W7t=s(w2e);y6r=r(W7t,"transfo-xl"),W7t.forEach(t),L6r=r(oPe," \u2014 "),UQ=n(oPe,"A",{href:!0});var Q7t=s(UQ);x6r=r(Q7t,"TFTransfoXLLMHeadModel"),Q7t.forEach(t),$6r=r(oPe," (Transformer-XL model)"),oPe.forEach(t),k6r=i(Ce),B7=n(Ce,"LI",{});var rPe=s(B7);A2e=n(rPe,"STRONG",{});var H7t=s(A2e);S6r=r(H7t,"xlm"),H7t.forEach(t),R6r=r(rPe," \u2014 "),JQ=n(rPe,"A",{href:!0});var U7t=s(JQ);P6r=r(U7t,"TFXLMWithLMHeadModel"),U7t.forEach(t),B6r=r(rPe," (XLM model)"),rPe.forEach(t),I6r=i(Ce),I7=n(Ce,"LI",{});var tPe=s(I7);y2e=n(tPe,"STRONG",{});var J7t=s(y2e);N6r=r(J7t,"xlnet"),J7t.forEach(t),q6r=r(tPe," \u2014 "),YQ=n(tPe,"A",{href:!0});var Y7t=s(YQ);j6r=r(Y7t,"TFXLNetLMHeadModel"),Y7t.forEach(t),D6r=r(tPe," (XLNet model)"),tPe.forEach(t),Ce.forEach(t),G6r=i(vl),T(N7.$$.fragment,vl),vl.forEach(t),bl.forEach(t),Aje=i(f),Yd=n(f,"H2",{class:!0});var SGe=s(Yd);q7=n(SGe,"A",{id:!0,class:!0,href:!0});var K7t=s(q7);L2e=n(K7t,"SPAN",{});var Z7t=s(L2e);T(y8.$$.fragment,Z7t),Z7t.forEach(t),K7t.forEach(t),O6r=i(SGe),x2e=n(SGe,"SPAN",{});var eMt=s(x2e);V6r=r(eMt,"TFAutoModelForImageClassification"),eMt.forEach(t),SGe.forEach(t),yje=i(f),er=n(f,"DIV",{class:!0});var Fl=s(er);T(L8.$$.fragment,Fl),X6r=i(Fl),Kd=n(Fl,"P",{});var Cee=s(Kd);z6r=r(Cee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),KQ=n(Cee,"A",{href:!0});var oMt=s(KQ);W6r=r(oMt,"from_pretrained()"),oMt.forEach(t),Q6r=r(Cee," class method or the "),ZQ=n(Cee,"A",{href:!0});var rMt=s(ZQ);H6r=r(rMt,"from_config()"),rMt.forEach(t),U6r=r(Cee,` class
method.`),Cee.forEach(t),J6r=i(Fl),x8=n(Fl,"P",{});var RGe=s(x8);Y6r=r(RGe,"This class cannot be instantiated directly using "),$2e=n(RGe,"CODE",{});var tMt=s($2e);K6r=r(tMt,"__init__()"),tMt.forEach(t),Z6r=r(RGe," (throws an error)."),RGe.forEach(t),e1r=i(Fl),$t=n(Fl,"DIV",{class:!0});var P0=s($t);T($8.$$.fragment,P0),o1r=i(P0),k2e=n(P0,"P",{});var aMt=s(k2e);r1r=r(aMt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),aMt.forEach(t),t1r=i(P0),Zd=n(P0,"P",{});var wee=s(Zd);a1r=r(wee,`Note:
Loading a model from its configuration file does `),S2e=n(wee,"STRONG",{});var nMt=s(S2e);n1r=r(nMt,"not"),nMt.forEach(t),s1r=r(wee,` load the model weights. It only affects the
model\u2019s configuration. Use `),eH=n(wee,"A",{href:!0});var sMt=s(eH);l1r=r(sMt,"from_pretrained()"),sMt.forEach(t),i1r=r(wee," to load the model weights."),wee.forEach(t),d1r=i(P0),T(j7.$$.fragment,P0),P0.forEach(t),c1r=i(Fl),Lr=n(Fl,"DIV",{class:!0});var Tl=s(Lr);T(k8.$$.fragment,Tl),f1r=i(Tl),R2e=n(Tl,"P",{});var lMt=s(R2e);m1r=r(lMt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),lMt.forEach(t),g1r=i(Tl),on=n(Tl,"P",{});var B0=s(on);h1r=r(B0,"The model class to instantiate is selected based on the "),P2e=n(B0,"CODE",{});var iMt=s(P2e);p1r=r(iMt,"model_type"),iMt.forEach(t),_1r=r(B0,` property of the config object (either
passed as an argument or loaded from `),B2e=n(B0,"CODE",{});var dMt=s(B2e);u1r=r(dMt,"pretrained_model_name_or_path"),dMt.forEach(t),b1r=r(B0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I2e=n(B0,"CODE",{});var cMt=s(I2e);v1r=r(cMt,"pretrained_model_name_or_path"),cMt.forEach(t),F1r=r(B0,":"),B0.forEach(t),T1r=i(Tl),rn=n(Tl,"UL",{});var I0=s(rn);D7=n(I0,"LI",{});var aPe=s(D7);N2e=n(aPe,"STRONG",{});var fMt=s(N2e);M1r=r(fMt,"convnext"),fMt.forEach(t),E1r=r(aPe," \u2014 "),oH=n(aPe,"A",{href:!0});var mMt=s(oH);C1r=r(mMt,"TFConvNextForImageClassification"),mMt.forEach(t),w1r=r(aPe," (ConvNext model)"),aPe.forEach(t),A1r=i(I0),G7=n(I0,"LI",{});var nPe=s(G7);q2e=n(nPe,"STRONG",{});var gMt=s(q2e);y1r=r(gMt,"data2vec-vision"),gMt.forEach(t),L1r=r(nPe," \u2014 "),rH=n(nPe,"A",{href:!0});var hMt=s(rH);x1r=r(hMt,"TFData2VecVisionForImageClassification"),hMt.forEach(t),$1r=r(nPe," (Data2VecVision model)"),nPe.forEach(t),k1r=i(I0),O7=n(I0,"LI",{});var sPe=s(O7);j2e=n(sPe,"STRONG",{});var pMt=s(j2e);S1r=r(pMt,"swin"),pMt.forEach(t),R1r=r(sPe," \u2014 "),tH=n(sPe,"A",{href:!0});var _Mt=s(tH);P1r=r(_Mt,"TFSwinForImageClassification"),_Mt.forEach(t),B1r=r(sPe," (Swin model)"),sPe.forEach(t),I1r=i(I0),V7=n(I0,"LI",{});var lPe=s(V7);D2e=n(lPe,"STRONG",{});var uMt=s(D2e);N1r=r(uMt,"vit"),uMt.forEach(t),q1r=r(lPe," \u2014 "),aH=n(lPe,"A",{href:!0});var bMt=s(aH);j1r=r(bMt,"TFViTForImageClassification"),bMt.forEach(t),D1r=r(lPe," (ViT model)"),lPe.forEach(t),I0.forEach(t),G1r=i(Tl),T(X7.$$.fragment,Tl),Tl.forEach(t),Fl.forEach(t),Lje=i(f),ec=n(f,"H2",{class:!0});var PGe=s(ec);z7=n(PGe,"A",{id:!0,class:!0,href:!0});var vMt=s(z7);G2e=n(vMt,"SPAN",{});var FMt=s(G2e);T(S8.$$.fragment,FMt),FMt.forEach(t),vMt.forEach(t),O1r=i(PGe),O2e=n(PGe,"SPAN",{});var TMt=s(O2e);V1r=r(TMt,"TFAutoModelForMaskedLM"),TMt.forEach(t),PGe.forEach(t),xje=i(f),or=n(f,"DIV",{class:!0});var Ml=s(or);T(R8.$$.fragment,Ml),X1r=i(Ml),oc=n(Ml,"P",{});var Aee=s(oc);z1r=r(Aee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),nH=n(Aee,"A",{href:!0});var MMt=s(nH);W1r=r(MMt,"from_pretrained()"),MMt.forEach(t),Q1r=r(Aee," class method or the "),sH=n(Aee,"A",{href:!0});var EMt=s(sH);H1r=r(EMt,"from_config()"),EMt.forEach(t),U1r=r(Aee,` class
method.`),Aee.forEach(t),J1r=i(Ml),P8=n(Ml,"P",{});var BGe=s(P8);Y1r=r(BGe,"This class cannot be instantiated directly using "),V2e=n(BGe,"CODE",{});var CMt=s(V2e);K1r=r(CMt,"__init__()"),CMt.forEach(t),Z1r=r(BGe," (throws an error)."),BGe.forEach(t),ebr=i(Ml),kt=n(Ml,"DIV",{class:!0});var N0=s(kt);T(B8.$$.fragment,N0),obr=i(N0),X2e=n(N0,"P",{});var wMt=s(X2e);rbr=r(wMt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),wMt.forEach(t),tbr=i(N0),rc=n(N0,"P",{});var yee=s(rc);abr=r(yee,`Note:
Loading a model from its configuration file does `),z2e=n(yee,"STRONG",{});var AMt=s(z2e);nbr=r(AMt,"not"),AMt.forEach(t),sbr=r(yee,` load the model weights. It only affects the
model\u2019s configuration. Use `),lH=n(yee,"A",{href:!0});var yMt=s(lH);lbr=r(yMt,"from_pretrained()"),yMt.forEach(t),ibr=r(yee," to load the model weights."),yee.forEach(t),dbr=i(N0),T(W7.$$.fragment,N0),N0.forEach(t),cbr=i(Ml),xr=n(Ml,"DIV",{class:!0});var El=s(xr);T(I8.$$.fragment,El),fbr=i(El),W2e=n(El,"P",{});var LMt=s(W2e);mbr=r(LMt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),LMt.forEach(t),gbr=i(El),tn=n(El,"P",{});var q0=s(tn);hbr=r(q0,"The model class to instantiate is selected based on the "),Q2e=n(q0,"CODE",{});var xMt=s(Q2e);pbr=r(xMt,"model_type"),xMt.forEach(t),_br=r(q0,` property of the config object (either
passed as an argument or loaded from `),H2e=n(q0,"CODE",{});var $Mt=s(H2e);ubr=r($Mt,"pretrained_model_name_or_path"),$Mt.forEach(t),bbr=r(q0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U2e=n(q0,"CODE",{});var kMt=s(U2e);vbr=r(kMt,"pretrained_model_name_or_path"),kMt.forEach(t),Fbr=r(q0,":"),q0.forEach(t),Tbr=i(El),ie=n(El,"UL",{});var fe=s(ie);Q7=n(fe,"LI",{});var iPe=s(Q7);J2e=n(iPe,"STRONG",{});var SMt=s(J2e);Mbr=r(SMt,"albert"),SMt.forEach(t),Ebr=r(iPe," \u2014 "),iH=n(iPe,"A",{href:!0});var RMt=s(iH);Cbr=r(RMt,"TFAlbertForMaskedLM"),RMt.forEach(t),wbr=r(iPe," (ALBERT model)"),iPe.forEach(t),Abr=i(fe),H7=n(fe,"LI",{});var dPe=s(H7);Y2e=n(dPe,"STRONG",{});var PMt=s(Y2e);ybr=r(PMt,"bert"),PMt.forEach(t),Lbr=r(dPe," \u2014 "),dH=n(dPe,"A",{href:!0});var BMt=s(dH);xbr=r(BMt,"TFBertForMaskedLM"),BMt.forEach(t),$br=r(dPe," (BERT model)"),dPe.forEach(t),kbr=i(fe),U7=n(fe,"LI",{});var cPe=s(U7);K2e=n(cPe,"STRONG",{});var IMt=s(K2e);Sbr=r(IMt,"camembert"),IMt.forEach(t),Rbr=r(cPe," \u2014 "),cH=n(cPe,"A",{href:!0});var NMt=s(cH);Pbr=r(NMt,"TFCamembertForMaskedLM"),NMt.forEach(t),Bbr=r(cPe," (CamemBERT model)"),cPe.forEach(t),Ibr=i(fe),J7=n(fe,"LI",{});var fPe=s(J7);Z2e=n(fPe,"STRONG",{});var qMt=s(Z2e);Nbr=r(qMt,"convbert"),qMt.forEach(t),qbr=r(fPe," \u2014 "),fH=n(fPe,"A",{href:!0});var jMt=s(fH);jbr=r(jMt,"TFConvBertForMaskedLM"),jMt.forEach(t),Dbr=r(fPe," (ConvBERT model)"),fPe.forEach(t),Gbr=i(fe),Y7=n(fe,"LI",{});var mPe=s(Y7);e4e=n(mPe,"STRONG",{});var DMt=s(e4e);Obr=r(DMt,"deberta"),DMt.forEach(t),Vbr=r(mPe," \u2014 "),mH=n(mPe,"A",{href:!0});var GMt=s(mH);Xbr=r(GMt,"TFDebertaForMaskedLM"),GMt.forEach(t),zbr=r(mPe," (DeBERTa model)"),mPe.forEach(t),Wbr=i(fe),K7=n(fe,"LI",{});var gPe=s(K7);o4e=n(gPe,"STRONG",{});var OMt=s(o4e);Qbr=r(OMt,"deberta-v2"),OMt.forEach(t),Hbr=r(gPe," \u2014 "),gH=n(gPe,"A",{href:!0});var VMt=s(gH);Ubr=r(VMt,"TFDebertaV2ForMaskedLM"),VMt.forEach(t),Jbr=r(gPe," (DeBERTa-v2 model)"),gPe.forEach(t),Ybr=i(fe),Z7=n(fe,"LI",{});var hPe=s(Z7);r4e=n(hPe,"STRONG",{});var XMt=s(r4e);Kbr=r(XMt,"distilbert"),XMt.forEach(t),Zbr=r(hPe," \u2014 "),hH=n(hPe,"A",{href:!0});var zMt=s(hH);e2r=r(zMt,"TFDistilBertForMaskedLM"),zMt.forEach(t),o2r=r(hPe," (DistilBERT model)"),hPe.forEach(t),r2r=i(fe),eM=n(fe,"LI",{});var pPe=s(eM);t4e=n(pPe,"STRONG",{});var WMt=s(t4e);t2r=r(WMt,"electra"),WMt.forEach(t),a2r=r(pPe," \u2014 "),pH=n(pPe,"A",{href:!0});var QMt=s(pH);n2r=r(QMt,"TFElectraForMaskedLM"),QMt.forEach(t),s2r=r(pPe," (ELECTRA model)"),pPe.forEach(t),l2r=i(fe),oM=n(fe,"LI",{});var _Pe=s(oM);a4e=n(_Pe,"STRONG",{});var HMt=s(a4e);i2r=r(HMt,"flaubert"),HMt.forEach(t),d2r=r(_Pe," \u2014 "),_H=n(_Pe,"A",{href:!0});var UMt=s(_H);c2r=r(UMt,"TFFlaubertWithLMHeadModel"),UMt.forEach(t),f2r=r(_Pe," (FlauBERT model)"),_Pe.forEach(t),m2r=i(fe),rM=n(fe,"LI",{});var uPe=s(rM);n4e=n(uPe,"STRONG",{});var JMt=s(n4e);g2r=r(JMt,"funnel"),JMt.forEach(t),h2r=r(uPe," \u2014 "),uH=n(uPe,"A",{href:!0});var YMt=s(uH);p2r=r(YMt,"TFFunnelForMaskedLM"),YMt.forEach(t),_2r=r(uPe," (Funnel Transformer model)"),uPe.forEach(t),u2r=i(fe),tM=n(fe,"LI",{});var bPe=s(tM);s4e=n(bPe,"STRONG",{});var KMt=s(s4e);b2r=r(KMt,"layoutlm"),KMt.forEach(t),v2r=r(bPe," \u2014 "),bH=n(bPe,"A",{href:!0});var ZMt=s(bH);F2r=r(ZMt,"TFLayoutLMForMaskedLM"),ZMt.forEach(t),T2r=r(bPe," (LayoutLM model)"),bPe.forEach(t),M2r=i(fe),aM=n(fe,"LI",{});var vPe=s(aM);l4e=n(vPe,"STRONG",{});var eEt=s(l4e);E2r=r(eEt,"longformer"),eEt.forEach(t),C2r=r(vPe," \u2014 "),vH=n(vPe,"A",{href:!0});var oEt=s(vH);w2r=r(oEt,"TFLongformerForMaskedLM"),oEt.forEach(t),A2r=r(vPe," (Longformer model)"),vPe.forEach(t),y2r=i(fe),nM=n(fe,"LI",{});var FPe=s(nM);i4e=n(FPe,"STRONG",{});var rEt=s(i4e);L2r=r(rEt,"mobilebert"),rEt.forEach(t),x2r=r(FPe," \u2014 "),FH=n(FPe,"A",{href:!0});var tEt=s(FH);$2r=r(tEt,"TFMobileBertForMaskedLM"),tEt.forEach(t),k2r=r(FPe," (MobileBERT model)"),FPe.forEach(t),S2r=i(fe),sM=n(fe,"LI",{});var TPe=s(sM);d4e=n(TPe,"STRONG",{});var aEt=s(d4e);R2r=r(aEt,"mpnet"),aEt.forEach(t),P2r=r(TPe," \u2014 "),TH=n(TPe,"A",{href:!0});var nEt=s(TH);B2r=r(nEt,"TFMPNetForMaskedLM"),nEt.forEach(t),I2r=r(TPe," (MPNet model)"),TPe.forEach(t),N2r=i(fe),lM=n(fe,"LI",{});var MPe=s(lM);c4e=n(MPe,"STRONG",{});var sEt=s(c4e);q2r=r(sEt,"rembert"),sEt.forEach(t),j2r=r(MPe," \u2014 "),MH=n(MPe,"A",{href:!0});var lEt=s(MH);D2r=r(lEt,"TFRemBertForMaskedLM"),lEt.forEach(t),G2r=r(MPe," (RemBERT model)"),MPe.forEach(t),O2r=i(fe),iM=n(fe,"LI",{});var EPe=s(iM);f4e=n(EPe,"STRONG",{});var iEt=s(f4e);V2r=r(iEt,"roberta"),iEt.forEach(t),X2r=r(EPe," \u2014 "),EH=n(EPe,"A",{href:!0});var dEt=s(EH);z2r=r(dEt,"TFRobertaForMaskedLM"),dEt.forEach(t),W2r=r(EPe," (RoBERTa model)"),EPe.forEach(t),Q2r=i(fe),dM=n(fe,"LI",{});var CPe=s(dM);m4e=n(CPe,"STRONG",{});var cEt=s(m4e);H2r=r(cEt,"roformer"),cEt.forEach(t),U2r=r(CPe," \u2014 "),CH=n(CPe,"A",{href:!0});var fEt=s(CH);J2r=r(fEt,"TFRoFormerForMaskedLM"),fEt.forEach(t),Y2r=r(CPe," (RoFormer model)"),CPe.forEach(t),K2r=i(fe),cM=n(fe,"LI",{});var wPe=s(cM);g4e=n(wPe,"STRONG",{});var mEt=s(g4e);Z2r=r(mEt,"tapas"),mEt.forEach(t),e4r=r(wPe," \u2014 "),wH=n(wPe,"A",{href:!0});var gEt=s(wH);o4r=r(gEt,"TFTapasForMaskedLM"),gEt.forEach(t),r4r=r(wPe," (TAPAS model)"),wPe.forEach(t),t4r=i(fe),fM=n(fe,"LI",{});var APe=s(fM);h4e=n(APe,"STRONG",{});var hEt=s(h4e);a4r=r(hEt,"xlm"),hEt.forEach(t),n4r=r(APe," \u2014 "),AH=n(APe,"A",{href:!0});var pEt=s(AH);s4r=r(pEt,"TFXLMWithLMHeadModel"),pEt.forEach(t),l4r=r(APe," (XLM model)"),APe.forEach(t),i4r=i(fe),mM=n(fe,"LI",{});var yPe=s(mM);p4e=n(yPe,"STRONG",{});var _Et=s(p4e);d4r=r(_Et,"xlm-roberta"),_Et.forEach(t),c4r=r(yPe," \u2014 "),yH=n(yPe,"A",{href:!0});var uEt=s(yH);f4r=r(uEt,"TFXLMRobertaForMaskedLM"),uEt.forEach(t),m4r=r(yPe," (XLM-RoBERTa model)"),yPe.forEach(t),fe.forEach(t),g4r=i(El),T(gM.$$.fragment,El),El.forEach(t),Ml.forEach(t),$je=i(f),tc=n(f,"H2",{class:!0});var IGe=s(tc);hM=n(IGe,"A",{id:!0,class:!0,href:!0});var bEt=s(hM);_4e=n(bEt,"SPAN",{});var vEt=s(_4e);T(N8.$$.fragment,vEt),vEt.forEach(t),bEt.forEach(t),h4r=i(IGe),u4e=n(IGe,"SPAN",{});var FEt=s(u4e);p4r=r(FEt,"TFAutoModelForSeq2SeqLM"),FEt.forEach(t),IGe.forEach(t),kje=i(f),rr=n(f,"DIV",{class:!0});var Cl=s(rr);T(q8.$$.fragment,Cl),_4r=i(Cl),ac=n(Cl,"P",{});var Lee=s(ac);u4r=r(Lee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),LH=n(Lee,"A",{href:!0});var TEt=s(LH);b4r=r(TEt,"from_pretrained()"),TEt.forEach(t),v4r=r(Lee," class method or the "),xH=n(Lee,"A",{href:!0});var MEt=s(xH);F4r=r(MEt,"from_config()"),MEt.forEach(t),T4r=r(Lee,` class
method.`),Lee.forEach(t),M4r=i(Cl),j8=n(Cl,"P",{});var NGe=s(j8);E4r=r(NGe,"This class cannot be instantiated directly using "),b4e=n(NGe,"CODE",{});var EEt=s(b4e);C4r=r(EEt,"__init__()"),EEt.forEach(t),w4r=r(NGe," (throws an error)."),NGe.forEach(t),A4r=i(Cl),St=n(Cl,"DIV",{class:!0});var j0=s(St);T(D8.$$.fragment,j0),y4r=i(j0),v4e=n(j0,"P",{});var CEt=s(v4e);L4r=r(CEt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),CEt.forEach(t),x4r=i(j0),nc=n(j0,"P",{});var xee=s(nc);$4r=r(xee,`Note:
Loading a model from its configuration file does `),F4e=n(xee,"STRONG",{});var wEt=s(F4e);k4r=r(wEt,"not"),wEt.forEach(t),S4r=r(xee,` load the model weights. It only affects the
model\u2019s configuration. Use `),$H=n(xee,"A",{href:!0});var AEt=s($H);R4r=r(AEt,"from_pretrained()"),AEt.forEach(t),P4r=r(xee," to load the model weights."),xee.forEach(t),B4r=i(j0),T(pM.$$.fragment,j0),j0.forEach(t),I4r=i(Cl),$r=n(Cl,"DIV",{class:!0});var wl=s($r);T(G8.$$.fragment,wl),N4r=i(wl),T4e=n(wl,"P",{});var yEt=s(T4e);q4r=r(yEt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),yEt.forEach(t),j4r=i(wl),an=n(wl,"P",{});var D0=s(an);D4r=r(D0,"The model class to instantiate is selected based on the "),M4e=n(D0,"CODE",{});var LEt=s(M4e);G4r=r(LEt,"model_type"),LEt.forEach(t),O4r=r(D0,` property of the config object (either
passed as an argument or loaded from `),E4e=n(D0,"CODE",{});var xEt=s(E4e);V4r=r(xEt,"pretrained_model_name_or_path"),xEt.forEach(t),X4r=r(D0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C4e=n(D0,"CODE",{});var $Et=s(C4e);z4r=r($Et,"pretrained_model_name_or_path"),$Et.forEach(t),W4r=r(D0,":"),D0.forEach(t),Q4r=i(wl),ye=n(wl,"UL",{});var Be=s(ye);_M=n(Be,"LI",{});var LPe=s(_M);w4e=n(LPe,"STRONG",{});var kEt=s(w4e);H4r=r(kEt,"bart"),kEt.forEach(t),U4r=r(LPe," \u2014 "),kH=n(LPe,"A",{href:!0});var SEt=s(kH);J4r=r(SEt,"TFBartForConditionalGeneration"),SEt.forEach(t),Y4r=r(LPe," (BART model)"),LPe.forEach(t),K4r=i(Be),uM=n(Be,"LI",{});var xPe=s(uM);A4e=n(xPe,"STRONG",{});var REt=s(A4e);Z4r=r(REt,"blenderbot"),REt.forEach(t),evr=r(xPe," \u2014 "),SH=n(xPe,"A",{href:!0});var PEt=s(SH);ovr=r(PEt,"TFBlenderbotForConditionalGeneration"),PEt.forEach(t),rvr=r(xPe," (Blenderbot model)"),xPe.forEach(t),tvr=i(Be),bM=n(Be,"LI",{});var $Pe=s(bM);y4e=n($Pe,"STRONG",{});var BEt=s(y4e);avr=r(BEt,"blenderbot-small"),BEt.forEach(t),nvr=r($Pe," \u2014 "),RH=n($Pe,"A",{href:!0});var IEt=s(RH);svr=r(IEt,"TFBlenderbotSmallForConditionalGeneration"),IEt.forEach(t),lvr=r($Pe," (BlenderbotSmall model)"),$Pe.forEach(t),ivr=i(Be),vM=n(Be,"LI",{});var kPe=s(vM);L4e=n(kPe,"STRONG",{});var NEt=s(L4e);dvr=r(NEt,"encoder-decoder"),NEt.forEach(t),cvr=r(kPe," \u2014 "),PH=n(kPe,"A",{href:!0});var qEt=s(PH);fvr=r(qEt,"TFEncoderDecoderModel"),qEt.forEach(t),mvr=r(kPe," (Encoder decoder model)"),kPe.forEach(t),gvr=i(Be),FM=n(Be,"LI",{});var SPe=s(FM);x4e=n(SPe,"STRONG",{});var jEt=s(x4e);hvr=r(jEt,"led"),jEt.forEach(t),pvr=r(SPe," \u2014 "),BH=n(SPe,"A",{href:!0});var DEt=s(BH);_vr=r(DEt,"TFLEDForConditionalGeneration"),DEt.forEach(t),uvr=r(SPe," (LED model)"),SPe.forEach(t),bvr=i(Be),TM=n(Be,"LI",{});var RPe=s(TM);$4e=n(RPe,"STRONG",{});var GEt=s($4e);vvr=r(GEt,"marian"),GEt.forEach(t),Fvr=r(RPe," \u2014 "),IH=n(RPe,"A",{href:!0});var OEt=s(IH);Tvr=r(OEt,"TFMarianMTModel"),OEt.forEach(t),Mvr=r(RPe," (Marian model)"),RPe.forEach(t),Evr=i(Be),MM=n(Be,"LI",{});var PPe=s(MM);k4e=n(PPe,"STRONG",{});var VEt=s(k4e);Cvr=r(VEt,"mbart"),VEt.forEach(t),wvr=r(PPe," \u2014 "),NH=n(PPe,"A",{href:!0});var XEt=s(NH);Avr=r(XEt,"TFMBartForConditionalGeneration"),XEt.forEach(t),yvr=r(PPe," (mBART model)"),PPe.forEach(t),Lvr=i(Be),EM=n(Be,"LI",{});var BPe=s(EM);S4e=n(BPe,"STRONG",{});var zEt=s(S4e);xvr=r(zEt,"mt5"),zEt.forEach(t),$vr=r(BPe," \u2014 "),qH=n(BPe,"A",{href:!0});var WEt=s(qH);kvr=r(WEt,"TFMT5ForConditionalGeneration"),WEt.forEach(t),Svr=r(BPe," (mT5 model)"),BPe.forEach(t),Rvr=i(Be),CM=n(Be,"LI",{});var IPe=s(CM);R4e=n(IPe,"STRONG",{});var QEt=s(R4e);Pvr=r(QEt,"pegasus"),QEt.forEach(t),Bvr=r(IPe," \u2014 "),jH=n(IPe,"A",{href:!0});var HEt=s(jH);Ivr=r(HEt,"TFPegasusForConditionalGeneration"),HEt.forEach(t),Nvr=r(IPe," (Pegasus model)"),IPe.forEach(t),qvr=i(Be),wM=n(Be,"LI",{});var NPe=s(wM);P4e=n(NPe,"STRONG",{});var UEt=s(P4e);jvr=r(UEt,"t5"),UEt.forEach(t),Dvr=r(NPe," \u2014 "),DH=n(NPe,"A",{href:!0});var JEt=s(DH);Gvr=r(JEt,"TFT5ForConditionalGeneration"),JEt.forEach(t),Ovr=r(NPe," (T5 model)"),NPe.forEach(t),Be.forEach(t),Vvr=i(wl),T(AM.$$.fragment,wl),wl.forEach(t),Cl.forEach(t),Sje=i(f),sc=n(f,"H2",{class:!0});var qGe=s(sc);yM=n(qGe,"A",{id:!0,class:!0,href:!0});var YEt=s(yM);B4e=n(YEt,"SPAN",{});var KEt=s(B4e);T(O8.$$.fragment,KEt),KEt.forEach(t),YEt.forEach(t),Xvr=i(qGe),I4e=n(qGe,"SPAN",{});var ZEt=s(I4e);zvr=r(ZEt,"TFAutoModelForSequenceClassification"),ZEt.forEach(t),qGe.forEach(t),Rje=i(f),tr=n(f,"DIV",{class:!0});var Al=s(tr);T(V8.$$.fragment,Al),Wvr=i(Al),lc=n(Al,"P",{});var $ee=s(lc);Qvr=r($ee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),GH=n($ee,"A",{href:!0});var eCt=s(GH);Hvr=r(eCt,"from_pretrained()"),eCt.forEach(t),Uvr=r($ee," class method or the "),OH=n($ee,"A",{href:!0});var oCt=s(OH);Jvr=r(oCt,"from_config()"),oCt.forEach(t),Yvr=r($ee,` class
method.`),$ee.forEach(t),Kvr=i(Al),X8=n(Al,"P",{});var jGe=s(X8);Zvr=r(jGe,"This class cannot be instantiated directly using "),N4e=n(jGe,"CODE",{});var rCt=s(N4e);eFr=r(rCt,"__init__()"),rCt.forEach(t),oFr=r(jGe," (throws an error)."),jGe.forEach(t),rFr=i(Al),Rt=n(Al,"DIV",{class:!0});var G0=s(Rt);T(z8.$$.fragment,G0),tFr=i(G0),q4e=n(G0,"P",{});var tCt=s(q4e);aFr=r(tCt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),tCt.forEach(t),nFr=i(G0),ic=n(G0,"P",{});var kee=s(ic);sFr=r(kee,`Note:
Loading a model from its configuration file does `),j4e=n(kee,"STRONG",{});var aCt=s(j4e);lFr=r(aCt,"not"),aCt.forEach(t),iFr=r(kee,` load the model weights. It only affects the
model\u2019s configuration. Use `),VH=n(kee,"A",{href:!0});var nCt=s(VH);dFr=r(nCt,"from_pretrained()"),nCt.forEach(t),cFr=r(kee," to load the model weights."),kee.forEach(t),fFr=i(G0),T(LM.$$.fragment,G0),G0.forEach(t),mFr=i(Al),kr=n(Al,"DIV",{class:!0});var yl=s(kr);T(W8.$$.fragment,yl),gFr=i(yl),D4e=n(yl,"P",{});var sCt=s(D4e);hFr=r(sCt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),sCt.forEach(t),pFr=i(yl),nn=n(yl,"P",{});var O0=s(nn);_Fr=r(O0,"The model class to instantiate is selected based on the "),G4e=n(O0,"CODE",{});var lCt=s(G4e);uFr=r(lCt,"model_type"),lCt.forEach(t),bFr=r(O0,` property of the config object (either
passed as an argument or loaded from `),O4e=n(O0,"CODE",{});var iCt=s(O4e);vFr=r(iCt,"pretrained_model_name_or_path"),iCt.forEach(t),FFr=r(O0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V4e=n(O0,"CODE",{});var dCt=s(V4e);TFr=r(dCt,"pretrained_model_name_or_path"),dCt.forEach(t),MFr=r(O0,":"),O0.forEach(t),EFr=i(yl),oe=n(yl,"UL",{});var ae=s(oe);xM=n(ae,"LI",{});var qPe=s(xM);X4e=n(qPe,"STRONG",{});var cCt=s(X4e);CFr=r(cCt,"albert"),cCt.forEach(t),wFr=r(qPe," \u2014 "),XH=n(qPe,"A",{href:!0});var fCt=s(XH);AFr=r(fCt,"TFAlbertForSequenceClassification"),fCt.forEach(t),yFr=r(qPe," (ALBERT model)"),qPe.forEach(t),LFr=i(ae),$M=n(ae,"LI",{});var jPe=s($M);z4e=n(jPe,"STRONG",{});var mCt=s(z4e);xFr=r(mCt,"bert"),mCt.forEach(t),$Fr=r(jPe," \u2014 "),zH=n(jPe,"A",{href:!0});var gCt=s(zH);kFr=r(gCt,"TFBertForSequenceClassification"),gCt.forEach(t),SFr=r(jPe," (BERT model)"),jPe.forEach(t),RFr=i(ae),kM=n(ae,"LI",{});var DPe=s(kM);W4e=n(DPe,"STRONG",{});var hCt=s(W4e);PFr=r(hCt,"camembert"),hCt.forEach(t),BFr=r(DPe," \u2014 "),WH=n(DPe,"A",{href:!0});var pCt=s(WH);IFr=r(pCt,"TFCamembertForSequenceClassification"),pCt.forEach(t),NFr=r(DPe," (CamemBERT model)"),DPe.forEach(t),qFr=i(ae),SM=n(ae,"LI",{});var GPe=s(SM);Q4e=n(GPe,"STRONG",{});var _Ct=s(Q4e);jFr=r(_Ct,"convbert"),_Ct.forEach(t),DFr=r(GPe," \u2014 "),QH=n(GPe,"A",{href:!0});var uCt=s(QH);GFr=r(uCt,"TFConvBertForSequenceClassification"),uCt.forEach(t),OFr=r(GPe," (ConvBERT model)"),GPe.forEach(t),VFr=i(ae),RM=n(ae,"LI",{});var OPe=s(RM);H4e=n(OPe,"STRONG",{});var bCt=s(H4e);XFr=r(bCt,"ctrl"),bCt.forEach(t),zFr=r(OPe," \u2014 "),HH=n(OPe,"A",{href:!0});var vCt=s(HH);WFr=r(vCt,"TFCTRLForSequenceClassification"),vCt.forEach(t),QFr=r(OPe," (CTRL model)"),OPe.forEach(t),HFr=i(ae),PM=n(ae,"LI",{});var VPe=s(PM);U4e=n(VPe,"STRONG",{});var FCt=s(U4e);UFr=r(FCt,"deberta"),FCt.forEach(t),JFr=r(VPe," \u2014 "),UH=n(VPe,"A",{href:!0});var TCt=s(UH);YFr=r(TCt,"TFDebertaForSequenceClassification"),TCt.forEach(t),KFr=r(VPe," (DeBERTa model)"),VPe.forEach(t),ZFr=i(ae),BM=n(ae,"LI",{});var XPe=s(BM);J4e=n(XPe,"STRONG",{});var MCt=s(J4e);eTr=r(MCt,"deberta-v2"),MCt.forEach(t),oTr=r(XPe," \u2014 "),JH=n(XPe,"A",{href:!0});var ECt=s(JH);rTr=r(ECt,"TFDebertaV2ForSequenceClassification"),ECt.forEach(t),tTr=r(XPe," (DeBERTa-v2 model)"),XPe.forEach(t),aTr=i(ae),IM=n(ae,"LI",{});var zPe=s(IM);Y4e=n(zPe,"STRONG",{});var CCt=s(Y4e);nTr=r(CCt,"distilbert"),CCt.forEach(t),sTr=r(zPe," \u2014 "),YH=n(zPe,"A",{href:!0});var wCt=s(YH);lTr=r(wCt,"TFDistilBertForSequenceClassification"),wCt.forEach(t),iTr=r(zPe," (DistilBERT model)"),zPe.forEach(t),dTr=i(ae),NM=n(ae,"LI",{});var WPe=s(NM);K4e=n(WPe,"STRONG",{});var ACt=s(K4e);cTr=r(ACt,"electra"),ACt.forEach(t),fTr=r(WPe," \u2014 "),KH=n(WPe,"A",{href:!0});var yCt=s(KH);mTr=r(yCt,"TFElectraForSequenceClassification"),yCt.forEach(t),gTr=r(WPe," (ELECTRA model)"),WPe.forEach(t),hTr=i(ae),qM=n(ae,"LI",{});var QPe=s(qM);Z4e=n(QPe,"STRONG",{});var LCt=s(Z4e);pTr=r(LCt,"flaubert"),LCt.forEach(t),_Tr=r(QPe," \u2014 "),ZH=n(QPe,"A",{href:!0});var xCt=s(ZH);uTr=r(xCt,"TFFlaubertForSequenceClassification"),xCt.forEach(t),bTr=r(QPe," (FlauBERT model)"),QPe.forEach(t),vTr=i(ae),jM=n(ae,"LI",{});var HPe=s(jM);eve=n(HPe,"STRONG",{});var $Ct=s(eve);FTr=r($Ct,"funnel"),$Ct.forEach(t),TTr=r(HPe," \u2014 "),eU=n(HPe,"A",{href:!0});var kCt=s(eU);MTr=r(kCt,"TFFunnelForSequenceClassification"),kCt.forEach(t),ETr=r(HPe," (Funnel Transformer model)"),HPe.forEach(t),CTr=i(ae),DM=n(ae,"LI",{});var UPe=s(DM);ove=n(UPe,"STRONG",{});var SCt=s(ove);wTr=r(SCt,"gpt2"),SCt.forEach(t),ATr=r(UPe," \u2014 "),oU=n(UPe,"A",{href:!0});var RCt=s(oU);yTr=r(RCt,"TFGPT2ForSequenceClassification"),RCt.forEach(t),LTr=r(UPe," (OpenAI GPT-2 model)"),UPe.forEach(t),xTr=i(ae),GM=n(ae,"LI",{});var JPe=s(GM);rve=n(JPe,"STRONG",{});var PCt=s(rve);$Tr=r(PCt,"gptj"),PCt.forEach(t),kTr=r(JPe," \u2014 "),rU=n(JPe,"A",{href:!0});var BCt=s(rU);STr=r(BCt,"TFGPTJForSequenceClassification"),BCt.forEach(t),RTr=r(JPe," (GPT-J model)"),JPe.forEach(t),PTr=i(ae),OM=n(ae,"LI",{});var YPe=s(OM);tve=n(YPe,"STRONG",{});var ICt=s(tve);BTr=r(ICt,"layoutlm"),ICt.forEach(t),ITr=r(YPe," \u2014 "),tU=n(YPe,"A",{href:!0});var NCt=s(tU);NTr=r(NCt,"TFLayoutLMForSequenceClassification"),NCt.forEach(t),qTr=r(YPe," (LayoutLM model)"),YPe.forEach(t),jTr=i(ae),VM=n(ae,"LI",{});var KPe=s(VM);ave=n(KPe,"STRONG",{});var qCt=s(ave);DTr=r(qCt,"longformer"),qCt.forEach(t),GTr=r(KPe," \u2014 "),aU=n(KPe,"A",{href:!0});var jCt=s(aU);OTr=r(jCt,"TFLongformerForSequenceClassification"),jCt.forEach(t),VTr=r(KPe," (Longformer model)"),KPe.forEach(t),XTr=i(ae),XM=n(ae,"LI",{});var ZPe=s(XM);nve=n(ZPe,"STRONG",{});var DCt=s(nve);zTr=r(DCt,"mobilebert"),DCt.forEach(t),WTr=r(ZPe," \u2014 "),nU=n(ZPe,"A",{href:!0});var GCt=s(nU);QTr=r(GCt,"TFMobileBertForSequenceClassification"),GCt.forEach(t),HTr=r(ZPe," (MobileBERT model)"),ZPe.forEach(t),UTr=i(ae),zM=n(ae,"LI",{});var eBe=s(zM);sve=n(eBe,"STRONG",{});var OCt=s(sve);JTr=r(OCt,"mpnet"),OCt.forEach(t),YTr=r(eBe," \u2014 "),sU=n(eBe,"A",{href:!0});var VCt=s(sU);KTr=r(VCt,"TFMPNetForSequenceClassification"),VCt.forEach(t),ZTr=r(eBe," (MPNet model)"),eBe.forEach(t),e7r=i(ae),WM=n(ae,"LI",{});var oBe=s(WM);lve=n(oBe,"STRONG",{});var XCt=s(lve);o7r=r(XCt,"openai-gpt"),XCt.forEach(t),r7r=r(oBe," \u2014 "),lU=n(oBe,"A",{href:!0});var zCt=s(lU);t7r=r(zCt,"TFOpenAIGPTForSequenceClassification"),zCt.forEach(t),a7r=r(oBe," (OpenAI GPT model)"),oBe.forEach(t),n7r=i(ae),QM=n(ae,"LI",{});var rBe=s(QM);ive=n(rBe,"STRONG",{});var WCt=s(ive);s7r=r(WCt,"rembert"),WCt.forEach(t),l7r=r(rBe," \u2014 "),iU=n(rBe,"A",{href:!0});var QCt=s(iU);i7r=r(QCt,"TFRemBertForSequenceClassification"),QCt.forEach(t),d7r=r(rBe," (RemBERT model)"),rBe.forEach(t),c7r=i(ae),HM=n(ae,"LI",{});var tBe=s(HM);dve=n(tBe,"STRONG",{});var HCt=s(dve);f7r=r(HCt,"roberta"),HCt.forEach(t),m7r=r(tBe," \u2014 "),dU=n(tBe,"A",{href:!0});var UCt=s(dU);g7r=r(UCt,"TFRobertaForSequenceClassification"),UCt.forEach(t),h7r=r(tBe," (RoBERTa model)"),tBe.forEach(t),p7r=i(ae),UM=n(ae,"LI",{});var aBe=s(UM);cve=n(aBe,"STRONG",{});var JCt=s(cve);_7r=r(JCt,"roformer"),JCt.forEach(t),u7r=r(aBe," \u2014 "),cU=n(aBe,"A",{href:!0});var YCt=s(cU);b7r=r(YCt,"TFRoFormerForSequenceClassification"),YCt.forEach(t),v7r=r(aBe," (RoFormer model)"),aBe.forEach(t),F7r=i(ae),JM=n(ae,"LI",{});var nBe=s(JM);fve=n(nBe,"STRONG",{});var KCt=s(fve);T7r=r(KCt,"tapas"),KCt.forEach(t),M7r=r(nBe," \u2014 "),fU=n(nBe,"A",{href:!0});var ZCt=s(fU);E7r=r(ZCt,"TFTapasForSequenceClassification"),ZCt.forEach(t),C7r=r(nBe," (TAPAS model)"),nBe.forEach(t),w7r=i(ae),YM=n(ae,"LI",{});var sBe=s(YM);mve=n(sBe,"STRONG",{});var e5t=s(mve);A7r=r(e5t,"transfo-xl"),e5t.forEach(t),y7r=r(sBe," \u2014 "),mU=n(sBe,"A",{href:!0});var o5t=s(mU);L7r=r(o5t,"TFTransfoXLForSequenceClassification"),o5t.forEach(t),x7r=r(sBe," (Transformer-XL model)"),sBe.forEach(t),$7r=i(ae),KM=n(ae,"LI",{});var lBe=s(KM);gve=n(lBe,"STRONG",{});var r5t=s(gve);k7r=r(r5t,"xlm"),r5t.forEach(t),S7r=r(lBe," \u2014 "),gU=n(lBe,"A",{href:!0});var t5t=s(gU);R7r=r(t5t,"TFXLMForSequenceClassification"),t5t.forEach(t),P7r=r(lBe," (XLM model)"),lBe.forEach(t),B7r=i(ae),ZM=n(ae,"LI",{});var iBe=s(ZM);hve=n(iBe,"STRONG",{});var a5t=s(hve);I7r=r(a5t,"xlm-roberta"),a5t.forEach(t),N7r=r(iBe," \u2014 "),hU=n(iBe,"A",{href:!0});var n5t=s(hU);q7r=r(n5t,"TFXLMRobertaForSequenceClassification"),n5t.forEach(t),j7r=r(iBe," (XLM-RoBERTa model)"),iBe.forEach(t),D7r=i(ae),eE=n(ae,"LI",{});var dBe=s(eE);pve=n(dBe,"STRONG",{});var s5t=s(pve);G7r=r(s5t,"xlnet"),s5t.forEach(t),O7r=r(dBe," \u2014 "),pU=n(dBe,"A",{href:!0});var l5t=s(pU);V7r=r(l5t,"TFXLNetForSequenceClassification"),l5t.forEach(t),X7r=r(dBe," (XLNet model)"),dBe.forEach(t),ae.forEach(t),z7r=i(yl),T(oE.$$.fragment,yl),yl.forEach(t),Al.forEach(t),Pje=i(f),dc=n(f,"H2",{class:!0});var DGe=s(dc);rE=n(DGe,"A",{id:!0,class:!0,href:!0});var i5t=s(rE);_ve=n(i5t,"SPAN",{});var d5t=s(_ve);T(Q8.$$.fragment,d5t),d5t.forEach(t),i5t.forEach(t),W7r=i(DGe),uve=n(DGe,"SPAN",{});var c5t=s(uve);Q7r=r(c5t,"TFAutoModelForMultipleChoice"),c5t.forEach(t),DGe.forEach(t),Bje=i(f),ar=n(f,"DIV",{class:!0});var Ll=s(ar);T(H8.$$.fragment,Ll),H7r=i(Ll),cc=n(Ll,"P",{});var See=s(cc);U7r=r(See,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),_U=n(See,"A",{href:!0});var f5t=s(_U);J7r=r(f5t,"from_pretrained()"),f5t.forEach(t),Y7r=r(See," class method or the "),uU=n(See,"A",{href:!0});var m5t=s(uU);K7r=r(m5t,"from_config()"),m5t.forEach(t),Z7r=r(See,` class
method.`),See.forEach(t),eMr=i(Ll),U8=n(Ll,"P",{});var GGe=s(U8);oMr=r(GGe,"This class cannot be instantiated directly using "),bve=n(GGe,"CODE",{});var g5t=s(bve);rMr=r(g5t,"__init__()"),g5t.forEach(t),tMr=r(GGe," (throws an error)."),GGe.forEach(t),aMr=i(Ll),Pt=n(Ll,"DIV",{class:!0});var V0=s(Pt);T(J8.$$.fragment,V0),nMr=i(V0),vve=n(V0,"P",{});var h5t=s(vve);sMr=r(h5t,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),h5t.forEach(t),lMr=i(V0),fc=n(V0,"P",{});var Ree=s(fc);iMr=r(Ree,`Note:
Loading a model from its configuration file does `),Fve=n(Ree,"STRONG",{});var p5t=s(Fve);dMr=r(p5t,"not"),p5t.forEach(t),cMr=r(Ree,` load the model weights. It only affects the
model\u2019s configuration. Use `),bU=n(Ree,"A",{href:!0});var _5t=s(bU);fMr=r(_5t,"from_pretrained()"),_5t.forEach(t),mMr=r(Ree," to load the model weights."),Ree.forEach(t),gMr=i(V0),T(tE.$$.fragment,V0),V0.forEach(t),hMr=i(Ll),Sr=n(Ll,"DIV",{class:!0});var xl=s(Sr);T(Y8.$$.fragment,xl),pMr=i(xl),Tve=n(xl,"P",{});var u5t=s(Tve);_Mr=r(u5t,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),u5t.forEach(t),uMr=i(xl),sn=n(xl,"P",{});var X0=s(sn);bMr=r(X0,"The model class to instantiate is selected based on the "),Mve=n(X0,"CODE",{});var b5t=s(Mve);vMr=r(b5t,"model_type"),b5t.forEach(t),FMr=r(X0,` property of the config object (either
passed as an argument or loaded from `),Eve=n(X0,"CODE",{});var v5t=s(Eve);TMr=r(v5t,"pretrained_model_name_or_path"),v5t.forEach(t),MMr=r(X0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cve=n(X0,"CODE",{});var F5t=s(Cve);EMr=r(F5t,"pretrained_model_name_or_path"),F5t.forEach(t),CMr=r(X0,":"),X0.forEach(t),wMr=i(xl),pe=n(xl,"UL",{});var be=s(pe);aE=n(be,"LI",{});var cBe=s(aE);wve=n(cBe,"STRONG",{});var T5t=s(wve);AMr=r(T5t,"albert"),T5t.forEach(t),yMr=r(cBe," \u2014 "),vU=n(cBe,"A",{href:!0});var M5t=s(vU);LMr=r(M5t,"TFAlbertForMultipleChoice"),M5t.forEach(t),xMr=r(cBe," (ALBERT model)"),cBe.forEach(t),$Mr=i(be),nE=n(be,"LI",{});var fBe=s(nE);Ave=n(fBe,"STRONG",{});var E5t=s(Ave);kMr=r(E5t,"bert"),E5t.forEach(t),SMr=r(fBe," \u2014 "),FU=n(fBe,"A",{href:!0});var C5t=s(FU);RMr=r(C5t,"TFBertForMultipleChoice"),C5t.forEach(t),PMr=r(fBe," (BERT model)"),fBe.forEach(t),BMr=i(be),sE=n(be,"LI",{});var mBe=s(sE);yve=n(mBe,"STRONG",{});var w5t=s(yve);IMr=r(w5t,"camembert"),w5t.forEach(t),NMr=r(mBe," \u2014 "),TU=n(mBe,"A",{href:!0});var A5t=s(TU);qMr=r(A5t,"TFCamembertForMultipleChoice"),A5t.forEach(t),jMr=r(mBe," (CamemBERT model)"),mBe.forEach(t),DMr=i(be),lE=n(be,"LI",{});var gBe=s(lE);Lve=n(gBe,"STRONG",{});var y5t=s(Lve);GMr=r(y5t,"convbert"),y5t.forEach(t),OMr=r(gBe," \u2014 "),MU=n(gBe,"A",{href:!0});var L5t=s(MU);VMr=r(L5t,"TFConvBertForMultipleChoice"),L5t.forEach(t),XMr=r(gBe," (ConvBERT model)"),gBe.forEach(t),zMr=i(be),iE=n(be,"LI",{});var hBe=s(iE);xve=n(hBe,"STRONG",{});var x5t=s(xve);WMr=r(x5t,"distilbert"),x5t.forEach(t),QMr=r(hBe," \u2014 "),EU=n(hBe,"A",{href:!0});var $5t=s(EU);HMr=r($5t,"TFDistilBertForMultipleChoice"),$5t.forEach(t),UMr=r(hBe," (DistilBERT model)"),hBe.forEach(t),JMr=i(be),dE=n(be,"LI",{});var pBe=s(dE);$ve=n(pBe,"STRONG",{});var k5t=s($ve);YMr=r(k5t,"electra"),k5t.forEach(t),KMr=r(pBe," \u2014 "),CU=n(pBe,"A",{href:!0});var S5t=s(CU);ZMr=r(S5t,"TFElectraForMultipleChoice"),S5t.forEach(t),eEr=r(pBe," (ELECTRA model)"),pBe.forEach(t),oEr=i(be),cE=n(be,"LI",{});var _Be=s(cE);kve=n(_Be,"STRONG",{});var R5t=s(kve);rEr=r(R5t,"flaubert"),R5t.forEach(t),tEr=r(_Be," \u2014 "),wU=n(_Be,"A",{href:!0});var P5t=s(wU);aEr=r(P5t,"TFFlaubertForMultipleChoice"),P5t.forEach(t),nEr=r(_Be," (FlauBERT model)"),_Be.forEach(t),sEr=i(be),fE=n(be,"LI",{});var uBe=s(fE);Sve=n(uBe,"STRONG",{});var B5t=s(Sve);lEr=r(B5t,"funnel"),B5t.forEach(t),iEr=r(uBe," \u2014 "),AU=n(uBe,"A",{href:!0});var I5t=s(AU);dEr=r(I5t,"TFFunnelForMultipleChoice"),I5t.forEach(t),cEr=r(uBe," (Funnel Transformer model)"),uBe.forEach(t),fEr=i(be),mE=n(be,"LI",{});var bBe=s(mE);Rve=n(bBe,"STRONG",{});var N5t=s(Rve);mEr=r(N5t,"longformer"),N5t.forEach(t),gEr=r(bBe," \u2014 "),yU=n(bBe,"A",{href:!0});var q5t=s(yU);hEr=r(q5t,"TFLongformerForMultipleChoice"),q5t.forEach(t),pEr=r(bBe," (Longformer model)"),bBe.forEach(t),_Er=i(be),gE=n(be,"LI",{});var vBe=s(gE);Pve=n(vBe,"STRONG",{});var j5t=s(Pve);uEr=r(j5t,"mobilebert"),j5t.forEach(t),bEr=r(vBe," \u2014 "),LU=n(vBe,"A",{href:!0});var D5t=s(LU);vEr=r(D5t,"TFMobileBertForMultipleChoice"),D5t.forEach(t),FEr=r(vBe," (MobileBERT model)"),vBe.forEach(t),TEr=i(be),hE=n(be,"LI",{});var FBe=s(hE);Bve=n(FBe,"STRONG",{});var G5t=s(Bve);MEr=r(G5t,"mpnet"),G5t.forEach(t),EEr=r(FBe," \u2014 "),xU=n(FBe,"A",{href:!0});var O5t=s(xU);CEr=r(O5t,"TFMPNetForMultipleChoice"),O5t.forEach(t),wEr=r(FBe," (MPNet model)"),FBe.forEach(t),AEr=i(be),pE=n(be,"LI",{});var TBe=s(pE);Ive=n(TBe,"STRONG",{});var V5t=s(Ive);yEr=r(V5t,"rembert"),V5t.forEach(t),LEr=r(TBe," \u2014 "),$U=n(TBe,"A",{href:!0});var X5t=s($U);xEr=r(X5t,"TFRemBertForMultipleChoice"),X5t.forEach(t),$Er=r(TBe," (RemBERT model)"),TBe.forEach(t),kEr=i(be),_E=n(be,"LI",{});var MBe=s(_E);Nve=n(MBe,"STRONG",{});var z5t=s(Nve);SEr=r(z5t,"roberta"),z5t.forEach(t),REr=r(MBe," \u2014 "),kU=n(MBe,"A",{href:!0});var W5t=s(kU);PEr=r(W5t,"TFRobertaForMultipleChoice"),W5t.forEach(t),BEr=r(MBe," (RoBERTa model)"),MBe.forEach(t),IEr=i(be),uE=n(be,"LI",{});var EBe=s(uE);qve=n(EBe,"STRONG",{});var Q5t=s(qve);NEr=r(Q5t,"roformer"),Q5t.forEach(t),qEr=r(EBe," \u2014 "),SU=n(EBe,"A",{href:!0});var H5t=s(SU);jEr=r(H5t,"TFRoFormerForMultipleChoice"),H5t.forEach(t),DEr=r(EBe," (RoFormer model)"),EBe.forEach(t),GEr=i(be),bE=n(be,"LI",{});var CBe=s(bE);jve=n(CBe,"STRONG",{});var U5t=s(jve);OEr=r(U5t,"xlm"),U5t.forEach(t),VEr=r(CBe," \u2014 "),RU=n(CBe,"A",{href:!0});var J5t=s(RU);XEr=r(J5t,"TFXLMForMultipleChoice"),J5t.forEach(t),zEr=r(CBe," (XLM model)"),CBe.forEach(t),WEr=i(be),vE=n(be,"LI",{});var wBe=s(vE);Dve=n(wBe,"STRONG",{});var Y5t=s(Dve);QEr=r(Y5t,"xlm-roberta"),Y5t.forEach(t),HEr=r(wBe," \u2014 "),PU=n(wBe,"A",{href:!0});var K5t=s(PU);UEr=r(K5t,"TFXLMRobertaForMultipleChoice"),K5t.forEach(t),JEr=r(wBe," (XLM-RoBERTa model)"),wBe.forEach(t),YEr=i(be),FE=n(be,"LI",{});var ABe=s(FE);Gve=n(ABe,"STRONG",{});var Z5t=s(Gve);KEr=r(Z5t,"xlnet"),Z5t.forEach(t),ZEr=r(ABe," \u2014 "),BU=n(ABe,"A",{href:!0});var e3t=s(BU);eCr=r(e3t,"TFXLNetForMultipleChoice"),e3t.forEach(t),oCr=r(ABe," (XLNet model)"),ABe.forEach(t),be.forEach(t),rCr=i(xl),T(TE.$$.fragment,xl),xl.forEach(t),Ll.forEach(t),Ije=i(f),mc=n(f,"H2",{class:!0});var OGe=s(mc);ME=n(OGe,"A",{id:!0,class:!0,href:!0});var o3t=s(ME);Ove=n(o3t,"SPAN",{});var r3t=s(Ove);T(K8.$$.fragment,r3t),r3t.forEach(t),o3t.forEach(t),tCr=i(OGe),Vve=n(OGe,"SPAN",{});var t3t=s(Vve);aCr=r(t3t,"TFAutoModelForNextSentencePrediction"),t3t.forEach(t),OGe.forEach(t),Nje=i(f),nr=n(f,"DIV",{class:!0});var $l=s(nr);T(Z8.$$.fragment,$l),nCr=i($l),gc=n($l,"P",{});var Pee=s(gc);sCr=r(Pee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),IU=n(Pee,"A",{href:!0});var a3t=s(IU);lCr=r(a3t,"from_pretrained()"),a3t.forEach(t),iCr=r(Pee," class method or the "),NU=n(Pee,"A",{href:!0});var n3t=s(NU);dCr=r(n3t,"from_config()"),n3t.forEach(t),cCr=r(Pee,` class
method.`),Pee.forEach(t),fCr=i($l),e9=n($l,"P",{});var VGe=s(e9);mCr=r(VGe,"This class cannot be instantiated directly using "),Xve=n(VGe,"CODE",{});var s3t=s(Xve);gCr=r(s3t,"__init__()"),s3t.forEach(t),hCr=r(VGe," (throws an error)."),VGe.forEach(t),pCr=i($l),Bt=n($l,"DIV",{class:!0});var z0=s(Bt);T(o9.$$.fragment,z0),_Cr=i(z0),zve=n(z0,"P",{});var l3t=s(zve);uCr=r(l3t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),l3t.forEach(t),bCr=i(z0),hc=n(z0,"P",{});var Bee=s(hc);vCr=r(Bee,`Note:
Loading a model from its configuration file does `),Wve=n(Bee,"STRONG",{});var i3t=s(Wve);FCr=r(i3t,"not"),i3t.forEach(t),TCr=r(Bee,` load the model weights. It only affects the
model\u2019s configuration. Use `),qU=n(Bee,"A",{href:!0});var d3t=s(qU);MCr=r(d3t,"from_pretrained()"),d3t.forEach(t),ECr=r(Bee," to load the model weights."),Bee.forEach(t),CCr=i(z0),T(EE.$$.fragment,z0),z0.forEach(t),wCr=i($l),Rr=n($l,"DIV",{class:!0});var kl=s(Rr);T(r9.$$.fragment,kl),ACr=i(kl),Qve=n(kl,"P",{});var c3t=s(Qve);yCr=r(c3t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),c3t.forEach(t),LCr=i(kl),ln=n(kl,"P",{});var W0=s(ln);xCr=r(W0,"The model class to instantiate is selected based on the "),Hve=n(W0,"CODE",{});var f3t=s(Hve);$Cr=r(f3t,"model_type"),f3t.forEach(t),kCr=r(W0,` property of the config object (either
passed as an argument or loaded from `),Uve=n(W0,"CODE",{});var m3t=s(Uve);SCr=r(m3t,"pretrained_model_name_or_path"),m3t.forEach(t),RCr=r(W0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jve=n(W0,"CODE",{});var g3t=s(Jve);PCr=r(g3t,"pretrained_model_name_or_path"),g3t.forEach(t),BCr=r(W0,":"),W0.forEach(t),ICr=i(kl),t9=n(kl,"UL",{});var XGe=s(t9);CE=n(XGe,"LI",{});var yBe=s(CE);Yve=n(yBe,"STRONG",{});var h3t=s(Yve);NCr=r(h3t,"bert"),h3t.forEach(t),qCr=r(yBe," \u2014 "),jU=n(yBe,"A",{href:!0});var p3t=s(jU);jCr=r(p3t,"TFBertForNextSentencePrediction"),p3t.forEach(t),DCr=r(yBe," (BERT model)"),yBe.forEach(t),GCr=i(XGe),wE=n(XGe,"LI",{});var LBe=s(wE);Kve=n(LBe,"STRONG",{});var _3t=s(Kve);OCr=r(_3t,"mobilebert"),_3t.forEach(t),VCr=r(LBe," \u2014 "),DU=n(LBe,"A",{href:!0});var u3t=s(DU);XCr=r(u3t,"TFMobileBertForNextSentencePrediction"),u3t.forEach(t),zCr=r(LBe," (MobileBERT model)"),LBe.forEach(t),XGe.forEach(t),WCr=i(kl),T(AE.$$.fragment,kl),kl.forEach(t),$l.forEach(t),qje=i(f),pc=n(f,"H2",{class:!0});var zGe=s(pc);yE=n(zGe,"A",{id:!0,class:!0,href:!0});var b3t=s(yE);Zve=n(b3t,"SPAN",{});var v3t=s(Zve);T(a9.$$.fragment,v3t),v3t.forEach(t),b3t.forEach(t),QCr=i(zGe),eFe=n(zGe,"SPAN",{});var F3t=s(eFe);HCr=r(F3t,"TFAutoModelForTableQuestionAnswering"),F3t.forEach(t),zGe.forEach(t),jje=i(f),sr=n(f,"DIV",{class:!0});var Sl=s(sr);T(n9.$$.fragment,Sl),UCr=i(Sl),_c=n(Sl,"P",{});var Iee=s(_c);JCr=r(Iee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),GU=n(Iee,"A",{href:!0});var T3t=s(GU);YCr=r(T3t,"from_pretrained()"),T3t.forEach(t),KCr=r(Iee," class method or the "),OU=n(Iee,"A",{href:!0});var M3t=s(OU);ZCr=r(M3t,"from_config()"),M3t.forEach(t),e5r=r(Iee,` class
method.`),Iee.forEach(t),o5r=i(Sl),s9=n(Sl,"P",{});var WGe=s(s9);r5r=r(WGe,"This class cannot be instantiated directly using "),oFe=n(WGe,"CODE",{});var E3t=s(oFe);t5r=r(E3t,"__init__()"),E3t.forEach(t),a5r=r(WGe," (throws an error)."),WGe.forEach(t),n5r=i(Sl),It=n(Sl,"DIV",{class:!0});var Q0=s(It);T(l9.$$.fragment,Q0),s5r=i(Q0),rFe=n(Q0,"P",{});var C3t=s(rFe);l5r=r(C3t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),C3t.forEach(t),i5r=i(Q0),uc=n(Q0,"P",{});var Nee=s(uc);d5r=r(Nee,`Note:
Loading a model from its configuration file does `),tFe=n(Nee,"STRONG",{});var w3t=s(tFe);c5r=r(w3t,"not"),w3t.forEach(t),f5r=r(Nee,` load the model weights. It only affects the
model\u2019s configuration. Use `),VU=n(Nee,"A",{href:!0});var A3t=s(VU);m5r=r(A3t,"from_pretrained()"),A3t.forEach(t),g5r=r(Nee," to load the model weights."),Nee.forEach(t),h5r=i(Q0),T(LE.$$.fragment,Q0),Q0.forEach(t),p5r=i(Sl),Pr=n(Sl,"DIV",{class:!0});var Rl=s(Pr);T(i9.$$.fragment,Rl),_5r=i(Rl),aFe=n(Rl,"P",{});var y3t=s(aFe);u5r=r(y3t,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),y3t.forEach(t),b5r=i(Rl),dn=n(Rl,"P",{});var H0=s(dn);v5r=r(H0,"The model class to instantiate is selected based on the "),nFe=n(H0,"CODE",{});var L3t=s(nFe);F5r=r(L3t,"model_type"),L3t.forEach(t),T5r=r(H0,` property of the config object (either
passed as an argument or loaded from `),sFe=n(H0,"CODE",{});var x3t=s(sFe);M5r=r(x3t,"pretrained_model_name_or_path"),x3t.forEach(t),E5r=r(H0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lFe=n(H0,"CODE",{});var $3t=s(lFe);C5r=r($3t,"pretrained_model_name_or_path"),$3t.forEach(t),w5r=r(H0,":"),H0.forEach(t),A5r=i(Rl),iFe=n(Rl,"UL",{});var k3t=s(iFe);xE=n(k3t,"LI",{});var xBe=s(xE);dFe=n(xBe,"STRONG",{});var S3t=s(dFe);y5r=r(S3t,"tapas"),S3t.forEach(t),L5r=r(xBe," \u2014 "),XU=n(xBe,"A",{href:!0});var R3t=s(XU);x5r=r(R3t,"TFTapasForQuestionAnswering"),R3t.forEach(t),$5r=r(xBe," (TAPAS model)"),xBe.forEach(t),k3t.forEach(t),k5r=i(Rl),T($E.$$.fragment,Rl),Rl.forEach(t),Sl.forEach(t),Dje=i(f),bc=n(f,"H2",{class:!0});var QGe=s(bc);kE=n(QGe,"A",{id:!0,class:!0,href:!0});var P3t=s(kE);cFe=n(P3t,"SPAN",{});var B3t=s(cFe);T(d9.$$.fragment,B3t),B3t.forEach(t),P3t.forEach(t),S5r=i(QGe),fFe=n(QGe,"SPAN",{});var I3t=s(fFe);R5r=r(I3t,"TFAutoModelForTokenClassification"),I3t.forEach(t),QGe.forEach(t),Gje=i(f),lr=n(f,"DIV",{class:!0});var Pl=s(lr);T(c9.$$.fragment,Pl),P5r=i(Pl),vc=n(Pl,"P",{});var qee=s(vc);B5r=r(qee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),zU=n(qee,"A",{href:!0});var N3t=s(zU);I5r=r(N3t,"from_pretrained()"),N3t.forEach(t),N5r=r(qee," class method or the "),WU=n(qee,"A",{href:!0});var q3t=s(WU);q5r=r(q3t,"from_config()"),q3t.forEach(t),j5r=r(qee,` class
method.`),qee.forEach(t),D5r=i(Pl),f9=n(Pl,"P",{});var HGe=s(f9);G5r=r(HGe,"This class cannot be instantiated directly using "),mFe=n(HGe,"CODE",{});var j3t=s(mFe);O5r=r(j3t,"__init__()"),j3t.forEach(t),V5r=r(HGe," (throws an error)."),HGe.forEach(t),X5r=i(Pl),Nt=n(Pl,"DIV",{class:!0});var U0=s(Nt);T(m9.$$.fragment,U0),z5r=i(U0),gFe=n(U0,"P",{});var D3t=s(gFe);W5r=r(D3t,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),D3t.forEach(t),Q5r=i(U0),Fc=n(U0,"P",{});var jee=s(Fc);H5r=r(jee,`Note:
Loading a model from its configuration file does `),hFe=n(jee,"STRONG",{});var G3t=s(hFe);U5r=r(G3t,"not"),G3t.forEach(t),J5r=r(jee,` load the model weights. It only affects the
model\u2019s configuration. Use `),QU=n(jee,"A",{href:!0});var O3t=s(QU);Y5r=r(O3t,"from_pretrained()"),O3t.forEach(t),K5r=r(jee," to load the model weights."),jee.forEach(t),Z5r=i(U0),T(SE.$$.fragment,U0),U0.forEach(t),e3r=i(Pl),Br=n(Pl,"DIV",{class:!0});var Bl=s(Br);T(g9.$$.fragment,Bl),o3r=i(Bl),pFe=n(Bl,"P",{});var V3t=s(pFe);r3r=r(V3t,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),V3t.forEach(t),t3r=i(Bl),cn=n(Bl,"P",{});var J0=s(cn);a3r=r(J0,"The model class to instantiate is selected based on the "),_Fe=n(J0,"CODE",{});var X3t=s(_Fe);n3r=r(X3t,"model_type"),X3t.forEach(t),s3r=r(J0,` property of the config object (either
passed as an argument or loaded from `),uFe=n(J0,"CODE",{});var z3t=s(uFe);l3r=r(z3t,"pretrained_model_name_or_path"),z3t.forEach(t),i3r=r(J0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bFe=n(J0,"CODE",{});var W3t=s(bFe);d3r=r(W3t,"pretrained_model_name_or_path"),W3t.forEach(t),c3r=r(J0,":"),J0.forEach(t),f3r=i(Bl),de=n(Bl,"UL",{});var me=s(de);RE=n(me,"LI",{});var $Be=s(RE);vFe=n($Be,"STRONG",{});var Q3t=s(vFe);m3r=r(Q3t,"albert"),Q3t.forEach(t),g3r=r($Be," \u2014 "),HU=n($Be,"A",{href:!0});var H3t=s(HU);h3r=r(H3t,"TFAlbertForTokenClassification"),H3t.forEach(t),p3r=r($Be," (ALBERT model)"),$Be.forEach(t),_3r=i(me),PE=n(me,"LI",{});var kBe=s(PE);FFe=n(kBe,"STRONG",{});var U3t=s(FFe);u3r=r(U3t,"bert"),U3t.forEach(t),b3r=r(kBe," \u2014 "),UU=n(kBe,"A",{href:!0});var J3t=s(UU);v3r=r(J3t,"TFBertForTokenClassification"),J3t.forEach(t),F3r=r(kBe," (BERT model)"),kBe.forEach(t),T3r=i(me),BE=n(me,"LI",{});var SBe=s(BE);TFe=n(SBe,"STRONG",{});var Y3t=s(TFe);M3r=r(Y3t,"camembert"),Y3t.forEach(t),E3r=r(SBe," \u2014 "),JU=n(SBe,"A",{href:!0});var K3t=s(JU);C3r=r(K3t,"TFCamembertForTokenClassification"),K3t.forEach(t),w3r=r(SBe," (CamemBERT model)"),SBe.forEach(t),A3r=i(me),IE=n(me,"LI",{});var RBe=s(IE);MFe=n(RBe,"STRONG",{});var Z3t=s(MFe);y3r=r(Z3t,"convbert"),Z3t.forEach(t),L3r=r(RBe," \u2014 "),YU=n(RBe,"A",{href:!0});var ewt=s(YU);x3r=r(ewt,"TFConvBertForTokenClassification"),ewt.forEach(t),$3r=r(RBe," (ConvBERT model)"),RBe.forEach(t),k3r=i(me),NE=n(me,"LI",{});var PBe=s(NE);EFe=n(PBe,"STRONG",{});var owt=s(EFe);S3r=r(owt,"deberta"),owt.forEach(t),R3r=r(PBe," \u2014 "),KU=n(PBe,"A",{href:!0});var rwt=s(KU);P3r=r(rwt,"TFDebertaForTokenClassification"),rwt.forEach(t),B3r=r(PBe," (DeBERTa model)"),PBe.forEach(t),I3r=i(me),qE=n(me,"LI",{});var BBe=s(qE);CFe=n(BBe,"STRONG",{});var twt=s(CFe);N3r=r(twt,"deberta-v2"),twt.forEach(t),q3r=r(BBe," \u2014 "),ZU=n(BBe,"A",{href:!0});var awt=s(ZU);j3r=r(awt,"TFDebertaV2ForTokenClassification"),awt.forEach(t),D3r=r(BBe," (DeBERTa-v2 model)"),BBe.forEach(t),G3r=i(me),jE=n(me,"LI",{});var IBe=s(jE);wFe=n(IBe,"STRONG",{});var nwt=s(wFe);O3r=r(nwt,"distilbert"),nwt.forEach(t),V3r=r(IBe," \u2014 "),eJ=n(IBe,"A",{href:!0});var swt=s(eJ);X3r=r(swt,"TFDistilBertForTokenClassification"),swt.forEach(t),z3r=r(IBe," (DistilBERT model)"),IBe.forEach(t),W3r=i(me),DE=n(me,"LI",{});var NBe=s(DE);AFe=n(NBe,"STRONG",{});var lwt=s(AFe);Q3r=r(lwt,"electra"),lwt.forEach(t),H3r=r(NBe," \u2014 "),oJ=n(NBe,"A",{href:!0});var iwt=s(oJ);U3r=r(iwt,"TFElectraForTokenClassification"),iwt.forEach(t),J3r=r(NBe," (ELECTRA model)"),NBe.forEach(t),Y3r=i(me),GE=n(me,"LI",{});var qBe=s(GE);yFe=n(qBe,"STRONG",{});var dwt=s(yFe);K3r=r(dwt,"flaubert"),dwt.forEach(t),Z3r=r(qBe," \u2014 "),rJ=n(qBe,"A",{href:!0});var cwt=s(rJ);ewr=r(cwt,"TFFlaubertForTokenClassification"),cwt.forEach(t),owr=r(qBe," (FlauBERT model)"),qBe.forEach(t),rwr=i(me),OE=n(me,"LI",{});var jBe=s(OE);LFe=n(jBe,"STRONG",{});var fwt=s(LFe);twr=r(fwt,"funnel"),fwt.forEach(t),awr=r(jBe," \u2014 "),tJ=n(jBe,"A",{href:!0});var mwt=s(tJ);nwr=r(mwt,"TFFunnelForTokenClassification"),mwt.forEach(t),swr=r(jBe," (Funnel Transformer model)"),jBe.forEach(t),lwr=i(me),VE=n(me,"LI",{});var DBe=s(VE);xFe=n(DBe,"STRONG",{});var gwt=s(xFe);iwr=r(gwt,"layoutlm"),gwt.forEach(t),dwr=r(DBe," \u2014 "),aJ=n(DBe,"A",{href:!0});var hwt=s(aJ);cwr=r(hwt,"TFLayoutLMForTokenClassification"),hwt.forEach(t),fwr=r(DBe," (LayoutLM model)"),DBe.forEach(t),mwr=i(me),XE=n(me,"LI",{});var GBe=s(XE);$Fe=n(GBe,"STRONG",{});var pwt=s($Fe);gwr=r(pwt,"longformer"),pwt.forEach(t),hwr=r(GBe," \u2014 "),nJ=n(GBe,"A",{href:!0});var _wt=s(nJ);pwr=r(_wt,"TFLongformerForTokenClassification"),_wt.forEach(t),_wr=r(GBe," (Longformer model)"),GBe.forEach(t),uwr=i(me),zE=n(me,"LI",{});var OBe=s(zE);kFe=n(OBe,"STRONG",{});var uwt=s(kFe);bwr=r(uwt,"mobilebert"),uwt.forEach(t),vwr=r(OBe," \u2014 "),sJ=n(OBe,"A",{href:!0});var bwt=s(sJ);Fwr=r(bwt,"TFMobileBertForTokenClassification"),bwt.forEach(t),Twr=r(OBe," (MobileBERT model)"),OBe.forEach(t),Mwr=i(me),WE=n(me,"LI",{});var VBe=s(WE);SFe=n(VBe,"STRONG",{});var vwt=s(SFe);Ewr=r(vwt,"mpnet"),vwt.forEach(t),Cwr=r(VBe," \u2014 "),lJ=n(VBe,"A",{href:!0});var Fwt=s(lJ);wwr=r(Fwt,"TFMPNetForTokenClassification"),Fwt.forEach(t),Awr=r(VBe," (MPNet model)"),VBe.forEach(t),ywr=i(me),QE=n(me,"LI",{});var XBe=s(QE);RFe=n(XBe,"STRONG",{});var Twt=s(RFe);Lwr=r(Twt,"rembert"),Twt.forEach(t),xwr=r(XBe," \u2014 "),iJ=n(XBe,"A",{href:!0});var Mwt=s(iJ);$wr=r(Mwt,"TFRemBertForTokenClassification"),Mwt.forEach(t),kwr=r(XBe," (RemBERT model)"),XBe.forEach(t),Swr=i(me),HE=n(me,"LI",{});var zBe=s(HE);PFe=n(zBe,"STRONG",{});var Ewt=s(PFe);Rwr=r(Ewt,"roberta"),Ewt.forEach(t),Pwr=r(zBe," \u2014 "),dJ=n(zBe,"A",{href:!0});var Cwt=s(dJ);Bwr=r(Cwt,"TFRobertaForTokenClassification"),Cwt.forEach(t),Iwr=r(zBe," (RoBERTa model)"),zBe.forEach(t),Nwr=i(me),UE=n(me,"LI",{});var WBe=s(UE);BFe=n(WBe,"STRONG",{});var wwt=s(BFe);qwr=r(wwt,"roformer"),wwt.forEach(t),jwr=r(WBe," \u2014 "),cJ=n(WBe,"A",{href:!0});var Awt=s(cJ);Dwr=r(Awt,"TFRoFormerForTokenClassification"),Awt.forEach(t),Gwr=r(WBe," (RoFormer model)"),WBe.forEach(t),Owr=i(me),JE=n(me,"LI",{});var QBe=s(JE);IFe=n(QBe,"STRONG",{});var ywt=s(IFe);Vwr=r(ywt,"xlm"),ywt.forEach(t),Xwr=r(QBe," \u2014 "),fJ=n(QBe,"A",{href:!0});var Lwt=s(fJ);zwr=r(Lwt,"TFXLMForTokenClassification"),Lwt.forEach(t),Wwr=r(QBe," (XLM model)"),QBe.forEach(t),Qwr=i(me),YE=n(me,"LI",{});var HBe=s(YE);NFe=n(HBe,"STRONG",{});var xwt=s(NFe);Hwr=r(xwt,"xlm-roberta"),xwt.forEach(t),Uwr=r(HBe," \u2014 "),mJ=n(HBe,"A",{href:!0});var $wt=s(mJ);Jwr=r($wt,"TFXLMRobertaForTokenClassification"),$wt.forEach(t),Ywr=r(HBe," (XLM-RoBERTa model)"),HBe.forEach(t),Kwr=i(me),KE=n(me,"LI",{});var UBe=s(KE);qFe=n(UBe,"STRONG",{});var kwt=s(qFe);Zwr=r(kwt,"xlnet"),kwt.forEach(t),e0r=r(UBe," \u2014 "),gJ=n(UBe,"A",{href:!0});var Swt=s(gJ);o0r=r(Swt,"TFXLNetForTokenClassification"),Swt.forEach(t),r0r=r(UBe," (XLNet model)"),UBe.forEach(t),me.forEach(t),t0r=i(Bl),T(ZE.$$.fragment,Bl),Bl.forEach(t),Pl.forEach(t),Oje=i(f),Tc=n(f,"H2",{class:!0});var UGe=s(Tc);eC=n(UGe,"A",{id:!0,class:!0,href:!0});var Rwt=s(eC);jFe=n(Rwt,"SPAN",{});var Pwt=s(jFe);T(h9.$$.fragment,Pwt),Pwt.forEach(t),Rwt.forEach(t),a0r=i(UGe),DFe=n(UGe,"SPAN",{});var Bwt=s(DFe);n0r=r(Bwt,"TFAutoModelForQuestionAnswering"),Bwt.forEach(t),UGe.forEach(t),Vje=i(f),ir=n(f,"DIV",{class:!0});var Il=s(ir);T(p9.$$.fragment,Il),s0r=i(Il),Mc=n(Il,"P",{});var Dee=s(Mc);l0r=r(Dee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),hJ=n(Dee,"A",{href:!0});var Iwt=s(hJ);i0r=r(Iwt,"from_pretrained()"),Iwt.forEach(t),d0r=r(Dee," class method or the "),pJ=n(Dee,"A",{href:!0});var Nwt=s(pJ);c0r=r(Nwt,"from_config()"),Nwt.forEach(t),f0r=r(Dee,` class
method.`),Dee.forEach(t),m0r=i(Il),_9=n(Il,"P",{});var JGe=s(_9);g0r=r(JGe,"This class cannot be instantiated directly using "),GFe=n(JGe,"CODE",{});var qwt=s(GFe);h0r=r(qwt,"__init__()"),qwt.forEach(t),p0r=r(JGe," (throws an error)."),JGe.forEach(t),_0r=i(Il),qt=n(Il,"DIV",{class:!0});var Y0=s(qt);T(u9.$$.fragment,Y0),u0r=i(Y0),OFe=n(Y0,"P",{});var jwt=s(OFe);b0r=r(jwt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),jwt.forEach(t),v0r=i(Y0),Ec=n(Y0,"P",{});var Gee=s(Ec);F0r=r(Gee,`Note:
Loading a model from its configuration file does `),VFe=n(Gee,"STRONG",{});var Dwt=s(VFe);T0r=r(Dwt,"not"),Dwt.forEach(t),M0r=r(Gee,` load the model weights. It only affects the
model\u2019s configuration. Use `),_J=n(Gee,"A",{href:!0});var Gwt=s(_J);E0r=r(Gwt,"from_pretrained()"),Gwt.forEach(t),C0r=r(Gee," to load the model weights."),Gee.forEach(t),w0r=i(Y0),T(oC.$$.fragment,Y0),Y0.forEach(t),A0r=i(Il),Ir=n(Il,"DIV",{class:!0});var Nl=s(Ir);T(b9.$$.fragment,Nl),y0r=i(Nl),XFe=n(Nl,"P",{});var Owt=s(XFe);L0r=r(Owt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Owt.forEach(t),x0r=i(Nl),fn=n(Nl,"P",{});var K0=s(fn);$0r=r(K0,"The model class to instantiate is selected based on the "),zFe=n(K0,"CODE",{});var Vwt=s(zFe);k0r=r(Vwt,"model_type"),Vwt.forEach(t),S0r=r(K0,` property of the config object (either
passed as an argument or loaded from `),WFe=n(K0,"CODE",{});var Xwt=s(WFe);R0r=r(Xwt,"pretrained_model_name_or_path"),Xwt.forEach(t),P0r=r(K0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QFe=n(K0,"CODE",{});var zwt=s(QFe);B0r=r(zwt,"pretrained_model_name_or_path"),zwt.forEach(t),I0r=r(K0,":"),K0.forEach(t),N0r=i(Nl),ce=n(Nl,"UL",{});var ge=s(ce);rC=n(ge,"LI",{});var JBe=s(rC);HFe=n(JBe,"STRONG",{});var Wwt=s(HFe);q0r=r(Wwt,"albert"),Wwt.forEach(t),j0r=r(JBe," \u2014 "),uJ=n(JBe,"A",{href:!0});var Qwt=s(uJ);D0r=r(Qwt,"TFAlbertForQuestionAnswering"),Qwt.forEach(t),G0r=r(JBe," (ALBERT model)"),JBe.forEach(t),O0r=i(ge),tC=n(ge,"LI",{});var YBe=s(tC);UFe=n(YBe,"STRONG",{});var Hwt=s(UFe);V0r=r(Hwt,"bert"),Hwt.forEach(t),X0r=r(YBe," \u2014 "),bJ=n(YBe,"A",{href:!0});var Uwt=s(bJ);z0r=r(Uwt,"TFBertForQuestionAnswering"),Uwt.forEach(t),W0r=r(YBe," (BERT model)"),YBe.forEach(t),Q0r=i(ge),aC=n(ge,"LI",{});var KBe=s(aC);JFe=n(KBe,"STRONG",{});var Jwt=s(JFe);H0r=r(Jwt,"camembert"),Jwt.forEach(t),U0r=r(KBe," \u2014 "),vJ=n(KBe,"A",{href:!0});var Ywt=s(vJ);J0r=r(Ywt,"TFCamembertForQuestionAnswering"),Ywt.forEach(t),Y0r=r(KBe," (CamemBERT model)"),KBe.forEach(t),K0r=i(ge),nC=n(ge,"LI",{});var ZBe=s(nC);YFe=n(ZBe,"STRONG",{});var Kwt=s(YFe);Z0r=r(Kwt,"convbert"),Kwt.forEach(t),eAr=r(ZBe," \u2014 "),FJ=n(ZBe,"A",{href:!0});var Zwt=s(FJ);oAr=r(Zwt,"TFConvBertForQuestionAnswering"),Zwt.forEach(t),rAr=r(ZBe," (ConvBERT model)"),ZBe.forEach(t),tAr=i(ge),sC=n(ge,"LI",{});var eIe=s(sC);KFe=n(eIe,"STRONG",{});var e0t=s(KFe);aAr=r(e0t,"deberta"),e0t.forEach(t),nAr=r(eIe," \u2014 "),TJ=n(eIe,"A",{href:!0});var o0t=s(TJ);sAr=r(o0t,"TFDebertaForQuestionAnswering"),o0t.forEach(t),lAr=r(eIe," (DeBERTa model)"),eIe.forEach(t),iAr=i(ge),lC=n(ge,"LI",{});var oIe=s(lC);ZFe=n(oIe,"STRONG",{});var r0t=s(ZFe);dAr=r(r0t,"deberta-v2"),r0t.forEach(t),cAr=r(oIe," \u2014 "),MJ=n(oIe,"A",{href:!0});var t0t=s(MJ);fAr=r(t0t,"TFDebertaV2ForQuestionAnswering"),t0t.forEach(t),mAr=r(oIe," (DeBERTa-v2 model)"),oIe.forEach(t),gAr=i(ge),iC=n(ge,"LI",{});var rIe=s(iC);eTe=n(rIe,"STRONG",{});var a0t=s(eTe);hAr=r(a0t,"distilbert"),a0t.forEach(t),pAr=r(rIe," \u2014 "),EJ=n(rIe,"A",{href:!0});var n0t=s(EJ);_Ar=r(n0t,"TFDistilBertForQuestionAnswering"),n0t.forEach(t),uAr=r(rIe," (DistilBERT model)"),rIe.forEach(t),bAr=i(ge),dC=n(ge,"LI",{});var tIe=s(dC);oTe=n(tIe,"STRONG",{});var s0t=s(oTe);vAr=r(s0t,"electra"),s0t.forEach(t),FAr=r(tIe," \u2014 "),CJ=n(tIe,"A",{href:!0});var l0t=s(CJ);TAr=r(l0t,"TFElectraForQuestionAnswering"),l0t.forEach(t),MAr=r(tIe," (ELECTRA model)"),tIe.forEach(t),EAr=i(ge),cC=n(ge,"LI",{});var aIe=s(cC);rTe=n(aIe,"STRONG",{});var i0t=s(rTe);CAr=r(i0t,"flaubert"),i0t.forEach(t),wAr=r(aIe," \u2014 "),wJ=n(aIe,"A",{href:!0});var d0t=s(wJ);AAr=r(d0t,"TFFlaubertForQuestionAnsweringSimple"),d0t.forEach(t),yAr=r(aIe," (FlauBERT model)"),aIe.forEach(t),LAr=i(ge),fC=n(ge,"LI",{});var nIe=s(fC);tTe=n(nIe,"STRONG",{});var c0t=s(tTe);xAr=r(c0t,"funnel"),c0t.forEach(t),$Ar=r(nIe," \u2014 "),AJ=n(nIe,"A",{href:!0});var f0t=s(AJ);kAr=r(f0t,"TFFunnelForQuestionAnswering"),f0t.forEach(t),SAr=r(nIe," (Funnel Transformer model)"),nIe.forEach(t),RAr=i(ge),mC=n(ge,"LI",{});var sIe=s(mC);aTe=n(sIe,"STRONG",{});var m0t=s(aTe);PAr=r(m0t,"gptj"),m0t.forEach(t),BAr=r(sIe," \u2014 "),yJ=n(sIe,"A",{href:!0});var g0t=s(yJ);IAr=r(g0t,"TFGPTJForQuestionAnswering"),g0t.forEach(t),NAr=r(sIe," (GPT-J model)"),sIe.forEach(t),qAr=i(ge),gC=n(ge,"LI",{});var lIe=s(gC);nTe=n(lIe,"STRONG",{});var h0t=s(nTe);jAr=r(h0t,"longformer"),h0t.forEach(t),DAr=r(lIe," \u2014 "),LJ=n(lIe,"A",{href:!0});var p0t=s(LJ);GAr=r(p0t,"TFLongformerForQuestionAnswering"),p0t.forEach(t),OAr=r(lIe," (Longformer model)"),lIe.forEach(t),VAr=i(ge),hC=n(ge,"LI",{});var iIe=s(hC);sTe=n(iIe,"STRONG",{});var _0t=s(sTe);XAr=r(_0t,"mobilebert"),_0t.forEach(t),zAr=r(iIe," \u2014 "),xJ=n(iIe,"A",{href:!0});var u0t=s(xJ);WAr=r(u0t,"TFMobileBertForQuestionAnswering"),u0t.forEach(t),QAr=r(iIe," (MobileBERT model)"),iIe.forEach(t),HAr=i(ge),pC=n(ge,"LI",{});var dIe=s(pC);lTe=n(dIe,"STRONG",{});var b0t=s(lTe);UAr=r(b0t,"mpnet"),b0t.forEach(t),JAr=r(dIe," \u2014 "),$J=n(dIe,"A",{href:!0});var v0t=s($J);YAr=r(v0t,"TFMPNetForQuestionAnswering"),v0t.forEach(t),KAr=r(dIe," (MPNet model)"),dIe.forEach(t),ZAr=i(ge),_C=n(ge,"LI",{});var cIe=s(_C);iTe=n(cIe,"STRONG",{});var F0t=s(iTe);eyr=r(F0t,"rembert"),F0t.forEach(t),oyr=r(cIe," \u2014 "),kJ=n(cIe,"A",{href:!0});var T0t=s(kJ);ryr=r(T0t,"TFRemBertForQuestionAnswering"),T0t.forEach(t),tyr=r(cIe," (RemBERT model)"),cIe.forEach(t),ayr=i(ge),uC=n(ge,"LI",{});var fIe=s(uC);dTe=n(fIe,"STRONG",{});var M0t=s(dTe);nyr=r(M0t,"roberta"),M0t.forEach(t),syr=r(fIe," \u2014 "),SJ=n(fIe,"A",{href:!0});var E0t=s(SJ);lyr=r(E0t,"TFRobertaForQuestionAnswering"),E0t.forEach(t),iyr=r(fIe," (RoBERTa model)"),fIe.forEach(t),dyr=i(ge),bC=n(ge,"LI",{});var mIe=s(bC);cTe=n(mIe,"STRONG",{});var C0t=s(cTe);cyr=r(C0t,"roformer"),C0t.forEach(t),fyr=r(mIe," \u2014 "),RJ=n(mIe,"A",{href:!0});var w0t=s(RJ);myr=r(w0t,"TFRoFormerForQuestionAnswering"),w0t.forEach(t),gyr=r(mIe," (RoFormer model)"),mIe.forEach(t),hyr=i(ge),vC=n(ge,"LI",{});var gIe=s(vC);fTe=n(gIe,"STRONG",{});var A0t=s(fTe);pyr=r(A0t,"xlm"),A0t.forEach(t),_yr=r(gIe," \u2014 "),PJ=n(gIe,"A",{href:!0});var y0t=s(PJ);uyr=r(y0t,"TFXLMForQuestionAnsweringSimple"),y0t.forEach(t),byr=r(gIe," (XLM model)"),gIe.forEach(t),vyr=i(ge),FC=n(ge,"LI",{});var hIe=s(FC);mTe=n(hIe,"STRONG",{});var L0t=s(mTe);Fyr=r(L0t,"xlm-roberta"),L0t.forEach(t),Tyr=r(hIe," \u2014 "),BJ=n(hIe,"A",{href:!0});var x0t=s(BJ);Myr=r(x0t,"TFXLMRobertaForQuestionAnswering"),x0t.forEach(t),Eyr=r(hIe," (XLM-RoBERTa model)"),hIe.forEach(t),Cyr=i(ge),TC=n(ge,"LI",{});var pIe=s(TC);gTe=n(pIe,"STRONG",{});var $0t=s(gTe);wyr=r($0t,"xlnet"),$0t.forEach(t),Ayr=r(pIe," \u2014 "),IJ=n(pIe,"A",{href:!0});var k0t=s(IJ);yyr=r(k0t,"TFXLNetForQuestionAnsweringSimple"),k0t.forEach(t),Lyr=r(pIe," (XLNet model)"),pIe.forEach(t),ge.forEach(t),xyr=i(Nl),T(MC.$$.fragment,Nl),Nl.forEach(t),Il.forEach(t),Xje=i(f),Cc=n(f,"H2",{class:!0});var YGe=s(Cc);EC=n(YGe,"A",{id:!0,class:!0,href:!0});var S0t=s(EC);hTe=n(S0t,"SPAN",{});var R0t=s(hTe);T(v9.$$.fragment,R0t),R0t.forEach(t),S0t.forEach(t),$yr=i(YGe),pTe=n(YGe,"SPAN",{});var P0t=s(pTe);kyr=r(P0t,"TFAutoModelForVision2Seq"),P0t.forEach(t),YGe.forEach(t),zje=i(f),dr=n(f,"DIV",{class:!0});var ql=s(dr);T(F9.$$.fragment,ql),Syr=i(ql),wc=n(ql,"P",{});var Oee=s(wc);Ryr=r(Oee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),NJ=n(Oee,"A",{href:!0});var B0t=s(NJ);Pyr=r(B0t,"from_pretrained()"),B0t.forEach(t),Byr=r(Oee," class method or the "),qJ=n(Oee,"A",{href:!0});var I0t=s(qJ);Iyr=r(I0t,"from_config()"),I0t.forEach(t),Nyr=r(Oee,` class
method.`),Oee.forEach(t),qyr=i(ql),T9=n(ql,"P",{});var KGe=s(T9);jyr=r(KGe,"This class cannot be instantiated directly using "),_Te=n(KGe,"CODE",{});var N0t=s(_Te);Dyr=r(N0t,"__init__()"),N0t.forEach(t),Gyr=r(KGe," (throws an error)."),KGe.forEach(t),Oyr=i(ql),jt=n(ql,"DIV",{class:!0});var Z0=s(jt);T(M9.$$.fragment,Z0),Vyr=i(Z0),uTe=n(Z0,"P",{});var q0t=s(uTe);Xyr=r(q0t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),q0t.forEach(t),zyr=i(Z0),Ac=n(Z0,"P",{});var Vee=s(Ac);Wyr=r(Vee,`Note:
Loading a model from its configuration file does `),bTe=n(Vee,"STRONG",{});var j0t=s(bTe);Qyr=r(j0t,"not"),j0t.forEach(t),Hyr=r(Vee,` load the model weights. It only affects the
model\u2019s configuration. Use `),jJ=n(Vee,"A",{href:!0});var D0t=s(jJ);Uyr=r(D0t,"from_pretrained()"),D0t.forEach(t),Jyr=r(Vee," to load the model weights."),Vee.forEach(t),Yyr=i(Z0),T(CC.$$.fragment,Z0),Z0.forEach(t),Kyr=i(ql),Nr=n(ql,"DIV",{class:!0});var jl=s(Nr);T(E9.$$.fragment,jl),Zyr=i(jl),vTe=n(jl,"P",{});var G0t=s(vTe);eLr=r(G0t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),G0t.forEach(t),oLr=i(jl),mn=n(jl,"P",{});var eA=s(mn);rLr=r(eA,"The model class to instantiate is selected based on the "),FTe=n(eA,"CODE",{});var O0t=s(FTe);tLr=r(O0t,"model_type"),O0t.forEach(t),aLr=r(eA,` property of the config object (either
passed as an argument or loaded from `),TTe=n(eA,"CODE",{});var V0t=s(TTe);nLr=r(V0t,"pretrained_model_name_or_path"),V0t.forEach(t),sLr=r(eA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MTe=n(eA,"CODE",{});var X0t=s(MTe);lLr=r(X0t,"pretrained_model_name_or_path"),X0t.forEach(t),iLr=r(eA,":"),eA.forEach(t),dLr=i(jl),ETe=n(jl,"UL",{});var z0t=s(ETe);wC=n(z0t,"LI",{});var _Ie=s(wC);CTe=n(_Ie,"STRONG",{});var W0t=s(CTe);cLr=r(W0t,"vision-encoder-decoder"),W0t.forEach(t),fLr=r(_Ie," \u2014 "),DJ=n(_Ie,"A",{href:!0});var Q0t=s(DJ);mLr=r(Q0t,"TFVisionEncoderDecoderModel"),Q0t.forEach(t),gLr=r(_Ie," (Vision Encoder decoder model)"),_Ie.forEach(t),z0t.forEach(t),hLr=i(jl),T(AC.$$.fragment,jl),jl.forEach(t),ql.forEach(t),Wje=i(f),yc=n(f,"H2",{class:!0});var ZGe=s(yc);yC=n(ZGe,"A",{id:!0,class:!0,href:!0});var H0t=s(yC);wTe=n(H0t,"SPAN",{});var U0t=s(wTe);T(C9.$$.fragment,U0t),U0t.forEach(t),H0t.forEach(t),pLr=i(ZGe),ATe=n(ZGe,"SPAN",{});var J0t=s(ATe);_Lr=r(J0t,"TFAutoModelForSpeechSeq2Seq"),J0t.forEach(t),ZGe.forEach(t),Qje=i(f),cr=n(f,"DIV",{class:!0});var Dl=s(cr);T(w9.$$.fragment,Dl),uLr=i(Dl),Lc=n(Dl,"P",{});var Xee=s(Lc);bLr=r(Xee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),GJ=n(Xee,"A",{href:!0});var Y0t=s(GJ);vLr=r(Y0t,"from_pretrained()"),Y0t.forEach(t),FLr=r(Xee," class method or the "),OJ=n(Xee,"A",{href:!0});var K0t=s(OJ);TLr=r(K0t,"from_config()"),K0t.forEach(t),MLr=r(Xee,` class
method.`),Xee.forEach(t),ELr=i(Dl),A9=n(Dl,"P",{});var eOe=s(A9);CLr=r(eOe,"This class cannot be instantiated directly using "),yTe=n(eOe,"CODE",{});var Z0t=s(yTe);wLr=r(Z0t,"__init__()"),Z0t.forEach(t),ALr=r(eOe," (throws an error)."),eOe.forEach(t),yLr=i(Dl),Dt=n(Dl,"DIV",{class:!0});var oA=s(Dt);T(y9.$$.fragment,oA),LLr=i(oA),LTe=n(oA,"P",{});var eAt=s(LTe);xLr=r(eAt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),eAt.forEach(t),$Lr=i(oA),xc=n(oA,"P",{});var zee=s(xc);kLr=r(zee,`Note:
Loading a model from its configuration file does `),xTe=n(zee,"STRONG",{});var oAt=s(xTe);SLr=r(oAt,"not"),oAt.forEach(t),RLr=r(zee,` load the model weights. It only affects the
model\u2019s configuration. Use `),VJ=n(zee,"A",{href:!0});var rAt=s(VJ);PLr=r(rAt,"from_pretrained()"),rAt.forEach(t),BLr=r(zee," to load the model weights."),zee.forEach(t),ILr=i(oA),T(LC.$$.fragment,oA),oA.forEach(t),NLr=i(Dl),qr=n(Dl,"DIV",{class:!0});var Gl=s(qr);T(L9.$$.fragment,Gl),qLr=i(Gl),$Te=n(Gl,"P",{});var tAt=s($Te);jLr=r(tAt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),tAt.forEach(t),DLr=i(Gl),gn=n(Gl,"P",{});var rA=s(gn);GLr=r(rA,"The model class to instantiate is selected based on the "),kTe=n(rA,"CODE",{});var aAt=s(kTe);OLr=r(aAt,"model_type"),aAt.forEach(t),VLr=r(rA,` property of the config object (either
passed as an argument or loaded from `),STe=n(rA,"CODE",{});var nAt=s(STe);XLr=r(nAt,"pretrained_model_name_or_path"),nAt.forEach(t),zLr=r(rA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RTe=n(rA,"CODE",{});var sAt=s(RTe);WLr=r(sAt,"pretrained_model_name_or_path"),sAt.forEach(t),QLr=r(rA,":"),rA.forEach(t),HLr=i(Gl),PTe=n(Gl,"UL",{});var lAt=s(PTe);xC=n(lAt,"LI",{});var uIe=s(xC);BTe=n(uIe,"STRONG",{});var iAt=s(BTe);ULr=r(iAt,"speech_to_text"),iAt.forEach(t),JLr=r(uIe," \u2014 "),XJ=n(uIe,"A",{href:!0});var dAt=s(XJ);YLr=r(dAt,"TFSpeech2TextForConditionalGeneration"),dAt.forEach(t),KLr=r(uIe," (Speech2Text model)"),uIe.forEach(t),lAt.forEach(t),ZLr=i(Gl),T($C.$$.fragment,Gl),Gl.forEach(t),Dl.forEach(t),Hje=i(f),$c=n(f,"H2",{class:!0});var oOe=s($c);kC=n(oOe,"A",{id:!0,class:!0,href:!0});var cAt=s(kC);ITe=n(cAt,"SPAN",{});var fAt=s(ITe);T(x9.$$.fragment,fAt),fAt.forEach(t),cAt.forEach(t),e8r=i(oOe),NTe=n(oOe,"SPAN",{});var mAt=s(NTe);o8r=r(mAt,"FlaxAutoModel"),mAt.forEach(t),oOe.forEach(t),Uje=i(f),fr=n(f,"DIV",{class:!0});var Ol=s(fr);T($9.$$.fragment,Ol),r8r=i(Ol),kc=n(Ol,"P",{});var Wee=s(kc);t8r=r(Wee,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),zJ=n(Wee,"A",{href:!0});var gAt=s(zJ);a8r=r(gAt,"from_pretrained()"),gAt.forEach(t),n8r=r(Wee," class method or the "),WJ=n(Wee,"A",{href:!0});var hAt=s(WJ);s8r=r(hAt,"from_config()"),hAt.forEach(t),l8r=r(Wee,` class
method.`),Wee.forEach(t),i8r=i(Ol),k9=n(Ol,"P",{});var rOe=s(k9);d8r=r(rOe,"This class cannot be instantiated directly using "),qTe=n(rOe,"CODE",{});var pAt=s(qTe);c8r=r(pAt,"__init__()"),pAt.forEach(t),f8r=r(rOe," (throws an error)."),rOe.forEach(t),m8r=i(Ol),Gt=n(Ol,"DIV",{class:!0});var tA=s(Gt);T(S9.$$.fragment,tA),g8r=i(tA),jTe=n(tA,"P",{});var _At=s(jTe);h8r=r(_At,"Instantiates one of the base model classes of the library from a configuration."),_At.forEach(t),p8r=i(tA),Sc=n(tA,"P",{});var Qee=s(Sc);_8r=r(Qee,`Note:
Loading a model from its configuration file does `),DTe=n(Qee,"STRONG",{});var uAt=s(DTe);u8r=r(uAt,"not"),uAt.forEach(t),b8r=r(Qee,` load the model weights. It only affects the
model\u2019s configuration. Use `),QJ=n(Qee,"A",{href:!0});var bAt=s(QJ);v8r=r(bAt,"from_pretrained()"),bAt.forEach(t),F8r=r(Qee," to load the model weights."),Qee.forEach(t),T8r=i(tA),T(SC.$$.fragment,tA),tA.forEach(t),M8r=i(Ol),jr=n(Ol,"DIV",{class:!0});var Vl=s(jr);T(R9.$$.fragment,Vl),E8r=i(Vl),GTe=n(Vl,"P",{});var vAt=s(GTe);C8r=r(vAt,"Instantiate one of the base model classes of the library from a pretrained model."),vAt.forEach(t),w8r=i(Vl),hn=n(Vl,"P",{});var aA=s(hn);A8r=r(aA,"The model class to instantiate is selected based on the "),OTe=n(aA,"CODE",{});var FAt=s(OTe);y8r=r(FAt,"model_type"),FAt.forEach(t),L8r=r(aA,` property of the config object (either
passed as an argument or loaded from `),VTe=n(aA,"CODE",{});var TAt=s(VTe);x8r=r(TAt,"pretrained_model_name_or_path"),TAt.forEach(t),$8r=r(aA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),XTe=n(aA,"CODE",{});var MAt=s(XTe);k8r=r(MAt,"pretrained_model_name_or_path"),MAt.forEach(t),S8r=r(aA,":"),aA.forEach(t),R8r=i(Vl),te=n(Vl,"UL",{});var ne=s(te);RC=n(ne,"LI",{});var bIe=s(RC);zTe=n(bIe,"STRONG",{});var EAt=s(zTe);P8r=r(EAt,"albert"),EAt.forEach(t),B8r=r(bIe," \u2014 "),HJ=n(bIe,"A",{href:!0});var CAt=s(HJ);I8r=r(CAt,"FlaxAlbertModel"),CAt.forEach(t),N8r=r(bIe," (ALBERT model)"),bIe.forEach(t),q8r=i(ne),PC=n(ne,"LI",{});var vIe=s(PC);WTe=n(vIe,"STRONG",{});var wAt=s(WTe);j8r=r(wAt,"bart"),wAt.forEach(t),D8r=r(vIe," \u2014 "),UJ=n(vIe,"A",{href:!0});var AAt=s(UJ);G8r=r(AAt,"FlaxBartModel"),AAt.forEach(t),O8r=r(vIe," (BART model)"),vIe.forEach(t),V8r=i(ne),BC=n(ne,"LI",{});var FIe=s(BC);QTe=n(FIe,"STRONG",{});var yAt=s(QTe);X8r=r(yAt,"beit"),yAt.forEach(t),z8r=r(FIe," \u2014 "),JJ=n(FIe,"A",{href:!0});var LAt=s(JJ);W8r=r(LAt,"FlaxBeitModel"),LAt.forEach(t),Q8r=r(FIe," (BEiT model)"),FIe.forEach(t),H8r=i(ne),IC=n(ne,"LI",{});var TIe=s(IC);HTe=n(TIe,"STRONG",{});var xAt=s(HTe);U8r=r(xAt,"bert"),xAt.forEach(t),J8r=r(TIe," \u2014 "),YJ=n(TIe,"A",{href:!0});var $At=s(YJ);Y8r=r($At,"FlaxBertModel"),$At.forEach(t),K8r=r(TIe," (BERT model)"),TIe.forEach(t),Z8r=i(ne),NC=n(ne,"LI",{});var MIe=s(NC);UTe=n(MIe,"STRONG",{});var kAt=s(UTe);e9r=r(kAt,"big_bird"),kAt.forEach(t),o9r=r(MIe," \u2014 "),KJ=n(MIe,"A",{href:!0});var SAt=s(KJ);r9r=r(SAt,"FlaxBigBirdModel"),SAt.forEach(t),t9r=r(MIe," (BigBird model)"),MIe.forEach(t),a9r=i(ne),qC=n(ne,"LI",{});var EIe=s(qC);JTe=n(EIe,"STRONG",{});var RAt=s(JTe);n9r=r(RAt,"blenderbot"),RAt.forEach(t),s9r=r(EIe," \u2014 "),ZJ=n(EIe,"A",{href:!0});var PAt=s(ZJ);l9r=r(PAt,"FlaxBlenderbotModel"),PAt.forEach(t),i9r=r(EIe," (Blenderbot model)"),EIe.forEach(t),d9r=i(ne),jC=n(ne,"LI",{});var CIe=s(jC);YTe=n(CIe,"STRONG",{});var BAt=s(YTe);c9r=r(BAt,"blenderbot-small"),BAt.forEach(t),f9r=r(CIe," \u2014 "),eY=n(CIe,"A",{href:!0});var IAt=s(eY);m9r=r(IAt,"FlaxBlenderbotSmallModel"),IAt.forEach(t),g9r=r(CIe," (BlenderbotSmall model)"),CIe.forEach(t),h9r=i(ne),DC=n(ne,"LI",{});var wIe=s(DC);KTe=n(wIe,"STRONG",{});var NAt=s(KTe);p9r=r(NAt,"clip"),NAt.forEach(t),_9r=r(wIe," \u2014 "),oY=n(wIe,"A",{href:!0});var qAt=s(oY);u9r=r(qAt,"FlaxCLIPModel"),qAt.forEach(t),b9r=r(wIe," (CLIP model)"),wIe.forEach(t),v9r=i(ne),GC=n(ne,"LI",{});var AIe=s(GC);ZTe=n(AIe,"STRONG",{});var jAt=s(ZTe);F9r=r(jAt,"distilbert"),jAt.forEach(t),T9r=r(AIe," \u2014 "),rY=n(AIe,"A",{href:!0});var DAt=s(rY);M9r=r(DAt,"FlaxDistilBertModel"),DAt.forEach(t),E9r=r(AIe," (DistilBERT model)"),AIe.forEach(t),C9r=i(ne),OC=n(ne,"LI",{});var yIe=s(OC);e7e=n(yIe,"STRONG",{});var GAt=s(e7e);w9r=r(GAt,"electra"),GAt.forEach(t),A9r=r(yIe," \u2014 "),tY=n(yIe,"A",{href:!0});var OAt=s(tY);y9r=r(OAt,"FlaxElectraModel"),OAt.forEach(t),L9r=r(yIe," (ELECTRA model)"),yIe.forEach(t),x9r=i(ne),VC=n(ne,"LI",{});var LIe=s(VC);o7e=n(LIe,"STRONG",{});var VAt=s(o7e);$9r=r(VAt,"gpt2"),VAt.forEach(t),k9r=r(LIe," \u2014 "),aY=n(LIe,"A",{href:!0});var XAt=s(aY);S9r=r(XAt,"FlaxGPT2Model"),XAt.forEach(t),R9r=r(LIe," (OpenAI GPT-2 model)"),LIe.forEach(t),P9r=i(ne),XC=n(ne,"LI",{});var xIe=s(XC);r7e=n(xIe,"STRONG",{});var zAt=s(r7e);B9r=r(zAt,"gpt_neo"),zAt.forEach(t),I9r=r(xIe," \u2014 "),nY=n(xIe,"A",{href:!0});var WAt=s(nY);N9r=r(WAt,"FlaxGPTNeoModel"),WAt.forEach(t),q9r=r(xIe," (GPT Neo model)"),xIe.forEach(t),j9r=i(ne),zC=n(ne,"LI",{});var $Ie=s(zC);t7e=n($Ie,"STRONG",{});var QAt=s(t7e);D9r=r(QAt,"gptj"),QAt.forEach(t),G9r=r($Ie," \u2014 "),sY=n($Ie,"A",{href:!0});var HAt=s(sY);O9r=r(HAt,"FlaxGPTJModel"),HAt.forEach(t),V9r=r($Ie," (GPT-J model)"),$Ie.forEach(t),X9r=i(ne),WC=n(ne,"LI",{});var kIe=s(WC);a7e=n(kIe,"STRONG",{});var UAt=s(a7e);z9r=r(UAt,"marian"),UAt.forEach(t),W9r=r(kIe," \u2014 "),lY=n(kIe,"A",{href:!0});var JAt=s(lY);Q9r=r(JAt,"FlaxMarianModel"),JAt.forEach(t),H9r=r(kIe," (Marian model)"),kIe.forEach(t),U9r=i(ne),QC=n(ne,"LI",{});var SIe=s(QC);n7e=n(SIe,"STRONG",{});var YAt=s(n7e);J9r=r(YAt,"mbart"),YAt.forEach(t),Y9r=r(SIe," \u2014 "),iY=n(SIe,"A",{href:!0});var KAt=s(iY);K9r=r(KAt,"FlaxMBartModel"),KAt.forEach(t),Z9r=r(SIe," (mBART model)"),SIe.forEach(t),exr=i(ne),HC=n(ne,"LI",{});var RIe=s(HC);s7e=n(RIe,"STRONG",{});var ZAt=s(s7e);oxr=r(ZAt,"mt5"),ZAt.forEach(t),rxr=r(RIe," \u2014 "),dY=n(RIe,"A",{href:!0});var eyt=s(dY);txr=r(eyt,"FlaxMT5Model"),eyt.forEach(t),axr=r(RIe," (mT5 model)"),RIe.forEach(t),nxr=i(ne),UC=n(ne,"LI",{});var PIe=s(UC);l7e=n(PIe,"STRONG",{});var oyt=s(l7e);sxr=r(oyt,"pegasus"),oyt.forEach(t),lxr=r(PIe," \u2014 "),cY=n(PIe,"A",{href:!0});var ryt=s(cY);ixr=r(ryt,"FlaxPegasusModel"),ryt.forEach(t),dxr=r(PIe," (Pegasus model)"),PIe.forEach(t),cxr=i(ne),JC=n(ne,"LI",{});var BIe=s(JC);i7e=n(BIe,"STRONG",{});var tyt=s(i7e);fxr=r(tyt,"roberta"),tyt.forEach(t),mxr=r(BIe," \u2014 "),fY=n(BIe,"A",{href:!0});var ayt=s(fY);gxr=r(ayt,"FlaxRobertaModel"),ayt.forEach(t),hxr=r(BIe," (RoBERTa model)"),BIe.forEach(t),pxr=i(ne),YC=n(ne,"LI",{});var IIe=s(YC);d7e=n(IIe,"STRONG",{});var nyt=s(d7e);_xr=r(nyt,"roformer"),nyt.forEach(t),uxr=r(IIe," \u2014 "),mY=n(IIe,"A",{href:!0});var syt=s(mY);bxr=r(syt,"FlaxRoFormerModel"),syt.forEach(t),vxr=r(IIe," (RoFormer model)"),IIe.forEach(t),Fxr=i(ne),KC=n(ne,"LI",{});var NIe=s(KC);c7e=n(NIe,"STRONG",{});var lyt=s(c7e);Txr=r(lyt,"t5"),lyt.forEach(t),Mxr=r(NIe," \u2014 "),gY=n(NIe,"A",{href:!0});var iyt=s(gY);Exr=r(iyt,"FlaxT5Model"),iyt.forEach(t),Cxr=r(NIe," (T5 model)"),NIe.forEach(t),wxr=i(ne),ZC=n(ne,"LI",{});var qIe=s(ZC);f7e=n(qIe,"STRONG",{});var dyt=s(f7e);Axr=r(dyt,"vision-text-dual-encoder"),dyt.forEach(t),yxr=r(qIe," \u2014 "),hY=n(qIe,"A",{href:!0});var cyt=s(hY);Lxr=r(cyt,"FlaxVisionTextDualEncoderModel"),cyt.forEach(t),xxr=r(qIe," (VisionTextDualEncoder model)"),qIe.forEach(t),$xr=i(ne),e5=n(ne,"LI",{});var jIe=s(e5);m7e=n(jIe,"STRONG",{});var fyt=s(m7e);kxr=r(fyt,"vit"),fyt.forEach(t),Sxr=r(jIe," \u2014 "),pY=n(jIe,"A",{href:!0});var myt=s(pY);Rxr=r(myt,"FlaxViTModel"),myt.forEach(t),Pxr=r(jIe," (ViT model)"),jIe.forEach(t),Bxr=i(ne),o5=n(ne,"LI",{});var DIe=s(o5);g7e=n(DIe,"STRONG",{});var gyt=s(g7e);Ixr=r(gyt,"wav2vec2"),gyt.forEach(t),Nxr=r(DIe," \u2014 "),_Y=n(DIe,"A",{href:!0});var hyt=s(_Y);qxr=r(hyt,"FlaxWav2Vec2Model"),hyt.forEach(t),jxr=r(DIe," (Wav2Vec2 model)"),DIe.forEach(t),Dxr=i(ne),r5=n(ne,"LI",{});var GIe=s(r5);h7e=n(GIe,"STRONG",{});var pyt=s(h7e);Gxr=r(pyt,"xglm"),pyt.forEach(t),Oxr=r(GIe," \u2014 "),uY=n(GIe,"A",{href:!0});var _yt=s(uY);Vxr=r(_yt,"FlaxXGLMModel"),_yt.forEach(t),Xxr=r(GIe," (XGLM model)"),GIe.forEach(t),zxr=i(ne),t5=n(ne,"LI",{});var OIe=s(t5);p7e=n(OIe,"STRONG",{});var uyt=s(p7e);Wxr=r(uyt,"xlm-roberta"),uyt.forEach(t),Qxr=r(OIe," \u2014 "),bY=n(OIe,"A",{href:!0});var byt=s(bY);Hxr=r(byt,"FlaxXLMRobertaModel"),byt.forEach(t),Uxr=r(OIe," (XLM-RoBERTa model)"),OIe.forEach(t),ne.forEach(t),Jxr=i(Vl),T(a5.$$.fragment,Vl),Vl.forEach(t),Ol.forEach(t),Jje=i(f),Rc=n(f,"H2",{class:!0});var tOe=s(Rc);n5=n(tOe,"A",{id:!0,class:!0,href:!0});var vyt=s(n5);_7e=n(vyt,"SPAN",{});var Fyt=s(_7e);T(P9.$$.fragment,Fyt),Fyt.forEach(t),vyt.forEach(t),Yxr=i(tOe),u7e=n(tOe,"SPAN",{});var Tyt=s(u7e);Kxr=r(Tyt,"FlaxAutoModelForCausalLM"),Tyt.forEach(t),tOe.forEach(t),Yje=i(f),mr=n(f,"DIV",{class:!0});var Xl=s(mr);T(B9.$$.fragment,Xl),Zxr=i(Xl),Pc=n(Xl,"P",{});var Hee=s(Pc);e$r=r(Hee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),vY=n(Hee,"A",{href:!0});var Myt=s(vY);o$r=r(Myt,"from_pretrained()"),Myt.forEach(t),r$r=r(Hee," class method or the "),FY=n(Hee,"A",{href:!0});var Eyt=s(FY);t$r=r(Eyt,"from_config()"),Eyt.forEach(t),a$r=r(Hee,` class
method.`),Hee.forEach(t),n$r=i(Xl),I9=n(Xl,"P",{});var aOe=s(I9);s$r=r(aOe,"This class cannot be instantiated directly using "),b7e=n(aOe,"CODE",{});var Cyt=s(b7e);l$r=r(Cyt,"__init__()"),Cyt.forEach(t),i$r=r(aOe," (throws an error)."),aOe.forEach(t),d$r=i(Xl),Ot=n(Xl,"DIV",{class:!0});var nA=s(Ot);T(N9.$$.fragment,nA),c$r=i(nA),v7e=n(nA,"P",{});var wyt=s(v7e);f$r=r(wyt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),wyt.forEach(t),m$r=i(nA),Bc=n(nA,"P",{});var Uee=s(Bc);g$r=r(Uee,`Note:
Loading a model from its configuration file does `),F7e=n(Uee,"STRONG",{});var Ayt=s(F7e);h$r=r(Ayt,"not"),Ayt.forEach(t),p$r=r(Uee,` load the model weights. It only affects the
model\u2019s configuration. Use `),TY=n(Uee,"A",{href:!0});var yyt=s(TY);_$r=r(yyt,"from_pretrained()"),yyt.forEach(t),u$r=r(Uee," to load the model weights."),Uee.forEach(t),b$r=i(nA),T(s5.$$.fragment,nA),nA.forEach(t),v$r=i(Xl),Dr=n(Xl,"DIV",{class:!0});var zl=s(Dr);T(q9.$$.fragment,zl),F$r=i(zl),T7e=n(zl,"P",{});var Lyt=s(T7e);T$r=r(Lyt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Lyt.forEach(t),M$r=i(zl),pn=n(zl,"P",{});var sA=s(pn);E$r=r(sA,"The model class to instantiate is selected based on the "),M7e=n(sA,"CODE",{});var xyt=s(M7e);C$r=r(xyt,"model_type"),xyt.forEach(t),w$r=r(sA,` property of the config object (either
passed as an argument or loaded from `),E7e=n(sA,"CODE",{});var $yt=s(E7e);A$r=r($yt,"pretrained_model_name_or_path"),$yt.forEach(t),y$r=r(sA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C7e=n(sA,"CODE",{});var kyt=s(C7e);L$r=r(kyt,"pretrained_model_name_or_path"),kyt.forEach(t),x$r=r(sA,":"),sA.forEach(t),$$r=i(zl),Re=n(zl,"UL",{});var Xe=s(Re);l5=n(Xe,"LI",{});var VIe=s(l5);w7e=n(VIe,"STRONG",{});var Syt=s(w7e);k$r=r(Syt,"bart"),Syt.forEach(t),S$r=r(VIe," \u2014 "),MY=n(VIe,"A",{href:!0});var Ryt=s(MY);R$r=r(Ryt,"FlaxBartForCausalLM"),Ryt.forEach(t),P$r=r(VIe," (BART model)"),VIe.forEach(t),B$r=i(Xe),i5=n(Xe,"LI",{});var XIe=s(i5);A7e=n(XIe,"STRONG",{});var Pyt=s(A7e);I$r=r(Pyt,"bert"),Pyt.forEach(t),N$r=r(XIe," \u2014 "),EY=n(XIe,"A",{href:!0});var Byt=s(EY);q$r=r(Byt,"FlaxBertForCausalLM"),Byt.forEach(t),j$r=r(XIe," (BERT model)"),XIe.forEach(t),D$r=i(Xe),d5=n(Xe,"LI",{});var zIe=s(d5);y7e=n(zIe,"STRONG",{});var Iyt=s(y7e);G$r=r(Iyt,"big_bird"),Iyt.forEach(t),O$r=r(zIe," \u2014 "),CY=n(zIe,"A",{href:!0});var Nyt=s(CY);V$r=r(Nyt,"FlaxBigBirdForCausalLM"),Nyt.forEach(t),X$r=r(zIe," (BigBird model)"),zIe.forEach(t),z$r=i(Xe),c5=n(Xe,"LI",{});var WIe=s(c5);L7e=n(WIe,"STRONG",{});var qyt=s(L7e);W$r=r(qyt,"electra"),qyt.forEach(t),Q$r=r(WIe," \u2014 "),wY=n(WIe,"A",{href:!0});var jyt=s(wY);H$r=r(jyt,"FlaxElectraForCausalLM"),jyt.forEach(t),U$r=r(WIe," (ELECTRA model)"),WIe.forEach(t),J$r=i(Xe),f5=n(Xe,"LI",{});var QIe=s(f5);x7e=n(QIe,"STRONG",{});var Dyt=s(x7e);Y$r=r(Dyt,"gpt2"),Dyt.forEach(t),K$r=r(QIe," \u2014 "),AY=n(QIe,"A",{href:!0});var Gyt=s(AY);Z$r=r(Gyt,"FlaxGPT2LMHeadModel"),Gyt.forEach(t),ekr=r(QIe," (OpenAI GPT-2 model)"),QIe.forEach(t),okr=i(Xe),m5=n(Xe,"LI",{});var HIe=s(m5);$7e=n(HIe,"STRONG",{});var Oyt=s($7e);rkr=r(Oyt,"gpt_neo"),Oyt.forEach(t),tkr=r(HIe," \u2014 "),yY=n(HIe,"A",{href:!0});var Vyt=s(yY);akr=r(Vyt,"FlaxGPTNeoForCausalLM"),Vyt.forEach(t),nkr=r(HIe," (GPT Neo model)"),HIe.forEach(t),skr=i(Xe),g5=n(Xe,"LI",{});var UIe=s(g5);k7e=n(UIe,"STRONG",{});var Xyt=s(k7e);lkr=r(Xyt,"gptj"),Xyt.forEach(t),ikr=r(UIe," \u2014 "),LY=n(UIe,"A",{href:!0});var zyt=s(LY);dkr=r(zyt,"FlaxGPTJForCausalLM"),zyt.forEach(t),ckr=r(UIe," (GPT-J model)"),UIe.forEach(t),fkr=i(Xe),h5=n(Xe,"LI",{});var JIe=s(h5);S7e=n(JIe,"STRONG",{});var Wyt=s(S7e);mkr=r(Wyt,"roberta"),Wyt.forEach(t),gkr=r(JIe," \u2014 "),xY=n(JIe,"A",{href:!0});var Qyt=s(xY);hkr=r(Qyt,"FlaxRobertaForCausalLM"),Qyt.forEach(t),pkr=r(JIe," (RoBERTa model)"),JIe.forEach(t),_kr=i(Xe),p5=n(Xe,"LI",{});var YIe=s(p5);R7e=n(YIe,"STRONG",{});var Hyt=s(R7e);ukr=r(Hyt,"xglm"),Hyt.forEach(t),bkr=r(YIe," \u2014 "),$Y=n(YIe,"A",{href:!0});var Uyt=s($Y);vkr=r(Uyt,"FlaxXGLMForCausalLM"),Uyt.forEach(t),Fkr=r(YIe," (XGLM model)"),YIe.forEach(t),Xe.forEach(t),Tkr=i(zl),T(_5.$$.fragment,zl),zl.forEach(t),Xl.forEach(t),Kje=i(f),Ic=n(f,"H2",{class:!0});var nOe=s(Ic);u5=n(nOe,"A",{id:!0,class:!0,href:!0});var Jyt=s(u5);P7e=n(Jyt,"SPAN",{});var Yyt=s(P7e);T(j9.$$.fragment,Yyt),Yyt.forEach(t),Jyt.forEach(t),Mkr=i(nOe),B7e=n(nOe,"SPAN",{});var Kyt=s(B7e);Ekr=r(Kyt,"FlaxAutoModelForPreTraining"),Kyt.forEach(t),nOe.forEach(t),Zje=i(f),gr=n(f,"DIV",{class:!0});var Wl=s(gr);T(D9.$$.fragment,Wl),Ckr=i(Wl),Nc=n(Wl,"P",{});var Jee=s(Nc);wkr=r(Jee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),kY=n(Jee,"A",{href:!0});var Zyt=s(kY);Akr=r(Zyt,"from_pretrained()"),Zyt.forEach(t),ykr=r(Jee," class method or the "),SY=n(Jee,"A",{href:!0});var eLt=s(SY);Lkr=r(eLt,"from_config()"),eLt.forEach(t),xkr=r(Jee,` class
method.`),Jee.forEach(t),$kr=i(Wl),G9=n(Wl,"P",{});var sOe=s(G9);kkr=r(sOe,"This class cannot be instantiated directly using "),I7e=n(sOe,"CODE",{});var oLt=s(I7e);Skr=r(oLt,"__init__()"),oLt.forEach(t),Rkr=r(sOe," (throws an error)."),sOe.forEach(t),Pkr=i(Wl),Vt=n(Wl,"DIV",{class:!0});var lA=s(Vt);T(O9.$$.fragment,lA),Bkr=i(lA),N7e=n(lA,"P",{});var rLt=s(N7e);Ikr=r(rLt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),rLt.forEach(t),Nkr=i(lA),qc=n(lA,"P",{});var Yee=s(qc);qkr=r(Yee,`Note:
Loading a model from its configuration file does `),q7e=n(Yee,"STRONG",{});var tLt=s(q7e);jkr=r(tLt,"not"),tLt.forEach(t),Dkr=r(Yee,` load the model weights. It only affects the
model\u2019s configuration. Use `),RY=n(Yee,"A",{href:!0});var aLt=s(RY);Gkr=r(aLt,"from_pretrained()"),aLt.forEach(t),Okr=r(Yee," to load the model weights."),Yee.forEach(t),Vkr=i(lA),T(b5.$$.fragment,lA),lA.forEach(t),Xkr=i(Wl),Gr=n(Wl,"DIV",{class:!0});var Ql=s(Gr);T(V9.$$.fragment,Ql),zkr=i(Ql),j7e=n(Ql,"P",{});var nLt=s(j7e);Wkr=r(nLt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),nLt.forEach(t),Qkr=i(Ql),_n=n(Ql,"P",{});var iA=s(_n);Hkr=r(iA,"The model class to instantiate is selected based on the "),D7e=n(iA,"CODE",{});var sLt=s(D7e);Ukr=r(sLt,"model_type"),sLt.forEach(t),Jkr=r(iA,` property of the config object (either
passed as an argument or loaded from `),G7e=n(iA,"CODE",{});var lLt=s(G7e);Ykr=r(lLt,"pretrained_model_name_or_path"),lLt.forEach(t),Kkr=r(iA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O7e=n(iA,"CODE",{});var iLt=s(O7e);Zkr=r(iLt,"pretrained_model_name_or_path"),iLt.forEach(t),eSr=r(iA,":"),iA.forEach(t),oSr=i(Ql),Ee=n(Ql,"UL",{});var we=s(Ee);v5=n(we,"LI",{});var KIe=s(v5);V7e=n(KIe,"STRONG",{});var dLt=s(V7e);rSr=r(dLt,"albert"),dLt.forEach(t),tSr=r(KIe," \u2014 "),PY=n(KIe,"A",{href:!0});var cLt=s(PY);aSr=r(cLt,"FlaxAlbertForPreTraining"),cLt.forEach(t),nSr=r(KIe," (ALBERT model)"),KIe.forEach(t),sSr=i(we),F5=n(we,"LI",{});var ZIe=s(F5);X7e=n(ZIe,"STRONG",{});var fLt=s(X7e);lSr=r(fLt,"bart"),fLt.forEach(t),iSr=r(ZIe," \u2014 "),BY=n(ZIe,"A",{href:!0});var mLt=s(BY);dSr=r(mLt,"FlaxBartForConditionalGeneration"),mLt.forEach(t),cSr=r(ZIe," (BART model)"),ZIe.forEach(t),fSr=i(we),T5=n(we,"LI",{});var eNe=s(T5);z7e=n(eNe,"STRONG",{});var gLt=s(z7e);mSr=r(gLt,"bert"),gLt.forEach(t),gSr=r(eNe," \u2014 "),IY=n(eNe,"A",{href:!0});var hLt=s(IY);hSr=r(hLt,"FlaxBertForPreTraining"),hLt.forEach(t),pSr=r(eNe," (BERT model)"),eNe.forEach(t),_Sr=i(we),M5=n(we,"LI",{});var oNe=s(M5);W7e=n(oNe,"STRONG",{});var pLt=s(W7e);uSr=r(pLt,"big_bird"),pLt.forEach(t),bSr=r(oNe," \u2014 "),NY=n(oNe,"A",{href:!0});var _Lt=s(NY);vSr=r(_Lt,"FlaxBigBirdForPreTraining"),_Lt.forEach(t),FSr=r(oNe," (BigBird model)"),oNe.forEach(t),TSr=i(we),E5=n(we,"LI",{});var rNe=s(E5);Q7e=n(rNe,"STRONG",{});var uLt=s(Q7e);MSr=r(uLt,"electra"),uLt.forEach(t),ESr=r(rNe," \u2014 "),qY=n(rNe,"A",{href:!0});var bLt=s(qY);CSr=r(bLt,"FlaxElectraForPreTraining"),bLt.forEach(t),wSr=r(rNe," (ELECTRA model)"),rNe.forEach(t),ASr=i(we),C5=n(we,"LI",{});var tNe=s(C5);H7e=n(tNe,"STRONG",{});var vLt=s(H7e);ySr=r(vLt,"mbart"),vLt.forEach(t),LSr=r(tNe," \u2014 "),jY=n(tNe,"A",{href:!0});var FLt=s(jY);xSr=r(FLt,"FlaxMBartForConditionalGeneration"),FLt.forEach(t),$Sr=r(tNe," (mBART model)"),tNe.forEach(t),kSr=i(we),w5=n(we,"LI",{});var aNe=s(w5);U7e=n(aNe,"STRONG",{});var TLt=s(U7e);SSr=r(TLt,"mt5"),TLt.forEach(t),RSr=r(aNe," \u2014 "),DY=n(aNe,"A",{href:!0});var MLt=s(DY);PSr=r(MLt,"FlaxMT5ForConditionalGeneration"),MLt.forEach(t),BSr=r(aNe," (mT5 model)"),aNe.forEach(t),ISr=i(we),A5=n(we,"LI",{});var nNe=s(A5);J7e=n(nNe,"STRONG",{});var ELt=s(J7e);NSr=r(ELt,"roberta"),ELt.forEach(t),qSr=r(nNe," \u2014 "),GY=n(nNe,"A",{href:!0});var CLt=s(GY);jSr=r(CLt,"FlaxRobertaForMaskedLM"),CLt.forEach(t),DSr=r(nNe," (RoBERTa model)"),nNe.forEach(t),GSr=i(we),y5=n(we,"LI",{});var sNe=s(y5);Y7e=n(sNe,"STRONG",{});var wLt=s(Y7e);OSr=r(wLt,"roformer"),wLt.forEach(t),VSr=r(sNe," \u2014 "),OY=n(sNe,"A",{href:!0});var ALt=s(OY);XSr=r(ALt,"FlaxRoFormerForMaskedLM"),ALt.forEach(t),zSr=r(sNe," (RoFormer model)"),sNe.forEach(t),WSr=i(we),L5=n(we,"LI",{});var lNe=s(L5);K7e=n(lNe,"STRONG",{});var yLt=s(K7e);QSr=r(yLt,"t5"),yLt.forEach(t),HSr=r(lNe," \u2014 "),VY=n(lNe,"A",{href:!0});var LLt=s(VY);USr=r(LLt,"FlaxT5ForConditionalGeneration"),LLt.forEach(t),JSr=r(lNe," (T5 model)"),lNe.forEach(t),YSr=i(we),x5=n(we,"LI",{});var iNe=s(x5);Z7e=n(iNe,"STRONG",{});var xLt=s(Z7e);KSr=r(xLt,"wav2vec2"),xLt.forEach(t),ZSr=r(iNe," \u2014 "),XY=n(iNe,"A",{href:!0});var $Lt=s(XY);eRr=r($Lt,"FlaxWav2Vec2ForPreTraining"),$Lt.forEach(t),oRr=r(iNe," (Wav2Vec2 model)"),iNe.forEach(t),rRr=i(we),$5=n(we,"LI",{});var dNe=s($5);eMe=n(dNe,"STRONG",{});var kLt=s(eMe);tRr=r(kLt,"xlm-roberta"),kLt.forEach(t),aRr=r(dNe," \u2014 "),zY=n(dNe,"A",{href:!0});var SLt=s(zY);nRr=r(SLt,"FlaxXLMRobertaForMaskedLM"),SLt.forEach(t),sRr=r(dNe," (XLM-RoBERTa model)"),dNe.forEach(t),we.forEach(t),lRr=i(Ql),T(k5.$$.fragment,Ql),Ql.forEach(t),Wl.forEach(t),eDe=i(f),jc=n(f,"H2",{class:!0});var lOe=s(jc);S5=n(lOe,"A",{id:!0,class:!0,href:!0});var RLt=s(S5);oMe=n(RLt,"SPAN",{});var PLt=s(oMe);T(X9.$$.fragment,PLt),PLt.forEach(t),RLt.forEach(t),iRr=i(lOe),rMe=n(lOe,"SPAN",{});var BLt=s(rMe);dRr=r(BLt,"FlaxAutoModelForMaskedLM"),BLt.forEach(t),lOe.forEach(t),oDe=i(f),hr=n(f,"DIV",{class:!0});var Hl=s(hr);T(z9.$$.fragment,Hl),cRr=i(Hl),Dc=n(Hl,"P",{});var Kee=s(Dc);fRr=r(Kee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),WY=n(Kee,"A",{href:!0});var ILt=s(WY);mRr=r(ILt,"from_pretrained()"),ILt.forEach(t),gRr=r(Kee," class method or the "),QY=n(Kee,"A",{href:!0});var NLt=s(QY);hRr=r(NLt,"from_config()"),NLt.forEach(t),pRr=r(Kee,` class
method.`),Kee.forEach(t),_Rr=i(Hl),W9=n(Hl,"P",{});var iOe=s(W9);uRr=r(iOe,"This class cannot be instantiated directly using "),tMe=n(iOe,"CODE",{});var qLt=s(tMe);bRr=r(qLt,"__init__()"),qLt.forEach(t),vRr=r(iOe," (throws an error)."),iOe.forEach(t),FRr=i(Hl),Xt=n(Hl,"DIV",{class:!0});var dA=s(Xt);T(Q9.$$.fragment,dA),TRr=i(dA),aMe=n(dA,"P",{});var jLt=s(aMe);MRr=r(jLt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),jLt.forEach(t),ERr=i(dA),Gc=n(dA,"P",{});var Zee=s(Gc);CRr=r(Zee,`Note:
Loading a model from its configuration file does `),nMe=n(Zee,"STRONG",{});var DLt=s(nMe);wRr=r(DLt,"not"),DLt.forEach(t),ARr=r(Zee,` load the model weights. It only affects the
model\u2019s configuration. Use `),HY=n(Zee,"A",{href:!0});var GLt=s(HY);yRr=r(GLt,"from_pretrained()"),GLt.forEach(t),LRr=r(Zee," to load the model weights."),Zee.forEach(t),xRr=i(dA),T(R5.$$.fragment,dA),dA.forEach(t),$Rr=i(Hl),Or=n(Hl,"DIV",{class:!0});var Ul=s(Or);T(H9.$$.fragment,Ul),kRr=i(Ul),sMe=n(Ul,"P",{});var OLt=s(sMe);SRr=r(OLt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),OLt.forEach(t),RRr=i(Ul),un=n(Ul,"P",{});var cA=s(un);PRr=r(cA,"The model class to instantiate is selected based on the "),lMe=n(cA,"CODE",{});var VLt=s(lMe);BRr=r(VLt,"model_type"),VLt.forEach(t),IRr=r(cA,` property of the config object (either
passed as an argument or loaded from `),iMe=n(cA,"CODE",{});var XLt=s(iMe);NRr=r(XLt,"pretrained_model_name_or_path"),XLt.forEach(t),qRr=r(cA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dMe=n(cA,"CODE",{});var zLt=s(dMe);jRr=r(zLt,"pretrained_model_name_or_path"),zLt.forEach(t),DRr=r(cA,":"),cA.forEach(t),GRr=i(Ul),Le=n(Ul,"UL",{});var Ie=s(Le);P5=n(Ie,"LI",{});var cNe=s(P5);cMe=n(cNe,"STRONG",{});var WLt=s(cMe);ORr=r(WLt,"albert"),WLt.forEach(t),VRr=r(cNe," \u2014 "),UY=n(cNe,"A",{href:!0});var QLt=s(UY);XRr=r(QLt,"FlaxAlbertForMaskedLM"),QLt.forEach(t),zRr=r(cNe," (ALBERT model)"),cNe.forEach(t),WRr=i(Ie),B5=n(Ie,"LI",{});var fNe=s(B5);fMe=n(fNe,"STRONG",{});var HLt=s(fMe);QRr=r(HLt,"bart"),HLt.forEach(t),HRr=r(fNe," \u2014 "),JY=n(fNe,"A",{href:!0});var ULt=s(JY);URr=r(ULt,"FlaxBartForConditionalGeneration"),ULt.forEach(t),JRr=r(fNe," (BART model)"),fNe.forEach(t),YRr=i(Ie),I5=n(Ie,"LI",{});var mNe=s(I5);mMe=n(mNe,"STRONG",{});var JLt=s(mMe);KRr=r(JLt,"bert"),JLt.forEach(t),ZRr=r(mNe," \u2014 "),YY=n(mNe,"A",{href:!0});var YLt=s(YY);ePr=r(YLt,"FlaxBertForMaskedLM"),YLt.forEach(t),oPr=r(mNe," (BERT model)"),mNe.forEach(t),rPr=i(Ie),N5=n(Ie,"LI",{});var gNe=s(N5);gMe=n(gNe,"STRONG",{});var KLt=s(gMe);tPr=r(KLt,"big_bird"),KLt.forEach(t),aPr=r(gNe," \u2014 "),KY=n(gNe,"A",{href:!0});var ZLt=s(KY);nPr=r(ZLt,"FlaxBigBirdForMaskedLM"),ZLt.forEach(t),sPr=r(gNe," (BigBird model)"),gNe.forEach(t),lPr=i(Ie),q5=n(Ie,"LI",{});var hNe=s(q5);hMe=n(hNe,"STRONG",{});var e8t=s(hMe);iPr=r(e8t,"distilbert"),e8t.forEach(t),dPr=r(hNe," \u2014 "),ZY=n(hNe,"A",{href:!0});var o8t=s(ZY);cPr=r(o8t,"FlaxDistilBertForMaskedLM"),o8t.forEach(t),fPr=r(hNe," (DistilBERT model)"),hNe.forEach(t),mPr=i(Ie),j5=n(Ie,"LI",{});var pNe=s(j5);pMe=n(pNe,"STRONG",{});var r8t=s(pMe);gPr=r(r8t,"electra"),r8t.forEach(t),hPr=r(pNe," \u2014 "),eK=n(pNe,"A",{href:!0});var t8t=s(eK);pPr=r(t8t,"FlaxElectraForMaskedLM"),t8t.forEach(t),_Pr=r(pNe," (ELECTRA model)"),pNe.forEach(t),uPr=i(Ie),D5=n(Ie,"LI",{});var _Ne=s(D5);_Me=n(_Ne,"STRONG",{});var a8t=s(_Me);bPr=r(a8t,"mbart"),a8t.forEach(t),vPr=r(_Ne," \u2014 "),oK=n(_Ne,"A",{href:!0});var n8t=s(oK);FPr=r(n8t,"FlaxMBartForConditionalGeneration"),n8t.forEach(t),TPr=r(_Ne," (mBART model)"),_Ne.forEach(t),MPr=i(Ie),G5=n(Ie,"LI",{});var uNe=s(G5);uMe=n(uNe,"STRONG",{});var s8t=s(uMe);EPr=r(s8t,"roberta"),s8t.forEach(t),CPr=r(uNe," \u2014 "),rK=n(uNe,"A",{href:!0});var l8t=s(rK);wPr=r(l8t,"FlaxRobertaForMaskedLM"),l8t.forEach(t),APr=r(uNe," (RoBERTa model)"),uNe.forEach(t),yPr=i(Ie),O5=n(Ie,"LI",{});var bNe=s(O5);bMe=n(bNe,"STRONG",{});var i8t=s(bMe);LPr=r(i8t,"roformer"),i8t.forEach(t),xPr=r(bNe," \u2014 "),tK=n(bNe,"A",{href:!0});var d8t=s(tK);$Pr=r(d8t,"FlaxRoFormerForMaskedLM"),d8t.forEach(t),kPr=r(bNe," (RoFormer model)"),bNe.forEach(t),SPr=i(Ie),V5=n(Ie,"LI",{});var vNe=s(V5);vMe=n(vNe,"STRONG",{});var c8t=s(vMe);RPr=r(c8t,"xlm-roberta"),c8t.forEach(t),PPr=r(vNe," \u2014 "),aK=n(vNe,"A",{href:!0});var f8t=s(aK);BPr=r(f8t,"FlaxXLMRobertaForMaskedLM"),f8t.forEach(t),IPr=r(vNe," (XLM-RoBERTa model)"),vNe.forEach(t),Ie.forEach(t),NPr=i(Ul),T(X5.$$.fragment,Ul),Ul.forEach(t),Hl.forEach(t),rDe=i(f),Oc=n(f,"H2",{class:!0});var dOe=s(Oc);z5=n(dOe,"A",{id:!0,class:!0,href:!0});var m8t=s(z5);FMe=n(m8t,"SPAN",{});var g8t=s(FMe);T(U9.$$.fragment,g8t),g8t.forEach(t),m8t.forEach(t),qPr=i(dOe),TMe=n(dOe,"SPAN",{});var h8t=s(TMe);jPr=r(h8t,"FlaxAutoModelForSeq2SeqLM"),h8t.forEach(t),dOe.forEach(t),tDe=i(f),pr=n(f,"DIV",{class:!0});var Jl=s(pr);T(J9.$$.fragment,Jl),DPr=i(Jl),Vc=n(Jl,"P",{});var eoe=s(Vc);GPr=r(eoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),nK=n(eoe,"A",{href:!0});var p8t=s(nK);OPr=r(p8t,"from_pretrained()"),p8t.forEach(t),VPr=r(eoe," class method or the "),sK=n(eoe,"A",{href:!0});var _8t=s(sK);XPr=r(_8t,"from_config()"),_8t.forEach(t),zPr=r(eoe,` class
method.`),eoe.forEach(t),WPr=i(Jl),Y9=n(Jl,"P",{});var cOe=s(Y9);QPr=r(cOe,"This class cannot be instantiated directly using "),MMe=n(cOe,"CODE",{});var u8t=s(MMe);HPr=r(u8t,"__init__()"),u8t.forEach(t),UPr=r(cOe," (throws an error)."),cOe.forEach(t),JPr=i(Jl),zt=n(Jl,"DIV",{class:!0});var fA=s(zt);T(K9.$$.fragment,fA),YPr=i(fA),EMe=n(fA,"P",{});var b8t=s(EMe);KPr=r(b8t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),b8t.forEach(t),ZPr=i(fA),Xc=n(fA,"P",{});var ooe=s(Xc);eBr=r(ooe,`Note:
Loading a model from its configuration file does `),CMe=n(ooe,"STRONG",{});var v8t=s(CMe);oBr=r(v8t,"not"),v8t.forEach(t),rBr=r(ooe,` load the model weights. It only affects the
model\u2019s configuration. Use `),lK=n(ooe,"A",{href:!0});var F8t=s(lK);tBr=r(F8t,"from_pretrained()"),F8t.forEach(t),aBr=r(ooe," to load the model weights."),ooe.forEach(t),nBr=i(fA),T(W5.$$.fragment,fA),fA.forEach(t),sBr=i(Jl),Vr=n(Jl,"DIV",{class:!0});var Yl=s(Vr);T(Z9.$$.fragment,Yl),lBr=i(Yl),wMe=n(Yl,"P",{});var T8t=s(wMe);iBr=r(T8t,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),T8t.forEach(t),dBr=i(Yl),bn=n(Yl,"P",{});var mA=s(bn);cBr=r(mA,"The model class to instantiate is selected based on the "),AMe=n(mA,"CODE",{});var M8t=s(AMe);fBr=r(M8t,"model_type"),M8t.forEach(t),mBr=r(mA,` property of the config object (either
passed as an argument or loaded from `),yMe=n(mA,"CODE",{});var E8t=s(yMe);gBr=r(E8t,"pretrained_model_name_or_path"),E8t.forEach(t),hBr=r(mA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LMe=n(mA,"CODE",{});var C8t=s(LMe);pBr=r(C8t,"pretrained_model_name_or_path"),C8t.forEach(t),_Br=r(mA,":"),mA.forEach(t),uBr=i(Yl),Pe=n(Yl,"UL",{});var ze=s(Pe);Q5=n(ze,"LI",{});var FNe=s(Q5);xMe=n(FNe,"STRONG",{});var w8t=s(xMe);bBr=r(w8t,"bart"),w8t.forEach(t),vBr=r(FNe," \u2014 "),iK=n(FNe,"A",{href:!0});var A8t=s(iK);FBr=r(A8t,"FlaxBartForConditionalGeneration"),A8t.forEach(t),TBr=r(FNe," (BART model)"),FNe.forEach(t),MBr=i(ze),H5=n(ze,"LI",{});var TNe=s(H5);$Me=n(TNe,"STRONG",{});var y8t=s($Me);EBr=r(y8t,"blenderbot"),y8t.forEach(t),CBr=r(TNe," \u2014 "),dK=n(TNe,"A",{href:!0});var L8t=s(dK);wBr=r(L8t,"FlaxBlenderbotForConditionalGeneration"),L8t.forEach(t),ABr=r(TNe," (Blenderbot model)"),TNe.forEach(t),yBr=i(ze),U5=n(ze,"LI",{});var MNe=s(U5);kMe=n(MNe,"STRONG",{});var x8t=s(kMe);LBr=r(x8t,"blenderbot-small"),x8t.forEach(t),xBr=r(MNe," \u2014 "),cK=n(MNe,"A",{href:!0});var $8t=s(cK);$Br=r($8t,"FlaxBlenderbotSmallForConditionalGeneration"),$8t.forEach(t),kBr=r(MNe," (BlenderbotSmall model)"),MNe.forEach(t),SBr=i(ze),J5=n(ze,"LI",{});var ENe=s(J5);SMe=n(ENe,"STRONG",{});var k8t=s(SMe);RBr=r(k8t,"encoder-decoder"),k8t.forEach(t),PBr=r(ENe," \u2014 "),fK=n(ENe,"A",{href:!0});var S8t=s(fK);BBr=r(S8t,"FlaxEncoderDecoderModel"),S8t.forEach(t),IBr=r(ENe," (Encoder decoder model)"),ENe.forEach(t),NBr=i(ze),Y5=n(ze,"LI",{});var CNe=s(Y5);RMe=n(CNe,"STRONG",{});var R8t=s(RMe);qBr=r(R8t,"marian"),R8t.forEach(t),jBr=r(CNe," \u2014 "),mK=n(CNe,"A",{href:!0});var P8t=s(mK);DBr=r(P8t,"FlaxMarianMTModel"),P8t.forEach(t),GBr=r(CNe," (Marian model)"),CNe.forEach(t),OBr=i(ze),K5=n(ze,"LI",{});var wNe=s(K5);PMe=n(wNe,"STRONG",{});var B8t=s(PMe);VBr=r(B8t,"mbart"),B8t.forEach(t),XBr=r(wNe," \u2014 "),gK=n(wNe,"A",{href:!0});var I8t=s(gK);zBr=r(I8t,"FlaxMBartForConditionalGeneration"),I8t.forEach(t),WBr=r(wNe," (mBART model)"),wNe.forEach(t),QBr=i(ze),Z5=n(ze,"LI",{});var ANe=s(Z5);BMe=n(ANe,"STRONG",{});var N8t=s(BMe);HBr=r(N8t,"mt5"),N8t.forEach(t),UBr=r(ANe," \u2014 "),hK=n(ANe,"A",{href:!0});var q8t=s(hK);JBr=r(q8t,"FlaxMT5ForConditionalGeneration"),q8t.forEach(t),YBr=r(ANe," (mT5 model)"),ANe.forEach(t),KBr=i(ze),e3=n(ze,"LI",{});var yNe=s(e3);IMe=n(yNe,"STRONG",{});var j8t=s(IMe);ZBr=r(j8t,"pegasus"),j8t.forEach(t),eIr=r(yNe," \u2014 "),pK=n(yNe,"A",{href:!0});var D8t=s(pK);oIr=r(D8t,"FlaxPegasusForConditionalGeneration"),D8t.forEach(t),rIr=r(yNe," (Pegasus model)"),yNe.forEach(t),tIr=i(ze),o3=n(ze,"LI",{});var LNe=s(o3);NMe=n(LNe,"STRONG",{});var G8t=s(NMe);aIr=r(G8t,"t5"),G8t.forEach(t),nIr=r(LNe," \u2014 "),_K=n(LNe,"A",{href:!0});var O8t=s(_K);sIr=r(O8t,"FlaxT5ForConditionalGeneration"),O8t.forEach(t),lIr=r(LNe," (T5 model)"),LNe.forEach(t),ze.forEach(t),iIr=i(Yl),T(r3.$$.fragment,Yl),Yl.forEach(t),Jl.forEach(t),aDe=i(f),zc=n(f,"H2",{class:!0});var fOe=s(zc);t3=n(fOe,"A",{id:!0,class:!0,href:!0});var V8t=s(t3);qMe=n(V8t,"SPAN",{});var X8t=s(qMe);T(ex.$$.fragment,X8t),X8t.forEach(t),V8t.forEach(t),dIr=i(fOe),jMe=n(fOe,"SPAN",{});var z8t=s(jMe);cIr=r(z8t,"FlaxAutoModelForSequenceClassification"),z8t.forEach(t),fOe.forEach(t),nDe=i(f),_r=n(f,"DIV",{class:!0});var Kl=s(_r);T(ox.$$.fragment,Kl),fIr=i(Kl),Wc=n(Kl,"P",{});var roe=s(Wc);mIr=r(roe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),uK=n(roe,"A",{href:!0});var W8t=s(uK);gIr=r(W8t,"from_pretrained()"),W8t.forEach(t),hIr=r(roe," class method or the "),bK=n(roe,"A",{href:!0});var Q8t=s(bK);pIr=r(Q8t,"from_config()"),Q8t.forEach(t),_Ir=r(roe,` class
method.`),roe.forEach(t),uIr=i(Kl),rx=n(Kl,"P",{});var mOe=s(rx);bIr=r(mOe,"This class cannot be instantiated directly using "),DMe=n(mOe,"CODE",{});var H8t=s(DMe);vIr=r(H8t,"__init__()"),H8t.forEach(t),FIr=r(mOe," (throws an error)."),mOe.forEach(t),TIr=i(Kl),Wt=n(Kl,"DIV",{class:!0});var gA=s(Wt);T(tx.$$.fragment,gA),MIr=i(gA),GMe=n(gA,"P",{});var U8t=s(GMe);EIr=r(U8t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),U8t.forEach(t),CIr=i(gA),Qc=n(gA,"P",{});var toe=s(Qc);wIr=r(toe,`Note:
Loading a model from its configuration file does `),OMe=n(toe,"STRONG",{});var J8t=s(OMe);AIr=r(J8t,"not"),J8t.forEach(t),yIr=r(toe,` load the model weights. It only affects the
model\u2019s configuration. Use `),vK=n(toe,"A",{href:!0});var Y8t=s(vK);LIr=r(Y8t,"from_pretrained()"),Y8t.forEach(t),xIr=r(toe," to load the model weights."),toe.forEach(t),$Ir=i(gA),T(a3.$$.fragment,gA),gA.forEach(t),kIr=i(Kl),Xr=n(Kl,"DIV",{class:!0});var Zl=s(Xr);T(ax.$$.fragment,Zl),SIr=i(Zl),VMe=n(Zl,"P",{});var K8t=s(VMe);RIr=r(K8t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),K8t.forEach(t),PIr=i(Zl),vn=n(Zl,"P",{});var hA=s(vn);BIr=r(hA,"The model class to instantiate is selected based on the "),XMe=n(hA,"CODE",{});var Z8t=s(XMe);IIr=r(Z8t,"model_type"),Z8t.forEach(t),NIr=r(hA,` property of the config object (either
passed as an argument or loaded from `),zMe=n(hA,"CODE",{});var e9t=s(zMe);qIr=r(e9t,"pretrained_model_name_or_path"),e9t.forEach(t),jIr=r(hA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WMe=n(hA,"CODE",{});var o9t=s(WMe);DIr=r(o9t,"pretrained_model_name_or_path"),o9t.forEach(t),GIr=r(hA,":"),hA.forEach(t),OIr=i(Zl),xe=n(Zl,"UL",{});var Ne=s(xe);n3=n(Ne,"LI",{});var xNe=s(n3);QMe=n(xNe,"STRONG",{});var r9t=s(QMe);VIr=r(r9t,"albert"),r9t.forEach(t),XIr=r(xNe," \u2014 "),FK=n(xNe,"A",{href:!0});var t9t=s(FK);zIr=r(t9t,"FlaxAlbertForSequenceClassification"),t9t.forEach(t),WIr=r(xNe," (ALBERT model)"),xNe.forEach(t),QIr=i(Ne),s3=n(Ne,"LI",{});var $Ne=s(s3);HMe=n($Ne,"STRONG",{});var a9t=s(HMe);HIr=r(a9t,"bart"),a9t.forEach(t),UIr=r($Ne," \u2014 "),TK=n($Ne,"A",{href:!0});var n9t=s(TK);JIr=r(n9t,"FlaxBartForSequenceClassification"),n9t.forEach(t),YIr=r($Ne," (BART model)"),$Ne.forEach(t),KIr=i(Ne),l3=n(Ne,"LI",{});var kNe=s(l3);UMe=n(kNe,"STRONG",{});var s9t=s(UMe);ZIr=r(s9t,"bert"),s9t.forEach(t),eNr=r(kNe," \u2014 "),MK=n(kNe,"A",{href:!0});var l9t=s(MK);oNr=r(l9t,"FlaxBertForSequenceClassification"),l9t.forEach(t),rNr=r(kNe," (BERT model)"),kNe.forEach(t),tNr=i(Ne),i3=n(Ne,"LI",{});var SNe=s(i3);JMe=n(SNe,"STRONG",{});var i9t=s(JMe);aNr=r(i9t,"big_bird"),i9t.forEach(t),nNr=r(SNe," \u2014 "),EK=n(SNe,"A",{href:!0});var d9t=s(EK);sNr=r(d9t,"FlaxBigBirdForSequenceClassification"),d9t.forEach(t),lNr=r(SNe," (BigBird model)"),SNe.forEach(t),iNr=i(Ne),d3=n(Ne,"LI",{});var RNe=s(d3);YMe=n(RNe,"STRONG",{});var c9t=s(YMe);dNr=r(c9t,"distilbert"),c9t.forEach(t),cNr=r(RNe," \u2014 "),CK=n(RNe,"A",{href:!0});var f9t=s(CK);fNr=r(f9t,"FlaxDistilBertForSequenceClassification"),f9t.forEach(t),mNr=r(RNe," (DistilBERT model)"),RNe.forEach(t),gNr=i(Ne),c3=n(Ne,"LI",{});var PNe=s(c3);KMe=n(PNe,"STRONG",{});var m9t=s(KMe);hNr=r(m9t,"electra"),m9t.forEach(t),pNr=r(PNe," \u2014 "),wK=n(PNe,"A",{href:!0});var g9t=s(wK);_Nr=r(g9t,"FlaxElectraForSequenceClassification"),g9t.forEach(t),uNr=r(PNe," (ELECTRA model)"),PNe.forEach(t),bNr=i(Ne),f3=n(Ne,"LI",{});var BNe=s(f3);ZMe=n(BNe,"STRONG",{});var h9t=s(ZMe);vNr=r(h9t,"mbart"),h9t.forEach(t),FNr=r(BNe," \u2014 "),AK=n(BNe,"A",{href:!0});var p9t=s(AK);TNr=r(p9t,"FlaxMBartForSequenceClassification"),p9t.forEach(t),MNr=r(BNe," (mBART model)"),BNe.forEach(t),ENr=i(Ne),m3=n(Ne,"LI",{});var INe=s(m3);eEe=n(INe,"STRONG",{});var _9t=s(eEe);CNr=r(_9t,"roberta"),_9t.forEach(t),wNr=r(INe," \u2014 "),yK=n(INe,"A",{href:!0});var u9t=s(yK);ANr=r(u9t,"FlaxRobertaForSequenceClassification"),u9t.forEach(t),yNr=r(INe," (RoBERTa model)"),INe.forEach(t),LNr=i(Ne),g3=n(Ne,"LI",{});var NNe=s(g3);oEe=n(NNe,"STRONG",{});var b9t=s(oEe);xNr=r(b9t,"roformer"),b9t.forEach(t),$Nr=r(NNe," \u2014 "),LK=n(NNe,"A",{href:!0});var v9t=s(LK);kNr=r(v9t,"FlaxRoFormerForSequenceClassification"),v9t.forEach(t),SNr=r(NNe," (RoFormer model)"),NNe.forEach(t),RNr=i(Ne),h3=n(Ne,"LI",{});var qNe=s(h3);rEe=n(qNe,"STRONG",{});var F9t=s(rEe);PNr=r(F9t,"xlm-roberta"),F9t.forEach(t),BNr=r(qNe," \u2014 "),xK=n(qNe,"A",{href:!0});var T9t=s(xK);INr=r(T9t,"FlaxXLMRobertaForSequenceClassification"),T9t.forEach(t),NNr=r(qNe," (XLM-RoBERTa model)"),qNe.forEach(t),Ne.forEach(t),qNr=i(Zl),T(p3.$$.fragment,Zl),Zl.forEach(t),Kl.forEach(t),sDe=i(f),Hc=n(f,"H2",{class:!0});var gOe=s(Hc);_3=n(gOe,"A",{id:!0,class:!0,href:!0});var M9t=s(_3);tEe=n(M9t,"SPAN",{});var E9t=s(tEe);T(nx.$$.fragment,E9t),E9t.forEach(t),M9t.forEach(t),jNr=i(gOe),aEe=n(gOe,"SPAN",{});var C9t=s(aEe);DNr=r(C9t,"FlaxAutoModelForQuestionAnswering"),C9t.forEach(t),gOe.forEach(t),lDe=i(f),ur=n(f,"DIV",{class:!0});var ei=s(ur);T(sx.$$.fragment,ei),GNr=i(ei),Uc=n(ei,"P",{});var aoe=s(Uc);ONr=r(aoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),$K=n(aoe,"A",{href:!0});var w9t=s($K);VNr=r(w9t,"from_pretrained()"),w9t.forEach(t),XNr=r(aoe," class method or the "),kK=n(aoe,"A",{href:!0});var A9t=s(kK);zNr=r(A9t,"from_config()"),A9t.forEach(t),WNr=r(aoe,` class
method.`),aoe.forEach(t),QNr=i(ei),lx=n(ei,"P",{});var hOe=s(lx);HNr=r(hOe,"This class cannot be instantiated directly using "),nEe=n(hOe,"CODE",{});var y9t=s(nEe);UNr=r(y9t,"__init__()"),y9t.forEach(t),JNr=r(hOe," (throws an error)."),hOe.forEach(t),YNr=i(ei),Qt=n(ei,"DIV",{class:!0});var pA=s(Qt);T(ix.$$.fragment,pA),KNr=i(pA),sEe=n(pA,"P",{});var L9t=s(sEe);ZNr=r(L9t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),L9t.forEach(t),eqr=i(pA),Jc=n(pA,"P",{});var noe=s(Jc);oqr=r(noe,`Note:
Loading a model from its configuration file does `),lEe=n(noe,"STRONG",{});var x9t=s(lEe);rqr=r(x9t,"not"),x9t.forEach(t),tqr=r(noe,` load the model weights. It only affects the
model\u2019s configuration. Use `),SK=n(noe,"A",{href:!0});var $9t=s(SK);aqr=r($9t,"from_pretrained()"),$9t.forEach(t),nqr=r(noe," to load the model weights."),noe.forEach(t),sqr=i(pA),T(u3.$$.fragment,pA),pA.forEach(t),lqr=i(ei),zr=n(ei,"DIV",{class:!0});var oi=s(zr);T(dx.$$.fragment,oi),iqr=i(oi),iEe=n(oi,"P",{});var k9t=s(iEe);dqr=r(k9t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),k9t.forEach(t),cqr=i(oi),Fn=n(oi,"P",{});var _A=s(Fn);fqr=r(_A,"The model class to instantiate is selected based on the "),dEe=n(_A,"CODE",{});var S9t=s(dEe);mqr=r(S9t,"model_type"),S9t.forEach(t),gqr=r(_A,` property of the config object (either
passed as an argument or loaded from `),cEe=n(_A,"CODE",{});var R9t=s(cEe);hqr=r(R9t,"pretrained_model_name_or_path"),R9t.forEach(t),pqr=r(_A,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fEe=n(_A,"CODE",{});var P9t=s(fEe);_qr=r(P9t,"pretrained_model_name_or_path"),P9t.forEach(t),uqr=r(_A,":"),_A.forEach(t),bqr=i(oi),$e=n(oi,"UL",{});var qe=s($e);b3=n(qe,"LI",{});var jNe=s(b3);mEe=n(jNe,"STRONG",{});var B9t=s(mEe);vqr=r(B9t,"albert"),B9t.forEach(t),Fqr=r(jNe," \u2014 "),RK=n(jNe,"A",{href:!0});var I9t=s(RK);Tqr=r(I9t,"FlaxAlbertForQuestionAnswering"),I9t.forEach(t),Mqr=r(jNe," (ALBERT model)"),jNe.forEach(t),Eqr=i(qe),v3=n(qe,"LI",{});var DNe=s(v3);gEe=n(DNe,"STRONG",{});var N9t=s(gEe);Cqr=r(N9t,"bart"),N9t.forEach(t),wqr=r(DNe," \u2014 "),PK=n(DNe,"A",{href:!0});var q9t=s(PK);Aqr=r(q9t,"FlaxBartForQuestionAnswering"),q9t.forEach(t),yqr=r(DNe," (BART model)"),DNe.forEach(t),Lqr=i(qe),F3=n(qe,"LI",{});var GNe=s(F3);hEe=n(GNe,"STRONG",{});var j9t=s(hEe);xqr=r(j9t,"bert"),j9t.forEach(t),$qr=r(GNe," \u2014 "),BK=n(GNe,"A",{href:!0});var D9t=s(BK);kqr=r(D9t,"FlaxBertForQuestionAnswering"),D9t.forEach(t),Sqr=r(GNe," (BERT model)"),GNe.forEach(t),Rqr=i(qe),T3=n(qe,"LI",{});var ONe=s(T3);pEe=n(ONe,"STRONG",{});var G9t=s(pEe);Pqr=r(G9t,"big_bird"),G9t.forEach(t),Bqr=r(ONe," \u2014 "),IK=n(ONe,"A",{href:!0});var O9t=s(IK);Iqr=r(O9t,"FlaxBigBirdForQuestionAnswering"),O9t.forEach(t),Nqr=r(ONe," (BigBird model)"),ONe.forEach(t),qqr=i(qe),M3=n(qe,"LI",{});var VNe=s(M3);_Ee=n(VNe,"STRONG",{});var V9t=s(_Ee);jqr=r(V9t,"distilbert"),V9t.forEach(t),Dqr=r(VNe," \u2014 "),NK=n(VNe,"A",{href:!0});var X9t=s(NK);Gqr=r(X9t,"FlaxDistilBertForQuestionAnswering"),X9t.forEach(t),Oqr=r(VNe," (DistilBERT model)"),VNe.forEach(t),Vqr=i(qe),E3=n(qe,"LI",{});var XNe=s(E3);uEe=n(XNe,"STRONG",{});var z9t=s(uEe);Xqr=r(z9t,"electra"),z9t.forEach(t),zqr=r(XNe," \u2014 "),qK=n(XNe,"A",{href:!0});var W9t=s(qK);Wqr=r(W9t,"FlaxElectraForQuestionAnswering"),W9t.forEach(t),Qqr=r(XNe," (ELECTRA model)"),XNe.forEach(t),Hqr=i(qe),C3=n(qe,"LI",{});var zNe=s(C3);bEe=n(zNe,"STRONG",{});var Q9t=s(bEe);Uqr=r(Q9t,"mbart"),Q9t.forEach(t),Jqr=r(zNe," \u2014 "),jK=n(zNe,"A",{href:!0});var H9t=s(jK);Yqr=r(H9t,"FlaxMBartForQuestionAnswering"),H9t.forEach(t),Kqr=r(zNe," (mBART model)"),zNe.forEach(t),Zqr=i(qe),w3=n(qe,"LI",{});var WNe=s(w3);vEe=n(WNe,"STRONG",{});var U9t=s(vEe);ejr=r(U9t,"roberta"),U9t.forEach(t),ojr=r(WNe," \u2014 "),DK=n(WNe,"A",{href:!0});var J9t=s(DK);rjr=r(J9t,"FlaxRobertaForQuestionAnswering"),J9t.forEach(t),tjr=r(WNe," (RoBERTa model)"),WNe.forEach(t),ajr=i(qe),A3=n(qe,"LI",{});var QNe=s(A3);FEe=n(QNe,"STRONG",{});var Y9t=s(FEe);njr=r(Y9t,"roformer"),Y9t.forEach(t),sjr=r(QNe," \u2014 "),GK=n(QNe,"A",{href:!0});var K9t=s(GK);ljr=r(K9t,"FlaxRoFormerForQuestionAnswering"),K9t.forEach(t),ijr=r(QNe," (RoFormer model)"),QNe.forEach(t),djr=i(qe),y3=n(qe,"LI",{});var HNe=s(y3);TEe=n(HNe,"STRONG",{});var Z9t=s(TEe);cjr=r(Z9t,"xlm-roberta"),Z9t.forEach(t),fjr=r(HNe," \u2014 "),OK=n(HNe,"A",{href:!0});var ext=s(OK);mjr=r(ext,"FlaxXLMRobertaForQuestionAnswering"),ext.forEach(t),gjr=r(HNe," (XLM-RoBERTa model)"),HNe.forEach(t),qe.forEach(t),hjr=i(oi),T(L3.$$.fragment,oi),oi.forEach(t),ei.forEach(t),iDe=i(f),Yc=n(f,"H2",{class:!0});var pOe=s(Yc);x3=n(pOe,"A",{id:!0,class:!0,href:!0});var oxt=s(x3);MEe=n(oxt,"SPAN",{});var rxt=s(MEe);T(cx.$$.fragment,rxt),rxt.forEach(t),oxt.forEach(t),pjr=i(pOe),EEe=n(pOe,"SPAN",{});var txt=s(EEe);_jr=r(txt,"FlaxAutoModelForTokenClassification"),txt.forEach(t),pOe.forEach(t),dDe=i(f),br=n(f,"DIV",{class:!0});var ri=s(br);T(fx.$$.fragment,ri),ujr=i(ri),Kc=n(ri,"P",{});var soe=s(Kc);bjr=r(soe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),VK=n(soe,"A",{href:!0});var axt=s(VK);vjr=r(axt,"from_pretrained()"),axt.forEach(t),Fjr=r(soe," class method or the "),XK=n(soe,"A",{href:!0});var nxt=s(XK);Tjr=r(nxt,"from_config()"),nxt.forEach(t),Mjr=r(soe,` class
method.`),soe.forEach(t),Ejr=i(ri),mx=n(ri,"P",{});var _Oe=s(mx);Cjr=r(_Oe,"This class cannot be instantiated directly using "),CEe=n(_Oe,"CODE",{});var sxt=s(CEe);wjr=r(sxt,"__init__()"),sxt.forEach(t),Ajr=r(_Oe," (throws an error)."),_Oe.forEach(t),yjr=i(ri),Ht=n(ri,"DIV",{class:!0});var uA=s(Ht);T(gx.$$.fragment,uA),Ljr=i(uA),wEe=n(uA,"P",{});var lxt=s(wEe);xjr=r(lxt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),lxt.forEach(t),$jr=i(uA),Zc=n(uA,"P",{});var loe=s(Zc);kjr=r(loe,`Note:
Loading a model from its configuration file does `),AEe=n(loe,"STRONG",{});var ixt=s(AEe);Sjr=r(ixt,"not"),ixt.forEach(t),Rjr=r(loe,` load the model weights. It only affects the
model\u2019s configuration. Use `),zK=n(loe,"A",{href:!0});var dxt=s(zK);Pjr=r(dxt,"from_pretrained()"),dxt.forEach(t),Bjr=r(loe," to load the model weights."),loe.forEach(t),Ijr=i(uA),T($3.$$.fragment,uA),uA.forEach(t),Njr=i(ri),Wr=n(ri,"DIV",{class:!0});var ti=s(Wr);T(hx.$$.fragment,ti),qjr=i(ti),yEe=n(ti,"P",{});var cxt=s(yEe);jjr=r(cxt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),cxt.forEach(t),Djr=i(ti),Tn=n(ti,"P",{});var bA=s(Tn);Gjr=r(bA,"The model class to instantiate is selected based on the "),LEe=n(bA,"CODE",{});var fxt=s(LEe);Ojr=r(fxt,"model_type"),fxt.forEach(t),Vjr=r(bA,` property of the config object (either
passed as an argument or loaded from `),xEe=n(bA,"CODE",{});var mxt=s(xEe);Xjr=r(mxt,"pretrained_model_name_or_path"),mxt.forEach(t),zjr=r(bA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Ee=n(bA,"CODE",{});var gxt=s($Ee);Wjr=r(gxt,"pretrained_model_name_or_path"),gxt.forEach(t),Qjr=r(bA,":"),bA.forEach(t),Hjr=i(ti),De=n(ti,"UL",{});var Fo=s(De);k3=n(Fo,"LI",{});var UNe=s(k3);kEe=n(UNe,"STRONG",{});var hxt=s(kEe);Ujr=r(hxt,"albert"),hxt.forEach(t),Jjr=r(UNe," \u2014 "),WK=n(UNe,"A",{href:!0});var pxt=s(WK);Yjr=r(pxt,"FlaxAlbertForTokenClassification"),pxt.forEach(t),Kjr=r(UNe," (ALBERT model)"),UNe.forEach(t),Zjr=i(Fo),S3=n(Fo,"LI",{});var JNe=s(S3);SEe=n(JNe,"STRONG",{});var _xt=s(SEe);eDr=r(_xt,"bert"),_xt.forEach(t),oDr=r(JNe," \u2014 "),QK=n(JNe,"A",{href:!0});var uxt=s(QK);rDr=r(uxt,"FlaxBertForTokenClassification"),uxt.forEach(t),tDr=r(JNe," (BERT model)"),JNe.forEach(t),aDr=i(Fo),R3=n(Fo,"LI",{});var YNe=s(R3);REe=n(YNe,"STRONG",{});var bxt=s(REe);nDr=r(bxt,"big_bird"),bxt.forEach(t),sDr=r(YNe," \u2014 "),HK=n(YNe,"A",{href:!0});var vxt=s(HK);lDr=r(vxt,"FlaxBigBirdForTokenClassification"),vxt.forEach(t),iDr=r(YNe," (BigBird model)"),YNe.forEach(t),dDr=i(Fo),P3=n(Fo,"LI",{});var KNe=s(P3);PEe=n(KNe,"STRONG",{});var Fxt=s(PEe);cDr=r(Fxt,"distilbert"),Fxt.forEach(t),fDr=r(KNe," \u2014 "),UK=n(KNe,"A",{href:!0});var Txt=s(UK);mDr=r(Txt,"FlaxDistilBertForTokenClassification"),Txt.forEach(t),gDr=r(KNe," (DistilBERT model)"),KNe.forEach(t),hDr=i(Fo),B3=n(Fo,"LI",{});var ZNe=s(B3);BEe=n(ZNe,"STRONG",{});var Mxt=s(BEe);pDr=r(Mxt,"electra"),Mxt.forEach(t),_Dr=r(ZNe," \u2014 "),JK=n(ZNe,"A",{href:!0});var Ext=s(JK);uDr=r(Ext,"FlaxElectraForTokenClassification"),Ext.forEach(t),bDr=r(ZNe," (ELECTRA model)"),ZNe.forEach(t),vDr=i(Fo),I3=n(Fo,"LI",{});var eqe=s(I3);IEe=n(eqe,"STRONG",{});var Cxt=s(IEe);FDr=r(Cxt,"roberta"),Cxt.forEach(t),TDr=r(eqe," \u2014 "),YK=n(eqe,"A",{href:!0});var wxt=s(YK);MDr=r(wxt,"FlaxRobertaForTokenClassification"),wxt.forEach(t),EDr=r(eqe," (RoBERTa model)"),eqe.forEach(t),CDr=i(Fo),N3=n(Fo,"LI",{});var oqe=s(N3);NEe=n(oqe,"STRONG",{});var Axt=s(NEe);wDr=r(Axt,"roformer"),Axt.forEach(t),ADr=r(oqe," \u2014 "),KK=n(oqe,"A",{href:!0});var yxt=s(KK);yDr=r(yxt,"FlaxRoFormerForTokenClassification"),yxt.forEach(t),LDr=r(oqe," (RoFormer model)"),oqe.forEach(t),xDr=i(Fo),q3=n(Fo,"LI",{});var rqe=s(q3);qEe=n(rqe,"STRONG",{});var Lxt=s(qEe);$Dr=r(Lxt,"xlm-roberta"),Lxt.forEach(t),kDr=r(rqe," \u2014 "),ZK=n(rqe,"A",{href:!0});var xxt=s(ZK);SDr=r(xxt,"FlaxXLMRobertaForTokenClassification"),xxt.forEach(t),RDr=r(rqe," (XLM-RoBERTa model)"),rqe.forEach(t),Fo.forEach(t),PDr=i(ti),T(j3.$$.fragment,ti),ti.forEach(t),ri.forEach(t),cDe=i(f),ef=n(f,"H2",{class:!0});var uOe=s(ef);D3=n(uOe,"A",{id:!0,class:!0,href:!0});var $xt=s(D3);jEe=n($xt,"SPAN",{});var kxt=s(jEe);T(px.$$.fragment,kxt),kxt.forEach(t),$xt.forEach(t),BDr=i(uOe),DEe=n(uOe,"SPAN",{});var Sxt=s(DEe);IDr=r(Sxt,"FlaxAutoModelForMultipleChoice"),Sxt.forEach(t),uOe.forEach(t),fDe=i(f),vr=n(f,"DIV",{class:!0});var ai=s(vr);T(_x.$$.fragment,ai),NDr=i(ai),of=n(ai,"P",{});var ioe=s(of);qDr=r(ioe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),eZ=n(ioe,"A",{href:!0});var Rxt=s(eZ);jDr=r(Rxt,"from_pretrained()"),Rxt.forEach(t),DDr=r(ioe," class method or the "),oZ=n(ioe,"A",{href:!0});var Pxt=s(oZ);GDr=r(Pxt,"from_config()"),Pxt.forEach(t),ODr=r(ioe,` class
method.`),ioe.forEach(t),VDr=i(ai),ux=n(ai,"P",{});var bOe=s(ux);XDr=r(bOe,"This class cannot be instantiated directly using "),GEe=n(bOe,"CODE",{});var Bxt=s(GEe);zDr=r(Bxt,"__init__()"),Bxt.forEach(t),WDr=r(bOe," (throws an error)."),bOe.forEach(t),QDr=i(ai),Ut=n(ai,"DIV",{class:!0});var vA=s(Ut);T(bx.$$.fragment,vA),HDr=i(vA),OEe=n(vA,"P",{});var Ixt=s(OEe);UDr=r(Ixt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Ixt.forEach(t),JDr=i(vA),rf=n(vA,"P",{});var doe=s(rf);YDr=r(doe,`Note:
Loading a model from its configuration file does `),VEe=n(doe,"STRONG",{});var Nxt=s(VEe);KDr=r(Nxt,"not"),Nxt.forEach(t),ZDr=r(doe,` load the model weights. It only affects the
model\u2019s configuration. Use `),rZ=n(doe,"A",{href:!0});var qxt=s(rZ);eGr=r(qxt,"from_pretrained()"),qxt.forEach(t),oGr=r(doe," to load the model weights."),doe.forEach(t),rGr=i(vA),T(G3.$$.fragment,vA),vA.forEach(t),tGr=i(ai),Qr=n(ai,"DIV",{class:!0});var ni=s(Qr);T(vx.$$.fragment,ni),aGr=i(ni),XEe=n(ni,"P",{});var jxt=s(XEe);nGr=r(jxt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),jxt.forEach(t),sGr=i(ni),Mn=n(ni,"P",{});var FA=s(Mn);lGr=r(FA,"The model class to instantiate is selected based on the "),zEe=n(FA,"CODE",{});var Dxt=s(zEe);iGr=r(Dxt,"model_type"),Dxt.forEach(t),dGr=r(FA,` property of the config object (either
passed as an argument or loaded from `),WEe=n(FA,"CODE",{});var Gxt=s(WEe);cGr=r(Gxt,"pretrained_model_name_or_path"),Gxt.forEach(t),fGr=r(FA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QEe=n(FA,"CODE",{});var Oxt=s(QEe);mGr=r(Oxt,"pretrained_model_name_or_path"),Oxt.forEach(t),gGr=r(FA,":"),FA.forEach(t),hGr=i(ni),Ge=n(ni,"UL",{});var To=s(Ge);O3=n(To,"LI",{});var tqe=s(O3);HEe=n(tqe,"STRONG",{});var Vxt=s(HEe);pGr=r(Vxt,"albert"),Vxt.forEach(t),_Gr=r(tqe," \u2014 "),tZ=n(tqe,"A",{href:!0});var Xxt=s(tZ);uGr=r(Xxt,"FlaxAlbertForMultipleChoice"),Xxt.forEach(t),bGr=r(tqe," (ALBERT model)"),tqe.forEach(t),vGr=i(To),V3=n(To,"LI",{});var aqe=s(V3);UEe=n(aqe,"STRONG",{});var zxt=s(UEe);FGr=r(zxt,"bert"),zxt.forEach(t),TGr=r(aqe," \u2014 "),aZ=n(aqe,"A",{href:!0});var Wxt=s(aZ);MGr=r(Wxt,"FlaxBertForMultipleChoice"),Wxt.forEach(t),EGr=r(aqe," (BERT model)"),aqe.forEach(t),CGr=i(To),X3=n(To,"LI",{});var nqe=s(X3);JEe=n(nqe,"STRONG",{});var Qxt=s(JEe);wGr=r(Qxt,"big_bird"),Qxt.forEach(t),AGr=r(nqe," \u2014 "),nZ=n(nqe,"A",{href:!0});var Hxt=s(nZ);yGr=r(Hxt,"FlaxBigBirdForMultipleChoice"),Hxt.forEach(t),LGr=r(nqe," (BigBird model)"),nqe.forEach(t),xGr=i(To),z3=n(To,"LI",{});var sqe=s(z3);YEe=n(sqe,"STRONG",{});var Uxt=s(YEe);$Gr=r(Uxt,"distilbert"),Uxt.forEach(t),kGr=r(sqe," \u2014 "),sZ=n(sqe,"A",{href:!0});var Jxt=s(sZ);SGr=r(Jxt,"FlaxDistilBertForMultipleChoice"),Jxt.forEach(t),RGr=r(sqe," (DistilBERT model)"),sqe.forEach(t),PGr=i(To),W3=n(To,"LI",{});var lqe=s(W3);KEe=n(lqe,"STRONG",{});var Yxt=s(KEe);BGr=r(Yxt,"electra"),Yxt.forEach(t),IGr=r(lqe," \u2014 "),lZ=n(lqe,"A",{href:!0});var Kxt=s(lZ);NGr=r(Kxt,"FlaxElectraForMultipleChoice"),Kxt.forEach(t),qGr=r(lqe," (ELECTRA model)"),lqe.forEach(t),jGr=i(To),Q3=n(To,"LI",{});var iqe=s(Q3);ZEe=n(iqe,"STRONG",{});var Zxt=s(ZEe);DGr=r(Zxt,"roberta"),Zxt.forEach(t),GGr=r(iqe," \u2014 "),iZ=n(iqe,"A",{href:!0});var e$t=s(iZ);OGr=r(e$t,"FlaxRobertaForMultipleChoice"),e$t.forEach(t),VGr=r(iqe," (RoBERTa model)"),iqe.forEach(t),XGr=i(To),H3=n(To,"LI",{});var dqe=s(H3);eCe=n(dqe,"STRONG",{});var o$t=s(eCe);zGr=r(o$t,"roformer"),o$t.forEach(t),WGr=r(dqe," \u2014 "),dZ=n(dqe,"A",{href:!0});var r$t=s(dZ);QGr=r(r$t,"FlaxRoFormerForMultipleChoice"),r$t.forEach(t),HGr=r(dqe," (RoFormer model)"),dqe.forEach(t),UGr=i(To),U3=n(To,"LI",{});var cqe=s(U3);oCe=n(cqe,"STRONG",{});var t$t=s(oCe);JGr=r(t$t,"xlm-roberta"),t$t.forEach(t),YGr=r(cqe," \u2014 "),cZ=n(cqe,"A",{href:!0});var a$t=s(cZ);KGr=r(a$t,"FlaxXLMRobertaForMultipleChoice"),a$t.forEach(t),ZGr=r(cqe," (XLM-RoBERTa model)"),cqe.forEach(t),To.forEach(t),eOr=i(ni),T(J3.$$.fragment,ni),ni.forEach(t),ai.forEach(t),mDe=i(f),tf=n(f,"H2",{class:!0});var vOe=s(tf);Y3=n(vOe,"A",{id:!0,class:!0,href:!0});var n$t=s(Y3);rCe=n(n$t,"SPAN",{});var s$t=s(rCe);T(Fx.$$.fragment,s$t),s$t.forEach(t),n$t.forEach(t),oOr=i(vOe),tCe=n(vOe,"SPAN",{});var l$t=s(tCe);rOr=r(l$t,"FlaxAutoModelForNextSentencePrediction"),l$t.forEach(t),vOe.forEach(t),gDe=i(f),Fr=n(f,"DIV",{class:!0});var si=s(Fr);T(Tx.$$.fragment,si),tOr=i(si),af=n(si,"P",{});var coe=s(af);aOr=r(coe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),fZ=n(coe,"A",{href:!0});var i$t=s(fZ);nOr=r(i$t,"from_pretrained()"),i$t.forEach(t),sOr=r(coe," class method or the "),mZ=n(coe,"A",{href:!0});var d$t=s(mZ);lOr=r(d$t,"from_config()"),d$t.forEach(t),iOr=r(coe,` class
method.`),coe.forEach(t),dOr=i(si),Mx=n(si,"P",{});var FOe=s(Mx);cOr=r(FOe,"This class cannot be instantiated directly using "),aCe=n(FOe,"CODE",{});var c$t=s(aCe);fOr=r(c$t,"__init__()"),c$t.forEach(t),mOr=r(FOe," (throws an error)."),FOe.forEach(t),gOr=i(si),Jt=n(si,"DIV",{class:!0});var TA=s(Jt);T(Ex.$$.fragment,TA),hOr=i(TA),nCe=n(TA,"P",{});var f$t=s(nCe);pOr=r(f$t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),f$t.forEach(t),_Or=i(TA),nf=n(TA,"P",{});var foe=s(nf);uOr=r(foe,`Note:
Loading a model from its configuration file does `),sCe=n(foe,"STRONG",{});var m$t=s(sCe);bOr=r(m$t,"not"),m$t.forEach(t),vOr=r(foe,` load the model weights. It only affects the
model\u2019s configuration. Use `),gZ=n(foe,"A",{href:!0});var g$t=s(gZ);FOr=r(g$t,"from_pretrained()"),g$t.forEach(t),TOr=r(foe," to load the model weights."),foe.forEach(t),MOr=i(TA),T(K3.$$.fragment,TA),TA.forEach(t),EOr=i(si),Hr=n(si,"DIV",{class:!0});var li=s(Hr);T(Cx.$$.fragment,li),COr=i(li),lCe=n(li,"P",{});var h$t=s(lCe);wOr=r(h$t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),h$t.forEach(t),AOr=i(li),En=n(li,"P",{});var MA=s(En);yOr=r(MA,"The model class to instantiate is selected based on the "),iCe=n(MA,"CODE",{});var p$t=s(iCe);LOr=r(p$t,"model_type"),p$t.forEach(t),xOr=r(MA,` property of the config object (either
passed as an argument or loaded from `),dCe=n(MA,"CODE",{});var _$t=s(dCe);$Or=r(_$t,"pretrained_model_name_or_path"),_$t.forEach(t),kOr=r(MA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cCe=n(MA,"CODE",{});var u$t=s(cCe);SOr=r(u$t,"pretrained_model_name_or_path"),u$t.forEach(t),ROr=r(MA,":"),MA.forEach(t),POr=i(li),fCe=n(li,"UL",{});var b$t=s(fCe);Z3=n(b$t,"LI",{});var fqe=s(Z3);mCe=n(fqe,"STRONG",{});var v$t=s(mCe);BOr=r(v$t,"bert"),v$t.forEach(t),IOr=r(fqe," \u2014 "),hZ=n(fqe,"A",{href:!0});var F$t=s(hZ);NOr=r(F$t,"FlaxBertForNextSentencePrediction"),F$t.forEach(t),qOr=r(fqe," (BERT model)"),fqe.forEach(t),b$t.forEach(t),jOr=i(li),T(ew.$$.fragment,li),li.forEach(t),si.forEach(t),hDe=i(f),sf=n(f,"H2",{class:!0});var TOe=s(sf);ow=n(TOe,"A",{id:!0,class:!0,href:!0});var T$t=s(ow);gCe=n(T$t,"SPAN",{});var M$t=s(gCe);T(wx.$$.fragment,M$t),M$t.forEach(t),T$t.forEach(t),DOr=i(TOe),hCe=n(TOe,"SPAN",{});var E$t=s(hCe);GOr=r(E$t,"FlaxAutoModelForImageClassification"),E$t.forEach(t),TOe.forEach(t),pDe=i(f),Tr=n(f,"DIV",{class:!0});var ii=s(Tr);T(Ax.$$.fragment,ii),OOr=i(ii),lf=n(ii,"P",{});var moe=s(lf);VOr=r(moe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),pZ=n(moe,"A",{href:!0});var C$t=s(pZ);XOr=r(C$t,"from_pretrained()"),C$t.forEach(t),zOr=r(moe," class method or the "),_Z=n(moe,"A",{href:!0});var w$t=s(_Z);WOr=r(w$t,"from_config()"),w$t.forEach(t),QOr=r(moe,` class
method.`),moe.forEach(t),HOr=i(ii),yx=n(ii,"P",{});var MOe=s(yx);UOr=r(MOe,"This class cannot be instantiated directly using "),pCe=n(MOe,"CODE",{});var A$t=s(pCe);JOr=r(A$t,"__init__()"),A$t.forEach(t),YOr=r(MOe," (throws an error)."),MOe.forEach(t),KOr=i(ii),Yt=n(ii,"DIV",{class:!0});var EA=s(Yt);T(Lx.$$.fragment,EA),ZOr=i(EA),_Ce=n(EA,"P",{});var y$t=s(_Ce);eVr=r(y$t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),y$t.forEach(t),oVr=i(EA),df=n(EA,"P",{});var goe=s(df);rVr=r(goe,`Note:
Loading a model from its configuration file does `),uCe=n(goe,"STRONG",{});var L$t=s(uCe);tVr=r(L$t,"not"),L$t.forEach(t),aVr=r(goe,` load the model weights. It only affects the
model\u2019s configuration. Use `),uZ=n(goe,"A",{href:!0});var x$t=s(uZ);nVr=r(x$t,"from_pretrained()"),x$t.forEach(t),sVr=r(goe," to load the model weights."),goe.forEach(t),lVr=i(EA),T(rw.$$.fragment,EA),EA.forEach(t),iVr=i(ii),Ur=n(ii,"DIV",{class:!0});var di=s(Ur);T(xx.$$.fragment,di),dVr=i(di),bCe=n(di,"P",{});var $$t=s(bCe);cVr=r($$t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),$$t.forEach(t),fVr=i(di),Cn=n(di,"P",{});var CA=s(Cn);mVr=r(CA,"The model class to instantiate is selected based on the "),vCe=n(CA,"CODE",{});var k$t=s(vCe);gVr=r(k$t,"model_type"),k$t.forEach(t),hVr=r(CA,` property of the config object (either
passed as an argument or loaded from `),FCe=n(CA,"CODE",{});var S$t=s(FCe);pVr=r(S$t,"pretrained_model_name_or_path"),S$t.forEach(t),_Vr=r(CA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TCe=n(CA,"CODE",{});var R$t=s(TCe);uVr=r(R$t,"pretrained_model_name_or_path"),R$t.forEach(t),bVr=r(CA,":"),CA.forEach(t),vVr=i(di),$x=n(di,"UL",{});var EOe=s($x);tw=n(EOe,"LI",{});var mqe=s(tw);MCe=n(mqe,"STRONG",{});var P$t=s(MCe);FVr=r(P$t,"beit"),P$t.forEach(t),TVr=r(mqe," \u2014 "),bZ=n(mqe,"A",{href:!0});var B$t=s(bZ);MVr=r(B$t,"FlaxBeitForImageClassification"),B$t.forEach(t),EVr=r(mqe," (BEiT model)"),mqe.forEach(t),CVr=i(EOe),aw=n(EOe,"LI",{});var gqe=s(aw);ECe=n(gqe,"STRONG",{});var I$t=s(ECe);wVr=r(I$t,"vit"),I$t.forEach(t),AVr=r(gqe," \u2014 "),vZ=n(gqe,"A",{href:!0});var N$t=s(vZ);yVr=r(N$t,"FlaxViTForImageClassification"),N$t.forEach(t),LVr=r(gqe," (ViT model)"),gqe.forEach(t),EOe.forEach(t),xVr=i(di),T(nw.$$.fragment,di),di.forEach(t),ii.forEach(t),_De=i(f),cf=n(f,"H2",{class:!0});var COe=s(cf);sw=n(COe,"A",{id:!0,class:!0,href:!0});var q$t=s(sw);CCe=n(q$t,"SPAN",{});var j$t=s(CCe);T(kx.$$.fragment,j$t),j$t.forEach(t),q$t.forEach(t),$Vr=i(COe),wCe=n(COe,"SPAN",{});var D$t=s(wCe);kVr=r(D$t,"FlaxAutoModelForVision2Seq"),D$t.forEach(t),COe.forEach(t),uDe=i(f),Mr=n(f,"DIV",{class:!0});var ci=s(Mr);T(Sx.$$.fragment,ci),SVr=i(ci),ff=n(ci,"P",{});var hoe=s(ff);RVr=r(hoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),FZ=n(hoe,"A",{href:!0});var G$t=s(FZ);PVr=r(G$t,"from_pretrained()"),G$t.forEach(t),BVr=r(hoe," class method or the "),TZ=n(hoe,"A",{href:!0});var O$t=s(TZ);IVr=r(O$t,"from_config()"),O$t.forEach(t),NVr=r(hoe,` class
method.`),hoe.forEach(t),qVr=i(ci),Rx=n(ci,"P",{});var wOe=s(Rx);jVr=r(wOe,"This class cannot be instantiated directly using "),ACe=n(wOe,"CODE",{});var V$t=s(ACe);DVr=r(V$t,"__init__()"),V$t.forEach(t),GVr=r(wOe," (throws an error)."),wOe.forEach(t),OVr=i(ci),Kt=n(ci,"DIV",{class:!0});var wA=s(Kt);T(Px.$$.fragment,wA),VVr=i(wA),yCe=n(wA,"P",{});var X$t=s(yCe);XVr=r(X$t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),X$t.forEach(t),zVr=i(wA),mf=n(wA,"P",{});var poe=s(mf);WVr=r(poe,`Note:
Loading a model from its configuration file does `),LCe=n(poe,"STRONG",{});var z$t=s(LCe);QVr=r(z$t,"not"),z$t.forEach(t),HVr=r(poe,` load the model weights. It only affects the
model\u2019s configuration. Use `),MZ=n(poe,"A",{href:!0});var W$t=s(MZ);UVr=r(W$t,"from_pretrained()"),W$t.forEach(t),JVr=r(poe," to load the model weights."),poe.forEach(t),YVr=i(wA),T(lw.$$.fragment,wA),wA.forEach(t),KVr=i(ci),Jr=n(ci,"DIV",{class:!0});var fi=s(Jr);T(Bx.$$.fragment,fi),ZVr=i(fi),xCe=n(fi,"P",{});var Q$t=s(xCe);eXr=r(Q$t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Q$t.forEach(t),oXr=i(fi),wn=n(fi,"P",{});var AA=s(wn);rXr=r(AA,"The model class to instantiate is selected based on the "),$Ce=n(AA,"CODE",{});var H$t=s($Ce);tXr=r(H$t,"model_type"),H$t.forEach(t),aXr=r(AA,` property of the config object (either
passed as an argument or loaded from `),kCe=n(AA,"CODE",{});var U$t=s(kCe);nXr=r(U$t,"pretrained_model_name_or_path"),U$t.forEach(t),sXr=r(AA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SCe=n(AA,"CODE",{});var J$t=s(SCe);lXr=r(J$t,"pretrained_model_name_or_path"),J$t.forEach(t),iXr=r(AA,":"),AA.forEach(t),dXr=i(fi),RCe=n(fi,"UL",{});var Y$t=s(RCe);iw=n(Y$t,"LI",{});var hqe=s(iw);PCe=n(hqe,"STRONG",{});var K$t=s(PCe);cXr=r(K$t,"vision-encoder-decoder"),K$t.forEach(t),fXr=r(hqe," \u2014 "),EZ=n(hqe,"A",{href:!0});var Z$t=s(EZ);mXr=r(Z$t,"FlaxVisionEncoderDecoderModel"),Z$t.forEach(t),gXr=r(hqe," (Vision Encoder decoder model)"),hqe.forEach(t),Y$t.forEach(t),hXr=i(fi),T(dw.$$.fragment,fi),fi.forEach(t),ci.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(tRt)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(yn,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.AutoConfig"),c(xn,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.AutoModel"),c($n,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.AutoTokenizer"),c(bi,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertModel"),c(Ff,"id","extending-the-auto-classes"),c(Ff,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ff,"href","#extending-the-auto-classes"),c(vi,"class","relative group"),c(Mf,"id","transformers.AutoConfig"),c(Mf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Mf,"href","#transformers.AutoConfig"),c(Fi,"class","relative group"),c(rk,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(tk,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertConfig"),c(ak,"href","/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartConfig"),c(nk,"href","/docs/transformers/pr_17466/en/model_doc/beit#transformers.BeitConfig"),c(sk,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertConfig"),c(lk,"href","/docs/transformers/pr_17466/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(ik,"href","/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdConfig"),c(dk,"href","/docs/transformers/pr_17466/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(ck,"href","/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(fk,"href","/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(mk,"href","/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertConfig"),c(gk,"href","/docs/transformers/pr_17466/en/model_doc/canine#transformers.CanineConfig"),c(hk,"href","/docs/transformers/pr_17466/en/model_doc/clip#transformers.CLIPConfig"),c(pk,"href","/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertConfig"),c(_k,"href","/docs/transformers/pr_17466/en/model_doc/convnext#transformers.ConvNextConfig"),c(uk,"href","/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.CTRLConfig"),c(bk,"href","/docs/transformers/pr_17466/en/model_doc/cvt#transformers.CvtConfig"),c(vk,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(Fk,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(Tk,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(Mk,"href","/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaConfig"),c(Ek,"href","/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(Ck,"href","/docs/transformers/pr_17466/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(wk,"href","/docs/transformers/pr_17466/en/model_doc/deit#transformers.DeiTConfig"),c(Ak,"href","/docs/transformers/pr_17466/en/model_doc/detr#transformers.DetrConfig"),c(yk,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertConfig"),c(Lk,"href","/docs/transformers/pr_17466/en/model_doc/dpr#transformers.DPRConfig"),c(xk,"href","/docs/transformers/pr_17466/en/model_doc/dpt#transformers.DPTConfig"),c($k,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraConfig"),c(kk,"href","/docs/transformers/pr_17466/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(Sk,"href","/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertConfig"),c(Rk,"href","/docs/transformers/pr_17466/en/model_doc/flava#transformers.FlavaConfig"),c(Pk,"href","/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetConfig"),c(Bk,"href","/docs/transformers/pr_17466/en/model_doc/fsmt#transformers.FSMTConfig"),c(Ik,"href","/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelConfig"),c(Nk,"href","/docs/transformers/pr_17466/en/model_doc/glpn#transformers.GLPNConfig"),c(qk,"href","/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2Config"),c(jk,"href","/docs/transformers/pr_17466/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(Dk,"href","/docs/transformers/pr_17466/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(Gk,"href","/docs/transformers/pr_17466/en/model_doc/gptj#transformers.GPTJConfig"),c(Ok,"href","/docs/transformers/pr_17466/en/model_doc/hubert#transformers.HubertConfig"),c(Vk,"href","/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertConfig"),c(Xk,"href","/docs/transformers/pr_17466/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(zk,"href","/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(Wk,"href","/docs/transformers/pr_17466/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(Qk,"href","/docs/transformers/pr_17466/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(Hk,"href","/docs/transformers/pr_17466/en/model_doc/led#transformers.LEDConfig"),c(Uk,"href","/docs/transformers/pr_17466/en/model_doc/levit#transformers.LevitConfig"),c(Jk,"href","/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerConfig"),c(Yk,"href","/docs/transformers/pr_17466/en/model_doc/luke#transformers.LukeConfig"),c(Kk,"href","/docs/transformers/pr_17466/en/model_doc/lxmert#transformers.LxmertConfig"),c(Zk,"href","/docs/transformers/pr_17466/en/model_doc/m2m_100#transformers.M2M100Config"),c(eS,"href","/docs/transformers/pr_17466/en/model_doc/marian#transformers.MarianConfig"),c(oS,"href","/docs/transformers/pr_17466/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(rS,"href","/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartConfig"),c(tS,"href","/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(aS,"href","/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(nS,"href","/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetConfig"),c(sS,"href","/docs/transformers/pr_17466/en/model_doc/mt5#transformers.MT5Config"),c(lS,"href","/docs/transformers/pr_17466/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(iS,"href","/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(dS,"href","/docs/transformers/pr_17466/en/model_doc/opt#transformers.OPTConfig"),c(cS,"href","/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.PegasusConfig"),c(fS,"href","/docs/transformers/pr_17466/en/model_doc/perceiver#transformers.PerceiverConfig"),c(mS,"href","/docs/transformers/pr_17466/en/model_doc/plbart#transformers.PLBartConfig"),c(gS,"href","/docs/transformers/pr_17466/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(hS,"href","/docs/transformers/pr_17466/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(pS,"href","/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(_S,"href","/docs/transformers/pr_17466/en/model_doc/rag#transformers.RagConfig"),c(uS,"href","/docs/transformers/pr_17466/en/model_doc/realm#transformers.RealmConfig"),c(bS,"href","/docs/transformers/pr_17466/en/model_doc/reformer#transformers.ReformerConfig"),c(vS,"href","/docs/transformers/pr_17466/en/model_doc/regnet#transformers.RegNetConfig"),c(FS,"href","/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertConfig"),c(TS,"href","/docs/transformers/pr_17466/en/model_doc/resnet#transformers.ResNetConfig"),c(MS,"href","/docs/transformers/pr_17466/en/model_doc/retribert#transformers.RetriBertConfig"),c(ES,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaConfig"),c(CS,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerConfig"),c(wS,"href","/docs/transformers/pr_17466/en/model_doc/segformer#transformers.SegformerConfig"),c(AS,"href","/docs/transformers/pr_17466/en/model_doc/sew#transformers.SEWConfig"),c(yS,"href","/docs/transformers/pr_17466/en/model_doc/sew-d#transformers.SEWDConfig"),c(LS,"href","/docs/transformers/pr_17466/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(xS,"href","/docs/transformers/pr_17466/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c($S,"href","/docs/transformers/pr_17466/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(kS,"href","/docs/transformers/pr_17466/en/model_doc/splinter#transformers.SplinterConfig"),c(SS,"href","/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(RS,"href","/docs/transformers/pr_17466/en/model_doc/swin#transformers.SwinConfig"),c(PS,"href","/docs/transformers/pr_17466/en/model_doc/t5#transformers.T5Config"),c(BS,"href","/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasConfig"),c(IS,"href","/docs/transformers/pr_17466/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(NS,"href","/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(qS,"href","/docs/transformers/pr_17466/en/model_doc/trocr#transformers.TrOCRConfig"),c(jS,"href","/docs/transformers/pr_17466/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(DS,"href","/docs/transformers/pr_17466/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(GS,"href","/docs/transformers/pr_17466/en/model_doc/van#transformers.VanConfig"),c(OS,"href","/docs/transformers/pr_17466/en/model_doc/vilt#transformers.ViltConfig"),c(VS,"href","/docs/transformers/pr_17466/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(XS,"href","/docs/transformers/pr_17466/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(zS,"href","/docs/transformers/pr_17466/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(WS,"href","/docs/transformers/pr_17466/en/model_doc/vit#transformers.ViTConfig"),c(QS,"href","/docs/transformers/pr_17466/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(HS,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(US,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(JS,"href","/docs/transformers/pr_17466/en/model_doc/wavlm#transformers.WavLMConfig"),c(YS,"href","/docs/transformers/pr_17466/en/model_doc/xglm#transformers.XGLMConfig"),c(KS,"href","/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMConfig"),c(ZS,"href","/docs/transformers/pr_17466/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(eR,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(oR,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(rR,"href","/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetConfig"),c(tR,"href","/docs/transformers/pr_17466/en/model_doc/yolos#transformers.YolosConfig"),c(aR,"href","/docs/transformers/pr_17466/en/model_doc/yoso#transformers.YosoConfig"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ag,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yg,"id","transformers.AutoTokenizer"),c(yg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yg,"href","#transformers.AutoTokenizer"),c(Mi,"class","relative group"),c(nR,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(sR,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertTokenizer"),c(lR,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(iR,"href","/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartTokenizer"),c(dR,"href","/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartTokenizerFast"),c(cR,"href","/docs/transformers/pr_17466/en/model_doc/barthez#transformers.BarthezTokenizer"),c(fR,"href","/docs/transformers/pr_17466/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(mR,"href","/docs/transformers/pr_17466/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(gR,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertTokenizer"),c(hR,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertTokenizerFast"),c(pR,"href","/docs/transformers/pr_17466/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(_R,"href","/docs/transformers/pr_17466/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(uR,"href","/docs/transformers/pr_17466/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(bR,"href","/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(vR,"href","/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(FR,"href","/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(TR,"href","/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(MR,"href","/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(ER,"href","/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(CR,"href","/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(wR,"href","/docs/transformers/pr_17466/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(AR,"href","/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertTokenizer"),c(yR,"href","/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(LR,"href","/docs/transformers/pr_17466/en/model_doc/canine#transformers.CanineTokenizer"),c(xR,"href","/docs/transformers/pr_17466/en/model_doc/clip#transformers.CLIPTokenizer"),c($R,"href","/docs/transformers/pr_17466/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(kR,"href","/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(SR,"href","/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(RR,"href","/docs/transformers/pr_17466/en/model_doc/cpm#transformers.CpmTokenizer"),c(PR,"href","/docs/transformers/pr_17466/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(BR,"href","/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(IR,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaTokenizer"),c(NR,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(qR,"href","/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaTokenizer"),c(jR,"href","/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(DR,"href","/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(GR,"href","/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(OR,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(VR,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(XR,"href","/docs/transformers/pr_17466/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(zR,"href","/docs/transformers/pr_17466/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(WR,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraTokenizer"),c(QR,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(HR,"href","/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(UR,"href","/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetTokenizer"),c(JR,"href","/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(YR,"href","/docs/transformers/pr_17466/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(KR,"href","/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelTokenizer"),c(ZR,"href","/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(eP,"href","/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(oP,"href","/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(rP,"href","/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(tP,"href","/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(aP,"href","/docs/transformers/pr_17466/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(nP,"href","/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(sP,"href","/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(lP,"href","/docs/transformers/pr_17466/en/model_doc/herbert#transformers.HerbertTokenizer"),c(iP,"href","/docs/transformers/pr_17466/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(dP,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(cP,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaTokenizer"),c(fP,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(mP,"href","/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(gP,"href","/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(hP,"href","/docs/transformers/pr_17466/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(pP,"href","/docs/transformers/pr_17466/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(_P,"href","/docs/transformers/pr_17466/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(uP,"href","/docs/transformers/pr_17466/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(bP,"href","/docs/transformers/pr_17466/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(vP,"href","/docs/transformers/pr_17466/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(FP,"href","/docs/transformers/pr_17466/en/model_doc/led#transformers.LEDTokenizer"),c(TP,"href","/docs/transformers/pr_17466/en/model_doc/led#transformers.LEDTokenizerFast"),c(MP,"href","/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerTokenizer"),c(EP,"href","/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(CP,"href","/docs/transformers/pr_17466/en/model_doc/luke#transformers.LukeTokenizer"),c(wP,"href","/docs/transformers/pr_17466/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(AP,"href","/docs/transformers/pr_17466/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(yP,"href","/docs/transformers/pr_17466/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(LP,"href","/docs/transformers/pr_17466/en/model_doc/marian#transformers.MarianTokenizer"),c(xP,"href","/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartTokenizer"),c($P,"href","/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(kP,"href","/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(SP,"href","/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(RP,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertTokenizer"),c(PP,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertTokenizerFast"),c(BP,"href","/docs/transformers/pr_17466/en/model_doc/mluke#transformers.MLukeTokenizer"),c(IP,"href","/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(NP,"href","/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(qP,"href","/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(jP,"href","/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(DP,"href","/docs/transformers/pr_17466/en/model_doc/t5#transformers.T5Tokenizer"),c(GP,"href","/docs/transformers/pr_17466/en/model_doc/t5#transformers.T5TokenizerFast"),c(OP,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertTokenizer"),c(VP,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(XP,"href","/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(zP,"href","/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(WP,"href","/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(QP,"href","/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(HP,"href","/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(UP,"href","/docs/transformers/pr_17466/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(JP,"href","/docs/transformers/pr_17466/en/model_doc/phobert#transformers.PhobertTokenizer"),c(YP,"href","/docs/transformers/pr_17466/en/model_doc/plbart#transformers.PLBartTokenizer"),c(KP,"href","/docs/transformers/pr_17466/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(ZP,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertTokenizer"),c(eB,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertTokenizerFast"),c(oB,"href","/docs/transformers/pr_17466/en/model_doc/rag#transformers.RagTokenizer"),c(rB,"href","/docs/transformers/pr_17466/en/model_doc/realm#transformers.RealmTokenizer"),c(tB,"href","/docs/transformers/pr_17466/en/model_doc/realm#transformers.RealmTokenizerFast"),c(aB,"href","/docs/transformers/pr_17466/en/model_doc/reformer#transformers.ReformerTokenizer"),c(nB,"href","/docs/transformers/pr_17466/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(sB,"href","/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertTokenizer"),c(lB,"href","/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(iB,"href","/docs/transformers/pr_17466/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(dB,"href","/docs/transformers/pr_17466/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(cB,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaTokenizer"),c(fB,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(mB,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(gB,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(hB,"href","/docs/transformers/pr_17466/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(pB,"href","/docs/transformers/pr_17466/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(_B,"href","/docs/transformers/pr_17466/en/model_doc/splinter#transformers.SplinterTokenizer"),c(uB,"href","/docs/transformers/pr_17466/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(bB,"href","/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(vB,"href","/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(FB,"href","/docs/transformers/pr_17466/en/model_doc/t5#transformers.T5Tokenizer"),c(TB,"href","/docs/transformers/pr_17466/en/model_doc/t5#transformers.T5TokenizerFast"),c(MB,"href","/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasTokenizer"),c(EB,"href","/docs/transformers/pr_17466/en/model_doc/tapex#transformers.TapexTokenizer"),c(CB,"href","/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(wB,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertTokenizer"),c(AB,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertTokenizerFast"),c(yB,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(LB,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(xB,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c($B,"href","/docs/transformers/pr_17466/en/model_doc/xglm#transformers.XGLMTokenizer"),c(kB,"href","/docs/transformers/pr_17466/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(SB,"href","/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMTokenizer"),c(RB,"href","/docs/transformers/pr_17466/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(PB,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(BB,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(IB,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaTokenizer"),c(NB,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(qB,"href","/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(jB,"href","/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(DB,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertTokenizer"),c(GB,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ih,"id","transformers.AutoFeatureExtractor"),c(ih,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ih,"href","#transformers.AutoFeatureExtractor"),c(Ei,"class","relative group"),c(OB,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(VB,"href","/docs/transformers/pr_17466/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(XB,"href","/docs/transformers/pr_17466/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(zB,"href","/docs/transformers/pr_17466/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(WB,"href","/docs/transformers/pr_17466/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(QB,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(HB,"href","/docs/transformers/pr_17466/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(UB,"href","/docs/transformers/pr_17466/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(JB,"href","/docs/transformers/pr_17466/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(YB,"href","/docs/transformers/pr_17466/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(KB,"href","/docs/transformers/pr_17466/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(ZB,"href","/docs/transformers/pr_17466/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(eI,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(oI,"href","/docs/transformers/pr_17466/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(rI,"href","/docs/transformers/pr_17466/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(tI,"href","/docs/transformers/pr_17466/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(aI,"href","/docs/transformers/pr_17466/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(nI,"href","/docs/transformers/pr_17466/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(sI,"href","/docs/transformers/pr_17466/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(lI,"href","/docs/transformers/pr_17466/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(iI,"href","/docs/transformers/pr_17466/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(dI,"href","/docs/transformers/pr_17466/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(cI,"href","/docs/transformers/pr_17466/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(fI,"href","/docs/transformers/pr_17466/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(mI,"href","/docs/transformers/pr_17466/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(gI,"href","/docs/transformers/pr_17466/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(hI,"href","/docs/transformers/pr_17466/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(pI,"href","/docs/transformers/pr_17466/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(_I,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(uI,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(bI,"href","/docs/transformers/pr_17466/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Gh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oh,"id","transformers.AutoProcessor"),c(Oh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Oh,"href","#transformers.AutoProcessor"),c(Ci,"class","relative group"),c(vI,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(FI,"href","/docs/transformers/pr_17466/en/model_doc/clip#transformers.CLIPProcessor"),c(TI,"href","/docs/transformers/pr_17466/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(MI,"href","/docs/transformers/pr_17466/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(EI,"href","/docs/transformers/pr_17466/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(CI,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(wI,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(AI,"href","/docs/transformers/pr_17466/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(yI,"href","/docs/transformers/pr_17466/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(LI,"href","/docs/transformers/pr_17466/en/model_doc/trocr#transformers.TrOCRProcessor"),c(xI,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c($I,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(kI,"href","/docs/transformers/pr_17466/en/model_doc/vilt#transformers.ViltProcessor"),c(SI,"href","/docs/transformers/pr_17466/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(RI,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(PI,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(BI,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ip,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dp,"id","transformers.AutoModel"),c(dp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dp,"href","#transformers.AutoModel"),c(Ai,"class","relative group"),c(II,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NI,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qI,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jI,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertModel"),c(DI,"href","/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartModel"),c(GI,"href","/docs/transformers/pr_17466/en/model_doc/beit#transformers.BeitModel"),c(OI,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertModel"),c(VI,"href","/docs/transformers/pr_17466/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(XI,"href","/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdModel"),c(zI,"href","/docs/transformers/pr_17466/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(WI,"href","/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(QI,"href","/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(HI,"href","/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertModel"),c(UI,"href","/docs/transformers/pr_17466/en/model_doc/canine#transformers.CanineModel"),c(JI,"href","/docs/transformers/pr_17466/en/model_doc/clip#transformers.CLIPModel"),c(YI,"href","/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertModel"),c(KI,"href","/docs/transformers/pr_17466/en/model_doc/convnext#transformers.ConvNextModel"),c(ZI,"href","/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.CTRLModel"),c(eN,"href","/docs/transformers/pr_17466/en/model_doc/cvt#transformers.CvtModel"),c(oN,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(rN,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(tN,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(aN,"href","/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaModel"),c(nN,"href","/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(sN,"href","/docs/transformers/pr_17466/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(lN,"href","/docs/transformers/pr_17466/en/model_doc/deit#transformers.DeiTModel"),c(iN,"href","/docs/transformers/pr_17466/en/model_doc/detr#transformers.DetrModel"),c(dN,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertModel"),c(cN,"href","/docs/transformers/pr_17466/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(fN,"href","/docs/transformers/pr_17466/en/model_doc/dpt#transformers.DPTModel"),c(mN,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraModel"),c(gN,"href","/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertModel"),c(hN,"href","/docs/transformers/pr_17466/en/model_doc/flava#transformers.FlavaModel"),c(pN,"href","/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetModel"),c(_N,"href","/docs/transformers/pr_17466/en/model_doc/fsmt#transformers.FSMTModel"),c(uN,"href","/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelModel"),c(bN,"href","/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelBaseModel"),c(vN,"href","/docs/transformers/pr_17466/en/model_doc/glpn#transformers.GLPNModel"),c(FN,"href","/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2Model"),c(TN,"href","/docs/transformers/pr_17466/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(MN,"href","/docs/transformers/pr_17466/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(EN,"href","/docs/transformers/pr_17466/en/model_doc/gptj#transformers.GPTJModel"),c(CN,"href","/docs/transformers/pr_17466/en/model_doc/hubert#transformers.HubertModel"),c(wN,"href","/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertModel"),c(AN,"href","/docs/transformers/pr_17466/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(yN,"href","/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(LN,"href","/docs/transformers/pr_17466/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(xN,"href","/docs/transformers/pr_17466/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c($N,"href","/docs/transformers/pr_17466/en/model_doc/led#transformers.LEDModel"),c(kN,"href","/docs/transformers/pr_17466/en/model_doc/levit#transformers.LevitModel"),c(SN,"href","/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerModel"),c(RN,"href","/docs/transformers/pr_17466/en/model_doc/luke#transformers.LukeModel"),c(PN,"href","/docs/transformers/pr_17466/en/model_doc/lxmert#transformers.LxmertModel"),c(BN,"href","/docs/transformers/pr_17466/en/model_doc/m2m_100#transformers.M2M100Model"),c(IN,"href","/docs/transformers/pr_17466/en/model_doc/marian#transformers.MarianModel"),c(NN,"href","/docs/transformers/pr_17466/en/model_doc/maskformer#transformers.MaskFormerModel"),c(qN,"href","/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartModel"),c(jN,"href","/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(DN,"href","/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertModel"),c(GN,"href","/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetModel"),c(ON,"href","/docs/transformers/pr_17466/en/model_doc/mt5#transformers.MT5Model"),c(VN,"href","/docs/transformers/pr_17466/en/model_doc/nystromformer#transformers.NystromformerModel"),c(XN,"href","/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(zN,"href","/docs/transformers/pr_17466/en/model_doc/opt#transformers.OPTModel"),c(WN,"href","/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.PegasusModel"),c(QN,"href","/docs/transformers/pr_17466/en/model_doc/perceiver#transformers.PerceiverModel"),c(HN,"href","/docs/transformers/pr_17466/en/model_doc/plbart#transformers.PLBartModel"),c(UN,"href","/docs/transformers/pr_17466/en/model_doc/poolformer#transformers.PoolFormerModel"),c(JN,"href","/docs/transformers/pr_17466/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(YN,"href","/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertModel"),c(KN,"href","/docs/transformers/pr_17466/en/model_doc/reformer#transformers.ReformerModel"),c(ZN,"href","/docs/transformers/pr_17466/en/model_doc/regnet#transformers.RegNetModel"),c(eq,"href","/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertModel"),c(oq,"href","/docs/transformers/pr_17466/en/model_doc/resnet#transformers.ResNetModel"),c(rq,"href","/docs/transformers/pr_17466/en/model_doc/retribert#transformers.RetriBertModel"),c(tq,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaModel"),c(aq,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerModel"),c(nq,"href","/docs/transformers/pr_17466/en/model_doc/segformer#transformers.SegformerModel"),c(sq,"href","/docs/transformers/pr_17466/en/model_doc/sew#transformers.SEWModel"),c(lq,"href","/docs/transformers/pr_17466/en/model_doc/sew-d#transformers.SEWDModel"),c(iq,"href","/docs/transformers/pr_17466/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(dq,"href","/docs/transformers/pr_17466/en/model_doc/splinter#transformers.SplinterModel"),c(cq,"href","/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(fq,"href","/docs/transformers/pr_17466/en/model_doc/swin#transformers.SwinModel"),c(mq,"href","/docs/transformers/pr_17466/en/model_doc/t5#transformers.T5Model"),c(gq,"href","/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasModel"),c(hq,"href","/docs/transformers/pr_17466/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(pq,"href","/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(_q,"href","/docs/transformers/pr_17466/en/model_doc/unispeech#transformers.UniSpeechModel"),c(uq,"href","/docs/transformers/pr_17466/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(bq,"href","/docs/transformers/pr_17466/en/model_doc/van#transformers.VanModel"),c(vq,"href","/docs/transformers/pr_17466/en/model_doc/vilt#transformers.ViltModel"),c(Fq,"href","/docs/transformers/pr_17466/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(Tq,"href","/docs/transformers/pr_17466/en/model_doc/visual_bert#transformers.VisualBertModel"),c(Mq,"href","/docs/transformers/pr_17466/en/model_doc/vit#transformers.ViTModel"),c(Eq,"href","/docs/transformers/pr_17466/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(Cq,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(wq,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(Aq,"href","/docs/transformers/pr_17466/en/model_doc/wavlm#transformers.WavLMModel"),c(yq,"href","/docs/transformers/pr_17466/en/model_doc/xglm#transformers.XGLMModel"),c(Lq,"href","/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMModel"),c(xq,"href","/docs/transformers/pr_17466/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c($q,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(kq,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(Sq,"href","/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetModel"),c(Rq,"href","/docs/transformers/pr_17466/en/model_doc/yolos#transformers.YolosModel"),c(Pq,"href","/docs/transformers/pr_17466/en/model_doc/yoso#transformers.YosoModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lu,"id","transformers.AutoModelForPreTraining"),c(lu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lu,"href","#transformers.AutoModelForPreTraining"),c(xi,"class","relative group"),c(Bq,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Iq,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Nq,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qq,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertForPreTraining"),c(jq,"href","/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(Dq,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertForPreTraining"),c(Gq,"href","/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(Oq,"href","/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(Vq,"href","/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(Xq,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(zq,"href","/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(Wq,"href","/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(Qq,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(Hq,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraForPreTraining"),c(Uq,"href","/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(Jq,"href","/docs/transformers/pr_17466/en/model_doc/flava#transformers.FlavaForPreTraining"),c(Yq,"href","/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetForPreTraining"),c(Kq,"href","/docs/transformers/pr_17466/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(Zq,"href","/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(ej,"href","/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(oj,"href","/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(rj,"href","/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(tj,"href","/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(aj,"href","/docs/transformers/pr_17466/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(nj,"href","/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(sj,"href","/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(lj,"href","/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(ij,"href","/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(dj,"href","/docs/transformers/pr_17466/en/model_doc/retribert#transformers.RetriBertModel"),c(cj,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(fj,"href","/docs/transformers/pr_17466/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(mj,"href","/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(gj,"href","/docs/transformers/pr_17466/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(hj,"href","/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(pj,"href","/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(_j,"href","/docs/transformers/pr_17466/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(uj,"href","/docs/transformers/pr_17466/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(bj,"href","/docs/transformers/pr_17466/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(vj,"href","/docs/transformers/pr_17466/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(Fj,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(Tj,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(Mj,"href","/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(Ej,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(Cj,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(wj,"href","/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zu,"id","transformers.AutoModelForCausalLM"),c(Zu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Zu,"href","#transformers.AutoModelForCausalLM"),c(Si,"class","relative group"),c(Aj,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yj,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Lj,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xj,"href","/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartForCausalLM"),c($j,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertLMHeadModel"),c(kj,"href","/docs/transformers/pr_17466/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(Sj,"href","/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(Rj,"href","/docs/transformers/pr_17466/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(Pj,"href","/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(Bj,"href","/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(Ij,"href","/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(Nj,"href","/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(qj,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(jj,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraForCausalLM"),c(Dj,"href","/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(Gj,"href","/docs/transformers/pr_17466/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(Oj,"href","/docs/transformers/pr_17466/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(Vj,"href","/docs/transformers/pr_17466/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(Xj,"href","/docs/transformers/pr_17466/en/model_doc/marian#transformers.MarianForCausalLM"),c(zj,"href","/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartForCausalLM"),c(Wj,"href","/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(Qj,"href","/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(Hj,"href","/docs/transformers/pr_17466/en/model_doc/opt#transformers.OPTForCausalLM"),c(Uj,"href","/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(Jj,"href","/docs/transformers/pr_17466/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(Yj,"href","/docs/transformers/pr_17466/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(Kj,"href","/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(Zj,"href","/docs/transformers/pr_17466/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(eD,"href","/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(oD,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(rD,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(tD,"href","/docs/transformers/pr_17466/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(aD,"href","/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(nD,"href","/docs/transformers/pr_17466/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(sD,"href","/docs/transformers/pr_17466/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(lD,"href","/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(iD,"href","/docs/transformers/pr_17466/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(dD,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(cD,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(fD,"href","/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(D6,"id","transformers.AutoModelForMaskedLM"),c(D6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(D6,"href","#transformers.AutoModelForMaskedLM"),c(Bi,"class","relative group"),c(mD,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gD,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hD,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pD,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(_D,"href","/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(uD,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertForMaskedLM"),c(bD,"href","/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(vD,"href","/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(FD,"href","/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(TD,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(MD,"href","/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(ED,"href","/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(CD,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(wD,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(AD,"href","/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(yD,"href","/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(LD,"href","/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(xD,"href","/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertForMaskedLM"),c($D,"href","/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(kD,"href","/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(SD,"href","/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(RD,"href","/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(PD,"href","/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(BD,"href","/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(ID,"href","/docs/transformers/pr_17466/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(ND,"href","/docs/transformers/pr_17466/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(qD,"href","/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(jD,"href","/docs/transformers/pr_17466/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(DD,"href","/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(GD,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(OD,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(VD,"href","/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(XD,"href","/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(zD,"href","/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(WD,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(QD,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(HD,"href","/docs/transformers/pr_17466/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(w1,"id","transformers.AutoModelForSeq2SeqLM"),c(w1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w1,"href","#transformers.AutoModelForSeq2SeqLM"),c(qi,"class","relative group"),c(UD,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JD,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YD,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KD,"href","/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(ZD,"href","/docs/transformers/pr_17466/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(eG,"href","/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(oG,"href","/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(rG,"href","/docs/transformers/pr_17466/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(tG,"href","/docs/transformers/pr_17466/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(aG,"href","/docs/transformers/pr_17466/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(nG,"href","/docs/transformers/pr_17466/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(sG,"href","/docs/transformers/pr_17466/en/model_doc/marian#transformers.MarianMTModel"),c(lG,"href","/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(iG,"href","/docs/transformers/pr_17466/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(dG,"href","/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(cG,"href","/docs/transformers/pr_17466/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(fG,"href","/docs/transformers/pr_17466/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(mG,"href","/docs/transformers/pr_17466/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(gG,"href","/docs/transformers/pr_17466/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(z1,"id","transformers.AutoModelForSequenceClassification"),c(z1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(z1,"href","#transformers.AutoModelForSequenceClassification"),c(Gi,"class","relative group"),c(hG,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pG,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_G,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uG,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(bG,"href","/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartForSequenceClassification"),c(vG,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertForSequenceClassification"),c(FG,"href","/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(TG,"href","/docs/transformers/pr_17466/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(MG,"href","/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(EG,"href","/docs/transformers/pr_17466/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(CG,"href","/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(wG,"href","/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(AG,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(yG,"href","/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(LG,"href","/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(xG,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c($G,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(kG,"href","/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(SG,"href","/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(RG,"href","/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(PG,"href","/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(BG,"href","/docs/transformers/pr_17466/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(IG,"href","/docs/transformers/pr_17466/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(NG,"href","/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(qG,"href","/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(jG,"href","/docs/transformers/pr_17466/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(DG,"href","/docs/transformers/pr_17466/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(GG,"href","/docs/transformers/pr_17466/en/model_doc/led#transformers.LEDForSequenceClassification"),c(OG,"href","/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(VG,"href","/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(XG,"href","/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(zG,"href","/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(WG,"href","/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(QG,"href","/docs/transformers/pr_17466/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(HG,"href","/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(UG,"href","/docs/transformers/pr_17466/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(JG,"href","/docs/transformers/pr_17466/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(YG,"href","/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(KG,"href","/docs/transformers/pr_17466/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(ZG,"href","/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(eO,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(oO,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(rO,"href","/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(tO,"href","/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(aO,"href","/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(nO,"href","/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(sO,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(lO,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(iO,"href","/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(dO,"href","/docs/transformers/pr_17466/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ob,"id","transformers.AutoModelForMultipleChoice"),c(Ob,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ob,"href","#transformers.AutoModelForMultipleChoice"),c(Xi,"class","relative group"),c(cO,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fO,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mO,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gO,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(hO,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertForMultipleChoice"),c(pO,"href","/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(_O,"href","/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(uO,"href","/docs/transformers/pr_17466/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(bO,"href","/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(vO,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(FO,"href","/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(TO,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(MO,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(EO,"href","/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(CO,"href","/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(wO,"href","/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(AO,"href","/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(yO,"href","/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(LO,"href","/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(xO,"href","/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c($O,"href","/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(kO,"href","/docs/transformers/pr_17466/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(SO,"href","/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(RO,"href","/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(PO,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(BO,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(IO,"href","/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(NO,"href","/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(qO,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(jO,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(DO,"href","/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(GO,"href","/docs/transformers/pr_17466/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(T2,"id","transformers.AutoModelForNextSentencePrediction"),c(T2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(T2,"href","#transformers.AutoModelForNextSentencePrediction"),c(Qi,"class","relative group"),c(OO,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VO,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XO,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zO,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(WO,"href","/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(QO,"href","/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(HO,"href","/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(UO,"href","/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($2,"id","transformers.AutoModelForTokenClassification"),c($2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($2,"href","#transformers.AutoModelForTokenClassification"),c(Ji,"class","relative group"),c(JO,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(YO,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(KO,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZO,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(eV,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertForTokenClassification"),c(oV,"href","/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(rV,"href","/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(tV,"href","/docs/transformers/pr_17466/en/model_doc/canine#transformers.CanineForTokenClassification"),c(aV,"href","/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(nV,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(sV,"href","/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(lV,"href","/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(iV,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(dV,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(cV,"href","/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(fV,"href","/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(mV,"href","/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(gV,"href","/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(hV,"href","/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(pV,"href","/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(_V,"href","/docs/transformers/pr_17466/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(uV,"href","/docs/transformers/pr_17466/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(bV,"href","/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(vV,"href","/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(FV,"href","/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(TV,"href","/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(MV,"href","/docs/transformers/pr_17466/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(EV,"href","/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(CV,"href","/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(wV,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(AV,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(yV,"href","/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(LV,"href","/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(xV,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c($V,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(kV,"href","/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(SV,"href","/docs/transformers/pr_17466/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(h4,"id","transformers.AutoModelForQuestionAnswering"),c(h4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(h4,"href","#transformers.AutoModelForQuestionAnswering"),c(Zi,"class","relative group"),c(RV,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PV,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BV,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IV,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(NV,"href","/docs/transformers/pr_17466/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(qV,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(jV,"href","/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(DV,"href","/docs/transformers/pr_17466/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(GV,"href","/docs/transformers/pr_17466/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(OV,"href","/docs/transformers/pr_17466/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(VV,"href","/docs/transformers/pr_17466/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(XV,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(zV,"href","/docs/transformers/pr_17466/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(WV,"href","/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(QV,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(HV,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(UV,"href","/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(JV,"href","/docs/transformers/pr_17466/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(YV,"href","/docs/transformers/pr_17466/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(KV,"href","/docs/transformers/pr_17466/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(ZV,"href","/docs/transformers/pr_17466/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(eX,"href","/docs/transformers/pr_17466/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(oX,"href","/docs/transformers/pr_17466/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(rX,"href","/docs/transformers/pr_17466/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(tX,"href","/docs/transformers/pr_17466/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(aX,"href","/docs/transformers/pr_17466/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(nX,"href","/docs/transformers/pr_17466/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(sX,"href","/docs/transformers/pr_17466/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(lX,"href","/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(iX,"href","/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(dX,"href","/docs/transformers/pr_17466/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(cX,"href","/docs/transformers/pr_17466/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(fX,"href","/docs/transformers/pr_17466/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(mX,"href","/docs/transformers/pr_17466/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(gX,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(hX,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(pX,"href","/docs/transformers/pr_17466/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(_X,"href","/docs/transformers/pr_17466/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(uX,"href","/docs/transformers/pr_17466/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(bX,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(vX,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(FX,"href","/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(TX,"href","/docs/transformers/pr_17466/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(av,"id","transformers.AutoModelForTableQuestionAnswering"),c(av,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(av,"href","#transformers.AutoModelForTableQuestionAnswering"),c(rd,"class","relative group"),c(MX,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(EX,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(CX,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wX,"href","/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dv,"id","transformers.AutoModelForImageClassification"),c(dv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dv,"href","#transformers.AutoModelForImageClassification"),c(nd,"class","relative group"),c(AX,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yX,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LX,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xX,"href","/docs/transformers/pr_17466/en/model_doc/beit#transformers.BeitForImageClassification"),c($X,"href","/docs/transformers/pr_17466/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(kX,"href","/docs/transformers/pr_17466/en/model_doc/cvt#transformers.CvtForImageClassification"),c(SX,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(RX,"href","/docs/transformers/pr_17466/en/model_doc/deit#transformers.DeiTForImageClassification"),c(PX,"href","/docs/transformers/pr_17466/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(BX,"href","/docs/transformers/pr_17466/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(IX,"href","/docs/transformers/pr_17466/en/model_doc/levit#transformers.LevitForImageClassification"),c(NX,"href","/docs/transformers/pr_17466/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(qX,"href","/docs/transformers/pr_17466/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(jX,"href","/docs/transformers/pr_17466/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(DX,"href","/docs/transformers/pr_17466/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(GX,"href","/docs/transformers/pr_17466/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(OX,"href","/docs/transformers/pr_17466/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(VX,"href","/docs/transformers/pr_17466/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(XX,"href","/docs/transformers/pr_17466/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(zX,"href","/docs/transformers/pr_17466/en/model_doc/swin#transformers.SwinForImageClassification"),c(WX,"href","/docs/transformers/pr_17466/en/model_doc/van#transformers.VanForImageClassification"),c(QX,"href","/docs/transformers/pr_17466/en/model_doc/vit#transformers.ViTForImageClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wv,"id","transformers.AutoModelForVision2Seq"),c(wv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(wv,"href","#transformers.AutoModelForVision2Seq"),c(id,"class","relative group"),c(HX,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UX,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JX,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YX,"href","/docs/transformers/pr_17466/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($v,"id","transformers.AutoModelForAudioClassification"),c($v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($v,"href","#transformers.AutoModelForAudioClassification"),c(fd,"class","relative group"),c(KX,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZX,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ez,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oz,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(rz,"href","/docs/transformers/pr_17466/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(tz,"href","/docs/transformers/pr_17466/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(az,"href","/docs/transformers/pr_17466/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(nz,"href","/docs/transformers/pr_17466/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(sz,"href","/docs/transformers/pr_17466/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(lz,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(iz,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(dz,"href","/docs/transformers/pr_17466/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vv,"id","transformers.AutoModelForAudioFrameClassification"),c(Vv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Vv,"href","#transformers.AutoModelForAudioFrameClassification"),c(hd,"class","relative group"),c(cz,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fz,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mz,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gz,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(hz,"href","/docs/transformers/pr_17466/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(pz,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(_z,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(uz,"href","/docs/transformers/pr_17466/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Kv,"id","transformers.AutoModelForCTC"),c(Kv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Kv,"href","#transformers.AutoModelForCTC"),c(ud,"class","relative group"),c(bz,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vz,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Fz,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tz,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(Mz,"href","/docs/transformers/pr_17466/en/model_doc/hubert#transformers.HubertForCTC"),c(Ez,"href","/docs/transformers/pr_17466/en/model_doc/sew#transformers.SEWForCTC"),c(Cz,"href","/docs/transformers/pr_17466/en/model_doc/sew-d#transformers.SEWDForCTC"),c(wz,"href","/docs/transformers/pr_17466/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(Az,"href","/docs/transformers/pr_17466/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(yz,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(Lz,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(xz,"href","/docs/transformers/pr_17466/en/model_doc/wavlm#transformers.WavLMForCTC"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fF,"id","transformers.AutoModelForSpeechSeq2Seq"),c(fF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fF,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Fd,"class","relative group"),c($z,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kz,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Sz,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Rz,"href","/docs/transformers/pr_17466/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(Pz,"href","/docs/transformers/pr_17466/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uF,"id","transformers.AutoModelForAudioXVector"),c(uF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uF,"href","#transformers.AutoModelForAudioXVector"),c(Ed,"class","relative group"),c(Bz,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Iz,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Nz,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qz,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(jz,"href","/docs/transformers/pr_17466/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(Dz,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(Gz,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(Oz,"href","/docs/transformers/pr_17466/en/model_doc/wavlm#transformers.WavLMForXVector"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AF,"id","transformers.AutoModelForMaskedImageModeling"),c(AF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(AF,"href","#transformers.AutoModelForMaskedImageModeling"),c(Ad,"class","relative group"),c(Vz,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xz,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zz,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wz,"href","/docs/transformers/pr_17466/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(Qz,"href","/docs/transformers/pr_17466/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(Hz,"href","/docs/transformers/pr_17466/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RF,"id","transformers.AutoModelForObjectDetection"),c(RF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(RF,"href","#transformers.AutoModelForObjectDetection"),c($d,"class","relative group"),c(Uz,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jz,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Yz,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Kz,"href","/docs/transformers/pr_17466/en/model_doc/detr#transformers.DetrForObjectDetection"),c(Zz,"href","/docs/transformers/pr_17466/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jF,"id","transformers.AutoModelForImageSegmentation"),c(jF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(jF,"href","#transformers.AutoModelForImageSegmentation"),c(Rd,"class","relative group"),c(eW,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oW,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rW,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tW,"href","/docs/transformers/pr_17466/en/model_doc/detr#transformers.DetrForSegmentation"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XF,"id","transformers.AutoModelForSemanticSegmentation"),c(XF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(XF,"href","#transformers.AutoModelForSemanticSegmentation"),c(Id,"class","relative group"),c(aW,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nW,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sW,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lW,"href","/docs/transformers/pr_17466/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(iW,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(dW,"href","/docs/transformers/pr_17466/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(cW,"href","/docs/transformers/pr_17466/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KF,"id","transformers.AutoModelForInstanceSegmentation"),c(KF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(KF,"href","#transformers.AutoModelForInstanceSegmentation"),c(jd,"class","relative group"),c(fW,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mW,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gW,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hW,"href","/docs/transformers/pr_17466/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tT,"id","transformers.TFAutoModel"),c(tT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(tT,"href","#transformers.TFAutoModel"),c(Od,"class","relative group"),c(pW,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_W,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(uW,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bW,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.TFAlbertModel"),c(vW,"href","/docs/transformers/pr_17466/en/model_doc/bart#transformers.TFBartModel"),c(FW,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.TFBertModel"),c(TW,"href","/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(MW,"href","/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(EW,"href","/docs/transformers/pr_17466/en/model_doc/camembert#transformers.TFCamembertModel"),c(CW,"href","/docs/transformers/pr_17466/en/model_doc/clip#transformers.TFCLIPModel"),c(wW,"href","/docs/transformers/pr_17466/en/model_doc/convbert#transformers.TFConvBertModel"),c(AW,"href","/docs/transformers/pr_17466/en/model_doc/convnext#transformers.TFConvNextModel"),c(yW,"href","/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.TFCTRLModel"),c(LW,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(xW,"href","/docs/transformers/pr_17466/en/model_doc/deberta#transformers.TFDebertaModel"),c($W,"href","/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(kW,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(SW,"href","/docs/transformers/pr_17466/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(RW,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.TFElectraModel"),c(PW,"href","/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(BW,"href","/docs/transformers/pr_17466/en/model_doc/funnel#transformers.TFFunnelModel"),c(IW,"href","/docs/transformers/pr_17466/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(NW,"href","/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.TFGPT2Model"),c(qW,"href","/docs/transformers/pr_17466/en/model_doc/gptj#transformers.TFGPTJModel"),c(jW,"href","/docs/transformers/pr_17466/en/model_doc/hubert#transformers.TFHubertModel"),c(DW,"href","/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(GW,"href","/docs/transformers/pr_17466/en/model_doc/led#transformers.TFLEDModel"),c(OW,"href","/docs/transformers/pr_17466/en/model_doc/longformer#transformers.TFLongformerModel"),c(VW,"href","/docs/transformers/pr_17466/en/model_doc/lxmert#transformers.TFLxmertModel"),c(XW,"href","/docs/transformers/pr_17466/en/model_doc/marian#transformers.TFMarianModel"),c(zW,"href","/docs/transformers/pr_17466/en/model_doc/mbart#transformers.TFMBartModel"),c(WW,"href","/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(QW,"href","/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.TFMPNetModel"),c(HW,"href","/docs/transformers/pr_17466/en/model_doc/mt5#transformers.TFMT5Model"),c(UW,"href","/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(JW,"href","/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.TFPegasusModel"),c(YW,"href","/docs/transformers/pr_17466/en/model_doc/rembert#transformers.TFRemBertModel"),c(KW,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.TFRobertaModel"),c(ZW,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.TFRoFormerModel"),c(eQ,"href","/docs/transformers/pr_17466/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(oQ,"href","/docs/transformers/pr_17466/en/model_doc/swin#transformers.TFSwinModel"),c(rQ,"href","/docs/transformers/pr_17466/en/model_doc/t5#transformers.TFT5Model"),c(tQ,"href","/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TFTapasModel"),c(aQ,"href","/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(nQ,"href","/docs/transformers/pr_17466/en/model_doc/vit#transformers.TFViTModel"),c(sQ,"href","/docs/transformers/pr_17466/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(lQ,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(iQ,"href","/docs/transformers/pr_17466/en/model_doc/xlm#transformers.TFXLMModel"),c(dQ,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(cQ,"href","/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.TFXLNetModel"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YT,"id","transformers.TFAutoModelForPreTraining"),c(YT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(YT,"href","#transformers.TFAutoModelForPreTraining"),c(zd,"class","relative group"),c(fQ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mQ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gQ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hQ,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(pQ,"href","/docs/transformers/pr_17466/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(_Q,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.TFBertForPreTraining"),c(uQ,"href","/docs/transformers/pr_17466/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(bQ,"href","/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(vQ,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(FQ,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(TQ,"href","/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(MQ,"href","/docs/transformers/pr_17466/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(EQ,"href","/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(CQ,"href","/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(wQ,"href","/docs/transformers/pr_17466/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(AQ,"href","/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(yQ,"href","/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(LQ,"href","/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(xQ,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c($Q,"href","/docs/transformers/pr_17466/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(kQ,"href","/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(SQ,"href","/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(RQ,"href","/docs/transformers/pr_17466/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(PQ,"href","/docs/transformers/pr_17466/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(BQ,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(IQ,"href","/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(E7,"id","transformers.TFAutoModelForCausalLM"),c(E7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(E7,"href","#transformers.TFAutoModelForCausalLM"),c(Hd,"class","relative group"),c(NQ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qQ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jQ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DQ,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(GQ,"href","/docs/transformers/pr_17466/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(OQ,"href","/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(VQ,"href","/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(XQ,"href","/docs/transformers/pr_17466/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(zQ,"href","/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(WQ,"href","/docs/transformers/pr_17466/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(QQ,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(HQ,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(UQ,"href","/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(JQ,"href","/docs/transformers/pr_17466/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(YQ,"href","/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(q7,"id","transformers.TFAutoModelForImageClassification"),c(q7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(q7,"href","#transformers.TFAutoModelForImageClassification"),c(Yd,"class","relative group"),c(KQ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZQ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eH,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oH,"href","/docs/transformers/pr_17466/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(rH,"href","/docs/transformers/pr_17466/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(tH,"href","/docs/transformers/pr_17466/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(aH,"href","/docs/transformers/pr_17466/en/model_doc/vit#transformers.TFViTForImageClassification"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(z7,"id","transformers.TFAutoModelForMaskedLM"),c(z7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(z7,"href","#transformers.TFAutoModelForMaskedLM"),c(ec,"class","relative group"),c(nH,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sH,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lH,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iH,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(dH,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(cH,"href","/docs/transformers/pr_17466/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(fH,"href","/docs/transformers/pr_17466/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(mH,"href","/docs/transformers/pr_17466/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(gH,"href","/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(hH,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(pH,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(_H,"href","/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(uH,"href","/docs/transformers/pr_17466/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(bH,"href","/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(vH,"href","/docs/transformers/pr_17466/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(FH,"href","/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(TH,"href","/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(MH,"href","/docs/transformers/pr_17466/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(EH,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(CH,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(wH,"href","/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(AH,"href","/docs/transformers/pr_17466/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(yH,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hM,"id","transformers.TFAutoModelForSeq2SeqLM"),c(hM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hM,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(tc,"class","relative group"),c(LH,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xH,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($H,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kH,"href","/docs/transformers/pr_17466/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(SH,"href","/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(RH,"href","/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(PH,"href","/docs/transformers/pr_17466/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(BH,"href","/docs/transformers/pr_17466/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(IH,"href","/docs/transformers/pr_17466/en/model_doc/marian#transformers.TFMarianMTModel"),c(NH,"href","/docs/transformers/pr_17466/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(qH,"href","/docs/transformers/pr_17466/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(jH,"href","/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(DH,"href","/docs/transformers/pr_17466/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yM,"id","transformers.TFAutoModelForSequenceClassification"),c(yM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yM,"href","#transformers.TFAutoModelForSequenceClassification"),c(sc,"class","relative group"),c(GH,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OH,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VH,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XH,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(zH,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(WH,"href","/docs/transformers/pr_17466/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(QH,"href","/docs/transformers/pr_17466/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(HH,"href","/docs/transformers/pr_17466/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(UH,"href","/docs/transformers/pr_17466/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(JH,"href","/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(YH,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(KH,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(ZH,"href","/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(eU,"href","/docs/transformers/pr_17466/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(oU,"href","/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(rU,"href","/docs/transformers/pr_17466/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(tU,"href","/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(aU,"href","/docs/transformers/pr_17466/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(nU,"href","/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(sU,"href","/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(lU,"href","/docs/transformers/pr_17466/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(iU,"href","/docs/transformers/pr_17466/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(dU,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(cU,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(fU,"href","/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(mU,"href","/docs/transformers/pr_17466/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(gU,"href","/docs/transformers/pr_17466/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(hU,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(pU,"href","/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rE,"id","transformers.TFAutoModelForMultipleChoice"),c(rE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(rE,"href","#transformers.TFAutoModelForMultipleChoice"),c(dc,"class","relative group"),c(_U,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uU,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bU,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vU,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(FU,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(TU,"href","/docs/transformers/pr_17466/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(MU,"href","/docs/transformers/pr_17466/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(EU,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(CU,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(wU,"href","/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(AU,"href","/docs/transformers/pr_17466/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(yU,"href","/docs/transformers/pr_17466/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(LU,"href","/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(xU,"href","/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c($U,"href","/docs/transformers/pr_17466/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(kU,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(SU,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(RU,"href","/docs/transformers/pr_17466/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(PU,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(BU,"href","/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ME,"id","transformers.TFAutoModelForNextSentencePrediction"),c(ME,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ME,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(mc,"class","relative group"),c(IU,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NU,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qU,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jU,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(DU,"href","/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yE,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(yE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yE,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(pc,"class","relative group"),c(GU,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OU,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VU,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XU,"href","/docs/transformers/pr_17466/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kE,"id","transformers.TFAutoModelForTokenClassification"),c(kE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kE,"href","#transformers.TFAutoModelForTokenClassification"),c(bc,"class","relative group"),c(zU,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(WU,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(QU,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HU,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(UU,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(JU,"href","/docs/transformers/pr_17466/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(YU,"href","/docs/transformers/pr_17466/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(KU,"href","/docs/transformers/pr_17466/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(ZU,"href","/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(eJ,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(oJ,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(rJ,"href","/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(tJ,"href","/docs/transformers/pr_17466/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(aJ,"href","/docs/transformers/pr_17466/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(nJ,"href","/docs/transformers/pr_17466/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(sJ,"href","/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(lJ,"href","/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(iJ,"href","/docs/transformers/pr_17466/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(dJ,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(cJ,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(fJ,"href","/docs/transformers/pr_17466/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(mJ,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(gJ,"href","/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eC,"id","transformers.TFAutoModelForQuestionAnswering"),c(eC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(eC,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Tc,"class","relative group"),c(hJ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pJ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_J,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uJ,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(bJ,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(vJ,"href","/docs/transformers/pr_17466/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(FJ,"href","/docs/transformers/pr_17466/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(TJ,"href","/docs/transformers/pr_17466/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(MJ,"href","/docs/transformers/pr_17466/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(EJ,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(CJ,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(wJ,"href","/docs/transformers/pr_17466/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(AJ,"href","/docs/transformers/pr_17466/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(yJ,"href","/docs/transformers/pr_17466/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(LJ,"href","/docs/transformers/pr_17466/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(xJ,"href","/docs/transformers/pr_17466/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c($J,"href","/docs/transformers/pr_17466/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(kJ,"href","/docs/transformers/pr_17466/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(SJ,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(RJ,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(PJ,"href","/docs/transformers/pr_17466/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(BJ,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(IJ,"href","/docs/transformers/pr_17466/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EC,"id","transformers.TFAutoModelForVision2Seq"),c(EC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(EC,"href","#transformers.TFAutoModelForVision2Seq"),c(Cc,"class","relative group"),c(NJ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qJ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jJ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DJ,"href","/docs/transformers/pr_17466/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yC,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(yC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yC,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(yc,"class","relative group"),c(GJ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OJ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VJ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XJ,"href","/docs/transformers/pr_17466/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kC,"id","transformers.FlaxAutoModel"),c(kC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kC,"href","#transformers.FlaxAutoModel"),c($c,"class","relative group"),c(zJ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(WJ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(QJ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HJ,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.FlaxAlbertModel"),c(UJ,"href","/docs/transformers/pr_17466/en/model_doc/bart#transformers.FlaxBartModel"),c(JJ,"href","/docs/transformers/pr_17466/en/model_doc/beit#transformers.FlaxBeitModel"),c(YJ,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.FlaxBertModel"),c(KJ,"href","/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(ZJ,"href","/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(eY,"href","/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(oY,"href","/docs/transformers/pr_17466/en/model_doc/clip#transformers.FlaxCLIPModel"),c(rY,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(tY,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.FlaxElectraModel"),c(aY,"href","/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(nY,"href","/docs/transformers/pr_17466/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(sY,"href","/docs/transformers/pr_17466/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(lY,"href","/docs/transformers/pr_17466/en/model_doc/marian#transformers.FlaxMarianModel"),c(iY,"href","/docs/transformers/pr_17466/en/model_doc/mbart#transformers.FlaxMBartModel"),c(dY,"href","/docs/transformers/pr_17466/en/model_doc/mt5#transformers.FlaxMT5Model"),c(cY,"href","/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(fY,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(mY,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(gY,"href","/docs/transformers/pr_17466/en/model_doc/t5#transformers.FlaxT5Model"),c(hY,"href","/docs/transformers/pr_17466/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(pY,"href","/docs/transformers/pr_17466/en/model_doc/vit#transformers.FlaxViTModel"),c(_Y,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(uY,"href","/docs/transformers/pr_17466/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(bY,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(n5,"id","transformers.FlaxAutoModelForCausalLM"),c(n5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(n5,"href","#transformers.FlaxAutoModelForCausalLM"),c(Rc,"class","relative group"),c(vY,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(FY,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(TY,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(MY,"href","/docs/transformers/pr_17466/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(EY,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(CY,"href","/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(wY,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(AY,"href","/docs/transformers/pr_17466/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(yY,"href","/docs/transformers/pr_17466/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(LY,"href","/docs/transformers/pr_17466/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(xY,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c($Y,"href","/docs/transformers/pr_17466/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(u5,"id","transformers.FlaxAutoModelForPreTraining"),c(u5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(u5,"href","#transformers.FlaxAutoModelForPreTraining"),c(Ic,"class","relative group"),c(kY,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(SY,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(RY,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PY,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(BY,"href","/docs/transformers/pr_17466/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(IY,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(NY,"href","/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(qY,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(jY,"href","/docs/transformers/pr_17466/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(DY,"href","/docs/transformers/pr_17466/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(GY,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(OY,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(VY,"href","/docs/transformers/pr_17466/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(XY,"href","/docs/transformers/pr_17466/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(zY,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(S5,"id","transformers.FlaxAutoModelForMaskedLM"),c(S5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(S5,"href","#transformers.FlaxAutoModelForMaskedLM"),c(jc,"class","relative group"),c(WY,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QY,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(HY,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UY,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(JY,"href","/docs/transformers/pr_17466/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(YY,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(KY,"href","/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(ZY,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(eK,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(oK,"href","/docs/transformers/pr_17466/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(rK,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(tK,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(aK,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(z5,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(z5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(z5,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(Oc,"class","relative group"),c(nK,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sK,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lK,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iK,"href","/docs/transformers/pr_17466/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(dK,"href","/docs/transformers/pr_17466/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(cK,"href","/docs/transformers/pr_17466/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(fK,"href","/docs/transformers/pr_17466/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(mK,"href","/docs/transformers/pr_17466/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(gK,"href","/docs/transformers/pr_17466/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(hK,"href","/docs/transformers/pr_17466/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(pK,"href","/docs/transformers/pr_17466/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(_K,"href","/docs/transformers/pr_17466/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(t3,"id","transformers.FlaxAutoModelForSequenceClassification"),c(t3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(t3,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(zc,"class","relative group"),c(uK,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bK,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vK,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FK,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(TK,"href","/docs/transformers/pr_17466/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(MK,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(EK,"href","/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(CK,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(wK,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(AK,"href","/docs/transformers/pr_17466/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(yK,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(LK,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(xK,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_3,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(_3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_3,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(Hc,"class","relative group"),c($K,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kK,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SK,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RK,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(PK,"href","/docs/transformers/pr_17466/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(BK,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(IK,"href","/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(NK,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(qK,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(jK,"href","/docs/transformers/pr_17466/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(DK,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(GK,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(OK,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(x3,"id","transformers.FlaxAutoModelForTokenClassification"),c(x3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(x3,"href","#transformers.FlaxAutoModelForTokenClassification"),c(Yc,"class","relative group"),c(VK,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(XK,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zK,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WK,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(QK,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(HK,"href","/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(UK,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(JK,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(YK,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(KK,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(ZK,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(D3,"id","transformers.FlaxAutoModelForMultipleChoice"),c(D3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(D3,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(ef,"class","relative group"),c(eZ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oZ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rZ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tZ,"href","/docs/transformers/pr_17466/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(aZ,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(nZ,"href","/docs/transformers/pr_17466/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(sZ,"href","/docs/transformers/pr_17466/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(lZ,"href","/docs/transformers/pr_17466/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(iZ,"href","/docs/transformers/pr_17466/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(dZ,"href","/docs/transformers/pr_17466/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(cZ,"href","/docs/transformers/pr_17466/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Y3,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(Y3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Y3,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(tf,"class","relative group"),c(fZ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mZ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gZ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hZ,"href","/docs/transformers/pr_17466/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ow,"id","transformers.FlaxAutoModelForImageClassification"),c(ow,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ow,"href","#transformers.FlaxAutoModelForImageClassification"),c(sf,"class","relative group"),c(pZ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_Z,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(uZ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bZ,"href","/docs/transformers/pr_17466/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(vZ,"href","/docs/transformers/pr_17466/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sw,"id","transformers.FlaxAutoModelForVision2Seq"),c(sw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sw,"href","#transformers.FlaxAutoModelForVision2Seq"),c(cf,"class","relative group"),c(FZ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TZ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MZ,"href","/docs/transformers/pr_17466/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EZ,"href","/docs/transformers/pr_17466/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,u){e(document.head,g),b(f,v,u),b(f,p,u),e(p,m),e(m,_),M(d,_,null),e(p,h),e(p,Mo),e(Mo,mi),b(f,_f,u),b(f,rt,u),e(rt,gi),e(rt,hi),e(hi,yA),e(rt,uf),b(f,je,u),b(f,We,u),e(We,pi),e(We,yn),e(yn,LA),e(We,Ln),e(We,xn),e(xn,xA),e(We,_i),e(We,$n),e($n,$A),e(We,ui),b(f,bf,u),M(Ca,f,u),b(f,Qe,u),b(f,Ae,u),e(Ae,J$),e(Ae,bi),e(bi,Y$),e(Ae,K$),b(f,Eo,u),b(f,wa,u),e(wa,Z$),e(wa,vf),e(vf,ek),e(wa,AOe),b(f,pqe,u),b(f,vi,u),e(vi,Ff),e(Ff,_oe),M(kA,_oe,null),e(vi,yOe),e(vi,uoe),e(uoe,LOe),b(f,_qe,u),b(f,kn,u),e(kn,xOe),e(kn,boe),e(boe,$Oe),e(kn,kOe),e(kn,voe),e(voe,SOe),e(kn,ROe),b(f,uqe,u),M(SA,f,u),b(f,bqe,u),b(f,ok,u),e(ok,POe),b(f,vqe,u),M(Tf,f,u),b(f,Fqe,u),b(f,Fi,u),e(Fi,Mf),e(Mf,Foe),M(RA,Foe,null),e(Fi,BOe),e(Fi,Toe),e(Toe,IOe),b(f,Tqe,u),b(f,Co,u),M(PA,Co,null),e(Co,NOe),e(Co,BA),e(BA,qOe),e(BA,rk),e(rk,jOe),e(BA,DOe),e(Co,GOe),e(Co,IA),e(IA,OOe),e(IA,Moe),e(Moe,VOe),e(IA,XOe),e(Co,zOe),e(Co,Er),M(NA,Er,null),e(Er,WOe),e(Er,Eoe),e(Eoe,QOe),e(Er,HOe),e(Er,Ti),e(Ti,UOe),e(Ti,Coe),e(Coe,JOe),e(Ti,YOe),e(Ti,woe),e(woe,KOe),e(Ti,ZOe),e(Er,eVe),e(Er,A),e(A,Ef),e(Ef,Aoe),e(Aoe,oVe),e(Ef,rVe),e(Ef,tk),e(tk,tVe),e(Ef,aVe),e(A,nVe),e(A,Cf),e(Cf,yoe),e(yoe,sVe),e(Cf,lVe),e(Cf,ak),e(ak,iVe),e(Cf,dVe),e(A,cVe),e(A,wf),e(wf,Loe),e(Loe,fVe),e(wf,mVe),e(wf,nk),e(nk,gVe),e(wf,hVe),e(A,pVe),e(A,Af),e(Af,xoe),e(xoe,_Ve),e(Af,uVe),e(Af,sk),e(sk,bVe),e(Af,vVe),e(A,FVe),e(A,yf),e(yf,$oe),e($oe,TVe),e(yf,MVe),e(yf,lk),e(lk,EVe),e(yf,CVe),e(A,wVe),e(A,Lf),e(Lf,koe),e(koe,AVe),e(Lf,yVe),e(Lf,ik),e(ik,LVe),e(Lf,xVe),e(A,$Ve),e(A,xf),e(xf,Soe),e(Soe,kVe),e(xf,SVe),e(xf,dk),e(dk,RVe),e(xf,PVe),e(A,BVe),e(A,$f),e($f,Roe),e(Roe,IVe),e($f,NVe),e($f,ck),e(ck,qVe),e($f,jVe),e(A,DVe),e(A,kf),e(kf,Poe),e(Poe,GVe),e(kf,OVe),e(kf,fk),e(fk,VVe),e(kf,XVe),e(A,zVe),e(A,Sf),e(Sf,Boe),e(Boe,WVe),e(Sf,QVe),e(Sf,mk),e(mk,HVe),e(Sf,UVe),e(A,JVe),e(A,Rf),e(Rf,Ioe),e(Ioe,YVe),e(Rf,KVe),e(Rf,gk),e(gk,ZVe),e(Rf,eXe),e(A,oXe),e(A,Pf),e(Pf,Noe),e(Noe,rXe),e(Pf,tXe),e(Pf,hk),e(hk,aXe),e(Pf,nXe),e(A,sXe),e(A,Bf),e(Bf,qoe),e(qoe,lXe),e(Bf,iXe),e(Bf,pk),e(pk,dXe),e(Bf,cXe),e(A,fXe),e(A,If),e(If,joe),e(joe,mXe),e(If,gXe),e(If,_k),e(_k,hXe),e(If,pXe),e(A,_Xe),e(A,Nf),e(Nf,Doe),e(Doe,uXe),e(Nf,bXe),e(Nf,uk),e(uk,vXe),e(Nf,FXe),e(A,TXe),e(A,qf),e(qf,Goe),e(Goe,MXe),e(qf,EXe),e(qf,bk),e(bk,CXe),e(qf,wXe),e(A,AXe),e(A,jf),e(jf,Ooe),e(Ooe,yXe),e(jf,LXe),e(jf,vk),e(vk,xXe),e(jf,$Xe),e(A,kXe),e(A,Df),e(Df,Voe),e(Voe,SXe),e(Df,RXe),e(Df,Fk),e(Fk,PXe),e(Df,BXe),e(A,IXe),e(A,Gf),e(Gf,Xoe),e(Xoe,NXe),e(Gf,qXe),e(Gf,Tk),e(Tk,jXe),e(Gf,DXe),e(A,GXe),e(A,Of),e(Of,zoe),e(zoe,OXe),e(Of,VXe),e(Of,Mk),e(Mk,XXe),e(Of,zXe),e(A,WXe),e(A,Vf),e(Vf,Woe),e(Woe,QXe),e(Vf,HXe),e(Vf,Ek),e(Ek,UXe),e(Vf,JXe),e(A,YXe),e(A,Xf),e(Xf,Qoe),e(Qoe,KXe),e(Xf,ZXe),e(Xf,Ck),e(Ck,eze),e(Xf,oze),e(A,rze),e(A,zf),e(zf,Hoe),e(Hoe,tze),e(zf,aze),e(zf,wk),e(wk,nze),e(zf,sze),e(A,lze),e(A,Wf),e(Wf,Uoe),e(Uoe,ize),e(Wf,dze),e(Wf,Ak),e(Ak,cze),e(Wf,fze),e(A,mze),e(A,Qf),e(Qf,Joe),e(Joe,gze),e(Qf,hze),e(Qf,yk),e(yk,pze),e(Qf,_ze),e(A,uze),e(A,Hf),e(Hf,Yoe),e(Yoe,bze),e(Hf,vze),e(Hf,Lk),e(Lk,Fze),e(Hf,Tze),e(A,Mze),e(A,Uf),e(Uf,Koe),e(Koe,Eze),e(Uf,Cze),e(Uf,xk),e(xk,wze),e(Uf,Aze),e(A,yze),e(A,Jf),e(Jf,Zoe),e(Zoe,Lze),e(Jf,xze),e(Jf,$k),e($k,$ze),e(Jf,kze),e(A,Sze),e(A,Yf),e(Yf,ere),e(ere,Rze),e(Yf,Pze),e(Yf,kk),e(kk,Bze),e(Yf,Ize),e(A,Nze),e(A,Kf),e(Kf,ore),e(ore,qze),e(Kf,jze),e(Kf,Sk),e(Sk,Dze),e(Kf,Gze),e(A,Oze),e(A,Zf),e(Zf,rre),e(rre,Vze),e(Zf,Xze),e(Zf,Rk),e(Rk,zze),e(Zf,Wze),e(A,Qze),e(A,em),e(em,tre),e(tre,Hze),e(em,Uze),e(em,Pk),e(Pk,Jze),e(em,Yze),e(A,Kze),e(A,om),e(om,are),e(are,Zze),e(om,eWe),e(om,Bk),e(Bk,oWe),e(om,rWe),e(A,tWe),e(A,rm),e(rm,nre),e(nre,aWe),e(rm,nWe),e(rm,Ik),e(Ik,sWe),e(rm,lWe),e(A,iWe),e(A,tm),e(tm,sre),e(sre,dWe),e(tm,cWe),e(tm,Nk),e(Nk,fWe),e(tm,mWe),e(A,gWe),e(A,am),e(am,lre),e(lre,hWe),e(am,pWe),e(am,qk),e(qk,_We),e(am,uWe),e(A,bWe),e(A,nm),e(nm,ire),e(ire,vWe),e(nm,FWe),e(nm,jk),e(jk,TWe),e(nm,MWe),e(A,EWe),e(A,sm),e(sm,dre),e(dre,CWe),e(sm,wWe),e(sm,Dk),e(Dk,AWe),e(sm,yWe),e(A,LWe),e(A,lm),e(lm,cre),e(cre,xWe),e(lm,$We),e(lm,Gk),e(Gk,kWe),e(lm,SWe),e(A,RWe),e(A,im),e(im,fre),e(fre,PWe),e(im,BWe),e(im,Ok),e(Ok,IWe),e(im,NWe),e(A,qWe),e(A,dm),e(dm,mre),e(mre,jWe),e(dm,DWe),e(dm,Vk),e(Vk,GWe),e(dm,OWe),e(A,VWe),e(A,cm),e(cm,gre),e(gre,XWe),e(cm,zWe),e(cm,Xk),e(Xk,WWe),e(cm,QWe),e(A,HWe),e(A,fm),e(fm,hre),e(hre,UWe),e(fm,JWe),e(fm,zk),e(zk,YWe),e(fm,KWe),e(A,ZWe),e(A,mm),e(mm,pre),e(pre,eQe),e(mm,oQe),e(mm,Wk),e(Wk,rQe),e(mm,tQe),e(A,aQe),e(A,gm),e(gm,_re),e(_re,nQe),e(gm,sQe),e(gm,Qk),e(Qk,lQe),e(gm,iQe),e(A,dQe),e(A,hm),e(hm,ure),e(ure,cQe),e(hm,fQe),e(hm,Hk),e(Hk,mQe),e(hm,gQe),e(A,hQe),e(A,pm),e(pm,bre),e(bre,pQe),e(pm,_Qe),e(pm,Uk),e(Uk,uQe),e(pm,bQe),e(A,vQe),e(A,_m),e(_m,vre),e(vre,FQe),e(_m,TQe),e(_m,Jk),e(Jk,MQe),e(_m,EQe),e(A,CQe),e(A,um),e(um,Fre),e(Fre,wQe),e(um,AQe),e(um,Yk),e(Yk,yQe),e(um,LQe),e(A,xQe),e(A,bm),e(bm,Tre),e(Tre,$Qe),e(bm,kQe),e(bm,Kk),e(Kk,SQe),e(bm,RQe),e(A,PQe),e(A,vm),e(vm,Mre),e(Mre,BQe),e(vm,IQe),e(vm,Zk),e(Zk,NQe),e(vm,qQe),e(A,jQe),e(A,Fm),e(Fm,Ere),e(Ere,DQe),e(Fm,GQe),e(Fm,eS),e(eS,OQe),e(Fm,VQe),e(A,XQe),e(A,Tm),e(Tm,Cre),e(Cre,zQe),e(Tm,WQe),e(Tm,oS),e(oS,QQe),e(Tm,HQe),e(A,UQe),e(A,Mm),e(Mm,wre),e(wre,JQe),e(Mm,YQe),e(Mm,rS),e(rS,KQe),e(Mm,ZQe),e(A,eHe),e(A,Em),e(Em,Are),e(Are,oHe),e(Em,rHe),e(Em,tS),e(tS,tHe),e(Em,aHe),e(A,nHe),e(A,Cm),e(Cm,yre),e(yre,sHe),e(Cm,lHe),e(Cm,aS),e(aS,iHe),e(Cm,dHe),e(A,cHe),e(A,wm),e(wm,Lre),e(Lre,fHe),e(wm,mHe),e(wm,nS),e(nS,gHe),e(wm,hHe),e(A,pHe),e(A,Am),e(Am,xre),e(xre,_He),e(Am,uHe),e(Am,sS),e(sS,bHe),e(Am,vHe),e(A,FHe),e(A,ym),e(ym,$re),e($re,THe),e(ym,MHe),e(ym,lS),e(lS,EHe),e(ym,CHe),e(A,wHe),e(A,Lm),e(Lm,kre),e(kre,AHe),e(Lm,yHe),e(Lm,iS),e(iS,LHe),e(Lm,xHe),e(A,$He),e(A,xm),e(xm,Sre),e(Sre,kHe),e(xm,SHe),e(xm,dS),e(dS,RHe),e(xm,PHe),e(A,BHe),e(A,$m),e($m,Rre),e(Rre,IHe),e($m,NHe),e($m,cS),e(cS,qHe),e($m,jHe),e(A,DHe),e(A,km),e(km,Pre),e(Pre,GHe),e(km,OHe),e(km,fS),e(fS,VHe),e(km,XHe),e(A,zHe),e(A,Sm),e(Sm,Bre),e(Bre,WHe),e(Sm,QHe),e(Sm,mS),e(mS,HHe),e(Sm,UHe),e(A,JHe),e(A,Rm),e(Rm,Ire),e(Ire,YHe),e(Rm,KHe),e(Rm,gS),e(gS,ZHe),e(Rm,eUe),e(A,oUe),e(A,Pm),e(Pm,Nre),e(Nre,rUe),e(Pm,tUe),e(Pm,hS),e(hS,aUe),e(Pm,nUe),e(A,sUe),e(A,Bm),e(Bm,qre),e(qre,lUe),e(Bm,iUe),e(Bm,pS),e(pS,dUe),e(Bm,cUe),e(A,fUe),e(A,Im),e(Im,jre),e(jre,mUe),e(Im,gUe),e(Im,_S),e(_S,hUe),e(Im,pUe),e(A,_Ue),e(A,Nm),e(Nm,Dre),e(Dre,uUe),e(Nm,bUe),e(Nm,uS),e(uS,vUe),e(Nm,FUe),e(A,TUe),e(A,qm),e(qm,Gre),e(Gre,MUe),e(qm,EUe),e(qm,bS),e(bS,CUe),e(qm,wUe),e(A,AUe),e(A,jm),e(jm,Ore),e(Ore,yUe),e(jm,LUe),e(jm,vS),e(vS,xUe),e(jm,$Ue),e(A,kUe),e(A,Dm),e(Dm,Vre),e(Vre,SUe),e(Dm,RUe),e(Dm,FS),e(FS,PUe),e(Dm,BUe),e(A,IUe),e(A,Gm),e(Gm,Xre),e(Xre,NUe),e(Gm,qUe),e(Gm,TS),e(TS,jUe),e(Gm,DUe),e(A,GUe),e(A,Om),e(Om,zre),e(zre,OUe),e(Om,VUe),e(Om,MS),e(MS,XUe),e(Om,zUe),e(A,WUe),e(A,Vm),e(Vm,Wre),e(Wre,QUe),e(Vm,HUe),e(Vm,ES),e(ES,UUe),e(Vm,JUe),e(A,YUe),e(A,Xm),e(Xm,Qre),e(Qre,KUe),e(Xm,ZUe),e(Xm,CS),e(CS,eJe),e(Xm,oJe),e(A,rJe),e(A,zm),e(zm,Hre),e(Hre,tJe),e(zm,aJe),e(zm,wS),e(wS,nJe),e(zm,sJe),e(A,lJe),e(A,Wm),e(Wm,Ure),e(Ure,iJe),e(Wm,dJe),e(Wm,AS),e(AS,cJe),e(Wm,fJe),e(A,mJe),e(A,Qm),e(Qm,Jre),e(Jre,gJe),e(Qm,hJe),e(Qm,yS),e(yS,pJe),e(Qm,_Je),e(A,uJe),e(A,Hm),e(Hm,Yre),e(Yre,bJe),e(Hm,vJe),e(Hm,LS),e(LS,FJe),e(Hm,TJe),e(A,MJe),e(A,Um),e(Um,Kre),e(Kre,EJe),e(Um,CJe),e(Um,xS),e(xS,wJe),e(Um,AJe),e(A,yJe),e(A,Jm),e(Jm,Zre),e(Zre,LJe),e(Jm,xJe),e(Jm,$S),e($S,$Je),e(Jm,kJe),e(A,SJe),e(A,Ym),e(Ym,ete),e(ete,RJe),e(Ym,PJe),e(Ym,kS),e(kS,BJe),e(Ym,IJe),e(A,NJe),e(A,Km),e(Km,ote),e(ote,qJe),e(Km,jJe),e(Km,SS),e(SS,DJe),e(Km,GJe),e(A,OJe),e(A,Zm),e(Zm,rte),e(rte,VJe),e(Zm,XJe),e(Zm,RS),e(RS,zJe),e(Zm,WJe),e(A,QJe),e(A,eg),e(eg,tte),e(tte,HJe),e(eg,UJe),e(eg,PS),e(PS,JJe),e(eg,YJe),e(A,KJe),e(A,og),e(og,ate),e(ate,ZJe),e(og,eYe),e(og,BS),e(BS,oYe),e(og,rYe),e(A,tYe),e(A,rg),e(rg,nte),e(nte,aYe),e(rg,nYe),e(rg,IS),e(IS,sYe),e(rg,lYe),e(A,iYe),e(A,tg),e(tg,ste),e(ste,dYe),e(tg,cYe),e(tg,NS),e(NS,fYe),e(tg,mYe),e(A,gYe),e(A,ag),e(ag,lte),e(lte,hYe),e(ag,pYe),e(ag,qS),e(qS,_Ye),e(ag,uYe),e(A,bYe),e(A,ng),e(ng,ite),e(ite,vYe),e(ng,FYe),e(ng,jS),e(jS,TYe),e(ng,MYe),e(A,EYe),e(A,sg),e(sg,dte),e(dte,CYe),e(sg,wYe),e(sg,DS),e(DS,AYe),e(sg,yYe),e(A,LYe),e(A,lg),e(lg,cte),e(cte,xYe),e(lg,$Ye),e(lg,GS),e(GS,kYe),e(lg,SYe),e(A,RYe),e(A,ig),e(ig,fte),e(fte,PYe),e(ig,BYe),e(ig,OS),e(OS,IYe),e(ig,NYe),e(A,qYe),e(A,dg),e(dg,mte),e(mte,jYe),e(dg,DYe),e(dg,VS),e(VS,GYe),e(dg,OYe),e(A,VYe),e(A,cg),e(cg,gte),e(gte,XYe),e(cg,zYe),e(cg,XS),e(XS,WYe),e(cg,QYe),e(A,HYe),e(A,fg),e(fg,hte),e(hte,UYe),e(fg,JYe),e(fg,zS),e(zS,YYe),e(fg,KYe),e(A,ZYe),e(A,mg),e(mg,pte),e(pte,eKe),e(mg,oKe),e(mg,WS),e(WS,rKe),e(mg,tKe),e(A,aKe),e(A,gg),e(gg,_te),e(_te,nKe),e(gg,sKe),e(gg,QS),e(QS,lKe),e(gg,iKe),e(A,dKe),e(A,hg),e(hg,ute),e(ute,cKe),e(hg,fKe),e(hg,HS),e(HS,mKe),e(hg,gKe),e(A,hKe),e(A,pg),e(pg,bte),e(bte,pKe),e(pg,_Ke),e(pg,US),e(US,uKe),e(pg,bKe),e(A,vKe),e(A,_g),e(_g,vte),e(vte,FKe),e(_g,TKe),e(_g,JS),e(JS,MKe),e(_g,EKe),e(A,CKe),e(A,ug),e(ug,Fte),e(Fte,wKe),e(ug,AKe),e(ug,YS),e(YS,yKe),e(ug,LKe),e(A,xKe),e(A,bg),e(bg,Tte),e(Tte,$Ke),e(bg,kKe),e(bg,KS),e(KS,SKe),e(bg,RKe),e(A,PKe),e(A,vg),e(vg,Mte),e(Mte,BKe),e(vg,IKe),e(vg,ZS),e(ZS,NKe),e(vg,qKe),e(A,jKe),e(A,Fg),e(Fg,Ete),e(Ete,DKe),e(Fg,GKe),e(Fg,eR),e(eR,OKe),e(Fg,VKe),e(A,XKe),e(A,Tg),e(Tg,Cte),e(Cte,zKe),e(Tg,WKe),e(Tg,oR),e(oR,QKe),e(Tg,HKe),e(A,UKe),e(A,Mg),e(Mg,wte),e(wte,JKe),e(Mg,YKe),e(Mg,rR),e(rR,KKe),e(Mg,ZKe),e(A,eZe),e(A,Eg),e(Eg,Ate),e(Ate,oZe),e(Eg,rZe),e(Eg,tR),e(tR,tZe),e(Eg,aZe),e(A,nZe),e(A,Cg),e(Cg,yte),e(yte,sZe),e(Cg,lZe),e(Cg,aR),e(aR,iZe),e(Cg,dZe),e(Er,cZe),M(wg,Er,null),e(Co,fZe),e(Co,Ag),M(qA,Ag,null),e(Ag,mZe),e(Ag,Lte),e(Lte,gZe),b(f,Mqe,u),b(f,Mi,u),e(Mi,yg),e(yg,xte),M(jA,xte,null),e(Mi,hZe),e(Mi,$te),e($te,pZe),b(f,Eqe,u),b(f,wo,u),M(DA,wo,null),e(wo,_Ze),e(wo,GA),e(GA,uZe),e(GA,nR),e(nR,bZe),e(GA,vZe),e(wo,FZe),e(wo,OA),e(OA,TZe),e(OA,kte),e(kte,MZe),e(OA,EZe),e(wo,CZe),e(wo,Cr),M(VA,Cr,null),e(Cr,wZe),e(Cr,Ste),e(Ste,AZe),e(Cr,yZe),e(Cr,Aa),e(Aa,LZe),e(Aa,Rte),e(Rte,xZe),e(Aa,$Ze),e(Aa,Pte),e(Pte,kZe),e(Aa,SZe),e(Aa,Bte),e(Bte,RZe),e(Aa,PZe),e(Cr,BZe),e(Cr,k),e(k,Sn),e(Sn,Ite),e(Ite,IZe),e(Sn,NZe),e(Sn,sR),e(sR,qZe),e(Sn,jZe),e(Sn,lR),e(lR,DZe),e(Sn,GZe),e(k,OZe),e(k,Rn),e(Rn,Nte),e(Nte,VZe),e(Rn,XZe),e(Rn,iR),e(iR,zZe),e(Rn,WZe),e(Rn,dR),e(dR,QZe),e(Rn,HZe),e(k,UZe),e(k,Pn),e(Pn,qte),e(qte,JZe),e(Pn,YZe),e(Pn,cR),e(cR,KZe),e(Pn,ZZe),e(Pn,fR),e(fR,eeo),e(Pn,oeo),e(k,reo),e(k,Lg),e(Lg,jte),e(jte,teo),e(Lg,aeo),e(Lg,mR),e(mR,neo),e(Lg,seo),e(k,leo),e(k,Bn),e(Bn,Dte),e(Dte,ieo),e(Bn,deo),e(Bn,gR),e(gR,ceo),e(Bn,feo),e(Bn,hR),e(hR,meo),e(Bn,geo),e(k,heo),e(k,xg),e(xg,Gte),e(Gte,peo),e(xg,_eo),e(xg,pR),e(pR,ueo),e(xg,beo),e(k,veo),e(k,$g),e($g,Ote),e(Ote,Feo),e($g,Teo),e($g,_R),e(_R,Meo),e($g,Eeo),e(k,Ceo),e(k,kg),e(kg,Vte),e(Vte,weo),e(kg,Aeo),e(kg,uR),e(uR,yeo),e(kg,Leo),e(k,xeo),e(k,In),e(In,Xte),e(Xte,$eo),e(In,keo),e(In,bR),e(bR,Seo),e(In,Reo),e(In,vR),e(vR,Peo),e(In,Beo),e(k,Ieo),e(k,Nn),e(Nn,zte),e(zte,Neo),e(Nn,qeo),e(Nn,FR),e(FR,jeo),e(Nn,Deo),e(Nn,TR),e(TR,Geo),e(Nn,Oeo),e(k,Veo),e(k,qn),e(qn,Wte),e(Wte,Xeo),e(qn,zeo),e(qn,MR),e(MR,Weo),e(qn,Qeo),e(qn,ER),e(ER,Heo),e(qn,Ueo),e(k,Jeo),e(k,Sg),e(Sg,Qte),e(Qte,Yeo),e(Sg,Keo),e(Sg,CR),e(CR,Zeo),e(Sg,eoo),e(k,ooo),e(k,Rg),e(Rg,Hte),e(Hte,roo),e(Rg,too),e(Rg,wR),e(wR,aoo),e(Rg,noo),e(k,soo),e(k,jn),e(jn,Ute),e(Ute,loo),e(jn,ioo),e(jn,AR),e(AR,doo),e(jn,coo),e(jn,yR),e(yR,foo),e(jn,moo),e(k,goo),e(k,Pg),e(Pg,Jte),e(Jte,hoo),e(Pg,poo),e(Pg,LR),e(LR,_oo),e(Pg,uoo),e(k,boo),e(k,Dn),e(Dn,Yte),e(Yte,voo),e(Dn,Foo),e(Dn,xR),e(xR,Too),e(Dn,Moo),e(Dn,$R),e($R,Eoo),e(Dn,Coo),e(k,woo),e(k,Gn),e(Gn,Kte),e(Kte,Aoo),e(Gn,yoo),e(Gn,kR),e(kR,Loo),e(Gn,xoo),e(Gn,SR),e(SR,$oo),e(Gn,koo),e(k,Soo),e(k,On),e(On,Zte),e(Zte,Roo),e(On,Poo),e(On,RR),e(RR,Boo),e(On,Ioo),e(On,PR),e(PR,Noo),e(On,qoo),e(k,joo),e(k,Bg),e(Bg,eae),e(eae,Doo),e(Bg,Goo),e(Bg,BR),e(BR,Ooo),e(Bg,Voo),e(k,Xoo),e(k,Vn),e(Vn,oae),e(oae,zoo),e(Vn,Woo),e(Vn,IR),e(IR,Qoo),e(Vn,Hoo),e(Vn,NR),e(NR,Uoo),e(Vn,Joo),e(k,Yoo),e(k,Xn),e(Xn,rae),e(rae,Koo),e(Xn,Zoo),e(Xn,qR),e(qR,ero),e(Xn,oro),e(Xn,jR),e(jR,rro),e(Xn,tro),e(k,aro),e(k,zn),e(zn,tae),e(tae,nro),e(zn,sro),e(zn,DR),e(DR,lro),e(zn,iro),e(zn,GR),e(GR,dro),e(zn,cro),e(k,fro),e(k,Wn),e(Wn,aae),e(aae,mro),e(Wn,gro),e(Wn,OR),e(OR,hro),e(Wn,pro),e(Wn,VR),e(VR,_ro),e(Wn,uro),e(k,bro),e(k,Qn),e(Qn,nae),e(nae,vro),e(Qn,Fro),e(Qn,XR),e(XR,Tro),e(Qn,Mro),e(Qn,zR),e(zR,Ero),e(Qn,Cro),e(k,wro),e(k,Hn),e(Hn,sae),e(sae,Aro),e(Hn,yro),e(Hn,WR),e(WR,Lro),e(Hn,xro),e(Hn,QR),e(QR,$ro),e(Hn,kro),e(k,Sro),e(k,Ig),e(Ig,lae),e(lae,Rro),e(Ig,Pro),e(Ig,HR),e(HR,Bro),e(Ig,Iro),e(k,Nro),e(k,Un),e(Un,iae),e(iae,qro),e(Un,jro),e(Un,UR),e(UR,Dro),e(Un,Gro),e(Un,JR),e(JR,Oro),e(Un,Vro),e(k,Xro),e(k,Ng),e(Ng,dae),e(dae,zro),e(Ng,Wro),e(Ng,YR),e(YR,Qro),e(Ng,Hro),e(k,Uro),e(k,Jn),e(Jn,cae),e(cae,Jro),e(Jn,Yro),e(Jn,KR),e(KR,Kro),e(Jn,Zro),e(Jn,ZR),e(ZR,eto),e(Jn,oto),e(k,rto),e(k,Yn),e(Yn,fae),e(fae,tto),e(Yn,ato),e(Yn,eP),e(eP,nto),e(Yn,sto),e(Yn,oP),e(oP,lto),e(Yn,ito),e(k,dto),e(k,Kn),e(Kn,mae),e(mae,cto),e(Kn,fto),e(Kn,rP),e(rP,mto),e(Kn,gto),e(Kn,tP),e(tP,hto),e(Kn,pto),e(k,_to),e(k,qg),e(qg,gae),e(gae,uto),e(qg,bto),e(qg,aP),e(aP,vto),e(qg,Fto),e(k,Tto),e(k,Zn),e(Zn,hae),e(hae,Mto),e(Zn,Eto),e(Zn,nP),e(nP,Cto),e(Zn,wto),e(Zn,sP),e(sP,Ato),e(Zn,yto),e(k,Lto),e(k,es),e(es,pae),e(pae,xto),e(es,$to),e(es,lP),e(lP,kto),e(es,Sto),e(es,iP),e(iP,Rto),e(es,Pto),e(k,Bto),e(k,jg),e(jg,_ae),e(_ae,Ito),e(jg,Nto),e(jg,dP),e(dP,qto),e(jg,jto),e(k,Dto),e(k,os),e(os,uae),e(uae,Gto),e(os,Oto),e(os,cP),e(cP,Vto),e(os,Xto),e(os,fP),e(fP,zto),e(os,Wto),e(k,Qto),e(k,rs),e(rs,bae),e(bae,Hto),e(rs,Uto),e(rs,mP),e(mP,Jto),e(rs,Yto),e(rs,gP),e(gP,Kto),e(rs,Zto),e(k,eao),e(k,ts),e(ts,vae),e(vae,oao),e(ts,rao),e(ts,hP),e(hP,tao),e(ts,aao),e(ts,pP),e(pP,nao),e(ts,sao),e(k,lao),e(k,as),e(as,Fae),e(Fae,iao),e(as,dao),e(as,_P),e(_P,cao),e(as,fao),e(as,uP),e(uP,mao),e(as,gao),e(k,hao),e(k,ns),e(ns,Tae),e(Tae,pao),e(ns,_ao),e(ns,bP),e(bP,uao),e(ns,bao),e(ns,vP),e(vP,vao),e(ns,Fao),e(k,Tao),e(k,ss),e(ss,Mae),e(Mae,Mao),e(ss,Eao),e(ss,FP),e(FP,Cao),e(ss,wao),e(ss,TP),e(TP,Aao),e(ss,yao),e(k,Lao),e(k,ls),e(ls,Eae),e(Eae,xao),e(ls,$ao),e(ls,MP),e(MP,kao),e(ls,Sao),e(ls,EP),e(EP,Rao),e(ls,Pao),e(k,Bao),e(k,Dg),e(Dg,Cae),e(Cae,Iao),e(Dg,Nao),e(Dg,CP),e(CP,qao),e(Dg,jao),e(k,Dao),e(k,is),e(is,wae),e(wae,Gao),e(is,Oao),e(is,wP),e(wP,Vao),e(is,Xao),e(is,AP),e(AP,zao),e(is,Wao),e(k,Qao),e(k,Gg),e(Gg,Aae),e(Aae,Hao),e(Gg,Uao),e(Gg,yP),e(yP,Jao),e(Gg,Yao),e(k,Kao),e(k,Og),e(Og,yae),e(yae,Zao),e(Og,eno),e(Og,LP),e(LP,ono),e(Og,rno),e(k,tno),e(k,ds),e(ds,Lae),e(Lae,ano),e(ds,nno),e(ds,xP),e(xP,sno),e(ds,lno),e(ds,$P),e($P,ino),e(ds,dno),e(k,cno),e(k,cs),e(cs,xae),e(xae,fno),e(cs,mno),e(cs,kP),e(kP,gno),e(cs,hno),e(cs,SP),e(SP,pno),e(cs,_no),e(k,uno),e(k,fs),e(fs,$ae),e($ae,bno),e(fs,vno),e(fs,RP),e(RP,Fno),e(fs,Tno),e(fs,PP),e(PP,Mno),e(fs,Eno),e(k,Cno),e(k,Vg),e(Vg,kae),e(kae,wno),e(Vg,Ano),e(Vg,BP),e(BP,yno),e(Vg,Lno),e(k,xno),e(k,ms),e(ms,Sae),e(Sae,$no),e(ms,kno),e(ms,IP),e(IP,Sno),e(ms,Rno),e(ms,NP),e(NP,Pno),e(ms,Bno),e(k,Ino),e(k,gs),e(gs,Rae),e(Rae,Nno),e(gs,qno),e(gs,qP),e(qP,jno),e(gs,Dno),e(gs,jP),e(jP,Gno),e(gs,Ono),e(k,Vno),e(k,hs),e(hs,Pae),e(Pae,Xno),e(hs,zno),e(hs,DP),e(DP,Wno),e(hs,Qno),e(hs,GP),e(GP,Hno),e(hs,Uno),e(k,Jno),e(k,ps),e(ps,Bae),e(Bae,Yno),e(ps,Kno),e(ps,OP),e(OP,Zno),e(ps,eso),e(ps,VP),e(VP,oso),e(ps,rso),e(k,tso),e(k,_s),e(_s,Iae),e(Iae,aso),e(_s,nso),e(_s,XP),e(XP,sso),e(_s,lso),e(_s,zP),e(zP,iso),e(_s,dso),e(k,cso),e(k,Xg),e(Xg,Nae),e(Nae,fso),e(Xg,mso),e(Xg,WP),e(WP,gso),e(Xg,hso),e(k,pso),e(k,us),e(us,qae),e(qae,_so),e(us,uso),e(us,QP),e(QP,bso),e(us,vso),e(us,HP),e(HP,Fso),e(us,Tso),e(k,Mso),e(k,zg),e(zg,jae),e(jae,Eso),e(zg,Cso),e(zg,UP),e(UP,wso),e(zg,Aso),e(k,yso),e(k,Wg),e(Wg,Dae),e(Dae,Lso),e(Wg,xso),e(Wg,JP),e(JP,$so),e(Wg,kso),e(k,Sso),e(k,Qg),e(Qg,Gae),e(Gae,Rso),e(Qg,Pso),e(Qg,YP),e(YP,Bso),e(Qg,Iso),e(k,Nso),e(k,Hg),e(Hg,Oae),e(Oae,qso),e(Hg,jso),e(Hg,KP),e(KP,Dso),e(Hg,Gso),e(k,Oso),e(k,bs),e(bs,Vae),e(Vae,Vso),e(bs,Xso),e(bs,ZP),e(ZP,zso),e(bs,Wso),e(bs,eB),e(eB,Qso),e(bs,Hso),e(k,Uso),e(k,Ug),e(Ug,Xae),e(Xae,Jso),e(Ug,Yso),e(Ug,oB),e(oB,Kso),e(Ug,Zso),e(k,elo),e(k,vs),e(vs,zae),e(zae,olo),e(vs,rlo),e(vs,rB),e(rB,tlo),e(vs,alo),e(vs,tB),e(tB,nlo),e(vs,slo),e(k,llo),e(k,Fs),e(Fs,Wae),e(Wae,ilo),e(Fs,dlo),e(Fs,aB),e(aB,clo),e(Fs,flo),e(Fs,nB),e(nB,mlo),e(Fs,glo),e(k,hlo),e(k,Ts),e(Ts,Qae),e(Qae,plo),e(Ts,_lo),e(Ts,sB),e(sB,ulo),e(Ts,blo),e(Ts,lB),e(lB,vlo),e(Ts,Flo),e(k,Tlo),e(k,Ms),e(Ms,Hae),e(Hae,Mlo),e(Ms,Elo),e(Ms,iB),e(iB,Clo),e(Ms,wlo),e(Ms,dB),e(dB,Alo),e(Ms,ylo),e(k,Llo),e(k,Es),e(Es,Uae),e(Uae,xlo),e(Es,$lo),e(Es,cB),e(cB,klo),e(Es,Slo),e(Es,fB),e(fB,Rlo),e(Es,Plo),e(k,Blo),e(k,Cs),e(Cs,Jae),e(Jae,Ilo),e(Cs,Nlo),e(Cs,mB),e(mB,qlo),e(Cs,jlo),e(Cs,gB),e(gB,Dlo),e(Cs,Glo),e(k,Olo),e(k,Jg),e(Jg,Yae),e(Yae,Vlo),e(Jg,Xlo),e(Jg,hB),e(hB,zlo),e(Jg,Wlo),e(k,Qlo),e(k,Yg),e(Yg,Kae),e(Kae,Hlo),e(Yg,Ulo),e(Yg,pB),e(pB,Jlo),e(Yg,Ylo),e(k,Klo),e(k,ws),e(ws,Zae),e(Zae,Zlo),e(ws,eio),e(ws,_B),e(_B,oio),e(ws,rio),e(ws,uB),e(uB,tio),e(ws,aio),e(k,nio),e(k,As),e(As,ene),e(ene,sio),e(As,lio),e(As,bB),e(bB,iio),e(As,dio),e(As,vB),e(vB,cio),e(As,fio),e(k,mio),e(k,ys),e(ys,one),e(one,gio),e(ys,hio),e(ys,FB),e(FB,pio),e(ys,_io),e(ys,TB),e(TB,uio),e(ys,bio),e(k,vio),e(k,Kg),e(Kg,rne),e(rne,Fio),e(Kg,Tio),e(Kg,MB),e(MB,Mio),e(Kg,Eio),e(k,Cio),e(k,Zg),e(Zg,tne),e(tne,wio),e(Zg,Aio),e(Zg,EB),e(EB,yio),e(Zg,Lio),e(k,xio),e(k,eh),e(eh,ane),e(ane,$io),e(eh,kio),e(eh,CB),e(CB,Sio),e(eh,Rio),e(k,Pio),e(k,Ls),e(Ls,nne),e(nne,Bio),e(Ls,Iio),e(Ls,wB),e(wB,Nio),e(Ls,qio),e(Ls,AB),e(AB,jio),e(Ls,Dio),e(k,Gio),e(k,oh),e(oh,sne),e(sne,Oio),e(oh,Vio),e(oh,yB),e(yB,Xio),e(oh,zio),e(k,Wio),e(k,rh),e(rh,lne),e(lne,Qio),e(rh,Hio),e(rh,LB),e(LB,Uio),e(rh,Jio),e(k,Yio),e(k,th),e(th,ine),e(ine,Kio),e(th,Zio),e(th,xB),e(xB,edo),e(th,odo),e(k,rdo),e(k,xs),e(xs,dne),e(dne,tdo),e(xs,ado),e(xs,$B),e($B,ndo),e(xs,sdo),e(xs,kB),e(kB,ldo),e(xs,ido),e(k,ddo),e(k,ah),e(ah,cne),e(cne,cdo),e(ah,fdo),e(ah,SB),e(SB,mdo),e(ah,gdo),e(k,hdo),e(k,nh),e(nh,fne),e(fne,pdo),e(nh,_do),e(nh,RB),e(RB,udo),e(nh,bdo),e(k,vdo),e(k,$s),e($s,mne),e(mne,Fdo),e($s,Tdo),e($s,PB),e(PB,Mdo),e($s,Edo),e($s,BB),e(BB,Cdo),e($s,wdo),e(k,Ado),e(k,ks),e(ks,gne),e(gne,ydo),e(ks,Ldo),e(ks,IB),e(IB,xdo),e(ks,$do),e(ks,NB),e(NB,kdo),e(ks,Sdo),e(k,Rdo),e(k,Ss),e(Ss,hne),e(hne,Pdo),e(Ss,Bdo),e(Ss,qB),e(qB,Ido),e(Ss,Ndo),e(Ss,jB),e(jB,qdo),e(Ss,jdo),e(k,Ddo),e(k,Rs),e(Rs,pne),e(pne,Gdo),e(Rs,Odo),e(Rs,DB),e(DB,Vdo),e(Rs,Xdo),e(Rs,GB),e(GB,zdo),e(Rs,Wdo),e(Cr,Qdo),M(sh,Cr,null),e(wo,Hdo),e(wo,lh),M(XA,lh,null),e(lh,Udo),e(lh,_ne),e(_ne,Jdo),b(f,Cqe,u),b(f,Ei,u),e(Ei,ih),e(ih,une),M(zA,une,null),e(Ei,Ydo),e(Ei,bne),e(bne,Kdo),b(f,wqe,u),b(f,Ao,u),M(WA,Ao,null),e(Ao,Zdo),e(Ao,QA),e(QA,eco),e(QA,OB),e(OB,oco),e(QA,rco),e(Ao,tco),e(Ao,HA),e(HA,aco),e(HA,vne),e(vne,nco),e(HA,sco),e(Ao,lco),e(Ao,He),M(UA,He,null),e(He,ico),e(He,Fne),e(Fne,dco),e(He,cco),e(He,ya),e(ya,fco),e(ya,Tne),e(Tne,mco),e(ya,gco),e(ya,Mne),e(Mne,hco),e(ya,pco),e(ya,Ene),e(Ene,_co),e(ya,uco),e(He,bco),e(He,Y),e(Y,dh),e(dh,Cne),e(Cne,vco),e(dh,Fco),e(dh,VB),e(VB,Tco),e(dh,Mco),e(Y,Eco),e(Y,ch),e(ch,wne),e(wne,Cco),e(ch,wco),e(ch,XB),e(XB,Aco),e(ch,yco),e(Y,Lco),e(Y,fh),e(fh,Ane),e(Ane,xco),e(fh,$co),e(fh,zB),e(zB,kco),e(fh,Sco),e(Y,Rco),e(Y,mh),e(mh,yne),e(yne,Pco),e(mh,Bco),e(mh,WB),e(WB,Ico),e(mh,Nco),e(Y,qco),e(Y,gh),e(gh,Lne),e(Lne,jco),e(gh,Dco),e(gh,QB),e(QB,Gco),e(gh,Oco),e(Y,Vco),e(Y,hh),e(hh,xne),e(xne,Xco),e(hh,zco),e(hh,HB),e(HB,Wco),e(hh,Qco),e(Y,Hco),e(Y,ph),e(ph,$ne),e($ne,Uco),e(ph,Jco),e(ph,UB),e(UB,Yco),e(ph,Kco),e(Y,Zco),e(Y,_h),e(_h,kne),e(kne,efo),e(_h,ofo),e(_h,JB),e(JB,rfo),e(_h,tfo),e(Y,afo),e(Y,uh),e(uh,Sne),e(Sne,nfo),e(uh,sfo),e(uh,YB),e(YB,lfo),e(uh,ifo),e(Y,dfo),e(Y,bh),e(bh,Rne),e(Rne,cfo),e(bh,ffo),e(bh,KB),e(KB,mfo),e(bh,gfo),e(Y,hfo),e(Y,vh),e(vh,Pne),e(Pne,pfo),e(vh,_fo),e(vh,ZB),e(ZB,ufo),e(vh,bfo),e(Y,vfo),e(Y,Fh),e(Fh,Bne),e(Bne,Ffo),e(Fh,Tfo),e(Fh,eI),e(eI,Mfo),e(Fh,Efo),e(Y,Cfo),e(Y,Th),e(Th,Ine),e(Ine,wfo),e(Th,Afo),e(Th,oI),e(oI,yfo),e(Th,Lfo),e(Y,xfo),e(Y,Mh),e(Mh,Nne),e(Nne,$fo),e(Mh,kfo),e(Mh,rI),e(rI,Sfo),e(Mh,Rfo),e(Y,Pfo),e(Y,Eh),e(Eh,qne),e(qne,Bfo),e(Eh,Ifo),e(Eh,tI),e(tI,Nfo),e(Eh,qfo),e(Y,jfo),e(Y,Ch),e(Ch,jne),e(jne,Dfo),e(Ch,Gfo),e(Ch,aI),e(aI,Ofo),e(Ch,Vfo),e(Y,Xfo),e(Y,wh),e(wh,Dne),e(Dne,zfo),e(wh,Wfo),e(wh,nI),e(nI,Qfo),e(wh,Hfo),e(Y,Ufo),e(Y,Ah),e(Ah,Gne),e(Gne,Jfo),e(Ah,Yfo),e(Ah,sI),e(sI,Kfo),e(Ah,Zfo),e(Y,emo),e(Y,yh),e(yh,One),e(One,omo),e(yh,rmo),e(yh,lI),e(lI,tmo),e(yh,amo),e(Y,nmo),e(Y,Lh),e(Lh,Vne),e(Vne,smo),e(Lh,lmo),e(Lh,iI),e(iI,imo),e(Lh,dmo),e(Y,cmo),e(Y,xh),e(xh,Xne),e(Xne,fmo),e(xh,mmo),e(xh,dI),e(dI,gmo),e(xh,hmo),e(Y,pmo),e(Y,$h),e($h,zne),e(zne,_mo),e($h,umo),e($h,cI),e(cI,bmo),e($h,vmo),e(Y,Fmo),e(Y,kh),e(kh,Wne),e(Wne,Tmo),e(kh,Mmo),e(kh,fI),e(fI,Emo),e(kh,Cmo),e(Y,wmo),e(Y,Sh),e(Sh,Qne),e(Qne,Amo),e(Sh,ymo),e(Sh,mI),e(mI,Lmo),e(Sh,xmo),e(Y,$mo),e(Y,Rh),e(Rh,Hne),e(Hne,kmo),e(Rh,Smo),e(Rh,gI),e(gI,Rmo),e(Rh,Pmo),e(Y,Bmo),e(Y,Ph),e(Ph,Une),e(Une,Imo),e(Ph,Nmo),e(Ph,hI),e(hI,qmo),e(Ph,jmo),e(Y,Dmo),e(Y,Bh),e(Bh,Jne),e(Jne,Gmo),e(Bh,Omo),e(Bh,pI),e(pI,Vmo),e(Bh,Xmo),e(Y,zmo),e(Y,Ih),e(Ih,Yne),e(Yne,Wmo),e(Ih,Qmo),e(Ih,_I),e(_I,Hmo),e(Ih,Umo),e(Y,Jmo),e(Y,Nh),e(Nh,Kne),e(Kne,Ymo),e(Nh,Kmo),e(Nh,uI),e(uI,Zmo),e(Nh,ego),e(Y,ogo),e(Y,qh),e(qh,Zne),e(Zne,rgo),e(qh,tgo),e(qh,bI),e(bI,ago),e(qh,ngo),e(He,sgo),M(jh,He,null),e(He,lgo),M(Dh,He,null),e(Ao,igo),e(Ao,Gh),M(JA,Gh,null),e(Gh,dgo),e(Gh,ese),e(ese,cgo),b(f,Aqe,u),b(f,Ci,u),e(Ci,Oh),e(Oh,ose),M(YA,ose,null),e(Ci,fgo),e(Ci,rse),e(rse,mgo),b(f,yqe,u),b(f,yo,u),M(KA,yo,null),e(yo,ggo),e(yo,ZA),e(ZA,hgo),e(ZA,vI),e(vI,pgo),e(ZA,_go),e(yo,ugo),e(yo,ey),e(ey,bgo),e(ey,tse),e(tse,vgo),e(ey,Fgo),e(yo,Tgo),e(yo,Ue),M(oy,Ue,null),e(Ue,Mgo),e(Ue,ase),e(ase,Ego),e(Ue,Cgo),e(Ue,wi),e(wi,wgo),e(wi,nse),e(nse,Ago),e(wi,ygo),e(wi,sse),e(sse,Lgo),e(wi,xgo),e(Ue,$go),e(Ue,he),e(he,Vh),e(Vh,lse),e(lse,kgo),e(Vh,Sgo),e(Vh,FI),e(FI,Rgo),e(Vh,Pgo),e(he,Bgo),e(he,Xh),e(Xh,ise),e(ise,Igo),e(Xh,Ngo),e(Xh,dse),e(dse,qgo),e(Xh,jgo),e(he,Dgo),e(he,zh),e(zh,cse),e(cse,Ggo),e(zh,Ogo),e(zh,TI),e(TI,Vgo),e(zh,Xgo),e(he,zgo),e(he,Wh),e(Wh,fse),e(fse,Wgo),e(Wh,Qgo),e(Wh,MI),e(MI,Hgo),e(Wh,Ugo),e(he,Jgo),e(he,Qh),e(Qh,mse),e(mse,Ygo),e(Qh,Kgo),e(Qh,EI),e(EI,Zgo),e(Qh,eho),e(he,oho),e(he,Hh),e(Hh,gse),e(gse,rho),e(Hh,tho),e(Hh,CI),e(CI,aho),e(Hh,nho),e(he,sho),e(he,Uh),e(Uh,hse),e(hse,lho),e(Uh,iho),e(Uh,wI),e(wI,dho),e(Uh,cho),e(he,fho),e(he,Jh),e(Jh,pse),e(pse,mho),e(Jh,gho),e(Jh,AI),e(AI,hho),e(Jh,pho),e(he,_ho),e(he,Yh),e(Yh,_se),e(_se,uho),e(Yh,bho),e(Yh,yI),e(yI,vho),e(Yh,Fho),e(he,Tho),e(he,Kh),e(Kh,use),e(use,Mho),e(Kh,Eho),e(Kh,LI),e(LI,Cho),e(Kh,who),e(he,Aho),e(he,Zh),e(Zh,bse),e(bse,yho),e(Zh,Lho),e(Zh,xI),e(xI,xho),e(Zh,$ho),e(he,kho),e(he,ep),e(ep,vse),e(vse,Sho),e(ep,Rho),e(ep,$I),e($I,Pho),e(ep,Bho),e(he,Iho),e(he,op),e(op,Fse),e(Fse,Nho),e(op,qho),e(op,kI),e(kI,jho),e(op,Dho),e(he,Gho),e(he,rp),e(rp,Tse),e(Tse,Oho),e(rp,Vho),e(rp,SI),e(SI,Xho),e(rp,zho),e(he,Who),e(he,tp),e(tp,Mse),e(Mse,Qho),e(tp,Hho),e(tp,RI),e(RI,Uho),e(tp,Jho),e(he,Yho),e(he,ap),e(ap,Ese),e(Ese,Kho),e(ap,Zho),e(ap,PI),e(PI,epo),e(ap,opo),e(he,rpo),e(he,np),e(np,Cse),e(Cse,tpo),e(np,apo),e(np,BI),e(BI,npo),e(np,spo),e(Ue,lpo),M(sp,Ue,null),e(Ue,ipo),M(lp,Ue,null),e(yo,dpo),e(yo,ip),M(ry,ip,null),e(ip,cpo),e(ip,wse),e(wse,fpo),b(f,Lqe,u),b(f,Ai,u),e(Ai,dp),e(dp,Ase),M(ty,Ase,null),e(Ai,mpo),e(Ai,yse),e(yse,gpo),b(f,xqe,u),b(f,Lo,u),M(ay,Lo,null),e(Lo,hpo),e(Lo,yi),e(yi,ppo),e(yi,II),e(II,_po),e(yi,upo),e(yi,NI),e(NI,bpo),e(yi,vpo),e(Lo,Fpo),e(Lo,ny),e(ny,Tpo),e(ny,Lse),e(Lse,Mpo),e(ny,Epo),e(Lo,Cpo),e(Lo,tt),M(sy,tt,null),e(tt,wpo),e(tt,xse),e(xse,Apo),e(tt,ypo),e(tt,Li),e(Li,Lpo),e(Li,$se),e($se,xpo),e(Li,$po),e(Li,qI),e(qI,kpo),e(Li,Spo),e(tt,Rpo),M(cp,tt,null),e(Lo,Ppo),e(Lo,Je),M(ly,Je,null),e(Je,Bpo),e(Je,kse),e(kse,Ipo),e(Je,Npo),e(Je,La),e(La,qpo),e(La,Sse),e(Sse,jpo),e(La,Dpo),e(La,Rse),e(Rse,Gpo),e(La,Opo),e(La,Pse),e(Pse,Vpo),e(La,Xpo),e(Je,zpo),e(Je,x),e(x,fp),e(fp,Bse),e(Bse,Wpo),e(fp,Qpo),e(fp,jI),e(jI,Hpo),e(fp,Upo),e(x,Jpo),e(x,mp),e(mp,Ise),e(Ise,Ypo),e(mp,Kpo),e(mp,DI),e(DI,Zpo),e(mp,e_o),e(x,o_o),e(x,gp),e(gp,Nse),e(Nse,r_o),e(gp,t_o),e(gp,GI),e(GI,a_o),e(gp,n_o),e(x,s_o),e(x,hp),e(hp,qse),e(qse,l_o),e(hp,i_o),e(hp,OI),e(OI,d_o),e(hp,c_o),e(x,f_o),e(x,pp),e(pp,jse),e(jse,m_o),e(pp,g_o),e(pp,VI),e(VI,h_o),e(pp,p_o),e(x,__o),e(x,_p),e(_p,Dse),e(Dse,u_o),e(_p,b_o),e(_p,XI),e(XI,v_o),e(_p,F_o),e(x,T_o),e(x,up),e(up,Gse),e(Gse,M_o),e(up,E_o),e(up,zI),e(zI,C_o),e(up,w_o),e(x,A_o),e(x,bp),e(bp,Ose),e(Ose,y_o),e(bp,L_o),e(bp,WI),e(WI,x_o),e(bp,$_o),e(x,k_o),e(x,vp),e(vp,Vse),e(Vse,S_o),e(vp,R_o),e(vp,QI),e(QI,P_o),e(vp,B_o),e(x,I_o),e(x,Fp),e(Fp,Xse),e(Xse,N_o),e(Fp,q_o),e(Fp,HI),e(HI,j_o),e(Fp,D_o),e(x,G_o),e(x,Tp),e(Tp,zse),e(zse,O_o),e(Tp,V_o),e(Tp,UI),e(UI,X_o),e(Tp,z_o),e(x,W_o),e(x,Mp),e(Mp,Wse),e(Wse,Q_o),e(Mp,H_o),e(Mp,JI),e(JI,U_o),e(Mp,J_o),e(x,Y_o),e(x,Ep),e(Ep,Qse),e(Qse,K_o),e(Ep,Z_o),e(Ep,YI),e(YI,euo),e(Ep,ouo),e(x,ruo),e(x,Cp),e(Cp,Hse),e(Hse,tuo),e(Cp,auo),e(Cp,KI),e(KI,nuo),e(Cp,suo),e(x,luo),e(x,wp),e(wp,Use),e(Use,iuo),e(wp,duo),e(wp,ZI),e(ZI,cuo),e(wp,fuo),e(x,muo),e(x,Ap),e(Ap,Jse),e(Jse,guo),e(Ap,huo),e(Ap,eN),e(eN,puo),e(Ap,_uo),e(x,uuo),e(x,yp),e(yp,Yse),e(Yse,buo),e(yp,vuo),e(yp,oN),e(oN,Fuo),e(yp,Tuo),e(x,Muo),e(x,Lp),e(Lp,Kse),e(Kse,Euo),e(Lp,Cuo),e(Lp,rN),e(rN,wuo),e(Lp,Auo),e(x,yuo),e(x,xp),e(xp,Zse),e(Zse,Luo),e(xp,xuo),e(xp,tN),e(tN,$uo),e(xp,kuo),e(x,Suo),e(x,$p),e($p,ele),e(ele,Ruo),e($p,Puo),e($p,aN),e(aN,Buo),e($p,Iuo),e(x,Nuo),e(x,kp),e(kp,ole),e(ole,quo),e(kp,juo),e(kp,nN),e(nN,Duo),e(kp,Guo),e(x,Ouo),e(x,Sp),e(Sp,rle),e(rle,Vuo),e(Sp,Xuo),e(Sp,sN),e(sN,zuo),e(Sp,Wuo),e(x,Quo),e(x,Rp),e(Rp,tle),e(tle,Huo),e(Rp,Uuo),e(Rp,lN),e(lN,Juo),e(Rp,Yuo),e(x,Kuo),e(x,Pp),e(Pp,ale),e(ale,Zuo),e(Pp,e6o),e(Pp,iN),e(iN,o6o),e(Pp,r6o),e(x,t6o),e(x,Bp),e(Bp,nle),e(nle,a6o),e(Bp,n6o),e(Bp,dN),e(dN,s6o),e(Bp,l6o),e(x,i6o),e(x,Ip),e(Ip,sle),e(sle,d6o),e(Ip,c6o),e(Ip,cN),e(cN,f6o),e(Ip,m6o),e(x,g6o),e(x,Np),e(Np,lle),e(lle,h6o),e(Np,p6o),e(Np,fN),e(fN,_6o),e(Np,u6o),e(x,b6o),e(x,qp),e(qp,ile),e(ile,v6o),e(qp,F6o),e(qp,mN),e(mN,T6o),e(qp,M6o),e(x,E6o),e(x,jp),e(jp,dle),e(dle,C6o),e(jp,w6o),e(jp,gN),e(gN,A6o),e(jp,y6o),e(x,L6o),e(x,Dp),e(Dp,cle),e(cle,x6o),e(Dp,$6o),e(Dp,hN),e(hN,k6o),e(Dp,S6o),e(x,R6o),e(x,Gp),e(Gp,fle),e(fle,P6o),e(Gp,B6o),e(Gp,pN),e(pN,I6o),e(Gp,N6o),e(x,q6o),e(x,Op),e(Op,mle),e(mle,j6o),e(Op,D6o),e(Op,_N),e(_N,G6o),e(Op,O6o),e(x,V6o),e(x,Ps),e(Ps,gle),e(gle,X6o),e(Ps,z6o),e(Ps,uN),e(uN,W6o),e(Ps,Q6o),e(Ps,bN),e(bN,H6o),e(Ps,U6o),e(x,J6o),e(x,Vp),e(Vp,hle),e(hle,Y6o),e(Vp,K6o),e(Vp,vN),e(vN,Z6o),e(Vp,e1o),e(x,o1o),e(x,Xp),e(Xp,ple),e(ple,r1o),e(Xp,t1o),e(Xp,FN),e(FN,a1o),e(Xp,n1o),e(x,s1o),e(x,zp),e(zp,_le),e(_le,l1o),e(zp,i1o),e(zp,TN),e(TN,d1o),e(zp,c1o),e(x,f1o),e(x,Wp),e(Wp,ule),e(ule,m1o),e(Wp,g1o),e(Wp,MN),e(MN,h1o),e(Wp,p1o),e(x,_1o),e(x,Qp),e(Qp,ble),e(ble,u1o),e(Qp,b1o),e(Qp,EN),e(EN,v1o),e(Qp,F1o),e(x,T1o),e(x,Hp),e(Hp,vle),e(vle,M1o),e(Hp,E1o),e(Hp,CN),e(CN,C1o),e(Hp,w1o),e(x,A1o),e(x,Up),e(Up,Fle),e(Fle,y1o),e(Up,L1o),e(Up,wN),e(wN,x1o),e(Up,$1o),e(x,k1o),e(x,Jp),e(Jp,Tle),e(Tle,S1o),e(Jp,R1o),e(Jp,AN),e(AN,P1o),e(Jp,B1o),e(x,I1o),e(x,Yp),e(Yp,Mle),e(Mle,N1o),e(Yp,q1o),e(Yp,yN),e(yN,j1o),e(Yp,D1o),e(x,G1o),e(x,Kp),e(Kp,Ele),e(Ele,O1o),e(Kp,V1o),e(Kp,LN),e(LN,X1o),e(Kp,z1o),e(x,W1o),e(x,Zp),e(Zp,Cle),e(Cle,Q1o),e(Zp,H1o),e(Zp,xN),e(xN,U1o),e(Zp,J1o),e(x,Y1o),e(x,e_),e(e_,wle),e(wle,K1o),e(e_,Z1o),e(e_,$N),e($N,ebo),e(e_,obo),e(x,rbo),e(x,o_),e(o_,Ale),e(Ale,tbo),e(o_,abo),e(o_,kN),e(kN,nbo),e(o_,sbo),e(x,lbo),e(x,r_),e(r_,yle),e(yle,ibo),e(r_,dbo),e(r_,SN),e(SN,cbo),e(r_,fbo),e(x,mbo),e(x,t_),e(t_,Lle),e(Lle,gbo),e(t_,hbo),e(t_,RN),e(RN,pbo),e(t_,_bo),e(x,ubo),e(x,a_),e(a_,xle),e(xle,bbo),e(a_,vbo),e(a_,PN),e(PN,Fbo),e(a_,Tbo),e(x,Mbo),e(x,n_),e(n_,$le),e($le,Ebo),e(n_,Cbo),e(n_,BN),e(BN,wbo),e(n_,Abo),e(x,ybo),e(x,s_),e(s_,kle),e(kle,Lbo),e(s_,xbo),e(s_,IN),e(IN,$bo),e(s_,kbo),e(x,Sbo),e(x,l_),e(l_,Sle),e(Sle,Rbo),e(l_,Pbo),e(l_,NN),e(NN,Bbo),e(l_,Ibo),e(x,Nbo),e(x,i_),e(i_,Rle),e(Rle,qbo),e(i_,jbo),e(i_,qN),e(qN,Dbo),e(i_,Gbo),e(x,Obo),e(x,d_),e(d_,Ple),e(Ple,Vbo),e(d_,Xbo),e(d_,jN),e(jN,zbo),e(d_,Wbo),e(x,Qbo),e(x,c_),e(c_,Ble),e(Ble,Hbo),e(c_,Ubo),e(c_,DN),e(DN,Jbo),e(c_,Ybo),e(x,Kbo),e(x,f_),e(f_,Ile),e(Ile,Zbo),e(f_,e2o),e(f_,GN),e(GN,o2o),e(f_,r2o),e(x,t2o),e(x,m_),e(m_,Nle),e(Nle,a2o),e(m_,n2o),e(m_,ON),e(ON,s2o),e(m_,l2o),e(x,i2o),e(x,g_),e(g_,qle),e(qle,d2o),e(g_,c2o),e(g_,VN),e(VN,f2o),e(g_,m2o),e(x,g2o),e(x,h_),e(h_,jle),e(jle,h2o),e(h_,p2o),e(h_,XN),e(XN,_2o),e(h_,u2o),e(x,b2o),e(x,p_),e(p_,Dle),e(Dle,v2o),e(p_,F2o),e(p_,zN),e(zN,T2o),e(p_,M2o),e(x,E2o),e(x,__),e(__,Gle),e(Gle,C2o),e(__,w2o),e(__,WN),e(WN,A2o),e(__,y2o),e(x,L2o),e(x,u_),e(u_,Ole),e(Ole,x2o),e(u_,$2o),e(u_,QN),e(QN,k2o),e(u_,S2o),e(x,R2o),e(x,b_),e(b_,Vle),e(Vle,P2o),e(b_,B2o),e(b_,HN),e(HN,I2o),e(b_,N2o),e(x,q2o),e(x,v_),e(v_,Xle),e(Xle,j2o),e(v_,D2o),e(v_,UN),e(UN,G2o),e(v_,O2o),e(x,V2o),e(x,F_),e(F_,zle),e(zle,X2o),e(F_,z2o),e(F_,JN),e(JN,W2o),e(F_,Q2o),e(x,H2o),e(x,T_),e(T_,Wle),e(Wle,U2o),e(T_,J2o),e(T_,YN),e(YN,Y2o),e(T_,K2o),e(x,Z2o),e(x,M_),e(M_,Qle),e(Qle,e4o),e(M_,o4o),e(M_,KN),e(KN,r4o),e(M_,t4o),e(x,a4o),e(x,E_),e(E_,Hle),e(Hle,n4o),e(E_,s4o),e(E_,ZN),e(ZN,l4o),e(E_,i4o),e(x,d4o),e(x,C_),e(C_,Ule),e(Ule,c4o),e(C_,f4o),e(C_,eq),e(eq,m4o),e(C_,g4o),e(x,h4o),e(x,w_),e(w_,Jle),e(Jle,p4o),e(w_,_4o),e(w_,oq),e(oq,u4o),e(w_,b4o),e(x,v4o),e(x,A_),e(A_,Yle),e(Yle,F4o),e(A_,T4o),e(A_,rq),e(rq,M4o),e(A_,E4o),e(x,C4o),e(x,y_),e(y_,Kle),e(Kle,w4o),e(y_,A4o),e(y_,tq),e(tq,y4o),e(y_,L4o),e(x,x4o),e(x,L_),e(L_,Zle),e(Zle,$4o),e(L_,k4o),e(L_,aq),e(aq,S4o),e(L_,R4o),e(x,P4o),e(x,x_),e(x_,eie),e(eie,B4o),e(x_,I4o),e(x_,nq),e(nq,N4o),e(x_,q4o),e(x,j4o),e(x,$_),e($_,oie),e(oie,D4o),e($_,G4o),e($_,sq),e(sq,O4o),e($_,V4o),e(x,X4o),e(x,k_),e(k_,rie),e(rie,z4o),e(k_,W4o),e(k_,lq),e(lq,Q4o),e(k_,H4o),e(x,U4o),e(x,S_),e(S_,tie),e(tie,J4o),e(S_,Y4o),e(S_,iq),e(iq,K4o),e(S_,Z4o),e(x,evo),e(x,R_),e(R_,aie),e(aie,ovo),e(R_,rvo),e(R_,dq),e(dq,tvo),e(R_,avo),e(x,nvo),e(x,P_),e(P_,nie),e(nie,svo),e(P_,lvo),e(P_,cq),e(cq,ivo),e(P_,dvo),e(x,cvo),e(x,B_),e(B_,sie),e(sie,fvo),e(B_,mvo),e(B_,fq),e(fq,gvo),e(B_,hvo),e(x,pvo),e(x,I_),e(I_,lie),e(lie,_vo),e(I_,uvo),e(I_,mq),e(mq,bvo),e(I_,vvo),e(x,Fvo),e(x,N_),e(N_,iie),e(iie,Tvo),e(N_,Mvo),e(N_,gq),e(gq,Evo),e(N_,Cvo),e(x,wvo),e(x,q_),e(q_,die),e(die,Avo),e(q_,yvo),e(q_,hq),e(hq,Lvo),e(q_,xvo),e(x,$vo),e(x,j_),e(j_,cie),e(cie,kvo),e(j_,Svo),e(j_,pq),e(pq,Rvo),e(j_,Pvo),e(x,Bvo),e(x,D_),e(D_,fie),e(fie,Ivo),e(D_,Nvo),e(D_,_q),e(_q,qvo),e(D_,jvo),e(x,Dvo),e(x,G_),e(G_,mie),e(mie,Gvo),e(G_,Ovo),e(G_,uq),e(uq,Vvo),e(G_,Xvo),e(x,zvo),e(x,O_),e(O_,gie),e(gie,Wvo),e(O_,Qvo),e(O_,bq),e(bq,Hvo),e(O_,Uvo),e(x,Jvo),e(x,V_),e(V_,hie),e(hie,Yvo),e(V_,Kvo),e(V_,vq),e(vq,Zvo),e(V_,eFo),e(x,oFo),e(x,X_),e(X_,pie),e(pie,rFo),e(X_,tFo),e(X_,Fq),e(Fq,aFo),e(X_,nFo),e(x,sFo),e(x,z_),e(z_,_ie),e(_ie,lFo),e(z_,iFo),e(z_,Tq),e(Tq,dFo),e(z_,cFo),e(x,fFo),e(x,W_),e(W_,uie),e(uie,mFo),e(W_,gFo),e(W_,Mq),e(Mq,hFo),e(W_,pFo),e(x,_Fo),e(x,Q_),e(Q_,bie),e(bie,uFo),e(Q_,bFo),e(Q_,Eq),e(Eq,vFo),e(Q_,FFo),e(x,TFo),e(x,H_),e(H_,vie),e(vie,MFo),e(H_,EFo),e(H_,Cq),e(Cq,CFo),e(H_,wFo),e(x,AFo),e(x,U_),e(U_,Fie),e(Fie,yFo),e(U_,LFo),e(U_,wq),e(wq,xFo),e(U_,$Fo),e(x,kFo),e(x,J_),e(J_,Tie),e(Tie,SFo),e(J_,RFo),e(J_,Aq),e(Aq,PFo),e(J_,BFo),e(x,IFo),e(x,Y_),e(Y_,Mie),e(Mie,NFo),e(Y_,qFo),e(Y_,yq),e(yq,jFo),e(Y_,DFo),e(x,GFo),e(x,K_),e(K_,Eie),e(Eie,OFo),e(K_,VFo),e(K_,Lq),e(Lq,XFo),e(K_,zFo),e(x,WFo),e(x,Z_),e(Z_,Cie),e(Cie,QFo),e(Z_,HFo),e(Z_,xq),e(xq,UFo),e(Z_,JFo),e(x,YFo),e(x,eu),e(eu,wie),e(wie,KFo),e(eu,ZFo),e(eu,$q),e($q,eTo),e(eu,oTo),e(x,rTo),e(x,ou),e(ou,Aie),e(Aie,tTo),e(ou,aTo),e(ou,kq),e(kq,nTo),e(ou,sTo),e(x,lTo),e(x,ru),e(ru,yie),e(yie,iTo),e(ru,dTo),e(ru,Sq),e(Sq,cTo),e(ru,fTo),e(x,mTo),e(x,tu),e(tu,Lie),e(Lie,gTo),e(tu,hTo),e(tu,Rq),e(Rq,pTo),e(tu,_To),e(x,uTo),e(x,au),e(au,xie),e(xie,bTo),e(au,vTo),e(au,Pq),e(Pq,FTo),e(au,TTo),e(Je,MTo),e(Je,nu),e(nu,ETo),e(nu,$ie),e($ie,CTo),e(nu,wTo),e(nu,kie),e(kie,ATo),e(Je,yTo),M(su,Je,null),b(f,$qe,u),b(f,xi,u),e(xi,lu),e(lu,Sie),M(iy,Sie,null),e(xi,LTo),e(xi,Rie),e(Rie,xTo),b(f,kqe,u),b(f,xo,u),M(dy,xo,null),e(xo,$To),e(xo,$i),e($i,kTo),e($i,Bq),e(Bq,STo),e($i,RTo),e($i,Iq),e(Iq,PTo),e($i,BTo),e(xo,ITo),e(xo,cy),e(cy,NTo),e(cy,Pie),e(Pie,qTo),e(cy,jTo),e(xo,DTo),e(xo,at),M(fy,at,null),e(at,GTo),e(at,Bie),e(Bie,OTo),e(at,VTo),e(at,ki),e(ki,XTo),e(ki,Iie),e(Iie,zTo),e(ki,WTo),e(ki,Nq),e(Nq,QTo),e(ki,HTo),e(at,UTo),M(iu,at,null),e(xo,JTo),e(xo,Ye),M(my,Ye,null),e(Ye,YTo),e(Ye,Nie),e(Nie,KTo),e(Ye,ZTo),e(Ye,xa),e(xa,e7o),e(xa,qie),e(qie,o7o),e(xa,r7o),e(xa,jie),e(jie,t7o),e(xa,a7o),e(xa,Die),e(Die,n7o),e(xa,s7o),e(Ye,l7o),e(Ye,G),e(G,du),e(du,Gie),e(Gie,i7o),e(du,d7o),e(du,qq),e(qq,c7o),e(du,f7o),e(G,m7o),e(G,cu),e(cu,Oie),e(Oie,g7o),e(cu,h7o),e(cu,jq),e(jq,p7o),e(cu,_7o),e(G,u7o),e(G,fu),e(fu,Vie),e(Vie,b7o),e(fu,v7o),e(fu,Dq),e(Dq,F7o),e(fu,T7o),e(G,M7o),e(G,mu),e(mu,Xie),e(Xie,E7o),e(mu,C7o),e(mu,Gq),e(Gq,w7o),e(mu,A7o),e(G,y7o),e(G,gu),e(gu,zie),e(zie,L7o),e(gu,x7o),e(gu,Oq),e(Oq,$7o),e(gu,k7o),e(G,S7o),e(G,hu),e(hu,Wie),e(Wie,R7o),e(hu,P7o),e(hu,Vq),e(Vq,B7o),e(hu,I7o),e(G,N7o),e(G,pu),e(pu,Qie),e(Qie,q7o),e(pu,j7o),e(pu,Xq),e(Xq,D7o),e(pu,G7o),e(G,O7o),e(G,_u),e(_u,Hie),e(Hie,V7o),e(_u,X7o),e(_u,zq),e(zq,z7o),e(_u,W7o),e(G,Q7o),e(G,uu),e(uu,Uie),e(Uie,H7o),e(uu,U7o),e(uu,Wq),e(Wq,J7o),e(uu,Y7o),e(G,K7o),e(G,bu),e(bu,Jie),e(Jie,Z7o),e(bu,eMo),e(bu,Qq),e(Qq,oMo),e(bu,rMo),e(G,tMo),e(G,vu),e(vu,Yie),e(Yie,aMo),e(vu,nMo),e(vu,Hq),e(Hq,sMo),e(vu,lMo),e(G,iMo),e(G,Fu),e(Fu,Kie),e(Kie,dMo),e(Fu,cMo),e(Fu,Uq),e(Uq,fMo),e(Fu,mMo),e(G,gMo),e(G,Tu),e(Tu,Zie),e(Zie,hMo),e(Tu,pMo),e(Tu,Jq),e(Jq,_Mo),e(Tu,uMo),e(G,bMo),e(G,Mu),e(Mu,ede),e(ede,vMo),e(Mu,FMo),e(Mu,Yq),e(Yq,TMo),e(Mu,MMo),e(G,EMo),e(G,Eu),e(Eu,ode),e(ode,CMo),e(Eu,wMo),e(Eu,Kq),e(Kq,AMo),e(Eu,yMo),e(G,LMo),e(G,Cu),e(Cu,rde),e(rde,xMo),e(Cu,$Mo),e(Cu,Zq),e(Zq,kMo),e(Cu,SMo),e(G,RMo),e(G,wu),e(wu,tde),e(tde,PMo),e(wu,BMo),e(wu,ej),e(ej,IMo),e(wu,NMo),e(G,qMo),e(G,Au),e(Au,ade),e(ade,jMo),e(Au,DMo),e(Au,oj),e(oj,GMo),e(Au,OMo),e(G,VMo),e(G,yu),e(yu,nde),e(nde,XMo),e(yu,zMo),e(yu,rj),e(rj,WMo),e(yu,QMo),e(G,HMo),e(G,Lu),e(Lu,sde),e(sde,UMo),e(Lu,JMo),e(Lu,tj),e(tj,YMo),e(Lu,KMo),e(G,ZMo),e(G,xu),e(xu,lde),e(lde,eEo),e(xu,oEo),e(xu,aj),e(aj,rEo),e(xu,tEo),e(G,aEo),e(G,$u),e($u,ide),e(ide,nEo),e($u,sEo),e($u,nj),e(nj,lEo),e($u,iEo),e(G,dEo),e(G,ku),e(ku,dde),e(dde,cEo),e(ku,fEo),e(ku,sj),e(sj,mEo),e(ku,gEo),e(G,hEo),e(G,Su),e(Su,cde),e(cde,pEo),e(Su,_Eo),e(Su,lj),e(lj,uEo),e(Su,bEo),e(G,vEo),e(G,Ru),e(Ru,fde),e(fde,FEo),e(Ru,TEo),e(Ru,ij),e(ij,MEo),e(Ru,EEo),e(G,CEo),e(G,Pu),e(Pu,mde),e(mde,wEo),e(Pu,AEo),e(Pu,dj),e(dj,yEo),e(Pu,LEo),e(G,xEo),e(G,Bu),e(Bu,gde),e(gde,$Eo),e(Bu,kEo),e(Bu,cj),e(cj,SEo),e(Bu,REo),e(G,PEo),e(G,Iu),e(Iu,hde),e(hde,BEo),e(Iu,IEo),e(Iu,fj),e(fj,NEo),e(Iu,qEo),e(G,jEo),e(G,Nu),e(Nu,pde),e(pde,DEo),e(Nu,GEo),e(Nu,mj),e(mj,OEo),e(Nu,VEo),e(G,XEo),e(G,qu),e(qu,_de),e(_de,zEo),e(qu,WEo),e(qu,gj),e(gj,QEo),e(qu,HEo),e(G,UEo),e(G,ju),e(ju,ude),e(ude,JEo),e(ju,YEo),e(ju,hj),e(hj,KEo),e(ju,ZEo),e(G,eCo),e(G,Du),e(Du,bde),e(bde,oCo),e(Du,rCo),e(Du,pj),e(pj,tCo),e(Du,aCo),e(G,nCo),e(G,Gu),e(Gu,vde),e(vde,sCo),e(Gu,lCo),e(Gu,_j),e(_j,iCo),e(Gu,dCo),e(G,cCo),e(G,Ou),e(Ou,Fde),e(Fde,fCo),e(Ou,mCo),e(Ou,uj),e(uj,gCo),e(Ou,hCo),e(G,pCo),e(G,Vu),e(Vu,Tde),e(Tde,_Co),e(Vu,uCo),e(Vu,bj),e(bj,bCo),e(Vu,vCo),e(G,FCo),e(G,Xu),e(Xu,Mde),e(Mde,TCo),e(Xu,MCo),e(Xu,vj),e(vj,ECo),e(Xu,CCo),e(G,wCo),e(G,zu),e(zu,Ede),e(Ede,ACo),e(zu,yCo),e(zu,Fj),e(Fj,LCo),e(zu,xCo),e(G,$Co),e(G,Wu),e(Wu,Cde),e(Cde,kCo),e(Wu,SCo),e(Wu,Tj),e(Tj,RCo),e(Wu,PCo),e(G,BCo),e(G,Qu),e(Qu,wde),e(wde,ICo),e(Qu,NCo),e(Qu,Mj),e(Mj,qCo),e(Qu,jCo),e(G,DCo),e(G,Hu),e(Hu,Ade),e(Ade,GCo),e(Hu,OCo),e(Hu,Ej),e(Ej,VCo),e(Hu,XCo),e(G,zCo),e(G,Uu),e(Uu,yde),e(yde,WCo),e(Uu,QCo),e(Uu,Cj),e(Cj,HCo),e(Uu,UCo),e(G,JCo),e(G,Ju),e(Ju,Lde),e(Lde,YCo),e(Ju,KCo),e(Ju,wj),e(wj,ZCo),e(Ju,e5o),e(Ye,o5o),e(Ye,Yu),e(Yu,r5o),e(Yu,xde),e(xde,t5o),e(Yu,a5o),e(Yu,$de),e($de,n5o),e(Ye,s5o),M(Ku,Ye,null),b(f,Sqe,u),b(f,Si,u),e(Si,Zu),e(Zu,kde),M(gy,kde,null),e(Si,l5o),e(Si,Sde),e(Sde,i5o),b(f,Rqe,u),b(f,$o,u),M(hy,$o,null),e($o,d5o),e($o,Ri),e(Ri,c5o),e(Ri,Aj),e(Aj,f5o),e(Ri,m5o),e(Ri,yj),e(yj,g5o),e(Ri,h5o),e($o,p5o),e($o,py),e(py,_5o),e(py,Rde),e(Rde,u5o),e(py,b5o),e($o,v5o),e($o,nt),M(_y,nt,null),e(nt,F5o),e(nt,Pde),e(Pde,T5o),e(nt,M5o),e(nt,Pi),e(Pi,E5o),e(Pi,Bde),e(Bde,C5o),e(Pi,w5o),e(Pi,Lj),e(Lj,A5o),e(Pi,y5o),e(nt,L5o),M(e6,nt,null),e($o,x5o),e($o,Ke),M(uy,Ke,null),e(Ke,$5o),e(Ke,Ide),e(Ide,k5o),e(Ke,S5o),e(Ke,$a),e($a,R5o),e($a,Nde),e(Nde,P5o),e($a,B5o),e($a,qde),e(qde,I5o),e($a,N5o),e($a,jde),e(jde,q5o),e($a,j5o),e(Ke,D5o),e(Ke,z),e(z,o6),e(o6,Dde),e(Dde,G5o),e(o6,O5o),e(o6,xj),e(xj,V5o),e(o6,X5o),e(z,z5o),e(z,r6),e(r6,Gde),e(Gde,W5o),e(r6,Q5o),e(r6,$j),e($j,H5o),e(r6,U5o),e(z,J5o),e(z,t6),e(t6,Ode),e(Ode,Y5o),e(t6,K5o),e(t6,kj),e(kj,Z5o),e(t6,e3o),e(z,o3o),e(z,a6),e(a6,Vde),e(Vde,r3o),e(a6,t3o),e(a6,Sj),e(Sj,a3o),e(a6,n3o),e(z,s3o),e(z,n6),e(n6,Xde),e(Xde,l3o),e(n6,i3o),e(n6,Rj),e(Rj,d3o),e(n6,c3o),e(z,f3o),e(z,s6),e(s6,zde),e(zde,m3o),e(s6,g3o),e(s6,Pj),e(Pj,h3o),e(s6,p3o),e(z,_3o),e(z,l6),e(l6,Wde),e(Wde,u3o),e(l6,b3o),e(l6,Bj),e(Bj,v3o),e(l6,F3o),e(z,T3o),e(z,i6),e(i6,Qde),e(Qde,M3o),e(i6,E3o),e(i6,Ij),e(Ij,C3o),e(i6,w3o),e(z,A3o),e(z,d6),e(d6,Hde),e(Hde,y3o),e(d6,L3o),e(d6,Nj),e(Nj,x3o),e(d6,$3o),e(z,k3o),e(z,c6),e(c6,Ude),e(Ude,S3o),e(c6,R3o),e(c6,qj),e(qj,P3o),e(c6,B3o),e(z,I3o),e(z,f6),e(f6,Jde),e(Jde,N3o),e(f6,q3o),e(f6,jj),e(jj,j3o),e(f6,D3o),e(z,G3o),e(z,m6),e(m6,Yde),e(Yde,O3o),e(m6,V3o),e(m6,Dj),e(Dj,X3o),e(m6,z3o),e(z,W3o),e(z,g6),e(g6,Kde),e(Kde,Q3o),e(g6,H3o),e(g6,Gj),e(Gj,U3o),e(g6,J3o),e(z,Y3o),e(z,h6),e(h6,Zde),e(Zde,K3o),e(h6,Z3o),e(h6,Oj),e(Oj,ewo),e(h6,owo),e(z,rwo),e(z,p6),e(p6,ece),e(ece,two),e(p6,awo),e(p6,Vj),e(Vj,nwo),e(p6,swo),e(z,lwo),e(z,_6),e(_6,oce),e(oce,iwo),e(_6,dwo),e(_6,Xj),e(Xj,cwo),e(_6,fwo),e(z,mwo),e(z,u6),e(u6,rce),e(rce,gwo),e(u6,hwo),e(u6,zj),e(zj,pwo),e(u6,_wo),e(z,uwo),e(z,b6),e(b6,tce),e(tce,bwo),e(b6,vwo),e(b6,Wj),e(Wj,Fwo),e(b6,Two),e(z,Mwo),e(z,v6),e(v6,ace),e(ace,Ewo),e(v6,Cwo),e(v6,Qj),e(Qj,wwo),e(v6,Awo),e(z,ywo),e(z,F6),e(F6,nce),e(nce,Lwo),e(F6,xwo),e(F6,Hj),e(Hj,$wo),e(F6,kwo),e(z,Swo),e(z,T6),e(T6,sce),e(sce,Rwo),e(T6,Pwo),e(T6,Uj),e(Uj,Bwo),e(T6,Iwo),e(z,Nwo),e(z,M6),e(M6,lce),e(lce,qwo),e(M6,jwo),e(M6,Jj),e(Jj,Dwo),e(M6,Gwo),e(z,Owo),e(z,E6),e(E6,ice),e(ice,Vwo),e(E6,Xwo),e(E6,Yj),e(Yj,zwo),e(E6,Wwo),e(z,Qwo),e(z,C6),e(C6,dce),e(dce,Hwo),e(C6,Uwo),e(C6,Kj),e(Kj,Jwo),e(C6,Ywo),e(z,Kwo),e(z,w6),e(w6,cce),e(cce,Zwo),e(w6,e0o),e(w6,Zj),e(Zj,o0o),e(w6,r0o),e(z,t0o),e(z,A6),e(A6,fce),e(fce,a0o),e(A6,n0o),e(A6,eD),e(eD,s0o),e(A6,l0o),e(z,i0o),e(z,y6),e(y6,mce),e(mce,d0o),e(y6,c0o),e(y6,oD),e(oD,f0o),e(y6,m0o),e(z,g0o),e(z,L6),e(L6,gce),e(gce,h0o),e(L6,p0o),e(L6,rD),e(rD,_0o),e(L6,u0o),e(z,b0o),e(z,x6),e(x6,hce),e(hce,v0o),e(x6,F0o),e(x6,tD),e(tD,T0o),e(x6,M0o),e(z,E0o),e(z,$6),e($6,pce),e(pce,C0o),e($6,w0o),e($6,aD),e(aD,A0o),e($6,y0o),e(z,L0o),e(z,k6),e(k6,_ce),e(_ce,x0o),e(k6,$0o),e(k6,nD),e(nD,k0o),e(k6,S0o),e(z,R0o),e(z,S6),e(S6,uce),e(uce,P0o),e(S6,B0o),e(S6,sD),e(sD,I0o),e(S6,N0o),e(z,q0o),e(z,R6),e(R6,bce),e(bce,j0o),e(R6,D0o),e(R6,lD),e(lD,G0o),e(R6,O0o),e(z,V0o),e(z,P6),e(P6,vce),e(vce,X0o),e(P6,z0o),e(P6,iD),e(iD,W0o),e(P6,Q0o),e(z,H0o),e(z,B6),e(B6,Fce),e(Fce,U0o),e(B6,J0o),e(B6,dD),e(dD,Y0o),e(B6,K0o),e(z,Z0o),e(z,I6),e(I6,Tce),e(Tce,eAo),e(I6,oAo),e(I6,cD),e(cD,rAo),e(I6,tAo),e(z,aAo),e(z,N6),e(N6,Mce),e(Mce,nAo),e(N6,sAo),e(N6,fD),e(fD,lAo),e(N6,iAo),e(Ke,dAo),e(Ke,q6),e(q6,cAo),e(q6,Ece),e(Ece,fAo),e(q6,mAo),e(q6,Cce),e(Cce,gAo),e(Ke,hAo),M(j6,Ke,null),b(f,Pqe,u),b(f,Bi,u),e(Bi,D6),e(D6,wce),M(by,wce,null),e(Bi,pAo),e(Bi,Ace),e(Ace,_Ao),b(f,Bqe,u),b(f,ko,u),M(vy,ko,null),e(ko,uAo),e(ko,Ii),e(Ii,bAo),e(Ii,mD),e(mD,vAo),e(Ii,FAo),e(Ii,gD),e(gD,TAo),e(Ii,MAo),e(ko,EAo),e(ko,Fy),e(Fy,CAo),e(Fy,yce),e(yce,wAo),e(Fy,AAo),e(ko,yAo),e(ko,st),M(Ty,st,null),e(st,LAo),e(st,Lce),e(Lce,xAo),e(st,$Ao),e(st,Ni),e(Ni,kAo),e(Ni,xce),e(xce,SAo),e(Ni,RAo),e(Ni,hD),e(hD,PAo),e(Ni,BAo),e(st,IAo),M(G6,st,null),e(ko,NAo),e(ko,Ze),M(My,Ze,null),e(Ze,qAo),e(Ze,$ce),e($ce,jAo),e(Ze,DAo),e(Ze,ka),e(ka,GAo),e(ka,kce),e(kce,OAo),e(ka,VAo),e(ka,Sce),e(Sce,XAo),e(ka,zAo),e(ka,Rce),e(Rce,WAo),e(ka,QAo),e(Ze,HAo),e(Ze,Q),e(Q,O6),e(O6,Pce),e(Pce,UAo),e(O6,JAo),e(O6,pD),e(pD,YAo),e(O6,KAo),e(Q,ZAo),e(Q,V6),e(V6,Bce),e(Bce,eyo),e(V6,oyo),e(V6,_D),e(_D,ryo),e(V6,tyo),e(Q,ayo),e(Q,X6),e(X6,Ice),e(Ice,nyo),e(X6,syo),e(X6,uD),e(uD,lyo),e(X6,iyo),e(Q,dyo),e(Q,z6),e(z6,Nce),e(Nce,cyo),e(z6,fyo),e(z6,bD),e(bD,myo),e(z6,gyo),e(Q,hyo),e(Q,W6),e(W6,qce),e(qce,pyo),e(W6,_yo),e(W6,vD),e(vD,uyo),e(W6,byo),e(Q,vyo),e(Q,Q6),e(Q6,jce),e(jce,Fyo),e(Q6,Tyo),e(Q6,FD),e(FD,Myo),e(Q6,Eyo),e(Q,Cyo),e(Q,H6),e(H6,Dce),e(Dce,wyo),e(H6,Ayo),e(H6,TD),e(TD,yyo),e(H6,Lyo),e(Q,xyo),e(Q,U6),e(U6,Gce),e(Gce,$yo),e(U6,kyo),e(U6,MD),e(MD,Syo),e(U6,Ryo),e(Q,Pyo),e(Q,J6),e(J6,Oce),e(Oce,Byo),e(J6,Iyo),e(J6,ED),e(ED,Nyo),e(J6,qyo),e(Q,jyo),e(Q,Y6),e(Y6,Vce),e(Vce,Dyo),e(Y6,Gyo),e(Y6,CD),e(CD,Oyo),e(Y6,Vyo),e(Q,Xyo),e(Q,K6),e(K6,Xce),e(Xce,zyo),e(K6,Wyo),e(K6,wD),e(wD,Qyo),e(K6,Hyo),e(Q,Uyo),e(Q,Z6),e(Z6,zce),e(zce,Jyo),e(Z6,Yyo),e(Z6,AD),e(AD,Kyo),e(Z6,Zyo),e(Q,eLo),e(Q,e1),e(e1,Wce),e(Wce,oLo),e(e1,rLo),e(e1,yD),e(yD,tLo),e(e1,aLo),e(Q,nLo),e(Q,o1),e(o1,Qce),e(Qce,sLo),e(o1,lLo),e(o1,LD),e(LD,iLo),e(o1,dLo),e(Q,cLo),e(Q,r1),e(r1,Hce),e(Hce,fLo),e(r1,mLo),e(r1,xD),e(xD,gLo),e(r1,hLo),e(Q,pLo),e(Q,t1),e(t1,Uce),e(Uce,_Lo),e(t1,uLo),e(t1,$D),e($D,bLo),e(t1,vLo),e(Q,FLo),e(Q,a1),e(a1,Jce),e(Jce,TLo),e(a1,MLo),e(a1,kD),e(kD,ELo),e(a1,CLo),e(Q,wLo),e(Q,n1),e(n1,Yce),e(Yce,ALo),e(n1,yLo),e(n1,SD),e(SD,LLo),e(n1,xLo),e(Q,$Lo),e(Q,s1),e(s1,Kce),e(Kce,kLo),e(s1,SLo),e(s1,RD),e(RD,RLo),e(s1,PLo),e(Q,BLo),e(Q,l1),e(l1,Zce),e(Zce,ILo),e(l1,NLo),e(l1,PD),e(PD,qLo),e(l1,jLo),e(Q,DLo),e(Q,i1),e(i1,efe),e(efe,GLo),e(i1,OLo),e(i1,BD),e(BD,VLo),e(i1,XLo),e(Q,zLo),e(Q,d1),e(d1,ofe),e(ofe,WLo),e(d1,QLo),e(d1,ID),e(ID,HLo),e(d1,ULo),e(Q,JLo),e(Q,c1),e(c1,rfe),e(rfe,YLo),e(c1,KLo),e(c1,ND),e(ND,ZLo),e(c1,e8o),e(Q,o8o),e(Q,f1),e(f1,tfe),e(tfe,r8o),e(f1,t8o),e(f1,qD),e(qD,a8o),e(f1,n8o),e(Q,s8o),e(Q,m1),e(m1,afe),e(afe,l8o),e(m1,i8o),e(m1,jD),e(jD,d8o),e(m1,c8o),e(Q,f8o),e(Q,g1),e(g1,nfe),e(nfe,m8o),e(g1,g8o),e(g1,DD),e(DD,h8o),e(g1,p8o),e(Q,_8o),e(Q,h1),e(h1,sfe),e(sfe,u8o),e(h1,b8o),e(h1,GD),e(GD,v8o),e(h1,F8o),e(Q,T8o),e(Q,p1),e(p1,lfe),e(lfe,M8o),e(p1,E8o),e(p1,OD),e(OD,C8o),e(p1,w8o),e(Q,A8o),e(Q,_1),e(_1,ife),e(ife,y8o),e(_1,L8o),e(_1,VD),e(VD,x8o),e(_1,$8o),e(Q,k8o),e(Q,u1),e(u1,dfe),e(dfe,S8o),e(u1,R8o),e(u1,XD),e(XD,P8o),e(u1,B8o),e(Q,I8o),e(Q,b1),e(b1,cfe),e(cfe,N8o),e(b1,q8o),e(b1,ffe),e(ffe,j8o),e(b1,D8o),e(Q,G8o),e(Q,v1),e(v1,mfe),e(mfe,O8o),e(v1,V8o),e(v1,zD),e(zD,X8o),e(v1,z8o),e(Q,W8o),e(Q,F1),e(F1,gfe),e(gfe,Q8o),e(F1,H8o),e(F1,WD),e(WD,U8o),e(F1,J8o),e(Q,Y8o),e(Q,T1),e(T1,hfe),e(hfe,K8o),e(T1,Z8o),e(T1,QD),e(QD,e9o),e(T1,o9o),e(Q,r9o),e(Q,M1),e(M1,pfe),e(pfe,t9o),e(M1,a9o),e(M1,HD),e(HD,n9o),e(M1,s9o),e(Ze,l9o),e(Ze,E1),e(E1,i9o),e(E1,_fe),e(_fe,d9o),e(E1,c9o),e(E1,ufe),e(ufe,f9o),e(Ze,m9o),M(C1,Ze,null),b(f,Iqe,u),b(f,qi,u),e(qi,w1),e(w1,bfe),M(Ey,bfe,null),e(qi,g9o),e(qi,vfe),e(vfe,h9o),b(f,Nqe,u),b(f,So,u),M(Cy,So,null),e(So,p9o),e(So,ji),e(ji,_9o),e(ji,UD),e(UD,u9o),e(ji,b9o),e(ji,JD),e(JD,v9o),e(ji,F9o),e(So,T9o),e(So,wy),e(wy,M9o),e(wy,Ffe),e(Ffe,E9o),e(wy,C9o),e(So,w9o),e(So,lt),M(Ay,lt,null),e(lt,A9o),e(lt,Tfe),e(Tfe,y9o),e(lt,L9o),e(lt,Di),e(Di,x9o),e(Di,Mfe),e(Mfe,$9o),e(Di,k9o),e(Di,YD),e(YD,S9o),e(Di,R9o),e(lt,P9o),M(A1,lt,null),e(So,B9o),e(So,eo),M(yy,eo,null),e(eo,I9o),e(eo,Efe),e(Efe,N9o),e(eo,q9o),e(eo,Sa),e(Sa,j9o),e(Sa,Cfe),e(Cfe,D9o),e(Sa,G9o),e(Sa,wfe),e(wfe,O9o),e(Sa,V9o),e(Sa,Afe),e(Afe,X9o),e(Sa,z9o),e(eo,W9o),e(eo,_e),e(_e,y1),e(y1,yfe),e(yfe,Q9o),e(y1,H9o),e(y1,KD),e(KD,U9o),e(y1,J9o),e(_e,Y9o),e(_e,L1),e(L1,Lfe),e(Lfe,K9o),e(L1,Z9o),e(L1,ZD),e(ZD,exo),e(L1,oxo),e(_e,rxo),e(_e,x1),e(x1,xfe),e(xfe,txo),e(x1,axo),e(x1,eG),e(eG,nxo),e(x1,sxo),e(_e,lxo),e(_e,$1),e($1,$fe),e($fe,ixo),e($1,dxo),e($1,oG),e(oG,cxo),e($1,fxo),e(_e,mxo),e(_e,k1),e(k1,kfe),e(kfe,gxo),e(k1,hxo),e(k1,rG),e(rG,pxo),e(k1,_xo),e(_e,uxo),e(_e,S1),e(S1,Sfe),e(Sfe,bxo),e(S1,vxo),e(S1,tG),e(tG,Fxo),e(S1,Txo),e(_e,Mxo),e(_e,R1),e(R1,Rfe),e(Rfe,Exo),e(R1,Cxo),e(R1,aG),e(aG,wxo),e(R1,Axo),e(_e,yxo),e(_e,P1),e(P1,Pfe),e(Pfe,Lxo),e(P1,xxo),e(P1,nG),e(nG,$xo),e(P1,kxo),e(_e,Sxo),e(_e,B1),e(B1,Bfe),e(Bfe,Rxo),e(B1,Pxo),e(B1,sG),e(sG,Bxo),e(B1,Ixo),e(_e,Nxo),e(_e,I1),e(I1,Ife),e(Ife,qxo),e(I1,jxo),e(I1,lG),e(lG,Dxo),e(I1,Gxo),e(_e,Oxo),e(_e,N1),e(N1,Nfe),e(Nfe,Vxo),e(N1,Xxo),e(N1,iG),e(iG,zxo),e(N1,Wxo),e(_e,Qxo),e(_e,q1),e(q1,qfe),e(qfe,Hxo),e(q1,Uxo),e(q1,dG),e(dG,Jxo),e(q1,Yxo),e(_e,Kxo),e(_e,j1),e(j1,jfe),e(jfe,Zxo),e(j1,e$o),e(j1,cG),e(cG,o$o),e(j1,r$o),e(_e,t$o),e(_e,D1),e(D1,Dfe),e(Dfe,a$o),e(D1,n$o),e(D1,fG),e(fG,s$o),e(D1,l$o),e(_e,i$o),e(_e,G1),e(G1,Gfe),e(Gfe,d$o),e(G1,c$o),e(G1,mG),e(mG,f$o),e(G1,m$o),e(_e,g$o),e(_e,O1),e(O1,Ofe),e(Ofe,h$o),e(O1,p$o),e(O1,gG),e(gG,_$o),e(O1,u$o),e(eo,b$o),e(eo,V1),e(V1,v$o),e(V1,Vfe),e(Vfe,F$o),e(V1,T$o),e(V1,Xfe),e(Xfe,M$o),e(eo,E$o),M(X1,eo,null),b(f,qqe,u),b(f,Gi,u),e(Gi,z1),e(z1,zfe),M(Ly,zfe,null),e(Gi,C$o),e(Gi,Wfe),e(Wfe,w$o),b(f,jqe,u),b(f,Ro,u),M(xy,Ro,null),e(Ro,A$o),e(Ro,Oi),e(Oi,y$o),e(Oi,hG),e(hG,L$o),e(Oi,x$o),e(Oi,pG),e(pG,$$o),e(Oi,k$o),e(Ro,S$o),e(Ro,$y),e($y,R$o),e($y,Qfe),e(Qfe,P$o),e($y,B$o),e(Ro,I$o),e(Ro,it),M(ky,it,null),e(it,N$o),e(it,Hfe),e(Hfe,q$o),e(it,j$o),e(it,Vi),e(Vi,D$o),e(Vi,Ufe),e(Ufe,G$o),e(Vi,O$o),e(Vi,_G),e(_G,V$o),e(Vi,X$o),e(it,z$o),M(W1,it,null),e(Ro,W$o),e(Ro,oo),M(Sy,oo,null),e(oo,Q$o),e(oo,Jfe),e(Jfe,H$o),e(oo,U$o),e(oo,Ra),e(Ra,J$o),e(Ra,Yfe),e(Yfe,Y$o),e(Ra,K$o),e(Ra,Kfe),e(Kfe,Z$o),e(Ra,eko),e(Ra,Zfe),e(Zfe,oko),e(Ra,rko),e(oo,tko),e(oo,N),e(N,Q1),e(Q1,eme),e(eme,ako),e(Q1,nko),e(Q1,uG),e(uG,sko),e(Q1,lko),e(N,iko),e(N,H1),e(H1,ome),e(ome,dko),e(H1,cko),e(H1,bG),e(bG,fko),e(H1,mko),e(N,gko),e(N,U1),e(U1,rme),e(rme,hko),e(U1,pko),e(U1,vG),e(vG,_ko),e(U1,uko),e(N,bko),e(N,J1),e(J1,tme),e(tme,vko),e(J1,Fko),e(J1,FG),e(FG,Tko),e(J1,Mko),e(N,Eko),e(N,Y1),e(Y1,ame),e(ame,Cko),e(Y1,wko),e(Y1,TG),e(TG,Ako),e(Y1,yko),e(N,Lko),e(N,K1),e(K1,nme),e(nme,xko),e(K1,$ko),e(K1,MG),e(MG,kko),e(K1,Sko),e(N,Rko),e(N,Z1),e(Z1,sme),e(sme,Pko),e(Z1,Bko),e(Z1,EG),e(EG,Iko),e(Z1,Nko),e(N,qko),e(N,eb),e(eb,lme),e(lme,jko),e(eb,Dko),e(eb,CG),e(CG,Gko),e(eb,Oko),e(N,Vko),e(N,ob),e(ob,ime),e(ime,Xko),e(ob,zko),e(ob,wG),e(wG,Wko),e(ob,Qko),e(N,Hko),e(N,rb),e(rb,dme),e(dme,Uko),e(rb,Jko),e(rb,AG),e(AG,Yko),e(rb,Kko),e(N,Zko),e(N,tb),e(tb,cme),e(cme,eSo),e(tb,oSo),e(tb,yG),e(yG,rSo),e(tb,tSo),e(N,aSo),e(N,ab),e(ab,fme),e(fme,nSo),e(ab,sSo),e(ab,LG),e(LG,lSo),e(ab,iSo),e(N,dSo),e(N,nb),e(nb,mme),e(mme,cSo),e(nb,fSo),e(nb,xG),e(xG,mSo),e(nb,gSo),e(N,hSo),e(N,sb),e(sb,gme),e(gme,pSo),e(sb,_So),e(sb,$G),e($G,uSo),e(sb,bSo),e(N,vSo),e(N,lb),e(lb,hme),e(hme,FSo),e(lb,TSo),e(lb,kG),e(kG,MSo),e(lb,ESo),e(N,CSo),e(N,ib),e(ib,pme),e(pme,wSo),e(ib,ASo),e(ib,SG),e(SG,ySo),e(ib,LSo),e(N,xSo),e(N,db),e(db,_me),e(_me,$So),e(db,kSo),e(db,RG),e(RG,SSo),e(db,RSo),e(N,PSo),e(N,cb),e(cb,ume),e(ume,BSo),e(cb,ISo),e(cb,PG),e(PG,NSo),e(cb,qSo),e(N,jSo),e(N,fb),e(fb,bme),e(bme,DSo),e(fb,GSo),e(fb,BG),e(BG,OSo),e(fb,VSo),e(N,XSo),e(N,mb),e(mb,vme),e(vme,zSo),e(mb,WSo),e(mb,IG),e(IG,QSo),e(mb,HSo),e(N,USo),e(N,gb),e(gb,Fme),e(Fme,JSo),e(gb,YSo),e(gb,NG),e(NG,KSo),e(gb,ZSo),e(N,eRo),e(N,hb),e(hb,Tme),e(Tme,oRo),e(hb,rRo),e(hb,qG),e(qG,tRo),e(hb,aRo),e(N,nRo),e(N,pb),e(pb,Mme),e(Mme,sRo),e(pb,lRo),e(pb,jG),e(jG,iRo),e(pb,dRo),e(N,cRo),e(N,_b),e(_b,Eme),e(Eme,fRo),e(_b,mRo),e(_b,DG),e(DG,gRo),e(_b,hRo),e(N,pRo),e(N,ub),e(ub,Cme),e(Cme,_Ro),e(ub,uRo),e(ub,GG),e(GG,bRo),e(ub,vRo),e(N,FRo),e(N,bb),e(bb,wme),e(wme,TRo),e(bb,MRo),e(bb,OG),e(OG,ERo),e(bb,CRo),e(N,wRo),e(N,vb),e(vb,Ame),e(Ame,ARo),e(vb,yRo),e(vb,VG),e(VG,LRo),e(vb,xRo),e(N,$Ro),e(N,Fb),e(Fb,yme),e(yme,kRo),e(Fb,SRo),e(Fb,XG),e(XG,RRo),e(Fb,PRo),e(N,BRo),e(N,Tb),e(Tb,Lme),e(Lme,IRo),e(Tb,NRo),e(Tb,zG),e(zG,qRo),e(Tb,jRo),e(N,DRo),e(N,Mb),e(Mb,xme),e(xme,GRo),e(Mb,ORo),e(Mb,WG),e(WG,VRo),e(Mb,XRo),e(N,zRo),e(N,Eb),e(Eb,$me),e($me,WRo),e(Eb,QRo),e(Eb,QG),e(QG,HRo),e(Eb,URo),e(N,JRo),e(N,Cb),e(Cb,kme),e(kme,YRo),e(Cb,KRo),e(Cb,HG),e(HG,ZRo),e(Cb,ePo),e(N,oPo),e(N,wb),e(wb,Sme),e(Sme,rPo),e(wb,tPo),e(wb,UG),e(UG,aPo),e(wb,nPo),e(N,sPo),e(N,Ab),e(Ab,Rme),e(Rme,lPo),e(Ab,iPo),e(Ab,JG),e(JG,dPo),e(Ab,cPo),e(N,fPo),e(N,yb),e(yb,Pme),e(Pme,mPo),e(yb,gPo),e(yb,YG),e(YG,hPo),e(yb,pPo),e(N,_Po),e(N,Lb),e(Lb,Bme),e(Bme,uPo),e(Lb,bPo),e(Lb,KG),e(KG,vPo),e(Lb,FPo),e(N,TPo),e(N,xb),e(xb,Ime),e(Ime,MPo),e(xb,EPo),e(xb,ZG),e(ZG,CPo),e(xb,wPo),e(N,APo),e(N,$b),e($b,Nme),e(Nme,yPo),e($b,LPo),e($b,eO),e(eO,xPo),e($b,$Po),e(N,kPo),e(N,kb),e(kb,qme),e(qme,SPo),e(kb,RPo),e(kb,oO),e(oO,PPo),e(kb,BPo),e(N,IPo),e(N,Sb),e(Sb,jme),e(jme,NPo),e(Sb,qPo),e(Sb,rO),e(rO,jPo),e(Sb,DPo),e(N,GPo),e(N,Rb),e(Rb,Dme),e(Dme,OPo),e(Rb,VPo),e(Rb,tO),e(tO,XPo),e(Rb,zPo),e(N,WPo),e(N,Pb),e(Pb,Gme),e(Gme,QPo),e(Pb,HPo),e(Pb,aO),e(aO,UPo),e(Pb,JPo),e(N,YPo),e(N,Bb),e(Bb,Ome),e(Ome,KPo),e(Bb,ZPo),e(Bb,nO),e(nO,eBo),e(Bb,oBo),e(N,rBo),e(N,Ib),e(Ib,Vme),e(Vme,tBo),e(Ib,aBo),e(Ib,sO),e(sO,nBo),e(Ib,sBo),e(N,lBo),e(N,Nb),e(Nb,Xme),e(Xme,iBo),e(Nb,dBo),e(Nb,lO),e(lO,cBo),e(Nb,fBo),e(N,mBo),e(N,qb),e(qb,zme),e(zme,gBo),e(qb,hBo),e(qb,iO),e(iO,pBo),e(qb,_Bo),e(N,uBo),e(N,jb),e(jb,Wme),e(Wme,bBo),e(jb,vBo),e(jb,dO),e(dO,FBo),e(jb,TBo),e(oo,MBo),e(oo,Db),e(Db,EBo),e(Db,Qme),e(Qme,CBo),e(Db,wBo),e(Db,Hme),e(Hme,ABo),e(oo,yBo),M(Gb,oo,null),b(f,Dqe,u),b(f,Xi,u),e(Xi,Ob),e(Ob,Ume),M(Ry,Ume,null),e(Xi,LBo),e(Xi,Jme),e(Jme,xBo),b(f,Gqe,u),b(f,Po,u),M(Py,Po,null),e(Po,$Bo),e(Po,zi),e(zi,kBo),e(zi,cO),e(cO,SBo),e(zi,RBo),e(zi,fO),e(fO,PBo),e(zi,BBo),e(Po,IBo),e(Po,By),e(By,NBo),e(By,Yme),e(Yme,qBo),e(By,jBo),e(Po,DBo),e(Po,dt),M(Iy,dt,null),e(dt,GBo),e(dt,Kme),e(Kme,OBo),e(dt,VBo),e(dt,Wi),e(Wi,XBo),e(Wi,Zme),e(Zme,zBo),e(Wi,WBo),e(Wi,mO),e(mO,QBo),e(Wi,HBo),e(dt,UBo),M(Vb,dt,null),e(Po,JBo),e(Po,ro),M(Ny,ro,null),e(ro,YBo),e(ro,ege),e(ege,KBo),e(ro,ZBo),e(ro,Pa),e(Pa,eIo),e(Pa,oge),e(oge,oIo),e(Pa,rIo),e(Pa,rge),e(rge,tIo),e(Pa,aIo),e(Pa,tge),e(tge,nIo),e(Pa,sIo),e(ro,lIo),e(ro,K),e(K,Xb),e(Xb,age),e(age,iIo),e(Xb,dIo),e(Xb,gO),e(gO,cIo),e(Xb,fIo),e(K,mIo),e(K,zb),e(zb,nge),e(nge,gIo),e(zb,hIo),e(zb,hO),e(hO,pIo),e(zb,_Io),e(K,uIo),e(K,Wb),e(Wb,sge),e(sge,bIo),e(Wb,vIo),e(Wb,pO),e(pO,FIo),e(Wb,TIo),e(K,MIo),e(K,Qb),e(Qb,lge),e(lge,EIo),e(Qb,CIo),e(Qb,_O),e(_O,wIo),e(Qb,AIo),e(K,yIo),e(K,Hb),e(Hb,ige),e(ige,LIo),e(Hb,xIo),e(Hb,uO),e(uO,$Io),e(Hb,kIo),e(K,SIo),e(K,Ub),e(Ub,dge),e(dge,RIo),e(Ub,PIo),e(Ub,bO),e(bO,BIo),e(Ub,IIo),e(K,NIo),e(K,Jb),e(Jb,cge),e(cge,qIo),e(Jb,jIo),e(Jb,vO),e(vO,DIo),e(Jb,GIo),e(K,OIo),e(K,Yb),e(Yb,fge),e(fge,VIo),e(Yb,XIo),e(Yb,FO),e(FO,zIo),e(Yb,WIo),e(K,QIo),e(K,Kb),e(Kb,mge),e(mge,HIo),e(Kb,UIo),e(Kb,TO),e(TO,JIo),e(Kb,YIo),e(K,KIo),e(K,Zb),e(Zb,gge),e(gge,ZIo),e(Zb,eNo),e(Zb,MO),e(MO,oNo),e(Zb,rNo),e(K,tNo),e(K,e2),e(e2,hge),e(hge,aNo),e(e2,nNo),e(e2,EO),e(EO,sNo),e(e2,lNo),e(K,iNo),e(K,o2),e(o2,pge),e(pge,dNo),e(o2,cNo),e(o2,CO),e(CO,fNo),e(o2,mNo),e(K,gNo),e(K,r2),e(r2,_ge),e(_ge,hNo),e(r2,pNo),e(r2,wO),e(wO,_No),e(r2,uNo),e(K,bNo),e(K,t2),e(t2,uge),e(uge,vNo),e(t2,FNo),e(t2,AO),e(AO,TNo),e(t2,MNo),e(K,ENo),e(K,a2),e(a2,bge),e(bge,CNo),e(a2,wNo),e(a2,yO),e(yO,ANo),e(a2,yNo),e(K,LNo),e(K,n2),e(n2,vge),e(vge,xNo),e(n2,$No),e(n2,LO),e(LO,kNo),e(n2,SNo),e(K,RNo),e(K,s2),e(s2,Fge),e(Fge,PNo),e(s2,BNo),e(s2,xO),e(xO,INo),e(s2,NNo),e(K,qNo),e(K,l2),e(l2,Tge),e(Tge,jNo),e(l2,DNo),e(l2,$O),e($O,GNo),e(l2,ONo),e(K,VNo),e(K,i2),e(i2,Mge),e(Mge,XNo),e(i2,zNo),e(i2,kO),e(kO,WNo),e(i2,QNo),e(K,HNo),e(K,d2),e(d2,Ege),e(Ege,UNo),e(d2,JNo),e(d2,SO),e(SO,YNo),e(d2,KNo),e(K,ZNo),e(K,c2),e(c2,Cge),e(Cge,eqo),e(c2,oqo),e(c2,RO),e(RO,rqo),e(c2,tqo),e(K,aqo),e(K,f2),e(f2,wge),e(wge,nqo),e(f2,sqo),e(f2,PO),e(PO,lqo),e(f2,iqo),e(K,dqo),e(K,m2),e(m2,Age),e(Age,cqo),e(m2,fqo),e(m2,BO),e(BO,mqo),e(m2,gqo),e(K,hqo),e(K,g2),e(g2,yge),e(yge,pqo),e(g2,_qo),e(g2,IO),e(IO,uqo),e(g2,bqo),e(K,vqo),e(K,h2),e(h2,Lge),e(Lge,Fqo),e(h2,Tqo),e(h2,NO),e(NO,Mqo),e(h2,Eqo),e(K,Cqo),e(K,p2),e(p2,xge),e(xge,wqo),e(p2,Aqo),e(p2,qO),e(qO,yqo),e(p2,Lqo),e(K,xqo),e(K,_2),e(_2,$ge),e($ge,$qo),e(_2,kqo),e(_2,jO),e(jO,Sqo),e(_2,Rqo),e(K,Pqo),e(K,u2),e(u2,kge),e(kge,Bqo),e(u2,Iqo),e(u2,DO),e(DO,Nqo),e(u2,qqo),e(K,jqo),e(K,b2),e(b2,Sge),e(Sge,Dqo),e(b2,Gqo),e(b2,GO),e(GO,Oqo),e(b2,Vqo),e(ro,Xqo),e(ro,v2),e(v2,zqo),e(v2,Rge),e(Rge,Wqo),e(v2,Qqo),e(v2,Pge),e(Pge,Hqo),e(ro,Uqo),M(F2,ro,null),b(f,Oqe,u),b(f,Qi,u),e(Qi,T2),e(T2,Bge),M(qy,Bge,null),e(Qi,Jqo),e(Qi,Ige),e(Ige,Yqo),b(f,Vqe,u),b(f,Bo,u),M(jy,Bo,null),e(Bo,Kqo),e(Bo,Hi),e(Hi,Zqo),e(Hi,OO),e(OO,ejo),e(Hi,ojo),e(Hi,VO),e(VO,rjo),e(Hi,tjo),e(Bo,ajo),e(Bo,Dy),e(Dy,njo),e(Dy,Nge),e(Nge,sjo),e(Dy,ljo),e(Bo,ijo),e(Bo,ct),M(Gy,ct,null),e(ct,djo),e(ct,qge),e(qge,cjo),e(ct,fjo),e(ct,Ui),e(Ui,mjo),e(Ui,jge),e(jge,gjo),e(Ui,hjo),e(Ui,XO),e(XO,pjo),e(Ui,_jo),e(ct,ujo),M(M2,ct,null),e(Bo,bjo),e(Bo,to),M(Oy,to,null),e(to,vjo),e(to,Dge),e(Dge,Fjo),e(to,Tjo),e(to,Ba),e(Ba,Mjo),e(Ba,Gge),e(Gge,Ejo),e(Ba,Cjo),e(Ba,Oge),e(Oge,wjo),e(Ba,Ajo),e(Ba,Vge),e(Vge,yjo),e(Ba,Ljo),e(to,xjo),e(to,Yr),e(Yr,E2),e(E2,Xge),e(Xge,$jo),e(E2,kjo),e(E2,zO),e(zO,Sjo),e(E2,Rjo),e(Yr,Pjo),e(Yr,C2),e(C2,zge),e(zge,Bjo),e(C2,Ijo),e(C2,WO),e(WO,Njo),e(C2,qjo),e(Yr,jjo),e(Yr,w2),e(w2,Wge),e(Wge,Djo),e(w2,Gjo),e(w2,QO),e(QO,Ojo),e(w2,Vjo),e(Yr,Xjo),e(Yr,A2),e(A2,Qge),e(Qge,zjo),e(A2,Wjo),e(A2,HO),e(HO,Qjo),e(A2,Hjo),e(Yr,Ujo),e(Yr,y2),e(y2,Hge),e(Hge,Jjo),e(y2,Yjo),e(y2,UO),e(UO,Kjo),e(y2,Zjo),e(to,eDo),e(to,L2),e(L2,oDo),e(L2,Uge),e(Uge,rDo),e(L2,tDo),e(L2,Jge),e(Jge,aDo),e(to,nDo),M(x2,to,null),b(f,Xqe,u),b(f,Ji,u),e(Ji,$2),e($2,Yge),M(Vy,Yge,null),e(Ji,sDo),e(Ji,Kge),e(Kge,lDo),b(f,zqe,u),b(f,Io,u),M(Xy,Io,null),e(Io,iDo),e(Io,Yi),e(Yi,dDo),e(Yi,JO),e(JO,cDo),e(Yi,fDo),e(Yi,YO),e(YO,mDo),e(Yi,gDo),e(Io,hDo),e(Io,zy),e(zy,pDo),e(zy,Zge),e(Zge,_Do),e(zy,uDo),e(Io,bDo),e(Io,ft),M(Wy,ft,null),e(ft,vDo),e(ft,ehe),e(ehe,FDo),e(ft,TDo),e(ft,Ki),e(Ki,MDo),e(Ki,ohe),e(ohe,EDo),e(Ki,CDo),e(Ki,KO),e(KO,wDo),e(Ki,ADo),e(ft,yDo),M(k2,ft,null),e(Io,LDo),e(Io,ao),M(Qy,ao,null),e(ao,xDo),e(ao,rhe),e(rhe,$Do),e(ao,kDo),e(ao,Ia),e(Ia,SDo),e(Ia,the),e(the,RDo),e(Ia,PDo),e(Ia,ahe),e(ahe,BDo),e(Ia,IDo),e(Ia,nhe),e(nhe,NDo),e(Ia,qDo),e(ao,jDo),e(ao,H),e(H,S2),e(S2,she),e(she,DDo),e(S2,GDo),e(S2,ZO),e(ZO,ODo),e(S2,VDo),e(H,XDo),e(H,R2),e(R2,lhe),e(lhe,zDo),e(R2,WDo),e(R2,eV),e(eV,QDo),e(R2,HDo),e(H,UDo),e(H,P2),e(P2,ihe),e(ihe,JDo),e(P2,YDo),e(P2,oV),e(oV,KDo),e(P2,ZDo),e(H,eGo),e(H,B2),e(B2,dhe),e(dhe,oGo),e(B2,rGo),e(B2,rV),e(rV,tGo),e(B2,aGo),e(H,nGo),e(H,I2),e(I2,che),e(che,sGo),e(I2,lGo),e(I2,tV),e(tV,iGo),e(I2,dGo),e(H,cGo),e(H,N2),e(N2,fhe),e(fhe,fGo),e(N2,mGo),e(N2,aV),e(aV,gGo),e(N2,hGo),e(H,pGo),e(H,q2),e(q2,mhe),e(mhe,_Go),e(q2,uGo),e(q2,nV),e(nV,bGo),e(q2,vGo),e(H,FGo),e(H,j2),e(j2,ghe),e(ghe,TGo),e(j2,MGo),e(j2,sV),e(sV,EGo),e(j2,CGo),e(H,wGo),e(H,D2),e(D2,hhe),e(hhe,AGo),e(D2,yGo),e(D2,lV),e(lV,LGo),e(D2,xGo),e(H,$Go),e(H,G2),e(G2,phe),e(phe,kGo),e(G2,SGo),e(G2,iV),e(iV,RGo),e(G2,PGo),e(H,BGo),e(H,O2),e(O2,_he),e(_he,IGo),e(O2,NGo),e(O2,dV),e(dV,qGo),e(O2,jGo),e(H,DGo),e(H,V2),e(V2,uhe),e(uhe,GGo),e(V2,OGo),e(V2,cV),e(cV,VGo),e(V2,XGo),e(H,zGo),e(H,X2),e(X2,bhe),e(bhe,WGo),e(X2,QGo),e(X2,fV),e(fV,HGo),e(X2,UGo),e(H,JGo),e(H,z2),e(z2,vhe),e(vhe,YGo),e(z2,KGo),e(z2,mV),e(mV,ZGo),e(z2,eOo),e(H,oOo),e(H,W2),e(W2,Fhe),e(Fhe,rOo),e(W2,tOo),e(W2,gV),e(gV,aOo),e(W2,nOo),e(H,sOo),e(H,Q2),e(Q2,The),e(The,lOo),e(Q2,iOo),e(Q2,hV),e(hV,dOo),e(Q2,cOo),e(H,fOo),e(H,H2),e(H2,Mhe),e(Mhe,mOo),e(H2,gOo),e(H2,pV),e(pV,hOo),e(H2,pOo),e(H,_Oo),e(H,U2),e(U2,Ehe),e(Ehe,uOo),e(U2,bOo),e(U2,_V),e(_V,vOo),e(U2,FOo),e(H,TOo),e(H,J2),e(J2,Che),e(Che,MOo),e(J2,EOo),e(J2,uV),e(uV,COo),e(J2,wOo),e(H,AOo),e(H,Y2),e(Y2,whe),e(whe,yOo),e(Y2,LOo),e(Y2,bV),e(bV,xOo),e(Y2,$Oo),e(H,kOo),e(H,K2),e(K2,Ahe),e(Ahe,SOo),e(K2,ROo),e(K2,vV),e(vV,POo),e(K2,BOo),e(H,IOo),e(H,Z2),e(Z2,yhe),e(yhe,NOo),e(Z2,qOo),e(Z2,FV),e(FV,jOo),e(Z2,DOo),e(H,GOo),e(H,e4),e(e4,Lhe),e(Lhe,OOo),e(e4,VOo),e(e4,TV),e(TV,XOo),e(e4,zOo),e(H,WOo),e(H,o4),e(o4,xhe),e(xhe,QOo),e(o4,HOo),e(o4,MV),e(MV,UOo),e(o4,JOo),e(H,YOo),e(H,r4),e(r4,$he),e($he,KOo),e(r4,ZOo),e(r4,EV),e(EV,eVo),e(r4,oVo),e(H,rVo),e(H,t4),e(t4,khe),e(khe,tVo),e(t4,aVo),e(t4,CV),e(CV,nVo),e(t4,sVo),e(H,lVo),e(H,a4),e(a4,She),e(She,iVo),e(a4,dVo),e(a4,wV),e(wV,cVo),e(a4,fVo),e(H,mVo),e(H,n4),e(n4,Rhe),e(Rhe,gVo),e(n4,hVo),e(n4,AV),e(AV,pVo),e(n4,_Vo),e(H,uVo),e(H,s4),e(s4,Phe),e(Phe,bVo),e(s4,vVo),e(s4,yV),e(yV,FVo),e(s4,TVo),e(H,MVo),e(H,l4),e(l4,Bhe),e(Bhe,EVo),e(l4,CVo),e(l4,LV),e(LV,wVo),e(l4,AVo),e(H,yVo),e(H,i4),e(i4,Ihe),e(Ihe,LVo),e(i4,xVo),e(i4,xV),e(xV,$Vo),e(i4,kVo),e(H,SVo),e(H,d4),e(d4,Nhe),e(Nhe,RVo),e(d4,PVo),e(d4,$V),e($V,BVo),e(d4,IVo),e(H,NVo),e(H,c4),e(c4,qhe),e(qhe,qVo),e(c4,jVo),e(c4,kV),e(kV,DVo),e(c4,GVo),e(H,OVo),e(H,f4),e(f4,jhe),e(jhe,VVo),e(f4,XVo),e(f4,SV),e(SV,zVo),e(f4,WVo),e(ao,QVo),e(ao,m4),e(m4,HVo),e(m4,Dhe),e(Dhe,UVo),e(m4,JVo),e(m4,Ghe),e(Ghe,YVo),e(ao,KVo),M(g4,ao,null),b(f,Wqe,u),b(f,Zi,u),e(Zi,h4),e(h4,Ohe),M(Hy,Ohe,null),e(Zi,ZVo),e(Zi,Vhe),e(Vhe,eXo),b(f,Qqe,u),b(f,No,u),M(Uy,No,null),e(No,oXo),e(No,ed),e(ed,rXo),e(ed,RV),e(RV,tXo),e(ed,aXo),e(ed,PV),e(PV,nXo),e(ed,sXo),e(No,lXo),e(No,Jy),e(Jy,iXo),e(Jy,Xhe),e(Xhe,dXo),e(Jy,cXo),e(No,fXo),e(No,mt),M(Yy,mt,null),e(mt,mXo),e(mt,zhe),e(zhe,gXo),e(mt,hXo),e(mt,od),e(od,pXo),e(od,Whe),e(Whe,_Xo),e(od,uXo),e(od,BV),e(BV,bXo),e(od,vXo),e(mt,FXo),M(p4,mt,null),e(No,TXo),e(No,no),M(Ky,no,null),e(no,MXo),e(no,Qhe),e(Qhe,EXo),e(no,CXo),e(no,Na),e(Na,wXo),e(Na,Hhe),e(Hhe,AXo),e(Na,yXo),e(Na,Uhe),e(Uhe,LXo),e(Na,xXo),e(Na,Jhe),e(Jhe,$Xo),e(Na,kXo),e(no,SXo),e(no,V),e(V,_4),e(_4,Yhe),e(Yhe,RXo),e(_4,PXo),e(_4,IV),e(IV,BXo),e(_4,IXo),e(V,NXo),e(V,u4),e(u4,Khe),e(Khe,qXo),e(u4,jXo),e(u4,NV),e(NV,DXo),e(u4,GXo),e(V,OXo),e(V,b4),e(b4,Zhe),e(Zhe,VXo),e(b4,XXo),e(b4,qV),e(qV,zXo),e(b4,WXo),e(V,QXo),e(V,v4),e(v4,epe),e(epe,HXo),e(v4,UXo),e(v4,jV),e(jV,JXo),e(v4,YXo),e(V,KXo),e(V,F4),e(F4,ope),e(ope,ZXo),e(F4,ezo),e(F4,DV),e(DV,ozo),e(F4,rzo),e(V,tzo),e(V,T4),e(T4,rpe),e(rpe,azo),e(T4,nzo),e(T4,GV),e(GV,szo),e(T4,lzo),e(V,izo),e(V,M4),e(M4,tpe),e(tpe,dzo),e(M4,czo),e(M4,OV),e(OV,fzo),e(M4,mzo),e(V,gzo),e(V,E4),e(E4,ape),e(ape,hzo),e(E4,pzo),e(E4,VV),e(VV,_zo),e(E4,uzo),e(V,bzo),e(V,C4),e(C4,npe),e(npe,vzo),e(C4,Fzo),e(C4,XV),e(XV,Tzo),e(C4,Mzo),e(V,Ezo),e(V,w4),e(w4,spe),e(spe,Czo),e(w4,wzo),e(w4,zV),e(zV,Azo),e(w4,yzo),e(V,Lzo),e(V,A4),e(A4,lpe),e(lpe,xzo),e(A4,$zo),e(A4,WV),e(WV,kzo),e(A4,Szo),e(V,Rzo),e(V,y4),e(y4,ipe),e(ipe,Pzo),e(y4,Bzo),e(y4,QV),e(QV,Izo),e(y4,Nzo),e(V,qzo),e(V,L4),e(L4,dpe),e(dpe,jzo),e(L4,Dzo),e(L4,HV),e(HV,Gzo),e(L4,Ozo),e(V,Vzo),e(V,x4),e(x4,cpe),e(cpe,Xzo),e(x4,zzo),e(x4,UV),e(UV,Wzo),e(x4,Qzo),e(V,Hzo),e(V,$4),e($4,fpe),e(fpe,Uzo),e($4,Jzo),e($4,JV),e(JV,Yzo),e($4,Kzo),e(V,Zzo),e(V,k4),e(k4,mpe),e(mpe,eWo),e(k4,oWo),e(k4,YV),e(YV,rWo),e(k4,tWo),e(V,aWo),e(V,S4),e(S4,gpe),e(gpe,nWo),e(S4,sWo),e(S4,KV),e(KV,lWo),e(S4,iWo),e(V,dWo),e(V,R4),e(R4,hpe),e(hpe,cWo),e(R4,fWo),e(R4,ZV),e(ZV,mWo),e(R4,gWo),e(V,hWo),e(V,P4),e(P4,ppe),e(ppe,pWo),e(P4,_Wo),e(P4,eX),e(eX,uWo),e(P4,bWo),e(V,vWo),e(V,B4),e(B4,_pe),e(_pe,FWo),e(B4,TWo),e(B4,oX),e(oX,MWo),e(B4,EWo),e(V,CWo),e(V,I4),e(I4,upe),e(upe,wWo),e(I4,AWo),e(I4,rX),e(rX,yWo),e(I4,LWo),e(V,xWo),e(V,N4),e(N4,bpe),e(bpe,$Wo),e(N4,kWo),e(N4,tX),e(tX,SWo),e(N4,RWo),e(V,PWo),e(V,q4),e(q4,vpe),e(vpe,BWo),e(q4,IWo),e(q4,aX),e(aX,NWo),e(q4,qWo),e(V,jWo),e(V,j4),e(j4,Fpe),e(Fpe,DWo),e(j4,GWo),e(j4,nX),e(nX,OWo),e(j4,VWo),e(V,XWo),e(V,D4),e(D4,Tpe),e(Tpe,zWo),e(D4,WWo),e(D4,sX),e(sX,QWo),e(D4,HWo),e(V,UWo),e(V,G4),e(G4,Mpe),e(Mpe,JWo),e(G4,YWo),e(G4,lX),e(lX,KWo),e(G4,ZWo),e(V,eQo),e(V,O4),e(O4,Epe),e(Epe,oQo),e(O4,rQo),e(O4,iX),e(iX,tQo),e(O4,aQo),e(V,nQo),e(V,V4),e(V4,Cpe),e(Cpe,sQo),e(V4,lQo),e(V4,dX),e(dX,iQo),e(V4,dQo),e(V,cQo),e(V,X4),e(X4,wpe),e(wpe,fQo),e(X4,mQo),e(X4,cX),e(cX,gQo),e(X4,hQo),e(V,pQo),e(V,z4),e(z4,Ape),e(Ape,_Qo),e(z4,uQo),e(z4,fX),e(fX,bQo),e(z4,vQo),e(V,FQo),e(V,W4),e(W4,ype),e(ype,TQo),e(W4,MQo),e(W4,mX),e(mX,EQo),e(W4,CQo),e(V,wQo),e(V,Q4),e(Q4,Lpe),e(Lpe,AQo),e(Q4,yQo),e(Q4,gX),e(gX,LQo),e(Q4,xQo),e(V,$Qo),e(V,H4),e(H4,xpe),e(xpe,kQo),e(H4,SQo),e(H4,hX),e(hX,RQo),e(H4,PQo),e(V,BQo),e(V,U4),e(U4,$pe),e($pe,IQo),e(U4,NQo),e(U4,pX),e(pX,qQo),e(U4,jQo),e(V,DQo),e(V,J4),e(J4,kpe),e(kpe,GQo),e(J4,OQo),e(J4,_X),e(_X,VQo),e(J4,XQo),e(V,zQo),e(V,Y4),e(Y4,Spe),e(Spe,WQo),e(Y4,QQo),e(Y4,uX),e(uX,HQo),e(Y4,UQo),e(V,JQo),e(V,K4),e(K4,Rpe),e(Rpe,YQo),e(K4,KQo),e(K4,bX),e(bX,ZQo),e(K4,eHo),e(V,oHo),e(V,Z4),e(Z4,Ppe),e(Ppe,rHo),e(Z4,tHo),e(Z4,vX),e(vX,aHo),e(Z4,nHo),e(V,sHo),e(V,ev),e(ev,Bpe),e(Bpe,lHo),e(ev,iHo),e(ev,FX),e(FX,dHo),e(ev,cHo),e(V,fHo),e(V,ov),e(ov,Ipe),e(Ipe,mHo),e(ov,gHo),e(ov,TX),e(TX,hHo),e(ov,pHo),e(no,_Ho),e(no,rv),e(rv,uHo),e(rv,Npe),e(Npe,bHo),e(rv,vHo),e(rv,qpe),e(qpe,FHo),e(no,THo),M(tv,no,null),b(f,Hqe,u),b(f,rd,u),e(rd,av),e(av,jpe),M(Zy,jpe,null),e(rd,MHo),e(rd,Dpe),e(Dpe,EHo),b(f,Uqe,u),b(f,qo,u),M(eL,qo,null),e(qo,CHo),e(qo,td),e(td,wHo),e(td,MX),e(MX,AHo),e(td,yHo),e(td,EX),e(EX,LHo),e(td,xHo),e(qo,$Ho),e(qo,oL),e(oL,kHo),e(oL,Gpe),e(Gpe,SHo),e(oL,RHo),e(qo,PHo),e(qo,gt),M(rL,gt,null),e(gt,BHo),e(gt,Ope),e(Ope,IHo),e(gt,NHo),e(gt,ad),e(ad,qHo),e(ad,Vpe),e(Vpe,jHo),e(ad,DHo),e(ad,CX),e(CX,GHo),e(ad,OHo),e(gt,VHo),M(nv,gt,null),e(qo,XHo),e(qo,so),M(tL,so,null),e(so,zHo),e(so,Xpe),e(Xpe,WHo),e(so,QHo),e(so,qa),e(qa,HHo),e(qa,zpe),e(zpe,UHo),e(qa,JHo),e(qa,Wpe),e(Wpe,YHo),e(qa,KHo),e(qa,Qpe),e(Qpe,ZHo),e(qa,eUo),e(so,oUo),e(so,Hpe),e(Hpe,sv),e(sv,Upe),e(Upe,rUo),e(sv,tUo),e(sv,wX),e(wX,aUo),e(sv,nUo),e(so,sUo),e(so,lv),e(lv,lUo),e(lv,Jpe),e(Jpe,iUo),e(lv,dUo),e(lv,Ype),e(Ype,cUo),e(so,fUo),M(iv,so,null),b(f,Jqe,u),b(f,nd,u),e(nd,dv),e(dv,Kpe),M(aL,Kpe,null),e(nd,mUo),e(nd,Zpe),e(Zpe,gUo),b(f,Yqe,u),b(f,jo,u),M(nL,jo,null),e(jo,hUo),e(jo,sd),e(sd,pUo),e(sd,AX),e(AX,_Uo),e(sd,uUo),e(sd,yX),e(yX,bUo),e(sd,vUo),e(jo,FUo),e(jo,sL),e(sL,TUo),e(sL,e_e),e(e_e,MUo),e(sL,EUo),e(jo,CUo),e(jo,ht),M(lL,ht,null),e(ht,wUo),e(ht,o_e),e(o_e,AUo),e(ht,yUo),e(ht,ld),e(ld,LUo),e(ld,r_e),e(r_e,xUo),e(ld,$Uo),e(ld,LX),e(LX,kUo),e(ld,SUo),e(ht,RUo),M(cv,ht,null),e(jo,PUo),e(jo,lo),M(iL,lo,null),e(lo,BUo),e(lo,t_e),e(t_e,IUo),e(lo,NUo),e(lo,ja),e(ja,qUo),e(ja,a_e),e(a_e,jUo),e(ja,DUo),e(ja,n_e),e(n_e,GUo),e(ja,OUo),e(ja,s_e),e(s_e,VUo),e(ja,XUo),e(lo,zUo),e(lo,ve),e(ve,fv),e(fv,l_e),e(l_e,WUo),e(fv,QUo),e(fv,xX),e(xX,HUo),e(fv,UUo),e(ve,JUo),e(ve,mv),e(mv,i_e),e(i_e,YUo),e(mv,KUo),e(mv,$X),e($X,ZUo),e(mv,eJo),e(ve,oJo),e(ve,gv),e(gv,d_e),e(d_e,rJo),e(gv,tJo),e(gv,kX),e(kX,aJo),e(gv,nJo),e(ve,sJo),e(ve,hv),e(hv,c_e),e(c_e,lJo),e(hv,iJo),e(hv,SX),e(SX,dJo),e(hv,cJo),e(ve,fJo),e(ve,Bs),e(Bs,f_e),e(f_e,mJo),e(Bs,gJo),e(Bs,RX),e(RX,hJo),e(Bs,pJo),e(Bs,PX),e(PX,_Jo),e(Bs,uJo),e(ve,bJo),e(ve,pv),e(pv,m_e),e(m_e,vJo),e(pv,FJo),e(pv,BX),e(BX,TJo),e(pv,MJo),e(ve,EJo),e(ve,Is),e(Is,g_e),e(g_e,CJo),e(Is,wJo),e(Is,IX),e(IX,AJo),e(Is,yJo),e(Is,NX),e(NX,LJo),e(Is,xJo),e(ve,$Jo),e(ve,pt),e(pt,h_e),e(h_e,kJo),e(pt,SJo),e(pt,qX),e(qX,RJo),e(pt,PJo),e(pt,jX),e(jX,BJo),e(pt,IJo),e(pt,DX),e(DX,NJo),e(pt,qJo),e(ve,jJo),e(ve,_v),e(_v,p_e),e(p_e,DJo),e(_v,GJo),e(_v,GX),e(GX,OJo),e(_v,VJo),e(ve,XJo),e(ve,uv),e(uv,__e),e(__e,zJo),e(uv,WJo),e(uv,OX),e(OX,QJo),e(uv,HJo),e(ve,UJo),e(ve,bv),e(bv,u_e),e(u_e,JJo),e(bv,YJo),e(bv,VX),e(VX,KJo),e(bv,ZJo),e(ve,eYo),e(ve,vv),e(vv,b_e),e(b_e,oYo),e(vv,rYo),e(vv,XX),e(XX,tYo),e(vv,aYo),e(ve,nYo),e(ve,Fv),e(Fv,v_e),e(v_e,sYo),e(Fv,lYo),e(Fv,zX),e(zX,iYo),e(Fv,dYo),e(ve,cYo),e(ve,Tv),e(Tv,F_e),e(F_e,fYo),e(Tv,mYo),e(Tv,WX),e(WX,gYo),e(Tv,hYo),e(ve,pYo),e(ve,Mv),e(Mv,T_e),e(T_e,_Yo),e(Mv,uYo),e(Mv,QX),e(QX,bYo),e(Mv,vYo),e(lo,FYo),e(lo,Ev),e(Ev,TYo),e(Ev,M_e),e(M_e,MYo),e(Ev,EYo),e(Ev,E_e),e(E_e,CYo),e(lo,wYo),M(Cv,lo,null),b(f,Kqe,u),b(f,id,u),e(id,wv),e(wv,C_e),M(dL,C_e,null),e(id,AYo),e(id,w_e),e(w_e,yYo),b(f,Zqe,u),b(f,Do,u),M(cL,Do,null),e(Do,LYo),e(Do,dd),e(dd,xYo),e(dd,HX),e(HX,$Yo),e(dd,kYo),e(dd,UX),e(UX,SYo),e(dd,RYo),e(Do,PYo),e(Do,fL),e(fL,BYo),e(fL,A_e),e(A_e,IYo),e(fL,NYo),e(Do,qYo),e(Do,_t),M(mL,_t,null),e(_t,jYo),e(_t,y_e),e(y_e,DYo),e(_t,GYo),e(_t,cd),e(cd,OYo),e(cd,L_e),e(L_e,VYo),e(cd,XYo),e(cd,JX),e(JX,zYo),e(cd,WYo),e(_t,QYo),M(Av,_t,null),e(Do,HYo),e(Do,io),M(gL,io,null),e(io,UYo),e(io,x_e),e(x_e,JYo),e(io,YYo),e(io,Da),e(Da,KYo),e(Da,$_e),e($_e,ZYo),e(Da,eKo),e(Da,k_e),e(k_e,oKo),e(Da,rKo),e(Da,S_e),e(S_e,tKo),e(Da,aKo),e(io,nKo),e(io,R_e),e(R_e,yv),e(yv,P_e),e(P_e,sKo),e(yv,lKo),e(yv,YX),e(YX,iKo),e(yv,dKo),e(io,cKo),e(io,Lv),e(Lv,fKo),e(Lv,B_e),e(B_e,mKo),e(Lv,gKo),e(Lv,I_e),e(I_e,hKo),e(io,pKo),M(xv,io,null),b(f,eje,u),b(f,fd,u),e(fd,$v),e($v,N_e),M(hL,N_e,null),e(fd,_Ko),e(fd,q_e),e(q_e,uKo),b(f,oje,u),b(f,Go,u),M(pL,Go,null),e(Go,bKo),e(Go,md),e(md,vKo),e(md,KX),e(KX,FKo),e(md,TKo),e(md,ZX),e(ZX,MKo),e(md,EKo),e(Go,CKo),e(Go,_L),e(_L,wKo),e(_L,j_e),e(j_e,AKo),e(_L,yKo),e(Go,LKo),e(Go,ut),M(uL,ut,null),e(ut,xKo),e(ut,D_e),e(D_e,$Ko),e(ut,kKo),e(ut,gd),e(gd,SKo),e(gd,G_e),e(G_e,RKo),e(gd,PKo),e(gd,ez),e(ez,BKo),e(gd,IKo),e(ut,NKo),M(kv,ut,null),e(Go,qKo),e(Go,co),M(bL,co,null),e(co,jKo),e(co,O_e),e(O_e,DKo),e(co,GKo),e(co,Ga),e(Ga,OKo),e(Ga,V_e),e(V_e,VKo),e(Ga,XKo),e(Ga,X_e),e(X_e,zKo),e(Ga,WKo),e(Ga,z_e),e(z_e,QKo),e(Ga,HKo),e(co,UKo),e(co,ke),e(ke,Sv),e(Sv,W_e),e(W_e,JKo),e(Sv,YKo),e(Sv,oz),e(oz,KKo),e(Sv,ZKo),e(ke,eZo),e(ke,Rv),e(Rv,Q_e),e(Q_e,oZo),e(Rv,rZo),e(Rv,rz),e(rz,tZo),e(Rv,aZo),e(ke,nZo),e(ke,Pv),e(Pv,H_e),e(H_e,sZo),e(Pv,lZo),e(Pv,tz),e(tz,iZo),e(Pv,dZo),e(ke,cZo),e(ke,Bv),e(Bv,U_e),e(U_e,fZo),e(Bv,mZo),e(Bv,az),e(az,gZo),e(Bv,hZo),e(ke,pZo),e(ke,Iv),e(Iv,J_e),e(J_e,_Zo),e(Iv,uZo),e(Iv,nz),e(nz,bZo),e(Iv,vZo),e(ke,FZo),e(ke,Nv),e(Nv,Y_e),e(Y_e,TZo),e(Nv,MZo),e(Nv,sz),e(sz,EZo),e(Nv,CZo),e(ke,wZo),e(ke,qv),e(qv,K_e),e(K_e,AZo),e(qv,yZo),e(qv,lz),e(lz,LZo),e(qv,xZo),e(ke,$Zo),e(ke,jv),e(jv,Z_e),e(Z_e,kZo),e(jv,SZo),e(jv,iz),e(iz,RZo),e(jv,PZo),e(ke,BZo),e(ke,Dv),e(Dv,eue),e(eue,IZo),e(Dv,NZo),e(Dv,dz),e(dz,qZo),e(Dv,jZo),e(co,DZo),e(co,Gv),e(Gv,GZo),e(Gv,oue),e(oue,OZo),e(Gv,VZo),e(Gv,rue),e(rue,XZo),e(co,zZo),M(Ov,co,null),b(f,rje,u),b(f,hd,u),e(hd,Vv),e(Vv,tue),M(vL,tue,null),e(hd,WZo),e(hd,aue),e(aue,QZo),b(f,tje,u),b(f,Oo,u),M(FL,Oo,null),e(Oo,HZo),e(Oo,pd),e(pd,UZo),e(pd,cz),e(cz,JZo),e(pd,YZo),e(pd,fz),e(fz,KZo),e(pd,ZZo),e(Oo,eer),e(Oo,TL),e(TL,oer),e(TL,nue),e(nue,rer),e(TL,ter),e(Oo,aer),e(Oo,bt),M(ML,bt,null),e(bt,ner),e(bt,sue),e(sue,ser),e(bt,ler),e(bt,_d),e(_d,ier),e(_d,lue),e(lue,der),e(_d,cer),e(_d,mz),e(mz,fer),e(_d,mer),e(bt,ger),M(Xv,bt,null),e(Oo,her),e(Oo,fo),M(EL,fo,null),e(fo,per),e(fo,iue),e(iue,_er),e(fo,uer),e(fo,Oa),e(Oa,ber),e(Oa,due),e(due,ver),e(Oa,Fer),e(Oa,cue),e(cue,Ter),e(Oa,Mer),e(Oa,fue),e(fue,Eer),e(Oa,Cer),e(fo,wer),e(fo,Kr),e(Kr,zv),e(zv,mue),e(mue,Aer),e(zv,yer),e(zv,gz),e(gz,Ler),e(zv,xer),e(Kr,$er),e(Kr,Wv),e(Wv,gue),e(gue,ker),e(Wv,Ser),e(Wv,hz),e(hz,Rer),e(Wv,Per),e(Kr,Ber),e(Kr,Qv),e(Qv,hue),e(hue,Ier),e(Qv,Ner),e(Qv,pz),e(pz,qer),e(Qv,jer),e(Kr,Der),e(Kr,Hv),e(Hv,pue),e(pue,Ger),e(Hv,Oer),e(Hv,_z),e(_z,Ver),e(Hv,Xer),e(Kr,zer),e(Kr,Uv),e(Uv,_ue),e(_ue,Wer),e(Uv,Qer),e(Uv,uz),e(uz,Her),e(Uv,Uer),e(fo,Jer),e(fo,Jv),e(Jv,Yer),e(Jv,uue),e(uue,Ker),e(Jv,Zer),e(Jv,bue),e(bue,eor),e(fo,oor),M(Yv,fo,null),b(f,aje,u),b(f,ud,u),e(ud,Kv),e(Kv,vue),M(CL,vue,null),e(ud,ror),e(ud,Fue),e(Fue,tor),b(f,nje,u),b(f,Vo,u),M(wL,Vo,null),e(Vo,aor),e(Vo,bd),e(bd,nor),e(bd,bz),e(bz,sor),e(bd,lor),e(bd,vz),e(vz,ior),e(bd,dor),e(Vo,cor),e(Vo,AL),e(AL,mor),e(AL,Tue),e(Tue,gor),e(AL,hor),e(Vo,por),e(Vo,vt),M(yL,vt,null),e(vt,_or),e(vt,Mue),e(Mue,uor),e(vt,bor),e(vt,vd),e(vd,vor),e(vd,Eue),e(Eue,For),e(vd,Tor),e(vd,Fz),e(Fz,Mor),e(vd,Eor),e(vt,Cor),M(Zv,vt,null),e(Vo,wor),e(Vo,mo),M(LL,mo,null),e(mo,Aor),e(mo,Cue),e(Cue,yor),e(mo,Lor),e(mo,Va),e(Va,xor),e(Va,wue),e(wue,$or),e(Va,kor),e(Va,Aue),e(Aue,Sor),e(Va,Ror),e(Va,yue),e(yue,Por),e(Va,Bor),e(mo,Ior),e(mo,Se),e(Se,eF),e(eF,Lue),e(Lue,Nor),e(eF,qor),e(eF,Tz),e(Tz,jor),e(eF,Dor),e(Se,Gor),e(Se,oF),e(oF,xue),e(xue,Oor),e(oF,Vor),e(oF,Mz),e(Mz,Xor),e(oF,zor),e(Se,Wor),e(Se,rF),e(rF,$ue),e($ue,Qor),e(rF,Hor),e(rF,Ez),e(Ez,Uor),e(rF,Jor),e(Se,Yor),e(Se,tF),e(tF,kue),e(kue,Kor),e(tF,Zor),e(tF,Cz),e(Cz,err),e(tF,orr),e(Se,rrr),e(Se,aF),e(aF,Sue),e(Sue,trr),e(aF,arr),e(aF,wz),e(wz,nrr),e(aF,srr),e(Se,lrr),e(Se,nF),e(nF,Rue),e(Rue,irr),e(nF,drr),e(nF,Az),e(Az,crr),e(nF,frr),e(Se,mrr),e(Se,sF),e(sF,Pue),e(Pue,grr),e(sF,hrr),e(sF,yz),e(yz,prr),e(sF,_rr),e(Se,urr),e(Se,lF),e(lF,Bue),e(Bue,brr),e(lF,vrr),e(lF,Lz),e(Lz,Frr),e(lF,Trr),e(Se,Mrr),e(Se,iF),e(iF,Iue),e(Iue,Err),e(iF,Crr),e(iF,xz),e(xz,wrr),e(iF,Arr),e(mo,yrr),e(mo,dF),e(dF,Lrr),e(dF,Nue),e(Nue,xrr),e(dF,$rr),e(dF,que),e(que,krr),e(mo,Srr),M(cF,mo,null),b(f,sje,u),b(f,Fd,u),e(Fd,fF),e(fF,jue),M(xL,jue,null),e(Fd,Rrr),e(Fd,Due),e(Due,Prr),b(f,lje,u),b(f,Xo,u),M($L,Xo,null),e(Xo,Brr),e(Xo,Td),e(Td,Irr),e(Td,$z),e($z,Nrr),e(Td,qrr),e(Td,kz),e(kz,jrr),e(Td,Drr),e(Xo,Grr),e(Xo,kL),e(kL,Orr),e(kL,Gue),e(Gue,Vrr),e(kL,Xrr),e(Xo,zrr),e(Xo,Ft),M(SL,Ft,null),e(Ft,Wrr),e(Ft,Oue),e(Oue,Qrr),e(Ft,Hrr),e(Ft,Md),e(Md,Urr),e(Md,Vue),e(Vue,Jrr),e(Md,Yrr),e(Md,Sz),e(Sz,Krr),e(Md,Zrr),e(Ft,etr),M(mF,Ft,null),e(Xo,otr),e(Xo,go),M(RL,go,null),e(go,rtr),e(go,Xue),e(Xue,ttr),e(go,atr),e(go,Xa),e(Xa,ntr),e(Xa,zue),e(zue,str),e(Xa,ltr),e(Xa,Wue),e(Wue,itr),e(Xa,dtr),e(Xa,Que),e(Que,ctr),e(Xa,ftr),e(go,mtr),e(go,PL),e(PL,gF),e(gF,Hue),e(Hue,gtr),e(gF,htr),e(gF,Rz),e(Rz,ptr),e(gF,_tr),e(PL,utr),e(PL,hF),e(hF,Uue),e(Uue,btr),e(hF,vtr),e(hF,Pz),e(Pz,Ftr),e(hF,Ttr),e(go,Mtr),e(go,pF),e(pF,Etr),e(pF,Jue),e(Jue,Ctr),e(pF,wtr),e(pF,Yue),e(Yue,Atr),e(go,ytr),M(_F,go,null),b(f,ije,u),b(f,Ed,u),e(Ed,uF),e(uF,Kue),M(BL,Kue,null),e(Ed,Ltr),e(Ed,Zue),e(Zue,xtr),b(f,dje,u),b(f,zo,u),M(IL,zo,null),e(zo,$tr),e(zo,Cd),e(Cd,ktr),e(Cd,Bz),e(Bz,Str),e(Cd,Rtr),e(Cd,Iz),e(Iz,Ptr),e(Cd,Btr),e(zo,Itr),e(zo,NL),e(NL,Ntr),e(NL,e6e),e(e6e,qtr),e(NL,jtr),e(zo,Dtr),e(zo,Tt),M(qL,Tt,null),e(Tt,Gtr),e(Tt,o6e),e(o6e,Otr),e(Tt,Vtr),e(Tt,wd),e(wd,Xtr),e(wd,r6e),e(r6e,ztr),e(wd,Wtr),e(wd,Nz),e(Nz,Qtr),e(wd,Htr),e(Tt,Utr),M(bF,Tt,null),e(zo,Jtr),e(zo,ho),M(jL,ho,null),e(ho,Ytr),e(ho,t6e),e(t6e,Ktr),e(ho,Ztr),e(ho,za),e(za,ear),e(za,a6e),e(a6e,oar),e(za,rar),e(za,n6e),e(n6e,tar),e(za,aar),e(za,s6e),e(s6e,nar),e(za,sar),e(ho,lar),e(ho,Zr),e(Zr,vF),e(vF,l6e),e(l6e,iar),e(vF,dar),e(vF,qz),e(qz,car),e(vF,far),e(Zr,mar),e(Zr,FF),e(FF,i6e),e(i6e,gar),e(FF,har),e(FF,jz),e(jz,par),e(FF,_ar),e(Zr,uar),e(Zr,TF),e(TF,d6e),e(d6e,bar),e(TF,Far),e(TF,Dz),e(Dz,Tar),e(TF,Mar),e(Zr,Ear),e(Zr,MF),e(MF,c6e),e(c6e,Car),e(MF,war),e(MF,Gz),e(Gz,Aar),e(MF,yar),e(Zr,Lar),e(Zr,EF),e(EF,f6e),e(f6e,xar),e(EF,$ar),e(EF,Oz),e(Oz,kar),e(EF,Sar),e(ho,Rar),e(ho,CF),e(CF,Par),e(CF,m6e),e(m6e,Bar),e(CF,Iar),e(CF,g6e),e(g6e,Nar),e(ho,qar),M(wF,ho,null),b(f,cje,u),b(f,Ad,u),e(Ad,AF),e(AF,h6e),M(DL,h6e,null),e(Ad,jar),e(Ad,p6e),e(p6e,Dar),b(f,fje,u),b(f,Wo,u),M(GL,Wo,null),e(Wo,Gar),e(Wo,yd),e(yd,Oar),e(yd,Vz),e(Vz,Var),e(yd,Xar),e(yd,Xz),e(Xz,zar),e(yd,War),e(Wo,Qar),e(Wo,OL),e(OL,Har),e(OL,_6e),e(_6e,Uar),e(OL,Jar),e(Wo,Yar),e(Wo,Mt),M(VL,Mt,null),e(Mt,Kar),e(Mt,u6e),e(u6e,Zar),e(Mt,enr),e(Mt,Ld),e(Ld,onr),e(Ld,b6e),e(b6e,rnr),e(Ld,tnr),e(Ld,zz),e(zz,anr),e(Ld,nnr),e(Mt,snr),M(yF,Mt,null),e(Wo,lnr),e(Wo,po),M(XL,po,null),e(po,inr),e(po,v6e),e(v6e,dnr),e(po,cnr),e(po,Wa),e(Wa,fnr),e(Wa,F6e),e(F6e,mnr),e(Wa,gnr),e(Wa,T6e),e(T6e,hnr),e(Wa,pnr),e(Wa,M6e),e(M6e,_nr),e(Wa,unr),e(po,bnr),e(po,xd),e(xd,LF),e(LF,E6e),e(E6e,vnr),e(LF,Fnr),e(LF,Wz),e(Wz,Tnr),e(LF,Mnr),e(xd,Enr),e(xd,xF),e(xF,C6e),e(C6e,Cnr),e(xF,wnr),e(xF,Qz),e(Qz,Anr),e(xF,ynr),e(xd,Lnr),e(xd,$F),e($F,w6e),e(w6e,xnr),e($F,$nr),e($F,Hz),e(Hz,knr),e($F,Snr),e(po,Rnr),e(po,kF),e(kF,Pnr),e(kF,A6e),e(A6e,Bnr),e(kF,Inr),e(kF,y6e),e(y6e,Nnr),e(po,qnr),M(SF,po,null),b(f,mje,u),b(f,$d,u),e($d,RF),e(RF,L6e),M(zL,L6e,null),e($d,jnr),e($d,x6e),e(x6e,Dnr),b(f,gje,u),b(f,Qo,u),M(WL,Qo,null),e(Qo,Gnr),e(Qo,kd),e(kd,Onr),e(kd,Uz),e(Uz,Vnr),e(kd,Xnr),e(kd,Jz),e(Jz,znr),e(kd,Wnr),e(Qo,Qnr),e(Qo,QL),e(QL,Hnr),e(QL,$6e),e($6e,Unr),e(QL,Jnr),e(Qo,Ynr),e(Qo,Et),M(HL,Et,null),e(Et,Knr),e(Et,k6e),e(k6e,Znr),e(Et,esr),e(Et,Sd),e(Sd,osr),e(Sd,S6e),e(S6e,rsr),e(Sd,tsr),e(Sd,Yz),e(Yz,asr),e(Sd,nsr),e(Et,ssr),M(PF,Et,null),e(Qo,lsr),e(Qo,_o),M(UL,_o,null),e(_o,isr),e(_o,R6e),e(R6e,dsr),e(_o,csr),e(_o,Qa),e(Qa,fsr),e(Qa,P6e),e(P6e,msr),e(Qa,gsr),e(Qa,B6e),e(B6e,hsr),e(Qa,psr),e(Qa,I6e),e(I6e,_sr),e(Qa,usr),e(_o,bsr),e(_o,JL),e(JL,BF),e(BF,N6e),e(N6e,vsr),e(BF,Fsr),e(BF,Kz),e(Kz,Tsr),e(BF,Msr),e(JL,Esr),e(JL,IF),e(IF,q6e),e(q6e,Csr),e(IF,wsr),e(IF,Zz),e(Zz,Asr),e(IF,ysr),e(_o,Lsr),e(_o,NF),e(NF,xsr),e(NF,j6e),e(j6e,$sr),e(NF,ksr),e(NF,D6e),e(D6e,Ssr),e(_o,Rsr),M(qF,_o,null),b(f,hje,u),b(f,Rd,u),e(Rd,jF),e(jF,G6e),M(YL,G6e,null),e(Rd,Psr),e(Rd,O6e),e(O6e,Bsr),b(f,pje,u),b(f,Ho,u),M(KL,Ho,null),e(Ho,Isr),e(Ho,Pd),e(Pd,Nsr),e(Pd,eW),e(eW,qsr),e(Pd,jsr),e(Pd,oW),e(oW,Dsr),e(Pd,Gsr),e(Ho,Osr),e(Ho,ZL),e(ZL,Vsr),e(ZL,V6e),e(V6e,Xsr),e(ZL,zsr),e(Ho,Wsr),e(Ho,Ct),M(e8,Ct,null),e(Ct,Qsr),e(Ct,X6e),e(X6e,Hsr),e(Ct,Usr),e(Ct,Bd),e(Bd,Jsr),e(Bd,z6e),e(z6e,Ysr),e(Bd,Ksr),e(Bd,rW),e(rW,Zsr),e(Bd,elr),e(Ct,olr),M(DF,Ct,null),e(Ho,rlr),e(Ho,uo),M(o8,uo,null),e(uo,tlr),e(uo,W6e),e(W6e,alr),e(uo,nlr),e(uo,Ha),e(Ha,slr),e(Ha,Q6e),e(Q6e,llr),e(Ha,ilr),e(Ha,H6e),e(H6e,dlr),e(Ha,clr),e(Ha,U6e),e(U6e,flr),e(Ha,mlr),e(uo,glr),e(uo,J6e),e(J6e,GF),e(GF,Y6e),e(Y6e,hlr),e(GF,plr),e(GF,tW),e(tW,_lr),e(GF,ulr),e(uo,blr),e(uo,OF),e(OF,vlr),e(OF,K6e),e(K6e,Flr),e(OF,Tlr),e(OF,Z6e),e(Z6e,Mlr),e(uo,Elr),M(VF,uo,null),b(f,_je,u),b(f,Id,u),e(Id,XF),e(XF,e1e),M(r8,e1e,null),e(Id,Clr),e(Id,o1e),e(o1e,wlr),b(f,uje,u),b(f,Uo,u),M(t8,Uo,null),e(Uo,Alr),e(Uo,Nd),e(Nd,ylr),e(Nd,aW),e(aW,Llr),e(Nd,xlr),e(Nd,nW),e(nW,$lr),e(Nd,klr),e(Uo,Slr),e(Uo,a8),e(a8,Rlr),e(a8,r1e),e(r1e,Plr),e(a8,Blr),e(Uo,Ilr),e(Uo,wt),M(n8,wt,null),e(wt,Nlr),e(wt,t1e),e(t1e,qlr),e(wt,jlr),e(wt,qd),e(qd,Dlr),e(qd,a1e),e(a1e,Glr),e(qd,Olr),e(qd,sW),e(sW,Vlr),e(qd,Xlr),e(wt,zlr),M(zF,wt,null),e(Uo,Wlr),e(Uo,bo),M(s8,bo,null),e(bo,Qlr),e(bo,n1e),e(n1e,Hlr),e(bo,Ulr),e(bo,Ua),e(Ua,Jlr),e(Ua,s1e),e(s1e,Ylr),e(Ua,Klr),e(Ua,l1e),e(l1e,Zlr),e(Ua,eir),e(Ua,i1e),e(i1e,oir),e(Ua,rir),e(bo,tir),e(bo,Ja),e(Ja,WF),e(WF,d1e),e(d1e,air),e(WF,nir),e(WF,lW),e(lW,sir),e(WF,lir),e(Ja,iir),e(Ja,QF),e(QF,c1e),e(c1e,dir),e(QF,cir),e(QF,iW),e(iW,fir),e(QF,mir),e(Ja,gir),e(Ja,HF),e(HF,f1e),e(f1e,hir),e(HF,pir),e(HF,dW),e(dW,_ir),e(HF,uir),e(Ja,bir),e(Ja,UF),e(UF,m1e),e(m1e,vir),e(UF,Fir),e(UF,cW),e(cW,Tir),e(UF,Mir),e(bo,Eir),e(bo,JF),e(JF,Cir),e(JF,g1e),e(g1e,wir),e(JF,Air),e(JF,h1e),e(h1e,yir),e(bo,Lir),M(YF,bo,null),b(f,bje,u),b(f,jd,u),e(jd,KF),e(KF,p1e),M(l8,p1e,null),e(jd,xir),e(jd,_1e),e(_1e,$ir),b(f,vje,u),b(f,Jo,u),M(i8,Jo,null),e(Jo,kir),e(Jo,Dd),e(Dd,Sir),e(Dd,fW),e(fW,Rir),e(Dd,Pir),e(Dd,mW),e(mW,Bir),e(Dd,Iir),e(Jo,Nir),e(Jo,d8),e(d8,qir),e(d8,u1e),e(u1e,jir),e(d8,Dir),e(Jo,Gir),e(Jo,At),M(c8,At,null),e(At,Oir),e(At,b1e),e(b1e,Vir),e(At,Xir),e(At,Gd),e(Gd,zir),e(Gd,v1e),e(v1e,Wir),e(Gd,Qir),e(Gd,gW),e(gW,Hir),e(Gd,Uir),e(At,Jir),M(ZF,At,null),e(Jo,Yir),e(Jo,vo),M(f8,vo,null),e(vo,Kir),e(vo,F1e),e(F1e,Zir),e(vo,edr),e(vo,Ya),e(Ya,odr),e(Ya,T1e),e(T1e,rdr),e(Ya,tdr),e(Ya,M1e),e(M1e,adr),e(Ya,ndr),e(Ya,E1e),e(E1e,sdr),e(Ya,ldr),e(vo,idr),e(vo,C1e),e(C1e,eT),e(eT,w1e),e(w1e,ddr),e(eT,cdr),e(eT,hW),e(hW,fdr),e(eT,mdr),e(vo,gdr),e(vo,oT),e(oT,hdr),e(oT,A1e),e(A1e,pdr),e(oT,_dr),e(oT,y1e),e(y1e,udr),e(vo,bdr),M(rT,vo,null),b(f,Fje,u),b(f,Od,u),e(Od,tT),e(tT,L1e),M(m8,L1e,null),e(Od,vdr),e(Od,x1e),e(x1e,Fdr),b(f,Tje,u),b(f,Yo,u),M(g8,Yo,null),e(Yo,Tdr),e(Yo,Vd),e(Vd,Mdr),e(Vd,pW),e(pW,Edr),e(Vd,Cdr),e(Vd,_W),e(_W,wdr),e(Vd,Adr),e(Yo,ydr),e(Yo,h8),e(h8,Ldr),e(h8,$1e),e($1e,xdr),e(h8,$dr),e(Yo,kdr),e(Yo,yt),M(p8,yt,null),e(yt,Sdr),e(yt,k1e),e(k1e,Rdr),e(yt,Pdr),e(yt,Xd),e(Xd,Bdr),e(Xd,S1e),e(S1e,Idr),e(Xd,Ndr),e(Xd,uW),e(uW,qdr),e(Xd,jdr),e(yt,Ddr),M(aT,yt,null),e(Yo,Gdr),e(Yo,wr),M(_8,wr,null),e(wr,Odr),e(wr,R1e),e(R1e,Vdr),e(wr,Xdr),e(wr,Ka),e(Ka,zdr),e(Ka,P1e),e(P1e,Wdr),e(Ka,Qdr),e(Ka,B1e),e(B1e,Hdr),e(Ka,Udr),e(Ka,I1e),e(I1e,Jdr),e(Ka,Ydr),e(wr,Kdr),e(wr,q),e(q,nT),e(nT,N1e),e(N1e,Zdr),e(nT,ecr),e(nT,bW),e(bW,ocr),e(nT,rcr),e(q,tcr),e(q,sT),e(sT,q1e),e(q1e,acr),e(sT,ncr),e(sT,vW),e(vW,scr),e(sT,lcr),e(q,icr),e(q,lT),e(lT,j1e),e(j1e,dcr),e(lT,ccr),e(lT,FW),e(FW,fcr),e(lT,mcr),e(q,gcr),e(q,iT),e(iT,D1e),e(D1e,hcr),e(iT,pcr),e(iT,TW),e(TW,_cr),e(iT,ucr),e(q,bcr),e(q,dT),e(dT,G1e),e(G1e,vcr),e(dT,Fcr),e(dT,MW),e(MW,Tcr),e(dT,Mcr),e(q,Ecr),e(q,cT),e(cT,O1e),e(O1e,Ccr),e(cT,wcr),e(cT,EW),e(EW,Acr),e(cT,ycr),e(q,Lcr),e(q,fT),e(fT,V1e),e(V1e,xcr),e(fT,$cr),e(fT,CW),e(CW,kcr),e(fT,Scr),e(q,Rcr),e(q,mT),e(mT,X1e),e(X1e,Pcr),e(mT,Bcr),e(mT,wW),e(wW,Icr),e(mT,Ncr),e(q,qcr),e(q,gT),e(gT,z1e),e(z1e,jcr),e(gT,Dcr),e(gT,AW),e(AW,Gcr),e(gT,Ocr),e(q,Vcr),e(q,hT),e(hT,W1e),e(W1e,Xcr),e(hT,zcr),e(hT,yW),e(yW,Wcr),e(hT,Qcr),e(q,Hcr),e(q,pT),e(pT,Q1e),e(Q1e,Ucr),e(pT,Jcr),e(pT,LW),e(LW,Ycr),e(pT,Kcr),e(q,Zcr),e(q,_T),e(_T,H1e),e(H1e,efr),e(_T,ofr),e(_T,xW),e(xW,rfr),e(_T,tfr),e(q,afr),e(q,uT),e(uT,U1e),e(U1e,nfr),e(uT,sfr),e(uT,$W),e($W,lfr),e(uT,ifr),e(q,dfr),e(q,bT),e(bT,J1e),e(J1e,cfr),e(bT,ffr),e(bT,kW),e(kW,mfr),e(bT,gfr),e(q,hfr),e(q,vT),e(vT,Y1e),e(Y1e,pfr),e(vT,_fr),e(vT,SW),e(SW,ufr),e(vT,bfr),e(q,vfr),e(q,FT),e(FT,K1e),e(K1e,Ffr),e(FT,Tfr),e(FT,RW),e(RW,Mfr),e(FT,Efr),e(q,Cfr),e(q,TT),e(TT,Z1e),e(Z1e,wfr),e(TT,Afr),e(TT,PW),e(PW,yfr),e(TT,Lfr),e(q,xfr),e(q,Ns),e(Ns,ebe),e(ebe,$fr),e(Ns,kfr),e(Ns,BW),e(BW,Sfr),e(Ns,Rfr),e(Ns,IW),e(IW,Pfr),e(Ns,Bfr),e(q,Ifr),e(q,MT),e(MT,obe),e(obe,Nfr),e(MT,qfr),e(MT,NW),e(NW,jfr),e(MT,Dfr),e(q,Gfr),e(q,ET),e(ET,rbe),e(rbe,Ofr),e(ET,Vfr),e(ET,qW),e(qW,Xfr),e(ET,zfr),e(q,Wfr),e(q,CT),e(CT,tbe),e(tbe,Qfr),e(CT,Hfr),e(CT,jW),e(jW,Ufr),e(CT,Jfr),e(q,Yfr),e(q,wT),e(wT,abe),e(abe,Kfr),e(wT,Zfr),e(wT,DW),e(DW,emr),e(wT,omr),e(q,rmr),e(q,AT),e(AT,nbe),e(nbe,tmr),e(AT,amr),e(AT,GW),e(GW,nmr),e(AT,smr),e(q,lmr),e(q,yT),e(yT,sbe),e(sbe,imr),e(yT,dmr),e(yT,OW),e(OW,cmr),e(yT,fmr),e(q,mmr),e(q,LT),e(LT,lbe),e(lbe,gmr),e(LT,hmr),e(LT,VW),e(VW,pmr),e(LT,_mr),e(q,umr),e(q,xT),e(xT,ibe),e(ibe,bmr),e(xT,vmr),e(xT,XW),e(XW,Fmr),e(xT,Tmr),e(q,Mmr),e(q,$T),e($T,dbe),e(dbe,Emr),e($T,Cmr),e($T,zW),e(zW,wmr),e($T,Amr),e(q,ymr),e(q,kT),e(kT,cbe),e(cbe,Lmr),e(kT,xmr),e(kT,WW),e(WW,$mr),e(kT,kmr),e(q,Smr),e(q,ST),e(ST,fbe),e(fbe,Rmr),e(ST,Pmr),e(ST,QW),e(QW,Bmr),e(ST,Imr),e(q,Nmr),e(q,RT),e(RT,mbe),e(mbe,qmr),e(RT,jmr),e(RT,HW),e(HW,Dmr),e(RT,Gmr),e(q,Omr),e(q,PT),e(PT,gbe),e(gbe,Vmr),e(PT,Xmr),e(PT,UW),e(UW,zmr),e(PT,Wmr),e(q,Qmr),e(q,BT),e(BT,hbe),e(hbe,Hmr),e(BT,Umr),e(BT,JW),e(JW,Jmr),e(BT,Ymr),e(q,Kmr),e(q,IT),e(IT,pbe),e(pbe,Zmr),e(IT,egr),e(IT,YW),e(YW,ogr),e(IT,rgr),e(q,tgr),e(q,NT),e(NT,_be),e(_be,agr),e(NT,ngr),e(NT,KW),e(KW,sgr),e(NT,lgr),e(q,igr),e(q,qT),e(qT,ube),e(ube,dgr),e(qT,cgr),e(qT,ZW),e(ZW,fgr),e(qT,mgr),e(q,ggr),e(q,jT),e(jT,bbe),e(bbe,hgr),e(jT,pgr),e(jT,eQ),e(eQ,_gr),e(jT,ugr),e(q,bgr),e(q,DT),e(DT,vbe),e(vbe,vgr),e(DT,Fgr),e(DT,oQ),e(oQ,Tgr),e(DT,Mgr),e(q,Egr),e(q,GT),e(GT,Fbe),e(Fbe,Cgr),e(GT,wgr),e(GT,rQ),e(rQ,Agr),e(GT,ygr),e(q,Lgr),e(q,OT),e(OT,Tbe),e(Tbe,xgr),e(OT,$gr),e(OT,tQ),e(tQ,kgr),e(OT,Sgr),e(q,Rgr),e(q,VT),e(VT,Mbe),e(Mbe,Pgr),e(VT,Bgr),e(VT,aQ),e(aQ,Igr),e(VT,Ngr),e(q,qgr),e(q,XT),e(XT,Ebe),e(Ebe,jgr),e(XT,Dgr),e(XT,nQ),e(nQ,Ggr),e(XT,Ogr),e(q,Vgr),e(q,zT),e(zT,Cbe),e(Cbe,Xgr),e(zT,zgr),e(zT,sQ),e(sQ,Wgr),e(zT,Qgr),e(q,Hgr),e(q,WT),e(WT,wbe),e(wbe,Ugr),e(WT,Jgr),e(WT,lQ),e(lQ,Ygr),e(WT,Kgr),e(q,Zgr),e(q,QT),e(QT,Abe),e(Abe,ehr),e(QT,ohr),e(QT,iQ),e(iQ,rhr),e(QT,thr),e(q,ahr),e(q,HT),e(HT,ybe),e(ybe,nhr),e(HT,shr),e(HT,dQ),e(dQ,lhr),e(HT,ihr),e(q,dhr),e(q,UT),e(UT,Lbe),e(Lbe,chr),e(UT,fhr),e(UT,cQ),e(cQ,mhr),e(UT,ghr),e(wr,hhr),M(JT,wr,null),b(f,Mje,u),b(f,zd,u),e(zd,YT),e(YT,xbe),M(u8,xbe,null),e(zd,phr),e(zd,$be),e($be,_hr),b(f,Eje,u),b(f,Ko,u),M(b8,Ko,null),e(Ko,uhr),e(Ko,Wd),e(Wd,bhr),e(Wd,fQ),e(fQ,vhr),e(Wd,Fhr),e(Wd,mQ),e(mQ,Thr),e(Wd,Mhr),e(Ko,Ehr),e(Ko,v8),e(v8,Chr),e(v8,kbe),e(kbe,whr),e(v8,Ahr),e(Ko,yhr),e(Ko,Lt),M(F8,Lt,null),e(Lt,Lhr),e(Lt,Sbe),e(Sbe,xhr),e(Lt,$hr),e(Lt,Qd),e(Qd,khr),e(Qd,Rbe),e(Rbe,Shr),e(Qd,Rhr),e(Qd,gQ),e(gQ,Phr),e(Qd,Bhr),e(Lt,Ihr),M(KT,Lt,null),e(Ko,Nhr),e(Ko,Ar),M(T8,Ar,null),e(Ar,qhr),e(Ar,Pbe),e(Pbe,jhr),e(Ar,Dhr),e(Ar,Za),e(Za,Ghr),e(Za,Bbe),e(Bbe,Ohr),e(Za,Vhr),e(Za,Ibe),e(Ibe,Xhr),e(Za,zhr),e(Za,Nbe),e(Nbe,Whr),e(Za,Qhr),e(Ar,Hhr),e(Ar,se),e(se,ZT),e(ZT,qbe),e(qbe,Uhr),e(ZT,Jhr),e(ZT,hQ),e(hQ,Yhr),e(ZT,Khr),e(se,Zhr),e(se,e7),e(e7,jbe),e(jbe,epr),e(e7,opr),e(e7,pQ),e(pQ,rpr),e(e7,tpr),e(se,apr),e(se,o7),e(o7,Dbe),e(Dbe,npr),e(o7,spr),e(o7,_Q),e(_Q,lpr),e(o7,ipr),e(se,dpr),e(se,r7),e(r7,Gbe),e(Gbe,cpr),e(r7,fpr),e(r7,uQ),e(uQ,mpr),e(r7,gpr),e(se,hpr),e(se,t7),e(t7,Obe),e(Obe,ppr),e(t7,_pr),e(t7,bQ),e(bQ,upr),e(t7,bpr),e(se,vpr),e(se,a7),e(a7,Vbe),e(Vbe,Fpr),e(a7,Tpr),e(a7,vQ),e(vQ,Mpr),e(a7,Epr),e(se,Cpr),e(se,n7),e(n7,Xbe),e(Xbe,wpr),e(n7,Apr),e(n7,FQ),e(FQ,ypr),e(n7,Lpr),e(se,xpr),e(se,s7),e(s7,zbe),e(zbe,$pr),e(s7,kpr),e(s7,TQ),e(TQ,Spr),e(s7,Rpr),e(se,Ppr),e(se,l7),e(l7,Wbe),e(Wbe,Bpr),e(l7,Ipr),e(l7,MQ),e(MQ,Npr),e(l7,qpr),e(se,jpr),e(se,i7),e(i7,Qbe),e(Qbe,Dpr),e(i7,Gpr),e(i7,EQ),e(EQ,Opr),e(i7,Vpr),e(se,Xpr),e(se,d7),e(d7,Hbe),e(Hbe,zpr),e(d7,Wpr),e(d7,CQ),e(CQ,Qpr),e(d7,Hpr),e(se,Upr),e(se,c7),e(c7,Ube),e(Ube,Jpr),e(c7,Ypr),e(c7,wQ),e(wQ,Kpr),e(c7,Zpr),e(se,e_r),e(se,f7),e(f7,Jbe),e(Jbe,o_r),e(f7,r_r),e(f7,AQ),e(AQ,t_r),e(f7,a_r),e(se,n_r),e(se,m7),e(m7,Ybe),e(Ybe,s_r),e(m7,l_r),e(m7,yQ),e(yQ,i_r),e(m7,d_r),e(se,c_r),e(se,g7),e(g7,Kbe),e(Kbe,f_r),e(g7,m_r),e(g7,LQ),e(LQ,g_r),e(g7,h_r),e(se,p_r),e(se,h7),e(h7,Zbe),e(Zbe,__r),e(h7,u_r),e(h7,xQ),e(xQ,b_r),e(h7,v_r),e(se,F_r),e(se,p7),e(p7,e2e),e(e2e,T_r),e(p7,M_r),e(p7,$Q),e($Q,E_r),e(p7,C_r),e(se,w_r),e(se,_7),e(_7,o2e),e(o2e,A_r),e(_7,y_r),e(_7,kQ),e(kQ,L_r),e(_7,x_r),e(se,$_r),e(se,u7),e(u7,r2e),e(r2e,k_r),e(u7,S_r),e(u7,SQ),e(SQ,R_r),e(u7,P_r),e(se,B_r),e(se,b7),e(b7,t2e),e(t2e,I_r),e(b7,N_r),e(b7,RQ),e(RQ,q_r),e(b7,j_r),e(se,D_r),e(se,v7),e(v7,a2e),e(a2e,G_r),e(v7,O_r),e(v7,PQ),e(PQ,V_r),e(v7,X_r),e(se,z_r),e(se,F7),e(F7,n2e),e(n2e,W_r),e(F7,Q_r),e(F7,BQ),e(BQ,H_r),e(F7,U_r),e(se,J_r),e(se,T7),e(T7,s2e),e(s2e,Y_r),e(T7,K_r),e(T7,IQ),e(IQ,Z_r),e(T7,eur),e(Ar,our),M(M7,Ar,null),b(f,Cje,u),b(f,Hd,u),e(Hd,E7),e(E7,l2e),M(M8,l2e,null),e(Hd,rur),e(Hd,i2e),e(i2e,tur),b(f,wje,u),b(f,Zo,u),M(E8,Zo,null),e(Zo,aur),e(Zo,Ud),e(Ud,nur),e(Ud,NQ),e(NQ,sur),e(Ud,lur),e(Ud,qQ),e(qQ,iur),e(Ud,dur),e(Zo,cur),e(Zo,C8),e(C8,fur),e(C8,d2e),e(d2e,mur),e(C8,gur),e(Zo,hur),e(Zo,xt),M(w8,xt,null),e(xt,pur),e(xt,c2e),e(c2e,_ur),e(xt,uur),e(xt,Jd),e(Jd,bur),e(Jd,f2e),e(f2e,vur),e(Jd,Fur),e(Jd,jQ),e(jQ,Tur),e(Jd,Mur),e(xt,Eur),M(C7,xt,null),e(Zo,Cur),e(Zo,yr),M(A8,yr,null),e(yr,wur),e(yr,m2e),e(m2e,Aur),e(yr,yur),e(yr,en),e(en,Lur),e(en,g2e),e(g2e,xur),e(en,$ur),e(en,h2e),e(h2e,kur),e(en,Sur),e(en,p2e),e(p2e,Rur),e(en,Pur),e(yr,Bur),e(yr,Me),e(Me,w7),e(w7,_2e),e(_2e,Iur),e(w7,Nur),e(w7,DQ),e(DQ,qur),e(w7,jur),e(Me,Dur),e(Me,A7),e(A7,u2e),e(u2e,Gur),e(A7,Our),e(A7,GQ),e(GQ,Vur),e(A7,Xur),e(Me,zur),e(Me,y7),e(y7,b2e),e(b2e,Wur),e(y7,Qur),e(y7,OQ),e(OQ,Hur),e(y7,Uur),e(Me,Jur),e(Me,L7),e(L7,v2e),e(v2e,Yur),e(L7,Kur),e(L7,VQ),e(VQ,Zur),e(L7,e6r),e(Me,o6r),e(Me,x7),e(x7,F2e),e(F2e,r6r),e(x7,t6r),e(x7,XQ),e(XQ,a6r),e(x7,n6r),e(Me,s6r),e(Me,$7),e($7,T2e),e(T2e,l6r),e($7,i6r),e($7,zQ),e(zQ,d6r),e($7,c6r),e(Me,f6r),e(Me,k7),e(k7,M2e),e(M2e,m6r),e(k7,g6r),e(k7,WQ),e(WQ,h6r),e(k7,p6r),e(Me,_6r),e(Me,S7),e(S7,E2e),e(E2e,u6r),e(S7,b6r),e(S7,QQ),e(QQ,v6r),e(S7,F6r),e(Me,T6r),e(Me,R7),e(R7,C2e),e(C2e,M6r),e(R7,E6r),e(R7,HQ),e(HQ,C6r),e(R7,w6r),e(Me,A6r),e(Me,P7),e(P7,w2e),e(w2e,y6r),e(P7,L6r),e(P7,UQ),e(UQ,x6r),e(P7,$6r),e(Me,k6r),e(Me,B7),e(B7,A2e),e(A2e,S6r),e(B7,R6r),e(B7,JQ),e(JQ,P6r),e(B7,B6r),e(Me,I6r),e(Me,I7),e(I7,y2e),e(y2e,N6r),e(I7,q6r),e(I7,YQ),e(YQ,j6r),e(I7,D6r),e(yr,G6r),M(N7,yr,null),b(f,Aje,u),b(f,Yd,u),e(Yd,q7),e(q7,L2e),M(y8,L2e,null),e(Yd,O6r),e(Yd,x2e),e(x2e,V6r),b(f,yje,u),b(f,er,u),M(L8,er,null),e(er,X6r),e(er,Kd),e(Kd,z6r),e(Kd,KQ),e(KQ,W6r),e(Kd,Q6r),e(Kd,ZQ),e(ZQ,H6r),e(Kd,U6r),e(er,J6r),e(er,x8),e(x8,Y6r),e(x8,$2e),e($2e,K6r),e(x8,Z6r),e(er,e1r),e(er,$t),M($8,$t,null),e($t,o1r),e($t,k2e),e(k2e,r1r),e($t,t1r),e($t,Zd),e(Zd,a1r),e(Zd,S2e),e(S2e,n1r),e(Zd,s1r),e(Zd,eH),e(eH,l1r),e(Zd,i1r),e($t,d1r),M(j7,$t,null),e(er,c1r),e(er,Lr),M(k8,Lr,null),e(Lr,f1r),e(Lr,R2e),e(R2e,m1r),e(Lr,g1r),e(Lr,on),e(on,h1r),e(on,P2e),e(P2e,p1r),e(on,_1r),e(on,B2e),e(B2e,u1r),e(on,b1r),e(on,I2e),e(I2e,v1r),e(on,F1r),e(Lr,T1r),e(Lr,rn),e(rn,D7),e(D7,N2e),e(N2e,M1r),e(D7,E1r),e(D7,oH),e(oH,C1r),e(D7,w1r),e(rn,A1r),e(rn,G7),e(G7,q2e),e(q2e,y1r),e(G7,L1r),e(G7,rH),e(rH,x1r),e(G7,$1r),e(rn,k1r),e(rn,O7),e(O7,j2e),e(j2e,S1r),e(O7,R1r),e(O7,tH),e(tH,P1r),e(O7,B1r),e(rn,I1r),e(rn,V7),e(V7,D2e),e(D2e,N1r),e(V7,q1r),e(V7,aH),e(aH,j1r),e(V7,D1r),e(Lr,G1r),M(X7,Lr,null),b(f,Lje,u),b(f,ec,u),e(ec,z7),e(z7,G2e),M(S8,G2e,null),e(ec,O1r),e(ec,O2e),e(O2e,V1r),b(f,xje,u),b(f,or,u),M(R8,or,null),e(or,X1r),e(or,oc),e(oc,z1r),e(oc,nH),e(nH,W1r),e(oc,Q1r),e(oc,sH),e(sH,H1r),e(oc,U1r),e(or,J1r),e(or,P8),e(P8,Y1r),e(P8,V2e),e(V2e,K1r),e(P8,Z1r),e(or,ebr),e(or,kt),M(B8,kt,null),e(kt,obr),e(kt,X2e),e(X2e,rbr),e(kt,tbr),e(kt,rc),e(rc,abr),e(rc,z2e),e(z2e,nbr),e(rc,sbr),e(rc,lH),e(lH,lbr),e(rc,ibr),e(kt,dbr),M(W7,kt,null),e(or,cbr),e(or,xr),M(I8,xr,null),e(xr,fbr),e(xr,W2e),e(W2e,mbr),e(xr,gbr),e(xr,tn),e(tn,hbr),e(tn,Q2e),e(Q2e,pbr),e(tn,_br),e(tn,H2e),e(H2e,ubr),e(tn,bbr),e(tn,U2e),e(U2e,vbr),e(tn,Fbr),e(xr,Tbr),e(xr,ie),e(ie,Q7),e(Q7,J2e),e(J2e,Mbr),e(Q7,Ebr),e(Q7,iH),e(iH,Cbr),e(Q7,wbr),e(ie,Abr),e(ie,H7),e(H7,Y2e),e(Y2e,ybr),e(H7,Lbr),e(H7,dH),e(dH,xbr),e(H7,$br),e(ie,kbr),e(ie,U7),e(U7,K2e),e(K2e,Sbr),e(U7,Rbr),e(U7,cH),e(cH,Pbr),e(U7,Bbr),e(ie,Ibr),e(ie,J7),e(J7,Z2e),e(Z2e,Nbr),e(J7,qbr),e(J7,fH),e(fH,jbr),e(J7,Dbr),e(ie,Gbr),e(ie,Y7),e(Y7,e4e),e(e4e,Obr),e(Y7,Vbr),e(Y7,mH),e(mH,Xbr),e(Y7,zbr),e(ie,Wbr),e(ie,K7),e(K7,o4e),e(o4e,Qbr),e(K7,Hbr),e(K7,gH),e(gH,Ubr),e(K7,Jbr),e(ie,Ybr),e(ie,Z7),e(Z7,r4e),e(r4e,Kbr),e(Z7,Zbr),e(Z7,hH),e(hH,e2r),e(Z7,o2r),e(ie,r2r),e(ie,eM),e(eM,t4e),e(t4e,t2r),e(eM,a2r),e(eM,pH),e(pH,n2r),e(eM,s2r),e(ie,l2r),e(ie,oM),e(oM,a4e),e(a4e,i2r),e(oM,d2r),e(oM,_H),e(_H,c2r),e(oM,f2r),e(ie,m2r),e(ie,rM),e(rM,n4e),e(n4e,g2r),e(rM,h2r),e(rM,uH),e(uH,p2r),e(rM,_2r),e(ie,u2r),e(ie,tM),e(tM,s4e),e(s4e,b2r),e(tM,v2r),e(tM,bH),e(bH,F2r),e(tM,T2r),e(ie,M2r),e(ie,aM),e(aM,l4e),e(l4e,E2r),e(aM,C2r),e(aM,vH),e(vH,w2r),e(aM,A2r),e(ie,y2r),e(ie,nM),e(nM,i4e),e(i4e,L2r),e(nM,x2r),e(nM,FH),e(FH,$2r),e(nM,k2r),e(ie,S2r),e(ie,sM),e(sM,d4e),e(d4e,R2r),e(sM,P2r),e(sM,TH),e(TH,B2r),e(sM,I2r),e(ie,N2r),e(ie,lM),e(lM,c4e),e(c4e,q2r),e(lM,j2r),e(lM,MH),e(MH,D2r),e(lM,G2r),e(ie,O2r),e(ie,iM),e(iM,f4e),e(f4e,V2r),e(iM,X2r),e(iM,EH),e(EH,z2r),e(iM,W2r),e(ie,Q2r),e(ie,dM),e(dM,m4e),e(m4e,H2r),e(dM,U2r),e(dM,CH),e(CH,J2r),e(dM,Y2r),e(ie,K2r),e(ie,cM),e(cM,g4e),e(g4e,Z2r),e(cM,e4r),e(cM,wH),e(wH,o4r),e(cM,r4r),e(ie,t4r),e(ie,fM),e(fM,h4e),e(h4e,a4r),e(fM,n4r),e(fM,AH),e(AH,s4r),e(fM,l4r),e(ie,i4r),e(ie,mM),e(mM,p4e),e(p4e,d4r),e(mM,c4r),e(mM,yH),e(yH,f4r),e(mM,m4r),e(xr,g4r),M(gM,xr,null),b(f,$je,u),b(f,tc,u),e(tc,hM),e(hM,_4e),M(N8,_4e,null),e(tc,h4r),e(tc,u4e),e(u4e,p4r),b(f,kje,u),b(f,rr,u),M(q8,rr,null),e(rr,_4r),e(rr,ac),e(ac,u4r),e(ac,LH),e(LH,b4r),e(ac,v4r),e(ac,xH),e(xH,F4r),e(ac,T4r),e(rr,M4r),e(rr,j8),e(j8,E4r),e(j8,b4e),e(b4e,C4r),e(j8,w4r),e(rr,A4r),e(rr,St),M(D8,St,null),e(St,y4r),e(St,v4e),e(v4e,L4r),e(St,x4r),e(St,nc),e(nc,$4r),e(nc,F4e),e(F4e,k4r),e(nc,S4r),e(nc,$H),e($H,R4r),e(nc,P4r),e(St,B4r),M(pM,St,null),e(rr,I4r),e(rr,$r),M(G8,$r,null),e($r,N4r),e($r,T4e),e(T4e,q4r),e($r,j4r),e($r,an),e(an,D4r),e(an,M4e),e(M4e,G4r),e(an,O4r),e(an,E4e),e(E4e,V4r),e(an,X4r),e(an,C4e),e(C4e,z4r),e(an,W4r),e($r,Q4r),e($r,ye),e(ye,_M),e(_M,w4e),e(w4e,H4r),e(_M,U4r),e(_M,kH),e(kH,J4r),e(_M,Y4r),e(ye,K4r),e(ye,uM),e(uM,A4e),e(A4e,Z4r),e(uM,evr),e(uM,SH),e(SH,ovr),e(uM,rvr),e(ye,tvr),e(ye,bM),e(bM,y4e),e(y4e,avr),e(bM,nvr),e(bM,RH),e(RH,svr),e(bM,lvr),e(ye,ivr),e(ye,vM),e(vM,L4e),e(L4e,dvr),e(vM,cvr),e(vM,PH),e(PH,fvr),e(vM,mvr),e(ye,gvr),e(ye,FM),e(FM,x4e),e(x4e,hvr),e(FM,pvr),e(FM,BH),e(BH,_vr),e(FM,uvr),e(ye,bvr),e(ye,TM),e(TM,$4e),e($4e,vvr),e(TM,Fvr),e(TM,IH),e(IH,Tvr),e(TM,Mvr),e(ye,Evr),e(ye,MM),e(MM,k4e),e(k4e,Cvr),e(MM,wvr),e(MM,NH),e(NH,Avr),e(MM,yvr),e(ye,Lvr),e(ye,EM),e(EM,S4e),e(S4e,xvr),e(EM,$vr),e(EM,qH),e(qH,kvr),e(EM,Svr),e(ye,Rvr),e(ye,CM),e(CM,R4e),e(R4e,Pvr),e(CM,Bvr),e(CM,jH),e(jH,Ivr),e(CM,Nvr),e(ye,qvr),e(ye,wM),e(wM,P4e),e(P4e,jvr),e(wM,Dvr),e(wM,DH),e(DH,Gvr),e(wM,Ovr),e($r,Vvr),M(AM,$r,null),b(f,Sje,u),b(f,sc,u),e(sc,yM),e(yM,B4e),M(O8,B4e,null),e(sc,Xvr),e(sc,I4e),e(I4e,zvr),b(f,Rje,u),b(f,tr,u),M(V8,tr,null),e(tr,Wvr),e(tr,lc),e(lc,Qvr),e(lc,GH),e(GH,Hvr),e(lc,Uvr),e(lc,OH),e(OH,Jvr),e(lc,Yvr),e(tr,Kvr),e(tr,X8),e(X8,Zvr),e(X8,N4e),e(N4e,eFr),e(X8,oFr),e(tr,rFr),e(tr,Rt),M(z8,Rt,null),e(Rt,tFr),e(Rt,q4e),e(q4e,aFr),e(Rt,nFr),e(Rt,ic),e(ic,sFr),e(ic,j4e),e(j4e,lFr),e(ic,iFr),e(ic,VH),e(VH,dFr),e(ic,cFr),e(Rt,fFr),M(LM,Rt,null),e(tr,mFr),e(tr,kr),M(W8,kr,null),e(kr,gFr),e(kr,D4e),e(D4e,hFr),e(kr,pFr),e(kr,nn),e(nn,_Fr),e(nn,G4e),e(G4e,uFr),e(nn,bFr),e(nn,O4e),e(O4e,vFr),e(nn,FFr),e(nn,V4e),e(V4e,TFr),e(nn,MFr),e(kr,EFr),e(kr,oe),e(oe,xM),e(xM,X4e),e(X4e,CFr),e(xM,wFr),e(xM,XH),e(XH,AFr),e(xM,yFr),e(oe,LFr),e(oe,$M),e($M,z4e),e(z4e,xFr),e($M,$Fr),e($M,zH),e(zH,kFr),e($M,SFr),e(oe,RFr),e(oe,kM),e(kM,W4e),e(W4e,PFr),e(kM,BFr),e(kM,WH),e(WH,IFr),e(kM,NFr),e(oe,qFr),e(oe,SM),e(SM,Q4e),e(Q4e,jFr),e(SM,DFr),e(SM,QH),e(QH,GFr),e(SM,OFr),e(oe,VFr),e(oe,RM),e(RM,H4e),e(H4e,XFr),e(RM,zFr),e(RM,HH),e(HH,WFr),e(RM,QFr),e(oe,HFr),e(oe,PM),e(PM,U4e),e(U4e,UFr),e(PM,JFr),e(PM,UH),e(UH,YFr),e(PM,KFr),e(oe,ZFr),e(oe,BM),e(BM,J4e),e(J4e,eTr),e(BM,oTr),e(BM,JH),e(JH,rTr),e(BM,tTr),e(oe,aTr),e(oe,IM),e(IM,Y4e),e(Y4e,nTr),e(IM,sTr),e(IM,YH),e(YH,lTr),e(IM,iTr),e(oe,dTr),e(oe,NM),e(NM,K4e),e(K4e,cTr),e(NM,fTr),e(NM,KH),e(KH,mTr),e(NM,gTr),e(oe,hTr),e(oe,qM),e(qM,Z4e),e(Z4e,pTr),e(qM,_Tr),e(qM,ZH),e(ZH,uTr),e(qM,bTr),e(oe,vTr),e(oe,jM),e(jM,eve),e(eve,FTr),e(jM,TTr),e(jM,eU),e(eU,MTr),e(jM,ETr),e(oe,CTr),e(oe,DM),e(DM,ove),e(ove,wTr),e(DM,ATr),e(DM,oU),e(oU,yTr),e(DM,LTr),e(oe,xTr),e(oe,GM),e(GM,rve),e(rve,$Tr),e(GM,kTr),e(GM,rU),e(rU,STr),e(GM,RTr),e(oe,PTr),e(oe,OM),e(OM,tve),e(tve,BTr),e(OM,ITr),e(OM,tU),e(tU,NTr),e(OM,qTr),e(oe,jTr),e(oe,VM),e(VM,ave),e(ave,DTr),e(VM,GTr),e(VM,aU),e(aU,OTr),e(VM,VTr),e(oe,XTr),e(oe,XM),e(XM,nve),e(nve,zTr),e(XM,WTr),e(XM,nU),e(nU,QTr),e(XM,HTr),e(oe,UTr),e(oe,zM),e(zM,sve),e(sve,JTr),e(zM,YTr),e(zM,sU),e(sU,KTr),e(zM,ZTr),e(oe,e7r),e(oe,WM),e(WM,lve),e(lve,o7r),e(WM,r7r),e(WM,lU),e(lU,t7r),e(WM,a7r),e(oe,n7r),e(oe,QM),e(QM,ive),e(ive,s7r),e(QM,l7r),e(QM,iU),e(iU,i7r),e(QM,d7r),e(oe,c7r),e(oe,HM),e(HM,dve),e(dve,f7r),e(HM,m7r),e(HM,dU),e(dU,g7r),e(HM,h7r),e(oe,p7r),e(oe,UM),e(UM,cve),e(cve,_7r),e(UM,u7r),e(UM,cU),e(cU,b7r),e(UM,v7r),e(oe,F7r),e(oe,JM),e(JM,fve),e(fve,T7r),e(JM,M7r),e(JM,fU),e(fU,E7r),e(JM,C7r),e(oe,w7r),e(oe,YM),e(YM,mve),e(mve,A7r),e(YM,y7r),e(YM,mU),e(mU,L7r),e(YM,x7r),e(oe,$7r),e(oe,KM),e(KM,gve),e(gve,k7r),e(KM,S7r),e(KM,gU),e(gU,R7r),e(KM,P7r),e(oe,B7r),e(oe,ZM),e(ZM,hve),e(hve,I7r),e(ZM,N7r),e(ZM,hU),e(hU,q7r),e(ZM,j7r),e(oe,D7r),e(oe,eE),e(eE,pve),e(pve,G7r),e(eE,O7r),e(eE,pU),e(pU,V7r),e(eE,X7r),e(kr,z7r),M(oE,kr,null),b(f,Pje,u),b(f,dc,u),e(dc,rE),e(rE,_ve),M(Q8,_ve,null),e(dc,W7r),e(dc,uve),e(uve,Q7r),b(f,Bje,u),b(f,ar,u),M(H8,ar,null),e(ar,H7r),e(ar,cc),e(cc,U7r),e(cc,_U),e(_U,J7r),e(cc,Y7r),e(cc,uU),e(uU,K7r),e(cc,Z7r),e(ar,eMr),e(ar,U8),e(U8,oMr),e(U8,bve),e(bve,rMr),e(U8,tMr),e(ar,aMr),e(ar,Pt),M(J8,Pt,null),e(Pt,nMr),e(Pt,vve),e(vve,sMr),e(Pt,lMr),e(Pt,fc),e(fc,iMr),e(fc,Fve),e(Fve,dMr),e(fc,cMr),e(fc,bU),e(bU,fMr),e(fc,mMr),e(Pt,gMr),M(tE,Pt,null),e(ar,hMr),e(ar,Sr),M(Y8,Sr,null),e(Sr,pMr),e(Sr,Tve),e(Tve,_Mr),e(Sr,uMr),e(Sr,sn),e(sn,bMr),e(sn,Mve),e(Mve,vMr),e(sn,FMr),e(sn,Eve),e(Eve,TMr),e(sn,MMr),e(sn,Cve),e(Cve,EMr),e(sn,CMr),e(Sr,wMr),e(Sr,pe),e(pe,aE),e(aE,wve),e(wve,AMr),e(aE,yMr),e(aE,vU),e(vU,LMr),e(aE,xMr),e(pe,$Mr),e(pe,nE),e(nE,Ave),e(Ave,kMr),e(nE,SMr),e(nE,FU),e(FU,RMr),e(nE,PMr),e(pe,BMr),e(pe,sE),e(sE,yve),e(yve,IMr),e(sE,NMr),e(sE,TU),e(TU,qMr),e(sE,jMr),e(pe,DMr),e(pe,lE),e(lE,Lve),e(Lve,GMr),e(lE,OMr),e(lE,MU),e(MU,VMr),e(lE,XMr),e(pe,zMr),e(pe,iE),e(iE,xve),e(xve,WMr),e(iE,QMr),e(iE,EU),e(EU,HMr),e(iE,UMr),e(pe,JMr),e(pe,dE),e(dE,$ve),e($ve,YMr),e(dE,KMr),e(dE,CU),e(CU,ZMr),e(dE,eEr),e(pe,oEr),e(pe,cE),e(cE,kve),e(kve,rEr),e(cE,tEr),e(cE,wU),e(wU,aEr),e(cE,nEr),e(pe,sEr),e(pe,fE),e(fE,Sve),e(Sve,lEr),e(fE,iEr),e(fE,AU),e(AU,dEr),e(fE,cEr),e(pe,fEr),e(pe,mE),e(mE,Rve),e(Rve,mEr),e(mE,gEr),e(mE,yU),e(yU,hEr),e(mE,pEr),e(pe,_Er),e(pe,gE),e(gE,Pve),e(Pve,uEr),e(gE,bEr),e(gE,LU),e(LU,vEr),e(gE,FEr),e(pe,TEr),e(pe,hE),e(hE,Bve),e(Bve,MEr),e(hE,EEr),e(hE,xU),e(xU,CEr),e(hE,wEr),e(pe,AEr),e(pe,pE),e(pE,Ive),e(Ive,yEr),e(pE,LEr),e(pE,$U),e($U,xEr),e(pE,$Er),e(pe,kEr),e(pe,_E),e(_E,Nve),e(Nve,SEr),e(_E,REr),e(_E,kU),e(kU,PEr),e(_E,BEr),e(pe,IEr),e(pe,uE),e(uE,qve),e(qve,NEr),e(uE,qEr),e(uE,SU),e(SU,jEr),e(uE,DEr),e(pe,GEr),e(pe,bE),e(bE,jve),e(jve,OEr),e(bE,VEr),e(bE,RU),e(RU,XEr),e(bE,zEr),e(pe,WEr),e(pe,vE),e(vE,Dve),e(Dve,QEr),e(vE,HEr),e(vE,PU),e(PU,UEr),e(vE,JEr),e(pe,YEr),e(pe,FE),e(FE,Gve),e(Gve,KEr),e(FE,ZEr),e(FE,BU),e(BU,eCr),e(FE,oCr),e(Sr,rCr),M(TE,Sr,null),b(f,Ije,u),b(f,mc,u),e(mc,ME),e(ME,Ove),M(K8,Ove,null),e(mc,tCr),e(mc,Vve),e(Vve,aCr),b(f,Nje,u),b(f,nr,u),M(Z8,nr,null),e(nr,nCr),e(nr,gc),e(gc,sCr),e(gc,IU),e(IU,lCr),e(gc,iCr),e(gc,NU),e(NU,dCr),e(gc,cCr),e(nr,fCr),e(nr,e9),e(e9,mCr),e(e9,Xve),e(Xve,gCr),e(e9,hCr),e(nr,pCr),e(nr,Bt),M(o9,Bt,null),e(Bt,_Cr),e(Bt,zve),e(zve,uCr),e(Bt,bCr),e(Bt,hc),e(hc,vCr),e(hc,Wve),e(Wve,FCr),e(hc,TCr),e(hc,qU),e(qU,MCr),e(hc,ECr),e(Bt,CCr),M(EE,Bt,null),e(nr,wCr),e(nr,Rr),M(r9,Rr,null),e(Rr,ACr),e(Rr,Qve),e(Qve,yCr),e(Rr,LCr),e(Rr,ln),e(ln,xCr),e(ln,Hve),e(Hve,$Cr),e(ln,kCr),e(ln,Uve),e(Uve,SCr),e(ln,RCr),e(ln,Jve),e(Jve,PCr),e(ln,BCr),e(Rr,ICr),e(Rr,t9),e(t9,CE),e(CE,Yve),e(Yve,NCr),e(CE,qCr),e(CE,jU),e(jU,jCr),e(CE,DCr),e(t9,GCr),e(t9,wE),e(wE,Kve),e(Kve,OCr),e(wE,VCr),e(wE,DU),e(DU,XCr),e(wE,zCr),e(Rr,WCr),M(AE,Rr,null),b(f,qje,u),b(f,pc,u),e(pc,yE),e(yE,Zve),M(a9,Zve,null),e(pc,QCr),e(pc,eFe),e(eFe,HCr),b(f,jje,u),b(f,sr,u),M(n9,sr,null),e(sr,UCr),e(sr,_c),e(_c,JCr),e(_c,GU),e(GU,YCr),e(_c,KCr),e(_c,OU),e(OU,ZCr),e(_c,e5r),e(sr,o5r),e(sr,s9),e(s9,r5r),e(s9,oFe),e(oFe,t5r),e(s9,a5r),e(sr,n5r),e(sr,It),M(l9,It,null),e(It,s5r),e(It,rFe),e(rFe,l5r),e(It,i5r),e(It,uc),e(uc,d5r),e(uc,tFe),e(tFe,c5r),e(uc,f5r),e(uc,VU),e(VU,m5r),e(uc,g5r),e(It,h5r),M(LE,It,null),e(sr,p5r),e(sr,Pr),M(i9,Pr,null),e(Pr,_5r),e(Pr,aFe),e(aFe,u5r),e(Pr,b5r),e(Pr,dn),e(dn,v5r),e(dn,nFe),e(nFe,F5r),e(dn,T5r),e(dn,sFe),e(sFe,M5r),e(dn,E5r),e(dn,lFe),e(lFe,C5r),e(dn,w5r),e(Pr,A5r),e(Pr,iFe),e(iFe,xE),e(xE,dFe),e(dFe,y5r),e(xE,L5r),e(xE,XU),e(XU,x5r),e(xE,$5r),e(Pr,k5r),M($E,Pr,null),b(f,Dje,u),b(f,bc,u),e(bc,kE),e(kE,cFe),M(d9,cFe,null),e(bc,S5r),e(bc,fFe),e(fFe,R5r),b(f,Gje,u),b(f,lr,u),M(c9,lr,null),e(lr,P5r),e(lr,vc),e(vc,B5r),e(vc,zU),e(zU,I5r),e(vc,N5r),e(vc,WU),e(WU,q5r),e(vc,j5r),e(lr,D5r),e(lr,f9),e(f9,G5r),e(f9,mFe),e(mFe,O5r),e(f9,V5r),e(lr,X5r),e(lr,Nt),M(m9,Nt,null),e(Nt,z5r),e(Nt,gFe),e(gFe,W5r),e(Nt,Q5r),e(Nt,Fc),e(Fc,H5r),e(Fc,hFe),e(hFe,U5r),e(Fc,J5r),e(Fc,QU),e(QU,Y5r),e(Fc,K5r),e(Nt,Z5r),M(SE,Nt,null),e(lr,e3r),e(lr,Br),M(g9,Br,null),e(Br,o3r),e(Br,pFe),e(pFe,r3r),e(Br,t3r),e(Br,cn),e(cn,a3r),e(cn,_Fe),e(_Fe,n3r),e(cn,s3r),e(cn,uFe),e(uFe,l3r),e(cn,i3r),e(cn,bFe),e(bFe,d3r),e(cn,c3r),e(Br,f3r),e(Br,de),e(de,RE),e(RE,vFe),e(vFe,m3r),e(RE,g3r),e(RE,HU),e(HU,h3r),e(RE,p3r),e(de,_3r),e(de,PE),e(PE,FFe),e(FFe,u3r),e(PE,b3r),e(PE,UU),e(UU,v3r),e(PE,F3r),e(de,T3r),e(de,BE),e(BE,TFe),e(TFe,M3r),e(BE,E3r),e(BE,JU),e(JU,C3r),e(BE,w3r),e(de,A3r),e(de,IE),e(IE,MFe),e(MFe,y3r),e(IE,L3r),e(IE,YU),e(YU,x3r),e(IE,$3r),e(de,k3r),e(de,NE),e(NE,EFe),e(EFe,S3r),e(NE,R3r),e(NE,KU),e(KU,P3r),e(NE,B3r),e(de,I3r),e(de,qE),e(qE,CFe),e(CFe,N3r),e(qE,q3r),e(qE,ZU),e(ZU,j3r),e(qE,D3r),e(de,G3r),e(de,jE),e(jE,wFe),e(wFe,O3r),e(jE,V3r),e(jE,eJ),e(eJ,X3r),e(jE,z3r),e(de,W3r),e(de,DE),e(DE,AFe),e(AFe,Q3r),e(DE,H3r),e(DE,oJ),e(oJ,U3r),e(DE,J3r),e(de,Y3r),e(de,GE),e(GE,yFe),e(yFe,K3r),e(GE,Z3r),e(GE,rJ),e(rJ,ewr),e(GE,owr),e(de,rwr),e(de,OE),e(OE,LFe),e(LFe,twr),e(OE,awr),e(OE,tJ),e(tJ,nwr),e(OE,swr),e(de,lwr),e(de,VE),e(VE,xFe),e(xFe,iwr),e(VE,dwr),e(VE,aJ),e(aJ,cwr),e(VE,fwr),e(de,mwr),e(de,XE),e(XE,$Fe),e($Fe,gwr),e(XE,hwr),e(XE,nJ),e(nJ,pwr),e(XE,_wr),e(de,uwr),e(de,zE),e(zE,kFe),e(kFe,bwr),e(zE,vwr),e(zE,sJ),e(sJ,Fwr),e(zE,Twr),e(de,Mwr),e(de,WE),e(WE,SFe),e(SFe,Ewr),e(WE,Cwr),e(WE,lJ),e(lJ,wwr),e(WE,Awr),e(de,ywr),e(de,QE),e(QE,RFe),e(RFe,Lwr),e(QE,xwr),e(QE,iJ),e(iJ,$wr),e(QE,kwr),e(de,Swr),e(de,HE),e(HE,PFe),e(PFe,Rwr),e(HE,Pwr),e(HE,dJ),e(dJ,Bwr),e(HE,Iwr),e(de,Nwr),e(de,UE),e(UE,BFe),e(BFe,qwr),e(UE,jwr),e(UE,cJ),e(cJ,Dwr),e(UE,Gwr),e(de,Owr),e(de,JE),e(JE,IFe),e(IFe,Vwr),e(JE,Xwr),e(JE,fJ),e(fJ,zwr),e(JE,Wwr),e(de,Qwr),e(de,YE),e(YE,NFe),e(NFe,Hwr),e(YE,Uwr),e(YE,mJ),e(mJ,Jwr),e(YE,Ywr),e(de,Kwr),e(de,KE),e(KE,qFe),e(qFe,Zwr),e(KE,e0r),e(KE,gJ),e(gJ,o0r),e(KE,r0r),e(Br,t0r),M(ZE,Br,null),b(f,Oje,u),b(f,Tc,u),e(Tc,eC),e(eC,jFe),M(h9,jFe,null),e(Tc,a0r),e(Tc,DFe),e(DFe,n0r),b(f,Vje,u),b(f,ir,u),M(p9,ir,null),e(ir,s0r),e(ir,Mc),e(Mc,l0r),e(Mc,hJ),e(hJ,i0r),e(Mc,d0r),e(Mc,pJ),e(pJ,c0r),e(Mc,f0r),e(ir,m0r),e(ir,_9),e(_9,g0r),e(_9,GFe),e(GFe,h0r),e(_9,p0r),e(ir,_0r),e(ir,qt),M(u9,qt,null),e(qt,u0r),e(qt,OFe),e(OFe,b0r),e(qt,v0r),e(qt,Ec),e(Ec,F0r),e(Ec,VFe),e(VFe,T0r),e(Ec,M0r),e(Ec,_J),e(_J,E0r),e(Ec,C0r),e(qt,w0r),M(oC,qt,null),e(ir,A0r),e(ir,Ir),M(b9,Ir,null),e(Ir,y0r),e(Ir,XFe),e(XFe,L0r),e(Ir,x0r),e(Ir,fn),e(fn,$0r),e(fn,zFe),e(zFe,k0r),e(fn,S0r),e(fn,WFe),e(WFe,R0r),e(fn,P0r),e(fn,QFe),e(QFe,B0r),e(fn,I0r),e(Ir,N0r),e(Ir,ce),e(ce,rC),e(rC,HFe),e(HFe,q0r),e(rC,j0r),e(rC,uJ),e(uJ,D0r),e(rC,G0r),e(ce,O0r),e(ce,tC),e(tC,UFe),e(UFe,V0r),e(tC,X0r),e(tC,bJ),e(bJ,z0r),e(tC,W0r),e(ce,Q0r),e(ce,aC),e(aC,JFe),e(JFe,H0r),e(aC,U0r),e(aC,vJ),e(vJ,J0r),e(aC,Y0r),e(ce,K0r),e(ce,nC),e(nC,YFe),e(YFe,Z0r),e(nC,eAr),e(nC,FJ),e(FJ,oAr),e(nC,rAr),e(ce,tAr),e(ce,sC),e(sC,KFe),e(KFe,aAr),e(sC,nAr),e(sC,TJ),e(TJ,sAr),e(sC,lAr),e(ce,iAr),e(ce,lC),e(lC,ZFe),e(ZFe,dAr),e(lC,cAr),e(lC,MJ),e(MJ,fAr),e(lC,mAr),e(ce,gAr),e(ce,iC),e(iC,eTe),e(eTe,hAr),e(iC,pAr),e(iC,EJ),e(EJ,_Ar),e(iC,uAr),e(ce,bAr),e(ce,dC),e(dC,oTe),e(oTe,vAr),e(dC,FAr),e(dC,CJ),e(CJ,TAr),e(dC,MAr),e(ce,EAr),e(ce,cC),e(cC,rTe),e(rTe,CAr),e(cC,wAr),e(cC,wJ),e(wJ,AAr),e(cC,yAr),e(ce,LAr),e(ce,fC),e(fC,tTe),e(tTe,xAr),e(fC,$Ar),e(fC,AJ),e(AJ,kAr),e(fC,SAr),e(ce,RAr),e(ce,mC),e(mC,aTe),e(aTe,PAr),e(mC,BAr),e(mC,yJ),e(yJ,IAr),e(mC,NAr),e(ce,qAr),e(ce,gC),e(gC,nTe),e(nTe,jAr),e(gC,DAr),e(gC,LJ),e(LJ,GAr),e(gC,OAr),e(ce,VAr),e(ce,hC),e(hC,sTe),e(sTe,XAr),e(hC,zAr),e(hC,xJ),e(xJ,WAr),e(hC,QAr),e(ce,HAr),e(ce,pC),e(pC,lTe),e(lTe,UAr),e(pC,JAr),e(pC,$J),e($J,YAr),e(pC,KAr),e(ce,ZAr),e(ce,_C),e(_C,iTe),e(iTe,eyr),e(_C,oyr),e(_C,kJ),e(kJ,ryr),e(_C,tyr),e(ce,ayr),e(ce,uC),e(uC,dTe),e(dTe,nyr),e(uC,syr),e(uC,SJ),e(SJ,lyr),e(uC,iyr),e(ce,dyr),e(ce,bC),e(bC,cTe),e(cTe,cyr),e(bC,fyr),e(bC,RJ),e(RJ,myr),e(bC,gyr),e(ce,hyr),e(ce,vC),e(vC,fTe),e(fTe,pyr),e(vC,_yr),e(vC,PJ),e(PJ,uyr),e(vC,byr),e(ce,vyr),e(ce,FC),e(FC,mTe),e(mTe,Fyr),e(FC,Tyr),e(FC,BJ),e(BJ,Myr),e(FC,Eyr),e(ce,Cyr),e(ce,TC),e(TC,gTe),e(gTe,wyr),e(TC,Ayr),e(TC,IJ),e(IJ,yyr),e(TC,Lyr),e(Ir,xyr),M(MC,Ir,null),b(f,Xje,u),b(f,Cc,u),e(Cc,EC),e(EC,hTe),M(v9,hTe,null),e(Cc,$yr),e(Cc,pTe),e(pTe,kyr),b(f,zje,u),b(f,dr,u),M(F9,dr,null),e(dr,Syr),e(dr,wc),e(wc,Ryr),e(wc,NJ),e(NJ,Pyr),e(wc,Byr),e(wc,qJ),e(qJ,Iyr),e(wc,Nyr),e(dr,qyr),e(dr,T9),e(T9,jyr),e(T9,_Te),e(_Te,Dyr),e(T9,Gyr),e(dr,Oyr),e(dr,jt),M(M9,jt,null),e(jt,Vyr),e(jt,uTe),e(uTe,Xyr),e(jt,zyr),e(jt,Ac),e(Ac,Wyr),e(Ac,bTe),e(bTe,Qyr),e(Ac,Hyr),e(Ac,jJ),e(jJ,Uyr),e(Ac,Jyr),e(jt,Yyr),M(CC,jt,null),e(dr,Kyr),e(dr,Nr),M(E9,Nr,null),e(Nr,Zyr),e(Nr,vTe),e(vTe,eLr),e(Nr,oLr),e(Nr,mn),e(mn,rLr),e(mn,FTe),e(FTe,tLr),e(mn,aLr),e(mn,TTe),e(TTe,nLr),e(mn,sLr),e(mn,MTe),e(MTe,lLr),e(mn,iLr),e(Nr,dLr),e(Nr,ETe),e(ETe,wC),e(wC,CTe),e(CTe,cLr),e(wC,fLr),e(wC,DJ),e(DJ,mLr),e(wC,gLr),e(Nr,hLr),M(AC,Nr,null),b(f,Wje,u),b(f,yc,u),e(yc,yC),e(yC,wTe),M(C9,wTe,null),e(yc,pLr),e(yc,ATe),e(ATe,_Lr),b(f,Qje,u),b(f,cr,u),M(w9,cr,null),e(cr,uLr),e(cr,Lc),e(Lc,bLr),e(Lc,GJ),e(GJ,vLr),e(Lc,FLr),e(Lc,OJ),e(OJ,TLr),e(Lc,MLr),e(cr,ELr),e(cr,A9),e(A9,CLr),e(A9,yTe),e(yTe,wLr),e(A9,ALr),e(cr,yLr),e(cr,Dt),M(y9,Dt,null),e(Dt,LLr),e(Dt,LTe),e(LTe,xLr),e(Dt,$Lr),e(Dt,xc),e(xc,kLr),e(xc,xTe),e(xTe,SLr),e(xc,RLr),e(xc,VJ),e(VJ,PLr),e(xc,BLr),e(Dt,ILr),M(LC,Dt,null),e(cr,NLr),e(cr,qr),M(L9,qr,null),e(qr,qLr),e(qr,$Te),e($Te,jLr),e(qr,DLr),e(qr,gn),e(gn,GLr),e(gn,kTe),e(kTe,OLr),e(gn,VLr),e(gn,STe),e(STe,XLr),e(gn,zLr),e(gn,RTe),e(RTe,WLr),e(gn,QLr),e(qr,HLr),e(qr,PTe),e(PTe,xC),e(xC,BTe),e(BTe,ULr),e(xC,JLr),e(xC,XJ),e(XJ,YLr),e(xC,KLr),e(qr,ZLr),M($C,qr,null),b(f,Hje,u),b(f,$c,u),e($c,kC),e(kC,ITe),M(x9,ITe,null),e($c,e8r),e($c,NTe),e(NTe,o8r),b(f,Uje,u),b(f,fr,u),M($9,fr,null),e(fr,r8r),e(fr,kc),e(kc,t8r),e(kc,zJ),e(zJ,a8r),e(kc,n8r),e(kc,WJ),e(WJ,s8r),e(kc,l8r),e(fr,i8r),e(fr,k9),e(k9,d8r),e(k9,qTe),e(qTe,c8r),e(k9,f8r),e(fr,m8r),e(fr,Gt),M(S9,Gt,null),e(Gt,g8r),e(Gt,jTe),e(jTe,h8r),e(Gt,p8r),e(Gt,Sc),e(Sc,_8r),e(Sc,DTe),e(DTe,u8r),e(Sc,b8r),e(Sc,QJ),e(QJ,v8r),e(Sc,F8r),e(Gt,T8r),M(SC,Gt,null),e(fr,M8r),e(fr,jr),M(R9,jr,null),e(jr,E8r),e(jr,GTe),e(GTe,C8r),e(jr,w8r),e(jr,hn),e(hn,A8r),e(hn,OTe),e(OTe,y8r),e(hn,L8r),e(hn,VTe),e(VTe,x8r),e(hn,$8r),e(hn,XTe),e(XTe,k8r),e(hn,S8r),e(jr,R8r),e(jr,te),e(te,RC),e(RC,zTe),e(zTe,P8r),e(RC,B8r),e(RC,HJ),e(HJ,I8r),e(RC,N8r),e(te,q8r),e(te,PC),e(PC,WTe),e(WTe,j8r),e(PC,D8r),e(PC,UJ),e(UJ,G8r),e(PC,O8r),e(te,V8r),e(te,BC),e(BC,QTe),e(QTe,X8r),e(BC,z8r),e(BC,JJ),e(JJ,W8r),e(BC,Q8r),e(te,H8r),e(te,IC),e(IC,HTe),e(HTe,U8r),e(IC,J8r),e(IC,YJ),e(YJ,Y8r),e(IC,K8r),e(te,Z8r),e(te,NC),e(NC,UTe),e(UTe,e9r),e(NC,o9r),e(NC,KJ),e(KJ,r9r),e(NC,t9r),e(te,a9r),e(te,qC),e(qC,JTe),e(JTe,n9r),e(qC,s9r),e(qC,ZJ),e(ZJ,l9r),e(qC,i9r),e(te,d9r),e(te,jC),e(jC,YTe),e(YTe,c9r),e(jC,f9r),e(jC,eY),e(eY,m9r),e(jC,g9r),e(te,h9r),e(te,DC),e(DC,KTe),e(KTe,p9r),e(DC,_9r),e(DC,oY),e(oY,u9r),e(DC,b9r),e(te,v9r),e(te,GC),e(GC,ZTe),e(ZTe,F9r),e(GC,T9r),e(GC,rY),e(rY,M9r),e(GC,E9r),e(te,C9r),e(te,OC),e(OC,e7e),e(e7e,w9r),e(OC,A9r),e(OC,tY),e(tY,y9r),e(OC,L9r),e(te,x9r),e(te,VC),e(VC,o7e),e(o7e,$9r),e(VC,k9r),e(VC,aY),e(aY,S9r),e(VC,R9r),e(te,P9r),e(te,XC),e(XC,r7e),e(r7e,B9r),e(XC,I9r),e(XC,nY),e(nY,N9r),e(XC,q9r),e(te,j9r),e(te,zC),e(zC,t7e),e(t7e,D9r),e(zC,G9r),e(zC,sY),e(sY,O9r),e(zC,V9r),e(te,X9r),e(te,WC),e(WC,a7e),e(a7e,z9r),e(WC,W9r),e(WC,lY),e(lY,Q9r),e(WC,H9r),e(te,U9r),e(te,QC),e(QC,n7e),e(n7e,J9r),e(QC,Y9r),e(QC,iY),e(iY,K9r),e(QC,Z9r),e(te,exr),e(te,HC),e(HC,s7e),e(s7e,oxr),e(HC,rxr),e(HC,dY),e(dY,txr),e(HC,axr),e(te,nxr),e(te,UC),e(UC,l7e),e(l7e,sxr),e(UC,lxr),e(UC,cY),e(cY,ixr),e(UC,dxr),e(te,cxr),e(te,JC),e(JC,i7e),e(i7e,fxr),e(JC,mxr),e(JC,fY),e(fY,gxr),e(JC,hxr),e(te,pxr),e(te,YC),e(YC,d7e),e(d7e,_xr),e(YC,uxr),e(YC,mY),e(mY,bxr),e(YC,vxr),e(te,Fxr),e(te,KC),e(KC,c7e),e(c7e,Txr),e(KC,Mxr),e(KC,gY),e(gY,Exr),e(KC,Cxr),e(te,wxr),e(te,ZC),e(ZC,f7e),e(f7e,Axr),e(ZC,yxr),e(ZC,hY),e(hY,Lxr),e(ZC,xxr),e(te,$xr),e(te,e5),e(e5,m7e),e(m7e,kxr),e(e5,Sxr),e(e5,pY),e(pY,Rxr),e(e5,Pxr),e(te,Bxr),e(te,o5),e(o5,g7e),e(g7e,Ixr),e(o5,Nxr),e(o5,_Y),e(_Y,qxr),e(o5,jxr),e(te,Dxr),e(te,r5),e(r5,h7e),e(h7e,Gxr),e(r5,Oxr),e(r5,uY),e(uY,Vxr),e(r5,Xxr),e(te,zxr),e(te,t5),e(t5,p7e),e(p7e,Wxr),e(t5,Qxr),e(t5,bY),e(bY,Hxr),e(t5,Uxr),e(jr,Jxr),M(a5,jr,null),b(f,Jje,u),b(f,Rc,u),e(Rc,n5),e(n5,_7e),M(P9,_7e,null),e(Rc,Yxr),e(Rc,u7e),e(u7e,Kxr),b(f,Yje,u),b(f,mr,u),M(B9,mr,null),e(mr,Zxr),e(mr,Pc),e(Pc,e$r),e(Pc,vY),e(vY,o$r),e(Pc,r$r),e(Pc,FY),e(FY,t$r),e(Pc,a$r),e(mr,n$r),e(mr,I9),e(I9,s$r),e(I9,b7e),e(b7e,l$r),e(I9,i$r),e(mr,d$r),e(mr,Ot),M(N9,Ot,null),e(Ot,c$r),e(Ot,v7e),e(v7e,f$r),e(Ot,m$r),e(Ot,Bc),e(Bc,g$r),e(Bc,F7e),e(F7e,h$r),e(Bc,p$r),e(Bc,TY),e(TY,_$r),e(Bc,u$r),e(Ot,b$r),M(s5,Ot,null),e(mr,v$r),e(mr,Dr),M(q9,Dr,null),e(Dr,F$r),e(Dr,T7e),e(T7e,T$r),e(Dr,M$r),e(Dr,pn),e(pn,E$r),e(pn,M7e),e(M7e,C$r),e(pn,w$r),e(pn,E7e),e(E7e,A$r),e(pn,y$r),e(pn,C7e),e(C7e,L$r),e(pn,x$r),e(Dr,$$r),e(Dr,Re),e(Re,l5),e(l5,w7e),e(w7e,k$r),e(l5,S$r),e(l5,MY),e(MY,R$r),e(l5,P$r),e(Re,B$r),e(Re,i5),e(i5,A7e),e(A7e,I$r),e(i5,N$r),e(i5,EY),e(EY,q$r),e(i5,j$r),e(Re,D$r),e(Re,d5),e(d5,y7e),e(y7e,G$r),e(d5,O$r),e(d5,CY),e(CY,V$r),e(d5,X$r),e(Re,z$r),e(Re,c5),e(c5,L7e),e(L7e,W$r),e(c5,Q$r),e(c5,wY),e(wY,H$r),e(c5,U$r),e(Re,J$r),e(Re,f5),e(f5,x7e),e(x7e,Y$r),e(f5,K$r),e(f5,AY),e(AY,Z$r),e(f5,ekr),e(Re,okr),e(Re,m5),e(m5,$7e),e($7e,rkr),e(m5,tkr),e(m5,yY),e(yY,akr),e(m5,nkr),e(Re,skr),e(Re,g5),e(g5,k7e),e(k7e,lkr),e(g5,ikr),e(g5,LY),e(LY,dkr),e(g5,ckr),e(Re,fkr),e(Re,h5),e(h5,S7e),e(S7e,mkr),e(h5,gkr),e(h5,xY),e(xY,hkr),e(h5,pkr),e(Re,_kr),e(Re,p5),e(p5,R7e),e(R7e,ukr),e(p5,bkr),e(p5,$Y),e($Y,vkr),e(p5,Fkr),e(Dr,Tkr),M(_5,Dr,null),b(f,Kje,u),b(f,Ic,u),e(Ic,u5),e(u5,P7e),M(j9,P7e,null),e(Ic,Mkr),e(Ic,B7e),e(B7e,Ekr),b(f,Zje,u),b(f,gr,u),M(D9,gr,null),e(gr,Ckr),e(gr,Nc),e(Nc,wkr),e(Nc,kY),e(kY,Akr),e(Nc,ykr),e(Nc,SY),e(SY,Lkr),e(Nc,xkr),e(gr,$kr),e(gr,G9),e(G9,kkr),e(G9,I7e),e(I7e,Skr),e(G9,Rkr),e(gr,Pkr),e(gr,Vt),M(O9,Vt,null),e(Vt,Bkr),e(Vt,N7e),e(N7e,Ikr),e(Vt,Nkr),e(Vt,qc),e(qc,qkr),e(qc,q7e),e(q7e,jkr),e(qc,Dkr),e(qc,RY),e(RY,Gkr),e(qc,Okr),e(Vt,Vkr),M(b5,Vt,null),e(gr,Xkr),e(gr,Gr),M(V9,Gr,null),e(Gr,zkr),e(Gr,j7e),e(j7e,Wkr),e(Gr,Qkr),e(Gr,_n),e(_n,Hkr),e(_n,D7e),e(D7e,Ukr),e(_n,Jkr),e(_n,G7e),e(G7e,Ykr),e(_n,Kkr),e(_n,O7e),e(O7e,Zkr),e(_n,eSr),e(Gr,oSr),e(Gr,Ee),e(Ee,v5),e(v5,V7e),e(V7e,rSr),e(v5,tSr),e(v5,PY),e(PY,aSr),e(v5,nSr),e(Ee,sSr),e(Ee,F5),e(F5,X7e),e(X7e,lSr),e(F5,iSr),e(F5,BY),e(BY,dSr),e(F5,cSr),e(Ee,fSr),e(Ee,T5),e(T5,z7e),e(z7e,mSr),e(T5,gSr),e(T5,IY),e(IY,hSr),e(T5,pSr),e(Ee,_Sr),e(Ee,M5),e(M5,W7e),e(W7e,uSr),e(M5,bSr),e(M5,NY),e(NY,vSr),e(M5,FSr),e(Ee,TSr),e(Ee,E5),e(E5,Q7e),e(Q7e,MSr),e(E5,ESr),e(E5,qY),e(qY,CSr),e(E5,wSr),e(Ee,ASr),e(Ee,C5),e(C5,H7e),e(H7e,ySr),e(C5,LSr),e(C5,jY),e(jY,xSr),e(C5,$Sr),e(Ee,kSr),e(Ee,w5),e(w5,U7e),e(U7e,SSr),e(w5,RSr),e(w5,DY),e(DY,PSr),e(w5,BSr),e(Ee,ISr),e(Ee,A5),e(A5,J7e),e(J7e,NSr),e(A5,qSr),e(A5,GY),e(GY,jSr),e(A5,DSr),e(Ee,GSr),e(Ee,y5),e(y5,Y7e),e(Y7e,OSr),e(y5,VSr),e(y5,OY),e(OY,XSr),e(y5,zSr),e(Ee,WSr),e(Ee,L5),e(L5,K7e),e(K7e,QSr),e(L5,HSr),e(L5,VY),e(VY,USr),e(L5,JSr),e(Ee,YSr),e(Ee,x5),e(x5,Z7e),e(Z7e,KSr),e(x5,ZSr),e(x5,XY),e(XY,eRr),e(x5,oRr),e(Ee,rRr),e(Ee,$5),e($5,eMe),e(eMe,tRr),e($5,aRr),e($5,zY),e(zY,nRr),e($5,sRr),e(Gr,lRr),M(k5,Gr,null),b(f,eDe,u),b(f,jc,u),e(jc,S5),e(S5,oMe),M(X9,oMe,null),e(jc,iRr),e(jc,rMe),e(rMe,dRr),b(f,oDe,u),b(f,hr,u),M(z9,hr,null),e(hr,cRr),e(hr,Dc),e(Dc,fRr),e(Dc,WY),e(WY,mRr),e(Dc,gRr),e(Dc,QY),e(QY,hRr),e(Dc,pRr),e(hr,_Rr),e(hr,W9),e(W9,uRr),e(W9,tMe),e(tMe,bRr),e(W9,vRr),e(hr,FRr),e(hr,Xt),M(Q9,Xt,null),e(Xt,TRr),e(Xt,aMe),e(aMe,MRr),e(Xt,ERr),e(Xt,Gc),e(Gc,CRr),e(Gc,nMe),e(nMe,wRr),e(Gc,ARr),e(Gc,HY),e(HY,yRr),e(Gc,LRr),e(Xt,xRr),M(R5,Xt,null),e(hr,$Rr),e(hr,Or),M(H9,Or,null),e(Or,kRr),e(Or,sMe),e(sMe,SRr),e(Or,RRr),e(Or,un),e(un,PRr),e(un,lMe),e(lMe,BRr),e(un,IRr),e(un,iMe),e(iMe,NRr),e(un,qRr),e(un,dMe),e(dMe,jRr),e(un,DRr),e(Or,GRr),e(Or,Le),e(Le,P5),e(P5,cMe),e(cMe,ORr),e(P5,VRr),e(P5,UY),e(UY,XRr),e(P5,zRr),e(Le,WRr),e(Le,B5),e(B5,fMe),e(fMe,QRr),e(B5,HRr),e(B5,JY),e(JY,URr),e(B5,JRr),e(Le,YRr),e(Le,I5),e(I5,mMe),e(mMe,KRr),e(I5,ZRr),e(I5,YY),e(YY,ePr),e(I5,oPr),e(Le,rPr),e(Le,N5),e(N5,gMe),e(gMe,tPr),e(N5,aPr),e(N5,KY),e(KY,nPr),e(N5,sPr),e(Le,lPr),e(Le,q5),e(q5,hMe),e(hMe,iPr),e(q5,dPr),e(q5,ZY),e(ZY,cPr),e(q5,fPr),e(Le,mPr),e(Le,j5),e(j5,pMe),e(pMe,gPr),e(j5,hPr),e(j5,eK),e(eK,pPr),e(j5,_Pr),e(Le,uPr),e(Le,D5),e(D5,_Me),e(_Me,bPr),e(D5,vPr),e(D5,oK),e(oK,FPr),e(D5,TPr),e(Le,MPr),e(Le,G5),e(G5,uMe),e(uMe,EPr),e(G5,CPr),e(G5,rK),e(rK,wPr),e(G5,APr),e(Le,yPr),e(Le,O5),e(O5,bMe),e(bMe,LPr),e(O5,xPr),e(O5,tK),e(tK,$Pr),e(O5,kPr),e(Le,SPr),e(Le,V5),e(V5,vMe),e(vMe,RPr),e(V5,PPr),e(V5,aK),e(aK,BPr),e(V5,IPr),e(Or,NPr),M(X5,Or,null),b(f,rDe,u),b(f,Oc,u),e(Oc,z5),e(z5,FMe),M(U9,FMe,null),e(Oc,qPr),e(Oc,TMe),e(TMe,jPr),b(f,tDe,u),b(f,pr,u),M(J9,pr,null),e(pr,DPr),e(pr,Vc),e(Vc,GPr),e(Vc,nK),e(nK,OPr),e(Vc,VPr),e(Vc,sK),e(sK,XPr),e(Vc,zPr),e(pr,WPr),e(pr,Y9),e(Y9,QPr),e(Y9,MMe),e(MMe,HPr),e(Y9,UPr),e(pr,JPr),e(pr,zt),M(K9,zt,null),e(zt,YPr),e(zt,EMe),e(EMe,KPr),e(zt,ZPr),e(zt,Xc),e(Xc,eBr),e(Xc,CMe),e(CMe,oBr),e(Xc,rBr),e(Xc,lK),e(lK,tBr),e(Xc,aBr),e(zt,nBr),M(W5,zt,null),e(pr,sBr),e(pr,Vr),M(Z9,Vr,null),e(Vr,lBr),e(Vr,wMe),e(wMe,iBr),e(Vr,dBr),e(Vr,bn),e(bn,cBr),e(bn,AMe),e(AMe,fBr),e(bn,mBr),e(bn,yMe),e(yMe,gBr),e(bn,hBr),e(bn,LMe),e(LMe,pBr),e(bn,_Br),e(Vr,uBr),e(Vr,Pe),e(Pe,Q5),e(Q5,xMe),e(xMe,bBr),e(Q5,vBr),e(Q5,iK),e(iK,FBr),e(Q5,TBr),e(Pe,MBr),e(Pe,H5),e(H5,$Me),e($Me,EBr),e(H5,CBr),e(H5,dK),e(dK,wBr),e(H5,ABr),e(Pe,yBr),e(Pe,U5),e(U5,kMe),e(kMe,LBr),e(U5,xBr),e(U5,cK),e(cK,$Br),e(U5,kBr),e(Pe,SBr),e(Pe,J5),e(J5,SMe),e(SMe,RBr),e(J5,PBr),e(J5,fK),e(fK,BBr),e(J5,IBr),e(Pe,NBr),e(Pe,Y5),e(Y5,RMe),e(RMe,qBr),e(Y5,jBr),e(Y5,mK),e(mK,DBr),e(Y5,GBr),e(Pe,OBr),e(Pe,K5),e(K5,PMe),e(PMe,VBr),e(K5,XBr),e(K5,gK),e(gK,zBr),e(K5,WBr),e(Pe,QBr),e(Pe,Z5),e(Z5,BMe),e(BMe,HBr),e(Z5,UBr),e(Z5,hK),e(hK,JBr),e(Z5,YBr),e(Pe,KBr),e(Pe,e3),e(e3,IMe),e(IMe,ZBr),e(e3,eIr),e(e3,pK),e(pK,oIr),e(e3,rIr),e(Pe,tIr),e(Pe,o3),e(o3,NMe),e(NMe,aIr),e(o3,nIr),e(o3,_K),e(_K,sIr),e(o3,lIr),e(Vr,iIr),M(r3,Vr,null),b(f,aDe,u),b(f,zc,u),e(zc,t3),e(t3,qMe),M(ex,qMe,null),e(zc,dIr),e(zc,jMe),e(jMe,cIr),b(f,nDe,u),b(f,_r,u),M(ox,_r,null),e(_r,fIr),e(_r,Wc),e(Wc,mIr),e(Wc,uK),e(uK,gIr),e(Wc,hIr),e(Wc,bK),e(bK,pIr),e(Wc,_Ir),e(_r,uIr),e(_r,rx),e(rx,bIr),e(rx,DMe),e(DMe,vIr),e(rx,FIr),e(_r,TIr),e(_r,Wt),M(tx,Wt,null),e(Wt,MIr),e(Wt,GMe),e(GMe,EIr),e(Wt,CIr),e(Wt,Qc),e(Qc,wIr),e(Qc,OMe),e(OMe,AIr),e(Qc,yIr),e(Qc,vK),e(vK,LIr),e(Qc,xIr),e(Wt,$Ir),M(a3,Wt,null),e(_r,kIr),e(_r,Xr),M(ax,Xr,null),e(Xr,SIr),e(Xr,VMe),e(VMe,RIr),e(Xr,PIr),e(Xr,vn),e(vn,BIr),e(vn,XMe),e(XMe,IIr),e(vn,NIr),e(vn,zMe),e(zMe,qIr),e(vn,jIr),e(vn,WMe),e(WMe,DIr),e(vn,GIr),e(Xr,OIr),e(Xr,xe),e(xe,n3),e(n3,QMe),e(QMe,VIr),e(n3,XIr),e(n3,FK),e(FK,zIr),e(n3,WIr),e(xe,QIr),e(xe,s3),e(s3,HMe),e(HMe,HIr),e(s3,UIr),e(s3,TK),e(TK,JIr),e(s3,YIr),e(xe,KIr),e(xe,l3),e(l3,UMe),e(UMe,ZIr),e(l3,eNr),e(l3,MK),e(MK,oNr),e(l3,rNr),e(xe,tNr),e(xe,i3),e(i3,JMe),e(JMe,aNr),e(i3,nNr),e(i3,EK),e(EK,sNr),e(i3,lNr),e(xe,iNr),e(xe,d3),e(d3,YMe),e(YMe,dNr),e(d3,cNr),e(d3,CK),e(CK,fNr),e(d3,mNr),e(xe,gNr),e(xe,c3),e(c3,KMe),e(KMe,hNr),e(c3,pNr),e(c3,wK),e(wK,_Nr),e(c3,uNr),e(xe,bNr),e(xe,f3),e(f3,ZMe),e(ZMe,vNr),e(f3,FNr),e(f3,AK),e(AK,TNr),e(f3,MNr),e(xe,ENr),e(xe,m3),e(m3,eEe),e(eEe,CNr),e(m3,wNr),e(m3,yK),e(yK,ANr),e(m3,yNr),e(xe,LNr),e(xe,g3),e(g3,oEe),e(oEe,xNr),e(g3,$Nr),e(g3,LK),e(LK,kNr),e(g3,SNr),e(xe,RNr),e(xe,h3),e(h3,rEe),e(rEe,PNr),e(h3,BNr),e(h3,xK),e(xK,INr),e(h3,NNr),e(Xr,qNr),M(p3,Xr,null),b(f,sDe,u),b(f,Hc,u),e(Hc,_3),e(_3,tEe),M(nx,tEe,null),e(Hc,jNr),e(Hc,aEe),e(aEe,DNr),b(f,lDe,u),b(f,ur,u),M(sx,ur,null),e(ur,GNr),e(ur,Uc),e(Uc,ONr),e(Uc,$K),e($K,VNr),e(Uc,XNr),e(Uc,kK),e(kK,zNr),e(Uc,WNr),e(ur,QNr),e(ur,lx),e(lx,HNr),e(lx,nEe),e(nEe,UNr),e(lx,JNr),e(ur,YNr),e(ur,Qt),M(ix,Qt,null),e(Qt,KNr),e(Qt,sEe),e(sEe,ZNr),e(Qt,eqr),e(Qt,Jc),e(Jc,oqr),e(Jc,lEe),e(lEe,rqr),e(Jc,tqr),e(Jc,SK),e(SK,aqr),e(Jc,nqr),e(Qt,sqr),M(u3,Qt,null),e(ur,lqr),e(ur,zr),M(dx,zr,null),e(zr,iqr),e(zr,iEe),e(iEe,dqr),e(zr,cqr),e(zr,Fn),e(Fn,fqr),e(Fn,dEe),e(dEe,mqr),e(Fn,gqr),e(Fn,cEe),e(cEe,hqr),e(Fn,pqr),e(Fn,fEe),e(fEe,_qr),e(Fn,uqr),e(zr,bqr),e(zr,$e),e($e,b3),e(b3,mEe),e(mEe,vqr),e(b3,Fqr),e(b3,RK),e(RK,Tqr),e(b3,Mqr),e($e,Eqr),e($e,v3),e(v3,gEe),e(gEe,Cqr),e(v3,wqr),e(v3,PK),e(PK,Aqr),e(v3,yqr),e($e,Lqr),e($e,F3),e(F3,hEe),e(hEe,xqr),e(F3,$qr),e(F3,BK),e(BK,kqr),e(F3,Sqr),e($e,Rqr),e($e,T3),e(T3,pEe),e(pEe,Pqr),e(T3,Bqr),e(T3,IK),e(IK,Iqr),e(T3,Nqr),e($e,qqr),e($e,M3),e(M3,_Ee),e(_Ee,jqr),e(M3,Dqr),e(M3,NK),e(NK,Gqr),e(M3,Oqr),e($e,Vqr),e($e,E3),e(E3,uEe),e(uEe,Xqr),e(E3,zqr),e(E3,qK),e(qK,Wqr),e(E3,Qqr),e($e,Hqr),e($e,C3),e(C3,bEe),e(bEe,Uqr),e(C3,Jqr),e(C3,jK),e(jK,Yqr),e(C3,Kqr),e($e,Zqr),e($e,w3),e(w3,vEe),e(vEe,ejr),e(w3,ojr),e(w3,DK),e(DK,rjr),e(w3,tjr),e($e,ajr),e($e,A3),e(A3,FEe),e(FEe,njr),e(A3,sjr),e(A3,GK),e(GK,ljr),e(A3,ijr),e($e,djr),e($e,y3),e(y3,TEe),e(TEe,cjr),e(y3,fjr),e(y3,OK),e(OK,mjr),e(y3,gjr),e(zr,hjr),M(L3,zr,null),b(f,iDe,u),b(f,Yc,u),e(Yc,x3),e(x3,MEe),M(cx,MEe,null),e(Yc,pjr),e(Yc,EEe),e(EEe,_jr),b(f,dDe,u),b(f,br,u),M(fx,br,null),e(br,ujr),e(br,Kc),e(Kc,bjr),e(Kc,VK),e(VK,vjr),e(Kc,Fjr),e(Kc,XK),e(XK,Tjr),e(Kc,Mjr),e(br,Ejr),e(br,mx),e(mx,Cjr),e(mx,CEe),e(CEe,wjr),e(mx,Ajr),e(br,yjr),e(br,Ht),M(gx,Ht,null),e(Ht,Ljr),e(Ht,wEe),e(wEe,xjr),e(Ht,$jr),e(Ht,Zc),e(Zc,kjr),e(Zc,AEe),e(AEe,Sjr),e(Zc,Rjr),e(Zc,zK),e(zK,Pjr),e(Zc,Bjr),e(Ht,Ijr),M($3,Ht,null),e(br,Njr),e(br,Wr),M(hx,Wr,null),e(Wr,qjr),e(Wr,yEe),e(yEe,jjr),e(Wr,Djr),e(Wr,Tn),e(Tn,Gjr),e(Tn,LEe),e(LEe,Ojr),e(Tn,Vjr),e(Tn,xEe),e(xEe,Xjr),e(Tn,zjr),e(Tn,$Ee),e($Ee,Wjr),e(Tn,Qjr),e(Wr,Hjr),e(Wr,De),e(De,k3),e(k3,kEe),e(kEe,Ujr),e(k3,Jjr),e(k3,WK),e(WK,Yjr),e(k3,Kjr),e(De,Zjr),e(De,S3),e(S3,SEe),e(SEe,eDr),e(S3,oDr),e(S3,QK),e(QK,rDr),e(S3,tDr),e(De,aDr),e(De,R3),e(R3,REe),e(REe,nDr),e(R3,sDr),e(R3,HK),e(HK,lDr),e(R3,iDr),e(De,dDr),e(De,P3),e(P3,PEe),e(PEe,cDr),e(P3,fDr),e(P3,UK),e(UK,mDr),e(P3,gDr),e(De,hDr),e(De,B3),e(B3,BEe),e(BEe,pDr),e(B3,_Dr),e(B3,JK),e(JK,uDr),e(B3,bDr),e(De,vDr),e(De,I3),e(I3,IEe),e(IEe,FDr),e(I3,TDr),e(I3,YK),e(YK,MDr),e(I3,EDr),e(De,CDr),e(De,N3),e(N3,NEe),e(NEe,wDr),e(N3,ADr),e(N3,KK),e(KK,yDr),e(N3,LDr),e(De,xDr),e(De,q3),e(q3,qEe),e(qEe,$Dr),e(q3,kDr),e(q3,ZK),e(ZK,SDr),e(q3,RDr),e(Wr,PDr),M(j3,Wr,null),b(f,cDe,u),b(f,ef,u),e(ef,D3),e(D3,jEe),M(px,jEe,null),e(ef,BDr),e(ef,DEe),e(DEe,IDr),b(f,fDe,u),b(f,vr,u),M(_x,vr,null),e(vr,NDr),e(vr,of),e(of,qDr),e(of,eZ),e(eZ,jDr),e(of,DDr),e(of,oZ),e(oZ,GDr),e(of,ODr),e(vr,VDr),e(vr,ux),e(ux,XDr),e(ux,GEe),e(GEe,zDr),e(ux,WDr),e(vr,QDr),e(vr,Ut),M(bx,Ut,null),e(Ut,HDr),e(Ut,OEe),e(OEe,UDr),e(Ut,JDr),e(Ut,rf),e(rf,YDr),e(rf,VEe),e(VEe,KDr),e(rf,ZDr),e(rf,rZ),e(rZ,eGr),e(rf,oGr),e(Ut,rGr),M(G3,Ut,null),e(vr,tGr),e(vr,Qr),M(vx,Qr,null),e(Qr,aGr),e(Qr,XEe),e(XEe,nGr),e(Qr,sGr),e(Qr,Mn),e(Mn,lGr),e(Mn,zEe),e(zEe,iGr),e(Mn,dGr),e(Mn,WEe),e(WEe,cGr),e(Mn,fGr),e(Mn,QEe),e(QEe,mGr),e(Mn,gGr),e(Qr,hGr),e(Qr,Ge),e(Ge,O3),e(O3,HEe),e(HEe,pGr),e(O3,_Gr),e(O3,tZ),e(tZ,uGr),e(O3,bGr),e(Ge,vGr),e(Ge,V3),e(V3,UEe),e(UEe,FGr),e(V3,TGr),e(V3,aZ),e(aZ,MGr),e(V3,EGr),e(Ge,CGr),e(Ge,X3),e(X3,JEe),e(JEe,wGr),e(X3,AGr),e(X3,nZ),e(nZ,yGr),e(X3,LGr),e(Ge,xGr),e(Ge,z3),e(z3,YEe),e(YEe,$Gr),e(z3,kGr),e(z3,sZ),e(sZ,SGr),e(z3,RGr),e(Ge,PGr),e(Ge,W3),e(W3,KEe),e(KEe,BGr),e(W3,IGr),e(W3,lZ),e(lZ,NGr),e(W3,qGr),e(Ge,jGr),e(Ge,Q3),e(Q3,ZEe),e(ZEe,DGr),e(Q3,GGr),e(Q3,iZ),e(iZ,OGr),e(Q3,VGr),e(Ge,XGr),e(Ge,H3),e(H3,eCe),e(eCe,zGr),e(H3,WGr),e(H3,dZ),e(dZ,QGr),e(H3,HGr),e(Ge,UGr),e(Ge,U3),e(U3,oCe),e(oCe,JGr),e(U3,YGr),e(U3,cZ),e(cZ,KGr),e(U3,ZGr),e(Qr,eOr),M(J3,Qr,null),b(f,mDe,u),b(f,tf,u),e(tf,Y3),e(Y3,rCe),M(Fx,rCe,null),e(tf,oOr),e(tf,tCe),e(tCe,rOr),b(f,gDe,u),b(f,Fr,u),M(Tx,Fr,null),e(Fr,tOr),e(Fr,af),e(af,aOr),e(af,fZ),e(fZ,nOr),e(af,sOr),e(af,mZ),e(mZ,lOr),e(af,iOr),e(Fr,dOr),e(Fr,Mx),e(Mx,cOr),e(Mx,aCe),e(aCe,fOr),e(Mx,mOr),e(Fr,gOr),e(Fr,Jt),M(Ex,Jt,null),e(Jt,hOr),e(Jt,nCe),e(nCe,pOr),e(Jt,_Or),e(Jt,nf),e(nf,uOr),e(nf,sCe),e(sCe,bOr),e(nf,vOr),e(nf,gZ),e(gZ,FOr),e(nf,TOr),e(Jt,MOr),M(K3,Jt,null),e(Fr,EOr),e(Fr,Hr),M(Cx,Hr,null),e(Hr,COr),e(Hr,lCe),e(lCe,wOr),e(Hr,AOr),e(Hr,En),e(En,yOr),e(En,iCe),e(iCe,LOr),e(En,xOr),e(En,dCe),e(dCe,$Or),e(En,kOr),e(En,cCe),e(cCe,SOr),e(En,ROr),e(Hr,POr),e(Hr,fCe),e(fCe,Z3),e(Z3,mCe),e(mCe,BOr),e(Z3,IOr),e(Z3,hZ),e(hZ,NOr),e(Z3,qOr),e(Hr,jOr),M(ew,Hr,null),b(f,hDe,u),b(f,sf,u),e(sf,ow),e(ow,gCe),M(wx,gCe,null),e(sf,DOr),e(sf,hCe),e(hCe,GOr),b(f,pDe,u),b(f,Tr,u),M(Ax,Tr,null),e(Tr,OOr),e(Tr,lf),e(lf,VOr),e(lf,pZ),e(pZ,XOr),e(lf,zOr),e(lf,_Z),e(_Z,WOr),e(lf,QOr),e(Tr,HOr),e(Tr,yx),e(yx,UOr),e(yx,pCe),e(pCe,JOr),e(yx,YOr),e(Tr,KOr),e(Tr,Yt),M(Lx,Yt,null),e(Yt,ZOr),e(Yt,_Ce),e(_Ce,eVr),e(Yt,oVr),e(Yt,df),e(df,rVr),e(df,uCe),e(uCe,tVr),e(df,aVr),e(df,uZ),e(uZ,nVr),e(df,sVr),e(Yt,lVr),M(rw,Yt,null),e(Tr,iVr),e(Tr,Ur),M(xx,Ur,null),e(Ur,dVr),e(Ur,bCe),e(bCe,cVr),e(Ur,fVr),e(Ur,Cn),e(Cn,mVr),e(Cn,vCe),e(vCe,gVr),e(Cn,hVr),e(Cn,FCe),e(FCe,pVr),e(Cn,_Vr),e(Cn,TCe),e(TCe,uVr),e(Cn,bVr),e(Ur,vVr),e(Ur,$x),e($x,tw),e(tw,MCe),e(MCe,FVr),e(tw,TVr),e(tw,bZ),e(bZ,MVr),e(tw,EVr),e($x,CVr),e($x,aw),e(aw,ECe),e(ECe,wVr),e(aw,AVr),e(aw,vZ),e(vZ,yVr),e(aw,LVr),e(Ur,xVr),M(nw,Ur,null),b(f,_De,u),b(f,cf,u),e(cf,sw),e(sw,CCe),M(kx,CCe,null),e(cf,$Vr),e(cf,wCe),e(wCe,kVr),b(f,uDe,u),b(f,Mr,u),M(Sx,Mr,null),e(Mr,SVr),e(Mr,ff),e(ff,RVr),e(ff,FZ),e(FZ,PVr),e(ff,BVr),e(ff,TZ),e(TZ,IVr),e(ff,NVr),e(Mr,qVr),e(Mr,Rx),e(Rx,jVr),e(Rx,ACe),e(ACe,DVr),e(Rx,GVr),e(Mr,OVr),e(Mr,Kt),M(Px,Kt,null),e(Kt,VVr),e(Kt,yCe),e(yCe,XVr),e(Kt,zVr),e(Kt,mf),e(mf,WVr),e(mf,LCe),e(LCe,QVr),e(mf,HVr),e(mf,MZ),e(MZ,UVr),e(mf,JVr),e(Kt,YVr),M(lw,Kt,null),e(Mr,KVr),e(Mr,Jr),M(Bx,Jr,null),e(Jr,ZVr),e(Jr,xCe),e(xCe,eXr),e(Jr,oXr),e(Jr,wn),e(wn,rXr),e(wn,$Ce),e($Ce,tXr),e(wn,aXr),e(wn,kCe),e(kCe,nXr),e(wn,sXr),e(wn,SCe),e(SCe,lXr),e(wn,iXr),e(Jr,dXr),e(Jr,RCe),e(RCe,iw),e(iw,PCe),e(PCe,cXr),e(iw,fXr),e(iw,EZ),e(EZ,mXr),e(iw,gXr),e(Jr,hXr),M(dw,Jr,null),bDe=!0},p(f,[u]){const Ix={};u&2&&(Ix.$$scope={dirty:u,ctx:f}),Tf.$set(Ix);const BCe={};u&2&&(BCe.$$scope={dirty:u,ctx:f}),wg.$set(BCe);const ICe={};u&2&&(ICe.$$scope={dirty:u,ctx:f}),sh.$set(ICe);const NCe={};u&2&&(NCe.$$scope={dirty:u,ctx:f}),jh.$set(NCe);const Nx={};u&2&&(Nx.$$scope={dirty:u,ctx:f}),Dh.$set(Nx);const qCe={};u&2&&(qCe.$$scope={dirty:u,ctx:f}),sp.$set(qCe);const An={};u&2&&(An.$$scope={dirty:u,ctx:f}),lp.$set(An);const jCe={};u&2&&(jCe.$$scope={dirty:u,ctx:f}),cp.$set(jCe);const DCe={};u&2&&(DCe.$$scope={dirty:u,ctx:f}),su.$set(DCe);const GCe={};u&2&&(GCe.$$scope={dirty:u,ctx:f}),iu.$set(GCe);const qx={};u&2&&(qx.$$scope={dirty:u,ctx:f}),Ku.$set(qx);const OCe={};u&2&&(OCe.$$scope={dirty:u,ctx:f}),e6.$set(OCe);const jx={};u&2&&(jx.$$scope={dirty:u,ctx:f}),j6.$set(jx);const VCe={};u&2&&(VCe.$$scope={dirty:u,ctx:f}),G6.$set(VCe);const Dx={};u&2&&(Dx.$$scope={dirty:u,ctx:f}),C1.$set(Dx);const XCe={};u&2&&(XCe.$$scope={dirty:u,ctx:f}),A1.$set(XCe);const zCe={};u&2&&(zCe.$$scope={dirty:u,ctx:f}),X1.$set(zCe);const WCe={};u&2&&(WCe.$$scope={dirty:u,ctx:f}),W1.$set(WCe);const gf={};u&2&&(gf.$$scope={dirty:u,ctx:f}),Gb.$set(gf);const QCe={};u&2&&(QCe.$$scope={dirty:u,ctx:f}),Vb.$set(QCe);const HCe={};u&2&&(HCe.$$scope={dirty:u,ctx:f}),F2.$set(HCe);const UCe={};u&2&&(UCe.$$scope={dirty:u,ctx:f}),M2.$set(UCe);const Gx={};u&2&&(Gx.$$scope={dirty:u,ctx:f}),x2.$set(Gx);const JCe={};u&2&&(JCe.$$scope={dirty:u,ctx:f}),k2.$set(JCe);const YCe={};u&2&&(YCe.$$scope={dirty:u,ctx:f}),g4.$set(YCe);const KCe={};u&2&&(KCe.$$scope={dirty:u,ctx:f}),p4.$set(KCe);const et={};u&2&&(et.$$scope={dirty:u,ctx:f}),tv.$set(et);const Ox={};u&2&&(Ox.$$scope={dirty:u,ctx:f}),nv.$set(Ox);const ZCe={};u&2&&(ZCe.$$scope={dirty:u,ctx:f}),iv.$set(ZCe);const Vx={};u&2&&(Vx.$$scope={dirty:u,ctx:f}),cv.$set(Vx);const e5e={};u&2&&(e5e.$$scope={dirty:u,ctx:f}),Cv.$set(e5e);const ot={};u&2&&(ot.$$scope={dirty:u,ctx:f}),Av.$set(ot);const o5e={};u&2&&(o5e.$$scope={dirty:u,ctx:f}),xv.$set(o5e);const hf={};u&2&&(hf.$$scope={dirty:u,ctx:f}),kv.$set(hf);const r5e={};u&2&&(r5e.$$scope={dirty:u,ctx:f}),Ov.$set(r5e);const t5e={};u&2&&(t5e.$$scope={dirty:u,ctx:f}),Xv.$set(t5e);const y={};u&2&&(y.$$scope={dirty:u,ctx:f}),Yv.$set(y);const cw={};u&2&&(cw.$$scope={dirty:u,ctx:f}),Zv.$set(cw);const a5e={};u&2&&(a5e.$$scope={dirty:u,ctx:f}),cF.$set(a5e);const n5e={};u&2&&(n5e.$$scope={dirty:u,ctx:f}),mF.$set(n5e);const fw={};u&2&&(fw.$$scope={dirty:u,ctx:f}),_F.$set(fw);const s5e={};u&2&&(s5e.$$scope={dirty:u,ctx:f}),bF.$set(s5e);const l5e={};u&2&&(l5e.$$scope={dirty:u,ctx:f}),wF.$set(l5e);const mw={};u&2&&(mw.$$scope={dirty:u,ctx:f}),yF.$set(mw);const i5e={};u&2&&(i5e.$$scope={dirty:u,ctx:f}),SF.$set(i5e);const d5e={};u&2&&(d5e.$$scope={dirty:u,ctx:f}),PF.$set(d5e);const gw={};u&2&&(gw.$$scope={dirty:u,ctx:f}),qF.$set(gw);const c5e={};u&2&&(c5e.$$scope={dirty:u,ctx:f}),DF.$set(c5e);const f5e={};u&2&&(f5e.$$scope={dirty:u,ctx:f}),VF.$set(f5e);const hw={};u&2&&(hw.$$scope={dirty:u,ctx:f}),zF.$set(hw);const m5e={};u&2&&(m5e.$$scope={dirty:u,ctx:f}),YF.$set(m5e);const g5e={};u&2&&(g5e.$$scope={dirty:u,ctx:f}),ZF.$set(g5e);const pw={};u&2&&(pw.$$scope={dirty:u,ctx:f}),rT.$set(pw);const h5e={};u&2&&(h5e.$$scope={dirty:u,ctx:f}),aT.$set(h5e);const p5e={};u&2&&(p5e.$$scope={dirty:u,ctx:f}),JT.$set(p5e);const _w={};u&2&&(_w.$$scope={dirty:u,ctx:f}),KT.$set(_w);const _5e={};u&2&&(_5e.$$scope={dirty:u,ctx:f}),M7.$set(_5e);const u5e={};u&2&&(u5e.$$scope={dirty:u,ctx:f}),C7.$set(u5e);const uw={};u&2&&(uw.$$scope={dirty:u,ctx:f}),N7.$set(uw);const b5e={};u&2&&(b5e.$$scope={dirty:u,ctx:f}),j7.$set(b5e);const v5e={};u&2&&(v5e.$$scope={dirty:u,ctx:f}),X7.$set(v5e);const bw={};u&2&&(bw.$$scope={dirty:u,ctx:f}),W7.$set(bw);const F5e={};u&2&&(F5e.$$scope={dirty:u,ctx:f}),gM.$set(F5e);const T5e={};u&2&&(T5e.$$scope={dirty:u,ctx:f}),pM.$set(T5e);const vw={};u&2&&(vw.$$scope={dirty:u,ctx:f}),AM.$set(vw);const M5e={};u&2&&(M5e.$$scope={dirty:u,ctx:f}),LM.$set(M5e);const E5e={};u&2&&(E5e.$$scope={dirty:u,ctx:f}),oE.$set(E5e);const Fw={};u&2&&(Fw.$$scope={dirty:u,ctx:f}),tE.$set(Fw);const C5e={};u&2&&(C5e.$$scope={dirty:u,ctx:f}),TE.$set(C5e);const w5e={};u&2&&(w5e.$$scope={dirty:u,ctx:f}),EE.$set(w5e);const Tw={};u&2&&(Tw.$$scope={dirty:u,ctx:f}),AE.$set(Tw);const A5e={};u&2&&(A5e.$$scope={dirty:u,ctx:f}),LE.$set(A5e);const y5e={};u&2&&(y5e.$$scope={dirty:u,ctx:f}),$E.$set(y5e);const Mw={};u&2&&(Mw.$$scope={dirty:u,ctx:f}),SE.$set(Mw);const L5e={};u&2&&(L5e.$$scope={dirty:u,ctx:f}),ZE.$set(L5e);const x5e={};u&2&&(x5e.$$scope={dirty:u,ctx:f}),oC.$set(x5e);const Ew={};u&2&&(Ew.$$scope={dirty:u,ctx:f}),MC.$set(Ew);const $5e={};u&2&&($5e.$$scope={dirty:u,ctx:f}),CC.$set($5e);const k5e={};u&2&&(k5e.$$scope={dirty:u,ctx:f}),AC.$set(k5e);const Cw={};u&2&&(Cw.$$scope={dirty:u,ctx:f}),LC.$set(Cw);const S5e={};u&2&&(S5e.$$scope={dirty:u,ctx:f}),$C.$set(S5e);const R5e={};u&2&&(R5e.$$scope={dirty:u,ctx:f}),SC.$set(R5e);const ww={};u&2&&(ww.$$scope={dirty:u,ctx:f}),a5.$set(ww);const P5e={};u&2&&(P5e.$$scope={dirty:u,ctx:f}),s5.$set(P5e);const B5e={};u&2&&(B5e.$$scope={dirty:u,ctx:f}),_5.$set(B5e);const Aw={};u&2&&(Aw.$$scope={dirty:u,ctx:f}),b5.$set(Aw);const I5e={};u&2&&(I5e.$$scope={dirty:u,ctx:f}),k5.$set(I5e);const N5e={};u&2&&(N5e.$$scope={dirty:u,ctx:f}),R5.$set(N5e);const yw={};u&2&&(yw.$$scope={dirty:u,ctx:f}),X5.$set(yw);const q5e={};u&2&&(q5e.$$scope={dirty:u,ctx:f}),W5.$set(q5e);const j5e={};u&2&&(j5e.$$scope={dirty:u,ctx:f}),r3.$set(j5e);const Lw={};u&2&&(Lw.$$scope={dirty:u,ctx:f}),a3.$set(Lw);const D5e={};u&2&&(D5e.$$scope={dirty:u,ctx:f}),p3.$set(D5e);const G5e={};u&2&&(G5e.$$scope={dirty:u,ctx:f}),u3.$set(G5e);const xw={};u&2&&(xw.$$scope={dirty:u,ctx:f}),L3.$set(xw);const O5e={};u&2&&(O5e.$$scope={dirty:u,ctx:f}),$3.$set(O5e);const V5e={};u&2&&(V5e.$$scope={dirty:u,ctx:f}),j3.$set(V5e);const $w={};u&2&&($w.$$scope={dirty:u,ctx:f}),G3.$set($w);const X5e={};u&2&&(X5e.$$scope={dirty:u,ctx:f}),J3.$set(X5e);const z5e={};u&2&&(z5e.$$scope={dirty:u,ctx:f}),K3.$set(z5e);const kw={};u&2&&(kw.$$scope={dirty:u,ctx:f}),ew.$set(kw);const W5e={};u&2&&(W5e.$$scope={dirty:u,ctx:f}),rw.$set(W5e);const Q5e={};u&2&&(Q5e.$$scope={dirty:u,ctx:f}),nw.$set(Q5e);const Sw={};u&2&&(Sw.$$scope={dirty:u,ctx:f}),lw.$set(Sw);const H5e={};u&2&&(H5e.$$scope={dirty:u,ctx:f}),dw.$set(H5e)},i(f){bDe||(E(d.$$.fragment,f),E(Ca.$$.fragment,f),E(kA.$$.fragment,f),E(SA.$$.fragment,f),E(Tf.$$.fragment,f),E(RA.$$.fragment,f),E(PA.$$.fragment,f),E(NA.$$.fragment,f),E(wg.$$.fragment,f),E(qA.$$.fragment,f),E(jA.$$.fragment,f),E(DA.$$.fragment,f),E(VA.$$.fragment,f),E(sh.$$.fragment,f),E(XA.$$.fragment,f),E(zA.$$.fragment,f),E(WA.$$.fragment,f),E(UA.$$.fragment,f),E(jh.$$.fragment,f),E(Dh.$$.fragment,f),E(JA.$$.fragment,f),E(YA.$$.fragment,f),E(KA.$$.fragment,f),E(oy.$$.fragment,f),E(sp.$$.fragment,f),E(lp.$$.fragment,f),E(ry.$$.fragment,f),E(ty.$$.fragment,f),E(ay.$$.fragment,f),E(sy.$$.fragment,f),E(cp.$$.fragment,f),E(ly.$$.fragment,f),E(su.$$.fragment,f),E(iy.$$.fragment,f),E(dy.$$.fragment,f),E(fy.$$.fragment,f),E(iu.$$.fragment,f),E(my.$$.fragment,f),E(Ku.$$.fragment,f),E(gy.$$.fragment,f),E(hy.$$.fragment,f),E(_y.$$.fragment,f),E(e6.$$.fragment,f),E(uy.$$.fragment,f),E(j6.$$.fragment,f),E(by.$$.fragment,f),E(vy.$$.fragment,f),E(Ty.$$.fragment,f),E(G6.$$.fragment,f),E(My.$$.fragment,f),E(C1.$$.fragment,f),E(Ey.$$.fragment,f),E(Cy.$$.fragment,f),E(Ay.$$.fragment,f),E(A1.$$.fragment,f),E(yy.$$.fragment,f),E(X1.$$.fragment,f),E(Ly.$$.fragment,f),E(xy.$$.fragment,f),E(ky.$$.fragment,f),E(W1.$$.fragment,f),E(Sy.$$.fragment,f),E(Gb.$$.fragment,f),E(Ry.$$.fragment,f),E(Py.$$.fragment,f),E(Iy.$$.fragment,f),E(Vb.$$.fragment,f),E(Ny.$$.fragment,f),E(F2.$$.fragment,f),E(qy.$$.fragment,f),E(jy.$$.fragment,f),E(Gy.$$.fragment,f),E(M2.$$.fragment,f),E(Oy.$$.fragment,f),E(x2.$$.fragment,f),E(Vy.$$.fragment,f),E(Xy.$$.fragment,f),E(Wy.$$.fragment,f),E(k2.$$.fragment,f),E(Qy.$$.fragment,f),E(g4.$$.fragment,f),E(Hy.$$.fragment,f),E(Uy.$$.fragment,f),E(Yy.$$.fragment,f),E(p4.$$.fragment,f),E(Ky.$$.fragment,f),E(tv.$$.fragment,f),E(Zy.$$.fragment,f),E(eL.$$.fragment,f),E(rL.$$.fragment,f),E(nv.$$.fragment,f),E(tL.$$.fragment,f),E(iv.$$.fragment,f),E(aL.$$.fragment,f),E(nL.$$.fragment,f),E(lL.$$.fragment,f),E(cv.$$.fragment,f),E(iL.$$.fragment,f),E(Cv.$$.fragment,f),E(dL.$$.fragment,f),E(cL.$$.fragment,f),E(mL.$$.fragment,f),E(Av.$$.fragment,f),E(gL.$$.fragment,f),E(xv.$$.fragment,f),E(hL.$$.fragment,f),E(pL.$$.fragment,f),E(uL.$$.fragment,f),E(kv.$$.fragment,f),E(bL.$$.fragment,f),E(Ov.$$.fragment,f),E(vL.$$.fragment,f),E(FL.$$.fragment,f),E(ML.$$.fragment,f),E(Xv.$$.fragment,f),E(EL.$$.fragment,f),E(Yv.$$.fragment,f),E(CL.$$.fragment,f),E(wL.$$.fragment,f),E(yL.$$.fragment,f),E(Zv.$$.fragment,f),E(LL.$$.fragment,f),E(cF.$$.fragment,f),E(xL.$$.fragment,f),E($L.$$.fragment,f),E(SL.$$.fragment,f),E(mF.$$.fragment,f),E(RL.$$.fragment,f),E(_F.$$.fragment,f),E(BL.$$.fragment,f),E(IL.$$.fragment,f),E(qL.$$.fragment,f),E(bF.$$.fragment,f),E(jL.$$.fragment,f),E(wF.$$.fragment,f),E(DL.$$.fragment,f),E(GL.$$.fragment,f),E(VL.$$.fragment,f),E(yF.$$.fragment,f),E(XL.$$.fragment,f),E(SF.$$.fragment,f),E(zL.$$.fragment,f),E(WL.$$.fragment,f),E(HL.$$.fragment,f),E(PF.$$.fragment,f),E(UL.$$.fragment,f),E(qF.$$.fragment,f),E(YL.$$.fragment,f),E(KL.$$.fragment,f),E(e8.$$.fragment,f),E(DF.$$.fragment,f),E(o8.$$.fragment,f),E(VF.$$.fragment,f),E(r8.$$.fragment,f),E(t8.$$.fragment,f),E(n8.$$.fragment,f),E(zF.$$.fragment,f),E(s8.$$.fragment,f),E(YF.$$.fragment,f),E(l8.$$.fragment,f),E(i8.$$.fragment,f),E(c8.$$.fragment,f),E(ZF.$$.fragment,f),E(f8.$$.fragment,f),E(rT.$$.fragment,f),E(m8.$$.fragment,f),E(g8.$$.fragment,f),E(p8.$$.fragment,f),E(aT.$$.fragment,f),E(_8.$$.fragment,f),E(JT.$$.fragment,f),E(u8.$$.fragment,f),E(b8.$$.fragment,f),E(F8.$$.fragment,f),E(KT.$$.fragment,f),E(T8.$$.fragment,f),E(M7.$$.fragment,f),E(M8.$$.fragment,f),E(E8.$$.fragment,f),E(w8.$$.fragment,f),E(C7.$$.fragment,f),E(A8.$$.fragment,f),E(N7.$$.fragment,f),E(y8.$$.fragment,f),E(L8.$$.fragment,f),E($8.$$.fragment,f),E(j7.$$.fragment,f),E(k8.$$.fragment,f),E(X7.$$.fragment,f),E(S8.$$.fragment,f),E(R8.$$.fragment,f),E(B8.$$.fragment,f),E(W7.$$.fragment,f),E(I8.$$.fragment,f),E(gM.$$.fragment,f),E(N8.$$.fragment,f),E(q8.$$.fragment,f),E(D8.$$.fragment,f),E(pM.$$.fragment,f),E(G8.$$.fragment,f),E(AM.$$.fragment,f),E(O8.$$.fragment,f),E(V8.$$.fragment,f),E(z8.$$.fragment,f),E(LM.$$.fragment,f),E(W8.$$.fragment,f),E(oE.$$.fragment,f),E(Q8.$$.fragment,f),E(H8.$$.fragment,f),E(J8.$$.fragment,f),E(tE.$$.fragment,f),E(Y8.$$.fragment,f),E(TE.$$.fragment,f),E(K8.$$.fragment,f),E(Z8.$$.fragment,f),E(o9.$$.fragment,f),E(EE.$$.fragment,f),E(r9.$$.fragment,f),E(AE.$$.fragment,f),E(a9.$$.fragment,f),E(n9.$$.fragment,f),E(l9.$$.fragment,f),E(LE.$$.fragment,f),E(i9.$$.fragment,f),E($E.$$.fragment,f),E(d9.$$.fragment,f),E(c9.$$.fragment,f),E(m9.$$.fragment,f),E(SE.$$.fragment,f),E(g9.$$.fragment,f),E(ZE.$$.fragment,f),E(h9.$$.fragment,f),E(p9.$$.fragment,f),E(u9.$$.fragment,f),E(oC.$$.fragment,f),E(b9.$$.fragment,f),E(MC.$$.fragment,f),E(v9.$$.fragment,f),E(F9.$$.fragment,f),E(M9.$$.fragment,f),E(CC.$$.fragment,f),E(E9.$$.fragment,f),E(AC.$$.fragment,f),E(C9.$$.fragment,f),E(w9.$$.fragment,f),E(y9.$$.fragment,f),E(LC.$$.fragment,f),E(L9.$$.fragment,f),E($C.$$.fragment,f),E(x9.$$.fragment,f),E($9.$$.fragment,f),E(S9.$$.fragment,f),E(SC.$$.fragment,f),E(R9.$$.fragment,f),E(a5.$$.fragment,f),E(P9.$$.fragment,f),E(B9.$$.fragment,f),E(N9.$$.fragment,f),E(s5.$$.fragment,f),E(q9.$$.fragment,f),E(_5.$$.fragment,f),E(j9.$$.fragment,f),E(D9.$$.fragment,f),E(O9.$$.fragment,f),E(b5.$$.fragment,f),E(V9.$$.fragment,f),E(k5.$$.fragment,f),E(X9.$$.fragment,f),E(z9.$$.fragment,f),E(Q9.$$.fragment,f),E(R5.$$.fragment,f),E(H9.$$.fragment,f),E(X5.$$.fragment,f),E(U9.$$.fragment,f),E(J9.$$.fragment,f),E(K9.$$.fragment,f),E(W5.$$.fragment,f),E(Z9.$$.fragment,f),E(r3.$$.fragment,f),E(ex.$$.fragment,f),E(ox.$$.fragment,f),E(tx.$$.fragment,f),E(a3.$$.fragment,f),E(ax.$$.fragment,f),E(p3.$$.fragment,f),E(nx.$$.fragment,f),E(sx.$$.fragment,f),E(ix.$$.fragment,f),E(u3.$$.fragment,f),E(dx.$$.fragment,f),E(L3.$$.fragment,f),E(cx.$$.fragment,f),E(fx.$$.fragment,f),E(gx.$$.fragment,f),E($3.$$.fragment,f),E(hx.$$.fragment,f),E(j3.$$.fragment,f),E(px.$$.fragment,f),E(_x.$$.fragment,f),E(bx.$$.fragment,f),E(G3.$$.fragment,f),E(vx.$$.fragment,f),E(J3.$$.fragment,f),E(Fx.$$.fragment,f),E(Tx.$$.fragment,f),E(Ex.$$.fragment,f),E(K3.$$.fragment,f),E(Cx.$$.fragment,f),E(ew.$$.fragment,f),E(wx.$$.fragment,f),E(Ax.$$.fragment,f),E(Lx.$$.fragment,f),E(rw.$$.fragment,f),E(xx.$$.fragment,f),E(nw.$$.fragment,f),E(kx.$$.fragment,f),E(Sx.$$.fragment,f),E(Px.$$.fragment,f),E(lw.$$.fragment,f),E(Bx.$$.fragment,f),E(dw.$$.fragment,f),bDe=!0)},o(f){C(d.$$.fragment,f),C(Ca.$$.fragment,f),C(kA.$$.fragment,f),C(SA.$$.fragment,f),C(Tf.$$.fragment,f),C(RA.$$.fragment,f),C(PA.$$.fragment,f),C(NA.$$.fragment,f),C(wg.$$.fragment,f),C(qA.$$.fragment,f),C(jA.$$.fragment,f),C(DA.$$.fragment,f),C(VA.$$.fragment,f),C(sh.$$.fragment,f),C(XA.$$.fragment,f),C(zA.$$.fragment,f),C(WA.$$.fragment,f),C(UA.$$.fragment,f),C(jh.$$.fragment,f),C(Dh.$$.fragment,f),C(JA.$$.fragment,f),C(YA.$$.fragment,f),C(KA.$$.fragment,f),C(oy.$$.fragment,f),C(sp.$$.fragment,f),C(lp.$$.fragment,f),C(ry.$$.fragment,f),C(ty.$$.fragment,f),C(ay.$$.fragment,f),C(sy.$$.fragment,f),C(cp.$$.fragment,f),C(ly.$$.fragment,f),C(su.$$.fragment,f),C(iy.$$.fragment,f),C(dy.$$.fragment,f),C(fy.$$.fragment,f),C(iu.$$.fragment,f),C(my.$$.fragment,f),C(Ku.$$.fragment,f),C(gy.$$.fragment,f),C(hy.$$.fragment,f),C(_y.$$.fragment,f),C(e6.$$.fragment,f),C(uy.$$.fragment,f),C(j6.$$.fragment,f),C(by.$$.fragment,f),C(vy.$$.fragment,f),C(Ty.$$.fragment,f),C(G6.$$.fragment,f),C(My.$$.fragment,f),C(C1.$$.fragment,f),C(Ey.$$.fragment,f),C(Cy.$$.fragment,f),C(Ay.$$.fragment,f),C(A1.$$.fragment,f),C(yy.$$.fragment,f),C(X1.$$.fragment,f),C(Ly.$$.fragment,f),C(xy.$$.fragment,f),C(ky.$$.fragment,f),C(W1.$$.fragment,f),C(Sy.$$.fragment,f),C(Gb.$$.fragment,f),C(Ry.$$.fragment,f),C(Py.$$.fragment,f),C(Iy.$$.fragment,f),C(Vb.$$.fragment,f),C(Ny.$$.fragment,f),C(F2.$$.fragment,f),C(qy.$$.fragment,f),C(jy.$$.fragment,f),C(Gy.$$.fragment,f),C(M2.$$.fragment,f),C(Oy.$$.fragment,f),C(x2.$$.fragment,f),C(Vy.$$.fragment,f),C(Xy.$$.fragment,f),C(Wy.$$.fragment,f),C(k2.$$.fragment,f),C(Qy.$$.fragment,f),C(g4.$$.fragment,f),C(Hy.$$.fragment,f),C(Uy.$$.fragment,f),C(Yy.$$.fragment,f),C(p4.$$.fragment,f),C(Ky.$$.fragment,f),C(tv.$$.fragment,f),C(Zy.$$.fragment,f),C(eL.$$.fragment,f),C(rL.$$.fragment,f),C(nv.$$.fragment,f),C(tL.$$.fragment,f),C(iv.$$.fragment,f),C(aL.$$.fragment,f),C(nL.$$.fragment,f),C(lL.$$.fragment,f),C(cv.$$.fragment,f),C(iL.$$.fragment,f),C(Cv.$$.fragment,f),C(dL.$$.fragment,f),C(cL.$$.fragment,f),C(mL.$$.fragment,f),C(Av.$$.fragment,f),C(gL.$$.fragment,f),C(xv.$$.fragment,f),C(hL.$$.fragment,f),C(pL.$$.fragment,f),C(uL.$$.fragment,f),C(kv.$$.fragment,f),C(bL.$$.fragment,f),C(Ov.$$.fragment,f),C(vL.$$.fragment,f),C(FL.$$.fragment,f),C(ML.$$.fragment,f),C(Xv.$$.fragment,f),C(EL.$$.fragment,f),C(Yv.$$.fragment,f),C(CL.$$.fragment,f),C(wL.$$.fragment,f),C(yL.$$.fragment,f),C(Zv.$$.fragment,f),C(LL.$$.fragment,f),C(cF.$$.fragment,f),C(xL.$$.fragment,f),C($L.$$.fragment,f),C(SL.$$.fragment,f),C(mF.$$.fragment,f),C(RL.$$.fragment,f),C(_F.$$.fragment,f),C(BL.$$.fragment,f),C(IL.$$.fragment,f),C(qL.$$.fragment,f),C(bF.$$.fragment,f),C(jL.$$.fragment,f),C(wF.$$.fragment,f),C(DL.$$.fragment,f),C(GL.$$.fragment,f),C(VL.$$.fragment,f),C(yF.$$.fragment,f),C(XL.$$.fragment,f),C(SF.$$.fragment,f),C(zL.$$.fragment,f),C(WL.$$.fragment,f),C(HL.$$.fragment,f),C(PF.$$.fragment,f),C(UL.$$.fragment,f),C(qF.$$.fragment,f),C(YL.$$.fragment,f),C(KL.$$.fragment,f),C(e8.$$.fragment,f),C(DF.$$.fragment,f),C(o8.$$.fragment,f),C(VF.$$.fragment,f),C(r8.$$.fragment,f),C(t8.$$.fragment,f),C(n8.$$.fragment,f),C(zF.$$.fragment,f),C(s8.$$.fragment,f),C(YF.$$.fragment,f),C(l8.$$.fragment,f),C(i8.$$.fragment,f),C(c8.$$.fragment,f),C(ZF.$$.fragment,f),C(f8.$$.fragment,f),C(rT.$$.fragment,f),C(m8.$$.fragment,f),C(g8.$$.fragment,f),C(p8.$$.fragment,f),C(aT.$$.fragment,f),C(_8.$$.fragment,f),C(JT.$$.fragment,f),C(u8.$$.fragment,f),C(b8.$$.fragment,f),C(F8.$$.fragment,f),C(KT.$$.fragment,f),C(T8.$$.fragment,f),C(M7.$$.fragment,f),C(M8.$$.fragment,f),C(E8.$$.fragment,f),C(w8.$$.fragment,f),C(C7.$$.fragment,f),C(A8.$$.fragment,f),C(N7.$$.fragment,f),C(y8.$$.fragment,f),C(L8.$$.fragment,f),C($8.$$.fragment,f),C(j7.$$.fragment,f),C(k8.$$.fragment,f),C(X7.$$.fragment,f),C(S8.$$.fragment,f),C(R8.$$.fragment,f),C(B8.$$.fragment,f),C(W7.$$.fragment,f),C(I8.$$.fragment,f),C(gM.$$.fragment,f),C(N8.$$.fragment,f),C(q8.$$.fragment,f),C(D8.$$.fragment,f),C(pM.$$.fragment,f),C(G8.$$.fragment,f),C(AM.$$.fragment,f),C(O8.$$.fragment,f),C(V8.$$.fragment,f),C(z8.$$.fragment,f),C(LM.$$.fragment,f),C(W8.$$.fragment,f),C(oE.$$.fragment,f),C(Q8.$$.fragment,f),C(H8.$$.fragment,f),C(J8.$$.fragment,f),C(tE.$$.fragment,f),C(Y8.$$.fragment,f),C(TE.$$.fragment,f),C(K8.$$.fragment,f),C(Z8.$$.fragment,f),C(o9.$$.fragment,f),C(EE.$$.fragment,f),C(r9.$$.fragment,f),C(AE.$$.fragment,f),C(a9.$$.fragment,f),C(n9.$$.fragment,f),C(l9.$$.fragment,f),C(LE.$$.fragment,f),C(i9.$$.fragment,f),C($E.$$.fragment,f),C(d9.$$.fragment,f),C(c9.$$.fragment,f),C(m9.$$.fragment,f),C(SE.$$.fragment,f),C(g9.$$.fragment,f),C(ZE.$$.fragment,f),C(h9.$$.fragment,f),C(p9.$$.fragment,f),C(u9.$$.fragment,f),C(oC.$$.fragment,f),C(b9.$$.fragment,f),C(MC.$$.fragment,f),C(v9.$$.fragment,f),C(F9.$$.fragment,f),C(M9.$$.fragment,f),C(CC.$$.fragment,f),C(E9.$$.fragment,f),C(AC.$$.fragment,f),C(C9.$$.fragment,f),C(w9.$$.fragment,f),C(y9.$$.fragment,f),C(LC.$$.fragment,f),C(L9.$$.fragment,f),C($C.$$.fragment,f),C(x9.$$.fragment,f),C($9.$$.fragment,f),C(S9.$$.fragment,f),C(SC.$$.fragment,f),C(R9.$$.fragment,f),C(a5.$$.fragment,f),C(P9.$$.fragment,f),C(B9.$$.fragment,f),C(N9.$$.fragment,f),C(s5.$$.fragment,f),C(q9.$$.fragment,f),C(_5.$$.fragment,f),C(j9.$$.fragment,f),C(D9.$$.fragment,f),C(O9.$$.fragment,f),C(b5.$$.fragment,f),C(V9.$$.fragment,f),C(k5.$$.fragment,f),C(X9.$$.fragment,f),C(z9.$$.fragment,f),C(Q9.$$.fragment,f),C(R5.$$.fragment,f),C(H9.$$.fragment,f),C(X5.$$.fragment,f),C(U9.$$.fragment,f),C(J9.$$.fragment,f),C(K9.$$.fragment,f),C(W5.$$.fragment,f),C(Z9.$$.fragment,f),C(r3.$$.fragment,f),C(ex.$$.fragment,f),C(ox.$$.fragment,f),C(tx.$$.fragment,f),C(a3.$$.fragment,f),C(ax.$$.fragment,f),C(p3.$$.fragment,f),C(nx.$$.fragment,f),C(sx.$$.fragment,f),C(ix.$$.fragment,f),C(u3.$$.fragment,f),C(dx.$$.fragment,f),C(L3.$$.fragment,f),C(cx.$$.fragment,f),C(fx.$$.fragment,f),C(gx.$$.fragment,f),C($3.$$.fragment,f),C(hx.$$.fragment,f),C(j3.$$.fragment,f),C(px.$$.fragment,f),C(_x.$$.fragment,f),C(bx.$$.fragment,f),C(G3.$$.fragment,f),C(vx.$$.fragment,f),C(J3.$$.fragment,f),C(Fx.$$.fragment,f),C(Tx.$$.fragment,f),C(Ex.$$.fragment,f),C(K3.$$.fragment,f),C(Cx.$$.fragment,f),C(ew.$$.fragment,f),C(wx.$$.fragment,f),C(Ax.$$.fragment,f),C(Lx.$$.fragment,f),C(rw.$$.fragment,f),C(xx.$$.fragment,f),C(nw.$$.fragment,f),C(kx.$$.fragment,f),C(Sx.$$.fragment,f),C(Px.$$.fragment,f),C(lw.$$.fragment,f),C(Bx.$$.fragment,f),C(dw.$$.fragment,f),bDe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(_f),f&&t(rt),f&&t(je),f&&t(We),f&&t(bf),w(Ca,f),f&&t(Qe),f&&t(Ae),f&&t(Eo),f&&t(wa),f&&t(pqe),f&&t(vi),w(kA),f&&t(_qe),f&&t(kn),f&&t(uqe),w(SA,f),f&&t(bqe),f&&t(ok),f&&t(vqe),w(Tf,f),f&&t(Fqe),f&&t(Fi),w(RA),f&&t(Tqe),f&&t(Co),w(PA),w(NA),w(wg),w(qA),f&&t(Mqe),f&&t(Mi),w(jA),f&&t(Eqe),f&&t(wo),w(DA),w(VA),w(sh),w(XA),f&&t(Cqe),f&&t(Ei),w(zA),f&&t(wqe),f&&t(Ao),w(WA),w(UA),w(jh),w(Dh),w(JA),f&&t(Aqe),f&&t(Ci),w(YA),f&&t(yqe),f&&t(yo),w(KA),w(oy),w(sp),w(lp),w(ry),f&&t(Lqe),f&&t(Ai),w(ty),f&&t(xqe),f&&t(Lo),w(ay),w(sy),w(cp),w(ly),w(su),f&&t($qe),f&&t(xi),w(iy),f&&t(kqe),f&&t(xo),w(dy),w(fy),w(iu),w(my),w(Ku),f&&t(Sqe),f&&t(Si),w(gy),f&&t(Rqe),f&&t($o),w(hy),w(_y),w(e6),w(uy),w(j6),f&&t(Pqe),f&&t(Bi),w(by),f&&t(Bqe),f&&t(ko),w(vy),w(Ty),w(G6),w(My),w(C1),f&&t(Iqe),f&&t(qi),w(Ey),f&&t(Nqe),f&&t(So),w(Cy),w(Ay),w(A1),w(yy),w(X1),f&&t(qqe),f&&t(Gi),w(Ly),f&&t(jqe),f&&t(Ro),w(xy),w(ky),w(W1),w(Sy),w(Gb),f&&t(Dqe),f&&t(Xi),w(Ry),f&&t(Gqe),f&&t(Po),w(Py),w(Iy),w(Vb),w(Ny),w(F2),f&&t(Oqe),f&&t(Qi),w(qy),f&&t(Vqe),f&&t(Bo),w(jy),w(Gy),w(M2),w(Oy),w(x2),f&&t(Xqe),f&&t(Ji),w(Vy),f&&t(zqe),f&&t(Io),w(Xy),w(Wy),w(k2),w(Qy),w(g4),f&&t(Wqe),f&&t(Zi),w(Hy),f&&t(Qqe),f&&t(No),w(Uy),w(Yy),w(p4),w(Ky),w(tv),f&&t(Hqe),f&&t(rd),w(Zy),f&&t(Uqe),f&&t(qo),w(eL),w(rL),w(nv),w(tL),w(iv),f&&t(Jqe),f&&t(nd),w(aL),f&&t(Yqe),f&&t(jo),w(nL),w(lL),w(cv),w(iL),w(Cv),f&&t(Kqe),f&&t(id),w(dL),f&&t(Zqe),f&&t(Do),w(cL),w(mL),w(Av),w(gL),w(xv),f&&t(eje),f&&t(fd),w(hL),f&&t(oje),f&&t(Go),w(pL),w(uL),w(kv),w(bL),w(Ov),f&&t(rje),f&&t(hd),w(vL),f&&t(tje),f&&t(Oo),w(FL),w(ML),w(Xv),w(EL),w(Yv),f&&t(aje),f&&t(ud),w(CL),f&&t(nje),f&&t(Vo),w(wL),w(yL),w(Zv),w(LL),w(cF),f&&t(sje),f&&t(Fd),w(xL),f&&t(lje),f&&t(Xo),w($L),w(SL),w(mF),w(RL),w(_F),f&&t(ije),f&&t(Ed),w(BL),f&&t(dje),f&&t(zo),w(IL),w(qL),w(bF),w(jL),w(wF),f&&t(cje),f&&t(Ad),w(DL),f&&t(fje),f&&t(Wo),w(GL),w(VL),w(yF),w(XL),w(SF),f&&t(mje),f&&t($d),w(zL),f&&t(gje),f&&t(Qo),w(WL),w(HL),w(PF),w(UL),w(qF),f&&t(hje),f&&t(Rd),w(YL),f&&t(pje),f&&t(Ho),w(KL),w(e8),w(DF),w(o8),w(VF),f&&t(_je),f&&t(Id),w(r8),f&&t(uje),f&&t(Uo),w(t8),w(n8),w(zF),w(s8),w(YF),f&&t(bje),f&&t(jd),w(l8),f&&t(vje),f&&t(Jo),w(i8),w(c8),w(ZF),w(f8),w(rT),f&&t(Fje),f&&t(Od),w(m8),f&&t(Tje),f&&t(Yo),w(g8),w(p8),w(aT),w(_8),w(JT),f&&t(Mje),f&&t(zd),w(u8),f&&t(Eje),f&&t(Ko),w(b8),w(F8),w(KT),w(T8),w(M7),f&&t(Cje),f&&t(Hd),w(M8),f&&t(wje),f&&t(Zo),w(E8),w(w8),w(C7),w(A8),w(N7),f&&t(Aje),f&&t(Yd),w(y8),f&&t(yje),f&&t(er),w(L8),w($8),w(j7),w(k8),w(X7),f&&t(Lje),f&&t(ec),w(S8),f&&t(xje),f&&t(or),w(R8),w(B8),w(W7),w(I8),w(gM),f&&t($je),f&&t(tc),w(N8),f&&t(kje),f&&t(rr),w(q8),w(D8),w(pM),w(G8),w(AM),f&&t(Sje),f&&t(sc),w(O8),f&&t(Rje),f&&t(tr),w(V8),w(z8),w(LM),w(W8),w(oE),f&&t(Pje),f&&t(dc),w(Q8),f&&t(Bje),f&&t(ar),w(H8),w(J8),w(tE),w(Y8),w(TE),f&&t(Ije),f&&t(mc),w(K8),f&&t(Nje),f&&t(nr),w(Z8),w(o9),w(EE),w(r9),w(AE),f&&t(qje),f&&t(pc),w(a9),f&&t(jje),f&&t(sr),w(n9),w(l9),w(LE),w(i9),w($E),f&&t(Dje),f&&t(bc),w(d9),f&&t(Gje),f&&t(lr),w(c9),w(m9),w(SE),w(g9),w(ZE),f&&t(Oje),f&&t(Tc),w(h9),f&&t(Vje),f&&t(ir),w(p9),w(u9),w(oC),w(b9),w(MC),f&&t(Xje),f&&t(Cc),w(v9),f&&t(zje),f&&t(dr),w(F9),w(M9),w(CC),w(E9),w(AC),f&&t(Wje),f&&t(yc),w(C9),f&&t(Qje),f&&t(cr),w(w9),w(y9),w(LC),w(L9),w($C),f&&t(Hje),f&&t($c),w(x9),f&&t(Uje),f&&t(fr),w($9),w(S9),w(SC),w(R9),w(a5),f&&t(Jje),f&&t(Rc),w(P9),f&&t(Yje),f&&t(mr),w(B9),w(N9),w(s5),w(q9),w(_5),f&&t(Kje),f&&t(Ic),w(j9),f&&t(Zje),f&&t(gr),w(D9),w(O9),w(b5),w(V9),w(k5),f&&t(eDe),f&&t(jc),w(X9),f&&t(oDe),f&&t(hr),w(z9),w(Q9),w(R5),w(H9),w(X5),f&&t(rDe),f&&t(Oc),w(U9),f&&t(tDe),f&&t(pr),w(J9),w(K9),w(W5),w(Z9),w(r3),f&&t(aDe),f&&t(zc),w(ex),f&&t(nDe),f&&t(_r),w(ox),w(tx),w(a3),w(ax),w(p3),f&&t(sDe),f&&t(Hc),w(nx),f&&t(lDe),f&&t(ur),w(sx),w(ix),w(u3),w(dx),w(L3),f&&t(iDe),f&&t(Yc),w(cx),f&&t(dDe),f&&t(br),w(fx),w(gx),w($3),w(hx),w(j3),f&&t(cDe),f&&t(ef),w(px),f&&t(fDe),f&&t(vr),w(_x),w(bx),w(G3),w(vx),w(J3),f&&t(mDe),f&&t(tf),w(Fx),f&&t(gDe),f&&t(Fr),w(Tx),w(Ex),w(K3),w(Cx),w(ew),f&&t(hDe),f&&t(sf),w(wx),f&&t(pDe),f&&t(Tr),w(Ax),w(Lx),w(rw),w(xx),w(nw),f&&t(_De),f&&t(cf),w(kx),f&&t(uDe),f&&t(Mr),w(Sx),w(Px),w(lw),w(Bx),w(dw)}}}const tRt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function aRt(L){return akt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class fRt extends ekt{constructor(g){super();okt(this,g,aRt,rRt,rkt,{})}}export{fRt as default,tRt as metadata};
