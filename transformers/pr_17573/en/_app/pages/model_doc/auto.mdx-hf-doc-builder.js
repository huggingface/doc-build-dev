import{S as vDt,i as FDt,s as TDt,e as a,k as l,w as F,t as o,M as MDt,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as EDt,L as I}from"../../chunks/vendor-hf-doc-builder.js";import{T as KYr}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as re}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function CDt(x){let g,v,p,m,_,d,h,Eo,Ti,yf,at,Mi,Ei,wL,xf,Oe,Qe,Ci,Rn,AL,Pn,Bn,LL,wi,In,yL,Ai,$f,xa;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),_=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Eo=o(`, make sure its
`),Ti=a("code"),yf=o("model_type"),at=o(" attribute is set to the same key you use when registering the config (here "),Mi=a("code"),Ei=o('"new-model"'),wL=o(")."),xf=l(),Oe=a("p"),Qe=o("Likewise, if your "),Ci=a("code"),Rn=o("NewModel"),AL=o(" is a subclass of "),Pn=a("a"),Bn=o("PreTrainedModel"),LL=o(`, make sure its
`),wi=a("code"),In=o("config_class"),yL=o(` attribute is set to the same class you use when registering the model (here
`),Ai=a("code"),$f=o("NewModelConfig"),xa=o(")."),this.h()},l(We){g=n(We,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var rS=s(p);m=r(rS,"NewModelConfig"),rS.forEach(t),_=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var Li=s(d);h=r(Li,"PretrainedConfig"),Li.forEach(t),Eo=r(Ae,`, make sure its
`),Ti=n(Ae,"CODE",{});var tS=s(Ti);yf=r(tS,"model_type"),tS.forEach(t),at=r(Ae," attribute is set to the same key you use when registering the config (here "),Mi=n(Ae,"CODE",{});var aS=s(Mi);Ei=r(aS,'"new-model"'),aS.forEach(t),wL=r(Ae,")."),Ae.forEach(t),xf=i(We),Oe=n(We,"P",{});var Co=s(Oe);Qe=r(Co,"Likewise, if your "),Ci=n(Co,"CODE",{});var $a=s(Ci);Rn=r($a,"NewModel"),$a.forEach(t),AL=r(Co," is a subclass of "),Pn=n(Co,"A",{href:!0});var nS=s(Pn);Bn=r(nS,"PreTrainedModel"),nS.forEach(t),LL=r(Co,`, make sure its
`),wi=n(Co,"CODE",{});var kf=s(wi);In=r(kf,"config_class"),kf.forEach(t),yL=r(Co,` attribute is set to the same class you use when registering the model (here
`),Ai=n(Co,"CODE",{});var sS=s(Ai);$f=r(sS,"NewModelConfig"),sS.forEach(t),xa=r(Co,")."),Co.forEach(t),this.h()},h(){c(Pn,"href","/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel")},m(We,Ae){b(We,g,Ae),e(g,v),e(g,p),e(p,m),e(g,_),e(g,d),e(d,h),e(g,Eo),e(g,Ti),e(Ti,yf),e(g,at),e(g,Mi),e(Mi,Ei),e(g,wL),b(We,xf,Ae),b(We,Oe,Ae),e(Oe,Qe),e(Oe,Ci),e(Ci,Rn),e(Oe,AL),e(Oe,Pn),e(Pn,Bn),e(Oe,LL),e(Oe,wi),e(wi,In),e(Oe,yL),e(Oe,Ai),e(Ai,$f),e(Oe,xa)},d(We){We&&t(g),We&&t(xf),We&&t(Oe)}}}function wDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ADt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LDt(x){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function yDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xDt(x){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function $Dt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ODt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function UDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Gt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function EGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function AGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $Gt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function OGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function UGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Ot(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function EOt(x){let g,v,p,m,_,d,h,Eo,Ti,yf,at,Mi,Ei,wL,xf,Oe,Qe,Ci,Rn,AL,Pn,Bn,LL,wi,In,yL,Ai,$f,xa,We,Ae,rS,Li,tS,aS,Co,$a,nS,kf,sS,eQe,jGe,yi,Sf,mte,xL,oQe,gte,rQe,DGe,Nn,tQe,hte,aQe,nQe,pte,sQe,lQe,GGe,$L,OGe,lS,iQe,VGe,Rf,XGe,xi,Pf,_te,kL,dQe,ute,cQe,zGe,wo,SL,fQe,RL,mQe,iS,gQe,hQe,pQe,PL,_Qe,bte,uQe,bQe,vQe,Ar,BL,FQe,vte,TQe,MQe,$i,EQe,Fte,CQe,wQe,Tte,AQe,LQe,yQe,A,Bf,Mte,xQe,$Qe,dS,kQe,SQe,RQe,If,Ete,PQe,BQe,cS,IQe,NQe,qQe,Nf,Cte,jQe,DQe,fS,GQe,OQe,VQe,qf,wte,XQe,zQe,mS,QQe,WQe,HQe,jf,Ate,UQe,JQe,gS,YQe,KQe,ZQe,Df,Lte,eWe,oWe,hS,rWe,tWe,aWe,Gf,yte,nWe,sWe,pS,lWe,iWe,dWe,Of,xte,cWe,fWe,_S,mWe,gWe,hWe,Vf,$te,pWe,_We,uS,uWe,bWe,vWe,Xf,kte,FWe,TWe,bS,MWe,EWe,CWe,zf,Ste,wWe,AWe,vS,LWe,yWe,xWe,Qf,Rte,$We,kWe,FS,SWe,RWe,PWe,Wf,Pte,BWe,IWe,TS,NWe,qWe,jWe,Hf,Bte,DWe,GWe,MS,OWe,VWe,XWe,Uf,Ite,zWe,QWe,ES,WWe,HWe,UWe,Jf,Nte,JWe,YWe,CS,KWe,ZWe,eHe,Yf,qte,oHe,rHe,wS,tHe,aHe,nHe,Kf,jte,sHe,lHe,AS,iHe,dHe,cHe,Zf,Dte,fHe,mHe,LS,gHe,hHe,pHe,em,Gte,_He,uHe,yS,bHe,vHe,FHe,om,Ote,THe,MHe,xS,EHe,CHe,wHe,rm,Vte,AHe,LHe,$S,yHe,xHe,$He,tm,Xte,kHe,SHe,kS,RHe,PHe,BHe,am,zte,IHe,NHe,SS,qHe,jHe,DHe,nm,Qte,GHe,OHe,RS,VHe,XHe,zHe,sm,Wte,QHe,WHe,PS,HHe,UHe,JHe,lm,Hte,YHe,KHe,BS,ZHe,eUe,oUe,im,Ute,rUe,tUe,IS,aUe,nUe,sUe,dm,Jte,lUe,iUe,NS,dUe,cUe,fUe,cm,Yte,mUe,gUe,qS,hUe,pUe,_Ue,fm,Kte,uUe,bUe,jS,vUe,FUe,TUe,mm,Zte,MUe,EUe,DS,CUe,wUe,AUe,gm,eae,LUe,yUe,GS,xUe,$Ue,kUe,hm,oae,SUe,RUe,OS,PUe,BUe,IUe,pm,rae,NUe,qUe,VS,jUe,DUe,GUe,_m,tae,OUe,VUe,XS,XUe,zUe,QUe,um,aae,WUe,HUe,zS,UUe,JUe,YUe,bm,nae,KUe,ZUe,QS,eJe,oJe,rJe,vm,sae,tJe,aJe,WS,nJe,sJe,lJe,Fm,lae,iJe,dJe,HS,cJe,fJe,mJe,Tm,iae,gJe,hJe,US,pJe,_Je,uJe,Mm,dae,bJe,vJe,JS,FJe,TJe,MJe,Em,cae,EJe,CJe,YS,wJe,AJe,LJe,Cm,fae,yJe,xJe,KS,$Je,kJe,SJe,wm,mae,RJe,PJe,ZS,BJe,IJe,NJe,Am,gae,qJe,jJe,eR,DJe,GJe,OJe,Lm,hae,VJe,XJe,oR,zJe,QJe,WJe,ym,pae,HJe,UJe,rR,JJe,YJe,KJe,xm,_ae,ZJe,eYe,tR,oYe,rYe,tYe,$m,uae,aYe,nYe,aR,sYe,lYe,iYe,km,bae,dYe,cYe,nR,fYe,mYe,gYe,Sm,vae,hYe,pYe,sR,_Ye,uYe,bYe,Rm,Fae,vYe,FYe,lR,TYe,MYe,EYe,Pm,Tae,CYe,wYe,iR,AYe,LYe,yYe,Bm,Mae,xYe,$Ye,dR,kYe,SYe,RYe,Im,Eae,PYe,BYe,cR,IYe,NYe,qYe,Nm,Cae,jYe,DYe,fR,GYe,OYe,VYe,qm,wae,XYe,zYe,mR,QYe,WYe,HYe,jm,Aae,UYe,JYe,gR,YYe,KYe,ZYe,Dm,Lae,eKe,oKe,hR,rKe,tKe,aKe,Gm,yae,nKe,sKe,pR,lKe,iKe,dKe,Om,xae,cKe,fKe,_R,mKe,gKe,hKe,Vm,$ae,pKe,_Ke,uR,uKe,bKe,vKe,Xm,kae,FKe,TKe,bR,MKe,EKe,CKe,zm,Sae,wKe,AKe,vR,LKe,yKe,xKe,Qm,Rae,$Ke,kKe,FR,SKe,RKe,PKe,Wm,Pae,BKe,IKe,TR,NKe,qKe,jKe,Hm,Bae,DKe,GKe,MR,OKe,VKe,XKe,Um,Iae,zKe,QKe,ER,WKe,HKe,UKe,Jm,Nae,JKe,YKe,CR,KKe,ZKe,eZe,Ym,qae,oZe,rZe,wR,tZe,aZe,nZe,Km,jae,sZe,lZe,AR,iZe,dZe,cZe,Zm,Dae,fZe,mZe,LR,gZe,hZe,pZe,eg,Gae,_Ze,uZe,yR,bZe,vZe,FZe,og,Oae,TZe,MZe,xR,EZe,CZe,wZe,rg,Vae,AZe,LZe,$R,yZe,xZe,$Ze,tg,Xae,kZe,SZe,kR,RZe,PZe,BZe,ag,zae,IZe,NZe,SR,qZe,jZe,DZe,ng,Qae,GZe,OZe,RR,VZe,XZe,zZe,sg,Wae,QZe,WZe,PR,HZe,UZe,JZe,lg,Hae,YZe,KZe,BR,ZZe,eeo,oeo,ig,Uae,reo,teo,IR,aeo,neo,seo,dg,Jae,leo,ieo,NR,deo,ceo,feo,cg,Yae,meo,geo,qR,heo,peo,_eo,fg,Kae,ueo,beo,jR,veo,Feo,Teo,mg,Zae,Meo,Eeo,DR,Ceo,weo,Aeo,gg,ene,Leo,yeo,GR,xeo,$eo,keo,hg,one,Seo,Reo,OR,Peo,Beo,Ieo,pg,rne,Neo,qeo,VR,jeo,Deo,Geo,_g,tne,Oeo,Veo,XR,Xeo,zeo,Qeo,ug,ane,Weo,Heo,zR,Ueo,Jeo,Yeo,bg,nne,Keo,Zeo,QR,eoo,ooo,roo,vg,sne,too,aoo,WR,noo,soo,loo,Fg,lne,ioo,doo,HR,coo,foo,moo,Tg,ine,goo,hoo,UR,poo,_oo,uoo,Mg,dne,boo,voo,JR,Foo,Too,Moo,Eg,cne,Eoo,Coo,YR,woo,Aoo,Loo,Cg,fne,yoo,xoo,KR,$oo,koo,Soo,wg,mne,Roo,Poo,ZR,Boo,Ioo,Noo,Ag,gne,qoo,joo,eP,Doo,Goo,Ooo,Lg,hne,Voo,Xoo,oP,zoo,Qoo,Woo,yg,pne,Hoo,Uoo,rP,Joo,Yoo,Koo,xg,_ne,Zoo,ero,tP,oro,rro,tro,$g,une,aro,nro,aP,sro,lro,iro,kg,bne,dro,cro,nP,fro,mro,gro,Sg,vne,hro,pro,sP,_ro,uro,bro,Rg,Fne,vro,Fro,lP,Tro,Mro,Ero,Pg,Tne,Cro,wro,iP,Aro,Lro,yro,Bg,Mne,xro,$ro,dP,kro,Sro,Rro,Ig,Ene,Pro,Bro,cP,Iro,Nro,qro,Ng,Cne,jro,Dro,fP,Gro,Oro,Vro,qg,wne,Xro,zro,mP,Qro,Wro,Hro,jg,Ane,Uro,Jro,gP,Yro,Kro,Zro,Dg,Lne,eto,oto,hP,rto,tto,ato,Gg,nto,Og,IL,sto,yne,lto,QGe,ki,Vg,xne,NL,ito,$ne,dto,WGe,Ao,qL,cto,jL,fto,pP,mto,gto,hto,DL,pto,kne,_to,uto,bto,Lr,GL,vto,Sne,Fto,Tto,ka,Mto,Rne,Eto,Cto,Pne,wto,Ato,Bne,Lto,yto,xto,k,qn,Ine,$to,kto,_P,Sto,Rto,uP,Pto,Bto,Ito,jn,Nne,Nto,qto,bP,jto,Dto,vP,Gto,Oto,Vto,Dn,qne,Xto,zto,FP,Qto,Wto,TP,Hto,Uto,Jto,Xg,jne,Yto,Kto,MP,Zto,eao,oao,Gn,Dne,rao,tao,EP,aao,nao,CP,sao,lao,iao,zg,Gne,dao,cao,wP,fao,mao,gao,Qg,One,hao,pao,AP,_ao,uao,bao,Wg,Vne,vao,Fao,LP,Tao,Mao,Eao,On,Xne,Cao,wao,yP,Aao,Lao,xP,yao,xao,$ao,Vn,zne,kao,Sao,$P,Rao,Pao,kP,Bao,Iao,Nao,Xn,Qne,qao,jao,SP,Dao,Gao,RP,Oao,Vao,Xao,Hg,Wne,zao,Qao,PP,Wao,Hao,Uao,Ug,Hne,Jao,Yao,BP,Kao,Zao,eno,Jg,Une,ono,rno,IP,tno,ano,nno,zn,Jne,sno,lno,NP,ino,dno,qP,cno,fno,mno,Yg,Yne,gno,hno,jP,pno,_no,uno,Qn,Kne,bno,vno,DP,Fno,Tno,GP,Mno,Eno,Cno,Wn,Zne,wno,Ano,OP,Lno,yno,VP,xno,$no,kno,Hn,ese,Sno,Rno,XP,Pno,Bno,zP,Ino,Nno,qno,Kg,ose,jno,Dno,QP,Gno,Ono,Vno,Un,rse,Xno,zno,WP,Qno,Wno,HP,Hno,Uno,Jno,Jn,tse,Yno,Kno,UP,Zno,eso,JP,oso,rso,tso,Yn,ase,aso,nso,YP,sso,lso,KP,iso,dso,cso,Kn,nse,fso,mso,ZP,gso,hso,eB,pso,_so,uso,Zn,sse,bso,vso,oB,Fso,Tso,rB,Mso,Eso,Cso,es,lse,wso,Aso,tB,Lso,yso,aB,xso,$so,kso,Zg,ise,Sso,Rso,nB,Pso,Bso,Iso,os,dse,Nso,qso,sB,jso,Dso,lB,Gso,Oso,Vso,eh,cse,Xso,zso,iB,Qso,Wso,Hso,rs,fse,Uso,Jso,dB,Yso,Kso,cB,Zso,elo,olo,ts,mse,rlo,tlo,fB,alo,nlo,mB,slo,llo,ilo,as,gse,dlo,clo,gB,flo,mlo,hB,glo,hlo,plo,oh,hse,_lo,ulo,pB,blo,vlo,Flo,ns,pse,Tlo,Mlo,_B,Elo,Clo,uB,wlo,Alo,Llo,ss,_se,ylo,xlo,bB,$lo,klo,vB,Slo,Rlo,Plo,rh,use,Blo,Ilo,FB,Nlo,qlo,jlo,ls,bse,Dlo,Glo,TB,Olo,Vlo,MB,Xlo,zlo,Qlo,is,vse,Wlo,Hlo,EB,Ulo,Jlo,CB,Ylo,Klo,Zlo,ds,Fse,eio,oio,wB,rio,tio,AB,aio,nio,sio,cs,Tse,lio,iio,LB,dio,cio,yB,fio,mio,gio,fs,Mse,hio,pio,xB,_io,uio,$B,bio,vio,Fio,ms,Ese,Tio,Mio,kB,Eio,Cio,SB,wio,Aio,Lio,gs,Cse,yio,xio,RB,$io,kio,PB,Sio,Rio,Pio,hs,wse,Bio,Iio,BB,Nio,qio,IB,jio,Dio,Gio,th,Ase,Oio,Vio,NB,Xio,zio,Qio,ps,Lse,Wio,Hio,qB,Uio,Jio,jB,Yio,Kio,Zio,ah,yse,edo,odo,DB,rdo,tdo,ado,nh,xse,ndo,sdo,GB,ldo,ido,ddo,_s,$se,cdo,fdo,OB,mdo,gdo,VB,hdo,pdo,_do,us,kse,udo,bdo,XB,vdo,Fdo,zB,Tdo,Mdo,Edo,bs,Sse,Cdo,wdo,QB,Ado,Ldo,WB,ydo,xdo,$do,sh,Rse,kdo,Sdo,HB,Rdo,Pdo,Bdo,vs,Pse,Ido,Ndo,UB,qdo,jdo,JB,Ddo,Gdo,Odo,Fs,Bse,Vdo,Xdo,YB,zdo,Qdo,KB,Wdo,Hdo,Udo,Ts,Ise,Jdo,Ydo,ZB,Kdo,Zdo,eI,eco,oco,rco,Ms,Nse,tco,aco,oI,nco,sco,rI,lco,ico,dco,Es,qse,cco,fco,tI,mco,gco,aI,hco,pco,_co,Cs,jse,uco,bco,nI,vco,Fco,sI,Tco,Mco,Eco,lh,Dse,Cco,wco,lI,Aco,Lco,yco,ws,Gse,xco,$co,iI,kco,Sco,dI,Rco,Pco,Bco,ih,Ose,Ico,Nco,cI,qco,jco,Dco,dh,Vse,Gco,Oco,fI,Vco,Xco,zco,ch,Xse,Qco,Wco,mI,Hco,Uco,Jco,fh,zse,Yco,Kco,gI,Zco,efo,ofo,As,Qse,rfo,tfo,hI,afo,nfo,pI,sfo,lfo,ifo,mh,Wse,dfo,cfo,_I,ffo,mfo,gfo,Ls,Hse,hfo,pfo,uI,_fo,ufo,bI,bfo,vfo,Ffo,ys,Use,Tfo,Mfo,vI,Efo,Cfo,FI,wfo,Afo,Lfo,xs,Jse,yfo,xfo,TI,$fo,kfo,MI,Sfo,Rfo,Pfo,$s,Yse,Bfo,Ifo,EI,Nfo,qfo,CI,jfo,Dfo,Gfo,ks,Kse,Ofo,Vfo,wI,Xfo,zfo,AI,Qfo,Wfo,Hfo,Ss,Zse,Ufo,Jfo,LI,Yfo,Kfo,yI,Zfo,emo,omo,gh,ele,rmo,tmo,xI,amo,nmo,smo,hh,ole,lmo,imo,$I,dmo,cmo,fmo,Rs,rle,mmo,gmo,kI,hmo,pmo,SI,_mo,umo,bmo,Ps,tle,vmo,Fmo,RI,Tmo,Mmo,PI,Emo,Cmo,wmo,Bs,ale,Amo,Lmo,BI,ymo,xmo,II,$mo,kmo,Smo,ph,nle,Rmo,Pmo,NI,Bmo,Imo,Nmo,_h,sle,qmo,jmo,qI,Dmo,Gmo,Omo,uh,lle,Vmo,Xmo,jI,zmo,Qmo,Wmo,Is,ile,Hmo,Umo,DI,Jmo,Ymo,GI,Kmo,Zmo,ego,Ns,dle,ogo,rgo,OI,tgo,ago,VI,ngo,sgo,lgo,bh,cle,igo,dgo,XI,cgo,fgo,mgo,vh,fle,ggo,hgo,zI,pgo,_go,ugo,Fh,mle,bgo,vgo,QI,Fgo,Tgo,Mgo,qs,gle,Ego,Cgo,WI,wgo,Ago,HI,Lgo,ygo,xgo,Th,hle,$go,kgo,UI,Sgo,Rgo,Pgo,Mh,ple,Bgo,Igo,JI,Ngo,qgo,jgo,js,_le,Dgo,Ggo,YI,Ogo,Vgo,KI,Xgo,zgo,Qgo,Ds,ule,Wgo,Hgo,ZI,Ugo,Jgo,eN,Ygo,Kgo,Zgo,Gs,ble,eho,oho,oN,rho,tho,rN,aho,nho,sho,Os,vle,lho,iho,tN,dho,cho,aN,fho,mho,gho,Eh,hho,Ch,OL,pho,Fle,_ho,HGe,Si,wh,Tle,VL,uho,Mle,bho,UGe,Lo,XL,vho,zL,Fho,nN,Tho,Mho,Eho,QL,Cho,Ele,who,Aho,Lho,He,WL,yho,Cle,xho,$ho,Sa,kho,wle,Sho,Rho,Ale,Pho,Bho,Lle,Iho,Nho,qho,Y,Ah,yle,jho,Dho,sN,Gho,Oho,Vho,Lh,xle,Xho,zho,lN,Qho,Who,Hho,yh,$le,Uho,Jho,iN,Yho,Kho,Zho,xh,kle,epo,opo,dN,rpo,tpo,apo,$h,Sle,npo,spo,cN,lpo,ipo,dpo,kh,Rle,cpo,fpo,fN,mpo,gpo,hpo,Sh,Ple,ppo,_po,mN,upo,bpo,vpo,Rh,Ble,Fpo,Tpo,gN,Mpo,Epo,Cpo,Ph,Ile,wpo,Apo,hN,Lpo,ypo,xpo,Bh,Nle,$po,kpo,pN,Spo,Rpo,Ppo,Ih,qle,Bpo,Ipo,_N,Npo,qpo,jpo,Nh,jle,Dpo,Gpo,uN,Opo,Vpo,Xpo,qh,Dle,zpo,Qpo,bN,Wpo,Hpo,Upo,jh,Gle,Jpo,Ypo,vN,Kpo,Zpo,e_o,Dh,Ole,o_o,r_o,FN,t_o,a_o,n_o,Gh,Vle,s_o,l_o,TN,i_o,d_o,c_o,Oh,Xle,f_o,m_o,MN,g_o,h_o,p_o,Vh,zle,__o,u_o,EN,b_o,v_o,F_o,Xh,Qle,T_o,M_o,CN,E_o,C_o,w_o,zh,Wle,A_o,L_o,wN,y_o,x_o,$_o,Qh,Hle,k_o,S_o,AN,R_o,P_o,B_o,Wh,Ule,I_o,N_o,LN,q_o,j_o,D_o,Hh,Jle,G_o,O_o,yN,V_o,X_o,z_o,Uh,Yle,Q_o,W_o,xN,H_o,U_o,J_o,Jh,Kle,Y_o,K_o,$N,Z_o,euo,ouo,Yh,Zle,ruo,tuo,kN,auo,nuo,suo,Kh,eie,luo,iuo,SN,duo,cuo,fuo,Zh,oie,muo,guo,RN,huo,puo,_uo,ep,rie,uuo,buo,PN,vuo,Fuo,Tuo,op,tie,Muo,Euo,BN,Cuo,wuo,Auo,rp,aie,Luo,yuo,IN,xuo,$uo,kuo,tp,nie,Suo,Ruo,NN,Puo,Buo,Iuo,ap,Nuo,np,quo,sp,HL,juo,sie,Duo,JGe,Ri,lp,lie,UL,Guo,iie,Ouo,YGe,yo,JL,Vuo,YL,Xuo,qN,zuo,Quo,Wuo,KL,Huo,die,Uuo,Juo,Yuo,Ue,ZL,Kuo,cie,Zuo,e1o,Pi,o1o,fie,r1o,t1o,mie,a1o,n1o,s1o,he,ip,gie,l1o,i1o,jN,d1o,c1o,f1o,dp,hie,m1o,g1o,pie,h1o,p1o,_1o,cp,_ie,u1o,b1o,DN,v1o,F1o,T1o,fp,uie,M1o,E1o,GN,C1o,w1o,A1o,mp,bie,L1o,y1o,ON,x1o,$1o,k1o,gp,vie,S1o,R1o,VN,P1o,B1o,I1o,hp,Fie,N1o,q1o,XN,j1o,D1o,G1o,pp,Tie,O1o,V1o,zN,X1o,z1o,Q1o,_p,Mie,W1o,H1o,QN,U1o,J1o,Y1o,up,Eie,K1o,Z1o,WN,e7o,o7o,r7o,bp,Cie,t7o,a7o,HN,n7o,s7o,l7o,vp,wie,i7o,d7o,UN,c7o,f7o,m7o,Fp,Aie,g7o,h7o,JN,p7o,_7o,u7o,Tp,Lie,b7o,v7o,YN,F7o,T7o,M7o,Mp,yie,E7o,C7o,KN,w7o,A7o,L7o,Ep,xie,y7o,x7o,ZN,$7o,k7o,S7o,Cp,$ie,R7o,P7o,eq,B7o,I7o,N7o,wp,q7o,Ap,j7o,Lp,ey,D7o,kie,G7o,KGe,Bi,yp,Sie,oy,O7o,Rie,V7o,ZGe,xo,ry,X7o,Ii,z7o,oq,Q7o,W7o,rq,H7o,U7o,J7o,ty,Y7o,Pie,K7o,Z7o,e2o,nt,ay,o2o,Bie,r2o,t2o,Ni,a2o,Iie,n2o,s2o,tq,l2o,i2o,d2o,xp,c2o,Je,ny,f2o,Nie,m2o,g2o,Ra,h2o,qie,p2o,_2o,jie,u2o,b2o,Die,v2o,F2o,T2o,y,$p,Gie,M2o,E2o,aq,C2o,w2o,A2o,kp,Oie,L2o,y2o,nq,x2o,$2o,k2o,Sp,Vie,S2o,R2o,sq,P2o,B2o,I2o,Rp,Xie,N2o,q2o,lq,j2o,D2o,G2o,Pp,zie,O2o,V2o,iq,X2o,z2o,Q2o,Bp,Qie,W2o,H2o,dq,U2o,J2o,Y2o,Ip,Wie,K2o,Z2o,cq,ebo,obo,rbo,Np,Hie,tbo,abo,fq,nbo,sbo,lbo,qp,Uie,ibo,dbo,mq,cbo,fbo,mbo,jp,Jie,gbo,hbo,gq,pbo,_bo,ubo,Dp,Yie,bbo,vbo,hq,Fbo,Tbo,Mbo,Gp,Kie,Ebo,Cbo,pq,wbo,Abo,Lbo,Op,Zie,ybo,xbo,_q,$bo,kbo,Sbo,Vp,ede,Rbo,Pbo,uq,Bbo,Ibo,Nbo,Xp,ode,qbo,jbo,bq,Dbo,Gbo,Obo,zp,rde,Vbo,Xbo,vq,zbo,Qbo,Wbo,Qp,tde,Hbo,Ubo,Fq,Jbo,Ybo,Kbo,Wp,ade,Zbo,e5o,Tq,o5o,r5o,t5o,Hp,nde,a5o,n5o,Mq,s5o,l5o,i5o,Up,sde,d5o,c5o,Eq,f5o,m5o,g5o,Jp,lde,h5o,p5o,Cq,_5o,u5o,b5o,Yp,ide,v5o,F5o,wq,T5o,M5o,E5o,Kp,dde,C5o,w5o,Aq,A5o,L5o,y5o,Zp,cde,x5o,$5o,Lq,k5o,S5o,R5o,e_,fde,P5o,B5o,yq,I5o,N5o,q5o,o_,mde,j5o,D5o,xq,G5o,O5o,V5o,r_,gde,X5o,z5o,$q,Q5o,W5o,H5o,t_,hde,U5o,J5o,kq,Y5o,K5o,Z5o,a_,pde,evo,ovo,Sq,rvo,tvo,avo,n_,_de,nvo,svo,Rq,lvo,ivo,dvo,s_,ude,cvo,fvo,Pq,mvo,gvo,hvo,l_,bde,pvo,_vo,Bq,uvo,bvo,vvo,i_,vde,Fvo,Tvo,Iq,Mvo,Evo,Cvo,Vs,Fde,wvo,Avo,Nq,Lvo,yvo,qq,xvo,$vo,kvo,d_,Tde,Svo,Rvo,jq,Pvo,Bvo,Ivo,c_,Mde,Nvo,qvo,Dq,jvo,Dvo,Gvo,f_,Ede,Ovo,Vvo,Gq,Xvo,zvo,Qvo,m_,Cde,Wvo,Hvo,Oq,Uvo,Jvo,Yvo,g_,wde,Kvo,Zvo,Vq,e3o,o3o,r3o,h_,Ade,t3o,a3o,Xq,n3o,s3o,l3o,p_,Lde,i3o,d3o,zq,c3o,f3o,m3o,__,yde,g3o,h3o,Qq,p3o,_3o,u3o,u_,xde,b3o,v3o,Wq,F3o,T3o,M3o,b_,$de,E3o,C3o,Hq,w3o,A3o,L3o,v_,kde,y3o,x3o,Uq,$3o,k3o,S3o,F_,Sde,R3o,P3o,Jq,B3o,I3o,N3o,T_,Rde,q3o,j3o,Yq,D3o,G3o,O3o,M_,Pde,V3o,X3o,Kq,z3o,Q3o,W3o,E_,Bde,H3o,U3o,Zq,J3o,Y3o,K3o,C_,Ide,Z3o,eFo,ej,oFo,rFo,tFo,w_,Nde,aFo,nFo,oj,sFo,lFo,iFo,A_,qde,dFo,cFo,rj,fFo,mFo,gFo,L_,jde,hFo,pFo,tj,_Fo,uFo,bFo,y_,Dde,vFo,FFo,aj,TFo,MFo,EFo,x_,Gde,CFo,wFo,nj,AFo,LFo,yFo,$_,Ode,xFo,$Fo,sj,kFo,SFo,RFo,k_,Vde,PFo,BFo,lj,IFo,NFo,qFo,S_,Xde,jFo,DFo,ij,GFo,OFo,VFo,R_,zde,XFo,zFo,dj,QFo,WFo,HFo,P_,Qde,UFo,JFo,cj,YFo,KFo,ZFo,B_,Wde,eTo,oTo,fj,rTo,tTo,aTo,I_,Hde,nTo,sTo,mj,lTo,iTo,dTo,N_,Ude,cTo,fTo,gj,mTo,gTo,hTo,q_,Jde,pTo,_To,hj,uTo,bTo,vTo,j_,Yde,FTo,TTo,pj,MTo,ETo,CTo,D_,Kde,wTo,ATo,_j,LTo,yTo,xTo,G_,Zde,$To,kTo,uj,STo,RTo,PTo,O_,ece,BTo,ITo,bj,NTo,qTo,jTo,V_,oce,DTo,GTo,vj,OTo,VTo,XTo,X_,rce,zTo,QTo,Fj,WTo,HTo,UTo,z_,tce,JTo,YTo,Tj,KTo,ZTo,eMo,Q_,ace,oMo,rMo,Mj,tMo,aMo,nMo,W_,nce,sMo,lMo,Ej,iMo,dMo,cMo,H_,sce,fMo,mMo,Cj,gMo,hMo,pMo,U_,lce,_Mo,uMo,wj,bMo,vMo,FMo,J_,ice,TMo,MMo,Aj,EMo,CMo,wMo,Y_,dce,AMo,LMo,Lj,yMo,xMo,$Mo,K_,cce,kMo,SMo,yj,RMo,PMo,BMo,Z_,fce,IMo,NMo,xj,qMo,jMo,DMo,eu,mce,GMo,OMo,$j,VMo,XMo,zMo,ou,gce,QMo,WMo,kj,HMo,UMo,JMo,ru,hce,YMo,KMo,Sj,ZMo,eEo,oEo,tu,pce,rEo,tEo,Rj,aEo,nEo,sEo,au,_ce,lEo,iEo,Pj,dEo,cEo,fEo,nu,uce,mEo,gEo,Bj,hEo,pEo,_Eo,su,bce,uEo,bEo,Ij,vEo,FEo,TEo,lu,vce,MEo,EEo,Nj,CEo,wEo,AEo,iu,Fce,LEo,yEo,qj,xEo,$Eo,kEo,du,Tce,SEo,REo,jj,PEo,BEo,IEo,cu,Mce,NEo,qEo,Dj,jEo,DEo,GEo,fu,Ece,OEo,VEo,Gj,XEo,zEo,QEo,mu,Cce,WEo,HEo,Oj,UEo,JEo,YEo,gu,wce,KEo,ZEo,Vj,e4o,o4o,r4o,hu,Ace,t4o,a4o,Xj,n4o,s4o,l4o,pu,Lce,i4o,d4o,zj,c4o,f4o,m4o,_u,yce,g4o,h4o,Qj,p4o,_4o,u4o,uu,xce,b4o,v4o,Wj,F4o,T4o,M4o,bu,$ce,E4o,C4o,Hj,w4o,A4o,L4o,vu,kce,y4o,x4o,Uj,$4o,k4o,S4o,Fu,Sce,R4o,P4o,Jj,B4o,I4o,N4o,Tu,Rce,q4o,j4o,Yj,D4o,G4o,O4o,Mu,Pce,V4o,X4o,Kj,z4o,Q4o,W4o,Eu,Bce,H4o,U4o,Zj,J4o,Y4o,K4o,Cu,Ice,Z4o,eCo,eD,oCo,rCo,tCo,wu,Nce,aCo,nCo,oD,sCo,lCo,iCo,Au,qce,dCo,cCo,rD,fCo,mCo,gCo,Lu,jce,hCo,pCo,tD,_Co,uCo,bCo,yu,vCo,Dce,FCo,TCo,Gce,MCo,ECo,xu,eOe,qi,$u,Oce,sy,CCo,Vce,wCo,oOe,$o,ly,ACo,ji,LCo,aD,yCo,xCo,nD,$Co,kCo,SCo,iy,RCo,Xce,PCo,BCo,ICo,st,dy,NCo,zce,qCo,jCo,Di,DCo,Qce,GCo,OCo,sD,VCo,XCo,zCo,ku,QCo,Ye,cy,WCo,Wce,HCo,UCo,Pa,JCo,Hce,YCo,KCo,Uce,ZCo,e0o,Jce,o0o,r0o,t0o,G,Su,Yce,a0o,n0o,lD,s0o,l0o,i0o,Ru,Kce,d0o,c0o,iD,f0o,m0o,g0o,Pu,Zce,h0o,p0o,dD,_0o,u0o,b0o,Bu,efe,v0o,F0o,cD,T0o,M0o,E0o,Iu,ofe,C0o,w0o,fD,A0o,L0o,y0o,Nu,rfe,x0o,$0o,mD,k0o,S0o,R0o,qu,tfe,P0o,B0o,gD,I0o,N0o,q0o,ju,afe,j0o,D0o,hD,G0o,O0o,V0o,Du,nfe,X0o,z0o,pD,Q0o,W0o,H0o,Gu,sfe,U0o,J0o,_D,Y0o,K0o,Z0o,Ou,lfe,ewo,owo,uD,rwo,two,awo,Vu,ife,nwo,swo,bD,lwo,iwo,dwo,Xu,dfe,cwo,fwo,vD,mwo,gwo,hwo,zu,cfe,pwo,_wo,FD,uwo,bwo,vwo,Qu,ffe,Fwo,Two,TD,Mwo,Ewo,Cwo,Wu,mfe,wwo,Awo,MD,Lwo,ywo,xwo,Hu,gfe,$wo,kwo,ED,Swo,Rwo,Pwo,Uu,hfe,Bwo,Iwo,CD,Nwo,qwo,jwo,Ju,pfe,Dwo,Gwo,wD,Owo,Vwo,Xwo,Yu,_fe,zwo,Qwo,AD,Wwo,Hwo,Uwo,Ku,ufe,Jwo,Ywo,LD,Kwo,Zwo,eAo,Zu,bfe,oAo,rAo,yD,tAo,aAo,nAo,e1,vfe,sAo,lAo,xD,iAo,dAo,cAo,o1,Ffe,fAo,mAo,$D,gAo,hAo,pAo,r1,Tfe,_Ao,uAo,kD,bAo,vAo,FAo,t1,Mfe,TAo,MAo,SD,EAo,CAo,wAo,a1,Efe,AAo,LAo,RD,yAo,xAo,$Ao,n1,Cfe,kAo,SAo,PD,RAo,PAo,BAo,s1,wfe,IAo,NAo,BD,qAo,jAo,DAo,l1,Afe,GAo,OAo,ID,VAo,XAo,zAo,i1,Lfe,QAo,WAo,ND,HAo,UAo,JAo,d1,yfe,YAo,KAo,qD,ZAo,e6o,o6o,c1,xfe,r6o,t6o,jD,a6o,n6o,s6o,f1,$fe,l6o,i6o,DD,d6o,c6o,f6o,m1,kfe,m6o,g6o,GD,h6o,p6o,_6o,g1,Sfe,u6o,b6o,OD,v6o,F6o,T6o,h1,Rfe,M6o,E6o,VD,C6o,w6o,A6o,p1,Pfe,L6o,y6o,XD,x6o,$6o,k6o,_1,Bfe,S6o,R6o,zD,P6o,B6o,I6o,u1,Ife,N6o,q6o,QD,j6o,D6o,G6o,b1,Nfe,O6o,V6o,WD,X6o,z6o,Q6o,v1,qfe,W6o,H6o,HD,U6o,J6o,Y6o,F1,jfe,K6o,Z6o,UD,eLo,oLo,rLo,T1,Dfe,tLo,aLo,JD,nLo,sLo,lLo,M1,iLo,Gfe,dLo,cLo,Ofe,fLo,mLo,E1,rOe,Gi,C1,Vfe,fy,gLo,Xfe,hLo,tOe,ko,my,pLo,Oi,_Lo,YD,uLo,bLo,KD,vLo,FLo,TLo,gy,MLo,zfe,ELo,CLo,wLo,lt,hy,ALo,Qfe,LLo,yLo,Vi,xLo,Wfe,$Lo,kLo,ZD,SLo,RLo,PLo,w1,BLo,Ke,py,ILo,Hfe,NLo,qLo,Ba,jLo,Ufe,DLo,GLo,Jfe,OLo,VLo,Yfe,XLo,zLo,QLo,z,A1,Kfe,WLo,HLo,eG,ULo,JLo,YLo,L1,Zfe,KLo,ZLo,oG,eyo,oyo,ryo,y1,eme,tyo,ayo,rG,nyo,syo,lyo,x1,ome,iyo,dyo,tG,cyo,fyo,myo,$1,rme,gyo,hyo,aG,pyo,_yo,uyo,k1,tme,byo,vyo,nG,Fyo,Tyo,Myo,S1,ame,Eyo,Cyo,sG,wyo,Ayo,Lyo,R1,nme,yyo,xyo,lG,$yo,kyo,Syo,P1,sme,Ryo,Pyo,iG,Byo,Iyo,Nyo,B1,lme,qyo,jyo,dG,Dyo,Gyo,Oyo,I1,ime,Vyo,Xyo,cG,zyo,Qyo,Wyo,N1,dme,Hyo,Uyo,fG,Jyo,Yyo,Kyo,q1,cme,Zyo,e8o,mG,o8o,r8o,t8o,j1,fme,a8o,n8o,gG,s8o,l8o,i8o,D1,mme,d8o,c8o,hG,f8o,m8o,g8o,G1,gme,h8o,p8o,pG,_8o,u8o,b8o,O1,hme,v8o,F8o,_G,T8o,M8o,E8o,V1,pme,C8o,w8o,uG,A8o,L8o,y8o,X1,_me,x8o,$8o,bG,k8o,S8o,R8o,z1,ume,P8o,B8o,vG,I8o,N8o,q8o,Q1,bme,j8o,D8o,FG,G8o,O8o,V8o,W1,vme,X8o,z8o,TG,Q8o,W8o,H8o,H1,Fme,U8o,J8o,MG,Y8o,K8o,Z8o,U1,Tme,e9o,o9o,EG,r9o,t9o,a9o,J1,Mme,n9o,s9o,CG,l9o,i9o,d9o,Y1,Eme,c9o,f9o,wG,m9o,g9o,h9o,K1,Cme,p9o,_9o,AG,u9o,b9o,v9o,Z1,wme,F9o,T9o,LG,M9o,E9o,C9o,e7,Ame,w9o,A9o,yG,L9o,y9o,x9o,o7,Lme,$9o,k9o,xG,S9o,R9o,P9o,r7,yme,B9o,I9o,$G,N9o,q9o,j9o,t7,xme,D9o,G9o,kG,O9o,V9o,X9o,a7,$me,z9o,Q9o,SG,W9o,H9o,U9o,n7,kme,J9o,Y9o,RG,K9o,Z9o,exo,s7,Sme,oxo,rxo,PG,txo,axo,nxo,l7,Rme,sxo,lxo,BG,ixo,dxo,cxo,i7,Pme,fxo,mxo,IG,gxo,hxo,pxo,d7,Bme,_xo,uxo,NG,bxo,vxo,Fxo,c7,Txo,Ime,Mxo,Exo,Nme,Cxo,wxo,f7,aOe,Xi,m7,qme,_y,Axo,jme,Lxo,nOe,So,uy,yxo,zi,xxo,qG,$xo,kxo,jG,Sxo,Rxo,Pxo,by,Bxo,Dme,Ixo,Nxo,qxo,it,vy,jxo,Gme,Dxo,Gxo,Qi,Oxo,Ome,Vxo,Xxo,DG,zxo,Qxo,Wxo,g7,Hxo,Ze,Fy,Uxo,Vme,Jxo,Yxo,Ia,Kxo,Xme,Zxo,e$o,zme,o$o,r$o,Qme,t$o,a$o,n$o,Q,h7,Wme,s$o,l$o,GG,i$o,d$o,c$o,p7,Hme,f$o,m$o,OG,g$o,h$o,p$o,_7,Ume,_$o,u$o,VG,b$o,v$o,F$o,u7,Jme,T$o,M$o,XG,E$o,C$o,w$o,b7,Yme,A$o,L$o,zG,y$o,x$o,$$o,v7,Kme,k$o,S$o,QG,R$o,P$o,B$o,F7,Zme,I$o,N$o,WG,q$o,j$o,D$o,T7,ege,G$o,O$o,HG,V$o,X$o,z$o,M7,oge,Q$o,W$o,UG,H$o,U$o,J$o,E7,rge,Y$o,K$o,JG,Z$o,eko,oko,C7,tge,rko,tko,YG,ako,nko,sko,w7,age,lko,iko,KG,dko,cko,fko,A7,nge,mko,gko,ZG,hko,pko,_ko,L7,sge,uko,bko,eO,vko,Fko,Tko,y7,lge,Mko,Eko,oO,Cko,wko,Ako,x7,ige,Lko,yko,rO,xko,$ko,kko,$7,dge,Sko,Rko,tO,Pko,Bko,Iko,k7,cge,Nko,qko,aO,jko,Dko,Gko,S7,fge,Oko,Vko,nO,Xko,zko,Qko,R7,mge,Wko,Hko,sO,Uko,Jko,Yko,P7,gge,Kko,Zko,lO,eSo,oSo,rSo,B7,hge,tSo,aSo,iO,nSo,sSo,lSo,I7,pge,iSo,dSo,dO,cSo,fSo,mSo,N7,_ge,gSo,hSo,cO,pSo,_So,uSo,q7,uge,bSo,vSo,fO,FSo,TSo,MSo,j7,bge,ESo,CSo,mO,wSo,ASo,LSo,D7,vge,ySo,xSo,gO,$So,kSo,SSo,G7,Fge,RSo,PSo,hO,BSo,ISo,NSo,O7,Tge,qSo,jSo,pO,DSo,GSo,OSo,V7,Mge,VSo,XSo,_O,zSo,QSo,WSo,X7,Ege,HSo,USo,uO,JSo,YSo,KSo,z7,Cge,ZSo,eRo,bO,oRo,rRo,tRo,Q7,wge,aRo,nRo,Age,sRo,lRo,iRo,W7,Lge,dRo,cRo,vO,fRo,mRo,gRo,H7,yge,hRo,pRo,FO,_Ro,uRo,bRo,U7,xge,vRo,FRo,TO,TRo,MRo,ERo,J7,$ge,CRo,wRo,MO,ARo,LRo,yRo,Y7,xRo,kge,$Ro,kRo,Sge,SRo,RRo,K7,sOe,Wi,Z7,Rge,Ty,PRo,Pge,BRo,lOe,Ro,My,IRo,Hi,NRo,EO,qRo,jRo,CO,DRo,GRo,ORo,Ey,VRo,Bge,XRo,zRo,QRo,dt,Cy,WRo,Ige,HRo,URo,Ui,JRo,Nge,YRo,KRo,wO,ZRo,ePo,oPo,e2,rPo,eo,wy,tPo,qge,aPo,nPo,Na,sPo,jge,lPo,iPo,Dge,dPo,cPo,Gge,fPo,mPo,gPo,pe,o2,Oge,hPo,pPo,AO,_Po,uPo,bPo,r2,Vge,vPo,FPo,LO,TPo,MPo,EPo,t2,Xge,CPo,wPo,yO,APo,LPo,yPo,a2,zge,xPo,$Po,xO,kPo,SPo,RPo,n2,Qge,PPo,BPo,$O,IPo,NPo,qPo,s2,Wge,jPo,DPo,kO,GPo,OPo,VPo,l2,Hge,XPo,zPo,SO,QPo,WPo,HPo,i2,Uge,UPo,JPo,RO,YPo,KPo,ZPo,d2,Jge,eBo,oBo,PO,rBo,tBo,aBo,c2,Yge,nBo,sBo,BO,lBo,iBo,dBo,f2,Kge,cBo,fBo,IO,mBo,gBo,hBo,m2,Zge,pBo,_Bo,NO,uBo,bBo,vBo,g2,ehe,FBo,TBo,qO,MBo,EBo,CBo,h2,ohe,wBo,ABo,jO,LBo,yBo,xBo,p2,rhe,$Bo,kBo,DO,SBo,RBo,PBo,_2,the,BBo,IBo,GO,NBo,qBo,jBo,u2,ahe,DBo,GBo,OO,OBo,VBo,XBo,b2,zBo,nhe,QBo,WBo,she,HBo,UBo,v2,iOe,Ji,F2,lhe,Ay,JBo,ihe,YBo,dOe,Po,Ly,KBo,Yi,ZBo,VO,eIo,oIo,XO,rIo,tIo,aIo,yy,nIo,dhe,sIo,lIo,iIo,ct,xy,dIo,che,cIo,fIo,Ki,mIo,fhe,gIo,hIo,zO,pIo,_Io,uIo,T2,bIo,oo,$y,vIo,mhe,FIo,TIo,qa,MIo,ghe,EIo,CIo,hhe,wIo,AIo,phe,LIo,yIo,xIo,N,M2,_he,$Io,kIo,QO,SIo,RIo,PIo,E2,uhe,BIo,IIo,WO,NIo,qIo,jIo,C2,bhe,DIo,GIo,HO,OIo,VIo,XIo,w2,vhe,zIo,QIo,UO,WIo,HIo,UIo,A2,Fhe,JIo,YIo,JO,KIo,ZIo,eNo,L2,The,oNo,rNo,YO,tNo,aNo,nNo,y2,Mhe,sNo,lNo,KO,iNo,dNo,cNo,x2,Ehe,fNo,mNo,ZO,gNo,hNo,pNo,$2,Che,_No,uNo,eV,bNo,vNo,FNo,k2,whe,TNo,MNo,oV,ENo,CNo,wNo,S2,Ahe,ANo,LNo,rV,yNo,xNo,$No,R2,Lhe,kNo,SNo,tV,RNo,PNo,BNo,P2,yhe,INo,NNo,aV,qNo,jNo,DNo,B2,xhe,GNo,ONo,nV,VNo,XNo,zNo,I2,$he,QNo,WNo,sV,HNo,UNo,JNo,N2,khe,YNo,KNo,lV,ZNo,eqo,oqo,q2,She,rqo,tqo,iV,aqo,nqo,sqo,j2,Rhe,lqo,iqo,dV,dqo,cqo,fqo,D2,Phe,mqo,gqo,cV,hqo,pqo,_qo,G2,Bhe,uqo,bqo,fV,vqo,Fqo,Tqo,O2,Ihe,Mqo,Eqo,mV,Cqo,wqo,Aqo,V2,Nhe,Lqo,yqo,gV,xqo,$qo,kqo,X2,qhe,Sqo,Rqo,hV,Pqo,Bqo,Iqo,z2,jhe,Nqo,qqo,pV,jqo,Dqo,Gqo,Q2,Dhe,Oqo,Vqo,_V,Xqo,zqo,Qqo,W2,Ghe,Wqo,Hqo,uV,Uqo,Jqo,Yqo,H2,Ohe,Kqo,Zqo,bV,ejo,ojo,rjo,U2,Vhe,tjo,ajo,vV,njo,sjo,ljo,J2,Xhe,ijo,djo,FV,cjo,fjo,mjo,Y2,zhe,gjo,hjo,TV,pjo,_jo,ujo,K2,Qhe,bjo,vjo,MV,Fjo,Tjo,Mjo,Z2,Whe,Ejo,Cjo,EV,wjo,Ajo,Ljo,eb,Hhe,yjo,xjo,CV,$jo,kjo,Sjo,ob,Uhe,Rjo,Pjo,wV,Bjo,Ijo,Njo,rb,Jhe,qjo,jjo,AV,Djo,Gjo,Ojo,tb,Yhe,Vjo,Xjo,LV,zjo,Qjo,Wjo,ab,Khe,Hjo,Ujo,yV,Jjo,Yjo,Kjo,nb,Zhe,Zjo,eDo,xV,oDo,rDo,tDo,sb,epe,aDo,nDo,$V,sDo,lDo,iDo,lb,ope,dDo,cDo,kV,fDo,mDo,gDo,ib,rpe,hDo,pDo,SV,_Do,uDo,bDo,db,tpe,vDo,FDo,RV,TDo,MDo,EDo,cb,ape,CDo,wDo,PV,ADo,LDo,yDo,fb,npe,xDo,$Do,BV,kDo,SDo,RDo,mb,spe,PDo,BDo,IV,IDo,NDo,qDo,gb,lpe,jDo,DDo,NV,GDo,ODo,VDo,hb,ipe,XDo,zDo,qV,QDo,WDo,HDo,pb,dpe,UDo,JDo,jV,YDo,KDo,ZDo,_b,cpe,eGo,oGo,DV,rGo,tGo,aGo,ub,nGo,fpe,sGo,lGo,mpe,iGo,dGo,bb,cOe,Zi,vb,gpe,ky,cGo,hpe,fGo,fOe,Bo,Sy,mGo,ed,gGo,GV,hGo,pGo,OV,_Go,uGo,bGo,Ry,vGo,ppe,FGo,TGo,MGo,ft,Py,EGo,_pe,CGo,wGo,od,AGo,upe,LGo,yGo,VV,xGo,$Go,kGo,Fb,SGo,ro,By,RGo,bpe,PGo,BGo,ja,IGo,vpe,NGo,qGo,Fpe,jGo,DGo,Tpe,GGo,OGo,VGo,Z,Tb,Mpe,XGo,zGo,XV,QGo,WGo,HGo,Mb,Epe,UGo,JGo,zV,YGo,KGo,ZGo,Eb,Cpe,eOo,oOo,QV,rOo,tOo,aOo,Cb,wpe,nOo,sOo,WV,lOo,iOo,dOo,wb,Ape,cOo,fOo,HV,mOo,gOo,hOo,Ab,Lpe,pOo,_Oo,UV,uOo,bOo,vOo,Lb,ype,FOo,TOo,JV,MOo,EOo,COo,yb,xpe,wOo,AOo,YV,LOo,yOo,xOo,xb,$pe,$Oo,kOo,KV,SOo,ROo,POo,$b,kpe,BOo,IOo,ZV,NOo,qOo,jOo,kb,Spe,DOo,GOo,eX,OOo,VOo,XOo,Sb,Rpe,zOo,QOo,oX,WOo,HOo,UOo,Rb,Ppe,JOo,YOo,rX,KOo,ZOo,eVo,Pb,Bpe,oVo,rVo,tX,tVo,aVo,nVo,Bb,Ipe,sVo,lVo,aX,iVo,dVo,cVo,Ib,Npe,fVo,mVo,nX,gVo,hVo,pVo,Nb,qpe,_Vo,uVo,sX,bVo,vVo,FVo,qb,jpe,TVo,MVo,lX,EVo,CVo,wVo,jb,Dpe,AVo,LVo,iX,yVo,xVo,$Vo,Db,Gpe,kVo,SVo,dX,RVo,PVo,BVo,Gb,Ope,IVo,NVo,cX,qVo,jVo,DVo,Ob,Vpe,GVo,OVo,fX,VVo,XVo,zVo,Vb,Xpe,QVo,WVo,mX,HVo,UVo,JVo,Xb,zpe,YVo,KVo,gX,ZVo,eXo,oXo,zb,Qpe,rXo,tXo,hX,aXo,nXo,sXo,Qb,Wpe,lXo,iXo,pX,dXo,cXo,fXo,Wb,Hpe,mXo,gXo,_X,hXo,pXo,_Xo,Hb,Upe,uXo,bXo,uX,vXo,FXo,TXo,Ub,Jpe,MXo,EXo,bX,CXo,wXo,AXo,Jb,Ype,LXo,yXo,vX,xXo,$Xo,kXo,Yb,SXo,Kpe,RXo,PXo,Zpe,BXo,IXo,Kb,mOe,rd,Zb,e_e,Iy,NXo,o_e,qXo,gOe,Io,Ny,jXo,td,DXo,FX,GXo,OXo,TX,VXo,XXo,zXo,qy,QXo,r_e,WXo,HXo,UXo,mt,jy,JXo,t_e,YXo,KXo,ad,ZXo,a_e,ezo,ozo,MX,rzo,tzo,azo,e5,nzo,to,Dy,szo,n_e,lzo,izo,Da,dzo,s_e,czo,fzo,l_e,mzo,gzo,i_e,hzo,pzo,_zo,No,o5,d_e,uzo,bzo,EX,vzo,Fzo,Tzo,r5,c_e,Mzo,Ezo,CX,Czo,wzo,Azo,t5,f_e,Lzo,yzo,wX,xzo,$zo,kzo,a5,m_e,Szo,Rzo,AX,Pzo,Bzo,Izo,n5,g_e,Nzo,qzo,LX,jzo,Dzo,Gzo,s5,h_e,Ozo,Vzo,yX,Xzo,zzo,Qzo,l5,Wzo,p_e,Hzo,Uzo,__e,Jzo,Yzo,i5,hOe,nd,d5,u_e,Gy,Kzo,b_e,Zzo,pOe,qo,Oy,eQo,sd,oQo,xX,rQo,tQo,$X,aQo,nQo,sQo,Vy,lQo,v_e,iQo,dQo,cQo,gt,Xy,fQo,F_e,mQo,gQo,ld,hQo,T_e,pQo,_Qo,kX,uQo,bQo,vQo,c5,FQo,ao,zy,TQo,M_e,MQo,EQo,Ga,CQo,E_e,wQo,AQo,C_e,LQo,yQo,w_e,xQo,$Qo,kQo,H,f5,A_e,SQo,RQo,SX,PQo,BQo,IQo,m5,L_e,NQo,qQo,RX,jQo,DQo,GQo,g5,y_e,OQo,VQo,PX,XQo,zQo,QQo,h5,x_e,WQo,HQo,BX,UQo,JQo,YQo,p5,$_e,KQo,ZQo,IX,eWo,oWo,rWo,_5,k_e,tWo,aWo,NX,nWo,sWo,lWo,u5,S_e,iWo,dWo,qX,cWo,fWo,mWo,b5,R_e,gWo,hWo,jX,pWo,_Wo,uWo,v5,P_e,bWo,vWo,DX,FWo,TWo,MWo,F5,B_e,EWo,CWo,GX,wWo,AWo,LWo,T5,I_e,yWo,xWo,OX,$Wo,kWo,SWo,M5,N_e,RWo,PWo,VX,BWo,IWo,NWo,E5,q_e,qWo,jWo,XX,DWo,GWo,OWo,C5,j_e,VWo,XWo,zX,zWo,QWo,WWo,w5,D_e,HWo,UWo,QX,JWo,YWo,KWo,A5,G_e,ZWo,eHo,WX,oHo,rHo,tHo,L5,O_e,aHo,nHo,HX,sHo,lHo,iHo,y5,V_e,dHo,cHo,UX,fHo,mHo,gHo,x5,X_e,hHo,pHo,JX,_Ho,uHo,bHo,$5,z_e,vHo,FHo,YX,THo,MHo,EHo,k5,Q_e,CHo,wHo,KX,AHo,LHo,yHo,S5,W_e,xHo,$Ho,ZX,kHo,SHo,RHo,R5,H_e,PHo,BHo,ez,IHo,NHo,qHo,P5,U_e,jHo,DHo,oz,GHo,OHo,VHo,B5,J_e,XHo,zHo,rz,QHo,WHo,HHo,I5,Y_e,UHo,JHo,tz,YHo,KHo,ZHo,N5,K_e,eUo,oUo,az,rUo,tUo,aUo,q5,Z_e,nUo,sUo,nz,lUo,iUo,dUo,j5,eue,cUo,fUo,sz,mUo,gUo,hUo,D5,oue,pUo,_Uo,lz,uUo,bUo,vUo,G5,rue,FUo,TUo,iz,MUo,EUo,CUo,O5,tue,wUo,AUo,dz,LUo,yUo,xUo,V5,aue,$Uo,kUo,cz,SUo,RUo,PUo,X5,nue,BUo,IUo,fz,NUo,qUo,jUo,z5,sue,DUo,GUo,mz,OUo,VUo,XUo,Q5,lue,zUo,QUo,gz,WUo,HUo,UUo,W5,JUo,iue,YUo,KUo,due,ZUo,eJo,H5,_Oe,id,U5,cue,Qy,oJo,fue,rJo,uOe,jo,Wy,tJo,dd,aJo,hz,nJo,sJo,pz,lJo,iJo,dJo,Hy,cJo,mue,fJo,mJo,gJo,ht,Uy,hJo,gue,pJo,_Jo,cd,uJo,hue,bJo,vJo,_z,FJo,TJo,MJo,J5,EJo,no,Jy,CJo,pue,wJo,AJo,Oa,LJo,_ue,yJo,xJo,uue,$Jo,kJo,bue,SJo,RJo,PJo,V,Y5,vue,BJo,IJo,uz,NJo,qJo,jJo,K5,Fue,DJo,GJo,bz,OJo,VJo,XJo,Z5,Tue,zJo,QJo,vz,WJo,HJo,UJo,ev,Mue,JJo,YJo,Fz,KJo,ZJo,eYo,ov,Eue,oYo,rYo,Tz,tYo,aYo,nYo,rv,Cue,sYo,lYo,Mz,iYo,dYo,cYo,tv,wue,fYo,mYo,Ez,gYo,hYo,pYo,av,Aue,_Yo,uYo,Cz,bYo,vYo,FYo,nv,Lue,TYo,MYo,wz,EYo,CYo,wYo,sv,yue,AYo,LYo,Az,yYo,xYo,$Yo,lv,xue,kYo,SYo,Lz,RYo,PYo,BYo,iv,$ue,IYo,NYo,yz,qYo,jYo,DYo,dv,kue,GYo,OYo,xz,VYo,XYo,zYo,cv,Sue,QYo,WYo,$z,HYo,UYo,JYo,fv,Rue,YYo,KYo,kz,ZYo,eKo,oKo,mv,Pue,rKo,tKo,Sz,aKo,nKo,sKo,gv,Bue,lKo,iKo,Rz,dKo,cKo,fKo,hv,Iue,mKo,gKo,Pz,hKo,pKo,_Ko,pv,Nue,uKo,bKo,Bz,vKo,FKo,TKo,_v,que,MKo,EKo,Iz,CKo,wKo,AKo,uv,jue,LKo,yKo,Nz,xKo,$Ko,kKo,bv,Due,SKo,RKo,qz,PKo,BKo,IKo,vv,Gue,NKo,qKo,jz,jKo,DKo,GKo,Fv,Oue,OKo,VKo,Dz,XKo,zKo,QKo,Tv,Vue,WKo,HKo,Gz,UKo,JKo,YKo,Mv,Xue,KKo,ZKo,Oz,eZo,oZo,rZo,Ev,zue,tZo,aZo,Vz,nZo,sZo,lZo,Cv,Que,iZo,dZo,Xz,cZo,fZo,mZo,wv,Wue,gZo,hZo,zz,pZo,_Zo,uZo,Av,Hue,bZo,vZo,Qz,FZo,TZo,MZo,Lv,Uue,EZo,CZo,Wz,wZo,AZo,LZo,yv,Jue,yZo,xZo,Hz,$Zo,kZo,SZo,xv,Yue,RZo,PZo,Uz,BZo,IZo,NZo,$v,Kue,qZo,jZo,Jz,DZo,GZo,OZo,kv,Zue,VZo,XZo,Yz,zZo,QZo,WZo,Sv,e1e,HZo,UZo,Kz,JZo,YZo,KZo,Rv,o1e,ZZo,eer,Zz,oer,rer,ter,Pv,r1e,aer,ner,eQ,ser,ler,ier,Bv,t1e,der,cer,oQ,fer,mer,ger,Iv,a1e,her,per,rQ,_er,uer,ber,Nv,n1e,ver,Fer,tQ,Ter,Mer,Eer,qv,Cer,s1e,wer,Aer,l1e,Ler,yer,jv,bOe,fd,Dv,i1e,Yy,xer,d1e,$er,vOe,Do,Ky,ker,md,Ser,aQ,Rer,Per,nQ,Ber,Ier,Ner,Zy,qer,c1e,jer,Der,Ger,pt,e8,Oer,f1e,Ver,Xer,gd,zer,m1e,Qer,Wer,sQ,Her,Uer,Jer,Gv,Yer,so,o8,Ker,g1e,Zer,eor,Va,oor,h1e,ror,tor,p1e,aor,nor,_1e,sor,lor,ior,u1e,Ov,b1e,dor,cor,lQ,mor,gor,hor,Vv,por,v1e,_or,uor,F1e,bor,vor,Xv,FOe,hd,zv,T1e,r8,For,M1e,Tor,TOe,Go,t8,Mor,pd,Eor,iQ,Cor,wor,dQ,Aor,Lor,yor,a8,xor,E1e,$or,kor,Sor,_t,n8,Ror,C1e,Por,Bor,_d,Ior,w1e,Nor,qor,cQ,jor,Dor,Gor,Qv,Oor,lo,s8,Vor,A1e,Xor,zor,Xa,Qor,L1e,Wor,Hor,y1e,Uor,Jor,x1e,Yor,Kor,Zor,Fe,Wv,$1e,err,orr,fQ,rrr,trr,arr,Hv,k1e,nrr,srr,mQ,lrr,irr,drr,Uv,S1e,crr,frr,gQ,mrr,grr,hrr,Jv,R1e,prr,_rr,hQ,urr,brr,vrr,Xs,P1e,Frr,Trr,pQ,Mrr,Err,_Q,Crr,wrr,Arr,Yv,B1e,Lrr,yrr,uQ,xrr,$rr,krr,zs,I1e,Srr,Rrr,bQ,Prr,Brr,vQ,Irr,Nrr,qrr,ut,N1e,jrr,Drr,FQ,Grr,Orr,TQ,Vrr,Xrr,MQ,zrr,Qrr,Wrr,Kv,q1e,Hrr,Urr,EQ,Jrr,Yrr,Krr,Zv,j1e,Zrr,etr,CQ,otr,rtr,ttr,e3,D1e,atr,ntr,wQ,str,ltr,itr,o3,G1e,dtr,ctr,AQ,ftr,mtr,gtr,r3,O1e,htr,ptr,LQ,_tr,utr,btr,t3,V1e,vtr,Ftr,yQ,Ttr,Mtr,Etr,a3,X1e,Ctr,wtr,xQ,Atr,Ltr,ytr,n3,xtr,z1e,$tr,ktr,Q1e,Str,Rtr,s3,MOe,ud,l3,W1e,l8,Ptr,H1e,Btr,EOe,Oo,i8,Itr,bd,Ntr,$Q,qtr,jtr,kQ,Dtr,Gtr,Otr,d8,Vtr,U1e,Xtr,ztr,Qtr,bt,c8,Wtr,J1e,Htr,Utr,vd,Jtr,Y1e,Ytr,Ktr,SQ,Ztr,ear,oar,i3,rar,io,f8,tar,K1e,aar,nar,za,sar,Z1e,lar,iar,e7e,dar,car,o7e,far,mar,gar,r7e,d3,t7e,har,par,RQ,_ar,uar,bar,c3,Far,a7e,Tar,Mar,n7e,Ear,Car,f3,COe,Fd,m3,s7e,m8,war,l7e,Aar,wOe,Vo,g8,Lar,Td,yar,PQ,xar,$ar,BQ,kar,Sar,Rar,h8,Par,i7e,Bar,Iar,Nar,vt,p8,qar,d7e,jar,Dar,Md,Gar,c7e,Oar,Var,IQ,Xar,zar,Qar,g3,War,co,_8,Har,f7e,Uar,Jar,Qa,Yar,m7e,Kar,Zar,g7e,enr,onr,h7e,rnr,tnr,anr,p7e,h3,_7e,nnr,snr,NQ,lnr,inr,dnr,p3,cnr,u7e,fnr,mnr,b7e,gnr,hnr,_3,AOe,Ed,u3,v7e,u8,pnr,F7e,_nr,LOe,Xo,b8,unr,Cd,bnr,qQ,vnr,Fnr,jQ,Tnr,Mnr,Enr,v8,Cnr,T7e,wnr,Anr,Lnr,Ft,F8,ynr,M7e,xnr,$nr,wd,knr,E7e,Snr,Rnr,DQ,Pnr,Bnr,Inr,b3,Nnr,fo,T8,qnr,C7e,jnr,Dnr,Wa,Gnr,w7e,Onr,Vnr,A7e,Xnr,znr,L7e,Qnr,Wnr,Hnr,Pe,v3,y7e,Unr,Jnr,GQ,Ynr,Knr,Znr,F3,x7e,esr,osr,OQ,rsr,tsr,asr,T3,$7e,nsr,ssr,VQ,lsr,isr,dsr,M3,k7e,csr,fsr,XQ,msr,gsr,hsr,E3,S7e,psr,_sr,zQ,usr,bsr,vsr,C3,R7e,Fsr,Tsr,QQ,Msr,Esr,Csr,w3,P7e,wsr,Asr,WQ,Lsr,ysr,xsr,A3,B7e,$sr,ksr,HQ,Ssr,Rsr,Psr,L3,I7e,Bsr,Isr,UQ,Nsr,qsr,jsr,y3,Dsr,N7e,Gsr,Osr,q7e,Vsr,Xsr,x3,yOe,Ad,$3,j7e,M8,zsr,D7e,Qsr,xOe,zo,E8,Wsr,Ld,Hsr,JQ,Usr,Jsr,YQ,Ysr,Ksr,Zsr,C8,elr,G7e,olr,rlr,tlr,Tt,w8,alr,O7e,nlr,slr,yd,llr,V7e,ilr,dlr,KQ,clr,flr,mlr,k3,glr,mo,A8,hlr,X7e,plr,_lr,Ha,ulr,z7e,blr,vlr,Q7e,Flr,Tlr,W7e,Mlr,Elr,Clr,et,S3,H7e,wlr,Alr,ZQ,Llr,ylr,xlr,R3,U7e,$lr,klr,eW,Slr,Rlr,Plr,P3,J7e,Blr,Ilr,oW,Nlr,qlr,jlr,B3,Y7e,Dlr,Glr,rW,Olr,Vlr,Xlr,I3,K7e,zlr,Qlr,tW,Wlr,Hlr,Ulr,N3,Jlr,Z7e,Ylr,Klr,e2e,Zlr,eir,q3,$Oe,xd,j3,o2e,L8,oir,r2e,rir,kOe,Qo,y8,tir,$d,air,aW,nir,sir,nW,lir,iir,dir,x8,cir,t2e,fir,mir,gir,Mt,$8,hir,a2e,pir,_ir,kd,uir,n2e,bir,vir,sW,Fir,Tir,Mir,D3,Eir,go,k8,Cir,s2e,wir,Air,Ua,Lir,l2e,yir,xir,i2e,$ir,kir,d2e,Sir,Rir,Pir,Le,G3,c2e,Bir,Iir,lW,Nir,qir,jir,O3,f2e,Dir,Gir,iW,Oir,Vir,Xir,V3,m2e,zir,Qir,dW,Wir,Hir,Uir,X3,g2e,Jir,Yir,cW,Kir,Zir,edr,z3,h2e,odr,rdr,fW,tdr,adr,ndr,Q3,p2e,sdr,ldr,mW,idr,ddr,cdr,W3,_2e,fdr,mdr,gW,gdr,hdr,pdr,H3,u2e,_dr,udr,hW,bdr,vdr,Fdr,U3,b2e,Tdr,Mdr,pW,Edr,Cdr,wdr,J3,v2e,Adr,Ldr,_W,ydr,xdr,$dr,Y3,kdr,F2e,Sdr,Rdr,T2e,Pdr,Bdr,K3,SOe,Sd,Z3,M2e,S8,Idr,E2e,Ndr,ROe,Wo,R8,qdr,Rd,jdr,uW,Ddr,Gdr,bW,Odr,Vdr,Xdr,P8,zdr,C2e,Qdr,Wdr,Hdr,Et,B8,Udr,w2e,Jdr,Ydr,Pd,Kdr,A2e,Zdr,ecr,vW,ocr,rcr,tcr,eF,acr,ho,I8,ncr,L2e,scr,lcr,Ja,icr,y2e,dcr,ccr,x2e,fcr,mcr,$2e,gcr,hcr,pcr,N8,oF,k2e,_cr,ucr,FW,bcr,vcr,Fcr,rF,S2e,Tcr,Mcr,TW,Ecr,Ccr,wcr,tF,Acr,R2e,Lcr,ycr,P2e,xcr,$cr,aF,POe,Bd,nF,B2e,q8,kcr,I2e,Scr,BOe,Ho,j8,Rcr,Id,Pcr,MW,Bcr,Icr,EW,Ncr,qcr,jcr,D8,Dcr,N2e,Gcr,Ocr,Vcr,Ct,G8,Xcr,q2e,zcr,Qcr,Nd,Wcr,j2e,Hcr,Ucr,CW,Jcr,Ycr,Kcr,sF,Zcr,po,O8,efr,D2e,ofr,rfr,Ya,tfr,G2e,afr,nfr,O2e,sfr,lfr,V2e,ifr,dfr,cfr,ot,lF,X2e,ffr,mfr,wW,gfr,hfr,pfr,iF,z2e,_fr,ufr,AW,bfr,vfr,Ffr,dF,Q2e,Tfr,Mfr,LW,Efr,Cfr,wfr,cF,W2e,Afr,Lfr,yW,yfr,xfr,$fr,fF,H2e,kfr,Sfr,xW,Rfr,Pfr,Bfr,mF,Ifr,U2e,Nfr,qfr,J2e,jfr,Dfr,gF,IOe,qd,hF,Y2e,V8,Gfr,K2e,Ofr,NOe,Uo,X8,Vfr,jd,Xfr,$W,zfr,Qfr,kW,Wfr,Hfr,Ufr,z8,Jfr,Z2e,Yfr,Kfr,Zfr,wt,Q8,emr,ebe,omr,rmr,Dd,tmr,obe,amr,nmr,SW,smr,lmr,imr,pF,dmr,_o,W8,cmr,rbe,fmr,mmr,Ka,gmr,tbe,hmr,pmr,abe,_mr,umr,nbe,bmr,vmr,Fmr,Gd,_F,sbe,Tmr,Mmr,RW,Emr,Cmr,wmr,uF,lbe,Amr,Lmr,PW,ymr,xmr,$mr,bF,ibe,kmr,Smr,BW,Rmr,Pmr,Bmr,vF,Imr,dbe,Nmr,qmr,cbe,jmr,Dmr,FF,qOe,Od,TF,fbe,H8,Gmr,mbe,Omr,jOe,Jo,U8,Vmr,Vd,Xmr,IW,zmr,Qmr,NW,Wmr,Hmr,Umr,J8,Jmr,gbe,Ymr,Kmr,Zmr,At,Y8,egr,hbe,ogr,rgr,Xd,tgr,pbe,agr,ngr,qW,sgr,lgr,igr,MF,dgr,uo,K8,cgr,_be,fgr,mgr,Za,ggr,ube,hgr,pgr,bbe,_gr,ugr,vbe,bgr,vgr,Fgr,Z8,EF,Fbe,Tgr,Mgr,jW,Egr,Cgr,wgr,CF,Tbe,Agr,Lgr,DW,ygr,xgr,$gr,wF,kgr,Mbe,Sgr,Rgr,Ebe,Pgr,Bgr,AF,DOe,zd,LF,Cbe,e9,Igr,wbe,Ngr,GOe,Yo,o9,qgr,Qd,jgr,GW,Dgr,Ggr,OW,Ogr,Vgr,Xgr,r9,zgr,Abe,Qgr,Wgr,Hgr,Lt,t9,Ugr,Lbe,Jgr,Ygr,Wd,Kgr,ybe,Zgr,ehr,VW,ohr,rhr,thr,yF,ahr,bo,a9,nhr,xbe,shr,lhr,en,ihr,$be,dhr,chr,kbe,fhr,mhr,Sbe,ghr,hhr,phr,Rbe,xF,Pbe,_hr,uhr,XW,bhr,vhr,Fhr,$F,Thr,Bbe,Mhr,Ehr,Ibe,Chr,whr,kF,OOe,Hd,SF,Nbe,n9,Ahr,qbe,Lhr,VOe,Ko,s9,yhr,Ud,xhr,zW,$hr,khr,QW,Shr,Rhr,Phr,l9,Bhr,jbe,Ihr,Nhr,qhr,yt,i9,jhr,Dbe,Dhr,Ghr,Jd,Ohr,Gbe,Vhr,Xhr,WW,zhr,Qhr,Whr,RF,Hhr,vo,d9,Uhr,Obe,Jhr,Yhr,on,Khr,Vbe,Zhr,epr,Xbe,opr,rpr,zbe,tpr,apr,npr,rn,PF,Qbe,spr,lpr,HW,ipr,dpr,cpr,BF,Wbe,fpr,mpr,UW,gpr,hpr,ppr,IF,Hbe,_pr,upr,JW,bpr,vpr,Fpr,NF,Ube,Tpr,Mpr,YW,Epr,Cpr,wpr,qF,Apr,Jbe,Lpr,ypr,Ybe,xpr,$pr,jF,XOe,Yd,DF,Kbe,c9,kpr,Zbe,Spr,zOe,Zo,f9,Rpr,Kd,Ppr,KW,Bpr,Ipr,ZW,Npr,qpr,jpr,m9,Dpr,e5e,Gpr,Opr,Vpr,xt,g9,Xpr,o5e,zpr,Qpr,Zd,Wpr,r5e,Hpr,Upr,eH,Jpr,Ypr,Kpr,GF,Zpr,Fo,h9,e_r,t5e,o_r,r_r,tn,t_r,a5e,a_r,n_r,n5e,s_r,l_r,s5e,i_r,d_r,c_r,l5e,OF,i5e,f_r,m_r,oH,g_r,h_r,p_r,VF,__r,d5e,u_r,b_r,c5e,v_r,F_r,XF,QOe,ec,zF,f5e,p9,T_r,m5e,M_r,WOe,er,_9,E_r,oc,C_r,rH,w_r,A_r,tH,L_r,y_r,x_r,u9,$_r,g5e,k_r,S_r,R_r,$t,b9,P_r,h5e,B_r,I_r,rc,N_r,p5e,q_r,j_r,aH,D_r,G_r,O_r,QF,V_r,yr,v9,X_r,_5e,z_r,Q_r,an,W_r,u5e,H_r,U_r,b5e,J_r,Y_r,v5e,K_r,Z_r,eur,j,WF,F5e,our,rur,nH,tur,aur,nur,HF,T5e,sur,lur,sH,iur,dur,cur,UF,M5e,fur,mur,lH,gur,hur,pur,JF,E5e,_ur,uur,iH,bur,vur,Fur,YF,C5e,Tur,Mur,dH,Eur,Cur,wur,KF,w5e,Aur,Lur,cH,yur,xur,$ur,ZF,A5e,kur,Sur,fH,Rur,Pur,Bur,eT,L5e,Iur,Nur,mH,qur,jur,Dur,oT,y5e,Gur,Our,gH,Vur,Xur,zur,rT,x5e,Qur,Wur,hH,Hur,Uur,Jur,tT,$5e,Yur,Kur,pH,Zur,e1r,o1r,aT,k5e,r1r,t1r,_H,a1r,n1r,s1r,nT,S5e,l1r,i1r,uH,d1r,c1r,f1r,sT,R5e,m1r,g1r,bH,h1r,p1r,_1r,lT,P5e,u1r,b1r,vH,v1r,F1r,T1r,iT,B5e,M1r,E1r,FH,C1r,w1r,A1r,dT,I5e,L1r,y1r,TH,x1r,$1r,k1r,Qs,N5e,S1r,R1r,MH,P1r,B1r,EH,I1r,N1r,q1r,cT,q5e,j1r,D1r,CH,G1r,O1r,V1r,fT,j5e,X1r,z1r,wH,Q1r,W1r,H1r,mT,D5e,U1r,J1r,AH,Y1r,K1r,Z1r,gT,G5e,e7r,o7r,LH,r7r,t7r,a7r,hT,O5e,n7r,s7r,yH,l7r,i7r,d7r,pT,V5e,c7r,f7r,xH,m7r,g7r,h7r,_T,X5e,p7r,_7r,$H,u7r,b7r,v7r,uT,z5e,F7r,T7r,kH,M7r,E7r,C7r,bT,Q5e,w7r,A7r,SH,L7r,y7r,x7r,vT,W5e,$7r,k7r,RH,S7r,R7r,P7r,FT,H5e,B7r,I7r,PH,N7r,q7r,j7r,TT,U5e,D7r,G7r,BH,O7r,V7r,X7r,MT,J5e,z7r,Q7r,IH,W7r,H7r,U7r,ET,Y5e,J7r,Y7r,NH,K7r,Z7r,e2r,CT,K5e,o2r,r2r,qH,t2r,a2r,n2r,wT,Z5e,s2r,l2r,jH,i2r,d2r,c2r,AT,eve,f2r,m2r,DH,g2r,h2r,p2r,LT,ove,_2r,u2r,GH,b2r,v2r,F2r,yT,rve,T2r,M2r,OH,E2r,C2r,w2r,xT,tve,A2r,L2r,VH,y2r,x2r,$2r,$T,ave,k2r,S2r,XH,R2r,P2r,B2r,kT,nve,I2r,N2r,zH,q2r,j2r,D2r,ST,sve,G2r,O2r,QH,V2r,X2r,z2r,RT,lve,Q2r,W2r,WH,H2r,U2r,J2r,PT,ive,Y2r,K2r,HH,Z2r,ebr,obr,BT,dve,rbr,tbr,UH,abr,nbr,sbr,IT,cve,lbr,ibr,JH,dbr,cbr,fbr,NT,fve,mbr,gbr,YH,hbr,pbr,_br,qT,mve,ubr,bbr,KH,vbr,Fbr,Tbr,jT,HOe,tc,DT,gve,F9,Mbr,hve,Ebr,UOe,or,T9,Cbr,ac,wbr,ZH,Abr,Lbr,eU,ybr,xbr,$br,M9,kbr,pve,Sbr,Rbr,Pbr,kt,E9,Bbr,_ve,Ibr,Nbr,nc,qbr,uve,jbr,Dbr,oU,Gbr,Obr,Vbr,GT,Xbr,xr,C9,zbr,bve,Qbr,Wbr,nn,Hbr,vve,Ubr,Jbr,Fve,Ybr,Kbr,Tve,Zbr,e5r,o5r,se,OT,Mve,r5r,t5r,rU,a5r,n5r,s5r,VT,Eve,l5r,i5r,tU,d5r,c5r,f5r,XT,Cve,m5r,g5r,aU,h5r,p5r,_5r,zT,wve,u5r,b5r,nU,v5r,F5r,T5r,QT,Ave,M5r,E5r,sU,C5r,w5r,A5r,WT,Lve,L5r,y5r,lU,x5r,$5r,k5r,HT,yve,S5r,R5r,iU,P5r,B5r,I5r,UT,xve,N5r,q5r,dU,j5r,D5r,G5r,JT,$ve,O5r,V5r,cU,X5r,z5r,Q5r,YT,kve,W5r,H5r,fU,U5r,J5r,Y5r,KT,Sve,K5r,Z5r,mU,evr,ovr,rvr,ZT,Rve,tvr,avr,gU,nvr,svr,lvr,eM,Pve,ivr,dvr,hU,cvr,fvr,mvr,oM,Bve,gvr,hvr,pU,pvr,_vr,uvr,rM,Ive,bvr,vvr,_U,Fvr,Tvr,Mvr,tM,Nve,Evr,Cvr,uU,wvr,Avr,Lvr,aM,qve,yvr,xvr,bU,$vr,kvr,Svr,nM,jve,Rvr,Pvr,vU,Bvr,Ivr,Nvr,sM,Dve,qvr,jvr,FU,Dvr,Gvr,Ovr,lM,Gve,Vvr,Xvr,TU,zvr,Qvr,Wvr,iM,Ove,Hvr,Uvr,MU,Jvr,Yvr,Kvr,dM,Vve,Zvr,e3r,EU,o3r,r3r,t3r,cM,Xve,a3r,n3r,CU,s3r,l3r,i3r,fM,JOe,sc,mM,zve,w9,d3r,Qve,c3r,YOe,rr,A9,f3r,lc,m3r,wU,g3r,h3r,AU,p3r,_3r,u3r,L9,b3r,Wve,v3r,F3r,T3r,St,y9,M3r,Hve,E3r,C3r,ic,w3r,Uve,A3r,L3r,LU,y3r,x3r,$3r,gM,k3r,$r,x9,S3r,Jve,R3r,P3r,sn,B3r,Yve,I3r,N3r,Kve,q3r,j3r,Zve,D3r,G3r,O3r,Me,hM,e3e,V3r,X3r,yU,z3r,Q3r,W3r,pM,o3e,H3r,U3r,xU,J3r,Y3r,K3r,_M,r3e,Z3r,eFr,$U,oFr,rFr,tFr,uM,t3e,aFr,nFr,kU,sFr,lFr,iFr,bM,a3e,dFr,cFr,SU,fFr,mFr,gFr,vM,n3e,hFr,pFr,RU,_Fr,uFr,bFr,FM,s3e,vFr,FFr,PU,TFr,MFr,EFr,TM,l3e,CFr,wFr,BU,AFr,LFr,yFr,MM,i3e,xFr,$Fr,IU,kFr,SFr,RFr,EM,d3e,PFr,BFr,NU,IFr,NFr,qFr,CM,c3e,jFr,DFr,qU,GFr,OFr,VFr,wM,f3e,XFr,zFr,jU,QFr,WFr,HFr,AM,m3e,UFr,JFr,DU,YFr,KFr,ZFr,LM,KOe,dc,yM,g3e,$9,eTr,h3e,oTr,ZOe,tr,k9,rTr,cc,tTr,GU,aTr,nTr,OU,sTr,lTr,iTr,S9,dTr,p3e,cTr,fTr,mTr,Rt,R9,gTr,_3e,hTr,pTr,fc,_Tr,u3e,uTr,bTr,VU,vTr,FTr,TTr,xM,MTr,kr,P9,ETr,b3e,CTr,wTr,ln,ATr,v3e,LTr,yTr,F3e,xTr,$Tr,T3e,kTr,STr,RTr,dn,$M,M3e,PTr,BTr,XU,ITr,NTr,qTr,kM,E3e,jTr,DTr,zU,GTr,OTr,VTr,SM,C3e,XTr,zTr,QU,QTr,WTr,HTr,RM,w3e,UTr,JTr,WU,YTr,KTr,ZTr,PM,eVe,mc,BM,A3e,B9,eMr,L3e,oMr,oVe,ar,I9,rMr,gc,tMr,HU,aMr,nMr,UU,sMr,lMr,iMr,N9,dMr,y3e,cMr,fMr,mMr,Pt,q9,gMr,x3e,hMr,pMr,hc,_Mr,$3e,uMr,bMr,JU,vMr,FMr,TMr,IM,MMr,Sr,j9,EMr,k3e,CMr,wMr,cn,AMr,S3e,LMr,yMr,R3e,xMr,$Mr,P3e,kMr,SMr,RMr,ie,NM,B3e,PMr,BMr,YU,IMr,NMr,qMr,qM,I3e,jMr,DMr,KU,GMr,OMr,VMr,jM,N3e,XMr,zMr,ZU,QMr,WMr,HMr,DM,q3e,UMr,JMr,eJ,YMr,KMr,ZMr,GM,j3e,eEr,oEr,oJ,rEr,tEr,aEr,OM,D3e,nEr,sEr,rJ,lEr,iEr,dEr,VM,G3e,cEr,fEr,tJ,mEr,gEr,hEr,XM,O3e,pEr,_Er,aJ,uEr,bEr,vEr,zM,V3e,FEr,TEr,nJ,MEr,EEr,CEr,QM,X3e,wEr,AEr,sJ,LEr,yEr,xEr,WM,z3e,$Er,kEr,lJ,SEr,REr,PEr,HM,Q3e,BEr,IEr,iJ,NEr,qEr,jEr,UM,W3e,DEr,GEr,dJ,OEr,VEr,XEr,JM,H3e,zEr,QEr,cJ,WEr,HEr,UEr,YM,U3e,JEr,YEr,fJ,KEr,ZEr,e4r,KM,J3e,o4r,r4r,mJ,t4r,a4r,n4r,ZM,Y3e,s4r,l4r,gJ,i4r,d4r,c4r,eE,K3e,f4r,m4r,hJ,g4r,h4r,p4r,oE,Z3e,_4r,u4r,pJ,b4r,v4r,F4r,rE,eFe,T4r,M4r,_J,E4r,C4r,w4r,tE,rVe,pc,aE,oFe,D9,A4r,rFe,L4r,tVe,nr,G9,y4r,_c,x4r,uJ,$4r,k4r,bJ,S4r,R4r,P4r,O9,B4r,tFe,I4r,N4r,q4r,Bt,V9,j4r,aFe,D4r,G4r,uc,O4r,nFe,V4r,X4r,vJ,z4r,Q4r,W4r,nE,H4r,Rr,X9,U4r,sFe,J4r,Y4r,fn,K4r,lFe,Z4r,eCr,iFe,oCr,rCr,dFe,tCr,aCr,nCr,ye,sE,cFe,sCr,lCr,FJ,iCr,dCr,cCr,lE,fFe,fCr,mCr,TJ,gCr,hCr,pCr,iE,mFe,_Cr,uCr,MJ,bCr,vCr,FCr,dE,gFe,TCr,MCr,EJ,ECr,CCr,wCr,cE,hFe,ACr,LCr,CJ,yCr,xCr,$Cr,fE,pFe,kCr,SCr,wJ,RCr,PCr,BCr,mE,_Fe,ICr,NCr,AJ,qCr,jCr,DCr,gE,uFe,GCr,OCr,LJ,VCr,XCr,zCr,hE,bFe,QCr,WCr,yJ,HCr,UCr,JCr,pE,vFe,YCr,KCr,xJ,ZCr,e0r,o0r,_E,aVe,bc,uE,FFe,z9,r0r,TFe,t0r,nVe,sr,Q9,a0r,vc,n0r,$J,s0r,l0r,kJ,i0r,d0r,c0r,W9,f0r,MFe,m0r,g0r,h0r,It,H9,p0r,EFe,_0r,u0r,Fc,b0r,CFe,v0r,F0r,SJ,T0r,M0r,E0r,bE,C0r,Pr,U9,w0r,wFe,A0r,L0r,mn,y0r,AFe,x0r,$0r,LFe,k0r,S0r,yFe,R0r,P0r,B0r,te,vE,xFe,I0r,N0r,RJ,q0r,j0r,D0r,FE,$Fe,G0r,O0r,PJ,V0r,X0r,z0r,TE,kFe,Q0r,W0r,BJ,H0r,U0r,J0r,ME,SFe,Y0r,K0r,IJ,Z0r,ewr,owr,EE,RFe,rwr,twr,NJ,awr,nwr,swr,CE,PFe,lwr,iwr,qJ,dwr,cwr,fwr,wE,BFe,mwr,gwr,jJ,hwr,pwr,_wr,AE,IFe,uwr,bwr,DJ,vwr,Fwr,Twr,LE,NFe,Mwr,Ewr,GJ,Cwr,wwr,Awr,yE,qFe,Lwr,ywr,OJ,xwr,$wr,kwr,xE,jFe,Swr,Rwr,VJ,Pwr,Bwr,Iwr,$E,DFe,Nwr,qwr,XJ,jwr,Dwr,Gwr,kE,GFe,Owr,Vwr,zJ,Xwr,zwr,Qwr,SE,OFe,Wwr,Hwr,QJ,Uwr,Jwr,Ywr,RE,VFe,Kwr,Zwr,WJ,eAr,oAr,rAr,PE,XFe,tAr,aAr,HJ,nAr,sAr,lAr,BE,zFe,iAr,dAr,UJ,cAr,fAr,mAr,IE,QFe,gAr,hAr,JJ,pAr,_Ar,uAr,NE,WFe,bAr,vAr,YJ,FAr,TAr,MAr,qE,HFe,EAr,CAr,KJ,wAr,AAr,LAr,jE,UFe,yAr,xAr,ZJ,$Ar,kAr,SAr,DE,JFe,RAr,PAr,eY,BAr,IAr,NAr,GE,YFe,qAr,jAr,oY,DAr,GAr,OAr,OE,KFe,VAr,XAr,rY,zAr,QAr,WAr,VE,ZFe,HAr,UAr,tY,JAr,YAr,KAr,XE,eTe,ZAr,e6r,aY,o6r,r6r,t6r,zE,sVe,Tc,QE,oTe,J9,a6r,rTe,n6r,lVe,lr,Y9,s6r,Mc,l6r,nY,i6r,d6r,sY,c6r,f6r,m6r,K9,g6r,tTe,h6r,p6r,_6r,Nt,Z9,u6r,aTe,b6r,v6r,Ec,F6r,nTe,T6r,M6r,lY,E6r,C6r,w6r,WE,A6r,Br,ex,L6r,sTe,y6r,x6r,gn,$6r,lTe,k6r,S6r,iTe,R6r,P6r,dTe,B6r,I6r,N6r,_e,HE,cTe,q6r,j6r,iY,D6r,G6r,O6r,UE,fTe,V6r,X6r,dY,z6r,Q6r,W6r,JE,mTe,H6r,U6r,cY,J6r,Y6r,K6r,YE,gTe,Z6r,eLr,fY,oLr,rLr,tLr,KE,hTe,aLr,nLr,mY,sLr,lLr,iLr,ZE,pTe,dLr,cLr,gY,fLr,mLr,gLr,e4,_Te,hLr,pLr,hY,_Lr,uLr,bLr,o4,uTe,vLr,FLr,pY,TLr,MLr,ELr,r4,bTe,CLr,wLr,_Y,ALr,LLr,yLr,t4,vTe,xLr,$Lr,uY,kLr,SLr,RLr,a4,FTe,PLr,BLr,bY,ILr,NLr,qLr,n4,TTe,jLr,DLr,vY,GLr,OLr,VLr,s4,MTe,XLr,zLr,FY,QLr,WLr,HLr,l4,ETe,ULr,JLr,TY,YLr,KLr,ZLr,i4,CTe,eyr,oyr,MY,ryr,tyr,ayr,d4,wTe,nyr,syr,EY,lyr,iyr,dyr,c4,ATe,cyr,fyr,CY,myr,gyr,hyr,f4,iVe,Cc,m4,LTe,ox,pyr,yTe,_yr,dVe,ir,rx,uyr,wc,byr,wY,vyr,Fyr,AY,Tyr,Myr,Eyr,tx,Cyr,xTe,wyr,Ayr,Lyr,qt,ax,yyr,$Te,xyr,$yr,Ac,kyr,kTe,Syr,Ryr,LY,Pyr,Byr,Iyr,g4,Nyr,Ir,nx,qyr,STe,jyr,Dyr,hn,Gyr,RTe,Oyr,Vyr,PTe,Xyr,zyr,BTe,Qyr,Wyr,Hyr,sx,h4,ITe,Uyr,Jyr,yY,Yyr,Kyr,Zyr,p4,NTe,e8r,o8r,xY,r8r,t8r,a8r,_4,cVe,Lc,u4,qTe,lx,n8r,jTe,s8r,fVe,dr,ix,l8r,yc,i8r,$Y,d8r,c8r,kY,f8r,m8r,g8r,dx,h8r,DTe,p8r,_8r,u8r,jt,cx,b8r,GTe,v8r,F8r,xc,T8r,OTe,M8r,E8r,SY,C8r,w8r,A8r,b4,L8r,Nr,fx,y8r,VTe,x8r,$8r,pn,k8r,XTe,S8r,R8r,zTe,P8r,B8r,QTe,I8r,N8r,q8r,WTe,v4,HTe,j8r,D8r,RY,G8r,O8r,V8r,F4,mVe,$c,T4,UTe,mx,X8r,JTe,z8r,gVe,cr,gx,Q8r,kc,W8r,PY,H8r,U8r,BY,J8r,Y8r,K8r,hx,Z8r,YTe,e9r,o9r,r9r,Dt,px,t9r,KTe,a9r,n9r,Sc,s9r,ZTe,l9r,i9r,IY,d9r,c9r,f9r,M4,m9r,qr,_x,g9r,eMe,h9r,p9r,_n,_9r,oMe,u9r,b9r,rMe,v9r,F9r,tMe,T9r,M9r,E9r,de,E4,aMe,C9r,w9r,NY,A9r,L9r,y9r,C4,nMe,x9r,$9r,qY,k9r,S9r,R9r,w4,sMe,P9r,B9r,jY,I9r,N9r,q9r,A4,lMe,j9r,D9r,DY,G9r,O9r,V9r,L4,iMe,X9r,z9r,GY,Q9r,W9r,H9r,y4,dMe,U9r,J9r,OY,Y9r,K9r,Z9r,x4,cMe,exr,oxr,VY,rxr,txr,axr,$4,fMe,nxr,sxr,XY,lxr,ixr,dxr,k4,mMe,cxr,fxr,zY,mxr,gxr,hxr,S4,gMe,pxr,_xr,QY,uxr,bxr,vxr,R4,hMe,Fxr,Txr,WY,Mxr,Exr,Cxr,P4,pMe,wxr,Axr,HY,Lxr,yxr,xxr,B4,_Me,$xr,kxr,UY,Sxr,Rxr,Pxr,I4,uMe,Bxr,Ixr,JY,Nxr,qxr,jxr,N4,bMe,Dxr,Gxr,YY,Oxr,Vxr,Xxr,q4,vMe,zxr,Qxr,KY,Wxr,Hxr,Uxr,j4,FMe,Jxr,Yxr,ZY,Kxr,Zxr,e$r,D4,TMe,o$r,r$r,eK,t$r,a$r,n$r,G4,MMe,s$r,l$r,oK,i$r,d$r,c$r,O4,EMe,f$r,m$r,rK,g$r,h$r,p$r,V4,hVe,Rc,X4,CMe,ux,_$r,wMe,u$r,pVe,fr,bx,b$r,Pc,v$r,tK,F$r,T$r,aK,M$r,E$r,C$r,vx,w$r,AMe,A$r,L$r,y$r,Gt,Fx,x$r,LMe,$$r,k$r,Bc,S$r,yMe,R$r,P$r,nK,B$r,I$r,N$r,z4,q$r,jr,Tx,j$r,xMe,D$r,G$r,un,O$r,$Me,V$r,X$r,kMe,z$r,Q$r,SMe,W$r,H$r,U$r,ce,Q4,RMe,J$r,Y$r,sK,K$r,Z$r,ekr,W4,PMe,okr,rkr,lK,tkr,akr,nkr,H4,BMe,skr,lkr,iK,ikr,dkr,ckr,U4,IMe,fkr,mkr,dK,gkr,hkr,pkr,J4,NMe,_kr,ukr,cK,bkr,vkr,Fkr,Y4,qMe,Tkr,Mkr,fK,Ekr,Ckr,wkr,K4,jMe,Akr,Lkr,mK,ykr,xkr,$kr,Z4,DMe,kkr,Skr,gK,Rkr,Pkr,Bkr,eC,GMe,Ikr,Nkr,hK,qkr,jkr,Dkr,oC,OMe,Gkr,Okr,pK,Vkr,Xkr,zkr,rC,VMe,Qkr,Wkr,_K,Hkr,Ukr,Jkr,tC,XMe,Ykr,Kkr,uK,Zkr,eSr,oSr,aC,zMe,rSr,tSr,bK,aSr,nSr,sSr,nC,QMe,lSr,iSr,vK,dSr,cSr,fSr,sC,WMe,mSr,gSr,FK,hSr,pSr,_Sr,lC,HMe,uSr,bSr,TK,vSr,FSr,TSr,iC,UMe,MSr,ESr,MK,CSr,wSr,ASr,dC,JMe,LSr,ySr,EK,xSr,$Sr,kSr,cC,YMe,SSr,RSr,CK,PSr,BSr,ISr,fC,KMe,NSr,qSr,wK,jSr,DSr,GSr,mC,_Ve,Ic,gC,ZMe,Mx,OSr,eEe,VSr,uVe,mr,Ex,XSr,Nc,zSr,AK,QSr,WSr,LK,HSr,USr,JSr,Cx,YSr,oEe,KSr,ZSr,eRr,Ot,wx,oRr,rEe,rRr,tRr,qc,aRr,tEe,nRr,sRr,yK,lRr,iRr,dRr,hC,cRr,Dr,Ax,fRr,aEe,mRr,gRr,bn,hRr,nEe,pRr,_Rr,sEe,uRr,bRr,lEe,vRr,FRr,TRr,iEe,pC,dEe,MRr,ERr,xK,CRr,wRr,ARr,_C,bVe,jc,uC,cEe,Lx,LRr,fEe,yRr,vVe,gr,yx,xRr,Dc,$Rr,$K,kRr,SRr,kK,RRr,PRr,BRr,xx,IRr,mEe,NRr,qRr,jRr,Vt,$x,DRr,gEe,GRr,ORr,Gc,VRr,hEe,XRr,zRr,SK,QRr,WRr,HRr,bC,URr,Gr,kx,JRr,pEe,YRr,KRr,vn,ZRr,_Ee,ePr,oPr,uEe,rPr,tPr,bEe,aPr,nPr,sPr,vEe,vC,FEe,lPr,iPr,RK,dPr,cPr,fPr,FC,FVe,Oc,TC,TEe,Sx,mPr,MEe,gPr,TVe,hr,Rx,hPr,Vc,pPr,PK,_Pr,uPr,BK,bPr,vPr,FPr,Px,TPr,EEe,MPr,EPr,CPr,Xt,Bx,wPr,CEe,APr,LPr,Xc,yPr,wEe,xPr,$Pr,IK,kPr,SPr,RPr,MC,PPr,Or,Ix,BPr,AEe,IPr,NPr,Fn,qPr,LEe,jPr,DPr,yEe,GPr,OPr,xEe,VPr,XPr,zPr,oe,EC,$Ee,QPr,WPr,NK,HPr,UPr,JPr,CC,kEe,YPr,KPr,qK,ZPr,eBr,oBr,wC,SEe,rBr,tBr,jK,aBr,nBr,sBr,AC,REe,lBr,iBr,DK,dBr,cBr,fBr,LC,PEe,mBr,gBr,GK,hBr,pBr,_Br,yC,BEe,uBr,bBr,OK,vBr,FBr,TBr,xC,IEe,MBr,EBr,VK,CBr,wBr,ABr,$C,NEe,LBr,yBr,XK,xBr,$Br,kBr,kC,qEe,SBr,RBr,zK,PBr,BBr,IBr,SC,jEe,NBr,qBr,QK,jBr,DBr,GBr,RC,DEe,OBr,VBr,WK,XBr,zBr,QBr,PC,GEe,WBr,HBr,HK,UBr,JBr,YBr,BC,OEe,KBr,ZBr,UK,eIr,oIr,rIr,IC,VEe,tIr,aIr,JK,nIr,sIr,lIr,NC,XEe,iIr,dIr,YK,cIr,fIr,mIr,qC,zEe,gIr,hIr,KK,pIr,_Ir,uIr,jC,QEe,bIr,vIr,ZK,FIr,TIr,MIr,DC,WEe,EIr,CIr,eZ,wIr,AIr,LIr,GC,HEe,yIr,xIr,oZ,$Ir,kIr,SIr,OC,UEe,RIr,PIr,rZ,BIr,IIr,NIr,VC,JEe,qIr,jIr,tZ,DIr,GIr,OIr,XC,YEe,VIr,XIr,aZ,zIr,QIr,WIr,zC,KEe,HIr,UIr,nZ,JIr,YIr,KIr,QC,ZEe,ZIr,eNr,sZ,oNr,rNr,tNr,WC,e4e,aNr,nNr,lZ,sNr,lNr,iNr,HC,o4e,dNr,cNr,iZ,fNr,mNr,gNr,UC,r4e,hNr,pNr,dZ,_Nr,uNr,bNr,JC,MVe,zc,YC,t4e,Nx,vNr,a4e,FNr,EVe,pr,qx,TNr,Qc,MNr,cZ,ENr,CNr,fZ,wNr,ANr,LNr,jx,yNr,n4e,xNr,$Nr,kNr,zt,Dx,SNr,s4e,RNr,PNr,Wc,BNr,l4e,INr,NNr,mZ,qNr,jNr,DNr,KC,GNr,Vr,Gx,ONr,i4e,VNr,XNr,Tn,zNr,d4e,QNr,WNr,c4e,HNr,UNr,f4e,JNr,YNr,KNr,xe,ZC,m4e,ZNr,eqr,gZ,oqr,rqr,tqr,e0,g4e,aqr,nqr,hZ,sqr,lqr,iqr,o0,h4e,dqr,cqr,pZ,fqr,mqr,gqr,r0,p4e,hqr,pqr,_Z,_qr,uqr,bqr,t0,_4e,vqr,Fqr,uZ,Tqr,Mqr,Eqr,a0,u4e,Cqr,wqr,bZ,Aqr,Lqr,yqr,n0,b4e,xqr,$qr,vZ,kqr,Sqr,Rqr,s0,v4e,Pqr,Bqr,FZ,Iqr,Nqr,qqr,l0,F4e,jqr,Dqr,TZ,Gqr,Oqr,Vqr,i0,T4e,Xqr,zqr,MZ,Qqr,Wqr,Hqr,d0,CVe,Hc,c0,M4e,Ox,Uqr,E4e,Jqr,wVe,_r,Vx,Yqr,Uc,Kqr,EZ,Zqr,ejr,CZ,ojr,rjr,tjr,Xx,ajr,C4e,njr,sjr,ljr,Qt,zx,ijr,w4e,djr,cjr,Jc,fjr,A4e,mjr,gjr,wZ,hjr,pjr,_jr,f0,ujr,Xr,Qx,bjr,L4e,vjr,Fjr,Mn,Tjr,y4e,Mjr,Ejr,x4e,Cjr,wjr,$4e,Ajr,Ljr,yjr,Ee,m0,k4e,xjr,$jr,AZ,kjr,Sjr,Rjr,g0,S4e,Pjr,Bjr,LZ,Ijr,Njr,qjr,h0,R4e,jjr,Djr,yZ,Gjr,Ojr,Vjr,p0,P4e,Xjr,zjr,xZ,Qjr,Wjr,Hjr,_0,B4e,Ujr,Jjr,$Z,Yjr,Kjr,Zjr,u0,I4e,eDr,oDr,kZ,rDr,tDr,aDr,b0,N4e,nDr,sDr,SZ,lDr,iDr,dDr,v0,q4e,cDr,fDr,RZ,mDr,gDr,hDr,F0,j4e,pDr,_Dr,PZ,uDr,bDr,vDr,T0,D4e,FDr,TDr,BZ,MDr,EDr,CDr,M0,G4e,wDr,ADr,IZ,LDr,yDr,xDr,E0,O4e,$Dr,kDr,NZ,SDr,RDr,PDr,C0,V4e,BDr,IDr,qZ,NDr,qDr,jDr,w0,AVe,Yc,A0,X4e,Wx,DDr,z4e,GDr,LVe,ur,Hx,ODr,Kc,VDr,jZ,XDr,zDr,DZ,QDr,WDr,HDr,Ux,UDr,Q4e,JDr,YDr,KDr,Wt,Jx,ZDr,W4e,eGr,oGr,Zc,rGr,H4e,tGr,aGr,GZ,nGr,sGr,lGr,L0,iGr,zr,Yx,dGr,U4e,cGr,fGr,En,mGr,J4e,gGr,hGr,Y4e,pGr,_Gr,K4e,uGr,bGr,vGr,$e,y0,Z4e,FGr,TGr,OZ,MGr,EGr,CGr,x0,eCe,wGr,AGr,VZ,LGr,yGr,xGr,$0,oCe,$Gr,kGr,XZ,SGr,RGr,PGr,k0,rCe,BGr,IGr,zZ,NGr,qGr,jGr,S0,tCe,DGr,GGr,QZ,OGr,VGr,XGr,R0,aCe,zGr,QGr,WZ,WGr,HGr,UGr,P0,nCe,JGr,YGr,HZ,KGr,ZGr,eOr,B0,sCe,oOr,rOr,UZ,tOr,aOr,nOr,I0,lCe,sOr,lOr,JZ,iOr,dOr,cOr,N0,iCe,fOr,mOr,YZ,gOr,hOr,pOr,q0,yVe,ef,j0,dCe,Kx,_Or,cCe,uOr,xVe,br,Zx,bOr,of,vOr,KZ,FOr,TOr,ZZ,MOr,EOr,COr,e$,wOr,fCe,AOr,LOr,yOr,Ht,o$,xOr,mCe,$Or,kOr,rf,SOr,gCe,ROr,POr,eee,BOr,IOr,NOr,D0,qOr,Qr,r$,jOr,hCe,DOr,GOr,Cn,OOr,pCe,VOr,XOr,_Ce,zOr,QOr,uCe,WOr,HOr,UOr,ke,G0,bCe,JOr,YOr,oee,KOr,ZOr,eVr,O0,vCe,oVr,rVr,ree,tVr,aVr,nVr,V0,FCe,sVr,lVr,tee,iVr,dVr,cVr,X0,TCe,fVr,mVr,aee,gVr,hVr,pVr,z0,MCe,_Vr,uVr,nee,bVr,vVr,FVr,Q0,ECe,TVr,MVr,see,EVr,CVr,wVr,W0,CCe,AVr,LVr,lee,yVr,xVr,$Vr,H0,wCe,kVr,SVr,iee,RVr,PVr,BVr,U0,ACe,IVr,NVr,dee,qVr,jVr,DVr,J0,LCe,GVr,OVr,cee,VVr,XVr,zVr,Y0,$Ve,tf,K0,yCe,t$,QVr,xCe,WVr,kVe,vr,a$,HVr,af,UVr,fee,JVr,YVr,mee,KVr,ZVr,eXr,n$,oXr,$Ce,rXr,tXr,aXr,Ut,s$,nXr,kCe,sXr,lXr,nf,iXr,SCe,dXr,cXr,gee,fXr,mXr,gXr,Z0,hXr,Wr,l$,pXr,RCe,_Xr,uXr,wn,bXr,PCe,vXr,FXr,BCe,TXr,MXr,ICe,EXr,CXr,wXr,Se,ew,NCe,AXr,LXr,hee,yXr,xXr,$Xr,ow,qCe,kXr,SXr,pee,RXr,PXr,BXr,rw,jCe,IXr,NXr,_ee,qXr,jXr,DXr,tw,DCe,GXr,OXr,uee,VXr,XXr,zXr,aw,GCe,QXr,WXr,bee,HXr,UXr,JXr,nw,OCe,YXr,KXr,vee,ZXr,ezr,ozr,sw,VCe,rzr,tzr,Fee,azr,nzr,szr,lw,XCe,lzr,izr,Tee,dzr,czr,fzr,iw,zCe,mzr,gzr,Mee,hzr,pzr,_zr,dw,QCe,uzr,bzr,Eee,vzr,Fzr,Tzr,cw,SVe,sf,fw,WCe,i$,Mzr,HCe,Ezr,RVe,Fr,d$,Czr,lf,wzr,Cee,Azr,Lzr,wee,yzr,xzr,$zr,c$,kzr,UCe,Szr,Rzr,Pzr,Jt,f$,Bzr,JCe,Izr,Nzr,df,qzr,YCe,jzr,Dzr,Aee,Gzr,Ozr,Vzr,mw,Xzr,Hr,m$,zzr,KCe,Qzr,Wzr,An,Hzr,ZCe,Uzr,Jzr,e0e,Yzr,Kzr,o0e,Zzr,eQr,oQr,Re,gw,r0e,rQr,tQr,Lee,aQr,nQr,sQr,hw,t0e,lQr,iQr,yee,dQr,cQr,fQr,pw,a0e,mQr,gQr,xee,hQr,pQr,_Qr,_w,n0e,uQr,bQr,$ee,vQr,FQr,TQr,uw,s0e,MQr,EQr,kee,CQr,wQr,AQr,bw,l0e,LQr,yQr,See,xQr,$Qr,kQr,vw,i0e,SQr,RQr,Ree,PQr,BQr,IQr,Fw,d0e,NQr,qQr,Pee,jQr,DQr,GQr,Tw,c0e,OQr,VQr,Bee,XQr,zQr,QQr,Mw,f0e,WQr,HQr,Iee,UQr,JQr,YQr,Ew,PVe,cf,Cw,m0e,g$,KQr,g0e,ZQr,BVe,Tr,h$,eWr,ff,oWr,Nee,rWr,tWr,qee,aWr,nWr,sWr,p$,lWr,h0e,iWr,dWr,cWr,Yt,_$,fWr,p0e,mWr,gWr,mf,hWr,_0e,pWr,_Wr,jee,uWr,bWr,vWr,ww,FWr,Ur,u$,TWr,u0e,MWr,EWr,Ln,CWr,b0e,wWr,AWr,v0e,LWr,yWr,F0e,xWr,$Wr,kWr,Ve,Aw,T0e,SWr,RWr,Dee,PWr,BWr,IWr,Lw,M0e,NWr,qWr,Gee,jWr,DWr,GWr,yw,E0e,OWr,VWr,Oee,XWr,zWr,QWr,xw,C0e,WWr,HWr,Vee,UWr,JWr,YWr,$w,w0e,KWr,ZWr,Xee,eHr,oHr,rHr,kw,A0e,tHr,aHr,zee,nHr,sHr,lHr,Sw,L0e,iHr,dHr,Qee,cHr,fHr,mHr,Rw,y0e,gHr,hHr,Wee,pHr,_Hr,uHr,Pw,IVe,gf,Bw,x0e,b$,bHr,$0e,vHr,NVe,Mr,v$,FHr,hf,THr,Hee,MHr,EHr,Uee,CHr,wHr,AHr,F$,LHr,k0e,yHr,xHr,$Hr,Kt,T$,kHr,S0e,SHr,RHr,pf,PHr,R0e,BHr,IHr,Jee,NHr,qHr,jHr,Iw,DHr,Jr,M$,GHr,P0e,OHr,VHr,yn,XHr,B0e,zHr,QHr,I0e,WHr,HHr,N0e,UHr,JHr,YHr,Xe,Nw,q0e,KHr,ZHr,Yee,eUr,oUr,rUr,qw,j0e,tUr,aUr,Kee,nUr,sUr,lUr,jw,D0e,iUr,dUr,Zee,cUr,fUr,mUr,Dw,G0e,gUr,hUr,eoe,pUr,_Ur,uUr,Gw,O0e,bUr,vUr,ooe,FUr,TUr,MUr,Ow,V0e,EUr,CUr,roe,wUr,AUr,LUr,Vw,X0e,yUr,xUr,toe,$Ur,kUr,SUr,Xw,z0e,RUr,PUr,aoe,BUr,IUr,NUr,zw,qVe,_f,Qw,Q0e,E$,qUr,W0e,jUr,jVe,Er,C$,DUr,uf,GUr,noe,OUr,VUr,soe,XUr,zUr,QUr,w$,WUr,H0e,HUr,UUr,JUr,Zt,A$,YUr,U0e,KUr,ZUr,bf,eJr,J0e,oJr,rJr,loe,tJr,aJr,nJr,Ww,sJr,Yr,L$,lJr,Y0e,iJr,dJr,xn,cJr,K0e,fJr,mJr,Z0e,gJr,hJr,ewe,pJr,_Jr,uJr,owe,Hw,rwe,bJr,vJr,ioe,FJr,TJr,MJr,Uw,DVe,vf,Jw,twe,y$,EJr,awe,CJr,GVe,Cr,x$,wJr,Ff,AJr,doe,LJr,yJr,coe,xJr,$Jr,kJr,$$,SJr,nwe,RJr,PJr,BJr,ea,k$,IJr,swe,NJr,qJr,Tf,jJr,lwe,DJr,GJr,foe,OJr,VJr,XJr,Yw,zJr,Kr,S$,QJr,iwe,WJr,HJr,$n,UJr,dwe,JJr,YJr,cwe,KJr,ZJr,fwe,eYr,oYr,rYr,R$,Kw,mwe,tYr,aYr,moe,nYr,sYr,lYr,Zw,gwe,iYr,dYr,goe,cYr,fYr,mYr,eA,OVe,Mf,oA,hwe,P$,gYr,pwe,hYr,VVe,wr,B$,pYr,Ef,_Yr,hoe,uYr,bYr,poe,vYr,FYr,TYr,I$,MYr,_we,EYr,CYr,wYr,oa,N$,AYr,uwe,LYr,yYr,Cf,xYr,bwe,$Yr,kYr,_oe,SYr,RYr,PYr,rA,BYr,Zr,q$,IYr,vwe,NYr,qYr,kn,jYr,Fwe,DYr,GYr,Twe,OYr,VYr,Mwe,XYr,zYr,QYr,Ewe,tA,Cwe,WYr,HYr,uoe,UYr,JYr,YYr,aA,XVe;return d=new re({}),xa=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),xL=new re({}),$L=new P({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Rf=new KYr({props:{warning:!0,$$slots:{default:[CDt]},$$scope:{ctx:x}}}),kL=new re({}),SL=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/configuration_auto.py#L598"}}),BL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/configuration_auto.py#L621"}}),Gg=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[wDt]},$$scope:{ctx:x}}}),IL=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/configuration_auto.py#L744"}}),NL=new re({}),qL=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/tokenization_auto.py#L400"}}),GL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17573/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/tokenization_auto.py#L414"}}),Eh=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[ADt]},$$scope:{ctx:x}}}),OL=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/tokenization_auto.py#L613"}}),VL=new re({}),XL=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/feature_extraction_auto.py#L193"}}),WL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17573/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/feature_extraction_auto.py#L207"}}),ap=new KYr({props:{$$slots:{default:[LDt]},$$scope:{ctx:x}}}),np=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[yDt]},$$scope:{ctx:x}}}),HL=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/feature_extraction_auto.py#L334"}}),UL=new re({}),JL=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/processing_auto.py#L88"}}),ZL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/processing_auto.py#L102"}}),wp=new KYr({props:{$$slots:{default:[xDt]},$$scope:{ctx:x}}}),Ap=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[$Dt]},$$scope:{ctx:x}}}),ey=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/processing_auto.py#L255"}}),oy=new re({}),ry=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L767"}}),ay=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),xp=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[kDt]},$$scope:{ctx:x}}}),ny=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),xu=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[SDt]},$$scope:{ctx:x}}}),sy=new re({}),ly=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L774"}}),dy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),ku=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[RDt]},$$scope:{ctx:x}}}),cy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),E1=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[PDt]},$$scope:{ctx:x}}}),fy=new re({}),my=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L789"}}),hy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),w1=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[BDt]},$$scope:{ctx:x}}}),py=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),f7=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[IDt]},$$scope:{ctx:x}}}),_y=new re({}),uy=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L796"}}),vy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),g7=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[NDt]},$$scope:{ctx:x}}}),Fy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),K7=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[qDt]},$$scope:{ctx:x}}}),Ty=new re({}),My=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L803"}}),Cy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),e2=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[jDt]},$$scope:{ctx:x}}}),wy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),v2=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[DDt]},$$scope:{ctx:x}}}),Ay=new re({}),Ly=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L812"}}),xy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),T2=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[GDt]},$$scope:{ctx:x}}}),$y=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),bb=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[ODt]},$$scope:{ctx:x}}}),ky=new re({}),Sy=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L857"}}),Py=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),Fb=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[VDt]},$$scope:{ctx:x}}}),By=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),Kb=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[XDt]},$$scope:{ctx:x}}}),Iy=new re({}),Ny=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L864"}}),jy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),e5=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[zDt]},$$scope:{ctx:x}}}),Dy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),i5=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[QDt]},$$scope:{ctx:x}}}),Gy=new re({}),Oy=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L850"}}),Xy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),c5=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[WDt]},$$scope:{ctx:x}}}),zy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),H5=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[HDt]},$$scope:{ctx:x}}}),Qy=new re({}),Wy=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L821"}}),Uy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),J5=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[UDt]},$$scope:{ctx:x}}}),Jy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),jv=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[JDt]},$$scope:{ctx:x}}}),Yy=new re({}),Ky=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L828"}}),e8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),Gv=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[YDt]},$$scope:{ctx:x}}}),o8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),Xv=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[KDt]},$$scope:{ctx:x}}}),r8=new re({}),t8=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L873"}}),n8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17573/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/pr_17573/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17573/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17573/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),Qv=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[ZDt]},$$scope:{ctx:x}}}),s8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),s3=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[eGt]},$$scope:{ctx:x}}}),l8=new re({}),i8=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L912"}}),c8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),i3=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[oGt]},$$scope:{ctx:x}}}),f8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),f3=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[rGt]},$$scope:{ctx:x}}}),m8=new re({}),g8=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L839"}}),p8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),g3=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[tGt]},$$scope:{ctx:x}}}),_8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),_3=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[aGt]},$$scope:{ctx:x}}}),u8=new re({}),b8=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L919"}}),F8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),b3=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[nGt]},$$scope:{ctx:x}}}),T8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),x3=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[sGt]},$$scope:{ctx:x}}}),M8=new re({}),E8=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L942"}}),w8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),k3=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[lGt]},$$scope:{ctx:x}}}),A8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),q3=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[iGt]},$$scope:{ctx:x}}}),L8=new re({}),y8=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L926"}}),$8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),D3=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[dGt]},$$scope:{ctx:x}}}),k8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),K3=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[cGt]},$$scope:{ctx:x}}}),S8=new re({}),R8=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L933"}}),B8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),eF=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[fGt]},$$scope:{ctx:x}}}),I8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),aF=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[mGt]},$$scope:{ctx:x}}}),q8=new re({}),j8=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L951"}}),G8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),sF=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[gGt]},$$scope:{ctx:x}}}),O8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),gF=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[hGt]},$$scope:{ctx:x}}}),V8=new re({}),X8=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L958"}}),Q8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),pF=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[pGt]},$$scope:{ctx:x}}}),W8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),FF=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[_Gt]},$$scope:{ctx:x}}}),H8=new re({}),U8=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L905"}}),Y8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),MF=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[uGt]},$$scope:{ctx:x}}}),K8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),AF=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[bGt]},$$scope:{ctx:x}}}),e9=new re({}),o9=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L880"}}),t9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),yF=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[vGt]},$$scope:{ctx:x}}}),a9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),kF=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[FGt]},$$scope:{ctx:x}}}),n9=new re({}),s9=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L887"}}),i9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),RF=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[TGt]},$$scope:{ctx:x}}}),d9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),jF=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[MGt]},$$scope:{ctx:x}}}),c9=new re({}),f9=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_auto.py#L896"}}),g9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),GF=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[EGt]},$$scope:{ctx:x}}}),h9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),XF=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[CGt]},$$scope:{ctx:x}}}),p9=new re({}),_9=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_tf_auto.py#L406"}}),b9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),QF=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[wGt]},$$scope:{ctx:x}}}),v9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),jT=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[AGt]},$$scope:{ctx:x}}}),F9=new re({}),T9=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_tf_auto.py#L413"}}),E9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),GT=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[LGt]},$$scope:{ctx:x}}}),C9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),fM=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[yGt]},$$scope:{ctx:x}}}),w9=new re({}),A9=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_tf_auto.py#L428"}}),y9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),gM=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[xGt]},$$scope:{ctx:x}}}),x9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),LM=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[$Gt]},$$scope:{ctx:x}}}),$9=new re({}),k9=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),R9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),xM=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[kGt]},$$scope:{ctx:x}}}),P9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),PM=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[SGt]},$$scope:{ctx:x}}}),B9=new re({}),I9=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_tf_auto.py#L469"}}),q9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),IM=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[RGt]},$$scope:{ctx:x}}}),j9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),tE=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[PGt]},$$scope:{ctx:x}}}),D9=new re({}),G9=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_tf_auto.py#L476"}}),V9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),nE=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[BGt]},$$scope:{ctx:x}}}),X9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),_E=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[IGt]},$$scope:{ctx:x}}}),z9=new re({}),Q9=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_tf_auto.py#L485"}}),H9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),bE=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[NGt]},$$scope:{ctx:x}}}),U9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),zE=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[qGt]},$$scope:{ctx:x}}}),J9=new re({}),Y9=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_tf_auto.py#L521"}}),Z9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),WE=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[jGt]},$$scope:{ctx:x}}}),ex=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),f4=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[DGt]},$$scope:{ctx:x}}}),ox=new re({}),rx=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_tf_auto.py#L528"}}),ax=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),g4=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[GGt]},$$scope:{ctx:x}}}),nx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),_4=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[OGt]},$$scope:{ctx:x}}}),lx=new re({}),ix=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_tf_auto.py#L501"}}),cx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),b4=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[VGt]},$$scope:{ctx:x}}}),fx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),F4=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[XGt]},$$scope:{ctx:x}}}),mx=new re({}),gx=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_tf_auto.py#L512"}}),px=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),M4=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[zGt]},$$scope:{ctx:x}}}),_x=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),V4=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[QGt]},$$scope:{ctx:x}}}),ux=new re({}),bx=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_tf_auto.py#L494"}}),Fx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),z4=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[WGt]},$$scope:{ctx:x}}}),Tx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),mC=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[HGt]},$$scope:{ctx:x}}}),Mx=new re({}),Ex=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_tf_auto.py#L462"}}),wx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),hC=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[UGt]},$$scope:{ctx:x}}}),Ax=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),_C=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[JGt]},$$scope:{ctx:x}}}),Lx=new re({}),yx=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_tf_auto.py#L537"}}),$x=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),bC=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[YGt]},$$scope:{ctx:x}}}),kx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),FC=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[KGt]},$$scope:{ctx:x}}}),Sx=new re({}),Rx=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),Bx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),MC=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[ZGt]},$$scope:{ctx:x}}}),Ix=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),JC=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[eOt]},$$scope:{ctx:x}}}),Nx=new re({}),qx=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),Dx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),KC=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[oOt]},$$scope:{ctx:x}}}),Gx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),d0=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[rOt]},$$scope:{ctx:x}}}),Ox=new re({}),Vx=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),zx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),f0=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[tOt]},$$scope:{ctx:x}}}),Qx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),w0=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[aOt]},$$scope:{ctx:x}}}),Wx=new re({}),Hx=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),Jx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),L0=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[nOt]},$$scope:{ctx:x}}}),Yx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),q0=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[sOt]},$$scope:{ctx:x}}}),Kx=new re({}),Zx=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),o$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),D0=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[lOt]},$$scope:{ctx:x}}}),r$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),Y0=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[iOt]},$$scope:{ctx:x}}}),t$=new re({}),a$=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),s$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),Z0=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[dOt]},$$scope:{ctx:x}}}),l$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),cw=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[cOt]},$$scope:{ctx:x}}}),i$=new re({}),d$=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),f$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),mw=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[fOt]},$$scope:{ctx:x}}}),m$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),Ew=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[mOt]},$$scope:{ctx:x}}}),g$=new re({}),h$=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),_$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),ww=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[gOt]},$$scope:{ctx:x}}}),u$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),Pw=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[hOt]},$$scope:{ctx:x}}}),b$=new re({}),v$=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),T$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),Iw=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[pOt]},$$scope:{ctx:x}}}),M$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),zw=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[_Ot]},$$scope:{ctx:x}}}),E$=new re({}),C$=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),A$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),Ww=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[uOt]},$$scope:{ctx:x}}}),L$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),Uw=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[bOt]},$$scope:{ctx:x}}}),y$=new re({}),x$=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),k$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17573/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),Yw=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[vOt]},$$scope:{ctx:x}}}),S$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),eA=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[FOt]},$$scope:{ctx:x}}}),P$=new re({}),B$=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),N$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17573/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17573/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L389"}}),rA=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[TOt]},$$scope:{ctx:x}}}),q$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17573/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17573/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17573/src/transformers/models/auto/auto_factory.py#L417"}}),aA=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[MOt]},$$scope:{ctx:x}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),_=a("span"),F(d.$$.fragment),h=l(),Eo=a("span"),Ti=o("Auto Classes"),yf=l(),at=a("p"),Mi=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Ei=a("code"),wL=o("from_pretrained()"),xf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Oe=l(),Qe=a("p"),Ci=o("Instantiating one of "),Rn=a("a"),AL=o("AutoConfig"),Pn=o(", "),Bn=a("a"),LL=o("AutoModel"),wi=o(`, and
`),In=a("a"),yL=o("AutoTokenizer"),Ai=o(" will directly create a class of the relevant architecture. For instance"),$f=l(),F(xa.$$.fragment),We=l(),Ae=a("p"),rS=o("will create a model that is an instance of "),Li=a("a"),tS=o("BertModel"),aS=o("."),Co=l(),$a=a("p"),nS=o("There is one class of "),kf=a("code"),sS=o("AutoModel"),eQe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),jGe=l(),yi=a("h2"),Sf=a("a"),mte=a("span"),F(xL.$$.fragment),oQe=l(),gte=a("span"),rQe=o("Extending the Auto Classes"),DGe=l(),Nn=a("p"),tQe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),hte=a("code"),aQe=o("NewModel"),nQe=o(", make sure you have a "),pte=a("code"),sQe=o("NewModelConfig"),lQe=o(` then you can add those to the auto
classes like this:`),GGe=l(),F($L.$$.fragment),OGe=l(),lS=a("p"),iQe=o("You will then be able to use the auto classes like you would usually do!"),VGe=l(),F(Rf.$$.fragment),XGe=l(),xi=a("h2"),Pf=a("a"),_te=a("span"),F(kL.$$.fragment),dQe=l(),ute=a("span"),cQe=o("AutoConfig"),zGe=l(),wo=a("div"),F(SL.$$.fragment),fQe=l(),RL=a("p"),mQe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),iS=a("a"),gQe=o("from_pretrained()"),hQe=o(" class method."),pQe=l(),PL=a("p"),_Qe=o("This class cannot be instantiated directly using "),bte=a("code"),uQe=o("__init__()"),bQe=o(" (throws an error)."),vQe=l(),Ar=a("div"),F(BL.$$.fragment),FQe=l(),vte=a("p"),TQe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),MQe=l(),$i=a("p"),EQe=o("The configuration class to instantiate is selected based on the "),Fte=a("code"),CQe=o("model_type"),wQe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Tte=a("code"),AQe=o("pretrained_model_name_or_path"),LQe=o(":"),yQe=l(),A=a("ul"),Bf=a("li"),Mte=a("strong"),xQe=o("albert"),$Qe=o(" \u2014 "),dS=a("a"),kQe=o("AlbertConfig"),SQe=o(" (ALBERT model)"),RQe=l(),If=a("li"),Ete=a("strong"),PQe=o("bart"),BQe=o(" \u2014 "),cS=a("a"),IQe=o("BartConfig"),NQe=o(" (BART model)"),qQe=l(),Nf=a("li"),Cte=a("strong"),jQe=o("beit"),DQe=o(" \u2014 "),fS=a("a"),GQe=o("BeitConfig"),OQe=o(" (BEiT model)"),VQe=l(),qf=a("li"),wte=a("strong"),XQe=o("bert"),zQe=o(" \u2014 "),mS=a("a"),QQe=o("BertConfig"),WQe=o(" (BERT model)"),HQe=l(),jf=a("li"),Ate=a("strong"),UQe=o("bert-generation"),JQe=o(" \u2014 "),gS=a("a"),YQe=o("BertGenerationConfig"),KQe=o(" (Bert Generation model)"),ZQe=l(),Df=a("li"),Lte=a("strong"),eWe=o("big_bird"),oWe=o(" \u2014 "),hS=a("a"),rWe=o("BigBirdConfig"),tWe=o(" (BigBird model)"),aWe=l(),Gf=a("li"),yte=a("strong"),nWe=o("bigbird_pegasus"),sWe=o(" \u2014 "),pS=a("a"),lWe=o("BigBirdPegasusConfig"),iWe=o(" (BigBird-Pegasus model)"),dWe=l(),Of=a("li"),xte=a("strong"),cWe=o("blenderbot"),fWe=o(" \u2014 "),_S=a("a"),mWe=o("BlenderbotConfig"),gWe=o(" (Blenderbot model)"),hWe=l(),Vf=a("li"),$te=a("strong"),pWe=o("blenderbot-small"),_We=o(" \u2014 "),uS=a("a"),uWe=o("BlenderbotSmallConfig"),bWe=o(" (BlenderbotSmall model)"),vWe=l(),Xf=a("li"),kte=a("strong"),FWe=o("bloom"),TWe=o(" \u2014 "),bS=a("a"),MWe=o("BloomConfig"),EWe=o(" (BLOOM model)"),CWe=l(),zf=a("li"),Ste=a("strong"),wWe=o("camembert"),AWe=o(" \u2014 "),vS=a("a"),LWe=o("CamembertConfig"),yWe=o(" (CamemBERT model)"),xWe=l(),Qf=a("li"),Rte=a("strong"),$We=o("canine"),kWe=o(" \u2014 "),FS=a("a"),SWe=o("CanineConfig"),RWe=o(" (CANINE model)"),PWe=l(),Wf=a("li"),Pte=a("strong"),BWe=o("clip"),IWe=o(" \u2014 "),TS=a("a"),NWe=o("CLIPConfig"),qWe=o(" (CLIP model)"),jWe=l(),Hf=a("li"),Bte=a("strong"),DWe=o("convbert"),GWe=o(" \u2014 "),MS=a("a"),OWe=o("ConvBertConfig"),VWe=o(" (ConvBERT model)"),XWe=l(),Uf=a("li"),Ite=a("strong"),zWe=o("convnext"),QWe=o(" \u2014 "),ES=a("a"),WWe=o("ConvNextConfig"),HWe=o(" (ConvNeXT model)"),UWe=l(),Jf=a("li"),Nte=a("strong"),JWe=o("ctrl"),YWe=o(" \u2014 "),CS=a("a"),KWe=o("CTRLConfig"),ZWe=o(" (CTRL model)"),eHe=l(),Yf=a("li"),qte=a("strong"),oHe=o("cvt"),rHe=o(" \u2014 "),wS=a("a"),tHe=o("CvtConfig"),aHe=o(" (CvT model)"),nHe=l(),Kf=a("li"),jte=a("strong"),sHe=o("data2vec-audio"),lHe=o(" \u2014 "),AS=a("a"),iHe=o("Data2VecAudioConfig"),dHe=o(" (Data2VecAudio model)"),cHe=l(),Zf=a("li"),Dte=a("strong"),fHe=o("data2vec-text"),mHe=o(" \u2014 "),LS=a("a"),gHe=o("Data2VecTextConfig"),hHe=o(" (Data2VecText model)"),pHe=l(),em=a("li"),Gte=a("strong"),_He=o("data2vec-vision"),uHe=o(" \u2014 "),yS=a("a"),bHe=o("Data2VecVisionConfig"),vHe=o(" (Data2VecVision model)"),FHe=l(),om=a("li"),Ote=a("strong"),THe=o("deberta"),MHe=o(" \u2014 "),xS=a("a"),EHe=o("DebertaConfig"),CHe=o(" (DeBERTa model)"),wHe=l(),rm=a("li"),Vte=a("strong"),AHe=o("deberta-v2"),LHe=o(" \u2014 "),$S=a("a"),yHe=o("DebertaV2Config"),xHe=o(" (DeBERTa-v2 model)"),$He=l(),tm=a("li"),Xte=a("strong"),kHe=o("decision_transformer"),SHe=o(" \u2014 "),kS=a("a"),RHe=o("DecisionTransformerConfig"),PHe=o(" (Decision Transformer model)"),BHe=l(),am=a("li"),zte=a("strong"),IHe=o("deit"),NHe=o(" \u2014 "),SS=a("a"),qHe=o("DeiTConfig"),jHe=o(" (DeiT model)"),DHe=l(),nm=a("li"),Qte=a("strong"),GHe=o("detr"),OHe=o(" \u2014 "),RS=a("a"),VHe=o("DetrConfig"),XHe=o(" (DETR model)"),zHe=l(),sm=a("li"),Wte=a("strong"),QHe=o("distilbert"),WHe=o(" \u2014 "),PS=a("a"),HHe=o("DistilBertConfig"),UHe=o(" (DistilBERT model)"),JHe=l(),lm=a("li"),Hte=a("strong"),YHe=o("dpr"),KHe=o(" \u2014 "),BS=a("a"),ZHe=o("DPRConfig"),eUe=o(" (DPR model)"),oUe=l(),im=a("li"),Ute=a("strong"),rUe=o("dpt"),tUe=o(" \u2014 "),IS=a("a"),aUe=o("DPTConfig"),nUe=o(" (DPT model)"),sUe=l(),dm=a("li"),Jte=a("strong"),lUe=o("electra"),iUe=o(" \u2014 "),NS=a("a"),dUe=o("ElectraConfig"),cUe=o(" (ELECTRA model)"),fUe=l(),cm=a("li"),Yte=a("strong"),mUe=o("encoder-decoder"),gUe=o(" \u2014 "),qS=a("a"),hUe=o("EncoderDecoderConfig"),pUe=o(" (Encoder decoder model)"),_Ue=l(),fm=a("li"),Kte=a("strong"),uUe=o("flaubert"),bUe=o(" \u2014 "),jS=a("a"),vUe=o("FlaubertConfig"),FUe=o(" (FlauBERT model)"),TUe=l(),mm=a("li"),Zte=a("strong"),MUe=o("flava"),EUe=o(" \u2014 "),DS=a("a"),CUe=o("FlavaConfig"),wUe=o(" (FLAVA model)"),AUe=l(),gm=a("li"),eae=a("strong"),LUe=o("fnet"),yUe=o(" \u2014 "),GS=a("a"),xUe=o("FNetConfig"),$Ue=o(" (FNet model)"),kUe=l(),hm=a("li"),oae=a("strong"),SUe=o("fsmt"),RUe=o(" \u2014 "),OS=a("a"),PUe=o("FSMTConfig"),BUe=o(" (FairSeq Machine-Translation model)"),IUe=l(),pm=a("li"),rae=a("strong"),NUe=o("funnel"),qUe=o(" \u2014 "),VS=a("a"),jUe=o("FunnelConfig"),DUe=o(" (Funnel Transformer model)"),GUe=l(),_m=a("li"),tae=a("strong"),OUe=o("glpn"),VUe=o(" \u2014 "),XS=a("a"),XUe=o("GLPNConfig"),zUe=o(" (GLPN model)"),QUe=l(),um=a("li"),aae=a("strong"),WUe=o("gpt2"),HUe=o(" \u2014 "),zS=a("a"),UUe=o("GPT2Config"),JUe=o(" (OpenAI GPT-2 model)"),YUe=l(),bm=a("li"),nae=a("strong"),KUe=o("gpt_neo"),ZUe=o(" \u2014 "),QS=a("a"),eJe=o("GPTNeoConfig"),oJe=o(" (GPT Neo model)"),rJe=l(),vm=a("li"),sae=a("strong"),tJe=o("gpt_neox"),aJe=o(" \u2014 "),WS=a("a"),nJe=o("GPTNeoXConfig"),sJe=o(" (GPT NeoX model)"),lJe=l(),Fm=a("li"),lae=a("strong"),iJe=o("gptj"),dJe=o(" \u2014 "),HS=a("a"),cJe=o("GPTJConfig"),fJe=o(" (GPT-J model)"),mJe=l(),Tm=a("li"),iae=a("strong"),gJe=o("hubert"),hJe=o(" \u2014 "),US=a("a"),pJe=o("HubertConfig"),_Je=o(" (Hubert model)"),uJe=l(),Mm=a("li"),dae=a("strong"),bJe=o("ibert"),vJe=o(" \u2014 "),JS=a("a"),FJe=o("IBertConfig"),TJe=o(" (I-BERT model)"),MJe=l(),Em=a("li"),cae=a("strong"),EJe=o("imagegpt"),CJe=o(" \u2014 "),YS=a("a"),wJe=o("ImageGPTConfig"),AJe=o(" (ImageGPT model)"),LJe=l(),Cm=a("li"),fae=a("strong"),yJe=o("layoutlm"),xJe=o(" \u2014 "),KS=a("a"),$Je=o("LayoutLMConfig"),kJe=o(" (LayoutLM model)"),SJe=l(),wm=a("li"),mae=a("strong"),RJe=o("layoutlmv2"),PJe=o(" \u2014 "),ZS=a("a"),BJe=o("LayoutLMv2Config"),IJe=o(" (LayoutLMv2 model)"),NJe=l(),Am=a("li"),gae=a("strong"),qJe=o("layoutlmv3"),jJe=o(" \u2014 "),eR=a("a"),DJe=o("LayoutLMv3Config"),GJe=o(" (LayoutLMv3 model)"),OJe=l(),Lm=a("li"),hae=a("strong"),VJe=o("led"),XJe=o(" \u2014 "),oR=a("a"),zJe=o("LEDConfig"),QJe=o(" (LED model)"),WJe=l(),ym=a("li"),pae=a("strong"),HJe=o("levit"),UJe=o(" \u2014 "),rR=a("a"),JJe=o("LevitConfig"),YJe=o(" (LeViT model)"),KJe=l(),xm=a("li"),_ae=a("strong"),ZJe=o("longformer"),eYe=o(" \u2014 "),tR=a("a"),oYe=o("LongformerConfig"),rYe=o(" (Longformer model)"),tYe=l(),$m=a("li"),uae=a("strong"),aYe=o("longt5"),nYe=o(" \u2014 "),aR=a("a"),sYe=o("LongT5Config"),lYe=o(" (LongT5 model)"),iYe=l(),km=a("li"),bae=a("strong"),dYe=o("luke"),cYe=o(" \u2014 "),nR=a("a"),fYe=o("LukeConfig"),mYe=o(" (LUKE model)"),gYe=l(),Sm=a("li"),vae=a("strong"),hYe=o("lxmert"),pYe=o(" \u2014 "),sR=a("a"),_Ye=o("LxmertConfig"),uYe=o(" (LXMERT model)"),bYe=l(),Rm=a("li"),Fae=a("strong"),vYe=o("m2m_100"),FYe=o(" \u2014 "),lR=a("a"),TYe=o("M2M100Config"),MYe=o(" (M2M100 model)"),EYe=l(),Pm=a("li"),Tae=a("strong"),CYe=o("marian"),wYe=o(" \u2014 "),iR=a("a"),AYe=o("MarianConfig"),LYe=o(" (Marian model)"),yYe=l(),Bm=a("li"),Mae=a("strong"),xYe=o("maskformer"),$Ye=o(" \u2014 "),dR=a("a"),kYe=o("MaskFormerConfig"),SYe=o(" (MaskFormer model)"),RYe=l(),Im=a("li"),Eae=a("strong"),PYe=o("mbart"),BYe=o(" \u2014 "),cR=a("a"),IYe=o("MBartConfig"),NYe=o(" (mBART model)"),qYe=l(),Nm=a("li"),Cae=a("strong"),jYe=o("mctct"),DYe=o(" \u2014 "),fR=a("a"),GYe=o("MCTCTConfig"),OYe=o(" (M-CTC-T model)"),VYe=l(),qm=a("li"),wae=a("strong"),XYe=o("megatron-bert"),zYe=o(" \u2014 "),mR=a("a"),QYe=o("MegatronBertConfig"),WYe=o(" (Megatron-BERT model)"),HYe=l(),jm=a("li"),Aae=a("strong"),UYe=o("mobilebert"),JYe=o(" \u2014 "),gR=a("a"),YYe=o("MobileBertConfig"),KYe=o(" (MobileBERT model)"),ZYe=l(),Dm=a("li"),Lae=a("strong"),eKe=o("mpnet"),oKe=o(" \u2014 "),hR=a("a"),rKe=o("MPNetConfig"),tKe=o(" (MPNet model)"),aKe=l(),Gm=a("li"),yae=a("strong"),nKe=o("mt5"),sKe=o(" \u2014 "),pR=a("a"),lKe=o("MT5Config"),iKe=o(" (MT5 model)"),dKe=l(),Om=a("li"),xae=a("strong"),cKe=o("nezha"),fKe=o(" \u2014 "),_R=a("a"),mKe=o("NezhaConfig"),gKe=o(" (Nezha model)"),hKe=l(),Vm=a("li"),$ae=a("strong"),pKe=o("nystromformer"),_Ke=o(" \u2014 "),uR=a("a"),uKe=o("NystromformerConfig"),bKe=o(" (Nystr\xF6mformer model)"),vKe=l(),Xm=a("li"),kae=a("strong"),FKe=o("openai-gpt"),TKe=o(" \u2014 "),bR=a("a"),MKe=o("OpenAIGPTConfig"),EKe=o(" (OpenAI GPT model)"),CKe=l(),zm=a("li"),Sae=a("strong"),wKe=o("opt"),AKe=o(" \u2014 "),vR=a("a"),LKe=o("OPTConfig"),yKe=o(" (OPT model)"),xKe=l(),Qm=a("li"),Rae=a("strong"),$Ke=o("pegasus"),kKe=o(" \u2014 "),FR=a("a"),SKe=o("PegasusConfig"),RKe=o(" (Pegasus model)"),PKe=l(),Wm=a("li"),Pae=a("strong"),BKe=o("perceiver"),IKe=o(" \u2014 "),TR=a("a"),NKe=o("PerceiverConfig"),qKe=o(" (Perceiver model)"),jKe=l(),Hm=a("li"),Bae=a("strong"),DKe=o("plbart"),GKe=o(" \u2014 "),MR=a("a"),OKe=o("PLBartConfig"),VKe=o(" (PLBart model)"),XKe=l(),Um=a("li"),Iae=a("strong"),zKe=o("poolformer"),QKe=o(" \u2014 "),ER=a("a"),WKe=o("PoolFormerConfig"),HKe=o(" (PoolFormer model)"),UKe=l(),Jm=a("li"),Nae=a("strong"),JKe=o("prophetnet"),YKe=o(" \u2014 "),CR=a("a"),KKe=o("ProphetNetConfig"),ZKe=o(" (ProphetNet model)"),eZe=l(),Ym=a("li"),qae=a("strong"),oZe=o("qdqbert"),rZe=o(" \u2014 "),wR=a("a"),tZe=o("QDQBertConfig"),aZe=o(" (QDQBert model)"),nZe=l(),Km=a("li"),jae=a("strong"),sZe=o("rag"),lZe=o(" \u2014 "),AR=a("a"),iZe=o("RagConfig"),dZe=o(" (RAG model)"),cZe=l(),Zm=a("li"),Dae=a("strong"),fZe=o("realm"),mZe=o(" \u2014 "),LR=a("a"),gZe=o("RealmConfig"),hZe=o(" (REALM model)"),pZe=l(),eg=a("li"),Gae=a("strong"),_Ze=o("reformer"),uZe=o(" \u2014 "),yR=a("a"),bZe=o("ReformerConfig"),vZe=o(" (Reformer model)"),FZe=l(),og=a("li"),Oae=a("strong"),TZe=o("regnet"),MZe=o(" \u2014 "),xR=a("a"),EZe=o("RegNetConfig"),CZe=o(" (RegNet model)"),wZe=l(),rg=a("li"),Vae=a("strong"),AZe=o("rembert"),LZe=o(" \u2014 "),$R=a("a"),yZe=o("RemBertConfig"),xZe=o(" (RemBERT model)"),$Ze=l(),tg=a("li"),Xae=a("strong"),kZe=o("resnet"),SZe=o(" \u2014 "),kR=a("a"),RZe=o("ResNetConfig"),PZe=o(" (ResNet model)"),BZe=l(),ag=a("li"),zae=a("strong"),IZe=o("retribert"),NZe=o(" \u2014 "),SR=a("a"),qZe=o("RetriBertConfig"),jZe=o(" (RetriBERT model)"),DZe=l(),ng=a("li"),Qae=a("strong"),GZe=o("roberta"),OZe=o(" \u2014 "),RR=a("a"),VZe=o("RobertaConfig"),XZe=o(" (RoBERTa model)"),zZe=l(),sg=a("li"),Wae=a("strong"),QZe=o("roformer"),WZe=o(" \u2014 "),PR=a("a"),HZe=o("RoFormerConfig"),UZe=o(" (RoFormer model)"),JZe=l(),lg=a("li"),Hae=a("strong"),YZe=o("segformer"),KZe=o(" \u2014 "),BR=a("a"),ZZe=o("SegformerConfig"),eeo=o(" (SegFormer model)"),oeo=l(),ig=a("li"),Uae=a("strong"),reo=o("sew"),teo=o(" \u2014 "),IR=a("a"),aeo=o("SEWConfig"),neo=o(" (SEW model)"),seo=l(),dg=a("li"),Jae=a("strong"),leo=o("sew-d"),ieo=o(" \u2014 "),NR=a("a"),deo=o("SEWDConfig"),ceo=o(" (SEW-D model)"),feo=l(),cg=a("li"),Yae=a("strong"),meo=o("speech-encoder-decoder"),geo=o(" \u2014 "),qR=a("a"),heo=o("SpeechEncoderDecoderConfig"),peo=o(" (Speech Encoder decoder model)"),_eo=l(),fg=a("li"),Kae=a("strong"),ueo=o("speech_to_text"),beo=o(" \u2014 "),jR=a("a"),veo=o("Speech2TextConfig"),Feo=o(" (Speech2Text model)"),Teo=l(),mg=a("li"),Zae=a("strong"),Meo=o("speech_to_text_2"),Eeo=o(" \u2014 "),DR=a("a"),Ceo=o("Speech2Text2Config"),weo=o(" (Speech2Text2 model)"),Aeo=l(),gg=a("li"),ene=a("strong"),Leo=o("splinter"),yeo=o(" \u2014 "),GR=a("a"),xeo=o("SplinterConfig"),$eo=o(" (Splinter model)"),keo=l(),hg=a("li"),one=a("strong"),Seo=o("squeezebert"),Reo=o(" \u2014 "),OR=a("a"),Peo=o("SqueezeBertConfig"),Beo=o(" (SqueezeBERT model)"),Ieo=l(),pg=a("li"),rne=a("strong"),Neo=o("swin"),qeo=o(" \u2014 "),VR=a("a"),jeo=o("SwinConfig"),Deo=o(" (Swin Transformer model)"),Geo=l(),_g=a("li"),tne=a("strong"),Oeo=o("t5"),Veo=o(" \u2014 "),XR=a("a"),Xeo=o("T5Config"),zeo=o(" (T5 model)"),Qeo=l(),ug=a("li"),ane=a("strong"),Weo=o("tapas"),Heo=o(" \u2014 "),zR=a("a"),Ueo=o("TapasConfig"),Jeo=o(" (TAPAS model)"),Yeo=l(),bg=a("li"),nne=a("strong"),Keo=o("trajectory_transformer"),Zeo=o(" \u2014 "),QR=a("a"),eoo=o("TrajectoryTransformerConfig"),ooo=o(" (Trajectory Transformer model)"),roo=l(),vg=a("li"),sne=a("strong"),too=o("transfo-xl"),aoo=o(" \u2014 "),WR=a("a"),noo=o("TransfoXLConfig"),soo=o(" (Transformer-XL model)"),loo=l(),Fg=a("li"),lne=a("strong"),ioo=o("trocr"),doo=o(" \u2014 "),HR=a("a"),coo=o("TrOCRConfig"),foo=o(" (TrOCR model)"),moo=l(),Tg=a("li"),ine=a("strong"),goo=o("unispeech"),hoo=o(" \u2014 "),UR=a("a"),poo=o("UniSpeechConfig"),_oo=o(" (UniSpeech model)"),uoo=l(),Mg=a("li"),dne=a("strong"),boo=o("unispeech-sat"),voo=o(" \u2014 "),JR=a("a"),Foo=o("UniSpeechSatConfig"),Too=o(" (UniSpeechSat model)"),Moo=l(),Eg=a("li"),cne=a("strong"),Eoo=o("van"),Coo=o(" \u2014 "),YR=a("a"),woo=o("VanConfig"),Aoo=o(" (VAN model)"),Loo=l(),Cg=a("li"),fne=a("strong"),yoo=o("vilt"),xoo=o(" \u2014 "),KR=a("a"),$oo=o("ViltConfig"),koo=o(" (ViLT model)"),Soo=l(),wg=a("li"),mne=a("strong"),Roo=o("vision-encoder-decoder"),Poo=o(" \u2014 "),ZR=a("a"),Boo=o("VisionEncoderDecoderConfig"),Ioo=o(" (Vision Encoder decoder model)"),Noo=l(),Ag=a("li"),gne=a("strong"),qoo=o("vision-text-dual-encoder"),joo=o(" \u2014 "),eP=a("a"),Doo=o("VisionTextDualEncoderConfig"),Goo=o(" (VisionTextDualEncoder model)"),Ooo=l(),Lg=a("li"),hne=a("strong"),Voo=o("visual_bert"),Xoo=o(" \u2014 "),oP=a("a"),zoo=o("VisualBertConfig"),Qoo=o(" (VisualBERT model)"),Woo=l(),yg=a("li"),pne=a("strong"),Hoo=o("vit"),Uoo=o(" \u2014 "),rP=a("a"),Joo=o("ViTConfig"),Yoo=o(" (ViT model)"),Koo=l(),xg=a("li"),_ne=a("strong"),Zoo=o("vit_mae"),ero=o(" \u2014 "),tP=a("a"),oro=o("ViTMAEConfig"),rro=o(" (ViTMAE model)"),tro=l(),$g=a("li"),une=a("strong"),aro=o("wav2vec2"),nro=o(" \u2014 "),aP=a("a"),sro=o("Wav2Vec2Config"),lro=o(" (Wav2Vec2 model)"),iro=l(),kg=a("li"),bne=a("strong"),dro=o("wav2vec2-conformer"),cro=o(" \u2014 "),nP=a("a"),fro=o("Wav2Vec2ConformerConfig"),mro=o(" (Wav2Vec2-Conformer model)"),gro=l(),Sg=a("li"),vne=a("strong"),hro=o("wavlm"),pro=o(" \u2014 "),sP=a("a"),_ro=o("WavLMConfig"),uro=o(" (WavLM model)"),bro=l(),Rg=a("li"),Fne=a("strong"),vro=o("xglm"),Fro=o(" \u2014 "),lP=a("a"),Tro=o("XGLMConfig"),Mro=o(" (XGLM model)"),Ero=l(),Pg=a("li"),Tne=a("strong"),Cro=o("xlm"),wro=o(" \u2014 "),iP=a("a"),Aro=o("XLMConfig"),Lro=o(" (XLM model)"),yro=l(),Bg=a("li"),Mne=a("strong"),xro=o("xlm-prophetnet"),$ro=o(" \u2014 "),dP=a("a"),kro=o("XLMProphetNetConfig"),Sro=o(" (XLM-ProphetNet model)"),Rro=l(),Ig=a("li"),Ene=a("strong"),Pro=o("xlm-roberta"),Bro=o(" \u2014 "),cP=a("a"),Iro=o("XLMRobertaConfig"),Nro=o(" (XLM-RoBERTa model)"),qro=l(),Ng=a("li"),Cne=a("strong"),jro=o("xlm-roberta-xl"),Dro=o(" \u2014 "),fP=a("a"),Gro=o("XLMRobertaXLConfig"),Oro=o(" (XLM-RoBERTa-XL model)"),Vro=l(),qg=a("li"),wne=a("strong"),Xro=o("xlnet"),zro=o(" \u2014 "),mP=a("a"),Qro=o("XLNetConfig"),Wro=o(" (XLNet model)"),Hro=l(),jg=a("li"),Ane=a("strong"),Uro=o("yolos"),Jro=o(" \u2014 "),gP=a("a"),Yro=o("YolosConfig"),Kro=o(" (YOLOS model)"),Zro=l(),Dg=a("li"),Lne=a("strong"),eto=o("yoso"),oto=o(" \u2014 "),hP=a("a"),rto=o("YosoConfig"),tto=o(" (YOSO model)"),ato=l(),F(Gg.$$.fragment),nto=l(),Og=a("div"),F(IL.$$.fragment),sto=l(),yne=a("p"),lto=o("Register a new configuration for this class."),QGe=l(),ki=a("h2"),Vg=a("a"),xne=a("span"),F(NL.$$.fragment),ito=l(),$ne=a("span"),dto=o("AutoTokenizer"),WGe=l(),Ao=a("div"),F(qL.$$.fragment),cto=l(),jL=a("p"),fto=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),pP=a("a"),mto=o("AutoTokenizer.from_pretrained()"),gto=o(" class method."),hto=l(),DL=a("p"),pto=o("This class cannot be instantiated directly using "),kne=a("code"),_to=o("__init__()"),uto=o(" (throws an error)."),bto=l(),Lr=a("div"),F(GL.$$.fragment),vto=l(),Sne=a("p"),Fto=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Tto=l(),ka=a("p"),Mto=o("The tokenizer class to instantiate is selected based on the "),Rne=a("code"),Eto=o("model_type"),Cto=o(` property of the config object (either
passed as an argument or loaded from `),Pne=a("code"),wto=o("pretrained_model_name_or_path"),Ato=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bne=a("code"),Lto=o("pretrained_model_name_or_path"),yto=o(":"),xto=l(),k=a("ul"),qn=a("li"),Ine=a("strong"),$to=o("albert"),kto=o(" \u2014 "),_P=a("a"),Sto=o("AlbertTokenizer"),Rto=o(" or "),uP=a("a"),Pto=o("AlbertTokenizerFast"),Bto=o(" (ALBERT model)"),Ito=l(),jn=a("li"),Nne=a("strong"),Nto=o("bart"),qto=o(" \u2014 "),bP=a("a"),jto=o("BartTokenizer"),Dto=o(" or "),vP=a("a"),Gto=o("BartTokenizerFast"),Oto=o(" (BART model)"),Vto=l(),Dn=a("li"),qne=a("strong"),Xto=o("barthez"),zto=o(" \u2014 "),FP=a("a"),Qto=o("BarthezTokenizer"),Wto=o(" or "),TP=a("a"),Hto=o("BarthezTokenizerFast"),Uto=o(" (BARThez model)"),Jto=l(),Xg=a("li"),jne=a("strong"),Yto=o("bartpho"),Kto=o(" \u2014 "),MP=a("a"),Zto=o("BartphoTokenizer"),eao=o(" (BARTpho model)"),oao=l(),Gn=a("li"),Dne=a("strong"),rao=o("bert"),tao=o(" \u2014 "),EP=a("a"),aao=o("BertTokenizer"),nao=o(" or "),CP=a("a"),sao=o("BertTokenizerFast"),lao=o(" (BERT model)"),iao=l(),zg=a("li"),Gne=a("strong"),dao=o("bert-generation"),cao=o(" \u2014 "),wP=a("a"),fao=o("BertGenerationTokenizer"),mao=o(" (Bert Generation model)"),gao=l(),Qg=a("li"),One=a("strong"),hao=o("bert-japanese"),pao=o(" \u2014 "),AP=a("a"),_ao=o("BertJapaneseTokenizer"),uao=o(" (BertJapanese model)"),bao=l(),Wg=a("li"),Vne=a("strong"),vao=o("bertweet"),Fao=o(" \u2014 "),LP=a("a"),Tao=o("BertweetTokenizer"),Mao=o(" (BERTweet model)"),Eao=l(),On=a("li"),Xne=a("strong"),Cao=o("big_bird"),wao=o(" \u2014 "),yP=a("a"),Aao=o("BigBirdTokenizer"),Lao=o(" or "),xP=a("a"),yao=o("BigBirdTokenizerFast"),xao=o(" (BigBird model)"),$ao=l(),Vn=a("li"),zne=a("strong"),kao=o("bigbird_pegasus"),Sao=o(" \u2014 "),$P=a("a"),Rao=o("PegasusTokenizer"),Pao=o(" or "),kP=a("a"),Bao=o("PegasusTokenizerFast"),Iao=o(" (BigBird-Pegasus model)"),Nao=l(),Xn=a("li"),Qne=a("strong"),qao=o("blenderbot"),jao=o(" \u2014 "),SP=a("a"),Dao=o("BlenderbotTokenizer"),Gao=o(" or "),RP=a("a"),Oao=o("BlenderbotTokenizerFast"),Vao=o(" (Blenderbot model)"),Xao=l(),Hg=a("li"),Wne=a("strong"),zao=o("blenderbot-small"),Qao=o(" \u2014 "),PP=a("a"),Wao=o("BlenderbotSmallTokenizer"),Hao=o(" (BlenderbotSmall model)"),Uao=l(),Ug=a("li"),Hne=a("strong"),Jao=o("bloom"),Yao=o(" \u2014 "),BP=a("a"),Kao=o("BloomTokenizerFast"),Zao=o(" (BLOOM model)"),eno=l(),Jg=a("li"),Une=a("strong"),ono=o("byt5"),rno=o(" \u2014 "),IP=a("a"),tno=o("ByT5Tokenizer"),ano=o(" (ByT5 model)"),nno=l(),zn=a("li"),Jne=a("strong"),sno=o("camembert"),lno=o(" \u2014 "),NP=a("a"),ino=o("CamembertTokenizer"),dno=o(" or "),qP=a("a"),cno=o("CamembertTokenizerFast"),fno=o(" (CamemBERT model)"),mno=l(),Yg=a("li"),Yne=a("strong"),gno=o("canine"),hno=o(" \u2014 "),jP=a("a"),pno=o("CanineTokenizer"),_no=o(" (CANINE model)"),uno=l(),Qn=a("li"),Kne=a("strong"),bno=o("clip"),vno=o(" \u2014 "),DP=a("a"),Fno=o("CLIPTokenizer"),Tno=o(" or "),GP=a("a"),Mno=o("CLIPTokenizerFast"),Eno=o(" (CLIP model)"),Cno=l(),Wn=a("li"),Zne=a("strong"),wno=o("convbert"),Ano=o(" \u2014 "),OP=a("a"),Lno=o("ConvBertTokenizer"),yno=o(" or "),VP=a("a"),xno=o("ConvBertTokenizerFast"),$no=o(" (ConvBERT model)"),kno=l(),Hn=a("li"),ese=a("strong"),Sno=o("cpm"),Rno=o(" \u2014 "),XP=a("a"),Pno=o("CpmTokenizer"),Bno=o(" or "),zP=a("a"),Ino=o("CpmTokenizerFast"),Nno=o(" (CPM model)"),qno=l(),Kg=a("li"),ose=a("strong"),jno=o("ctrl"),Dno=o(" \u2014 "),QP=a("a"),Gno=o("CTRLTokenizer"),Ono=o(" (CTRL model)"),Vno=l(),Un=a("li"),rse=a("strong"),Xno=o("data2vec-text"),zno=o(" \u2014 "),WP=a("a"),Qno=o("RobertaTokenizer"),Wno=o(" or "),HP=a("a"),Hno=o("RobertaTokenizerFast"),Uno=o(" (Data2VecText model)"),Jno=l(),Jn=a("li"),tse=a("strong"),Yno=o("deberta"),Kno=o(" \u2014 "),UP=a("a"),Zno=o("DebertaTokenizer"),eso=o(" or "),JP=a("a"),oso=o("DebertaTokenizerFast"),rso=o(" (DeBERTa model)"),tso=l(),Yn=a("li"),ase=a("strong"),aso=o("deberta-v2"),nso=o(" \u2014 "),YP=a("a"),sso=o("DebertaV2Tokenizer"),lso=o(" or "),KP=a("a"),iso=o("DebertaV2TokenizerFast"),dso=o(" (DeBERTa-v2 model)"),cso=l(),Kn=a("li"),nse=a("strong"),fso=o("distilbert"),mso=o(" \u2014 "),ZP=a("a"),gso=o("DistilBertTokenizer"),hso=o(" or "),eB=a("a"),pso=o("DistilBertTokenizerFast"),_so=o(" (DistilBERT model)"),uso=l(),Zn=a("li"),sse=a("strong"),bso=o("dpr"),vso=o(" \u2014 "),oB=a("a"),Fso=o("DPRQuestionEncoderTokenizer"),Tso=o(" or "),rB=a("a"),Mso=o("DPRQuestionEncoderTokenizerFast"),Eso=o(" (DPR model)"),Cso=l(),es=a("li"),lse=a("strong"),wso=o("electra"),Aso=o(" \u2014 "),tB=a("a"),Lso=o("ElectraTokenizer"),yso=o(" or "),aB=a("a"),xso=o("ElectraTokenizerFast"),$so=o(" (ELECTRA model)"),kso=l(),Zg=a("li"),ise=a("strong"),Sso=o("flaubert"),Rso=o(" \u2014 "),nB=a("a"),Pso=o("FlaubertTokenizer"),Bso=o(" (FlauBERT model)"),Iso=l(),os=a("li"),dse=a("strong"),Nso=o("fnet"),qso=o(" \u2014 "),sB=a("a"),jso=o("FNetTokenizer"),Dso=o(" or "),lB=a("a"),Gso=o("FNetTokenizerFast"),Oso=o(" (FNet model)"),Vso=l(),eh=a("li"),cse=a("strong"),Xso=o("fsmt"),zso=o(" \u2014 "),iB=a("a"),Qso=o("FSMTTokenizer"),Wso=o(" (FairSeq Machine-Translation model)"),Hso=l(),rs=a("li"),fse=a("strong"),Uso=o("funnel"),Jso=o(" \u2014 "),dB=a("a"),Yso=o("FunnelTokenizer"),Kso=o(" or "),cB=a("a"),Zso=o("FunnelTokenizerFast"),elo=o(" (Funnel Transformer model)"),olo=l(),ts=a("li"),mse=a("strong"),rlo=o("gpt2"),tlo=o(" \u2014 "),fB=a("a"),alo=o("GPT2Tokenizer"),nlo=o(" or "),mB=a("a"),slo=o("GPT2TokenizerFast"),llo=o(" (OpenAI GPT-2 model)"),ilo=l(),as=a("li"),gse=a("strong"),dlo=o("gpt_neo"),clo=o(" \u2014 "),gB=a("a"),flo=o("GPT2Tokenizer"),mlo=o(" or "),hB=a("a"),glo=o("GPT2TokenizerFast"),hlo=o(" (GPT Neo model)"),plo=l(),oh=a("li"),hse=a("strong"),_lo=o("gpt_neox"),ulo=o(" \u2014 "),pB=a("a"),blo=o("GPTNeoXTokenizerFast"),vlo=o(" (GPT NeoX model)"),Flo=l(),ns=a("li"),pse=a("strong"),Tlo=o("gptj"),Mlo=o(" \u2014 "),_B=a("a"),Elo=o("GPT2Tokenizer"),Clo=o(" or "),uB=a("a"),wlo=o("GPT2TokenizerFast"),Alo=o(" (GPT-J model)"),Llo=l(),ss=a("li"),_se=a("strong"),ylo=o("herbert"),xlo=o(" \u2014 "),bB=a("a"),$lo=o("HerbertTokenizer"),klo=o(" or "),vB=a("a"),Slo=o("HerbertTokenizerFast"),Rlo=o(" (HerBERT model)"),Plo=l(),rh=a("li"),use=a("strong"),Blo=o("hubert"),Ilo=o(" \u2014 "),FB=a("a"),Nlo=o("Wav2Vec2CTCTokenizer"),qlo=o(" (Hubert model)"),jlo=l(),ls=a("li"),bse=a("strong"),Dlo=o("ibert"),Glo=o(" \u2014 "),TB=a("a"),Olo=o("RobertaTokenizer"),Vlo=o(" or "),MB=a("a"),Xlo=o("RobertaTokenizerFast"),zlo=o(" (I-BERT model)"),Qlo=l(),is=a("li"),vse=a("strong"),Wlo=o("layoutlm"),Hlo=o(" \u2014 "),EB=a("a"),Ulo=o("LayoutLMTokenizer"),Jlo=o(" or "),CB=a("a"),Ylo=o("LayoutLMTokenizerFast"),Klo=o(" (LayoutLM model)"),Zlo=l(),ds=a("li"),Fse=a("strong"),eio=o("layoutlmv2"),oio=o(" \u2014 "),wB=a("a"),rio=o("LayoutLMv2Tokenizer"),tio=o(" or "),AB=a("a"),aio=o("LayoutLMv2TokenizerFast"),nio=o(" (LayoutLMv2 model)"),sio=l(),cs=a("li"),Tse=a("strong"),lio=o("layoutlmv3"),iio=o(" \u2014 "),LB=a("a"),dio=o("LayoutLMv3Tokenizer"),cio=o(" or "),yB=a("a"),fio=o("LayoutLMv3TokenizerFast"),mio=o(" (LayoutLMv3 model)"),gio=l(),fs=a("li"),Mse=a("strong"),hio=o("layoutxlm"),pio=o(" \u2014 "),xB=a("a"),_io=o("LayoutXLMTokenizer"),uio=o(" or "),$B=a("a"),bio=o("LayoutXLMTokenizerFast"),vio=o(" (LayoutXLM model)"),Fio=l(),ms=a("li"),Ese=a("strong"),Tio=o("led"),Mio=o(" \u2014 "),kB=a("a"),Eio=o("LEDTokenizer"),Cio=o(" or "),SB=a("a"),wio=o("LEDTokenizerFast"),Aio=o(" (LED model)"),Lio=l(),gs=a("li"),Cse=a("strong"),yio=o("longformer"),xio=o(" \u2014 "),RB=a("a"),$io=o("LongformerTokenizer"),kio=o(" or "),PB=a("a"),Sio=o("LongformerTokenizerFast"),Rio=o(" (Longformer model)"),Pio=l(),hs=a("li"),wse=a("strong"),Bio=o("longt5"),Iio=o(" \u2014 "),BB=a("a"),Nio=o("T5Tokenizer"),qio=o(" or "),IB=a("a"),jio=o("T5TokenizerFast"),Dio=o(" (LongT5 model)"),Gio=l(),th=a("li"),Ase=a("strong"),Oio=o("luke"),Vio=o(" \u2014 "),NB=a("a"),Xio=o("LukeTokenizer"),zio=o(" (LUKE model)"),Qio=l(),ps=a("li"),Lse=a("strong"),Wio=o("lxmert"),Hio=o(" \u2014 "),qB=a("a"),Uio=o("LxmertTokenizer"),Jio=o(" or "),jB=a("a"),Yio=o("LxmertTokenizerFast"),Kio=o(" (LXMERT model)"),Zio=l(),ah=a("li"),yse=a("strong"),edo=o("m2m_100"),odo=o(" \u2014 "),DB=a("a"),rdo=o("M2M100Tokenizer"),tdo=o(" (M2M100 model)"),ado=l(),nh=a("li"),xse=a("strong"),ndo=o("marian"),sdo=o(" \u2014 "),GB=a("a"),ldo=o("MarianTokenizer"),ido=o(" (Marian model)"),ddo=l(),_s=a("li"),$se=a("strong"),cdo=o("mbart"),fdo=o(" \u2014 "),OB=a("a"),mdo=o("MBartTokenizer"),gdo=o(" or "),VB=a("a"),hdo=o("MBartTokenizerFast"),pdo=o(" (mBART model)"),_do=l(),us=a("li"),kse=a("strong"),udo=o("mbart50"),bdo=o(" \u2014 "),XB=a("a"),vdo=o("MBart50Tokenizer"),Fdo=o(" or "),zB=a("a"),Tdo=o("MBart50TokenizerFast"),Mdo=o(" (mBART-50 model)"),Edo=l(),bs=a("li"),Sse=a("strong"),Cdo=o("megatron-bert"),wdo=o(" \u2014 "),QB=a("a"),Ado=o("BertTokenizer"),Ldo=o(" or "),WB=a("a"),ydo=o("BertTokenizerFast"),xdo=o(" (Megatron-BERT model)"),$do=l(),sh=a("li"),Rse=a("strong"),kdo=o("mluke"),Sdo=o(" \u2014 "),HB=a("a"),Rdo=o("MLukeTokenizer"),Pdo=o(" (mLUKE model)"),Bdo=l(),vs=a("li"),Pse=a("strong"),Ido=o("mobilebert"),Ndo=o(" \u2014 "),UB=a("a"),qdo=o("MobileBertTokenizer"),jdo=o(" or "),JB=a("a"),Ddo=o("MobileBertTokenizerFast"),Gdo=o(" (MobileBERT model)"),Odo=l(),Fs=a("li"),Bse=a("strong"),Vdo=o("mpnet"),Xdo=o(" \u2014 "),YB=a("a"),zdo=o("MPNetTokenizer"),Qdo=o(" or "),KB=a("a"),Wdo=o("MPNetTokenizerFast"),Hdo=o(" (MPNet model)"),Udo=l(),Ts=a("li"),Ise=a("strong"),Jdo=o("mt5"),Ydo=o(" \u2014 "),ZB=a("a"),Kdo=o("MT5Tokenizer"),Zdo=o(" or "),eI=a("a"),eco=o("MT5TokenizerFast"),oco=o(" (MT5 model)"),rco=l(),Ms=a("li"),Nse=a("strong"),tco=o("nezha"),aco=o(" \u2014 "),oI=a("a"),nco=o("BertTokenizer"),sco=o(" or "),rI=a("a"),lco=o("BertTokenizerFast"),ico=o(" (Nezha model)"),dco=l(),Es=a("li"),qse=a("strong"),cco=o("nystromformer"),fco=o(" \u2014 "),tI=a("a"),mco=o("AlbertTokenizer"),gco=o(" or "),aI=a("a"),hco=o("AlbertTokenizerFast"),pco=o(" (Nystr\xF6mformer model)"),_co=l(),Cs=a("li"),jse=a("strong"),uco=o("openai-gpt"),bco=o(" \u2014 "),nI=a("a"),vco=o("OpenAIGPTTokenizer"),Fco=o(" or "),sI=a("a"),Tco=o("OpenAIGPTTokenizerFast"),Mco=o(" (OpenAI GPT model)"),Eco=l(),lh=a("li"),Dse=a("strong"),Cco=o("opt"),wco=o(" \u2014 "),lI=a("a"),Aco=o("GPT2Tokenizer"),Lco=o(" (OPT model)"),yco=l(),ws=a("li"),Gse=a("strong"),xco=o("pegasus"),$co=o(" \u2014 "),iI=a("a"),kco=o("PegasusTokenizer"),Sco=o(" or "),dI=a("a"),Rco=o("PegasusTokenizerFast"),Pco=o(" (Pegasus model)"),Bco=l(),ih=a("li"),Ose=a("strong"),Ico=o("perceiver"),Nco=o(" \u2014 "),cI=a("a"),qco=o("PerceiverTokenizer"),jco=o(" (Perceiver model)"),Dco=l(),dh=a("li"),Vse=a("strong"),Gco=o("phobert"),Oco=o(" \u2014 "),fI=a("a"),Vco=o("PhobertTokenizer"),Xco=o(" (PhoBERT model)"),zco=l(),ch=a("li"),Xse=a("strong"),Qco=o("plbart"),Wco=o(" \u2014 "),mI=a("a"),Hco=o("PLBartTokenizer"),Uco=o(" (PLBart model)"),Jco=l(),fh=a("li"),zse=a("strong"),Yco=o("prophetnet"),Kco=o(" \u2014 "),gI=a("a"),Zco=o("ProphetNetTokenizer"),efo=o(" (ProphetNet model)"),ofo=l(),As=a("li"),Qse=a("strong"),rfo=o("qdqbert"),tfo=o(" \u2014 "),hI=a("a"),afo=o("BertTokenizer"),nfo=o(" or "),pI=a("a"),sfo=o("BertTokenizerFast"),lfo=o(" (QDQBert model)"),ifo=l(),mh=a("li"),Wse=a("strong"),dfo=o("rag"),cfo=o(" \u2014 "),_I=a("a"),ffo=o("RagTokenizer"),mfo=o(" (RAG model)"),gfo=l(),Ls=a("li"),Hse=a("strong"),hfo=o("realm"),pfo=o(" \u2014 "),uI=a("a"),_fo=o("RealmTokenizer"),ufo=o(" or "),bI=a("a"),bfo=o("RealmTokenizerFast"),vfo=o(" (REALM model)"),Ffo=l(),ys=a("li"),Use=a("strong"),Tfo=o("reformer"),Mfo=o(" \u2014 "),vI=a("a"),Efo=o("ReformerTokenizer"),Cfo=o(" or "),FI=a("a"),wfo=o("ReformerTokenizerFast"),Afo=o(" (Reformer model)"),Lfo=l(),xs=a("li"),Jse=a("strong"),yfo=o("rembert"),xfo=o(" \u2014 "),TI=a("a"),$fo=o("RemBertTokenizer"),kfo=o(" or "),MI=a("a"),Sfo=o("RemBertTokenizerFast"),Rfo=o(" (RemBERT model)"),Pfo=l(),$s=a("li"),Yse=a("strong"),Bfo=o("retribert"),Ifo=o(" \u2014 "),EI=a("a"),Nfo=o("RetriBertTokenizer"),qfo=o(" or "),CI=a("a"),jfo=o("RetriBertTokenizerFast"),Dfo=o(" (RetriBERT model)"),Gfo=l(),ks=a("li"),Kse=a("strong"),Ofo=o("roberta"),Vfo=o(" \u2014 "),wI=a("a"),Xfo=o("RobertaTokenizer"),zfo=o(" or "),AI=a("a"),Qfo=o("RobertaTokenizerFast"),Wfo=o(" (RoBERTa model)"),Hfo=l(),Ss=a("li"),Zse=a("strong"),Ufo=o("roformer"),Jfo=o(" \u2014 "),LI=a("a"),Yfo=o("RoFormerTokenizer"),Kfo=o(" or "),yI=a("a"),Zfo=o("RoFormerTokenizerFast"),emo=o(" (RoFormer model)"),omo=l(),gh=a("li"),ele=a("strong"),rmo=o("speech_to_text"),tmo=o(" \u2014 "),xI=a("a"),amo=o("Speech2TextTokenizer"),nmo=o(" (Speech2Text model)"),smo=l(),hh=a("li"),ole=a("strong"),lmo=o("speech_to_text_2"),imo=o(" \u2014 "),$I=a("a"),dmo=o("Speech2Text2Tokenizer"),cmo=o(" (Speech2Text2 model)"),fmo=l(),Rs=a("li"),rle=a("strong"),mmo=o("splinter"),gmo=o(" \u2014 "),kI=a("a"),hmo=o("SplinterTokenizer"),pmo=o(" or "),SI=a("a"),_mo=o("SplinterTokenizerFast"),umo=o(" (Splinter model)"),bmo=l(),Ps=a("li"),tle=a("strong"),vmo=o("squeezebert"),Fmo=o(" \u2014 "),RI=a("a"),Tmo=o("SqueezeBertTokenizer"),Mmo=o(" or "),PI=a("a"),Emo=o("SqueezeBertTokenizerFast"),Cmo=o(" (SqueezeBERT model)"),wmo=l(),Bs=a("li"),ale=a("strong"),Amo=o("t5"),Lmo=o(" \u2014 "),BI=a("a"),ymo=o("T5Tokenizer"),xmo=o(" or "),II=a("a"),$mo=o("T5TokenizerFast"),kmo=o(" (T5 model)"),Smo=l(),ph=a("li"),nle=a("strong"),Rmo=o("tapas"),Pmo=o(" \u2014 "),NI=a("a"),Bmo=o("TapasTokenizer"),Imo=o(" (TAPAS model)"),Nmo=l(),_h=a("li"),sle=a("strong"),qmo=o("tapex"),jmo=o(" \u2014 "),qI=a("a"),Dmo=o("TapexTokenizer"),Gmo=o(" (TAPEX model)"),Omo=l(),uh=a("li"),lle=a("strong"),Vmo=o("transfo-xl"),Xmo=o(" \u2014 "),jI=a("a"),zmo=o("TransfoXLTokenizer"),Qmo=o(" (Transformer-XL model)"),Wmo=l(),Is=a("li"),ile=a("strong"),Hmo=o("vilt"),Umo=o(" \u2014 "),DI=a("a"),Jmo=o("BertTokenizer"),Ymo=o(" or "),GI=a("a"),Kmo=o("BertTokenizerFast"),Zmo=o(" (ViLT model)"),ego=l(),Ns=a("li"),dle=a("strong"),ogo=o("visual_bert"),rgo=o(" \u2014 "),OI=a("a"),tgo=o("BertTokenizer"),ago=o(" or "),VI=a("a"),ngo=o("BertTokenizerFast"),sgo=o(" (VisualBERT model)"),lgo=l(),bh=a("li"),cle=a("strong"),igo=o("wav2vec2"),dgo=o(" \u2014 "),XI=a("a"),cgo=o("Wav2Vec2CTCTokenizer"),fgo=o(" (Wav2Vec2 model)"),mgo=l(),vh=a("li"),fle=a("strong"),ggo=o("wav2vec2-conformer"),hgo=o(" \u2014 "),zI=a("a"),pgo=o("Wav2Vec2CTCTokenizer"),_go=o(" (Wav2Vec2-Conformer model)"),ugo=l(),Fh=a("li"),mle=a("strong"),bgo=o("wav2vec2_phoneme"),vgo=o(" \u2014 "),QI=a("a"),Fgo=o("Wav2Vec2PhonemeCTCTokenizer"),Tgo=o(" (Wav2Vec2Phoneme model)"),Mgo=l(),qs=a("li"),gle=a("strong"),Ego=o("xglm"),Cgo=o(" \u2014 "),WI=a("a"),wgo=o("XGLMTokenizer"),Ago=o(" or "),HI=a("a"),Lgo=o("XGLMTokenizerFast"),ygo=o(" (XGLM model)"),xgo=l(),Th=a("li"),hle=a("strong"),$go=o("xlm"),kgo=o(" \u2014 "),UI=a("a"),Sgo=o("XLMTokenizer"),Rgo=o(" (XLM model)"),Pgo=l(),Mh=a("li"),ple=a("strong"),Bgo=o("xlm-prophetnet"),Igo=o(" \u2014 "),JI=a("a"),Ngo=o("XLMProphetNetTokenizer"),qgo=o(" (XLM-ProphetNet model)"),jgo=l(),js=a("li"),_le=a("strong"),Dgo=o("xlm-roberta"),Ggo=o(" \u2014 "),YI=a("a"),Ogo=o("XLMRobertaTokenizer"),Vgo=o(" or "),KI=a("a"),Xgo=o("XLMRobertaTokenizerFast"),zgo=o(" (XLM-RoBERTa model)"),Qgo=l(),Ds=a("li"),ule=a("strong"),Wgo=o("xlm-roberta-xl"),Hgo=o(" \u2014 "),ZI=a("a"),Ugo=o("RobertaTokenizer"),Jgo=o(" or "),eN=a("a"),Ygo=o("RobertaTokenizerFast"),Kgo=o(" (XLM-RoBERTa-XL model)"),Zgo=l(),Gs=a("li"),ble=a("strong"),eho=o("xlnet"),oho=o(" \u2014 "),oN=a("a"),rho=o("XLNetTokenizer"),tho=o(" or "),rN=a("a"),aho=o("XLNetTokenizerFast"),nho=o(" (XLNet model)"),sho=l(),Os=a("li"),vle=a("strong"),lho=o("yoso"),iho=o(" \u2014 "),tN=a("a"),dho=o("AlbertTokenizer"),cho=o(" or "),aN=a("a"),fho=o("AlbertTokenizerFast"),mho=o(" (YOSO model)"),gho=l(),F(Eh.$$.fragment),hho=l(),Ch=a("div"),F(OL.$$.fragment),pho=l(),Fle=a("p"),_ho=o("Register a new tokenizer in this mapping."),HGe=l(),Si=a("h2"),wh=a("a"),Tle=a("span"),F(VL.$$.fragment),uho=l(),Mle=a("span"),bho=o("AutoFeatureExtractor"),UGe=l(),Lo=a("div"),F(XL.$$.fragment),vho=l(),zL=a("p"),Fho=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),nN=a("a"),Tho=o("AutoFeatureExtractor.from_pretrained()"),Mho=o(" class method."),Eho=l(),QL=a("p"),Cho=o("This class cannot be instantiated directly using "),Ele=a("code"),who=o("__init__()"),Aho=o(" (throws an error)."),Lho=l(),He=a("div"),F(WL.$$.fragment),yho=l(),Cle=a("p"),xho=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),$ho=l(),Sa=a("p"),kho=o("The feature extractor class to instantiate is selected based on the "),wle=a("code"),Sho=o("model_type"),Rho=o(` property of the config object
(either passed as an argument or loaded from `),Ale=a("code"),Pho=o("pretrained_model_name_or_path"),Bho=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Lle=a("code"),Iho=o("pretrained_model_name_or_path"),Nho=o(":"),qho=l(),Y=a("ul"),Ah=a("li"),yle=a("strong"),jho=o("beit"),Dho=o(" \u2014 "),sN=a("a"),Gho=o("BeitFeatureExtractor"),Oho=o(" (BEiT model)"),Vho=l(),Lh=a("li"),xle=a("strong"),Xho=o("clip"),zho=o(" \u2014 "),lN=a("a"),Qho=o("CLIPFeatureExtractor"),Who=o(" (CLIP model)"),Hho=l(),yh=a("li"),$le=a("strong"),Uho=o("convnext"),Jho=o(" \u2014 "),iN=a("a"),Yho=o("ConvNextFeatureExtractor"),Kho=o(" (ConvNeXT model)"),Zho=l(),xh=a("li"),kle=a("strong"),epo=o("cvt"),opo=o(" \u2014 "),dN=a("a"),rpo=o("ConvNextFeatureExtractor"),tpo=o(" (CvT model)"),apo=l(),$h=a("li"),Sle=a("strong"),npo=o("data2vec-audio"),spo=o(" \u2014 "),cN=a("a"),lpo=o("Wav2Vec2FeatureExtractor"),ipo=o(" (Data2VecAudio model)"),dpo=l(),kh=a("li"),Rle=a("strong"),cpo=o("data2vec-vision"),fpo=o(" \u2014 "),fN=a("a"),mpo=o("BeitFeatureExtractor"),gpo=o(" (Data2VecVision model)"),hpo=l(),Sh=a("li"),Ple=a("strong"),ppo=o("deit"),_po=o(" \u2014 "),mN=a("a"),upo=o("DeiTFeatureExtractor"),bpo=o(" (DeiT model)"),vpo=l(),Rh=a("li"),Ble=a("strong"),Fpo=o("detr"),Tpo=o(" \u2014 "),gN=a("a"),Mpo=o("DetrFeatureExtractor"),Epo=o(" (DETR model)"),Cpo=l(),Ph=a("li"),Ile=a("strong"),wpo=o("dpt"),Apo=o(" \u2014 "),hN=a("a"),Lpo=o("DPTFeatureExtractor"),ypo=o(" (DPT model)"),xpo=l(),Bh=a("li"),Nle=a("strong"),$po=o("flava"),kpo=o(" \u2014 "),pN=a("a"),Spo=o("FlavaFeatureExtractor"),Rpo=o(" (FLAVA model)"),Ppo=l(),Ih=a("li"),qle=a("strong"),Bpo=o("glpn"),Ipo=o(" \u2014 "),_N=a("a"),Npo=o("GLPNFeatureExtractor"),qpo=o(" (GLPN model)"),jpo=l(),Nh=a("li"),jle=a("strong"),Dpo=o("hubert"),Gpo=o(" \u2014 "),uN=a("a"),Opo=o("Wav2Vec2FeatureExtractor"),Vpo=o(" (Hubert model)"),Xpo=l(),qh=a("li"),Dle=a("strong"),zpo=o("imagegpt"),Qpo=o(" \u2014 "),bN=a("a"),Wpo=o("ImageGPTFeatureExtractor"),Hpo=o(" (ImageGPT model)"),Upo=l(),jh=a("li"),Gle=a("strong"),Jpo=o("layoutlmv2"),Ypo=o(" \u2014 "),vN=a("a"),Kpo=o("LayoutLMv2FeatureExtractor"),Zpo=o(" (LayoutLMv2 model)"),e_o=l(),Dh=a("li"),Ole=a("strong"),o_o=o("layoutlmv3"),r_o=o(" \u2014 "),FN=a("a"),t_o=o("LayoutLMv3FeatureExtractor"),a_o=o(" (LayoutLMv3 model)"),n_o=l(),Gh=a("li"),Vle=a("strong"),s_o=o("levit"),l_o=o(" \u2014 "),TN=a("a"),i_o=o("LevitFeatureExtractor"),d_o=o(" (LeViT model)"),c_o=l(),Oh=a("li"),Xle=a("strong"),f_o=o("maskformer"),m_o=o(" \u2014 "),MN=a("a"),g_o=o("MaskFormerFeatureExtractor"),h_o=o(" (MaskFormer model)"),p_o=l(),Vh=a("li"),zle=a("strong"),__o=o("mctct"),u_o=o(" \u2014 "),EN=a("a"),b_o=o("MCTCTFeatureExtractor"),v_o=o(" (M-CTC-T model)"),F_o=l(),Xh=a("li"),Qle=a("strong"),T_o=o("perceiver"),M_o=o(" \u2014 "),CN=a("a"),E_o=o("PerceiverFeatureExtractor"),C_o=o(" (Perceiver model)"),w_o=l(),zh=a("li"),Wle=a("strong"),A_o=o("poolformer"),L_o=o(" \u2014 "),wN=a("a"),y_o=o("PoolFormerFeatureExtractor"),x_o=o(" (PoolFormer model)"),$_o=l(),Qh=a("li"),Hle=a("strong"),k_o=o("regnet"),S_o=o(" \u2014 "),AN=a("a"),R_o=o("ConvNextFeatureExtractor"),P_o=o(" (RegNet model)"),B_o=l(),Wh=a("li"),Ule=a("strong"),I_o=o("resnet"),N_o=o(" \u2014 "),LN=a("a"),q_o=o("ConvNextFeatureExtractor"),j_o=o(" (ResNet model)"),D_o=l(),Hh=a("li"),Jle=a("strong"),G_o=o("segformer"),O_o=o(" \u2014 "),yN=a("a"),V_o=o("SegformerFeatureExtractor"),X_o=o(" (SegFormer model)"),z_o=l(),Uh=a("li"),Yle=a("strong"),Q_o=o("speech_to_text"),W_o=o(" \u2014 "),xN=a("a"),H_o=o("Speech2TextFeatureExtractor"),U_o=o(" (Speech2Text model)"),J_o=l(),Jh=a("li"),Kle=a("strong"),Y_o=o("swin"),K_o=o(" \u2014 "),$N=a("a"),Z_o=o("ViTFeatureExtractor"),euo=o(" (Swin Transformer model)"),ouo=l(),Yh=a("li"),Zle=a("strong"),ruo=o("van"),tuo=o(" \u2014 "),kN=a("a"),auo=o("ConvNextFeatureExtractor"),nuo=o(" (VAN model)"),suo=l(),Kh=a("li"),eie=a("strong"),luo=o("vilt"),iuo=o(" \u2014 "),SN=a("a"),duo=o("ViltFeatureExtractor"),cuo=o(" (ViLT model)"),fuo=l(),Zh=a("li"),oie=a("strong"),muo=o("vit"),guo=o(" \u2014 "),RN=a("a"),huo=o("ViTFeatureExtractor"),puo=o(" (ViT model)"),_uo=l(),ep=a("li"),rie=a("strong"),uuo=o("vit_mae"),buo=o(" \u2014 "),PN=a("a"),vuo=o("ViTFeatureExtractor"),Fuo=o(" (ViTMAE model)"),Tuo=l(),op=a("li"),tie=a("strong"),Muo=o("wav2vec2"),Euo=o(" \u2014 "),BN=a("a"),Cuo=o("Wav2Vec2FeatureExtractor"),wuo=o(" (Wav2Vec2 model)"),Auo=l(),rp=a("li"),aie=a("strong"),Luo=o("wav2vec2-conformer"),yuo=o(" \u2014 "),IN=a("a"),xuo=o("Wav2Vec2FeatureExtractor"),$uo=o(" (Wav2Vec2-Conformer model)"),kuo=l(),tp=a("li"),nie=a("strong"),Suo=o("yolos"),Ruo=o(" \u2014 "),NN=a("a"),Puo=o("YolosFeatureExtractor"),Buo=o(" (YOLOS model)"),Iuo=l(),F(ap.$$.fragment),Nuo=l(),F(np.$$.fragment),quo=l(),sp=a("div"),F(HL.$$.fragment),juo=l(),sie=a("p"),Duo=o("Register a new feature extractor for this class."),JGe=l(),Ri=a("h2"),lp=a("a"),lie=a("span"),F(UL.$$.fragment),Guo=l(),iie=a("span"),Ouo=o("AutoProcessor"),YGe=l(),yo=a("div"),F(JL.$$.fragment),Vuo=l(),YL=a("p"),Xuo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),qN=a("a"),zuo=o("AutoProcessor.from_pretrained()"),Quo=o(" class method."),Wuo=l(),KL=a("p"),Huo=o("This class cannot be instantiated directly using "),die=a("code"),Uuo=o("__init__()"),Juo=o(" (throws an error)."),Yuo=l(),Ue=a("div"),F(ZL.$$.fragment),Kuo=l(),cie=a("p"),Zuo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),e1o=l(),Pi=a("p"),o1o=o("The processor class to instantiate is selected based on the "),fie=a("code"),r1o=o("model_type"),t1o=o(` property of the config object (either
passed as an argument or loaded from `),mie=a("code"),a1o=o("pretrained_model_name_or_path"),n1o=o(" if possible):"),s1o=l(),he=a("ul"),ip=a("li"),gie=a("strong"),l1o=o("clip"),i1o=o(" \u2014 "),jN=a("a"),d1o=o("CLIPProcessor"),c1o=o(" (CLIP model)"),f1o=l(),dp=a("li"),hie=a("strong"),m1o=o("flava"),g1o=o(" \u2014 "),pie=a("code"),h1o=o("FLAVAProcessor"),p1o=o(" (FLAVA model)"),_1o=l(),cp=a("li"),_ie=a("strong"),u1o=o("layoutlmv2"),b1o=o(" \u2014 "),DN=a("a"),v1o=o("LayoutLMv2Processor"),F1o=o(" (LayoutLMv2 model)"),T1o=l(),fp=a("li"),uie=a("strong"),M1o=o("layoutlmv3"),E1o=o(" \u2014 "),GN=a("a"),C1o=o("LayoutLMv3Processor"),w1o=o(" (LayoutLMv3 model)"),A1o=l(),mp=a("li"),bie=a("strong"),L1o=o("layoutxlm"),y1o=o(" \u2014 "),ON=a("a"),x1o=o("LayoutXLMProcessor"),$1o=o(" (LayoutXLM model)"),k1o=l(),gp=a("li"),vie=a("strong"),S1o=o("sew"),R1o=o(" \u2014 "),VN=a("a"),P1o=o("Wav2Vec2Processor"),B1o=o(" (SEW model)"),I1o=l(),hp=a("li"),Fie=a("strong"),N1o=o("sew-d"),q1o=o(" \u2014 "),XN=a("a"),j1o=o("Wav2Vec2Processor"),D1o=o(" (SEW-D model)"),G1o=l(),pp=a("li"),Tie=a("strong"),O1o=o("speech_to_text"),V1o=o(" \u2014 "),zN=a("a"),X1o=o("Speech2TextProcessor"),z1o=o(" (Speech2Text model)"),Q1o=l(),_p=a("li"),Mie=a("strong"),W1o=o("speech_to_text_2"),H1o=o(" \u2014 "),QN=a("a"),U1o=o("Speech2Text2Processor"),J1o=o(" (Speech2Text2 model)"),Y1o=l(),up=a("li"),Eie=a("strong"),K1o=o("trocr"),Z1o=o(" \u2014 "),WN=a("a"),e7o=o("TrOCRProcessor"),o7o=o(" (TrOCR model)"),r7o=l(),bp=a("li"),Cie=a("strong"),t7o=o("unispeech"),a7o=o(" \u2014 "),HN=a("a"),n7o=o("Wav2Vec2Processor"),s7o=o(" (UniSpeech model)"),l7o=l(),vp=a("li"),wie=a("strong"),i7o=o("unispeech-sat"),d7o=o(" \u2014 "),UN=a("a"),c7o=o("Wav2Vec2Processor"),f7o=o(" (UniSpeechSat model)"),m7o=l(),Fp=a("li"),Aie=a("strong"),g7o=o("vilt"),h7o=o(" \u2014 "),JN=a("a"),p7o=o("ViltProcessor"),_7o=o(" (ViLT model)"),u7o=l(),Tp=a("li"),Lie=a("strong"),b7o=o("vision-text-dual-encoder"),v7o=o(" \u2014 "),YN=a("a"),F7o=o("VisionTextDualEncoderProcessor"),T7o=o(" (VisionTextDualEncoder model)"),M7o=l(),Mp=a("li"),yie=a("strong"),E7o=o("wav2vec2"),C7o=o(" \u2014 "),KN=a("a"),w7o=o("Wav2Vec2Processor"),A7o=o(" (Wav2Vec2 model)"),L7o=l(),Ep=a("li"),xie=a("strong"),y7o=o("wav2vec2-conformer"),x7o=o(" \u2014 "),ZN=a("a"),$7o=o("Wav2Vec2Processor"),k7o=o(" (Wav2Vec2-Conformer model)"),S7o=l(),Cp=a("li"),$ie=a("strong"),R7o=o("wavlm"),P7o=o(" \u2014 "),eq=a("a"),B7o=o("Wav2Vec2Processor"),I7o=o(" (WavLM model)"),N7o=l(),F(wp.$$.fragment),q7o=l(),F(Ap.$$.fragment),j7o=l(),Lp=a("div"),F(ey.$$.fragment),D7o=l(),kie=a("p"),G7o=o("Register a new processor for this class."),KGe=l(),Bi=a("h2"),yp=a("a"),Sie=a("span"),F(oy.$$.fragment),O7o=l(),Rie=a("span"),V7o=o("AutoModel"),ZGe=l(),xo=a("div"),F(ry.$$.fragment),X7o=l(),Ii=a("p"),z7o=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),oq=a("a"),Q7o=o("from_pretrained()"),W7o=o(" class method or the "),rq=a("a"),H7o=o("from_config()"),U7o=o(` class
method.`),J7o=l(),ty=a("p"),Y7o=o("This class cannot be instantiated directly using "),Pie=a("code"),K7o=o("__init__()"),Z7o=o(" (throws an error)."),e2o=l(),nt=a("div"),F(ay.$$.fragment),o2o=l(),Bie=a("p"),r2o=o("Instantiates one of the base model classes of the library from a configuration."),t2o=l(),Ni=a("p"),a2o=o(`Note:
Loading a model from its configuration file does `),Iie=a("strong"),n2o=o("not"),s2o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tq=a("a"),l2o=o("from_pretrained()"),i2o=o(" to load the model weights."),d2o=l(),F(xp.$$.fragment),c2o=l(),Je=a("div"),F(ny.$$.fragment),f2o=l(),Nie=a("p"),m2o=o("Instantiate one of the base model classes of the library from a pretrained model."),g2o=l(),Ra=a("p"),h2o=o("The model class to instantiate is selected based on the "),qie=a("code"),p2o=o("model_type"),_2o=o(` property of the config object (either
passed as an argument or loaded from `),jie=a("code"),u2o=o("pretrained_model_name_or_path"),b2o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Die=a("code"),v2o=o("pretrained_model_name_or_path"),F2o=o(":"),T2o=l(),y=a("ul"),$p=a("li"),Gie=a("strong"),M2o=o("albert"),E2o=o(" \u2014 "),aq=a("a"),C2o=o("AlbertModel"),w2o=o(" (ALBERT model)"),A2o=l(),kp=a("li"),Oie=a("strong"),L2o=o("bart"),y2o=o(" \u2014 "),nq=a("a"),x2o=o("BartModel"),$2o=o(" (BART model)"),k2o=l(),Sp=a("li"),Vie=a("strong"),S2o=o("beit"),R2o=o(" \u2014 "),sq=a("a"),P2o=o("BeitModel"),B2o=o(" (BEiT model)"),I2o=l(),Rp=a("li"),Xie=a("strong"),N2o=o("bert"),q2o=o(" \u2014 "),lq=a("a"),j2o=o("BertModel"),D2o=o(" (BERT model)"),G2o=l(),Pp=a("li"),zie=a("strong"),O2o=o("bert-generation"),V2o=o(" \u2014 "),iq=a("a"),X2o=o("BertGenerationEncoder"),z2o=o(" (Bert Generation model)"),Q2o=l(),Bp=a("li"),Qie=a("strong"),W2o=o("big_bird"),H2o=o(" \u2014 "),dq=a("a"),U2o=o("BigBirdModel"),J2o=o(" (BigBird model)"),Y2o=l(),Ip=a("li"),Wie=a("strong"),K2o=o("bigbird_pegasus"),Z2o=o(" \u2014 "),cq=a("a"),ebo=o("BigBirdPegasusModel"),obo=o(" (BigBird-Pegasus model)"),rbo=l(),Np=a("li"),Hie=a("strong"),tbo=o("blenderbot"),abo=o(" \u2014 "),fq=a("a"),nbo=o("BlenderbotModel"),sbo=o(" (Blenderbot model)"),lbo=l(),qp=a("li"),Uie=a("strong"),ibo=o("blenderbot-small"),dbo=o(" \u2014 "),mq=a("a"),cbo=o("BlenderbotSmallModel"),fbo=o(" (BlenderbotSmall model)"),mbo=l(),jp=a("li"),Jie=a("strong"),gbo=o("bloom"),hbo=o(" \u2014 "),gq=a("a"),pbo=o("BloomModel"),_bo=o(" (BLOOM model)"),ubo=l(),Dp=a("li"),Yie=a("strong"),bbo=o("camembert"),vbo=o(" \u2014 "),hq=a("a"),Fbo=o("CamembertModel"),Tbo=o(" (CamemBERT model)"),Mbo=l(),Gp=a("li"),Kie=a("strong"),Ebo=o("canine"),Cbo=o(" \u2014 "),pq=a("a"),wbo=o("CanineModel"),Abo=o(" (CANINE model)"),Lbo=l(),Op=a("li"),Zie=a("strong"),ybo=o("clip"),xbo=o(" \u2014 "),_q=a("a"),$bo=o("CLIPModel"),kbo=o(" (CLIP model)"),Sbo=l(),Vp=a("li"),ede=a("strong"),Rbo=o("convbert"),Pbo=o(" \u2014 "),uq=a("a"),Bbo=o("ConvBertModel"),Ibo=o(" (ConvBERT model)"),Nbo=l(),Xp=a("li"),ode=a("strong"),qbo=o("convnext"),jbo=o(" \u2014 "),bq=a("a"),Dbo=o("ConvNextModel"),Gbo=o(" (ConvNeXT model)"),Obo=l(),zp=a("li"),rde=a("strong"),Vbo=o("ctrl"),Xbo=o(" \u2014 "),vq=a("a"),zbo=o("CTRLModel"),Qbo=o(" (CTRL model)"),Wbo=l(),Qp=a("li"),tde=a("strong"),Hbo=o("cvt"),Ubo=o(" \u2014 "),Fq=a("a"),Jbo=o("CvtModel"),Ybo=o(" (CvT model)"),Kbo=l(),Wp=a("li"),ade=a("strong"),Zbo=o("data2vec-audio"),e5o=o(" \u2014 "),Tq=a("a"),o5o=o("Data2VecAudioModel"),r5o=o(" (Data2VecAudio model)"),t5o=l(),Hp=a("li"),nde=a("strong"),a5o=o("data2vec-text"),n5o=o(" \u2014 "),Mq=a("a"),s5o=o("Data2VecTextModel"),l5o=o(" (Data2VecText model)"),i5o=l(),Up=a("li"),sde=a("strong"),d5o=o("data2vec-vision"),c5o=o(" \u2014 "),Eq=a("a"),f5o=o("Data2VecVisionModel"),m5o=o(" (Data2VecVision model)"),g5o=l(),Jp=a("li"),lde=a("strong"),h5o=o("deberta"),p5o=o(" \u2014 "),Cq=a("a"),_5o=o("DebertaModel"),u5o=o(" (DeBERTa model)"),b5o=l(),Yp=a("li"),ide=a("strong"),v5o=o("deberta-v2"),F5o=o(" \u2014 "),wq=a("a"),T5o=o("DebertaV2Model"),M5o=o(" (DeBERTa-v2 model)"),E5o=l(),Kp=a("li"),dde=a("strong"),C5o=o("decision_transformer"),w5o=o(" \u2014 "),Aq=a("a"),A5o=o("DecisionTransformerModel"),L5o=o(" (Decision Transformer model)"),y5o=l(),Zp=a("li"),cde=a("strong"),x5o=o("deit"),$5o=o(" \u2014 "),Lq=a("a"),k5o=o("DeiTModel"),S5o=o(" (DeiT model)"),R5o=l(),e_=a("li"),fde=a("strong"),P5o=o("detr"),B5o=o(" \u2014 "),yq=a("a"),I5o=o("DetrModel"),N5o=o(" (DETR model)"),q5o=l(),o_=a("li"),mde=a("strong"),j5o=o("distilbert"),D5o=o(" \u2014 "),xq=a("a"),G5o=o("DistilBertModel"),O5o=o(" (DistilBERT model)"),V5o=l(),r_=a("li"),gde=a("strong"),X5o=o("dpr"),z5o=o(" \u2014 "),$q=a("a"),Q5o=o("DPRQuestionEncoder"),W5o=o(" (DPR model)"),H5o=l(),t_=a("li"),hde=a("strong"),U5o=o("dpt"),J5o=o(" \u2014 "),kq=a("a"),Y5o=o("DPTModel"),K5o=o(" (DPT model)"),Z5o=l(),a_=a("li"),pde=a("strong"),evo=o("electra"),ovo=o(" \u2014 "),Sq=a("a"),rvo=o("ElectraModel"),tvo=o(" (ELECTRA model)"),avo=l(),n_=a("li"),_de=a("strong"),nvo=o("flaubert"),svo=o(" \u2014 "),Rq=a("a"),lvo=o("FlaubertModel"),ivo=o(" (FlauBERT model)"),dvo=l(),s_=a("li"),ude=a("strong"),cvo=o("flava"),fvo=o(" \u2014 "),Pq=a("a"),mvo=o("FlavaModel"),gvo=o(" (FLAVA model)"),hvo=l(),l_=a("li"),bde=a("strong"),pvo=o("fnet"),_vo=o(" \u2014 "),Bq=a("a"),uvo=o("FNetModel"),bvo=o(" (FNet model)"),vvo=l(),i_=a("li"),vde=a("strong"),Fvo=o("fsmt"),Tvo=o(" \u2014 "),Iq=a("a"),Mvo=o("FSMTModel"),Evo=o(" (FairSeq Machine-Translation model)"),Cvo=l(),Vs=a("li"),Fde=a("strong"),wvo=o("funnel"),Avo=o(" \u2014 "),Nq=a("a"),Lvo=o("FunnelModel"),yvo=o(" or "),qq=a("a"),xvo=o("FunnelBaseModel"),$vo=o(" (Funnel Transformer model)"),kvo=l(),d_=a("li"),Tde=a("strong"),Svo=o("glpn"),Rvo=o(" \u2014 "),jq=a("a"),Pvo=o("GLPNModel"),Bvo=o(" (GLPN model)"),Ivo=l(),c_=a("li"),Mde=a("strong"),Nvo=o("gpt2"),qvo=o(" \u2014 "),Dq=a("a"),jvo=o("GPT2Model"),Dvo=o(" (OpenAI GPT-2 model)"),Gvo=l(),f_=a("li"),Ede=a("strong"),Ovo=o("gpt_neo"),Vvo=o(" \u2014 "),Gq=a("a"),Xvo=o("GPTNeoModel"),zvo=o(" (GPT Neo model)"),Qvo=l(),m_=a("li"),Cde=a("strong"),Wvo=o("gpt_neox"),Hvo=o(" \u2014 "),Oq=a("a"),Uvo=o("GPTNeoXModel"),Jvo=o(" (GPT NeoX model)"),Yvo=l(),g_=a("li"),wde=a("strong"),Kvo=o("gptj"),Zvo=o(" \u2014 "),Vq=a("a"),e3o=o("GPTJModel"),o3o=o(" (GPT-J model)"),r3o=l(),h_=a("li"),Ade=a("strong"),t3o=o("hubert"),a3o=o(" \u2014 "),Xq=a("a"),n3o=o("HubertModel"),s3o=o(" (Hubert model)"),l3o=l(),p_=a("li"),Lde=a("strong"),i3o=o("ibert"),d3o=o(" \u2014 "),zq=a("a"),c3o=o("IBertModel"),f3o=o(" (I-BERT model)"),m3o=l(),__=a("li"),yde=a("strong"),g3o=o("imagegpt"),h3o=o(" \u2014 "),Qq=a("a"),p3o=o("ImageGPTModel"),_3o=o(" (ImageGPT model)"),u3o=l(),u_=a("li"),xde=a("strong"),b3o=o("layoutlm"),v3o=o(" \u2014 "),Wq=a("a"),F3o=o("LayoutLMModel"),T3o=o(" (LayoutLM model)"),M3o=l(),b_=a("li"),$de=a("strong"),E3o=o("layoutlmv2"),C3o=o(" \u2014 "),Hq=a("a"),w3o=o("LayoutLMv2Model"),A3o=o(" (LayoutLMv2 model)"),L3o=l(),v_=a("li"),kde=a("strong"),y3o=o("layoutlmv3"),x3o=o(" \u2014 "),Uq=a("a"),$3o=o("LayoutLMv3Model"),k3o=o(" (LayoutLMv3 model)"),S3o=l(),F_=a("li"),Sde=a("strong"),R3o=o("led"),P3o=o(" \u2014 "),Jq=a("a"),B3o=o("LEDModel"),I3o=o(" (LED model)"),N3o=l(),T_=a("li"),Rde=a("strong"),q3o=o("levit"),j3o=o(" \u2014 "),Yq=a("a"),D3o=o("LevitModel"),G3o=o(" (LeViT model)"),O3o=l(),M_=a("li"),Pde=a("strong"),V3o=o("longformer"),X3o=o(" \u2014 "),Kq=a("a"),z3o=o("LongformerModel"),Q3o=o(" (Longformer model)"),W3o=l(),E_=a("li"),Bde=a("strong"),H3o=o("longt5"),U3o=o(" \u2014 "),Zq=a("a"),J3o=o("LongT5Model"),Y3o=o(" (LongT5 model)"),K3o=l(),C_=a("li"),Ide=a("strong"),Z3o=o("luke"),eFo=o(" \u2014 "),ej=a("a"),oFo=o("LukeModel"),rFo=o(" (LUKE model)"),tFo=l(),w_=a("li"),Nde=a("strong"),aFo=o("lxmert"),nFo=o(" \u2014 "),oj=a("a"),sFo=o("LxmertModel"),lFo=o(" (LXMERT model)"),iFo=l(),A_=a("li"),qde=a("strong"),dFo=o("m2m_100"),cFo=o(" \u2014 "),rj=a("a"),fFo=o("M2M100Model"),mFo=o(" (M2M100 model)"),gFo=l(),L_=a("li"),jde=a("strong"),hFo=o("marian"),pFo=o(" \u2014 "),tj=a("a"),_Fo=o("MarianModel"),uFo=o(" (Marian model)"),bFo=l(),y_=a("li"),Dde=a("strong"),vFo=o("maskformer"),FFo=o(" \u2014 "),aj=a("a"),TFo=o("MaskFormerModel"),MFo=o(" (MaskFormer model)"),EFo=l(),x_=a("li"),Gde=a("strong"),CFo=o("mbart"),wFo=o(" \u2014 "),nj=a("a"),AFo=o("MBartModel"),LFo=o(" (mBART model)"),yFo=l(),$_=a("li"),Ode=a("strong"),xFo=o("mctct"),$Fo=o(" \u2014 "),sj=a("a"),kFo=o("MCTCTModel"),SFo=o(" (M-CTC-T model)"),RFo=l(),k_=a("li"),Vde=a("strong"),PFo=o("megatron-bert"),BFo=o(" \u2014 "),lj=a("a"),IFo=o("MegatronBertModel"),NFo=o(" (Megatron-BERT model)"),qFo=l(),S_=a("li"),Xde=a("strong"),jFo=o("mobilebert"),DFo=o(" \u2014 "),ij=a("a"),GFo=o("MobileBertModel"),OFo=o(" (MobileBERT model)"),VFo=l(),R_=a("li"),zde=a("strong"),XFo=o("mpnet"),zFo=o(" \u2014 "),dj=a("a"),QFo=o("MPNetModel"),WFo=o(" (MPNet model)"),HFo=l(),P_=a("li"),Qde=a("strong"),UFo=o("mt5"),JFo=o(" \u2014 "),cj=a("a"),YFo=o("MT5Model"),KFo=o(" (MT5 model)"),ZFo=l(),B_=a("li"),Wde=a("strong"),eTo=o("nezha"),oTo=o(" \u2014 "),fj=a("a"),rTo=o("NezhaModel"),tTo=o(" (Nezha model)"),aTo=l(),I_=a("li"),Hde=a("strong"),nTo=o("nystromformer"),sTo=o(" \u2014 "),mj=a("a"),lTo=o("NystromformerModel"),iTo=o(" (Nystr\xF6mformer model)"),dTo=l(),N_=a("li"),Ude=a("strong"),cTo=o("openai-gpt"),fTo=o(" \u2014 "),gj=a("a"),mTo=o("OpenAIGPTModel"),gTo=o(" (OpenAI GPT model)"),hTo=l(),q_=a("li"),Jde=a("strong"),pTo=o("opt"),_To=o(" \u2014 "),hj=a("a"),uTo=o("OPTModel"),bTo=o(" (OPT model)"),vTo=l(),j_=a("li"),Yde=a("strong"),FTo=o("pegasus"),TTo=o(" \u2014 "),pj=a("a"),MTo=o("PegasusModel"),ETo=o(" (Pegasus model)"),CTo=l(),D_=a("li"),Kde=a("strong"),wTo=o("perceiver"),ATo=o(" \u2014 "),_j=a("a"),LTo=o("PerceiverModel"),yTo=o(" (Perceiver model)"),xTo=l(),G_=a("li"),Zde=a("strong"),$To=o("plbart"),kTo=o(" \u2014 "),uj=a("a"),STo=o("PLBartModel"),RTo=o(" (PLBart model)"),PTo=l(),O_=a("li"),ece=a("strong"),BTo=o("poolformer"),ITo=o(" \u2014 "),bj=a("a"),NTo=o("PoolFormerModel"),qTo=o(" (PoolFormer model)"),jTo=l(),V_=a("li"),oce=a("strong"),DTo=o("prophetnet"),GTo=o(" \u2014 "),vj=a("a"),OTo=o("ProphetNetModel"),VTo=o(" (ProphetNet model)"),XTo=l(),X_=a("li"),rce=a("strong"),zTo=o("qdqbert"),QTo=o(" \u2014 "),Fj=a("a"),WTo=o("QDQBertModel"),HTo=o(" (QDQBert model)"),UTo=l(),z_=a("li"),tce=a("strong"),JTo=o("reformer"),YTo=o(" \u2014 "),Tj=a("a"),KTo=o("ReformerModel"),ZTo=o(" (Reformer model)"),eMo=l(),Q_=a("li"),ace=a("strong"),oMo=o("regnet"),rMo=o(" \u2014 "),Mj=a("a"),tMo=o("RegNetModel"),aMo=o(" (RegNet model)"),nMo=l(),W_=a("li"),nce=a("strong"),sMo=o("rembert"),lMo=o(" \u2014 "),Ej=a("a"),iMo=o("RemBertModel"),dMo=o(" (RemBERT model)"),cMo=l(),H_=a("li"),sce=a("strong"),fMo=o("resnet"),mMo=o(" \u2014 "),Cj=a("a"),gMo=o("ResNetModel"),hMo=o(" (ResNet model)"),pMo=l(),U_=a("li"),lce=a("strong"),_Mo=o("retribert"),uMo=o(" \u2014 "),wj=a("a"),bMo=o("RetriBertModel"),vMo=o(" (RetriBERT model)"),FMo=l(),J_=a("li"),ice=a("strong"),TMo=o("roberta"),MMo=o(" \u2014 "),Aj=a("a"),EMo=o("RobertaModel"),CMo=o(" (RoBERTa model)"),wMo=l(),Y_=a("li"),dce=a("strong"),AMo=o("roformer"),LMo=o(" \u2014 "),Lj=a("a"),yMo=o("RoFormerModel"),xMo=o(" (RoFormer model)"),$Mo=l(),K_=a("li"),cce=a("strong"),kMo=o("segformer"),SMo=o(" \u2014 "),yj=a("a"),RMo=o("SegformerModel"),PMo=o(" (SegFormer model)"),BMo=l(),Z_=a("li"),fce=a("strong"),IMo=o("sew"),NMo=o(" \u2014 "),xj=a("a"),qMo=o("SEWModel"),jMo=o(" (SEW model)"),DMo=l(),eu=a("li"),mce=a("strong"),GMo=o("sew-d"),OMo=o(" \u2014 "),$j=a("a"),VMo=o("SEWDModel"),XMo=o(" (SEW-D model)"),zMo=l(),ou=a("li"),gce=a("strong"),QMo=o("speech_to_text"),WMo=o(" \u2014 "),kj=a("a"),HMo=o("Speech2TextModel"),UMo=o(" (Speech2Text model)"),JMo=l(),ru=a("li"),hce=a("strong"),YMo=o("splinter"),KMo=o(" \u2014 "),Sj=a("a"),ZMo=o("SplinterModel"),eEo=o(" (Splinter model)"),oEo=l(),tu=a("li"),pce=a("strong"),rEo=o("squeezebert"),tEo=o(" \u2014 "),Rj=a("a"),aEo=o("SqueezeBertModel"),nEo=o(" (SqueezeBERT model)"),sEo=l(),au=a("li"),_ce=a("strong"),lEo=o("swin"),iEo=o(" \u2014 "),Pj=a("a"),dEo=o("SwinModel"),cEo=o(" (Swin Transformer model)"),fEo=l(),nu=a("li"),uce=a("strong"),mEo=o("t5"),gEo=o(" \u2014 "),Bj=a("a"),hEo=o("T5Model"),pEo=o(" (T5 model)"),_Eo=l(),su=a("li"),bce=a("strong"),uEo=o("tapas"),bEo=o(" \u2014 "),Ij=a("a"),vEo=o("TapasModel"),FEo=o(" (TAPAS model)"),TEo=l(),lu=a("li"),vce=a("strong"),MEo=o("trajectory_transformer"),EEo=o(" \u2014 "),Nj=a("a"),CEo=o("TrajectoryTransformerModel"),wEo=o(" (Trajectory Transformer model)"),AEo=l(),iu=a("li"),Fce=a("strong"),LEo=o("transfo-xl"),yEo=o(" \u2014 "),qj=a("a"),xEo=o("TransfoXLModel"),$Eo=o(" (Transformer-XL model)"),kEo=l(),du=a("li"),Tce=a("strong"),SEo=o("unispeech"),REo=o(" \u2014 "),jj=a("a"),PEo=o("UniSpeechModel"),BEo=o(" (UniSpeech model)"),IEo=l(),cu=a("li"),Mce=a("strong"),NEo=o("unispeech-sat"),qEo=o(" \u2014 "),Dj=a("a"),jEo=o("UniSpeechSatModel"),DEo=o(" (UniSpeechSat model)"),GEo=l(),fu=a("li"),Ece=a("strong"),OEo=o("van"),VEo=o(" \u2014 "),Gj=a("a"),XEo=o("VanModel"),zEo=o(" (VAN model)"),QEo=l(),mu=a("li"),Cce=a("strong"),WEo=o("vilt"),HEo=o(" \u2014 "),Oj=a("a"),UEo=o("ViltModel"),JEo=o(" (ViLT model)"),YEo=l(),gu=a("li"),wce=a("strong"),KEo=o("vision-text-dual-encoder"),ZEo=o(" \u2014 "),Vj=a("a"),e4o=o("VisionTextDualEncoderModel"),o4o=o(" (VisionTextDualEncoder model)"),r4o=l(),hu=a("li"),Ace=a("strong"),t4o=o("visual_bert"),a4o=o(" \u2014 "),Xj=a("a"),n4o=o("VisualBertModel"),s4o=o(" (VisualBERT model)"),l4o=l(),pu=a("li"),Lce=a("strong"),i4o=o("vit"),d4o=o(" \u2014 "),zj=a("a"),c4o=o("ViTModel"),f4o=o(" (ViT model)"),m4o=l(),_u=a("li"),yce=a("strong"),g4o=o("vit_mae"),h4o=o(" \u2014 "),Qj=a("a"),p4o=o("ViTMAEModel"),_4o=o(" (ViTMAE model)"),u4o=l(),uu=a("li"),xce=a("strong"),b4o=o("wav2vec2"),v4o=o(" \u2014 "),Wj=a("a"),F4o=o("Wav2Vec2Model"),T4o=o(" (Wav2Vec2 model)"),M4o=l(),bu=a("li"),$ce=a("strong"),E4o=o("wav2vec2-conformer"),C4o=o(" \u2014 "),Hj=a("a"),w4o=o("Wav2Vec2ConformerModel"),A4o=o(" (Wav2Vec2-Conformer model)"),L4o=l(),vu=a("li"),kce=a("strong"),y4o=o("wavlm"),x4o=o(" \u2014 "),Uj=a("a"),$4o=o("WavLMModel"),k4o=o(" (WavLM model)"),S4o=l(),Fu=a("li"),Sce=a("strong"),R4o=o("xglm"),P4o=o(" \u2014 "),Jj=a("a"),B4o=o("XGLMModel"),I4o=o(" (XGLM model)"),N4o=l(),Tu=a("li"),Rce=a("strong"),q4o=o("xlm"),j4o=o(" \u2014 "),Yj=a("a"),D4o=o("XLMModel"),G4o=o(" (XLM model)"),O4o=l(),Mu=a("li"),Pce=a("strong"),V4o=o("xlm-prophetnet"),X4o=o(" \u2014 "),Kj=a("a"),z4o=o("XLMProphetNetModel"),Q4o=o(" (XLM-ProphetNet model)"),W4o=l(),Eu=a("li"),Bce=a("strong"),H4o=o("xlm-roberta"),U4o=o(" \u2014 "),Zj=a("a"),J4o=o("XLMRobertaModel"),Y4o=o(" (XLM-RoBERTa model)"),K4o=l(),Cu=a("li"),Ice=a("strong"),Z4o=o("xlm-roberta-xl"),eCo=o(" \u2014 "),eD=a("a"),oCo=o("XLMRobertaXLModel"),rCo=o(" (XLM-RoBERTa-XL model)"),tCo=l(),wu=a("li"),Nce=a("strong"),aCo=o("xlnet"),nCo=o(" \u2014 "),oD=a("a"),sCo=o("XLNetModel"),lCo=o(" (XLNet model)"),iCo=l(),Au=a("li"),qce=a("strong"),dCo=o("yolos"),cCo=o(" \u2014 "),rD=a("a"),fCo=o("YolosModel"),mCo=o(" (YOLOS model)"),gCo=l(),Lu=a("li"),jce=a("strong"),hCo=o("yoso"),pCo=o(" \u2014 "),tD=a("a"),_Co=o("YosoModel"),uCo=o(" (YOSO model)"),bCo=l(),yu=a("p"),vCo=o("The model is set in evaluation mode by default using "),Dce=a("code"),FCo=o("model.eval()"),TCo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gce=a("code"),MCo=o("model.train()"),ECo=l(),F(xu.$$.fragment),eOe=l(),qi=a("h2"),$u=a("a"),Oce=a("span"),F(sy.$$.fragment),CCo=l(),Vce=a("span"),wCo=o("AutoModelForPreTraining"),oOe=l(),$o=a("div"),F(ly.$$.fragment),ACo=l(),ji=a("p"),LCo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),aD=a("a"),yCo=o("from_pretrained()"),xCo=o(" class method or the "),nD=a("a"),$Co=o("from_config()"),kCo=o(` class
method.`),SCo=l(),iy=a("p"),RCo=o("This class cannot be instantiated directly using "),Xce=a("code"),PCo=o("__init__()"),BCo=o(" (throws an error)."),ICo=l(),st=a("div"),F(dy.$$.fragment),NCo=l(),zce=a("p"),qCo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),jCo=l(),Di=a("p"),DCo=o(`Note:
Loading a model from its configuration file does `),Qce=a("strong"),GCo=o("not"),OCo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sD=a("a"),VCo=o("from_pretrained()"),XCo=o(" to load the model weights."),zCo=l(),F(ku.$$.fragment),QCo=l(),Ye=a("div"),F(cy.$$.fragment),WCo=l(),Wce=a("p"),HCo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),UCo=l(),Pa=a("p"),JCo=o("The model class to instantiate is selected based on the "),Hce=a("code"),YCo=o("model_type"),KCo=o(` property of the config object (either
passed as an argument or loaded from `),Uce=a("code"),ZCo=o("pretrained_model_name_or_path"),e0o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jce=a("code"),o0o=o("pretrained_model_name_or_path"),r0o=o(":"),t0o=l(),G=a("ul"),Su=a("li"),Yce=a("strong"),a0o=o("albert"),n0o=o(" \u2014 "),lD=a("a"),s0o=o("AlbertForPreTraining"),l0o=o(" (ALBERT model)"),i0o=l(),Ru=a("li"),Kce=a("strong"),d0o=o("bart"),c0o=o(" \u2014 "),iD=a("a"),f0o=o("BartForConditionalGeneration"),m0o=o(" (BART model)"),g0o=l(),Pu=a("li"),Zce=a("strong"),h0o=o("bert"),p0o=o(" \u2014 "),dD=a("a"),_0o=o("BertForPreTraining"),u0o=o(" (BERT model)"),b0o=l(),Bu=a("li"),efe=a("strong"),v0o=o("big_bird"),F0o=o(" \u2014 "),cD=a("a"),T0o=o("BigBirdForPreTraining"),M0o=o(" (BigBird model)"),E0o=l(),Iu=a("li"),ofe=a("strong"),C0o=o("bloom"),w0o=o(" \u2014 "),fD=a("a"),A0o=o("BloomForCausalLM"),L0o=o(" (BLOOM model)"),y0o=l(),Nu=a("li"),rfe=a("strong"),x0o=o("camembert"),$0o=o(" \u2014 "),mD=a("a"),k0o=o("CamembertForMaskedLM"),S0o=o(" (CamemBERT model)"),R0o=l(),qu=a("li"),tfe=a("strong"),P0o=o("ctrl"),B0o=o(" \u2014 "),gD=a("a"),I0o=o("CTRLLMHeadModel"),N0o=o(" (CTRL model)"),q0o=l(),ju=a("li"),afe=a("strong"),j0o=o("data2vec-text"),D0o=o(" \u2014 "),hD=a("a"),G0o=o("Data2VecTextForMaskedLM"),O0o=o(" (Data2VecText model)"),V0o=l(),Du=a("li"),nfe=a("strong"),X0o=o("deberta"),z0o=o(" \u2014 "),pD=a("a"),Q0o=o("DebertaForMaskedLM"),W0o=o(" (DeBERTa model)"),H0o=l(),Gu=a("li"),sfe=a("strong"),U0o=o("deberta-v2"),J0o=o(" \u2014 "),_D=a("a"),Y0o=o("DebertaV2ForMaskedLM"),K0o=o(" (DeBERTa-v2 model)"),Z0o=l(),Ou=a("li"),lfe=a("strong"),ewo=o("distilbert"),owo=o(" \u2014 "),uD=a("a"),rwo=o("DistilBertForMaskedLM"),two=o(" (DistilBERT model)"),awo=l(),Vu=a("li"),ife=a("strong"),nwo=o("electra"),swo=o(" \u2014 "),bD=a("a"),lwo=o("ElectraForPreTraining"),iwo=o(" (ELECTRA model)"),dwo=l(),Xu=a("li"),dfe=a("strong"),cwo=o("flaubert"),fwo=o(" \u2014 "),vD=a("a"),mwo=o("FlaubertWithLMHeadModel"),gwo=o(" (FlauBERT model)"),hwo=l(),zu=a("li"),cfe=a("strong"),pwo=o("flava"),_wo=o(" \u2014 "),FD=a("a"),uwo=o("FlavaForPreTraining"),bwo=o(" (FLAVA model)"),vwo=l(),Qu=a("li"),ffe=a("strong"),Fwo=o("fnet"),Two=o(" \u2014 "),TD=a("a"),Mwo=o("FNetForPreTraining"),Ewo=o(" (FNet model)"),Cwo=l(),Wu=a("li"),mfe=a("strong"),wwo=o("fsmt"),Awo=o(" \u2014 "),MD=a("a"),Lwo=o("FSMTForConditionalGeneration"),ywo=o(" (FairSeq Machine-Translation model)"),xwo=l(),Hu=a("li"),gfe=a("strong"),$wo=o("funnel"),kwo=o(" \u2014 "),ED=a("a"),Swo=o("FunnelForPreTraining"),Rwo=o(" (Funnel Transformer model)"),Pwo=l(),Uu=a("li"),hfe=a("strong"),Bwo=o("gpt2"),Iwo=o(" \u2014 "),CD=a("a"),Nwo=o("GPT2LMHeadModel"),qwo=o(" (OpenAI GPT-2 model)"),jwo=l(),Ju=a("li"),pfe=a("strong"),Dwo=o("ibert"),Gwo=o(" \u2014 "),wD=a("a"),Owo=o("IBertForMaskedLM"),Vwo=o(" (I-BERT model)"),Xwo=l(),Yu=a("li"),_fe=a("strong"),zwo=o("layoutlm"),Qwo=o(" \u2014 "),AD=a("a"),Wwo=o("LayoutLMForMaskedLM"),Hwo=o(" (LayoutLM model)"),Uwo=l(),Ku=a("li"),ufe=a("strong"),Jwo=o("longformer"),Ywo=o(" \u2014 "),LD=a("a"),Kwo=o("LongformerForMaskedLM"),Zwo=o(" (Longformer model)"),eAo=l(),Zu=a("li"),bfe=a("strong"),oAo=o("lxmert"),rAo=o(" \u2014 "),yD=a("a"),tAo=o("LxmertForPreTraining"),aAo=o(" (LXMERT model)"),nAo=l(),e1=a("li"),vfe=a("strong"),sAo=o("megatron-bert"),lAo=o(" \u2014 "),xD=a("a"),iAo=o("MegatronBertForPreTraining"),dAo=o(" (Megatron-BERT model)"),cAo=l(),o1=a("li"),Ffe=a("strong"),fAo=o("mobilebert"),mAo=o(" \u2014 "),$D=a("a"),gAo=o("MobileBertForPreTraining"),hAo=o(" (MobileBERT model)"),pAo=l(),r1=a("li"),Tfe=a("strong"),_Ao=o("mpnet"),uAo=o(" \u2014 "),kD=a("a"),bAo=o("MPNetForMaskedLM"),vAo=o(" (MPNet model)"),FAo=l(),t1=a("li"),Mfe=a("strong"),TAo=o("nezha"),MAo=o(" \u2014 "),SD=a("a"),EAo=o("NezhaForPreTraining"),CAo=o(" (Nezha model)"),wAo=l(),a1=a("li"),Efe=a("strong"),AAo=o("openai-gpt"),LAo=o(" \u2014 "),RD=a("a"),yAo=o("OpenAIGPTLMHeadModel"),xAo=o(" (OpenAI GPT model)"),$Ao=l(),n1=a("li"),Cfe=a("strong"),kAo=o("retribert"),SAo=o(" \u2014 "),PD=a("a"),RAo=o("RetriBertModel"),PAo=o(" (RetriBERT model)"),BAo=l(),s1=a("li"),wfe=a("strong"),IAo=o("roberta"),NAo=o(" \u2014 "),BD=a("a"),qAo=o("RobertaForMaskedLM"),jAo=o(" (RoBERTa model)"),DAo=l(),l1=a("li"),Afe=a("strong"),GAo=o("splinter"),OAo=o(" \u2014 "),ID=a("a"),VAo=o("SplinterForPreTraining"),XAo=o(" (Splinter model)"),zAo=l(),i1=a("li"),Lfe=a("strong"),QAo=o("squeezebert"),WAo=o(" \u2014 "),ND=a("a"),HAo=o("SqueezeBertForMaskedLM"),UAo=o(" (SqueezeBERT model)"),JAo=l(),d1=a("li"),yfe=a("strong"),YAo=o("t5"),KAo=o(" \u2014 "),qD=a("a"),ZAo=o("T5ForConditionalGeneration"),e6o=o(" (T5 model)"),o6o=l(),c1=a("li"),xfe=a("strong"),r6o=o("tapas"),t6o=o(" \u2014 "),jD=a("a"),a6o=o("TapasForMaskedLM"),n6o=o(" (TAPAS model)"),s6o=l(),f1=a("li"),$fe=a("strong"),l6o=o("transfo-xl"),i6o=o(" \u2014 "),DD=a("a"),d6o=o("TransfoXLLMHeadModel"),c6o=o(" (Transformer-XL model)"),f6o=l(),m1=a("li"),kfe=a("strong"),m6o=o("unispeech"),g6o=o(" \u2014 "),GD=a("a"),h6o=o("UniSpeechForPreTraining"),p6o=o(" (UniSpeech model)"),_6o=l(),g1=a("li"),Sfe=a("strong"),u6o=o("unispeech-sat"),b6o=o(" \u2014 "),OD=a("a"),v6o=o("UniSpeechSatForPreTraining"),F6o=o(" (UniSpeechSat model)"),T6o=l(),h1=a("li"),Rfe=a("strong"),M6o=o("visual_bert"),E6o=o(" \u2014 "),VD=a("a"),C6o=o("VisualBertForPreTraining"),w6o=o(" (VisualBERT model)"),A6o=l(),p1=a("li"),Pfe=a("strong"),L6o=o("vit_mae"),y6o=o(" \u2014 "),XD=a("a"),x6o=o("ViTMAEForPreTraining"),$6o=o(" (ViTMAE model)"),k6o=l(),_1=a("li"),Bfe=a("strong"),S6o=o("wav2vec2"),R6o=o(" \u2014 "),zD=a("a"),P6o=o("Wav2Vec2ForPreTraining"),B6o=o(" (Wav2Vec2 model)"),I6o=l(),u1=a("li"),Ife=a("strong"),N6o=o("wav2vec2-conformer"),q6o=o(" \u2014 "),QD=a("a"),j6o=o("Wav2Vec2ConformerForPreTraining"),D6o=o(" (Wav2Vec2-Conformer model)"),G6o=l(),b1=a("li"),Nfe=a("strong"),O6o=o("xlm"),V6o=o(" \u2014 "),WD=a("a"),X6o=o("XLMWithLMHeadModel"),z6o=o(" (XLM model)"),Q6o=l(),v1=a("li"),qfe=a("strong"),W6o=o("xlm-roberta"),H6o=o(" \u2014 "),HD=a("a"),U6o=o("XLMRobertaForMaskedLM"),J6o=o(" (XLM-RoBERTa model)"),Y6o=l(),F1=a("li"),jfe=a("strong"),K6o=o("xlm-roberta-xl"),Z6o=o(" \u2014 "),UD=a("a"),eLo=o("XLMRobertaXLForMaskedLM"),oLo=o(" (XLM-RoBERTa-XL model)"),rLo=l(),T1=a("li"),Dfe=a("strong"),tLo=o("xlnet"),aLo=o(" \u2014 "),JD=a("a"),nLo=o("XLNetLMHeadModel"),sLo=o(" (XLNet model)"),lLo=l(),M1=a("p"),iLo=o("The model is set in evaluation mode by default using "),Gfe=a("code"),dLo=o("model.eval()"),cLo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ofe=a("code"),fLo=o("model.train()"),mLo=l(),F(E1.$$.fragment),rOe=l(),Gi=a("h2"),C1=a("a"),Vfe=a("span"),F(fy.$$.fragment),gLo=l(),Xfe=a("span"),hLo=o("AutoModelForCausalLM"),tOe=l(),ko=a("div"),F(my.$$.fragment),pLo=l(),Oi=a("p"),_Lo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),YD=a("a"),uLo=o("from_pretrained()"),bLo=o(" class method or the "),KD=a("a"),vLo=o("from_config()"),FLo=o(` class
method.`),TLo=l(),gy=a("p"),MLo=o("This class cannot be instantiated directly using "),zfe=a("code"),ELo=o("__init__()"),CLo=o(" (throws an error)."),wLo=l(),lt=a("div"),F(hy.$$.fragment),ALo=l(),Qfe=a("p"),LLo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),yLo=l(),Vi=a("p"),xLo=o(`Note:
Loading a model from its configuration file does `),Wfe=a("strong"),$Lo=o("not"),kLo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZD=a("a"),SLo=o("from_pretrained()"),RLo=o(" to load the model weights."),PLo=l(),F(w1.$$.fragment),BLo=l(),Ke=a("div"),F(py.$$.fragment),ILo=l(),Hfe=a("p"),NLo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),qLo=l(),Ba=a("p"),jLo=o("The model class to instantiate is selected based on the "),Ufe=a("code"),DLo=o("model_type"),GLo=o(` property of the config object (either
passed as an argument or loaded from `),Jfe=a("code"),OLo=o("pretrained_model_name_or_path"),VLo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yfe=a("code"),XLo=o("pretrained_model_name_or_path"),zLo=o(":"),QLo=l(),z=a("ul"),A1=a("li"),Kfe=a("strong"),WLo=o("bart"),HLo=o(" \u2014 "),eG=a("a"),ULo=o("BartForCausalLM"),JLo=o(" (BART model)"),YLo=l(),L1=a("li"),Zfe=a("strong"),KLo=o("bert"),ZLo=o(" \u2014 "),oG=a("a"),eyo=o("BertLMHeadModel"),oyo=o(" (BERT model)"),ryo=l(),y1=a("li"),eme=a("strong"),tyo=o("bert-generation"),ayo=o(" \u2014 "),rG=a("a"),nyo=o("BertGenerationDecoder"),syo=o(" (Bert Generation model)"),lyo=l(),x1=a("li"),ome=a("strong"),iyo=o("big_bird"),dyo=o(" \u2014 "),tG=a("a"),cyo=o("BigBirdForCausalLM"),fyo=o(" (BigBird model)"),myo=l(),$1=a("li"),rme=a("strong"),gyo=o("bigbird_pegasus"),hyo=o(" \u2014 "),aG=a("a"),pyo=o("BigBirdPegasusForCausalLM"),_yo=o(" (BigBird-Pegasus model)"),uyo=l(),k1=a("li"),tme=a("strong"),byo=o("blenderbot"),vyo=o(" \u2014 "),nG=a("a"),Fyo=o("BlenderbotForCausalLM"),Tyo=o(" (Blenderbot model)"),Myo=l(),S1=a("li"),ame=a("strong"),Eyo=o("blenderbot-small"),Cyo=o(" \u2014 "),sG=a("a"),wyo=o("BlenderbotSmallForCausalLM"),Ayo=o(" (BlenderbotSmall model)"),Lyo=l(),R1=a("li"),nme=a("strong"),yyo=o("bloom"),xyo=o(" \u2014 "),lG=a("a"),$yo=o("BloomForCausalLM"),kyo=o(" (BLOOM model)"),Syo=l(),P1=a("li"),sme=a("strong"),Ryo=o("camembert"),Pyo=o(" \u2014 "),iG=a("a"),Byo=o("CamembertForCausalLM"),Iyo=o(" (CamemBERT model)"),Nyo=l(),B1=a("li"),lme=a("strong"),qyo=o("ctrl"),jyo=o(" \u2014 "),dG=a("a"),Dyo=o("CTRLLMHeadModel"),Gyo=o(" (CTRL model)"),Oyo=l(),I1=a("li"),ime=a("strong"),Vyo=o("data2vec-text"),Xyo=o(" \u2014 "),cG=a("a"),zyo=o("Data2VecTextForCausalLM"),Qyo=o(" (Data2VecText model)"),Wyo=l(),N1=a("li"),dme=a("strong"),Hyo=o("electra"),Uyo=o(" \u2014 "),fG=a("a"),Jyo=o("ElectraForCausalLM"),Yyo=o(" (ELECTRA model)"),Kyo=l(),q1=a("li"),cme=a("strong"),Zyo=o("gpt2"),e8o=o(" \u2014 "),mG=a("a"),o8o=o("GPT2LMHeadModel"),r8o=o(" (OpenAI GPT-2 model)"),t8o=l(),j1=a("li"),fme=a("strong"),a8o=o("gpt_neo"),n8o=o(" \u2014 "),gG=a("a"),s8o=o("GPTNeoForCausalLM"),l8o=o(" (GPT Neo model)"),i8o=l(),D1=a("li"),mme=a("strong"),d8o=o("gpt_neox"),c8o=o(" \u2014 "),hG=a("a"),f8o=o("GPTNeoXForCausalLM"),m8o=o(" (GPT NeoX model)"),g8o=l(),G1=a("li"),gme=a("strong"),h8o=o("gptj"),p8o=o(" \u2014 "),pG=a("a"),_8o=o("GPTJForCausalLM"),u8o=o(" (GPT-J model)"),b8o=l(),O1=a("li"),hme=a("strong"),v8o=o("marian"),F8o=o(" \u2014 "),_G=a("a"),T8o=o("MarianForCausalLM"),M8o=o(" (Marian model)"),E8o=l(),V1=a("li"),pme=a("strong"),C8o=o("mbart"),w8o=o(" \u2014 "),uG=a("a"),A8o=o("MBartForCausalLM"),L8o=o(" (mBART model)"),y8o=l(),X1=a("li"),_me=a("strong"),x8o=o("megatron-bert"),$8o=o(" \u2014 "),bG=a("a"),k8o=o("MegatronBertForCausalLM"),S8o=o(" (Megatron-BERT model)"),R8o=l(),z1=a("li"),ume=a("strong"),P8o=o("openai-gpt"),B8o=o(" \u2014 "),vG=a("a"),I8o=o("OpenAIGPTLMHeadModel"),N8o=o(" (OpenAI GPT model)"),q8o=l(),Q1=a("li"),bme=a("strong"),j8o=o("opt"),D8o=o(" \u2014 "),FG=a("a"),G8o=o("OPTForCausalLM"),O8o=o(" (OPT model)"),V8o=l(),W1=a("li"),vme=a("strong"),X8o=o("pegasus"),z8o=o(" \u2014 "),TG=a("a"),Q8o=o("PegasusForCausalLM"),W8o=o(" (Pegasus model)"),H8o=l(),H1=a("li"),Fme=a("strong"),U8o=o("plbart"),J8o=o(" \u2014 "),MG=a("a"),Y8o=o("PLBartForCausalLM"),K8o=o(" (PLBart model)"),Z8o=l(),U1=a("li"),Tme=a("strong"),e9o=o("prophetnet"),o9o=o(" \u2014 "),EG=a("a"),r9o=o("ProphetNetForCausalLM"),t9o=o(" (ProphetNet model)"),a9o=l(),J1=a("li"),Mme=a("strong"),n9o=o("qdqbert"),s9o=o(" \u2014 "),CG=a("a"),l9o=o("QDQBertLMHeadModel"),i9o=o(" (QDQBert model)"),d9o=l(),Y1=a("li"),Eme=a("strong"),c9o=o("reformer"),f9o=o(" \u2014 "),wG=a("a"),m9o=o("ReformerModelWithLMHead"),g9o=o(" (Reformer model)"),h9o=l(),K1=a("li"),Cme=a("strong"),p9o=o("rembert"),_9o=o(" \u2014 "),AG=a("a"),u9o=o("RemBertForCausalLM"),b9o=o(" (RemBERT model)"),v9o=l(),Z1=a("li"),wme=a("strong"),F9o=o("roberta"),T9o=o(" \u2014 "),LG=a("a"),M9o=o("RobertaForCausalLM"),E9o=o(" (RoBERTa model)"),C9o=l(),e7=a("li"),Ame=a("strong"),w9o=o("roformer"),A9o=o(" \u2014 "),yG=a("a"),L9o=o("RoFormerForCausalLM"),y9o=o(" (RoFormer model)"),x9o=l(),o7=a("li"),Lme=a("strong"),$9o=o("speech_to_text_2"),k9o=o(" \u2014 "),xG=a("a"),S9o=o("Speech2Text2ForCausalLM"),R9o=o(" (Speech2Text2 model)"),P9o=l(),r7=a("li"),yme=a("strong"),B9o=o("transfo-xl"),I9o=o(" \u2014 "),$G=a("a"),N9o=o("TransfoXLLMHeadModel"),q9o=o(" (Transformer-XL model)"),j9o=l(),t7=a("li"),xme=a("strong"),D9o=o("trocr"),G9o=o(" \u2014 "),kG=a("a"),O9o=o("TrOCRForCausalLM"),V9o=o(" (TrOCR model)"),X9o=l(),a7=a("li"),$me=a("strong"),z9o=o("xglm"),Q9o=o(" \u2014 "),SG=a("a"),W9o=o("XGLMForCausalLM"),H9o=o(" (XGLM model)"),U9o=l(),n7=a("li"),kme=a("strong"),J9o=o("xlm"),Y9o=o(" \u2014 "),RG=a("a"),K9o=o("XLMWithLMHeadModel"),Z9o=o(" (XLM model)"),exo=l(),s7=a("li"),Sme=a("strong"),oxo=o("xlm-prophetnet"),rxo=o(" \u2014 "),PG=a("a"),txo=o("XLMProphetNetForCausalLM"),axo=o(" (XLM-ProphetNet model)"),nxo=l(),l7=a("li"),Rme=a("strong"),sxo=o("xlm-roberta"),lxo=o(" \u2014 "),BG=a("a"),ixo=o("XLMRobertaForCausalLM"),dxo=o(" (XLM-RoBERTa model)"),cxo=l(),i7=a("li"),Pme=a("strong"),fxo=o("xlm-roberta-xl"),mxo=o(" \u2014 "),IG=a("a"),gxo=o("XLMRobertaXLForCausalLM"),hxo=o(" (XLM-RoBERTa-XL model)"),pxo=l(),d7=a("li"),Bme=a("strong"),_xo=o("xlnet"),uxo=o(" \u2014 "),NG=a("a"),bxo=o("XLNetLMHeadModel"),vxo=o(" (XLNet model)"),Fxo=l(),c7=a("p"),Txo=o("The model is set in evaluation mode by default using "),Ime=a("code"),Mxo=o("model.eval()"),Exo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nme=a("code"),Cxo=o("model.train()"),wxo=l(),F(f7.$$.fragment),aOe=l(),Xi=a("h2"),m7=a("a"),qme=a("span"),F(_y.$$.fragment),Axo=l(),jme=a("span"),Lxo=o("AutoModelForMaskedLM"),nOe=l(),So=a("div"),F(uy.$$.fragment),yxo=l(),zi=a("p"),xxo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),qG=a("a"),$xo=o("from_pretrained()"),kxo=o(" class method or the "),jG=a("a"),Sxo=o("from_config()"),Rxo=o(` class
method.`),Pxo=l(),by=a("p"),Bxo=o("This class cannot be instantiated directly using "),Dme=a("code"),Ixo=o("__init__()"),Nxo=o(" (throws an error)."),qxo=l(),it=a("div"),F(vy.$$.fragment),jxo=l(),Gme=a("p"),Dxo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Gxo=l(),Qi=a("p"),Oxo=o(`Note:
Loading a model from its configuration file does `),Ome=a("strong"),Vxo=o("not"),Xxo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DG=a("a"),zxo=o("from_pretrained()"),Qxo=o(" to load the model weights."),Wxo=l(),F(g7.$$.fragment),Hxo=l(),Ze=a("div"),F(Fy.$$.fragment),Uxo=l(),Vme=a("p"),Jxo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Yxo=l(),Ia=a("p"),Kxo=o("The model class to instantiate is selected based on the "),Xme=a("code"),Zxo=o("model_type"),e$o=o(` property of the config object (either
passed as an argument or loaded from `),zme=a("code"),o$o=o("pretrained_model_name_or_path"),r$o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qme=a("code"),t$o=o("pretrained_model_name_or_path"),a$o=o(":"),n$o=l(),Q=a("ul"),h7=a("li"),Wme=a("strong"),s$o=o("albert"),l$o=o(" \u2014 "),GG=a("a"),i$o=o("AlbertForMaskedLM"),d$o=o(" (ALBERT model)"),c$o=l(),p7=a("li"),Hme=a("strong"),f$o=o("bart"),m$o=o(" \u2014 "),OG=a("a"),g$o=o("BartForConditionalGeneration"),h$o=o(" (BART model)"),p$o=l(),_7=a("li"),Ume=a("strong"),_$o=o("bert"),u$o=o(" \u2014 "),VG=a("a"),b$o=o("BertForMaskedLM"),v$o=o(" (BERT model)"),F$o=l(),u7=a("li"),Jme=a("strong"),T$o=o("big_bird"),M$o=o(" \u2014 "),XG=a("a"),E$o=o("BigBirdForMaskedLM"),C$o=o(" (BigBird model)"),w$o=l(),b7=a("li"),Yme=a("strong"),A$o=o("camembert"),L$o=o(" \u2014 "),zG=a("a"),y$o=o("CamembertForMaskedLM"),x$o=o(" (CamemBERT model)"),$$o=l(),v7=a("li"),Kme=a("strong"),k$o=o("convbert"),S$o=o(" \u2014 "),QG=a("a"),R$o=o("ConvBertForMaskedLM"),P$o=o(" (ConvBERT model)"),B$o=l(),F7=a("li"),Zme=a("strong"),I$o=o("data2vec-text"),N$o=o(" \u2014 "),WG=a("a"),q$o=o("Data2VecTextForMaskedLM"),j$o=o(" (Data2VecText model)"),D$o=l(),T7=a("li"),ege=a("strong"),G$o=o("deberta"),O$o=o(" \u2014 "),HG=a("a"),V$o=o("DebertaForMaskedLM"),X$o=o(" (DeBERTa model)"),z$o=l(),M7=a("li"),oge=a("strong"),Q$o=o("deberta-v2"),W$o=o(" \u2014 "),UG=a("a"),H$o=o("DebertaV2ForMaskedLM"),U$o=o(" (DeBERTa-v2 model)"),J$o=l(),E7=a("li"),rge=a("strong"),Y$o=o("distilbert"),K$o=o(" \u2014 "),JG=a("a"),Z$o=o("DistilBertForMaskedLM"),eko=o(" (DistilBERT model)"),oko=l(),C7=a("li"),tge=a("strong"),rko=o("electra"),tko=o(" \u2014 "),YG=a("a"),ako=o("ElectraForMaskedLM"),nko=o(" (ELECTRA model)"),sko=l(),w7=a("li"),age=a("strong"),lko=o("flaubert"),iko=o(" \u2014 "),KG=a("a"),dko=o("FlaubertWithLMHeadModel"),cko=o(" (FlauBERT model)"),fko=l(),A7=a("li"),nge=a("strong"),mko=o("fnet"),gko=o(" \u2014 "),ZG=a("a"),hko=o("FNetForMaskedLM"),pko=o(" (FNet model)"),_ko=l(),L7=a("li"),sge=a("strong"),uko=o("funnel"),bko=o(" \u2014 "),eO=a("a"),vko=o("FunnelForMaskedLM"),Fko=o(" (Funnel Transformer model)"),Tko=l(),y7=a("li"),lge=a("strong"),Mko=o("ibert"),Eko=o(" \u2014 "),oO=a("a"),Cko=o("IBertForMaskedLM"),wko=o(" (I-BERT model)"),Ako=l(),x7=a("li"),ige=a("strong"),Lko=o("layoutlm"),yko=o(" \u2014 "),rO=a("a"),xko=o("LayoutLMForMaskedLM"),$ko=o(" (LayoutLM model)"),kko=l(),$7=a("li"),dge=a("strong"),Sko=o("longformer"),Rko=o(" \u2014 "),tO=a("a"),Pko=o("LongformerForMaskedLM"),Bko=o(" (Longformer model)"),Iko=l(),k7=a("li"),cge=a("strong"),Nko=o("luke"),qko=o(" \u2014 "),aO=a("a"),jko=o("LukeForMaskedLM"),Dko=o(" (LUKE model)"),Gko=l(),S7=a("li"),fge=a("strong"),Oko=o("mbart"),Vko=o(" \u2014 "),nO=a("a"),Xko=o("MBartForConditionalGeneration"),zko=o(" (mBART model)"),Qko=l(),R7=a("li"),mge=a("strong"),Wko=o("megatron-bert"),Hko=o(" \u2014 "),sO=a("a"),Uko=o("MegatronBertForMaskedLM"),Jko=o(" (Megatron-BERT model)"),Yko=l(),P7=a("li"),gge=a("strong"),Kko=o("mobilebert"),Zko=o(" \u2014 "),lO=a("a"),eSo=o("MobileBertForMaskedLM"),oSo=o(" (MobileBERT model)"),rSo=l(),B7=a("li"),hge=a("strong"),tSo=o("mpnet"),aSo=o(" \u2014 "),iO=a("a"),nSo=o("MPNetForMaskedLM"),sSo=o(" (MPNet model)"),lSo=l(),I7=a("li"),pge=a("strong"),iSo=o("nezha"),dSo=o(" \u2014 "),dO=a("a"),cSo=o("NezhaForMaskedLM"),fSo=o(" (Nezha model)"),mSo=l(),N7=a("li"),_ge=a("strong"),gSo=o("nystromformer"),hSo=o(" \u2014 "),cO=a("a"),pSo=o("NystromformerForMaskedLM"),_So=o(" (Nystr\xF6mformer model)"),uSo=l(),q7=a("li"),uge=a("strong"),bSo=o("perceiver"),vSo=o(" \u2014 "),fO=a("a"),FSo=o("PerceiverForMaskedLM"),TSo=o(" (Perceiver model)"),MSo=l(),j7=a("li"),bge=a("strong"),ESo=o("qdqbert"),CSo=o(" \u2014 "),mO=a("a"),wSo=o("QDQBertForMaskedLM"),ASo=o(" (QDQBert model)"),LSo=l(),D7=a("li"),vge=a("strong"),ySo=o("reformer"),xSo=o(" \u2014 "),gO=a("a"),$So=o("ReformerForMaskedLM"),kSo=o(" (Reformer model)"),SSo=l(),G7=a("li"),Fge=a("strong"),RSo=o("rembert"),PSo=o(" \u2014 "),hO=a("a"),BSo=o("RemBertForMaskedLM"),ISo=o(" (RemBERT model)"),NSo=l(),O7=a("li"),Tge=a("strong"),qSo=o("roberta"),jSo=o(" \u2014 "),pO=a("a"),DSo=o("RobertaForMaskedLM"),GSo=o(" (RoBERTa model)"),OSo=l(),V7=a("li"),Mge=a("strong"),VSo=o("roformer"),XSo=o(" \u2014 "),_O=a("a"),zSo=o("RoFormerForMaskedLM"),QSo=o(" (RoFormer model)"),WSo=l(),X7=a("li"),Ege=a("strong"),HSo=o("squeezebert"),USo=o(" \u2014 "),uO=a("a"),JSo=o("SqueezeBertForMaskedLM"),YSo=o(" (SqueezeBERT model)"),KSo=l(),z7=a("li"),Cge=a("strong"),ZSo=o("tapas"),eRo=o(" \u2014 "),bO=a("a"),oRo=o("TapasForMaskedLM"),rRo=o(" (TAPAS model)"),tRo=l(),Q7=a("li"),wge=a("strong"),aRo=o("wav2vec2"),nRo=o(" \u2014 "),Age=a("code"),sRo=o("Wav2Vec2ForMaskedLM"),lRo=o(" (Wav2Vec2 model)"),iRo=l(),W7=a("li"),Lge=a("strong"),dRo=o("xlm"),cRo=o(" \u2014 "),vO=a("a"),fRo=o("XLMWithLMHeadModel"),mRo=o(" (XLM model)"),gRo=l(),H7=a("li"),yge=a("strong"),hRo=o("xlm-roberta"),pRo=o(" \u2014 "),FO=a("a"),_Ro=o("XLMRobertaForMaskedLM"),uRo=o(" (XLM-RoBERTa model)"),bRo=l(),U7=a("li"),xge=a("strong"),vRo=o("xlm-roberta-xl"),FRo=o(" \u2014 "),TO=a("a"),TRo=o("XLMRobertaXLForMaskedLM"),MRo=o(" (XLM-RoBERTa-XL model)"),ERo=l(),J7=a("li"),$ge=a("strong"),CRo=o("yoso"),wRo=o(" \u2014 "),MO=a("a"),ARo=o("YosoForMaskedLM"),LRo=o(" (YOSO model)"),yRo=l(),Y7=a("p"),xRo=o("The model is set in evaluation mode by default using "),kge=a("code"),$Ro=o("model.eval()"),kRo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Sge=a("code"),SRo=o("model.train()"),RRo=l(),F(K7.$$.fragment),sOe=l(),Wi=a("h2"),Z7=a("a"),Rge=a("span"),F(Ty.$$.fragment),PRo=l(),Pge=a("span"),BRo=o("AutoModelForSeq2SeqLM"),lOe=l(),Ro=a("div"),F(My.$$.fragment),IRo=l(),Hi=a("p"),NRo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),EO=a("a"),qRo=o("from_pretrained()"),jRo=o(" class method or the "),CO=a("a"),DRo=o("from_config()"),GRo=o(` class
method.`),ORo=l(),Ey=a("p"),VRo=o("This class cannot be instantiated directly using "),Bge=a("code"),XRo=o("__init__()"),zRo=o(" (throws an error)."),QRo=l(),dt=a("div"),F(Cy.$$.fragment),WRo=l(),Ige=a("p"),HRo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),URo=l(),Ui=a("p"),JRo=o(`Note:
Loading a model from its configuration file does `),Nge=a("strong"),YRo=o("not"),KRo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wO=a("a"),ZRo=o("from_pretrained()"),ePo=o(" to load the model weights."),oPo=l(),F(e2.$$.fragment),rPo=l(),eo=a("div"),F(wy.$$.fragment),tPo=l(),qge=a("p"),aPo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),nPo=l(),Na=a("p"),sPo=o("The model class to instantiate is selected based on the "),jge=a("code"),lPo=o("model_type"),iPo=o(` property of the config object (either
passed as an argument or loaded from `),Dge=a("code"),dPo=o("pretrained_model_name_or_path"),cPo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gge=a("code"),fPo=o("pretrained_model_name_or_path"),mPo=o(":"),gPo=l(),pe=a("ul"),o2=a("li"),Oge=a("strong"),hPo=o("bart"),pPo=o(" \u2014 "),AO=a("a"),_Po=o("BartForConditionalGeneration"),uPo=o(" (BART model)"),bPo=l(),r2=a("li"),Vge=a("strong"),vPo=o("bigbird_pegasus"),FPo=o(" \u2014 "),LO=a("a"),TPo=o("BigBirdPegasusForConditionalGeneration"),MPo=o(" (BigBird-Pegasus model)"),EPo=l(),t2=a("li"),Xge=a("strong"),CPo=o("blenderbot"),wPo=o(" \u2014 "),yO=a("a"),APo=o("BlenderbotForConditionalGeneration"),LPo=o(" (Blenderbot model)"),yPo=l(),a2=a("li"),zge=a("strong"),xPo=o("blenderbot-small"),$Po=o(" \u2014 "),xO=a("a"),kPo=o("BlenderbotSmallForConditionalGeneration"),SPo=o(" (BlenderbotSmall model)"),RPo=l(),n2=a("li"),Qge=a("strong"),PPo=o("encoder-decoder"),BPo=o(" \u2014 "),$O=a("a"),IPo=o("EncoderDecoderModel"),NPo=o(" (Encoder decoder model)"),qPo=l(),s2=a("li"),Wge=a("strong"),jPo=o("fsmt"),DPo=o(" \u2014 "),kO=a("a"),GPo=o("FSMTForConditionalGeneration"),OPo=o(" (FairSeq Machine-Translation model)"),VPo=l(),l2=a("li"),Hge=a("strong"),XPo=o("led"),zPo=o(" \u2014 "),SO=a("a"),QPo=o("LEDForConditionalGeneration"),WPo=o(" (LED model)"),HPo=l(),i2=a("li"),Uge=a("strong"),UPo=o("longt5"),JPo=o(" \u2014 "),RO=a("a"),YPo=o("LongT5ForConditionalGeneration"),KPo=o(" (LongT5 model)"),ZPo=l(),d2=a("li"),Jge=a("strong"),eBo=o("m2m_100"),oBo=o(" \u2014 "),PO=a("a"),rBo=o("M2M100ForConditionalGeneration"),tBo=o(" (M2M100 model)"),aBo=l(),c2=a("li"),Yge=a("strong"),nBo=o("marian"),sBo=o(" \u2014 "),BO=a("a"),lBo=o("MarianMTModel"),iBo=o(" (Marian model)"),dBo=l(),f2=a("li"),Kge=a("strong"),cBo=o("mbart"),fBo=o(" \u2014 "),IO=a("a"),mBo=o("MBartForConditionalGeneration"),gBo=o(" (mBART model)"),hBo=l(),m2=a("li"),Zge=a("strong"),pBo=o("mt5"),_Bo=o(" \u2014 "),NO=a("a"),uBo=o("MT5ForConditionalGeneration"),bBo=o(" (MT5 model)"),vBo=l(),g2=a("li"),ehe=a("strong"),FBo=o("pegasus"),TBo=o(" \u2014 "),qO=a("a"),MBo=o("PegasusForConditionalGeneration"),EBo=o(" (Pegasus model)"),CBo=l(),h2=a("li"),ohe=a("strong"),wBo=o("plbart"),ABo=o(" \u2014 "),jO=a("a"),LBo=o("PLBartForConditionalGeneration"),yBo=o(" (PLBart model)"),xBo=l(),p2=a("li"),rhe=a("strong"),$Bo=o("prophetnet"),kBo=o(" \u2014 "),DO=a("a"),SBo=o("ProphetNetForConditionalGeneration"),RBo=o(" (ProphetNet model)"),PBo=l(),_2=a("li"),the=a("strong"),BBo=o("t5"),IBo=o(" \u2014 "),GO=a("a"),NBo=o("T5ForConditionalGeneration"),qBo=o(" (T5 model)"),jBo=l(),u2=a("li"),ahe=a("strong"),DBo=o("xlm-prophetnet"),GBo=o(" \u2014 "),OO=a("a"),OBo=o("XLMProphetNetForConditionalGeneration"),VBo=o(" (XLM-ProphetNet model)"),XBo=l(),b2=a("p"),zBo=o("The model is set in evaluation mode by default using "),nhe=a("code"),QBo=o("model.eval()"),WBo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),she=a("code"),HBo=o("model.train()"),UBo=l(),F(v2.$$.fragment),iOe=l(),Ji=a("h2"),F2=a("a"),lhe=a("span"),F(Ay.$$.fragment),JBo=l(),ihe=a("span"),YBo=o("AutoModelForSequenceClassification"),dOe=l(),Po=a("div"),F(Ly.$$.fragment),KBo=l(),Yi=a("p"),ZBo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),VO=a("a"),eIo=o("from_pretrained()"),oIo=o(" class method or the "),XO=a("a"),rIo=o("from_config()"),tIo=o(` class
method.`),aIo=l(),yy=a("p"),nIo=o("This class cannot be instantiated directly using "),dhe=a("code"),sIo=o("__init__()"),lIo=o(" (throws an error)."),iIo=l(),ct=a("div"),F(xy.$$.fragment),dIo=l(),che=a("p"),cIo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),fIo=l(),Ki=a("p"),mIo=o(`Note:
Loading a model from its configuration file does `),fhe=a("strong"),gIo=o("not"),hIo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zO=a("a"),pIo=o("from_pretrained()"),_Io=o(" to load the model weights."),uIo=l(),F(T2.$$.fragment),bIo=l(),oo=a("div"),F($y.$$.fragment),vIo=l(),mhe=a("p"),FIo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),TIo=l(),qa=a("p"),MIo=o("The model class to instantiate is selected based on the "),ghe=a("code"),EIo=o("model_type"),CIo=o(` property of the config object (either
passed as an argument or loaded from `),hhe=a("code"),wIo=o("pretrained_model_name_or_path"),AIo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),phe=a("code"),LIo=o("pretrained_model_name_or_path"),yIo=o(":"),xIo=l(),N=a("ul"),M2=a("li"),_he=a("strong"),$Io=o("albert"),kIo=o(" \u2014 "),QO=a("a"),SIo=o("AlbertForSequenceClassification"),RIo=o(" (ALBERT model)"),PIo=l(),E2=a("li"),uhe=a("strong"),BIo=o("bart"),IIo=o(" \u2014 "),WO=a("a"),NIo=o("BartForSequenceClassification"),qIo=o(" (BART model)"),jIo=l(),C2=a("li"),bhe=a("strong"),DIo=o("bert"),GIo=o(" \u2014 "),HO=a("a"),OIo=o("BertForSequenceClassification"),VIo=o(" (BERT model)"),XIo=l(),w2=a("li"),vhe=a("strong"),zIo=o("big_bird"),QIo=o(" \u2014 "),UO=a("a"),WIo=o("BigBirdForSequenceClassification"),HIo=o(" (BigBird model)"),UIo=l(),A2=a("li"),Fhe=a("strong"),JIo=o("bigbird_pegasus"),YIo=o(" \u2014 "),JO=a("a"),KIo=o("BigBirdPegasusForSequenceClassification"),ZIo=o(" (BigBird-Pegasus model)"),eNo=l(),L2=a("li"),The=a("strong"),oNo=o("bloom"),rNo=o(" \u2014 "),YO=a("a"),tNo=o("BloomForSequenceClassification"),aNo=o(" (BLOOM model)"),nNo=l(),y2=a("li"),Mhe=a("strong"),sNo=o("camembert"),lNo=o(" \u2014 "),KO=a("a"),iNo=o("CamembertForSequenceClassification"),dNo=o(" (CamemBERT model)"),cNo=l(),x2=a("li"),Ehe=a("strong"),fNo=o("canine"),mNo=o(" \u2014 "),ZO=a("a"),gNo=o("CanineForSequenceClassification"),hNo=o(" (CANINE model)"),pNo=l(),$2=a("li"),Che=a("strong"),_No=o("convbert"),uNo=o(" \u2014 "),eV=a("a"),bNo=o("ConvBertForSequenceClassification"),vNo=o(" (ConvBERT model)"),FNo=l(),k2=a("li"),whe=a("strong"),TNo=o("ctrl"),MNo=o(" \u2014 "),oV=a("a"),ENo=o("CTRLForSequenceClassification"),CNo=o(" (CTRL model)"),wNo=l(),S2=a("li"),Ahe=a("strong"),ANo=o("data2vec-text"),LNo=o(" \u2014 "),rV=a("a"),yNo=o("Data2VecTextForSequenceClassification"),xNo=o(" (Data2VecText model)"),$No=l(),R2=a("li"),Lhe=a("strong"),kNo=o("deberta"),SNo=o(" \u2014 "),tV=a("a"),RNo=o("DebertaForSequenceClassification"),PNo=o(" (DeBERTa model)"),BNo=l(),P2=a("li"),yhe=a("strong"),INo=o("deberta-v2"),NNo=o(" \u2014 "),aV=a("a"),qNo=o("DebertaV2ForSequenceClassification"),jNo=o(" (DeBERTa-v2 model)"),DNo=l(),B2=a("li"),xhe=a("strong"),GNo=o("distilbert"),ONo=o(" \u2014 "),nV=a("a"),VNo=o("DistilBertForSequenceClassification"),XNo=o(" (DistilBERT model)"),zNo=l(),I2=a("li"),$he=a("strong"),QNo=o("electra"),WNo=o(" \u2014 "),sV=a("a"),HNo=o("ElectraForSequenceClassification"),UNo=o(" (ELECTRA model)"),JNo=l(),N2=a("li"),khe=a("strong"),YNo=o("flaubert"),KNo=o(" \u2014 "),lV=a("a"),ZNo=o("FlaubertForSequenceClassification"),eqo=o(" (FlauBERT model)"),oqo=l(),q2=a("li"),She=a("strong"),rqo=o("fnet"),tqo=o(" \u2014 "),iV=a("a"),aqo=o("FNetForSequenceClassification"),nqo=o(" (FNet model)"),sqo=l(),j2=a("li"),Rhe=a("strong"),lqo=o("funnel"),iqo=o(" \u2014 "),dV=a("a"),dqo=o("FunnelForSequenceClassification"),cqo=o(" (Funnel Transformer model)"),fqo=l(),D2=a("li"),Phe=a("strong"),mqo=o("gpt2"),gqo=o(" \u2014 "),cV=a("a"),hqo=o("GPT2ForSequenceClassification"),pqo=o(" (OpenAI GPT-2 model)"),_qo=l(),G2=a("li"),Bhe=a("strong"),uqo=o("gpt_neo"),bqo=o(" \u2014 "),fV=a("a"),vqo=o("GPTNeoForSequenceClassification"),Fqo=o(" (GPT Neo model)"),Tqo=l(),O2=a("li"),Ihe=a("strong"),Mqo=o("gptj"),Eqo=o(" \u2014 "),mV=a("a"),Cqo=o("GPTJForSequenceClassification"),wqo=o(" (GPT-J model)"),Aqo=l(),V2=a("li"),Nhe=a("strong"),Lqo=o("ibert"),yqo=o(" \u2014 "),gV=a("a"),xqo=o("IBertForSequenceClassification"),$qo=o(" (I-BERT model)"),kqo=l(),X2=a("li"),qhe=a("strong"),Sqo=o("layoutlm"),Rqo=o(" \u2014 "),hV=a("a"),Pqo=o("LayoutLMForSequenceClassification"),Bqo=o(" (LayoutLM model)"),Iqo=l(),z2=a("li"),jhe=a("strong"),Nqo=o("layoutlmv2"),qqo=o(" \u2014 "),pV=a("a"),jqo=o("LayoutLMv2ForSequenceClassification"),Dqo=o(" (LayoutLMv2 model)"),Gqo=l(),Q2=a("li"),Dhe=a("strong"),Oqo=o("layoutlmv3"),Vqo=o(" \u2014 "),_V=a("a"),Xqo=o("LayoutLMv3ForSequenceClassification"),zqo=o(" (LayoutLMv3 model)"),Qqo=l(),W2=a("li"),Ghe=a("strong"),Wqo=o("led"),Hqo=o(" \u2014 "),uV=a("a"),Uqo=o("LEDForSequenceClassification"),Jqo=o(" (LED model)"),Yqo=l(),H2=a("li"),Ohe=a("strong"),Kqo=o("longformer"),Zqo=o(" \u2014 "),bV=a("a"),ejo=o("LongformerForSequenceClassification"),ojo=o(" (Longformer model)"),rjo=l(),U2=a("li"),Vhe=a("strong"),tjo=o("mbart"),ajo=o(" \u2014 "),vV=a("a"),njo=o("MBartForSequenceClassification"),sjo=o(" (mBART model)"),ljo=l(),J2=a("li"),Xhe=a("strong"),ijo=o("megatron-bert"),djo=o(" \u2014 "),FV=a("a"),cjo=o("MegatronBertForSequenceClassification"),fjo=o(" (Megatron-BERT model)"),mjo=l(),Y2=a("li"),zhe=a("strong"),gjo=o("mobilebert"),hjo=o(" \u2014 "),TV=a("a"),pjo=o("MobileBertForSequenceClassification"),_jo=o(" (MobileBERT model)"),ujo=l(),K2=a("li"),Qhe=a("strong"),bjo=o("mpnet"),vjo=o(" \u2014 "),MV=a("a"),Fjo=o("MPNetForSequenceClassification"),Tjo=o(" (MPNet model)"),Mjo=l(),Z2=a("li"),Whe=a("strong"),Ejo=o("nezha"),Cjo=o(" \u2014 "),EV=a("a"),wjo=o("NezhaForSequenceClassification"),Ajo=o(" (Nezha model)"),Ljo=l(),eb=a("li"),Hhe=a("strong"),yjo=o("nystromformer"),xjo=o(" \u2014 "),CV=a("a"),$jo=o("NystromformerForSequenceClassification"),kjo=o(" (Nystr\xF6mformer model)"),Sjo=l(),ob=a("li"),Uhe=a("strong"),Rjo=o("openai-gpt"),Pjo=o(" \u2014 "),wV=a("a"),Bjo=o("OpenAIGPTForSequenceClassification"),Ijo=o(" (OpenAI GPT model)"),Njo=l(),rb=a("li"),Jhe=a("strong"),qjo=o("perceiver"),jjo=o(" \u2014 "),AV=a("a"),Djo=o("PerceiverForSequenceClassification"),Gjo=o(" (Perceiver model)"),Ojo=l(),tb=a("li"),Yhe=a("strong"),Vjo=o("plbart"),Xjo=o(" \u2014 "),LV=a("a"),zjo=o("PLBartForSequenceClassification"),Qjo=o(" (PLBart model)"),Wjo=l(),ab=a("li"),Khe=a("strong"),Hjo=o("qdqbert"),Ujo=o(" \u2014 "),yV=a("a"),Jjo=o("QDQBertForSequenceClassification"),Yjo=o(" (QDQBert model)"),Kjo=l(),nb=a("li"),Zhe=a("strong"),Zjo=o("reformer"),eDo=o(" \u2014 "),xV=a("a"),oDo=o("ReformerForSequenceClassification"),rDo=o(" (Reformer model)"),tDo=l(),sb=a("li"),epe=a("strong"),aDo=o("rembert"),nDo=o(" \u2014 "),$V=a("a"),sDo=o("RemBertForSequenceClassification"),lDo=o(" (RemBERT model)"),iDo=l(),lb=a("li"),ope=a("strong"),dDo=o("roberta"),cDo=o(" \u2014 "),kV=a("a"),fDo=o("RobertaForSequenceClassification"),mDo=o(" (RoBERTa model)"),gDo=l(),ib=a("li"),rpe=a("strong"),hDo=o("roformer"),pDo=o(" \u2014 "),SV=a("a"),_Do=o("RoFormerForSequenceClassification"),uDo=o(" (RoFormer model)"),bDo=l(),db=a("li"),tpe=a("strong"),vDo=o("squeezebert"),FDo=o(" \u2014 "),RV=a("a"),TDo=o("SqueezeBertForSequenceClassification"),MDo=o(" (SqueezeBERT model)"),EDo=l(),cb=a("li"),ape=a("strong"),CDo=o("tapas"),wDo=o(" \u2014 "),PV=a("a"),ADo=o("TapasForSequenceClassification"),LDo=o(" (TAPAS model)"),yDo=l(),fb=a("li"),npe=a("strong"),xDo=o("transfo-xl"),$Do=o(" \u2014 "),BV=a("a"),kDo=o("TransfoXLForSequenceClassification"),SDo=o(" (Transformer-XL model)"),RDo=l(),mb=a("li"),spe=a("strong"),PDo=o("xlm"),BDo=o(" \u2014 "),IV=a("a"),IDo=o("XLMForSequenceClassification"),NDo=o(" (XLM model)"),qDo=l(),gb=a("li"),lpe=a("strong"),jDo=o("xlm-roberta"),DDo=o(" \u2014 "),NV=a("a"),GDo=o("XLMRobertaForSequenceClassification"),ODo=o(" (XLM-RoBERTa model)"),VDo=l(),hb=a("li"),ipe=a("strong"),XDo=o("xlm-roberta-xl"),zDo=o(" \u2014 "),qV=a("a"),QDo=o("XLMRobertaXLForSequenceClassification"),WDo=o(" (XLM-RoBERTa-XL model)"),HDo=l(),pb=a("li"),dpe=a("strong"),UDo=o("xlnet"),JDo=o(" \u2014 "),jV=a("a"),YDo=o("XLNetForSequenceClassification"),KDo=o(" (XLNet model)"),ZDo=l(),_b=a("li"),cpe=a("strong"),eGo=o("yoso"),oGo=o(" \u2014 "),DV=a("a"),rGo=o("YosoForSequenceClassification"),tGo=o(" (YOSO model)"),aGo=l(),ub=a("p"),nGo=o("The model is set in evaluation mode by default using "),fpe=a("code"),sGo=o("model.eval()"),lGo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mpe=a("code"),iGo=o("model.train()"),dGo=l(),F(bb.$$.fragment),cOe=l(),Zi=a("h2"),vb=a("a"),gpe=a("span"),F(ky.$$.fragment),cGo=l(),hpe=a("span"),fGo=o("AutoModelForMultipleChoice"),fOe=l(),Bo=a("div"),F(Sy.$$.fragment),mGo=l(),ed=a("p"),gGo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),GV=a("a"),hGo=o("from_pretrained()"),pGo=o(" class method or the "),OV=a("a"),_Go=o("from_config()"),uGo=o(` class
method.`),bGo=l(),Ry=a("p"),vGo=o("This class cannot be instantiated directly using "),ppe=a("code"),FGo=o("__init__()"),TGo=o(" (throws an error)."),MGo=l(),ft=a("div"),F(Py.$$.fragment),EGo=l(),_pe=a("p"),CGo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),wGo=l(),od=a("p"),AGo=o(`Note:
Loading a model from its configuration file does `),upe=a("strong"),LGo=o("not"),yGo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VV=a("a"),xGo=o("from_pretrained()"),$Go=o(" to load the model weights."),kGo=l(),F(Fb.$$.fragment),SGo=l(),ro=a("div"),F(By.$$.fragment),RGo=l(),bpe=a("p"),PGo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),BGo=l(),ja=a("p"),IGo=o("The model class to instantiate is selected based on the "),vpe=a("code"),NGo=o("model_type"),qGo=o(` property of the config object (either
passed as an argument or loaded from `),Fpe=a("code"),jGo=o("pretrained_model_name_or_path"),DGo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tpe=a("code"),GGo=o("pretrained_model_name_or_path"),OGo=o(":"),VGo=l(),Z=a("ul"),Tb=a("li"),Mpe=a("strong"),XGo=o("albert"),zGo=o(" \u2014 "),XV=a("a"),QGo=o("AlbertForMultipleChoice"),WGo=o(" (ALBERT model)"),HGo=l(),Mb=a("li"),Epe=a("strong"),UGo=o("bert"),JGo=o(" \u2014 "),zV=a("a"),YGo=o("BertForMultipleChoice"),KGo=o(" (BERT model)"),ZGo=l(),Eb=a("li"),Cpe=a("strong"),eOo=o("big_bird"),oOo=o(" \u2014 "),QV=a("a"),rOo=o("BigBirdForMultipleChoice"),tOo=o(" (BigBird model)"),aOo=l(),Cb=a("li"),wpe=a("strong"),nOo=o("camembert"),sOo=o(" \u2014 "),WV=a("a"),lOo=o("CamembertForMultipleChoice"),iOo=o(" (CamemBERT model)"),dOo=l(),wb=a("li"),Ape=a("strong"),cOo=o("canine"),fOo=o(" \u2014 "),HV=a("a"),mOo=o("CanineForMultipleChoice"),gOo=o(" (CANINE model)"),hOo=l(),Ab=a("li"),Lpe=a("strong"),pOo=o("convbert"),_Oo=o(" \u2014 "),UV=a("a"),uOo=o("ConvBertForMultipleChoice"),bOo=o(" (ConvBERT model)"),vOo=l(),Lb=a("li"),ype=a("strong"),FOo=o("data2vec-text"),TOo=o(" \u2014 "),JV=a("a"),MOo=o("Data2VecTextForMultipleChoice"),EOo=o(" (Data2VecText model)"),COo=l(),yb=a("li"),xpe=a("strong"),wOo=o("deberta-v2"),AOo=o(" \u2014 "),YV=a("a"),LOo=o("DebertaV2ForMultipleChoice"),yOo=o(" (DeBERTa-v2 model)"),xOo=l(),xb=a("li"),$pe=a("strong"),$Oo=o("distilbert"),kOo=o(" \u2014 "),KV=a("a"),SOo=o("DistilBertForMultipleChoice"),ROo=o(" (DistilBERT model)"),POo=l(),$b=a("li"),kpe=a("strong"),BOo=o("electra"),IOo=o(" \u2014 "),ZV=a("a"),NOo=o("ElectraForMultipleChoice"),qOo=o(" (ELECTRA model)"),jOo=l(),kb=a("li"),Spe=a("strong"),DOo=o("flaubert"),GOo=o(" \u2014 "),eX=a("a"),OOo=o("FlaubertForMultipleChoice"),VOo=o(" (FlauBERT model)"),XOo=l(),Sb=a("li"),Rpe=a("strong"),zOo=o("fnet"),QOo=o(" \u2014 "),oX=a("a"),WOo=o("FNetForMultipleChoice"),HOo=o(" (FNet model)"),UOo=l(),Rb=a("li"),Ppe=a("strong"),JOo=o("funnel"),YOo=o(" \u2014 "),rX=a("a"),KOo=o("FunnelForMultipleChoice"),ZOo=o(" (Funnel Transformer model)"),eVo=l(),Pb=a("li"),Bpe=a("strong"),oVo=o("ibert"),rVo=o(" \u2014 "),tX=a("a"),tVo=o("IBertForMultipleChoice"),aVo=o(" (I-BERT model)"),nVo=l(),Bb=a("li"),Ipe=a("strong"),sVo=o("longformer"),lVo=o(" \u2014 "),aX=a("a"),iVo=o("LongformerForMultipleChoice"),dVo=o(" (Longformer model)"),cVo=l(),Ib=a("li"),Npe=a("strong"),fVo=o("megatron-bert"),mVo=o(" \u2014 "),nX=a("a"),gVo=o("MegatronBertForMultipleChoice"),hVo=o(" (Megatron-BERT model)"),pVo=l(),Nb=a("li"),qpe=a("strong"),_Vo=o("mobilebert"),uVo=o(" \u2014 "),sX=a("a"),bVo=o("MobileBertForMultipleChoice"),vVo=o(" (MobileBERT model)"),FVo=l(),qb=a("li"),jpe=a("strong"),TVo=o("mpnet"),MVo=o(" \u2014 "),lX=a("a"),EVo=o("MPNetForMultipleChoice"),CVo=o(" (MPNet model)"),wVo=l(),jb=a("li"),Dpe=a("strong"),AVo=o("nezha"),LVo=o(" \u2014 "),iX=a("a"),yVo=o("NezhaForMultipleChoice"),xVo=o(" (Nezha model)"),$Vo=l(),Db=a("li"),Gpe=a("strong"),kVo=o("nystromformer"),SVo=o(" \u2014 "),dX=a("a"),RVo=o("NystromformerForMultipleChoice"),PVo=o(" (Nystr\xF6mformer model)"),BVo=l(),Gb=a("li"),Ope=a("strong"),IVo=o("qdqbert"),NVo=o(" \u2014 "),cX=a("a"),qVo=o("QDQBertForMultipleChoice"),jVo=o(" (QDQBert model)"),DVo=l(),Ob=a("li"),Vpe=a("strong"),GVo=o("rembert"),OVo=o(" \u2014 "),fX=a("a"),VVo=o("RemBertForMultipleChoice"),XVo=o(" (RemBERT model)"),zVo=l(),Vb=a("li"),Xpe=a("strong"),QVo=o("roberta"),WVo=o(" \u2014 "),mX=a("a"),HVo=o("RobertaForMultipleChoice"),UVo=o(" (RoBERTa model)"),JVo=l(),Xb=a("li"),zpe=a("strong"),YVo=o("roformer"),KVo=o(" \u2014 "),gX=a("a"),ZVo=o("RoFormerForMultipleChoice"),eXo=o(" (RoFormer model)"),oXo=l(),zb=a("li"),Qpe=a("strong"),rXo=o("squeezebert"),tXo=o(" \u2014 "),hX=a("a"),aXo=o("SqueezeBertForMultipleChoice"),nXo=o(" (SqueezeBERT model)"),sXo=l(),Qb=a("li"),Wpe=a("strong"),lXo=o("xlm"),iXo=o(" \u2014 "),pX=a("a"),dXo=o("XLMForMultipleChoice"),cXo=o(" (XLM model)"),fXo=l(),Wb=a("li"),Hpe=a("strong"),mXo=o("xlm-roberta"),gXo=o(" \u2014 "),_X=a("a"),hXo=o("XLMRobertaForMultipleChoice"),pXo=o(" (XLM-RoBERTa model)"),_Xo=l(),Hb=a("li"),Upe=a("strong"),uXo=o("xlm-roberta-xl"),bXo=o(" \u2014 "),uX=a("a"),vXo=o("XLMRobertaXLForMultipleChoice"),FXo=o(" (XLM-RoBERTa-XL model)"),TXo=l(),Ub=a("li"),Jpe=a("strong"),MXo=o("xlnet"),EXo=o(" \u2014 "),bX=a("a"),CXo=o("XLNetForMultipleChoice"),wXo=o(" (XLNet model)"),AXo=l(),Jb=a("li"),Ype=a("strong"),LXo=o("yoso"),yXo=o(" \u2014 "),vX=a("a"),xXo=o("YosoForMultipleChoice"),$Xo=o(" (YOSO model)"),kXo=l(),Yb=a("p"),SXo=o("The model is set in evaluation mode by default using "),Kpe=a("code"),RXo=o("model.eval()"),PXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Zpe=a("code"),BXo=o("model.train()"),IXo=l(),F(Kb.$$.fragment),mOe=l(),rd=a("h2"),Zb=a("a"),e_e=a("span"),F(Iy.$$.fragment),NXo=l(),o_e=a("span"),qXo=o("AutoModelForNextSentencePrediction"),gOe=l(),Io=a("div"),F(Ny.$$.fragment),jXo=l(),td=a("p"),DXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),FX=a("a"),GXo=o("from_pretrained()"),OXo=o(" class method or the "),TX=a("a"),VXo=o("from_config()"),XXo=o(` class
method.`),zXo=l(),qy=a("p"),QXo=o("This class cannot be instantiated directly using "),r_e=a("code"),WXo=o("__init__()"),HXo=o(" (throws an error)."),UXo=l(),mt=a("div"),F(jy.$$.fragment),JXo=l(),t_e=a("p"),YXo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),KXo=l(),ad=a("p"),ZXo=o(`Note:
Loading a model from its configuration file does `),a_e=a("strong"),ezo=o("not"),ozo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MX=a("a"),rzo=o("from_pretrained()"),tzo=o(" to load the model weights."),azo=l(),F(e5.$$.fragment),nzo=l(),to=a("div"),F(Dy.$$.fragment),szo=l(),n_e=a("p"),lzo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),izo=l(),Da=a("p"),dzo=o("The model class to instantiate is selected based on the "),s_e=a("code"),czo=o("model_type"),fzo=o(` property of the config object (either
passed as an argument or loaded from `),l_e=a("code"),mzo=o("pretrained_model_name_or_path"),gzo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i_e=a("code"),hzo=o("pretrained_model_name_or_path"),pzo=o(":"),_zo=l(),No=a("ul"),o5=a("li"),d_e=a("strong"),uzo=o("bert"),bzo=o(" \u2014 "),EX=a("a"),vzo=o("BertForNextSentencePrediction"),Fzo=o(" (BERT model)"),Tzo=l(),r5=a("li"),c_e=a("strong"),Mzo=o("fnet"),Ezo=o(" \u2014 "),CX=a("a"),Czo=o("FNetForNextSentencePrediction"),wzo=o(" (FNet model)"),Azo=l(),t5=a("li"),f_e=a("strong"),Lzo=o("megatron-bert"),yzo=o(" \u2014 "),wX=a("a"),xzo=o("MegatronBertForNextSentencePrediction"),$zo=o(" (Megatron-BERT model)"),kzo=l(),a5=a("li"),m_e=a("strong"),Szo=o("mobilebert"),Rzo=o(" \u2014 "),AX=a("a"),Pzo=o("MobileBertForNextSentencePrediction"),Bzo=o(" (MobileBERT model)"),Izo=l(),n5=a("li"),g_e=a("strong"),Nzo=o("nezha"),qzo=o(" \u2014 "),LX=a("a"),jzo=o("NezhaForNextSentencePrediction"),Dzo=o(" (Nezha model)"),Gzo=l(),s5=a("li"),h_e=a("strong"),Ozo=o("qdqbert"),Vzo=o(" \u2014 "),yX=a("a"),Xzo=o("QDQBertForNextSentencePrediction"),zzo=o(" (QDQBert model)"),Qzo=l(),l5=a("p"),Wzo=o("The model is set in evaluation mode by default using "),p_e=a("code"),Hzo=o("model.eval()"),Uzo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),__e=a("code"),Jzo=o("model.train()"),Yzo=l(),F(i5.$$.fragment),hOe=l(),nd=a("h2"),d5=a("a"),u_e=a("span"),F(Gy.$$.fragment),Kzo=l(),b_e=a("span"),Zzo=o("AutoModelForTokenClassification"),pOe=l(),qo=a("div"),F(Oy.$$.fragment),eQo=l(),sd=a("p"),oQo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),xX=a("a"),rQo=o("from_pretrained()"),tQo=o(" class method or the "),$X=a("a"),aQo=o("from_config()"),nQo=o(` class
method.`),sQo=l(),Vy=a("p"),lQo=o("This class cannot be instantiated directly using "),v_e=a("code"),iQo=o("__init__()"),dQo=o(" (throws an error)."),cQo=l(),gt=a("div"),F(Xy.$$.fragment),fQo=l(),F_e=a("p"),mQo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),gQo=l(),ld=a("p"),hQo=o(`Note:
Loading a model from its configuration file does `),T_e=a("strong"),pQo=o("not"),_Qo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kX=a("a"),uQo=o("from_pretrained()"),bQo=o(" to load the model weights."),vQo=l(),F(c5.$$.fragment),FQo=l(),ao=a("div"),F(zy.$$.fragment),TQo=l(),M_e=a("p"),MQo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),EQo=l(),Ga=a("p"),CQo=o("The model class to instantiate is selected based on the "),E_e=a("code"),wQo=o("model_type"),AQo=o(` property of the config object (either
passed as an argument or loaded from `),C_e=a("code"),LQo=o("pretrained_model_name_or_path"),yQo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w_e=a("code"),xQo=o("pretrained_model_name_or_path"),$Qo=o(":"),kQo=l(),H=a("ul"),f5=a("li"),A_e=a("strong"),SQo=o("albert"),RQo=o(" \u2014 "),SX=a("a"),PQo=o("AlbertForTokenClassification"),BQo=o(" (ALBERT model)"),IQo=l(),m5=a("li"),L_e=a("strong"),NQo=o("bert"),qQo=o(" \u2014 "),RX=a("a"),jQo=o("BertForTokenClassification"),DQo=o(" (BERT model)"),GQo=l(),g5=a("li"),y_e=a("strong"),OQo=o("big_bird"),VQo=o(" \u2014 "),PX=a("a"),XQo=o("BigBirdForTokenClassification"),zQo=o(" (BigBird model)"),QQo=l(),h5=a("li"),x_e=a("strong"),WQo=o("bloom"),HQo=o(" \u2014 "),BX=a("a"),UQo=o("BloomForTokenClassification"),JQo=o(" (BLOOM model)"),YQo=l(),p5=a("li"),$_e=a("strong"),KQo=o("camembert"),ZQo=o(" \u2014 "),IX=a("a"),eWo=o("CamembertForTokenClassification"),oWo=o(" (CamemBERT model)"),rWo=l(),_5=a("li"),k_e=a("strong"),tWo=o("canine"),aWo=o(" \u2014 "),NX=a("a"),nWo=o("CanineForTokenClassification"),sWo=o(" (CANINE model)"),lWo=l(),u5=a("li"),S_e=a("strong"),iWo=o("convbert"),dWo=o(" \u2014 "),qX=a("a"),cWo=o("ConvBertForTokenClassification"),fWo=o(" (ConvBERT model)"),mWo=l(),b5=a("li"),R_e=a("strong"),gWo=o("data2vec-text"),hWo=o(" \u2014 "),jX=a("a"),pWo=o("Data2VecTextForTokenClassification"),_Wo=o(" (Data2VecText model)"),uWo=l(),v5=a("li"),P_e=a("strong"),bWo=o("deberta"),vWo=o(" \u2014 "),DX=a("a"),FWo=o("DebertaForTokenClassification"),TWo=o(" (DeBERTa model)"),MWo=l(),F5=a("li"),B_e=a("strong"),EWo=o("deberta-v2"),CWo=o(" \u2014 "),GX=a("a"),wWo=o("DebertaV2ForTokenClassification"),AWo=o(" (DeBERTa-v2 model)"),LWo=l(),T5=a("li"),I_e=a("strong"),yWo=o("distilbert"),xWo=o(" \u2014 "),OX=a("a"),$Wo=o("DistilBertForTokenClassification"),kWo=o(" (DistilBERT model)"),SWo=l(),M5=a("li"),N_e=a("strong"),RWo=o("electra"),PWo=o(" \u2014 "),VX=a("a"),BWo=o("ElectraForTokenClassification"),IWo=o(" (ELECTRA model)"),NWo=l(),E5=a("li"),q_e=a("strong"),qWo=o("flaubert"),jWo=o(" \u2014 "),XX=a("a"),DWo=o("FlaubertForTokenClassification"),GWo=o(" (FlauBERT model)"),OWo=l(),C5=a("li"),j_e=a("strong"),VWo=o("fnet"),XWo=o(" \u2014 "),zX=a("a"),zWo=o("FNetForTokenClassification"),QWo=o(" (FNet model)"),WWo=l(),w5=a("li"),D_e=a("strong"),HWo=o("funnel"),UWo=o(" \u2014 "),QX=a("a"),JWo=o("FunnelForTokenClassification"),YWo=o(" (Funnel Transformer model)"),KWo=l(),A5=a("li"),G_e=a("strong"),ZWo=o("gpt2"),eHo=o(" \u2014 "),WX=a("a"),oHo=o("GPT2ForTokenClassification"),rHo=o(" (OpenAI GPT-2 model)"),tHo=l(),L5=a("li"),O_e=a("strong"),aHo=o("ibert"),nHo=o(" \u2014 "),HX=a("a"),sHo=o("IBertForTokenClassification"),lHo=o(" (I-BERT model)"),iHo=l(),y5=a("li"),V_e=a("strong"),dHo=o("layoutlm"),cHo=o(" \u2014 "),UX=a("a"),fHo=o("LayoutLMForTokenClassification"),mHo=o(" (LayoutLM model)"),gHo=l(),x5=a("li"),X_e=a("strong"),hHo=o("layoutlmv2"),pHo=o(" \u2014 "),JX=a("a"),_Ho=o("LayoutLMv2ForTokenClassification"),uHo=o(" (LayoutLMv2 model)"),bHo=l(),$5=a("li"),z_e=a("strong"),vHo=o("layoutlmv3"),FHo=o(" \u2014 "),YX=a("a"),THo=o("LayoutLMv3ForTokenClassification"),MHo=o(" (LayoutLMv3 model)"),EHo=l(),k5=a("li"),Q_e=a("strong"),CHo=o("longformer"),wHo=o(" \u2014 "),KX=a("a"),AHo=o("LongformerForTokenClassification"),LHo=o(" (Longformer model)"),yHo=l(),S5=a("li"),W_e=a("strong"),xHo=o("megatron-bert"),$Ho=o(" \u2014 "),ZX=a("a"),kHo=o("MegatronBertForTokenClassification"),SHo=o(" (Megatron-BERT model)"),RHo=l(),R5=a("li"),H_e=a("strong"),PHo=o("mobilebert"),BHo=o(" \u2014 "),ez=a("a"),IHo=o("MobileBertForTokenClassification"),NHo=o(" (MobileBERT model)"),qHo=l(),P5=a("li"),U_e=a("strong"),jHo=o("mpnet"),DHo=o(" \u2014 "),oz=a("a"),GHo=o("MPNetForTokenClassification"),OHo=o(" (MPNet model)"),VHo=l(),B5=a("li"),J_e=a("strong"),XHo=o("nezha"),zHo=o(" \u2014 "),rz=a("a"),QHo=o("NezhaForTokenClassification"),WHo=o(" (Nezha model)"),HHo=l(),I5=a("li"),Y_e=a("strong"),UHo=o("nystromformer"),JHo=o(" \u2014 "),tz=a("a"),YHo=o("NystromformerForTokenClassification"),KHo=o(" (Nystr\xF6mformer model)"),ZHo=l(),N5=a("li"),K_e=a("strong"),eUo=o("qdqbert"),oUo=o(" \u2014 "),az=a("a"),rUo=o("QDQBertForTokenClassification"),tUo=o(" (QDQBert model)"),aUo=l(),q5=a("li"),Z_e=a("strong"),nUo=o("rembert"),sUo=o(" \u2014 "),nz=a("a"),lUo=o("RemBertForTokenClassification"),iUo=o(" (RemBERT model)"),dUo=l(),j5=a("li"),eue=a("strong"),cUo=o("roberta"),fUo=o(" \u2014 "),sz=a("a"),mUo=o("RobertaForTokenClassification"),gUo=o(" (RoBERTa model)"),hUo=l(),D5=a("li"),oue=a("strong"),pUo=o("roformer"),_Uo=o(" \u2014 "),lz=a("a"),uUo=o("RoFormerForTokenClassification"),bUo=o(" (RoFormer model)"),vUo=l(),G5=a("li"),rue=a("strong"),FUo=o("squeezebert"),TUo=o(" \u2014 "),iz=a("a"),MUo=o("SqueezeBertForTokenClassification"),EUo=o(" (SqueezeBERT model)"),CUo=l(),O5=a("li"),tue=a("strong"),wUo=o("xlm"),AUo=o(" \u2014 "),dz=a("a"),LUo=o("XLMForTokenClassification"),yUo=o(" (XLM model)"),xUo=l(),V5=a("li"),aue=a("strong"),$Uo=o("xlm-roberta"),kUo=o(" \u2014 "),cz=a("a"),SUo=o("XLMRobertaForTokenClassification"),RUo=o(" (XLM-RoBERTa model)"),PUo=l(),X5=a("li"),nue=a("strong"),BUo=o("xlm-roberta-xl"),IUo=o(" \u2014 "),fz=a("a"),NUo=o("XLMRobertaXLForTokenClassification"),qUo=o(" (XLM-RoBERTa-XL model)"),jUo=l(),z5=a("li"),sue=a("strong"),DUo=o("xlnet"),GUo=o(" \u2014 "),mz=a("a"),OUo=o("XLNetForTokenClassification"),VUo=o(" (XLNet model)"),XUo=l(),Q5=a("li"),lue=a("strong"),zUo=o("yoso"),QUo=o(" \u2014 "),gz=a("a"),WUo=o("YosoForTokenClassification"),HUo=o(" (YOSO model)"),UUo=l(),W5=a("p"),JUo=o("The model is set in evaluation mode by default using "),iue=a("code"),YUo=o("model.eval()"),KUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),due=a("code"),ZUo=o("model.train()"),eJo=l(),F(H5.$$.fragment),_Oe=l(),id=a("h2"),U5=a("a"),cue=a("span"),F(Qy.$$.fragment),oJo=l(),fue=a("span"),rJo=o("AutoModelForQuestionAnswering"),uOe=l(),jo=a("div"),F(Wy.$$.fragment),tJo=l(),dd=a("p"),aJo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),hz=a("a"),nJo=o("from_pretrained()"),sJo=o(" class method or the "),pz=a("a"),lJo=o("from_config()"),iJo=o(` class
method.`),dJo=l(),Hy=a("p"),cJo=o("This class cannot be instantiated directly using "),mue=a("code"),fJo=o("__init__()"),mJo=o(" (throws an error)."),gJo=l(),ht=a("div"),F(Uy.$$.fragment),hJo=l(),gue=a("p"),pJo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),_Jo=l(),cd=a("p"),uJo=o(`Note:
Loading a model from its configuration file does `),hue=a("strong"),bJo=o("not"),vJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_z=a("a"),FJo=o("from_pretrained()"),TJo=o(" to load the model weights."),MJo=l(),F(J5.$$.fragment),EJo=l(),no=a("div"),F(Jy.$$.fragment),CJo=l(),pue=a("p"),wJo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),AJo=l(),Oa=a("p"),LJo=o("The model class to instantiate is selected based on the "),_ue=a("code"),yJo=o("model_type"),xJo=o(` property of the config object (either
passed as an argument or loaded from `),uue=a("code"),$Jo=o("pretrained_model_name_or_path"),kJo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bue=a("code"),SJo=o("pretrained_model_name_or_path"),RJo=o(":"),PJo=l(),V=a("ul"),Y5=a("li"),vue=a("strong"),BJo=o("albert"),IJo=o(" \u2014 "),uz=a("a"),NJo=o("AlbertForQuestionAnswering"),qJo=o(" (ALBERT model)"),jJo=l(),K5=a("li"),Fue=a("strong"),DJo=o("bart"),GJo=o(" \u2014 "),bz=a("a"),OJo=o("BartForQuestionAnswering"),VJo=o(" (BART model)"),XJo=l(),Z5=a("li"),Tue=a("strong"),zJo=o("bert"),QJo=o(" \u2014 "),vz=a("a"),WJo=o("BertForQuestionAnswering"),HJo=o(" (BERT model)"),UJo=l(),ev=a("li"),Mue=a("strong"),JJo=o("big_bird"),YJo=o(" \u2014 "),Fz=a("a"),KJo=o("BigBirdForQuestionAnswering"),ZJo=o(" (BigBird model)"),eYo=l(),ov=a("li"),Eue=a("strong"),oYo=o("bigbird_pegasus"),rYo=o(" \u2014 "),Tz=a("a"),tYo=o("BigBirdPegasusForQuestionAnswering"),aYo=o(" (BigBird-Pegasus model)"),nYo=l(),rv=a("li"),Cue=a("strong"),sYo=o("camembert"),lYo=o(" \u2014 "),Mz=a("a"),iYo=o("CamembertForQuestionAnswering"),dYo=o(" (CamemBERT model)"),cYo=l(),tv=a("li"),wue=a("strong"),fYo=o("canine"),mYo=o(" \u2014 "),Ez=a("a"),gYo=o("CanineForQuestionAnswering"),hYo=o(" (CANINE model)"),pYo=l(),av=a("li"),Aue=a("strong"),_Yo=o("convbert"),uYo=o(" \u2014 "),Cz=a("a"),bYo=o("ConvBertForQuestionAnswering"),vYo=o(" (ConvBERT model)"),FYo=l(),nv=a("li"),Lue=a("strong"),TYo=o("data2vec-text"),MYo=o(" \u2014 "),wz=a("a"),EYo=o("Data2VecTextForQuestionAnswering"),CYo=o(" (Data2VecText model)"),wYo=l(),sv=a("li"),yue=a("strong"),AYo=o("deberta"),LYo=o(" \u2014 "),Az=a("a"),yYo=o("DebertaForQuestionAnswering"),xYo=o(" (DeBERTa model)"),$Yo=l(),lv=a("li"),xue=a("strong"),kYo=o("deberta-v2"),SYo=o(" \u2014 "),Lz=a("a"),RYo=o("DebertaV2ForQuestionAnswering"),PYo=o(" (DeBERTa-v2 model)"),BYo=l(),iv=a("li"),$ue=a("strong"),IYo=o("distilbert"),NYo=o(" \u2014 "),yz=a("a"),qYo=o("DistilBertForQuestionAnswering"),jYo=o(" (DistilBERT model)"),DYo=l(),dv=a("li"),kue=a("strong"),GYo=o("electra"),OYo=o(" \u2014 "),xz=a("a"),VYo=o("ElectraForQuestionAnswering"),XYo=o(" (ELECTRA model)"),zYo=l(),cv=a("li"),Sue=a("strong"),QYo=o("flaubert"),WYo=o(" \u2014 "),$z=a("a"),HYo=o("FlaubertForQuestionAnsweringSimple"),UYo=o(" (FlauBERT model)"),JYo=l(),fv=a("li"),Rue=a("strong"),YYo=o("fnet"),KYo=o(" \u2014 "),kz=a("a"),ZYo=o("FNetForQuestionAnswering"),eKo=o(" (FNet model)"),oKo=l(),mv=a("li"),Pue=a("strong"),rKo=o("funnel"),tKo=o(" \u2014 "),Sz=a("a"),aKo=o("FunnelForQuestionAnswering"),nKo=o(" (Funnel Transformer model)"),sKo=l(),gv=a("li"),Bue=a("strong"),lKo=o("gptj"),iKo=o(" \u2014 "),Rz=a("a"),dKo=o("GPTJForQuestionAnswering"),cKo=o(" (GPT-J model)"),fKo=l(),hv=a("li"),Iue=a("strong"),mKo=o("ibert"),gKo=o(" \u2014 "),Pz=a("a"),hKo=o("IBertForQuestionAnswering"),pKo=o(" (I-BERT model)"),_Ko=l(),pv=a("li"),Nue=a("strong"),uKo=o("layoutlmv2"),bKo=o(" \u2014 "),Bz=a("a"),vKo=o("LayoutLMv2ForQuestionAnswering"),FKo=o(" (LayoutLMv2 model)"),TKo=l(),_v=a("li"),que=a("strong"),MKo=o("layoutlmv3"),EKo=o(" \u2014 "),Iz=a("a"),CKo=o("LayoutLMv3ForQuestionAnswering"),wKo=o(" (LayoutLMv3 model)"),AKo=l(),uv=a("li"),jue=a("strong"),LKo=o("led"),yKo=o(" \u2014 "),Nz=a("a"),xKo=o("LEDForQuestionAnswering"),$Ko=o(" (LED model)"),kKo=l(),bv=a("li"),Due=a("strong"),SKo=o("longformer"),RKo=o(" \u2014 "),qz=a("a"),PKo=o("LongformerForQuestionAnswering"),BKo=o(" (Longformer model)"),IKo=l(),vv=a("li"),Gue=a("strong"),NKo=o("lxmert"),qKo=o(" \u2014 "),jz=a("a"),jKo=o("LxmertForQuestionAnswering"),DKo=o(" (LXMERT model)"),GKo=l(),Fv=a("li"),Oue=a("strong"),OKo=o("mbart"),VKo=o(" \u2014 "),Dz=a("a"),XKo=o("MBartForQuestionAnswering"),zKo=o(" (mBART model)"),QKo=l(),Tv=a("li"),Vue=a("strong"),WKo=o("megatron-bert"),HKo=o(" \u2014 "),Gz=a("a"),UKo=o("MegatronBertForQuestionAnswering"),JKo=o(" (Megatron-BERT model)"),YKo=l(),Mv=a("li"),Xue=a("strong"),KKo=o("mobilebert"),ZKo=o(" \u2014 "),Oz=a("a"),eZo=o("MobileBertForQuestionAnswering"),oZo=o(" (MobileBERT model)"),rZo=l(),Ev=a("li"),zue=a("strong"),tZo=o("mpnet"),aZo=o(" \u2014 "),Vz=a("a"),nZo=o("MPNetForQuestionAnswering"),sZo=o(" (MPNet model)"),lZo=l(),Cv=a("li"),Que=a("strong"),iZo=o("nezha"),dZo=o(" \u2014 "),Xz=a("a"),cZo=o("NezhaForQuestionAnswering"),fZo=o(" (Nezha model)"),mZo=l(),wv=a("li"),Wue=a("strong"),gZo=o("nystromformer"),hZo=o(" \u2014 "),zz=a("a"),pZo=o("NystromformerForQuestionAnswering"),_Zo=o(" (Nystr\xF6mformer model)"),uZo=l(),Av=a("li"),Hue=a("strong"),bZo=o("qdqbert"),vZo=o(" \u2014 "),Qz=a("a"),FZo=o("QDQBertForQuestionAnswering"),TZo=o(" (QDQBert model)"),MZo=l(),Lv=a("li"),Uue=a("strong"),EZo=o("reformer"),CZo=o(" \u2014 "),Wz=a("a"),wZo=o("ReformerForQuestionAnswering"),AZo=o(" (Reformer model)"),LZo=l(),yv=a("li"),Jue=a("strong"),yZo=o("rembert"),xZo=o(" \u2014 "),Hz=a("a"),$Zo=o("RemBertForQuestionAnswering"),kZo=o(" (RemBERT model)"),SZo=l(),xv=a("li"),Yue=a("strong"),RZo=o("roberta"),PZo=o(" \u2014 "),Uz=a("a"),BZo=o("RobertaForQuestionAnswering"),IZo=o(" (RoBERTa model)"),NZo=l(),$v=a("li"),Kue=a("strong"),qZo=o("roformer"),jZo=o(" \u2014 "),Jz=a("a"),DZo=o("RoFormerForQuestionAnswering"),GZo=o(" (RoFormer model)"),OZo=l(),kv=a("li"),Zue=a("strong"),VZo=o("splinter"),XZo=o(" \u2014 "),Yz=a("a"),zZo=o("SplinterForQuestionAnswering"),QZo=o(" (Splinter model)"),WZo=l(),Sv=a("li"),e1e=a("strong"),HZo=o("squeezebert"),UZo=o(" \u2014 "),Kz=a("a"),JZo=o("SqueezeBertForQuestionAnswering"),YZo=o(" (SqueezeBERT model)"),KZo=l(),Rv=a("li"),o1e=a("strong"),ZZo=o("xlm"),eer=o(" \u2014 "),Zz=a("a"),oer=o("XLMForQuestionAnsweringSimple"),rer=o(" (XLM model)"),ter=l(),Pv=a("li"),r1e=a("strong"),aer=o("xlm-roberta"),ner=o(" \u2014 "),eQ=a("a"),ser=o("XLMRobertaForQuestionAnswering"),ler=o(" (XLM-RoBERTa model)"),ier=l(),Bv=a("li"),t1e=a("strong"),der=o("xlm-roberta-xl"),cer=o(" \u2014 "),oQ=a("a"),fer=o("XLMRobertaXLForQuestionAnswering"),mer=o(" (XLM-RoBERTa-XL model)"),ger=l(),Iv=a("li"),a1e=a("strong"),her=o("xlnet"),per=o(" \u2014 "),rQ=a("a"),_er=o("XLNetForQuestionAnsweringSimple"),uer=o(" (XLNet model)"),ber=l(),Nv=a("li"),n1e=a("strong"),ver=o("yoso"),Fer=o(" \u2014 "),tQ=a("a"),Ter=o("YosoForQuestionAnswering"),Mer=o(" (YOSO model)"),Eer=l(),qv=a("p"),Cer=o("The model is set in evaluation mode by default using "),s1e=a("code"),wer=o("model.eval()"),Aer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l1e=a("code"),Ler=o("model.train()"),yer=l(),F(jv.$$.fragment),bOe=l(),fd=a("h2"),Dv=a("a"),i1e=a("span"),F(Yy.$$.fragment),xer=l(),d1e=a("span"),$er=o("AutoModelForTableQuestionAnswering"),vOe=l(),Do=a("div"),F(Ky.$$.fragment),ker=l(),md=a("p"),Ser=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),aQ=a("a"),Rer=o("from_pretrained()"),Per=o(" class method or the "),nQ=a("a"),Ber=o("from_config()"),Ier=o(` class
method.`),Ner=l(),Zy=a("p"),qer=o("This class cannot be instantiated directly using "),c1e=a("code"),jer=o("__init__()"),Der=o(" (throws an error)."),Ger=l(),pt=a("div"),F(e8.$$.fragment),Oer=l(),f1e=a("p"),Ver=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Xer=l(),gd=a("p"),zer=o(`Note:
Loading a model from its configuration file does `),m1e=a("strong"),Qer=o("not"),Wer=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sQ=a("a"),Her=o("from_pretrained()"),Uer=o(" to load the model weights."),Jer=l(),F(Gv.$$.fragment),Yer=l(),so=a("div"),F(o8.$$.fragment),Ker=l(),g1e=a("p"),Zer=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),eor=l(),Va=a("p"),oor=o("The model class to instantiate is selected based on the "),h1e=a("code"),ror=o("model_type"),tor=o(` property of the config object (either
passed as an argument or loaded from `),p1e=a("code"),aor=o("pretrained_model_name_or_path"),nor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_1e=a("code"),sor=o("pretrained_model_name_or_path"),lor=o(":"),ior=l(),u1e=a("ul"),Ov=a("li"),b1e=a("strong"),dor=o("tapas"),cor=o(" \u2014 "),lQ=a("a"),mor=o("TapasForQuestionAnswering"),gor=o(" (TAPAS model)"),hor=l(),Vv=a("p"),por=o("The model is set in evaluation mode by default using "),v1e=a("code"),_or=o("model.eval()"),uor=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F1e=a("code"),bor=o("model.train()"),vor=l(),F(Xv.$$.fragment),FOe=l(),hd=a("h2"),zv=a("a"),T1e=a("span"),F(r8.$$.fragment),For=l(),M1e=a("span"),Tor=o("AutoModelForImageClassification"),TOe=l(),Go=a("div"),F(t8.$$.fragment),Mor=l(),pd=a("p"),Eor=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),iQ=a("a"),Cor=o("from_pretrained()"),wor=o(" class method or the "),dQ=a("a"),Aor=o("from_config()"),Lor=o(` class
method.`),yor=l(),a8=a("p"),xor=o("This class cannot be instantiated directly using "),E1e=a("code"),$or=o("__init__()"),kor=o(" (throws an error)."),Sor=l(),_t=a("div"),F(n8.$$.fragment),Ror=l(),C1e=a("p"),Por=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Bor=l(),_d=a("p"),Ior=o(`Note:
Loading a model from its configuration file does `),w1e=a("strong"),Nor=o("not"),qor=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=a("a"),jor=o("from_pretrained()"),Dor=o(" to load the model weights."),Gor=l(),F(Qv.$$.fragment),Oor=l(),lo=a("div"),F(s8.$$.fragment),Vor=l(),A1e=a("p"),Xor=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),zor=l(),Xa=a("p"),Qor=o("The model class to instantiate is selected based on the "),L1e=a("code"),Wor=o("model_type"),Hor=o(` property of the config object (either
passed as an argument or loaded from `),y1e=a("code"),Uor=o("pretrained_model_name_or_path"),Jor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x1e=a("code"),Yor=o("pretrained_model_name_or_path"),Kor=o(":"),Zor=l(),Fe=a("ul"),Wv=a("li"),$1e=a("strong"),err=o("beit"),orr=o(" \u2014 "),fQ=a("a"),rrr=o("BeitForImageClassification"),trr=o(" (BEiT model)"),arr=l(),Hv=a("li"),k1e=a("strong"),nrr=o("convnext"),srr=o(" \u2014 "),mQ=a("a"),lrr=o("ConvNextForImageClassification"),irr=o(" (ConvNeXT model)"),drr=l(),Uv=a("li"),S1e=a("strong"),crr=o("cvt"),frr=o(" \u2014 "),gQ=a("a"),mrr=o("CvtForImageClassification"),grr=o(" (CvT model)"),hrr=l(),Jv=a("li"),R1e=a("strong"),prr=o("data2vec-vision"),_rr=o(" \u2014 "),hQ=a("a"),urr=o("Data2VecVisionForImageClassification"),brr=o(" (Data2VecVision model)"),vrr=l(),Xs=a("li"),P1e=a("strong"),Frr=o("deit"),Trr=o(" \u2014 "),pQ=a("a"),Mrr=o("DeiTForImageClassification"),Err=o(" or "),_Q=a("a"),Crr=o("DeiTForImageClassificationWithTeacher"),wrr=o(" (DeiT model)"),Arr=l(),Yv=a("li"),B1e=a("strong"),Lrr=o("imagegpt"),yrr=o(" \u2014 "),uQ=a("a"),xrr=o("ImageGPTForImageClassification"),$rr=o(" (ImageGPT model)"),krr=l(),zs=a("li"),I1e=a("strong"),Srr=o("levit"),Rrr=o(" \u2014 "),bQ=a("a"),Prr=o("LevitForImageClassification"),Brr=o(" or "),vQ=a("a"),Irr=o("LevitForImageClassificationWithTeacher"),Nrr=o(" (LeViT model)"),qrr=l(),ut=a("li"),N1e=a("strong"),jrr=o("perceiver"),Drr=o(" \u2014 "),FQ=a("a"),Grr=o("PerceiverForImageClassificationLearned"),Orr=o(" or "),TQ=a("a"),Vrr=o("PerceiverForImageClassificationFourier"),Xrr=o(" or "),MQ=a("a"),zrr=o("PerceiverForImageClassificationConvProcessing"),Qrr=o(" (Perceiver model)"),Wrr=l(),Kv=a("li"),q1e=a("strong"),Hrr=o("poolformer"),Urr=o(" \u2014 "),EQ=a("a"),Jrr=o("PoolFormerForImageClassification"),Yrr=o(" (PoolFormer model)"),Krr=l(),Zv=a("li"),j1e=a("strong"),Zrr=o("regnet"),etr=o(" \u2014 "),CQ=a("a"),otr=o("RegNetForImageClassification"),rtr=o(" (RegNet model)"),ttr=l(),e3=a("li"),D1e=a("strong"),atr=o("resnet"),ntr=o(" \u2014 "),wQ=a("a"),str=o("ResNetForImageClassification"),ltr=o(" (ResNet model)"),itr=l(),o3=a("li"),G1e=a("strong"),dtr=o("segformer"),ctr=o(" \u2014 "),AQ=a("a"),ftr=o("SegformerForImageClassification"),mtr=o(" (SegFormer model)"),gtr=l(),r3=a("li"),O1e=a("strong"),htr=o("swin"),ptr=o(" \u2014 "),LQ=a("a"),_tr=o("SwinForImageClassification"),utr=o(" (Swin Transformer model)"),btr=l(),t3=a("li"),V1e=a("strong"),vtr=o("van"),Ftr=o(" \u2014 "),yQ=a("a"),Ttr=o("VanForImageClassification"),Mtr=o(" (VAN model)"),Etr=l(),a3=a("li"),X1e=a("strong"),Ctr=o("vit"),wtr=o(" \u2014 "),xQ=a("a"),Atr=o("ViTForImageClassification"),Ltr=o(" (ViT model)"),ytr=l(),n3=a("p"),xtr=o("The model is set in evaluation mode by default using "),z1e=a("code"),$tr=o("model.eval()"),ktr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q1e=a("code"),Str=o("model.train()"),Rtr=l(),F(s3.$$.fragment),MOe=l(),ud=a("h2"),l3=a("a"),W1e=a("span"),F(l8.$$.fragment),Ptr=l(),H1e=a("span"),Btr=o("AutoModelForVision2Seq"),EOe=l(),Oo=a("div"),F(i8.$$.fragment),Itr=l(),bd=a("p"),Ntr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),$Q=a("a"),qtr=o("from_pretrained()"),jtr=o(" class method or the "),kQ=a("a"),Dtr=o("from_config()"),Gtr=o(` class
method.`),Otr=l(),d8=a("p"),Vtr=o("This class cannot be instantiated directly using "),U1e=a("code"),Xtr=o("__init__()"),ztr=o(" (throws an error)."),Qtr=l(),bt=a("div"),F(c8.$$.fragment),Wtr=l(),J1e=a("p"),Htr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Utr=l(),vd=a("p"),Jtr=o(`Note:
Loading a model from its configuration file does `),Y1e=a("strong"),Ytr=o("not"),Ktr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SQ=a("a"),Ztr=o("from_pretrained()"),ear=o(" to load the model weights."),oar=l(),F(i3.$$.fragment),rar=l(),io=a("div"),F(f8.$$.fragment),tar=l(),K1e=a("p"),aar=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),nar=l(),za=a("p"),sar=o("The model class to instantiate is selected based on the "),Z1e=a("code"),lar=o("model_type"),iar=o(` property of the config object (either
passed as an argument or loaded from `),e7e=a("code"),dar=o("pretrained_model_name_or_path"),car=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o7e=a("code"),far=o("pretrained_model_name_or_path"),mar=o(":"),gar=l(),r7e=a("ul"),d3=a("li"),t7e=a("strong"),har=o("vision-encoder-decoder"),par=o(" \u2014 "),RQ=a("a"),_ar=o("VisionEncoderDecoderModel"),uar=o(" (Vision Encoder decoder model)"),bar=l(),c3=a("p"),Far=o("The model is set in evaluation mode by default using "),a7e=a("code"),Tar=o("model.eval()"),Mar=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n7e=a("code"),Ear=o("model.train()"),Car=l(),F(f3.$$.fragment),COe=l(),Fd=a("h2"),m3=a("a"),s7e=a("span"),F(m8.$$.fragment),war=l(),l7e=a("span"),Aar=o("AutoModelForVisualQuestionAnswering"),wOe=l(),Vo=a("div"),F(g8.$$.fragment),Lar=l(),Td=a("p"),yar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),PQ=a("a"),xar=o("from_pretrained()"),$ar=o(" class method or the "),BQ=a("a"),kar=o("from_config()"),Sar=o(` class
method.`),Rar=l(),h8=a("p"),Par=o("This class cannot be instantiated directly using "),i7e=a("code"),Bar=o("__init__()"),Iar=o(" (throws an error)."),Nar=l(),vt=a("div"),F(p8.$$.fragment),qar=l(),d7e=a("p"),jar=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Dar=l(),Md=a("p"),Gar=o(`Note:
Loading a model from its configuration file does `),c7e=a("strong"),Oar=o("not"),Var=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IQ=a("a"),Xar=o("from_pretrained()"),zar=o(" to load the model weights."),Qar=l(),F(g3.$$.fragment),War=l(),co=a("div"),F(_8.$$.fragment),Har=l(),f7e=a("p"),Uar=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),Jar=l(),Qa=a("p"),Yar=o("The model class to instantiate is selected based on the "),m7e=a("code"),Kar=o("model_type"),Zar=o(` property of the config object (either
passed as an argument or loaded from `),g7e=a("code"),enr=o("pretrained_model_name_or_path"),onr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h7e=a("code"),rnr=o("pretrained_model_name_or_path"),tnr=o(":"),anr=l(),p7e=a("ul"),h3=a("li"),_7e=a("strong"),nnr=o("vilt"),snr=o(" \u2014 "),NQ=a("a"),lnr=o("ViltForQuestionAnswering"),inr=o(" (ViLT model)"),dnr=l(),p3=a("p"),cnr=o("The model is set in evaluation mode by default using "),u7e=a("code"),fnr=o("model.eval()"),mnr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b7e=a("code"),gnr=o("model.train()"),hnr=l(),F(_3.$$.fragment),AOe=l(),Ed=a("h2"),u3=a("a"),v7e=a("span"),F(u8.$$.fragment),pnr=l(),F7e=a("span"),_nr=o("AutoModelForAudioClassification"),LOe=l(),Xo=a("div"),F(b8.$$.fragment),unr=l(),Cd=a("p"),bnr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),qQ=a("a"),vnr=o("from_pretrained()"),Fnr=o(" class method or the "),jQ=a("a"),Tnr=o("from_config()"),Mnr=o(` class
method.`),Enr=l(),v8=a("p"),Cnr=o("This class cannot be instantiated directly using "),T7e=a("code"),wnr=o("__init__()"),Anr=o(" (throws an error)."),Lnr=l(),Ft=a("div"),F(F8.$$.fragment),ynr=l(),M7e=a("p"),xnr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),$nr=l(),wd=a("p"),knr=o(`Note:
Loading a model from its configuration file does `),E7e=a("strong"),Snr=o("not"),Rnr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DQ=a("a"),Pnr=o("from_pretrained()"),Bnr=o(" to load the model weights."),Inr=l(),F(b3.$$.fragment),Nnr=l(),fo=a("div"),F(T8.$$.fragment),qnr=l(),C7e=a("p"),jnr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Dnr=l(),Wa=a("p"),Gnr=o("The model class to instantiate is selected based on the "),w7e=a("code"),Onr=o("model_type"),Vnr=o(` property of the config object (either
passed as an argument or loaded from `),A7e=a("code"),Xnr=o("pretrained_model_name_or_path"),znr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L7e=a("code"),Qnr=o("pretrained_model_name_or_path"),Wnr=o(":"),Hnr=l(),Pe=a("ul"),v3=a("li"),y7e=a("strong"),Unr=o("data2vec-audio"),Jnr=o(" \u2014 "),GQ=a("a"),Ynr=o("Data2VecAudioForSequenceClassification"),Knr=o(" (Data2VecAudio model)"),Znr=l(),F3=a("li"),x7e=a("strong"),esr=o("hubert"),osr=o(" \u2014 "),OQ=a("a"),rsr=o("HubertForSequenceClassification"),tsr=o(" (Hubert model)"),asr=l(),T3=a("li"),$7e=a("strong"),nsr=o("sew"),ssr=o(" \u2014 "),VQ=a("a"),lsr=o("SEWForSequenceClassification"),isr=o(" (SEW model)"),dsr=l(),M3=a("li"),k7e=a("strong"),csr=o("sew-d"),fsr=o(" \u2014 "),XQ=a("a"),msr=o("SEWDForSequenceClassification"),gsr=o(" (SEW-D model)"),hsr=l(),E3=a("li"),S7e=a("strong"),psr=o("unispeech"),_sr=o(" \u2014 "),zQ=a("a"),usr=o("UniSpeechForSequenceClassification"),bsr=o(" (UniSpeech model)"),vsr=l(),C3=a("li"),R7e=a("strong"),Fsr=o("unispeech-sat"),Tsr=o(" \u2014 "),QQ=a("a"),Msr=o("UniSpeechSatForSequenceClassification"),Esr=o(" (UniSpeechSat model)"),Csr=l(),w3=a("li"),P7e=a("strong"),wsr=o("wav2vec2"),Asr=o(" \u2014 "),WQ=a("a"),Lsr=o("Wav2Vec2ForSequenceClassification"),ysr=o(" (Wav2Vec2 model)"),xsr=l(),A3=a("li"),B7e=a("strong"),$sr=o("wav2vec2-conformer"),ksr=o(" \u2014 "),HQ=a("a"),Ssr=o("Wav2Vec2ConformerForSequenceClassification"),Rsr=o(" (Wav2Vec2-Conformer model)"),Psr=l(),L3=a("li"),I7e=a("strong"),Bsr=o("wavlm"),Isr=o(" \u2014 "),UQ=a("a"),Nsr=o("WavLMForSequenceClassification"),qsr=o(" (WavLM model)"),jsr=l(),y3=a("p"),Dsr=o("The model is set in evaluation mode by default using "),N7e=a("code"),Gsr=o("model.eval()"),Osr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q7e=a("code"),Vsr=o("model.train()"),Xsr=l(),F(x3.$$.fragment),yOe=l(),Ad=a("h2"),$3=a("a"),j7e=a("span"),F(M8.$$.fragment),zsr=l(),D7e=a("span"),Qsr=o("AutoModelForAudioFrameClassification"),xOe=l(),zo=a("div"),F(E8.$$.fragment),Wsr=l(),Ld=a("p"),Hsr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),JQ=a("a"),Usr=o("from_pretrained()"),Jsr=o(" class method or the "),YQ=a("a"),Ysr=o("from_config()"),Ksr=o(` class
method.`),Zsr=l(),C8=a("p"),elr=o("This class cannot be instantiated directly using "),G7e=a("code"),olr=o("__init__()"),rlr=o(" (throws an error)."),tlr=l(),Tt=a("div"),F(w8.$$.fragment),alr=l(),O7e=a("p"),nlr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),slr=l(),yd=a("p"),llr=o(`Note:
Loading a model from its configuration file does `),V7e=a("strong"),ilr=o("not"),dlr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KQ=a("a"),clr=o("from_pretrained()"),flr=o(" to load the model weights."),mlr=l(),F(k3.$$.fragment),glr=l(),mo=a("div"),F(A8.$$.fragment),hlr=l(),X7e=a("p"),plr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),_lr=l(),Ha=a("p"),ulr=o("The model class to instantiate is selected based on the "),z7e=a("code"),blr=o("model_type"),vlr=o(` property of the config object (either
passed as an argument or loaded from `),Q7e=a("code"),Flr=o("pretrained_model_name_or_path"),Tlr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W7e=a("code"),Mlr=o("pretrained_model_name_or_path"),Elr=o(":"),Clr=l(),et=a("ul"),S3=a("li"),H7e=a("strong"),wlr=o("data2vec-audio"),Alr=o(" \u2014 "),ZQ=a("a"),Llr=o("Data2VecAudioForAudioFrameClassification"),ylr=o(" (Data2VecAudio model)"),xlr=l(),R3=a("li"),U7e=a("strong"),$lr=o("unispeech-sat"),klr=o(" \u2014 "),eW=a("a"),Slr=o("UniSpeechSatForAudioFrameClassification"),Rlr=o(" (UniSpeechSat model)"),Plr=l(),P3=a("li"),J7e=a("strong"),Blr=o("wav2vec2"),Ilr=o(" \u2014 "),oW=a("a"),Nlr=o("Wav2Vec2ForAudioFrameClassification"),qlr=o(" (Wav2Vec2 model)"),jlr=l(),B3=a("li"),Y7e=a("strong"),Dlr=o("wav2vec2-conformer"),Glr=o(" \u2014 "),rW=a("a"),Olr=o("Wav2Vec2ConformerForAudioFrameClassification"),Vlr=o(" (Wav2Vec2-Conformer model)"),Xlr=l(),I3=a("li"),K7e=a("strong"),zlr=o("wavlm"),Qlr=o(" \u2014 "),tW=a("a"),Wlr=o("WavLMForAudioFrameClassification"),Hlr=o(" (WavLM model)"),Ulr=l(),N3=a("p"),Jlr=o("The model is set in evaluation mode by default using "),Z7e=a("code"),Ylr=o("model.eval()"),Klr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),e2e=a("code"),Zlr=o("model.train()"),eir=l(),F(q3.$$.fragment),$Oe=l(),xd=a("h2"),j3=a("a"),o2e=a("span"),F(L8.$$.fragment),oir=l(),r2e=a("span"),rir=o("AutoModelForCTC"),kOe=l(),Qo=a("div"),F(y8.$$.fragment),tir=l(),$d=a("p"),air=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),aW=a("a"),nir=o("from_pretrained()"),sir=o(" class method or the "),nW=a("a"),lir=o("from_config()"),iir=o(` class
method.`),dir=l(),x8=a("p"),cir=o("This class cannot be instantiated directly using "),t2e=a("code"),fir=o("__init__()"),mir=o(" (throws an error)."),gir=l(),Mt=a("div"),F($8.$$.fragment),hir=l(),a2e=a("p"),pir=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),_ir=l(),kd=a("p"),uir=o(`Note:
Loading a model from its configuration file does `),n2e=a("strong"),bir=o("not"),vir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sW=a("a"),Fir=o("from_pretrained()"),Tir=o(" to load the model weights."),Mir=l(),F(D3.$$.fragment),Eir=l(),go=a("div"),F(k8.$$.fragment),Cir=l(),s2e=a("p"),wir=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Air=l(),Ua=a("p"),Lir=o("The model class to instantiate is selected based on the "),l2e=a("code"),yir=o("model_type"),xir=o(` property of the config object (either
passed as an argument or loaded from `),i2e=a("code"),$ir=o("pretrained_model_name_or_path"),kir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d2e=a("code"),Sir=o("pretrained_model_name_or_path"),Rir=o(":"),Pir=l(),Le=a("ul"),G3=a("li"),c2e=a("strong"),Bir=o("data2vec-audio"),Iir=o(" \u2014 "),lW=a("a"),Nir=o("Data2VecAudioForCTC"),qir=o(" (Data2VecAudio model)"),jir=l(),O3=a("li"),f2e=a("strong"),Dir=o("hubert"),Gir=o(" \u2014 "),iW=a("a"),Oir=o("HubertForCTC"),Vir=o(" (Hubert model)"),Xir=l(),V3=a("li"),m2e=a("strong"),zir=o("mctct"),Qir=o(" \u2014 "),dW=a("a"),Wir=o("MCTCTForCTC"),Hir=o(" (M-CTC-T model)"),Uir=l(),X3=a("li"),g2e=a("strong"),Jir=o("sew"),Yir=o(" \u2014 "),cW=a("a"),Kir=o("SEWForCTC"),Zir=o(" (SEW model)"),edr=l(),z3=a("li"),h2e=a("strong"),odr=o("sew-d"),rdr=o(" \u2014 "),fW=a("a"),tdr=o("SEWDForCTC"),adr=o(" (SEW-D model)"),ndr=l(),Q3=a("li"),p2e=a("strong"),sdr=o("unispeech"),ldr=o(" \u2014 "),mW=a("a"),idr=o("UniSpeechForCTC"),ddr=o(" (UniSpeech model)"),cdr=l(),W3=a("li"),_2e=a("strong"),fdr=o("unispeech-sat"),mdr=o(" \u2014 "),gW=a("a"),gdr=o("UniSpeechSatForCTC"),hdr=o(" (UniSpeechSat model)"),pdr=l(),H3=a("li"),u2e=a("strong"),_dr=o("wav2vec2"),udr=o(" \u2014 "),hW=a("a"),bdr=o("Wav2Vec2ForCTC"),vdr=o(" (Wav2Vec2 model)"),Fdr=l(),U3=a("li"),b2e=a("strong"),Tdr=o("wav2vec2-conformer"),Mdr=o(" \u2014 "),pW=a("a"),Edr=o("Wav2Vec2ConformerForCTC"),Cdr=o(" (Wav2Vec2-Conformer model)"),wdr=l(),J3=a("li"),v2e=a("strong"),Adr=o("wavlm"),Ldr=o(" \u2014 "),_W=a("a"),ydr=o("WavLMForCTC"),xdr=o(" (WavLM model)"),$dr=l(),Y3=a("p"),kdr=o("The model is set in evaluation mode by default using "),F2e=a("code"),Sdr=o("model.eval()"),Rdr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),T2e=a("code"),Pdr=o("model.train()"),Bdr=l(),F(K3.$$.fragment),SOe=l(),Sd=a("h2"),Z3=a("a"),M2e=a("span"),F(S8.$$.fragment),Idr=l(),E2e=a("span"),Ndr=o("AutoModelForSpeechSeq2Seq"),ROe=l(),Wo=a("div"),F(R8.$$.fragment),qdr=l(),Rd=a("p"),jdr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),uW=a("a"),Ddr=o("from_pretrained()"),Gdr=o(" class method or the "),bW=a("a"),Odr=o("from_config()"),Vdr=o(` class
method.`),Xdr=l(),P8=a("p"),zdr=o("This class cannot be instantiated directly using "),C2e=a("code"),Qdr=o("__init__()"),Wdr=o(" (throws an error)."),Hdr=l(),Et=a("div"),F(B8.$$.fragment),Udr=l(),w2e=a("p"),Jdr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Ydr=l(),Pd=a("p"),Kdr=o(`Note:
Loading a model from its configuration file does `),A2e=a("strong"),Zdr=o("not"),ecr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vW=a("a"),ocr=o("from_pretrained()"),rcr=o(" to load the model weights."),tcr=l(),F(eF.$$.fragment),acr=l(),ho=a("div"),F(I8.$$.fragment),ncr=l(),L2e=a("p"),scr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),lcr=l(),Ja=a("p"),icr=o("The model class to instantiate is selected based on the "),y2e=a("code"),dcr=o("model_type"),ccr=o(` property of the config object (either
passed as an argument or loaded from `),x2e=a("code"),fcr=o("pretrained_model_name_or_path"),mcr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$2e=a("code"),gcr=o("pretrained_model_name_or_path"),hcr=o(":"),pcr=l(),N8=a("ul"),oF=a("li"),k2e=a("strong"),_cr=o("speech-encoder-decoder"),ucr=o(" \u2014 "),FW=a("a"),bcr=o("SpeechEncoderDecoderModel"),vcr=o(" (Speech Encoder decoder model)"),Fcr=l(),rF=a("li"),S2e=a("strong"),Tcr=o("speech_to_text"),Mcr=o(" \u2014 "),TW=a("a"),Ecr=o("Speech2TextForConditionalGeneration"),Ccr=o(" (Speech2Text model)"),wcr=l(),tF=a("p"),Acr=o("The model is set in evaluation mode by default using "),R2e=a("code"),Lcr=o("model.eval()"),ycr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P2e=a("code"),xcr=o("model.train()"),$cr=l(),F(aF.$$.fragment),POe=l(),Bd=a("h2"),nF=a("a"),B2e=a("span"),F(q8.$$.fragment),kcr=l(),I2e=a("span"),Scr=o("AutoModelForAudioXVector"),BOe=l(),Ho=a("div"),F(j8.$$.fragment),Rcr=l(),Id=a("p"),Pcr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),MW=a("a"),Bcr=o("from_pretrained()"),Icr=o(" class method or the "),EW=a("a"),Ncr=o("from_config()"),qcr=o(` class
method.`),jcr=l(),D8=a("p"),Dcr=o("This class cannot be instantiated directly using "),N2e=a("code"),Gcr=o("__init__()"),Ocr=o(" (throws an error)."),Vcr=l(),Ct=a("div"),F(G8.$$.fragment),Xcr=l(),q2e=a("p"),zcr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Qcr=l(),Nd=a("p"),Wcr=o(`Note:
Loading a model from its configuration file does `),j2e=a("strong"),Hcr=o("not"),Ucr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CW=a("a"),Jcr=o("from_pretrained()"),Ycr=o(" to load the model weights."),Kcr=l(),F(sF.$$.fragment),Zcr=l(),po=a("div"),F(O8.$$.fragment),efr=l(),D2e=a("p"),ofr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),rfr=l(),Ya=a("p"),tfr=o("The model class to instantiate is selected based on the "),G2e=a("code"),afr=o("model_type"),nfr=o(` property of the config object (either
passed as an argument or loaded from `),O2e=a("code"),sfr=o("pretrained_model_name_or_path"),lfr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V2e=a("code"),ifr=o("pretrained_model_name_or_path"),dfr=o(":"),cfr=l(),ot=a("ul"),lF=a("li"),X2e=a("strong"),ffr=o("data2vec-audio"),mfr=o(" \u2014 "),wW=a("a"),gfr=o("Data2VecAudioForXVector"),hfr=o(" (Data2VecAudio model)"),pfr=l(),iF=a("li"),z2e=a("strong"),_fr=o("unispeech-sat"),ufr=o(" \u2014 "),AW=a("a"),bfr=o("UniSpeechSatForXVector"),vfr=o(" (UniSpeechSat model)"),Ffr=l(),dF=a("li"),Q2e=a("strong"),Tfr=o("wav2vec2"),Mfr=o(" \u2014 "),LW=a("a"),Efr=o("Wav2Vec2ForXVector"),Cfr=o(" (Wav2Vec2 model)"),wfr=l(),cF=a("li"),W2e=a("strong"),Afr=o("wav2vec2-conformer"),Lfr=o(" \u2014 "),yW=a("a"),yfr=o("Wav2Vec2ConformerForXVector"),xfr=o(" (Wav2Vec2-Conformer model)"),$fr=l(),fF=a("li"),H2e=a("strong"),kfr=o("wavlm"),Sfr=o(" \u2014 "),xW=a("a"),Rfr=o("WavLMForXVector"),Pfr=o(" (WavLM model)"),Bfr=l(),mF=a("p"),Ifr=o("The model is set in evaluation mode by default using "),U2e=a("code"),Nfr=o("model.eval()"),qfr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),J2e=a("code"),jfr=o("model.train()"),Dfr=l(),F(gF.$$.fragment),IOe=l(),qd=a("h2"),hF=a("a"),Y2e=a("span"),F(V8.$$.fragment),Gfr=l(),K2e=a("span"),Ofr=o("AutoModelForMaskedImageModeling"),NOe=l(),Uo=a("div"),F(X8.$$.fragment),Vfr=l(),jd=a("p"),Xfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),$W=a("a"),zfr=o("from_pretrained()"),Qfr=o(" class method or the "),kW=a("a"),Wfr=o("from_config()"),Hfr=o(` class
method.`),Ufr=l(),z8=a("p"),Jfr=o("This class cannot be instantiated directly using "),Z2e=a("code"),Yfr=o("__init__()"),Kfr=o(" (throws an error)."),Zfr=l(),wt=a("div"),F(Q8.$$.fragment),emr=l(),ebe=a("p"),omr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),rmr=l(),Dd=a("p"),tmr=o(`Note:
Loading a model from its configuration file does `),obe=a("strong"),amr=o("not"),nmr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SW=a("a"),smr=o("from_pretrained()"),lmr=o(" to load the model weights."),imr=l(),F(pF.$$.fragment),dmr=l(),_o=a("div"),F(W8.$$.fragment),cmr=l(),rbe=a("p"),fmr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),mmr=l(),Ka=a("p"),gmr=o("The model class to instantiate is selected based on the "),tbe=a("code"),hmr=o("model_type"),pmr=o(` property of the config object (either
passed as an argument or loaded from `),abe=a("code"),_mr=o("pretrained_model_name_or_path"),umr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nbe=a("code"),bmr=o("pretrained_model_name_or_path"),vmr=o(":"),Fmr=l(),Gd=a("ul"),_F=a("li"),sbe=a("strong"),Tmr=o("deit"),Mmr=o(" \u2014 "),RW=a("a"),Emr=o("DeiTForMaskedImageModeling"),Cmr=o(" (DeiT model)"),wmr=l(),uF=a("li"),lbe=a("strong"),Amr=o("swin"),Lmr=o(" \u2014 "),PW=a("a"),ymr=o("SwinForMaskedImageModeling"),xmr=o(" (Swin Transformer model)"),$mr=l(),bF=a("li"),ibe=a("strong"),kmr=o("vit"),Smr=o(" \u2014 "),BW=a("a"),Rmr=o("ViTForMaskedImageModeling"),Pmr=o(" (ViT model)"),Bmr=l(),vF=a("p"),Imr=o("The model is set in evaluation mode by default using "),dbe=a("code"),Nmr=o("model.eval()"),qmr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cbe=a("code"),jmr=o("model.train()"),Dmr=l(),F(FF.$$.fragment),qOe=l(),Od=a("h2"),TF=a("a"),fbe=a("span"),F(H8.$$.fragment),Gmr=l(),mbe=a("span"),Omr=o("AutoModelForObjectDetection"),jOe=l(),Jo=a("div"),F(U8.$$.fragment),Vmr=l(),Vd=a("p"),Xmr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),IW=a("a"),zmr=o("from_pretrained()"),Qmr=o(" class method or the "),NW=a("a"),Wmr=o("from_config()"),Hmr=o(` class
method.`),Umr=l(),J8=a("p"),Jmr=o("This class cannot be instantiated directly using "),gbe=a("code"),Ymr=o("__init__()"),Kmr=o(" (throws an error)."),Zmr=l(),At=a("div"),F(Y8.$$.fragment),egr=l(),hbe=a("p"),ogr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),rgr=l(),Xd=a("p"),tgr=o(`Note:
Loading a model from its configuration file does `),pbe=a("strong"),agr=o("not"),ngr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qW=a("a"),sgr=o("from_pretrained()"),lgr=o(" to load the model weights."),igr=l(),F(MF.$$.fragment),dgr=l(),uo=a("div"),F(K8.$$.fragment),cgr=l(),_be=a("p"),fgr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),mgr=l(),Za=a("p"),ggr=o("The model class to instantiate is selected based on the "),ube=a("code"),hgr=o("model_type"),pgr=o(` property of the config object (either
passed as an argument or loaded from `),bbe=a("code"),_gr=o("pretrained_model_name_or_path"),ugr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vbe=a("code"),bgr=o("pretrained_model_name_or_path"),vgr=o(":"),Fgr=l(),Z8=a("ul"),EF=a("li"),Fbe=a("strong"),Tgr=o("detr"),Mgr=o(" \u2014 "),jW=a("a"),Egr=o("DetrForObjectDetection"),Cgr=o(" (DETR model)"),wgr=l(),CF=a("li"),Tbe=a("strong"),Agr=o("yolos"),Lgr=o(" \u2014 "),DW=a("a"),ygr=o("YolosForObjectDetection"),xgr=o(" (YOLOS model)"),$gr=l(),wF=a("p"),kgr=o("The model is set in evaluation mode by default using "),Mbe=a("code"),Sgr=o("model.eval()"),Rgr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ebe=a("code"),Pgr=o("model.train()"),Bgr=l(),F(AF.$$.fragment),DOe=l(),zd=a("h2"),LF=a("a"),Cbe=a("span"),F(e9.$$.fragment),Igr=l(),wbe=a("span"),Ngr=o("AutoModelForImageSegmentation"),GOe=l(),Yo=a("div"),F(o9.$$.fragment),qgr=l(),Qd=a("p"),jgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),GW=a("a"),Dgr=o("from_pretrained()"),Ggr=o(" class method or the "),OW=a("a"),Ogr=o("from_config()"),Vgr=o(` class
method.`),Xgr=l(),r9=a("p"),zgr=o("This class cannot be instantiated directly using "),Abe=a("code"),Qgr=o("__init__()"),Wgr=o(" (throws an error)."),Hgr=l(),Lt=a("div"),F(t9.$$.fragment),Ugr=l(),Lbe=a("p"),Jgr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Ygr=l(),Wd=a("p"),Kgr=o(`Note:
Loading a model from its configuration file does `),ybe=a("strong"),Zgr=o("not"),ehr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VW=a("a"),ohr=o("from_pretrained()"),rhr=o(" to load the model weights."),thr=l(),F(yF.$$.fragment),ahr=l(),bo=a("div"),F(a9.$$.fragment),nhr=l(),xbe=a("p"),shr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),lhr=l(),en=a("p"),ihr=o("The model class to instantiate is selected based on the "),$be=a("code"),dhr=o("model_type"),chr=o(` property of the config object (either
passed as an argument or loaded from `),kbe=a("code"),fhr=o("pretrained_model_name_or_path"),mhr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sbe=a("code"),ghr=o("pretrained_model_name_or_path"),hhr=o(":"),phr=l(),Rbe=a("ul"),xF=a("li"),Pbe=a("strong"),_hr=o("detr"),uhr=o(" \u2014 "),XW=a("a"),bhr=o("DetrForSegmentation"),vhr=o(" (DETR model)"),Fhr=l(),$F=a("p"),Thr=o("The model is set in evaluation mode by default using "),Bbe=a("code"),Mhr=o("model.eval()"),Ehr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ibe=a("code"),Chr=o("model.train()"),whr=l(),F(kF.$$.fragment),OOe=l(),Hd=a("h2"),SF=a("a"),Nbe=a("span"),F(n9.$$.fragment),Ahr=l(),qbe=a("span"),Lhr=o("AutoModelForSemanticSegmentation"),VOe=l(),Ko=a("div"),F(s9.$$.fragment),yhr=l(),Ud=a("p"),xhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),zW=a("a"),$hr=o("from_pretrained()"),khr=o(" class method or the "),QW=a("a"),Shr=o("from_config()"),Rhr=o(` class
method.`),Phr=l(),l9=a("p"),Bhr=o("This class cannot be instantiated directly using "),jbe=a("code"),Ihr=o("__init__()"),Nhr=o(" (throws an error)."),qhr=l(),yt=a("div"),F(i9.$$.fragment),jhr=l(),Dbe=a("p"),Dhr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Ghr=l(),Jd=a("p"),Ohr=o(`Note:
Loading a model from its configuration file does `),Gbe=a("strong"),Vhr=o("not"),Xhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WW=a("a"),zhr=o("from_pretrained()"),Qhr=o(" to load the model weights."),Whr=l(),F(RF.$$.fragment),Hhr=l(),vo=a("div"),F(d9.$$.fragment),Uhr=l(),Obe=a("p"),Jhr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Yhr=l(),on=a("p"),Khr=o("The model class to instantiate is selected based on the "),Vbe=a("code"),Zhr=o("model_type"),epr=o(` property of the config object (either
passed as an argument or loaded from `),Xbe=a("code"),opr=o("pretrained_model_name_or_path"),rpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zbe=a("code"),tpr=o("pretrained_model_name_or_path"),apr=o(":"),npr=l(),rn=a("ul"),PF=a("li"),Qbe=a("strong"),spr=o("beit"),lpr=o(" \u2014 "),HW=a("a"),ipr=o("BeitForSemanticSegmentation"),dpr=o(" (BEiT model)"),cpr=l(),BF=a("li"),Wbe=a("strong"),fpr=o("data2vec-vision"),mpr=o(" \u2014 "),UW=a("a"),gpr=o("Data2VecVisionForSemanticSegmentation"),hpr=o(" (Data2VecVision model)"),ppr=l(),IF=a("li"),Hbe=a("strong"),_pr=o("dpt"),upr=o(" \u2014 "),JW=a("a"),bpr=o("DPTForSemanticSegmentation"),vpr=o(" (DPT model)"),Fpr=l(),NF=a("li"),Ube=a("strong"),Tpr=o("segformer"),Mpr=o(" \u2014 "),YW=a("a"),Epr=o("SegformerForSemanticSegmentation"),Cpr=o(" (SegFormer model)"),wpr=l(),qF=a("p"),Apr=o("The model is set in evaluation mode by default using "),Jbe=a("code"),Lpr=o("model.eval()"),ypr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ybe=a("code"),xpr=o("model.train()"),$pr=l(),F(jF.$$.fragment),XOe=l(),Yd=a("h2"),DF=a("a"),Kbe=a("span"),F(c9.$$.fragment),kpr=l(),Zbe=a("span"),Spr=o("AutoModelForInstanceSegmentation"),zOe=l(),Zo=a("div"),F(f9.$$.fragment),Rpr=l(),Kd=a("p"),Ppr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),KW=a("a"),Bpr=o("from_pretrained()"),Ipr=o(" class method or the "),ZW=a("a"),Npr=o("from_config()"),qpr=o(` class
method.`),jpr=l(),m9=a("p"),Dpr=o("This class cannot be instantiated directly using "),e5e=a("code"),Gpr=o("__init__()"),Opr=o(" (throws an error)."),Vpr=l(),xt=a("div"),F(g9.$$.fragment),Xpr=l(),o5e=a("p"),zpr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Qpr=l(),Zd=a("p"),Wpr=o(`Note:
Loading a model from its configuration file does `),r5e=a("strong"),Hpr=o("not"),Upr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eH=a("a"),Jpr=o("from_pretrained()"),Ypr=o(" to load the model weights."),Kpr=l(),F(GF.$$.fragment),Zpr=l(),Fo=a("div"),F(h9.$$.fragment),e_r=l(),t5e=a("p"),o_r=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),r_r=l(),tn=a("p"),t_r=o("The model class to instantiate is selected based on the "),a5e=a("code"),a_r=o("model_type"),n_r=o(` property of the config object (either
passed as an argument or loaded from `),n5e=a("code"),s_r=o("pretrained_model_name_or_path"),l_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s5e=a("code"),i_r=o("pretrained_model_name_or_path"),d_r=o(":"),c_r=l(),l5e=a("ul"),OF=a("li"),i5e=a("strong"),f_r=o("maskformer"),m_r=o(" \u2014 "),oH=a("a"),g_r=o("MaskFormerForInstanceSegmentation"),h_r=o(" (MaskFormer model)"),p_r=l(),VF=a("p"),__r=o("The model is set in evaluation mode by default using "),d5e=a("code"),u_r=o("model.eval()"),b_r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c5e=a("code"),v_r=o("model.train()"),F_r=l(),F(XF.$$.fragment),QOe=l(),ec=a("h2"),zF=a("a"),f5e=a("span"),F(p9.$$.fragment),T_r=l(),m5e=a("span"),M_r=o("TFAutoModel"),WOe=l(),er=a("div"),F(_9.$$.fragment),E_r=l(),oc=a("p"),C_r=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),rH=a("a"),w_r=o("from_pretrained()"),A_r=o(" class method or the "),tH=a("a"),L_r=o("from_config()"),y_r=o(` class
method.`),x_r=l(),u9=a("p"),$_r=o("This class cannot be instantiated directly using "),g5e=a("code"),k_r=o("__init__()"),S_r=o(" (throws an error)."),R_r=l(),$t=a("div"),F(b9.$$.fragment),P_r=l(),h5e=a("p"),B_r=o("Instantiates one of the base model classes of the library from a configuration."),I_r=l(),rc=a("p"),N_r=o(`Note:
Loading a model from its configuration file does `),p5e=a("strong"),q_r=o("not"),j_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aH=a("a"),D_r=o("from_pretrained()"),G_r=o(" to load the model weights."),O_r=l(),F(QF.$$.fragment),V_r=l(),yr=a("div"),F(v9.$$.fragment),X_r=l(),_5e=a("p"),z_r=o("Instantiate one of the base model classes of the library from a pretrained model."),Q_r=l(),an=a("p"),W_r=o("The model class to instantiate is selected based on the "),u5e=a("code"),H_r=o("model_type"),U_r=o(` property of the config object (either
passed as an argument or loaded from `),b5e=a("code"),J_r=o("pretrained_model_name_or_path"),Y_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v5e=a("code"),K_r=o("pretrained_model_name_or_path"),Z_r=o(":"),eur=l(),j=a("ul"),WF=a("li"),F5e=a("strong"),our=o("albert"),rur=o(" \u2014 "),nH=a("a"),tur=o("TFAlbertModel"),aur=o(" (ALBERT model)"),nur=l(),HF=a("li"),T5e=a("strong"),sur=o("bart"),lur=o(" \u2014 "),sH=a("a"),iur=o("TFBartModel"),dur=o(" (BART model)"),cur=l(),UF=a("li"),M5e=a("strong"),fur=o("bert"),mur=o(" \u2014 "),lH=a("a"),gur=o("TFBertModel"),hur=o(" (BERT model)"),pur=l(),JF=a("li"),E5e=a("strong"),_ur=o("blenderbot"),uur=o(" \u2014 "),iH=a("a"),bur=o("TFBlenderbotModel"),vur=o(" (Blenderbot model)"),Fur=l(),YF=a("li"),C5e=a("strong"),Tur=o("blenderbot-small"),Mur=o(" \u2014 "),dH=a("a"),Eur=o("TFBlenderbotSmallModel"),Cur=o(" (BlenderbotSmall model)"),wur=l(),KF=a("li"),w5e=a("strong"),Aur=o("camembert"),Lur=o(" \u2014 "),cH=a("a"),yur=o("TFCamembertModel"),xur=o(" (CamemBERT model)"),$ur=l(),ZF=a("li"),A5e=a("strong"),kur=o("clip"),Sur=o(" \u2014 "),fH=a("a"),Rur=o("TFCLIPModel"),Pur=o(" (CLIP model)"),Bur=l(),eT=a("li"),L5e=a("strong"),Iur=o("convbert"),Nur=o(" \u2014 "),mH=a("a"),qur=o("TFConvBertModel"),jur=o(" (ConvBERT model)"),Dur=l(),oT=a("li"),y5e=a("strong"),Gur=o("convnext"),Our=o(" \u2014 "),gH=a("a"),Vur=o("TFConvNextModel"),Xur=o(" (ConvNeXT model)"),zur=l(),rT=a("li"),x5e=a("strong"),Qur=o("ctrl"),Wur=o(" \u2014 "),hH=a("a"),Hur=o("TFCTRLModel"),Uur=o(" (CTRL model)"),Jur=l(),tT=a("li"),$5e=a("strong"),Yur=o("data2vec-vision"),Kur=o(" \u2014 "),pH=a("a"),Zur=o("TFData2VecVisionModel"),e1r=o(" (Data2VecVision model)"),o1r=l(),aT=a("li"),k5e=a("strong"),r1r=o("deberta"),t1r=o(" \u2014 "),_H=a("a"),a1r=o("TFDebertaModel"),n1r=o(" (DeBERTa model)"),s1r=l(),nT=a("li"),S5e=a("strong"),l1r=o("deberta-v2"),i1r=o(" \u2014 "),uH=a("a"),d1r=o("TFDebertaV2Model"),c1r=o(" (DeBERTa-v2 model)"),f1r=l(),sT=a("li"),R5e=a("strong"),m1r=o("distilbert"),g1r=o(" \u2014 "),bH=a("a"),h1r=o("TFDistilBertModel"),p1r=o(" (DistilBERT model)"),_1r=l(),lT=a("li"),P5e=a("strong"),u1r=o("dpr"),b1r=o(" \u2014 "),vH=a("a"),v1r=o("TFDPRQuestionEncoder"),F1r=o(" (DPR model)"),T1r=l(),iT=a("li"),B5e=a("strong"),M1r=o("electra"),E1r=o(" \u2014 "),FH=a("a"),C1r=o("TFElectraModel"),w1r=o(" (ELECTRA model)"),A1r=l(),dT=a("li"),I5e=a("strong"),L1r=o("flaubert"),y1r=o(" \u2014 "),TH=a("a"),x1r=o("TFFlaubertModel"),$1r=o(" (FlauBERT model)"),k1r=l(),Qs=a("li"),N5e=a("strong"),S1r=o("funnel"),R1r=o(" \u2014 "),MH=a("a"),P1r=o("TFFunnelModel"),B1r=o(" or "),EH=a("a"),I1r=o("TFFunnelBaseModel"),N1r=o(" (Funnel Transformer model)"),q1r=l(),cT=a("li"),q5e=a("strong"),j1r=o("gpt2"),D1r=o(" \u2014 "),CH=a("a"),G1r=o("TFGPT2Model"),O1r=o(" (OpenAI GPT-2 model)"),V1r=l(),fT=a("li"),j5e=a("strong"),X1r=o("gptj"),z1r=o(" \u2014 "),wH=a("a"),Q1r=o("TFGPTJModel"),W1r=o(" (GPT-J model)"),H1r=l(),mT=a("li"),D5e=a("strong"),U1r=o("hubert"),J1r=o(" \u2014 "),AH=a("a"),Y1r=o("TFHubertModel"),K1r=o(" (Hubert model)"),Z1r=l(),gT=a("li"),G5e=a("strong"),e7r=o("layoutlm"),o7r=o(" \u2014 "),LH=a("a"),r7r=o("TFLayoutLMModel"),t7r=o(" (LayoutLM model)"),a7r=l(),hT=a("li"),O5e=a("strong"),n7r=o("led"),s7r=o(" \u2014 "),yH=a("a"),l7r=o("TFLEDModel"),i7r=o(" (LED model)"),d7r=l(),pT=a("li"),V5e=a("strong"),c7r=o("longformer"),f7r=o(" \u2014 "),xH=a("a"),m7r=o("TFLongformerModel"),g7r=o(" (Longformer model)"),h7r=l(),_T=a("li"),X5e=a("strong"),p7r=o("lxmert"),_7r=o(" \u2014 "),$H=a("a"),u7r=o("TFLxmertModel"),b7r=o(" (LXMERT model)"),v7r=l(),uT=a("li"),z5e=a("strong"),F7r=o("marian"),T7r=o(" \u2014 "),kH=a("a"),M7r=o("TFMarianModel"),E7r=o(" (Marian model)"),C7r=l(),bT=a("li"),Q5e=a("strong"),w7r=o("mbart"),A7r=o(" \u2014 "),SH=a("a"),L7r=o("TFMBartModel"),y7r=o(" (mBART model)"),x7r=l(),vT=a("li"),W5e=a("strong"),$7r=o("mobilebert"),k7r=o(" \u2014 "),RH=a("a"),S7r=o("TFMobileBertModel"),R7r=o(" (MobileBERT model)"),P7r=l(),FT=a("li"),H5e=a("strong"),B7r=o("mpnet"),I7r=o(" \u2014 "),PH=a("a"),N7r=o("TFMPNetModel"),q7r=o(" (MPNet model)"),j7r=l(),TT=a("li"),U5e=a("strong"),D7r=o("mt5"),G7r=o(" \u2014 "),BH=a("a"),O7r=o("TFMT5Model"),V7r=o(" (MT5 model)"),X7r=l(),MT=a("li"),J5e=a("strong"),z7r=o("openai-gpt"),Q7r=o(" \u2014 "),IH=a("a"),W7r=o("TFOpenAIGPTModel"),H7r=o(" (OpenAI GPT model)"),U7r=l(),ET=a("li"),Y5e=a("strong"),J7r=o("opt"),Y7r=o(" \u2014 "),NH=a("a"),K7r=o("TFOPTModel"),Z7r=o(" (OPT model)"),e2r=l(),CT=a("li"),K5e=a("strong"),o2r=o("pegasus"),r2r=o(" \u2014 "),qH=a("a"),t2r=o("TFPegasusModel"),a2r=o(" (Pegasus model)"),n2r=l(),wT=a("li"),Z5e=a("strong"),s2r=o("rembert"),l2r=o(" \u2014 "),jH=a("a"),i2r=o("TFRemBertModel"),d2r=o(" (RemBERT model)"),c2r=l(),AT=a("li"),eve=a("strong"),f2r=o("roberta"),m2r=o(" \u2014 "),DH=a("a"),g2r=o("TFRobertaModel"),h2r=o(" (RoBERTa model)"),p2r=l(),LT=a("li"),ove=a("strong"),_2r=o("roformer"),u2r=o(" \u2014 "),GH=a("a"),b2r=o("TFRoFormerModel"),v2r=o(" (RoFormer model)"),F2r=l(),yT=a("li"),rve=a("strong"),T2r=o("speech_to_text"),M2r=o(" \u2014 "),OH=a("a"),E2r=o("TFSpeech2TextModel"),C2r=o(" (Speech2Text model)"),w2r=l(),xT=a("li"),tve=a("strong"),A2r=o("swin"),L2r=o(" \u2014 "),VH=a("a"),y2r=o("TFSwinModel"),x2r=o(" (Swin Transformer model)"),$2r=l(),$T=a("li"),ave=a("strong"),k2r=o("t5"),S2r=o(" \u2014 "),XH=a("a"),R2r=o("TFT5Model"),P2r=o(" (T5 model)"),B2r=l(),kT=a("li"),nve=a("strong"),I2r=o("tapas"),N2r=o(" \u2014 "),zH=a("a"),q2r=o("TFTapasModel"),j2r=o(" (TAPAS model)"),D2r=l(),ST=a("li"),sve=a("strong"),G2r=o("transfo-xl"),O2r=o(" \u2014 "),QH=a("a"),V2r=o("TFTransfoXLModel"),X2r=o(" (Transformer-XL model)"),z2r=l(),RT=a("li"),lve=a("strong"),Q2r=o("vit"),W2r=o(" \u2014 "),WH=a("a"),H2r=o("TFViTModel"),U2r=o(" (ViT model)"),J2r=l(),PT=a("li"),ive=a("strong"),Y2r=o("vit_mae"),K2r=o(" \u2014 "),HH=a("a"),Z2r=o("TFViTMAEModel"),ebr=o(" (ViTMAE model)"),obr=l(),BT=a("li"),dve=a("strong"),rbr=o("wav2vec2"),tbr=o(" \u2014 "),UH=a("a"),abr=o("TFWav2Vec2Model"),nbr=o(" (Wav2Vec2 model)"),sbr=l(),IT=a("li"),cve=a("strong"),lbr=o("xlm"),ibr=o(" \u2014 "),JH=a("a"),dbr=o("TFXLMModel"),cbr=o(" (XLM model)"),fbr=l(),NT=a("li"),fve=a("strong"),mbr=o("xlm-roberta"),gbr=o(" \u2014 "),YH=a("a"),hbr=o("TFXLMRobertaModel"),pbr=o(" (XLM-RoBERTa model)"),_br=l(),qT=a("li"),mve=a("strong"),ubr=o("xlnet"),bbr=o(" \u2014 "),KH=a("a"),vbr=o("TFXLNetModel"),Fbr=o(" (XLNet model)"),Tbr=l(),F(jT.$$.fragment),HOe=l(),tc=a("h2"),DT=a("a"),gve=a("span"),F(F9.$$.fragment),Mbr=l(),hve=a("span"),Ebr=o("TFAutoModelForPreTraining"),UOe=l(),or=a("div"),F(T9.$$.fragment),Cbr=l(),ac=a("p"),wbr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ZH=a("a"),Abr=o("from_pretrained()"),Lbr=o(" class method or the "),eU=a("a"),ybr=o("from_config()"),xbr=o(` class
method.`),$br=l(),M9=a("p"),kbr=o("This class cannot be instantiated directly using "),pve=a("code"),Sbr=o("__init__()"),Rbr=o(" (throws an error)."),Pbr=l(),kt=a("div"),F(E9.$$.fragment),Bbr=l(),_ve=a("p"),Ibr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Nbr=l(),nc=a("p"),qbr=o(`Note:
Loading a model from its configuration file does `),uve=a("strong"),jbr=o("not"),Dbr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oU=a("a"),Gbr=o("from_pretrained()"),Obr=o(" to load the model weights."),Vbr=l(),F(GT.$$.fragment),Xbr=l(),xr=a("div"),F(C9.$$.fragment),zbr=l(),bve=a("p"),Qbr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Wbr=l(),nn=a("p"),Hbr=o("The model class to instantiate is selected based on the "),vve=a("code"),Ubr=o("model_type"),Jbr=o(` property of the config object (either
passed as an argument or loaded from `),Fve=a("code"),Ybr=o("pretrained_model_name_or_path"),Kbr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tve=a("code"),Zbr=o("pretrained_model_name_or_path"),e5r=o(":"),o5r=l(),se=a("ul"),OT=a("li"),Mve=a("strong"),r5r=o("albert"),t5r=o(" \u2014 "),rU=a("a"),a5r=o("TFAlbertForPreTraining"),n5r=o(" (ALBERT model)"),s5r=l(),VT=a("li"),Eve=a("strong"),l5r=o("bart"),i5r=o(" \u2014 "),tU=a("a"),d5r=o("TFBartForConditionalGeneration"),c5r=o(" (BART model)"),f5r=l(),XT=a("li"),Cve=a("strong"),m5r=o("bert"),g5r=o(" \u2014 "),aU=a("a"),h5r=o("TFBertForPreTraining"),p5r=o(" (BERT model)"),_5r=l(),zT=a("li"),wve=a("strong"),u5r=o("camembert"),b5r=o(" \u2014 "),nU=a("a"),v5r=o("TFCamembertForMaskedLM"),F5r=o(" (CamemBERT model)"),T5r=l(),QT=a("li"),Ave=a("strong"),M5r=o("ctrl"),E5r=o(" \u2014 "),sU=a("a"),C5r=o("TFCTRLLMHeadModel"),w5r=o(" (CTRL model)"),A5r=l(),WT=a("li"),Lve=a("strong"),L5r=o("distilbert"),y5r=o(" \u2014 "),lU=a("a"),x5r=o("TFDistilBertForMaskedLM"),$5r=o(" (DistilBERT model)"),k5r=l(),HT=a("li"),yve=a("strong"),S5r=o("electra"),R5r=o(" \u2014 "),iU=a("a"),P5r=o("TFElectraForPreTraining"),B5r=o(" (ELECTRA model)"),I5r=l(),UT=a("li"),xve=a("strong"),N5r=o("flaubert"),q5r=o(" \u2014 "),dU=a("a"),j5r=o("TFFlaubertWithLMHeadModel"),D5r=o(" (FlauBERT model)"),G5r=l(),JT=a("li"),$ve=a("strong"),O5r=o("funnel"),V5r=o(" \u2014 "),cU=a("a"),X5r=o("TFFunnelForPreTraining"),z5r=o(" (Funnel Transformer model)"),Q5r=l(),YT=a("li"),kve=a("strong"),W5r=o("gpt2"),H5r=o(" \u2014 "),fU=a("a"),U5r=o("TFGPT2LMHeadModel"),J5r=o(" (OpenAI GPT-2 model)"),Y5r=l(),KT=a("li"),Sve=a("strong"),K5r=o("layoutlm"),Z5r=o(" \u2014 "),mU=a("a"),evr=o("TFLayoutLMForMaskedLM"),ovr=o(" (LayoutLM model)"),rvr=l(),ZT=a("li"),Rve=a("strong"),tvr=o("lxmert"),avr=o(" \u2014 "),gU=a("a"),nvr=o("TFLxmertForPreTraining"),svr=o(" (LXMERT model)"),lvr=l(),eM=a("li"),Pve=a("strong"),ivr=o("mobilebert"),dvr=o(" \u2014 "),hU=a("a"),cvr=o("TFMobileBertForPreTraining"),fvr=o(" (MobileBERT model)"),mvr=l(),oM=a("li"),Bve=a("strong"),gvr=o("mpnet"),hvr=o(" \u2014 "),pU=a("a"),pvr=o("TFMPNetForMaskedLM"),_vr=o(" (MPNet model)"),uvr=l(),rM=a("li"),Ive=a("strong"),bvr=o("openai-gpt"),vvr=o(" \u2014 "),_U=a("a"),Fvr=o("TFOpenAIGPTLMHeadModel"),Tvr=o(" (OpenAI GPT model)"),Mvr=l(),tM=a("li"),Nve=a("strong"),Evr=o("roberta"),Cvr=o(" \u2014 "),uU=a("a"),wvr=o("TFRobertaForMaskedLM"),Avr=o(" (RoBERTa model)"),Lvr=l(),aM=a("li"),qve=a("strong"),yvr=o("t5"),xvr=o(" \u2014 "),bU=a("a"),$vr=o("TFT5ForConditionalGeneration"),kvr=o(" (T5 model)"),Svr=l(),nM=a("li"),jve=a("strong"),Rvr=o("tapas"),Pvr=o(" \u2014 "),vU=a("a"),Bvr=o("TFTapasForMaskedLM"),Ivr=o(" (TAPAS model)"),Nvr=l(),sM=a("li"),Dve=a("strong"),qvr=o("transfo-xl"),jvr=o(" \u2014 "),FU=a("a"),Dvr=o("TFTransfoXLLMHeadModel"),Gvr=o(" (Transformer-XL model)"),Ovr=l(),lM=a("li"),Gve=a("strong"),Vvr=o("vit_mae"),Xvr=o(" \u2014 "),TU=a("a"),zvr=o("TFViTMAEForPreTraining"),Qvr=o(" (ViTMAE model)"),Wvr=l(),iM=a("li"),Ove=a("strong"),Hvr=o("xlm"),Uvr=o(" \u2014 "),MU=a("a"),Jvr=o("TFXLMWithLMHeadModel"),Yvr=o(" (XLM model)"),Kvr=l(),dM=a("li"),Vve=a("strong"),Zvr=o("xlm-roberta"),e3r=o(" \u2014 "),EU=a("a"),o3r=o("TFXLMRobertaForMaskedLM"),r3r=o(" (XLM-RoBERTa model)"),t3r=l(),cM=a("li"),Xve=a("strong"),a3r=o("xlnet"),n3r=o(" \u2014 "),CU=a("a"),s3r=o("TFXLNetLMHeadModel"),l3r=o(" (XLNet model)"),i3r=l(),F(fM.$$.fragment),JOe=l(),sc=a("h2"),mM=a("a"),zve=a("span"),F(w9.$$.fragment),d3r=l(),Qve=a("span"),c3r=o("TFAutoModelForCausalLM"),YOe=l(),rr=a("div"),F(A9.$$.fragment),f3r=l(),lc=a("p"),m3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),wU=a("a"),g3r=o("from_pretrained()"),h3r=o(" class method or the "),AU=a("a"),p3r=o("from_config()"),_3r=o(` class
method.`),u3r=l(),L9=a("p"),b3r=o("This class cannot be instantiated directly using "),Wve=a("code"),v3r=o("__init__()"),F3r=o(" (throws an error)."),T3r=l(),St=a("div"),F(y9.$$.fragment),M3r=l(),Hve=a("p"),E3r=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),C3r=l(),ic=a("p"),w3r=o(`Note:
Loading a model from its configuration file does `),Uve=a("strong"),A3r=o("not"),L3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LU=a("a"),y3r=o("from_pretrained()"),x3r=o(" to load the model weights."),$3r=l(),F(gM.$$.fragment),k3r=l(),$r=a("div"),F(x9.$$.fragment),S3r=l(),Jve=a("p"),R3r=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),P3r=l(),sn=a("p"),B3r=o("The model class to instantiate is selected based on the "),Yve=a("code"),I3r=o("model_type"),N3r=o(` property of the config object (either
passed as an argument or loaded from `),Kve=a("code"),q3r=o("pretrained_model_name_or_path"),j3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zve=a("code"),D3r=o("pretrained_model_name_or_path"),G3r=o(":"),O3r=l(),Me=a("ul"),hM=a("li"),e3e=a("strong"),V3r=o("bert"),X3r=o(" \u2014 "),yU=a("a"),z3r=o("TFBertLMHeadModel"),Q3r=o(" (BERT model)"),W3r=l(),pM=a("li"),o3e=a("strong"),H3r=o("camembert"),U3r=o(" \u2014 "),xU=a("a"),J3r=o("TFCamembertForCausalLM"),Y3r=o(" (CamemBERT model)"),K3r=l(),_M=a("li"),r3e=a("strong"),Z3r=o("ctrl"),eFr=o(" \u2014 "),$U=a("a"),oFr=o("TFCTRLLMHeadModel"),rFr=o(" (CTRL model)"),tFr=l(),uM=a("li"),t3e=a("strong"),aFr=o("gpt2"),nFr=o(" \u2014 "),kU=a("a"),sFr=o("TFGPT2LMHeadModel"),lFr=o(" (OpenAI GPT-2 model)"),iFr=l(),bM=a("li"),a3e=a("strong"),dFr=o("gptj"),cFr=o(" \u2014 "),SU=a("a"),fFr=o("TFGPTJForCausalLM"),mFr=o(" (GPT-J model)"),gFr=l(),vM=a("li"),n3e=a("strong"),hFr=o("openai-gpt"),pFr=o(" \u2014 "),RU=a("a"),_Fr=o("TFOpenAIGPTLMHeadModel"),uFr=o(" (OpenAI GPT model)"),bFr=l(),FM=a("li"),s3e=a("strong"),vFr=o("opt"),FFr=o(" \u2014 "),PU=a("a"),TFr=o("TFOPTForCausalLM"),MFr=o(" (OPT model)"),EFr=l(),TM=a("li"),l3e=a("strong"),CFr=o("rembert"),wFr=o(" \u2014 "),BU=a("a"),AFr=o("TFRemBertForCausalLM"),LFr=o(" (RemBERT model)"),yFr=l(),MM=a("li"),i3e=a("strong"),xFr=o("roberta"),$Fr=o(" \u2014 "),IU=a("a"),kFr=o("TFRobertaForCausalLM"),SFr=o(" (RoBERTa model)"),RFr=l(),EM=a("li"),d3e=a("strong"),PFr=o("roformer"),BFr=o(" \u2014 "),NU=a("a"),IFr=o("TFRoFormerForCausalLM"),NFr=o(" (RoFormer model)"),qFr=l(),CM=a("li"),c3e=a("strong"),jFr=o("transfo-xl"),DFr=o(" \u2014 "),qU=a("a"),GFr=o("TFTransfoXLLMHeadModel"),OFr=o(" (Transformer-XL model)"),VFr=l(),wM=a("li"),f3e=a("strong"),XFr=o("xlm"),zFr=o(" \u2014 "),jU=a("a"),QFr=o("TFXLMWithLMHeadModel"),WFr=o(" (XLM model)"),HFr=l(),AM=a("li"),m3e=a("strong"),UFr=o("xlnet"),JFr=o(" \u2014 "),DU=a("a"),YFr=o("TFXLNetLMHeadModel"),KFr=o(" (XLNet model)"),ZFr=l(),F(LM.$$.fragment),KOe=l(),dc=a("h2"),yM=a("a"),g3e=a("span"),F($9.$$.fragment),eTr=l(),h3e=a("span"),oTr=o("TFAutoModelForImageClassification"),ZOe=l(),tr=a("div"),F(k9.$$.fragment),rTr=l(),cc=a("p"),tTr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),GU=a("a"),aTr=o("from_pretrained()"),nTr=o(" class method or the "),OU=a("a"),sTr=o("from_config()"),lTr=o(` class
method.`),iTr=l(),S9=a("p"),dTr=o("This class cannot be instantiated directly using "),p3e=a("code"),cTr=o("__init__()"),fTr=o(" (throws an error)."),mTr=l(),Rt=a("div"),F(R9.$$.fragment),gTr=l(),_3e=a("p"),hTr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),pTr=l(),fc=a("p"),_Tr=o(`Note:
Loading a model from its configuration file does `),u3e=a("strong"),uTr=o("not"),bTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VU=a("a"),vTr=o("from_pretrained()"),FTr=o(" to load the model weights."),TTr=l(),F(xM.$$.fragment),MTr=l(),kr=a("div"),F(P9.$$.fragment),ETr=l(),b3e=a("p"),CTr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),wTr=l(),ln=a("p"),ATr=o("The model class to instantiate is selected based on the "),v3e=a("code"),LTr=o("model_type"),yTr=o(` property of the config object (either
passed as an argument or loaded from `),F3e=a("code"),xTr=o("pretrained_model_name_or_path"),$Tr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T3e=a("code"),kTr=o("pretrained_model_name_or_path"),STr=o(":"),RTr=l(),dn=a("ul"),$M=a("li"),M3e=a("strong"),PTr=o("convnext"),BTr=o(" \u2014 "),XU=a("a"),ITr=o("TFConvNextForImageClassification"),NTr=o(" (ConvNeXT model)"),qTr=l(),kM=a("li"),E3e=a("strong"),jTr=o("data2vec-vision"),DTr=o(" \u2014 "),zU=a("a"),GTr=o("TFData2VecVisionForImageClassification"),OTr=o(" (Data2VecVision model)"),VTr=l(),SM=a("li"),C3e=a("strong"),XTr=o("swin"),zTr=o(" \u2014 "),QU=a("a"),QTr=o("TFSwinForImageClassification"),WTr=o(" (Swin Transformer model)"),HTr=l(),RM=a("li"),w3e=a("strong"),UTr=o("vit"),JTr=o(" \u2014 "),WU=a("a"),YTr=o("TFViTForImageClassification"),KTr=o(" (ViT model)"),ZTr=l(),F(PM.$$.fragment),eVe=l(),mc=a("h2"),BM=a("a"),A3e=a("span"),F(B9.$$.fragment),eMr=l(),L3e=a("span"),oMr=o("TFAutoModelForMaskedLM"),oVe=l(),ar=a("div"),F(I9.$$.fragment),rMr=l(),gc=a("p"),tMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),HU=a("a"),aMr=o("from_pretrained()"),nMr=o(" class method or the "),UU=a("a"),sMr=o("from_config()"),lMr=o(` class
method.`),iMr=l(),N9=a("p"),dMr=o("This class cannot be instantiated directly using "),y3e=a("code"),cMr=o("__init__()"),fMr=o(" (throws an error)."),mMr=l(),Pt=a("div"),F(q9.$$.fragment),gMr=l(),x3e=a("p"),hMr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),pMr=l(),hc=a("p"),_Mr=o(`Note:
Loading a model from its configuration file does `),$3e=a("strong"),uMr=o("not"),bMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JU=a("a"),vMr=o("from_pretrained()"),FMr=o(" to load the model weights."),TMr=l(),F(IM.$$.fragment),MMr=l(),Sr=a("div"),F(j9.$$.fragment),EMr=l(),k3e=a("p"),CMr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),wMr=l(),cn=a("p"),AMr=o("The model class to instantiate is selected based on the "),S3e=a("code"),LMr=o("model_type"),yMr=o(` property of the config object (either
passed as an argument or loaded from `),R3e=a("code"),xMr=o("pretrained_model_name_or_path"),$Mr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P3e=a("code"),kMr=o("pretrained_model_name_or_path"),SMr=o(":"),RMr=l(),ie=a("ul"),NM=a("li"),B3e=a("strong"),PMr=o("albert"),BMr=o(" \u2014 "),YU=a("a"),IMr=o("TFAlbertForMaskedLM"),NMr=o(" (ALBERT model)"),qMr=l(),qM=a("li"),I3e=a("strong"),jMr=o("bert"),DMr=o(" \u2014 "),KU=a("a"),GMr=o("TFBertForMaskedLM"),OMr=o(" (BERT model)"),VMr=l(),jM=a("li"),N3e=a("strong"),XMr=o("camembert"),zMr=o(" \u2014 "),ZU=a("a"),QMr=o("TFCamembertForMaskedLM"),WMr=o(" (CamemBERT model)"),HMr=l(),DM=a("li"),q3e=a("strong"),UMr=o("convbert"),JMr=o(" \u2014 "),eJ=a("a"),YMr=o("TFConvBertForMaskedLM"),KMr=o(" (ConvBERT model)"),ZMr=l(),GM=a("li"),j3e=a("strong"),eEr=o("deberta"),oEr=o(" \u2014 "),oJ=a("a"),rEr=o("TFDebertaForMaskedLM"),tEr=o(" (DeBERTa model)"),aEr=l(),OM=a("li"),D3e=a("strong"),nEr=o("deberta-v2"),sEr=o(" \u2014 "),rJ=a("a"),lEr=o("TFDebertaV2ForMaskedLM"),iEr=o(" (DeBERTa-v2 model)"),dEr=l(),VM=a("li"),G3e=a("strong"),cEr=o("distilbert"),fEr=o(" \u2014 "),tJ=a("a"),mEr=o("TFDistilBertForMaskedLM"),gEr=o(" (DistilBERT model)"),hEr=l(),XM=a("li"),O3e=a("strong"),pEr=o("electra"),_Er=o(" \u2014 "),aJ=a("a"),uEr=o("TFElectraForMaskedLM"),bEr=o(" (ELECTRA model)"),vEr=l(),zM=a("li"),V3e=a("strong"),FEr=o("flaubert"),TEr=o(" \u2014 "),nJ=a("a"),MEr=o("TFFlaubertWithLMHeadModel"),EEr=o(" (FlauBERT model)"),CEr=l(),QM=a("li"),X3e=a("strong"),wEr=o("funnel"),AEr=o(" \u2014 "),sJ=a("a"),LEr=o("TFFunnelForMaskedLM"),yEr=o(" (Funnel Transformer model)"),xEr=l(),WM=a("li"),z3e=a("strong"),$Er=o("layoutlm"),kEr=o(" \u2014 "),lJ=a("a"),SEr=o("TFLayoutLMForMaskedLM"),REr=o(" (LayoutLM model)"),PEr=l(),HM=a("li"),Q3e=a("strong"),BEr=o("longformer"),IEr=o(" \u2014 "),iJ=a("a"),NEr=o("TFLongformerForMaskedLM"),qEr=o(" (Longformer model)"),jEr=l(),UM=a("li"),W3e=a("strong"),DEr=o("mobilebert"),GEr=o(" \u2014 "),dJ=a("a"),OEr=o("TFMobileBertForMaskedLM"),VEr=o(" (MobileBERT model)"),XEr=l(),JM=a("li"),H3e=a("strong"),zEr=o("mpnet"),QEr=o(" \u2014 "),cJ=a("a"),WEr=o("TFMPNetForMaskedLM"),HEr=o(" (MPNet model)"),UEr=l(),YM=a("li"),U3e=a("strong"),JEr=o("rembert"),YEr=o(" \u2014 "),fJ=a("a"),KEr=o("TFRemBertForMaskedLM"),ZEr=o(" (RemBERT model)"),e4r=l(),KM=a("li"),J3e=a("strong"),o4r=o("roberta"),r4r=o(" \u2014 "),mJ=a("a"),t4r=o("TFRobertaForMaskedLM"),a4r=o(" (RoBERTa model)"),n4r=l(),ZM=a("li"),Y3e=a("strong"),s4r=o("roformer"),l4r=o(" \u2014 "),gJ=a("a"),i4r=o("TFRoFormerForMaskedLM"),d4r=o(" (RoFormer model)"),c4r=l(),eE=a("li"),K3e=a("strong"),f4r=o("tapas"),m4r=o(" \u2014 "),hJ=a("a"),g4r=o("TFTapasForMaskedLM"),h4r=o(" (TAPAS model)"),p4r=l(),oE=a("li"),Z3e=a("strong"),_4r=o("xlm"),u4r=o(" \u2014 "),pJ=a("a"),b4r=o("TFXLMWithLMHeadModel"),v4r=o(" (XLM model)"),F4r=l(),rE=a("li"),eFe=a("strong"),T4r=o("xlm-roberta"),M4r=o(" \u2014 "),_J=a("a"),E4r=o("TFXLMRobertaForMaskedLM"),C4r=o(" (XLM-RoBERTa model)"),w4r=l(),F(tE.$$.fragment),rVe=l(),pc=a("h2"),aE=a("a"),oFe=a("span"),F(D9.$$.fragment),A4r=l(),rFe=a("span"),L4r=o("TFAutoModelForSeq2SeqLM"),tVe=l(),nr=a("div"),F(G9.$$.fragment),y4r=l(),_c=a("p"),x4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),uJ=a("a"),$4r=o("from_pretrained()"),k4r=o(" class method or the "),bJ=a("a"),S4r=o("from_config()"),R4r=o(` class
method.`),P4r=l(),O9=a("p"),B4r=o("This class cannot be instantiated directly using "),tFe=a("code"),I4r=o("__init__()"),N4r=o(" (throws an error)."),q4r=l(),Bt=a("div"),F(V9.$$.fragment),j4r=l(),aFe=a("p"),D4r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),G4r=l(),uc=a("p"),O4r=o(`Note:
Loading a model from its configuration file does `),nFe=a("strong"),V4r=o("not"),X4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vJ=a("a"),z4r=o("from_pretrained()"),Q4r=o(" to load the model weights."),W4r=l(),F(nE.$$.fragment),H4r=l(),Rr=a("div"),F(X9.$$.fragment),U4r=l(),sFe=a("p"),J4r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Y4r=l(),fn=a("p"),K4r=o("The model class to instantiate is selected based on the "),lFe=a("code"),Z4r=o("model_type"),eCr=o(` property of the config object (either
passed as an argument or loaded from `),iFe=a("code"),oCr=o("pretrained_model_name_or_path"),rCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dFe=a("code"),tCr=o("pretrained_model_name_or_path"),aCr=o(":"),nCr=l(),ye=a("ul"),sE=a("li"),cFe=a("strong"),sCr=o("bart"),lCr=o(" \u2014 "),FJ=a("a"),iCr=o("TFBartForConditionalGeneration"),dCr=o(" (BART model)"),cCr=l(),lE=a("li"),fFe=a("strong"),fCr=o("blenderbot"),mCr=o(" \u2014 "),TJ=a("a"),gCr=o("TFBlenderbotForConditionalGeneration"),hCr=o(" (Blenderbot model)"),pCr=l(),iE=a("li"),mFe=a("strong"),_Cr=o("blenderbot-small"),uCr=o(" \u2014 "),MJ=a("a"),bCr=o("TFBlenderbotSmallForConditionalGeneration"),vCr=o(" (BlenderbotSmall model)"),FCr=l(),dE=a("li"),gFe=a("strong"),TCr=o("encoder-decoder"),MCr=o(" \u2014 "),EJ=a("a"),ECr=o("TFEncoderDecoderModel"),CCr=o(" (Encoder decoder model)"),wCr=l(),cE=a("li"),hFe=a("strong"),ACr=o("led"),LCr=o(" \u2014 "),CJ=a("a"),yCr=o("TFLEDForConditionalGeneration"),xCr=o(" (LED model)"),$Cr=l(),fE=a("li"),pFe=a("strong"),kCr=o("marian"),SCr=o(" \u2014 "),wJ=a("a"),RCr=o("TFMarianMTModel"),PCr=o(" (Marian model)"),BCr=l(),mE=a("li"),_Fe=a("strong"),ICr=o("mbart"),NCr=o(" \u2014 "),AJ=a("a"),qCr=o("TFMBartForConditionalGeneration"),jCr=o(" (mBART model)"),DCr=l(),gE=a("li"),uFe=a("strong"),GCr=o("mt5"),OCr=o(" \u2014 "),LJ=a("a"),VCr=o("TFMT5ForConditionalGeneration"),XCr=o(" (MT5 model)"),zCr=l(),hE=a("li"),bFe=a("strong"),QCr=o("pegasus"),WCr=o(" \u2014 "),yJ=a("a"),HCr=o("TFPegasusForConditionalGeneration"),UCr=o(" (Pegasus model)"),JCr=l(),pE=a("li"),vFe=a("strong"),YCr=o("t5"),KCr=o(" \u2014 "),xJ=a("a"),ZCr=o("TFT5ForConditionalGeneration"),e0r=o(" (T5 model)"),o0r=l(),F(_E.$$.fragment),aVe=l(),bc=a("h2"),uE=a("a"),FFe=a("span"),F(z9.$$.fragment),r0r=l(),TFe=a("span"),t0r=o("TFAutoModelForSequenceClassification"),nVe=l(),sr=a("div"),F(Q9.$$.fragment),a0r=l(),vc=a("p"),n0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),$J=a("a"),s0r=o("from_pretrained()"),l0r=o(" class method or the "),kJ=a("a"),i0r=o("from_config()"),d0r=o(` class
method.`),c0r=l(),W9=a("p"),f0r=o("This class cannot be instantiated directly using "),MFe=a("code"),m0r=o("__init__()"),g0r=o(" (throws an error)."),h0r=l(),It=a("div"),F(H9.$$.fragment),p0r=l(),EFe=a("p"),_0r=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),u0r=l(),Fc=a("p"),b0r=o(`Note:
Loading a model from its configuration file does `),CFe=a("strong"),v0r=o("not"),F0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SJ=a("a"),T0r=o("from_pretrained()"),M0r=o(" to load the model weights."),E0r=l(),F(bE.$$.fragment),C0r=l(),Pr=a("div"),F(U9.$$.fragment),w0r=l(),wFe=a("p"),A0r=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),L0r=l(),mn=a("p"),y0r=o("The model class to instantiate is selected based on the "),AFe=a("code"),x0r=o("model_type"),$0r=o(` property of the config object (either
passed as an argument or loaded from `),LFe=a("code"),k0r=o("pretrained_model_name_or_path"),S0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yFe=a("code"),R0r=o("pretrained_model_name_or_path"),P0r=o(":"),B0r=l(),te=a("ul"),vE=a("li"),xFe=a("strong"),I0r=o("albert"),N0r=o(" \u2014 "),RJ=a("a"),q0r=o("TFAlbertForSequenceClassification"),j0r=o(" (ALBERT model)"),D0r=l(),FE=a("li"),$Fe=a("strong"),G0r=o("bert"),O0r=o(" \u2014 "),PJ=a("a"),V0r=o("TFBertForSequenceClassification"),X0r=o(" (BERT model)"),z0r=l(),TE=a("li"),kFe=a("strong"),Q0r=o("camembert"),W0r=o(" \u2014 "),BJ=a("a"),H0r=o("TFCamembertForSequenceClassification"),U0r=o(" (CamemBERT model)"),J0r=l(),ME=a("li"),SFe=a("strong"),Y0r=o("convbert"),K0r=o(" \u2014 "),IJ=a("a"),Z0r=o("TFConvBertForSequenceClassification"),ewr=o(" (ConvBERT model)"),owr=l(),EE=a("li"),RFe=a("strong"),rwr=o("ctrl"),twr=o(" \u2014 "),NJ=a("a"),awr=o("TFCTRLForSequenceClassification"),nwr=o(" (CTRL model)"),swr=l(),CE=a("li"),PFe=a("strong"),lwr=o("deberta"),iwr=o(" \u2014 "),qJ=a("a"),dwr=o("TFDebertaForSequenceClassification"),cwr=o(" (DeBERTa model)"),fwr=l(),wE=a("li"),BFe=a("strong"),mwr=o("deberta-v2"),gwr=o(" \u2014 "),jJ=a("a"),hwr=o("TFDebertaV2ForSequenceClassification"),pwr=o(" (DeBERTa-v2 model)"),_wr=l(),AE=a("li"),IFe=a("strong"),uwr=o("distilbert"),bwr=o(" \u2014 "),DJ=a("a"),vwr=o("TFDistilBertForSequenceClassification"),Fwr=o(" (DistilBERT model)"),Twr=l(),LE=a("li"),NFe=a("strong"),Mwr=o("electra"),Ewr=o(" \u2014 "),GJ=a("a"),Cwr=o("TFElectraForSequenceClassification"),wwr=o(" (ELECTRA model)"),Awr=l(),yE=a("li"),qFe=a("strong"),Lwr=o("flaubert"),ywr=o(" \u2014 "),OJ=a("a"),xwr=o("TFFlaubertForSequenceClassification"),$wr=o(" (FlauBERT model)"),kwr=l(),xE=a("li"),jFe=a("strong"),Swr=o("funnel"),Rwr=o(" \u2014 "),VJ=a("a"),Pwr=o("TFFunnelForSequenceClassification"),Bwr=o(" (Funnel Transformer model)"),Iwr=l(),$E=a("li"),DFe=a("strong"),Nwr=o("gpt2"),qwr=o(" \u2014 "),XJ=a("a"),jwr=o("TFGPT2ForSequenceClassification"),Dwr=o(" (OpenAI GPT-2 model)"),Gwr=l(),kE=a("li"),GFe=a("strong"),Owr=o("gptj"),Vwr=o(" \u2014 "),zJ=a("a"),Xwr=o("TFGPTJForSequenceClassification"),zwr=o(" (GPT-J model)"),Qwr=l(),SE=a("li"),OFe=a("strong"),Wwr=o("layoutlm"),Hwr=o(" \u2014 "),QJ=a("a"),Uwr=o("TFLayoutLMForSequenceClassification"),Jwr=o(" (LayoutLM model)"),Ywr=l(),RE=a("li"),VFe=a("strong"),Kwr=o("longformer"),Zwr=o(" \u2014 "),WJ=a("a"),eAr=o("TFLongformerForSequenceClassification"),oAr=o(" (Longformer model)"),rAr=l(),PE=a("li"),XFe=a("strong"),tAr=o("mobilebert"),aAr=o(" \u2014 "),HJ=a("a"),nAr=o("TFMobileBertForSequenceClassification"),sAr=o(" (MobileBERT model)"),lAr=l(),BE=a("li"),zFe=a("strong"),iAr=o("mpnet"),dAr=o(" \u2014 "),UJ=a("a"),cAr=o("TFMPNetForSequenceClassification"),fAr=o(" (MPNet model)"),mAr=l(),IE=a("li"),QFe=a("strong"),gAr=o("openai-gpt"),hAr=o(" \u2014 "),JJ=a("a"),pAr=o("TFOpenAIGPTForSequenceClassification"),_Ar=o(" (OpenAI GPT model)"),uAr=l(),NE=a("li"),WFe=a("strong"),bAr=o("rembert"),vAr=o(" \u2014 "),YJ=a("a"),FAr=o("TFRemBertForSequenceClassification"),TAr=o(" (RemBERT model)"),MAr=l(),qE=a("li"),HFe=a("strong"),EAr=o("roberta"),CAr=o(" \u2014 "),KJ=a("a"),wAr=o("TFRobertaForSequenceClassification"),AAr=o(" (RoBERTa model)"),LAr=l(),jE=a("li"),UFe=a("strong"),yAr=o("roformer"),xAr=o(" \u2014 "),ZJ=a("a"),$Ar=o("TFRoFormerForSequenceClassification"),kAr=o(" (RoFormer model)"),SAr=l(),DE=a("li"),JFe=a("strong"),RAr=o("tapas"),PAr=o(" \u2014 "),eY=a("a"),BAr=o("TFTapasForSequenceClassification"),IAr=o(" (TAPAS model)"),NAr=l(),GE=a("li"),YFe=a("strong"),qAr=o("transfo-xl"),jAr=o(" \u2014 "),oY=a("a"),DAr=o("TFTransfoXLForSequenceClassification"),GAr=o(" (Transformer-XL model)"),OAr=l(),OE=a("li"),KFe=a("strong"),VAr=o("xlm"),XAr=o(" \u2014 "),rY=a("a"),zAr=o("TFXLMForSequenceClassification"),QAr=o(" (XLM model)"),WAr=l(),VE=a("li"),ZFe=a("strong"),HAr=o("xlm-roberta"),UAr=o(" \u2014 "),tY=a("a"),JAr=o("TFXLMRobertaForSequenceClassification"),YAr=o(" (XLM-RoBERTa model)"),KAr=l(),XE=a("li"),eTe=a("strong"),ZAr=o("xlnet"),e6r=o(" \u2014 "),aY=a("a"),o6r=o("TFXLNetForSequenceClassification"),r6r=o(" (XLNet model)"),t6r=l(),F(zE.$$.fragment),sVe=l(),Tc=a("h2"),QE=a("a"),oTe=a("span"),F(J9.$$.fragment),a6r=l(),rTe=a("span"),n6r=o("TFAutoModelForMultipleChoice"),lVe=l(),lr=a("div"),F(Y9.$$.fragment),s6r=l(),Mc=a("p"),l6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),nY=a("a"),i6r=o("from_pretrained()"),d6r=o(" class method or the "),sY=a("a"),c6r=o("from_config()"),f6r=o(` class
method.`),m6r=l(),K9=a("p"),g6r=o("This class cannot be instantiated directly using "),tTe=a("code"),h6r=o("__init__()"),p6r=o(" (throws an error)."),_6r=l(),Nt=a("div"),F(Z9.$$.fragment),u6r=l(),aTe=a("p"),b6r=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),v6r=l(),Ec=a("p"),F6r=o(`Note:
Loading a model from its configuration file does `),nTe=a("strong"),T6r=o("not"),M6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lY=a("a"),E6r=o("from_pretrained()"),C6r=o(" to load the model weights."),w6r=l(),F(WE.$$.fragment),A6r=l(),Br=a("div"),F(ex.$$.fragment),L6r=l(),sTe=a("p"),y6r=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),x6r=l(),gn=a("p"),$6r=o("The model class to instantiate is selected based on the "),lTe=a("code"),k6r=o("model_type"),S6r=o(` property of the config object (either
passed as an argument or loaded from `),iTe=a("code"),R6r=o("pretrained_model_name_or_path"),P6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dTe=a("code"),B6r=o("pretrained_model_name_or_path"),I6r=o(":"),N6r=l(),_e=a("ul"),HE=a("li"),cTe=a("strong"),q6r=o("albert"),j6r=o(" \u2014 "),iY=a("a"),D6r=o("TFAlbertForMultipleChoice"),G6r=o(" (ALBERT model)"),O6r=l(),UE=a("li"),fTe=a("strong"),V6r=o("bert"),X6r=o(" \u2014 "),dY=a("a"),z6r=o("TFBertForMultipleChoice"),Q6r=o(" (BERT model)"),W6r=l(),JE=a("li"),mTe=a("strong"),H6r=o("camembert"),U6r=o(" \u2014 "),cY=a("a"),J6r=o("TFCamembertForMultipleChoice"),Y6r=o(" (CamemBERT model)"),K6r=l(),YE=a("li"),gTe=a("strong"),Z6r=o("convbert"),eLr=o(" \u2014 "),fY=a("a"),oLr=o("TFConvBertForMultipleChoice"),rLr=o(" (ConvBERT model)"),tLr=l(),KE=a("li"),hTe=a("strong"),aLr=o("distilbert"),nLr=o(" \u2014 "),mY=a("a"),sLr=o("TFDistilBertForMultipleChoice"),lLr=o(" (DistilBERT model)"),iLr=l(),ZE=a("li"),pTe=a("strong"),dLr=o("electra"),cLr=o(" \u2014 "),gY=a("a"),fLr=o("TFElectraForMultipleChoice"),mLr=o(" (ELECTRA model)"),gLr=l(),e4=a("li"),_Te=a("strong"),hLr=o("flaubert"),pLr=o(" \u2014 "),hY=a("a"),_Lr=o("TFFlaubertForMultipleChoice"),uLr=o(" (FlauBERT model)"),bLr=l(),o4=a("li"),uTe=a("strong"),vLr=o("funnel"),FLr=o(" \u2014 "),pY=a("a"),TLr=o("TFFunnelForMultipleChoice"),MLr=o(" (Funnel Transformer model)"),ELr=l(),r4=a("li"),bTe=a("strong"),CLr=o("longformer"),wLr=o(" \u2014 "),_Y=a("a"),ALr=o("TFLongformerForMultipleChoice"),LLr=o(" (Longformer model)"),yLr=l(),t4=a("li"),vTe=a("strong"),xLr=o("mobilebert"),$Lr=o(" \u2014 "),uY=a("a"),kLr=o("TFMobileBertForMultipleChoice"),SLr=o(" (MobileBERT model)"),RLr=l(),a4=a("li"),FTe=a("strong"),PLr=o("mpnet"),BLr=o(" \u2014 "),bY=a("a"),ILr=o("TFMPNetForMultipleChoice"),NLr=o(" (MPNet model)"),qLr=l(),n4=a("li"),TTe=a("strong"),jLr=o("rembert"),DLr=o(" \u2014 "),vY=a("a"),GLr=o("TFRemBertForMultipleChoice"),OLr=o(" (RemBERT model)"),VLr=l(),s4=a("li"),MTe=a("strong"),XLr=o("roberta"),zLr=o(" \u2014 "),FY=a("a"),QLr=o("TFRobertaForMultipleChoice"),WLr=o(" (RoBERTa model)"),HLr=l(),l4=a("li"),ETe=a("strong"),ULr=o("roformer"),JLr=o(" \u2014 "),TY=a("a"),YLr=o("TFRoFormerForMultipleChoice"),KLr=o(" (RoFormer model)"),ZLr=l(),i4=a("li"),CTe=a("strong"),eyr=o("xlm"),oyr=o(" \u2014 "),MY=a("a"),ryr=o("TFXLMForMultipleChoice"),tyr=o(" (XLM model)"),ayr=l(),d4=a("li"),wTe=a("strong"),nyr=o("xlm-roberta"),syr=o(" \u2014 "),EY=a("a"),lyr=o("TFXLMRobertaForMultipleChoice"),iyr=o(" (XLM-RoBERTa model)"),dyr=l(),c4=a("li"),ATe=a("strong"),cyr=o("xlnet"),fyr=o(" \u2014 "),CY=a("a"),myr=o("TFXLNetForMultipleChoice"),gyr=o(" (XLNet model)"),hyr=l(),F(f4.$$.fragment),iVe=l(),Cc=a("h2"),m4=a("a"),LTe=a("span"),F(ox.$$.fragment),pyr=l(),yTe=a("span"),_yr=o("TFAutoModelForNextSentencePrediction"),dVe=l(),ir=a("div"),F(rx.$$.fragment),uyr=l(),wc=a("p"),byr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),wY=a("a"),vyr=o("from_pretrained()"),Fyr=o(" class method or the "),AY=a("a"),Tyr=o("from_config()"),Myr=o(` class
method.`),Eyr=l(),tx=a("p"),Cyr=o("This class cannot be instantiated directly using "),xTe=a("code"),wyr=o("__init__()"),Ayr=o(" (throws an error)."),Lyr=l(),qt=a("div"),F(ax.$$.fragment),yyr=l(),$Te=a("p"),xyr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),$yr=l(),Ac=a("p"),kyr=o(`Note:
Loading a model from its configuration file does `),kTe=a("strong"),Syr=o("not"),Ryr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LY=a("a"),Pyr=o("from_pretrained()"),Byr=o(" to load the model weights."),Iyr=l(),F(g4.$$.fragment),Nyr=l(),Ir=a("div"),F(nx.$$.fragment),qyr=l(),STe=a("p"),jyr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Dyr=l(),hn=a("p"),Gyr=o("The model class to instantiate is selected based on the "),RTe=a("code"),Oyr=o("model_type"),Vyr=o(` property of the config object (either
passed as an argument or loaded from `),PTe=a("code"),Xyr=o("pretrained_model_name_or_path"),zyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BTe=a("code"),Qyr=o("pretrained_model_name_or_path"),Wyr=o(":"),Hyr=l(),sx=a("ul"),h4=a("li"),ITe=a("strong"),Uyr=o("bert"),Jyr=o(" \u2014 "),yY=a("a"),Yyr=o("TFBertForNextSentencePrediction"),Kyr=o(" (BERT model)"),Zyr=l(),p4=a("li"),NTe=a("strong"),e8r=o("mobilebert"),o8r=o(" \u2014 "),xY=a("a"),r8r=o("TFMobileBertForNextSentencePrediction"),t8r=o(" (MobileBERT model)"),a8r=l(),F(_4.$$.fragment),cVe=l(),Lc=a("h2"),u4=a("a"),qTe=a("span"),F(lx.$$.fragment),n8r=l(),jTe=a("span"),s8r=o("TFAutoModelForTableQuestionAnswering"),fVe=l(),dr=a("div"),F(ix.$$.fragment),l8r=l(),yc=a("p"),i8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),$Y=a("a"),d8r=o("from_pretrained()"),c8r=o(" class method or the "),kY=a("a"),f8r=o("from_config()"),m8r=o(` class
method.`),g8r=l(),dx=a("p"),h8r=o("This class cannot be instantiated directly using "),DTe=a("code"),p8r=o("__init__()"),_8r=o(" (throws an error)."),u8r=l(),jt=a("div"),F(cx.$$.fragment),b8r=l(),GTe=a("p"),v8r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),F8r=l(),xc=a("p"),T8r=o(`Note:
Loading a model from its configuration file does `),OTe=a("strong"),M8r=o("not"),E8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SY=a("a"),C8r=o("from_pretrained()"),w8r=o(" to load the model weights."),A8r=l(),F(b4.$$.fragment),L8r=l(),Nr=a("div"),F(fx.$$.fragment),y8r=l(),VTe=a("p"),x8r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),$8r=l(),pn=a("p"),k8r=o("The model class to instantiate is selected based on the "),XTe=a("code"),S8r=o("model_type"),R8r=o(` property of the config object (either
passed as an argument or loaded from `),zTe=a("code"),P8r=o("pretrained_model_name_or_path"),B8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QTe=a("code"),I8r=o("pretrained_model_name_or_path"),N8r=o(":"),q8r=l(),WTe=a("ul"),v4=a("li"),HTe=a("strong"),j8r=o("tapas"),D8r=o(" \u2014 "),RY=a("a"),G8r=o("TFTapasForQuestionAnswering"),O8r=o(" (TAPAS model)"),V8r=l(),F(F4.$$.fragment),mVe=l(),$c=a("h2"),T4=a("a"),UTe=a("span"),F(mx.$$.fragment),X8r=l(),JTe=a("span"),z8r=o("TFAutoModelForTokenClassification"),gVe=l(),cr=a("div"),F(gx.$$.fragment),Q8r=l(),kc=a("p"),W8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),PY=a("a"),H8r=o("from_pretrained()"),U8r=o(" class method or the "),BY=a("a"),J8r=o("from_config()"),Y8r=o(` class
method.`),K8r=l(),hx=a("p"),Z8r=o("This class cannot be instantiated directly using "),YTe=a("code"),e9r=o("__init__()"),o9r=o(" (throws an error)."),r9r=l(),Dt=a("div"),F(px.$$.fragment),t9r=l(),KTe=a("p"),a9r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),n9r=l(),Sc=a("p"),s9r=o(`Note:
Loading a model from its configuration file does `),ZTe=a("strong"),l9r=o("not"),i9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=a("a"),d9r=o("from_pretrained()"),c9r=o(" to load the model weights."),f9r=l(),F(M4.$$.fragment),m9r=l(),qr=a("div"),F(_x.$$.fragment),g9r=l(),eMe=a("p"),h9r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),p9r=l(),_n=a("p"),_9r=o("The model class to instantiate is selected based on the "),oMe=a("code"),u9r=o("model_type"),b9r=o(` property of the config object (either
passed as an argument or loaded from `),rMe=a("code"),v9r=o("pretrained_model_name_or_path"),F9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tMe=a("code"),T9r=o("pretrained_model_name_or_path"),M9r=o(":"),E9r=l(),de=a("ul"),E4=a("li"),aMe=a("strong"),C9r=o("albert"),w9r=o(" \u2014 "),NY=a("a"),A9r=o("TFAlbertForTokenClassification"),L9r=o(" (ALBERT model)"),y9r=l(),C4=a("li"),nMe=a("strong"),x9r=o("bert"),$9r=o(" \u2014 "),qY=a("a"),k9r=o("TFBertForTokenClassification"),S9r=o(" (BERT model)"),R9r=l(),w4=a("li"),sMe=a("strong"),P9r=o("camembert"),B9r=o(" \u2014 "),jY=a("a"),I9r=o("TFCamembertForTokenClassification"),N9r=o(" (CamemBERT model)"),q9r=l(),A4=a("li"),lMe=a("strong"),j9r=o("convbert"),D9r=o(" \u2014 "),DY=a("a"),G9r=o("TFConvBertForTokenClassification"),O9r=o(" (ConvBERT model)"),V9r=l(),L4=a("li"),iMe=a("strong"),X9r=o("deberta"),z9r=o(" \u2014 "),GY=a("a"),Q9r=o("TFDebertaForTokenClassification"),W9r=o(" (DeBERTa model)"),H9r=l(),y4=a("li"),dMe=a("strong"),U9r=o("deberta-v2"),J9r=o(" \u2014 "),OY=a("a"),Y9r=o("TFDebertaV2ForTokenClassification"),K9r=o(" (DeBERTa-v2 model)"),Z9r=l(),x4=a("li"),cMe=a("strong"),exr=o("distilbert"),oxr=o(" \u2014 "),VY=a("a"),rxr=o("TFDistilBertForTokenClassification"),txr=o(" (DistilBERT model)"),axr=l(),$4=a("li"),fMe=a("strong"),nxr=o("electra"),sxr=o(" \u2014 "),XY=a("a"),lxr=o("TFElectraForTokenClassification"),ixr=o(" (ELECTRA model)"),dxr=l(),k4=a("li"),mMe=a("strong"),cxr=o("flaubert"),fxr=o(" \u2014 "),zY=a("a"),mxr=o("TFFlaubertForTokenClassification"),gxr=o(" (FlauBERT model)"),hxr=l(),S4=a("li"),gMe=a("strong"),pxr=o("funnel"),_xr=o(" \u2014 "),QY=a("a"),uxr=o("TFFunnelForTokenClassification"),bxr=o(" (Funnel Transformer model)"),vxr=l(),R4=a("li"),hMe=a("strong"),Fxr=o("layoutlm"),Txr=o(" \u2014 "),WY=a("a"),Mxr=o("TFLayoutLMForTokenClassification"),Exr=o(" (LayoutLM model)"),Cxr=l(),P4=a("li"),pMe=a("strong"),wxr=o("longformer"),Axr=o(" \u2014 "),HY=a("a"),Lxr=o("TFLongformerForTokenClassification"),yxr=o(" (Longformer model)"),xxr=l(),B4=a("li"),_Me=a("strong"),$xr=o("mobilebert"),kxr=o(" \u2014 "),UY=a("a"),Sxr=o("TFMobileBertForTokenClassification"),Rxr=o(" (MobileBERT model)"),Pxr=l(),I4=a("li"),uMe=a("strong"),Bxr=o("mpnet"),Ixr=o(" \u2014 "),JY=a("a"),Nxr=o("TFMPNetForTokenClassification"),qxr=o(" (MPNet model)"),jxr=l(),N4=a("li"),bMe=a("strong"),Dxr=o("rembert"),Gxr=o(" \u2014 "),YY=a("a"),Oxr=o("TFRemBertForTokenClassification"),Vxr=o(" (RemBERT model)"),Xxr=l(),q4=a("li"),vMe=a("strong"),zxr=o("roberta"),Qxr=o(" \u2014 "),KY=a("a"),Wxr=o("TFRobertaForTokenClassification"),Hxr=o(" (RoBERTa model)"),Uxr=l(),j4=a("li"),FMe=a("strong"),Jxr=o("roformer"),Yxr=o(" \u2014 "),ZY=a("a"),Kxr=o("TFRoFormerForTokenClassification"),Zxr=o(" (RoFormer model)"),e$r=l(),D4=a("li"),TMe=a("strong"),o$r=o("xlm"),r$r=o(" \u2014 "),eK=a("a"),t$r=o("TFXLMForTokenClassification"),a$r=o(" (XLM model)"),n$r=l(),G4=a("li"),MMe=a("strong"),s$r=o("xlm-roberta"),l$r=o(" \u2014 "),oK=a("a"),i$r=o("TFXLMRobertaForTokenClassification"),d$r=o(" (XLM-RoBERTa model)"),c$r=l(),O4=a("li"),EMe=a("strong"),f$r=o("xlnet"),m$r=o(" \u2014 "),rK=a("a"),g$r=o("TFXLNetForTokenClassification"),h$r=o(" (XLNet model)"),p$r=l(),F(V4.$$.fragment),hVe=l(),Rc=a("h2"),X4=a("a"),CMe=a("span"),F(ux.$$.fragment),_$r=l(),wMe=a("span"),u$r=o("TFAutoModelForQuestionAnswering"),pVe=l(),fr=a("div"),F(bx.$$.fragment),b$r=l(),Pc=a("p"),v$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),tK=a("a"),F$r=o("from_pretrained()"),T$r=o(" class method or the "),aK=a("a"),M$r=o("from_config()"),E$r=o(` class
method.`),C$r=l(),vx=a("p"),w$r=o("This class cannot be instantiated directly using "),AMe=a("code"),A$r=o("__init__()"),L$r=o(" (throws an error)."),y$r=l(),Gt=a("div"),F(Fx.$$.fragment),x$r=l(),LMe=a("p"),$$r=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),k$r=l(),Bc=a("p"),S$r=o(`Note:
Loading a model from its configuration file does `),yMe=a("strong"),R$r=o("not"),P$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=a("a"),B$r=o("from_pretrained()"),I$r=o(" to load the model weights."),N$r=l(),F(z4.$$.fragment),q$r=l(),jr=a("div"),F(Tx.$$.fragment),j$r=l(),xMe=a("p"),D$r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),G$r=l(),un=a("p"),O$r=o("The model class to instantiate is selected based on the "),$Me=a("code"),V$r=o("model_type"),X$r=o(` property of the config object (either
passed as an argument or loaded from `),kMe=a("code"),z$r=o("pretrained_model_name_or_path"),Q$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SMe=a("code"),W$r=o("pretrained_model_name_or_path"),H$r=o(":"),U$r=l(),ce=a("ul"),Q4=a("li"),RMe=a("strong"),J$r=o("albert"),Y$r=o(" \u2014 "),sK=a("a"),K$r=o("TFAlbertForQuestionAnswering"),Z$r=o(" (ALBERT model)"),ekr=l(),W4=a("li"),PMe=a("strong"),okr=o("bert"),rkr=o(" \u2014 "),lK=a("a"),tkr=o("TFBertForQuestionAnswering"),akr=o(" (BERT model)"),nkr=l(),H4=a("li"),BMe=a("strong"),skr=o("camembert"),lkr=o(" \u2014 "),iK=a("a"),ikr=o("TFCamembertForQuestionAnswering"),dkr=o(" (CamemBERT model)"),ckr=l(),U4=a("li"),IMe=a("strong"),fkr=o("convbert"),mkr=o(" \u2014 "),dK=a("a"),gkr=o("TFConvBertForQuestionAnswering"),hkr=o(" (ConvBERT model)"),pkr=l(),J4=a("li"),NMe=a("strong"),_kr=o("deberta"),ukr=o(" \u2014 "),cK=a("a"),bkr=o("TFDebertaForQuestionAnswering"),vkr=o(" (DeBERTa model)"),Fkr=l(),Y4=a("li"),qMe=a("strong"),Tkr=o("deberta-v2"),Mkr=o(" \u2014 "),fK=a("a"),Ekr=o("TFDebertaV2ForQuestionAnswering"),Ckr=o(" (DeBERTa-v2 model)"),wkr=l(),K4=a("li"),jMe=a("strong"),Akr=o("distilbert"),Lkr=o(" \u2014 "),mK=a("a"),ykr=o("TFDistilBertForQuestionAnswering"),xkr=o(" (DistilBERT model)"),$kr=l(),Z4=a("li"),DMe=a("strong"),kkr=o("electra"),Skr=o(" \u2014 "),gK=a("a"),Rkr=o("TFElectraForQuestionAnswering"),Pkr=o(" (ELECTRA model)"),Bkr=l(),eC=a("li"),GMe=a("strong"),Ikr=o("flaubert"),Nkr=o(" \u2014 "),hK=a("a"),qkr=o("TFFlaubertForQuestionAnsweringSimple"),jkr=o(" (FlauBERT model)"),Dkr=l(),oC=a("li"),OMe=a("strong"),Gkr=o("funnel"),Okr=o(" \u2014 "),pK=a("a"),Vkr=o("TFFunnelForQuestionAnswering"),Xkr=o(" (Funnel Transformer model)"),zkr=l(),rC=a("li"),VMe=a("strong"),Qkr=o("gptj"),Wkr=o(" \u2014 "),_K=a("a"),Hkr=o("TFGPTJForQuestionAnswering"),Ukr=o(" (GPT-J model)"),Jkr=l(),tC=a("li"),XMe=a("strong"),Ykr=o("longformer"),Kkr=o(" \u2014 "),uK=a("a"),Zkr=o("TFLongformerForQuestionAnswering"),eSr=o(" (Longformer model)"),oSr=l(),aC=a("li"),zMe=a("strong"),rSr=o("mobilebert"),tSr=o(" \u2014 "),bK=a("a"),aSr=o("TFMobileBertForQuestionAnswering"),nSr=o(" (MobileBERT model)"),sSr=l(),nC=a("li"),QMe=a("strong"),lSr=o("mpnet"),iSr=o(" \u2014 "),vK=a("a"),dSr=o("TFMPNetForQuestionAnswering"),cSr=o(" (MPNet model)"),fSr=l(),sC=a("li"),WMe=a("strong"),mSr=o("rembert"),gSr=o(" \u2014 "),FK=a("a"),hSr=o("TFRemBertForQuestionAnswering"),pSr=o(" (RemBERT model)"),_Sr=l(),lC=a("li"),HMe=a("strong"),uSr=o("roberta"),bSr=o(" \u2014 "),TK=a("a"),vSr=o("TFRobertaForQuestionAnswering"),FSr=o(" (RoBERTa model)"),TSr=l(),iC=a("li"),UMe=a("strong"),MSr=o("roformer"),ESr=o(" \u2014 "),MK=a("a"),CSr=o("TFRoFormerForQuestionAnswering"),wSr=o(" (RoFormer model)"),ASr=l(),dC=a("li"),JMe=a("strong"),LSr=o("xlm"),ySr=o(" \u2014 "),EK=a("a"),xSr=o("TFXLMForQuestionAnsweringSimple"),$Sr=o(" (XLM model)"),kSr=l(),cC=a("li"),YMe=a("strong"),SSr=o("xlm-roberta"),RSr=o(" \u2014 "),CK=a("a"),PSr=o("TFXLMRobertaForQuestionAnswering"),BSr=o(" (XLM-RoBERTa model)"),ISr=l(),fC=a("li"),KMe=a("strong"),NSr=o("xlnet"),qSr=o(" \u2014 "),wK=a("a"),jSr=o("TFXLNetForQuestionAnsweringSimple"),DSr=o(" (XLNet model)"),GSr=l(),F(mC.$$.fragment),_Ve=l(),Ic=a("h2"),gC=a("a"),ZMe=a("span"),F(Mx.$$.fragment),OSr=l(),eEe=a("span"),VSr=o("TFAutoModelForVision2Seq"),uVe=l(),mr=a("div"),F(Ex.$$.fragment),XSr=l(),Nc=a("p"),zSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),AK=a("a"),QSr=o("from_pretrained()"),WSr=o(" class method or the "),LK=a("a"),HSr=o("from_config()"),USr=o(` class
method.`),JSr=l(),Cx=a("p"),YSr=o("This class cannot be instantiated directly using "),oEe=a("code"),KSr=o("__init__()"),ZSr=o(" (throws an error)."),eRr=l(),Ot=a("div"),F(wx.$$.fragment),oRr=l(),rEe=a("p"),rRr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),tRr=l(),qc=a("p"),aRr=o(`Note:
Loading a model from its configuration file does `),tEe=a("strong"),nRr=o("not"),sRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yK=a("a"),lRr=o("from_pretrained()"),iRr=o(" to load the model weights."),dRr=l(),F(hC.$$.fragment),cRr=l(),Dr=a("div"),F(Ax.$$.fragment),fRr=l(),aEe=a("p"),mRr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),gRr=l(),bn=a("p"),hRr=o("The model class to instantiate is selected based on the "),nEe=a("code"),pRr=o("model_type"),_Rr=o(` property of the config object (either
passed as an argument or loaded from `),sEe=a("code"),uRr=o("pretrained_model_name_or_path"),bRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lEe=a("code"),vRr=o("pretrained_model_name_or_path"),FRr=o(":"),TRr=l(),iEe=a("ul"),pC=a("li"),dEe=a("strong"),MRr=o("vision-encoder-decoder"),ERr=o(" \u2014 "),xK=a("a"),CRr=o("TFVisionEncoderDecoderModel"),wRr=o(" (Vision Encoder decoder model)"),ARr=l(),F(_C.$$.fragment),bVe=l(),jc=a("h2"),uC=a("a"),cEe=a("span"),F(Lx.$$.fragment),LRr=l(),fEe=a("span"),yRr=o("TFAutoModelForSpeechSeq2Seq"),vVe=l(),gr=a("div"),F(yx.$$.fragment),xRr=l(),Dc=a("p"),$Rr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),$K=a("a"),kRr=o("from_pretrained()"),SRr=o(" class method or the "),kK=a("a"),RRr=o("from_config()"),PRr=o(` class
method.`),BRr=l(),xx=a("p"),IRr=o("This class cannot be instantiated directly using "),mEe=a("code"),NRr=o("__init__()"),qRr=o(" (throws an error)."),jRr=l(),Vt=a("div"),F($x.$$.fragment),DRr=l(),gEe=a("p"),GRr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),ORr=l(),Gc=a("p"),VRr=o(`Note:
Loading a model from its configuration file does `),hEe=a("strong"),XRr=o("not"),zRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SK=a("a"),QRr=o("from_pretrained()"),WRr=o(" to load the model weights."),HRr=l(),F(bC.$$.fragment),URr=l(),Gr=a("div"),F(kx.$$.fragment),JRr=l(),pEe=a("p"),YRr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),KRr=l(),vn=a("p"),ZRr=o("The model class to instantiate is selected based on the "),_Ee=a("code"),ePr=o("model_type"),oPr=o(` property of the config object (either
passed as an argument or loaded from `),uEe=a("code"),rPr=o("pretrained_model_name_or_path"),tPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bEe=a("code"),aPr=o("pretrained_model_name_or_path"),nPr=o(":"),sPr=l(),vEe=a("ul"),vC=a("li"),FEe=a("strong"),lPr=o("speech_to_text"),iPr=o(" \u2014 "),RK=a("a"),dPr=o("TFSpeech2TextForConditionalGeneration"),cPr=o(" (Speech2Text model)"),fPr=l(),F(FC.$$.fragment),FVe=l(),Oc=a("h2"),TC=a("a"),TEe=a("span"),F(Sx.$$.fragment),mPr=l(),MEe=a("span"),gPr=o("FlaxAutoModel"),TVe=l(),hr=a("div"),F(Rx.$$.fragment),hPr=l(),Vc=a("p"),pPr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),PK=a("a"),_Pr=o("from_pretrained()"),uPr=o(" class method or the "),BK=a("a"),bPr=o("from_config()"),vPr=o(` class
method.`),FPr=l(),Px=a("p"),TPr=o("This class cannot be instantiated directly using "),EEe=a("code"),MPr=o("__init__()"),EPr=o(" (throws an error)."),CPr=l(),Xt=a("div"),F(Bx.$$.fragment),wPr=l(),CEe=a("p"),APr=o("Instantiates one of the base model classes of the library from a configuration."),LPr=l(),Xc=a("p"),yPr=o(`Note:
Loading a model from its configuration file does `),wEe=a("strong"),xPr=o("not"),$Pr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=a("a"),kPr=o("from_pretrained()"),SPr=o(" to load the model weights."),RPr=l(),F(MC.$$.fragment),PPr=l(),Or=a("div"),F(Ix.$$.fragment),BPr=l(),AEe=a("p"),IPr=o("Instantiate one of the base model classes of the library from a pretrained model."),NPr=l(),Fn=a("p"),qPr=o("The model class to instantiate is selected based on the "),LEe=a("code"),jPr=o("model_type"),DPr=o(` property of the config object (either
passed as an argument or loaded from `),yEe=a("code"),GPr=o("pretrained_model_name_or_path"),OPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xEe=a("code"),VPr=o("pretrained_model_name_or_path"),XPr=o(":"),zPr=l(),oe=a("ul"),EC=a("li"),$Ee=a("strong"),QPr=o("albert"),WPr=o(" \u2014 "),NK=a("a"),HPr=o("FlaxAlbertModel"),UPr=o(" (ALBERT model)"),JPr=l(),CC=a("li"),kEe=a("strong"),YPr=o("bart"),KPr=o(" \u2014 "),qK=a("a"),ZPr=o("FlaxBartModel"),eBr=o(" (BART model)"),oBr=l(),wC=a("li"),SEe=a("strong"),rBr=o("beit"),tBr=o(" \u2014 "),jK=a("a"),aBr=o("FlaxBeitModel"),nBr=o(" (BEiT model)"),sBr=l(),AC=a("li"),REe=a("strong"),lBr=o("bert"),iBr=o(" \u2014 "),DK=a("a"),dBr=o("FlaxBertModel"),cBr=o(" (BERT model)"),fBr=l(),LC=a("li"),PEe=a("strong"),mBr=o("big_bird"),gBr=o(" \u2014 "),GK=a("a"),hBr=o("FlaxBigBirdModel"),pBr=o(" (BigBird model)"),_Br=l(),yC=a("li"),BEe=a("strong"),uBr=o("blenderbot"),bBr=o(" \u2014 "),OK=a("a"),vBr=o("FlaxBlenderbotModel"),FBr=o(" (Blenderbot model)"),TBr=l(),xC=a("li"),IEe=a("strong"),MBr=o("blenderbot-small"),EBr=o(" \u2014 "),VK=a("a"),CBr=o("FlaxBlenderbotSmallModel"),wBr=o(" (BlenderbotSmall model)"),ABr=l(),$C=a("li"),NEe=a("strong"),LBr=o("clip"),yBr=o(" \u2014 "),XK=a("a"),xBr=o("FlaxCLIPModel"),$Br=o(" (CLIP model)"),kBr=l(),kC=a("li"),qEe=a("strong"),SBr=o("distilbert"),RBr=o(" \u2014 "),zK=a("a"),PBr=o("FlaxDistilBertModel"),BBr=o(" (DistilBERT model)"),IBr=l(),SC=a("li"),jEe=a("strong"),NBr=o("electra"),qBr=o(" \u2014 "),QK=a("a"),jBr=o("FlaxElectraModel"),DBr=o(" (ELECTRA model)"),GBr=l(),RC=a("li"),DEe=a("strong"),OBr=o("gpt2"),VBr=o(" \u2014 "),WK=a("a"),XBr=o("FlaxGPT2Model"),zBr=o(" (OpenAI GPT-2 model)"),QBr=l(),PC=a("li"),GEe=a("strong"),WBr=o("gpt_neo"),HBr=o(" \u2014 "),HK=a("a"),UBr=o("FlaxGPTNeoModel"),JBr=o(" (GPT Neo model)"),YBr=l(),BC=a("li"),OEe=a("strong"),KBr=o("gptj"),ZBr=o(" \u2014 "),UK=a("a"),eIr=o("FlaxGPTJModel"),oIr=o(" (GPT-J model)"),rIr=l(),IC=a("li"),VEe=a("strong"),tIr=o("longt5"),aIr=o(" \u2014 "),JK=a("a"),nIr=o("FlaxLongT5Model"),sIr=o(" (LongT5 model)"),lIr=l(),NC=a("li"),XEe=a("strong"),iIr=o("marian"),dIr=o(" \u2014 "),YK=a("a"),cIr=o("FlaxMarianModel"),fIr=o(" (Marian model)"),mIr=l(),qC=a("li"),zEe=a("strong"),gIr=o("mbart"),hIr=o(" \u2014 "),KK=a("a"),pIr=o("FlaxMBartModel"),_Ir=o(" (mBART model)"),uIr=l(),jC=a("li"),QEe=a("strong"),bIr=o("mt5"),vIr=o(" \u2014 "),ZK=a("a"),FIr=o("FlaxMT5Model"),TIr=o(" (MT5 model)"),MIr=l(),DC=a("li"),WEe=a("strong"),EIr=o("opt"),CIr=o(" \u2014 "),eZ=a("a"),wIr=o("FlaxOPTModel"),AIr=o(" (OPT model)"),LIr=l(),GC=a("li"),HEe=a("strong"),yIr=o("pegasus"),xIr=o(" \u2014 "),oZ=a("a"),$Ir=o("FlaxPegasusModel"),kIr=o(" (Pegasus model)"),SIr=l(),OC=a("li"),UEe=a("strong"),RIr=o("roberta"),PIr=o(" \u2014 "),rZ=a("a"),BIr=o("FlaxRobertaModel"),IIr=o(" (RoBERTa model)"),NIr=l(),VC=a("li"),JEe=a("strong"),qIr=o("roformer"),jIr=o(" \u2014 "),tZ=a("a"),DIr=o("FlaxRoFormerModel"),GIr=o(" (RoFormer model)"),OIr=l(),XC=a("li"),YEe=a("strong"),VIr=o("t5"),XIr=o(" \u2014 "),aZ=a("a"),zIr=o("FlaxT5Model"),QIr=o(" (T5 model)"),WIr=l(),zC=a("li"),KEe=a("strong"),HIr=o("vision-text-dual-encoder"),UIr=o(" \u2014 "),nZ=a("a"),JIr=o("FlaxVisionTextDualEncoderModel"),YIr=o(" (VisionTextDualEncoder model)"),KIr=l(),QC=a("li"),ZEe=a("strong"),ZIr=o("vit"),eNr=o(" \u2014 "),sZ=a("a"),oNr=o("FlaxViTModel"),rNr=o(" (ViT model)"),tNr=l(),WC=a("li"),e4e=a("strong"),aNr=o("wav2vec2"),nNr=o(" \u2014 "),lZ=a("a"),sNr=o("FlaxWav2Vec2Model"),lNr=o(" (Wav2Vec2 model)"),iNr=l(),HC=a("li"),o4e=a("strong"),dNr=o("xglm"),cNr=o(" \u2014 "),iZ=a("a"),fNr=o("FlaxXGLMModel"),mNr=o(" (XGLM model)"),gNr=l(),UC=a("li"),r4e=a("strong"),hNr=o("xlm-roberta"),pNr=o(" \u2014 "),dZ=a("a"),_Nr=o("FlaxXLMRobertaModel"),uNr=o(" (XLM-RoBERTa model)"),bNr=l(),F(JC.$$.fragment),MVe=l(),zc=a("h2"),YC=a("a"),t4e=a("span"),F(Nx.$$.fragment),vNr=l(),a4e=a("span"),FNr=o("FlaxAutoModelForCausalLM"),EVe=l(),pr=a("div"),F(qx.$$.fragment),TNr=l(),Qc=a("p"),MNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),cZ=a("a"),ENr=o("from_pretrained()"),CNr=o(" class method or the "),fZ=a("a"),wNr=o("from_config()"),ANr=o(` class
method.`),LNr=l(),jx=a("p"),yNr=o("This class cannot be instantiated directly using "),n4e=a("code"),xNr=o("__init__()"),$Nr=o(" (throws an error)."),kNr=l(),zt=a("div"),F(Dx.$$.fragment),SNr=l(),s4e=a("p"),RNr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),PNr=l(),Wc=a("p"),BNr=o(`Note:
Loading a model from its configuration file does `),l4e=a("strong"),INr=o("not"),NNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mZ=a("a"),qNr=o("from_pretrained()"),jNr=o(" to load the model weights."),DNr=l(),F(KC.$$.fragment),GNr=l(),Vr=a("div"),F(Gx.$$.fragment),ONr=l(),i4e=a("p"),VNr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),XNr=l(),Tn=a("p"),zNr=o("The model class to instantiate is selected based on the "),d4e=a("code"),QNr=o("model_type"),WNr=o(` property of the config object (either
passed as an argument or loaded from `),c4e=a("code"),HNr=o("pretrained_model_name_or_path"),UNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f4e=a("code"),JNr=o("pretrained_model_name_or_path"),YNr=o(":"),KNr=l(),xe=a("ul"),ZC=a("li"),m4e=a("strong"),ZNr=o("bart"),eqr=o(" \u2014 "),gZ=a("a"),oqr=o("FlaxBartForCausalLM"),rqr=o(" (BART model)"),tqr=l(),e0=a("li"),g4e=a("strong"),aqr=o("bert"),nqr=o(" \u2014 "),hZ=a("a"),sqr=o("FlaxBertForCausalLM"),lqr=o(" (BERT model)"),iqr=l(),o0=a("li"),h4e=a("strong"),dqr=o("big_bird"),cqr=o(" \u2014 "),pZ=a("a"),fqr=o("FlaxBigBirdForCausalLM"),mqr=o(" (BigBird model)"),gqr=l(),r0=a("li"),p4e=a("strong"),hqr=o("electra"),pqr=o(" \u2014 "),_Z=a("a"),_qr=o("FlaxElectraForCausalLM"),uqr=o(" (ELECTRA model)"),bqr=l(),t0=a("li"),_4e=a("strong"),vqr=o("gpt2"),Fqr=o(" \u2014 "),uZ=a("a"),Tqr=o("FlaxGPT2LMHeadModel"),Mqr=o(" (OpenAI GPT-2 model)"),Eqr=l(),a0=a("li"),u4e=a("strong"),Cqr=o("gpt_neo"),wqr=o(" \u2014 "),bZ=a("a"),Aqr=o("FlaxGPTNeoForCausalLM"),Lqr=o(" (GPT Neo model)"),yqr=l(),n0=a("li"),b4e=a("strong"),xqr=o("gptj"),$qr=o(" \u2014 "),vZ=a("a"),kqr=o("FlaxGPTJForCausalLM"),Sqr=o(" (GPT-J model)"),Rqr=l(),s0=a("li"),v4e=a("strong"),Pqr=o("opt"),Bqr=o(" \u2014 "),FZ=a("a"),Iqr=o("FlaxOPTForCausalLM"),Nqr=o(" (OPT model)"),qqr=l(),l0=a("li"),F4e=a("strong"),jqr=o("roberta"),Dqr=o(" \u2014 "),TZ=a("a"),Gqr=o("FlaxRobertaForCausalLM"),Oqr=o(" (RoBERTa model)"),Vqr=l(),i0=a("li"),T4e=a("strong"),Xqr=o("xglm"),zqr=o(" \u2014 "),MZ=a("a"),Qqr=o("FlaxXGLMForCausalLM"),Wqr=o(" (XGLM model)"),Hqr=l(),F(d0.$$.fragment),CVe=l(),Hc=a("h2"),c0=a("a"),M4e=a("span"),F(Ox.$$.fragment),Uqr=l(),E4e=a("span"),Jqr=o("FlaxAutoModelForPreTraining"),wVe=l(),_r=a("div"),F(Vx.$$.fragment),Yqr=l(),Uc=a("p"),Kqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),EZ=a("a"),Zqr=o("from_pretrained()"),ejr=o(" class method or the "),CZ=a("a"),ojr=o("from_config()"),rjr=o(` class
method.`),tjr=l(),Xx=a("p"),ajr=o("This class cannot be instantiated directly using "),C4e=a("code"),njr=o("__init__()"),sjr=o(" (throws an error)."),ljr=l(),Qt=a("div"),F(zx.$$.fragment),ijr=l(),w4e=a("p"),djr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),cjr=l(),Jc=a("p"),fjr=o(`Note:
Loading a model from its configuration file does `),A4e=a("strong"),mjr=o("not"),gjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wZ=a("a"),hjr=o("from_pretrained()"),pjr=o(" to load the model weights."),_jr=l(),F(f0.$$.fragment),ujr=l(),Xr=a("div"),F(Qx.$$.fragment),bjr=l(),L4e=a("p"),vjr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Fjr=l(),Mn=a("p"),Tjr=o("The model class to instantiate is selected based on the "),y4e=a("code"),Mjr=o("model_type"),Ejr=o(` property of the config object (either
passed as an argument or loaded from `),x4e=a("code"),Cjr=o("pretrained_model_name_or_path"),wjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$4e=a("code"),Ajr=o("pretrained_model_name_or_path"),Ljr=o(":"),yjr=l(),Ee=a("ul"),m0=a("li"),k4e=a("strong"),xjr=o("albert"),$jr=o(" \u2014 "),AZ=a("a"),kjr=o("FlaxAlbertForPreTraining"),Sjr=o(" (ALBERT model)"),Rjr=l(),g0=a("li"),S4e=a("strong"),Pjr=o("bart"),Bjr=o(" \u2014 "),LZ=a("a"),Ijr=o("FlaxBartForConditionalGeneration"),Njr=o(" (BART model)"),qjr=l(),h0=a("li"),R4e=a("strong"),jjr=o("bert"),Djr=o(" \u2014 "),yZ=a("a"),Gjr=o("FlaxBertForPreTraining"),Ojr=o(" (BERT model)"),Vjr=l(),p0=a("li"),P4e=a("strong"),Xjr=o("big_bird"),zjr=o(" \u2014 "),xZ=a("a"),Qjr=o("FlaxBigBirdForPreTraining"),Wjr=o(" (BigBird model)"),Hjr=l(),_0=a("li"),B4e=a("strong"),Ujr=o("electra"),Jjr=o(" \u2014 "),$Z=a("a"),Yjr=o("FlaxElectraForPreTraining"),Kjr=o(" (ELECTRA model)"),Zjr=l(),u0=a("li"),I4e=a("strong"),eDr=o("longt5"),oDr=o(" \u2014 "),kZ=a("a"),rDr=o("FlaxLongT5ForConditionalGeneration"),tDr=o(" (LongT5 model)"),aDr=l(),b0=a("li"),N4e=a("strong"),nDr=o("mbart"),sDr=o(" \u2014 "),SZ=a("a"),lDr=o("FlaxMBartForConditionalGeneration"),iDr=o(" (mBART model)"),dDr=l(),v0=a("li"),q4e=a("strong"),cDr=o("mt5"),fDr=o(" \u2014 "),RZ=a("a"),mDr=o("FlaxMT5ForConditionalGeneration"),gDr=o(" (MT5 model)"),hDr=l(),F0=a("li"),j4e=a("strong"),pDr=o("roberta"),_Dr=o(" \u2014 "),PZ=a("a"),uDr=o("FlaxRobertaForMaskedLM"),bDr=o(" (RoBERTa model)"),vDr=l(),T0=a("li"),D4e=a("strong"),FDr=o("roformer"),TDr=o(" \u2014 "),BZ=a("a"),MDr=o("FlaxRoFormerForMaskedLM"),EDr=o(" (RoFormer model)"),CDr=l(),M0=a("li"),G4e=a("strong"),wDr=o("t5"),ADr=o(" \u2014 "),IZ=a("a"),LDr=o("FlaxT5ForConditionalGeneration"),yDr=o(" (T5 model)"),xDr=l(),E0=a("li"),O4e=a("strong"),$Dr=o("wav2vec2"),kDr=o(" \u2014 "),NZ=a("a"),SDr=o("FlaxWav2Vec2ForPreTraining"),RDr=o(" (Wav2Vec2 model)"),PDr=l(),C0=a("li"),V4e=a("strong"),BDr=o("xlm-roberta"),IDr=o(" \u2014 "),qZ=a("a"),NDr=o("FlaxXLMRobertaForMaskedLM"),qDr=o(" (XLM-RoBERTa model)"),jDr=l(),F(w0.$$.fragment),AVe=l(),Yc=a("h2"),A0=a("a"),X4e=a("span"),F(Wx.$$.fragment),DDr=l(),z4e=a("span"),GDr=o("FlaxAutoModelForMaskedLM"),LVe=l(),ur=a("div"),F(Hx.$$.fragment),ODr=l(),Kc=a("p"),VDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),jZ=a("a"),XDr=o("from_pretrained()"),zDr=o(" class method or the "),DZ=a("a"),QDr=o("from_config()"),WDr=o(` class
method.`),HDr=l(),Ux=a("p"),UDr=o("This class cannot be instantiated directly using "),Q4e=a("code"),JDr=o("__init__()"),YDr=o(" (throws an error)."),KDr=l(),Wt=a("div"),F(Jx.$$.fragment),ZDr=l(),W4e=a("p"),eGr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),oGr=l(),Zc=a("p"),rGr=o(`Note:
Loading a model from its configuration file does `),H4e=a("strong"),tGr=o("not"),aGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GZ=a("a"),nGr=o("from_pretrained()"),sGr=o(" to load the model weights."),lGr=l(),F(L0.$$.fragment),iGr=l(),zr=a("div"),F(Yx.$$.fragment),dGr=l(),U4e=a("p"),cGr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),fGr=l(),En=a("p"),mGr=o("The model class to instantiate is selected based on the "),J4e=a("code"),gGr=o("model_type"),hGr=o(` property of the config object (either
passed as an argument or loaded from `),Y4e=a("code"),pGr=o("pretrained_model_name_or_path"),_Gr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K4e=a("code"),uGr=o("pretrained_model_name_or_path"),bGr=o(":"),vGr=l(),$e=a("ul"),y0=a("li"),Z4e=a("strong"),FGr=o("albert"),TGr=o(" \u2014 "),OZ=a("a"),MGr=o("FlaxAlbertForMaskedLM"),EGr=o(" (ALBERT model)"),CGr=l(),x0=a("li"),eCe=a("strong"),wGr=o("bart"),AGr=o(" \u2014 "),VZ=a("a"),LGr=o("FlaxBartForConditionalGeneration"),yGr=o(" (BART model)"),xGr=l(),$0=a("li"),oCe=a("strong"),$Gr=o("bert"),kGr=o(" \u2014 "),XZ=a("a"),SGr=o("FlaxBertForMaskedLM"),RGr=o(" (BERT model)"),PGr=l(),k0=a("li"),rCe=a("strong"),BGr=o("big_bird"),IGr=o(" \u2014 "),zZ=a("a"),NGr=o("FlaxBigBirdForMaskedLM"),qGr=o(" (BigBird model)"),jGr=l(),S0=a("li"),tCe=a("strong"),DGr=o("distilbert"),GGr=o(" \u2014 "),QZ=a("a"),OGr=o("FlaxDistilBertForMaskedLM"),VGr=o(" (DistilBERT model)"),XGr=l(),R0=a("li"),aCe=a("strong"),zGr=o("electra"),QGr=o(" \u2014 "),WZ=a("a"),WGr=o("FlaxElectraForMaskedLM"),HGr=o(" (ELECTRA model)"),UGr=l(),P0=a("li"),nCe=a("strong"),JGr=o("mbart"),YGr=o(" \u2014 "),HZ=a("a"),KGr=o("FlaxMBartForConditionalGeneration"),ZGr=o(" (mBART model)"),eOr=l(),B0=a("li"),sCe=a("strong"),oOr=o("roberta"),rOr=o(" \u2014 "),UZ=a("a"),tOr=o("FlaxRobertaForMaskedLM"),aOr=o(" (RoBERTa model)"),nOr=l(),I0=a("li"),lCe=a("strong"),sOr=o("roformer"),lOr=o(" \u2014 "),JZ=a("a"),iOr=o("FlaxRoFormerForMaskedLM"),dOr=o(" (RoFormer model)"),cOr=l(),N0=a("li"),iCe=a("strong"),fOr=o("xlm-roberta"),mOr=o(" \u2014 "),YZ=a("a"),gOr=o("FlaxXLMRobertaForMaskedLM"),hOr=o(" (XLM-RoBERTa model)"),pOr=l(),F(q0.$$.fragment),yVe=l(),ef=a("h2"),j0=a("a"),dCe=a("span"),F(Kx.$$.fragment),_Or=l(),cCe=a("span"),uOr=o("FlaxAutoModelForSeq2SeqLM"),xVe=l(),br=a("div"),F(Zx.$$.fragment),bOr=l(),of=a("p"),vOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),KZ=a("a"),FOr=o("from_pretrained()"),TOr=o(" class method or the "),ZZ=a("a"),MOr=o("from_config()"),EOr=o(` class
method.`),COr=l(),e$=a("p"),wOr=o("This class cannot be instantiated directly using "),fCe=a("code"),AOr=o("__init__()"),LOr=o(" (throws an error)."),yOr=l(),Ht=a("div"),F(o$.$$.fragment),xOr=l(),mCe=a("p"),$Or=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),kOr=l(),rf=a("p"),SOr=o(`Note:
Loading a model from its configuration file does `),gCe=a("strong"),ROr=o("not"),POr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eee=a("a"),BOr=o("from_pretrained()"),IOr=o(" to load the model weights."),NOr=l(),F(D0.$$.fragment),qOr=l(),Qr=a("div"),F(r$.$$.fragment),jOr=l(),hCe=a("p"),DOr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),GOr=l(),Cn=a("p"),OOr=o("The model class to instantiate is selected based on the "),pCe=a("code"),VOr=o("model_type"),XOr=o(` property of the config object (either
passed as an argument or loaded from `),_Ce=a("code"),zOr=o("pretrained_model_name_or_path"),QOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uCe=a("code"),WOr=o("pretrained_model_name_or_path"),HOr=o(":"),UOr=l(),ke=a("ul"),G0=a("li"),bCe=a("strong"),JOr=o("bart"),YOr=o(" \u2014 "),oee=a("a"),KOr=o("FlaxBartForConditionalGeneration"),ZOr=o(" (BART model)"),eVr=l(),O0=a("li"),vCe=a("strong"),oVr=o("blenderbot"),rVr=o(" \u2014 "),ree=a("a"),tVr=o("FlaxBlenderbotForConditionalGeneration"),aVr=o(" (Blenderbot model)"),nVr=l(),V0=a("li"),FCe=a("strong"),sVr=o("blenderbot-small"),lVr=o(" \u2014 "),tee=a("a"),iVr=o("FlaxBlenderbotSmallForConditionalGeneration"),dVr=o(" (BlenderbotSmall model)"),cVr=l(),X0=a("li"),TCe=a("strong"),fVr=o("encoder-decoder"),mVr=o(" \u2014 "),aee=a("a"),gVr=o("FlaxEncoderDecoderModel"),hVr=o(" (Encoder decoder model)"),pVr=l(),z0=a("li"),MCe=a("strong"),_Vr=o("longt5"),uVr=o(" \u2014 "),nee=a("a"),bVr=o("FlaxLongT5ForConditionalGeneration"),vVr=o(" (LongT5 model)"),FVr=l(),Q0=a("li"),ECe=a("strong"),TVr=o("marian"),MVr=o(" \u2014 "),see=a("a"),EVr=o("FlaxMarianMTModel"),CVr=o(" (Marian model)"),wVr=l(),W0=a("li"),CCe=a("strong"),AVr=o("mbart"),LVr=o(" \u2014 "),lee=a("a"),yVr=o("FlaxMBartForConditionalGeneration"),xVr=o(" (mBART model)"),$Vr=l(),H0=a("li"),wCe=a("strong"),kVr=o("mt5"),SVr=o(" \u2014 "),iee=a("a"),RVr=o("FlaxMT5ForConditionalGeneration"),PVr=o(" (MT5 model)"),BVr=l(),U0=a("li"),ACe=a("strong"),IVr=o("pegasus"),NVr=o(" \u2014 "),dee=a("a"),qVr=o("FlaxPegasusForConditionalGeneration"),jVr=o(" (Pegasus model)"),DVr=l(),J0=a("li"),LCe=a("strong"),GVr=o("t5"),OVr=o(" \u2014 "),cee=a("a"),VVr=o("FlaxT5ForConditionalGeneration"),XVr=o(" (T5 model)"),zVr=l(),F(Y0.$$.fragment),$Ve=l(),tf=a("h2"),K0=a("a"),yCe=a("span"),F(t$.$$.fragment),QVr=l(),xCe=a("span"),WVr=o("FlaxAutoModelForSequenceClassification"),kVe=l(),vr=a("div"),F(a$.$$.fragment),HVr=l(),af=a("p"),UVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),fee=a("a"),JVr=o("from_pretrained()"),YVr=o(" class method or the "),mee=a("a"),KVr=o("from_config()"),ZVr=o(` class
method.`),eXr=l(),n$=a("p"),oXr=o("This class cannot be instantiated directly using "),$Ce=a("code"),rXr=o("__init__()"),tXr=o(" (throws an error)."),aXr=l(),Ut=a("div"),F(s$.$$.fragment),nXr=l(),kCe=a("p"),sXr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),lXr=l(),nf=a("p"),iXr=o(`Note:
Loading a model from its configuration file does `),SCe=a("strong"),dXr=o("not"),cXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gee=a("a"),fXr=o("from_pretrained()"),mXr=o(" to load the model weights."),gXr=l(),F(Z0.$$.fragment),hXr=l(),Wr=a("div"),F(l$.$$.fragment),pXr=l(),RCe=a("p"),_Xr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),uXr=l(),wn=a("p"),bXr=o("The model class to instantiate is selected based on the "),PCe=a("code"),vXr=o("model_type"),FXr=o(` property of the config object (either
passed as an argument or loaded from `),BCe=a("code"),TXr=o("pretrained_model_name_or_path"),MXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ICe=a("code"),EXr=o("pretrained_model_name_or_path"),CXr=o(":"),wXr=l(),Se=a("ul"),ew=a("li"),NCe=a("strong"),AXr=o("albert"),LXr=o(" \u2014 "),hee=a("a"),yXr=o("FlaxAlbertForSequenceClassification"),xXr=o(" (ALBERT model)"),$Xr=l(),ow=a("li"),qCe=a("strong"),kXr=o("bart"),SXr=o(" \u2014 "),pee=a("a"),RXr=o("FlaxBartForSequenceClassification"),PXr=o(" (BART model)"),BXr=l(),rw=a("li"),jCe=a("strong"),IXr=o("bert"),NXr=o(" \u2014 "),_ee=a("a"),qXr=o("FlaxBertForSequenceClassification"),jXr=o(" (BERT model)"),DXr=l(),tw=a("li"),DCe=a("strong"),GXr=o("big_bird"),OXr=o(" \u2014 "),uee=a("a"),VXr=o("FlaxBigBirdForSequenceClassification"),XXr=o(" (BigBird model)"),zXr=l(),aw=a("li"),GCe=a("strong"),QXr=o("distilbert"),WXr=o(" \u2014 "),bee=a("a"),HXr=o("FlaxDistilBertForSequenceClassification"),UXr=o(" (DistilBERT model)"),JXr=l(),nw=a("li"),OCe=a("strong"),YXr=o("electra"),KXr=o(" \u2014 "),vee=a("a"),ZXr=o("FlaxElectraForSequenceClassification"),ezr=o(" (ELECTRA model)"),ozr=l(),sw=a("li"),VCe=a("strong"),rzr=o("mbart"),tzr=o(" \u2014 "),Fee=a("a"),azr=o("FlaxMBartForSequenceClassification"),nzr=o(" (mBART model)"),szr=l(),lw=a("li"),XCe=a("strong"),lzr=o("roberta"),izr=o(" \u2014 "),Tee=a("a"),dzr=o("FlaxRobertaForSequenceClassification"),czr=o(" (RoBERTa model)"),fzr=l(),iw=a("li"),zCe=a("strong"),mzr=o("roformer"),gzr=o(" \u2014 "),Mee=a("a"),hzr=o("FlaxRoFormerForSequenceClassification"),pzr=o(" (RoFormer model)"),_zr=l(),dw=a("li"),QCe=a("strong"),uzr=o("xlm-roberta"),bzr=o(" \u2014 "),Eee=a("a"),vzr=o("FlaxXLMRobertaForSequenceClassification"),Fzr=o(" (XLM-RoBERTa model)"),Tzr=l(),F(cw.$$.fragment),SVe=l(),sf=a("h2"),fw=a("a"),WCe=a("span"),F(i$.$$.fragment),Mzr=l(),HCe=a("span"),Ezr=o("FlaxAutoModelForQuestionAnswering"),RVe=l(),Fr=a("div"),F(d$.$$.fragment),Czr=l(),lf=a("p"),wzr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Cee=a("a"),Azr=o("from_pretrained()"),Lzr=o(" class method or the "),wee=a("a"),yzr=o("from_config()"),xzr=o(` class
method.`),$zr=l(),c$=a("p"),kzr=o("This class cannot be instantiated directly using "),UCe=a("code"),Szr=o("__init__()"),Rzr=o(" (throws an error)."),Pzr=l(),Jt=a("div"),F(f$.$$.fragment),Bzr=l(),JCe=a("p"),Izr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Nzr=l(),df=a("p"),qzr=o(`Note:
Loading a model from its configuration file does `),YCe=a("strong"),jzr=o("not"),Dzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Aee=a("a"),Gzr=o("from_pretrained()"),Ozr=o(" to load the model weights."),Vzr=l(),F(mw.$$.fragment),Xzr=l(),Hr=a("div"),F(m$.$$.fragment),zzr=l(),KCe=a("p"),Qzr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Wzr=l(),An=a("p"),Hzr=o("The model class to instantiate is selected based on the "),ZCe=a("code"),Uzr=o("model_type"),Jzr=o(` property of the config object (either
passed as an argument or loaded from `),e0e=a("code"),Yzr=o("pretrained_model_name_or_path"),Kzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o0e=a("code"),Zzr=o("pretrained_model_name_or_path"),eQr=o(":"),oQr=l(),Re=a("ul"),gw=a("li"),r0e=a("strong"),rQr=o("albert"),tQr=o(" \u2014 "),Lee=a("a"),aQr=o("FlaxAlbertForQuestionAnswering"),nQr=o(" (ALBERT model)"),sQr=l(),hw=a("li"),t0e=a("strong"),lQr=o("bart"),iQr=o(" \u2014 "),yee=a("a"),dQr=o("FlaxBartForQuestionAnswering"),cQr=o(" (BART model)"),fQr=l(),pw=a("li"),a0e=a("strong"),mQr=o("bert"),gQr=o(" \u2014 "),xee=a("a"),hQr=o("FlaxBertForQuestionAnswering"),pQr=o(" (BERT model)"),_Qr=l(),_w=a("li"),n0e=a("strong"),uQr=o("big_bird"),bQr=o(" \u2014 "),$ee=a("a"),vQr=o("FlaxBigBirdForQuestionAnswering"),FQr=o(" (BigBird model)"),TQr=l(),uw=a("li"),s0e=a("strong"),MQr=o("distilbert"),EQr=o(" \u2014 "),kee=a("a"),CQr=o("FlaxDistilBertForQuestionAnswering"),wQr=o(" (DistilBERT model)"),AQr=l(),bw=a("li"),l0e=a("strong"),LQr=o("electra"),yQr=o(" \u2014 "),See=a("a"),xQr=o("FlaxElectraForQuestionAnswering"),$Qr=o(" (ELECTRA model)"),kQr=l(),vw=a("li"),i0e=a("strong"),SQr=o("mbart"),RQr=o(" \u2014 "),Ree=a("a"),PQr=o("FlaxMBartForQuestionAnswering"),BQr=o(" (mBART model)"),IQr=l(),Fw=a("li"),d0e=a("strong"),NQr=o("roberta"),qQr=o(" \u2014 "),Pee=a("a"),jQr=o("FlaxRobertaForQuestionAnswering"),DQr=o(" (RoBERTa model)"),GQr=l(),Tw=a("li"),c0e=a("strong"),OQr=o("roformer"),VQr=o(" \u2014 "),Bee=a("a"),XQr=o("FlaxRoFormerForQuestionAnswering"),zQr=o(" (RoFormer model)"),QQr=l(),Mw=a("li"),f0e=a("strong"),WQr=o("xlm-roberta"),HQr=o(" \u2014 "),Iee=a("a"),UQr=o("FlaxXLMRobertaForQuestionAnswering"),JQr=o(" (XLM-RoBERTa model)"),YQr=l(),F(Ew.$$.fragment),PVe=l(),cf=a("h2"),Cw=a("a"),m0e=a("span"),F(g$.$$.fragment),KQr=l(),g0e=a("span"),ZQr=o("FlaxAutoModelForTokenClassification"),BVe=l(),Tr=a("div"),F(h$.$$.fragment),eWr=l(),ff=a("p"),oWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Nee=a("a"),rWr=o("from_pretrained()"),tWr=o(" class method or the "),qee=a("a"),aWr=o("from_config()"),nWr=o(` class
method.`),sWr=l(),p$=a("p"),lWr=o("This class cannot be instantiated directly using "),h0e=a("code"),iWr=o("__init__()"),dWr=o(" (throws an error)."),cWr=l(),Yt=a("div"),F(_$.$$.fragment),fWr=l(),p0e=a("p"),mWr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),gWr=l(),mf=a("p"),hWr=o(`Note:
Loading a model from its configuration file does `),_0e=a("strong"),pWr=o("not"),_Wr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jee=a("a"),uWr=o("from_pretrained()"),bWr=o(" to load the model weights."),vWr=l(),F(ww.$$.fragment),FWr=l(),Ur=a("div"),F(u$.$$.fragment),TWr=l(),u0e=a("p"),MWr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),EWr=l(),Ln=a("p"),CWr=o("The model class to instantiate is selected based on the "),b0e=a("code"),wWr=o("model_type"),AWr=o(` property of the config object (either
passed as an argument or loaded from `),v0e=a("code"),LWr=o("pretrained_model_name_or_path"),yWr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F0e=a("code"),xWr=o("pretrained_model_name_or_path"),$Wr=o(":"),kWr=l(),Ve=a("ul"),Aw=a("li"),T0e=a("strong"),SWr=o("albert"),RWr=o(" \u2014 "),Dee=a("a"),PWr=o("FlaxAlbertForTokenClassification"),BWr=o(" (ALBERT model)"),IWr=l(),Lw=a("li"),M0e=a("strong"),NWr=o("bert"),qWr=o(" \u2014 "),Gee=a("a"),jWr=o("FlaxBertForTokenClassification"),DWr=o(" (BERT model)"),GWr=l(),yw=a("li"),E0e=a("strong"),OWr=o("big_bird"),VWr=o(" \u2014 "),Oee=a("a"),XWr=o("FlaxBigBirdForTokenClassification"),zWr=o(" (BigBird model)"),QWr=l(),xw=a("li"),C0e=a("strong"),WWr=o("distilbert"),HWr=o(" \u2014 "),Vee=a("a"),UWr=o("FlaxDistilBertForTokenClassification"),JWr=o(" (DistilBERT model)"),YWr=l(),$w=a("li"),w0e=a("strong"),KWr=o("electra"),ZWr=o(" \u2014 "),Xee=a("a"),eHr=o("FlaxElectraForTokenClassification"),oHr=o(" (ELECTRA model)"),rHr=l(),kw=a("li"),A0e=a("strong"),tHr=o("roberta"),aHr=o(" \u2014 "),zee=a("a"),nHr=o("FlaxRobertaForTokenClassification"),sHr=o(" (RoBERTa model)"),lHr=l(),Sw=a("li"),L0e=a("strong"),iHr=o("roformer"),dHr=o(" \u2014 "),Qee=a("a"),cHr=o("FlaxRoFormerForTokenClassification"),fHr=o(" (RoFormer model)"),mHr=l(),Rw=a("li"),y0e=a("strong"),gHr=o("xlm-roberta"),hHr=o(" \u2014 "),Wee=a("a"),pHr=o("FlaxXLMRobertaForTokenClassification"),_Hr=o(" (XLM-RoBERTa model)"),uHr=l(),F(Pw.$$.fragment),IVe=l(),gf=a("h2"),Bw=a("a"),x0e=a("span"),F(b$.$$.fragment),bHr=l(),$0e=a("span"),vHr=o("FlaxAutoModelForMultipleChoice"),NVe=l(),Mr=a("div"),F(v$.$$.fragment),FHr=l(),hf=a("p"),THr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Hee=a("a"),MHr=o("from_pretrained()"),EHr=o(" class method or the "),Uee=a("a"),CHr=o("from_config()"),wHr=o(` class
method.`),AHr=l(),F$=a("p"),LHr=o("This class cannot be instantiated directly using "),k0e=a("code"),yHr=o("__init__()"),xHr=o(" (throws an error)."),$Hr=l(),Kt=a("div"),F(T$.$$.fragment),kHr=l(),S0e=a("p"),SHr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),RHr=l(),pf=a("p"),PHr=o(`Note:
Loading a model from its configuration file does `),R0e=a("strong"),BHr=o("not"),IHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jee=a("a"),NHr=o("from_pretrained()"),qHr=o(" to load the model weights."),jHr=l(),F(Iw.$$.fragment),DHr=l(),Jr=a("div"),F(M$.$$.fragment),GHr=l(),P0e=a("p"),OHr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),VHr=l(),yn=a("p"),XHr=o("The model class to instantiate is selected based on the "),B0e=a("code"),zHr=o("model_type"),QHr=o(` property of the config object (either
passed as an argument or loaded from `),I0e=a("code"),WHr=o("pretrained_model_name_or_path"),HHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N0e=a("code"),UHr=o("pretrained_model_name_or_path"),JHr=o(":"),YHr=l(),Xe=a("ul"),Nw=a("li"),q0e=a("strong"),KHr=o("albert"),ZHr=o(" \u2014 "),Yee=a("a"),eUr=o("FlaxAlbertForMultipleChoice"),oUr=o(" (ALBERT model)"),rUr=l(),qw=a("li"),j0e=a("strong"),tUr=o("bert"),aUr=o(" \u2014 "),Kee=a("a"),nUr=o("FlaxBertForMultipleChoice"),sUr=o(" (BERT model)"),lUr=l(),jw=a("li"),D0e=a("strong"),iUr=o("big_bird"),dUr=o(" \u2014 "),Zee=a("a"),cUr=o("FlaxBigBirdForMultipleChoice"),fUr=o(" (BigBird model)"),mUr=l(),Dw=a("li"),G0e=a("strong"),gUr=o("distilbert"),hUr=o(" \u2014 "),eoe=a("a"),pUr=o("FlaxDistilBertForMultipleChoice"),_Ur=o(" (DistilBERT model)"),uUr=l(),Gw=a("li"),O0e=a("strong"),bUr=o("electra"),vUr=o(" \u2014 "),ooe=a("a"),FUr=o("FlaxElectraForMultipleChoice"),TUr=o(" (ELECTRA model)"),MUr=l(),Ow=a("li"),V0e=a("strong"),EUr=o("roberta"),CUr=o(" \u2014 "),roe=a("a"),wUr=o("FlaxRobertaForMultipleChoice"),AUr=o(" (RoBERTa model)"),LUr=l(),Vw=a("li"),X0e=a("strong"),yUr=o("roformer"),xUr=o(" \u2014 "),toe=a("a"),$Ur=o("FlaxRoFormerForMultipleChoice"),kUr=o(" (RoFormer model)"),SUr=l(),Xw=a("li"),z0e=a("strong"),RUr=o("xlm-roberta"),PUr=o(" \u2014 "),aoe=a("a"),BUr=o("FlaxXLMRobertaForMultipleChoice"),IUr=o(" (XLM-RoBERTa model)"),NUr=l(),F(zw.$$.fragment),qVe=l(),_f=a("h2"),Qw=a("a"),Q0e=a("span"),F(E$.$$.fragment),qUr=l(),W0e=a("span"),jUr=o("FlaxAutoModelForNextSentencePrediction"),jVe=l(),Er=a("div"),F(C$.$$.fragment),DUr=l(),uf=a("p"),GUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),noe=a("a"),OUr=o("from_pretrained()"),VUr=o(" class method or the "),soe=a("a"),XUr=o("from_config()"),zUr=o(` class
method.`),QUr=l(),w$=a("p"),WUr=o("This class cannot be instantiated directly using "),H0e=a("code"),HUr=o("__init__()"),UUr=o(" (throws an error)."),JUr=l(),Zt=a("div"),F(A$.$$.fragment),YUr=l(),U0e=a("p"),KUr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),ZUr=l(),bf=a("p"),eJr=o(`Note:
Loading a model from its configuration file does `),J0e=a("strong"),oJr=o("not"),rJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),loe=a("a"),tJr=o("from_pretrained()"),aJr=o(" to load the model weights."),nJr=l(),F(Ww.$$.fragment),sJr=l(),Yr=a("div"),F(L$.$$.fragment),lJr=l(),Y0e=a("p"),iJr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),dJr=l(),xn=a("p"),cJr=o("The model class to instantiate is selected based on the "),K0e=a("code"),fJr=o("model_type"),mJr=o(` property of the config object (either
passed as an argument or loaded from `),Z0e=a("code"),gJr=o("pretrained_model_name_or_path"),hJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ewe=a("code"),pJr=o("pretrained_model_name_or_path"),_Jr=o(":"),uJr=l(),owe=a("ul"),Hw=a("li"),rwe=a("strong"),bJr=o("bert"),vJr=o(" \u2014 "),ioe=a("a"),FJr=o("FlaxBertForNextSentencePrediction"),TJr=o(" (BERT model)"),MJr=l(),F(Uw.$$.fragment),DVe=l(),vf=a("h2"),Jw=a("a"),twe=a("span"),F(y$.$$.fragment),EJr=l(),awe=a("span"),CJr=o("FlaxAutoModelForImageClassification"),GVe=l(),Cr=a("div"),F(x$.$$.fragment),wJr=l(),Ff=a("p"),AJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),doe=a("a"),LJr=o("from_pretrained()"),yJr=o(" class method or the "),coe=a("a"),xJr=o("from_config()"),$Jr=o(` class
method.`),kJr=l(),$$=a("p"),SJr=o("This class cannot be instantiated directly using "),nwe=a("code"),RJr=o("__init__()"),PJr=o(" (throws an error)."),BJr=l(),ea=a("div"),F(k$.$$.fragment),IJr=l(),swe=a("p"),NJr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),qJr=l(),Tf=a("p"),jJr=o(`Note:
Loading a model from its configuration file does `),lwe=a("strong"),DJr=o("not"),GJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),foe=a("a"),OJr=o("from_pretrained()"),VJr=o(" to load the model weights."),XJr=l(),F(Yw.$$.fragment),zJr=l(),Kr=a("div"),F(S$.$$.fragment),QJr=l(),iwe=a("p"),WJr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),HJr=l(),$n=a("p"),UJr=o("The model class to instantiate is selected based on the "),dwe=a("code"),JJr=o("model_type"),YJr=o(` property of the config object (either
passed as an argument or loaded from `),cwe=a("code"),KJr=o("pretrained_model_name_or_path"),ZJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fwe=a("code"),eYr=o("pretrained_model_name_or_path"),oYr=o(":"),rYr=l(),R$=a("ul"),Kw=a("li"),mwe=a("strong"),tYr=o("beit"),aYr=o(" \u2014 "),moe=a("a"),nYr=o("FlaxBeitForImageClassification"),sYr=o(" (BEiT model)"),lYr=l(),Zw=a("li"),gwe=a("strong"),iYr=o("vit"),dYr=o(" \u2014 "),goe=a("a"),cYr=o("FlaxViTForImageClassification"),fYr=o(" (ViT model)"),mYr=l(),F(eA.$$.fragment),OVe=l(),Mf=a("h2"),oA=a("a"),hwe=a("span"),F(P$.$$.fragment),gYr=l(),pwe=a("span"),hYr=o("FlaxAutoModelForVision2Seq"),VVe=l(),wr=a("div"),F(B$.$$.fragment),pYr=l(),Ef=a("p"),_Yr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),hoe=a("a"),uYr=o("from_pretrained()"),bYr=o(" class method or the "),poe=a("a"),vYr=o("from_config()"),FYr=o(` class
method.`),TYr=l(),I$=a("p"),MYr=o("This class cannot be instantiated directly using "),_we=a("code"),EYr=o("__init__()"),CYr=o(" (throws an error)."),wYr=l(),oa=a("div"),F(N$.$$.fragment),AYr=l(),uwe=a("p"),LYr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),yYr=l(),Cf=a("p"),xYr=o(`Note:
Loading a model from its configuration file does `),bwe=a("strong"),$Yr=o("not"),kYr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_oe=a("a"),SYr=o("from_pretrained()"),RYr=o(" to load the model weights."),PYr=l(),F(rA.$$.fragment),BYr=l(),Zr=a("div"),F(q$.$$.fragment),IYr=l(),vwe=a("p"),NYr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),qYr=l(),kn=a("p"),jYr=o("The model class to instantiate is selected based on the "),Fwe=a("code"),DYr=o("model_type"),GYr=o(` property of the config object (either
passed as an argument or loaded from `),Twe=a("code"),OYr=o("pretrained_model_name_or_path"),VYr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mwe=a("code"),XYr=o("pretrained_model_name_or_path"),zYr=o(":"),QYr=l(),Ewe=a("ul"),tA=a("li"),Cwe=a("strong"),WYr=o("vision-encoder-decoder"),HYr=o(" \u2014 "),uoe=a("a"),UYr=o("FlaxVisionEncoderDecoderModel"),JYr=o(" (Vision Encoder decoder model)"),YYr=l(),F(aA.$$.fragment),this.h()},l(f){const u=MDt('[data-svelte="svelte-1phssyn"]',document.head);g=n(u,"META",{name:!0,content:!0}),u.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var j$=s(p);m=n(j$,"A",{id:!0,class:!0,href:!0});var wwe=s(m);_=n(wwe,"SPAN",{});var Awe=s(_);T(d.$$.fragment,Awe),Awe.forEach(t),wwe.forEach(t),h=i(j$),Eo=n(j$,"SPAN",{});var Lwe=s(Eo);Ti=r(Lwe,"Auto Classes"),Lwe.forEach(t),j$.forEach(t),yf=i(f),at=n(f,"P",{});var D$=s(at);Mi=r(D$,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Ei=n(D$,"CODE",{});var ywe=s(Ei);wL=r(ywe,"from_pretrained()"),ywe.forEach(t),xf=r(D$,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),D$.forEach(t),Oe=i(f),Qe=n(f,"P",{});var Sn=s(Qe);Ci=r(Sn,"Instantiating one of "),Rn=n(Sn,"A",{href:!0});var xwe=s(Rn);AL=r(xwe,"AutoConfig"),xwe.forEach(t),Pn=r(Sn,", "),Bn=n(Sn,"A",{href:!0});var $we=s(Bn);LL=r($we,"AutoModel"),$we.forEach(t),wi=r(Sn,`, and
`),In=n(Sn,"A",{href:!0});var kwe=s(In);yL=r(kwe,"AutoTokenizer"),kwe.forEach(t),Ai=r(Sn," will directly create a class of the relevant architecture. For instance"),Sn.forEach(t),$f=i(f),T(xa.$$.fragment,f),We=i(f),Ae=n(f,"P",{});var G$=s(Ae);rS=r(G$,"will create a model that is an instance of "),Li=n(G$,"A",{href:!0});var Swe=s(Li);tS=r(Swe,"BertModel"),Swe.forEach(t),aS=r(G$,"."),G$.forEach(t),Co=i(f),$a=n(f,"P",{});var O$=s($a);nS=r(O$,"There is one class of "),kf=n(O$,"CODE",{});var Rwe=s(kf);sS=r(Rwe,"AutoModel"),Rwe.forEach(t),eQe=r(O$," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),O$.forEach(t),jGe=i(f),yi=n(f,"H2",{class:!0});var V$=s(yi);Sf=n(V$,"A",{id:!0,class:!0,href:!0});var Pwe=s(Sf);mte=n(Pwe,"SPAN",{});var Bwe=s(mte);T(xL.$$.fragment,Bwe),Bwe.forEach(t),Pwe.forEach(t),oQe=i(V$),gte=n(V$,"SPAN",{});var Iwe=s(gte);rQe=r(Iwe,"Extending the Auto Classes"),Iwe.forEach(t),V$.forEach(t),DGe=i(f),Nn=n(f,"P",{});var wf=s(Nn);tQe=r(wf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),hte=n(wf,"CODE",{});var Nwe=s(hte);aQe=r(Nwe,"NewModel"),Nwe.forEach(t),nQe=r(wf,", make sure you have a "),pte=n(wf,"CODE",{});var qwe=s(pte);sQe=r(qwe,"NewModelConfig"),qwe.forEach(t),lQe=r(wf,` then you can add those to the auto
classes like this:`),wf.forEach(t),GGe=i(f),T($L.$$.fragment,f),OGe=i(f),lS=n(f,"P",{});var jwe=s(lS);iQe=r(jwe,"You will then be able to use the auto classes like you would usually do!"),jwe.forEach(t),VGe=i(f),T(Rf.$$.fragment,f),XGe=i(f),xi=n(f,"H2",{class:!0});var X$=s(xi);Pf=n(X$,"A",{id:!0,class:!0,href:!0});var Dwe=s(Pf);_te=n(Dwe,"SPAN",{});var Gwe=s(_te);T(kL.$$.fragment,Gwe),Gwe.forEach(t),Dwe.forEach(t),dQe=i(X$),ute=n(X$,"SPAN",{});var Owe=s(ute);cQe=r(Owe,"AutoConfig"),Owe.forEach(t),X$.forEach(t),zGe=i(f),wo=n(f,"DIV",{class:!0});var rt=s(wo);T(SL.$$.fragment,rt),fQe=i(rt),RL=n(rt,"P",{});var z$=s(RL);mQe=r(z$,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),iS=n(z$,"A",{href:!0});var Vwe=s(iS);gQe=r(Vwe,"from_pretrained()"),Vwe.forEach(t),hQe=r(z$," class method."),z$.forEach(t),pQe=i(rt),PL=n(rt,"P",{});var Q$=s(PL);_Qe=r(Q$,"This class cannot be instantiated directly using "),bte=n(Q$,"CODE",{});var Xwe=s(bte);uQe=r(Xwe,"__init__()"),Xwe.forEach(t),bQe=r(Q$," (throws an error)."),Q$.forEach(t),vQe=i(rt),Ar=n(rt,"DIV",{class:!0});var tt=s(Ar);T(BL.$$.fragment,tt),FQe=i(tt),vte=n(tt,"P",{});var zwe=s(vte);TQe=r(zwe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),zwe.forEach(t),MQe=i(tt),$i=n(tt,"P",{});var Af=s($i);EQe=r(Af,"The configuration class to instantiate is selected based on the "),Fte=n(Af,"CODE",{});var Qwe=s(Fte);CQe=r(Qwe,"model_type"),Qwe.forEach(t),wQe=r(Af,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Tte=n(Af,"CODE",{});var Wwe=s(Tte);AQe=r(Wwe,"pretrained_model_name_or_path"),Wwe.forEach(t),LQe=r(Af,":"),Af.forEach(t),yQe=i(tt),A=n(tt,"UL",{});var L=s(A);Bf=n(L,"LI",{});var nA=s(Bf);Mte=n(nA,"STRONG",{});var Hwe=s(Mte);xQe=r(Hwe,"albert"),Hwe.forEach(t),$Qe=r(nA," \u2014 "),dS=n(nA,"A",{href:!0});var Uwe=s(dS);kQe=r(Uwe,"AlbertConfig"),Uwe.forEach(t),SQe=r(nA," (ALBERT model)"),nA.forEach(t),RQe=i(L),If=n(L,"LI",{});var sA=s(If);Ete=n(sA,"STRONG",{});var Jwe=s(Ete);PQe=r(Jwe,"bart"),Jwe.forEach(t),BQe=r(sA," \u2014 "),cS=n(sA,"A",{href:!0});var Ywe=s(cS);IQe=r(Ywe,"BartConfig"),Ywe.forEach(t),NQe=r(sA," (BART model)"),sA.forEach(t),qQe=i(L),Nf=n(L,"LI",{});var lA=s(Nf);Cte=n(lA,"STRONG",{});var Kwe=s(Cte);jQe=r(Kwe,"beit"),Kwe.forEach(t),DQe=r(lA," \u2014 "),fS=n(lA,"A",{href:!0});var Zwe=s(fS);GQe=r(Zwe,"BeitConfig"),Zwe.forEach(t),OQe=r(lA," (BEiT model)"),lA.forEach(t),VQe=i(L),qf=n(L,"LI",{});var iA=s(qf);wte=n(iA,"STRONG",{});var eAe=s(wte);XQe=r(eAe,"bert"),eAe.forEach(t),zQe=r(iA," \u2014 "),mS=n(iA,"A",{href:!0});var oAe=s(mS);QQe=r(oAe,"BertConfig"),oAe.forEach(t),WQe=r(iA," (BERT model)"),iA.forEach(t),HQe=i(L),jf=n(L,"LI",{});var dA=s(jf);Ate=n(dA,"STRONG",{});var rAe=s(Ate);UQe=r(rAe,"bert-generation"),rAe.forEach(t),JQe=r(dA," \u2014 "),gS=n(dA,"A",{href:!0});var tAe=s(gS);YQe=r(tAe,"BertGenerationConfig"),tAe.forEach(t),KQe=r(dA," (Bert Generation model)"),dA.forEach(t),ZQe=i(L),Df=n(L,"LI",{});var cA=s(Df);Lte=n(cA,"STRONG",{});var aAe=s(Lte);eWe=r(aAe,"big_bird"),aAe.forEach(t),oWe=r(cA," \u2014 "),hS=n(cA,"A",{href:!0});var nAe=s(hS);rWe=r(nAe,"BigBirdConfig"),nAe.forEach(t),tWe=r(cA," (BigBird model)"),cA.forEach(t),aWe=i(L),Gf=n(L,"LI",{});var fA=s(Gf);yte=n(fA,"STRONG",{});var sAe=s(yte);nWe=r(sAe,"bigbird_pegasus"),sAe.forEach(t),sWe=r(fA," \u2014 "),pS=n(fA,"A",{href:!0});var lAe=s(pS);lWe=r(lAe,"BigBirdPegasusConfig"),lAe.forEach(t),iWe=r(fA," (BigBird-Pegasus model)"),fA.forEach(t),dWe=i(L),Of=n(L,"LI",{});var mA=s(Of);xte=n(mA,"STRONG",{});var iAe=s(xte);cWe=r(iAe,"blenderbot"),iAe.forEach(t),fWe=r(mA," \u2014 "),_S=n(mA,"A",{href:!0});var dAe=s(_S);mWe=r(dAe,"BlenderbotConfig"),dAe.forEach(t),gWe=r(mA," (Blenderbot model)"),mA.forEach(t),hWe=i(L),Vf=n(L,"LI",{});var gA=s(Vf);$te=n(gA,"STRONG",{});var cAe=s($te);pWe=r(cAe,"blenderbot-small"),cAe.forEach(t),_We=r(gA," \u2014 "),uS=n(gA,"A",{href:!0});var fAe=s(uS);uWe=r(fAe,"BlenderbotSmallConfig"),fAe.forEach(t),bWe=r(gA," (BlenderbotSmall model)"),gA.forEach(t),vWe=i(L),Xf=n(L,"LI",{});var hA=s(Xf);kte=n(hA,"STRONG",{});var mAe=s(kte);FWe=r(mAe,"bloom"),mAe.forEach(t),TWe=r(hA," \u2014 "),bS=n(hA,"A",{href:!0});var gAe=s(bS);MWe=r(gAe,"BloomConfig"),gAe.forEach(t),EWe=r(hA," (BLOOM model)"),hA.forEach(t),CWe=i(L),zf=n(L,"LI",{});var pA=s(zf);Ste=n(pA,"STRONG",{});var hAe=s(Ste);wWe=r(hAe,"camembert"),hAe.forEach(t),AWe=r(pA," \u2014 "),vS=n(pA,"A",{href:!0});var pAe=s(vS);LWe=r(pAe,"CamembertConfig"),pAe.forEach(t),yWe=r(pA," (CamemBERT model)"),pA.forEach(t),xWe=i(L),Qf=n(L,"LI",{});var _A=s(Qf);Rte=n(_A,"STRONG",{});var _Ae=s(Rte);$We=r(_Ae,"canine"),_Ae.forEach(t),kWe=r(_A," \u2014 "),FS=n(_A,"A",{href:!0});var uAe=s(FS);SWe=r(uAe,"CanineConfig"),uAe.forEach(t),RWe=r(_A," (CANINE model)"),_A.forEach(t),PWe=i(L),Wf=n(L,"LI",{});var uA=s(Wf);Pte=n(uA,"STRONG",{});var bAe=s(Pte);BWe=r(bAe,"clip"),bAe.forEach(t),IWe=r(uA," \u2014 "),TS=n(uA,"A",{href:!0});var vAe=s(TS);NWe=r(vAe,"CLIPConfig"),vAe.forEach(t),qWe=r(uA," (CLIP model)"),uA.forEach(t),jWe=i(L),Hf=n(L,"LI",{});var bA=s(Hf);Bte=n(bA,"STRONG",{});var FAe=s(Bte);DWe=r(FAe,"convbert"),FAe.forEach(t),GWe=r(bA," \u2014 "),MS=n(bA,"A",{href:!0});var TAe=s(MS);OWe=r(TAe,"ConvBertConfig"),TAe.forEach(t),VWe=r(bA," (ConvBERT model)"),bA.forEach(t),XWe=i(L),Uf=n(L,"LI",{});var vA=s(Uf);Ite=n(vA,"STRONG",{});var MAe=s(Ite);zWe=r(MAe,"convnext"),MAe.forEach(t),QWe=r(vA," \u2014 "),ES=n(vA,"A",{href:!0});var EAe=s(ES);WWe=r(EAe,"ConvNextConfig"),EAe.forEach(t),HWe=r(vA," (ConvNeXT model)"),vA.forEach(t),UWe=i(L),Jf=n(L,"LI",{});var FA=s(Jf);Nte=n(FA,"STRONG",{});var CAe=s(Nte);JWe=r(CAe,"ctrl"),CAe.forEach(t),YWe=r(FA," \u2014 "),CS=n(FA,"A",{href:!0});var wAe=s(CS);KWe=r(wAe,"CTRLConfig"),wAe.forEach(t),ZWe=r(FA," (CTRL model)"),FA.forEach(t),eHe=i(L),Yf=n(L,"LI",{});var TA=s(Yf);qte=n(TA,"STRONG",{});var AAe=s(qte);oHe=r(AAe,"cvt"),AAe.forEach(t),rHe=r(TA," \u2014 "),wS=n(TA,"A",{href:!0});var LAe=s(wS);tHe=r(LAe,"CvtConfig"),LAe.forEach(t),aHe=r(TA," (CvT model)"),TA.forEach(t),nHe=i(L),Kf=n(L,"LI",{});var MA=s(Kf);jte=n(MA,"STRONG",{});var yAe=s(jte);sHe=r(yAe,"data2vec-audio"),yAe.forEach(t),lHe=r(MA," \u2014 "),AS=n(MA,"A",{href:!0});var xAe=s(AS);iHe=r(xAe,"Data2VecAudioConfig"),xAe.forEach(t),dHe=r(MA," (Data2VecAudio model)"),MA.forEach(t),cHe=i(L),Zf=n(L,"LI",{});var EA=s(Zf);Dte=n(EA,"STRONG",{});var $Ae=s(Dte);fHe=r($Ae,"data2vec-text"),$Ae.forEach(t),mHe=r(EA," \u2014 "),LS=n(EA,"A",{href:!0});var kAe=s(LS);gHe=r(kAe,"Data2VecTextConfig"),kAe.forEach(t),hHe=r(EA," (Data2VecText model)"),EA.forEach(t),pHe=i(L),em=n(L,"LI",{});var CA=s(em);Gte=n(CA,"STRONG",{});var SAe=s(Gte);_He=r(SAe,"data2vec-vision"),SAe.forEach(t),uHe=r(CA," \u2014 "),yS=n(CA,"A",{href:!0});var RAe=s(yS);bHe=r(RAe,"Data2VecVisionConfig"),RAe.forEach(t),vHe=r(CA," (Data2VecVision model)"),CA.forEach(t),FHe=i(L),om=n(L,"LI",{});var wA=s(om);Ote=n(wA,"STRONG",{});var PAe=s(Ote);THe=r(PAe,"deberta"),PAe.forEach(t),MHe=r(wA," \u2014 "),xS=n(wA,"A",{href:!0});var BAe=s(xS);EHe=r(BAe,"DebertaConfig"),BAe.forEach(t),CHe=r(wA," (DeBERTa model)"),wA.forEach(t),wHe=i(L),rm=n(L,"LI",{});var AA=s(rm);Vte=n(AA,"STRONG",{});var IAe=s(Vte);AHe=r(IAe,"deberta-v2"),IAe.forEach(t),LHe=r(AA," \u2014 "),$S=n(AA,"A",{href:!0});var NAe=s($S);yHe=r(NAe,"DebertaV2Config"),NAe.forEach(t),xHe=r(AA," (DeBERTa-v2 model)"),AA.forEach(t),$He=i(L),tm=n(L,"LI",{});var LA=s(tm);Xte=n(LA,"STRONG",{});var qAe=s(Xte);kHe=r(qAe,"decision_transformer"),qAe.forEach(t),SHe=r(LA," \u2014 "),kS=n(LA,"A",{href:!0});var jAe=s(kS);RHe=r(jAe,"DecisionTransformerConfig"),jAe.forEach(t),PHe=r(LA," (Decision Transformer model)"),LA.forEach(t),BHe=i(L),am=n(L,"LI",{});var yA=s(am);zte=n(yA,"STRONG",{});var ZYr=s(zte);IHe=r(ZYr,"deit"),ZYr.forEach(t),NHe=r(yA," \u2014 "),SS=n(yA,"A",{href:!0});var eKr=s(SS);qHe=r(eKr,"DeiTConfig"),eKr.forEach(t),jHe=r(yA," (DeiT model)"),yA.forEach(t),DHe=i(L),nm=n(L,"LI",{});var DAe=s(nm);Qte=n(DAe,"STRONG",{});var oKr=s(Qte);GHe=r(oKr,"detr"),oKr.forEach(t),OHe=r(DAe," \u2014 "),RS=n(DAe,"A",{href:!0});var rKr=s(RS);VHe=r(rKr,"DetrConfig"),rKr.forEach(t),XHe=r(DAe," (DETR model)"),DAe.forEach(t),zHe=i(L),sm=n(L,"LI",{});var GAe=s(sm);Wte=n(GAe,"STRONG",{});var tKr=s(Wte);QHe=r(tKr,"distilbert"),tKr.forEach(t),WHe=r(GAe," \u2014 "),PS=n(GAe,"A",{href:!0});var aKr=s(PS);HHe=r(aKr,"DistilBertConfig"),aKr.forEach(t),UHe=r(GAe," (DistilBERT model)"),GAe.forEach(t),JHe=i(L),lm=n(L,"LI",{});var OAe=s(lm);Hte=n(OAe,"STRONG",{});var nKr=s(Hte);YHe=r(nKr,"dpr"),nKr.forEach(t),KHe=r(OAe," \u2014 "),BS=n(OAe,"A",{href:!0});var sKr=s(BS);ZHe=r(sKr,"DPRConfig"),sKr.forEach(t),eUe=r(OAe," (DPR model)"),OAe.forEach(t),oUe=i(L),im=n(L,"LI",{});var VAe=s(im);Ute=n(VAe,"STRONG",{});var lKr=s(Ute);rUe=r(lKr,"dpt"),lKr.forEach(t),tUe=r(VAe," \u2014 "),IS=n(VAe,"A",{href:!0});var iKr=s(IS);aUe=r(iKr,"DPTConfig"),iKr.forEach(t),nUe=r(VAe," (DPT model)"),VAe.forEach(t),sUe=i(L),dm=n(L,"LI",{});var XAe=s(dm);Jte=n(XAe,"STRONG",{});var dKr=s(Jte);lUe=r(dKr,"electra"),dKr.forEach(t),iUe=r(XAe," \u2014 "),NS=n(XAe,"A",{href:!0});var cKr=s(NS);dUe=r(cKr,"ElectraConfig"),cKr.forEach(t),cUe=r(XAe," (ELECTRA model)"),XAe.forEach(t),fUe=i(L),cm=n(L,"LI",{});var zAe=s(cm);Yte=n(zAe,"STRONG",{});var fKr=s(Yte);mUe=r(fKr,"encoder-decoder"),fKr.forEach(t),gUe=r(zAe," \u2014 "),qS=n(zAe,"A",{href:!0});var mKr=s(qS);hUe=r(mKr,"EncoderDecoderConfig"),mKr.forEach(t),pUe=r(zAe," (Encoder decoder model)"),zAe.forEach(t),_Ue=i(L),fm=n(L,"LI",{});var QAe=s(fm);Kte=n(QAe,"STRONG",{});var gKr=s(Kte);uUe=r(gKr,"flaubert"),gKr.forEach(t),bUe=r(QAe," \u2014 "),jS=n(QAe,"A",{href:!0});var hKr=s(jS);vUe=r(hKr,"FlaubertConfig"),hKr.forEach(t),FUe=r(QAe," (FlauBERT model)"),QAe.forEach(t),TUe=i(L),mm=n(L,"LI",{});var WAe=s(mm);Zte=n(WAe,"STRONG",{});var pKr=s(Zte);MUe=r(pKr,"flava"),pKr.forEach(t),EUe=r(WAe," \u2014 "),DS=n(WAe,"A",{href:!0});var _Kr=s(DS);CUe=r(_Kr,"FlavaConfig"),_Kr.forEach(t),wUe=r(WAe," (FLAVA model)"),WAe.forEach(t),AUe=i(L),gm=n(L,"LI",{});var HAe=s(gm);eae=n(HAe,"STRONG",{});var uKr=s(eae);LUe=r(uKr,"fnet"),uKr.forEach(t),yUe=r(HAe," \u2014 "),GS=n(HAe,"A",{href:!0});var bKr=s(GS);xUe=r(bKr,"FNetConfig"),bKr.forEach(t),$Ue=r(HAe," (FNet model)"),HAe.forEach(t),kUe=i(L),hm=n(L,"LI",{});var UAe=s(hm);oae=n(UAe,"STRONG",{});var vKr=s(oae);SUe=r(vKr,"fsmt"),vKr.forEach(t),RUe=r(UAe," \u2014 "),OS=n(UAe,"A",{href:!0});var FKr=s(OS);PUe=r(FKr,"FSMTConfig"),FKr.forEach(t),BUe=r(UAe," (FairSeq Machine-Translation model)"),UAe.forEach(t),IUe=i(L),pm=n(L,"LI",{});var JAe=s(pm);rae=n(JAe,"STRONG",{});var TKr=s(rae);NUe=r(TKr,"funnel"),TKr.forEach(t),qUe=r(JAe," \u2014 "),VS=n(JAe,"A",{href:!0});var MKr=s(VS);jUe=r(MKr,"FunnelConfig"),MKr.forEach(t),DUe=r(JAe," (Funnel Transformer model)"),JAe.forEach(t),GUe=i(L),_m=n(L,"LI",{});var YAe=s(_m);tae=n(YAe,"STRONG",{});var EKr=s(tae);OUe=r(EKr,"glpn"),EKr.forEach(t),VUe=r(YAe," \u2014 "),XS=n(YAe,"A",{href:!0});var CKr=s(XS);XUe=r(CKr,"GLPNConfig"),CKr.forEach(t),zUe=r(YAe," (GLPN model)"),YAe.forEach(t),QUe=i(L),um=n(L,"LI",{});var KAe=s(um);aae=n(KAe,"STRONG",{});var wKr=s(aae);WUe=r(wKr,"gpt2"),wKr.forEach(t),HUe=r(KAe," \u2014 "),zS=n(KAe,"A",{href:!0});var AKr=s(zS);UUe=r(AKr,"GPT2Config"),AKr.forEach(t),JUe=r(KAe," (OpenAI GPT-2 model)"),KAe.forEach(t),YUe=i(L),bm=n(L,"LI",{});var ZAe=s(bm);nae=n(ZAe,"STRONG",{});var LKr=s(nae);KUe=r(LKr,"gpt_neo"),LKr.forEach(t),ZUe=r(ZAe," \u2014 "),QS=n(ZAe,"A",{href:!0});var yKr=s(QS);eJe=r(yKr,"GPTNeoConfig"),yKr.forEach(t),oJe=r(ZAe," (GPT Neo model)"),ZAe.forEach(t),rJe=i(L),vm=n(L,"LI",{});var e6e=s(vm);sae=n(e6e,"STRONG",{});var xKr=s(sae);tJe=r(xKr,"gpt_neox"),xKr.forEach(t),aJe=r(e6e," \u2014 "),WS=n(e6e,"A",{href:!0});var $Kr=s(WS);nJe=r($Kr,"GPTNeoXConfig"),$Kr.forEach(t),sJe=r(e6e," (GPT NeoX model)"),e6e.forEach(t),lJe=i(L),Fm=n(L,"LI",{});var o6e=s(Fm);lae=n(o6e,"STRONG",{});var kKr=s(lae);iJe=r(kKr,"gptj"),kKr.forEach(t),dJe=r(o6e," \u2014 "),HS=n(o6e,"A",{href:!0});var SKr=s(HS);cJe=r(SKr,"GPTJConfig"),SKr.forEach(t),fJe=r(o6e," (GPT-J model)"),o6e.forEach(t),mJe=i(L),Tm=n(L,"LI",{});var r6e=s(Tm);iae=n(r6e,"STRONG",{});var RKr=s(iae);gJe=r(RKr,"hubert"),RKr.forEach(t),hJe=r(r6e," \u2014 "),US=n(r6e,"A",{href:!0});var PKr=s(US);pJe=r(PKr,"HubertConfig"),PKr.forEach(t),_Je=r(r6e," (Hubert model)"),r6e.forEach(t),uJe=i(L),Mm=n(L,"LI",{});var t6e=s(Mm);dae=n(t6e,"STRONG",{});var BKr=s(dae);bJe=r(BKr,"ibert"),BKr.forEach(t),vJe=r(t6e," \u2014 "),JS=n(t6e,"A",{href:!0});var IKr=s(JS);FJe=r(IKr,"IBertConfig"),IKr.forEach(t),TJe=r(t6e," (I-BERT model)"),t6e.forEach(t),MJe=i(L),Em=n(L,"LI",{});var a6e=s(Em);cae=n(a6e,"STRONG",{});var NKr=s(cae);EJe=r(NKr,"imagegpt"),NKr.forEach(t),CJe=r(a6e," \u2014 "),YS=n(a6e,"A",{href:!0});var qKr=s(YS);wJe=r(qKr,"ImageGPTConfig"),qKr.forEach(t),AJe=r(a6e," (ImageGPT model)"),a6e.forEach(t),LJe=i(L),Cm=n(L,"LI",{});var n6e=s(Cm);fae=n(n6e,"STRONG",{});var jKr=s(fae);yJe=r(jKr,"layoutlm"),jKr.forEach(t),xJe=r(n6e," \u2014 "),KS=n(n6e,"A",{href:!0});var DKr=s(KS);$Je=r(DKr,"LayoutLMConfig"),DKr.forEach(t),kJe=r(n6e," (LayoutLM model)"),n6e.forEach(t),SJe=i(L),wm=n(L,"LI",{});var s6e=s(wm);mae=n(s6e,"STRONG",{});var GKr=s(mae);RJe=r(GKr,"layoutlmv2"),GKr.forEach(t),PJe=r(s6e," \u2014 "),ZS=n(s6e,"A",{href:!0});var OKr=s(ZS);BJe=r(OKr,"LayoutLMv2Config"),OKr.forEach(t),IJe=r(s6e," (LayoutLMv2 model)"),s6e.forEach(t),NJe=i(L),Am=n(L,"LI",{});var l6e=s(Am);gae=n(l6e,"STRONG",{});var VKr=s(gae);qJe=r(VKr,"layoutlmv3"),VKr.forEach(t),jJe=r(l6e," \u2014 "),eR=n(l6e,"A",{href:!0});var XKr=s(eR);DJe=r(XKr,"LayoutLMv3Config"),XKr.forEach(t),GJe=r(l6e," (LayoutLMv3 model)"),l6e.forEach(t),OJe=i(L),Lm=n(L,"LI",{});var i6e=s(Lm);hae=n(i6e,"STRONG",{});var zKr=s(hae);VJe=r(zKr,"led"),zKr.forEach(t),XJe=r(i6e," \u2014 "),oR=n(i6e,"A",{href:!0});var QKr=s(oR);zJe=r(QKr,"LEDConfig"),QKr.forEach(t),QJe=r(i6e," (LED model)"),i6e.forEach(t),WJe=i(L),ym=n(L,"LI",{});var d6e=s(ym);pae=n(d6e,"STRONG",{});var WKr=s(pae);HJe=r(WKr,"levit"),WKr.forEach(t),UJe=r(d6e," \u2014 "),rR=n(d6e,"A",{href:!0});var HKr=s(rR);JJe=r(HKr,"LevitConfig"),HKr.forEach(t),YJe=r(d6e," (LeViT model)"),d6e.forEach(t),KJe=i(L),xm=n(L,"LI",{});var c6e=s(xm);_ae=n(c6e,"STRONG",{});var UKr=s(_ae);ZJe=r(UKr,"longformer"),UKr.forEach(t),eYe=r(c6e," \u2014 "),tR=n(c6e,"A",{href:!0});var JKr=s(tR);oYe=r(JKr,"LongformerConfig"),JKr.forEach(t),rYe=r(c6e," (Longformer model)"),c6e.forEach(t),tYe=i(L),$m=n(L,"LI",{});var f6e=s($m);uae=n(f6e,"STRONG",{});var YKr=s(uae);aYe=r(YKr,"longt5"),YKr.forEach(t),nYe=r(f6e," \u2014 "),aR=n(f6e,"A",{href:!0});var KKr=s(aR);sYe=r(KKr,"LongT5Config"),KKr.forEach(t),lYe=r(f6e," (LongT5 model)"),f6e.forEach(t),iYe=i(L),km=n(L,"LI",{});var m6e=s(km);bae=n(m6e,"STRONG",{});var ZKr=s(bae);dYe=r(ZKr,"luke"),ZKr.forEach(t),cYe=r(m6e," \u2014 "),nR=n(m6e,"A",{href:!0});var eZr=s(nR);fYe=r(eZr,"LukeConfig"),eZr.forEach(t),mYe=r(m6e," (LUKE model)"),m6e.forEach(t),gYe=i(L),Sm=n(L,"LI",{});var g6e=s(Sm);vae=n(g6e,"STRONG",{});var oZr=s(vae);hYe=r(oZr,"lxmert"),oZr.forEach(t),pYe=r(g6e," \u2014 "),sR=n(g6e,"A",{href:!0});var rZr=s(sR);_Ye=r(rZr,"LxmertConfig"),rZr.forEach(t),uYe=r(g6e," (LXMERT model)"),g6e.forEach(t),bYe=i(L),Rm=n(L,"LI",{});var h6e=s(Rm);Fae=n(h6e,"STRONG",{});var tZr=s(Fae);vYe=r(tZr,"m2m_100"),tZr.forEach(t),FYe=r(h6e," \u2014 "),lR=n(h6e,"A",{href:!0});var aZr=s(lR);TYe=r(aZr,"M2M100Config"),aZr.forEach(t),MYe=r(h6e," (M2M100 model)"),h6e.forEach(t),EYe=i(L),Pm=n(L,"LI",{});var p6e=s(Pm);Tae=n(p6e,"STRONG",{});var nZr=s(Tae);CYe=r(nZr,"marian"),nZr.forEach(t),wYe=r(p6e," \u2014 "),iR=n(p6e,"A",{href:!0});var sZr=s(iR);AYe=r(sZr,"MarianConfig"),sZr.forEach(t),LYe=r(p6e," (Marian model)"),p6e.forEach(t),yYe=i(L),Bm=n(L,"LI",{});var _6e=s(Bm);Mae=n(_6e,"STRONG",{});var lZr=s(Mae);xYe=r(lZr,"maskformer"),lZr.forEach(t),$Ye=r(_6e," \u2014 "),dR=n(_6e,"A",{href:!0});var iZr=s(dR);kYe=r(iZr,"MaskFormerConfig"),iZr.forEach(t),SYe=r(_6e," (MaskFormer model)"),_6e.forEach(t),RYe=i(L),Im=n(L,"LI",{});var u6e=s(Im);Eae=n(u6e,"STRONG",{});var dZr=s(Eae);PYe=r(dZr,"mbart"),dZr.forEach(t),BYe=r(u6e," \u2014 "),cR=n(u6e,"A",{href:!0});var cZr=s(cR);IYe=r(cZr,"MBartConfig"),cZr.forEach(t),NYe=r(u6e," (mBART model)"),u6e.forEach(t),qYe=i(L),Nm=n(L,"LI",{});var b6e=s(Nm);Cae=n(b6e,"STRONG",{});var fZr=s(Cae);jYe=r(fZr,"mctct"),fZr.forEach(t),DYe=r(b6e," \u2014 "),fR=n(b6e,"A",{href:!0});var mZr=s(fR);GYe=r(mZr,"MCTCTConfig"),mZr.forEach(t),OYe=r(b6e," (M-CTC-T model)"),b6e.forEach(t),VYe=i(L),qm=n(L,"LI",{});var v6e=s(qm);wae=n(v6e,"STRONG",{});var gZr=s(wae);XYe=r(gZr,"megatron-bert"),gZr.forEach(t),zYe=r(v6e," \u2014 "),mR=n(v6e,"A",{href:!0});var hZr=s(mR);QYe=r(hZr,"MegatronBertConfig"),hZr.forEach(t),WYe=r(v6e," (Megatron-BERT model)"),v6e.forEach(t),HYe=i(L),jm=n(L,"LI",{});var F6e=s(jm);Aae=n(F6e,"STRONG",{});var pZr=s(Aae);UYe=r(pZr,"mobilebert"),pZr.forEach(t),JYe=r(F6e," \u2014 "),gR=n(F6e,"A",{href:!0});var _Zr=s(gR);YYe=r(_Zr,"MobileBertConfig"),_Zr.forEach(t),KYe=r(F6e," (MobileBERT model)"),F6e.forEach(t),ZYe=i(L),Dm=n(L,"LI",{});var T6e=s(Dm);Lae=n(T6e,"STRONG",{});var uZr=s(Lae);eKe=r(uZr,"mpnet"),uZr.forEach(t),oKe=r(T6e," \u2014 "),hR=n(T6e,"A",{href:!0});var bZr=s(hR);rKe=r(bZr,"MPNetConfig"),bZr.forEach(t),tKe=r(T6e," (MPNet model)"),T6e.forEach(t),aKe=i(L),Gm=n(L,"LI",{});var M6e=s(Gm);yae=n(M6e,"STRONG",{});var vZr=s(yae);nKe=r(vZr,"mt5"),vZr.forEach(t),sKe=r(M6e," \u2014 "),pR=n(M6e,"A",{href:!0});var FZr=s(pR);lKe=r(FZr,"MT5Config"),FZr.forEach(t),iKe=r(M6e," (MT5 model)"),M6e.forEach(t),dKe=i(L),Om=n(L,"LI",{});var E6e=s(Om);xae=n(E6e,"STRONG",{});var TZr=s(xae);cKe=r(TZr,"nezha"),TZr.forEach(t),fKe=r(E6e," \u2014 "),_R=n(E6e,"A",{href:!0});var MZr=s(_R);mKe=r(MZr,"NezhaConfig"),MZr.forEach(t),gKe=r(E6e," (Nezha model)"),E6e.forEach(t),hKe=i(L),Vm=n(L,"LI",{});var C6e=s(Vm);$ae=n(C6e,"STRONG",{});var EZr=s($ae);pKe=r(EZr,"nystromformer"),EZr.forEach(t),_Ke=r(C6e," \u2014 "),uR=n(C6e,"A",{href:!0});var CZr=s(uR);uKe=r(CZr,"NystromformerConfig"),CZr.forEach(t),bKe=r(C6e," (Nystr\xF6mformer model)"),C6e.forEach(t),vKe=i(L),Xm=n(L,"LI",{});var w6e=s(Xm);kae=n(w6e,"STRONG",{});var wZr=s(kae);FKe=r(wZr,"openai-gpt"),wZr.forEach(t),TKe=r(w6e," \u2014 "),bR=n(w6e,"A",{href:!0});var AZr=s(bR);MKe=r(AZr,"OpenAIGPTConfig"),AZr.forEach(t),EKe=r(w6e," (OpenAI GPT model)"),w6e.forEach(t),CKe=i(L),zm=n(L,"LI",{});var A6e=s(zm);Sae=n(A6e,"STRONG",{});var LZr=s(Sae);wKe=r(LZr,"opt"),LZr.forEach(t),AKe=r(A6e," \u2014 "),vR=n(A6e,"A",{href:!0});var yZr=s(vR);LKe=r(yZr,"OPTConfig"),yZr.forEach(t),yKe=r(A6e," (OPT model)"),A6e.forEach(t),xKe=i(L),Qm=n(L,"LI",{});var L6e=s(Qm);Rae=n(L6e,"STRONG",{});var xZr=s(Rae);$Ke=r(xZr,"pegasus"),xZr.forEach(t),kKe=r(L6e," \u2014 "),FR=n(L6e,"A",{href:!0});var $Zr=s(FR);SKe=r($Zr,"PegasusConfig"),$Zr.forEach(t),RKe=r(L6e," (Pegasus model)"),L6e.forEach(t),PKe=i(L),Wm=n(L,"LI",{});var y6e=s(Wm);Pae=n(y6e,"STRONG",{});var kZr=s(Pae);BKe=r(kZr,"perceiver"),kZr.forEach(t),IKe=r(y6e," \u2014 "),TR=n(y6e,"A",{href:!0});var SZr=s(TR);NKe=r(SZr,"PerceiverConfig"),SZr.forEach(t),qKe=r(y6e," (Perceiver model)"),y6e.forEach(t),jKe=i(L),Hm=n(L,"LI",{});var x6e=s(Hm);Bae=n(x6e,"STRONG",{});var RZr=s(Bae);DKe=r(RZr,"plbart"),RZr.forEach(t),GKe=r(x6e," \u2014 "),MR=n(x6e,"A",{href:!0});var PZr=s(MR);OKe=r(PZr,"PLBartConfig"),PZr.forEach(t),VKe=r(x6e," (PLBart model)"),x6e.forEach(t),XKe=i(L),Um=n(L,"LI",{});var $6e=s(Um);Iae=n($6e,"STRONG",{});var BZr=s(Iae);zKe=r(BZr,"poolformer"),BZr.forEach(t),QKe=r($6e," \u2014 "),ER=n($6e,"A",{href:!0});var IZr=s(ER);WKe=r(IZr,"PoolFormerConfig"),IZr.forEach(t),HKe=r($6e," (PoolFormer model)"),$6e.forEach(t),UKe=i(L),Jm=n(L,"LI",{});var k6e=s(Jm);Nae=n(k6e,"STRONG",{});var NZr=s(Nae);JKe=r(NZr,"prophetnet"),NZr.forEach(t),YKe=r(k6e," \u2014 "),CR=n(k6e,"A",{href:!0});var qZr=s(CR);KKe=r(qZr,"ProphetNetConfig"),qZr.forEach(t),ZKe=r(k6e," (ProphetNet model)"),k6e.forEach(t),eZe=i(L),Ym=n(L,"LI",{});var S6e=s(Ym);qae=n(S6e,"STRONG",{});var jZr=s(qae);oZe=r(jZr,"qdqbert"),jZr.forEach(t),rZe=r(S6e," \u2014 "),wR=n(S6e,"A",{href:!0});var DZr=s(wR);tZe=r(DZr,"QDQBertConfig"),DZr.forEach(t),aZe=r(S6e," (QDQBert model)"),S6e.forEach(t),nZe=i(L),Km=n(L,"LI",{});var R6e=s(Km);jae=n(R6e,"STRONG",{});var GZr=s(jae);sZe=r(GZr,"rag"),GZr.forEach(t),lZe=r(R6e," \u2014 "),AR=n(R6e,"A",{href:!0});var OZr=s(AR);iZe=r(OZr,"RagConfig"),OZr.forEach(t),dZe=r(R6e," (RAG model)"),R6e.forEach(t),cZe=i(L),Zm=n(L,"LI",{});var P6e=s(Zm);Dae=n(P6e,"STRONG",{});var VZr=s(Dae);fZe=r(VZr,"realm"),VZr.forEach(t),mZe=r(P6e," \u2014 "),LR=n(P6e,"A",{href:!0});var XZr=s(LR);gZe=r(XZr,"RealmConfig"),XZr.forEach(t),hZe=r(P6e," (REALM model)"),P6e.forEach(t),pZe=i(L),eg=n(L,"LI",{});var B6e=s(eg);Gae=n(B6e,"STRONG",{});var zZr=s(Gae);_Ze=r(zZr,"reformer"),zZr.forEach(t),uZe=r(B6e," \u2014 "),yR=n(B6e,"A",{href:!0});var QZr=s(yR);bZe=r(QZr,"ReformerConfig"),QZr.forEach(t),vZe=r(B6e," (Reformer model)"),B6e.forEach(t),FZe=i(L),og=n(L,"LI",{});var I6e=s(og);Oae=n(I6e,"STRONG",{});var WZr=s(Oae);TZe=r(WZr,"regnet"),WZr.forEach(t),MZe=r(I6e," \u2014 "),xR=n(I6e,"A",{href:!0});var HZr=s(xR);EZe=r(HZr,"RegNetConfig"),HZr.forEach(t),CZe=r(I6e," (RegNet model)"),I6e.forEach(t),wZe=i(L),rg=n(L,"LI",{});var N6e=s(rg);Vae=n(N6e,"STRONG",{});var UZr=s(Vae);AZe=r(UZr,"rembert"),UZr.forEach(t),LZe=r(N6e," \u2014 "),$R=n(N6e,"A",{href:!0});var JZr=s($R);yZe=r(JZr,"RemBertConfig"),JZr.forEach(t),xZe=r(N6e," (RemBERT model)"),N6e.forEach(t),$Ze=i(L),tg=n(L,"LI",{});var q6e=s(tg);Xae=n(q6e,"STRONG",{});var YZr=s(Xae);kZe=r(YZr,"resnet"),YZr.forEach(t),SZe=r(q6e," \u2014 "),kR=n(q6e,"A",{href:!0});var KZr=s(kR);RZe=r(KZr,"ResNetConfig"),KZr.forEach(t),PZe=r(q6e," (ResNet model)"),q6e.forEach(t),BZe=i(L),ag=n(L,"LI",{});var j6e=s(ag);zae=n(j6e,"STRONG",{});var ZZr=s(zae);IZe=r(ZZr,"retribert"),ZZr.forEach(t),NZe=r(j6e," \u2014 "),SR=n(j6e,"A",{href:!0});var eet=s(SR);qZe=r(eet,"RetriBertConfig"),eet.forEach(t),jZe=r(j6e," (RetriBERT model)"),j6e.forEach(t),DZe=i(L),ng=n(L,"LI",{});var D6e=s(ng);Qae=n(D6e,"STRONG",{});var oet=s(Qae);GZe=r(oet,"roberta"),oet.forEach(t),OZe=r(D6e," \u2014 "),RR=n(D6e,"A",{href:!0});var ret=s(RR);VZe=r(ret,"RobertaConfig"),ret.forEach(t),XZe=r(D6e," (RoBERTa model)"),D6e.forEach(t),zZe=i(L),sg=n(L,"LI",{});var G6e=s(sg);Wae=n(G6e,"STRONG",{});var tet=s(Wae);QZe=r(tet,"roformer"),tet.forEach(t),WZe=r(G6e," \u2014 "),PR=n(G6e,"A",{href:!0});var aet=s(PR);HZe=r(aet,"RoFormerConfig"),aet.forEach(t),UZe=r(G6e," (RoFormer model)"),G6e.forEach(t),JZe=i(L),lg=n(L,"LI",{});var O6e=s(lg);Hae=n(O6e,"STRONG",{});var net=s(Hae);YZe=r(net,"segformer"),net.forEach(t),KZe=r(O6e," \u2014 "),BR=n(O6e,"A",{href:!0});var set=s(BR);ZZe=r(set,"SegformerConfig"),set.forEach(t),eeo=r(O6e," (SegFormer model)"),O6e.forEach(t),oeo=i(L),ig=n(L,"LI",{});var V6e=s(ig);Uae=n(V6e,"STRONG",{});var iet=s(Uae);reo=r(iet,"sew"),iet.forEach(t),teo=r(V6e," \u2014 "),IR=n(V6e,"A",{href:!0});var det=s(IR);aeo=r(det,"SEWConfig"),det.forEach(t),neo=r(V6e," (SEW model)"),V6e.forEach(t),seo=i(L),dg=n(L,"LI",{});var X6e=s(dg);Jae=n(X6e,"STRONG",{});var cet=s(Jae);leo=r(cet,"sew-d"),cet.forEach(t),ieo=r(X6e," \u2014 "),NR=n(X6e,"A",{href:!0});var fet=s(NR);deo=r(fet,"SEWDConfig"),fet.forEach(t),ceo=r(X6e," (SEW-D model)"),X6e.forEach(t),feo=i(L),cg=n(L,"LI",{});var z6e=s(cg);Yae=n(z6e,"STRONG",{});var met=s(Yae);meo=r(met,"speech-encoder-decoder"),met.forEach(t),geo=r(z6e," \u2014 "),qR=n(z6e,"A",{href:!0});var get=s(qR);heo=r(get,"SpeechEncoderDecoderConfig"),get.forEach(t),peo=r(z6e," (Speech Encoder decoder model)"),z6e.forEach(t),_eo=i(L),fg=n(L,"LI",{});var Q6e=s(fg);Kae=n(Q6e,"STRONG",{});var het=s(Kae);ueo=r(het,"speech_to_text"),het.forEach(t),beo=r(Q6e," \u2014 "),jR=n(Q6e,"A",{href:!0});var pet=s(jR);veo=r(pet,"Speech2TextConfig"),pet.forEach(t),Feo=r(Q6e," (Speech2Text model)"),Q6e.forEach(t),Teo=i(L),mg=n(L,"LI",{});var W6e=s(mg);Zae=n(W6e,"STRONG",{});var _et=s(Zae);Meo=r(_et,"speech_to_text_2"),_et.forEach(t),Eeo=r(W6e," \u2014 "),DR=n(W6e,"A",{href:!0});var uet=s(DR);Ceo=r(uet,"Speech2Text2Config"),uet.forEach(t),weo=r(W6e," (Speech2Text2 model)"),W6e.forEach(t),Aeo=i(L),gg=n(L,"LI",{});var H6e=s(gg);ene=n(H6e,"STRONG",{});var bet=s(ene);Leo=r(bet,"splinter"),bet.forEach(t),yeo=r(H6e," \u2014 "),GR=n(H6e,"A",{href:!0});var vet=s(GR);xeo=r(vet,"SplinterConfig"),vet.forEach(t),$eo=r(H6e," (Splinter model)"),H6e.forEach(t),keo=i(L),hg=n(L,"LI",{});var U6e=s(hg);one=n(U6e,"STRONG",{});var Fet=s(one);Seo=r(Fet,"squeezebert"),Fet.forEach(t),Reo=r(U6e," \u2014 "),OR=n(U6e,"A",{href:!0});var Tet=s(OR);Peo=r(Tet,"SqueezeBertConfig"),Tet.forEach(t),Beo=r(U6e," (SqueezeBERT model)"),U6e.forEach(t),Ieo=i(L),pg=n(L,"LI",{});var J6e=s(pg);rne=n(J6e,"STRONG",{});var Met=s(rne);Neo=r(Met,"swin"),Met.forEach(t),qeo=r(J6e," \u2014 "),VR=n(J6e,"A",{href:!0});var Eet=s(VR);jeo=r(Eet,"SwinConfig"),Eet.forEach(t),Deo=r(J6e," (Swin Transformer model)"),J6e.forEach(t),Geo=i(L),_g=n(L,"LI",{});var Y6e=s(_g);tne=n(Y6e,"STRONG",{});var Cet=s(tne);Oeo=r(Cet,"t5"),Cet.forEach(t),Veo=r(Y6e," \u2014 "),XR=n(Y6e,"A",{href:!0});var wet=s(XR);Xeo=r(wet,"T5Config"),wet.forEach(t),zeo=r(Y6e," (T5 model)"),Y6e.forEach(t),Qeo=i(L),ug=n(L,"LI",{});var K6e=s(ug);ane=n(K6e,"STRONG",{});var Aet=s(ane);Weo=r(Aet,"tapas"),Aet.forEach(t),Heo=r(K6e," \u2014 "),zR=n(K6e,"A",{href:!0});var Let=s(zR);Ueo=r(Let,"TapasConfig"),Let.forEach(t),Jeo=r(K6e," (TAPAS model)"),K6e.forEach(t),Yeo=i(L),bg=n(L,"LI",{});var Z6e=s(bg);nne=n(Z6e,"STRONG",{});var yet=s(nne);Keo=r(yet,"trajectory_transformer"),yet.forEach(t),Zeo=r(Z6e," \u2014 "),QR=n(Z6e,"A",{href:!0});var xet=s(QR);eoo=r(xet,"TrajectoryTransformerConfig"),xet.forEach(t),ooo=r(Z6e," (Trajectory Transformer model)"),Z6e.forEach(t),roo=i(L),vg=n(L,"LI",{});var eLe=s(vg);sne=n(eLe,"STRONG",{});var $et=s(sne);too=r($et,"transfo-xl"),$et.forEach(t),aoo=r(eLe," \u2014 "),WR=n(eLe,"A",{href:!0});var ket=s(WR);noo=r(ket,"TransfoXLConfig"),ket.forEach(t),soo=r(eLe," (Transformer-XL model)"),eLe.forEach(t),loo=i(L),Fg=n(L,"LI",{});var oLe=s(Fg);lne=n(oLe,"STRONG",{});var Set=s(lne);ioo=r(Set,"trocr"),Set.forEach(t),doo=r(oLe," \u2014 "),HR=n(oLe,"A",{href:!0});var Ret=s(HR);coo=r(Ret,"TrOCRConfig"),Ret.forEach(t),foo=r(oLe," (TrOCR model)"),oLe.forEach(t),moo=i(L),Tg=n(L,"LI",{});var rLe=s(Tg);ine=n(rLe,"STRONG",{});var Pet=s(ine);goo=r(Pet,"unispeech"),Pet.forEach(t),hoo=r(rLe," \u2014 "),UR=n(rLe,"A",{href:!0});var Bet=s(UR);poo=r(Bet,"UniSpeechConfig"),Bet.forEach(t),_oo=r(rLe," (UniSpeech model)"),rLe.forEach(t),uoo=i(L),Mg=n(L,"LI",{});var tLe=s(Mg);dne=n(tLe,"STRONG",{});var Iet=s(dne);boo=r(Iet,"unispeech-sat"),Iet.forEach(t),voo=r(tLe," \u2014 "),JR=n(tLe,"A",{href:!0});var Net=s(JR);Foo=r(Net,"UniSpeechSatConfig"),Net.forEach(t),Too=r(tLe," (UniSpeechSat model)"),tLe.forEach(t),Moo=i(L),Eg=n(L,"LI",{});var aLe=s(Eg);cne=n(aLe,"STRONG",{});var qet=s(cne);Eoo=r(qet,"van"),qet.forEach(t),Coo=r(aLe," \u2014 "),YR=n(aLe,"A",{href:!0});var jet=s(YR);woo=r(jet,"VanConfig"),jet.forEach(t),Aoo=r(aLe," (VAN model)"),aLe.forEach(t),Loo=i(L),Cg=n(L,"LI",{});var nLe=s(Cg);fne=n(nLe,"STRONG",{});var Det=s(fne);yoo=r(Det,"vilt"),Det.forEach(t),xoo=r(nLe," \u2014 "),KR=n(nLe,"A",{href:!0});var Get=s(KR);$oo=r(Get,"ViltConfig"),Get.forEach(t),koo=r(nLe," (ViLT model)"),nLe.forEach(t),Soo=i(L),wg=n(L,"LI",{});var sLe=s(wg);mne=n(sLe,"STRONG",{});var Oet=s(mne);Roo=r(Oet,"vision-encoder-decoder"),Oet.forEach(t),Poo=r(sLe," \u2014 "),ZR=n(sLe,"A",{href:!0});var Vet=s(ZR);Boo=r(Vet,"VisionEncoderDecoderConfig"),Vet.forEach(t),Ioo=r(sLe," (Vision Encoder decoder model)"),sLe.forEach(t),Noo=i(L),Ag=n(L,"LI",{});var lLe=s(Ag);gne=n(lLe,"STRONG",{});var Xet=s(gne);qoo=r(Xet,"vision-text-dual-encoder"),Xet.forEach(t),joo=r(lLe," \u2014 "),eP=n(lLe,"A",{href:!0});var zet=s(eP);Doo=r(zet,"VisionTextDualEncoderConfig"),zet.forEach(t),Goo=r(lLe," (VisionTextDualEncoder model)"),lLe.forEach(t),Ooo=i(L),Lg=n(L,"LI",{});var iLe=s(Lg);hne=n(iLe,"STRONG",{});var Qet=s(hne);Voo=r(Qet,"visual_bert"),Qet.forEach(t),Xoo=r(iLe," \u2014 "),oP=n(iLe,"A",{href:!0});var Wet=s(oP);zoo=r(Wet,"VisualBertConfig"),Wet.forEach(t),Qoo=r(iLe," (VisualBERT model)"),iLe.forEach(t),Woo=i(L),yg=n(L,"LI",{});var dLe=s(yg);pne=n(dLe,"STRONG",{});var Het=s(pne);Hoo=r(Het,"vit"),Het.forEach(t),Uoo=r(dLe," \u2014 "),rP=n(dLe,"A",{href:!0});var Uet=s(rP);Joo=r(Uet,"ViTConfig"),Uet.forEach(t),Yoo=r(dLe," (ViT model)"),dLe.forEach(t),Koo=i(L),xg=n(L,"LI",{});var cLe=s(xg);_ne=n(cLe,"STRONG",{});var Jet=s(_ne);Zoo=r(Jet,"vit_mae"),Jet.forEach(t),ero=r(cLe," \u2014 "),tP=n(cLe,"A",{href:!0});var Yet=s(tP);oro=r(Yet,"ViTMAEConfig"),Yet.forEach(t),rro=r(cLe," (ViTMAE model)"),cLe.forEach(t),tro=i(L),$g=n(L,"LI",{});var fLe=s($g);une=n(fLe,"STRONG",{});var Ket=s(une);aro=r(Ket,"wav2vec2"),Ket.forEach(t),nro=r(fLe," \u2014 "),aP=n(fLe,"A",{href:!0});var Zet=s(aP);sro=r(Zet,"Wav2Vec2Config"),Zet.forEach(t),lro=r(fLe," (Wav2Vec2 model)"),fLe.forEach(t),iro=i(L),kg=n(L,"LI",{});var mLe=s(kg);bne=n(mLe,"STRONG",{});var eot=s(bne);dro=r(eot,"wav2vec2-conformer"),eot.forEach(t),cro=r(mLe," \u2014 "),nP=n(mLe,"A",{href:!0});var oot=s(nP);fro=r(oot,"Wav2Vec2ConformerConfig"),oot.forEach(t),mro=r(mLe," (Wav2Vec2-Conformer model)"),mLe.forEach(t),gro=i(L),Sg=n(L,"LI",{});var gLe=s(Sg);vne=n(gLe,"STRONG",{});var rot=s(vne);hro=r(rot,"wavlm"),rot.forEach(t),pro=r(gLe," \u2014 "),sP=n(gLe,"A",{href:!0});var tot=s(sP);_ro=r(tot,"WavLMConfig"),tot.forEach(t),uro=r(gLe," (WavLM model)"),gLe.forEach(t),bro=i(L),Rg=n(L,"LI",{});var hLe=s(Rg);Fne=n(hLe,"STRONG",{});var aot=s(Fne);vro=r(aot,"xglm"),aot.forEach(t),Fro=r(hLe," \u2014 "),lP=n(hLe,"A",{href:!0});var not=s(lP);Tro=r(not,"XGLMConfig"),not.forEach(t),Mro=r(hLe," (XGLM model)"),hLe.forEach(t),Ero=i(L),Pg=n(L,"LI",{});var pLe=s(Pg);Tne=n(pLe,"STRONG",{});var sot=s(Tne);Cro=r(sot,"xlm"),sot.forEach(t),wro=r(pLe," \u2014 "),iP=n(pLe,"A",{href:!0});var lot=s(iP);Aro=r(lot,"XLMConfig"),lot.forEach(t),Lro=r(pLe," (XLM model)"),pLe.forEach(t),yro=i(L),Bg=n(L,"LI",{});var _Le=s(Bg);Mne=n(_Le,"STRONG",{});var iot=s(Mne);xro=r(iot,"xlm-prophetnet"),iot.forEach(t),$ro=r(_Le," \u2014 "),dP=n(_Le,"A",{href:!0});var dot=s(dP);kro=r(dot,"XLMProphetNetConfig"),dot.forEach(t),Sro=r(_Le," (XLM-ProphetNet model)"),_Le.forEach(t),Rro=i(L),Ig=n(L,"LI",{});var uLe=s(Ig);Ene=n(uLe,"STRONG",{});var cot=s(Ene);Pro=r(cot,"xlm-roberta"),cot.forEach(t),Bro=r(uLe," \u2014 "),cP=n(uLe,"A",{href:!0});var fot=s(cP);Iro=r(fot,"XLMRobertaConfig"),fot.forEach(t),Nro=r(uLe," (XLM-RoBERTa model)"),uLe.forEach(t),qro=i(L),Ng=n(L,"LI",{});var bLe=s(Ng);Cne=n(bLe,"STRONG",{});var mot=s(Cne);jro=r(mot,"xlm-roberta-xl"),mot.forEach(t),Dro=r(bLe," \u2014 "),fP=n(bLe,"A",{href:!0});var got=s(fP);Gro=r(got,"XLMRobertaXLConfig"),got.forEach(t),Oro=r(bLe," (XLM-RoBERTa-XL model)"),bLe.forEach(t),Vro=i(L),qg=n(L,"LI",{});var vLe=s(qg);wne=n(vLe,"STRONG",{});var hot=s(wne);Xro=r(hot,"xlnet"),hot.forEach(t),zro=r(vLe," \u2014 "),mP=n(vLe,"A",{href:!0});var pot=s(mP);Qro=r(pot,"XLNetConfig"),pot.forEach(t),Wro=r(vLe," (XLNet model)"),vLe.forEach(t),Hro=i(L),jg=n(L,"LI",{});var FLe=s(jg);Ane=n(FLe,"STRONG",{});var _ot=s(Ane);Uro=r(_ot,"yolos"),_ot.forEach(t),Jro=r(FLe," \u2014 "),gP=n(FLe,"A",{href:!0});var uot=s(gP);Yro=r(uot,"YolosConfig"),uot.forEach(t),Kro=r(FLe," (YOLOS model)"),FLe.forEach(t),Zro=i(L),Dg=n(L,"LI",{});var TLe=s(Dg);Lne=n(TLe,"STRONG",{});var bot=s(Lne);eto=r(bot,"yoso"),bot.forEach(t),oto=r(TLe," \u2014 "),hP=n(TLe,"A",{href:!0});var vot=s(hP);rto=r(vot,"YosoConfig"),vot.forEach(t),tto=r(TLe," (YOSO model)"),TLe.forEach(t),L.forEach(t),ato=i(tt),T(Gg.$$.fragment,tt),tt.forEach(t),nto=i(rt),Og=n(rt,"DIV",{class:!0});var zVe=s(Og);T(IL.$$.fragment,zVe),sto=i(zVe),yne=n(zVe,"P",{});var Fot=s(yne);lto=r(Fot,"Register a new configuration for this class."),Fot.forEach(t),zVe.forEach(t),rt.forEach(t),QGe=i(f),ki=n(f,"H2",{class:!0});var QVe=s(ki);Vg=n(QVe,"A",{id:!0,class:!0,href:!0});var Tot=s(Vg);xne=n(Tot,"SPAN",{});var Mot=s(xne);T(NL.$$.fragment,Mot),Mot.forEach(t),Tot.forEach(t),ito=i(QVe),$ne=n(QVe,"SPAN",{});var Eot=s($ne);dto=r(Eot,"AutoTokenizer"),Eot.forEach(t),QVe.forEach(t),WGe=i(f),Ao=n(f,"DIV",{class:!0});var Ws=s(Ao);T(qL.$$.fragment,Ws),cto=i(Ws),jL=n(Ws,"P",{});var WVe=s(jL);fto=r(WVe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),pP=n(WVe,"A",{href:!0});var Cot=s(pP);mto=r(Cot,"AutoTokenizer.from_pretrained()"),Cot.forEach(t),gto=r(WVe," class method."),WVe.forEach(t),hto=i(Ws),DL=n(Ws,"P",{});var HVe=s(DL);pto=r(HVe,"This class cannot be instantiated directly using "),kne=n(HVe,"CODE",{});var wot=s(kne);_to=r(wot,"__init__()"),wot.forEach(t),uto=r(HVe," (throws an error)."),HVe.forEach(t),bto=i(Ws),Lr=n(Ws,"DIV",{class:!0});var Hs=s(Lr);T(GL.$$.fragment,Hs),vto=i(Hs),Sne=n(Hs,"P",{});var Aot=s(Sne);Fto=r(Aot,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Aot.forEach(t),Tto=i(Hs),ka=n(Hs,"P",{});var xA=s(ka);Mto=r(xA,"The tokenizer class to instantiate is selected based on the "),Rne=n(xA,"CODE",{});var Lot=s(Rne);Eto=r(Lot,"model_type"),Lot.forEach(t),Cto=r(xA,` property of the config object (either
passed as an argument or loaded from `),Pne=n(xA,"CODE",{});var yot=s(Pne);wto=r(yot,"pretrained_model_name_or_path"),yot.forEach(t),Ato=r(xA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bne=n(xA,"CODE",{});var xot=s(Bne);Lto=r(xot,"pretrained_model_name_or_path"),xot.forEach(t),yto=r(xA,":"),xA.forEach(t),xto=i(Hs),k=n(Hs,"UL",{});var S=s(k);qn=n(S,"LI",{});var W$=s(qn);Ine=n(W$,"STRONG",{});var $ot=s(Ine);$to=r($ot,"albert"),$ot.forEach(t),kto=r(W$," \u2014 "),_P=n(W$,"A",{href:!0});var kot=s(_P);Sto=r(kot,"AlbertTokenizer"),kot.forEach(t),Rto=r(W$," or "),uP=n(W$,"A",{href:!0});var Sot=s(uP);Pto=r(Sot,"AlbertTokenizerFast"),Sot.forEach(t),Bto=r(W$," (ALBERT model)"),W$.forEach(t),Ito=i(S),jn=n(S,"LI",{});var H$=s(jn);Nne=n(H$,"STRONG",{});var Rot=s(Nne);Nto=r(Rot,"bart"),Rot.forEach(t),qto=r(H$," \u2014 "),bP=n(H$,"A",{href:!0});var Pot=s(bP);jto=r(Pot,"BartTokenizer"),Pot.forEach(t),Dto=r(H$," or "),vP=n(H$,"A",{href:!0});var Bot=s(vP);Gto=r(Bot,"BartTokenizerFast"),Bot.forEach(t),Oto=r(H$," (BART model)"),H$.forEach(t),Vto=i(S),Dn=n(S,"LI",{});var U$=s(Dn);qne=n(U$,"STRONG",{});var Iot=s(qne);Xto=r(Iot,"barthez"),Iot.forEach(t),zto=r(U$," \u2014 "),FP=n(U$,"A",{href:!0});var Not=s(FP);Qto=r(Not,"BarthezTokenizer"),Not.forEach(t),Wto=r(U$," or "),TP=n(U$,"A",{href:!0});var qot=s(TP);Hto=r(qot,"BarthezTokenizerFast"),qot.forEach(t),Uto=r(U$," (BARThez model)"),U$.forEach(t),Jto=i(S),Xg=n(S,"LI",{});var MLe=s(Xg);jne=n(MLe,"STRONG",{});var jot=s(jne);Yto=r(jot,"bartpho"),jot.forEach(t),Kto=r(MLe," \u2014 "),MP=n(MLe,"A",{href:!0});var Dot=s(MP);Zto=r(Dot,"BartphoTokenizer"),Dot.forEach(t),eao=r(MLe," (BARTpho model)"),MLe.forEach(t),oao=i(S),Gn=n(S,"LI",{});var J$=s(Gn);Dne=n(J$,"STRONG",{});var Got=s(Dne);rao=r(Got,"bert"),Got.forEach(t),tao=r(J$," \u2014 "),EP=n(J$,"A",{href:!0});var Oot=s(EP);aao=r(Oot,"BertTokenizer"),Oot.forEach(t),nao=r(J$," or "),CP=n(J$,"A",{href:!0});var Vot=s(CP);sao=r(Vot,"BertTokenizerFast"),Vot.forEach(t),lao=r(J$," (BERT model)"),J$.forEach(t),iao=i(S),zg=n(S,"LI",{});var ELe=s(zg);Gne=n(ELe,"STRONG",{});var Xot=s(Gne);dao=r(Xot,"bert-generation"),Xot.forEach(t),cao=r(ELe," \u2014 "),wP=n(ELe,"A",{href:!0});var zot=s(wP);fao=r(zot,"BertGenerationTokenizer"),zot.forEach(t),mao=r(ELe," (Bert Generation model)"),ELe.forEach(t),gao=i(S),Qg=n(S,"LI",{});var CLe=s(Qg);One=n(CLe,"STRONG",{});var Qot=s(One);hao=r(Qot,"bert-japanese"),Qot.forEach(t),pao=r(CLe," \u2014 "),AP=n(CLe,"A",{href:!0});var Wot=s(AP);_ao=r(Wot,"BertJapaneseTokenizer"),Wot.forEach(t),uao=r(CLe," (BertJapanese model)"),CLe.forEach(t),bao=i(S),Wg=n(S,"LI",{});var wLe=s(Wg);Vne=n(wLe,"STRONG",{});var Hot=s(Vne);vao=r(Hot,"bertweet"),Hot.forEach(t),Fao=r(wLe," \u2014 "),LP=n(wLe,"A",{href:!0});var Uot=s(LP);Tao=r(Uot,"BertweetTokenizer"),Uot.forEach(t),Mao=r(wLe," (BERTweet model)"),wLe.forEach(t),Eao=i(S),On=n(S,"LI",{});var Y$=s(On);Xne=n(Y$,"STRONG",{});var Jot=s(Xne);Cao=r(Jot,"big_bird"),Jot.forEach(t),wao=r(Y$," \u2014 "),yP=n(Y$,"A",{href:!0});var Yot=s(yP);Aao=r(Yot,"BigBirdTokenizer"),Yot.forEach(t),Lao=r(Y$," or "),xP=n(Y$,"A",{href:!0});var Kot=s(xP);yao=r(Kot,"BigBirdTokenizerFast"),Kot.forEach(t),xao=r(Y$," (BigBird model)"),Y$.forEach(t),$ao=i(S),Vn=n(S,"LI",{});var K$=s(Vn);zne=n(K$,"STRONG",{});var Zot=s(zne);kao=r(Zot,"bigbird_pegasus"),Zot.forEach(t),Sao=r(K$," \u2014 "),$P=n(K$,"A",{href:!0});var ert=s($P);Rao=r(ert,"PegasusTokenizer"),ert.forEach(t),Pao=r(K$," or "),kP=n(K$,"A",{href:!0});var ort=s(kP);Bao=r(ort,"PegasusTokenizerFast"),ort.forEach(t),Iao=r(K$," (BigBird-Pegasus model)"),K$.forEach(t),Nao=i(S),Xn=n(S,"LI",{});var Z$=s(Xn);Qne=n(Z$,"STRONG",{});var rrt=s(Qne);qao=r(rrt,"blenderbot"),rrt.forEach(t),jao=r(Z$," \u2014 "),SP=n(Z$,"A",{href:!0});var trt=s(SP);Dao=r(trt,"BlenderbotTokenizer"),trt.forEach(t),Gao=r(Z$," or "),RP=n(Z$,"A",{href:!0});var art=s(RP);Oao=r(art,"BlenderbotTokenizerFast"),art.forEach(t),Vao=r(Z$," (Blenderbot model)"),Z$.forEach(t),Xao=i(S),Hg=n(S,"LI",{});var ALe=s(Hg);Wne=n(ALe,"STRONG",{});var nrt=s(Wne);zao=r(nrt,"blenderbot-small"),nrt.forEach(t),Qao=r(ALe," \u2014 "),PP=n(ALe,"A",{href:!0});var srt=s(PP);Wao=r(srt,"BlenderbotSmallTokenizer"),srt.forEach(t),Hao=r(ALe," (BlenderbotSmall model)"),ALe.forEach(t),Uao=i(S),Ug=n(S,"LI",{});var LLe=s(Ug);Hne=n(LLe,"STRONG",{});var lrt=s(Hne);Jao=r(lrt,"bloom"),lrt.forEach(t),Yao=r(LLe," \u2014 "),BP=n(LLe,"A",{href:!0});var irt=s(BP);Kao=r(irt,"BloomTokenizerFast"),irt.forEach(t),Zao=r(LLe," (BLOOM model)"),LLe.forEach(t),eno=i(S),Jg=n(S,"LI",{});var yLe=s(Jg);Une=n(yLe,"STRONG",{});var drt=s(Une);ono=r(drt,"byt5"),drt.forEach(t),rno=r(yLe," \u2014 "),IP=n(yLe,"A",{href:!0});var crt=s(IP);tno=r(crt,"ByT5Tokenizer"),crt.forEach(t),ano=r(yLe," (ByT5 model)"),yLe.forEach(t),nno=i(S),zn=n(S,"LI",{});var ek=s(zn);Jne=n(ek,"STRONG",{});var frt=s(Jne);sno=r(frt,"camembert"),frt.forEach(t),lno=r(ek," \u2014 "),NP=n(ek,"A",{href:!0});var mrt=s(NP);ino=r(mrt,"CamembertTokenizer"),mrt.forEach(t),dno=r(ek," or "),qP=n(ek,"A",{href:!0});var grt=s(qP);cno=r(grt,"CamembertTokenizerFast"),grt.forEach(t),fno=r(ek," (CamemBERT model)"),ek.forEach(t),mno=i(S),Yg=n(S,"LI",{});var xLe=s(Yg);Yne=n(xLe,"STRONG",{});var hrt=s(Yne);gno=r(hrt,"canine"),hrt.forEach(t),hno=r(xLe," \u2014 "),jP=n(xLe,"A",{href:!0});var prt=s(jP);pno=r(prt,"CanineTokenizer"),prt.forEach(t),_no=r(xLe," (CANINE model)"),xLe.forEach(t),uno=i(S),Qn=n(S,"LI",{});var ok=s(Qn);Kne=n(ok,"STRONG",{});var _rt=s(Kne);bno=r(_rt,"clip"),_rt.forEach(t),vno=r(ok," \u2014 "),DP=n(ok,"A",{href:!0});var urt=s(DP);Fno=r(urt,"CLIPTokenizer"),urt.forEach(t),Tno=r(ok," or "),GP=n(ok,"A",{href:!0});var brt=s(GP);Mno=r(brt,"CLIPTokenizerFast"),brt.forEach(t),Eno=r(ok," (CLIP model)"),ok.forEach(t),Cno=i(S),Wn=n(S,"LI",{});var rk=s(Wn);Zne=n(rk,"STRONG",{});var vrt=s(Zne);wno=r(vrt,"convbert"),vrt.forEach(t),Ano=r(rk," \u2014 "),OP=n(rk,"A",{href:!0});var Frt=s(OP);Lno=r(Frt,"ConvBertTokenizer"),Frt.forEach(t),yno=r(rk," or "),VP=n(rk,"A",{href:!0});var Trt=s(VP);xno=r(Trt,"ConvBertTokenizerFast"),Trt.forEach(t),$no=r(rk," (ConvBERT model)"),rk.forEach(t),kno=i(S),Hn=n(S,"LI",{});var tk=s(Hn);ese=n(tk,"STRONG",{});var Mrt=s(ese);Sno=r(Mrt,"cpm"),Mrt.forEach(t),Rno=r(tk," \u2014 "),XP=n(tk,"A",{href:!0});var Ert=s(XP);Pno=r(Ert,"CpmTokenizer"),Ert.forEach(t),Bno=r(tk," or "),zP=n(tk,"A",{href:!0});var Crt=s(zP);Ino=r(Crt,"CpmTokenizerFast"),Crt.forEach(t),Nno=r(tk," (CPM model)"),tk.forEach(t),qno=i(S),Kg=n(S,"LI",{});var $Le=s(Kg);ose=n($Le,"STRONG",{});var wrt=s(ose);jno=r(wrt,"ctrl"),wrt.forEach(t),Dno=r($Le," \u2014 "),QP=n($Le,"A",{href:!0});var Art=s(QP);Gno=r(Art,"CTRLTokenizer"),Art.forEach(t),Ono=r($Le," (CTRL model)"),$Le.forEach(t),Vno=i(S),Un=n(S,"LI",{});var ak=s(Un);rse=n(ak,"STRONG",{});var Lrt=s(rse);Xno=r(Lrt,"data2vec-text"),Lrt.forEach(t),zno=r(ak," \u2014 "),WP=n(ak,"A",{href:!0});var yrt=s(WP);Qno=r(yrt,"RobertaTokenizer"),yrt.forEach(t),Wno=r(ak," or "),HP=n(ak,"A",{href:!0});var xrt=s(HP);Hno=r(xrt,"RobertaTokenizerFast"),xrt.forEach(t),Uno=r(ak," (Data2VecText model)"),ak.forEach(t),Jno=i(S),Jn=n(S,"LI",{});var nk=s(Jn);tse=n(nk,"STRONG",{});var $rt=s(tse);Yno=r($rt,"deberta"),$rt.forEach(t),Kno=r(nk," \u2014 "),UP=n(nk,"A",{href:!0});var krt=s(UP);Zno=r(krt,"DebertaTokenizer"),krt.forEach(t),eso=r(nk," or "),JP=n(nk,"A",{href:!0});var Srt=s(JP);oso=r(Srt,"DebertaTokenizerFast"),Srt.forEach(t),rso=r(nk," (DeBERTa model)"),nk.forEach(t),tso=i(S),Yn=n(S,"LI",{});var sk=s(Yn);ase=n(sk,"STRONG",{});var Rrt=s(ase);aso=r(Rrt,"deberta-v2"),Rrt.forEach(t),nso=r(sk," \u2014 "),YP=n(sk,"A",{href:!0});var Prt=s(YP);sso=r(Prt,"DebertaV2Tokenizer"),Prt.forEach(t),lso=r(sk," or "),KP=n(sk,"A",{href:!0});var Brt=s(KP);iso=r(Brt,"DebertaV2TokenizerFast"),Brt.forEach(t),dso=r(sk," (DeBERTa-v2 model)"),sk.forEach(t),cso=i(S),Kn=n(S,"LI",{});var lk=s(Kn);nse=n(lk,"STRONG",{});var Irt=s(nse);fso=r(Irt,"distilbert"),Irt.forEach(t),mso=r(lk," \u2014 "),ZP=n(lk,"A",{href:!0});var Nrt=s(ZP);gso=r(Nrt,"DistilBertTokenizer"),Nrt.forEach(t),hso=r(lk," or "),eB=n(lk,"A",{href:!0});var qrt=s(eB);pso=r(qrt,"DistilBertTokenizerFast"),qrt.forEach(t),_so=r(lk," (DistilBERT model)"),lk.forEach(t),uso=i(S),Zn=n(S,"LI",{});var ik=s(Zn);sse=n(ik,"STRONG",{});var jrt=s(sse);bso=r(jrt,"dpr"),jrt.forEach(t),vso=r(ik," \u2014 "),oB=n(ik,"A",{href:!0});var Drt=s(oB);Fso=r(Drt,"DPRQuestionEncoderTokenizer"),Drt.forEach(t),Tso=r(ik," or "),rB=n(ik,"A",{href:!0});var Grt=s(rB);Mso=r(Grt,"DPRQuestionEncoderTokenizerFast"),Grt.forEach(t),Eso=r(ik," (DPR model)"),ik.forEach(t),Cso=i(S),es=n(S,"LI",{});var dk=s(es);lse=n(dk,"STRONG",{});var Ort=s(lse);wso=r(Ort,"electra"),Ort.forEach(t),Aso=r(dk," \u2014 "),tB=n(dk,"A",{href:!0});var Vrt=s(tB);Lso=r(Vrt,"ElectraTokenizer"),Vrt.forEach(t),yso=r(dk," or "),aB=n(dk,"A",{href:!0});var Xrt=s(aB);xso=r(Xrt,"ElectraTokenizerFast"),Xrt.forEach(t),$so=r(dk," (ELECTRA model)"),dk.forEach(t),kso=i(S),Zg=n(S,"LI",{});var kLe=s(Zg);ise=n(kLe,"STRONG",{});var zrt=s(ise);Sso=r(zrt,"flaubert"),zrt.forEach(t),Rso=r(kLe," \u2014 "),nB=n(kLe,"A",{href:!0});var Qrt=s(nB);Pso=r(Qrt,"FlaubertTokenizer"),Qrt.forEach(t),Bso=r(kLe," (FlauBERT model)"),kLe.forEach(t),Iso=i(S),os=n(S,"LI",{});var ck=s(os);dse=n(ck,"STRONG",{});var Wrt=s(dse);Nso=r(Wrt,"fnet"),Wrt.forEach(t),qso=r(ck," \u2014 "),sB=n(ck,"A",{href:!0});var Hrt=s(sB);jso=r(Hrt,"FNetTokenizer"),Hrt.forEach(t),Dso=r(ck," or "),lB=n(ck,"A",{href:!0});var Urt=s(lB);Gso=r(Urt,"FNetTokenizerFast"),Urt.forEach(t),Oso=r(ck," (FNet model)"),ck.forEach(t),Vso=i(S),eh=n(S,"LI",{});var SLe=s(eh);cse=n(SLe,"STRONG",{});var Jrt=s(cse);Xso=r(Jrt,"fsmt"),Jrt.forEach(t),zso=r(SLe," \u2014 "),iB=n(SLe,"A",{href:!0});var Yrt=s(iB);Qso=r(Yrt,"FSMTTokenizer"),Yrt.forEach(t),Wso=r(SLe," (FairSeq Machine-Translation model)"),SLe.forEach(t),Hso=i(S),rs=n(S,"LI",{});var fk=s(rs);fse=n(fk,"STRONG",{});var Krt=s(fse);Uso=r(Krt,"funnel"),Krt.forEach(t),Jso=r(fk," \u2014 "),dB=n(fk,"A",{href:!0});var Zrt=s(dB);Yso=r(Zrt,"FunnelTokenizer"),Zrt.forEach(t),Kso=r(fk," or "),cB=n(fk,"A",{href:!0});var ett=s(cB);Zso=r(ett,"FunnelTokenizerFast"),ett.forEach(t),elo=r(fk," (Funnel Transformer model)"),fk.forEach(t),olo=i(S),ts=n(S,"LI",{});var mk=s(ts);mse=n(mk,"STRONG",{});var ott=s(mse);rlo=r(ott,"gpt2"),ott.forEach(t),tlo=r(mk," \u2014 "),fB=n(mk,"A",{href:!0});var rtt=s(fB);alo=r(rtt,"GPT2Tokenizer"),rtt.forEach(t),nlo=r(mk," or "),mB=n(mk,"A",{href:!0});var ttt=s(mB);slo=r(ttt,"GPT2TokenizerFast"),ttt.forEach(t),llo=r(mk," (OpenAI GPT-2 model)"),mk.forEach(t),ilo=i(S),as=n(S,"LI",{});var gk=s(as);gse=n(gk,"STRONG",{});var att=s(gse);dlo=r(att,"gpt_neo"),att.forEach(t),clo=r(gk," \u2014 "),gB=n(gk,"A",{href:!0});var ntt=s(gB);flo=r(ntt,"GPT2Tokenizer"),ntt.forEach(t),mlo=r(gk," or "),hB=n(gk,"A",{href:!0});var stt=s(hB);glo=r(stt,"GPT2TokenizerFast"),stt.forEach(t),hlo=r(gk," (GPT Neo model)"),gk.forEach(t),plo=i(S),oh=n(S,"LI",{});var RLe=s(oh);hse=n(RLe,"STRONG",{});var ltt=s(hse);_lo=r(ltt,"gpt_neox"),ltt.forEach(t),ulo=r(RLe," \u2014 "),pB=n(RLe,"A",{href:!0});var itt=s(pB);blo=r(itt,"GPTNeoXTokenizerFast"),itt.forEach(t),vlo=r(RLe," (GPT NeoX model)"),RLe.forEach(t),Flo=i(S),ns=n(S,"LI",{});var hk=s(ns);pse=n(hk,"STRONG",{});var dtt=s(pse);Tlo=r(dtt,"gptj"),dtt.forEach(t),Mlo=r(hk," \u2014 "),_B=n(hk,"A",{href:!0});var ctt=s(_B);Elo=r(ctt,"GPT2Tokenizer"),ctt.forEach(t),Clo=r(hk," or "),uB=n(hk,"A",{href:!0});var ftt=s(uB);wlo=r(ftt,"GPT2TokenizerFast"),ftt.forEach(t),Alo=r(hk," (GPT-J model)"),hk.forEach(t),Llo=i(S),ss=n(S,"LI",{});var pk=s(ss);_se=n(pk,"STRONG",{});var mtt=s(_se);ylo=r(mtt,"herbert"),mtt.forEach(t),xlo=r(pk," \u2014 "),bB=n(pk,"A",{href:!0});var gtt=s(bB);$lo=r(gtt,"HerbertTokenizer"),gtt.forEach(t),klo=r(pk," or "),vB=n(pk,"A",{href:!0});var htt=s(vB);Slo=r(htt,"HerbertTokenizerFast"),htt.forEach(t),Rlo=r(pk," (HerBERT model)"),pk.forEach(t),Plo=i(S),rh=n(S,"LI",{});var PLe=s(rh);use=n(PLe,"STRONG",{});var ptt=s(use);Blo=r(ptt,"hubert"),ptt.forEach(t),Ilo=r(PLe," \u2014 "),FB=n(PLe,"A",{href:!0});var _tt=s(FB);Nlo=r(_tt,"Wav2Vec2CTCTokenizer"),_tt.forEach(t),qlo=r(PLe," (Hubert model)"),PLe.forEach(t),jlo=i(S),ls=n(S,"LI",{});var _k=s(ls);bse=n(_k,"STRONG",{});var utt=s(bse);Dlo=r(utt,"ibert"),utt.forEach(t),Glo=r(_k," \u2014 "),TB=n(_k,"A",{href:!0});var btt=s(TB);Olo=r(btt,"RobertaTokenizer"),btt.forEach(t),Vlo=r(_k," or "),MB=n(_k,"A",{href:!0});var vtt=s(MB);Xlo=r(vtt,"RobertaTokenizerFast"),vtt.forEach(t),zlo=r(_k," (I-BERT model)"),_k.forEach(t),Qlo=i(S),is=n(S,"LI",{});var uk=s(is);vse=n(uk,"STRONG",{});var Ftt=s(vse);Wlo=r(Ftt,"layoutlm"),Ftt.forEach(t),Hlo=r(uk," \u2014 "),EB=n(uk,"A",{href:!0});var Ttt=s(EB);Ulo=r(Ttt,"LayoutLMTokenizer"),Ttt.forEach(t),Jlo=r(uk," or "),CB=n(uk,"A",{href:!0});var Mtt=s(CB);Ylo=r(Mtt,"LayoutLMTokenizerFast"),Mtt.forEach(t),Klo=r(uk," (LayoutLM model)"),uk.forEach(t),Zlo=i(S),ds=n(S,"LI",{});var bk=s(ds);Fse=n(bk,"STRONG",{});var Ett=s(Fse);eio=r(Ett,"layoutlmv2"),Ett.forEach(t),oio=r(bk," \u2014 "),wB=n(bk,"A",{href:!0});var Ctt=s(wB);rio=r(Ctt,"LayoutLMv2Tokenizer"),Ctt.forEach(t),tio=r(bk," or "),AB=n(bk,"A",{href:!0});var wtt=s(AB);aio=r(wtt,"LayoutLMv2TokenizerFast"),wtt.forEach(t),nio=r(bk," (LayoutLMv2 model)"),bk.forEach(t),sio=i(S),cs=n(S,"LI",{});var vk=s(cs);Tse=n(vk,"STRONG",{});var Att=s(Tse);lio=r(Att,"layoutlmv3"),Att.forEach(t),iio=r(vk," \u2014 "),LB=n(vk,"A",{href:!0});var Ltt=s(LB);dio=r(Ltt,"LayoutLMv3Tokenizer"),Ltt.forEach(t),cio=r(vk," or "),yB=n(vk,"A",{href:!0});var ytt=s(yB);fio=r(ytt,"LayoutLMv3TokenizerFast"),ytt.forEach(t),mio=r(vk," (LayoutLMv3 model)"),vk.forEach(t),gio=i(S),fs=n(S,"LI",{});var Fk=s(fs);Mse=n(Fk,"STRONG",{});var xtt=s(Mse);hio=r(xtt,"layoutxlm"),xtt.forEach(t),pio=r(Fk," \u2014 "),xB=n(Fk,"A",{href:!0});var $tt=s(xB);_io=r($tt,"LayoutXLMTokenizer"),$tt.forEach(t),uio=r(Fk," or "),$B=n(Fk,"A",{href:!0});var ktt=s($B);bio=r(ktt,"LayoutXLMTokenizerFast"),ktt.forEach(t),vio=r(Fk," (LayoutXLM model)"),Fk.forEach(t),Fio=i(S),ms=n(S,"LI",{});var Tk=s(ms);Ese=n(Tk,"STRONG",{});var Stt=s(Ese);Tio=r(Stt,"led"),Stt.forEach(t),Mio=r(Tk," \u2014 "),kB=n(Tk,"A",{href:!0});var Rtt=s(kB);Eio=r(Rtt,"LEDTokenizer"),Rtt.forEach(t),Cio=r(Tk," or "),SB=n(Tk,"A",{href:!0});var Ptt=s(SB);wio=r(Ptt,"LEDTokenizerFast"),Ptt.forEach(t),Aio=r(Tk," (LED model)"),Tk.forEach(t),Lio=i(S),gs=n(S,"LI",{});var Mk=s(gs);Cse=n(Mk,"STRONG",{});var Btt=s(Cse);yio=r(Btt,"longformer"),Btt.forEach(t),xio=r(Mk," \u2014 "),RB=n(Mk,"A",{href:!0});var Itt=s(RB);$io=r(Itt,"LongformerTokenizer"),Itt.forEach(t),kio=r(Mk," or "),PB=n(Mk,"A",{href:!0});var Ntt=s(PB);Sio=r(Ntt,"LongformerTokenizerFast"),Ntt.forEach(t),Rio=r(Mk," (Longformer model)"),Mk.forEach(t),Pio=i(S),hs=n(S,"LI",{});var Ek=s(hs);wse=n(Ek,"STRONG",{});var qtt=s(wse);Bio=r(qtt,"longt5"),qtt.forEach(t),Iio=r(Ek," \u2014 "),BB=n(Ek,"A",{href:!0});var jtt=s(BB);Nio=r(jtt,"T5Tokenizer"),jtt.forEach(t),qio=r(Ek," or "),IB=n(Ek,"A",{href:!0});var Dtt=s(IB);jio=r(Dtt,"T5TokenizerFast"),Dtt.forEach(t),Dio=r(Ek," (LongT5 model)"),Ek.forEach(t),Gio=i(S),th=n(S,"LI",{});var BLe=s(th);Ase=n(BLe,"STRONG",{});var Gtt=s(Ase);Oio=r(Gtt,"luke"),Gtt.forEach(t),Vio=r(BLe," \u2014 "),NB=n(BLe,"A",{href:!0});var Ott=s(NB);Xio=r(Ott,"LukeTokenizer"),Ott.forEach(t),zio=r(BLe," (LUKE model)"),BLe.forEach(t),Qio=i(S),ps=n(S,"LI",{});var Ck=s(ps);Lse=n(Ck,"STRONG",{});var Vtt=s(Lse);Wio=r(Vtt,"lxmert"),Vtt.forEach(t),Hio=r(Ck," \u2014 "),qB=n(Ck,"A",{href:!0});var Xtt=s(qB);Uio=r(Xtt,"LxmertTokenizer"),Xtt.forEach(t),Jio=r(Ck," or "),jB=n(Ck,"A",{href:!0});var ztt=s(jB);Yio=r(ztt,"LxmertTokenizerFast"),ztt.forEach(t),Kio=r(Ck," (LXMERT model)"),Ck.forEach(t),Zio=i(S),ah=n(S,"LI",{});var ILe=s(ah);yse=n(ILe,"STRONG",{});var Qtt=s(yse);edo=r(Qtt,"m2m_100"),Qtt.forEach(t),odo=r(ILe," \u2014 "),DB=n(ILe,"A",{href:!0});var Wtt=s(DB);rdo=r(Wtt,"M2M100Tokenizer"),Wtt.forEach(t),tdo=r(ILe," (M2M100 model)"),ILe.forEach(t),ado=i(S),nh=n(S,"LI",{});var NLe=s(nh);xse=n(NLe,"STRONG",{});var Htt=s(xse);ndo=r(Htt,"marian"),Htt.forEach(t),sdo=r(NLe," \u2014 "),GB=n(NLe,"A",{href:!0});var Utt=s(GB);ldo=r(Utt,"MarianTokenizer"),Utt.forEach(t),ido=r(NLe," (Marian model)"),NLe.forEach(t),ddo=i(S),_s=n(S,"LI",{});var wk=s(_s);$se=n(wk,"STRONG",{});var Jtt=s($se);cdo=r(Jtt,"mbart"),Jtt.forEach(t),fdo=r(wk," \u2014 "),OB=n(wk,"A",{href:!0});var Ytt=s(OB);mdo=r(Ytt,"MBartTokenizer"),Ytt.forEach(t),gdo=r(wk," or "),VB=n(wk,"A",{href:!0});var Ktt=s(VB);hdo=r(Ktt,"MBartTokenizerFast"),Ktt.forEach(t),pdo=r(wk," (mBART model)"),wk.forEach(t),_do=i(S),us=n(S,"LI",{});var Ak=s(us);kse=n(Ak,"STRONG",{});var Ztt=s(kse);udo=r(Ztt,"mbart50"),Ztt.forEach(t),bdo=r(Ak," \u2014 "),XB=n(Ak,"A",{href:!0});var eat=s(XB);vdo=r(eat,"MBart50Tokenizer"),eat.forEach(t),Fdo=r(Ak," or "),zB=n(Ak,"A",{href:!0});var oat=s(zB);Tdo=r(oat,"MBart50TokenizerFast"),oat.forEach(t),Mdo=r(Ak," (mBART-50 model)"),Ak.forEach(t),Edo=i(S),bs=n(S,"LI",{});var Lk=s(bs);Sse=n(Lk,"STRONG",{});var rat=s(Sse);Cdo=r(rat,"megatron-bert"),rat.forEach(t),wdo=r(Lk," \u2014 "),QB=n(Lk,"A",{href:!0});var tat=s(QB);Ado=r(tat,"BertTokenizer"),tat.forEach(t),Ldo=r(Lk," or "),WB=n(Lk,"A",{href:!0});var aat=s(WB);ydo=r(aat,"BertTokenizerFast"),aat.forEach(t),xdo=r(Lk," (Megatron-BERT model)"),Lk.forEach(t),$do=i(S),sh=n(S,"LI",{});var qLe=s(sh);Rse=n(qLe,"STRONG",{});var nat=s(Rse);kdo=r(nat,"mluke"),nat.forEach(t),Sdo=r(qLe," \u2014 "),HB=n(qLe,"A",{href:!0});var sat=s(HB);Rdo=r(sat,"MLukeTokenizer"),sat.forEach(t),Pdo=r(qLe," (mLUKE model)"),qLe.forEach(t),Bdo=i(S),vs=n(S,"LI",{});var yk=s(vs);Pse=n(yk,"STRONG",{});var lat=s(Pse);Ido=r(lat,"mobilebert"),lat.forEach(t),Ndo=r(yk," \u2014 "),UB=n(yk,"A",{href:!0});var iat=s(UB);qdo=r(iat,"MobileBertTokenizer"),iat.forEach(t),jdo=r(yk," or "),JB=n(yk,"A",{href:!0});var dat=s(JB);Ddo=r(dat,"MobileBertTokenizerFast"),dat.forEach(t),Gdo=r(yk," (MobileBERT model)"),yk.forEach(t),Odo=i(S),Fs=n(S,"LI",{});var xk=s(Fs);Bse=n(xk,"STRONG",{});var cat=s(Bse);Vdo=r(cat,"mpnet"),cat.forEach(t),Xdo=r(xk," \u2014 "),YB=n(xk,"A",{href:!0});var fat=s(YB);zdo=r(fat,"MPNetTokenizer"),fat.forEach(t),Qdo=r(xk," or "),KB=n(xk,"A",{href:!0});var mat=s(KB);Wdo=r(mat,"MPNetTokenizerFast"),mat.forEach(t),Hdo=r(xk," (MPNet model)"),xk.forEach(t),Udo=i(S),Ts=n(S,"LI",{});var $k=s(Ts);Ise=n($k,"STRONG",{});var gat=s(Ise);Jdo=r(gat,"mt5"),gat.forEach(t),Ydo=r($k," \u2014 "),ZB=n($k,"A",{href:!0});var hat=s(ZB);Kdo=r(hat,"MT5Tokenizer"),hat.forEach(t),Zdo=r($k," or "),eI=n($k,"A",{href:!0});var pat=s(eI);eco=r(pat,"MT5TokenizerFast"),pat.forEach(t),oco=r($k," (MT5 model)"),$k.forEach(t),rco=i(S),Ms=n(S,"LI",{});var kk=s(Ms);Nse=n(kk,"STRONG",{});var _at=s(Nse);tco=r(_at,"nezha"),_at.forEach(t),aco=r(kk," \u2014 "),oI=n(kk,"A",{href:!0});var uat=s(oI);nco=r(uat,"BertTokenizer"),uat.forEach(t),sco=r(kk," or "),rI=n(kk,"A",{href:!0});var bat=s(rI);lco=r(bat,"BertTokenizerFast"),bat.forEach(t),ico=r(kk," (Nezha model)"),kk.forEach(t),dco=i(S),Es=n(S,"LI",{});var Sk=s(Es);qse=n(Sk,"STRONG",{});var vat=s(qse);cco=r(vat,"nystromformer"),vat.forEach(t),fco=r(Sk," \u2014 "),tI=n(Sk,"A",{href:!0});var Fat=s(tI);mco=r(Fat,"AlbertTokenizer"),Fat.forEach(t),gco=r(Sk," or "),aI=n(Sk,"A",{href:!0});var Tat=s(aI);hco=r(Tat,"AlbertTokenizerFast"),Tat.forEach(t),pco=r(Sk," (Nystr\xF6mformer model)"),Sk.forEach(t),_co=i(S),Cs=n(S,"LI",{});var Rk=s(Cs);jse=n(Rk,"STRONG",{});var Mat=s(jse);uco=r(Mat,"openai-gpt"),Mat.forEach(t),bco=r(Rk," \u2014 "),nI=n(Rk,"A",{href:!0});var Eat=s(nI);vco=r(Eat,"OpenAIGPTTokenizer"),Eat.forEach(t),Fco=r(Rk," or "),sI=n(Rk,"A",{href:!0});var Cat=s(sI);Tco=r(Cat,"OpenAIGPTTokenizerFast"),Cat.forEach(t),Mco=r(Rk," (OpenAI GPT model)"),Rk.forEach(t),Eco=i(S),lh=n(S,"LI",{});var jLe=s(lh);Dse=n(jLe,"STRONG",{});var wat=s(Dse);Cco=r(wat,"opt"),wat.forEach(t),wco=r(jLe," \u2014 "),lI=n(jLe,"A",{href:!0});var Aat=s(lI);Aco=r(Aat,"GPT2Tokenizer"),Aat.forEach(t),Lco=r(jLe," (OPT model)"),jLe.forEach(t),yco=i(S),ws=n(S,"LI",{});var Pk=s(ws);Gse=n(Pk,"STRONG",{});var Lat=s(Gse);xco=r(Lat,"pegasus"),Lat.forEach(t),$co=r(Pk," \u2014 "),iI=n(Pk,"A",{href:!0});var yat=s(iI);kco=r(yat,"PegasusTokenizer"),yat.forEach(t),Sco=r(Pk," or "),dI=n(Pk,"A",{href:!0});var xat=s(dI);Rco=r(xat,"PegasusTokenizerFast"),xat.forEach(t),Pco=r(Pk," (Pegasus model)"),Pk.forEach(t),Bco=i(S),ih=n(S,"LI",{});var DLe=s(ih);Ose=n(DLe,"STRONG",{});var $at=s(Ose);Ico=r($at,"perceiver"),$at.forEach(t),Nco=r(DLe," \u2014 "),cI=n(DLe,"A",{href:!0});var kat=s(cI);qco=r(kat,"PerceiverTokenizer"),kat.forEach(t),jco=r(DLe," (Perceiver model)"),DLe.forEach(t),Dco=i(S),dh=n(S,"LI",{});var GLe=s(dh);Vse=n(GLe,"STRONG",{});var Sat=s(Vse);Gco=r(Sat,"phobert"),Sat.forEach(t),Oco=r(GLe," \u2014 "),fI=n(GLe,"A",{href:!0});var Rat=s(fI);Vco=r(Rat,"PhobertTokenizer"),Rat.forEach(t),Xco=r(GLe," (PhoBERT model)"),GLe.forEach(t),zco=i(S),ch=n(S,"LI",{});var OLe=s(ch);Xse=n(OLe,"STRONG",{});var Pat=s(Xse);Qco=r(Pat,"plbart"),Pat.forEach(t),Wco=r(OLe," \u2014 "),mI=n(OLe,"A",{href:!0});var Bat=s(mI);Hco=r(Bat,"PLBartTokenizer"),Bat.forEach(t),Uco=r(OLe," (PLBart model)"),OLe.forEach(t),Jco=i(S),fh=n(S,"LI",{});var VLe=s(fh);zse=n(VLe,"STRONG",{});var Iat=s(zse);Yco=r(Iat,"prophetnet"),Iat.forEach(t),Kco=r(VLe," \u2014 "),gI=n(VLe,"A",{href:!0});var Nat=s(gI);Zco=r(Nat,"ProphetNetTokenizer"),Nat.forEach(t),efo=r(VLe," (ProphetNet model)"),VLe.forEach(t),ofo=i(S),As=n(S,"LI",{});var Bk=s(As);Qse=n(Bk,"STRONG",{});var qat=s(Qse);rfo=r(qat,"qdqbert"),qat.forEach(t),tfo=r(Bk," \u2014 "),hI=n(Bk,"A",{href:!0});var jat=s(hI);afo=r(jat,"BertTokenizer"),jat.forEach(t),nfo=r(Bk," or "),pI=n(Bk,"A",{href:!0});var Dat=s(pI);sfo=r(Dat,"BertTokenizerFast"),Dat.forEach(t),lfo=r(Bk," (QDQBert model)"),Bk.forEach(t),ifo=i(S),mh=n(S,"LI",{});var XLe=s(mh);Wse=n(XLe,"STRONG",{});var Gat=s(Wse);dfo=r(Gat,"rag"),Gat.forEach(t),cfo=r(XLe," \u2014 "),_I=n(XLe,"A",{href:!0});var Oat=s(_I);ffo=r(Oat,"RagTokenizer"),Oat.forEach(t),mfo=r(XLe," (RAG model)"),XLe.forEach(t),gfo=i(S),Ls=n(S,"LI",{});var Ik=s(Ls);Hse=n(Ik,"STRONG",{});var Vat=s(Hse);hfo=r(Vat,"realm"),Vat.forEach(t),pfo=r(Ik," \u2014 "),uI=n(Ik,"A",{href:!0});var Xat=s(uI);_fo=r(Xat,"RealmTokenizer"),Xat.forEach(t),ufo=r(Ik," or "),bI=n(Ik,"A",{href:!0});var zat=s(bI);bfo=r(zat,"RealmTokenizerFast"),zat.forEach(t),vfo=r(Ik," (REALM model)"),Ik.forEach(t),Ffo=i(S),ys=n(S,"LI",{});var Nk=s(ys);Use=n(Nk,"STRONG",{});var Qat=s(Use);Tfo=r(Qat,"reformer"),Qat.forEach(t),Mfo=r(Nk," \u2014 "),vI=n(Nk,"A",{href:!0});var Wat=s(vI);Efo=r(Wat,"ReformerTokenizer"),Wat.forEach(t),Cfo=r(Nk," or "),FI=n(Nk,"A",{href:!0});var Hat=s(FI);wfo=r(Hat,"ReformerTokenizerFast"),Hat.forEach(t),Afo=r(Nk," (Reformer model)"),Nk.forEach(t),Lfo=i(S),xs=n(S,"LI",{});var qk=s(xs);Jse=n(qk,"STRONG",{});var Uat=s(Jse);yfo=r(Uat,"rembert"),Uat.forEach(t),xfo=r(qk," \u2014 "),TI=n(qk,"A",{href:!0});var Jat=s(TI);$fo=r(Jat,"RemBertTokenizer"),Jat.forEach(t),kfo=r(qk," or "),MI=n(qk,"A",{href:!0});var Yat=s(MI);Sfo=r(Yat,"RemBertTokenizerFast"),Yat.forEach(t),Rfo=r(qk," (RemBERT model)"),qk.forEach(t),Pfo=i(S),$s=n(S,"LI",{});var jk=s($s);Yse=n(jk,"STRONG",{});var Kat=s(Yse);Bfo=r(Kat,"retribert"),Kat.forEach(t),Ifo=r(jk," \u2014 "),EI=n(jk,"A",{href:!0});var Zat=s(EI);Nfo=r(Zat,"RetriBertTokenizer"),Zat.forEach(t),qfo=r(jk," or "),CI=n(jk,"A",{href:!0});var ent=s(CI);jfo=r(ent,"RetriBertTokenizerFast"),ent.forEach(t),Dfo=r(jk," (RetriBERT model)"),jk.forEach(t),Gfo=i(S),ks=n(S,"LI",{});var Dk=s(ks);Kse=n(Dk,"STRONG",{});var ont=s(Kse);Ofo=r(ont,"roberta"),ont.forEach(t),Vfo=r(Dk," \u2014 "),wI=n(Dk,"A",{href:!0});var rnt=s(wI);Xfo=r(rnt,"RobertaTokenizer"),rnt.forEach(t),zfo=r(Dk," or "),AI=n(Dk,"A",{href:!0});var tnt=s(AI);Qfo=r(tnt,"RobertaTokenizerFast"),tnt.forEach(t),Wfo=r(Dk," (RoBERTa model)"),Dk.forEach(t),Hfo=i(S),Ss=n(S,"LI",{});var Gk=s(Ss);Zse=n(Gk,"STRONG",{});var ant=s(Zse);Ufo=r(ant,"roformer"),ant.forEach(t),Jfo=r(Gk," \u2014 "),LI=n(Gk,"A",{href:!0});var nnt=s(LI);Yfo=r(nnt,"RoFormerTokenizer"),nnt.forEach(t),Kfo=r(Gk," or "),yI=n(Gk,"A",{href:!0});var snt=s(yI);Zfo=r(snt,"RoFormerTokenizerFast"),snt.forEach(t),emo=r(Gk," (RoFormer model)"),Gk.forEach(t),omo=i(S),gh=n(S,"LI",{});var zLe=s(gh);ele=n(zLe,"STRONG",{});var lnt=s(ele);rmo=r(lnt,"speech_to_text"),lnt.forEach(t),tmo=r(zLe," \u2014 "),xI=n(zLe,"A",{href:!0});var int=s(xI);amo=r(int,"Speech2TextTokenizer"),int.forEach(t),nmo=r(zLe," (Speech2Text model)"),zLe.forEach(t),smo=i(S),hh=n(S,"LI",{});var QLe=s(hh);ole=n(QLe,"STRONG",{});var dnt=s(ole);lmo=r(dnt,"speech_to_text_2"),dnt.forEach(t),imo=r(QLe," \u2014 "),$I=n(QLe,"A",{href:!0});var cnt=s($I);dmo=r(cnt,"Speech2Text2Tokenizer"),cnt.forEach(t),cmo=r(QLe," (Speech2Text2 model)"),QLe.forEach(t),fmo=i(S),Rs=n(S,"LI",{});var Ok=s(Rs);rle=n(Ok,"STRONG",{});var fnt=s(rle);mmo=r(fnt,"splinter"),fnt.forEach(t),gmo=r(Ok," \u2014 "),kI=n(Ok,"A",{href:!0});var mnt=s(kI);hmo=r(mnt,"SplinterTokenizer"),mnt.forEach(t),pmo=r(Ok," or "),SI=n(Ok,"A",{href:!0});var gnt=s(SI);_mo=r(gnt,"SplinterTokenizerFast"),gnt.forEach(t),umo=r(Ok," (Splinter model)"),Ok.forEach(t),bmo=i(S),Ps=n(S,"LI",{});var Vk=s(Ps);tle=n(Vk,"STRONG",{});var hnt=s(tle);vmo=r(hnt,"squeezebert"),hnt.forEach(t),Fmo=r(Vk," \u2014 "),RI=n(Vk,"A",{href:!0});var pnt=s(RI);Tmo=r(pnt,"SqueezeBertTokenizer"),pnt.forEach(t),Mmo=r(Vk," or "),PI=n(Vk,"A",{href:!0});var _nt=s(PI);Emo=r(_nt,"SqueezeBertTokenizerFast"),_nt.forEach(t),Cmo=r(Vk," (SqueezeBERT model)"),Vk.forEach(t),wmo=i(S),Bs=n(S,"LI",{});var Xk=s(Bs);ale=n(Xk,"STRONG",{});var unt=s(ale);Amo=r(unt,"t5"),unt.forEach(t),Lmo=r(Xk," \u2014 "),BI=n(Xk,"A",{href:!0});var bnt=s(BI);ymo=r(bnt,"T5Tokenizer"),bnt.forEach(t),xmo=r(Xk," or "),II=n(Xk,"A",{href:!0});var vnt=s(II);$mo=r(vnt,"T5TokenizerFast"),vnt.forEach(t),kmo=r(Xk," (T5 model)"),Xk.forEach(t),Smo=i(S),ph=n(S,"LI",{});var WLe=s(ph);nle=n(WLe,"STRONG",{});var Fnt=s(nle);Rmo=r(Fnt,"tapas"),Fnt.forEach(t),Pmo=r(WLe," \u2014 "),NI=n(WLe,"A",{href:!0});var Tnt=s(NI);Bmo=r(Tnt,"TapasTokenizer"),Tnt.forEach(t),Imo=r(WLe," (TAPAS model)"),WLe.forEach(t),Nmo=i(S),_h=n(S,"LI",{});var HLe=s(_h);sle=n(HLe,"STRONG",{});var Mnt=s(sle);qmo=r(Mnt,"tapex"),Mnt.forEach(t),jmo=r(HLe," \u2014 "),qI=n(HLe,"A",{href:!0});var Ent=s(qI);Dmo=r(Ent,"TapexTokenizer"),Ent.forEach(t),Gmo=r(HLe," (TAPEX model)"),HLe.forEach(t),Omo=i(S),uh=n(S,"LI",{});var ULe=s(uh);lle=n(ULe,"STRONG",{});var Cnt=s(lle);Vmo=r(Cnt,"transfo-xl"),Cnt.forEach(t),Xmo=r(ULe," \u2014 "),jI=n(ULe,"A",{href:!0});var wnt=s(jI);zmo=r(wnt,"TransfoXLTokenizer"),wnt.forEach(t),Qmo=r(ULe," (Transformer-XL model)"),ULe.forEach(t),Wmo=i(S),Is=n(S,"LI",{});var zk=s(Is);ile=n(zk,"STRONG",{});var Ant=s(ile);Hmo=r(Ant,"vilt"),Ant.forEach(t),Umo=r(zk," \u2014 "),DI=n(zk,"A",{href:!0});var Lnt=s(DI);Jmo=r(Lnt,"BertTokenizer"),Lnt.forEach(t),Ymo=r(zk," or "),GI=n(zk,"A",{href:!0});var ynt=s(GI);Kmo=r(ynt,"BertTokenizerFast"),ynt.forEach(t),Zmo=r(zk," (ViLT model)"),zk.forEach(t),ego=i(S),Ns=n(S,"LI",{});var Qk=s(Ns);dle=n(Qk,"STRONG",{});var xnt=s(dle);ogo=r(xnt,"visual_bert"),xnt.forEach(t),rgo=r(Qk," \u2014 "),OI=n(Qk,"A",{href:!0});var $nt=s(OI);tgo=r($nt,"BertTokenizer"),$nt.forEach(t),ago=r(Qk," or "),VI=n(Qk,"A",{href:!0});var knt=s(VI);ngo=r(knt,"BertTokenizerFast"),knt.forEach(t),sgo=r(Qk," (VisualBERT model)"),Qk.forEach(t),lgo=i(S),bh=n(S,"LI",{});var JLe=s(bh);cle=n(JLe,"STRONG",{});var Snt=s(cle);igo=r(Snt,"wav2vec2"),Snt.forEach(t),dgo=r(JLe," \u2014 "),XI=n(JLe,"A",{href:!0});var Rnt=s(XI);cgo=r(Rnt,"Wav2Vec2CTCTokenizer"),Rnt.forEach(t),fgo=r(JLe," (Wav2Vec2 model)"),JLe.forEach(t),mgo=i(S),vh=n(S,"LI",{});var YLe=s(vh);fle=n(YLe,"STRONG",{});var Pnt=s(fle);ggo=r(Pnt,"wav2vec2-conformer"),Pnt.forEach(t),hgo=r(YLe," \u2014 "),zI=n(YLe,"A",{href:!0});var Bnt=s(zI);pgo=r(Bnt,"Wav2Vec2CTCTokenizer"),Bnt.forEach(t),_go=r(YLe," (Wav2Vec2-Conformer model)"),YLe.forEach(t),ugo=i(S),Fh=n(S,"LI",{});var KLe=s(Fh);mle=n(KLe,"STRONG",{});var Int=s(mle);bgo=r(Int,"wav2vec2_phoneme"),Int.forEach(t),vgo=r(KLe," \u2014 "),QI=n(KLe,"A",{href:!0});var Nnt=s(QI);Fgo=r(Nnt,"Wav2Vec2PhonemeCTCTokenizer"),Nnt.forEach(t),Tgo=r(KLe," (Wav2Vec2Phoneme model)"),KLe.forEach(t),Mgo=i(S),qs=n(S,"LI",{});var Wk=s(qs);gle=n(Wk,"STRONG",{});var qnt=s(gle);Ego=r(qnt,"xglm"),qnt.forEach(t),Cgo=r(Wk," \u2014 "),WI=n(Wk,"A",{href:!0});var jnt=s(WI);wgo=r(jnt,"XGLMTokenizer"),jnt.forEach(t),Ago=r(Wk," or "),HI=n(Wk,"A",{href:!0});var Dnt=s(HI);Lgo=r(Dnt,"XGLMTokenizerFast"),Dnt.forEach(t),ygo=r(Wk," (XGLM model)"),Wk.forEach(t),xgo=i(S),Th=n(S,"LI",{});var ZLe=s(Th);hle=n(ZLe,"STRONG",{});var Gnt=s(hle);$go=r(Gnt,"xlm"),Gnt.forEach(t),kgo=r(ZLe," \u2014 "),UI=n(ZLe,"A",{href:!0});var Ont=s(UI);Sgo=r(Ont,"XLMTokenizer"),Ont.forEach(t),Rgo=r(ZLe," (XLM model)"),ZLe.forEach(t),Pgo=i(S),Mh=n(S,"LI",{});var eye=s(Mh);ple=n(eye,"STRONG",{});var Vnt=s(ple);Bgo=r(Vnt,"xlm-prophetnet"),Vnt.forEach(t),Igo=r(eye," \u2014 "),JI=n(eye,"A",{href:!0});var Xnt=s(JI);Ngo=r(Xnt,"XLMProphetNetTokenizer"),Xnt.forEach(t),qgo=r(eye," (XLM-ProphetNet model)"),eye.forEach(t),jgo=i(S),js=n(S,"LI",{});var Hk=s(js);_le=n(Hk,"STRONG",{});var znt=s(_le);Dgo=r(znt,"xlm-roberta"),znt.forEach(t),Ggo=r(Hk," \u2014 "),YI=n(Hk,"A",{href:!0});var Qnt=s(YI);Ogo=r(Qnt,"XLMRobertaTokenizer"),Qnt.forEach(t),Vgo=r(Hk," or "),KI=n(Hk,"A",{href:!0});var Wnt=s(KI);Xgo=r(Wnt,"XLMRobertaTokenizerFast"),Wnt.forEach(t),zgo=r(Hk," (XLM-RoBERTa model)"),Hk.forEach(t),Qgo=i(S),Ds=n(S,"LI",{});var Uk=s(Ds);ule=n(Uk,"STRONG",{});var Hnt=s(ule);Wgo=r(Hnt,"xlm-roberta-xl"),Hnt.forEach(t),Hgo=r(Uk," \u2014 "),ZI=n(Uk,"A",{href:!0});var Unt=s(ZI);Ugo=r(Unt,"RobertaTokenizer"),Unt.forEach(t),Jgo=r(Uk," or "),eN=n(Uk,"A",{href:!0});var Jnt=s(eN);Ygo=r(Jnt,"RobertaTokenizerFast"),Jnt.forEach(t),Kgo=r(Uk," (XLM-RoBERTa-XL model)"),Uk.forEach(t),Zgo=i(S),Gs=n(S,"LI",{});var Jk=s(Gs);ble=n(Jk,"STRONG",{});var Ynt=s(ble);eho=r(Ynt,"xlnet"),Ynt.forEach(t),oho=r(Jk," \u2014 "),oN=n(Jk,"A",{href:!0});var Knt=s(oN);rho=r(Knt,"XLNetTokenizer"),Knt.forEach(t),tho=r(Jk," or "),rN=n(Jk,"A",{href:!0});var Znt=s(rN);aho=r(Znt,"XLNetTokenizerFast"),Znt.forEach(t),nho=r(Jk," (XLNet model)"),Jk.forEach(t),sho=i(S),Os=n(S,"LI",{});var Yk=s(Os);vle=n(Yk,"STRONG",{});var est=s(vle);lho=r(est,"yoso"),est.forEach(t),iho=r(Yk," \u2014 "),tN=n(Yk,"A",{href:!0});var ost=s(tN);dho=r(ost,"AlbertTokenizer"),ost.forEach(t),cho=r(Yk," or "),aN=n(Yk,"A",{href:!0});var rst=s(aN);fho=r(rst,"AlbertTokenizerFast"),rst.forEach(t),mho=r(Yk," (YOSO model)"),Yk.forEach(t),S.forEach(t),gho=i(Hs),T(Eh.$$.fragment,Hs),Hs.forEach(t),hho=i(Ws),Ch=n(Ws,"DIV",{class:!0});var UVe=s(Ch);T(OL.$$.fragment,UVe),pho=i(UVe),Fle=n(UVe,"P",{});var tst=s(Fle);_ho=r(tst,"Register a new tokenizer in this mapping."),tst.forEach(t),UVe.forEach(t),Ws.forEach(t),HGe=i(f),Si=n(f,"H2",{class:!0});var JVe=s(Si);wh=n(JVe,"A",{id:!0,class:!0,href:!0});var ast=s(wh);Tle=n(ast,"SPAN",{});var nst=s(Tle);T(VL.$$.fragment,nst),nst.forEach(t),ast.forEach(t),uho=i(JVe),Mle=n(JVe,"SPAN",{});var sst=s(Mle);bho=r(sst,"AutoFeatureExtractor"),sst.forEach(t),JVe.forEach(t),UGe=i(f),Lo=n(f,"DIV",{class:!0});var Us=s(Lo);T(XL.$$.fragment,Us),vho=i(Us),zL=n(Us,"P",{});var YVe=s(zL);Fho=r(YVe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),nN=n(YVe,"A",{href:!0});var lst=s(nN);Tho=r(lst,"AutoFeatureExtractor.from_pretrained()"),lst.forEach(t),Mho=r(YVe," class method."),YVe.forEach(t),Eho=i(Us),QL=n(Us,"P",{});var KVe=s(QL);Cho=r(KVe,"This class cannot be instantiated directly using "),Ele=n(KVe,"CODE",{});var ist=s(Ele);who=r(ist,"__init__()"),ist.forEach(t),Aho=r(KVe," (throws an error)."),KVe.forEach(t),Lho=i(Us),He=n(Us,"DIV",{class:!0});var ra=s(He);T(WL.$$.fragment,ra),yho=i(ra),Cle=n(ra,"P",{});var dst=s(Cle);xho=r(dst,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),dst.forEach(t),$ho=i(ra),Sa=n(ra,"P",{});var $A=s(Sa);kho=r($A,"The feature extractor class to instantiate is selected based on the "),wle=n($A,"CODE",{});var cst=s(wle);Sho=r(cst,"model_type"),cst.forEach(t),Rho=r($A,` property of the config object
(either passed as an argument or loaded from `),Ale=n($A,"CODE",{});var fst=s(Ale);Pho=r(fst,"pretrained_model_name_or_path"),fst.forEach(t),Bho=r($A,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Lle=n($A,"CODE",{});var mst=s(Lle);Iho=r(mst,"pretrained_model_name_or_path"),mst.forEach(t),Nho=r($A,":"),$A.forEach(t),qho=i(ra),Y=n(ra,"UL",{});var K=s(Y);Ah=n(K,"LI",{});var oye=s(Ah);yle=n(oye,"STRONG",{});var gst=s(yle);jho=r(gst,"beit"),gst.forEach(t),Dho=r(oye," \u2014 "),sN=n(oye,"A",{href:!0});var hst=s(sN);Gho=r(hst,"BeitFeatureExtractor"),hst.forEach(t),Oho=r(oye," (BEiT model)"),oye.forEach(t),Vho=i(K),Lh=n(K,"LI",{});var rye=s(Lh);xle=n(rye,"STRONG",{});var pst=s(xle);Xho=r(pst,"clip"),pst.forEach(t),zho=r(rye," \u2014 "),lN=n(rye,"A",{href:!0});var _st=s(lN);Qho=r(_st,"CLIPFeatureExtractor"),_st.forEach(t),Who=r(rye," (CLIP model)"),rye.forEach(t),Hho=i(K),yh=n(K,"LI",{});var tye=s(yh);$le=n(tye,"STRONG",{});var ust=s($le);Uho=r(ust,"convnext"),ust.forEach(t),Jho=r(tye," \u2014 "),iN=n(tye,"A",{href:!0});var bst=s(iN);Yho=r(bst,"ConvNextFeatureExtractor"),bst.forEach(t),Kho=r(tye," (ConvNeXT model)"),tye.forEach(t),Zho=i(K),xh=n(K,"LI",{});var aye=s(xh);kle=n(aye,"STRONG",{});var vst=s(kle);epo=r(vst,"cvt"),vst.forEach(t),opo=r(aye," \u2014 "),dN=n(aye,"A",{href:!0});var Fst=s(dN);rpo=r(Fst,"ConvNextFeatureExtractor"),Fst.forEach(t),tpo=r(aye," (CvT model)"),aye.forEach(t),apo=i(K),$h=n(K,"LI",{});var nye=s($h);Sle=n(nye,"STRONG",{});var Tst=s(Sle);npo=r(Tst,"data2vec-audio"),Tst.forEach(t),spo=r(nye," \u2014 "),cN=n(nye,"A",{href:!0});var Mst=s(cN);lpo=r(Mst,"Wav2Vec2FeatureExtractor"),Mst.forEach(t),ipo=r(nye," (Data2VecAudio model)"),nye.forEach(t),dpo=i(K),kh=n(K,"LI",{});var sye=s(kh);Rle=n(sye,"STRONG",{});var Est=s(Rle);cpo=r(Est,"data2vec-vision"),Est.forEach(t),fpo=r(sye," \u2014 "),fN=n(sye,"A",{href:!0});var Cst=s(fN);mpo=r(Cst,"BeitFeatureExtractor"),Cst.forEach(t),gpo=r(sye," (Data2VecVision model)"),sye.forEach(t),hpo=i(K),Sh=n(K,"LI",{});var lye=s(Sh);Ple=n(lye,"STRONG",{});var wst=s(Ple);ppo=r(wst,"deit"),wst.forEach(t),_po=r(lye," \u2014 "),mN=n(lye,"A",{href:!0});var Ast=s(mN);upo=r(Ast,"DeiTFeatureExtractor"),Ast.forEach(t),bpo=r(lye," (DeiT model)"),lye.forEach(t),vpo=i(K),Rh=n(K,"LI",{});var iye=s(Rh);Ble=n(iye,"STRONG",{});var Lst=s(Ble);Fpo=r(Lst,"detr"),Lst.forEach(t),Tpo=r(iye," \u2014 "),gN=n(iye,"A",{href:!0});var yst=s(gN);Mpo=r(yst,"DetrFeatureExtractor"),yst.forEach(t),Epo=r(iye," (DETR model)"),iye.forEach(t),Cpo=i(K),Ph=n(K,"LI",{});var dye=s(Ph);Ile=n(dye,"STRONG",{});var xst=s(Ile);wpo=r(xst,"dpt"),xst.forEach(t),Apo=r(dye," \u2014 "),hN=n(dye,"A",{href:!0});var $st=s(hN);Lpo=r($st,"DPTFeatureExtractor"),$st.forEach(t),ypo=r(dye," (DPT model)"),dye.forEach(t),xpo=i(K),Bh=n(K,"LI",{});var cye=s(Bh);Nle=n(cye,"STRONG",{});var kst=s(Nle);$po=r(kst,"flava"),kst.forEach(t),kpo=r(cye," \u2014 "),pN=n(cye,"A",{href:!0});var Sst=s(pN);Spo=r(Sst,"FlavaFeatureExtractor"),Sst.forEach(t),Rpo=r(cye," (FLAVA model)"),cye.forEach(t),Ppo=i(K),Ih=n(K,"LI",{});var fye=s(Ih);qle=n(fye,"STRONG",{});var Rst=s(qle);Bpo=r(Rst,"glpn"),Rst.forEach(t),Ipo=r(fye," \u2014 "),_N=n(fye,"A",{href:!0});var Pst=s(_N);Npo=r(Pst,"GLPNFeatureExtractor"),Pst.forEach(t),qpo=r(fye," (GLPN model)"),fye.forEach(t),jpo=i(K),Nh=n(K,"LI",{});var mye=s(Nh);jle=n(mye,"STRONG",{});var Bst=s(jle);Dpo=r(Bst,"hubert"),Bst.forEach(t),Gpo=r(mye," \u2014 "),uN=n(mye,"A",{href:!0});var Ist=s(uN);Opo=r(Ist,"Wav2Vec2FeatureExtractor"),Ist.forEach(t),Vpo=r(mye," (Hubert model)"),mye.forEach(t),Xpo=i(K),qh=n(K,"LI",{});var gye=s(qh);Dle=n(gye,"STRONG",{});var Nst=s(Dle);zpo=r(Nst,"imagegpt"),Nst.forEach(t),Qpo=r(gye," \u2014 "),bN=n(gye,"A",{href:!0});var qst=s(bN);Wpo=r(qst,"ImageGPTFeatureExtractor"),qst.forEach(t),Hpo=r(gye," (ImageGPT model)"),gye.forEach(t),Upo=i(K),jh=n(K,"LI",{});var hye=s(jh);Gle=n(hye,"STRONG",{});var jst=s(Gle);Jpo=r(jst,"layoutlmv2"),jst.forEach(t),Ypo=r(hye," \u2014 "),vN=n(hye,"A",{href:!0});var Dst=s(vN);Kpo=r(Dst,"LayoutLMv2FeatureExtractor"),Dst.forEach(t),Zpo=r(hye," (LayoutLMv2 model)"),hye.forEach(t),e_o=i(K),Dh=n(K,"LI",{});var pye=s(Dh);Ole=n(pye,"STRONG",{});var Gst=s(Ole);o_o=r(Gst,"layoutlmv3"),Gst.forEach(t),r_o=r(pye," \u2014 "),FN=n(pye,"A",{href:!0});var Ost=s(FN);t_o=r(Ost,"LayoutLMv3FeatureExtractor"),Ost.forEach(t),a_o=r(pye," (LayoutLMv3 model)"),pye.forEach(t),n_o=i(K),Gh=n(K,"LI",{});var _ye=s(Gh);Vle=n(_ye,"STRONG",{});var Vst=s(Vle);s_o=r(Vst,"levit"),Vst.forEach(t),l_o=r(_ye," \u2014 "),TN=n(_ye,"A",{href:!0});var Xst=s(TN);i_o=r(Xst,"LevitFeatureExtractor"),Xst.forEach(t),d_o=r(_ye," (LeViT model)"),_ye.forEach(t),c_o=i(K),Oh=n(K,"LI",{});var uye=s(Oh);Xle=n(uye,"STRONG",{});var zst=s(Xle);f_o=r(zst,"maskformer"),zst.forEach(t),m_o=r(uye," \u2014 "),MN=n(uye,"A",{href:!0});var Qst=s(MN);g_o=r(Qst,"MaskFormerFeatureExtractor"),Qst.forEach(t),h_o=r(uye," (MaskFormer model)"),uye.forEach(t),p_o=i(K),Vh=n(K,"LI",{});var bye=s(Vh);zle=n(bye,"STRONG",{});var Wst=s(zle);__o=r(Wst,"mctct"),Wst.forEach(t),u_o=r(bye," \u2014 "),EN=n(bye,"A",{href:!0});var Hst=s(EN);b_o=r(Hst,"MCTCTFeatureExtractor"),Hst.forEach(t),v_o=r(bye," (M-CTC-T model)"),bye.forEach(t),F_o=i(K),Xh=n(K,"LI",{});var vye=s(Xh);Qle=n(vye,"STRONG",{});var Ust=s(Qle);T_o=r(Ust,"perceiver"),Ust.forEach(t),M_o=r(vye," \u2014 "),CN=n(vye,"A",{href:!0});var Jst=s(CN);E_o=r(Jst,"PerceiverFeatureExtractor"),Jst.forEach(t),C_o=r(vye," (Perceiver model)"),vye.forEach(t),w_o=i(K),zh=n(K,"LI",{});var Fye=s(zh);Wle=n(Fye,"STRONG",{});var Yst=s(Wle);A_o=r(Yst,"poolformer"),Yst.forEach(t),L_o=r(Fye," \u2014 "),wN=n(Fye,"A",{href:!0});var Kst=s(wN);y_o=r(Kst,"PoolFormerFeatureExtractor"),Kst.forEach(t),x_o=r(Fye," (PoolFormer model)"),Fye.forEach(t),$_o=i(K),Qh=n(K,"LI",{});var Tye=s(Qh);Hle=n(Tye,"STRONG",{});var Zst=s(Hle);k_o=r(Zst,"regnet"),Zst.forEach(t),S_o=r(Tye," \u2014 "),AN=n(Tye,"A",{href:!0});var elt=s(AN);R_o=r(elt,"ConvNextFeatureExtractor"),elt.forEach(t),P_o=r(Tye," (RegNet model)"),Tye.forEach(t),B_o=i(K),Wh=n(K,"LI",{});var Mye=s(Wh);Ule=n(Mye,"STRONG",{});var olt=s(Ule);I_o=r(olt,"resnet"),olt.forEach(t),N_o=r(Mye," \u2014 "),LN=n(Mye,"A",{href:!0});var rlt=s(LN);q_o=r(rlt,"ConvNextFeatureExtractor"),rlt.forEach(t),j_o=r(Mye," (ResNet model)"),Mye.forEach(t),D_o=i(K),Hh=n(K,"LI",{});var Eye=s(Hh);Jle=n(Eye,"STRONG",{});var tlt=s(Jle);G_o=r(tlt,"segformer"),tlt.forEach(t),O_o=r(Eye," \u2014 "),yN=n(Eye,"A",{href:!0});var alt=s(yN);V_o=r(alt,"SegformerFeatureExtractor"),alt.forEach(t),X_o=r(Eye," (SegFormer model)"),Eye.forEach(t),z_o=i(K),Uh=n(K,"LI",{});var Cye=s(Uh);Yle=n(Cye,"STRONG",{});var nlt=s(Yle);Q_o=r(nlt,"speech_to_text"),nlt.forEach(t),W_o=r(Cye," \u2014 "),xN=n(Cye,"A",{href:!0});var slt=s(xN);H_o=r(slt,"Speech2TextFeatureExtractor"),slt.forEach(t),U_o=r(Cye," (Speech2Text model)"),Cye.forEach(t),J_o=i(K),Jh=n(K,"LI",{});var wye=s(Jh);Kle=n(wye,"STRONG",{});var llt=s(Kle);Y_o=r(llt,"swin"),llt.forEach(t),K_o=r(wye," \u2014 "),$N=n(wye,"A",{href:!0});var ilt=s($N);Z_o=r(ilt,"ViTFeatureExtractor"),ilt.forEach(t),euo=r(wye," (Swin Transformer model)"),wye.forEach(t),ouo=i(K),Yh=n(K,"LI",{});var Aye=s(Yh);Zle=n(Aye,"STRONG",{});var dlt=s(Zle);ruo=r(dlt,"van"),dlt.forEach(t),tuo=r(Aye," \u2014 "),kN=n(Aye,"A",{href:!0});var clt=s(kN);auo=r(clt,"ConvNextFeatureExtractor"),clt.forEach(t),nuo=r(Aye," (VAN model)"),Aye.forEach(t),suo=i(K),Kh=n(K,"LI",{});var Lye=s(Kh);eie=n(Lye,"STRONG",{});var flt=s(eie);luo=r(flt,"vilt"),flt.forEach(t),iuo=r(Lye," \u2014 "),SN=n(Lye,"A",{href:!0});var mlt=s(SN);duo=r(mlt,"ViltFeatureExtractor"),mlt.forEach(t),cuo=r(Lye," (ViLT model)"),Lye.forEach(t),fuo=i(K),Zh=n(K,"LI",{});var yye=s(Zh);oie=n(yye,"STRONG",{});var glt=s(oie);muo=r(glt,"vit"),glt.forEach(t),guo=r(yye," \u2014 "),RN=n(yye,"A",{href:!0});var hlt=s(RN);huo=r(hlt,"ViTFeatureExtractor"),hlt.forEach(t),puo=r(yye," (ViT model)"),yye.forEach(t),_uo=i(K),ep=n(K,"LI",{});var xye=s(ep);rie=n(xye,"STRONG",{});var plt=s(rie);uuo=r(plt,"vit_mae"),plt.forEach(t),buo=r(xye," \u2014 "),PN=n(xye,"A",{href:!0});var _lt=s(PN);vuo=r(_lt,"ViTFeatureExtractor"),_lt.forEach(t),Fuo=r(xye," (ViTMAE model)"),xye.forEach(t),Tuo=i(K),op=n(K,"LI",{});var $ye=s(op);tie=n($ye,"STRONG",{});var ult=s(tie);Muo=r(ult,"wav2vec2"),ult.forEach(t),Euo=r($ye," \u2014 "),BN=n($ye,"A",{href:!0});var blt=s(BN);Cuo=r(blt,"Wav2Vec2FeatureExtractor"),blt.forEach(t),wuo=r($ye," (Wav2Vec2 model)"),$ye.forEach(t),Auo=i(K),rp=n(K,"LI",{});var kye=s(rp);aie=n(kye,"STRONG",{});var vlt=s(aie);Luo=r(vlt,"wav2vec2-conformer"),vlt.forEach(t),yuo=r(kye," \u2014 "),IN=n(kye,"A",{href:!0});var Flt=s(IN);xuo=r(Flt,"Wav2Vec2FeatureExtractor"),Flt.forEach(t),$uo=r(kye," (Wav2Vec2-Conformer model)"),kye.forEach(t),kuo=i(K),tp=n(K,"LI",{});var Sye=s(tp);nie=n(Sye,"STRONG",{});var Tlt=s(nie);Suo=r(Tlt,"yolos"),Tlt.forEach(t),Ruo=r(Sye," \u2014 "),NN=n(Sye,"A",{href:!0});var Mlt=s(NN);Puo=r(Mlt,"YolosFeatureExtractor"),Mlt.forEach(t),Buo=r(Sye," (YOLOS model)"),Sye.forEach(t),K.forEach(t),Iuo=i(ra),T(ap.$$.fragment,ra),Nuo=i(ra),T(np.$$.fragment,ra),ra.forEach(t),quo=i(Us),sp=n(Us,"DIV",{class:!0});var ZVe=s(sp);T(HL.$$.fragment,ZVe),juo=i(ZVe),sie=n(ZVe,"P",{});var Elt=s(sie);Duo=r(Elt,"Register a new feature extractor for this class."),Elt.forEach(t),ZVe.forEach(t),Us.forEach(t),JGe=i(f),Ri=n(f,"H2",{class:!0});var eXe=s(Ri);lp=n(eXe,"A",{id:!0,class:!0,href:!0});var Clt=s(lp);lie=n(Clt,"SPAN",{});var wlt=s(lie);T(UL.$$.fragment,wlt),wlt.forEach(t),Clt.forEach(t),Guo=i(eXe),iie=n(eXe,"SPAN",{});var Alt=s(iie);Ouo=r(Alt,"AutoProcessor"),Alt.forEach(t),eXe.forEach(t),YGe=i(f),yo=n(f,"DIV",{class:!0});var Js=s(yo);T(JL.$$.fragment,Js),Vuo=i(Js),YL=n(Js,"P",{});var oXe=s(YL);Xuo=r(oXe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),qN=n(oXe,"A",{href:!0});var Llt=s(qN);zuo=r(Llt,"AutoProcessor.from_pretrained()"),Llt.forEach(t),Quo=r(oXe," class method."),oXe.forEach(t),Wuo=i(Js),KL=n(Js,"P",{});var rXe=s(KL);Huo=r(rXe,"This class cannot be instantiated directly using "),die=n(rXe,"CODE",{});var ylt=s(die);Uuo=r(ylt,"__init__()"),ylt.forEach(t),Juo=r(rXe," (throws an error)."),rXe.forEach(t),Yuo=i(Js),Ue=n(Js,"DIV",{class:!0});var ta=s(Ue);T(ZL.$$.fragment,ta),Kuo=i(ta),cie=n(ta,"P",{});var xlt=s(cie);Zuo=r(xlt,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),xlt.forEach(t),e1o=i(ta),Pi=n(ta,"P",{});var boe=s(Pi);o1o=r(boe,"The processor class to instantiate is selected based on the "),fie=n(boe,"CODE",{});var $lt=s(fie);r1o=r($lt,"model_type"),$lt.forEach(t),t1o=r(boe,` property of the config object (either
passed as an argument or loaded from `),mie=n(boe,"CODE",{});var klt=s(mie);a1o=r(klt,"pretrained_model_name_or_path"),klt.forEach(t),n1o=r(boe," if possible):"),boe.forEach(t),s1o=i(ta),he=n(ta,"UL",{});var ue=s(he);ip=n(ue,"LI",{});var Rye=s(ip);gie=n(Rye,"STRONG",{});var Slt=s(gie);l1o=r(Slt,"clip"),Slt.forEach(t),i1o=r(Rye," \u2014 "),jN=n(Rye,"A",{href:!0});var Rlt=s(jN);d1o=r(Rlt,"CLIPProcessor"),Rlt.forEach(t),c1o=r(Rye," (CLIP model)"),Rye.forEach(t),f1o=i(ue),dp=n(ue,"LI",{});var Pye=s(dp);hie=n(Pye,"STRONG",{});var Plt=s(hie);m1o=r(Plt,"flava"),Plt.forEach(t),g1o=r(Pye," \u2014 "),pie=n(Pye,"CODE",{});var Blt=s(pie);h1o=r(Blt,"FLAVAProcessor"),Blt.forEach(t),p1o=r(Pye," (FLAVA model)"),Pye.forEach(t),_1o=i(ue),cp=n(ue,"LI",{});var Bye=s(cp);_ie=n(Bye,"STRONG",{});var Ilt=s(_ie);u1o=r(Ilt,"layoutlmv2"),Ilt.forEach(t),b1o=r(Bye," \u2014 "),DN=n(Bye,"A",{href:!0});var Nlt=s(DN);v1o=r(Nlt,"LayoutLMv2Processor"),Nlt.forEach(t),F1o=r(Bye," (LayoutLMv2 model)"),Bye.forEach(t),T1o=i(ue),fp=n(ue,"LI",{});var Iye=s(fp);uie=n(Iye,"STRONG",{});var qlt=s(uie);M1o=r(qlt,"layoutlmv3"),qlt.forEach(t),E1o=r(Iye," \u2014 "),GN=n(Iye,"A",{href:!0});var jlt=s(GN);C1o=r(jlt,"LayoutLMv3Processor"),jlt.forEach(t),w1o=r(Iye," (LayoutLMv3 model)"),Iye.forEach(t),A1o=i(ue),mp=n(ue,"LI",{});var Nye=s(mp);bie=n(Nye,"STRONG",{});var Dlt=s(bie);L1o=r(Dlt,"layoutxlm"),Dlt.forEach(t),y1o=r(Nye," \u2014 "),ON=n(Nye,"A",{href:!0});var Glt=s(ON);x1o=r(Glt,"LayoutXLMProcessor"),Glt.forEach(t),$1o=r(Nye," (LayoutXLM model)"),Nye.forEach(t),k1o=i(ue),gp=n(ue,"LI",{});var qye=s(gp);vie=n(qye,"STRONG",{});var Olt=s(vie);S1o=r(Olt,"sew"),Olt.forEach(t),R1o=r(qye," \u2014 "),VN=n(qye,"A",{href:!0});var Vlt=s(VN);P1o=r(Vlt,"Wav2Vec2Processor"),Vlt.forEach(t),B1o=r(qye," (SEW model)"),qye.forEach(t),I1o=i(ue),hp=n(ue,"LI",{});var jye=s(hp);Fie=n(jye,"STRONG",{});var Xlt=s(Fie);N1o=r(Xlt,"sew-d"),Xlt.forEach(t),q1o=r(jye," \u2014 "),XN=n(jye,"A",{href:!0});var zlt=s(XN);j1o=r(zlt,"Wav2Vec2Processor"),zlt.forEach(t),D1o=r(jye," (SEW-D model)"),jye.forEach(t),G1o=i(ue),pp=n(ue,"LI",{});var Dye=s(pp);Tie=n(Dye,"STRONG",{});var Qlt=s(Tie);O1o=r(Qlt,"speech_to_text"),Qlt.forEach(t),V1o=r(Dye," \u2014 "),zN=n(Dye,"A",{href:!0});var Wlt=s(zN);X1o=r(Wlt,"Speech2TextProcessor"),Wlt.forEach(t),z1o=r(Dye," (Speech2Text model)"),Dye.forEach(t),Q1o=i(ue),_p=n(ue,"LI",{});var Gye=s(_p);Mie=n(Gye,"STRONG",{});var Hlt=s(Mie);W1o=r(Hlt,"speech_to_text_2"),Hlt.forEach(t),H1o=r(Gye," \u2014 "),QN=n(Gye,"A",{href:!0});var Ult=s(QN);U1o=r(Ult,"Speech2Text2Processor"),Ult.forEach(t),J1o=r(Gye," (Speech2Text2 model)"),Gye.forEach(t),Y1o=i(ue),up=n(ue,"LI",{});var Oye=s(up);Eie=n(Oye,"STRONG",{});var Jlt=s(Eie);K1o=r(Jlt,"trocr"),Jlt.forEach(t),Z1o=r(Oye," \u2014 "),WN=n(Oye,"A",{href:!0});var Ylt=s(WN);e7o=r(Ylt,"TrOCRProcessor"),Ylt.forEach(t),o7o=r(Oye," (TrOCR model)"),Oye.forEach(t),r7o=i(ue),bp=n(ue,"LI",{});var Vye=s(bp);Cie=n(Vye,"STRONG",{});var Klt=s(Cie);t7o=r(Klt,"unispeech"),Klt.forEach(t),a7o=r(Vye," \u2014 "),HN=n(Vye,"A",{href:!0});var Zlt=s(HN);n7o=r(Zlt,"Wav2Vec2Processor"),Zlt.forEach(t),s7o=r(Vye," (UniSpeech model)"),Vye.forEach(t),l7o=i(ue),vp=n(ue,"LI",{});var Xye=s(vp);wie=n(Xye,"STRONG",{});var eit=s(wie);i7o=r(eit,"unispeech-sat"),eit.forEach(t),d7o=r(Xye," \u2014 "),UN=n(Xye,"A",{href:!0});var oit=s(UN);c7o=r(oit,"Wav2Vec2Processor"),oit.forEach(t),f7o=r(Xye," (UniSpeechSat model)"),Xye.forEach(t),m7o=i(ue),Fp=n(ue,"LI",{});var zye=s(Fp);Aie=n(zye,"STRONG",{});var rit=s(Aie);g7o=r(rit,"vilt"),rit.forEach(t),h7o=r(zye," \u2014 "),JN=n(zye,"A",{href:!0});var tit=s(JN);p7o=r(tit,"ViltProcessor"),tit.forEach(t),_7o=r(zye," (ViLT model)"),zye.forEach(t),u7o=i(ue),Tp=n(ue,"LI",{});var Qye=s(Tp);Lie=n(Qye,"STRONG",{});var ait=s(Lie);b7o=r(ait,"vision-text-dual-encoder"),ait.forEach(t),v7o=r(Qye," \u2014 "),YN=n(Qye,"A",{href:!0});var nit=s(YN);F7o=r(nit,"VisionTextDualEncoderProcessor"),nit.forEach(t),T7o=r(Qye," (VisionTextDualEncoder model)"),Qye.forEach(t),M7o=i(ue),Mp=n(ue,"LI",{});var Wye=s(Mp);yie=n(Wye,"STRONG",{});var sit=s(yie);E7o=r(sit,"wav2vec2"),sit.forEach(t),C7o=r(Wye," \u2014 "),KN=n(Wye,"A",{href:!0});var lit=s(KN);w7o=r(lit,"Wav2Vec2Processor"),lit.forEach(t),A7o=r(Wye," (Wav2Vec2 model)"),Wye.forEach(t),L7o=i(ue),Ep=n(ue,"LI",{});var Hye=s(Ep);xie=n(Hye,"STRONG",{});var iit=s(xie);y7o=r(iit,"wav2vec2-conformer"),iit.forEach(t),x7o=r(Hye," \u2014 "),ZN=n(Hye,"A",{href:!0});var dit=s(ZN);$7o=r(dit,"Wav2Vec2Processor"),dit.forEach(t),k7o=r(Hye," (Wav2Vec2-Conformer model)"),Hye.forEach(t),S7o=i(ue),Cp=n(ue,"LI",{});var Uye=s(Cp);$ie=n(Uye,"STRONG",{});var cit=s($ie);R7o=r(cit,"wavlm"),cit.forEach(t),P7o=r(Uye," \u2014 "),eq=n(Uye,"A",{href:!0});var fit=s(eq);B7o=r(fit,"Wav2Vec2Processor"),fit.forEach(t),I7o=r(Uye," (WavLM model)"),Uye.forEach(t),ue.forEach(t),N7o=i(ta),T(wp.$$.fragment,ta),q7o=i(ta),T(Ap.$$.fragment,ta),ta.forEach(t),j7o=i(Js),Lp=n(Js,"DIV",{class:!0});var tXe=s(Lp);T(ey.$$.fragment,tXe),D7o=i(tXe),kie=n(tXe,"P",{});var mit=s(kie);G7o=r(mit,"Register a new processor for this class."),mit.forEach(t),tXe.forEach(t),Js.forEach(t),KGe=i(f),Bi=n(f,"H2",{class:!0});var aXe=s(Bi);yp=n(aXe,"A",{id:!0,class:!0,href:!0});var git=s(yp);Sie=n(git,"SPAN",{});var hit=s(Sie);T(oy.$$.fragment,hit),hit.forEach(t),git.forEach(t),O7o=i(aXe),Rie=n(aXe,"SPAN",{});var pit=s(Rie);V7o=r(pit,"AutoModel"),pit.forEach(t),aXe.forEach(t),ZGe=i(f),xo=n(f,"DIV",{class:!0});var Ys=s(xo);T(ry.$$.fragment,Ys),X7o=i(Ys),Ii=n(Ys,"P",{});var voe=s(Ii);z7o=r(voe,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),oq=n(voe,"A",{href:!0});var _it=s(oq);Q7o=r(_it,"from_pretrained()"),_it.forEach(t),W7o=r(voe," class method or the "),rq=n(voe,"A",{href:!0});var uit=s(rq);H7o=r(uit,"from_config()"),uit.forEach(t),U7o=r(voe,` class
method.`),voe.forEach(t),J7o=i(Ys),ty=n(Ys,"P",{});var nXe=s(ty);Y7o=r(nXe,"This class cannot be instantiated directly using "),Pie=n(nXe,"CODE",{});var bit=s(Pie);K7o=r(bit,"__init__()"),bit.forEach(t),Z7o=r(nXe," (throws an error)."),nXe.forEach(t),e2o=i(Ys),nt=n(Ys,"DIV",{class:!0});var kA=s(nt);T(ay.$$.fragment,kA),o2o=i(kA),Bie=n(kA,"P",{});var vit=s(Bie);r2o=r(vit,"Instantiates one of the base model classes of the library from a configuration."),vit.forEach(t),t2o=i(kA),Ni=n(kA,"P",{});var Foe=s(Ni);a2o=r(Foe,`Note:
Loading a model from its configuration file does `),Iie=n(Foe,"STRONG",{});var Fit=s(Iie);n2o=r(Fit,"not"),Fit.forEach(t),s2o=r(Foe,` load the model weights. It only affects the
model\u2019s configuration. Use `),tq=n(Foe,"A",{href:!0});var Tit=s(tq);l2o=r(Tit,"from_pretrained()"),Tit.forEach(t),i2o=r(Foe," to load the model weights."),Foe.forEach(t),d2o=i(kA),T(xp.$$.fragment,kA),kA.forEach(t),c2o=i(Ys),Je=n(Ys,"DIV",{class:!0});var aa=s(Je);T(ny.$$.fragment,aa),f2o=i(aa),Nie=n(aa,"P",{});var Mit=s(Nie);m2o=r(Mit,"Instantiate one of the base model classes of the library from a pretrained model."),Mit.forEach(t),g2o=i(aa),Ra=n(aa,"P",{});var SA=s(Ra);h2o=r(SA,"The model class to instantiate is selected based on the "),qie=n(SA,"CODE",{});var Eit=s(qie);p2o=r(Eit,"model_type"),Eit.forEach(t),_2o=r(SA,` property of the config object (either
passed as an argument or loaded from `),jie=n(SA,"CODE",{});var Cit=s(jie);u2o=r(Cit,"pretrained_model_name_or_path"),Cit.forEach(t),b2o=r(SA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Die=n(SA,"CODE",{});var wit=s(Die);v2o=r(wit,"pretrained_model_name_or_path"),wit.forEach(t),F2o=r(SA,":"),SA.forEach(t),T2o=i(aa),y=n(aa,"UL",{});var $=s(y);$p=n($,"LI",{});var Jye=s($p);Gie=n(Jye,"STRONG",{});var Ait=s(Gie);M2o=r(Ait,"albert"),Ait.forEach(t),E2o=r(Jye," \u2014 "),aq=n(Jye,"A",{href:!0});var Lit=s(aq);C2o=r(Lit,"AlbertModel"),Lit.forEach(t),w2o=r(Jye," (ALBERT model)"),Jye.forEach(t),A2o=i($),kp=n($,"LI",{});var Yye=s(kp);Oie=n(Yye,"STRONG",{});var yit=s(Oie);L2o=r(yit,"bart"),yit.forEach(t),y2o=r(Yye," \u2014 "),nq=n(Yye,"A",{href:!0});var xit=s(nq);x2o=r(xit,"BartModel"),xit.forEach(t),$2o=r(Yye," (BART model)"),Yye.forEach(t),k2o=i($),Sp=n($,"LI",{});var Kye=s(Sp);Vie=n(Kye,"STRONG",{});var $it=s(Vie);S2o=r($it,"beit"),$it.forEach(t),R2o=r(Kye," \u2014 "),sq=n(Kye,"A",{href:!0});var kit=s(sq);P2o=r(kit,"BeitModel"),kit.forEach(t),B2o=r(Kye," (BEiT model)"),Kye.forEach(t),I2o=i($),Rp=n($,"LI",{});var Zye=s(Rp);Xie=n(Zye,"STRONG",{});var Sit=s(Xie);N2o=r(Sit,"bert"),Sit.forEach(t),q2o=r(Zye," \u2014 "),lq=n(Zye,"A",{href:!0});var Rit=s(lq);j2o=r(Rit,"BertModel"),Rit.forEach(t),D2o=r(Zye," (BERT model)"),Zye.forEach(t),G2o=i($),Pp=n($,"LI",{});var e8e=s(Pp);zie=n(e8e,"STRONG",{});var Pit=s(zie);O2o=r(Pit,"bert-generation"),Pit.forEach(t),V2o=r(e8e," \u2014 "),iq=n(e8e,"A",{href:!0});var Bit=s(iq);X2o=r(Bit,"BertGenerationEncoder"),Bit.forEach(t),z2o=r(e8e," (Bert Generation model)"),e8e.forEach(t),Q2o=i($),Bp=n($,"LI",{});var o8e=s(Bp);Qie=n(o8e,"STRONG",{});var Iit=s(Qie);W2o=r(Iit,"big_bird"),Iit.forEach(t),H2o=r(o8e," \u2014 "),dq=n(o8e,"A",{href:!0});var Nit=s(dq);U2o=r(Nit,"BigBirdModel"),Nit.forEach(t),J2o=r(o8e," (BigBird model)"),o8e.forEach(t),Y2o=i($),Ip=n($,"LI",{});var r8e=s(Ip);Wie=n(r8e,"STRONG",{});var qit=s(Wie);K2o=r(qit,"bigbird_pegasus"),qit.forEach(t),Z2o=r(r8e," \u2014 "),cq=n(r8e,"A",{href:!0});var jit=s(cq);ebo=r(jit,"BigBirdPegasusModel"),jit.forEach(t),obo=r(r8e," (BigBird-Pegasus model)"),r8e.forEach(t),rbo=i($),Np=n($,"LI",{});var t8e=s(Np);Hie=n(t8e,"STRONG",{});var Dit=s(Hie);tbo=r(Dit,"blenderbot"),Dit.forEach(t),abo=r(t8e," \u2014 "),fq=n(t8e,"A",{href:!0});var Git=s(fq);nbo=r(Git,"BlenderbotModel"),Git.forEach(t),sbo=r(t8e," (Blenderbot model)"),t8e.forEach(t),lbo=i($),qp=n($,"LI",{});var a8e=s(qp);Uie=n(a8e,"STRONG",{});var Oit=s(Uie);ibo=r(Oit,"blenderbot-small"),Oit.forEach(t),dbo=r(a8e," \u2014 "),mq=n(a8e,"A",{href:!0});var Vit=s(mq);cbo=r(Vit,"BlenderbotSmallModel"),Vit.forEach(t),fbo=r(a8e," (BlenderbotSmall model)"),a8e.forEach(t),mbo=i($),jp=n($,"LI",{});var n8e=s(jp);Jie=n(n8e,"STRONG",{});var Xit=s(Jie);gbo=r(Xit,"bloom"),Xit.forEach(t),hbo=r(n8e," \u2014 "),gq=n(n8e,"A",{href:!0});var zit=s(gq);pbo=r(zit,"BloomModel"),zit.forEach(t),_bo=r(n8e," (BLOOM model)"),n8e.forEach(t),ubo=i($),Dp=n($,"LI",{});var s8e=s(Dp);Yie=n(s8e,"STRONG",{});var Qit=s(Yie);bbo=r(Qit,"camembert"),Qit.forEach(t),vbo=r(s8e," \u2014 "),hq=n(s8e,"A",{href:!0});var Wit=s(hq);Fbo=r(Wit,"CamembertModel"),Wit.forEach(t),Tbo=r(s8e," (CamemBERT model)"),s8e.forEach(t),Mbo=i($),Gp=n($,"LI",{});var l8e=s(Gp);Kie=n(l8e,"STRONG",{});var Hit=s(Kie);Ebo=r(Hit,"canine"),Hit.forEach(t),Cbo=r(l8e," \u2014 "),pq=n(l8e,"A",{href:!0});var Uit=s(pq);wbo=r(Uit,"CanineModel"),Uit.forEach(t),Abo=r(l8e," (CANINE model)"),l8e.forEach(t),Lbo=i($),Op=n($,"LI",{});var i8e=s(Op);Zie=n(i8e,"STRONG",{});var Jit=s(Zie);ybo=r(Jit,"clip"),Jit.forEach(t),xbo=r(i8e," \u2014 "),_q=n(i8e,"A",{href:!0});var Yit=s(_q);$bo=r(Yit,"CLIPModel"),Yit.forEach(t),kbo=r(i8e," (CLIP model)"),i8e.forEach(t),Sbo=i($),Vp=n($,"LI",{});var d8e=s(Vp);ede=n(d8e,"STRONG",{});var Kit=s(ede);Rbo=r(Kit,"convbert"),Kit.forEach(t),Pbo=r(d8e," \u2014 "),uq=n(d8e,"A",{href:!0});var Zit=s(uq);Bbo=r(Zit,"ConvBertModel"),Zit.forEach(t),Ibo=r(d8e," (ConvBERT model)"),d8e.forEach(t),Nbo=i($),Xp=n($,"LI",{});var c8e=s(Xp);ode=n(c8e,"STRONG",{});var edt=s(ode);qbo=r(edt,"convnext"),edt.forEach(t),jbo=r(c8e," \u2014 "),bq=n(c8e,"A",{href:!0});var odt=s(bq);Dbo=r(odt,"ConvNextModel"),odt.forEach(t),Gbo=r(c8e," (ConvNeXT model)"),c8e.forEach(t),Obo=i($),zp=n($,"LI",{});var f8e=s(zp);rde=n(f8e,"STRONG",{});var rdt=s(rde);Vbo=r(rdt,"ctrl"),rdt.forEach(t),Xbo=r(f8e," \u2014 "),vq=n(f8e,"A",{href:!0});var tdt=s(vq);zbo=r(tdt,"CTRLModel"),tdt.forEach(t),Qbo=r(f8e," (CTRL model)"),f8e.forEach(t),Wbo=i($),Qp=n($,"LI",{});var m8e=s(Qp);tde=n(m8e,"STRONG",{});var adt=s(tde);Hbo=r(adt,"cvt"),adt.forEach(t),Ubo=r(m8e," \u2014 "),Fq=n(m8e,"A",{href:!0});var ndt=s(Fq);Jbo=r(ndt,"CvtModel"),ndt.forEach(t),Ybo=r(m8e," (CvT model)"),m8e.forEach(t),Kbo=i($),Wp=n($,"LI",{});var g8e=s(Wp);ade=n(g8e,"STRONG",{});var sdt=s(ade);Zbo=r(sdt,"data2vec-audio"),sdt.forEach(t),e5o=r(g8e," \u2014 "),Tq=n(g8e,"A",{href:!0});var ldt=s(Tq);o5o=r(ldt,"Data2VecAudioModel"),ldt.forEach(t),r5o=r(g8e," (Data2VecAudio model)"),g8e.forEach(t),t5o=i($),Hp=n($,"LI",{});var h8e=s(Hp);nde=n(h8e,"STRONG",{});var idt=s(nde);a5o=r(idt,"data2vec-text"),idt.forEach(t),n5o=r(h8e," \u2014 "),Mq=n(h8e,"A",{href:!0});var ddt=s(Mq);s5o=r(ddt,"Data2VecTextModel"),ddt.forEach(t),l5o=r(h8e," (Data2VecText model)"),h8e.forEach(t),i5o=i($),Up=n($,"LI",{});var p8e=s(Up);sde=n(p8e,"STRONG",{});var cdt=s(sde);d5o=r(cdt,"data2vec-vision"),cdt.forEach(t),c5o=r(p8e," \u2014 "),Eq=n(p8e,"A",{href:!0});var fdt=s(Eq);f5o=r(fdt,"Data2VecVisionModel"),fdt.forEach(t),m5o=r(p8e," (Data2VecVision model)"),p8e.forEach(t),g5o=i($),Jp=n($,"LI",{});var _8e=s(Jp);lde=n(_8e,"STRONG",{});var mdt=s(lde);h5o=r(mdt,"deberta"),mdt.forEach(t),p5o=r(_8e," \u2014 "),Cq=n(_8e,"A",{href:!0});var gdt=s(Cq);_5o=r(gdt,"DebertaModel"),gdt.forEach(t),u5o=r(_8e," (DeBERTa model)"),_8e.forEach(t),b5o=i($),Yp=n($,"LI",{});var u8e=s(Yp);ide=n(u8e,"STRONG",{});var hdt=s(ide);v5o=r(hdt,"deberta-v2"),hdt.forEach(t),F5o=r(u8e," \u2014 "),wq=n(u8e,"A",{href:!0});var pdt=s(wq);T5o=r(pdt,"DebertaV2Model"),pdt.forEach(t),M5o=r(u8e," (DeBERTa-v2 model)"),u8e.forEach(t),E5o=i($),Kp=n($,"LI",{});var b8e=s(Kp);dde=n(b8e,"STRONG",{});var _dt=s(dde);C5o=r(_dt,"decision_transformer"),_dt.forEach(t),w5o=r(b8e," \u2014 "),Aq=n(b8e,"A",{href:!0});var udt=s(Aq);A5o=r(udt,"DecisionTransformerModel"),udt.forEach(t),L5o=r(b8e," (Decision Transformer model)"),b8e.forEach(t),y5o=i($),Zp=n($,"LI",{});var v8e=s(Zp);cde=n(v8e,"STRONG",{});var bdt=s(cde);x5o=r(bdt,"deit"),bdt.forEach(t),$5o=r(v8e," \u2014 "),Lq=n(v8e,"A",{href:!0});var vdt=s(Lq);k5o=r(vdt,"DeiTModel"),vdt.forEach(t),S5o=r(v8e," (DeiT model)"),v8e.forEach(t),R5o=i($),e_=n($,"LI",{});var F8e=s(e_);fde=n(F8e,"STRONG",{});var Fdt=s(fde);P5o=r(Fdt,"detr"),Fdt.forEach(t),B5o=r(F8e," \u2014 "),yq=n(F8e,"A",{href:!0});var Tdt=s(yq);I5o=r(Tdt,"DetrModel"),Tdt.forEach(t),N5o=r(F8e," (DETR model)"),F8e.forEach(t),q5o=i($),o_=n($,"LI",{});var T8e=s(o_);mde=n(T8e,"STRONG",{});var Mdt=s(mde);j5o=r(Mdt,"distilbert"),Mdt.forEach(t),D5o=r(T8e," \u2014 "),xq=n(T8e,"A",{href:!0});var Edt=s(xq);G5o=r(Edt,"DistilBertModel"),Edt.forEach(t),O5o=r(T8e," (DistilBERT model)"),T8e.forEach(t),V5o=i($),r_=n($,"LI",{});var M8e=s(r_);gde=n(M8e,"STRONG",{});var Cdt=s(gde);X5o=r(Cdt,"dpr"),Cdt.forEach(t),z5o=r(M8e," \u2014 "),$q=n(M8e,"A",{href:!0});var wdt=s($q);Q5o=r(wdt,"DPRQuestionEncoder"),wdt.forEach(t),W5o=r(M8e," (DPR model)"),M8e.forEach(t),H5o=i($),t_=n($,"LI",{});var E8e=s(t_);hde=n(E8e,"STRONG",{});var Adt=s(hde);U5o=r(Adt,"dpt"),Adt.forEach(t),J5o=r(E8e," \u2014 "),kq=n(E8e,"A",{href:!0});var Ldt=s(kq);Y5o=r(Ldt,"DPTModel"),Ldt.forEach(t),K5o=r(E8e," (DPT model)"),E8e.forEach(t),Z5o=i($),a_=n($,"LI",{});var C8e=s(a_);pde=n(C8e,"STRONG",{});var ydt=s(pde);evo=r(ydt,"electra"),ydt.forEach(t),ovo=r(C8e," \u2014 "),Sq=n(C8e,"A",{href:!0});var xdt=s(Sq);rvo=r(xdt,"ElectraModel"),xdt.forEach(t),tvo=r(C8e," (ELECTRA model)"),C8e.forEach(t),avo=i($),n_=n($,"LI",{});var w8e=s(n_);_de=n(w8e,"STRONG",{});var $dt=s(_de);nvo=r($dt,"flaubert"),$dt.forEach(t),svo=r(w8e," \u2014 "),Rq=n(w8e,"A",{href:!0});var kdt=s(Rq);lvo=r(kdt,"FlaubertModel"),kdt.forEach(t),ivo=r(w8e," (FlauBERT model)"),w8e.forEach(t),dvo=i($),s_=n($,"LI",{});var A8e=s(s_);ude=n(A8e,"STRONG",{});var Sdt=s(ude);cvo=r(Sdt,"flava"),Sdt.forEach(t),fvo=r(A8e," \u2014 "),Pq=n(A8e,"A",{href:!0});var Rdt=s(Pq);mvo=r(Rdt,"FlavaModel"),Rdt.forEach(t),gvo=r(A8e," (FLAVA model)"),A8e.forEach(t),hvo=i($),l_=n($,"LI",{});var L8e=s(l_);bde=n(L8e,"STRONG",{});var Pdt=s(bde);pvo=r(Pdt,"fnet"),Pdt.forEach(t),_vo=r(L8e," \u2014 "),Bq=n(L8e,"A",{href:!0});var Bdt=s(Bq);uvo=r(Bdt,"FNetModel"),Bdt.forEach(t),bvo=r(L8e," (FNet model)"),L8e.forEach(t),vvo=i($),i_=n($,"LI",{});var y8e=s(i_);vde=n(y8e,"STRONG",{});var Idt=s(vde);Fvo=r(Idt,"fsmt"),Idt.forEach(t),Tvo=r(y8e," \u2014 "),Iq=n(y8e,"A",{href:!0});var Ndt=s(Iq);Mvo=r(Ndt,"FSMTModel"),Ndt.forEach(t),Evo=r(y8e," (FairSeq Machine-Translation model)"),y8e.forEach(t),Cvo=i($),Vs=n($,"LI",{});var Kk=s(Vs);Fde=n(Kk,"STRONG",{});var qdt=s(Fde);wvo=r(qdt,"funnel"),qdt.forEach(t),Avo=r(Kk," \u2014 "),Nq=n(Kk,"A",{href:!0});var jdt=s(Nq);Lvo=r(jdt,"FunnelModel"),jdt.forEach(t),yvo=r(Kk," or "),qq=n(Kk,"A",{href:!0});var Ddt=s(qq);xvo=r(Ddt,"FunnelBaseModel"),Ddt.forEach(t),$vo=r(Kk," (Funnel Transformer model)"),Kk.forEach(t),kvo=i($),d_=n($,"LI",{});var x8e=s(d_);Tde=n(x8e,"STRONG",{});var Gdt=s(Tde);Svo=r(Gdt,"glpn"),Gdt.forEach(t),Rvo=r(x8e," \u2014 "),jq=n(x8e,"A",{href:!0});var Odt=s(jq);Pvo=r(Odt,"GLPNModel"),Odt.forEach(t),Bvo=r(x8e," (GLPN model)"),x8e.forEach(t),Ivo=i($),c_=n($,"LI",{});var $8e=s(c_);Mde=n($8e,"STRONG",{});var Vdt=s(Mde);Nvo=r(Vdt,"gpt2"),Vdt.forEach(t),qvo=r($8e," \u2014 "),Dq=n($8e,"A",{href:!0});var Xdt=s(Dq);jvo=r(Xdt,"GPT2Model"),Xdt.forEach(t),Dvo=r($8e," (OpenAI GPT-2 model)"),$8e.forEach(t),Gvo=i($),f_=n($,"LI",{});var k8e=s(f_);Ede=n(k8e,"STRONG",{});var zdt=s(Ede);Ovo=r(zdt,"gpt_neo"),zdt.forEach(t),Vvo=r(k8e," \u2014 "),Gq=n(k8e,"A",{href:!0});var Qdt=s(Gq);Xvo=r(Qdt,"GPTNeoModel"),Qdt.forEach(t),zvo=r(k8e," (GPT Neo model)"),k8e.forEach(t),Qvo=i($),m_=n($,"LI",{});var S8e=s(m_);Cde=n(S8e,"STRONG",{});var Wdt=s(Cde);Wvo=r(Wdt,"gpt_neox"),Wdt.forEach(t),Hvo=r(S8e," \u2014 "),Oq=n(S8e,"A",{href:!0});var Hdt=s(Oq);Uvo=r(Hdt,"GPTNeoXModel"),Hdt.forEach(t),Jvo=r(S8e," (GPT NeoX model)"),S8e.forEach(t),Yvo=i($),g_=n($,"LI",{});var R8e=s(g_);wde=n(R8e,"STRONG",{});var Udt=s(wde);Kvo=r(Udt,"gptj"),Udt.forEach(t),Zvo=r(R8e," \u2014 "),Vq=n(R8e,"A",{href:!0});var Jdt=s(Vq);e3o=r(Jdt,"GPTJModel"),Jdt.forEach(t),o3o=r(R8e," (GPT-J model)"),R8e.forEach(t),r3o=i($),h_=n($,"LI",{});var P8e=s(h_);Ade=n(P8e,"STRONG",{});var Ydt=s(Ade);t3o=r(Ydt,"hubert"),Ydt.forEach(t),a3o=r(P8e," \u2014 "),Xq=n(P8e,"A",{href:!0});var Kdt=s(Xq);n3o=r(Kdt,"HubertModel"),Kdt.forEach(t),s3o=r(P8e," (Hubert model)"),P8e.forEach(t),l3o=i($),p_=n($,"LI",{});var B8e=s(p_);Lde=n(B8e,"STRONG",{});var Zdt=s(Lde);i3o=r(Zdt,"ibert"),Zdt.forEach(t),d3o=r(B8e," \u2014 "),zq=n(B8e,"A",{href:!0});var ect=s(zq);c3o=r(ect,"IBertModel"),ect.forEach(t),f3o=r(B8e," (I-BERT model)"),B8e.forEach(t),m3o=i($),__=n($,"LI",{});var I8e=s(__);yde=n(I8e,"STRONG",{});var oct=s(yde);g3o=r(oct,"imagegpt"),oct.forEach(t),h3o=r(I8e," \u2014 "),Qq=n(I8e,"A",{href:!0});var rct=s(Qq);p3o=r(rct,"ImageGPTModel"),rct.forEach(t),_3o=r(I8e," (ImageGPT model)"),I8e.forEach(t),u3o=i($),u_=n($,"LI",{});var N8e=s(u_);xde=n(N8e,"STRONG",{});var tct=s(xde);b3o=r(tct,"layoutlm"),tct.forEach(t),v3o=r(N8e," \u2014 "),Wq=n(N8e,"A",{href:!0});var act=s(Wq);F3o=r(act,"LayoutLMModel"),act.forEach(t),T3o=r(N8e," (LayoutLM model)"),N8e.forEach(t),M3o=i($),b_=n($,"LI",{});var q8e=s(b_);$de=n(q8e,"STRONG",{});var nct=s($de);E3o=r(nct,"layoutlmv2"),nct.forEach(t),C3o=r(q8e," \u2014 "),Hq=n(q8e,"A",{href:!0});var sct=s(Hq);w3o=r(sct,"LayoutLMv2Model"),sct.forEach(t),A3o=r(q8e," (LayoutLMv2 model)"),q8e.forEach(t),L3o=i($),v_=n($,"LI",{});var j8e=s(v_);kde=n(j8e,"STRONG",{});var lct=s(kde);y3o=r(lct,"layoutlmv3"),lct.forEach(t),x3o=r(j8e," \u2014 "),Uq=n(j8e,"A",{href:!0});var ict=s(Uq);$3o=r(ict,"LayoutLMv3Model"),ict.forEach(t),k3o=r(j8e," (LayoutLMv3 model)"),j8e.forEach(t),S3o=i($),F_=n($,"LI",{});var D8e=s(F_);Sde=n(D8e,"STRONG",{});var dct=s(Sde);R3o=r(dct,"led"),dct.forEach(t),P3o=r(D8e," \u2014 "),Jq=n(D8e,"A",{href:!0});var cct=s(Jq);B3o=r(cct,"LEDModel"),cct.forEach(t),I3o=r(D8e," (LED model)"),D8e.forEach(t),N3o=i($),T_=n($,"LI",{});var G8e=s(T_);Rde=n(G8e,"STRONG",{});var fct=s(Rde);q3o=r(fct,"levit"),fct.forEach(t),j3o=r(G8e," \u2014 "),Yq=n(G8e,"A",{href:!0});var mct=s(Yq);D3o=r(mct,"LevitModel"),mct.forEach(t),G3o=r(G8e," (LeViT model)"),G8e.forEach(t),O3o=i($),M_=n($,"LI",{});var O8e=s(M_);Pde=n(O8e,"STRONG",{});var gct=s(Pde);V3o=r(gct,"longformer"),gct.forEach(t),X3o=r(O8e," \u2014 "),Kq=n(O8e,"A",{href:!0});var hct=s(Kq);z3o=r(hct,"LongformerModel"),hct.forEach(t),Q3o=r(O8e," (Longformer model)"),O8e.forEach(t),W3o=i($),E_=n($,"LI",{});var V8e=s(E_);Bde=n(V8e,"STRONG",{});var pct=s(Bde);H3o=r(pct,"longt5"),pct.forEach(t),U3o=r(V8e," \u2014 "),Zq=n(V8e,"A",{href:!0});var _ct=s(Zq);J3o=r(_ct,"LongT5Model"),_ct.forEach(t),Y3o=r(V8e," (LongT5 model)"),V8e.forEach(t),K3o=i($),C_=n($,"LI",{});var X8e=s(C_);Ide=n(X8e,"STRONG",{});var uct=s(Ide);Z3o=r(uct,"luke"),uct.forEach(t),eFo=r(X8e," \u2014 "),ej=n(X8e,"A",{href:!0});var bct=s(ej);oFo=r(bct,"LukeModel"),bct.forEach(t),rFo=r(X8e," (LUKE model)"),X8e.forEach(t),tFo=i($),w_=n($,"LI",{});var z8e=s(w_);Nde=n(z8e,"STRONG",{});var vct=s(Nde);aFo=r(vct,"lxmert"),vct.forEach(t),nFo=r(z8e," \u2014 "),oj=n(z8e,"A",{href:!0});var Fct=s(oj);sFo=r(Fct,"LxmertModel"),Fct.forEach(t),lFo=r(z8e," (LXMERT model)"),z8e.forEach(t),iFo=i($),A_=n($,"LI",{});var Q8e=s(A_);qde=n(Q8e,"STRONG",{});var Tct=s(qde);dFo=r(Tct,"m2m_100"),Tct.forEach(t),cFo=r(Q8e," \u2014 "),rj=n(Q8e,"A",{href:!0});var Mct=s(rj);fFo=r(Mct,"M2M100Model"),Mct.forEach(t),mFo=r(Q8e," (M2M100 model)"),Q8e.forEach(t),gFo=i($),L_=n($,"LI",{});var W8e=s(L_);jde=n(W8e,"STRONG",{});var Ect=s(jde);hFo=r(Ect,"marian"),Ect.forEach(t),pFo=r(W8e," \u2014 "),tj=n(W8e,"A",{href:!0});var Cct=s(tj);_Fo=r(Cct,"MarianModel"),Cct.forEach(t),uFo=r(W8e," (Marian model)"),W8e.forEach(t),bFo=i($),y_=n($,"LI",{});var H8e=s(y_);Dde=n(H8e,"STRONG",{});var wct=s(Dde);vFo=r(wct,"maskformer"),wct.forEach(t),FFo=r(H8e," \u2014 "),aj=n(H8e,"A",{href:!0});var Act=s(aj);TFo=r(Act,"MaskFormerModel"),Act.forEach(t),MFo=r(H8e," (MaskFormer model)"),H8e.forEach(t),EFo=i($),x_=n($,"LI",{});var U8e=s(x_);Gde=n(U8e,"STRONG",{});var Lct=s(Gde);CFo=r(Lct,"mbart"),Lct.forEach(t),wFo=r(U8e," \u2014 "),nj=n(U8e,"A",{href:!0});var yct=s(nj);AFo=r(yct,"MBartModel"),yct.forEach(t),LFo=r(U8e," (mBART model)"),U8e.forEach(t),yFo=i($),$_=n($,"LI",{});var J8e=s($_);Ode=n(J8e,"STRONG",{});var xct=s(Ode);xFo=r(xct,"mctct"),xct.forEach(t),$Fo=r(J8e," \u2014 "),sj=n(J8e,"A",{href:!0});var $ct=s(sj);kFo=r($ct,"MCTCTModel"),$ct.forEach(t),SFo=r(J8e," (M-CTC-T model)"),J8e.forEach(t),RFo=i($),k_=n($,"LI",{});var Y8e=s(k_);Vde=n(Y8e,"STRONG",{});var kct=s(Vde);PFo=r(kct,"megatron-bert"),kct.forEach(t),BFo=r(Y8e," \u2014 "),lj=n(Y8e,"A",{href:!0});var Sct=s(lj);IFo=r(Sct,"MegatronBertModel"),Sct.forEach(t),NFo=r(Y8e," (Megatron-BERT model)"),Y8e.forEach(t),qFo=i($),S_=n($,"LI",{});var K8e=s(S_);Xde=n(K8e,"STRONG",{});var Rct=s(Xde);jFo=r(Rct,"mobilebert"),Rct.forEach(t),DFo=r(K8e," \u2014 "),ij=n(K8e,"A",{href:!0});var Pct=s(ij);GFo=r(Pct,"MobileBertModel"),Pct.forEach(t),OFo=r(K8e," (MobileBERT model)"),K8e.forEach(t),VFo=i($),R_=n($,"LI",{});var Z8e=s(R_);zde=n(Z8e,"STRONG",{});var Bct=s(zde);XFo=r(Bct,"mpnet"),Bct.forEach(t),zFo=r(Z8e," \u2014 "),dj=n(Z8e,"A",{href:!0});var Ict=s(dj);QFo=r(Ict,"MPNetModel"),Ict.forEach(t),WFo=r(Z8e," (MPNet model)"),Z8e.forEach(t),HFo=i($),P_=n($,"LI",{});var e9e=s(P_);Qde=n(e9e,"STRONG",{});var Nct=s(Qde);UFo=r(Nct,"mt5"),Nct.forEach(t),JFo=r(e9e," \u2014 "),cj=n(e9e,"A",{href:!0});var qct=s(cj);YFo=r(qct,"MT5Model"),qct.forEach(t),KFo=r(e9e," (MT5 model)"),e9e.forEach(t),ZFo=i($),B_=n($,"LI",{});var o9e=s(B_);Wde=n(o9e,"STRONG",{});var jct=s(Wde);eTo=r(jct,"nezha"),jct.forEach(t),oTo=r(o9e," \u2014 "),fj=n(o9e,"A",{href:!0});var Dct=s(fj);rTo=r(Dct,"NezhaModel"),Dct.forEach(t),tTo=r(o9e," (Nezha model)"),o9e.forEach(t),aTo=i($),I_=n($,"LI",{});var r9e=s(I_);Hde=n(r9e,"STRONG",{});var Gct=s(Hde);nTo=r(Gct,"nystromformer"),Gct.forEach(t),sTo=r(r9e," \u2014 "),mj=n(r9e,"A",{href:!0});var Oct=s(mj);lTo=r(Oct,"NystromformerModel"),Oct.forEach(t),iTo=r(r9e," (Nystr\xF6mformer model)"),r9e.forEach(t),dTo=i($),N_=n($,"LI",{});var t9e=s(N_);Ude=n(t9e,"STRONG",{});var Vct=s(Ude);cTo=r(Vct,"openai-gpt"),Vct.forEach(t),fTo=r(t9e," \u2014 "),gj=n(t9e,"A",{href:!0});var Xct=s(gj);mTo=r(Xct,"OpenAIGPTModel"),Xct.forEach(t),gTo=r(t9e," (OpenAI GPT model)"),t9e.forEach(t),hTo=i($),q_=n($,"LI",{});var a9e=s(q_);Jde=n(a9e,"STRONG",{});var zct=s(Jde);pTo=r(zct,"opt"),zct.forEach(t),_To=r(a9e," \u2014 "),hj=n(a9e,"A",{href:!0});var Qct=s(hj);uTo=r(Qct,"OPTModel"),Qct.forEach(t),bTo=r(a9e," (OPT model)"),a9e.forEach(t),vTo=i($),j_=n($,"LI",{});var n9e=s(j_);Yde=n(n9e,"STRONG",{});var Wct=s(Yde);FTo=r(Wct,"pegasus"),Wct.forEach(t),TTo=r(n9e," \u2014 "),pj=n(n9e,"A",{href:!0});var Hct=s(pj);MTo=r(Hct,"PegasusModel"),Hct.forEach(t),ETo=r(n9e," (Pegasus model)"),n9e.forEach(t),CTo=i($),D_=n($,"LI",{});var s9e=s(D_);Kde=n(s9e,"STRONG",{});var Uct=s(Kde);wTo=r(Uct,"perceiver"),Uct.forEach(t),ATo=r(s9e," \u2014 "),_j=n(s9e,"A",{href:!0});var Jct=s(_j);LTo=r(Jct,"PerceiverModel"),Jct.forEach(t),yTo=r(s9e," (Perceiver model)"),s9e.forEach(t),xTo=i($),G_=n($,"LI",{});var l9e=s(G_);Zde=n(l9e,"STRONG",{});var Yct=s(Zde);$To=r(Yct,"plbart"),Yct.forEach(t),kTo=r(l9e," \u2014 "),uj=n(l9e,"A",{href:!0});var Kct=s(uj);STo=r(Kct,"PLBartModel"),Kct.forEach(t),RTo=r(l9e," (PLBart model)"),l9e.forEach(t),PTo=i($),O_=n($,"LI",{});var i9e=s(O_);ece=n(i9e,"STRONG",{});var Zct=s(ece);BTo=r(Zct,"poolformer"),Zct.forEach(t),ITo=r(i9e," \u2014 "),bj=n(i9e,"A",{href:!0});var eft=s(bj);NTo=r(eft,"PoolFormerModel"),eft.forEach(t),qTo=r(i9e," (PoolFormer model)"),i9e.forEach(t),jTo=i($),V_=n($,"LI",{});var d9e=s(V_);oce=n(d9e,"STRONG",{});var oft=s(oce);DTo=r(oft,"prophetnet"),oft.forEach(t),GTo=r(d9e," \u2014 "),vj=n(d9e,"A",{href:!0});var rft=s(vj);OTo=r(rft,"ProphetNetModel"),rft.forEach(t),VTo=r(d9e," (ProphetNet model)"),d9e.forEach(t),XTo=i($),X_=n($,"LI",{});var c9e=s(X_);rce=n(c9e,"STRONG",{});var tft=s(rce);zTo=r(tft,"qdqbert"),tft.forEach(t),QTo=r(c9e," \u2014 "),Fj=n(c9e,"A",{href:!0});var aft=s(Fj);WTo=r(aft,"QDQBertModel"),aft.forEach(t),HTo=r(c9e," (QDQBert model)"),c9e.forEach(t),UTo=i($),z_=n($,"LI",{});var f9e=s(z_);tce=n(f9e,"STRONG",{});var nft=s(tce);JTo=r(nft,"reformer"),nft.forEach(t),YTo=r(f9e," \u2014 "),Tj=n(f9e,"A",{href:!0});var sft=s(Tj);KTo=r(sft,"ReformerModel"),sft.forEach(t),ZTo=r(f9e," (Reformer model)"),f9e.forEach(t),eMo=i($),Q_=n($,"LI",{});var m9e=s(Q_);ace=n(m9e,"STRONG",{});var lft=s(ace);oMo=r(lft,"regnet"),lft.forEach(t),rMo=r(m9e," \u2014 "),Mj=n(m9e,"A",{href:!0});var ift=s(Mj);tMo=r(ift,"RegNetModel"),ift.forEach(t),aMo=r(m9e," (RegNet model)"),m9e.forEach(t),nMo=i($),W_=n($,"LI",{});var g9e=s(W_);nce=n(g9e,"STRONG",{});var dft=s(nce);sMo=r(dft,"rembert"),dft.forEach(t),lMo=r(g9e," \u2014 "),Ej=n(g9e,"A",{href:!0});var cft=s(Ej);iMo=r(cft,"RemBertModel"),cft.forEach(t),dMo=r(g9e," (RemBERT model)"),g9e.forEach(t),cMo=i($),H_=n($,"LI",{});var h9e=s(H_);sce=n(h9e,"STRONG",{});var fft=s(sce);fMo=r(fft,"resnet"),fft.forEach(t),mMo=r(h9e," \u2014 "),Cj=n(h9e,"A",{href:!0});var mft=s(Cj);gMo=r(mft,"ResNetModel"),mft.forEach(t),hMo=r(h9e," (ResNet model)"),h9e.forEach(t),pMo=i($),U_=n($,"LI",{});var p9e=s(U_);lce=n(p9e,"STRONG",{});var gft=s(lce);_Mo=r(gft,"retribert"),gft.forEach(t),uMo=r(p9e," \u2014 "),wj=n(p9e,"A",{href:!0});var hft=s(wj);bMo=r(hft,"RetriBertModel"),hft.forEach(t),vMo=r(p9e," (RetriBERT model)"),p9e.forEach(t),FMo=i($),J_=n($,"LI",{});var _9e=s(J_);ice=n(_9e,"STRONG",{});var pft=s(ice);TMo=r(pft,"roberta"),pft.forEach(t),MMo=r(_9e," \u2014 "),Aj=n(_9e,"A",{href:!0});var _ft=s(Aj);EMo=r(_ft,"RobertaModel"),_ft.forEach(t),CMo=r(_9e," (RoBERTa model)"),_9e.forEach(t),wMo=i($),Y_=n($,"LI",{});var u9e=s(Y_);dce=n(u9e,"STRONG",{});var uft=s(dce);AMo=r(uft,"roformer"),uft.forEach(t),LMo=r(u9e," \u2014 "),Lj=n(u9e,"A",{href:!0});var bft=s(Lj);yMo=r(bft,"RoFormerModel"),bft.forEach(t),xMo=r(u9e," (RoFormer model)"),u9e.forEach(t),$Mo=i($),K_=n($,"LI",{});var b9e=s(K_);cce=n(b9e,"STRONG",{});var vft=s(cce);kMo=r(vft,"segformer"),vft.forEach(t),SMo=r(b9e," \u2014 "),yj=n(b9e,"A",{href:!0});var Fft=s(yj);RMo=r(Fft,"SegformerModel"),Fft.forEach(t),PMo=r(b9e," (SegFormer model)"),b9e.forEach(t),BMo=i($),Z_=n($,"LI",{});var v9e=s(Z_);fce=n(v9e,"STRONG",{});var Tft=s(fce);IMo=r(Tft,"sew"),Tft.forEach(t),NMo=r(v9e," \u2014 "),xj=n(v9e,"A",{href:!0});var Mft=s(xj);qMo=r(Mft,"SEWModel"),Mft.forEach(t),jMo=r(v9e," (SEW model)"),v9e.forEach(t),DMo=i($),eu=n($,"LI",{});var F9e=s(eu);mce=n(F9e,"STRONG",{});var Eft=s(mce);GMo=r(Eft,"sew-d"),Eft.forEach(t),OMo=r(F9e," \u2014 "),$j=n(F9e,"A",{href:!0});var Cft=s($j);VMo=r(Cft,"SEWDModel"),Cft.forEach(t),XMo=r(F9e," (SEW-D model)"),F9e.forEach(t),zMo=i($),ou=n($,"LI",{});var T9e=s(ou);gce=n(T9e,"STRONG",{});var wft=s(gce);QMo=r(wft,"speech_to_text"),wft.forEach(t),WMo=r(T9e," \u2014 "),kj=n(T9e,"A",{href:!0});var Aft=s(kj);HMo=r(Aft,"Speech2TextModel"),Aft.forEach(t),UMo=r(T9e," (Speech2Text model)"),T9e.forEach(t),JMo=i($),ru=n($,"LI",{});var M9e=s(ru);hce=n(M9e,"STRONG",{});var Lft=s(hce);YMo=r(Lft,"splinter"),Lft.forEach(t),KMo=r(M9e," \u2014 "),Sj=n(M9e,"A",{href:!0});var yft=s(Sj);ZMo=r(yft,"SplinterModel"),yft.forEach(t),eEo=r(M9e," (Splinter model)"),M9e.forEach(t),oEo=i($),tu=n($,"LI",{});var E9e=s(tu);pce=n(E9e,"STRONG",{});var xft=s(pce);rEo=r(xft,"squeezebert"),xft.forEach(t),tEo=r(E9e," \u2014 "),Rj=n(E9e,"A",{href:!0});var $ft=s(Rj);aEo=r($ft,"SqueezeBertModel"),$ft.forEach(t),nEo=r(E9e," (SqueezeBERT model)"),E9e.forEach(t),sEo=i($),au=n($,"LI",{});var C9e=s(au);_ce=n(C9e,"STRONG",{});var kft=s(_ce);lEo=r(kft,"swin"),kft.forEach(t),iEo=r(C9e," \u2014 "),Pj=n(C9e,"A",{href:!0});var Sft=s(Pj);dEo=r(Sft,"SwinModel"),Sft.forEach(t),cEo=r(C9e," (Swin Transformer model)"),C9e.forEach(t),fEo=i($),nu=n($,"LI",{});var w9e=s(nu);uce=n(w9e,"STRONG",{});var Rft=s(uce);mEo=r(Rft,"t5"),Rft.forEach(t),gEo=r(w9e," \u2014 "),Bj=n(w9e,"A",{href:!0});var Pft=s(Bj);hEo=r(Pft,"T5Model"),Pft.forEach(t),pEo=r(w9e," (T5 model)"),w9e.forEach(t),_Eo=i($),su=n($,"LI",{});var A9e=s(su);bce=n(A9e,"STRONG",{});var Bft=s(bce);uEo=r(Bft,"tapas"),Bft.forEach(t),bEo=r(A9e," \u2014 "),Ij=n(A9e,"A",{href:!0});var Ift=s(Ij);vEo=r(Ift,"TapasModel"),Ift.forEach(t),FEo=r(A9e," (TAPAS model)"),A9e.forEach(t),TEo=i($),lu=n($,"LI",{});var L9e=s(lu);vce=n(L9e,"STRONG",{});var Nft=s(vce);MEo=r(Nft,"trajectory_transformer"),Nft.forEach(t),EEo=r(L9e," \u2014 "),Nj=n(L9e,"A",{href:!0});var qft=s(Nj);CEo=r(qft,"TrajectoryTransformerModel"),qft.forEach(t),wEo=r(L9e," (Trajectory Transformer model)"),L9e.forEach(t),AEo=i($),iu=n($,"LI",{});var y9e=s(iu);Fce=n(y9e,"STRONG",{});var jft=s(Fce);LEo=r(jft,"transfo-xl"),jft.forEach(t),yEo=r(y9e," \u2014 "),qj=n(y9e,"A",{href:!0});var Dft=s(qj);xEo=r(Dft,"TransfoXLModel"),Dft.forEach(t),$Eo=r(y9e," (Transformer-XL model)"),y9e.forEach(t),kEo=i($),du=n($,"LI",{});var x9e=s(du);Tce=n(x9e,"STRONG",{});var Gft=s(Tce);SEo=r(Gft,"unispeech"),Gft.forEach(t),REo=r(x9e," \u2014 "),jj=n(x9e,"A",{href:!0});var Oft=s(jj);PEo=r(Oft,"UniSpeechModel"),Oft.forEach(t),BEo=r(x9e," (UniSpeech model)"),x9e.forEach(t),IEo=i($),cu=n($,"LI",{});var $9e=s(cu);Mce=n($9e,"STRONG",{});var Vft=s(Mce);NEo=r(Vft,"unispeech-sat"),Vft.forEach(t),qEo=r($9e," \u2014 "),Dj=n($9e,"A",{href:!0});var Xft=s(Dj);jEo=r(Xft,"UniSpeechSatModel"),Xft.forEach(t),DEo=r($9e," (UniSpeechSat model)"),$9e.forEach(t),GEo=i($),fu=n($,"LI",{});var k9e=s(fu);Ece=n(k9e,"STRONG",{});var zft=s(Ece);OEo=r(zft,"van"),zft.forEach(t),VEo=r(k9e," \u2014 "),Gj=n(k9e,"A",{href:!0});var Qft=s(Gj);XEo=r(Qft,"VanModel"),Qft.forEach(t),zEo=r(k9e," (VAN model)"),k9e.forEach(t),QEo=i($),mu=n($,"LI",{});var S9e=s(mu);Cce=n(S9e,"STRONG",{});var Wft=s(Cce);WEo=r(Wft,"vilt"),Wft.forEach(t),HEo=r(S9e," \u2014 "),Oj=n(S9e,"A",{href:!0});var Hft=s(Oj);UEo=r(Hft,"ViltModel"),Hft.forEach(t),JEo=r(S9e," (ViLT model)"),S9e.forEach(t),YEo=i($),gu=n($,"LI",{});var R9e=s(gu);wce=n(R9e,"STRONG",{});var Uft=s(wce);KEo=r(Uft,"vision-text-dual-encoder"),Uft.forEach(t),ZEo=r(R9e," \u2014 "),Vj=n(R9e,"A",{href:!0});var Jft=s(Vj);e4o=r(Jft,"VisionTextDualEncoderModel"),Jft.forEach(t),o4o=r(R9e," (VisionTextDualEncoder model)"),R9e.forEach(t),r4o=i($),hu=n($,"LI",{});var P9e=s(hu);Ace=n(P9e,"STRONG",{});var Yft=s(Ace);t4o=r(Yft,"visual_bert"),Yft.forEach(t),a4o=r(P9e," \u2014 "),Xj=n(P9e,"A",{href:!0});var Kft=s(Xj);n4o=r(Kft,"VisualBertModel"),Kft.forEach(t),s4o=r(P9e," (VisualBERT model)"),P9e.forEach(t),l4o=i($),pu=n($,"LI",{});var B9e=s(pu);Lce=n(B9e,"STRONG",{});var Zft=s(Lce);i4o=r(Zft,"vit"),Zft.forEach(t),d4o=r(B9e," \u2014 "),zj=n(B9e,"A",{href:!0});var emt=s(zj);c4o=r(emt,"ViTModel"),emt.forEach(t),f4o=r(B9e," (ViT model)"),B9e.forEach(t),m4o=i($),_u=n($,"LI",{});var I9e=s(_u);yce=n(I9e,"STRONG",{});var omt=s(yce);g4o=r(omt,"vit_mae"),omt.forEach(t),h4o=r(I9e," \u2014 "),Qj=n(I9e,"A",{href:!0});var rmt=s(Qj);p4o=r(rmt,"ViTMAEModel"),rmt.forEach(t),_4o=r(I9e," (ViTMAE model)"),I9e.forEach(t),u4o=i($),uu=n($,"LI",{});var N9e=s(uu);xce=n(N9e,"STRONG",{});var tmt=s(xce);b4o=r(tmt,"wav2vec2"),tmt.forEach(t),v4o=r(N9e," \u2014 "),Wj=n(N9e,"A",{href:!0});var amt=s(Wj);F4o=r(amt,"Wav2Vec2Model"),amt.forEach(t),T4o=r(N9e," (Wav2Vec2 model)"),N9e.forEach(t),M4o=i($),bu=n($,"LI",{});var q9e=s(bu);$ce=n(q9e,"STRONG",{});var nmt=s($ce);E4o=r(nmt,"wav2vec2-conformer"),nmt.forEach(t),C4o=r(q9e," \u2014 "),Hj=n(q9e,"A",{href:!0});var smt=s(Hj);w4o=r(smt,"Wav2Vec2ConformerModel"),smt.forEach(t),A4o=r(q9e," (Wav2Vec2-Conformer model)"),q9e.forEach(t),L4o=i($),vu=n($,"LI",{});var j9e=s(vu);kce=n(j9e,"STRONG",{});var lmt=s(kce);y4o=r(lmt,"wavlm"),lmt.forEach(t),x4o=r(j9e," \u2014 "),Uj=n(j9e,"A",{href:!0});var imt=s(Uj);$4o=r(imt,"WavLMModel"),imt.forEach(t),k4o=r(j9e," (WavLM model)"),j9e.forEach(t),S4o=i($),Fu=n($,"LI",{});var D9e=s(Fu);Sce=n(D9e,"STRONG",{});var dmt=s(Sce);R4o=r(dmt,"xglm"),dmt.forEach(t),P4o=r(D9e," \u2014 "),Jj=n(D9e,"A",{href:!0});var cmt=s(Jj);B4o=r(cmt,"XGLMModel"),cmt.forEach(t),I4o=r(D9e," (XGLM model)"),D9e.forEach(t),N4o=i($),Tu=n($,"LI",{});var G9e=s(Tu);Rce=n(G9e,"STRONG",{});var fmt=s(Rce);q4o=r(fmt,"xlm"),fmt.forEach(t),j4o=r(G9e," \u2014 "),Yj=n(G9e,"A",{href:!0});var mmt=s(Yj);D4o=r(mmt,"XLMModel"),mmt.forEach(t),G4o=r(G9e," (XLM model)"),G9e.forEach(t),O4o=i($),Mu=n($,"LI",{});var O9e=s(Mu);Pce=n(O9e,"STRONG",{});var gmt=s(Pce);V4o=r(gmt,"xlm-prophetnet"),gmt.forEach(t),X4o=r(O9e," \u2014 "),Kj=n(O9e,"A",{href:!0});var hmt=s(Kj);z4o=r(hmt,"XLMProphetNetModel"),hmt.forEach(t),Q4o=r(O9e," (XLM-ProphetNet model)"),O9e.forEach(t),W4o=i($),Eu=n($,"LI",{});var V9e=s(Eu);Bce=n(V9e,"STRONG",{});var pmt=s(Bce);H4o=r(pmt,"xlm-roberta"),pmt.forEach(t),U4o=r(V9e," \u2014 "),Zj=n(V9e,"A",{href:!0});var _mt=s(Zj);J4o=r(_mt,"XLMRobertaModel"),_mt.forEach(t),Y4o=r(V9e," (XLM-RoBERTa model)"),V9e.forEach(t),K4o=i($),Cu=n($,"LI",{});var X9e=s(Cu);Ice=n(X9e,"STRONG",{});var umt=s(Ice);Z4o=r(umt,"xlm-roberta-xl"),umt.forEach(t),eCo=r(X9e," \u2014 "),eD=n(X9e,"A",{href:!0});var bmt=s(eD);oCo=r(bmt,"XLMRobertaXLModel"),bmt.forEach(t),rCo=r(X9e," (XLM-RoBERTa-XL model)"),X9e.forEach(t),tCo=i($),wu=n($,"LI",{});var z9e=s(wu);Nce=n(z9e,"STRONG",{});var vmt=s(Nce);aCo=r(vmt,"xlnet"),vmt.forEach(t),nCo=r(z9e," \u2014 "),oD=n(z9e,"A",{href:!0});var Fmt=s(oD);sCo=r(Fmt,"XLNetModel"),Fmt.forEach(t),lCo=r(z9e," (XLNet model)"),z9e.forEach(t),iCo=i($),Au=n($,"LI",{});var Q9e=s(Au);qce=n(Q9e,"STRONG",{});var Tmt=s(qce);dCo=r(Tmt,"yolos"),Tmt.forEach(t),cCo=r(Q9e," \u2014 "),rD=n(Q9e,"A",{href:!0});var Mmt=s(rD);fCo=r(Mmt,"YolosModel"),Mmt.forEach(t),mCo=r(Q9e," (YOLOS model)"),Q9e.forEach(t),gCo=i($),Lu=n($,"LI",{});var W9e=s(Lu);jce=n(W9e,"STRONG",{});var Emt=s(jce);hCo=r(Emt,"yoso"),Emt.forEach(t),pCo=r(W9e," \u2014 "),tD=n(W9e,"A",{href:!0});var Cmt=s(tD);_Co=r(Cmt,"YosoModel"),Cmt.forEach(t),uCo=r(W9e," (YOSO model)"),W9e.forEach(t),$.forEach(t),bCo=i(aa),yu=n(aa,"P",{});var H9e=s(yu);vCo=r(H9e,"The model is set in evaluation mode by default using "),Dce=n(H9e,"CODE",{});var wmt=s(Dce);FCo=r(wmt,"model.eval()"),wmt.forEach(t),TCo=r(H9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gce=n(H9e,"CODE",{});var Amt=s(Gce);MCo=r(Amt,"model.train()"),Amt.forEach(t),H9e.forEach(t),ECo=i(aa),T(xu.$$.fragment,aa),aa.forEach(t),Ys.forEach(t),eOe=i(f),qi=n(f,"H2",{class:!0});var sXe=s(qi);$u=n(sXe,"A",{id:!0,class:!0,href:!0});var Lmt=s($u);Oce=n(Lmt,"SPAN",{});var ymt=s(Oce);T(sy.$$.fragment,ymt),ymt.forEach(t),Lmt.forEach(t),CCo=i(sXe),Vce=n(sXe,"SPAN",{});var xmt=s(Vce);wCo=r(xmt,"AutoModelForPreTraining"),xmt.forEach(t),sXe.forEach(t),oOe=i(f),$o=n(f,"DIV",{class:!0});var Ks=s($o);T(ly.$$.fragment,Ks),ACo=i(Ks),ji=n(Ks,"P",{});var Toe=s(ji);LCo=r(Toe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),aD=n(Toe,"A",{href:!0});var $mt=s(aD);yCo=r($mt,"from_pretrained()"),$mt.forEach(t),xCo=r(Toe," class method or the "),nD=n(Toe,"A",{href:!0});var kmt=s(nD);$Co=r(kmt,"from_config()"),kmt.forEach(t),kCo=r(Toe,` class
method.`),Toe.forEach(t),SCo=i(Ks),iy=n(Ks,"P",{});var lXe=s(iy);RCo=r(lXe,"This class cannot be instantiated directly using "),Xce=n(lXe,"CODE",{});var Smt=s(Xce);PCo=r(Smt,"__init__()"),Smt.forEach(t),BCo=r(lXe," (throws an error)."),lXe.forEach(t),ICo=i(Ks),st=n(Ks,"DIV",{class:!0});var RA=s(st);T(dy.$$.fragment,RA),NCo=i(RA),zce=n(RA,"P",{});var Rmt=s(zce);qCo=r(Rmt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Rmt.forEach(t),jCo=i(RA),Di=n(RA,"P",{});var Moe=s(Di);DCo=r(Moe,`Note:
Loading a model from its configuration file does `),Qce=n(Moe,"STRONG",{});var Pmt=s(Qce);GCo=r(Pmt,"not"),Pmt.forEach(t),OCo=r(Moe,` load the model weights. It only affects the
model\u2019s configuration. Use `),sD=n(Moe,"A",{href:!0});var Bmt=s(sD);VCo=r(Bmt,"from_pretrained()"),Bmt.forEach(t),XCo=r(Moe," to load the model weights."),Moe.forEach(t),zCo=i(RA),T(ku.$$.fragment,RA),RA.forEach(t),QCo=i(Ks),Ye=n(Ks,"DIV",{class:!0});var na=s(Ye);T(cy.$$.fragment,na),WCo=i(na),Wce=n(na,"P",{});var Imt=s(Wce);HCo=r(Imt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Imt.forEach(t),UCo=i(na),Pa=n(na,"P",{});var PA=s(Pa);JCo=r(PA,"The model class to instantiate is selected based on the "),Hce=n(PA,"CODE",{});var Nmt=s(Hce);YCo=r(Nmt,"model_type"),Nmt.forEach(t),KCo=r(PA,` property of the config object (either
passed as an argument or loaded from `),Uce=n(PA,"CODE",{});var qmt=s(Uce);ZCo=r(qmt,"pretrained_model_name_or_path"),qmt.forEach(t),e0o=r(PA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jce=n(PA,"CODE",{});var jmt=s(Jce);o0o=r(jmt,"pretrained_model_name_or_path"),jmt.forEach(t),r0o=r(PA,":"),PA.forEach(t),t0o=i(na),G=n(na,"UL",{});var O=s(G);Su=n(O,"LI",{});var U9e=s(Su);Yce=n(U9e,"STRONG",{});var Dmt=s(Yce);a0o=r(Dmt,"albert"),Dmt.forEach(t),n0o=r(U9e," \u2014 "),lD=n(U9e,"A",{href:!0});var Gmt=s(lD);s0o=r(Gmt,"AlbertForPreTraining"),Gmt.forEach(t),l0o=r(U9e," (ALBERT model)"),U9e.forEach(t),i0o=i(O),Ru=n(O,"LI",{});var J9e=s(Ru);Kce=n(J9e,"STRONG",{});var Omt=s(Kce);d0o=r(Omt,"bart"),Omt.forEach(t),c0o=r(J9e," \u2014 "),iD=n(J9e,"A",{href:!0});var Vmt=s(iD);f0o=r(Vmt,"BartForConditionalGeneration"),Vmt.forEach(t),m0o=r(J9e," (BART model)"),J9e.forEach(t),g0o=i(O),Pu=n(O,"LI",{});var Y9e=s(Pu);Zce=n(Y9e,"STRONG",{});var Xmt=s(Zce);h0o=r(Xmt,"bert"),Xmt.forEach(t),p0o=r(Y9e," \u2014 "),dD=n(Y9e,"A",{href:!0});var zmt=s(dD);_0o=r(zmt,"BertForPreTraining"),zmt.forEach(t),u0o=r(Y9e," (BERT model)"),Y9e.forEach(t),b0o=i(O),Bu=n(O,"LI",{});var K9e=s(Bu);efe=n(K9e,"STRONG",{});var Qmt=s(efe);v0o=r(Qmt,"big_bird"),Qmt.forEach(t),F0o=r(K9e," \u2014 "),cD=n(K9e,"A",{href:!0});var Wmt=s(cD);T0o=r(Wmt,"BigBirdForPreTraining"),Wmt.forEach(t),M0o=r(K9e," (BigBird model)"),K9e.forEach(t),E0o=i(O),Iu=n(O,"LI",{});var Z9e=s(Iu);ofe=n(Z9e,"STRONG",{});var Hmt=s(ofe);C0o=r(Hmt,"bloom"),Hmt.forEach(t),w0o=r(Z9e," \u2014 "),fD=n(Z9e,"A",{href:!0});var Umt=s(fD);A0o=r(Umt,"BloomForCausalLM"),Umt.forEach(t),L0o=r(Z9e," (BLOOM model)"),Z9e.forEach(t),y0o=i(O),Nu=n(O,"LI",{});var exe=s(Nu);rfe=n(exe,"STRONG",{});var Jmt=s(rfe);x0o=r(Jmt,"camembert"),Jmt.forEach(t),$0o=r(exe," \u2014 "),mD=n(exe,"A",{href:!0});var Ymt=s(mD);k0o=r(Ymt,"CamembertForMaskedLM"),Ymt.forEach(t),S0o=r(exe," (CamemBERT model)"),exe.forEach(t),R0o=i(O),qu=n(O,"LI",{});var oxe=s(qu);tfe=n(oxe,"STRONG",{});var Kmt=s(tfe);P0o=r(Kmt,"ctrl"),Kmt.forEach(t),B0o=r(oxe," \u2014 "),gD=n(oxe,"A",{href:!0});var Zmt=s(gD);I0o=r(Zmt,"CTRLLMHeadModel"),Zmt.forEach(t),N0o=r(oxe," (CTRL model)"),oxe.forEach(t),q0o=i(O),ju=n(O,"LI",{});var rxe=s(ju);afe=n(rxe,"STRONG",{});var egt=s(afe);j0o=r(egt,"data2vec-text"),egt.forEach(t),D0o=r(rxe," \u2014 "),hD=n(rxe,"A",{href:!0});var ogt=s(hD);G0o=r(ogt,"Data2VecTextForMaskedLM"),ogt.forEach(t),O0o=r(rxe," (Data2VecText model)"),rxe.forEach(t),V0o=i(O),Du=n(O,"LI",{});var txe=s(Du);nfe=n(txe,"STRONG",{});var rgt=s(nfe);X0o=r(rgt,"deberta"),rgt.forEach(t),z0o=r(txe," \u2014 "),pD=n(txe,"A",{href:!0});var tgt=s(pD);Q0o=r(tgt,"DebertaForMaskedLM"),tgt.forEach(t),W0o=r(txe," (DeBERTa model)"),txe.forEach(t),H0o=i(O),Gu=n(O,"LI",{});var axe=s(Gu);sfe=n(axe,"STRONG",{});var agt=s(sfe);U0o=r(agt,"deberta-v2"),agt.forEach(t),J0o=r(axe," \u2014 "),_D=n(axe,"A",{href:!0});var ngt=s(_D);Y0o=r(ngt,"DebertaV2ForMaskedLM"),ngt.forEach(t),K0o=r(axe," (DeBERTa-v2 model)"),axe.forEach(t),Z0o=i(O),Ou=n(O,"LI",{});var nxe=s(Ou);lfe=n(nxe,"STRONG",{});var sgt=s(lfe);ewo=r(sgt,"distilbert"),sgt.forEach(t),owo=r(nxe," \u2014 "),uD=n(nxe,"A",{href:!0});var lgt=s(uD);rwo=r(lgt,"DistilBertForMaskedLM"),lgt.forEach(t),two=r(nxe," (DistilBERT model)"),nxe.forEach(t),awo=i(O),Vu=n(O,"LI",{});var sxe=s(Vu);ife=n(sxe,"STRONG",{});var igt=s(ife);nwo=r(igt,"electra"),igt.forEach(t),swo=r(sxe," \u2014 "),bD=n(sxe,"A",{href:!0});var dgt=s(bD);lwo=r(dgt,"ElectraForPreTraining"),dgt.forEach(t),iwo=r(sxe," (ELECTRA model)"),sxe.forEach(t),dwo=i(O),Xu=n(O,"LI",{});var lxe=s(Xu);dfe=n(lxe,"STRONG",{});var cgt=s(dfe);cwo=r(cgt,"flaubert"),cgt.forEach(t),fwo=r(lxe," \u2014 "),vD=n(lxe,"A",{href:!0});var fgt=s(vD);mwo=r(fgt,"FlaubertWithLMHeadModel"),fgt.forEach(t),gwo=r(lxe," (FlauBERT model)"),lxe.forEach(t),hwo=i(O),zu=n(O,"LI",{});var ixe=s(zu);cfe=n(ixe,"STRONG",{});var mgt=s(cfe);pwo=r(mgt,"flava"),mgt.forEach(t),_wo=r(ixe," \u2014 "),FD=n(ixe,"A",{href:!0});var ggt=s(FD);uwo=r(ggt,"FlavaForPreTraining"),ggt.forEach(t),bwo=r(ixe," (FLAVA model)"),ixe.forEach(t),vwo=i(O),Qu=n(O,"LI",{});var dxe=s(Qu);ffe=n(dxe,"STRONG",{});var hgt=s(ffe);Fwo=r(hgt,"fnet"),hgt.forEach(t),Two=r(dxe," \u2014 "),TD=n(dxe,"A",{href:!0});var pgt=s(TD);Mwo=r(pgt,"FNetForPreTraining"),pgt.forEach(t),Ewo=r(dxe," (FNet model)"),dxe.forEach(t),Cwo=i(O),Wu=n(O,"LI",{});var cxe=s(Wu);mfe=n(cxe,"STRONG",{});var _gt=s(mfe);wwo=r(_gt,"fsmt"),_gt.forEach(t),Awo=r(cxe," \u2014 "),MD=n(cxe,"A",{href:!0});var ugt=s(MD);Lwo=r(ugt,"FSMTForConditionalGeneration"),ugt.forEach(t),ywo=r(cxe," (FairSeq Machine-Translation model)"),cxe.forEach(t),xwo=i(O),Hu=n(O,"LI",{});var fxe=s(Hu);gfe=n(fxe,"STRONG",{});var bgt=s(gfe);$wo=r(bgt,"funnel"),bgt.forEach(t),kwo=r(fxe," \u2014 "),ED=n(fxe,"A",{href:!0});var vgt=s(ED);Swo=r(vgt,"FunnelForPreTraining"),vgt.forEach(t),Rwo=r(fxe," (Funnel Transformer model)"),fxe.forEach(t),Pwo=i(O),Uu=n(O,"LI",{});var mxe=s(Uu);hfe=n(mxe,"STRONG",{});var Fgt=s(hfe);Bwo=r(Fgt,"gpt2"),Fgt.forEach(t),Iwo=r(mxe," \u2014 "),CD=n(mxe,"A",{href:!0});var Tgt=s(CD);Nwo=r(Tgt,"GPT2LMHeadModel"),Tgt.forEach(t),qwo=r(mxe," (OpenAI GPT-2 model)"),mxe.forEach(t),jwo=i(O),Ju=n(O,"LI",{});var gxe=s(Ju);pfe=n(gxe,"STRONG",{});var Mgt=s(pfe);Dwo=r(Mgt,"ibert"),Mgt.forEach(t),Gwo=r(gxe," \u2014 "),wD=n(gxe,"A",{href:!0});var Egt=s(wD);Owo=r(Egt,"IBertForMaskedLM"),Egt.forEach(t),Vwo=r(gxe," (I-BERT model)"),gxe.forEach(t),Xwo=i(O),Yu=n(O,"LI",{});var hxe=s(Yu);_fe=n(hxe,"STRONG",{});var Cgt=s(_fe);zwo=r(Cgt,"layoutlm"),Cgt.forEach(t),Qwo=r(hxe," \u2014 "),AD=n(hxe,"A",{href:!0});var wgt=s(AD);Wwo=r(wgt,"LayoutLMForMaskedLM"),wgt.forEach(t),Hwo=r(hxe," (LayoutLM model)"),hxe.forEach(t),Uwo=i(O),Ku=n(O,"LI",{});var pxe=s(Ku);ufe=n(pxe,"STRONG",{});var Agt=s(ufe);Jwo=r(Agt,"longformer"),Agt.forEach(t),Ywo=r(pxe," \u2014 "),LD=n(pxe,"A",{href:!0});var Lgt=s(LD);Kwo=r(Lgt,"LongformerForMaskedLM"),Lgt.forEach(t),Zwo=r(pxe," (Longformer model)"),pxe.forEach(t),eAo=i(O),Zu=n(O,"LI",{});var _xe=s(Zu);bfe=n(_xe,"STRONG",{});var ygt=s(bfe);oAo=r(ygt,"lxmert"),ygt.forEach(t),rAo=r(_xe," \u2014 "),yD=n(_xe,"A",{href:!0});var xgt=s(yD);tAo=r(xgt,"LxmertForPreTraining"),xgt.forEach(t),aAo=r(_xe," (LXMERT model)"),_xe.forEach(t),nAo=i(O),e1=n(O,"LI",{});var uxe=s(e1);vfe=n(uxe,"STRONG",{});var $gt=s(vfe);sAo=r($gt,"megatron-bert"),$gt.forEach(t),lAo=r(uxe," \u2014 "),xD=n(uxe,"A",{href:!0});var kgt=s(xD);iAo=r(kgt,"MegatronBertForPreTraining"),kgt.forEach(t),dAo=r(uxe," (Megatron-BERT model)"),uxe.forEach(t),cAo=i(O),o1=n(O,"LI",{});var bxe=s(o1);Ffe=n(bxe,"STRONG",{});var Sgt=s(Ffe);fAo=r(Sgt,"mobilebert"),Sgt.forEach(t),mAo=r(bxe," \u2014 "),$D=n(bxe,"A",{href:!0});var Rgt=s($D);gAo=r(Rgt,"MobileBertForPreTraining"),Rgt.forEach(t),hAo=r(bxe," (MobileBERT model)"),bxe.forEach(t),pAo=i(O),r1=n(O,"LI",{});var vxe=s(r1);Tfe=n(vxe,"STRONG",{});var Pgt=s(Tfe);_Ao=r(Pgt,"mpnet"),Pgt.forEach(t),uAo=r(vxe," \u2014 "),kD=n(vxe,"A",{href:!0});var Bgt=s(kD);bAo=r(Bgt,"MPNetForMaskedLM"),Bgt.forEach(t),vAo=r(vxe," (MPNet model)"),vxe.forEach(t),FAo=i(O),t1=n(O,"LI",{});var Fxe=s(t1);Mfe=n(Fxe,"STRONG",{});var Igt=s(Mfe);TAo=r(Igt,"nezha"),Igt.forEach(t),MAo=r(Fxe," \u2014 "),SD=n(Fxe,"A",{href:!0});var Ngt=s(SD);EAo=r(Ngt,"NezhaForPreTraining"),Ngt.forEach(t),CAo=r(Fxe," (Nezha model)"),Fxe.forEach(t),wAo=i(O),a1=n(O,"LI",{});var Txe=s(a1);Efe=n(Txe,"STRONG",{});var qgt=s(Efe);AAo=r(qgt,"openai-gpt"),qgt.forEach(t),LAo=r(Txe," \u2014 "),RD=n(Txe,"A",{href:!0});var jgt=s(RD);yAo=r(jgt,"OpenAIGPTLMHeadModel"),jgt.forEach(t),xAo=r(Txe," (OpenAI GPT model)"),Txe.forEach(t),$Ao=i(O),n1=n(O,"LI",{});var Mxe=s(n1);Cfe=n(Mxe,"STRONG",{});var Dgt=s(Cfe);kAo=r(Dgt,"retribert"),Dgt.forEach(t),SAo=r(Mxe," \u2014 "),PD=n(Mxe,"A",{href:!0});var Ggt=s(PD);RAo=r(Ggt,"RetriBertModel"),Ggt.forEach(t),PAo=r(Mxe," (RetriBERT model)"),Mxe.forEach(t),BAo=i(O),s1=n(O,"LI",{});var Exe=s(s1);wfe=n(Exe,"STRONG",{});var Ogt=s(wfe);IAo=r(Ogt,"roberta"),Ogt.forEach(t),NAo=r(Exe," \u2014 "),BD=n(Exe,"A",{href:!0});var Vgt=s(BD);qAo=r(Vgt,"RobertaForMaskedLM"),Vgt.forEach(t),jAo=r(Exe," (RoBERTa model)"),Exe.forEach(t),DAo=i(O),l1=n(O,"LI",{});var Cxe=s(l1);Afe=n(Cxe,"STRONG",{});var Xgt=s(Afe);GAo=r(Xgt,"splinter"),Xgt.forEach(t),OAo=r(Cxe," \u2014 "),ID=n(Cxe,"A",{href:!0});var zgt=s(ID);VAo=r(zgt,"SplinterForPreTraining"),zgt.forEach(t),XAo=r(Cxe," (Splinter model)"),Cxe.forEach(t),zAo=i(O),i1=n(O,"LI",{});var wxe=s(i1);Lfe=n(wxe,"STRONG",{});var Qgt=s(Lfe);QAo=r(Qgt,"squeezebert"),Qgt.forEach(t),WAo=r(wxe," \u2014 "),ND=n(wxe,"A",{href:!0});var Wgt=s(ND);HAo=r(Wgt,"SqueezeBertForMaskedLM"),Wgt.forEach(t),UAo=r(wxe," (SqueezeBERT model)"),wxe.forEach(t),JAo=i(O),d1=n(O,"LI",{});var Axe=s(d1);yfe=n(Axe,"STRONG",{});var Hgt=s(yfe);YAo=r(Hgt,"t5"),Hgt.forEach(t),KAo=r(Axe," \u2014 "),qD=n(Axe,"A",{href:!0});var Ugt=s(qD);ZAo=r(Ugt,"T5ForConditionalGeneration"),Ugt.forEach(t),e6o=r(Axe," (T5 model)"),Axe.forEach(t),o6o=i(O),c1=n(O,"LI",{});var Lxe=s(c1);xfe=n(Lxe,"STRONG",{});var Jgt=s(xfe);r6o=r(Jgt,"tapas"),Jgt.forEach(t),t6o=r(Lxe," \u2014 "),jD=n(Lxe,"A",{href:!0});var Ygt=s(jD);a6o=r(Ygt,"TapasForMaskedLM"),Ygt.forEach(t),n6o=r(Lxe," (TAPAS model)"),Lxe.forEach(t),s6o=i(O),f1=n(O,"LI",{});var yxe=s(f1);$fe=n(yxe,"STRONG",{});var Kgt=s($fe);l6o=r(Kgt,"transfo-xl"),Kgt.forEach(t),i6o=r(yxe," \u2014 "),DD=n(yxe,"A",{href:!0});var Zgt=s(DD);d6o=r(Zgt,"TransfoXLLMHeadModel"),Zgt.forEach(t),c6o=r(yxe," (Transformer-XL model)"),yxe.forEach(t),f6o=i(O),m1=n(O,"LI",{});var xxe=s(m1);kfe=n(xxe,"STRONG",{});var eht=s(kfe);m6o=r(eht,"unispeech"),eht.forEach(t),g6o=r(xxe," \u2014 "),GD=n(xxe,"A",{href:!0});var oht=s(GD);h6o=r(oht,"UniSpeechForPreTraining"),oht.forEach(t),p6o=r(xxe," (UniSpeech model)"),xxe.forEach(t),_6o=i(O),g1=n(O,"LI",{});var $xe=s(g1);Sfe=n($xe,"STRONG",{});var rht=s(Sfe);u6o=r(rht,"unispeech-sat"),rht.forEach(t),b6o=r($xe," \u2014 "),OD=n($xe,"A",{href:!0});var tht=s(OD);v6o=r(tht,"UniSpeechSatForPreTraining"),tht.forEach(t),F6o=r($xe," (UniSpeechSat model)"),$xe.forEach(t),T6o=i(O),h1=n(O,"LI",{});var kxe=s(h1);Rfe=n(kxe,"STRONG",{});var aht=s(Rfe);M6o=r(aht,"visual_bert"),aht.forEach(t),E6o=r(kxe," \u2014 "),VD=n(kxe,"A",{href:!0});var nht=s(VD);C6o=r(nht,"VisualBertForPreTraining"),nht.forEach(t),w6o=r(kxe," (VisualBERT model)"),kxe.forEach(t),A6o=i(O),p1=n(O,"LI",{});var Sxe=s(p1);Pfe=n(Sxe,"STRONG",{});var sht=s(Pfe);L6o=r(sht,"vit_mae"),sht.forEach(t),y6o=r(Sxe," \u2014 "),XD=n(Sxe,"A",{href:!0});var lht=s(XD);x6o=r(lht,"ViTMAEForPreTraining"),lht.forEach(t),$6o=r(Sxe," (ViTMAE model)"),Sxe.forEach(t),k6o=i(O),_1=n(O,"LI",{});var Rxe=s(_1);Bfe=n(Rxe,"STRONG",{});var iht=s(Bfe);S6o=r(iht,"wav2vec2"),iht.forEach(t),R6o=r(Rxe," \u2014 "),zD=n(Rxe,"A",{href:!0});var dht=s(zD);P6o=r(dht,"Wav2Vec2ForPreTraining"),dht.forEach(t),B6o=r(Rxe," (Wav2Vec2 model)"),Rxe.forEach(t),I6o=i(O),u1=n(O,"LI",{});var Pxe=s(u1);Ife=n(Pxe,"STRONG",{});var cht=s(Ife);N6o=r(cht,"wav2vec2-conformer"),cht.forEach(t),q6o=r(Pxe," \u2014 "),QD=n(Pxe,"A",{href:!0});var fht=s(QD);j6o=r(fht,"Wav2Vec2ConformerForPreTraining"),fht.forEach(t),D6o=r(Pxe," (Wav2Vec2-Conformer model)"),Pxe.forEach(t),G6o=i(O),b1=n(O,"LI",{});var Bxe=s(b1);Nfe=n(Bxe,"STRONG",{});var mht=s(Nfe);O6o=r(mht,"xlm"),mht.forEach(t),V6o=r(Bxe," \u2014 "),WD=n(Bxe,"A",{href:!0});var ght=s(WD);X6o=r(ght,"XLMWithLMHeadModel"),ght.forEach(t),z6o=r(Bxe," (XLM model)"),Bxe.forEach(t),Q6o=i(O),v1=n(O,"LI",{});var Ixe=s(v1);qfe=n(Ixe,"STRONG",{});var hht=s(qfe);W6o=r(hht,"xlm-roberta"),hht.forEach(t),H6o=r(Ixe," \u2014 "),HD=n(Ixe,"A",{href:!0});var pht=s(HD);U6o=r(pht,"XLMRobertaForMaskedLM"),pht.forEach(t),J6o=r(Ixe," (XLM-RoBERTa model)"),Ixe.forEach(t),Y6o=i(O),F1=n(O,"LI",{});var Nxe=s(F1);jfe=n(Nxe,"STRONG",{});var _ht=s(jfe);K6o=r(_ht,"xlm-roberta-xl"),_ht.forEach(t),Z6o=r(Nxe," \u2014 "),UD=n(Nxe,"A",{href:!0});var uht=s(UD);eLo=r(uht,"XLMRobertaXLForMaskedLM"),uht.forEach(t),oLo=r(Nxe," (XLM-RoBERTa-XL model)"),Nxe.forEach(t),rLo=i(O),T1=n(O,"LI",{});var qxe=s(T1);Dfe=n(qxe,"STRONG",{});var bht=s(Dfe);tLo=r(bht,"xlnet"),bht.forEach(t),aLo=r(qxe," \u2014 "),JD=n(qxe,"A",{href:!0});var vht=s(JD);nLo=r(vht,"XLNetLMHeadModel"),vht.forEach(t),sLo=r(qxe," (XLNet model)"),qxe.forEach(t),O.forEach(t),lLo=i(na),M1=n(na,"P",{});var jxe=s(M1);iLo=r(jxe,"The model is set in evaluation mode by default using "),Gfe=n(jxe,"CODE",{});var Fht=s(Gfe);dLo=r(Fht,"model.eval()"),Fht.forEach(t),cLo=r(jxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ofe=n(jxe,"CODE",{});var Tht=s(Ofe);fLo=r(Tht,"model.train()"),Tht.forEach(t),jxe.forEach(t),mLo=i(na),T(E1.$$.fragment,na),na.forEach(t),Ks.forEach(t),rOe=i(f),Gi=n(f,"H2",{class:!0});var iXe=s(Gi);C1=n(iXe,"A",{id:!0,class:!0,href:!0});var Mht=s(C1);Vfe=n(Mht,"SPAN",{});var Eht=s(Vfe);T(fy.$$.fragment,Eht),Eht.forEach(t),Mht.forEach(t),gLo=i(iXe),Xfe=n(iXe,"SPAN",{});var Cht=s(Xfe);hLo=r(Cht,"AutoModelForCausalLM"),Cht.forEach(t),iXe.forEach(t),tOe=i(f),ko=n(f,"DIV",{class:!0});var Zs=s(ko);T(my.$$.fragment,Zs),pLo=i(Zs),Oi=n(Zs,"P",{});var Eoe=s(Oi);_Lo=r(Eoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),YD=n(Eoe,"A",{href:!0});var wht=s(YD);uLo=r(wht,"from_pretrained()"),wht.forEach(t),bLo=r(Eoe," class method or the "),KD=n(Eoe,"A",{href:!0});var Aht=s(KD);vLo=r(Aht,"from_config()"),Aht.forEach(t),FLo=r(Eoe,` class
method.`),Eoe.forEach(t),TLo=i(Zs),gy=n(Zs,"P",{});var dXe=s(gy);MLo=r(dXe,"This class cannot be instantiated directly using "),zfe=n(dXe,"CODE",{});var Lht=s(zfe);ELo=r(Lht,"__init__()"),Lht.forEach(t),CLo=r(dXe," (throws an error)."),dXe.forEach(t),wLo=i(Zs),lt=n(Zs,"DIV",{class:!0});var BA=s(lt);T(hy.$$.fragment,BA),ALo=i(BA),Qfe=n(BA,"P",{});var yht=s(Qfe);LLo=r(yht,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),yht.forEach(t),yLo=i(BA),Vi=n(BA,"P",{});var Coe=s(Vi);xLo=r(Coe,`Note:
Loading a model from its configuration file does `),Wfe=n(Coe,"STRONG",{});var xht=s(Wfe);$Lo=r(xht,"not"),xht.forEach(t),kLo=r(Coe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZD=n(Coe,"A",{href:!0});var $ht=s(ZD);SLo=r($ht,"from_pretrained()"),$ht.forEach(t),RLo=r(Coe," to load the model weights."),Coe.forEach(t),PLo=i(BA),T(w1.$$.fragment,BA),BA.forEach(t),BLo=i(Zs),Ke=n(Zs,"DIV",{class:!0});var sa=s(Ke);T(py.$$.fragment,sa),ILo=i(sa),Hfe=n(sa,"P",{});var kht=s(Hfe);NLo=r(kht,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),kht.forEach(t),qLo=i(sa),Ba=n(sa,"P",{});var IA=s(Ba);jLo=r(IA,"The model class to instantiate is selected based on the "),Ufe=n(IA,"CODE",{});var Sht=s(Ufe);DLo=r(Sht,"model_type"),Sht.forEach(t),GLo=r(IA,` property of the config object (either
passed as an argument or loaded from `),Jfe=n(IA,"CODE",{});var Rht=s(Jfe);OLo=r(Rht,"pretrained_model_name_or_path"),Rht.forEach(t),VLo=r(IA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yfe=n(IA,"CODE",{});var Pht=s(Yfe);XLo=r(Pht,"pretrained_model_name_or_path"),Pht.forEach(t),zLo=r(IA,":"),IA.forEach(t),QLo=i(sa),z=n(sa,"UL",{});var W=s(z);A1=n(W,"LI",{});var Dxe=s(A1);Kfe=n(Dxe,"STRONG",{});var Bht=s(Kfe);WLo=r(Bht,"bart"),Bht.forEach(t),HLo=r(Dxe," \u2014 "),eG=n(Dxe,"A",{href:!0});var Iht=s(eG);ULo=r(Iht,"BartForCausalLM"),Iht.forEach(t),JLo=r(Dxe," (BART model)"),Dxe.forEach(t),YLo=i(W),L1=n(W,"LI",{});var Gxe=s(L1);Zfe=n(Gxe,"STRONG",{});var Nht=s(Zfe);KLo=r(Nht,"bert"),Nht.forEach(t),ZLo=r(Gxe," \u2014 "),oG=n(Gxe,"A",{href:!0});var qht=s(oG);eyo=r(qht,"BertLMHeadModel"),qht.forEach(t),oyo=r(Gxe," (BERT model)"),Gxe.forEach(t),ryo=i(W),y1=n(W,"LI",{});var Oxe=s(y1);eme=n(Oxe,"STRONG",{});var jht=s(eme);tyo=r(jht,"bert-generation"),jht.forEach(t),ayo=r(Oxe," \u2014 "),rG=n(Oxe,"A",{href:!0});var Dht=s(rG);nyo=r(Dht,"BertGenerationDecoder"),Dht.forEach(t),syo=r(Oxe," (Bert Generation model)"),Oxe.forEach(t),lyo=i(W),x1=n(W,"LI",{});var Vxe=s(x1);ome=n(Vxe,"STRONG",{});var Ght=s(ome);iyo=r(Ght,"big_bird"),Ght.forEach(t),dyo=r(Vxe," \u2014 "),tG=n(Vxe,"A",{href:!0});var Oht=s(tG);cyo=r(Oht,"BigBirdForCausalLM"),Oht.forEach(t),fyo=r(Vxe," (BigBird model)"),Vxe.forEach(t),myo=i(W),$1=n(W,"LI",{});var Xxe=s($1);rme=n(Xxe,"STRONG",{});var Vht=s(rme);gyo=r(Vht,"bigbird_pegasus"),Vht.forEach(t),hyo=r(Xxe," \u2014 "),aG=n(Xxe,"A",{href:!0});var Xht=s(aG);pyo=r(Xht,"BigBirdPegasusForCausalLM"),Xht.forEach(t),_yo=r(Xxe," (BigBird-Pegasus model)"),Xxe.forEach(t),uyo=i(W),k1=n(W,"LI",{});var zxe=s(k1);tme=n(zxe,"STRONG",{});var zht=s(tme);byo=r(zht,"blenderbot"),zht.forEach(t),vyo=r(zxe," \u2014 "),nG=n(zxe,"A",{href:!0});var Qht=s(nG);Fyo=r(Qht,"BlenderbotForCausalLM"),Qht.forEach(t),Tyo=r(zxe," (Blenderbot model)"),zxe.forEach(t),Myo=i(W),S1=n(W,"LI",{});var Qxe=s(S1);ame=n(Qxe,"STRONG",{});var Wht=s(ame);Eyo=r(Wht,"blenderbot-small"),Wht.forEach(t),Cyo=r(Qxe," \u2014 "),sG=n(Qxe,"A",{href:!0});var Hht=s(sG);wyo=r(Hht,"BlenderbotSmallForCausalLM"),Hht.forEach(t),Ayo=r(Qxe," (BlenderbotSmall model)"),Qxe.forEach(t),Lyo=i(W),R1=n(W,"LI",{});var Wxe=s(R1);nme=n(Wxe,"STRONG",{});var Uht=s(nme);yyo=r(Uht,"bloom"),Uht.forEach(t),xyo=r(Wxe," \u2014 "),lG=n(Wxe,"A",{href:!0});var Jht=s(lG);$yo=r(Jht,"BloomForCausalLM"),Jht.forEach(t),kyo=r(Wxe," (BLOOM model)"),Wxe.forEach(t),Syo=i(W),P1=n(W,"LI",{});var Hxe=s(P1);sme=n(Hxe,"STRONG",{});var Yht=s(sme);Ryo=r(Yht,"camembert"),Yht.forEach(t),Pyo=r(Hxe," \u2014 "),iG=n(Hxe,"A",{href:!0});var Kht=s(iG);Byo=r(Kht,"CamembertForCausalLM"),Kht.forEach(t),Iyo=r(Hxe," (CamemBERT model)"),Hxe.forEach(t),Nyo=i(W),B1=n(W,"LI",{});var Uxe=s(B1);lme=n(Uxe,"STRONG",{});var Zht=s(lme);qyo=r(Zht,"ctrl"),Zht.forEach(t),jyo=r(Uxe," \u2014 "),dG=n(Uxe,"A",{href:!0});var ept=s(dG);Dyo=r(ept,"CTRLLMHeadModel"),ept.forEach(t),Gyo=r(Uxe," (CTRL model)"),Uxe.forEach(t),Oyo=i(W),I1=n(W,"LI",{});var Jxe=s(I1);ime=n(Jxe,"STRONG",{});var opt=s(ime);Vyo=r(opt,"data2vec-text"),opt.forEach(t),Xyo=r(Jxe," \u2014 "),cG=n(Jxe,"A",{href:!0});var rpt=s(cG);zyo=r(rpt,"Data2VecTextForCausalLM"),rpt.forEach(t),Qyo=r(Jxe," (Data2VecText model)"),Jxe.forEach(t),Wyo=i(W),N1=n(W,"LI",{});var Yxe=s(N1);dme=n(Yxe,"STRONG",{});var tpt=s(dme);Hyo=r(tpt,"electra"),tpt.forEach(t),Uyo=r(Yxe," \u2014 "),fG=n(Yxe,"A",{href:!0});var apt=s(fG);Jyo=r(apt,"ElectraForCausalLM"),apt.forEach(t),Yyo=r(Yxe," (ELECTRA model)"),Yxe.forEach(t),Kyo=i(W),q1=n(W,"LI",{});var Kxe=s(q1);cme=n(Kxe,"STRONG",{});var npt=s(cme);Zyo=r(npt,"gpt2"),npt.forEach(t),e8o=r(Kxe," \u2014 "),mG=n(Kxe,"A",{href:!0});var spt=s(mG);o8o=r(spt,"GPT2LMHeadModel"),spt.forEach(t),r8o=r(Kxe," (OpenAI GPT-2 model)"),Kxe.forEach(t),t8o=i(W),j1=n(W,"LI",{});var Zxe=s(j1);fme=n(Zxe,"STRONG",{});var lpt=s(fme);a8o=r(lpt,"gpt_neo"),lpt.forEach(t),n8o=r(Zxe," \u2014 "),gG=n(Zxe,"A",{href:!0});var ipt=s(gG);s8o=r(ipt,"GPTNeoForCausalLM"),ipt.forEach(t),l8o=r(Zxe," (GPT Neo model)"),Zxe.forEach(t),i8o=i(W),D1=n(W,"LI",{});var e$e=s(D1);mme=n(e$e,"STRONG",{});var dpt=s(mme);d8o=r(dpt,"gpt_neox"),dpt.forEach(t),c8o=r(e$e," \u2014 "),hG=n(e$e,"A",{href:!0});var cpt=s(hG);f8o=r(cpt,"GPTNeoXForCausalLM"),cpt.forEach(t),m8o=r(e$e," (GPT NeoX model)"),e$e.forEach(t),g8o=i(W),G1=n(W,"LI",{});var o$e=s(G1);gme=n(o$e,"STRONG",{});var fpt=s(gme);h8o=r(fpt,"gptj"),fpt.forEach(t),p8o=r(o$e," \u2014 "),pG=n(o$e,"A",{href:!0});var mpt=s(pG);_8o=r(mpt,"GPTJForCausalLM"),mpt.forEach(t),u8o=r(o$e," (GPT-J model)"),o$e.forEach(t),b8o=i(W),O1=n(W,"LI",{});var r$e=s(O1);hme=n(r$e,"STRONG",{});var gpt=s(hme);v8o=r(gpt,"marian"),gpt.forEach(t),F8o=r(r$e," \u2014 "),_G=n(r$e,"A",{href:!0});var hpt=s(_G);T8o=r(hpt,"MarianForCausalLM"),hpt.forEach(t),M8o=r(r$e," (Marian model)"),r$e.forEach(t),E8o=i(W),V1=n(W,"LI",{});var t$e=s(V1);pme=n(t$e,"STRONG",{});var ppt=s(pme);C8o=r(ppt,"mbart"),ppt.forEach(t),w8o=r(t$e," \u2014 "),uG=n(t$e,"A",{href:!0});var _pt=s(uG);A8o=r(_pt,"MBartForCausalLM"),_pt.forEach(t),L8o=r(t$e," (mBART model)"),t$e.forEach(t),y8o=i(W),X1=n(W,"LI",{});var a$e=s(X1);_me=n(a$e,"STRONG",{});var upt=s(_me);x8o=r(upt,"megatron-bert"),upt.forEach(t),$8o=r(a$e," \u2014 "),bG=n(a$e,"A",{href:!0});var bpt=s(bG);k8o=r(bpt,"MegatronBertForCausalLM"),bpt.forEach(t),S8o=r(a$e," (Megatron-BERT model)"),a$e.forEach(t),R8o=i(W),z1=n(W,"LI",{});var n$e=s(z1);ume=n(n$e,"STRONG",{});var vpt=s(ume);P8o=r(vpt,"openai-gpt"),vpt.forEach(t),B8o=r(n$e," \u2014 "),vG=n(n$e,"A",{href:!0});var Fpt=s(vG);I8o=r(Fpt,"OpenAIGPTLMHeadModel"),Fpt.forEach(t),N8o=r(n$e," (OpenAI GPT model)"),n$e.forEach(t),q8o=i(W),Q1=n(W,"LI",{});var s$e=s(Q1);bme=n(s$e,"STRONG",{});var Tpt=s(bme);j8o=r(Tpt,"opt"),Tpt.forEach(t),D8o=r(s$e," \u2014 "),FG=n(s$e,"A",{href:!0});var Mpt=s(FG);G8o=r(Mpt,"OPTForCausalLM"),Mpt.forEach(t),O8o=r(s$e," (OPT model)"),s$e.forEach(t),V8o=i(W),W1=n(W,"LI",{});var l$e=s(W1);vme=n(l$e,"STRONG",{});var Ept=s(vme);X8o=r(Ept,"pegasus"),Ept.forEach(t),z8o=r(l$e," \u2014 "),TG=n(l$e,"A",{href:!0});var Cpt=s(TG);Q8o=r(Cpt,"PegasusForCausalLM"),Cpt.forEach(t),W8o=r(l$e," (Pegasus model)"),l$e.forEach(t),H8o=i(W),H1=n(W,"LI",{});var i$e=s(H1);Fme=n(i$e,"STRONG",{});var wpt=s(Fme);U8o=r(wpt,"plbart"),wpt.forEach(t),J8o=r(i$e," \u2014 "),MG=n(i$e,"A",{href:!0});var Apt=s(MG);Y8o=r(Apt,"PLBartForCausalLM"),Apt.forEach(t),K8o=r(i$e," (PLBart model)"),i$e.forEach(t),Z8o=i(W),U1=n(W,"LI",{});var d$e=s(U1);Tme=n(d$e,"STRONG",{});var Lpt=s(Tme);e9o=r(Lpt,"prophetnet"),Lpt.forEach(t),o9o=r(d$e," \u2014 "),EG=n(d$e,"A",{href:!0});var ypt=s(EG);r9o=r(ypt,"ProphetNetForCausalLM"),ypt.forEach(t),t9o=r(d$e," (ProphetNet model)"),d$e.forEach(t),a9o=i(W),J1=n(W,"LI",{});var c$e=s(J1);Mme=n(c$e,"STRONG",{});var xpt=s(Mme);n9o=r(xpt,"qdqbert"),xpt.forEach(t),s9o=r(c$e," \u2014 "),CG=n(c$e,"A",{href:!0});var $pt=s(CG);l9o=r($pt,"QDQBertLMHeadModel"),$pt.forEach(t),i9o=r(c$e," (QDQBert model)"),c$e.forEach(t),d9o=i(W),Y1=n(W,"LI",{});var f$e=s(Y1);Eme=n(f$e,"STRONG",{});var kpt=s(Eme);c9o=r(kpt,"reformer"),kpt.forEach(t),f9o=r(f$e," \u2014 "),wG=n(f$e,"A",{href:!0});var Spt=s(wG);m9o=r(Spt,"ReformerModelWithLMHead"),Spt.forEach(t),g9o=r(f$e," (Reformer model)"),f$e.forEach(t),h9o=i(W),K1=n(W,"LI",{});var m$e=s(K1);Cme=n(m$e,"STRONG",{});var Rpt=s(Cme);p9o=r(Rpt,"rembert"),Rpt.forEach(t),_9o=r(m$e," \u2014 "),AG=n(m$e,"A",{href:!0});var Ppt=s(AG);u9o=r(Ppt,"RemBertForCausalLM"),Ppt.forEach(t),b9o=r(m$e," (RemBERT model)"),m$e.forEach(t),v9o=i(W),Z1=n(W,"LI",{});var g$e=s(Z1);wme=n(g$e,"STRONG",{});var Bpt=s(wme);F9o=r(Bpt,"roberta"),Bpt.forEach(t),T9o=r(g$e," \u2014 "),LG=n(g$e,"A",{href:!0});var Ipt=s(LG);M9o=r(Ipt,"RobertaForCausalLM"),Ipt.forEach(t),E9o=r(g$e," (RoBERTa model)"),g$e.forEach(t),C9o=i(W),e7=n(W,"LI",{});var h$e=s(e7);Ame=n(h$e,"STRONG",{});var Npt=s(Ame);w9o=r(Npt,"roformer"),Npt.forEach(t),A9o=r(h$e," \u2014 "),yG=n(h$e,"A",{href:!0});var qpt=s(yG);L9o=r(qpt,"RoFormerForCausalLM"),qpt.forEach(t),y9o=r(h$e," (RoFormer model)"),h$e.forEach(t),x9o=i(W),o7=n(W,"LI",{});var p$e=s(o7);Lme=n(p$e,"STRONG",{});var jpt=s(Lme);$9o=r(jpt,"speech_to_text_2"),jpt.forEach(t),k9o=r(p$e," \u2014 "),xG=n(p$e,"A",{href:!0});var Dpt=s(xG);S9o=r(Dpt,"Speech2Text2ForCausalLM"),Dpt.forEach(t),R9o=r(p$e," (Speech2Text2 model)"),p$e.forEach(t),P9o=i(W),r7=n(W,"LI",{});var _$e=s(r7);yme=n(_$e,"STRONG",{});var Gpt=s(yme);B9o=r(Gpt,"transfo-xl"),Gpt.forEach(t),I9o=r(_$e," \u2014 "),$G=n(_$e,"A",{href:!0});var Opt=s($G);N9o=r(Opt,"TransfoXLLMHeadModel"),Opt.forEach(t),q9o=r(_$e," (Transformer-XL model)"),_$e.forEach(t),j9o=i(W),t7=n(W,"LI",{});var u$e=s(t7);xme=n(u$e,"STRONG",{});var Vpt=s(xme);D9o=r(Vpt,"trocr"),Vpt.forEach(t),G9o=r(u$e," \u2014 "),kG=n(u$e,"A",{href:!0});var Xpt=s(kG);O9o=r(Xpt,"TrOCRForCausalLM"),Xpt.forEach(t),V9o=r(u$e," (TrOCR model)"),u$e.forEach(t),X9o=i(W),a7=n(W,"LI",{});var b$e=s(a7);$me=n(b$e,"STRONG",{});var zpt=s($me);z9o=r(zpt,"xglm"),zpt.forEach(t),Q9o=r(b$e," \u2014 "),SG=n(b$e,"A",{href:!0});var Qpt=s(SG);W9o=r(Qpt,"XGLMForCausalLM"),Qpt.forEach(t),H9o=r(b$e," (XGLM model)"),b$e.forEach(t),U9o=i(W),n7=n(W,"LI",{});var v$e=s(n7);kme=n(v$e,"STRONG",{});var Wpt=s(kme);J9o=r(Wpt,"xlm"),Wpt.forEach(t),Y9o=r(v$e," \u2014 "),RG=n(v$e,"A",{href:!0});var Hpt=s(RG);K9o=r(Hpt,"XLMWithLMHeadModel"),Hpt.forEach(t),Z9o=r(v$e," (XLM model)"),v$e.forEach(t),exo=i(W),s7=n(W,"LI",{});var F$e=s(s7);Sme=n(F$e,"STRONG",{});var Upt=s(Sme);oxo=r(Upt,"xlm-prophetnet"),Upt.forEach(t),rxo=r(F$e," \u2014 "),PG=n(F$e,"A",{href:!0});var Jpt=s(PG);txo=r(Jpt,"XLMProphetNetForCausalLM"),Jpt.forEach(t),axo=r(F$e," (XLM-ProphetNet model)"),F$e.forEach(t),nxo=i(W),l7=n(W,"LI",{});var T$e=s(l7);Rme=n(T$e,"STRONG",{});var Ypt=s(Rme);sxo=r(Ypt,"xlm-roberta"),Ypt.forEach(t),lxo=r(T$e," \u2014 "),BG=n(T$e,"A",{href:!0});var Kpt=s(BG);ixo=r(Kpt,"XLMRobertaForCausalLM"),Kpt.forEach(t),dxo=r(T$e," (XLM-RoBERTa model)"),T$e.forEach(t),cxo=i(W),i7=n(W,"LI",{});var M$e=s(i7);Pme=n(M$e,"STRONG",{});var Zpt=s(Pme);fxo=r(Zpt,"xlm-roberta-xl"),Zpt.forEach(t),mxo=r(M$e," \u2014 "),IG=n(M$e,"A",{href:!0});var e_t=s(IG);gxo=r(e_t,"XLMRobertaXLForCausalLM"),e_t.forEach(t),hxo=r(M$e," (XLM-RoBERTa-XL model)"),M$e.forEach(t),pxo=i(W),d7=n(W,"LI",{});var E$e=s(d7);Bme=n(E$e,"STRONG",{});var o_t=s(Bme);_xo=r(o_t,"xlnet"),o_t.forEach(t),uxo=r(E$e," \u2014 "),NG=n(E$e,"A",{href:!0});var r_t=s(NG);bxo=r(r_t,"XLNetLMHeadModel"),r_t.forEach(t),vxo=r(E$e," (XLNet model)"),E$e.forEach(t),W.forEach(t),Fxo=i(sa),c7=n(sa,"P",{});var C$e=s(c7);Txo=r(C$e,"The model is set in evaluation mode by default using "),Ime=n(C$e,"CODE",{});var t_t=s(Ime);Mxo=r(t_t,"model.eval()"),t_t.forEach(t),Exo=r(C$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nme=n(C$e,"CODE",{});var a_t=s(Nme);Cxo=r(a_t,"model.train()"),a_t.forEach(t),C$e.forEach(t),wxo=i(sa),T(f7.$$.fragment,sa),sa.forEach(t),Zs.forEach(t),aOe=i(f),Xi=n(f,"H2",{class:!0});var cXe=s(Xi);m7=n(cXe,"A",{id:!0,class:!0,href:!0});var n_t=s(m7);qme=n(n_t,"SPAN",{});var s_t=s(qme);T(_y.$$.fragment,s_t),s_t.forEach(t),n_t.forEach(t),Axo=i(cXe),jme=n(cXe,"SPAN",{});var l_t=s(jme);Lxo=r(l_t,"AutoModelForMaskedLM"),l_t.forEach(t),cXe.forEach(t),nOe=i(f),So=n(f,"DIV",{class:!0});var el=s(So);T(uy.$$.fragment,el),yxo=i(el),zi=n(el,"P",{});var woe=s(zi);xxo=r(woe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),qG=n(woe,"A",{href:!0});var i_t=s(qG);$xo=r(i_t,"from_pretrained()"),i_t.forEach(t),kxo=r(woe," class method or the "),jG=n(woe,"A",{href:!0});var d_t=s(jG);Sxo=r(d_t,"from_config()"),d_t.forEach(t),Rxo=r(woe,` class
method.`),woe.forEach(t),Pxo=i(el),by=n(el,"P",{});var fXe=s(by);Bxo=r(fXe,"This class cannot be instantiated directly using "),Dme=n(fXe,"CODE",{});var c_t=s(Dme);Ixo=r(c_t,"__init__()"),c_t.forEach(t),Nxo=r(fXe," (throws an error)."),fXe.forEach(t),qxo=i(el),it=n(el,"DIV",{class:!0});var NA=s(it);T(vy.$$.fragment,NA),jxo=i(NA),Gme=n(NA,"P",{});var f_t=s(Gme);Dxo=r(f_t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),f_t.forEach(t),Gxo=i(NA),Qi=n(NA,"P",{});var Aoe=s(Qi);Oxo=r(Aoe,`Note:
Loading a model from its configuration file does `),Ome=n(Aoe,"STRONG",{});var m_t=s(Ome);Vxo=r(m_t,"not"),m_t.forEach(t),Xxo=r(Aoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),DG=n(Aoe,"A",{href:!0});var g_t=s(DG);zxo=r(g_t,"from_pretrained()"),g_t.forEach(t),Qxo=r(Aoe," to load the model weights."),Aoe.forEach(t),Wxo=i(NA),T(g7.$$.fragment,NA),NA.forEach(t),Hxo=i(el),Ze=n(el,"DIV",{class:!0});var la=s(Ze);T(Fy.$$.fragment,la),Uxo=i(la),Vme=n(la,"P",{});var h_t=s(Vme);Jxo=r(h_t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),h_t.forEach(t),Yxo=i(la),Ia=n(la,"P",{});var qA=s(Ia);Kxo=r(qA,"The model class to instantiate is selected based on the "),Xme=n(qA,"CODE",{});var p_t=s(Xme);Zxo=r(p_t,"model_type"),p_t.forEach(t),e$o=r(qA,` property of the config object (either
passed as an argument or loaded from `),zme=n(qA,"CODE",{});var __t=s(zme);o$o=r(__t,"pretrained_model_name_or_path"),__t.forEach(t),r$o=r(qA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qme=n(qA,"CODE",{});var u_t=s(Qme);t$o=r(u_t,"pretrained_model_name_or_path"),u_t.forEach(t),a$o=r(qA,":"),qA.forEach(t),n$o=i(la),Q=n(la,"UL",{});var U=s(Q);h7=n(U,"LI",{});var w$e=s(h7);Wme=n(w$e,"STRONG",{});var b_t=s(Wme);s$o=r(b_t,"albert"),b_t.forEach(t),l$o=r(w$e," \u2014 "),GG=n(w$e,"A",{href:!0});var v_t=s(GG);i$o=r(v_t,"AlbertForMaskedLM"),v_t.forEach(t),d$o=r(w$e," (ALBERT model)"),w$e.forEach(t),c$o=i(U),p7=n(U,"LI",{});var A$e=s(p7);Hme=n(A$e,"STRONG",{});var F_t=s(Hme);f$o=r(F_t,"bart"),F_t.forEach(t),m$o=r(A$e," \u2014 "),OG=n(A$e,"A",{href:!0});var T_t=s(OG);g$o=r(T_t,"BartForConditionalGeneration"),T_t.forEach(t),h$o=r(A$e," (BART model)"),A$e.forEach(t),p$o=i(U),_7=n(U,"LI",{});var L$e=s(_7);Ume=n(L$e,"STRONG",{});var M_t=s(Ume);_$o=r(M_t,"bert"),M_t.forEach(t),u$o=r(L$e," \u2014 "),VG=n(L$e,"A",{href:!0});var E_t=s(VG);b$o=r(E_t,"BertForMaskedLM"),E_t.forEach(t),v$o=r(L$e," (BERT model)"),L$e.forEach(t),F$o=i(U),u7=n(U,"LI",{});var y$e=s(u7);Jme=n(y$e,"STRONG",{});var C_t=s(Jme);T$o=r(C_t,"big_bird"),C_t.forEach(t),M$o=r(y$e," \u2014 "),XG=n(y$e,"A",{href:!0});var w_t=s(XG);E$o=r(w_t,"BigBirdForMaskedLM"),w_t.forEach(t),C$o=r(y$e," (BigBird model)"),y$e.forEach(t),w$o=i(U),b7=n(U,"LI",{});var x$e=s(b7);Yme=n(x$e,"STRONG",{});var A_t=s(Yme);A$o=r(A_t,"camembert"),A_t.forEach(t),L$o=r(x$e," \u2014 "),zG=n(x$e,"A",{href:!0});var L_t=s(zG);y$o=r(L_t,"CamembertForMaskedLM"),L_t.forEach(t),x$o=r(x$e," (CamemBERT model)"),x$e.forEach(t),$$o=i(U),v7=n(U,"LI",{});var $$e=s(v7);Kme=n($$e,"STRONG",{});var y_t=s(Kme);k$o=r(y_t,"convbert"),y_t.forEach(t),S$o=r($$e," \u2014 "),QG=n($$e,"A",{href:!0});var x_t=s(QG);R$o=r(x_t,"ConvBertForMaskedLM"),x_t.forEach(t),P$o=r($$e," (ConvBERT model)"),$$e.forEach(t),B$o=i(U),F7=n(U,"LI",{});var k$e=s(F7);Zme=n(k$e,"STRONG",{});var $_t=s(Zme);I$o=r($_t,"data2vec-text"),$_t.forEach(t),N$o=r(k$e," \u2014 "),WG=n(k$e,"A",{href:!0});var k_t=s(WG);q$o=r(k_t,"Data2VecTextForMaskedLM"),k_t.forEach(t),j$o=r(k$e," (Data2VecText model)"),k$e.forEach(t),D$o=i(U),T7=n(U,"LI",{});var S$e=s(T7);ege=n(S$e,"STRONG",{});var S_t=s(ege);G$o=r(S_t,"deberta"),S_t.forEach(t),O$o=r(S$e," \u2014 "),HG=n(S$e,"A",{href:!0});var R_t=s(HG);V$o=r(R_t,"DebertaForMaskedLM"),R_t.forEach(t),X$o=r(S$e," (DeBERTa model)"),S$e.forEach(t),z$o=i(U),M7=n(U,"LI",{});var R$e=s(M7);oge=n(R$e,"STRONG",{});var P_t=s(oge);Q$o=r(P_t,"deberta-v2"),P_t.forEach(t),W$o=r(R$e," \u2014 "),UG=n(R$e,"A",{href:!0});var B_t=s(UG);H$o=r(B_t,"DebertaV2ForMaskedLM"),B_t.forEach(t),U$o=r(R$e," (DeBERTa-v2 model)"),R$e.forEach(t),J$o=i(U),E7=n(U,"LI",{});var P$e=s(E7);rge=n(P$e,"STRONG",{});var I_t=s(rge);Y$o=r(I_t,"distilbert"),I_t.forEach(t),K$o=r(P$e," \u2014 "),JG=n(P$e,"A",{href:!0});var N_t=s(JG);Z$o=r(N_t,"DistilBertForMaskedLM"),N_t.forEach(t),eko=r(P$e," (DistilBERT model)"),P$e.forEach(t),oko=i(U),C7=n(U,"LI",{});var B$e=s(C7);tge=n(B$e,"STRONG",{});var q_t=s(tge);rko=r(q_t,"electra"),q_t.forEach(t),tko=r(B$e," \u2014 "),YG=n(B$e,"A",{href:!0});var j_t=s(YG);ako=r(j_t,"ElectraForMaskedLM"),j_t.forEach(t),nko=r(B$e," (ELECTRA model)"),B$e.forEach(t),sko=i(U),w7=n(U,"LI",{});var I$e=s(w7);age=n(I$e,"STRONG",{});var D_t=s(age);lko=r(D_t,"flaubert"),D_t.forEach(t),iko=r(I$e," \u2014 "),KG=n(I$e,"A",{href:!0});var G_t=s(KG);dko=r(G_t,"FlaubertWithLMHeadModel"),G_t.forEach(t),cko=r(I$e," (FlauBERT model)"),I$e.forEach(t),fko=i(U),A7=n(U,"LI",{});var N$e=s(A7);nge=n(N$e,"STRONG",{});var O_t=s(nge);mko=r(O_t,"fnet"),O_t.forEach(t),gko=r(N$e," \u2014 "),ZG=n(N$e,"A",{href:!0});var V_t=s(ZG);hko=r(V_t,"FNetForMaskedLM"),V_t.forEach(t),pko=r(N$e," (FNet model)"),N$e.forEach(t),_ko=i(U),L7=n(U,"LI",{});var q$e=s(L7);sge=n(q$e,"STRONG",{});var X_t=s(sge);uko=r(X_t,"funnel"),X_t.forEach(t),bko=r(q$e," \u2014 "),eO=n(q$e,"A",{href:!0});var z_t=s(eO);vko=r(z_t,"FunnelForMaskedLM"),z_t.forEach(t),Fko=r(q$e," (Funnel Transformer model)"),q$e.forEach(t),Tko=i(U),y7=n(U,"LI",{});var j$e=s(y7);lge=n(j$e,"STRONG",{});var Q_t=s(lge);Mko=r(Q_t,"ibert"),Q_t.forEach(t),Eko=r(j$e," \u2014 "),oO=n(j$e,"A",{href:!0});var W_t=s(oO);Cko=r(W_t,"IBertForMaskedLM"),W_t.forEach(t),wko=r(j$e," (I-BERT model)"),j$e.forEach(t),Ako=i(U),x7=n(U,"LI",{});var D$e=s(x7);ige=n(D$e,"STRONG",{});var H_t=s(ige);Lko=r(H_t,"layoutlm"),H_t.forEach(t),yko=r(D$e," \u2014 "),rO=n(D$e,"A",{href:!0});var U_t=s(rO);xko=r(U_t,"LayoutLMForMaskedLM"),U_t.forEach(t),$ko=r(D$e," (LayoutLM model)"),D$e.forEach(t),kko=i(U),$7=n(U,"LI",{});var G$e=s($7);dge=n(G$e,"STRONG",{});var J_t=s(dge);Sko=r(J_t,"longformer"),J_t.forEach(t),Rko=r(G$e," \u2014 "),tO=n(G$e,"A",{href:!0});var Y_t=s(tO);Pko=r(Y_t,"LongformerForMaskedLM"),Y_t.forEach(t),Bko=r(G$e," (Longformer model)"),G$e.forEach(t),Iko=i(U),k7=n(U,"LI",{});var O$e=s(k7);cge=n(O$e,"STRONG",{});var K_t=s(cge);Nko=r(K_t,"luke"),K_t.forEach(t),qko=r(O$e," \u2014 "),aO=n(O$e,"A",{href:!0});var Z_t=s(aO);jko=r(Z_t,"LukeForMaskedLM"),Z_t.forEach(t),Dko=r(O$e," (LUKE model)"),O$e.forEach(t),Gko=i(U),S7=n(U,"LI",{});var V$e=s(S7);fge=n(V$e,"STRONG",{});var eut=s(fge);Oko=r(eut,"mbart"),eut.forEach(t),Vko=r(V$e," \u2014 "),nO=n(V$e,"A",{href:!0});var out=s(nO);Xko=r(out,"MBartForConditionalGeneration"),out.forEach(t),zko=r(V$e," (mBART model)"),V$e.forEach(t),Qko=i(U),R7=n(U,"LI",{});var X$e=s(R7);mge=n(X$e,"STRONG",{});var rut=s(mge);Wko=r(rut,"megatron-bert"),rut.forEach(t),Hko=r(X$e," \u2014 "),sO=n(X$e,"A",{href:!0});var tut=s(sO);Uko=r(tut,"MegatronBertForMaskedLM"),tut.forEach(t),Jko=r(X$e," (Megatron-BERT model)"),X$e.forEach(t),Yko=i(U),P7=n(U,"LI",{});var z$e=s(P7);gge=n(z$e,"STRONG",{});var aut=s(gge);Kko=r(aut,"mobilebert"),aut.forEach(t),Zko=r(z$e," \u2014 "),lO=n(z$e,"A",{href:!0});var nut=s(lO);eSo=r(nut,"MobileBertForMaskedLM"),nut.forEach(t),oSo=r(z$e," (MobileBERT model)"),z$e.forEach(t),rSo=i(U),B7=n(U,"LI",{});var Q$e=s(B7);hge=n(Q$e,"STRONG",{});var sut=s(hge);tSo=r(sut,"mpnet"),sut.forEach(t),aSo=r(Q$e," \u2014 "),iO=n(Q$e,"A",{href:!0});var lut=s(iO);nSo=r(lut,"MPNetForMaskedLM"),lut.forEach(t),sSo=r(Q$e," (MPNet model)"),Q$e.forEach(t),lSo=i(U),I7=n(U,"LI",{});var W$e=s(I7);pge=n(W$e,"STRONG",{});var iut=s(pge);iSo=r(iut,"nezha"),iut.forEach(t),dSo=r(W$e," \u2014 "),dO=n(W$e,"A",{href:!0});var dut=s(dO);cSo=r(dut,"NezhaForMaskedLM"),dut.forEach(t),fSo=r(W$e," (Nezha model)"),W$e.forEach(t),mSo=i(U),N7=n(U,"LI",{});var H$e=s(N7);_ge=n(H$e,"STRONG",{});var cut=s(_ge);gSo=r(cut,"nystromformer"),cut.forEach(t),hSo=r(H$e," \u2014 "),cO=n(H$e,"A",{href:!0});var fut=s(cO);pSo=r(fut,"NystromformerForMaskedLM"),fut.forEach(t),_So=r(H$e," (Nystr\xF6mformer model)"),H$e.forEach(t),uSo=i(U),q7=n(U,"LI",{});var U$e=s(q7);uge=n(U$e,"STRONG",{});var mut=s(uge);bSo=r(mut,"perceiver"),mut.forEach(t),vSo=r(U$e," \u2014 "),fO=n(U$e,"A",{href:!0});var gut=s(fO);FSo=r(gut,"PerceiverForMaskedLM"),gut.forEach(t),TSo=r(U$e," (Perceiver model)"),U$e.forEach(t),MSo=i(U),j7=n(U,"LI",{});var J$e=s(j7);bge=n(J$e,"STRONG",{});var hut=s(bge);ESo=r(hut,"qdqbert"),hut.forEach(t),CSo=r(J$e," \u2014 "),mO=n(J$e,"A",{href:!0});var put=s(mO);wSo=r(put,"QDQBertForMaskedLM"),put.forEach(t),ASo=r(J$e," (QDQBert model)"),J$e.forEach(t),LSo=i(U),D7=n(U,"LI",{});var Y$e=s(D7);vge=n(Y$e,"STRONG",{});var _ut=s(vge);ySo=r(_ut,"reformer"),_ut.forEach(t),xSo=r(Y$e," \u2014 "),gO=n(Y$e,"A",{href:!0});var uut=s(gO);$So=r(uut,"ReformerForMaskedLM"),uut.forEach(t),kSo=r(Y$e," (Reformer model)"),Y$e.forEach(t),SSo=i(U),G7=n(U,"LI",{});var K$e=s(G7);Fge=n(K$e,"STRONG",{});var but=s(Fge);RSo=r(but,"rembert"),but.forEach(t),PSo=r(K$e," \u2014 "),hO=n(K$e,"A",{href:!0});var vut=s(hO);BSo=r(vut,"RemBertForMaskedLM"),vut.forEach(t),ISo=r(K$e," (RemBERT model)"),K$e.forEach(t),NSo=i(U),O7=n(U,"LI",{});var Z$e=s(O7);Tge=n(Z$e,"STRONG",{});var Fut=s(Tge);qSo=r(Fut,"roberta"),Fut.forEach(t),jSo=r(Z$e," \u2014 "),pO=n(Z$e,"A",{href:!0});var Tut=s(pO);DSo=r(Tut,"RobertaForMaskedLM"),Tut.forEach(t),GSo=r(Z$e," (RoBERTa model)"),Z$e.forEach(t),OSo=i(U),V7=n(U,"LI",{});var eke=s(V7);Mge=n(eke,"STRONG",{});var Mut=s(Mge);VSo=r(Mut,"roformer"),Mut.forEach(t),XSo=r(eke," \u2014 "),_O=n(eke,"A",{href:!0});var Eut=s(_O);zSo=r(Eut,"RoFormerForMaskedLM"),Eut.forEach(t),QSo=r(eke," (RoFormer model)"),eke.forEach(t),WSo=i(U),X7=n(U,"LI",{});var oke=s(X7);Ege=n(oke,"STRONG",{});var Cut=s(Ege);HSo=r(Cut,"squeezebert"),Cut.forEach(t),USo=r(oke," \u2014 "),uO=n(oke,"A",{href:!0});var wut=s(uO);JSo=r(wut,"SqueezeBertForMaskedLM"),wut.forEach(t),YSo=r(oke," (SqueezeBERT model)"),oke.forEach(t),KSo=i(U),z7=n(U,"LI",{});var rke=s(z7);Cge=n(rke,"STRONG",{});var Aut=s(Cge);ZSo=r(Aut,"tapas"),Aut.forEach(t),eRo=r(rke," \u2014 "),bO=n(rke,"A",{href:!0});var Lut=s(bO);oRo=r(Lut,"TapasForMaskedLM"),Lut.forEach(t),rRo=r(rke," (TAPAS model)"),rke.forEach(t),tRo=i(U),Q7=n(U,"LI",{});var tke=s(Q7);wge=n(tke,"STRONG",{});var yut=s(wge);aRo=r(yut,"wav2vec2"),yut.forEach(t),nRo=r(tke," \u2014 "),Age=n(tke,"CODE",{});var xut=s(Age);sRo=r(xut,"Wav2Vec2ForMaskedLM"),xut.forEach(t),lRo=r(tke," (Wav2Vec2 model)"),tke.forEach(t),iRo=i(U),W7=n(U,"LI",{});var ake=s(W7);Lge=n(ake,"STRONG",{});var $ut=s(Lge);dRo=r($ut,"xlm"),$ut.forEach(t),cRo=r(ake," \u2014 "),vO=n(ake,"A",{href:!0});var kut=s(vO);fRo=r(kut,"XLMWithLMHeadModel"),kut.forEach(t),mRo=r(ake," (XLM model)"),ake.forEach(t),gRo=i(U),H7=n(U,"LI",{});var nke=s(H7);yge=n(nke,"STRONG",{});var Sut=s(yge);hRo=r(Sut,"xlm-roberta"),Sut.forEach(t),pRo=r(nke," \u2014 "),FO=n(nke,"A",{href:!0});var Rut=s(FO);_Ro=r(Rut,"XLMRobertaForMaskedLM"),Rut.forEach(t),uRo=r(nke," (XLM-RoBERTa model)"),nke.forEach(t),bRo=i(U),U7=n(U,"LI",{});var ske=s(U7);xge=n(ske,"STRONG",{});var Put=s(xge);vRo=r(Put,"xlm-roberta-xl"),Put.forEach(t),FRo=r(ske," \u2014 "),TO=n(ske,"A",{href:!0});var But=s(TO);TRo=r(But,"XLMRobertaXLForMaskedLM"),But.forEach(t),MRo=r(ske," (XLM-RoBERTa-XL model)"),ske.forEach(t),ERo=i(U),J7=n(U,"LI",{});var lke=s(J7);$ge=n(lke,"STRONG",{});var Iut=s($ge);CRo=r(Iut,"yoso"),Iut.forEach(t),wRo=r(lke," \u2014 "),MO=n(lke,"A",{href:!0});var Nut=s(MO);ARo=r(Nut,"YosoForMaskedLM"),Nut.forEach(t),LRo=r(lke," (YOSO model)"),lke.forEach(t),U.forEach(t),yRo=i(la),Y7=n(la,"P",{});var ike=s(Y7);xRo=r(ike,"The model is set in evaluation mode by default using "),kge=n(ike,"CODE",{});var qut=s(kge);$Ro=r(qut,"model.eval()"),qut.forEach(t),kRo=r(ike,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Sge=n(ike,"CODE",{});var jut=s(Sge);SRo=r(jut,"model.train()"),jut.forEach(t),ike.forEach(t),RRo=i(la),T(K7.$$.fragment,la),la.forEach(t),el.forEach(t),sOe=i(f),Wi=n(f,"H2",{class:!0});var mXe=s(Wi);Z7=n(mXe,"A",{id:!0,class:!0,href:!0});var Dut=s(Z7);Rge=n(Dut,"SPAN",{});var Gut=s(Rge);T(Ty.$$.fragment,Gut),Gut.forEach(t),Dut.forEach(t),PRo=i(mXe),Pge=n(mXe,"SPAN",{});var Out=s(Pge);BRo=r(Out,"AutoModelForSeq2SeqLM"),Out.forEach(t),mXe.forEach(t),lOe=i(f),Ro=n(f,"DIV",{class:!0});var ol=s(Ro);T(My.$$.fragment,ol),IRo=i(ol),Hi=n(ol,"P",{});var Loe=s(Hi);NRo=r(Loe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),EO=n(Loe,"A",{href:!0});var Vut=s(EO);qRo=r(Vut,"from_pretrained()"),Vut.forEach(t),jRo=r(Loe," class method or the "),CO=n(Loe,"A",{href:!0});var Xut=s(CO);DRo=r(Xut,"from_config()"),Xut.forEach(t),GRo=r(Loe,` class
method.`),Loe.forEach(t),ORo=i(ol),Ey=n(ol,"P",{});var gXe=s(Ey);VRo=r(gXe,"This class cannot be instantiated directly using "),Bge=n(gXe,"CODE",{});var zut=s(Bge);XRo=r(zut,"__init__()"),zut.forEach(t),zRo=r(gXe," (throws an error)."),gXe.forEach(t),QRo=i(ol),dt=n(ol,"DIV",{class:!0});var jA=s(dt);T(Cy.$$.fragment,jA),WRo=i(jA),Ige=n(jA,"P",{});var Qut=s(Ige);HRo=r(Qut,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Qut.forEach(t),URo=i(jA),Ui=n(jA,"P",{});var yoe=s(Ui);JRo=r(yoe,`Note:
Loading a model from its configuration file does `),Nge=n(yoe,"STRONG",{});var Wut=s(Nge);YRo=r(Wut,"not"),Wut.forEach(t),KRo=r(yoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),wO=n(yoe,"A",{href:!0});var Hut=s(wO);ZRo=r(Hut,"from_pretrained()"),Hut.forEach(t),ePo=r(yoe," to load the model weights."),yoe.forEach(t),oPo=i(jA),T(e2.$$.fragment,jA),jA.forEach(t),rPo=i(ol),eo=n(ol,"DIV",{class:!0});var ia=s(eo);T(wy.$$.fragment,ia),tPo=i(ia),qge=n(ia,"P",{});var Uut=s(qge);aPo=r(Uut,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Uut.forEach(t),nPo=i(ia),Na=n(ia,"P",{});var DA=s(Na);sPo=r(DA,"The model class to instantiate is selected based on the "),jge=n(DA,"CODE",{});var Jut=s(jge);lPo=r(Jut,"model_type"),Jut.forEach(t),iPo=r(DA,` property of the config object (either
passed as an argument or loaded from `),Dge=n(DA,"CODE",{});var Yut=s(Dge);dPo=r(Yut,"pretrained_model_name_or_path"),Yut.forEach(t),cPo=r(DA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gge=n(DA,"CODE",{});var Kut=s(Gge);fPo=r(Kut,"pretrained_model_name_or_path"),Kut.forEach(t),mPo=r(DA,":"),DA.forEach(t),gPo=i(ia),pe=n(ia,"UL",{});var be=s(pe);o2=n(be,"LI",{});var dke=s(o2);Oge=n(dke,"STRONG",{});var Zut=s(Oge);hPo=r(Zut,"bart"),Zut.forEach(t),pPo=r(dke," \u2014 "),AO=n(dke,"A",{href:!0});var e1t=s(AO);_Po=r(e1t,"BartForConditionalGeneration"),e1t.forEach(t),uPo=r(dke," (BART model)"),dke.forEach(t),bPo=i(be),r2=n(be,"LI",{});var cke=s(r2);Vge=n(cke,"STRONG",{});var o1t=s(Vge);vPo=r(o1t,"bigbird_pegasus"),o1t.forEach(t),FPo=r(cke," \u2014 "),LO=n(cke,"A",{href:!0});var r1t=s(LO);TPo=r(r1t,"BigBirdPegasusForConditionalGeneration"),r1t.forEach(t),MPo=r(cke," (BigBird-Pegasus model)"),cke.forEach(t),EPo=i(be),t2=n(be,"LI",{});var fke=s(t2);Xge=n(fke,"STRONG",{});var t1t=s(Xge);CPo=r(t1t,"blenderbot"),t1t.forEach(t),wPo=r(fke," \u2014 "),yO=n(fke,"A",{href:!0});var a1t=s(yO);APo=r(a1t,"BlenderbotForConditionalGeneration"),a1t.forEach(t),LPo=r(fke," (Blenderbot model)"),fke.forEach(t),yPo=i(be),a2=n(be,"LI",{});var mke=s(a2);zge=n(mke,"STRONG",{});var n1t=s(zge);xPo=r(n1t,"blenderbot-small"),n1t.forEach(t),$Po=r(mke," \u2014 "),xO=n(mke,"A",{href:!0});var s1t=s(xO);kPo=r(s1t,"BlenderbotSmallForConditionalGeneration"),s1t.forEach(t),SPo=r(mke," (BlenderbotSmall model)"),mke.forEach(t),RPo=i(be),n2=n(be,"LI",{});var gke=s(n2);Qge=n(gke,"STRONG",{});var l1t=s(Qge);PPo=r(l1t,"encoder-decoder"),l1t.forEach(t),BPo=r(gke," \u2014 "),$O=n(gke,"A",{href:!0});var i1t=s($O);IPo=r(i1t,"EncoderDecoderModel"),i1t.forEach(t),NPo=r(gke," (Encoder decoder model)"),gke.forEach(t),qPo=i(be),s2=n(be,"LI",{});var hke=s(s2);Wge=n(hke,"STRONG",{});var d1t=s(Wge);jPo=r(d1t,"fsmt"),d1t.forEach(t),DPo=r(hke," \u2014 "),kO=n(hke,"A",{href:!0});var c1t=s(kO);GPo=r(c1t,"FSMTForConditionalGeneration"),c1t.forEach(t),OPo=r(hke," (FairSeq Machine-Translation model)"),hke.forEach(t),VPo=i(be),l2=n(be,"LI",{});var pke=s(l2);Hge=n(pke,"STRONG",{});var f1t=s(Hge);XPo=r(f1t,"led"),f1t.forEach(t),zPo=r(pke," \u2014 "),SO=n(pke,"A",{href:!0});var m1t=s(SO);QPo=r(m1t,"LEDForConditionalGeneration"),m1t.forEach(t),WPo=r(pke," (LED model)"),pke.forEach(t),HPo=i(be),i2=n(be,"LI",{});var _ke=s(i2);Uge=n(_ke,"STRONG",{});var g1t=s(Uge);UPo=r(g1t,"longt5"),g1t.forEach(t),JPo=r(_ke," \u2014 "),RO=n(_ke,"A",{href:!0});var h1t=s(RO);YPo=r(h1t,"LongT5ForConditionalGeneration"),h1t.forEach(t),KPo=r(_ke," (LongT5 model)"),_ke.forEach(t),ZPo=i(be),d2=n(be,"LI",{});var uke=s(d2);Jge=n(uke,"STRONG",{});var p1t=s(Jge);eBo=r(p1t,"m2m_100"),p1t.forEach(t),oBo=r(uke," \u2014 "),PO=n(uke,"A",{href:!0});var _1t=s(PO);rBo=r(_1t,"M2M100ForConditionalGeneration"),_1t.forEach(t),tBo=r(uke," (M2M100 model)"),uke.forEach(t),aBo=i(be),c2=n(be,"LI",{});var bke=s(c2);Yge=n(bke,"STRONG",{});var u1t=s(Yge);nBo=r(u1t,"marian"),u1t.forEach(t),sBo=r(bke," \u2014 "),BO=n(bke,"A",{href:!0});var b1t=s(BO);lBo=r(b1t,"MarianMTModel"),b1t.forEach(t),iBo=r(bke," (Marian model)"),bke.forEach(t),dBo=i(be),f2=n(be,"LI",{});var vke=s(f2);Kge=n(vke,"STRONG",{});var v1t=s(Kge);cBo=r(v1t,"mbart"),v1t.forEach(t),fBo=r(vke," \u2014 "),IO=n(vke,"A",{href:!0});var F1t=s(IO);mBo=r(F1t,"MBartForConditionalGeneration"),F1t.forEach(t),gBo=r(vke," (mBART model)"),vke.forEach(t),hBo=i(be),m2=n(be,"LI",{});var Fke=s(m2);Zge=n(Fke,"STRONG",{});var T1t=s(Zge);pBo=r(T1t,"mt5"),T1t.forEach(t),_Bo=r(Fke," \u2014 "),NO=n(Fke,"A",{href:!0});var M1t=s(NO);uBo=r(M1t,"MT5ForConditionalGeneration"),M1t.forEach(t),bBo=r(Fke," (MT5 model)"),Fke.forEach(t),vBo=i(be),g2=n(be,"LI",{});var Tke=s(g2);ehe=n(Tke,"STRONG",{});var E1t=s(ehe);FBo=r(E1t,"pegasus"),E1t.forEach(t),TBo=r(Tke," \u2014 "),qO=n(Tke,"A",{href:!0});var C1t=s(qO);MBo=r(C1t,"PegasusForConditionalGeneration"),C1t.forEach(t),EBo=r(Tke," (Pegasus model)"),Tke.forEach(t),CBo=i(be),h2=n(be,"LI",{});var Mke=s(h2);ohe=n(Mke,"STRONG",{});var w1t=s(ohe);wBo=r(w1t,"plbart"),w1t.forEach(t),ABo=r(Mke," \u2014 "),jO=n(Mke,"A",{href:!0});var A1t=s(jO);LBo=r(A1t,"PLBartForConditionalGeneration"),A1t.forEach(t),yBo=r(Mke," (PLBart model)"),Mke.forEach(t),xBo=i(be),p2=n(be,"LI",{});var Eke=s(p2);rhe=n(Eke,"STRONG",{});var L1t=s(rhe);$Bo=r(L1t,"prophetnet"),L1t.forEach(t),kBo=r(Eke," \u2014 "),DO=n(Eke,"A",{href:!0});var y1t=s(DO);SBo=r(y1t,"ProphetNetForConditionalGeneration"),y1t.forEach(t),RBo=r(Eke," (ProphetNet model)"),Eke.forEach(t),PBo=i(be),_2=n(be,"LI",{});var Cke=s(_2);the=n(Cke,"STRONG",{});var x1t=s(the);BBo=r(x1t,"t5"),x1t.forEach(t),IBo=r(Cke," \u2014 "),GO=n(Cke,"A",{href:!0});var $1t=s(GO);NBo=r($1t,"T5ForConditionalGeneration"),$1t.forEach(t),qBo=r(Cke," (T5 model)"),Cke.forEach(t),jBo=i(be),u2=n(be,"LI",{});var wke=s(u2);ahe=n(wke,"STRONG",{});var k1t=s(ahe);DBo=r(k1t,"xlm-prophetnet"),k1t.forEach(t),GBo=r(wke," \u2014 "),OO=n(wke,"A",{href:!0});var S1t=s(OO);OBo=r(S1t,"XLMProphetNetForConditionalGeneration"),S1t.forEach(t),VBo=r(wke," (XLM-ProphetNet model)"),wke.forEach(t),be.forEach(t),XBo=i(ia),b2=n(ia,"P",{});var Ake=s(b2);zBo=r(Ake,"The model is set in evaluation mode by default using "),nhe=n(Ake,"CODE",{});var R1t=s(nhe);QBo=r(R1t,"model.eval()"),R1t.forEach(t),WBo=r(Ake,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),she=n(Ake,"CODE",{});var P1t=s(she);HBo=r(P1t,"model.train()"),P1t.forEach(t),Ake.forEach(t),UBo=i(ia),T(v2.$$.fragment,ia),ia.forEach(t),ol.forEach(t),iOe=i(f),Ji=n(f,"H2",{class:!0});var hXe=s(Ji);F2=n(hXe,"A",{id:!0,class:!0,href:!0});var B1t=s(F2);lhe=n(B1t,"SPAN",{});var I1t=s(lhe);T(Ay.$$.fragment,I1t),I1t.forEach(t),B1t.forEach(t),JBo=i(hXe),ihe=n(hXe,"SPAN",{});var N1t=s(ihe);YBo=r(N1t,"AutoModelForSequenceClassification"),N1t.forEach(t),hXe.forEach(t),dOe=i(f),Po=n(f,"DIV",{class:!0});var rl=s(Po);T(Ly.$$.fragment,rl),KBo=i(rl),Yi=n(rl,"P",{});var xoe=s(Yi);ZBo=r(xoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),VO=n(xoe,"A",{href:!0});var q1t=s(VO);eIo=r(q1t,"from_pretrained()"),q1t.forEach(t),oIo=r(xoe," class method or the "),XO=n(xoe,"A",{href:!0});var j1t=s(XO);rIo=r(j1t,"from_config()"),j1t.forEach(t),tIo=r(xoe,` class
method.`),xoe.forEach(t),aIo=i(rl),yy=n(rl,"P",{});var pXe=s(yy);nIo=r(pXe,"This class cannot be instantiated directly using "),dhe=n(pXe,"CODE",{});var D1t=s(dhe);sIo=r(D1t,"__init__()"),D1t.forEach(t),lIo=r(pXe," (throws an error)."),pXe.forEach(t),iIo=i(rl),ct=n(rl,"DIV",{class:!0});var GA=s(ct);T(xy.$$.fragment,GA),dIo=i(GA),che=n(GA,"P",{});var G1t=s(che);cIo=r(G1t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),G1t.forEach(t),fIo=i(GA),Ki=n(GA,"P",{});var $oe=s(Ki);mIo=r($oe,`Note:
Loading a model from its configuration file does `),fhe=n($oe,"STRONG",{});var O1t=s(fhe);gIo=r(O1t,"not"),O1t.forEach(t),hIo=r($oe,` load the model weights. It only affects the
model\u2019s configuration. Use `),zO=n($oe,"A",{href:!0});var V1t=s(zO);pIo=r(V1t,"from_pretrained()"),V1t.forEach(t),_Io=r($oe," to load the model weights."),$oe.forEach(t),uIo=i(GA),T(T2.$$.fragment,GA),GA.forEach(t),bIo=i(rl),oo=n(rl,"DIV",{class:!0});var da=s(oo);T($y.$$.fragment,da),vIo=i(da),mhe=n(da,"P",{});var X1t=s(mhe);FIo=r(X1t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),X1t.forEach(t),TIo=i(da),qa=n(da,"P",{});var OA=s(qa);MIo=r(OA,"The model class to instantiate is selected based on the "),ghe=n(OA,"CODE",{});var z1t=s(ghe);EIo=r(z1t,"model_type"),z1t.forEach(t),CIo=r(OA,` property of the config object (either
passed as an argument or loaded from `),hhe=n(OA,"CODE",{});var Q1t=s(hhe);wIo=r(Q1t,"pretrained_model_name_or_path"),Q1t.forEach(t),AIo=r(OA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),phe=n(OA,"CODE",{});var W1t=s(phe);LIo=r(W1t,"pretrained_model_name_or_path"),W1t.forEach(t),yIo=r(OA,":"),OA.forEach(t),xIo=i(da),N=n(da,"UL",{});var q=s(N);M2=n(q,"LI",{});var Lke=s(M2);_he=n(Lke,"STRONG",{});var H1t=s(_he);$Io=r(H1t,"albert"),H1t.forEach(t),kIo=r(Lke," \u2014 "),QO=n(Lke,"A",{href:!0});var U1t=s(QO);SIo=r(U1t,"AlbertForSequenceClassification"),U1t.forEach(t),RIo=r(Lke," (ALBERT model)"),Lke.forEach(t),PIo=i(q),E2=n(q,"LI",{});var yke=s(E2);uhe=n(yke,"STRONG",{});var J1t=s(uhe);BIo=r(J1t,"bart"),J1t.forEach(t),IIo=r(yke," \u2014 "),WO=n(yke,"A",{href:!0});var Y1t=s(WO);NIo=r(Y1t,"BartForSequenceClassification"),Y1t.forEach(t),qIo=r(yke," (BART model)"),yke.forEach(t),jIo=i(q),C2=n(q,"LI",{});var xke=s(C2);bhe=n(xke,"STRONG",{});var K1t=s(bhe);DIo=r(K1t,"bert"),K1t.forEach(t),GIo=r(xke," \u2014 "),HO=n(xke,"A",{href:!0});var Z1t=s(HO);OIo=r(Z1t,"BertForSequenceClassification"),Z1t.forEach(t),VIo=r(xke," (BERT model)"),xke.forEach(t),XIo=i(q),w2=n(q,"LI",{});var $ke=s(w2);vhe=n($ke,"STRONG",{});var e7t=s(vhe);zIo=r(e7t,"big_bird"),e7t.forEach(t),QIo=r($ke," \u2014 "),UO=n($ke,"A",{href:!0});var o7t=s(UO);WIo=r(o7t,"BigBirdForSequenceClassification"),o7t.forEach(t),HIo=r($ke," (BigBird model)"),$ke.forEach(t),UIo=i(q),A2=n(q,"LI",{});var kke=s(A2);Fhe=n(kke,"STRONG",{});var r7t=s(Fhe);JIo=r(r7t,"bigbird_pegasus"),r7t.forEach(t),YIo=r(kke," \u2014 "),JO=n(kke,"A",{href:!0});var t7t=s(JO);KIo=r(t7t,"BigBirdPegasusForSequenceClassification"),t7t.forEach(t),ZIo=r(kke," (BigBird-Pegasus model)"),kke.forEach(t),eNo=i(q),L2=n(q,"LI",{});var Ske=s(L2);The=n(Ske,"STRONG",{});var a7t=s(The);oNo=r(a7t,"bloom"),a7t.forEach(t),rNo=r(Ske," \u2014 "),YO=n(Ske,"A",{href:!0});var n7t=s(YO);tNo=r(n7t,"BloomForSequenceClassification"),n7t.forEach(t),aNo=r(Ske," (BLOOM model)"),Ske.forEach(t),nNo=i(q),y2=n(q,"LI",{});var Rke=s(y2);Mhe=n(Rke,"STRONG",{});var s7t=s(Mhe);sNo=r(s7t,"camembert"),s7t.forEach(t),lNo=r(Rke," \u2014 "),KO=n(Rke,"A",{href:!0});var l7t=s(KO);iNo=r(l7t,"CamembertForSequenceClassification"),l7t.forEach(t),dNo=r(Rke," (CamemBERT model)"),Rke.forEach(t),cNo=i(q),x2=n(q,"LI",{});var Pke=s(x2);Ehe=n(Pke,"STRONG",{});var i7t=s(Ehe);fNo=r(i7t,"canine"),i7t.forEach(t),mNo=r(Pke," \u2014 "),ZO=n(Pke,"A",{href:!0});var d7t=s(ZO);gNo=r(d7t,"CanineForSequenceClassification"),d7t.forEach(t),hNo=r(Pke," (CANINE model)"),Pke.forEach(t),pNo=i(q),$2=n(q,"LI",{});var Bke=s($2);Che=n(Bke,"STRONG",{});var c7t=s(Che);_No=r(c7t,"convbert"),c7t.forEach(t),uNo=r(Bke," \u2014 "),eV=n(Bke,"A",{href:!0});var f7t=s(eV);bNo=r(f7t,"ConvBertForSequenceClassification"),f7t.forEach(t),vNo=r(Bke," (ConvBERT model)"),Bke.forEach(t),FNo=i(q),k2=n(q,"LI",{});var Ike=s(k2);whe=n(Ike,"STRONG",{});var m7t=s(whe);TNo=r(m7t,"ctrl"),m7t.forEach(t),MNo=r(Ike," \u2014 "),oV=n(Ike,"A",{href:!0});var g7t=s(oV);ENo=r(g7t,"CTRLForSequenceClassification"),g7t.forEach(t),CNo=r(Ike," (CTRL model)"),Ike.forEach(t),wNo=i(q),S2=n(q,"LI",{});var Nke=s(S2);Ahe=n(Nke,"STRONG",{});var h7t=s(Ahe);ANo=r(h7t,"data2vec-text"),h7t.forEach(t),LNo=r(Nke," \u2014 "),rV=n(Nke,"A",{href:!0});var p7t=s(rV);yNo=r(p7t,"Data2VecTextForSequenceClassification"),p7t.forEach(t),xNo=r(Nke," (Data2VecText model)"),Nke.forEach(t),$No=i(q),R2=n(q,"LI",{});var qke=s(R2);Lhe=n(qke,"STRONG",{});var _7t=s(Lhe);kNo=r(_7t,"deberta"),_7t.forEach(t),SNo=r(qke," \u2014 "),tV=n(qke,"A",{href:!0});var u7t=s(tV);RNo=r(u7t,"DebertaForSequenceClassification"),u7t.forEach(t),PNo=r(qke," (DeBERTa model)"),qke.forEach(t),BNo=i(q),P2=n(q,"LI",{});var jke=s(P2);yhe=n(jke,"STRONG",{});var b7t=s(yhe);INo=r(b7t,"deberta-v2"),b7t.forEach(t),NNo=r(jke," \u2014 "),aV=n(jke,"A",{href:!0});var v7t=s(aV);qNo=r(v7t,"DebertaV2ForSequenceClassification"),v7t.forEach(t),jNo=r(jke," (DeBERTa-v2 model)"),jke.forEach(t),DNo=i(q),B2=n(q,"LI",{});var Dke=s(B2);xhe=n(Dke,"STRONG",{});var F7t=s(xhe);GNo=r(F7t,"distilbert"),F7t.forEach(t),ONo=r(Dke," \u2014 "),nV=n(Dke,"A",{href:!0});var T7t=s(nV);VNo=r(T7t,"DistilBertForSequenceClassification"),T7t.forEach(t),XNo=r(Dke," (DistilBERT model)"),Dke.forEach(t),zNo=i(q),I2=n(q,"LI",{});var Gke=s(I2);$he=n(Gke,"STRONG",{});var M7t=s($he);QNo=r(M7t,"electra"),M7t.forEach(t),WNo=r(Gke," \u2014 "),sV=n(Gke,"A",{href:!0});var E7t=s(sV);HNo=r(E7t,"ElectraForSequenceClassification"),E7t.forEach(t),UNo=r(Gke," (ELECTRA model)"),Gke.forEach(t),JNo=i(q),N2=n(q,"LI",{});var Oke=s(N2);khe=n(Oke,"STRONG",{});var C7t=s(khe);YNo=r(C7t,"flaubert"),C7t.forEach(t),KNo=r(Oke," \u2014 "),lV=n(Oke,"A",{href:!0});var w7t=s(lV);ZNo=r(w7t,"FlaubertForSequenceClassification"),w7t.forEach(t),eqo=r(Oke," (FlauBERT model)"),Oke.forEach(t),oqo=i(q),q2=n(q,"LI",{});var Vke=s(q2);She=n(Vke,"STRONG",{});var A7t=s(She);rqo=r(A7t,"fnet"),A7t.forEach(t),tqo=r(Vke," \u2014 "),iV=n(Vke,"A",{href:!0});var L7t=s(iV);aqo=r(L7t,"FNetForSequenceClassification"),L7t.forEach(t),nqo=r(Vke," (FNet model)"),Vke.forEach(t),sqo=i(q),j2=n(q,"LI",{});var Xke=s(j2);Rhe=n(Xke,"STRONG",{});var y7t=s(Rhe);lqo=r(y7t,"funnel"),y7t.forEach(t),iqo=r(Xke," \u2014 "),dV=n(Xke,"A",{href:!0});var x7t=s(dV);dqo=r(x7t,"FunnelForSequenceClassification"),x7t.forEach(t),cqo=r(Xke," (Funnel Transformer model)"),Xke.forEach(t),fqo=i(q),D2=n(q,"LI",{});var zke=s(D2);Phe=n(zke,"STRONG",{});var $7t=s(Phe);mqo=r($7t,"gpt2"),$7t.forEach(t),gqo=r(zke," \u2014 "),cV=n(zke,"A",{href:!0});var k7t=s(cV);hqo=r(k7t,"GPT2ForSequenceClassification"),k7t.forEach(t),pqo=r(zke," (OpenAI GPT-2 model)"),zke.forEach(t),_qo=i(q),G2=n(q,"LI",{});var Qke=s(G2);Bhe=n(Qke,"STRONG",{});var S7t=s(Bhe);uqo=r(S7t,"gpt_neo"),S7t.forEach(t),bqo=r(Qke," \u2014 "),fV=n(Qke,"A",{href:!0});var R7t=s(fV);vqo=r(R7t,"GPTNeoForSequenceClassification"),R7t.forEach(t),Fqo=r(Qke," (GPT Neo model)"),Qke.forEach(t),Tqo=i(q),O2=n(q,"LI",{});var Wke=s(O2);Ihe=n(Wke,"STRONG",{});var P7t=s(Ihe);Mqo=r(P7t,"gptj"),P7t.forEach(t),Eqo=r(Wke," \u2014 "),mV=n(Wke,"A",{href:!0});var B7t=s(mV);Cqo=r(B7t,"GPTJForSequenceClassification"),B7t.forEach(t),wqo=r(Wke," (GPT-J model)"),Wke.forEach(t),Aqo=i(q),V2=n(q,"LI",{});var Hke=s(V2);Nhe=n(Hke,"STRONG",{});var I7t=s(Nhe);Lqo=r(I7t,"ibert"),I7t.forEach(t),yqo=r(Hke," \u2014 "),gV=n(Hke,"A",{href:!0});var N7t=s(gV);xqo=r(N7t,"IBertForSequenceClassification"),N7t.forEach(t),$qo=r(Hke," (I-BERT model)"),Hke.forEach(t),kqo=i(q),X2=n(q,"LI",{});var Uke=s(X2);qhe=n(Uke,"STRONG",{});var q7t=s(qhe);Sqo=r(q7t,"layoutlm"),q7t.forEach(t),Rqo=r(Uke," \u2014 "),hV=n(Uke,"A",{href:!0});var j7t=s(hV);Pqo=r(j7t,"LayoutLMForSequenceClassification"),j7t.forEach(t),Bqo=r(Uke," (LayoutLM model)"),Uke.forEach(t),Iqo=i(q),z2=n(q,"LI",{});var Jke=s(z2);jhe=n(Jke,"STRONG",{});var D7t=s(jhe);Nqo=r(D7t,"layoutlmv2"),D7t.forEach(t),qqo=r(Jke," \u2014 "),pV=n(Jke,"A",{href:!0});var G7t=s(pV);jqo=r(G7t,"LayoutLMv2ForSequenceClassification"),G7t.forEach(t),Dqo=r(Jke," (LayoutLMv2 model)"),Jke.forEach(t),Gqo=i(q),Q2=n(q,"LI",{});var Yke=s(Q2);Dhe=n(Yke,"STRONG",{});var O7t=s(Dhe);Oqo=r(O7t,"layoutlmv3"),O7t.forEach(t),Vqo=r(Yke," \u2014 "),_V=n(Yke,"A",{href:!0});var V7t=s(_V);Xqo=r(V7t,"LayoutLMv3ForSequenceClassification"),V7t.forEach(t),zqo=r(Yke," (LayoutLMv3 model)"),Yke.forEach(t),Qqo=i(q),W2=n(q,"LI",{});var Kke=s(W2);Ghe=n(Kke,"STRONG",{});var X7t=s(Ghe);Wqo=r(X7t,"led"),X7t.forEach(t),Hqo=r(Kke," \u2014 "),uV=n(Kke,"A",{href:!0});var z7t=s(uV);Uqo=r(z7t,"LEDForSequenceClassification"),z7t.forEach(t),Jqo=r(Kke," (LED model)"),Kke.forEach(t),Yqo=i(q),H2=n(q,"LI",{});var Zke=s(H2);Ohe=n(Zke,"STRONG",{});var Q7t=s(Ohe);Kqo=r(Q7t,"longformer"),Q7t.forEach(t),Zqo=r(Zke," \u2014 "),bV=n(Zke,"A",{href:!0});var W7t=s(bV);ejo=r(W7t,"LongformerForSequenceClassification"),W7t.forEach(t),ojo=r(Zke," (Longformer model)"),Zke.forEach(t),rjo=i(q),U2=n(q,"LI",{});var eSe=s(U2);Vhe=n(eSe,"STRONG",{});var H7t=s(Vhe);tjo=r(H7t,"mbart"),H7t.forEach(t),ajo=r(eSe," \u2014 "),vV=n(eSe,"A",{href:!0});var U7t=s(vV);njo=r(U7t,"MBartForSequenceClassification"),U7t.forEach(t),sjo=r(eSe," (mBART model)"),eSe.forEach(t),ljo=i(q),J2=n(q,"LI",{});var oSe=s(J2);Xhe=n(oSe,"STRONG",{});var J7t=s(Xhe);ijo=r(J7t,"megatron-bert"),J7t.forEach(t),djo=r(oSe," \u2014 "),FV=n(oSe,"A",{href:!0});var Y7t=s(FV);cjo=r(Y7t,"MegatronBertForSequenceClassification"),Y7t.forEach(t),fjo=r(oSe," (Megatron-BERT model)"),oSe.forEach(t),mjo=i(q),Y2=n(q,"LI",{});var rSe=s(Y2);zhe=n(rSe,"STRONG",{});var K7t=s(zhe);gjo=r(K7t,"mobilebert"),K7t.forEach(t),hjo=r(rSe," \u2014 "),TV=n(rSe,"A",{href:!0});var Z7t=s(TV);pjo=r(Z7t,"MobileBertForSequenceClassification"),Z7t.forEach(t),_jo=r(rSe," (MobileBERT model)"),rSe.forEach(t),ujo=i(q),K2=n(q,"LI",{});var tSe=s(K2);Qhe=n(tSe,"STRONG",{});var e2t=s(Qhe);bjo=r(e2t,"mpnet"),e2t.forEach(t),vjo=r(tSe," \u2014 "),MV=n(tSe,"A",{href:!0});var o2t=s(MV);Fjo=r(o2t,"MPNetForSequenceClassification"),o2t.forEach(t),Tjo=r(tSe," (MPNet model)"),tSe.forEach(t),Mjo=i(q),Z2=n(q,"LI",{});var aSe=s(Z2);Whe=n(aSe,"STRONG",{});var r2t=s(Whe);Ejo=r(r2t,"nezha"),r2t.forEach(t),Cjo=r(aSe," \u2014 "),EV=n(aSe,"A",{href:!0});var t2t=s(EV);wjo=r(t2t,"NezhaForSequenceClassification"),t2t.forEach(t),Ajo=r(aSe," (Nezha model)"),aSe.forEach(t),Ljo=i(q),eb=n(q,"LI",{});var nSe=s(eb);Hhe=n(nSe,"STRONG",{});var a2t=s(Hhe);yjo=r(a2t,"nystromformer"),a2t.forEach(t),xjo=r(nSe," \u2014 "),CV=n(nSe,"A",{href:!0});var n2t=s(CV);$jo=r(n2t,"NystromformerForSequenceClassification"),n2t.forEach(t),kjo=r(nSe," (Nystr\xF6mformer model)"),nSe.forEach(t),Sjo=i(q),ob=n(q,"LI",{});var sSe=s(ob);Uhe=n(sSe,"STRONG",{});var s2t=s(Uhe);Rjo=r(s2t,"openai-gpt"),s2t.forEach(t),Pjo=r(sSe," \u2014 "),wV=n(sSe,"A",{href:!0});var l2t=s(wV);Bjo=r(l2t,"OpenAIGPTForSequenceClassification"),l2t.forEach(t),Ijo=r(sSe," (OpenAI GPT model)"),sSe.forEach(t),Njo=i(q),rb=n(q,"LI",{});var lSe=s(rb);Jhe=n(lSe,"STRONG",{});var i2t=s(Jhe);qjo=r(i2t,"perceiver"),i2t.forEach(t),jjo=r(lSe," \u2014 "),AV=n(lSe,"A",{href:!0});var d2t=s(AV);Djo=r(d2t,"PerceiverForSequenceClassification"),d2t.forEach(t),Gjo=r(lSe," (Perceiver model)"),lSe.forEach(t),Ojo=i(q),tb=n(q,"LI",{});var iSe=s(tb);Yhe=n(iSe,"STRONG",{});var c2t=s(Yhe);Vjo=r(c2t,"plbart"),c2t.forEach(t),Xjo=r(iSe," \u2014 "),LV=n(iSe,"A",{href:!0});var f2t=s(LV);zjo=r(f2t,"PLBartForSequenceClassification"),f2t.forEach(t),Qjo=r(iSe," (PLBart model)"),iSe.forEach(t),Wjo=i(q),ab=n(q,"LI",{});var dSe=s(ab);Khe=n(dSe,"STRONG",{});var m2t=s(Khe);Hjo=r(m2t,"qdqbert"),m2t.forEach(t),Ujo=r(dSe," \u2014 "),yV=n(dSe,"A",{href:!0});var g2t=s(yV);Jjo=r(g2t,"QDQBertForSequenceClassification"),g2t.forEach(t),Yjo=r(dSe," (QDQBert model)"),dSe.forEach(t),Kjo=i(q),nb=n(q,"LI",{});var cSe=s(nb);Zhe=n(cSe,"STRONG",{});var h2t=s(Zhe);Zjo=r(h2t,"reformer"),h2t.forEach(t),eDo=r(cSe," \u2014 "),xV=n(cSe,"A",{href:!0});var p2t=s(xV);oDo=r(p2t,"ReformerForSequenceClassification"),p2t.forEach(t),rDo=r(cSe," (Reformer model)"),cSe.forEach(t),tDo=i(q),sb=n(q,"LI",{});var fSe=s(sb);epe=n(fSe,"STRONG",{});var _2t=s(epe);aDo=r(_2t,"rembert"),_2t.forEach(t),nDo=r(fSe," \u2014 "),$V=n(fSe,"A",{href:!0});var u2t=s($V);sDo=r(u2t,"RemBertForSequenceClassification"),u2t.forEach(t),lDo=r(fSe," (RemBERT model)"),fSe.forEach(t),iDo=i(q),lb=n(q,"LI",{});var mSe=s(lb);ope=n(mSe,"STRONG",{});var b2t=s(ope);dDo=r(b2t,"roberta"),b2t.forEach(t),cDo=r(mSe," \u2014 "),kV=n(mSe,"A",{href:!0});var v2t=s(kV);fDo=r(v2t,"RobertaForSequenceClassification"),v2t.forEach(t),mDo=r(mSe," (RoBERTa model)"),mSe.forEach(t),gDo=i(q),ib=n(q,"LI",{});var gSe=s(ib);rpe=n(gSe,"STRONG",{});var F2t=s(rpe);hDo=r(F2t,"roformer"),F2t.forEach(t),pDo=r(gSe," \u2014 "),SV=n(gSe,"A",{href:!0});var T2t=s(SV);_Do=r(T2t,"RoFormerForSequenceClassification"),T2t.forEach(t),uDo=r(gSe," (RoFormer model)"),gSe.forEach(t),bDo=i(q),db=n(q,"LI",{});var hSe=s(db);tpe=n(hSe,"STRONG",{});var M2t=s(tpe);vDo=r(M2t,"squeezebert"),M2t.forEach(t),FDo=r(hSe," \u2014 "),RV=n(hSe,"A",{href:!0});var E2t=s(RV);TDo=r(E2t,"SqueezeBertForSequenceClassification"),E2t.forEach(t),MDo=r(hSe," (SqueezeBERT model)"),hSe.forEach(t),EDo=i(q),cb=n(q,"LI",{});var pSe=s(cb);ape=n(pSe,"STRONG",{});var C2t=s(ape);CDo=r(C2t,"tapas"),C2t.forEach(t),wDo=r(pSe," \u2014 "),PV=n(pSe,"A",{href:!0});var w2t=s(PV);ADo=r(w2t,"TapasForSequenceClassification"),w2t.forEach(t),LDo=r(pSe," (TAPAS model)"),pSe.forEach(t),yDo=i(q),fb=n(q,"LI",{});var _Se=s(fb);npe=n(_Se,"STRONG",{});var A2t=s(npe);xDo=r(A2t,"transfo-xl"),A2t.forEach(t),$Do=r(_Se," \u2014 "),BV=n(_Se,"A",{href:!0});var L2t=s(BV);kDo=r(L2t,"TransfoXLForSequenceClassification"),L2t.forEach(t),SDo=r(_Se," (Transformer-XL model)"),_Se.forEach(t),RDo=i(q),mb=n(q,"LI",{});var uSe=s(mb);spe=n(uSe,"STRONG",{});var y2t=s(spe);PDo=r(y2t,"xlm"),y2t.forEach(t),BDo=r(uSe," \u2014 "),IV=n(uSe,"A",{href:!0});var x2t=s(IV);IDo=r(x2t,"XLMForSequenceClassification"),x2t.forEach(t),NDo=r(uSe," (XLM model)"),uSe.forEach(t),qDo=i(q),gb=n(q,"LI",{});var bSe=s(gb);lpe=n(bSe,"STRONG",{});var $2t=s(lpe);jDo=r($2t,"xlm-roberta"),$2t.forEach(t),DDo=r(bSe," \u2014 "),NV=n(bSe,"A",{href:!0});var k2t=s(NV);GDo=r(k2t,"XLMRobertaForSequenceClassification"),k2t.forEach(t),ODo=r(bSe," (XLM-RoBERTa model)"),bSe.forEach(t),VDo=i(q),hb=n(q,"LI",{});var vSe=s(hb);ipe=n(vSe,"STRONG",{});var S2t=s(ipe);XDo=r(S2t,"xlm-roberta-xl"),S2t.forEach(t),zDo=r(vSe," \u2014 "),qV=n(vSe,"A",{href:!0});var R2t=s(qV);QDo=r(R2t,"XLMRobertaXLForSequenceClassification"),R2t.forEach(t),WDo=r(vSe," (XLM-RoBERTa-XL model)"),vSe.forEach(t),HDo=i(q),pb=n(q,"LI",{});var FSe=s(pb);dpe=n(FSe,"STRONG",{});var P2t=s(dpe);UDo=r(P2t,"xlnet"),P2t.forEach(t),JDo=r(FSe," \u2014 "),jV=n(FSe,"A",{href:!0});var B2t=s(jV);YDo=r(B2t,"XLNetForSequenceClassification"),B2t.forEach(t),KDo=r(FSe," (XLNet model)"),FSe.forEach(t),ZDo=i(q),_b=n(q,"LI",{});var TSe=s(_b);cpe=n(TSe,"STRONG",{});var I2t=s(cpe);eGo=r(I2t,"yoso"),I2t.forEach(t),oGo=r(TSe," \u2014 "),DV=n(TSe,"A",{href:!0});var N2t=s(DV);rGo=r(N2t,"YosoForSequenceClassification"),N2t.forEach(t),tGo=r(TSe," (YOSO model)"),TSe.forEach(t),q.forEach(t),aGo=i(da),ub=n(da,"P",{});var MSe=s(ub);nGo=r(MSe,"The model is set in evaluation mode by default using "),fpe=n(MSe,"CODE",{});var q2t=s(fpe);sGo=r(q2t,"model.eval()"),q2t.forEach(t),lGo=r(MSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mpe=n(MSe,"CODE",{});var j2t=s(mpe);iGo=r(j2t,"model.train()"),j2t.forEach(t),MSe.forEach(t),dGo=i(da),T(bb.$$.fragment,da),da.forEach(t),rl.forEach(t),cOe=i(f),Zi=n(f,"H2",{class:!0});var _Xe=s(Zi);vb=n(_Xe,"A",{id:!0,class:!0,href:!0});var D2t=s(vb);gpe=n(D2t,"SPAN",{});var G2t=s(gpe);T(ky.$$.fragment,G2t),G2t.forEach(t),D2t.forEach(t),cGo=i(_Xe),hpe=n(_Xe,"SPAN",{});var O2t=s(hpe);fGo=r(O2t,"AutoModelForMultipleChoice"),O2t.forEach(t),_Xe.forEach(t),fOe=i(f),Bo=n(f,"DIV",{class:!0});var tl=s(Bo);T(Sy.$$.fragment,tl),mGo=i(tl),ed=n(tl,"P",{});var koe=s(ed);gGo=r(koe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),GV=n(koe,"A",{href:!0});var V2t=s(GV);hGo=r(V2t,"from_pretrained()"),V2t.forEach(t),pGo=r(koe," class method or the "),OV=n(koe,"A",{href:!0});var X2t=s(OV);_Go=r(X2t,"from_config()"),X2t.forEach(t),uGo=r(koe,` class
method.`),koe.forEach(t),bGo=i(tl),Ry=n(tl,"P",{});var uXe=s(Ry);vGo=r(uXe,"This class cannot be instantiated directly using "),ppe=n(uXe,"CODE",{});var z2t=s(ppe);FGo=r(z2t,"__init__()"),z2t.forEach(t),TGo=r(uXe," (throws an error)."),uXe.forEach(t),MGo=i(tl),ft=n(tl,"DIV",{class:!0});var VA=s(ft);T(Py.$$.fragment,VA),EGo=i(VA),_pe=n(VA,"P",{});var Q2t=s(_pe);CGo=r(Q2t,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Q2t.forEach(t),wGo=i(VA),od=n(VA,"P",{});var Soe=s(od);AGo=r(Soe,`Note:
Loading a model from its configuration file does `),upe=n(Soe,"STRONG",{});var W2t=s(upe);LGo=r(W2t,"not"),W2t.forEach(t),yGo=r(Soe,` load the model weights. It only affects the
model\u2019s configuration. Use `),VV=n(Soe,"A",{href:!0});var H2t=s(VV);xGo=r(H2t,"from_pretrained()"),H2t.forEach(t),$Go=r(Soe," to load the model weights."),Soe.forEach(t),kGo=i(VA),T(Fb.$$.fragment,VA),VA.forEach(t),SGo=i(tl),ro=n(tl,"DIV",{class:!0});var ca=s(ro);T(By.$$.fragment,ca),RGo=i(ca),bpe=n(ca,"P",{});var U2t=s(bpe);PGo=r(U2t,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),U2t.forEach(t),BGo=i(ca),ja=n(ca,"P",{});var XA=s(ja);IGo=r(XA,"The model class to instantiate is selected based on the "),vpe=n(XA,"CODE",{});var J2t=s(vpe);NGo=r(J2t,"model_type"),J2t.forEach(t),qGo=r(XA,` property of the config object (either
passed as an argument or loaded from `),Fpe=n(XA,"CODE",{});var Y2t=s(Fpe);jGo=r(Y2t,"pretrained_model_name_or_path"),Y2t.forEach(t),DGo=r(XA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tpe=n(XA,"CODE",{});var K2t=s(Tpe);GGo=r(K2t,"pretrained_model_name_or_path"),K2t.forEach(t),OGo=r(XA,":"),XA.forEach(t),VGo=i(ca),Z=n(ca,"UL",{});var ee=s(Z);Tb=n(ee,"LI",{});var ESe=s(Tb);Mpe=n(ESe,"STRONG",{});var Z2t=s(Mpe);XGo=r(Z2t,"albert"),Z2t.forEach(t),zGo=r(ESe," \u2014 "),XV=n(ESe,"A",{href:!0});var ebt=s(XV);QGo=r(ebt,"AlbertForMultipleChoice"),ebt.forEach(t),WGo=r(ESe," (ALBERT model)"),ESe.forEach(t),HGo=i(ee),Mb=n(ee,"LI",{});var CSe=s(Mb);Epe=n(CSe,"STRONG",{});var obt=s(Epe);UGo=r(obt,"bert"),obt.forEach(t),JGo=r(CSe," \u2014 "),zV=n(CSe,"A",{href:!0});var rbt=s(zV);YGo=r(rbt,"BertForMultipleChoice"),rbt.forEach(t),KGo=r(CSe," (BERT model)"),CSe.forEach(t),ZGo=i(ee),Eb=n(ee,"LI",{});var wSe=s(Eb);Cpe=n(wSe,"STRONG",{});var tbt=s(Cpe);eOo=r(tbt,"big_bird"),tbt.forEach(t),oOo=r(wSe," \u2014 "),QV=n(wSe,"A",{href:!0});var abt=s(QV);rOo=r(abt,"BigBirdForMultipleChoice"),abt.forEach(t),tOo=r(wSe," (BigBird model)"),wSe.forEach(t),aOo=i(ee),Cb=n(ee,"LI",{});var ASe=s(Cb);wpe=n(ASe,"STRONG",{});var nbt=s(wpe);nOo=r(nbt,"camembert"),nbt.forEach(t),sOo=r(ASe," \u2014 "),WV=n(ASe,"A",{href:!0});var sbt=s(WV);lOo=r(sbt,"CamembertForMultipleChoice"),sbt.forEach(t),iOo=r(ASe," (CamemBERT model)"),ASe.forEach(t),dOo=i(ee),wb=n(ee,"LI",{});var LSe=s(wb);Ape=n(LSe,"STRONG",{});var lbt=s(Ape);cOo=r(lbt,"canine"),lbt.forEach(t),fOo=r(LSe," \u2014 "),HV=n(LSe,"A",{href:!0});var ibt=s(HV);mOo=r(ibt,"CanineForMultipleChoice"),ibt.forEach(t),gOo=r(LSe," (CANINE model)"),LSe.forEach(t),hOo=i(ee),Ab=n(ee,"LI",{});var ySe=s(Ab);Lpe=n(ySe,"STRONG",{});var dbt=s(Lpe);pOo=r(dbt,"convbert"),dbt.forEach(t),_Oo=r(ySe," \u2014 "),UV=n(ySe,"A",{href:!0});var cbt=s(UV);uOo=r(cbt,"ConvBertForMultipleChoice"),cbt.forEach(t),bOo=r(ySe," (ConvBERT model)"),ySe.forEach(t),vOo=i(ee),Lb=n(ee,"LI",{});var xSe=s(Lb);ype=n(xSe,"STRONG",{});var fbt=s(ype);FOo=r(fbt,"data2vec-text"),fbt.forEach(t),TOo=r(xSe," \u2014 "),JV=n(xSe,"A",{href:!0});var mbt=s(JV);MOo=r(mbt,"Data2VecTextForMultipleChoice"),mbt.forEach(t),EOo=r(xSe," (Data2VecText model)"),xSe.forEach(t),COo=i(ee),yb=n(ee,"LI",{});var $Se=s(yb);xpe=n($Se,"STRONG",{});var gbt=s(xpe);wOo=r(gbt,"deberta-v2"),gbt.forEach(t),AOo=r($Se," \u2014 "),YV=n($Se,"A",{href:!0});var hbt=s(YV);LOo=r(hbt,"DebertaV2ForMultipleChoice"),hbt.forEach(t),yOo=r($Se," (DeBERTa-v2 model)"),$Se.forEach(t),xOo=i(ee),xb=n(ee,"LI",{});var kSe=s(xb);$pe=n(kSe,"STRONG",{});var pbt=s($pe);$Oo=r(pbt,"distilbert"),pbt.forEach(t),kOo=r(kSe," \u2014 "),KV=n(kSe,"A",{href:!0});var _bt=s(KV);SOo=r(_bt,"DistilBertForMultipleChoice"),_bt.forEach(t),ROo=r(kSe," (DistilBERT model)"),kSe.forEach(t),POo=i(ee),$b=n(ee,"LI",{});var SSe=s($b);kpe=n(SSe,"STRONG",{});var ubt=s(kpe);BOo=r(ubt,"electra"),ubt.forEach(t),IOo=r(SSe," \u2014 "),ZV=n(SSe,"A",{href:!0});var bbt=s(ZV);NOo=r(bbt,"ElectraForMultipleChoice"),bbt.forEach(t),qOo=r(SSe," (ELECTRA model)"),SSe.forEach(t),jOo=i(ee),kb=n(ee,"LI",{});var RSe=s(kb);Spe=n(RSe,"STRONG",{});var vbt=s(Spe);DOo=r(vbt,"flaubert"),vbt.forEach(t),GOo=r(RSe," \u2014 "),eX=n(RSe,"A",{href:!0});var Fbt=s(eX);OOo=r(Fbt,"FlaubertForMultipleChoice"),Fbt.forEach(t),VOo=r(RSe," (FlauBERT model)"),RSe.forEach(t),XOo=i(ee),Sb=n(ee,"LI",{});var PSe=s(Sb);Rpe=n(PSe,"STRONG",{});var Tbt=s(Rpe);zOo=r(Tbt,"fnet"),Tbt.forEach(t),QOo=r(PSe," \u2014 "),oX=n(PSe,"A",{href:!0});var Mbt=s(oX);WOo=r(Mbt,"FNetForMultipleChoice"),Mbt.forEach(t),HOo=r(PSe," (FNet model)"),PSe.forEach(t),UOo=i(ee),Rb=n(ee,"LI",{});var BSe=s(Rb);Ppe=n(BSe,"STRONG",{});var Ebt=s(Ppe);JOo=r(Ebt,"funnel"),Ebt.forEach(t),YOo=r(BSe," \u2014 "),rX=n(BSe,"A",{href:!0});var Cbt=s(rX);KOo=r(Cbt,"FunnelForMultipleChoice"),Cbt.forEach(t),ZOo=r(BSe," (Funnel Transformer model)"),BSe.forEach(t),eVo=i(ee),Pb=n(ee,"LI",{});var ISe=s(Pb);Bpe=n(ISe,"STRONG",{});var wbt=s(Bpe);oVo=r(wbt,"ibert"),wbt.forEach(t),rVo=r(ISe," \u2014 "),tX=n(ISe,"A",{href:!0});var Abt=s(tX);tVo=r(Abt,"IBertForMultipleChoice"),Abt.forEach(t),aVo=r(ISe," (I-BERT model)"),ISe.forEach(t),nVo=i(ee),Bb=n(ee,"LI",{});var NSe=s(Bb);Ipe=n(NSe,"STRONG",{});var Lbt=s(Ipe);sVo=r(Lbt,"longformer"),Lbt.forEach(t),lVo=r(NSe," \u2014 "),aX=n(NSe,"A",{href:!0});var ybt=s(aX);iVo=r(ybt,"LongformerForMultipleChoice"),ybt.forEach(t),dVo=r(NSe," (Longformer model)"),NSe.forEach(t),cVo=i(ee),Ib=n(ee,"LI",{});var qSe=s(Ib);Npe=n(qSe,"STRONG",{});var xbt=s(Npe);fVo=r(xbt,"megatron-bert"),xbt.forEach(t),mVo=r(qSe," \u2014 "),nX=n(qSe,"A",{href:!0});var $bt=s(nX);gVo=r($bt,"MegatronBertForMultipleChoice"),$bt.forEach(t),hVo=r(qSe," (Megatron-BERT model)"),qSe.forEach(t),pVo=i(ee),Nb=n(ee,"LI",{});var jSe=s(Nb);qpe=n(jSe,"STRONG",{});var kbt=s(qpe);_Vo=r(kbt,"mobilebert"),kbt.forEach(t),uVo=r(jSe," \u2014 "),sX=n(jSe,"A",{href:!0});var Sbt=s(sX);bVo=r(Sbt,"MobileBertForMultipleChoice"),Sbt.forEach(t),vVo=r(jSe," (MobileBERT model)"),jSe.forEach(t),FVo=i(ee),qb=n(ee,"LI",{});var DSe=s(qb);jpe=n(DSe,"STRONG",{});var Rbt=s(jpe);TVo=r(Rbt,"mpnet"),Rbt.forEach(t),MVo=r(DSe," \u2014 "),lX=n(DSe,"A",{href:!0});var Pbt=s(lX);EVo=r(Pbt,"MPNetForMultipleChoice"),Pbt.forEach(t),CVo=r(DSe," (MPNet model)"),DSe.forEach(t),wVo=i(ee),jb=n(ee,"LI",{});var GSe=s(jb);Dpe=n(GSe,"STRONG",{});var Bbt=s(Dpe);AVo=r(Bbt,"nezha"),Bbt.forEach(t),LVo=r(GSe," \u2014 "),iX=n(GSe,"A",{href:!0});var Ibt=s(iX);yVo=r(Ibt,"NezhaForMultipleChoice"),Ibt.forEach(t),xVo=r(GSe," (Nezha model)"),GSe.forEach(t),$Vo=i(ee),Db=n(ee,"LI",{});var OSe=s(Db);Gpe=n(OSe,"STRONG",{});var Nbt=s(Gpe);kVo=r(Nbt,"nystromformer"),Nbt.forEach(t),SVo=r(OSe," \u2014 "),dX=n(OSe,"A",{href:!0});var qbt=s(dX);RVo=r(qbt,"NystromformerForMultipleChoice"),qbt.forEach(t),PVo=r(OSe," (Nystr\xF6mformer model)"),OSe.forEach(t),BVo=i(ee),Gb=n(ee,"LI",{});var VSe=s(Gb);Ope=n(VSe,"STRONG",{});var jbt=s(Ope);IVo=r(jbt,"qdqbert"),jbt.forEach(t),NVo=r(VSe," \u2014 "),cX=n(VSe,"A",{href:!0});var Dbt=s(cX);qVo=r(Dbt,"QDQBertForMultipleChoice"),Dbt.forEach(t),jVo=r(VSe," (QDQBert model)"),VSe.forEach(t),DVo=i(ee),Ob=n(ee,"LI",{});var XSe=s(Ob);Vpe=n(XSe,"STRONG",{});var Gbt=s(Vpe);GVo=r(Gbt,"rembert"),Gbt.forEach(t),OVo=r(XSe," \u2014 "),fX=n(XSe,"A",{href:!0});var Obt=s(fX);VVo=r(Obt,"RemBertForMultipleChoice"),Obt.forEach(t),XVo=r(XSe," (RemBERT model)"),XSe.forEach(t),zVo=i(ee),Vb=n(ee,"LI",{});var zSe=s(Vb);Xpe=n(zSe,"STRONG",{});var Vbt=s(Xpe);QVo=r(Vbt,"roberta"),Vbt.forEach(t),WVo=r(zSe," \u2014 "),mX=n(zSe,"A",{href:!0});var Xbt=s(mX);HVo=r(Xbt,"RobertaForMultipleChoice"),Xbt.forEach(t),UVo=r(zSe," (RoBERTa model)"),zSe.forEach(t),JVo=i(ee),Xb=n(ee,"LI",{});var QSe=s(Xb);zpe=n(QSe,"STRONG",{});var zbt=s(zpe);YVo=r(zbt,"roformer"),zbt.forEach(t),KVo=r(QSe," \u2014 "),gX=n(QSe,"A",{href:!0});var Qbt=s(gX);ZVo=r(Qbt,"RoFormerForMultipleChoice"),Qbt.forEach(t),eXo=r(QSe," (RoFormer model)"),QSe.forEach(t),oXo=i(ee),zb=n(ee,"LI",{});var WSe=s(zb);Qpe=n(WSe,"STRONG",{});var Wbt=s(Qpe);rXo=r(Wbt,"squeezebert"),Wbt.forEach(t),tXo=r(WSe," \u2014 "),hX=n(WSe,"A",{href:!0});var Hbt=s(hX);aXo=r(Hbt,"SqueezeBertForMultipleChoice"),Hbt.forEach(t),nXo=r(WSe," (SqueezeBERT model)"),WSe.forEach(t),sXo=i(ee),Qb=n(ee,"LI",{});var HSe=s(Qb);Wpe=n(HSe,"STRONG",{});var Ubt=s(Wpe);lXo=r(Ubt,"xlm"),Ubt.forEach(t),iXo=r(HSe," \u2014 "),pX=n(HSe,"A",{href:!0});var Jbt=s(pX);dXo=r(Jbt,"XLMForMultipleChoice"),Jbt.forEach(t),cXo=r(HSe," (XLM model)"),HSe.forEach(t),fXo=i(ee),Wb=n(ee,"LI",{});var USe=s(Wb);Hpe=n(USe,"STRONG",{});var Ybt=s(Hpe);mXo=r(Ybt,"xlm-roberta"),Ybt.forEach(t),gXo=r(USe," \u2014 "),_X=n(USe,"A",{href:!0});var Kbt=s(_X);hXo=r(Kbt,"XLMRobertaForMultipleChoice"),Kbt.forEach(t),pXo=r(USe," (XLM-RoBERTa model)"),USe.forEach(t),_Xo=i(ee),Hb=n(ee,"LI",{});var JSe=s(Hb);Upe=n(JSe,"STRONG",{});var Zbt=s(Upe);uXo=r(Zbt,"xlm-roberta-xl"),Zbt.forEach(t),bXo=r(JSe," \u2014 "),uX=n(JSe,"A",{href:!0});var e5t=s(uX);vXo=r(e5t,"XLMRobertaXLForMultipleChoice"),e5t.forEach(t),FXo=r(JSe," (XLM-RoBERTa-XL model)"),JSe.forEach(t),TXo=i(ee),Ub=n(ee,"LI",{});var YSe=s(Ub);Jpe=n(YSe,"STRONG",{});var o5t=s(Jpe);MXo=r(o5t,"xlnet"),o5t.forEach(t),EXo=r(YSe," \u2014 "),bX=n(YSe,"A",{href:!0});var r5t=s(bX);CXo=r(r5t,"XLNetForMultipleChoice"),r5t.forEach(t),wXo=r(YSe," (XLNet model)"),YSe.forEach(t),AXo=i(ee),Jb=n(ee,"LI",{});var KSe=s(Jb);Ype=n(KSe,"STRONG",{});var t5t=s(Ype);LXo=r(t5t,"yoso"),t5t.forEach(t),yXo=r(KSe," \u2014 "),vX=n(KSe,"A",{href:!0});var a5t=s(vX);xXo=r(a5t,"YosoForMultipleChoice"),a5t.forEach(t),$Xo=r(KSe," (YOSO model)"),KSe.forEach(t),ee.forEach(t),kXo=i(ca),Yb=n(ca,"P",{});var ZSe=s(Yb);SXo=r(ZSe,"The model is set in evaluation mode by default using "),Kpe=n(ZSe,"CODE",{});var n5t=s(Kpe);RXo=r(n5t,"model.eval()"),n5t.forEach(t),PXo=r(ZSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Zpe=n(ZSe,"CODE",{});var s5t=s(Zpe);BXo=r(s5t,"model.train()"),s5t.forEach(t),ZSe.forEach(t),IXo=i(ca),T(Kb.$$.fragment,ca),ca.forEach(t),tl.forEach(t),mOe=i(f),rd=n(f,"H2",{class:!0});var bXe=s(rd);Zb=n(bXe,"A",{id:!0,class:!0,href:!0});var l5t=s(Zb);e_e=n(l5t,"SPAN",{});var i5t=s(e_e);T(Iy.$$.fragment,i5t),i5t.forEach(t),l5t.forEach(t),NXo=i(bXe),o_e=n(bXe,"SPAN",{});var d5t=s(o_e);qXo=r(d5t,"AutoModelForNextSentencePrediction"),d5t.forEach(t),bXe.forEach(t),gOe=i(f),Io=n(f,"DIV",{class:!0});var al=s(Io);T(Ny.$$.fragment,al),jXo=i(al),td=n(al,"P",{});var Roe=s(td);DXo=r(Roe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),FX=n(Roe,"A",{href:!0});var c5t=s(FX);GXo=r(c5t,"from_pretrained()"),c5t.forEach(t),OXo=r(Roe," class method or the "),TX=n(Roe,"A",{href:!0});var f5t=s(TX);VXo=r(f5t,"from_config()"),f5t.forEach(t),XXo=r(Roe,` class
method.`),Roe.forEach(t),zXo=i(al),qy=n(al,"P",{});var vXe=s(qy);QXo=r(vXe,"This class cannot be instantiated directly using "),r_e=n(vXe,"CODE",{});var m5t=s(r_e);WXo=r(m5t,"__init__()"),m5t.forEach(t),HXo=r(vXe," (throws an error)."),vXe.forEach(t),UXo=i(al),mt=n(al,"DIV",{class:!0});var zA=s(mt);T(jy.$$.fragment,zA),JXo=i(zA),t_e=n(zA,"P",{});var g5t=s(t_e);YXo=r(g5t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),g5t.forEach(t),KXo=i(zA),ad=n(zA,"P",{});var Poe=s(ad);ZXo=r(Poe,`Note:
Loading a model from its configuration file does `),a_e=n(Poe,"STRONG",{});var h5t=s(a_e);ezo=r(h5t,"not"),h5t.forEach(t),ozo=r(Poe,` load the model weights. It only affects the
model\u2019s configuration. Use `),MX=n(Poe,"A",{href:!0});var p5t=s(MX);rzo=r(p5t,"from_pretrained()"),p5t.forEach(t),tzo=r(Poe," to load the model weights."),Poe.forEach(t),azo=i(zA),T(e5.$$.fragment,zA),zA.forEach(t),nzo=i(al),to=n(al,"DIV",{class:!0});var fa=s(to);T(Dy.$$.fragment,fa),szo=i(fa),n_e=n(fa,"P",{});var _5t=s(n_e);lzo=r(_5t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),_5t.forEach(t),izo=i(fa),Da=n(fa,"P",{});var QA=s(Da);dzo=r(QA,"The model class to instantiate is selected based on the "),s_e=n(QA,"CODE",{});var u5t=s(s_e);czo=r(u5t,"model_type"),u5t.forEach(t),fzo=r(QA,` property of the config object (either
passed as an argument or loaded from `),l_e=n(QA,"CODE",{});var b5t=s(l_e);mzo=r(b5t,"pretrained_model_name_or_path"),b5t.forEach(t),gzo=r(QA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i_e=n(QA,"CODE",{});var v5t=s(i_e);hzo=r(v5t,"pretrained_model_name_or_path"),v5t.forEach(t),pzo=r(QA,":"),QA.forEach(t),_zo=i(fa),No=n(fa,"UL",{});var ma=s(No);o5=n(ma,"LI",{});var eRe=s(o5);d_e=n(eRe,"STRONG",{});var F5t=s(d_e);uzo=r(F5t,"bert"),F5t.forEach(t),bzo=r(eRe," \u2014 "),EX=n(eRe,"A",{href:!0});var T5t=s(EX);vzo=r(T5t,"BertForNextSentencePrediction"),T5t.forEach(t),Fzo=r(eRe," (BERT model)"),eRe.forEach(t),Tzo=i(ma),r5=n(ma,"LI",{});var oRe=s(r5);c_e=n(oRe,"STRONG",{});var M5t=s(c_e);Mzo=r(M5t,"fnet"),M5t.forEach(t),Ezo=r(oRe," \u2014 "),CX=n(oRe,"A",{href:!0});var E5t=s(CX);Czo=r(E5t,"FNetForNextSentencePrediction"),E5t.forEach(t),wzo=r(oRe," (FNet model)"),oRe.forEach(t),Azo=i(ma),t5=n(ma,"LI",{});var rRe=s(t5);f_e=n(rRe,"STRONG",{});var C5t=s(f_e);Lzo=r(C5t,"megatron-bert"),C5t.forEach(t),yzo=r(rRe," \u2014 "),wX=n(rRe,"A",{href:!0});var w5t=s(wX);xzo=r(w5t,"MegatronBertForNextSentencePrediction"),w5t.forEach(t),$zo=r(rRe," (Megatron-BERT model)"),rRe.forEach(t),kzo=i(ma),a5=n(ma,"LI",{});var tRe=s(a5);m_e=n(tRe,"STRONG",{});var A5t=s(m_e);Szo=r(A5t,"mobilebert"),A5t.forEach(t),Rzo=r(tRe," \u2014 "),AX=n(tRe,"A",{href:!0});var L5t=s(AX);Pzo=r(L5t,"MobileBertForNextSentencePrediction"),L5t.forEach(t),Bzo=r(tRe," (MobileBERT model)"),tRe.forEach(t),Izo=i(ma),n5=n(ma,"LI",{});var aRe=s(n5);g_e=n(aRe,"STRONG",{});var y5t=s(g_e);Nzo=r(y5t,"nezha"),y5t.forEach(t),qzo=r(aRe," \u2014 "),LX=n(aRe,"A",{href:!0});var x5t=s(LX);jzo=r(x5t,"NezhaForNextSentencePrediction"),x5t.forEach(t),Dzo=r(aRe," (Nezha model)"),aRe.forEach(t),Gzo=i(ma),s5=n(ma,"LI",{});var nRe=s(s5);h_e=n(nRe,"STRONG",{});var $5t=s(h_e);Ozo=r($5t,"qdqbert"),$5t.forEach(t),Vzo=r(nRe," \u2014 "),yX=n(nRe,"A",{href:!0});var k5t=s(yX);Xzo=r(k5t,"QDQBertForNextSentencePrediction"),k5t.forEach(t),zzo=r(nRe," (QDQBert model)"),nRe.forEach(t),ma.forEach(t),Qzo=i(fa),l5=n(fa,"P",{});var sRe=s(l5);Wzo=r(sRe,"The model is set in evaluation mode by default using "),p_e=n(sRe,"CODE",{});var S5t=s(p_e);Hzo=r(S5t,"model.eval()"),S5t.forEach(t),Uzo=r(sRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),__e=n(sRe,"CODE",{});var R5t=s(__e);Jzo=r(R5t,"model.train()"),R5t.forEach(t),sRe.forEach(t),Yzo=i(fa),T(i5.$$.fragment,fa),fa.forEach(t),al.forEach(t),hOe=i(f),nd=n(f,"H2",{class:!0});var FXe=s(nd);d5=n(FXe,"A",{id:!0,class:!0,href:!0});var P5t=s(d5);u_e=n(P5t,"SPAN",{});var B5t=s(u_e);T(Gy.$$.fragment,B5t),B5t.forEach(t),P5t.forEach(t),Kzo=i(FXe),b_e=n(FXe,"SPAN",{});var I5t=s(b_e);Zzo=r(I5t,"AutoModelForTokenClassification"),I5t.forEach(t),FXe.forEach(t),pOe=i(f),qo=n(f,"DIV",{class:!0});var nl=s(qo);T(Oy.$$.fragment,nl),eQo=i(nl),sd=n(nl,"P",{});var Boe=s(sd);oQo=r(Boe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),xX=n(Boe,"A",{href:!0});var N5t=s(xX);rQo=r(N5t,"from_pretrained()"),N5t.forEach(t),tQo=r(Boe," class method or the "),$X=n(Boe,"A",{href:!0});var q5t=s($X);aQo=r(q5t,"from_config()"),q5t.forEach(t),nQo=r(Boe,` class
method.`),Boe.forEach(t),sQo=i(nl),Vy=n(nl,"P",{});var TXe=s(Vy);lQo=r(TXe,"This class cannot be instantiated directly using "),v_e=n(TXe,"CODE",{});var j5t=s(v_e);iQo=r(j5t,"__init__()"),j5t.forEach(t),dQo=r(TXe," (throws an error)."),TXe.forEach(t),cQo=i(nl),gt=n(nl,"DIV",{class:!0});var WA=s(gt);T(Xy.$$.fragment,WA),fQo=i(WA),F_e=n(WA,"P",{});var D5t=s(F_e);mQo=r(D5t,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),D5t.forEach(t),gQo=i(WA),ld=n(WA,"P",{});var Ioe=s(ld);hQo=r(Ioe,`Note:
Loading a model from its configuration file does `),T_e=n(Ioe,"STRONG",{});var G5t=s(T_e);pQo=r(G5t,"not"),G5t.forEach(t),_Qo=r(Ioe,` load the model weights. It only affects the
model\u2019s configuration. Use `),kX=n(Ioe,"A",{href:!0});var O5t=s(kX);uQo=r(O5t,"from_pretrained()"),O5t.forEach(t),bQo=r(Ioe," to load the model weights."),Ioe.forEach(t),vQo=i(WA),T(c5.$$.fragment,WA),WA.forEach(t),FQo=i(nl),ao=n(nl,"DIV",{class:!0});var ga=s(ao);T(zy.$$.fragment,ga),TQo=i(ga),M_e=n(ga,"P",{});var V5t=s(M_e);MQo=r(V5t,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),V5t.forEach(t),EQo=i(ga),Ga=n(ga,"P",{});var HA=s(Ga);CQo=r(HA,"The model class to instantiate is selected based on the "),E_e=n(HA,"CODE",{});var X5t=s(E_e);wQo=r(X5t,"model_type"),X5t.forEach(t),AQo=r(HA,` property of the config object (either
passed as an argument or loaded from `),C_e=n(HA,"CODE",{});var z5t=s(C_e);LQo=r(z5t,"pretrained_model_name_or_path"),z5t.forEach(t),yQo=r(HA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w_e=n(HA,"CODE",{});var Q5t=s(w_e);xQo=r(Q5t,"pretrained_model_name_or_path"),Q5t.forEach(t),$Qo=r(HA,":"),HA.forEach(t),kQo=i(ga),H=n(ga,"UL",{});var J=s(H);f5=n(J,"LI",{});var lRe=s(f5);A_e=n(lRe,"STRONG",{});var W5t=s(A_e);SQo=r(W5t,"albert"),W5t.forEach(t),RQo=r(lRe," \u2014 "),SX=n(lRe,"A",{href:!0});var H5t=s(SX);PQo=r(H5t,"AlbertForTokenClassification"),H5t.forEach(t),BQo=r(lRe," (ALBERT model)"),lRe.forEach(t),IQo=i(J),m5=n(J,"LI",{});var iRe=s(m5);L_e=n(iRe,"STRONG",{});var U5t=s(L_e);NQo=r(U5t,"bert"),U5t.forEach(t),qQo=r(iRe," \u2014 "),RX=n(iRe,"A",{href:!0});var J5t=s(RX);jQo=r(J5t,"BertForTokenClassification"),J5t.forEach(t),DQo=r(iRe," (BERT model)"),iRe.forEach(t),GQo=i(J),g5=n(J,"LI",{});var dRe=s(g5);y_e=n(dRe,"STRONG",{});var Y5t=s(y_e);OQo=r(Y5t,"big_bird"),Y5t.forEach(t),VQo=r(dRe," \u2014 "),PX=n(dRe,"A",{href:!0});var K5t=s(PX);XQo=r(K5t,"BigBirdForTokenClassification"),K5t.forEach(t),zQo=r(dRe," (BigBird model)"),dRe.forEach(t),QQo=i(J),h5=n(J,"LI",{});var cRe=s(h5);x_e=n(cRe,"STRONG",{});var Z5t=s(x_e);WQo=r(Z5t,"bloom"),Z5t.forEach(t),HQo=r(cRe," \u2014 "),BX=n(cRe,"A",{href:!0});var evt=s(BX);UQo=r(evt,"BloomForTokenClassification"),evt.forEach(t),JQo=r(cRe," (BLOOM model)"),cRe.forEach(t),YQo=i(J),p5=n(J,"LI",{});var fRe=s(p5);$_e=n(fRe,"STRONG",{});var ovt=s($_e);KQo=r(ovt,"camembert"),ovt.forEach(t),ZQo=r(fRe," \u2014 "),IX=n(fRe,"A",{href:!0});var rvt=s(IX);eWo=r(rvt,"CamembertForTokenClassification"),rvt.forEach(t),oWo=r(fRe," (CamemBERT model)"),fRe.forEach(t),rWo=i(J),_5=n(J,"LI",{});var mRe=s(_5);k_e=n(mRe,"STRONG",{});var tvt=s(k_e);tWo=r(tvt,"canine"),tvt.forEach(t),aWo=r(mRe," \u2014 "),NX=n(mRe,"A",{href:!0});var avt=s(NX);nWo=r(avt,"CanineForTokenClassification"),avt.forEach(t),sWo=r(mRe," (CANINE model)"),mRe.forEach(t),lWo=i(J),u5=n(J,"LI",{});var gRe=s(u5);S_e=n(gRe,"STRONG",{});var nvt=s(S_e);iWo=r(nvt,"convbert"),nvt.forEach(t),dWo=r(gRe," \u2014 "),qX=n(gRe,"A",{href:!0});var svt=s(qX);cWo=r(svt,"ConvBertForTokenClassification"),svt.forEach(t),fWo=r(gRe," (ConvBERT model)"),gRe.forEach(t),mWo=i(J),b5=n(J,"LI",{});var hRe=s(b5);R_e=n(hRe,"STRONG",{});var lvt=s(R_e);gWo=r(lvt,"data2vec-text"),lvt.forEach(t),hWo=r(hRe," \u2014 "),jX=n(hRe,"A",{href:!0});var ivt=s(jX);pWo=r(ivt,"Data2VecTextForTokenClassification"),ivt.forEach(t),_Wo=r(hRe," (Data2VecText model)"),hRe.forEach(t),uWo=i(J),v5=n(J,"LI",{});var pRe=s(v5);P_e=n(pRe,"STRONG",{});var dvt=s(P_e);bWo=r(dvt,"deberta"),dvt.forEach(t),vWo=r(pRe," \u2014 "),DX=n(pRe,"A",{href:!0});var cvt=s(DX);FWo=r(cvt,"DebertaForTokenClassification"),cvt.forEach(t),TWo=r(pRe," (DeBERTa model)"),pRe.forEach(t),MWo=i(J),F5=n(J,"LI",{});var _Re=s(F5);B_e=n(_Re,"STRONG",{});var fvt=s(B_e);EWo=r(fvt,"deberta-v2"),fvt.forEach(t),CWo=r(_Re," \u2014 "),GX=n(_Re,"A",{href:!0});var mvt=s(GX);wWo=r(mvt,"DebertaV2ForTokenClassification"),mvt.forEach(t),AWo=r(_Re," (DeBERTa-v2 model)"),_Re.forEach(t),LWo=i(J),T5=n(J,"LI",{});var uRe=s(T5);I_e=n(uRe,"STRONG",{});var gvt=s(I_e);yWo=r(gvt,"distilbert"),gvt.forEach(t),xWo=r(uRe," \u2014 "),OX=n(uRe,"A",{href:!0});var hvt=s(OX);$Wo=r(hvt,"DistilBertForTokenClassification"),hvt.forEach(t),kWo=r(uRe," (DistilBERT model)"),uRe.forEach(t),SWo=i(J),M5=n(J,"LI",{});var bRe=s(M5);N_e=n(bRe,"STRONG",{});var pvt=s(N_e);RWo=r(pvt,"electra"),pvt.forEach(t),PWo=r(bRe," \u2014 "),VX=n(bRe,"A",{href:!0});var _vt=s(VX);BWo=r(_vt,"ElectraForTokenClassification"),_vt.forEach(t),IWo=r(bRe," (ELECTRA model)"),bRe.forEach(t),NWo=i(J),E5=n(J,"LI",{});var vRe=s(E5);q_e=n(vRe,"STRONG",{});var uvt=s(q_e);qWo=r(uvt,"flaubert"),uvt.forEach(t),jWo=r(vRe," \u2014 "),XX=n(vRe,"A",{href:!0});var bvt=s(XX);DWo=r(bvt,"FlaubertForTokenClassification"),bvt.forEach(t),GWo=r(vRe," (FlauBERT model)"),vRe.forEach(t),OWo=i(J),C5=n(J,"LI",{});var FRe=s(C5);j_e=n(FRe,"STRONG",{});var vvt=s(j_e);VWo=r(vvt,"fnet"),vvt.forEach(t),XWo=r(FRe," \u2014 "),zX=n(FRe,"A",{href:!0});var Fvt=s(zX);zWo=r(Fvt,"FNetForTokenClassification"),Fvt.forEach(t),QWo=r(FRe," (FNet model)"),FRe.forEach(t),WWo=i(J),w5=n(J,"LI",{});var TRe=s(w5);D_e=n(TRe,"STRONG",{});var Tvt=s(D_e);HWo=r(Tvt,"funnel"),Tvt.forEach(t),UWo=r(TRe," \u2014 "),QX=n(TRe,"A",{href:!0});var Mvt=s(QX);JWo=r(Mvt,"FunnelForTokenClassification"),Mvt.forEach(t),YWo=r(TRe," (Funnel Transformer model)"),TRe.forEach(t),KWo=i(J),A5=n(J,"LI",{});var MRe=s(A5);G_e=n(MRe,"STRONG",{});var Evt=s(G_e);ZWo=r(Evt,"gpt2"),Evt.forEach(t),eHo=r(MRe," \u2014 "),WX=n(MRe,"A",{href:!0});var Cvt=s(WX);oHo=r(Cvt,"GPT2ForTokenClassification"),Cvt.forEach(t),rHo=r(MRe," (OpenAI GPT-2 model)"),MRe.forEach(t),tHo=i(J),L5=n(J,"LI",{});var ERe=s(L5);O_e=n(ERe,"STRONG",{});var wvt=s(O_e);aHo=r(wvt,"ibert"),wvt.forEach(t),nHo=r(ERe," \u2014 "),HX=n(ERe,"A",{href:!0});var Avt=s(HX);sHo=r(Avt,"IBertForTokenClassification"),Avt.forEach(t),lHo=r(ERe," (I-BERT model)"),ERe.forEach(t),iHo=i(J),y5=n(J,"LI",{});var CRe=s(y5);V_e=n(CRe,"STRONG",{});var Lvt=s(V_e);dHo=r(Lvt,"layoutlm"),Lvt.forEach(t),cHo=r(CRe," \u2014 "),UX=n(CRe,"A",{href:!0});var yvt=s(UX);fHo=r(yvt,"LayoutLMForTokenClassification"),yvt.forEach(t),mHo=r(CRe," (LayoutLM model)"),CRe.forEach(t),gHo=i(J),x5=n(J,"LI",{});var wRe=s(x5);X_e=n(wRe,"STRONG",{});var xvt=s(X_e);hHo=r(xvt,"layoutlmv2"),xvt.forEach(t),pHo=r(wRe," \u2014 "),JX=n(wRe,"A",{href:!0});var $vt=s(JX);_Ho=r($vt,"LayoutLMv2ForTokenClassification"),$vt.forEach(t),uHo=r(wRe," (LayoutLMv2 model)"),wRe.forEach(t),bHo=i(J),$5=n(J,"LI",{});var ARe=s($5);z_e=n(ARe,"STRONG",{});var kvt=s(z_e);vHo=r(kvt,"layoutlmv3"),kvt.forEach(t),FHo=r(ARe," \u2014 "),YX=n(ARe,"A",{href:!0});var Svt=s(YX);THo=r(Svt,"LayoutLMv3ForTokenClassification"),Svt.forEach(t),MHo=r(ARe," (LayoutLMv3 model)"),ARe.forEach(t),EHo=i(J),k5=n(J,"LI",{});var LRe=s(k5);Q_e=n(LRe,"STRONG",{});var Rvt=s(Q_e);CHo=r(Rvt,"longformer"),Rvt.forEach(t),wHo=r(LRe," \u2014 "),KX=n(LRe,"A",{href:!0});var Pvt=s(KX);AHo=r(Pvt,"LongformerForTokenClassification"),Pvt.forEach(t),LHo=r(LRe," (Longformer model)"),LRe.forEach(t),yHo=i(J),S5=n(J,"LI",{});var yRe=s(S5);W_e=n(yRe,"STRONG",{});var Bvt=s(W_e);xHo=r(Bvt,"megatron-bert"),Bvt.forEach(t),$Ho=r(yRe," \u2014 "),ZX=n(yRe,"A",{href:!0});var Ivt=s(ZX);kHo=r(Ivt,"MegatronBertForTokenClassification"),Ivt.forEach(t),SHo=r(yRe," (Megatron-BERT model)"),yRe.forEach(t),RHo=i(J),R5=n(J,"LI",{});var xRe=s(R5);H_e=n(xRe,"STRONG",{});var Nvt=s(H_e);PHo=r(Nvt,"mobilebert"),Nvt.forEach(t),BHo=r(xRe," \u2014 "),ez=n(xRe,"A",{href:!0});var qvt=s(ez);IHo=r(qvt,"MobileBertForTokenClassification"),qvt.forEach(t),NHo=r(xRe," (MobileBERT model)"),xRe.forEach(t),qHo=i(J),P5=n(J,"LI",{});var $Re=s(P5);U_e=n($Re,"STRONG",{});var jvt=s(U_e);jHo=r(jvt,"mpnet"),jvt.forEach(t),DHo=r($Re," \u2014 "),oz=n($Re,"A",{href:!0});var Dvt=s(oz);GHo=r(Dvt,"MPNetForTokenClassification"),Dvt.forEach(t),OHo=r($Re," (MPNet model)"),$Re.forEach(t),VHo=i(J),B5=n(J,"LI",{});var kRe=s(B5);J_e=n(kRe,"STRONG",{});var Gvt=s(J_e);XHo=r(Gvt,"nezha"),Gvt.forEach(t),zHo=r(kRe," \u2014 "),rz=n(kRe,"A",{href:!0});var Ovt=s(rz);QHo=r(Ovt,"NezhaForTokenClassification"),Ovt.forEach(t),WHo=r(kRe," (Nezha model)"),kRe.forEach(t),HHo=i(J),I5=n(J,"LI",{});var SRe=s(I5);Y_e=n(SRe,"STRONG",{});var Vvt=s(Y_e);UHo=r(Vvt,"nystromformer"),Vvt.forEach(t),JHo=r(SRe," \u2014 "),tz=n(SRe,"A",{href:!0});var Xvt=s(tz);YHo=r(Xvt,"NystromformerForTokenClassification"),Xvt.forEach(t),KHo=r(SRe," (Nystr\xF6mformer model)"),SRe.forEach(t),ZHo=i(J),N5=n(J,"LI",{});var RRe=s(N5);K_e=n(RRe,"STRONG",{});var zvt=s(K_e);eUo=r(zvt,"qdqbert"),zvt.forEach(t),oUo=r(RRe," \u2014 "),az=n(RRe,"A",{href:!0});var Qvt=s(az);rUo=r(Qvt,"QDQBertForTokenClassification"),Qvt.forEach(t),tUo=r(RRe," (QDQBert model)"),RRe.forEach(t),aUo=i(J),q5=n(J,"LI",{});var PRe=s(q5);Z_e=n(PRe,"STRONG",{});var Wvt=s(Z_e);nUo=r(Wvt,"rembert"),Wvt.forEach(t),sUo=r(PRe," \u2014 "),nz=n(PRe,"A",{href:!0});var Hvt=s(nz);lUo=r(Hvt,"RemBertForTokenClassification"),Hvt.forEach(t),iUo=r(PRe," (RemBERT model)"),PRe.forEach(t),dUo=i(J),j5=n(J,"LI",{});var BRe=s(j5);eue=n(BRe,"STRONG",{});var Uvt=s(eue);cUo=r(Uvt,"roberta"),Uvt.forEach(t),fUo=r(BRe," \u2014 "),sz=n(BRe,"A",{href:!0});var Jvt=s(sz);mUo=r(Jvt,"RobertaForTokenClassification"),Jvt.forEach(t),gUo=r(BRe," (RoBERTa model)"),BRe.forEach(t),hUo=i(J),D5=n(J,"LI",{});var IRe=s(D5);oue=n(IRe,"STRONG",{});var Yvt=s(oue);pUo=r(Yvt,"roformer"),Yvt.forEach(t),_Uo=r(IRe," \u2014 "),lz=n(IRe,"A",{href:!0});var Kvt=s(lz);uUo=r(Kvt,"RoFormerForTokenClassification"),Kvt.forEach(t),bUo=r(IRe," (RoFormer model)"),IRe.forEach(t),vUo=i(J),G5=n(J,"LI",{});var NRe=s(G5);rue=n(NRe,"STRONG",{});var Zvt=s(rue);FUo=r(Zvt,"squeezebert"),Zvt.forEach(t),TUo=r(NRe," \u2014 "),iz=n(NRe,"A",{href:!0});var e3t=s(iz);MUo=r(e3t,"SqueezeBertForTokenClassification"),e3t.forEach(t),EUo=r(NRe," (SqueezeBERT model)"),NRe.forEach(t),CUo=i(J),O5=n(J,"LI",{});var qRe=s(O5);tue=n(qRe,"STRONG",{});var o3t=s(tue);wUo=r(o3t,"xlm"),o3t.forEach(t),AUo=r(qRe," \u2014 "),dz=n(qRe,"A",{href:!0});var r3t=s(dz);LUo=r(r3t,"XLMForTokenClassification"),r3t.forEach(t),yUo=r(qRe," (XLM model)"),qRe.forEach(t),xUo=i(J),V5=n(J,"LI",{});var jRe=s(V5);aue=n(jRe,"STRONG",{});var t3t=s(aue);$Uo=r(t3t,"xlm-roberta"),t3t.forEach(t),kUo=r(jRe," \u2014 "),cz=n(jRe,"A",{href:!0});var a3t=s(cz);SUo=r(a3t,"XLMRobertaForTokenClassification"),a3t.forEach(t),RUo=r(jRe," (XLM-RoBERTa model)"),jRe.forEach(t),PUo=i(J),X5=n(J,"LI",{});var DRe=s(X5);nue=n(DRe,"STRONG",{});var n3t=s(nue);BUo=r(n3t,"xlm-roberta-xl"),n3t.forEach(t),IUo=r(DRe," \u2014 "),fz=n(DRe,"A",{href:!0});var s3t=s(fz);NUo=r(s3t,"XLMRobertaXLForTokenClassification"),s3t.forEach(t),qUo=r(DRe," (XLM-RoBERTa-XL model)"),DRe.forEach(t),jUo=i(J),z5=n(J,"LI",{});var GRe=s(z5);sue=n(GRe,"STRONG",{});var l3t=s(sue);DUo=r(l3t,"xlnet"),l3t.forEach(t),GUo=r(GRe," \u2014 "),mz=n(GRe,"A",{href:!0});var i3t=s(mz);OUo=r(i3t,"XLNetForTokenClassification"),i3t.forEach(t),VUo=r(GRe," (XLNet model)"),GRe.forEach(t),XUo=i(J),Q5=n(J,"LI",{});var ORe=s(Q5);lue=n(ORe,"STRONG",{});var d3t=s(lue);zUo=r(d3t,"yoso"),d3t.forEach(t),QUo=r(ORe," \u2014 "),gz=n(ORe,"A",{href:!0});var c3t=s(gz);WUo=r(c3t,"YosoForTokenClassification"),c3t.forEach(t),HUo=r(ORe," (YOSO model)"),ORe.forEach(t),J.forEach(t),UUo=i(ga),W5=n(ga,"P",{});var VRe=s(W5);JUo=r(VRe,"The model is set in evaluation mode by default using "),iue=n(VRe,"CODE",{});var f3t=s(iue);YUo=r(f3t,"model.eval()"),f3t.forEach(t),KUo=r(VRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),due=n(VRe,"CODE",{});var m3t=s(due);ZUo=r(m3t,"model.train()"),m3t.forEach(t),VRe.forEach(t),eJo=i(ga),T(H5.$$.fragment,ga),ga.forEach(t),nl.forEach(t),_Oe=i(f),id=n(f,"H2",{class:!0});var MXe=s(id);U5=n(MXe,"A",{id:!0,class:!0,href:!0});var g3t=s(U5);cue=n(g3t,"SPAN",{});var h3t=s(cue);T(Qy.$$.fragment,h3t),h3t.forEach(t),g3t.forEach(t),oJo=i(MXe),fue=n(MXe,"SPAN",{});var p3t=s(fue);rJo=r(p3t,"AutoModelForQuestionAnswering"),p3t.forEach(t),MXe.forEach(t),uOe=i(f),jo=n(f,"DIV",{class:!0});var sl=s(jo);T(Wy.$$.fragment,sl),tJo=i(sl),dd=n(sl,"P",{});var Noe=s(dd);aJo=r(Noe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),hz=n(Noe,"A",{href:!0});var _3t=s(hz);nJo=r(_3t,"from_pretrained()"),_3t.forEach(t),sJo=r(Noe," class method or the "),pz=n(Noe,"A",{href:!0});var u3t=s(pz);lJo=r(u3t,"from_config()"),u3t.forEach(t),iJo=r(Noe,` class
method.`),Noe.forEach(t),dJo=i(sl),Hy=n(sl,"P",{});var EXe=s(Hy);cJo=r(EXe,"This class cannot be instantiated directly using "),mue=n(EXe,"CODE",{});var b3t=s(mue);fJo=r(b3t,"__init__()"),b3t.forEach(t),mJo=r(EXe," (throws an error)."),EXe.forEach(t),gJo=i(sl),ht=n(sl,"DIV",{class:!0});var UA=s(ht);T(Uy.$$.fragment,UA),hJo=i(UA),gue=n(UA,"P",{});var v3t=s(gue);pJo=r(v3t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),v3t.forEach(t),_Jo=i(UA),cd=n(UA,"P",{});var qoe=s(cd);uJo=r(qoe,`Note:
Loading a model from its configuration file does `),hue=n(qoe,"STRONG",{});var F3t=s(hue);bJo=r(F3t,"not"),F3t.forEach(t),vJo=r(qoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),_z=n(qoe,"A",{href:!0});var T3t=s(_z);FJo=r(T3t,"from_pretrained()"),T3t.forEach(t),TJo=r(qoe," to load the model weights."),qoe.forEach(t),MJo=i(UA),T(J5.$$.fragment,UA),UA.forEach(t),EJo=i(sl),no=n(sl,"DIV",{class:!0});var ha=s(no);T(Jy.$$.fragment,ha),CJo=i(ha),pue=n(ha,"P",{});var M3t=s(pue);wJo=r(M3t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),M3t.forEach(t),AJo=i(ha),Oa=n(ha,"P",{});var JA=s(Oa);LJo=r(JA,"The model class to instantiate is selected based on the "),_ue=n(JA,"CODE",{});var E3t=s(_ue);yJo=r(E3t,"model_type"),E3t.forEach(t),xJo=r(JA,` property of the config object (either
passed as an argument or loaded from `),uue=n(JA,"CODE",{});var C3t=s(uue);$Jo=r(C3t,"pretrained_model_name_or_path"),C3t.forEach(t),kJo=r(JA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bue=n(JA,"CODE",{});var w3t=s(bue);SJo=r(w3t,"pretrained_model_name_or_path"),w3t.forEach(t),RJo=r(JA,":"),JA.forEach(t),PJo=i(ha),V=n(ha,"UL",{});var X=s(V);Y5=n(X,"LI",{});var XRe=s(Y5);vue=n(XRe,"STRONG",{});var A3t=s(vue);BJo=r(A3t,"albert"),A3t.forEach(t),IJo=r(XRe," \u2014 "),uz=n(XRe,"A",{href:!0});var L3t=s(uz);NJo=r(L3t,"AlbertForQuestionAnswering"),L3t.forEach(t),qJo=r(XRe," (ALBERT model)"),XRe.forEach(t),jJo=i(X),K5=n(X,"LI",{});var zRe=s(K5);Fue=n(zRe,"STRONG",{});var y3t=s(Fue);DJo=r(y3t,"bart"),y3t.forEach(t),GJo=r(zRe," \u2014 "),bz=n(zRe,"A",{href:!0});var x3t=s(bz);OJo=r(x3t,"BartForQuestionAnswering"),x3t.forEach(t),VJo=r(zRe," (BART model)"),zRe.forEach(t),XJo=i(X),Z5=n(X,"LI",{});var QRe=s(Z5);Tue=n(QRe,"STRONG",{});var $3t=s(Tue);zJo=r($3t,"bert"),$3t.forEach(t),QJo=r(QRe," \u2014 "),vz=n(QRe,"A",{href:!0});var k3t=s(vz);WJo=r(k3t,"BertForQuestionAnswering"),k3t.forEach(t),HJo=r(QRe," (BERT model)"),QRe.forEach(t),UJo=i(X),ev=n(X,"LI",{});var WRe=s(ev);Mue=n(WRe,"STRONG",{});var S3t=s(Mue);JJo=r(S3t,"big_bird"),S3t.forEach(t),YJo=r(WRe," \u2014 "),Fz=n(WRe,"A",{href:!0});var R3t=s(Fz);KJo=r(R3t,"BigBirdForQuestionAnswering"),R3t.forEach(t),ZJo=r(WRe," (BigBird model)"),WRe.forEach(t),eYo=i(X),ov=n(X,"LI",{});var HRe=s(ov);Eue=n(HRe,"STRONG",{});var P3t=s(Eue);oYo=r(P3t,"bigbird_pegasus"),P3t.forEach(t),rYo=r(HRe," \u2014 "),Tz=n(HRe,"A",{href:!0});var B3t=s(Tz);tYo=r(B3t,"BigBirdPegasusForQuestionAnswering"),B3t.forEach(t),aYo=r(HRe," (BigBird-Pegasus model)"),HRe.forEach(t),nYo=i(X),rv=n(X,"LI",{});var URe=s(rv);Cue=n(URe,"STRONG",{});var I3t=s(Cue);sYo=r(I3t,"camembert"),I3t.forEach(t),lYo=r(URe," \u2014 "),Mz=n(URe,"A",{href:!0});var N3t=s(Mz);iYo=r(N3t,"CamembertForQuestionAnswering"),N3t.forEach(t),dYo=r(URe," (CamemBERT model)"),URe.forEach(t),cYo=i(X),tv=n(X,"LI",{});var JRe=s(tv);wue=n(JRe,"STRONG",{});var q3t=s(wue);fYo=r(q3t,"canine"),q3t.forEach(t),mYo=r(JRe," \u2014 "),Ez=n(JRe,"A",{href:!0});var j3t=s(Ez);gYo=r(j3t,"CanineForQuestionAnswering"),j3t.forEach(t),hYo=r(JRe," (CANINE model)"),JRe.forEach(t),pYo=i(X),av=n(X,"LI",{});var YRe=s(av);Aue=n(YRe,"STRONG",{});var D3t=s(Aue);_Yo=r(D3t,"convbert"),D3t.forEach(t),uYo=r(YRe," \u2014 "),Cz=n(YRe,"A",{href:!0});var G3t=s(Cz);bYo=r(G3t,"ConvBertForQuestionAnswering"),G3t.forEach(t),vYo=r(YRe," (ConvBERT model)"),YRe.forEach(t),FYo=i(X),nv=n(X,"LI",{});var KRe=s(nv);Lue=n(KRe,"STRONG",{});var O3t=s(Lue);TYo=r(O3t,"data2vec-text"),O3t.forEach(t),MYo=r(KRe," \u2014 "),wz=n(KRe,"A",{href:!0});var V3t=s(wz);EYo=r(V3t,"Data2VecTextForQuestionAnswering"),V3t.forEach(t),CYo=r(KRe," (Data2VecText model)"),KRe.forEach(t),wYo=i(X),sv=n(X,"LI",{});var ZRe=s(sv);yue=n(ZRe,"STRONG",{});var X3t=s(yue);AYo=r(X3t,"deberta"),X3t.forEach(t),LYo=r(ZRe," \u2014 "),Az=n(ZRe,"A",{href:!0});var z3t=s(Az);yYo=r(z3t,"DebertaForQuestionAnswering"),z3t.forEach(t),xYo=r(ZRe," (DeBERTa model)"),ZRe.forEach(t),$Yo=i(X),lv=n(X,"LI",{});var ePe=s(lv);xue=n(ePe,"STRONG",{});var Q3t=s(xue);kYo=r(Q3t,"deberta-v2"),Q3t.forEach(t),SYo=r(ePe," \u2014 "),Lz=n(ePe,"A",{href:!0});var W3t=s(Lz);RYo=r(W3t,"DebertaV2ForQuestionAnswering"),W3t.forEach(t),PYo=r(ePe," (DeBERTa-v2 model)"),ePe.forEach(t),BYo=i(X),iv=n(X,"LI",{});var oPe=s(iv);$ue=n(oPe,"STRONG",{});var H3t=s($ue);IYo=r(H3t,"distilbert"),H3t.forEach(t),NYo=r(oPe," \u2014 "),yz=n(oPe,"A",{href:!0});var U3t=s(yz);qYo=r(U3t,"DistilBertForQuestionAnswering"),U3t.forEach(t),jYo=r(oPe," (DistilBERT model)"),oPe.forEach(t),DYo=i(X),dv=n(X,"LI",{});var rPe=s(dv);kue=n(rPe,"STRONG",{});var J3t=s(kue);GYo=r(J3t,"electra"),J3t.forEach(t),OYo=r(rPe," \u2014 "),xz=n(rPe,"A",{href:!0});var Y3t=s(xz);VYo=r(Y3t,"ElectraForQuestionAnswering"),Y3t.forEach(t),XYo=r(rPe," (ELECTRA model)"),rPe.forEach(t),zYo=i(X),cv=n(X,"LI",{});var tPe=s(cv);Sue=n(tPe,"STRONG",{});var K3t=s(Sue);QYo=r(K3t,"flaubert"),K3t.forEach(t),WYo=r(tPe," \u2014 "),$z=n(tPe,"A",{href:!0});var Z3t=s($z);HYo=r(Z3t,"FlaubertForQuestionAnsweringSimple"),Z3t.forEach(t),UYo=r(tPe," (FlauBERT model)"),tPe.forEach(t),JYo=i(X),fv=n(X,"LI",{});var aPe=s(fv);Rue=n(aPe,"STRONG",{});var eFt=s(Rue);YYo=r(eFt,"fnet"),eFt.forEach(t),KYo=r(aPe," \u2014 "),kz=n(aPe,"A",{href:!0});var oFt=s(kz);ZYo=r(oFt,"FNetForQuestionAnswering"),oFt.forEach(t),eKo=r(aPe," (FNet model)"),aPe.forEach(t),oKo=i(X),mv=n(X,"LI",{});var nPe=s(mv);Pue=n(nPe,"STRONG",{});var rFt=s(Pue);rKo=r(rFt,"funnel"),rFt.forEach(t),tKo=r(nPe," \u2014 "),Sz=n(nPe,"A",{href:!0});var tFt=s(Sz);aKo=r(tFt,"FunnelForQuestionAnswering"),tFt.forEach(t),nKo=r(nPe," (Funnel Transformer model)"),nPe.forEach(t),sKo=i(X),gv=n(X,"LI",{});var sPe=s(gv);Bue=n(sPe,"STRONG",{});var aFt=s(Bue);lKo=r(aFt,"gptj"),aFt.forEach(t),iKo=r(sPe," \u2014 "),Rz=n(sPe,"A",{href:!0});var nFt=s(Rz);dKo=r(nFt,"GPTJForQuestionAnswering"),nFt.forEach(t),cKo=r(sPe," (GPT-J model)"),sPe.forEach(t),fKo=i(X),hv=n(X,"LI",{});var lPe=s(hv);Iue=n(lPe,"STRONG",{});var sFt=s(Iue);mKo=r(sFt,"ibert"),sFt.forEach(t),gKo=r(lPe," \u2014 "),Pz=n(lPe,"A",{href:!0});var lFt=s(Pz);hKo=r(lFt,"IBertForQuestionAnswering"),lFt.forEach(t),pKo=r(lPe," (I-BERT model)"),lPe.forEach(t),_Ko=i(X),pv=n(X,"LI",{});var iPe=s(pv);Nue=n(iPe,"STRONG",{});var iFt=s(Nue);uKo=r(iFt,"layoutlmv2"),iFt.forEach(t),bKo=r(iPe," \u2014 "),Bz=n(iPe,"A",{href:!0});var dFt=s(Bz);vKo=r(dFt,"LayoutLMv2ForQuestionAnswering"),dFt.forEach(t),FKo=r(iPe," (LayoutLMv2 model)"),iPe.forEach(t),TKo=i(X),_v=n(X,"LI",{});var dPe=s(_v);que=n(dPe,"STRONG",{});var cFt=s(que);MKo=r(cFt,"layoutlmv3"),cFt.forEach(t),EKo=r(dPe," \u2014 "),Iz=n(dPe,"A",{href:!0});var fFt=s(Iz);CKo=r(fFt,"LayoutLMv3ForQuestionAnswering"),fFt.forEach(t),wKo=r(dPe," (LayoutLMv3 model)"),dPe.forEach(t),AKo=i(X),uv=n(X,"LI",{});var cPe=s(uv);jue=n(cPe,"STRONG",{});var mFt=s(jue);LKo=r(mFt,"led"),mFt.forEach(t),yKo=r(cPe," \u2014 "),Nz=n(cPe,"A",{href:!0});var gFt=s(Nz);xKo=r(gFt,"LEDForQuestionAnswering"),gFt.forEach(t),$Ko=r(cPe," (LED model)"),cPe.forEach(t),kKo=i(X),bv=n(X,"LI",{});var fPe=s(bv);Due=n(fPe,"STRONG",{});var hFt=s(Due);SKo=r(hFt,"longformer"),hFt.forEach(t),RKo=r(fPe," \u2014 "),qz=n(fPe,"A",{href:!0});var pFt=s(qz);PKo=r(pFt,"LongformerForQuestionAnswering"),pFt.forEach(t),BKo=r(fPe," (Longformer model)"),fPe.forEach(t),IKo=i(X),vv=n(X,"LI",{});var mPe=s(vv);Gue=n(mPe,"STRONG",{});var _Ft=s(Gue);NKo=r(_Ft,"lxmert"),_Ft.forEach(t),qKo=r(mPe," \u2014 "),jz=n(mPe,"A",{href:!0});var uFt=s(jz);jKo=r(uFt,"LxmertForQuestionAnswering"),uFt.forEach(t),DKo=r(mPe," (LXMERT model)"),mPe.forEach(t),GKo=i(X),Fv=n(X,"LI",{});var gPe=s(Fv);Oue=n(gPe,"STRONG",{});var bFt=s(Oue);OKo=r(bFt,"mbart"),bFt.forEach(t),VKo=r(gPe," \u2014 "),Dz=n(gPe,"A",{href:!0});var vFt=s(Dz);XKo=r(vFt,"MBartForQuestionAnswering"),vFt.forEach(t),zKo=r(gPe," (mBART model)"),gPe.forEach(t),QKo=i(X),Tv=n(X,"LI",{});var hPe=s(Tv);Vue=n(hPe,"STRONG",{});var FFt=s(Vue);WKo=r(FFt,"megatron-bert"),FFt.forEach(t),HKo=r(hPe," \u2014 "),Gz=n(hPe,"A",{href:!0});var TFt=s(Gz);UKo=r(TFt,"MegatronBertForQuestionAnswering"),TFt.forEach(t),JKo=r(hPe," (Megatron-BERT model)"),hPe.forEach(t),YKo=i(X),Mv=n(X,"LI",{});var pPe=s(Mv);Xue=n(pPe,"STRONG",{});var MFt=s(Xue);KKo=r(MFt,"mobilebert"),MFt.forEach(t),ZKo=r(pPe," \u2014 "),Oz=n(pPe,"A",{href:!0});var EFt=s(Oz);eZo=r(EFt,"MobileBertForQuestionAnswering"),EFt.forEach(t),oZo=r(pPe," (MobileBERT model)"),pPe.forEach(t),rZo=i(X),Ev=n(X,"LI",{});var _Pe=s(Ev);zue=n(_Pe,"STRONG",{});var CFt=s(zue);tZo=r(CFt,"mpnet"),CFt.forEach(t),aZo=r(_Pe," \u2014 "),Vz=n(_Pe,"A",{href:!0});var wFt=s(Vz);nZo=r(wFt,"MPNetForQuestionAnswering"),wFt.forEach(t),sZo=r(_Pe," (MPNet model)"),_Pe.forEach(t),lZo=i(X),Cv=n(X,"LI",{});var uPe=s(Cv);Que=n(uPe,"STRONG",{});var AFt=s(Que);iZo=r(AFt,"nezha"),AFt.forEach(t),dZo=r(uPe," \u2014 "),Xz=n(uPe,"A",{href:!0});var LFt=s(Xz);cZo=r(LFt,"NezhaForQuestionAnswering"),LFt.forEach(t),fZo=r(uPe," (Nezha model)"),uPe.forEach(t),mZo=i(X),wv=n(X,"LI",{});var bPe=s(wv);Wue=n(bPe,"STRONG",{});var yFt=s(Wue);gZo=r(yFt,"nystromformer"),yFt.forEach(t),hZo=r(bPe," \u2014 "),zz=n(bPe,"A",{href:!0});var xFt=s(zz);pZo=r(xFt,"NystromformerForQuestionAnswering"),xFt.forEach(t),_Zo=r(bPe," (Nystr\xF6mformer model)"),bPe.forEach(t),uZo=i(X),Av=n(X,"LI",{});var vPe=s(Av);Hue=n(vPe,"STRONG",{});var $Ft=s(Hue);bZo=r($Ft,"qdqbert"),$Ft.forEach(t),vZo=r(vPe," \u2014 "),Qz=n(vPe,"A",{href:!0});var kFt=s(Qz);FZo=r(kFt,"QDQBertForQuestionAnswering"),kFt.forEach(t),TZo=r(vPe," (QDQBert model)"),vPe.forEach(t),MZo=i(X),Lv=n(X,"LI",{});var FPe=s(Lv);Uue=n(FPe,"STRONG",{});var SFt=s(Uue);EZo=r(SFt,"reformer"),SFt.forEach(t),CZo=r(FPe," \u2014 "),Wz=n(FPe,"A",{href:!0});var RFt=s(Wz);wZo=r(RFt,"ReformerForQuestionAnswering"),RFt.forEach(t),AZo=r(FPe," (Reformer model)"),FPe.forEach(t),LZo=i(X),yv=n(X,"LI",{});var TPe=s(yv);Jue=n(TPe,"STRONG",{});var PFt=s(Jue);yZo=r(PFt,"rembert"),PFt.forEach(t),xZo=r(TPe," \u2014 "),Hz=n(TPe,"A",{href:!0});var BFt=s(Hz);$Zo=r(BFt,"RemBertForQuestionAnswering"),BFt.forEach(t),kZo=r(TPe," (RemBERT model)"),TPe.forEach(t),SZo=i(X),xv=n(X,"LI",{});var MPe=s(xv);Yue=n(MPe,"STRONG",{});var IFt=s(Yue);RZo=r(IFt,"roberta"),IFt.forEach(t),PZo=r(MPe," \u2014 "),Uz=n(MPe,"A",{href:!0});var NFt=s(Uz);BZo=r(NFt,"RobertaForQuestionAnswering"),NFt.forEach(t),IZo=r(MPe," (RoBERTa model)"),MPe.forEach(t),NZo=i(X),$v=n(X,"LI",{});var EPe=s($v);Kue=n(EPe,"STRONG",{});var qFt=s(Kue);qZo=r(qFt,"roformer"),qFt.forEach(t),jZo=r(EPe," \u2014 "),Jz=n(EPe,"A",{href:!0});var jFt=s(Jz);DZo=r(jFt,"RoFormerForQuestionAnswering"),jFt.forEach(t),GZo=r(EPe," (RoFormer model)"),EPe.forEach(t),OZo=i(X),kv=n(X,"LI",{});var CPe=s(kv);Zue=n(CPe,"STRONG",{});var DFt=s(Zue);VZo=r(DFt,"splinter"),DFt.forEach(t),XZo=r(CPe," \u2014 "),Yz=n(CPe,"A",{href:!0});var GFt=s(Yz);zZo=r(GFt,"SplinterForQuestionAnswering"),GFt.forEach(t),QZo=r(CPe," (Splinter model)"),CPe.forEach(t),WZo=i(X),Sv=n(X,"LI",{});var wPe=s(Sv);e1e=n(wPe,"STRONG",{});var OFt=s(e1e);HZo=r(OFt,"squeezebert"),OFt.forEach(t),UZo=r(wPe," \u2014 "),Kz=n(wPe,"A",{href:!0});var VFt=s(Kz);JZo=r(VFt,"SqueezeBertForQuestionAnswering"),VFt.forEach(t),YZo=r(wPe," (SqueezeBERT model)"),wPe.forEach(t),KZo=i(X),Rv=n(X,"LI",{});var APe=s(Rv);o1e=n(APe,"STRONG",{});var XFt=s(o1e);ZZo=r(XFt,"xlm"),XFt.forEach(t),eer=r(APe," \u2014 "),Zz=n(APe,"A",{href:!0});var zFt=s(Zz);oer=r(zFt,"XLMForQuestionAnsweringSimple"),zFt.forEach(t),rer=r(APe," (XLM model)"),APe.forEach(t),ter=i(X),Pv=n(X,"LI",{});var LPe=s(Pv);r1e=n(LPe,"STRONG",{});var QFt=s(r1e);aer=r(QFt,"xlm-roberta"),QFt.forEach(t),ner=r(LPe," \u2014 "),eQ=n(LPe,"A",{href:!0});var WFt=s(eQ);ser=r(WFt,"XLMRobertaForQuestionAnswering"),WFt.forEach(t),ler=r(LPe," (XLM-RoBERTa model)"),LPe.forEach(t),ier=i(X),Bv=n(X,"LI",{});var yPe=s(Bv);t1e=n(yPe,"STRONG",{});var HFt=s(t1e);der=r(HFt,"xlm-roberta-xl"),HFt.forEach(t),cer=r(yPe," \u2014 "),oQ=n(yPe,"A",{href:!0});var UFt=s(oQ);fer=r(UFt,"XLMRobertaXLForQuestionAnswering"),UFt.forEach(t),mer=r(yPe," (XLM-RoBERTa-XL model)"),yPe.forEach(t),ger=i(X),Iv=n(X,"LI",{});var xPe=s(Iv);a1e=n(xPe,"STRONG",{});var JFt=s(a1e);her=r(JFt,"xlnet"),JFt.forEach(t),per=r(xPe," \u2014 "),rQ=n(xPe,"A",{href:!0});var YFt=s(rQ);_er=r(YFt,"XLNetForQuestionAnsweringSimple"),YFt.forEach(t),uer=r(xPe," (XLNet model)"),xPe.forEach(t),ber=i(X),Nv=n(X,"LI",{});var $Pe=s(Nv);n1e=n($Pe,"STRONG",{});var KFt=s(n1e);ver=r(KFt,"yoso"),KFt.forEach(t),Fer=r($Pe," \u2014 "),tQ=n($Pe,"A",{href:!0});var ZFt=s(tQ);Ter=r(ZFt,"YosoForQuestionAnswering"),ZFt.forEach(t),Mer=r($Pe," (YOSO model)"),$Pe.forEach(t),X.forEach(t),Eer=i(ha),qv=n(ha,"P",{});var kPe=s(qv);Cer=r(kPe,"The model is set in evaluation mode by default using "),s1e=n(kPe,"CODE",{});var eTt=s(s1e);wer=r(eTt,"model.eval()"),eTt.forEach(t),Aer=r(kPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l1e=n(kPe,"CODE",{});var oTt=s(l1e);Ler=r(oTt,"model.train()"),oTt.forEach(t),kPe.forEach(t),yer=i(ha),T(jv.$$.fragment,ha),ha.forEach(t),sl.forEach(t),bOe=i(f),fd=n(f,"H2",{class:!0});var CXe=s(fd);Dv=n(CXe,"A",{id:!0,class:!0,href:!0});var rTt=s(Dv);i1e=n(rTt,"SPAN",{});var tTt=s(i1e);T(Yy.$$.fragment,tTt),tTt.forEach(t),rTt.forEach(t),xer=i(CXe),d1e=n(CXe,"SPAN",{});var aTt=s(d1e);$er=r(aTt,"AutoModelForTableQuestionAnswering"),aTt.forEach(t),CXe.forEach(t),vOe=i(f),Do=n(f,"DIV",{class:!0});var ll=s(Do);T(Ky.$$.fragment,ll),ker=i(ll),md=n(ll,"P",{});var joe=s(md);Ser=r(joe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),aQ=n(joe,"A",{href:!0});var nTt=s(aQ);Rer=r(nTt,"from_pretrained()"),nTt.forEach(t),Per=r(joe," class method or the "),nQ=n(joe,"A",{href:!0});var sTt=s(nQ);Ber=r(sTt,"from_config()"),sTt.forEach(t),Ier=r(joe,` class
method.`),joe.forEach(t),Ner=i(ll),Zy=n(ll,"P",{});var wXe=s(Zy);qer=r(wXe,"This class cannot be instantiated directly using "),c1e=n(wXe,"CODE",{});var lTt=s(c1e);jer=r(lTt,"__init__()"),lTt.forEach(t),Der=r(wXe," (throws an error)."),wXe.forEach(t),Ger=i(ll),pt=n(ll,"DIV",{class:!0});var YA=s(pt);T(e8.$$.fragment,YA),Oer=i(YA),f1e=n(YA,"P",{});var iTt=s(f1e);Ver=r(iTt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),iTt.forEach(t),Xer=i(YA),gd=n(YA,"P",{});var Doe=s(gd);zer=r(Doe,`Note:
Loading a model from its configuration file does `),m1e=n(Doe,"STRONG",{});var dTt=s(m1e);Qer=r(dTt,"not"),dTt.forEach(t),Wer=r(Doe,` load the model weights. It only affects the
model\u2019s configuration. Use `),sQ=n(Doe,"A",{href:!0});var cTt=s(sQ);Her=r(cTt,"from_pretrained()"),cTt.forEach(t),Uer=r(Doe," to load the model weights."),Doe.forEach(t),Jer=i(YA),T(Gv.$$.fragment,YA),YA.forEach(t),Yer=i(ll),so=n(ll,"DIV",{class:!0});var pa=s(so);T(o8.$$.fragment,pa),Ker=i(pa),g1e=n(pa,"P",{});var fTt=s(g1e);Zer=r(fTt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),fTt.forEach(t),eor=i(pa),Va=n(pa,"P",{});var KA=s(Va);oor=r(KA,"The model class to instantiate is selected based on the "),h1e=n(KA,"CODE",{});var mTt=s(h1e);ror=r(mTt,"model_type"),mTt.forEach(t),tor=r(KA,` property of the config object (either
passed as an argument or loaded from `),p1e=n(KA,"CODE",{});var gTt=s(p1e);aor=r(gTt,"pretrained_model_name_or_path"),gTt.forEach(t),nor=r(KA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_1e=n(KA,"CODE",{});var hTt=s(_1e);sor=r(hTt,"pretrained_model_name_or_path"),hTt.forEach(t),lor=r(KA,":"),KA.forEach(t),ior=i(pa),u1e=n(pa,"UL",{});var pTt=s(u1e);Ov=n(pTt,"LI",{});var SPe=s(Ov);b1e=n(SPe,"STRONG",{});var _Tt=s(b1e);dor=r(_Tt,"tapas"),_Tt.forEach(t),cor=r(SPe," \u2014 "),lQ=n(SPe,"A",{href:!0});var uTt=s(lQ);mor=r(uTt,"TapasForQuestionAnswering"),uTt.forEach(t),gor=r(SPe," (TAPAS model)"),SPe.forEach(t),pTt.forEach(t),hor=i(pa),Vv=n(pa,"P",{});var RPe=s(Vv);por=r(RPe,"The model is set in evaluation mode by default using "),v1e=n(RPe,"CODE",{});var bTt=s(v1e);_or=r(bTt,"model.eval()"),bTt.forEach(t),uor=r(RPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F1e=n(RPe,"CODE",{});var vTt=s(F1e);bor=r(vTt,"model.train()"),vTt.forEach(t),RPe.forEach(t),vor=i(pa),T(Xv.$$.fragment,pa),pa.forEach(t),ll.forEach(t),FOe=i(f),hd=n(f,"H2",{class:!0});var AXe=s(hd);zv=n(AXe,"A",{id:!0,class:!0,href:!0});var FTt=s(zv);T1e=n(FTt,"SPAN",{});var TTt=s(T1e);T(r8.$$.fragment,TTt),TTt.forEach(t),FTt.forEach(t),For=i(AXe),M1e=n(AXe,"SPAN",{});var MTt=s(M1e);Tor=r(MTt,"AutoModelForImageClassification"),MTt.forEach(t),AXe.forEach(t),TOe=i(f),Go=n(f,"DIV",{class:!0});var il=s(Go);T(t8.$$.fragment,il),Mor=i(il),pd=n(il,"P",{});var Goe=s(pd);Eor=r(Goe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),iQ=n(Goe,"A",{href:!0});var ETt=s(iQ);Cor=r(ETt,"from_pretrained()"),ETt.forEach(t),wor=r(Goe," class method or the "),dQ=n(Goe,"A",{href:!0});var CTt=s(dQ);Aor=r(CTt,"from_config()"),CTt.forEach(t),Lor=r(Goe,` class
method.`),Goe.forEach(t),yor=i(il),a8=n(il,"P",{});var LXe=s(a8);xor=r(LXe,"This class cannot be instantiated directly using "),E1e=n(LXe,"CODE",{});var wTt=s(E1e);$or=r(wTt,"__init__()"),wTt.forEach(t),kor=r(LXe," (throws an error)."),LXe.forEach(t),Sor=i(il),_t=n(il,"DIV",{class:!0});var ZA=s(_t);T(n8.$$.fragment,ZA),Ror=i(ZA),C1e=n(ZA,"P",{});var ATt=s(C1e);Por=r(ATt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),ATt.forEach(t),Bor=i(ZA),_d=n(ZA,"P",{});var Ooe=s(_d);Ior=r(Ooe,`Note:
Loading a model from its configuration file does `),w1e=n(Ooe,"STRONG",{});var LTt=s(w1e);Nor=r(LTt,"not"),LTt.forEach(t),qor=r(Ooe,` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=n(Ooe,"A",{href:!0});var yTt=s(cQ);jor=r(yTt,"from_pretrained()"),yTt.forEach(t),Dor=r(Ooe," to load the model weights."),Ooe.forEach(t),Gor=i(ZA),T(Qv.$$.fragment,ZA),ZA.forEach(t),Oor=i(il),lo=n(il,"DIV",{class:!0});var _a=s(lo);T(s8.$$.fragment,_a),Vor=i(_a),A1e=n(_a,"P",{});var xTt=s(A1e);Xor=r(xTt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),xTt.forEach(t),zor=i(_a),Xa=n(_a,"P",{});var e6=s(Xa);Qor=r(e6,"The model class to instantiate is selected based on the "),L1e=n(e6,"CODE",{});var $Tt=s(L1e);Wor=r($Tt,"model_type"),$Tt.forEach(t),Hor=r(e6,` property of the config object (either
passed as an argument or loaded from `),y1e=n(e6,"CODE",{});var kTt=s(y1e);Uor=r(kTt,"pretrained_model_name_or_path"),kTt.forEach(t),Jor=r(e6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x1e=n(e6,"CODE",{});var STt=s(x1e);Yor=r(STt,"pretrained_model_name_or_path"),STt.forEach(t),Kor=r(e6,":"),e6.forEach(t),Zor=i(_a),Fe=n(_a,"UL",{});var Te=s(Fe);Wv=n(Te,"LI",{});var PPe=s(Wv);$1e=n(PPe,"STRONG",{});var RTt=s($1e);err=r(RTt,"beit"),RTt.forEach(t),orr=r(PPe," \u2014 "),fQ=n(PPe,"A",{href:!0});var PTt=s(fQ);rrr=r(PTt,"BeitForImageClassification"),PTt.forEach(t),trr=r(PPe," (BEiT model)"),PPe.forEach(t),arr=i(Te),Hv=n(Te,"LI",{});var BPe=s(Hv);k1e=n(BPe,"STRONG",{});var BTt=s(k1e);nrr=r(BTt,"convnext"),BTt.forEach(t),srr=r(BPe," \u2014 "),mQ=n(BPe,"A",{href:!0});var ITt=s(mQ);lrr=r(ITt,"ConvNextForImageClassification"),ITt.forEach(t),irr=r(BPe," (ConvNeXT model)"),BPe.forEach(t),drr=i(Te),Uv=n(Te,"LI",{});var IPe=s(Uv);S1e=n(IPe,"STRONG",{});var NTt=s(S1e);crr=r(NTt,"cvt"),NTt.forEach(t),frr=r(IPe," \u2014 "),gQ=n(IPe,"A",{href:!0});var qTt=s(gQ);mrr=r(qTt,"CvtForImageClassification"),qTt.forEach(t),grr=r(IPe," (CvT model)"),IPe.forEach(t),hrr=i(Te),Jv=n(Te,"LI",{});var NPe=s(Jv);R1e=n(NPe,"STRONG",{});var jTt=s(R1e);prr=r(jTt,"data2vec-vision"),jTt.forEach(t),_rr=r(NPe," \u2014 "),hQ=n(NPe,"A",{href:!0});var DTt=s(hQ);urr=r(DTt,"Data2VecVisionForImageClassification"),DTt.forEach(t),brr=r(NPe," (Data2VecVision model)"),NPe.forEach(t),vrr=i(Te),Xs=n(Te,"LI",{});var Zk=s(Xs);P1e=n(Zk,"STRONG",{});var GTt=s(P1e);Frr=r(GTt,"deit"),GTt.forEach(t),Trr=r(Zk," \u2014 "),pQ=n(Zk,"A",{href:!0});var OTt=s(pQ);Mrr=r(OTt,"DeiTForImageClassification"),OTt.forEach(t),Err=r(Zk," or "),_Q=n(Zk,"A",{href:!0});var VTt=s(_Q);Crr=r(VTt,"DeiTForImageClassificationWithTeacher"),VTt.forEach(t),wrr=r(Zk," (DeiT model)"),Zk.forEach(t),Arr=i(Te),Yv=n(Te,"LI",{});var qPe=s(Yv);B1e=n(qPe,"STRONG",{});var XTt=s(B1e);Lrr=r(XTt,"imagegpt"),XTt.forEach(t),yrr=r(qPe," \u2014 "),uQ=n(qPe,"A",{href:!0});var zTt=s(uQ);xrr=r(zTt,"ImageGPTForImageClassification"),zTt.forEach(t),$rr=r(qPe," (ImageGPT model)"),qPe.forEach(t),krr=i(Te),zs=n(Te,"LI",{});var eS=s(zs);I1e=n(eS,"STRONG",{});var QTt=s(I1e);Srr=r(QTt,"levit"),QTt.forEach(t),Rrr=r(eS," \u2014 "),bQ=n(eS,"A",{href:!0});var WTt=s(bQ);Prr=r(WTt,"LevitForImageClassification"),WTt.forEach(t),Brr=r(eS," or "),vQ=n(eS,"A",{href:!0});var HTt=s(vQ);Irr=r(HTt,"LevitForImageClassificationWithTeacher"),HTt.forEach(t),Nrr=r(eS," (LeViT model)"),eS.forEach(t),qrr=i(Te),ut=n(Te,"LI",{});var Lf=s(ut);N1e=n(Lf,"STRONG",{});var UTt=s(N1e);jrr=r(UTt,"perceiver"),UTt.forEach(t),Drr=r(Lf," \u2014 "),FQ=n(Lf,"A",{href:!0});var JTt=s(FQ);Grr=r(JTt,"PerceiverForImageClassificationLearned"),JTt.forEach(t),Orr=r(Lf," or "),TQ=n(Lf,"A",{href:!0});var YTt=s(TQ);Vrr=r(YTt,"PerceiverForImageClassificationFourier"),YTt.forEach(t),Xrr=r(Lf," or "),MQ=n(Lf,"A",{href:!0});var KTt=s(MQ);zrr=r(KTt,"PerceiverForImageClassificationConvProcessing"),KTt.forEach(t),Qrr=r(Lf," (Perceiver model)"),Lf.forEach(t),Wrr=i(Te),Kv=n(Te,"LI",{});var jPe=s(Kv);q1e=n(jPe,"STRONG",{});var ZTt=s(q1e);Hrr=r(ZTt,"poolformer"),ZTt.forEach(t),Urr=r(jPe," \u2014 "),EQ=n(jPe,"A",{href:!0});var eMt=s(EQ);Jrr=r(eMt,"PoolFormerForImageClassification"),eMt.forEach(t),Yrr=r(jPe," (PoolFormer model)"),jPe.forEach(t),Krr=i(Te),Zv=n(Te,"LI",{});var DPe=s(Zv);j1e=n(DPe,"STRONG",{});var oMt=s(j1e);Zrr=r(oMt,"regnet"),oMt.forEach(t),etr=r(DPe," \u2014 "),CQ=n(DPe,"A",{href:!0});var rMt=s(CQ);otr=r(rMt,"RegNetForImageClassification"),rMt.forEach(t),rtr=r(DPe," (RegNet model)"),DPe.forEach(t),ttr=i(Te),e3=n(Te,"LI",{});var GPe=s(e3);D1e=n(GPe,"STRONG",{});var tMt=s(D1e);atr=r(tMt,"resnet"),tMt.forEach(t),ntr=r(GPe," \u2014 "),wQ=n(GPe,"A",{href:!0});var aMt=s(wQ);str=r(aMt,"ResNetForImageClassification"),aMt.forEach(t),ltr=r(GPe," (ResNet model)"),GPe.forEach(t),itr=i(Te),o3=n(Te,"LI",{});var OPe=s(o3);G1e=n(OPe,"STRONG",{});var nMt=s(G1e);dtr=r(nMt,"segformer"),nMt.forEach(t),ctr=r(OPe," \u2014 "),AQ=n(OPe,"A",{href:!0});var sMt=s(AQ);ftr=r(sMt,"SegformerForImageClassification"),sMt.forEach(t),mtr=r(OPe," (SegFormer model)"),OPe.forEach(t),gtr=i(Te),r3=n(Te,"LI",{});var VPe=s(r3);O1e=n(VPe,"STRONG",{});var lMt=s(O1e);htr=r(lMt,"swin"),lMt.forEach(t),ptr=r(VPe," \u2014 "),LQ=n(VPe,"A",{href:!0});var iMt=s(LQ);_tr=r(iMt,"SwinForImageClassification"),iMt.forEach(t),utr=r(VPe," (Swin Transformer model)"),VPe.forEach(t),btr=i(Te),t3=n(Te,"LI",{});var XPe=s(t3);V1e=n(XPe,"STRONG",{});var dMt=s(V1e);vtr=r(dMt,"van"),dMt.forEach(t),Ftr=r(XPe," \u2014 "),yQ=n(XPe,"A",{href:!0});var cMt=s(yQ);Ttr=r(cMt,"VanForImageClassification"),cMt.forEach(t),Mtr=r(XPe," (VAN model)"),XPe.forEach(t),Etr=i(Te),a3=n(Te,"LI",{});var zPe=s(a3);X1e=n(zPe,"STRONG",{});var fMt=s(X1e);Ctr=r(fMt,"vit"),fMt.forEach(t),wtr=r(zPe," \u2014 "),xQ=n(zPe,"A",{href:!0});var mMt=s(xQ);Atr=r(mMt,"ViTForImageClassification"),mMt.forEach(t),Ltr=r(zPe," (ViT model)"),zPe.forEach(t),Te.forEach(t),ytr=i(_a),n3=n(_a,"P",{});var QPe=s(n3);xtr=r(QPe,"The model is set in evaluation mode by default using "),z1e=n(QPe,"CODE",{});var gMt=s(z1e);$tr=r(gMt,"model.eval()"),gMt.forEach(t),ktr=r(QPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q1e=n(QPe,"CODE",{});var hMt=s(Q1e);Str=r(hMt,"model.train()"),hMt.forEach(t),QPe.forEach(t),Rtr=i(_a),T(s3.$$.fragment,_a),_a.forEach(t),il.forEach(t),MOe=i(f),ud=n(f,"H2",{class:!0});var yXe=s(ud);l3=n(yXe,"A",{id:!0,class:!0,href:!0});var pMt=s(l3);W1e=n(pMt,"SPAN",{});var _Mt=s(W1e);T(l8.$$.fragment,_Mt),_Mt.forEach(t),pMt.forEach(t),Ptr=i(yXe),H1e=n(yXe,"SPAN",{});var uMt=s(H1e);Btr=r(uMt,"AutoModelForVision2Seq"),uMt.forEach(t),yXe.forEach(t),EOe=i(f),Oo=n(f,"DIV",{class:!0});var dl=s(Oo);T(i8.$$.fragment,dl),Itr=i(dl),bd=n(dl,"P",{});var Voe=s(bd);Ntr=r(Voe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),$Q=n(Voe,"A",{href:!0});var bMt=s($Q);qtr=r(bMt,"from_pretrained()"),bMt.forEach(t),jtr=r(Voe," class method or the "),kQ=n(Voe,"A",{href:!0});var vMt=s(kQ);Dtr=r(vMt,"from_config()"),vMt.forEach(t),Gtr=r(Voe,` class
method.`),Voe.forEach(t),Otr=i(dl),d8=n(dl,"P",{});var xXe=s(d8);Vtr=r(xXe,"This class cannot be instantiated directly using "),U1e=n(xXe,"CODE",{});var FMt=s(U1e);Xtr=r(FMt,"__init__()"),FMt.forEach(t),ztr=r(xXe," (throws an error)."),xXe.forEach(t),Qtr=i(dl),bt=n(dl,"DIV",{class:!0});var o6=s(bt);T(c8.$$.fragment,o6),Wtr=i(o6),J1e=n(o6,"P",{});var TMt=s(J1e);Htr=r(TMt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),TMt.forEach(t),Utr=i(o6),vd=n(o6,"P",{});var Xoe=s(vd);Jtr=r(Xoe,`Note:
Loading a model from its configuration file does `),Y1e=n(Xoe,"STRONG",{});var MMt=s(Y1e);Ytr=r(MMt,"not"),MMt.forEach(t),Ktr=r(Xoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),SQ=n(Xoe,"A",{href:!0});var EMt=s(SQ);Ztr=r(EMt,"from_pretrained()"),EMt.forEach(t),ear=r(Xoe," to load the model weights."),Xoe.forEach(t),oar=i(o6),T(i3.$$.fragment,o6),o6.forEach(t),rar=i(dl),io=n(dl,"DIV",{class:!0});var ua=s(io);T(f8.$$.fragment,ua),tar=i(ua),K1e=n(ua,"P",{});var CMt=s(K1e);aar=r(CMt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),CMt.forEach(t),nar=i(ua),za=n(ua,"P",{});var r6=s(za);sar=r(r6,"The model class to instantiate is selected based on the "),Z1e=n(r6,"CODE",{});var wMt=s(Z1e);lar=r(wMt,"model_type"),wMt.forEach(t),iar=r(r6,` property of the config object (either
passed as an argument or loaded from `),e7e=n(r6,"CODE",{});var AMt=s(e7e);dar=r(AMt,"pretrained_model_name_or_path"),AMt.forEach(t),car=r(r6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o7e=n(r6,"CODE",{});var LMt=s(o7e);far=r(LMt,"pretrained_model_name_or_path"),LMt.forEach(t),mar=r(r6,":"),r6.forEach(t),gar=i(ua),r7e=n(ua,"UL",{});var yMt=s(r7e);d3=n(yMt,"LI",{});var WPe=s(d3);t7e=n(WPe,"STRONG",{});var xMt=s(t7e);har=r(xMt,"vision-encoder-decoder"),xMt.forEach(t),par=r(WPe," \u2014 "),RQ=n(WPe,"A",{href:!0});var $Mt=s(RQ);_ar=r($Mt,"VisionEncoderDecoderModel"),$Mt.forEach(t),uar=r(WPe," (Vision Encoder decoder model)"),WPe.forEach(t),yMt.forEach(t),bar=i(ua),c3=n(ua,"P",{});var HPe=s(c3);Far=r(HPe,"The model is set in evaluation mode by default using "),a7e=n(HPe,"CODE",{});var kMt=s(a7e);Tar=r(kMt,"model.eval()"),kMt.forEach(t),Mar=r(HPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n7e=n(HPe,"CODE",{});var SMt=s(n7e);Ear=r(SMt,"model.train()"),SMt.forEach(t),HPe.forEach(t),Car=i(ua),T(f3.$$.fragment,ua),ua.forEach(t),dl.forEach(t),COe=i(f),Fd=n(f,"H2",{class:!0});var $Xe=s(Fd);m3=n($Xe,"A",{id:!0,class:!0,href:!0});var RMt=s(m3);s7e=n(RMt,"SPAN",{});var PMt=s(s7e);T(m8.$$.fragment,PMt),PMt.forEach(t),RMt.forEach(t),war=i($Xe),l7e=n($Xe,"SPAN",{});var BMt=s(l7e);Aar=r(BMt,"AutoModelForVisualQuestionAnswering"),BMt.forEach(t),$Xe.forEach(t),wOe=i(f),Vo=n(f,"DIV",{class:!0});var cl=s(Vo);T(g8.$$.fragment,cl),Lar=i(cl),Td=n(cl,"P",{});var zoe=s(Td);yar=r(zoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),PQ=n(zoe,"A",{href:!0});var IMt=s(PQ);xar=r(IMt,"from_pretrained()"),IMt.forEach(t),$ar=r(zoe," class method or the "),BQ=n(zoe,"A",{href:!0});var NMt=s(BQ);kar=r(NMt,"from_config()"),NMt.forEach(t),Sar=r(zoe,` class
method.`),zoe.forEach(t),Rar=i(cl),h8=n(cl,"P",{});var kXe=s(h8);Par=r(kXe,"This class cannot be instantiated directly using "),i7e=n(kXe,"CODE",{});var qMt=s(i7e);Bar=r(qMt,"__init__()"),qMt.forEach(t),Iar=r(kXe," (throws an error)."),kXe.forEach(t),Nar=i(cl),vt=n(cl,"DIV",{class:!0});var t6=s(vt);T(p8.$$.fragment,t6),qar=i(t6),d7e=n(t6,"P",{});var jMt=s(d7e);jar=r(jMt,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),jMt.forEach(t),Dar=i(t6),Md=n(t6,"P",{});var Qoe=s(Md);Gar=r(Qoe,`Note:
Loading a model from its configuration file does `),c7e=n(Qoe,"STRONG",{});var DMt=s(c7e);Oar=r(DMt,"not"),DMt.forEach(t),Var=r(Qoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),IQ=n(Qoe,"A",{href:!0});var GMt=s(IQ);Xar=r(GMt,"from_pretrained()"),GMt.forEach(t),zar=r(Qoe," to load the model weights."),Qoe.forEach(t),Qar=i(t6),T(g3.$$.fragment,t6),t6.forEach(t),War=i(cl),co=n(cl,"DIV",{class:!0});var ba=s(co);T(_8.$$.fragment,ba),Har=i(ba),f7e=n(ba,"P",{});var OMt=s(f7e);Uar=r(OMt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),OMt.forEach(t),Jar=i(ba),Qa=n(ba,"P",{});var a6=s(Qa);Yar=r(a6,"The model class to instantiate is selected based on the "),m7e=n(a6,"CODE",{});var VMt=s(m7e);Kar=r(VMt,"model_type"),VMt.forEach(t),Zar=r(a6,` property of the config object (either
passed as an argument or loaded from `),g7e=n(a6,"CODE",{});var XMt=s(g7e);enr=r(XMt,"pretrained_model_name_or_path"),XMt.forEach(t),onr=r(a6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h7e=n(a6,"CODE",{});var zMt=s(h7e);rnr=r(zMt,"pretrained_model_name_or_path"),zMt.forEach(t),tnr=r(a6,":"),a6.forEach(t),anr=i(ba),p7e=n(ba,"UL",{});var QMt=s(p7e);h3=n(QMt,"LI",{});var UPe=s(h3);_7e=n(UPe,"STRONG",{});var WMt=s(_7e);nnr=r(WMt,"vilt"),WMt.forEach(t),snr=r(UPe," \u2014 "),NQ=n(UPe,"A",{href:!0});var HMt=s(NQ);lnr=r(HMt,"ViltForQuestionAnswering"),HMt.forEach(t),inr=r(UPe," (ViLT model)"),UPe.forEach(t),QMt.forEach(t),dnr=i(ba),p3=n(ba,"P",{});var JPe=s(p3);cnr=r(JPe,"The model is set in evaluation mode by default using "),u7e=n(JPe,"CODE",{});var UMt=s(u7e);fnr=r(UMt,"model.eval()"),UMt.forEach(t),mnr=r(JPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b7e=n(JPe,"CODE",{});var JMt=s(b7e);gnr=r(JMt,"model.train()"),JMt.forEach(t),JPe.forEach(t),hnr=i(ba),T(_3.$$.fragment,ba),ba.forEach(t),cl.forEach(t),AOe=i(f),Ed=n(f,"H2",{class:!0});var SXe=s(Ed);u3=n(SXe,"A",{id:!0,class:!0,href:!0});var YMt=s(u3);v7e=n(YMt,"SPAN",{});var KMt=s(v7e);T(u8.$$.fragment,KMt),KMt.forEach(t),YMt.forEach(t),pnr=i(SXe),F7e=n(SXe,"SPAN",{});var ZMt=s(F7e);_nr=r(ZMt,"AutoModelForAudioClassification"),ZMt.forEach(t),SXe.forEach(t),LOe=i(f),Xo=n(f,"DIV",{class:!0});var fl=s(Xo);T(b8.$$.fragment,fl),unr=i(fl),Cd=n(fl,"P",{});var Woe=s(Cd);bnr=r(Woe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),qQ=n(Woe,"A",{href:!0});var eEt=s(qQ);vnr=r(eEt,"from_pretrained()"),eEt.forEach(t),Fnr=r(Woe," class method or the "),jQ=n(Woe,"A",{href:!0});var oEt=s(jQ);Tnr=r(oEt,"from_config()"),oEt.forEach(t),Mnr=r(Woe,` class
method.`),Woe.forEach(t),Enr=i(fl),v8=n(fl,"P",{});var RXe=s(v8);Cnr=r(RXe,"This class cannot be instantiated directly using "),T7e=n(RXe,"CODE",{});var rEt=s(T7e);wnr=r(rEt,"__init__()"),rEt.forEach(t),Anr=r(RXe," (throws an error)."),RXe.forEach(t),Lnr=i(fl),Ft=n(fl,"DIV",{class:!0});var n6=s(Ft);T(F8.$$.fragment,n6),ynr=i(n6),M7e=n(n6,"P",{});var tEt=s(M7e);xnr=r(tEt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),tEt.forEach(t),$nr=i(n6),wd=n(n6,"P",{});var Hoe=s(wd);knr=r(Hoe,`Note:
Loading a model from its configuration file does `),E7e=n(Hoe,"STRONG",{});var aEt=s(E7e);Snr=r(aEt,"not"),aEt.forEach(t),Rnr=r(Hoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),DQ=n(Hoe,"A",{href:!0});var nEt=s(DQ);Pnr=r(nEt,"from_pretrained()"),nEt.forEach(t),Bnr=r(Hoe," to load the model weights."),Hoe.forEach(t),Inr=i(n6),T(b3.$$.fragment,n6),n6.forEach(t),Nnr=i(fl),fo=n(fl,"DIV",{class:!0});var va=s(fo);T(T8.$$.fragment,va),qnr=i(va),C7e=n(va,"P",{});var sEt=s(C7e);jnr=r(sEt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),sEt.forEach(t),Dnr=i(va),Wa=n(va,"P",{});var s6=s(Wa);Gnr=r(s6,"The model class to instantiate is selected based on the "),w7e=n(s6,"CODE",{});var lEt=s(w7e);Onr=r(lEt,"model_type"),lEt.forEach(t),Vnr=r(s6,` property of the config object (either
passed as an argument or loaded from `),A7e=n(s6,"CODE",{});var iEt=s(A7e);Xnr=r(iEt,"pretrained_model_name_or_path"),iEt.forEach(t),znr=r(s6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L7e=n(s6,"CODE",{});var dEt=s(L7e);Qnr=r(dEt,"pretrained_model_name_or_path"),dEt.forEach(t),Wnr=r(s6,":"),s6.forEach(t),Hnr=i(va),Pe=n(va,"UL",{});var ze=s(Pe);v3=n(ze,"LI",{});var YPe=s(v3);y7e=n(YPe,"STRONG",{});var cEt=s(y7e);Unr=r(cEt,"data2vec-audio"),cEt.forEach(t),Jnr=r(YPe," \u2014 "),GQ=n(YPe,"A",{href:!0});var fEt=s(GQ);Ynr=r(fEt,"Data2VecAudioForSequenceClassification"),fEt.forEach(t),Knr=r(YPe," (Data2VecAudio model)"),YPe.forEach(t),Znr=i(ze),F3=n(ze,"LI",{});var KPe=s(F3);x7e=n(KPe,"STRONG",{});var mEt=s(x7e);esr=r(mEt,"hubert"),mEt.forEach(t),osr=r(KPe," \u2014 "),OQ=n(KPe,"A",{href:!0});var gEt=s(OQ);rsr=r(gEt,"HubertForSequenceClassification"),gEt.forEach(t),tsr=r(KPe," (Hubert model)"),KPe.forEach(t),asr=i(ze),T3=n(ze,"LI",{});var ZPe=s(T3);$7e=n(ZPe,"STRONG",{});var hEt=s($7e);nsr=r(hEt,"sew"),hEt.forEach(t),ssr=r(ZPe," \u2014 "),VQ=n(ZPe,"A",{href:!0});var pEt=s(VQ);lsr=r(pEt,"SEWForSequenceClassification"),pEt.forEach(t),isr=r(ZPe," (SEW model)"),ZPe.forEach(t),dsr=i(ze),M3=n(ze,"LI",{});var eBe=s(M3);k7e=n(eBe,"STRONG",{});var _Et=s(k7e);csr=r(_Et,"sew-d"),_Et.forEach(t),fsr=r(eBe," \u2014 "),XQ=n(eBe,"A",{href:!0});var uEt=s(XQ);msr=r(uEt,"SEWDForSequenceClassification"),uEt.forEach(t),gsr=r(eBe," (SEW-D model)"),eBe.forEach(t),hsr=i(ze),E3=n(ze,"LI",{});var oBe=s(E3);S7e=n(oBe,"STRONG",{});var bEt=s(S7e);psr=r(bEt,"unispeech"),bEt.forEach(t),_sr=r(oBe," \u2014 "),zQ=n(oBe,"A",{href:!0});var vEt=s(zQ);usr=r(vEt,"UniSpeechForSequenceClassification"),vEt.forEach(t),bsr=r(oBe," (UniSpeech model)"),oBe.forEach(t),vsr=i(ze),C3=n(ze,"LI",{});var rBe=s(C3);R7e=n(rBe,"STRONG",{});var FEt=s(R7e);Fsr=r(FEt,"unispeech-sat"),FEt.forEach(t),Tsr=r(rBe," \u2014 "),QQ=n(rBe,"A",{href:!0});var TEt=s(QQ);Msr=r(TEt,"UniSpeechSatForSequenceClassification"),TEt.forEach(t),Esr=r(rBe," (UniSpeechSat model)"),rBe.forEach(t),Csr=i(ze),w3=n(ze,"LI",{});var tBe=s(w3);P7e=n(tBe,"STRONG",{});var MEt=s(P7e);wsr=r(MEt,"wav2vec2"),MEt.forEach(t),Asr=r(tBe," \u2014 "),WQ=n(tBe,"A",{href:!0});var EEt=s(WQ);Lsr=r(EEt,"Wav2Vec2ForSequenceClassification"),EEt.forEach(t),ysr=r(tBe," (Wav2Vec2 model)"),tBe.forEach(t),xsr=i(ze),A3=n(ze,"LI",{});var aBe=s(A3);B7e=n(aBe,"STRONG",{});var CEt=s(B7e);$sr=r(CEt,"wav2vec2-conformer"),CEt.forEach(t),ksr=r(aBe," \u2014 "),HQ=n(aBe,"A",{href:!0});var wEt=s(HQ);Ssr=r(wEt,"Wav2Vec2ConformerForSequenceClassification"),wEt.forEach(t),Rsr=r(aBe," (Wav2Vec2-Conformer model)"),aBe.forEach(t),Psr=i(ze),L3=n(ze,"LI",{});var nBe=s(L3);I7e=n(nBe,"STRONG",{});var AEt=s(I7e);Bsr=r(AEt,"wavlm"),AEt.forEach(t),Isr=r(nBe," \u2014 "),UQ=n(nBe,"A",{href:!0});var LEt=s(UQ);Nsr=r(LEt,"WavLMForSequenceClassification"),LEt.forEach(t),qsr=r(nBe," (WavLM model)"),nBe.forEach(t),ze.forEach(t),jsr=i(va),y3=n(va,"P",{});var sBe=s(y3);Dsr=r(sBe,"The model is set in evaluation mode by default using "),N7e=n(sBe,"CODE",{});var yEt=s(N7e);Gsr=r(yEt,"model.eval()"),yEt.forEach(t),Osr=r(sBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q7e=n(sBe,"CODE",{});var xEt=s(q7e);Vsr=r(xEt,"model.train()"),xEt.forEach(t),sBe.forEach(t),Xsr=i(va),T(x3.$$.fragment,va),va.forEach(t),fl.forEach(t),yOe=i(f),Ad=n(f,"H2",{class:!0});var PXe=s(Ad);$3=n(PXe,"A",{id:!0,class:!0,href:!0});var $Et=s($3);j7e=n($Et,"SPAN",{});var kEt=s(j7e);T(M8.$$.fragment,kEt),kEt.forEach(t),$Et.forEach(t),zsr=i(PXe),D7e=n(PXe,"SPAN",{});var SEt=s(D7e);Qsr=r(SEt,"AutoModelForAudioFrameClassification"),SEt.forEach(t),PXe.forEach(t),xOe=i(f),zo=n(f,"DIV",{class:!0});var ml=s(zo);T(E8.$$.fragment,ml),Wsr=i(ml),Ld=n(ml,"P",{});var Uoe=s(Ld);Hsr=r(Uoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),JQ=n(Uoe,"A",{href:!0});var REt=s(JQ);Usr=r(REt,"from_pretrained()"),REt.forEach(t),Jsr=r(Uoe," class method or the "),YQ=n(Uoe,"A",{href:!0});var PEt=s(YQ);Ysr=r(PEt,"from_config()"),PEt.forEach(t),Ksr=r(Uoe,` class
method.`),Uoe.forEach(t),Zsr=i(ml),C8=n(ml,"P",{});var BXe=s(C8);elr=r(BXe,"This class cannot be instantiated directly using "),G7e=n(BXe,"CODE",{});var BEt=s(G7e);olr=r(BEt,"__init__()"),BEt.forEach(t),rlr=r(BXe," (throws an error)."),BXe.forEach(t),tlr=i(ml),Tt=n(ml,"DIV",{class:!0});var l6=s(Tt);T(w8.$$.fragment,l6),alr=i(l6),O7e=n(l6,"P",{});var IEt=s(O7e);nlr=r(IEt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),IEt.forEach(t),slr=i(l6),yd=n(l6,"P",{});var Joe=s(yd);llr=r(Joe,`Note:
Loading a model from its configuration file does `),V7e=n(Joe,"STRONG",{});var NEt=s(V7e);ilr=r(NEt,"not"),NEt.forEach(t),dlr=r(Joe,` load the model weights. It only affects the
model\u2019s configuration. Use `),KQ=n(Joe,"A",{href:!0});var qEt=s(KQ);clr=r(qEt,"from_pretrained()"),qEt.forEach(t),flr=r(Joe," to load the model weights."),Joe.forEach(t),mlr=i(l6),T(k3.$$.fragment,l6),l6.forEach(t),glr=i(ml),mo=n(ml,"DIV",{class:!0});var Fa=s(mo);T(A8.$$.fragment,Fa),hlr=i(Fa),X7e=n(Fa,"P",{});var jEt=s(X7e);plr=r(jEt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),jEt.forEach(t),_lr=i(Fa),Ha=n(Fa,"P",{});var i6=s(Ha);ulr=r(i6,"The model class to instantiate is selected based on the "),z7e=n(i6,"CODE",{});var DEt=s(z7e);blr=r(DEt,"model_type"),DEt.forEach(t),vlr=r(i6,` property of the config object (either
passed as an argument or loaded from `),Q7e=n(i6,"CODE",{});var GEt=s(Q7e);Flr=r(GEt,"pretrained_model_name_or_path"),GEt.forEach(t),Tlr=r(i6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W7e=n(i6,"CODE",{});var OEt=s(W7e);Mlr=r(OEt,"pretrained_model_name_or_path"),OEt.forEach(t),Elr=r(i6,":"),i6.forEach(t),Clr=i(Fa),et=n(Fa,"UL",{});var gl=s(et);S3=n(gl,"LI",{});var lBe=s(S3);H7e=n(lBe,"STRONG",{});var VEt=s(H7e);wlr=r(VEt,"data2vec-audio"),VEt.forEach(t),Alr=r(lBe," \u2014 "),ZQ=n(lBe,"A",{href:!0});var XEt=s(ZQ);Llr=r(XEt,"Data2VecAudioForAudioFrameClassification"),XEt.forEach(t),ylr=r(lBe," (Data2VecAudio model)"),lBe.forEach(t),xlr=i(gl),R3=n(gl,"LI",{});var iBe=s(R3);U7e=n(iBe,"STRONG",{});var zEt=s(U7e);$lr=r(zEt,"unispeech-sat"),zEt.forEach(t),klr=r(iBe," \u2014 "),eW=n(iBe,"A",{href:!0});var QEt=s(eW);Slr=r(QEt,"UniSpeechSatForAudioFrameClassification"),QEt.forEach(t),Rlr=r(iBe," (UniSpeechSat model)"),iBe.forEach(t),Plr=i(gl),P3=n(gl,"LI",{});var dBe=s(P3);J7e=n(dBe,"STRONG",{});var WEt=s(J7e);Blr=r(WEt,"wav2vec2"),WEt.forEach(t),Ilr=r(dBe," \u2014 "),oW=n(dBe,"A",{href:!0});var HEt=s(oW);Nlr=r(HEt,"Wav2Vec2ForAudioFrameClassification"),HEt.forEach(t),qlr=r(dBe," (Wav2Vec2 model)"),dBe.forEach(t),jlr=i(gl),B3=n(gl,"LI",{});var cBe=s(B3);Y7e=n(cBe,"STRONG",{});var UEt=s(Y7e);Dlr=r(UEt,"wav2vec2-conformer"),UEt.forEach(t),Glr=r(cBe," \u2014 "),rW=n(cBe,"A",{href:!0});var JEt=s(rW);Olr=r(JEt,"Wav2Vec2ConformerForAudioFrameClassification"),JEt.forEach(t),Vlr=r(cBe," (Wav2Vec2-Conformer model)"),cBe.forEach(t),Xlr=i(gl),I3=n(gl,"LI",{});var fBe=s(I3);K7e=n(fBe,"STRONG",{});var YEt=s(K7e);zlr=r(YEt,"wavlm"),YEt.forEach(t),Qlr=r(fBe," \u2014 "),tW=n(fBe,"A",{href:!0});var KEt=s(tW);Wlr=r(KEt,"WavLMForAudioFrameClassification"),KEt.forEach(t),Hlr=r(fBe," (WavLM model)"),fBe.forEach(t),gl.forEach(t),Ulr=i(Fa),N3=n(Fa,"P",{});var mBe=s(N3);Jlr=r(mBe,"The model is set in evaluation mode by default using "),Z7e=n(mBe,"CODE",{});var ZEt=s(Z7e);Ylr=r(ZEt,"model.eval()"),ZEt.forEach(t),Klr=r(mBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),e2e=n(mBe,"CODE",{});var e4t=s(e2e);Zlr=r(e4t,"model.train()"),e4t.forEach(t),mBe.forEach(t),eir=i(Fa),T(q3.$$.fragment,Fa),Fa.forEach(t),ml.forEach(t),$Oe=i(f),xd=n(f,"H2",{class:!0});var IXe=s(xd);j3=n(IXe,"A",{id:!0,class:!0,href:!0});var o4t=s(j3);o2e=n(o4t,"SPAN",{});var r4t=s(o2e);T(L8.$$.fragment,r4t),r4t.forEach(t),o4t.forEach(t),oir=i(IXe),r2e=n(IXe,"SPAN",{});var t4t=s(r2e);rir=r(t4t,"AutoModelForCTC"),t4t.forEach(t),IXe.forEach(t),kOe=i(f),Qo=n(f,"DIV",{class:!0});var hl=s(Qo);T(y8.$$.fragment,hl),tir=i(hl),$d=n(hl,"P",{});var Yoe=s($d);air=r(Yoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),aW=n(Yoe,"A",{href:!0});var a4t=s(aW);nir=r(a4t,"from_pretrained()"),a4t.forEach(t),sir=r(Yoe," class method or the "),nW=n(Yoe,"A",{href:!0});var n4t=s(nW);lir=r(n4t,"from_config()"),n4t.forEach(t),iir=r(Yoe,` class
method.`),Yoe.forEach(t),dir=i(hl),x8=n(hl,"P",{});var NXe=s(x8);cir=r(NXe,"This class cannot be instantiated directly using "),t2e=n(NXe,"CODE",{});var s4t=s(t2e);fir=r(s4t,"__init__()"),s4t.forEach(t),mir=r(NXe," (throws an error)."),NXe.forEach(t),gir=i(hl),Mt=n(hl,"DIV",{class:!0});var d6=s(Mt);T($8.$$.fragment,d6),hir=i(d6),a2e=n(d6,"P",{});var l4t=s(a2e);pir=r(l4t,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),l4t.forEach(t),_ir=i(d6),kd=n(d6,"P",{});var Koe=s(kd);uir=r(Koe,`Note:
Loading a model from its configuration file does `),n2e=n(Koe,"STRONG",{});var i4t=s(n2e);bir=r(i4t,"not"),i4t.forEach(t),vir=r(Koe,` load the model weights. It only affects the
model\u2019s configuration. Use `),sW=n(Koe,"A",{href:!0});var d4t=s(sW);Fir=r(d4t,"from_pretrained()"),d4t.forEach(t),Tir=r(Koe," to load the model weights."),Koe.forEach(t),Mir=i(d6),T(D3.$$.fragment,d6),d6.forEach(t),Eir=i(hl),go=n(hl,"DIV",{class:!0});var Ta=s(go);T(k8.$$.fragment,Ta),Cir=i(Ta),s2e=n(Ta,"P",{});var c4t=s(s2e);wir=r(c4t,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),c4t.forEach(t),Air=i(Ta),Ua=n(Ta,"P",{});var c6=s(Ua);Lir=r(c6,"The model class to instantiate is selected based on the "),l2e=n(c6,"CODE",{});var f4t=s(l2e);yir=r(f4t,"model_type"),f4t.forEach(t),xir=r(c6,` property of the config object (either
passed as an argument or loaded from `),i2e=n(c6,"CODE",{});var m4t=s(i2e);$ir=r(m4t,"pretrained_model_name_or_path"),m4t.forEach(t),kir=r(c6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d2e=n(c6,"CODE",{});var g4t=s(d2e);Sir=r(g4t,"pretrained_model_name_or_path"),g4t.forEach(t),Rir=r(c6,":"),c6.forEach(t),Pir=i(Ta),Le=n(Ta,"UL",{});var Be=s(Le);G3=n(Be,"LI",{});var gBe=s(G3);c2e=n(gBe,"STRONG",{});var h4t=s(c2e);Bir=r(h4t,"data2vec-audio"),h4t.forEach(t),Iir=r(gBe," \u2014 "),lW=n(gBe,"A",{href:!0});var p4t=s(lW);Nir=r(p4t,"Data2VecAudioForCTC"),p4t.forEach(t),qir=r(gBe," (Data2VecAudio model)"),gBe.forEach(t),jir=i(Be),O3=n(Be,"LI",{});var hBe=s(O3);f2e=n(hBe,"STRONG",{});var _4t=s(f2e);Dir=r(_4t,"hubert"),_4t.forEach(t),Gir=r(hBe," \u2014 "),iW=n(hBe,"A",{href:!0});var u4t=s(iW);Oir=r(u4t,"HubertForCTC"),u4t.forEach(t),Vir=r(hBe," (Hubert model)"),hBe.forEach(t),Xir=i(Be),V3=n(Be,"LI",{});var pBe=s(V3);m2e=n(pBe,"STRONG",{});var b4t=s(m2e);zir=r(b4t,"mctct"),b4t.forEach(t),Qir=r(pBe," \u2014 "),dW=n(pBe,"A",{href:!0});var v4t=s(dW);Wir=r(v4t,"MCTCTForCTC"),v4t.forEach(t),Hir=r(pBe," (M-CTC-T model)"),pBe.forEach(t),Uir=i(Be),X3=n(Be,"LI",{});var _Be=s(X3);g2e=n(_Be,"STRONG",{});var F4t=s(g2e);Jir=r(F4t,"sew"),F4t.forEach(t),Yir=r(_Be," \u2014 "),cW=n(_Be,"A",{href:!0});var T4t=s(cW);Kir=r(T4t,"SEWForCTC"),T4t.forEach(t),Zir=r(_Be," (SEW model)"),_Be.forEach(t),edr=i(Be),z3=n(Be,"LI",{});var uBe=s(z3);h2e=n(uBe,"STRONG",{});var M4t=s(h2e);odr=r(M4t,"sew-d"),M4t.forEach(t),rdr=r(uBe," \u2014 "),fW=n(uBe,"A",{href:!0});var E4t=s(fW);tdr=r(E4t,"SEWDForCTC"),E4t.forEach(t),adr=r(uBe," (SEW-D model)"),uBe.forEach(t),ndr=i(Be),Q3=n(Be,"LI",{});var bBe=s(Q3);p2e=n(bBe,"STRONG",{});var C4t=s(p2e);sdr=r(C4t,"unispeech"),C4t.forEach(t),ldr=r(bBe," \u2014 "),mW=n(bBe,"A",{href:!0});var w4t=s(mW);idr=r(w4t,"UniSpeechForCTC"),w4t.forEach(t),ddr=r(bBe," (UniSpeech model)"),bBe.forEach(t),cdr=i(Be),W3=n(Be,"LI",{});var vBe=s(W3);_2e=n(vBe,"STRONG",{});var A4t=s(_2e);fdr=r(A4t,"unispeech-sat"),A4t.forEach(t),mdr=r(vBe," \u2014 "),gW=n(vBe,"A",{href:!0});var L4t=s(gW);gdr=r(L4t,"UniSpeechSatForCTC"),L4t.forEach(t),hdr=r(vBe," (UniSpeechSat model)"),vBe.forEach(t),pdr=i(Be),H3=n(Be,"LI",{});var FBe=s(H3);u2e=n(FBe,"STRONG",{});var y4t=s(u2e);_dr=r(y4t,"wav2vec2"),y4t.forEach(t),udr=r(FBe," \u2014 "),hW=n(FBe,"A",{href:!0});var x4t=s(hW);bdr=r(x4t,"Wav2Vec2ForCTC"),x4t.forEach(t),vdr=r(FBe," (Wav2Vec2 model)"),FBe.forEach(t),Fdr=i(Be),U3=n(Be,"LI",{});var TBe=s(U3);b2e=n(TBe,"STRONG",{});var $4t=s(b2e);Tdr=r($4t,"wav2vec2-conformer"),$4t.forEach(t),Mdr=r(TBe," \u2014 "),pW=n(TBe,"A",{href:!0});var k4t=s(pW);Edr=r(k4t,"Wav2Vec2ConformerForCTC"),k4t.forEach(t),Cdr=r(TBe," (Wav2Vec2-Conformer model)"),TBe.forEach(t),wdr=i(Be),J3=n(Be,"LI",{});var MBe=s(J3);v2e=n(MBe,"STRONG",{});var S4t=s(v2e);Adr=r(S4t,"wavlm"),S4t.forEach(t),Ldr=r(MBe," \u2014 "),_W=n(MBe,"A",{href:!0});var R4t=s(_W);ydr=r(R4t,"WavLMForCTC"),R4t.forEach(t),xdr=r(MBe," (WavLM model)"),MBe.forEach(t),Be.forEach(t),$dr=i(Ta),Y3=n(Ta,"P",{});var EBe=s(Y3);kdr=r(EBe,"The model is set in evaluation mode by default using "),F2e=n(EBe,"CODE",{});var P4t=s(F2e);Sdr=r(P4t,"model.eval()"),P4t.forEach(t),Rdr=r(EBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),T2e=n(EBe,"CODE",{});var B4t=s(T2e);Pdr=r(B4t,"model.train()"),B4t.forEach(t),EBe.forEach(t),Bdr=i(Ta),T(K3.$$.fragment,Ta),Ta.forEach(t),hl.forEach(t),SOe=i(f),Sd=n(f,"H2",{class:!0});var qXe=s(Sd);Z3=n(qXe,"A",{id:!0,class:!0,href:!0});var I4t=s(Z3);M2e=n(I4t,"SPAN",{});var N4t=s(M2e);T(S8.$$.fragment,N4t),N4t.forEach(t),I4t.forEach(t),Idr=i(qXe),E2e=n(qXe,"SPAN",{});var q4t=s(E2e);Ndr=r(q4t,"AutoModelForSpeechSeq2Seq"),q4t.forEach(t),qXe.forEach(t),ROe=i(f),Wo=n(f,"DIV",{class:!0});var pl=s(Wo);T(R8.$$.fragment,pl),qdr=i(pl),Rd=n(pl,"P",{});var Zoe=s(Rd);jdr=r(Zoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),uW=n(Zoe,"A",{href:!0});var j4t=s(uW);Ddr=r(j4t,"from_pretrained()"),j4t.forEach(t),Gdr=r(Zoe," class method or the "),bW=n(Zoe,"A",{href:!0});var D4t=s(bW);Odr=r(D4t,"from_config()"),D4t.forEach(t),Vdr=r(Zoe,` class
method.`),Zoe.forEach(t),Xdr=i(pl),P8=n(pl,"P",{});var jXe=s(P8);zdr=r(jXe,"This class cannot be instantiated directly using "),C2e=n(jXe,"CODE",{});var G4t=s(C2e);Qdr=r(G4t,"__init__()"),G4t.forEach(t),Wdr=r(jXe," (throws an error)."),jXe.forEach(t),Hdr=i(pl),Et=n(pl,"DIV",{class:!0});var f6=s(Et);T(B8.$$.fragment,f6),Udr=i(f6),w2e=n(f6,"P",{});var O4t=s(w2e);Jdr=r(O4t,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),O4t.forEach(t),Ydr=i(f6),Pd=n(f6,"P",{});var ere=s(Pd);Kdr=r(ere,`Note:
Loading a model from its configuration file does `),A2e=n(ere,"STRONG",{});var V4t=s(A2e);Zdr=r(V4t,"not"),V4t.forEach(t),ecr=r(ere,` load the model weights. It only affects the
model\u2019s configuration. Use `),vW=n(ere,"A",{href:!0});var X4t=s(vW);ocr=r(X4t,"from_pretrained()"),X4t.forEach(t),rcr=r(ere," to load the model weights."),ere.forEach(t),tcr=i(f6),T(eF.$$.fragment,f6),f6.forEach(t),acr=i(pl),ho=n(pl,"DIV",{class:!0});var Ma=s(ho);T(I8.$$.fragment,Ma),ncr=i(Ma),L2e=n(Ma,"P",{});var z4t=s(L2e);scr=r(z4t,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),z4t.forEach(t),lcr=i(Ma),Ja=n(Ma,"P",{});var m6=s(Ja);icr=r(m6,"The model class to instantiate is selected based on the "),y2e=n(m6,"CODE",{});var Q4t=s(y2e);dcr=r(Q4t,"model_type"),Q4t.forEach(t),ccr=r(m6,` property of the config object (either
passed as an argument or loaded from `),x2e=n(m6,"CODE",{});var W4t=s(x2e);fcr=r(W4t,"pretrained_model_name_or_path"),W4t.forEach(t),mcr=r(m6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$2e=n(m6,"CODE",{});var H4t=s($2e);gcr=r(H4t,"pretrained_model_name_or_path"),H4t.forEach(t),hcr=r(m6,":"),m6.forEach(t),pcr=i(Ma),N8=n(Ma,"UL",{});var DXe=s(N8);oF=n(DXe,"LI",{});var CBe=s(oF);k2e=n(CBe,"STRONG",{});var U4t=s(k2e);_cr=r(U4t,"speech-encoder-decoder"),U4t.forEach(t),ucr=r(CBe," \u2014 "),FW=n(CBe,"A",{href:!0});var J4t=s(FW);bcr=r(J4t,"SpeechEncoderDecoderModel"),J4t.forEach(t),vcr=r(CBe," (Speech Encoder decoder model)"),CBe.forEach(t),Fcr=i(DXe),rF=n(DXe,"LI",{});var wBe=s(rF);S2e=n(wBe,"STRONG",{});var Y4t=s(S2e);Tcr=r(Y4t,"speech_to_text"),Y4t.forEach(t),Mcr=r(wBe," \u2014 "),TW=n(wBe,"A",{href:!0});var K4t=s(TW);Ecr=r(K4t,"Speech2TextForConditionalGeneration"),K4t.forEach(t),Ccr=r(wBe," (Speech2Text model)"),wBe.forEach(t),DXe.forEach(t),wcr=i(Ma),tF=n(Ma,"P",{});var ABe=s(tF);Acr=r(ABe,"The model is set in evaluation mode by default using "),R2e=n(ABe,"CODE",{});var Z4t=s(R2e);Lcr=r(Z4t,"model.eval()"),Z4t.forEach(t),ycr=r(ABe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P2e=n(ABe,"CODE",{});var eCt=s(P2e);xcr=r(eCt,"model.train()"),eCt.forEach(t),ABe.forEach(t),$cr=i(Ma),T(aF.$$.fragment,Ma),Ma.forEach(t),pl.forEach(t),POe=i(f),Bd=n(f,"H2",{class:!0});var GXe=s(Bd);nF=n(GXe,"A",{id:!0,class:!0,href:!0});var oCt=s(nF);B2e=n(oCt,"SPAN",{});var rCt=s(B2e);T(q8.$$.fragment,rCt),rCt.forEach(t),oCt.forEach(t),kcr=i(GXe),I2e=n(GXe,"SPAN",{});var tCt=s(I2e);Scr=r(tCt,"AutoModelForAudioXVector"),tCt.forEach(t),GXe.forEach(t),BOe=i(f),Ho=n(f,"DIV",{class:!0});var _l=s(Ho);T(j8.$$.fragment,_l),Rcr=i(_l),Id=n(_l,"P",{});var ore=s(Id);Pcr=r(ore,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),MW=n(ore,"A",{href:!0});var aCt=s(MW);Bcr=r(aCt,"from_pretrained()"),aCt.forEach(t),Icr=r(ore," class method or the "),EW=n(ore,"A",{href:!0});var nCt=s(EW);Ncr=r(nCt,"from_config()"),nCt.forEach(t),qcr=r(ore,` class
method.`),ore.forEach(t),jcr=i(_l),D8=n(_l,"P",{});var OXe=s(D8);Dcr=r(OXe,"This class cannot be instantiated directly using "),N2e=n(OXe,"CODE",{});var sCt=s(N2e);Gcr=r(sCt,"__init__()"),sCt.forEach(t),Ocr=r(OXe," (throws an error)."),OXe.forEach(t),Vcr=i(_l),Ct=n(_l,"DIV",{class:!0});var g6=s(Ct);T(G8.$$.fragment,g6),Xcr=i(g6),q2e=n(g6,"P",{});var lCt=s(q2e);zcr=r(lCt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),lCt.forEach(t),Qcr=i(g6),Nd=n(g6,"P",{});var rre=s(Nd);Wcr=r(rre,`Note:
Loading a model from its configuration file does `),j2e=n(rre,"STRONG",{});var iCt=s(j2e);Hcr=r(iCt,"not"),iCt.forEach(t),Ucr=r(rre,` load the model weights. It only affects the
model\u2019s configuration. Use `),CW=n(rre,"A",{href:!0});var dCt=s(CW);Jcr=r(dCt,"from_pretrained()"),dCt.forEach(t),Ycr=r(rre," to load the model weights."),rre.forEach(t),Kcr=i(g6),T(sF.$$.fragment,g6),g6.forEach(t),Zcr=i(_l),po=n(_l,"DIV",{class:!0});var Ea=s(po);T(O8.$$.fragment,Ea),efr=i(Ea),D2e=n(Ea,"P",{});var cCt=s(D2e);ofr=r(cCt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),cCt.forEach(t),rfr=i(Ea),Ya=n(Ea,"P",{});var h6=s(Ya);tfr=r(h6,"The model class to instantiate is selected based on the "),G2e=n(h6,"CODE",{});var fCt=s(G2e);afr=r(fCt,"model_type"),fCt.forEach(t),nfr=r(h6,` property of the config object (either
passed as an argument or loaded from `),O2e=n(h6,"CODE",{});var mCt=s(O2e);sfr=r(mCt,"pretrained_model_name_or_path"),mCt.forEach(t),lfr=r(h6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V2e=n(h6,"CODE",{});var gCt=s(V2e);ifr=r(gCt,"pretrained_model_name_or_path"),gCt.forEach(t),dfr=r(h6,":"),h6.forEach(t),cfr=i(Ea),ot=n(Ea,"UL",{});var ul=s(ot);lF=n(ul,"LI",{});var LBe=s(lF);X2e=n(LBe,"STRONG",{});var hCt=s(X2e);ffr=r(hCt,"data2vec-audio"),hCt.forEach(t),mfr=r(LBe," \u2014 "),wW=n(LBe,"A",{href:!0});var pCt=s(wW);gfr=r(pCt,"Data2VecAudioForXVector"),pCt.forEach(t),hfr=r(LBe," (Data2VecAudio model)"),LBe.forEach(t),pfr=i(ul),iF=n(ul,"LI",{});var yBe=s(iF);z2e=n(yBe,"STRONG",{});var _Ct=s(z2e);_fr=r(_Ct,"unispeech-sat"),_Ct.forEach(t),ufr=r(yBe," \u2014 "),AW=n(yBe,"A",{href:!0});var uCt=s(AW);bfr=r(uCt,"UniSpeechSatForXVector"),uCt.forEach(t),vfr=r(yBe," (UniSpeechSat model)"),yBe.forEach(t),Ffr=i(ul),dF=n(ul,"LI",{});var xBe=s(dF);Q2e=n(xBe,"STRONG",{});var bCt=s(Q2e);Tfr=r(bCt,"wav2vec2"),bCt.forEach(t),Mfr=r(xBe," \u2014 "),LW=n(xBe,"A",{href:!0});var vCt=s(LW);Efr=r(vCt,"Wav2Vec2ForXVector"),vCt.forEach(t),Cfr=r(xBe," (Wav2Vec2 model)"),xBe.forEach(t),wfr=i(ul),cF=n(ul,"LI",{});var $Be=s(cF);W2e=n($Be,"STRONG",{});var FCt=s(W2e);Afr=r(FCt,"wav2vec2-conformer"),FCt.forEach(t),Lfr=r($Be," \u2014 "),yW=n($Be,"A",{href:!0});var TCt=s(yW);yfr=r(TCt,"Wav2Vec2ConformerForXVector"),TCt.forEach(t),xfr=r($Be," (Wav2Vec2-Conformer model)"),$Be.forEach(t),$fr=i(ul),fF=n(ul,"LI",{});var kBe=s(fF);H2e=n(kBe,"STRONG",{});var MCt=s(H2e);kfr=r(MCt,"wavlm"),MCt.forEach(t),Sfr=r(kBe," \u2014 "),xW=n(kBe,"A",{href:!0});var ECt=s(xW);Rfr=r(ECt,"WavLMForXVector"),ECt.forEach(t),Pfr=r(kBe," (WavLM model)"),kBe.forEach(t),ul.forEach(t),Bfr=i(Ea),mF=n(Ea,"P",{});var SBe=s(mF);Ifr=r(SBe,"The model is set in evaluation mode by default using "),U2e=n(SBe,"CODE",{});var CCt=s(U2e);Nfr=r(CCt,"model.eval()"),CCt.forEach(t),qfr=r(SBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),J2e=n(SBe,"CODE",{});var wCt=s(J2e);jfr=r(wCt,"model.train()"),wCt.forEach(t),SBe.forEach(t),Dfr=i(Ea),T(gF.$$.fragment,Ea),Ea.forEach(t),_l.forEach(t),IOe=i(f),qd=n(f,"H2",{class:!0});var VXe=s(qd);hF=n(VXe,"A",{id:!0,class:!0,href:!0});var ACt=s(hF);Y2e=n(ACt,"SPAN",{});var LCt=s(Y2e);T(V8.$$.fragment,LCt),LCt.forEach(t),ACt.forEach(t),Gfr=i(VXe),K2e=n(VXe,"SPAN",{});var yCt=s(K2e);Ofr=r(yCt,"AutoModelForMaskedImageModeling"),yCt.forEach(t),VXe.forEach(t),NOe=i(f),Uo=n(f,"DIV",{class:!0});var bl=s(Uo);T(X8.$$.fragment,bl),Vfr=i(bl),jd=n(bl,"P",{});var tre=s(jd);Xfr=r(tre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),$W=n(tre,"A",{href:!0});var xCt=s($W);zfr=r(xCt,"from_pretrained()"),xCt.forEach(t),Qfr=r(tre," class method or the "),kW=n(tre,"A",{href:!0});var $Ct=s(kW);Wfr=r($Ct,"from_config()"),$Ct.forEach(t),Hfr=r(tre,` class
method.`),tre.forEach(t),Ufr=i(bl),z8=n(bl,"P",{});var XXe=s(z8);Jfr=r(XXe,"This class cannot be instantiated directly using "),Z2e=n(XXe,"CODE",{});var kCt=s(Z2e);Yfr=r(kCt,"__init__()"),kCt.forEach(t),Kfr=r(XXe," (throws an error)."),XXe.forEach(t),Zfr=i(bl),wt=n(bl,"DIV",{class:!0});var p6=s(wt);T(Q8.$$.fragment,p6),emr=i(p6),ebe=n(p6,"P",{});var SCt=s(ebe);omr=r(SCt,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),SCt.forEach(t),rmr=i(p6),Dd=n(p6,"P",{});var are=s(Dd);tmr=r(are,`Note:
Loading a model from its configuration file does `),obe=n(are,"STRONG",{});var RCt=s(obe);amr=r(RCt,"not"),RCt.forEach(t),nmr=r(are,` load the model weights. It only affects the
model\u2019s configuration. Use `),SW=n(are,"A",{href:!0});var PCt=s(SW);smr=r(PCt,"from_pretrained()"),PCt.forEach(t),lmr=r(are," to load the model weights."),are.forEach(t),imr=i(p6),T(pF.$$.fragment,p6),p6.forEach(t),dmr=i(bl),_o=n(bl,"DIV",{class:!0});var Ca=s(_o);T(W8.$$.fragment,Ca),cmr=i(Ca),rbe=n(Ca,"P",{});var BCt=s(rbe);fmr=r(BCt,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),BCt.forEach(t),mmr=i(Ca),Ka=n(Ca,"P",{});var _6=s(Ka);gmr=r(_6,"The model class to instantiate is selected based on the "),tbe=n(_6,"CODE",{});var ICt=s(tbe);hmr=r(ICt,"model_type"),ICt.forEach(t),pmr=r(_6,` property of the config object (either
passed as an argument or loaded from `),abe=n(_6,"CODE",{});var NCt=s(abe);_mr=r(NCt,"pretrained_model_name_or_path"),NCt.forEach(t),umr=r(_6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nbe=n(_6,"CODE",{});var qCt=s(nbe);bmr=r(qCt,"pretrained_model_name_or_path"),qCt.forEach(t),vmr=r(_6,":"),_6.forEach(t),Fmr=i(Ca),Gd=n(Ca,"UL",{});var nre=s(Gd);_F=n(nre,"LI",{});var RBe=s(_F);sbe=n(RBe,"STRONG",{});var jCt=s(sbe);Tmr=r(jCt,"deit"),jCt.forEach(t),Mmr=r(RBe," \u2014 "),RW=n(RBe,"A",{href:!0});var DCt=s(RW);Emr=r(DCt,"DeiTForMaskedImageModeling"),DCt.forEach(t),Cmr=r(RBe," (DeiT model)"),RBe.forEach(t),wmr=i(nre),uF=n(nre,"LI",{});var PBe=s(uF);lbe=n(PBe,"STRONG",{});var GCt=s(lbe);Amr=r(GCt,"swin"),GCt.forEach(t),Lmr=r(PBe," \u2014 "),PW=n(PBe,"A",{href:!0});var OCt=s(PW);ymr=r(OCt,"SwinForMaskedImageModeling"),OCt.forEach(t),xmr=r(PBe," (Swin Transformer model)"),PBe.forEach(t),$mr=i(nre),bF=n(nre,"LI",{});var BBe=s(bF);ibe=n(BBe,"STRONG",{});var VCt=s(ibe);kmr=r(VCt,"vit"),VCt.forEach(t),Smr=r(BBe," \u2014 "),BW=n(BBe,"A",{href:!0});var XCt=s(BW);Rmr=r(XCt,"ViTForMaskedImageModeling"),XCt.forEach(t),Pmr=r(BBe," (ViT model)"),BBe.forEach(t),nre.forEach(t),Bmr=i(Ca),vF=n(Ca,"P",{});var IBe=s(vF);Imr=r(IBe,"The model is set in evaluation mode by default using "),dbe=n(IBe,"CODE",{});var zCt=s(dbe);Nmr=r(zCt,"model.eval()"),zCt.forEach(t),qmr=r(IBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cbe=n(IBe,"CODE",{});var QCt=s(cbe);jmr=r(QCt,"model.train()"),QCt.forEach(t),IBe.forEach(t),Dmr=i(Ca),T(FF.$$.fragment,Ca),Ca.forEach(t),bl.forEach(t),qOe=i(f),Od=n(f,"H2",{class:!0});var zXe=s(Od);TF=n(zXe,"A",{id:!0,class:!0,href:!0});var WCt=s(TF);fbe=n(WCt,"SPAN",{});var HCt=s(fbe);T(H8.$$.fragment,HCt),HCt.forEach(t),WCt.forEach(t),Gmr=i(zXe),mbe=n(zXe,"SPAN",{});var UCt=s(mbe);Omr=r(UCt,"AutoModelForObjectDetection"),UCt.forEach(t),zXe.forEach(t),jOe=i(f),Jo=n(f,"DIV",{class:!0});var vl=s(Jo);T(U8.$$.fragment,vl),Vmr=i(vl),Vd=n(vl,"P",{});var sre=s(Vd);Xmr=r(sre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),IW=n(sre,"A",{href:!0});var JCt=s(IW);zmr=r(JCt,"from_pretrained()"),JCt.forEach(t),Qmr=r(sre," class method or the "),NW=n(sre,"A",{href:!0});var YCt=s(NW);Wmr=r(YCt,"from_config()"),YCt.forEach(t),Hmr=r(sre,` class
method.`),sre.forEach(t),Umr=i(vl),J8=n(vl,"P",{});var QXe=s(J8);Jmr=r(QXe,"This class cannot be instantiated directly using "),gbe=n(QXe,"CODE",{});var KCt=s(gbe);Ymr=r(KCt,"__init__()"),KCt.forEach(t),Kmr=r(QXe," (throws an error)."),QXe.forEach(t),Zmr=i(vl),At=n(vl,"DIV",{class:!0});var u6=s(At);T(Y8.$$.fragment,u6),egr=i(u6),hbe=n(u6,"P",{});var ZCt=s(hbe);ogr=r(ZCt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),ZCt.forEach(t),rgr=i(u6),Xd=n(u6,"P",{});var lre=s(Xd);tgr=r(lre,`Note:
Loading a model from its configuration file does `),pbe=n(lre,"STRONG",{});var e0t=s(pbe);agr=r(e0t,"not"),e0t.forEach(t),ngr=r(lre,` load the model weights. It only affects the
model\u2019s configuration. Use `),qW=n(lre,"A",{href:!0});var o0t=s(qW);sgr=r(o0t,"from_pretrained()"),o0t.forEach(t),lgr=r(lre," to load the model weights."),lre.forEach(t),igr=i(u6),T(MF.$$.fragment,u6),u6.forEach(t),dgr=i(vl),uo=n(vl,"DIV",{class:!0});var wa=s(uo);T(K8.$$.fragment,wa),cgr=i(wa),_be=n(wa,"P",{});var r0t=s(_be);fgr=r(r0t,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),r0t.forEach(t),mgr=i(wa),Za=n(wa,"P",{});var b6=s(Za);ggr=r(b6,"The model class to instantiate is selected based on the "),ube=n(b6,"CODE",{});var t0t=s(ube);hgr=r(t0t,"model_type"),t0t.forEach(t),pgr=r(b6,` property of the config object (either
passed as an argument or loaded from `),bbe=n(b6,"CODE",{});var a0t=s(bbe);_gr=r(a0t,"pretrained_model_name_or_path"),a0t.forEach(t),ugr=r(b6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vbe=n(b6,"CODE",{});var n0t=s(vbe);bgr=r(n0t,"pretrained_model_name_or_path"),n0t.forEach(t),vgr=r(b6,":"),b6.forEach(t),Fgr=i(wa),Z8=n(wa,"UL",{});var WXe=s(Z8);EF=n(WXe,"LI",{});var NBe=s(EF);Fbe=n(NBe,"STRONG",{});var s0t=s(Fbe);Tgr=r(s0t,"detr"),s0t.forEach(t),Mgr=r(NBe," \u2014 "),jW=n(NBe,"A",{href:!0});var l0t=s(jW);Egr=r(l0t,"DetrForObjectDetection"),l0t.forEach(t),Cgr=r(NBe," (DETR model)"),NBe.forEach(t),wgr=i(WXe),CF=n(WXe,"LI",{});var qBe=s(CF);Tbe=n(qBe,"STRONG",{});var i0t=s(Tbe);Agr=r(i0t,"yolos"),i0t.forEach(t),Lgr=r(qBe," \u2014 "),DW=n(qBe,"A",{href:!0});var d0t=s(DW);ygr=r(d0t,"YolosForObjectDetection"),d0t.forEach(t),xgr=r(qBe," (YOLOS model)"),qBe.forEach(t),WXe.forEach(t),$gr=i(wa),wF=n(wa,"P",{});var jBe=s(wF);kgr=r(jBe,"The model is set in evaluation mode by default using "),Mbe=n(jBe,"CODE",{});var c0t=s(Mbe);Sgr=r(c0t,"model.eval()"),c0t.forEach(t),Rgr=r(jBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ebe=n(jBe,"CODE",{});var f0t=s(Ebe);Pgr=r(f0t,"model.train()"),f0t.forEach(t),jBe.forEach(t),Bgr=i(wa),T(AF.$$.fragment,wa),wa.forEach(t),vl.forEach(t),DOe=i(f),zd=n(f,"H2",{class:!0});var HXe=s(zd);LF=n(HXe,"A",{id:!0,class:!0,href:!0});var m0t=s(LF);Cbe=n(m0t,"SPAN",{});var g0t=s(Cbe);T(e9.$$.fragment,g0t),g0t.forEach(t),m0t.forEach(t),Igr=i(HXe),wbe=n(HXe,"SPAN",{});var h0t=s(wbe);Ngr=r(h0t,"AutoModelForImageSegmentation"),h0t.forEach(t),HXe.forEach(t),GOe=i(f),Yo=n(f,"DIV",{class:!0});var Fl=s(Yo);T(o9.$$.fragment,Fl),qgr=i(Fl),Qd=n(Fl,"P",{});var ire=s(Qd);jgr=r(ire,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),GW=n(ire,"A",{href:!0});var p0t=s(GW);Dgr=r(p0t,"from_pretrained()"),p0t.forEach(t),Ggr=r(ire," class method or the "),OW=n(ire,"A",{href:!0});var _0t=s(OW);Ogr=r(_0t,"from_config()"),_0t.forEach(t),Vgr=r(ire,` class
method.`),ire.forEach(t),Xgr=i(Fl),r9=n(Fl,"P",{});var UXe=s(r9);zgr=r(UXe,"This class cannot be instantiated directly using "),Abe=n(UXe,"CODE",{});var u0t=s(Abe);Qgr=r(u0t,"__init__()"),u0t.forEach(t),Wgr=r(UXe," (throws an error)."),UXe.forEach(t),Hgr=i(Fl),Lt=n(Fl,"DIV",{class:!0});var v6=s(Lt);T(t9.$$.fragment,v6),Ugr=i(v6),Lbe=n(v6,"P",{});var b0t=s(Lbe);Jgr=r(b0t,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),b0t.forEach(t),Ygr=i(v6),Wd=n(v6,"P",{});var dre=s(Wd);Kgr=r(dre,`Note:
Loading a model from its configuration file does `),ybe=n(dre,"STRONG",{});var v0t=s(ybe);Zgr=r(v0t,"not"),v0t.forEach(t),ehr=r(dre,` load the model weights. It only affects the
model\u2019s configuration. Use `),VW=n(dre,"A",{href:!0});var F0t=s(VW);ohr=r(F0t,"from_pretrained()"),F0t.forEach(t),rhr=r(dre," to load the model weights."),dre.forEach(t),thr=i(v6),T(yF.$$.fragment,v6),v6.forEach(t),ahr=i(Fl),bo=n(Fl,"DIV",{class:!0});var Aa=s(bo);T(a9.$$.fragment,Aa),nhr=i(Aa),xbe=n(Aa,"P",{});var T0t=s(xbe);shr=r(T0t,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),T0t.forEach(t),lhr=i(Aa),en=n(Aa,"P",{});var F6=s(en);ihr=r(F6,"The model class to instantiate is selected based on the "),$be=n(F6,"CODE",{});var M0t=s($be);dhr=r(M0t,"model_type"),M0t.forEach(t),chr=r(F6,` property of the config object (either
passed as an argument or loaded from `),kbe=n(F6,"CODE",{});var E0t=s(kbe);fhr=r(E0t,"pretrained_model_name_or_path"),E0t.forEach(t),mhr=r(F6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sbe=n(F6,"CODE",{});var C0t=s(Sbe);ghr=r(C0t,"pretrained_model_name_or_path"),C0t.forEach(t),hhr=r(F6,":"),F6.forEach(t),phr=i(Aa),Rbe=n(Aa,"UL",{});var w0t=s(Rbe);xF=n(w0t,"LI",{});var DBe=s(xF);Pbe=n(DBe,"STRONG",{});var A0t=s(Pbe);_hr=r(A0t,"detr"),A0t.forEach(t),uhr=r(DBe," \u2014 "),XW=n(DBe,"A",{href:!0});var L0t=s(XW);bhr=r(L0t,"DetrForSegmentation"),L0t.forEach(t),vhr=r(DBe," (DETR model)"),DBe.forEach(t),w0t.forEach(t),Fhr=i(Aa),$F=n(Aa,"P",{});var GBe=s($F);Thr=r(GBe,"The model is set in evaluation mode by default using "),Bbe=n(GBe,"CODE",{});var y0t=s(Bbe);Mhr=r(y0t,"model.eval()"),y0t.forEach(t),Ehr=r(GBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ibe=n(GBe,"CODE",{});var x0t=s(Ibe);Chr=r(x0t,"model.train()"),x0t.forEach(t),GBe.forEach(t),whr=i(Aa),T(kF.$$.fragment,Aa),Aa.forEach(t),Fl.forEach(t),OOe=i(f),Hd=n(f,"H2",{class:!0});var JXe=s(Hd);SF=n(JXe,"A",{id:!0,class:!0,href:!0});var $0t=s(SF);Nbe=n($0t,"SPAN",{});var k0t=s(Nbe);T(n9.$$.fragment,k0t),k0t.forEach(t),$0t.forEach(t),Ahr=i(JXe),qbe=n(JXe,"SPAN",{});var S0t=s(qbe);Lhr=r(S0t,"AutoModelForSemanticSegmentation"),S0t.forEach(t),JXe.forEach(t),VOe=i(f),Ko=n(f,"DIV",{class:!0});var Tl=s(Ko);T(s9.$$.fragment,Tl),yhr=i(Tl),Ud=n(Tl,"P",{});var cre=s(Ud);xhr=r(cre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),zW=n(cre,"A",{href:!0});var R0t=s(zW);$hr=r(R0t,"from_pretrained()"),R0t.forEach(t),khr=r(cre," class method or the "),QW=n(cre,"A",{href:!0});var P0t=s(QW);Shr=r(P0t,"from_config()"),P0t.forEach(t),Rhr=r(cre,` class
method.`),cre.forEach(t),Phr=i(Tl),l9=n(Tl,"P",{});var YXe=s(l9);Bhr=r(YXe,"This class cannot be instantiated directly using "),jbe=n(YXe,"CODE",{});var B0t=s(jbe);Ihr=r(B0t,"__init__()"),B0t.forEach(t),Nhr=r(YXe," (throws an error)."),YXe.forEach(t),qhr=i(Tl),yt=n(Tl,"DIV",{class:!0});var T6=s(yt);T(i9.$$.fragment,T6),jhr=i(T6),Dbe=n(T6,"P",{});var I0t=s(Dbe);Dhr=r(I0t,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),I0t.forEach(t),Ghr=i(T6),Jd=n(T6,"P",{});var fre=s(Jd);Ohr=r(fre,`Note:
Loading a model from its configuration file does `),Gbe=n(fre,"STRONG",{});var N0t=s(Gbe);Vhr=r(N0t,"not"),N0t.forEach(t),Xhr=r(fre,` load the model weights. It only affects the
model\u2019s configuration. Use `),WW=n(fre,"A",{href:!0});var q0t=s(WW);zhr=r(q0t,"from_pretrained()"),q0t.forEach(t),Qhr=r(fre," to load the model weights."),fre.forEach(t),Whr=i(T6),T(RF.$$.fragment,T6),T6.forEach(t),Hhr=i(Tl),vo=n(Tl,"DIV",{class:!0});var La=s(vo);T(d9.$$.fragment,La),Uhr=i(La),Obe=n(La,"P",{});var j0t=s(Obe);Jhr=r(j0t,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),j0t.forEach(t),Yhr=i(La),on=n(La,"P",{});var M6=s(on);Khr=r(M6,"The model class to instantiate is selected based on the "),Vbe=n(M6,"CODE",{});var D0t=s(Vbe);Zhr=r(D0t,"model_type"),D0t.forEach(t),epr=r(M6,` property of the config object (either
passed as an argument or loaded from `),Xbe=n(M6,"CODE",{});var G0t=s(Xbe);opr=r(G0t,"pretrained_model_name_or_path"),G0t.forEach(t),rpr=r(M6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zbe=n(M6,"CODE",{});var O0t=s(zbe);tpr=r(O0t,"pretrained_model_name_or_path"),O0t.forEach(t),apr=r(M6,":"),M6.forEach(t),npr=i(La),rn=n(La,"UL",{});var E6=s(rn);PF=n(E6,"LI",{});var OBe=s(PF);Qbe=n(OBe,"STRONG",{});var V0t=s(Qbe);spr=r(V0t,"beit"),V0t.forEach(t),lpr=r(OBe," \u2014 "),HW=n(OBe,"A",{href:!0});var X0t=s(HW);ipr=r(X0t,"BeitForSemanticSegmentation"),X0t.forEach(t),dpr=r(OBe," (BEiT model)"),OBe.forEach(t),cpr=i(E6),BF=n(E6,"LI",{});var VBe=s(BF);Wbe=n(VBe,"STRONG",{});var z0t=s(Wbe);fpr=r(z0t,"data2vec-vision"),z0t.forEach(t),mpr=r(VBe," \u2014 "),UW=n(VBe,"A",{href:!0});var Q0t=s(UW);gpr=r(Q0t,"Data2VecVisionForSemanticSegmentation"),Q0t.forEach(t),hpr=r(VBe," (Data2VecVision model)"),VBe.forEach(t),ppr=i(E6),IF=n(E6,"LI",{});var XBe=s(IF);Hbe=n(XBe,"STRONG",{});var W0t=s(Hbe);_pr=r(W0t,"dpt"),W0t.forEach(t),upr=r(XBe," \u2014 "),JW=n(XBe,"A",{href:!0});var H0t=s(JW);bpr=r(H0t,"DPTForSemanticSegmentation"),H0t.forEach(t),vpr=r(XBe," (DPT model)"),XBe.forEach(t),Fpr=i(E6),NF=n(E6,"LI",{});var zBe=s(NF);Ube=n(zBe,"STRONG",{});var U0t=s(Ube);Tpr=r(U0t,"segformer"),U0t.forEach(t),Mpr=r(zBe," \u2014 "),YW=n(zBe,"A",{href:!0});var J0t=s(YW);Epr=r(J0t,"SegformerForSemanticSegmentation"),J0t.forEach(t),Cpr=r(zBe," (SegFormer model)"),zBe.forEach(t),E6.forEach(t),wpr=i(La),qF=n(La,"P",{});var QBe=s(qF);Apr=r(QBe,"The model is set in evaluation mode by default using "),Jbe=n(QBe,"CODE",{});var Y0t=s(Jbe);Lpr=r(Y0t,"model.eval()"),Y0t.forEach(t),ypr=r(QBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ybe=n(QBe,"CODE",{});var K0t=s(Ybe);xpr=r(K0t,"model.train()"),K0t.forEach(t),QBe.forEach(t),$pr=i(La),T(jF.$$.fragment,La),La.forEach(t),Tl.forEach(t),XOe=i(f),Yd=n(f,"H2",{class:!0});var KXe=s(Yd);DF=n(KXe,"A",{id:!0,class:!0,href:!0});var Z0t=s(DF);Kbe=n(Z0t,"SPAN",{});var ewt=s(Kbe);T(c9.$$.fragment,ewt),ewt.forEach(t),Z0t.forEach(t),kpr=i(KXe),Zbe=n(KXe,"SPAN",{});var owt=s(Zbe);Spr=r(owt,"AutoModelForInstanceSegmentation"),owt.forEach(t),KXe.forEach(t),zOe=i(f),Zo=n(f,"DIV",{class:!0});var Ml=s(Zo);T(f9.$$.fragment,Ml),Rpr=i(Ml),Kd=n(Ml,"P",{});var mre=s(Kd);Ppr=r(mre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),KW=n(mre,"A",{href:!0});var rwt=s(KW);Bpr=r(rwt,"from_pretrained()"),rwt.forEach(t),Ipr=r(mre," class method or the "),ZW=n(mre,"A",{href:!0});var twt=s(ZW);Npr=r(twt,"from_config()"),twt.forEach(t),qpr=r(mre,` class
method.`),mre.forEach(t),jpr=i(Ml),m9=n(Ml,"P",{});var ZXe=s(m9);Dpr=r(ZXe,"This class cannot be instantiated directly using "),e5e=n(ZXe,"CODE",{});var awt=s(e5e);Gpr=r(awt,"__init__()"),awt.forEach(t),Opr=r(ZXe," (throws an error)."),ZXe.forEach(t),Vpr=i(Ml),xt=n(Ml,"DIV",{class:!0});var C6=s(xt);T(g9.$$.fragment,C6),Xpr=i(C6),o5e=n(C6,"P",{});var nwt=s(o5e);zpr=r(nwt,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),nwt.forEach(t),Qpr=i(C6),Zd=n(C6,"P",{});var gre=s(Zd);Wpr=r(gre,`Note:
Loading a model from its configuration file does `),r5e=n(gre,"STRONG",{});var swt=s(r5e);Hpr=r(swt,"not"),swt.forEach(t),Upr=r(gre,` load the model weights. It only affects the
model\u2019s configuration. Use `),eH=n(gre,"A",{href:!0});var lwt=s(eH);Jpr=r(lwt,"from_pretrained()"),lwt.forEach(t),Ypr=r(gre," to load the model weights."),gre.forEach(t),Kpr=i(C6),T(GF.$$.fragment,C6),C6.forEach(t),Zpr=i(Ml),Fo=n(Ml,"DIV",{class:!0});var ya=s(Fo);T(h9.$$.fragment,ya),e_r=i(ya),t5e=n(ya,"P",{});var iwt=s(t5e);o_r=r(iwt,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),iwt.forEach(t),r_r=i(ya),tn=n(ya,"P",{});var w6=s(tn);t_r=r(w6,"The model class to instantiate is selected based on the "),a5e=n(w6,"CODE",{});var dwt=s(a5e);a_r=r(dwt,"model_type"),dwt.forEach(t),n_r=r(w6,` property of the config object (either
passed as an argument or loaded from `),n5e=n(w6,"CODE",{});var cwt=s(n5e);s_r=r(cwt,"pretrained_model_name_or_path"),cwt.forEach(t),l_r=r(w6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s5e=n(w6,"CODE",{});var fwt=s(s5e);i_r=r(fwt,"pretrained_model_name_or_path"),fwt.forEach(t),d_r=r(w6,":"),w6.forEach(t),c_r=i(ya),l5e=n(ya,"UL",{});var mwt=s(l5e);OF=n(mwt,"LI",{});var WBe=s(OF);i5e=n(WBe,"STRONG",{});var gwt=s(i5e);f_r=r(gwt,"maskformer"),gwt.forEach(t),m_r=r(WBe," \u2014 "),oH=n(WBe,"A",{href:!0});var hwt=s(oH);g_r=r(hwt,"MaskFormerForInstanceSegmentation"),hwt.forEach(t),h_r=r(WBe," (MaskFormer model)"),WBe.forEach(t),mwt.forEach(t),p_r=i(ya),VF=n(ya,"P",{});var HBe=s(VF);__r=r(HBe,"The model is set in evaluation mode by default using "),d5e=n(HBe,"CODE",{});var pwt=s(d5e);u_r=r(pwt,"model.eval()"),pwt.forEach(t),b_r=r(HBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c5e=n(HBe,"CODE",{});var _wt=s(c5e);v_r=r(_wt,"model.train()"),_wt.forEach(t),HBe.forEach(t),F_r=i(ya),T(XF.$$.fragment,ya),ya.forEach(t),Ml.forEach(t),QOe=i(f),ec=n(f,"H2",{class:!0});var eze=s(ec);zF=n(eze,"A",{id:!0,class:!0,href:!0});var uwt=s(zF);f5e=n(uwt,"SPAN",{});var bwt=s(f5e);T(p9.$$.fragment,bwt),bwt.forEach(t),uwt.forEach(t),T_r=i(eze),m5e=n(eze,"SPAN",{});var vwt=s(m5e);M_r=r(vwt,"TFAutoModel"),vwt.forEach(t),eze.forEach(t),WOe=i(f),er=n(f,"DIV",{class:!0});var El=s(er);T(_9.$$.fragment,El),E_r=i(El),oc=n(El,"P",{});var hre=s(oc);C_r=r(hre,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),rH=n(hre,"A",{href:!0});var Fwt=s(rH);w_r=r(Fwt,"from_pretrained()"),Fwt.forEach(t),A_r=r(hre," class method or the "),tH=n(hre,"A",{href:!0});var Twt=s(tH);L_r=r(Twt,"from_config()"),Twt.forEach(t),y_r=r(hre,` class
method.`),hre.forEach(t),x_r=i(El),u9=n(El,"P",{});var oze=s(u9);$_r=r(oze,"This class cannot be instantiated directly using "),g5e=n(oze,"CODE",{});var Mwt=s(g5e);k_r=r(Mwt,"__init__()"),Mwt.forEach(t),S_r=r(oze," (throws an error)."),oze.forEach(t),R_r=i(El),$t=n(El,"DIV",{class:!0});var A6=s($t);T(b9.$$.fragment,A6),P_r=i(A6),h5e=n(A6,"P",{});var Ewt=s(h5e);B_r=r(Ewt,"Instantiates one of the base model classes of the library from a configuration."),Ewt.forEach(t),I_r=i(A6),rc=n(A6,"P",{});var pre=s(rc);N_r=r(pre,`Note:
Loading a model from its configuration file does `),p5e=n(pre,"STRONG",{});var Cwt=s(p5e);q_r=r(Cwt,"not"),Cwt.forEach(t),j_r=r(pre,` load the model weights. It only affects the
model\u2019s configuration. Use `),aH=n(pre,"A",{href:!0});var wwt=s(aH);D_r=r(wwt,"from_pretrained()"),wwt.forEach(t),G_r=r(pre," to load the model weights."),pre.forEach(t),O_r=i(A6),T(QF.$$.fragment,A6),A6.forEach(t),V_r=i(El),yr=n(El,"DIV",{class:!0});var Cl=s(yr);T(v9.$$.fragment,Cl),X_r=i(Cl),_5e=n(Cl,"P",{});var Awt=s(_5e);z_r=r(Awt,"Instantiate one of the base model classes of the library from a pretrained model."),Awt.forEach(t),Q_r=i(Cl),an=n(Cl,"P",{});var L6=s(an);W_r=r(L6,"The model class to instantiate is selected based on the "),u5e=n(L6,"CODE",{});var Lwt=s(u5e);H_r=r(Lwt,"model_type"),Lwt.forEach(t),U_r=r(L6,` property of the config object (either
passed as an argument or loaded from `),b5e=n(L6,"CODE",{});var ywt=s(b5e);J_r=r(ywt,"pretrained_model_name_or_path"),ywt.forEach(t),Y_r=r(L6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v5e=n(L6,"CODE",{});var xwt=s(v5e);K_r=r(xwt,"pretrained_model_name_or_path"),xwt.forEach(t),Z_r=r(L6,":"),L6.forEach(t),eur=i(Cl),j=n(Cl,"UL",{});var D=s(j);WF=n(D,"LI",{});var UBe=s(WF);F5e=n(UBe,"STRONG",{});var $wt=s(F5e);our=r($wt,"albert"),$wt.forEach(t),rur=r(UBe," \u2014 "),nH=n(UBe,"A",{href:!0});var kwt=s(nH);tur=r(kwt,"TFAlbertModel"),kwt.forEach(t),aur=r(UBe," (ALBERT model)"),UBe.forEach(t),nur=i(D),HF=n(D,"LI",{});var JBe=s(HF);T5e=n(JBe,"STRONG",{});var Swt=s(T5e);sur=r(Swt,"bart"),Swt.forEach(t),lur=r(JBe," \u2014 "),sH=n(JBe,"A",{href:!0});var Rwt=s(sH);iur=r(Rwt,"TFBartModel"),Rwt.forEach(t),dur=r(JBe," (BART model)"),JBe.forEach(t),cur=i(D),UF=n(D,"LI",{});var YBe=s(UF);M5e=n(YBe,"STRONG",{});var Pwt=s(M5e);fur=r(Pwt,"bert"),Pwt.forEach(t),mur=r(YBe," \u2014 "),lH=n(YBe,"A",{href:!0});var Bwt=s(lH);gur=r(Bwt,"TFBertModel"),Bwt.forEach(t),hur=r(YBe," (BERT model)"),YBe.forEach(t),pur=i(D),JF=n(D,"LI",{});var KBe=s(JF);E5e=n(KBe,"STRONG",{});var Iwt=s(E5e);_ur=r(Iwt,"blenderbot"),Iwt.forEach(t),uur=r(KBe," \u2014 "),iH=n(KBe,"A",{href:!0});var Nwt=s(iH);bur=r(Nwt,"TFBlenderbotModel"),Nwt.forEach(t),vur=r(KBe," (Blenderbot model)"),KBe.forEach(t),Fur=i(D),YF=n(D,"LI",{});var ZBe=s(YF);C5e=n(ZBe,"STRONG",{});var qwt=s(C5e);Tur=r(qwt,"blenderbot-small"),qwt.forEach(t),Mur=r(ZBe," \u2014 "),dH=n(ZBe,"A",{href:!0});var jwt=s(dH);Eur=r(jwt,"TFBlenderbotSmallModel"),jwt.forEach(t),Cur=r(ZBe," (BlenderbotSmall model)"),ZBe.forEach(t),wur=i(D),KF=n(D,"LI",{});var eIe=s(KF);w5e=n(eIe,"STRONG",{});var Dwt=s(w5e);Aur=r(Dwt,"camembert"),Dwt.forEach(t),Lur=r(eIe," \u2014 "),cH=n(eIe,"A",{href:!0});var Gwt=s(cH);yur=r(Gwt,"TFCamembertModel"),Gwt.forEach(t),xur=r(eIe," (CamemBERT model)"),eIe.forEach(t),$ur=i(D),ZF=n(D,"LI",{});var oIe=s(ZF);A5e=n(oIe,"STRONG",{});var Owt=s(A5e);kur=r(Owt,"clip"),Owt.forEach(t),Sur=r(oIe," \u2014 "),fH=n(oIe,"A",{href:!0});var Vwt=s(fH);Rur=r(Vwt,"TFCLIPModel"),Vwt.forEach(t),Pur=r(oIe," (CLIP model)"),oIe.forEach(t),Bur=i(D),eT=n(D,"LI",{});var rIe=s(eT);L5e=n(rIe,"STRONG",{});var Xwt=s(L5e);Iur=r(Xwt,"convbert"),Xwt.forEach(t),Nur=r(rIe," \u2014 "),mH=n(rIe,"A",{href:!0});var zwt=s(mH);qur=r(zwt,"TFConvBertModel"),zwt.forEach(t),jur=r(rIe," (ConvBERT model)"),rIe.forEach(t),Dur=i(D),oT=n(D,"LI",{});var tIe=s(oT);y5e=n(tIe,"STRONG",{});var Qwt=s(y5e);Gur=r(Qwt,"convnext"),Qwt.forEach(t),Our=r(tIe," \u2014 "),gH=n(tIe,"A",{href:!0});var Wwt=s(gH);Vur=r(Wwt,"TFConvNextModel"),Wwt.forEach(t),Xur=r(tIe," (ConvNeXT model)"),tIe.forEach(t),zur=i(D),rT=n(D,"LI",{});var aIe=s(rT);x5e=n(aIe,"STRONG",{});var Hwt=s(x5e);Qur=r(Hwt,"ctrl"),Hwt.forEach(t),Wur=r(aIe," \u2014 "),hH=n(aIe,"A",{href:!0});var Uwt=s(hH);Hur=r(Uwt,"TFCTRLModel"),Uwt.forEach(t),Uur=r(aIe," (CTRL model)"),aIe.forEach(t),Jur=i(D),tT=n(D,"LI",{});var nIe=s(tT);$5e=n(nIe,"STRONG",{});var Jwt=s($5e);Yur=r(Jwt,"data2vec-vision"),Jwt.forEach(t),Kur=r(nIe," \u2014 "),pH=n(nIe,"A",{href:!0});var Ywt=s(pH);Zur=r(Ywt,"TFData2VecVisionModel"),Ywt.forEach(t),e1r=r(nIe," (Data2VecVision model)"),nIe.forEach(t),o1r=i(D),aT=n(D,"LI",{});var sIe=s(aT);k5e=n(sIe,"STRONG",{});var Kwt=s(k5e);r1r=r(Kwt,"deberta"),Kwt.forEach(t),t1r=r(sIe," \u2014 "),_H=n(sIe,"A",{href:!0});var Zwt=s(_H);a1r=r(Zwt,"TFDebertaModel"),Zwt.forEach(t),n1r=r(sIe," (DeBERTa model)"),sIe.forEach(t),s1r=i(D),nT=n(D,"LI",{});var lIe=s(nT);S5e=n(lIe,"STRONG",{});var eAt=s(S5e);l1r=r(eAt,"deberta-v2"),eAt.forEach(t),i1r=r(lIe," \u2014 "),uH=n(lIe,"A",{href:!0});var oAt=s(uH);d1r=r(oAt,"TFDebertaV2Model"),oAt.forEach(t),c1r=r(lIe," (DeBERTa-v2 model)"),lIe.forEach(t),f1r=i(D),sT=n(D,"LI",{});var iIe=s(sT);R5e=n(iIe,"STRONG",{});var rAt=s(R5e);m1r=r(rAt,"distilbert"),rAt.forEach(t),g1r=r(iIe," \u2014 "),bH=n(iIe,"A",{href:!0});var tAt=s(bH);h1r=r(tAt,"TFDistilBertModel"),tAt.forEach(t),p1r=r(iIe," (DistilBERT model)"),iIe.forEach(t),_1r=i(D),lT=n(D,"LI",{});var dIe=s(lT);P5e=n(dIe,"STRONG",{});var aAt=s(P5e);u1r=r(aAt,"dpr"),aAt.forEach(t),b1r=r(dIe," \u2014 "),vH=n(dIe,"A",{href:!0});var nAt=s(vH);v1r=r(nAt,"TFDPRQuestionEncoder"),nAt.forEach(t),F1r=r(dIe," (DPR model)"),dIe.forEach(t),T1r=i(D),iT=n(D,"LI",{});var cIe=s(iT);B5e=n(cIe,"STRONG",{});var sAt=s(B5e);M1r=r(sAt,"electra"),sAt.forEach(t),E1r=r(cIe," \u2014 "),FH=n(cIe,"A",{href:!0});var lAt=s(FH);C1r=r(lAt,"TFElectraModel"),lAt.forEach(t),w1r=r(cIe," (ELECTRA model)"),cIe.forEach(t),A1r=i(D),dT=n(D,"LI",{});var fIe=s(dT);I5e=n(fIe,"STRONG",{});var iAt=s(I5e);L1r=r(iAt,"flaubert"),iAt.forEach(t),y1r=r(fIe," \u2014 "),TH=n(fIe,"A",{href:!0});var dAt=s(TH);x1r=r(dAt,"TFFlaubertModel"),dAt.forEach(t),$1r=r(fIe," (FlauBERT model)"),fIe.forEach(t),k1r=i(D),Qs=n(D,"LI",{});var oS=s(Qs);N5e=n(oS,"STRONG",{});var cAt=s(N5e);S1r=r(cAt,"funnel"),cAt.forEach(t),R1r=r(oS," \u2014 "),MH=n(oS,"A",{href:!0});var fAt=s(MH);P1r=r(fAt,"TFFunnelModel"),fAt.forEach(t),B1r=r(oS," or "),EH=n(oS,"A",{href:!0});var mAt=s(EH);I1r=r(mAt,"TFFunnelBaseModel"),mAt.forEach(t),N1r=r(oS," (Funnel Transformer model)"),oS.forEach(t),q1r=i(D),cT=n(D,"LI",{});var mIe=s(cT);q5e=n(mIe,"STRONG",{});var gAt=s(q5e);j1r=r(gAt,"gpt2"),gAt.forEach(t),D1r=r(mIe," \u2014 "),CH=n(mIe,"A",{href:!0});var hAt=s(CH);G1r=r(hAt,"TFGPT2Model"),hAt.forEach(t),O1r=r(mIe," (OpenAI GPT-2 model)"),mIe.forEach(t),V1r=i(D),fT=n(D,"LI",{});var gIe=s(fT);j5e=n(gIe,"STRONG",{});var pAt=s(j5e);X1r=r(pAt,"gptj"),pAt.forEach(t),z1r=r(gIe," \u2014 "),wH=n(gIe,"A",{href:!0});var _At=s(wH);Q1r=r(_At,"TFGPTJModel"),_At.forEach(t),W1r=r(gIe," (GPT-J model)"),gIe.forEach(t),H1r=i(D),mT=n(D,"LI",{});var hIe=s(mT);D5e=n(hIe,"STRONG",{});var uAt=s(D5e);U1r=r(uAt,"hubert"),uAt.forEach(t),J1r=r(hIe," \u2014 "),AH=n(hIe,"A",{href:!0});var bAt=s(AH);Y1r=r(bAt,"TFHubertModel"),bAt.forEach(t),K1r=r(hIe," (Hubert model)"),hIe.forEach(t),Z1r=i(D),gT=n(D,"LI",{});var pIe=s(gT);G5e=n(pIe,"STRONG",{});var vAt=s(G5e);e7r=r(vAt,"layoutlm"),vAt.forEach(t),o7r=r(pIe," \u2014 "),LH=n(pIe,"A",{href:!0});var FAt=s(LH);r7r=r(FAt,"TFLayoutLMModel"),FAt.forEach(t),t7r=r(pIe," (LayoutLM model)"),pIe.forEach(t),a7r=i(D),hT=n(D,"LI",{});var _Ie=s(hT);O5e=n(_Ie,"STRONG",{});var TAt=s(O5e);n7r=r(TAt,"led"),TAt.forEach(t),s7r=r(_Ie," \u2014 "),yH=n(_Ie,"A",{href:!0});var MAt=s(yH);l7r=r(MAt,"TFLEDModel"),MAt.forEach(t),i7r=r(_Ie," (LED model)"),_Ie.forEach(t),d7r=i(D),pT=n(D,"LI",{});var uIe=s(pT);V5e=n(uIe,"STRONG",{});var EAt=s(V5e);c7r=r(EAt,"longformer"),EAt.forEach(t),f7r=r(uIe," \u2014 "),xH=n(uIe,"A",{href:!0});var CAt=s(xH);m7r=r(CAt,"TFLongformerModel"),CAt.forEach(t),g7r=r(uIe," (Longformer model)"),uIe.forEach(t),h7r=i(D),_T=n(D,"LI",{});var bIe=s(_T);X5e=n(bIe,"STRONG",{});var wAt=s(X5e);p7r=r(wAt,"lxmert"),wAt.forEach(t),_7r=r(bIe," \u2014 "),$H=n(bIe,"A",{href:!0});var AAt=s($H);u7r=r(AAt,"TFLxmertModel"),AAt.forEach(t),b7r=r(bIe," (LXMERT model)"),bIe.forEach(t),v7r=i(D),uT=n(D,"LI",{});var vIe=s(uT);z5e=n(vIe,"STRONG",{});var LAt=s(z5e);F7r=r(LAt,"marian"),LAt.forEach(t),T7r=r(vIe," \u2014 "),kH=n(vIe,"A",{href:!0});var yAt=s(kH);M7r=r(yAt,"TFMarianModel"),yAt.forEach(t),E7r=r(vIe," (Marian model)"),vIe.forEach(t),C7r=i(D),bT=n(D,"LI",{});var FIe=s(bT);Q5e=n(FIe,"STRONG",{});var xAt=s(Q5e);w7r=r(xAt,"mbart"),xAt.forEach(t),A7r=r(FIe," \u2014 "),SH=n(FIe,"A",{href:!0});var $At=s(SH);L7r=r($At,"TFMBartModel"),$At.forEach(t),y7r=r(FIe," (mBART model)"),FIe.forEach(t),x7r=i(D),vT=n(D,"LI",{});var TIe=s(vT);W5e=n(TIe,"STRONG",{});var kAt=s(W5e);$7r=r(kAt,"mobilebert"),kAt.forEach(t),k7r=r(TIe," \u2014 "),RH=n(TIe,"A",{href:!0});var SAt=s(RH);S7r=r(SAt,"TFMobileBertModel"),SAt.forEach(t),R7r=r(TIe," (MobileBERT model)"),TIe.forEach(t),P7r=i(D),FT=n(D,"LI",{});var MIe=s(FT);H5e=n(MIe,"STRONG",{});var RAt=s(H5e);B7r=r(RAt,"mpnet"),RAt.forEach(t),I7r=r(MIe," \u2014 "),PH=n(MIe,"A",{href:!0});var PAt=s(PH);N7r=r(PAt,"TFMPNetModel"),PAt.forEach(t),q7r=r(MIe," (MPNet model)"),MIe.forEach(t),j7r=i(D),TT=n(D,"LI",{});var EIe=s(TT);U5e=n(EIe,"STRONG",{});var BAt=s(U5e);D7r=r(BAt,"mt5"),BAt.forEach(t),G7r=r(EIe," \u2014 "),BH=n(EIe,"A",{href:!0});var IAt=s(BH);O7r=r(IAt,"TFMT5Model"),IAt.forEach(t),V7r=r(EIe," (MT5 model)"),EIe.forEach(t),X7r=i(D),MT=n(D,"LI",{});var CIe=s(MT);J5e=n(CIe,"STRONG",{});var NAt=s(J5e);z7r=r(NAt,"openai-gpt"),NAt.forEach(t),Q7r=r(CIe," \u2014 "),IH=n(CIe,"A",{href:!0});var qAt=s(IH);W7r=r(qAt,"TFOpenAIGPTModel"),qAt.forEach(t),H7r=r(CIe," (OpenAI GPT model)"),CIe.forEach(t),U7r=i(D),ET=n(D,"LI",{});var wIe=s(ET);Y5e=n(wIe,"STRONG",{});var jAt=s(Y5e);J7r=r(jAt,"opt"),jAt.forEach(t),Y7r=r(wIe," \u2014 "),NH=n(wIe,"A",{href:!0});var DAt=s(NH);K7r=r(DAt,"TFOPTModel"),DAt.forEach(t),Z7r=r(wIe," (OPT model)"),wIe.forEach(t),e2r=i(D),CT=n(D,"LI",{});var AIe=s(CT);K5e=n(AIe,"STRONG",{});var GAt=s(K5e);o2r=r(GAt,"pegasus"),GAt.forEach(t),r2r=r(AIe," \u2014 "),qH=n(AIe,"A",{href:!0});var OAt=s(qH);t2r=r(OAt,"TFPegasusModel"),OAt.forEach(t),a2r=r(AIe," (Pegasus model)"),AIe.forEach(t),n2r=i(D),wT=n(D,"LI",{});var LIe=s(wT);Z5e=n(LIe,"STRONG",{});var VAt=s(Z5e);s2r=r(VAt,"rembert"),VAt.forEach(t),l2r=r(LIe," \u2014 "),jH=n(LIe,"A",{href:!0});var XAt=s(jH);i2r=r(XAt,"TFRemBertModel"),XAt.forEach(t),d2r=r(LIe," (RemBERT model)"),LIe.forEach(t),c2r=i(D),AT=n(D,"LI",{});var yIe=s(AT);eve=n(yIe,"STRONG",{});var zAt=s(eve);f2r=r(zAt,"roberta"),zAt.forEach(t),m2r=r(yIe," \u2014 "),DH=n(yIe,"A",{href:!0});var QAt=s(DH);g2r=r(QAt,"TFRobertaModel"),QAt.forEach(t),h2r=r(yIe," (RoBERTa model)"),yIe.forEach(t),p2r=i(D),LT=n(D,"LI",{});var xIe=s(LT);ove=n(xIe,"STRONG",{});var WAt=s(ove);_2r=r(WAt,"roformer"),WAt.forEach(t),u2r=r(xIe," \u2014 "),GH=n(xIe,"A",{href:!0});var HAt=s(GH);b2r=r(HAt,"TFRoFormerModel"),HAt.forEach(t),v2r=r(xIe," (RoFormer model)"),xIe.forEach(t),F2r=i(D),yT=n(D,"LI",{});var $Ie=s(yT);rve=n($Ie,"STRONG",{});var UAt=s(rve);T2r=r(UAt,"speech_to_text"),UAt.forEach(t),M2r=r($Ie," \u2014 "),OH=n($Ie,"A",{href:!0});var JAt=s(OH);E2r=r(JAt,"TFSpeech2TextModel"),JAt.forEach(t),C2r=r($Ie," (Speech2Text model)"),$Ie.forEach(t),w2r=i(D),xT=n(D,"LI",{});var kIe=s(xT);tve=n(kIe,"STRONG",{});var YAt=s(tve);A2r=r(YAt,"swin"),YAt.forEach(t),L2r=r(kIe," \u2014 "),VH=n(kIe,"A",{href:!0});var KAt=s(VH);y2r=r(KAt,"TFSwinModel"),KAt.forEach(t),x2r=r(kIe," (Swin Transformer model)"),kIe.forEach(t),$2r=i(D),$T=n(D,"LI",{});var SIe=s($T);ave=n(SIe,"STRONG",{});var ZAt=s(ave);k2r=r(ZAt,"t5"),ZAt.forEach(t),S2r=r(SIe," \u2014 "),XH=n(SIe,"A",{href:!0});var e6t=s(XH);R2r=r(e6t,"TFT5Model"),e6t.forEach(t),P2r=r(SIe," (T5 model)"),SIe.forEach(t),B2r=i(D),kT=n(D,"LI",{});var RIe=s(kT);nve=n(RIe,"STRONG",{});var o6t=s(nve);I2r=r(o6t,"tapas"),o6t.forEach(t),N2r=r(RIe," \u2014 "),zH=n(RIe,"A",{href:!0});var r6t=s(zH);q2r=r(r6t,"TFTapasModel"),r6t.forEach(t),j2r=r(RIe," (TAPAS model)"),RIe.forEach(t),D2r=i(D),ST=n(D,"LI",{});var PIe=s(ST);sve=n(PIe,"STRONG",{});var t6t=s(sve);G2r=r(t6t,"transfo-xl"),t6t.forEach(t),O2r=r(PIe," \u2014 "),QH=n(PIe,"A",{href:!0});var a6t=s(QH);V2r=r(a6t,"TFTransfoXLModel"),a6t.forEach(t),X2r=r(PIe," (Transformer-XL model)"),PIe.forEach(t),z2r=i(D),RT=n(D,"LI",{});var BIe=s(RT);lve=n(BIe,"STRONG",{});var n6t=s(lve);Q2r=r(n6t,"vit"),n6t.forEach(t),W2r=r(BIe," \u2014 "),WH=n(BIe,"A",{href:!0});var s6t=s(WH);H2r=r(s6t,"TFViTModel"),s6t.forEach(t),U2r=r(BIe," (ViT model)"),BIe.forEach(t),J2r=i(D),PT=n(D,"LI",{});var IIe=s(PT);ive=n(IIe,"STRONG",{});var l6t=s(ive);Y2r=r(l6t,"vit_mae"),l6t.forEach(t),K2r=r(IIe," \u2014 "),HH=n(IIe,"A",{href:!0});var i6t=s(HH);Z2r=r(i6t,"TFViTMAEModel"),i6t.forEach(t),ebr=r(IIe," (ViTMAE model)"),IIe.forEach(t),obr=i(D),BT=n(D,"LI",{});var NIe=s(BT);dve=n(NIe,"STRONG",{});var d6t=s(dve);rbr=r(d6t,"wav2vec2"),d6t.forEach(t),tbr=r(NIe," \u2014 "),UH=n(NIe,"A",{href:!0});var c6t=s(UH);abr=r(c6t,"TFWav2Vec2Model"),c6t.forEach(t),nbr=r(NIe," (Wav2Vec2 model)"),NIe.forEach(t),sbr=i(D),IT=n(D,"LI",{});var qIe=s(IT);cve=n(qIe,"STRONG",{});var f6t=s(cve);lbr=r(f6t,"xlm"),f6t.forEach(t),ibr=r(qIe," \u2014 "),JH=n(qIe,"A",{href:!0});var m6t=s(JH);dbr=r(m6t,"TFXLMModel"),m6t.forEach(t),cbr=r(qIe," (XLM model)"),qIe.forEach(t),fbr=i(D),NT=n(D,"LI",{});var jIe=s(NT);fve=n(jIe,"STRONG",{});var g6t=s(fve);mbr=r(g6t,"xlm-roberta"),g6t.forEach(t),gbr=r(jIe," \u2014 "),YH=n(jIe,"A",{href:!0});var h6t=s(YH);hbr=r(h6t,"TFXLMRobertaModel"),h6t.forEach(t),pbr=r(jIe," (XLM-RoBERTa model)"),jIe.forEach(t),_br=i(D),qT=n(D,"LI",{});var DIe=s(qT);mve=n(DIe,"STRONG",{});var p6t=s(mve);ubr=r(p6t,"xlnet"),p6t.forEach(t),bbr=r(DIe," \u2014 "),KH=n(DIe,"A",{href:!0});var _6t=s(KH);vbr=r(_6t,"TFXLNetModel"),_6t.forEach(t),Fbr=r(DIe," (XLNet model)"),DIe.forEach(t),D.forEach(t),Tbr=i(Cl),T(jT.$$.fragment,Cl),Cl.forEach(t),El.forEach(t),HOe=i(f),tc=n(f,"H2",{class:!0});var rze=s(tc);DT=n(rze,"A",{id:!0,class:!0,href:!0});var u6t=s(DT);gve=n(u6t,"SPAN",{});var b6t=s(gve);T(F9.$$.fragment,b6t),b6t.forEach(t),u6t.forEach(t),Mbr=i(rze),hve=n(rze,"SPAN",{});var v6t=s(hve);Ebr=r(v6t,"TFAutoModelForPreTraining"),v6t.forEach(t),rze.forEach(t),UOe=i(f),or=n(f,"DIV",{class:!0});var wl=s(or);T(T9.$$.fragment,wl),Cbr=i(wl),ac=n(wl,"P",{});var _re=s(ac);wbr=r(_re,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ZH=n(_re,"A",{href:!0});var F6t=s(ZH);Abr=r(F6t,"from_pretrained()"),F6t.forEach(t),Lbr=r(_re," class method or the "),eU=n(_re,"A",{href:!0});var T6t=s(eU);ybr=r(T6t,"from_config()"),T6t.forEach(t),xbr=r(_re,` class
method.`),_re.forEach(t),$br=i(wl),M9=n(wl,"P",{});var tze=s(M9);kbr=r(tze,"This class cannot be instantiated directly using "),pve=n(tze,"CODE",{});var M6t=s(pve);Sbr=r(M6t,"__init__()"),M6t.forEach(t),Rbr=r(tze," (throws an error)."),tze.forEach(t),Pbr=i(wl),kt=n(wl,"DIV",{class:!0});var y6=s(kt);T(E9.$$.fragment,y6),Bbr=i(y6),_ve=n(y6,"P",{});var E6t=s(_ve);Ibr=r(E6t,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),E6t.forEach(t),Nbr=i(y6),nc=n(y6,"P",{});var ure=s(nc);qbr=r(ure,`Note:
Loading a model from its configuration file does `),uve=n(ure,"STRONG",{});var C6t=s(uve);jbr=r(C6t,"not"),C6t.forEach(t),Dbr=r(ure,` load the model weights. It only affects the
model\u2019s configuration. Use `),oU=n(ure,"A",{href:!0});var w6t=s(oU);Gbr=r(w6t,"from_pretrained()"),w6t.forEach(t),Obr=r(ure," to load the model weights."),ure.forEach(t),Vbr=i(y6),T(GT.$$.fragment,y6),y6.forEach(t),Xbr=i(wl),xr=n(wl,"DIV",{class:!0});var Al=s(xr);T(C9.$$.fragment,Al),zbr=i(Al),bve=n(Al,"P",{});var A6t=s(bve);Qbr=r(A6t,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),A6t.forEach(t),Wbr=i(Al),nn=n(Al,"P",{});var x6=s(nn);Hbr=r(x6,"The model class to instantiate is selected based on the "),vve=n(x6,"CODE",{});var L6t=s(vve);Ubr=r(L6t,"model_type"),L6t.forEach(t),Jbr=r(x6,` property of the config object (either
passed as an argument or loaded from `),Fve=n(x6,"CODE",{});var y6t=s(Fve);Ybr=r(y6t,"pretrained_model_name_or_path"),y6t.forEach(t),Kbr=r(x6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tve=n(x6,"CODE",{});var x6t=s(Tve);Zbr=r(x6t,"pretrained_model_name_or_path"),x6t.forEach(t),e5r=r(x6,":"),x6.forEach(t),o5r=i(Al),se=n(Al,"UL",{});var le=s(se);OT=n(le,"LI",{});var GIe=s(OT);Mve=n(GIe,"STRONG",{});var $6t=s(Mve);r5r=r($6t,"albert"),$6t.forEach(t),t5r=r(GIe," \u2014 "),rU=n(GIe,"A",{href:!0});var k6t=s(rU);a5r=r(k6t,"TFAlbertForPreTraining"),k6t.forEach(t),n5r=r(GIe," (ALBERT model)"),GIe.forEach(t),s5r=i(le),VT=n(le,"LI",{});var OIe=s(VT);Eve=n(OIe,"STRONG",{});var S6t=s(Eve);l5r=r(S6t,"bart"),S6t.forEach(t),i5r=r(OIe," \u2014 "),tU=n(OIe,"A",{href:!0});var R6t=s(tU);d5r=r(R6t,"TFBartForConditionalGeneration"),R6t.forEach(t),c5r=r(OIe," (BART model)"),OIe.forEach(t),f5r=i(le),XT=n(le,"LI",{});var VIe=s(XT);Cve=n(VIe,"STRONG",{});var P6t=s(Cve);m5r=r(P6t,"bert"),P6t.forEach(t),g5r=r(VIe," \u2014 "),aU=n(VIe,"A",{href:!0});var B6t=s(aU);h5r=r(B6t,"TFBertForPreTraining"),B6t.forEach(t),p5r=r(VIe," (BERT model)"),VIe.forEach(t),_5r=i(le),zT=n(le,"LI",{});var XIe=s(zT);wve=n(XIe,"STRONG",{});var I6t=s(wve);u5r=r(I6t,"camembert"),I6t.forEach(t),b5r=r(XIe," \u2014 "),nU=n(XIe,"A",{href:!0});var N6t=s(nU);v5r=r(N6t,"TFCamembertForMaskedLM"),N6t.forEach(t),F5r=r(XIe," (CamemBERT model)"),XIe.forEach(t),T5r=i(le),QT=n(le,"LI",{});var zIe=s(QT);Ave=n(zIe,"STRONG",{});var q6t=s(Ave);M5r=r(q6t,"ctrl"),q6t.forEach(t),E5r=r(zIe," \u2014 "),sU=n(zIe,"A",{href:!0});var j6t=s(sU);C5r=r(j6t,"TFCTRLLMHeadModel"),j6t.forEach(t),w5r=r(zIe," (CTRL model)"),zIe.forEach(t),A5r=i(le),WT=n(le,"LI",{});var QIe=s(WT);Lve=n(QIe,"STRONG",{});var D6t=s(Lve);L5r=r(D6t,"distilbert"),D6t.forEach(t),y5r=r(QIe," \u2014 "),lU=n(QIe,"A",{href:!0});var G6t=s(lU);x5r=r(G6t,"TFDistilBertForMaskedLM"),G6t.forEach(t),$5r=r(QIe," (DistilBERT model)"),QIe.forEach(t),k5r=i(le),HT=n(le,"LI",{});var WIe=s(HT);yve=n(WIe,"STRONG",{});var O6t=s(yve);S5r=r(O6t,"electra"),O6t.forEach(t),R5r=r(WIe," \u2014 "),iU=n(WIe,"A",{href:!0});var V6t=s(iU);P5r=r(V6t,"TFElectraForPreTraining"),V6t.forEach(t),B5r=r(WIe," (ELECTRA model)"),WIe.forEach(t),I5r=i(le),UT=n(le,"LI",{});var HIe=s(UT);xve=n(HIe,"STRONG",{});var X6t=s(xve);N5r=r(X6t,"flaubert"),X6t.forEach(t),q5r=r(HIe," \u2014 "),dU=n(HIe,"A",{href:!0});var z6t=s(dU);j5r=r(z6t,"TFFlaubertWithLMHeadModel"),z6t.forEach(t),D5r=r(HIe," (FlauBERT model)"),HIe.forEach(t),G5r=i(le),JT=n(le,"LI",{});var UIe=s(JT);$ve=n(UIe,"STRONG",{});var Q6t=s($ve);O5r=r(Q6t,"funnel"),Q6t.forEach(t),V5r=r(UIe," \u2014 "),cU=n(UIe,"A",{href:!0});var W6t=s(cU);X5r=r(W6t,"TFFunnelForPreTraining"),W6t.forEach(t),z5r=r(UIe," (Funnel Transformer model)"),UIe.forEach(t),Q5r=i(le),YT=n(le,"LI",{});var JIe=s(YT);kve=n(JIe,"STRONG",{});var H6t=s(kve);W5r=r(H6t,"gpt2"),H6t.forEach(t),H5r=r(JIe," \u2014 "),fU=n(JIe,"A",{href:!0});var U6t=s(fU);U5r=r(U6t,"TFGPT2LMHeadModel"),U6t.forEach(t),J5r=r(JIe," (OpenAI GPT-2 model)"),JIe.forEach(t),Y5r=i(le),KT=n(le,"LI",{});var YIe=s(KT);Sve=n(YIe,"STRONG",{});var J6t=s(Sve);K5r=r(J6t,"layoutlm"),J6t.forEach(t),Z5r=r(YIe," \u2014 "),mU=n(YIe,"A",{href:!0});var Y6t=s(mU);evr=r(Y6t,"TFLayoutLMForMaskedLM"),Y6t.forEach(t),ovr=r(YIe," (LayoutLM model)"),YIe.forEach(t),rvr=i(le),ZT=n(le,"LI",{});var KIe=s(ZT);Rve=n(KIe,"STRONG",{});var K6t=s(Rve);tvr=r(K6t,"lxmert"),K6t.forEach(t),avr=r(KIe," \u2014 "),gU=n(KIe,"A",{href:!0});var Z6t=s(gU);nvr=r(Z6t,"TFLxmertForPreTraining"),Z6t.forEach(t),svr=r(KIe," (LXMERT model)"),KIe.forEach(t),lvr=i(le),eM=n(le,"LI",{});var ZIe=s(eM);Pve=n(ZIe,"STRONG",{});var eLt=s(Pve);ivr=r(eLt,"mobilebert"),eLt.forEach(t),dvr=r(ZIe," \u2014 "),hU=n(ZIe,"A",{href:!0});var oLt=s(hU);cvr=r(oLt,"TFMobileBertForPreTraining"),oLt.forEach(t),fvr=r(ZIe," (MobileBERT model)"),ZIe.forEach(t),mvr=i(le),oM=n(le,"LI",{});var eNe=s(oM);Bve=n(eNe,"STRONG",{});var rLt=s(Bve);gvr=r(rLt,"mpnet"),rLt.forEach(t),hvr=r(eNe," \u2014 "),pU=n(eNe,"A",{href:!0});var tLt=s(pU);pvr=r(tLt,"TFMPNetForMaskedLM"),tLt.forEach(t),_vr=r(eNe," (MPNet model)"),eNe.forEach(t),uvr=i(le),rM=n(le,"LI",{});var oNe=s(rM);Ive=n(oNe,"STRONG",{});var aLt=s(Ive);bvr=r(aLt,"openai-gpt"),aLt.forEach(t),vvr=r(oNe," \u2014 "),_U=n(oNe,"A",{href:!0});var nLt=s(_U);Fvr=r(nLt,"TFOpenAIGPTLMHeadModel"),nLt.forEach(t),Tvr=r(oNe," (OpenAI GPT model)"),oNe.forEach(t),Mvr=i(le),tM=n(le,"LI",{});var rNe=s(tM);Nve=n(rNe,"STRONG",{});var sLt=s(Nve);Evr=r(sLt,"roberta"),sLt.forEach(t),Cvr=r(rNe," \u2014 "),uU=n(rNe,"A",{href:!0});var lLt=s(uU);wvr=r(lLt,"TFRobertaForMaskedLM"),lLt.forEach(t),Avr=r(rNe," (RoBERTa model)"),rNe.forEach(t),Lvr=i(le),aM=n(le,"LI",{});var tNe=s(aM);qve=n(tNe,"STRONG",{});var iLt=s(qve);yvr=r(iLt,"t5"),iLt.forEach(t),xvr=r(tNe," \u2014 "),bU=n(tNe,"A",{href:!0});var dLt=s(bU);$vr=r(dLt,"TFT5ForConditionalGeneration"),dLt.forEach(t),kvr=r(tNe," (T5 model)"),tNe.forEach(t),Svr=i(le),nM=n(le,"LI",{});var aNe=s(nM);jve=n(aNe,"STRONG",{});var cLt=s(jve);Rvr=r(cLt,"tapas"),cLt.forEach(t),Pvr=r(aNe," \u2014 "),vU=n(aNe,"A",{href:!0});var fLt=s(vU);Bvr=r(fLt,"TFTapasForMaskedLM"),fLt.forEach(t),Ivr=r(aNe," (TAPAS model)"),aNe.forEach(t),Nvr=i(le),sM=n(le,"LI",{});var nNe=s(sM);Dve=n(nNe,"STRONG",{});var mLt=s(Dve);qvr=r(mLt,"transfo-xl"),mLt.forEach(t),jvr=r(nNe," \u2014 "),FU=n(nNe,"A",{href:!0});var gLt=s(FU);Dvr=r(gLt,"TFTransfoXLLMHeadModel"),gLt.forEach(t),Gvr=r(nNe," (Transformer-XL model)"),nNe.forEach(t),Ovr=i(le),lM=n(le,"LI",{});var sNe=s(lM);Gve=n(sNe,"STRONG",{});var hLt=s(Gve);Vvr=r(hLt,"vit_mae"),hLt.forEach(t),Xvr=r(sNe," \u2014 "),TU=n(sNe,"A",{href:!0});var pLt=s(TU);zvr=r(pLt,"TFViTMAEForPreTraining"),pLt.forEach(t),Qvr=r(sNe," (ViTMAE model)"),sNe.forEach(t),Wvr=i(le),iM=n(le,"LI",{});var lNe=s(iM);Ove=n(lNe,"STRONG",{});var _Lt=s(Ove);Hvr=r(_Lt,"xlm"),_Lt.forEach(t),Uvr=r(lNe," \u2014 "),MU=n(lNe,"A",{href:!0});var uLt=s(MU);Jvr=r(uLt,"TFXLMWithLMHeadModel"),uLt.forEach(t),Yvr=r(lNe," (XLM model)"),lNe.forEach(t),Kvr=i(le),dM=n(le,"LI",{});var iNe=s(dM);Vve=n(iNe,"STRONG",{});var bLt=s(Vve);Zvr=r(bLt,"xlm-roberta"),bLt.forEach(t),e3r=r(iNe," \u2014 "),EU=n(iNe,"A",{href:!0});var vLt=s(EU);o3r=r(vLt,"TFXLMRobertaForMaskedLM"),vLt.forEach(t),r3r=r(iNe," (XLM-RoBERTa model)"),iNe.forEach(t),t3r=i(le),cM=n(le,"LI",{});var dNe=s(cM);Xve=n(dNe,"STRONG",{});var FLt=s(Xve);a3r=r(FLt,"xlnet"),FLt.forEach(t),n3r=r(dNe," \u2014 "),CU=n(dNe,"A",{href:!0});var TLt=s(CU);s3r=r(TLt,"TFXLNetLMHeadModel"),TLt.forEach(t),l3r=r(dNe," (XLNet model)"),dNe.forEach(t),le.forEach(t),i3r=i(Al),T(fM.$$.fragment,Al),Al.forEach(t),wl.forEach(t),JOe=i(f),sc=n(f,"H2",{class:!0});var aze=s(sc);mM=n(aze,"A",{id:!0,class:!0,href:!0});var MLt=s(mM);zve=n(MLt,"SPAN",{});var ELt=s(zve);T(w9.$$.fragment,ELt),ELt.forEach(t),MLt.forEach(t),d3r=i(aze),Qve=n(aze,"SPAN",{});var CLt=s(Qve);c3r=r(CLt,"TFAutoModelForCausalLM"),CLt.forEach(t),aze.forEach(t),YOe=i(f),rr=n(f,"DIV",{class:!0});var Ll=s(rr);T(A9.$$.fragment,Ll),f3r=i(Ll),lc=n(Ll,"P",{});var bre=s(lc);m3r=r(bre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),wU=n(bre,"A",{href:!0});var wLt=s(wU);g3r=r(wLt,"from_pretrained()"),wLt.forEach(t),h3r=r(bre," class method or the "),AU=n(bre,"A",{href:!0});var ALt=s(AU);p3r=r(ALt,"from_config()"),ALt.forEach(t),_3r=r(bre,` class
method.`),bre.forEach(t),u3r=i(Ll),L9=n(Ll,"P",{});var nze=s(L9);b3r=r(nze,"This class cannot be instantiated directly using "),Wve=n(nze,"CODE",{});var LLt=s(Wve);v3r=r(LLt,"__init__()"),LLt.forEach(t),F3r=r(nze," (throws an error)."),nze.forEach(t),T3r=i(Ll),St=n(Ll,"DIV",{class:!0});var $6=s(St);T(y9.$$.fragment,$6),M3r=i($6),Hve=n($6,"P",{});var yLt=s(Hve);E3r=r(yLt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),yLt.forEach(t),C3r=i($6),ic=n($6,"P",{});var vre=s(ic);w3r=r(vre,`Note:
Loading a model from its configuration file does `),Uve=n(vre,"STRONG",{});var xLt=s(Uve);A3r=r(xLt,"not"),xLt.forEach(t),L3r=r(vre,` load the model weights. It only affects the
model\u2019s configuration. Use `),LU=n(vre,"A",{href:!0});var $Lt=s(LU);y3r=r($Lt,"from_pretrained()"),$Lt.forEach(t),x3r=r(vre," to load the model weights."),vre.forEach(t),$3r=i($6),T(gM.$$.fragment,$6),$6.forEach(t),k3r=i(Ll),$r=n(Ll,"DIV",{class:!0});var yl=s($r);T(x9.$$.fragment,yl),S3r=i(yl),Jve=n(yl,"P",{});var kLt=s(Jve);R3r=r(kLt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),kLt.forEach(t),P3r=i(yl),sn=n(yl,"P",{});var k6=s(sn);B3r=r(k6,"The model class to instantiate is selected based on the "),Yve=n(k6,"CODE",{});var SLt=s(Yve);I3r=r(SLt,"model_type"),SLt.forEach(t),N3r=r(k6,` property of the config object (either
passed as an argument or loaded from `),Kve=n(k6,"CODE",{});var RLt=s(Kve);q3r=r(RLt,"pretrained_model_name_or_path"),RLt.forEach(t),j3r=r(k6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zve=n(k6,"CODE",{});var PLt=s(Zve);D3r=r(PLt,"pretrained_model_name_or_path"),PLt.forEach(t),G3r=r(k6,":"),k6.forEach(t),O3r=i(yl),Me=n(yl,"UL",{});var Ce=s(Me);hM=n(Ce,"LI",{});var cNe=s(hM);e3e=n(cNe,"STRONG",{});var BLt=s(e3e);V3r=r(BLt,"bert"),BLt.forEach(t),X3r=r(cNe," \u2014 "),yU=n(cNe,"A",{href:!0});var ILt=s(yU);z3r=r(ILt,"TFBertLMHeadModel"),ILt.forEach(t),Q3r=r(cNe," (BERT model)"),cNe.forEach(t),W3r=i(Ce),pM=n(Ce,"LI",{});var fNe=s(pM);o3e=n(fNe,"STRONG",{});var NLt=s(o3e);H3r=r(NLt,"camembert"),NLt.forEach(t),U3r=r(fNe," \u2014 "),xU=n(fNe,"A",{href:!0});var qLt=s(xU);J3r=r(qLt,"TFCamembertForCausalLM"),qLt.forEach(t),Y3r=r(fNe," (CamemBERT model)"),fNe.forEach(t),K3r=i(Ce),_M=n(Ce,"LI",{});var mNe=s(_M);r3e=n(mNe,"STRONG",{});var jLt=s(r3e);Z3r=r(jLt,"ctrl"),jLt.forEach(t),eFr=r(mNe," \u2014 "),$U=n(mNe,"A",{href:!0});var DLt=s($U);oFr=r(DLt,"TFCTRLLMHeadModel"),DLt.forEach(t),rFr=r(mNe," (CTRL model)"),mNe.forEach(t),tFr=i(Ce),uM=n(Ce,"LI",{});var gNe=s(uM);t3e=n(gNe,"STRONG",{});var GLt=s(t3e);aFr=r(GLt,"gpt2"),GLt.forEach(t),nFr=r(gNe," \u2014 "),kU=n(gNe,"A",{href:!0});var OLt=s(kU);sFr=r(OLt,"TFGPT2LMHeadModel"),OLt.forEach(t),lFr=r(gNe," (OpenAI GPT-2 model)"),gNe.forEach(t),iFr=i(Ce),bM=n(Ce,"LI",{});var hNe=s(bM);a3e=n(hNe,"STRONG",{});var VLt=s(a3e);dFr=r(VLt,"gptj"),VLt.forEach(t),cFr=r(hNe," \u2014 "),SU=n(hNe,"A",{href:!0});var XLt=s(SU);fFr=r(XLt,"TFGPTJForCausalLM"),XLt.forEach(t),mFr=r(hNe," (GPT-J model)"),hNe.forEach(t),gFr=i(Ce),vM=n(Ce,"LI",{});var pNe=s(vM);n3e=n(pNe,"STRONG",{});var zLt=s(n3e);hFr=r(zLt,"openai-gpt"),zLt.forEach(t),pFr=r(pNe," \u2014 "),RU=n(pNe,"A",{href:!0});var QLt=s(RU);_Fr=r(QLt,"TFOpenAIGPTLMHeadModel"),QLt.forEach(t),uFr=r(pNe," (OpenAI GPT model)"),pNe.forEach(t),bFr=i(Ce),FM=n(Ce,"LI",{});var _Ne=s(FM);s3e=n(_Ne,"STRONG",{});var WLt=s(s3e);vFr=r(WLt,"opt"),WLt.forEach(t),FFr=r(_Ne," \u2014 "),PU=n(_Ne,"A",{href:!0});var HLt=s(PU);TFr=r(HLt,"TFOPTForCausalLM"),HLt.forEach(t),MFr=r(_Ne," (OPT model)"),_Ne.forEach(t),EFr=i(Ce),TM=n(Ce,"LI",{});var uNe=s(TM);l3e=n(uNe,"STRONG",{});var ULt=s(l3e);CFr=r(ULt,"rembert"),ULt.forEach(t),wFr=r(uNe," \u2014 "),BU=n(uNe,"A",{href:!0});var JLt=s(BU);AFr=r(JLt,"TFRemBertForCausalLM"),JLt.forEach(t),LFr=r(uNe," (RemBERT model)"),uNe.forEach(t),yFr=i(Ce),MM=n(Ce,"LI",{});var bNe=s(MM);i3e=n(bNe,"STRONG",{});var YLt=s(i3e);xFr=r(YLt,"roberta"),YLt.forEach(t),$Fr=r(bNe," \u2014 "),IU=n(bNe,"A",{href:!0});var KLt=s(IU);kFr=r(KLt,"TFRobertaForCausalLM"),KLt.forEach(t),SFr=r(bNe," (RoBERTa model)"),bNe.forEach(t),RFr=i(Ce),EM=n(Ce,"LI",{});var vNe=s(EM);d3e=n(vNe,"STRONG",{});var ZLt=s(d3e);PFr=r(ZLt,"roformer"),ZLt.forEach(t),BFr=r(vNe," \u2014 "),NU=n(vNe,"A",{href:!0});var eyt=s(NU);IFr=r(eyt,"TFRoFormerForCausalLM"),eyt.forEach(t),NFr=r(vNe," (RoFormer model)"),vNe.forEach(t),qFr=i(Ce),CM=n(Ce,"LI",{});var FNe=s(CM);c3e=n(FNe,"STRONG",{});var oyt=s(c3e);jFr=r(oyt,"transfo-xl"),oyt.forEach(t),DFr=r(FNe," \u2014 "),qU=n(FNe,"A",{href:!0});var ryt=s(qU);GFr=r(ryt,"TFTransfoXLLMHeadModel"),ryt.forEach(t),OFr=r(FNe," (Transformer-XL model)"),FNe.forEach(t),VFr=i(Ce),wM=n(Ce,"LI",{});var TNe=s(wM);f3e=n(TNe,"STRONG",{});var tyt=s(f3e);XFr=r(tyt,"xlm"),tyt.forEach(t),zFr=r(TNe," \u2014 "),jU=n(TNe,"A",{href:!0});var ayt=s(jU);QFr=r(ayt,"TFXLMWithLMHeadModel"),ayt.forEach(t),WFr=r(TNe," (XLM model)"),TNe.forEach(t),HFr=i(Ce),AM=n(Ce,"LI",{});var MNe=s(AM);m3e=n(MNe,"STRONG",{});var nyt=s(m3e);UFr=r(nyt,"xlnet"),nyt.forEach(t),JFr=r(MNe," \u2014 "),DU=n(MNe,"A",{href:!0});var syt=s(DU);YFr=r(syt,"TFXLNetLMHeadModel"),syt.forEach(t),KFr=r(MNe," (XLNet model)"),MNe.forEach(t),Ce.forEach(t),ZFr=i(yl),T(LM.$$.fragment,yl),yl.forEach(t),Ll.forEach(t),KOe=i(f),dc=n(f,"H2",{class:!0});var sze=s(dc);yM=n(sze,"A",{id:!0,class:!0,href:!0});var lyt=s(yM);g3e=n(lyt,"SPAN",{});var iyt=s(g3e);T($9.$$.fragment,iyt),iyt.forEach(t),lyt.forEach(t),eTr=i(sze),h3e=n(sze,"SPAN",{});var dyt=s(h3e);oTr=r(dyt,"TFAutoModelForImageClassification"),dyt.forEach(t),sze.forEach(t),ZOe=i(f),tr=n(f,"DIV",{class:!0});var xl=s(tr);T(k9.$$.fragment,xl),rTr=i(xl),cc=n(xl,"P",{});var Fre=s(cc);tTr=r(Fre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),GU=n(Fre,"A",{href:!0});var cyt=s(GU);aTr=r(cyt,"from_pretrained()"),cyt.forEach(t),nTr=r(Fre," class method or the "),OU=n(Fre,"A",{href:!0});var fyt=s(OU);sTr=r(fyt,"from_config()"),fyt.forEach(t),lTr=r(Fre,` class
method.`),Fre.forEach(t),iTr=i(xl),S9=n(xl,"P",{});var lze=s(S9);dTr=r(lze,"This class cannot be instantiated directly using "),p3e=n(lze,"CODE",{});var myt=s(p3e);cTr=r(myt,"__init__()"),myt.forEach(t),fTr=r(lze," (throws an error)."),lze.forEach(t),mTr=i(xl),Rt=n(xl,"DIV",{class:!0});var S6=s(Rt);T(R9.$$.fragment,S6),gTr=i(S6),_3e=n(S6,"P",{});var gyt=s(_3e);hTr=r(gyt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),gyt.forEach(t),pTr=i(S6),fc=n(S6,"P",{});var Tre=s(fc);_Tr=r(Tre,`Note:
Loading a model from its configuration file does `),u3e=n(Tre,"STRONG",{});var hyt=s(u3e);uTr=r(hyt,"not"),hyt.forEach(t),bTr=r(Tre,` load the model weights. It only affects the
model\u2019s configuration. Use `),VU=n(Tre,"A",{href:!0});var pyt=s(VU);vTr=r(pyt,"from_pretrained()"),pyt.forEach(t),FTr=r(Tre," to load the model weights."),Tre.forEach(t),TTr=i(S6),T(xM.$$.fragment,S6),S6.forEach(t),MTr=i(xl),kr=n(xl,"DIV",{class:!0});var $l=s(kr);T(P9.$$.fragment,$l),ETr=i($l),b3e=n($l,"P",{});var _yt=s(b3e);CTr=r(_yt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),_yt.forEach(t),wTr=i($l),ln=n($l,"P",{});var R6=s(ln);ATr=r(R6,"The model class to instantiate is selected based on the "),v3e=n(R6,"CODE",{});var uyt=s(v3e);LTr=r(uyt,"model_type"),uyt.forEach(t),yTr=r(R6,` property of the config object (either
passed as an argument or loaded from `),F3e=n(R6,"CODE",{});var byt=s(F3e);xTr=r(byt,"pretrained_model_name_or_path"),byt.forEach(t),$Tr=r(R6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T3e=n(R6,"CODE",{});var vyt=s(T3e);kTr=r(vyt,"pretrained_model_name_or_path"),vyt.forEach(t),STr=r(R6,":"),R6.forEach(t),RTr=i($l),dn=n($l,"UL",{});var P6=s(dn);$M=n(P6,"LI",{});var ENe=s($M);M3e=n(ENe,"STRONG",{});var Fyt=s(M3e);PTr=r(Fyt,"convnext"),Fyt.forEach(t),BTr=r(ENe," \u2014 "),XU=n(ENe,"A",{href:!0});var Tyt=s(XU);ITr=r(Tyt,"TFConvNextForImageClassification"),Tyt.forEach(t),NTr=r(ENe," (ConvNeXT model)"),ENe.forEach(t),qTr=i(P6),kM=n(P6,"LI",{});var CNe=s(kM);E3e=n(CNe,"STRONG",{});var Myt=s(E3e);jTr=r(Myt,"data2vec-vision"),Myt.forEach(t),DTr=r(CNe," \u2014 "),zU=n(CNe,"A",{href:!0});var Eyt=s(zU);GTr=r(Eyt,"TFData2VecVisionForImageClassification"),Eyt.forEach(t),OTr=r(CNe," (Data2VecVision model)"),CNe.forEach(t),VTr=i(P6),SM=n(P6,"LI",{});var wNe=s(SM);C3e=n(wNe,"STRONG",{});var Cyt=s(C3e);XTr=r(Cyt,"swin"),Cyt.forEach(t),zTr=r(wNe," \u2014 "),QU=n(wNe,"A",{href:!0});var wyt=s(QU);QTr=r(wyt,"TFSwinForImageClassification"),wyt.forEach(t),WTr=r(wNe," (Swin Transformer model)"),wNe.forEach(t),HTr=i(P6),RM=n(P6,"LI",{});var ANe=s(RM);w3e=n(ANe,"STRONG",{});var Ayt=s(w3e);UTr=r(Ayt,"vit"),Ayt.forEach(t),JTr=r(ANe," \u2014 "),WU=n(ANe,"A",{href:!0});var Lyt=s(WU);YTr=r(Lyt,"TFViTForImageClassification"),Lyt.forEach(t),KTr=r(ANe," (ViT model)"),ANe.forEach(t),P6.forEach(t),ZTr=i($l),T(PM.$$.fragment,$l),$l.forEach(t),xl.forEach(t),eVe=i(f),mc=n(f,"H2",{class:!0});var ize=s(mc);BM=n(ize,"A",{id:!0,class:!0,href:!0});var yyt=s(BM);A3e=n(yyt,"SPAN",{});var xyt=s(A3e);T(B9.$$.fragment,xyt),xyt.forEach(t),yyt.forEach(t),eMr=i(ize),L3e=n(ize,"SPAN",{});var $yt=s(L3e);oMr=r($yt,"TFAutoModelForMaskedLM"),$yt.forEach(t),ize.forEach(t),oVe=i(f),ar=n(f,"DIV",{class:!0});var kl=s(ar);T(I9.$$.fragment,kl),rMr=i(kl),gc=n(kl,"P",{});var Mre=s(gc);tMr=r(Mre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),HU=n(Mre,"A",{href:!0});var kyt=s(HU);aMr=r(kyt,"from_pretrained()"),kyt.forEach(t),nMr=r(Mre," class method or the "),UU=n(Mre,"A",{href:!0});var Syt=s(UU);sMr=r(Syt,"from_config()"),Syt.forEach(t),lMr=r(Mre,` class
method.`),Mre.forEach(t),iMr=i(kl),N9=n(kl,"P",{});var dze=s(N9);dMr=r(dze,"This class cannot be instantiated directly using "),y3e=n(dze,"CODE",{});var Ryt=s(y3e);cMr=r(Ryt,"__init__()"),Ryt.forEach(t),fMr=r(dze," (throws an error)."),dze.forEach(t),mMr=i(kl),Pt=n(kl,"DIV",{class:!0});var B6=s(Pt);T(q9.$$.fragment,B6),gMr=i(B6),x3e=n(B6,"P",{});var Pyt=s(x3e);hMr=r(Pyt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Pyt.forEach(t),pMr=i(B6),hc=n(B6,"P",{});var Ere=s(hc);_Mr=r(Ere,`Note:
Loading a model from its configuration file does `),$3e=n(Ere,"STRONG",{});var Byt=s($3e);uMr=r(Byt,"not"),Byt.forEach(t),bMr=r(Ere,` load the model weights. It only affects the
model\u2019s configuration. Use `),JU=n(Ere,"A",{href:!0});var Iyt=s(JU);vMr=r(Iyt,"from_pretrained()"),Iyt.forEach(t),FMr=r(Ere," to load the model weights."),Ere.forEach(t),TMr=i(B6),T(IM.$$.fragment,B6),B6.forEach(t),MMr=i(kl),Sr=n(kl,"DIV",{class:!0});var Sl=s(Sr);T(j9.$$.fragment,Sl),EMr=i(Sl),k3e=n(Sl,"P",{});var Nyt=s(k3e);CMr=r(Nyt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Nyt.forEach(t),wMr=i(Sl),cn=n(Sl,"P",{});var I6=s(cn);AMr=r(I6,"The model class to instantiate is selected based on the "),S3e=n(I6,"CODE",{});var qyt=s(S3e);LMr=r(qyt,"model_type"),qyt.forEach(t),yMr=r(I6,` property of the config object (either
passed as an argument or loaded from `),R3e=n(I6,"CODE",{});var jyt=s(R3e);xMr=r(jyt,"pretrained_model_name_or_path"),jyt.forEach(t),$Mr=r(I6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P3e=n(I6,"CODE",{});var Dyt=s(P3e);kMr=r(Dyt,"pretrained_model_name_or_path"),Dyt.forEach(t),SMr=r(I6,":"),I6.forEach(t),RMr=i(Sl),ie=n(Sl,"UL",{});var fe=s(ie);NM=n(fe,"LI",{});var LNe=s(NM);B3e=n(LNe,"STRONG",{});var Gyt=s(B3e);PMr=r(Gyt,"albert"),Gyt.forEach(t),BMr=r(LNe," \u2014 "),YU=n(LNe,"A",{href:!0});var Oyt=s(YU);IMr=r(Oyt,"TFAlbertForMaskedLM"),Oyt.forEach(t),NMr=r(LNe," (ALBERT model)"),LNe.forEach(t),qMr=i(fe),qM=n(fe,"LI",{});var yNe=s(qM);I3e=n(yNe,"STRONG",{});var Vyt=s(I3e);jMr=r(Vyt,"bert"),Vyt.forEach(t),DMr=r(yNe," \u2014 "),KU=n(yNe,"A",{href:!0});var Xyt=s(KU);GMr=r(Xyt,"TFBertForMaskedLM"),Xyt.forEach(t),OMr=r(yNe," (BERT model)"),yNe.forEach(t),VMr=i(fe),jM=n(fe,"LI",{});var xNe=s(jM);N3e=n(xNe,"STRONG",{});var zyt=s(N3e);XMr=r(zyt,"camembert"),zyt.forEach(t),zMr=r(xNe," \u2014 "),ZU=n(xNe,"A",{href:!0});var Qyt=s(ZU);QMr=r(Qyt,"TFCamembertForMaskedLM"),Qyt.forEach(t),WMr=r(xNe," (CamemBERT model)"),xNe.forEach(t),HMr=i(fe),DM=n(fe,"LI",{});var $Ne=s(DM);q3e=n($Ne,"STRONG",{});var Wyt=s(q3e);UMr=r(Wyt,"convbert"),Wyt.forEach(t),JMr=r($Ne," \u2014 "),eJ=n($Ne,"A",{href:!0});var Hyt=s(eJ);YMr=r(Hyt,"TFConvBertForMaskedLM"),Hyt.forEach(t),KMr=r($Ne," (ConvBERT model)"),$Ne.forEach(t),ZMr=i(fe),GM=n(fe,"LI",{});var kNe=s(GM);j3e=n(kNe,"STRONG",{});var Uyt=s(j3e);eEr=r(Uyt,"deberta"),Uyt.forEach(t),oEr=r(kNe," \u2014 "),oJ=n(kNe,"A",{href:!0});var Jyt=s(oJ);rEr=r(Jyt,"TFDebertaForMaskedLM"),Jyt.forEach(t),tEr=r(kNe," (DeBERTa model)"),kNe.forEach(t),aEr=i(fe),OM=n(fe,"LI",{});var SNe=s(OM);D3e=n(SNe,"STRONG",{});var Yyt=s(D3e);nEr=r(Yyt,"deberta-v2"),Yyt.forEach(t),sEr=r(SNe," \u2014 "),rJ=n(SNe,"A",{href:!0});var Kyt=s(rJ);lEr=r(Kyt,"TFDebertaV2ForMaskedLM"),Kyt.forEach(t),iEr=r(SNe," (DeBERTa-v2 model)"),SNe.forEach(t),dEr=i(fe),VM=n(fe,"LI",{});var RNe=s(VM);G3e=n(RNe,"STRONG",{});var Zyt=s(G3e);cEr=r(Zyt,"distilbert"),Zyt.forEach(t),fEr=r(RNe," \u2014 "),tJ=n(RNe,"A",{href:!0});var e8t=s(tJ);mEr=r(e8t,"TFDistilBertForMaskedLM"),e8t.forEach(t),gEr=r(RNe," (DistilBERT model)"),RNe.forEach(t),hEr=i(fe),XM=n(fe,"LI",{});var PNe=s(XM);O3e=n(PNe,"STRONG",{});var o8t=s(O3e);pEr=r(o8t,"electra"),o8t.forEach(t),_Er=r(PNe," \u2014 "),aJ=n(PNe,"A",{href:!0});var r8t=s(aJ);uEr=r(r8t,"TFElectraForMaskedLM"),r8t.forEach(t),bEr=r(PNe," (ELECTRA model)"),PNe.forEach(t),vEr=i(fe),zM=n(fe,"LI",{});var BNe=s(zM);V3e=n(BNe,"STRONG",{});var t8t=s(V3e);FEr=r(t8t,"flaubert"),t8t.forEach(t),TEr=r(BNe," \u2014 "),nJ=n(BNe,"A",{href:!0});var a8t=s(nJ);MEr=r(a8t,"TFFlaubertWithLMHeadModel"),a8t.forEach(t),EEr=r(BNe," (FlauBERT model)"),BNe.forEach(t),CEr=i(fe),QM=n(fe,"LI",{});var INe=s(QM);X3e=n(INe,"STRONG",{});var n8t=s(X3e);wEr=r(n8t,"funnel"),n8t.forEach(t),AEr=r(INe," \u2014 "),sJ=n(INe,"A",{href:!0});var s8t=s(sJ);LEr=r(s8t,"TFFunnelForMaskedLM"),s8t.forEach(t),yEr=r(INe," (Funnel Transformer model)"),INe.forEach(t),xEr=i(fe),WM=n(fe,"LI",{});var NNe=s(WM);z3e=n(NNe,"STRONG",{});var l8t=s(z3e);$Er=r(l8t,"layoutlm"),l8t.forEach(t),kEr=r(NNe," \u2014 "),lJ=n(NNe,"A",{href:!0});var i8t=s(lJ);SEr=r(i8t,"TFLayoutLMForMaskedLM"),i8t.forEach(t),REr=r(NNe," (LayoutLM model)"),NNe.forEach(t),PEr=i(fe),HM=n(fe,"LI",{});var qNe=s(HM);Q3e=n(qNe,"STRONG",{});var d8t=s(Q3e);BEr=r(d8t,"longformer"),d8t.forEach(t),IEr=r(qNe," \u2014 "),iJ=n(qNe,"A",{href:!0});var c8t=s(iJ);NEr=r(c8t,"TFLongformerForMaskedLM"),c8t.forEach(t),qEr=r(qNe," (Longformer model)"),qNe.forEach(t),jEr=i(fe),UM=n(fe,"LI",{});var jNe=s(UM);W3e=n(jNe,"STRONG",{});var f8t=s(W3e);DEr=r(f8t,"mobilebert"),f8t.forEach(t),GEr=r(jNe," \u2014 "),dJ=n(jNe,"A",{href:!0});var m8t=s(dJ);OEr=r(m8t,"TFMobileBertForMaskedLM"),m8t.forEach(t),VEr=r(jNe," (MobileBERT model)"),jNe.forEach(t),XEr=i(fe),JM=n(fe,"LI",{});var DNe=s(JM);H3e=n(DNe,"STRONG",{});var g8t=s(H3e);zEr=r(g8t,"mpnet"),g8t.forEach(t),QEr=r(DNe," \u2014 "),cJ=n(DNe,"A",{href:!0});var h8t=s(cJ);WEr=r(h8t,"TFMPNetForMaskedLM"),h8t.forEach(t),HEr=r(DNe," (MPNet model)"),DNe.forEach(t),UEr=i(fe),YM=n(fe,"LI",{});var GNe=s(YM);U3e=n(GNe,"STRONG",{});var p8t=s(U3e);JEr=r(p8t,"rembert"),p8t.forEach(t),YEr=r(GNe," \u2014 "),fJ=n(GNe,"A",{href:!0});var _8t=s(fJ);KEr=r(_8t,"TFRemBertForMaskedLM"),_8t.forEach(t),ZEr=r(GNe," (RemBERT model)"),GNe.forEach(t),e4r=i(fe),KM=n(fe,"LI",{});var ONe=s(KM);J3e=n(ONe,"STRONG",{});var u8t=s(J3e);o4r=r(u8t,"roberta"),u8t.forEach(t),r4r=r(ONe," \u2014 "),mJ=n(ONe,"A",{href:!0});var b8t=s(mJ);t4r=r(b8t,"TFRobertaForMaskedLM"),b8t.forEach(t),a4r=r(ONe," (RoBERTa model)"),ONe.forEach(t),n4r=i(fe),ZM=n(fe,"LI",{});var VNe=s(ZM);Y3e=n(VNe,"STRONG",{});var v8t=s(Y3e);s4r=r(v8t,"roformer"),v8t.forEach(t),l4r=r(VNe," \u2014 "),gJ=n(VNe,"A",{href:!0});var F8t=s(gJ);i4r=r(F8t,"TFRoFormerForMaskedLM"),F8t.forEach(t),d4r=r(VNe," (RoFormer model)"),VNe.forEach(t),c4r=i(fe),eE=n(fe,"LI",{});var XNe=s(eE);K3e=n(XNe,"STRONG",{});var T8t=s(K3e);f4r=r(T8t,"tapas"),T8t.forEach(t),m4r=r(XNe," \u2014 "),hJ=n(XNe,"A",{href:!0});var M8t=s(hJ);g4r=r(M8t,"TFTapasForMaskedLM"),M8t.forEach(t),h4r=r(XNe," (TAPAS model)"),XNe.forEach(t),p4r=i(fe),oE=n(fe,"LI",{});var zNe=s(oE);Z3e=n(zNe,"STRONG",{});var E8t=s(Z3e);_4r=r(E8t,"xlm"),E8t.forEach(t),u4r=r(zNe," \u2014 "),pJ=n(zNe,"A",{href:!0});var C8t=s(pJ);b4r=r(C8t,"TFXLMWithLMHeadModel"),C8t.forEach(t),v4r=r(zNe," (XLM model)"),zNe.forEach(t),F4r=i(fe),rE=n(fe,"LI",{});var QNe=s(rE);eFe=n(QNe,"STRONG",{});var w8t=s(eFe);T4r=r(w8t,"xlm-roberta"),w8t.forEach(t),M4r=r(QNe," \u2014 "),_J=n(QNe,"A",{href:!0});var A8t=s(_J);E4r=r(A8t,"TFXLMRobertaForMaskedLM"),A8t.forEach(t),C4r=r(QNe," (XLM-RoBERTa model)"),QNe.forEach(t),fe.forEach(t),w4r=i(Sl),T(tE.$$.fragment,Sl),Sl.forEach(t),kl.forEach(t),rVe=i(f),pc=n(f,"H2",{class:!0});var cze=s(pc);aE=n(cze,"A",{id:!0,class:!0,href:!0});var L8t=s(aE);oFe=n(L8t,"SPAN",{});var y8t=s(oFe);T(D9.$$.fragment,y8t),y8t.forEach(t),L8t.forEach(t),A4r=i(cze),rFe=n(cze,"SPAN",{});var x8t=s(rFe);L4r=r(x8t,"TFAutoModelForSeq2SeqLM"),x8t.forEach(t),cze.forEach(t),tVe=i(f),nr=n(f,"DIV",{class:!0});var Rl=s(nr);T(G9.$$.fragment,Rl),y4r=i(Rl),_c=n(Rl,"P",{});var Cre=s(_c);x4r=r(Cre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),uJ=n(Cre,"A",{href:!0});var $8t=s(uJ);$4r=r($8t,"from_pretrained()"),$8t.forEach(t),k4r=r(Cre," class method or the "),bJ=n(Cre,"A",{href:!0});var k8t=s(bJ);S4r=r(k8t,"from_config()"),k8t.forEach(t),R4r=r(Cre,` class
method.`),Cre.forEach(t),P4r=i(Rl),O9=n(Rl,"P",{});var fze=s(O9);B4r=r(fze,"This class cannot be instantiated directly using "),tFe=n(fze,"CODE",{});var S8t=s(tFe);I4r=r(S8t,"__init__()"),S8t.forEach(t),N4r=r(fze," (throws an error)."),fze.forEach(t),q4r=i(Rl),Bt=n(Rl,"DIV",{class:!0});var N6=s(Bt);T(V9.$$.fragment,N6),j4r=i(N6),aFe=n(N6,"P",{});var R8t=s(aFe);D4r=r(R8t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),R8t.forEach(t),G4r=i(N6),uc=n(N6,"P",{});var wre=s(uc);O4r=r(wre,`Note:
Loading a model from its configuration file does `),nFe=n(wre,"STRONG",{});var P8t=s(nFe);V4r=r(P8t,"not"),P8t.forEach(t),X4r=r(wre,` load the model weights. It only affects the
model\u2019s configuration. Use `),vJ=n(wre,"A",{href:!0});var B8t=s(vJ);z4r=r(B8t,"from_pretrained()"),B8t.forEach(t),Q4r=r(wre," to load the model weights."),wre.forEach(t),W4r=i(N6),T(nE.$$.fragment,N6),N6.forEach(t),H4r=i(Rl),Rr=n(Rl,"DIV",{class:!0});var Pl=s(Rr);T(X9.$$.fragment,Pl),U4r=i(Pl),sFe=n(Pl,"P",{});var I8t=s(sFe);J4r=r(I8t,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),I8t.forEach(t),Y4r=i(Pl),fn=n(Pl,"P",{});var q6=s(fn);K4r=r(q6,"The model class to instantiate is selected based on the "),lFe=n(q6,"CODE",{});var N8t=s(lFe);Z4r=r(N8t,"model_type"),N8t.forEach(t),eCr=r(q6,` property of the config object (either
passed as an argument or loaded from `),iFe=n(q6,"CODE",{});var q8t=s(iFe);oCr=r(q8t,"pretrained_model_name_or_path"),q8t.forEach(t),rCr=r(q6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dFe=n(q6,"CODE",{});var j8t=s(dFe);tCr=r(j8t,"pretrained_model_name_or_path"),j8t.forEach(t),aCr=r(q6,":"),q6.forEach(t),nCr=i(Pl),ye=n(Pl,"UL",{});var Ie=s(ye);sE=n(Ie,"LI",{});var WNe=s(sE);cFe=n(WNe,"STRONG",{});var D8t=s(cFe);sCr=r(D8t,"bart"),D8t.forEach(t),lCr=r(WNe," \u2014 "),FJ=n(WNe,"A",{href:!0});var G8t=s(FJ);iCr=r(G8t,"TFBartForConditionalGeneration"),G8t.forEach(t),dCr=r(WNe," (BART model)"),WNe.forEach(t),cCr=i(Ie),lE=n(Ie,"LI",{});var HNe=s(lE);fFe=n(HNe,"STRONG",{});var O8t=s(fFe);fCr=r(O8t,"blenderbot"),O8t.forEach(t),mCr=r(HNe," \u2014 "),TJ=n(HNe,"A",{href:!0});var V8t=s(TJ);gCr=r(V8t,"TFBlenderbotForConditionalGeneration"),V8t.forEach(t),hCr=r(HNe," (Blenderbot model)"),HNe.forEach(t),pCr=i(Ie),iE=n(Ie,"LI",{});var UNe=s(iE);mFe=n(UNe,"STRONG",{});var X8t=s(mFe);_Cr=r(X8t,"blenderbot-small"),X8t.forEach(t),uCr=r(UNe," \u2014 "),MJ=n(UNe,"A",{href:!0});var z8t=s(MJ);bCr=r(z8t,"TFBlenderbotSmallForConditionalGeneration"),z8t.forEach(t),vCr=r(UNe," (BlenderbotSmall model)"),UNe.forEach(t),FCr=i(Ie),dE=n(Ie,"LI",{});var JNe=s(dE);gFe=n(JNe,"STRONG",{});var Q8t=s(gFe);TCr=r(Q8t,"encoder-decoder"),Q8t.forEach(t),MCr=r(JNe," \u2014 "),EJ=n(JNe,"A",{href:!0});var W8t=s(EJ);ECr=r(W8t,"TFEncoderDecoderModel"),W8t.forEach(t),CCr=r(JNe," (Encoder decoder model)"),JNe.forEach(t),wCr=i(Ie),cE=n(Ie,"LI",{});var YNe=s(cE);hFe=n(YNe,"STRONG",{});var H8t=s(hFe);ACr=r(H8t,"led"),H8t.forEach(t),LCr=r(YNe," \u2014 "),CJ=n(YNe,"A",{href:!0});var U8t=s(CJ);yCr=r(U8t,"TFLEDForConditionalGeneration"),U8t.forEach(t),xCr=r(YNe," (LED model)"),YNe.forEach(t),$Cr=i(Ie),fE=n(Ie,"LI",{});var KNe=s(fE);pFe=n(KNe,"STRONG",{});var J8t=s(pFe);kCr=r(J8t,"marian"),J8t.forEach(t),SCr=r(KNe," \u2014 "),wJ=n(KNe,"A",{href:!0});var Y8t=s(wJ);RCr=r(Y8t,"TFMarianMTModel"),Y8t.forEach(t),PCr=r(KNe," (Marian model)"),KNe.forEach(t),BCr=i(Ie),mE=n(Ie,"LI",{});var ZNe=s(mE);_Fe=n(ZNe,"STRONG",{});var K8t=s(_Fe);ICr=r(K8t,"mbart"),K8t.forEach(t),NCr=r(ZNe," \u2014 "),AJ=n(ZNe,"A",{href:!0});var Z8t=s(AJ);qCr=r(Z8t,"TFMBartForConditionalGeneration"),Z8t.forEach(t),jCr=r(ZNe," (mBART model)"),ZNe.forEach(t),DCr=i(Ie),gE=n(Ie,"LI",{});var eqe=s(gE);uFe=n(eqe,"STRONG",{});var e9t=s(uFe);GCr=r(e9t,"mt5"),e9t.forEach(t),OCr=r(eqe," \u2014 "),LJ=n(eqe,"A",{href:!0});var o9t=s(LJ);VCr=r(o9t,"TFMT5ForConditionalGeneration"),o9t.forEach(t),XCr=r(eqe," (MT5 model)"),eqe.forEach(t),zCr=i(Ie),hE=n(Ie,"LI",{});var oqe=s(hE);bFe=n(oqe,"STRONG",{});var r9t=s(bFe);QCr=r(r9t,"pegasus"),r9t.forEach(t),WCr=r(oqe," \u2014 "),yJ=n(oqe,"A",{href:!0});var t9t=s(yJ);HCr=r(t9t,"TFPegasusForConditionalGeneration"),t9t.forEach(t),UCr=r(oqe," (Pegasus model)"),oqe.forEach(t),JCr=i(Ie),pE=n(Ie,"LI",{});var rqe=s(pE);vFe=n(rqe,"STRONG",{});var a9t=s(vFe);YCr=r(a9t,"t5"),a9t.forEach(t),KCr=r(rqe," \u2014 "),xJ=n(rqe,"A",{href:!0});var n9t=s(xJ);ZCr=r(n9t,"TFT5ForConditionalGeneration"),n9t.forEach(t),e0r=r(rqe," (T5 model)"),rqe.forEach(t),Ie.forEach(t),o0r=i(Pl),T(_E.$$.fragment,Pl),Pl.forEach(t),Rl.forEach(t),aVe=i(f),bc=n(f,"H2",{class:!0});var mze=s(bc);uE=n(mze,"A",{id:!0,class:!0,href:!0});var s9t=s(uE);FFe=n(s9t,"SPAN",{});var l9t=s(FFe);T(z9.$$.fragment,l9t),l9t.forEach(t),s9t.forEach(t),r0r=i(mze),TFe=n(mze,"SPAN",{});var i9t=s(TFe);t0r=r(i9t,"TFAutoModelForSequenceClassification"),i9t.forEach(t),mze.forEach(t),nVe=i(f),sr=n(f,"DIV",{class:!0});var Bl=s(sr);T(Q9.$$.fragment,Bl),a0r=i(Bl),vc=n(Bl,"P",{});var Are=s(vc);n0r=r(Are,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),$J=n(Are,"A",{href:!0});var d9t=s($J);s0r=r(d9t,"from_pretrained()"),d9t.forEach(t),l0r=r(Are," class method or the "),kJ=n(Are,"A",{href:!0});var c9t=s(kJ);i0r=r(c9t,"from_config()"),c9t.forEach(t),d0r=r(Are,` class
method.`),Are.forEach(t),c0r=i(Bl),W9=n(Bl,"P",{});var gze=s(W9);f0r=r(gze,"This class cannot be instantiated directly using "),MFe=n(gze,"CODE",{});var f9t=s(MFe);m0r=r(f9t,"__init__()"),f9t.forEach(t),g0r=r(gze," (throws an error)."),gze.forEach(t),h0r=i(Bl),It=n(Bl,"DIV",{class:!0});var j6=s(It);T(H9.$$.fragment,j6),p0r=i(j6),EFe=n(j6,"P",{});var m9t=s(EFe);_0r=r(m9t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),m9t.forEach(t),u0r=i(j6),Fc=n(j6,"P",{});var Lre=s(Fc);b0r=r(Lre,`Note:
Loading a model from its configuration file does `),CFe=n(Lre,"STRONG",{});var g9t=s(CFe);v0r=r(g9t,"not"),g9t.forEach(t),F0r=r(Lre,` load the model weights. It only affects the
model\u2019s configuration. Use `),SJ=n(Lre,"A",{href:!0});var h9t=s(SJ);T0r=r(h9t,"from_pretrained()"),h9t.forEach(t),M0r=r(Lre," to load the model weights."),Lre.forEach(t),E0r=i(j6),T(bE.$$.fragment,j6),j6.forEach(t),C0r=i(Bl),Pr=n(Bl,"DIV",{class:!0});var Il=s(Pr);T(U9.$$.fragment,Il),w0r=i(Il),wFe=n(Il,"P",{});var p9t=s(wFe);A0r=r(p9t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),p9t.forEach(t),L0r=i(Il),mn=n(Il,"P",{});var D6=s(mn);y0r=r(D6,"The model class to instantiate is selected based on the "),AFe=n(D6,"CODE",{});var _9t=s(AFe);x0r=r(_9t,"model_type"),_9t.forEach(t),$0r=r(D6,` property of the config object (either
passed as an argument or loaded from `),LFe=n(D6,"CODE",{});var u9t=s(LFe);k0r=r(u9t,"pretrained_model_name_or_path"),u9t.forEach(t),S0r=r(D6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yFe=n(D6,"CODE",{});var b9t=s(yFe);R0r=r(b9t,"pretrained_model_name_or_path"),b9t.forEach(t),P0r=r(D6,":"),D6.forEach(t),B0r=i(Il),te=n(Il,"UL",{});var ne=s(te);vE=n(ne,"LI",{});var tqe=s(vE);xFe=n(tqe,"STRONG",{});var v9t=s(xFe);I0r=r(v9t,"albert"),v9t.forEach(t),N0r=r(tqe," \u2014 "),RJ=n(tqe,"A",{href:!0});var F9t=s(RJ);q0r=r(F9t,"TFAlbertForSequenceClassification"),F9t.forEach(t),j0r=r(tqe," (ALBERT model)"),tqe.forEach(t),D0r=i(ne),FE=n(ne,"LI",{});var aqe=s(FE);$Fe=n(aqe,"STRONG",{});var T9t=s($Fe);G0r=r(T9t,"bert"),T9t.forEach(t),O0r=r(aqe," \u2014 "),PJ=n(aqe,"A",{href:!0});var M9t=s(PJ);V0r=r(M9t,"TFBertForSequenceClassification"),M9t.forEach(t),X0r=r(aqe," (BERT model)"),aqe.forEach(t),z0r=i(ne),TE=n(ne,"LI",{});var nqe=s(TE);kFe=n(nqe,"STRONG",{});var E9t=s(kFe);Q0r=r(E9t,"camembert"),E9t.forEach(t),W0r=r(nqe," \u2014 "),BJ=n(nqe,"A",{href:!0});var C9t=s(BJ);H0r=r(C9t,"TFCamembertForSequenceClassification"),C9t.forEach(t),U0r=r(nqe," (CamemBERT model)"),nqe.forEach(t),J0r=i(ne),ME=n(ne,"LI",{});var sqe=s(ME);SFe=n(sqe,"STRONG",{});var w9t=s(SFe);Y0r=r(w9t,"convbert"),w9t.forEach(t),K0r=r(sqe," \u2014 "),IJ=n(sqe,"A",{href:!0});var A9t=s(IJ);Z0r=r(A9t,"TFConvBertForSequenceClassification"),A9t.forEach(t),ewr=r(sqe," (ConvBERT model)"),sqe.forEach(t),owr=i(ne),EE=n(ne,"LI",{});var lqe=s(EE);RFe=n(lqe,"STRONG",{});var L9t=s(RFe);rwr=r(L9t,"ctrl"),L9t.forEach(t),twr=r(lqe," \u2014 "),NJ=n(lqe,"A",{href:!0});var y9t=s(NJ);awr=r(y9t,"TFCTRLForSequenceClassification"),y9t.forEach(t),nwr=r(lqe," (CTRL model)"),lqe.forEach(t),swr=i(ne),CE=n(ne,"LI",{});var iqe=s(CE);PFe=n(iqe,"STRONG",{});var x9t=s(PFe);lwr=r(x9t,"deberta"),x9t.forEach(t),iwr=r(iqe," \u2014 "),qJ=n(iqe,"A",{href:!0});var $9t=s(qJ);dwr=r($9t,"TFDebertaForSequenceClassification"),$9t.forEach(t),cwr=r(iqe," (DeBERTa model)"),iqe.forEach(t),fwr=i(ne),wE=n(ne,"LI",{});var dqe=s(wE);BFe=n(dqe,"STRONG",{});var k9t=s(BFe);mwr=r(k9t,"deberta-v2"),k9t.forEach(t),gwr=r(dqe," \u2014 "),jJ=n(dqe,"A",{href:!0});var S9t=s(jJ);hwr=r(S9t,"TFDebertaV2ForSequenceClassification"),S9t.forEach(t),pwr=r(dqe," (DeBERTa-v2 model)"),dqe.forEach(t),_wr=i(ne),AE=n(ne,"LI",{});var cqe=s(AE);IFe=n(cqe,"STRONG",{});var R9t=s(IFe);uwr=r(R9t,"distilbert"),R9t.forEach(t),bwr=r(cqe," \u2014 "),DJ=n(cqe,"A",{href:!0});var P9t=s(DJ);vwr=r(P9t,"TFDistilBertForSequenceClassification"),P9t.forEach(t),Fwr=r(cqe," (DistilBERT model)"),cqe.forEach(t),Twr=i(ne),LE=n(ne,"LI",{});var fqe=s(LE);NFe=n(fqe,"STRONG",{});var B9t=s(NFe);Mwr=r(B9t,"electra"),B9t.forEach(t),Ewr=r(fqe," \u2014 "),GJ=n(fqe,"A",{href:!0});var I9t=s(GJ);Cwr=r(I9t,"TFElectraForSequenceClassification"),I9t.forEach(t),wwr=r(fqe," (ELECTRA model)"),fqe.forEach(t),Awr=i(ne),yE=n(ne,"LI",{});var mqe=s(yE);qFe=n(mqe,"STRONG",{});var N9t=s(qFe);Lwr=r(N9t,"flaubert"),N9t.forEach(t),ywr=r(mqe," \u2014 "),OJ=n(mqe,"A",{href:!0});var q9t=s(OJ);xwr=r(q9t,"TFFlaubertForSequenceClassification"),q9t.forEach(t),$wr=r(mqe," (FlauBERT model)"),mqe.forEach(t),kwr=i(ne),xE=n(ne,"LI",{});var gqe=s(xE);jFe=n(gqe,"STRONG",{});var j9t=s(jFe);Swr=r(j9t,"funnel"),j9t.forEach(t),Rwr=r(gqe," \u2014 "),VJ=n(gqe,"A",{href:!0});var D9t=s(VJ);Pwr=r(D9t,"TFFunnelForSequenceClassification"),D9t.forEach(t),Bwr=r(gqe," (Funnel Transformer model)"),gqe.forEach(t),Iwr=i(ne),$E=n(ne,"LI",{});var hqe=s($E);DFe=n(hqe,"STRONG",{});var G9t=s(DFe);Nwr=r(G9t,"gpt2"),G9t.forEach(t),qwr=r(hqe," \u2014 "),XJ=n(hqe,"A",{href:!0});var O9t=s(XJ);jwr=r(O9t,"TFGPT2ForSequenceClassification"),O9t.forEach(t),Dwr=r(hqe," (OpenAI GPT-2 model)"),hqe.forEach(t),Gwr=i(ne),kE=n(ne,"LI",{});var pqe=s(kE);GFe=n(pqe,"STRONG",{});var V9t=s(GFe);Owr=r(V9t,"gptj"),V9t.forEach(t),Vwr=r(pqe," \u2014 "),zJ=n(pqe,"A",{href:!0});var X9t=s(zJ);Xwr=r(X9t,"TFGPTJForSequenceClassification"),X9t.forEach(t),zwr=r(pqe," (GPT-J model)"),pqe.forEach(t),Qwr=i(ne),SE=n(ne,"LI",{});var _qe=s(SE);OFe=n(_qe,"STRONG",{});var z9t=s(OFe);Wwr=r(z9t,"layoutlm"),z9t.forEach(t),Hwr=r(_qe," \u2014 "),QJ=n(_qe,"A",{href:!0});var Q9t=s(QJ);Uwr=r(Q9t,"TFLayoutLMForSequenceClassification"),Q9t.forEach(t),Jwr=r(_qe," (LayoutLM model)"),_qe.forEach(t),Ywr=i(ne),RE=n(ne,"LI",{});var uqe=s(RE);VFe=n(uqe,"STRONG",{});var W9t=s(VFe);Kwr=r(W9t,"longformer"),W9t.forEach(t),Zwr=r(uqe," \u2014 "),WJ=n(uqe,"A",{href:!0});var H9t=s(WJ);eAr=r(H9t,"TFLongformerForSequenceClassification"),H9t.forEach(t),oAr=r(uqe," (Longformer model)"),uqe.forEach(t),rAr=i(ne),PE=n(ne,"LI",{});var bqe=s(PE);XFe=n(bqe,"STRONG",{});var U9t=s(XFe);tAr=r(U9t,"mobilebert"),U9t.forEach(t),aAr=r(bqe," \u2014 "),HJ=n(bqe,"A",{href:!0});var J9t=s(HJ);nAr=r(J9t,"TFMobileBertForSequenceClassification"),J9t.forEach(t),sAr=r(bqe," (MobileBERT model)"),bqe.forEach(t),lAr=i(ne),BE=n(ne,"LI",{});var vqe=s(BE);zFe=n(vqe,"STRONG",{});var Y9t=s(zFe);iAr=r(Y9t,"mpnet"),Y9t.forEach(t),dAr=r(vqe," \u2014 "),UJ=n(vqe,"A",{href:!0});var K9t=s(UJ);cAr=r(K9t,"TFMPNetForSequenceClassification"),K9t.forEach(t),fAr=r(vqe," (MPNet model)"),vqe.forEach(t),mAr=i(ne),IE=n(ne,"LI",{});var Fqe=s(IE);QFe=n(Fqe,"STRONG",{});var Z9t=s(QFe);gAr=r(Z9t,"openai-gpt"),Z9t.forEach(t),hAr=r(Fqe," \u2014 "),JJ=n(Fqe,"A",{href:!0});var ext=s(JJ);pAr=r(ext,"TFOpenAIGPTForSequenceClassification"),ext.forEach(t),_Ar=r(Fqe," (OpenAI GPT model)"),Fqe.forEach(t),uAr=i(ne),NE=n(ne,"LI",{});var Tqe=s(NE);WFe=n(Tqe,"STRONG",{});var oxt=s(WFe);bAr=r(oxt,"rembert"),oxt.forEach(t),vAr=r(Tqe," \u2014 "),YJ=n(Tqe,"A",{href:!0});var rxt=s(YJ);FAr=r(rxt,"TFRemBertForSequenceClassification"),rxt.forEach(t),TAr=r(Tqe," (RemBERT model)"),Tqe.forEach(t),MAr=i(ne),qE=n(ne,"LI",{});var Mqe=s(qE);HFe=n(Mqe,"STRONG",{});var txt=s(HFe);EAr=r(txt,"roberta"),txt.forEach(t),CAr=r(Mqe," \u2014 "),KJ=n(Mqe,"A",{href:!0});var axt=s(KJ);wAr=r(axt,"TFRobertaForSequenceClassification"),axt.forEach(t),AAr=r(Mqe," (RoBERTa model)"),Mqe.forEach(t),LAr=i(ne),jE=n(ne,"LI",{});var Eqe=s(jE);UFe=n(Eqe,"STRONG",{});var nxt=s(UFe);yAr=r(nxt,"roformer"),nxt.forEach(t),xAr=r(Eqe," \u2014 "),ZJ=n(Eqe,"A",{href:!0});var sxt=s(ZJ);$Ar=r(sxt,"TFRoFormerForSequenceClassification"),sxt.forEach(t),kAr=r(Eqe," (RoFormer model)"),Eqe.forEach(t),SAr=i(ne),DE=n(ne,"LI",{});var Cqe=s(DE);JFe=n(Cqe,"STRONG",{});var lxt=s(JFe);RAr=r(lxt,"tapas"),lxt.forEach(t),PAr=r(Cqe," \u2014 "),eY=n(Cqe,"A",{href:!0});var ixt=s(eY);BAr=r(ixt,"TFTapasForSequenceClassification"),ixt.forEach(t),IAr=r(Cqe," (TAPAS model)"),Cqe.forEach(t),NAr=i(ne),GE=n(ne,"LI",{});var wqe=s(GE);YFe=n(wqe,"STRONG",{});var dxt=s(YFe);qAr=r(dxt,"transfo-xl"),dxt.forEach(t),jAr=r(wqe," \u2014 "),oY=n(wqe,"A",{href:!0});var cxt=s(oY);DAr=r(cxt,"TFTransfoXLForSequenceClassification"),cxt.forEach(t),GAr=r(wqe," (Transformer-XL model)"),wqe.forEach(t),OAr=i(ne),OE=n(ne,"LI",{});var Aqe=s(OE);KFe=n(Aqe,"STRONG",{});var fxt=s(KFe);VAr=r(fxt,"xlm"),fxt.forEach(t),XAr=r(Aqe," \u2014 "),rY=n(Aqe,"A",{href:!0});var mxt=s(rY);zAr=r(mxt,"TFXLMForSequenceClassification"),mxt.forEach(t),QAr=r(Aqe," (XLM model)"),Aqe.forEach(t),WAr=i(ne),VE=n(ne,"LI",{});var Lqe=s(VE);ZFe=n(Lqe,"STRONG",{});var gxt=s(ZFe);HAr=r(gxt,"xlm-roberta"),gxt.forEach(t),UAr=r(Lqe," \u2014 "),tY=n(Lqe,"A",{href:!0});var hxt=s(tY);JAr=r(hxt,"TFXLMRobertaForSequenceClassification"),hxt.forEach(t),YAr=r(Lqe," (XLM-RoBERTa model)"),Lqe.forEach(t),KAr=i(ne),XE=n(ne,"LI",{});var yqe=s(XE);eTe=n(yqe,"STRONG",{});var pxt=s(eTe);ZAr=r(pxt,"xlnet"),pxt.forEach(t),e6r=r(yqe," \u2014 "),aY=n(yqe,"A",{href:!0});var _xt=s(aY);o6r=r(_xt,"TFXLNetForSequenceClassification"),_xt.forEach(t),r6r=r(yqe," (XLNet model)"),yqe.forEach(t),ne.forEach(t),t6r=i(Il),T(zE.$$.fragment,Il),Il.forEach(t),Bl.forEach(t),sVe=i(f),Tc=n(f,"H2",{class:!0});var hze=s(Tc);QE=n(hze,"A",{id:!0,class:!0,href:!0});var uxt=s(QE);oTe=n(uxt,"SPAN",{});var bxt=s(oTe);T(J9.$$.fragment,bxt),bxt.forEach(t),uxt.forEach(t),a6r=i(hze),rTe=n(hze,"SPAN",{});var vxt=s(rTe);n6r=r(vxt,"TFAutoModelForMultipleChoice"),vxt.forEach(t),hze.forEach(t),lVe=i(f),lr=n(f,"DIV",{class:!0});var Nl=s(lr);T(Y9.$$.fragment,Nl),s6r=i(Nl),Mc=n(Nl,"P",{});var yre=s(Mc);l6r=r(yre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),nY=n(yre,"A",{href:!0});var Fxt=s(nY);i6r=r(Fxt,"from_pretrained()"),Fxt.forEach(t),d6r=r(yre," class method or the "),sY=n(yre,"A",{href:!0});var Txt=s(sY);c6r=r(Txt,"from_config()"),Txt.forEach(t),f6r=r(yre,` class
method.`),yre.forEach(t),m6r=i(Nl),K9=n(Nl,"P",{});var pze=s(K9);g6r=r(pze,"This class cannot be instantiated directly using "),tTe=n(pze,"CODE",{});var Mxt=s(tTe);h6r=r(Mxt,"__init__()"),Mxt.forEach(t),p6r=r(pze," (throws an error)."),pze.forEach(t),_6r=i(Nl),Nt=n(Nl,"DIV",{class:!0});var G6=s(Nt);T(Z9.$$.fragment,G6),u6r=i(G6),aTe=n(G6,"P",{});var Ext=s(aTe);b6r=r(Ext,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Ext.forEach(t),v6r=i(G6),Ec=n(G6,"P",{});var xre=s(Ec);F6r=r(xre,`Note:
Loading a model from its configuration file does `),nTe=n(xre,"STRONG",{});var Cxt=s(nTe);T6r=r(Cxt,"not"),Cxt.forEach(t),M6r=r(xre,` load the model weights. It only affects the
model\u2019s configuration. Use `),lY=n(xre,"A",{href:!0});var wxt=s(lY);E6r=r(wxt,"from_pretrained()"),wxt.forEach(t),C6r=r(xre," to load the model weights."),xre.forEach(t),w6r=i(G6),T(WE.$$.fragment,G6),G6.forEach(t),A6r=i(Nl),Br=n(Nl,"DIV",{class:!0});var ql=s(Br);T(ex.$$.fragment,ql),L6r=i(ql),sTe=n(ql,"P",{});var Axt=s(sTe);y6r=r(Axt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Axt.forEach(t),x6r=i(ql),gn=n(ql,"P",{});var O6=s(gn);$6r=r(O6,"The model class to instantiate is selected based on the "),lTe=n(O6,"CODE",{});var Lxt=s(lTe);k6r=r(Lxt,"model_type"),Lxt.forEach(t),S6r=r(O6,` property of the config object (either
passed as an argument or loaded from `),iTe=n(O6,"CODE",{});var yxt=s(iTe);R6r=r(yxt,"pretrained_model_name_or_path"),yxt.forEach(t),P6r=r(O6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dTe=n(O6,"CODE",{});var xxt=s(dTe);B6r=r(xxt,"pretrained_model_name_or_path"),xxt.forEach(t),I6r=r(O6,":"),O6.forEach(t),N6r=i(ql),_e=n(ql,"UL",{});var ve=s(_e);HE=n(ve,"LI",{});var xqe=s(HE);cTe=n(xqe,"STRONG",{});var $xt=s(cTe);q6r=r($xt,"albert"),$xt.forEach(t),j6r=r(xqe," \u2014 "),iY=n(xqe,"A",{href:!0});var kxt=s(iY);D6r=r(kxt,"TFAlbertForMultipleChoice"),kxt.forEach(t),G6r=r(xqe," (ALBERT model)"),xqe.forEach(t),O6r=i(ve),UE=n(ve,"LI",{});var $qe=s(UE);fTe=n($qe,"STRONG",{});var Sxt=s(fTe);V6r=r(Sxt,"bert"),Sxt.forEach(t),X6r=r($qe," \u2014 "),dY=n($qe,"A",{href:!0});var Rxt=s(dY);z6r=r(Rxt,"TFBertForMultipleChoice"),Rxt.forEach(t),Q6r=r($qe," (BERT model)"),$qe.forEach(t),W6r=i(ve),JE=n(ve,"LI",{});var kqe=s(JE);mTe=n(kqe,"STRONG",{});var Pxt=s(mTe);H6r=r(Pxt,"camembert"),Pxt.forEach(t),U6r=r(kqe," \u2014 "),cY=n(kqe,"A",{href:!0});var Bxt=s(cY);J6r=r(Bxt,"TFCamembertForMultipleChoice"),Bxt.forEach(t),Y6r=r(kqe," (CamemBERT model)"),kqe.forEach(t),K6r=i(ve),YE=n(ve,"LI",{});var Sqe=s(YE);gTe=n(Sqe,"STRONG",{});var Ixt=s(gTe);Z6r=r(Ixt,"convbert"),Ixt.forEach(t),eLr=r(Sqe," \u2014 "),fY=n(Sqe,"A",{href:!0});var Nxt=s(fY);oLr=r(Nxt,"TFConvBertForMultipleChoice"),Nxt.forEach(t),rLr=r(Sqe," (ConvBERT model)"),Sqe.forEach(t),tLr=i(ve),KE=n(ve,"LI",{});var Rqe=s(KE);hTe=n(Rqe,"STRONG",{});var qxt=s(hTe);aLr=r(qxt,"distilbert"),qxt.forEach(t),nLr=r(Rqe," \u2014 "),mY=n(Rqe,"A",{href:!0});var jxt=s(mY);sLr=r(jxt,"TFDistilBertForMultipleChoice"),jxt.forEach(t),lLr=r(Rqe," (DistilBERT model)"),Rqe.forEach(t),iLr=i(ve),ZE=n(ve,"LI",{});var Pqe=s(ZE);pTe=n(Pqe,"STRONG",{});var Dxt=s(pTe);dLr=r(Dxt,"electra"),Dxt.forEach(t),cLr=r(Pqe," \u2014 "),gY=n(Pqe,"A",{href:!0});var Gxt=s(gY);fLr=r(Gxt,"TFElectraForMultipleChoice"),Gxt.forEach(t),mLr=r(Pqe," (ELECTRA model)"),Pqe.forEach(t),gLr=i(ve),e4=n(ve,"LI",{});var Bqe=s(e4);_Te=n(Bqe,"STRONG",{});var Oxt=s(_Te);hLr=r(Oxt,"flaubert"),Oxt.forEach(t),pLr=r(Bqe," \u2014 "),hY=n(Bqe,"A",{href:!0});var Vxt=s(hY);_Lr=r(Vxt,"TFFlaubertForMultipleChoice"),Vxt.forEach(t),uLr=r(Bqe," (FlauBERT model)"),Bqe.forEach(t),bLr=i(ve),o4=n(ve,"LI",{});var Iqe=s(o4);uTe=n(Iqe,"STRONG",{});var Xxt=s(uTe);vLr=r(Xxt,"funnel"),Xxt.forEach(t),FLr=r(Iqe," \u2014 "),pY=n(Iqe,"A",{href:!0});var zxt=s(pY);TLr=r(zxt,"TFFunnelForMultipleChoice"),zxt.forEach(t),MLr=r(Iqe," (Funnel Transformer model)"),Iqe.forEach(t),ELr=i(ve),r4=n(ve,"LI",{});var Nqe=s(r4);bTe=n(Nqe,"STRONG",{});var Qxt=s(bTe);CLr=r(Qxt,"longformer"),Qxt.forEach(t),wLr=r(Nqe," \u2014 "),_Y=n(Nqe,"A",{href:!0});var Wxt=s(_Y);ALr=r(Wxt,"TFLongformerForMultipleChoice"),Wxt.forEach(t),LLr=r(Nqe," (Longformer model)"),Nqe.forEach(t),yLr=i(ve),t4=n(ve,"LI",{});var qqe=s(t4);vTe=n(qqe,"STRONG",{});var Hxt=s(vTe);xLr=r(Hxt,"mobilebert"),Hxt.forEach(t),$Lr=r(qqe," \u2014 "),uY=n(qqe,"A",{href:!0});var Uxt=s(uY);kLr=r(Uxt,"TFMobileBertForMultipleChoice"),Uxt.forEach(t),SLr=r(qqe," (MobileBERT model)"),qqe.forEach(t),RLr=i(ve),a4=n(ve,"LI",{});var jqe=s(a4);FTe=n(jqe,"STRONG",{});var Jxt=s(FTe);PLr=r(Jxt,"mpnet"),Jxt.forEach(t),BLr=r(jqe," \u2014 "),bY=n(jqe,"A",{href:!0});var Yxt=s(bY);ILr=r(Yxt,"TFMPNetForMultipleChoice"),Yxt.forEach(t),NLr=r(jqe," (MPNet model)"),jqe.forEach(t),qLr=i(ve),n4=n(ve,"LI",{});var Dqe=s(n4);TTe=n(Dqe,"STRONG",{});var Kxt=s(TTe);jLr=r(Kxt,"rembert"),Kxt.forEach(t),DLr=r(Dqe," \u2014 "),vY=n(Dqe,"A",{href:!0});var Zxt=s(vY);GLr=r(Zxt,"TFRemBertForMultipleChoice"),Zxt.forEach(t),OLr=r(Dqe," (RemBERT model)"),Dqe.forEach(t),VLr=i(ve),s4=n(ve,"LI",{});var Gqe=s(s4);MTe=n(Gqe,"STRONG",{});var e$t=s(MTe);XLr=r(e$t,"roberta"),e$t.forEach(t),zLr=r(Gqe," \u2014 "),FY=n(Gqe,"A",{href:!0});var o$t=s(FY);QLr=r(o$t,"TFRobertaForMultipleChoice"),o$t.forEach(t),WLr=r(Gqe," (RoBERTa model)"),Gqe.forEach(t),HLr=i(ve),l4=n(ve,"LI",{});var Oqe=s(l4);ETe=n(Oqe,"STRONG",{});var r$t=s(ETe);ULr=r(r$t,"roformer"),r$t.forEach(t),JLr=r(Oqe," \u2014 "),TY=n(Oqe,"A",{href:!0});var t$t=s(TY);YLr=r(t$t,"TFRoFormerForMultipleChoice"),t$t.forEach(t),KLr=r(Oqe," (RoFormer model)"),Oqe.forEach(t),ZLr=i(ve),i4=n(ve,"LI",{});var Vqe=s(i4);CTe=n(Vqe,"STRONG",{});var a$t=s(CTe);eyr=r(a$t,"xlm"),a$t.forEach(t),oyr=r(Vqe," \u2014 "),MY=n(Vqe,"A",{href:!0});var n$t=s(MY);ryr=r(n$t,"TFXLMForMultipleChoice"),n$t.forEach(t),tyr=r(Vqe," (XLM model)"),Vqe.forEach(t),ayr=i(ve),d4=n(ve,"LI",{});var Xqe=s(d4);wTe=n(Xqe,"STRONG",{});var s$t=s(wTe);nyr=r(s$t,"xlm-roberta"),s$t.forEach(t),syr=r(Xqe," \u2014 "),EY=n(Xqe,"A",{href:!0});var l$t=s(EY);lyr=r(l$t,"TFXLMRobertaForMultipleChoice"),l$t.forEach(t),iyr=r(Xqe," (XLM-RoBERTa model)"),Xqe.forEach(t),dyr=i(ve),c4=n(ve,"LI",{});var zqe=s(c4);ATe=n(zqe,"STRONG",{});var i$t=s(ATe);cyr=r(i$t,"xlnet"),i$t.forEach(t),fyr=r(zqe," \u2014 "),CY=n(zqe,"A",{href:!0});var d$t=s(CY);myr=r(d$t,"TFXLNetForMultipleChoice"),d$t.forEach(t),gyr=r(zqe," (XLNet model)"),zqe.forEach(t),ve.forEach(t),hyr=i(ql),T(f4.$$.fragment,ql),ql.forEach(t),Nl.forEach(t),iVe=i(f),Cc=n(f,"H2",{class:!0});var _ze=s(Cc);m4=n(_ze,"A",{id:!0,class:!0,href:!0});var c$t=s(m4);LTe=n(c$t,"SPAN",{});var f$t=s(LTe);T(ox.$$.fragment,f$t),f$t.forEach(t),c$t.forEach(t),pyr=i(_ze),yTe=n(_ze,"SPAN",{});var m$t=s(yTe);_yr=r(m$t,"TFAutoModelForNextSentencePrediction"),m$t.forEach(t),_ze.forEach(t),dVe=i(f),ir=n(f,"DIV",{class:!0});var jl=s(ir);T(rx.$$.fragment,jl),uyr=i(jl),wc=n(jl,"P",{});var $re=s(wc);byr=r($re,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),wY=n($re,"A",{href:!0});var g$t=s(wY);vyr=r(g$t,"from_pretrained()"),g$t.forEach(t),Fyr=r($re," class method or the "),AY=n($re,"A",{href:!0});var h$t=s(AY);Tyr=r(h$t,"from_config()"),h$t.forEach(t),Myr=r($re,` class
method.`),$re.forEach(t),Eyr=i(jl),tx=n(jl,"P",{});var uze=s(tx);Cyr=r(uze,"This class cannot be instantiated directly using "),xTe=n(uze,"CODE",{});var p$t=s(xTe);wyr=r(p$t,"__init__()"),p$t.forEach(t),Ayr=r(uze," (throws an error)."),uze.forEach(t),Lyr=i(jl),qt=n(jl,"DIV",{class:!0});var V6=s(qt);T(ax.$$.fragment,V6),yyr=i(V6),$Te=n(V6,"P",{});var _$t=s($Te);xyr=r(_$t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),_$t.forEach(t),$yr=i(V6),Ac=n(V6,"P",{});var kre=s(Ac);kyr=r(kre,`Note:
Loading a model from its configuration file does `),kTe=n(kre,"STRONG",{});var u$t=s(kTe);Syr=r(u$t,"not"),u$t.forEach(t),Ryr=r(kre,` load the model weights. It only affects the
model\u2019s configuration. Use `),LY=n(kre,"A",{href:!0});var b$t=s(LY);Pyr=r(b$t,"from_pretrained()"),b$t.forEach(t),Byr=r(kre," to load the model weights."),kre.forEach(t),Iyr=i(V6),T(g4.$$.fragment,V6),V6.forEach(t),Nyr=i(jl),Ir=n(jl,"DIV",{class:!0});var Dl=s(Ir);T(nx.$$.fragment,Dl),qyr=i(Dl),STe=n(Dl,"P",{});var v$t=s(STe);jyr=r(v$t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),v$t.forEach(t),Dyr=i(Dl),hn=n(Dl,"P",{});var X6=s(hn);Gyr=r(X6,"The model class to instantiate is selected based on the "),RTe=n(X6,"CODE",{});var F$t=s(RTe);Oyr=r(F$t,"model_type"),F$t.forEach(t),Vyr=r(X6,` property of the config object (either
passed as an argument or loaded from `),PTe=n(X6,"CODE",{});var T$t=s(PTe);Xyr=r(T$t,"pretrained_model_name_or_path"),T$t.forEach(t),zyr=r(X6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BTe=n(X6,"CODE",{});var M$t=s(BTe);Qyr=r(M$t,"pretrained_model_name_or_path"),M$t.forEach(t),Wyr=r(X6,":"),X6.forEach(t),Hyr=i(Dl),sx=n(Dl,"UL",{});var bze=s(sx);h4=n(bze,"LI",{});var Qqe=s(h4);ITe=n(Qqe,"STRONG",{});var E$t=s(ITe);Uyr=r(E$t,"bert"),E$t.forEach(t),Jyr=r(Qqe," \u2014 "),yY=n(Qqe,"A",{href:!0});var C$t=s(yY);Yyr=r(C$t,"TFBertForNextSentencePrediction"),C$t.forEach(t),Kyr=r(Qqe," (BERT model)"),Qqe.forEach(t),Zyr=i(bze),p4=n(bze,"LI",{});var Wqe=s(p4);NTe=n(Wqe,"STRONG",{});var w$t=s(NTe);e8r=r(w$t,"mobilebert"),w$t.forEach(t),o8r=r(Wqe," \u2014 "),xY=n(Wqe,"A",{href:!0});var A$t=s(xY);r8r=r(A$t,"TFMobileBertForNextSentencePrediction"),A$t.forEach(t),t8r=r(Wqe," (MobileBERT model)"),Wqe.forEach(t),bze.forEach(t),a8r=i(Dl),T(_4.$$.fragment,Dl),Dl.forEach(t),jl.forEach(t),cVe=i(f),Lc=n(f,"H2",{class:!0});var vze=s(Lc);u4=n(vze,"A",{id:!0,class:!0,href:!0});var L$t=s(u4);qTe=n(L$t,"SPAN",{});var y$t=s(qTe);T(lx.$$.fragment,y$t),y$t.forEach(t),L$t.forEach(t),n8r=i(vze),jTe=n(vze,"SPAN",{});var x$t=s(jTe);s8r=r(x$t,"TFAutoModelForTableQuestionAnswering"),x$t.forEach(t),vze.forEach(t),fVe=i(f),dr=n(f,"DIV",{class:!0});var Gl=s(dr);T(ix.$$.fragment,Gl),l8r=i(Gl),yc=n(Gl,"P",{});var Sre=s(yc);i8r=r(Sre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),$Y=n(Sre,"A",{href:!0});var $$t=s($Y);d8r=r($$t,"from_pretrained()"),$$t.forEach(t),c8r=r(Sre," class method or the "),kY=n(Sre,"A",{href:!0});var k$t=s(kY);f8r=r(k$t,"from_config()"),k$t.forEach(t),m8r=r(Sre,` class
method.`),Sre.forEach(t),g8r=i(Gl),dx=n(Gl,"P",{});var Fze=s(dx);h8r=r(Fze,"This class cannot be instantiated directly using "),DTe=n(Fze,"CODE",{});var S$t=s(DTe);p8r=r(S$t,"__init__()"),S$t.forEach(t),_8r=r(Fze," (throws an error)."),Fze.forEach(t),u8r=i(Gl),jt=n(Gl,"DIV",{class:!0});var z6=s(jt);T(cx.$$.fragment,z6),b8r=i(z6),GTe=n(z6,"P",{});var R$t=s(GTe);v8r=r(R$t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),R$t.forEach(t),F8r=i(z6),xc=n(z6,"P",{});var Rre=s(xc);T8r=r(Rre,`Note:
Loading a model from its configuration file does `),OTe=n(Rre,"STRONG",{});var P$t=s(OTe);M8r=r(P$t,"not"),P$t.forEach(t),E8r=r(Rre,` load the model weights. It only affects the
model\u2019s configuration. Use `),SY=n(Rre,"A",{href:!0});var B$t=s(SY);C8r=r(B$t,"from_pretrained()"),B$t.forEach(t),w8r=r(Rre," to load the model weights."),Rre.forEach(t),A8r=i(z6),T(b4.$$.fragment,z6),z6.forEach(t),L8r=i(Gl),Nr=n(Gl,"DIV",{class:!0});var Ol=s(Nr);T(fx.$$.fragment,Ol),y8r=i(Ol),VTe=n(Ol,"P",{});var I$t=s(VTe);x8r=r(I$t,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),I$t.forEach(t),$8r=i(Ol),pn=n(Ol,"P",{});var Q6=s(pn);k8r=r(Q6,"The model class to instantiate is selected based on the "),XTe=n(Q6,"CODE",{});var N$t=s(XTe);S8r=r(N$t,"model_type"),N$t.forEach(t),R8r=r(Q6,` property of the config object (either
passed as an argument or loaded from `),zTe=n(Q6,"CODE",{});var q$t=s(zTe);P8r=r(q$t,"pretrained_model_name_or_path"),q$t.forEach(t),B8r=r(Q6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QTe=n(Q6,"CODE",{});var j$t=s(QTe);I8r=r(j$t,"pretrained_model_name_or_path"),j$t.forEach(t),N8r=r(Q6,":"),Q6.forEach(t),q8r=i(Ol),WTe=n(Ol,"UL",{});var D$t=s(WTe);v4=n(D$t,"LI",{});var Hqe=s(v4);HTe=n(Hqe,"STRONG",{});var G$t=s(HTe);j8r=r(G$t,"tapas"),G$t.forEach(t),D8r=r(Hqe," \u2014 "),RY=n(Hqe,"A",{href:!0});var O$t=s(RY);G8r=r(O$t,"TFTapasForQuestionAnswering"),O$t.forEach(t),O8r=r(Hqe," (TAPAS model)"),Hqe.forEach(t),D$t.forEach(t),V8r=i(Ol),T(F4.$$.fragment,Ol),Ol.forEach(t),Gl.forEach(t),mVe=i(f),$c=n(f,"H2",{class:!0});var Tze=s($c);T4=n(Tze,"A",{id:!0,class:!0,href:!0});var V$t=s(T4);UTe=n(V$t,"SPAN",{});var X$t=s(UTe);T(mx.$$.fragment,X$t),X$t.forEach(t),V$t.forEach(t),X8r=i(Tze),JTe=n(Tze,"SPAN",{});var z$t=s(JTe);z8r=r(z$t,"TFAutoModelForTokenClassification"),z$t.forEach(t),Tze.forEach(t),gVe=i(f),cr=n(f,"DIV",{class:!0});var Vl=s(cr);T(gx.$$.fragment,Vl),Q8r=i(Vl),kc=n(Vl,"P",{});var Pre=s(kc);W8r=r(Pre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),PY=n(Pre,"A",{href:!0});var Q$t=s(PY);H8r=r(Q$t,"from_pretrained()"),Q$t.forEach(t),U8r=r(Pre," class method or the "),BY=n(Pre,"A",{href:!0});var W$t=s(BY);J8r=r(W$t,"from_config()"),W$t.forEach(t),Y8r=r(Pre,` class
method.`),Pre.forEach(t),K8r=i(Vl),hx=n(Vl,"P",{});var Mze=s(hx);Z8r=r(Mze,"This class cannot be instantiated directly using "),YTe=n(Mze,"CODE",{});var H$t=s(YTe);e9r=r(H$t,"__init__()"),H$t.forEach(t),o9r=r(Mze," (throws an error)."),Mze.forEach(t),r9r=i(Vl),Dt=n(Vl,"DIV",{class:!0});var W6=s(Dt);T(px.$$.fragment,W6),t9r=i(W6),KTe=n(W6,"P",{});var U$t=s(KTe);a9r=r(U$t,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),U$t.forEach(t),n9r=i(W6),Sc=n(W6,"P",{});var Bre=s(Sc);s9r=r(Bre,`Note:
Loading a model from its configuration file does `),ZTe=n(Bre,"STRONG",{});var J$t=s(ZTe);l9r=r(J$t,"not"),J$t.forEach(t),i9r=r(Bre,` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=n(Bre,"A",{href:!0});var Y$t=s(IY);d9r=r(Y$t,"from_pretrained()"),Y$t.forEach(t),c9r=r(Bre," to load the model weights."),Bre.forEach(t),f9r=i(W6),T(M4.$$.fragment,W6),W6.forEach(t),m9r=i(Vl),qr=n(Vl,"DIV",{class:!0});var Xl=s(qr);T(_x.$$.fragment,Xl),g9r=i(Xl),eMe=n(Xl,"P",{});var K$t=s(eMe);h9r=r(K$t,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),K$t.forEach(t),p9r=i(Xl),_n=n(Xl,"P",{});var H6=s(_n);_9r=r(H6,"The model class to instantiate is selected based on the "),oMe=n(H6,"CODE",{});var Z$t=s(oMe);u9r=r(Z$t,"model_type"),Z$t.forEach(t),b9r=r(H6,` property of the config object (either
passed as an argument or loaded from `),rMe=n(H6,"CODE",{});var ekt=s(rMe);v9r=r(ekt,"pretrained_model_name_or_path"),ekt.forEach(t),F9r=r(H6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tMe=n(H6,"CODE",{});var okt=s(tMe);T9r=r(okt,"pretrained_model_name_or_path"),okt.forEach(t),M9r=r(H6,":"),H6.forEach(t),E9r=i(Xl),de=n(Xl,"UL",{});var me=s(de);E4=n(me,"LI",{});var Uqe=s(E4);aMe=n(Uqe,"STRONG",{});var rkt=s(aMe);C9r=r(rkt,"albert"),rkt.forEach(t),w9r=r(Uqe," \u2014 "),NY=n(Uqe,"A",{href:!0});var tkt=s(NY);A9r=r(tkt,"TFAlbertForTokenClassification"),tkt.forEach(t),L9r=r(Uqe," (ALBERT model)"),Uqe.forEach(t),y9r=i(me),C4=n(me,"LI",{});var Jqe=s(C4);nMe=n(Jqe,"STRONG",{});var akt=s(nMe);x9r=r(akt,"bert"),akt.forEach(t),$9r=r(Jqe," \u2014 "),qY=n(Jqe,"A",{href:!0});var nkt=s(qY);k9r=r(nkt,"TFBertForTokenClassification"),nkt.forEach(t),S9r=r(Jqe," (BERT model)"),Jqe.forEach(t),R9r=i(me),w4=n(me,"LI",{});var Yqe=s(w4);sMe=n(Yqe,"STRONG",{});var skt=s(sMe);P9r=r(skt,"camembert"),skt.forEach(t),B9r=r(Yqe," \u2014 "),jY=n(Yqe,"A",{href:!0});var lkt=s(jY);I9r=r(lkt,"TFCamembertForTokenClassification"),lkt.forEach(t),N9r=r(Yqe," (CamemBERT model)"),Yqe.forEach(t),q9r=i(me),A4=n(me,"LI",{});var Kqe=s(A4);lMe=n(Kqe,"STRONG",{});var ikt=s(lMe);j9r=r(ikt,"convbert"),ikt.forEach(t),D9r=r(Kqe," \u2014 "),DY=n(Kqe,"A",{href:!0});var dkt=s(DY);G9r=r(dkt,"TFConvBertForTokenClassification"),dkt.forEach(t),O9r=r(Kqe," (ConvBERT model)"),Kqe.forEach(t),V9r=i(me),L4=n(me,"LI",{});var Zqe=s(L4);iMe=n(Zqe,"STRONG",{});var ckt=s(iMe);X9r=r(ckt,"deberta"),ckt.forEach(t),z9r=r(Zqe," \u2014 "),GY=n(Zqe,"A",{href:!0});var fkt=s(GY);Q9r=r(fkt,"TFDebertaForTokenClassification"),fkt.forEach(t),W9r=r(Zqe," (DeBERTa model)"),Zqe.forEach(t),H9r=i(me),y4=n(me,"LI",{});var eje=s(y4);dMe=n(eje,"STRONG",{});var mkt=s(dMe);U9r=r(mkt,"deberta-v2"),mkt.forEach(t),J9r=r(eje," \u2014 "),OY=n(eje,"A",{href:!0});var gkt=s(OY);Y9r=r(gkt,"TFDebertaV2ForTokenClassification"),gkt.forEach(t),K9r=r(eje," (DeBERTa-v2 model)"),eje.forEach(t),Z9r=i(me),x4=n(me,"LI",{});var oje=s(x4);cMe=n(oje,"STRONG",{});var hkt=s(cMe);exr=r(hkt,"distilbert"),hkt.forEach(t),oxr=r(oje," \u2014 "),VY=n(oje,"A",{href:!0});var pkt=s(VY);rxr=r(pkt,"TFDistilBertForTokenClassification"),pkt.forEach(t),txr=r(oje," (DistilBERT model)"),oje.forEach(t),axr=i(me),$4=n(me,"LI",{});var rje=s($4);fMe=n(rje,"STRONG",{});var _kt=s(fMe);nxr=r(_kt,"electra"),_kt.forEach(t),sxr=r(rje," \u2014 "),XY=n(rje,"A",{href:!0});var ukt=s(XY);lxr=r(ukt,"TFElectraForTokenClassification"),ukt.forEach(t),ixr=r(rje," (ELECTRA model)"),rje.forEach(t),dxr=i(me),k4=n(me,"LI",{});var tje=s(k4);mMe=n(tje,"STRONG",{});var bkt=s(mMe);cxr=r(bkt,"flaubert"),bkt.forEach(t),fxr=r(tje," \u2014 "),zY=n(tje,"A",{href:!0});var vkt=s(zY);mxr=r(vkt,"TFFlaubertForTokenClassification"),vkt.forEach(t),gxr=r(tje," (FlauBERT model)"),tje.forEach(t),hxr=i(me),S4=n(me,"LI",{});var aje=s(S4);gMe=n(aje,"STRONG",{});var Fkt=s(gMe);pxr=r(Fkt,"funnel"),Fkt.forEach(t),_xr=r(aje," \u2014 "),QY=n(aje,"A",{href:!0});var Tkt=s(QY);uxr=r(Tkt,"TFFunnelForTokenClassification"),Tkt.forEach(t),bxr=r(aje," (Funnel Transformer model)"),aje.forEach(t),vxr=i(me),R4=n(me,"LI",{});var nje=s(R4);hMe=n(nje,"STRONG",{});var Mkt=s(hMe);Fxr=r(Mkt,"layoutlm"),Mkt.forEach(t),Txr=r(nje," \u2014 "),WY=n(nje,"A",{href:!0});var Ekt=s(WY);Mxr=r(Ekt,"TFLayoutLMForTokenClassification"),Ekt.forEach(t),Exr=r(nje," (LayoutLM model)"),nje.forEach(t),Cxr=i(me),P4=n(me,"LI",{});var sje=s(P4);pMe=n(sje,"STRONG",{});var Ckt=s(pMe);wxr=r(Ckt,"longformer"),Ckt.forEach(t),Axr=r(sje," \u2014 "),HY=n(sje,"A",{href:!0});var wkt=s(HY);Lxr=r(wkt,"TFLongformerForTokenClassification"),wkt.forEach(t),yxr=r(sje," (Longformer model)"),sje.forEach(t),xxr=i(me),B4=n(me,"LI",{});var lje=s(B4);_Me=n(lje,"STRONG",{});var Akt=s(_Me);$xr=r(Akt,"mobilebert"),Akt.forEach(t),kxr=r(lje," \u2014 "),UY=n(lje,"A",{href:!0});var Lkt=s(UY);Sxr=r(Lkt,"TFMobileBertForTokenClassification"),Lkt.forEach(t),Rxr=r(lje," (MobileBERT model)"),lje.forEach(t),Pxr=i(me),I4=n(me,"LI",{});var ije=s(I4);uMe=n(ije,"STRONG",{});var ykt=s(uMe);Bxr=r(ykt,"mpnet"),ykt.forEach(t),Ixr=r(ije," \u2014 "),JY=n(ije,"A",{href:!0});var xkt=s(JY);Nxr=r(xkt,"TFMPNetForTokenClassification"),xkt.forEach(t),qxr=r(ije," (MPNet model)"),ije.forEach(t),jxr=i(me),N4=n(me,"LI",{});var dje=s(N4);bMe=n(dje,"STRONG",{});var $kt=s(bMe);Dxr=r($kt,"rembert"),$kt.forEach(t),Gxr=r(dje," \u2014 "),YY=n(dje,"A",{href:!0});var kkt=s(YY);Oxr=r(kkt,"TFRemBertForTokenClassification"),kkt.forEach(t),Vxr=r(dje," (RemBERT model)"),dje.forEach(t),Xxr=i(me),q4=n(me,"LI",{});var cje=s(q4);vMe=n(cje,"STRONG",{});var Skt=s(vMe);zxr=r(Skt,"roberta"),Skt.forEach(t),Qxr=r(cje," \u2014 "),KY=n(cje,"A",{href:!0});var Rkt=s(KY);Wxr=r(Rkt,"TFRobertaForTokenClassification"),Rkt.forEach(t),Hxr=r(cje," (RoBERTa model)"),cje.forEach(t),Uxr=i(me),j4=n(me,"LI",{});var fje=s(j4);FMe=n(fje,"STRONG",{});var Pkt=s(FMe);Jxr=r(Pkt,"roformer"),Pkt.forEach(t),Yxr=r(fje," \u2014 "),ZY=n(fje,"A",{href:!0});var Bkt=s(ZY);Kxr=r(Bkt,"TFRoFormerForTokenClassification"),Bkt.forEach(t),Zxr=r(fje," (RoFormer model)"),fje.forEach(t),e$r=i(me),D4=n(me,"LI",{});var mje=s(D4);TMe=n(mje,"STRONG",{});var Ikt=s(TMe);o$r=r(Ikt,"xlm"),Ikt.forEach(t),r$r=r(mje," \u2014 "),eK=n(mje,"A",{href:!0});var Nkt=s(eK);t$r=r(Nkt,"TFXLMForTokenClassification"),Nkt.forEach(t),a$r=r(mje," (XLM model)"),mje.forEach(t),n$r=i(me),G4=n(me,"LI",{});var gje=s(G4);MMe=n(gje,"STRONG",{});var qkt=s(MMe);s$r=r(qkt,"xlm-roberta"),qkt.forEach(t),l$r=r(gje," \u2014 "),oK=n(gje,"A",{href:!0});var jkt=s(oK);i$r=r(jkt,"TFXLMRobertaForTokenClassification"),jkt.forEach(t),d$r=r(gje," (XLM-RoBERTa model)"),gje.forEach(t),c$r=i(me),O4=n(me,"LI",{});var hje=s(O4);EMe=n(hje,"STRONG",{});var Dkt=s(EMe);f$r=r(Dkt,"xlnet"),Dkt.forEach(t),m$r=r(hje," \u2014 "),rK=n(hje,"A",{href:!0});var Gkt=s(rK);g$r=r(Gkt,"TFXLNetForTokenClassification"),Gkt.forEach(t),h$r=r(hje," (XLNet model)"),hje.forEach(t),me.forEach(t),p$r=i(Xl),T(V4.$$.fragment,Xl),Xl.forEach(t),Vl.forEach(t),hVe=i(f),Rc=n(f,"H2",{class:!0});var Eze=s(Rc);X4=n(Eze,"A",{id:!0,class:!0,href:!0});var Okt=s(X4);CMe=n(Okt,"SPAN",{});var Vkt=s(CMe);T(ux.$$.fragment,Vkt),Vkt.forEach(t),Okt.forEach(t),_$r=i(Eze),wMe=n(Eze,"SPAN",{});var Xkt=s(wMe);u$r=r(Xkt,"TFAutoModelForQuestionAnswering"),Xkt.forEach(t),Eze.forEach(t),pVe=i(f),fr=n(f,"DIV",{class:!0});var zl=s(fr);T(bx.$$.fragment,zl),b$r=i(zl),Pc=n(zl,"P",{});var Ire=s(Pc);v$r=r(Ire,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),tK=n(Ire,"A",{href:!0});var zkt=s(tK);F$r=r(zkt,"from_pretrained()"),zkt.forEach(t),T$r=r(Ire," class method or the "),aK=n(Ire,"A",{href:!0});var Qkt=s(aK);M$r=r(Qkt,"from_config()"),Qkt.forEach(t),E$r=r(Ire,` class
method.`),Ire.forEach(t),C$r=i(zl),vx=n(zl,"P",{});var Cze=s(vx);w$r=r(Cze,"This class cannot be instantiated directly using "),AMe=n(Cze,"CODE",{});var Wkt=s(AMe);A$r=r(Wkt,"__init__()"),Wkt.forEach(t),L$r=r(Cze," (throws an error)."),Cze.forEach(t),y$r=i(zl),Gt=n(zl,"DIV",{class:!0});var U6=s(Gt);T(Fx.$$.fragment,U6),x$r=i(U6),LMe=n(U6,"P",{});var Hkt=s(LMe);$$r=r(Hkt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Hkt.forEach(t),k$r=i(U6),Bc=n(U6,"P",{});var Nre=s(Bc);S$r=r(Nre,`Note:
Loading a model from its configuration file does `),yMe=n(Nre,"STRONG",{});var Ukt=s(yMe);R$r=r(Ukt,"not"),Ukt.forEach(t),P$r=r(Nre,` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=n(Nre,"A",{href:!0});var Jkt=s(nK);B$r=r(Jkt,"from_pretrained()"),Jkt.forEach(t),I$r=r(Nre," to load the model weights."),Nre.forEach(t),N$r=i(U6),T(z4.$$.fragment,U6),U6.forEach(t),q$r=i(zl),jr=n(zl,"DIV",{class:!0});var Ql=s(jr);T(Tx.$$.fragment,Ql),j$r=i(Ql),xMe=n(Ql,"P",{});var Ykt=s(xMe);D$r=r(Ykt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Ykt.forEach(t),G$r=i(Ql),un=n(Ql,"P",{});var J6=s(un);O$r=r(J6,"The model class to instantiate is selected based on the "),$Me=n(J6,"CODE",{});var Kkt=s($Me);V$r=r(Kkt,"model_type"),Kkt.forEach(t),X$r=r(J6,` property of the config object (either
passed as an argument or loaded from `),kMe=n(J6,"CODE",{});var Zkt=s(kMe);z$r=r(Zkt,"pretrained_model_name_or_path"),Zkt.forEach(t),Q$r=r(J6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SMe=n(J6,"CODE",{});var eSt=s(SMe);W$r=r(eSt,"pretrained_model_name_or_path"),eSt.forEach(t),H$r=r(J6,":"),J6.forEach(t),U$r=i(Ql),ce=n(Ql,"UL",{});var ge=s(ce);Q4=n(ge,"LI",{});var pje=s(Q4);RMe=n(pje,"STRONG",{});var oSt=s(RMe);J$r=r(oSt,"albert"),oSt.forEach(t),Y$r=r(pje," \u2014 "),sK=n(pje,"A",{href:!0});var rSt=s(sK);K$r=r(rSt,"TFAlbertForQuestionAnswering"),rSt.forEach(t),Z$r=r(pje," (ALBERT model)"),pje.forEach(t),ekr=i(ge),W4=n(ge,"LI",{});var _je=s(W4);PMe=n(_je,"STRONG",{});var tSt=s(PMe);okr=r(tSt,"bert"),tSt.forEach(t),rkr=r(_je," \u2014 "),lK=n(_je,"A",{href:!0});var aSt=s(lK);tkr=r(aSt,"TFBertForQuestionAnswering"),aSt.forEach(t),akr=r(_je," (BERT model)"),_je.forEach(t),nkr=i(ge),H4=n(ge,"LI",{});var uje=s(H4);BMe=n(uje,"STRONG",{});var nSt=s(BMe);skr=r(nSt,"camembert"),nSt.forEach(t),lkr=r(uje," \u2014 "),iK=n(uje,"A",{href:!0});var sSt=s(iK);ikr=r(sSt,"TFCamembertForQuestionAnswering"),sSt.forEach(t),dkr=r(uje," (CamemBERT model)"),uje.forEach(t),ckr=i(ge),U4=n(ge,"LI",{});var bje=s(U4);IMe=n(bje,"STRONG",{});var lSt=s(IMe);fkr=r(lSt,"convbert"),lSt.forEach(t),mkr=r(bje," \u2014 "),dK=n(bje,"A",{href:!0});var iSt=s(dK);gkr=r(iSt,"TFConvBertForQuestionAnswering"),iSt.forEach(t),hkr=r(bje," (ConvBERT model)"),bje.forEach(t),pkr=i(ge),J4=n(ge,"LI",{});var vje=s(J4);NMe=n(vje,"STRONG",{});var dSt=s(NMe);_kr=r(dSt,"deberta"),dSt.forEach(t),ukr=r(vje," \u2014 "),cK=n(vje,"A",{href:!0});var cSt=s(cK);bkr=r(cSt,"TFDebertaForQuestionAnswering"),cSt.forEach(t),vkr=r(vje," (DeBERTa model)"),vje.forEach(t),Fkr=i(ge),Y4=n(ge,"LI",{});var Fje=s(Y4);qMe=n(Fje,"STRONG",{});var fSt=s(qMe);Tkr=r(fSt,"deberta-v2"),fSt.forEach(t),Mkr=r(Fje," \u2014 "),fK=n(Fje,"A",{href:!0});var mSt=s(fK);Ekr=r(mSt,"TFDebertaV2ForQuestionAnswering"),mSt.forEach(t),Ckr=r(Fje," (DeBERTa-v2 model)"),Fje.forEach(t),wkr=i(ge),K4=n(ge,"LI",{});var Tje=s(K4);jMe=n(Tje,"STRONG",{});var gSt=s(jMe);Akr=r(gSt,"distilbert"),gSt.forEach(t),Lkr=r(Tje," \u2014 "),mK=n(Tje,"A",{href:!0});var hSt=s(mK);ykr=r(hSt,"TFDistilBertForQuestionAnswering"),hSt.forEach(t),xkr=r(Tje," (DistilBERT model)"),Tje.forEach(t),$kr=i(ge),Z4=n(ge,"LI",{});var Mje=s(Z4);DMe=n(Mje,"STRONG",{});var pSt=s(DMe);kkr=r(pSt,"electra"),pSt.forEach(t),Skr=r(Mje," \u2014 "),gK=n(Mje,"A",{href:!0});var _St=s(gK);Rkr=r(_St,"TFElectraForQuestionAnswering"),_St.forEach(t),Pkr=r(Mje," (ELECTRA model)"),Mje.forEach(t),Bkr=i(ge),eC=n(ge,"LI",{});var Eje=s(eC);GMe=n(Eje,"STRONG",{});var uSt=s(GMe);Ikr=r(uSt,"flaubert"),uSt.forEach(t),Nkr=r(Eje," \u2014 "),hK=n(Eje,"A",{href:!0});var bSt=s(hK);qkr=r(bSt,"TFFlaubertForQuestionAnsweringSimple"),bSt.forEach(t),jkr=r(Eje," (FlauBERT model)"),Eje.forEach(t),Dkr=i(ge),oC=n(ge,"LI",{});var Cje=s(oC);OMe=n(Cje,"STRONG",{});var vSt=s(OMe);Gkr=r(vSt,"funnel"),vSt.forEach(t),Okr=r(Cje," \u2014 "),pK=n(Cje,"A",{href:!0});var FSt=s(pK);Vkr=r(FSt,"TFFunnelForQuestionAnswering"),FSt.forEach(t),Xkr=r(Cje," (Funnel Transformer model)"),Cje.forEach(t),zkr=i(ge),rC=n(ge,"LI",{});var wje=s(rC);VMe=n(wje,"STRONG",{});var TSt=s(VMe);Qkr=r(TSt,"gptj"),TSt.forEach(t),Wkr=r(wje," \u2014 "),_K=n(wje,"A",{href:!0});var MSt=s(_K);Hkr=r(MSt,"TFGPTJForQuestionAnswering"),MSt.forEach(t),Ukr=r(wje," (GPT-J model)"),wje.forEach(t),Jkr=i(ge),tC=n(ge,"LI",{});var Aje=s(tC);XMe=n(Aje,"STRONG",{});var ESt=s(XMe);Ykr=r(ESt,"longformer"),ESt.forEach(t),Kkr=r(Aje," \u2014 "),uK=n(Aje,"A",{href:!0});var CSt=s(uK);Zkr=r(CSt,"TFLongformerForQuestionAnswering"),CSt.forEach(t),eSr=r(Aje," (Longformer model)"),Aje.forEach(t),oSr=i(ge),aC=n(ge,"LI",{});var Lje=s(aC);zMe=n(Lje,"STRONG",{});var wSt=s(zMe);rSr=r(wSt,"mobilebert"),wSt.forEach(t),tSr=r(Lje," \u2014 "),bK=n(Lje,"A",{href:!0});var ASt=s(bK);aSr=r(ASt,"TFMobileBertForQuestionAnswering"),ASt.forEach(t),nSr=r(Lje," (MobileBERT model)"),Lje.forEach(t),sSr=i(ge),nC=n(ge,"LI",{});var yje=s(nC);QMe=n(yje,"STRONG",{});var LSt=s(QMe);lSr=r(LSt,"mpnet"),LSt.forEach(t),iSr=r(yje," \u2014 "),vK=n(yje,"A",{href:!0});var ySt=s(vK);dSr=r(ySt,"TFMPNetForQuestionAnswering"),ySt.forEach(t),cSr=r(yje," (MPNet model)"),yje.forEach(t),fSr=i(ge),sC=n(ge,"LI",{});var xje=s(sC);WMe=n(xje,"STRONG",{});var xSt=s(WMe);mSr=r(xSt,"rembert"),xSt.forEach(t),gSr=r(xje," \u2014 "),FK=n(xje,"A",{href:!0});var $St=s(FK);hSr=r($St,"TFRemBertForQuestionAnswering"),$St.forEach(t),pSr=r(xje," (RemBERT model)"),xje.forEach(t),_Sr=i(ge),lC=n(ge,"LI",{});var $je=s(lC);HMe=n($je,"STRONG",{});var kSt=s(HMe);uSr=r(kSt,"roberta"),kSt.forEach(t),bSr=r($je," \u2014 "),TK=n($je,"A",{href:!0});var SSt=s(TK);vSr=r(SSt,"TFRobertaForQuestionAnswering"),SSt.forEach(t),FSr=r($je," (RoBERTa model)"),$je.forEach(t),TSr=i(ge),iC=n(ge,"LI",{});var kje=s(iC);UMe=n(kje,"STRONG",{});var RSt=s(UMe);MSr=r(RSt,"roformer"),RSt.forEach(t),ESr=r(kje," \u2014 "),MK=n(kje,"A",{href:!0});var PSt=s(MK);CSr=r(PSt,"TFRoFormerForQuestionAnswering"),PSt.forEach(t),wSr=r(kje," (RoFormer model)"),kje.forEach(t),ASr=i(ge),dC=n(ge,"LI",{});var Sje=s(dC);JMe=n(Sje,"STRONG",{});var BSt=s(JMe);LSr=r(BSt,"xlm"),BSt.forEach(t),ySr=r(Sje," \u2014 "),EK=n(Sje,"A",{href:!0});var ISt=s(EK);xSr=r(ISt,"TFXLMForQuestionAnsweringSimple"),ISt.forEach(t),$Sr=r(Sje," (XLM model)"),Sje.forEach(t),kSr=i(ge),cC=n(ge,"LI",{});var Rje=s(cC);YMe=n(Rje,"STRONG",{});var NSt=s(YMe);SSr=r(NSt,"xlm-roberta"),NSt.forEach(t),RSr=r(Rje," \u2014 "),CK=n(Rje,"A",{href:!0});var qSt=s(CK);PSr=r(qSt,"TFXLMRobertaForQuestionAnswering"),qSt.forEach(t),BSr=r(Rje," (XLM-RoBERTa model)"),Rje.forEach(t),ISr=i(ge),fC=n(ge,"LI",{});var Pje=s(fC);KMe=n(Pje,"STRONG",{});var jSt=s(KMe);NSr=r(jSt,"xlnet"),jSt.forEach(t),qSr=r(Pje," \u2014 "),wK=n(Pje,"A",{href:!0});var DSt=s(wK);jSr=r(DSt,"TFXLNetForQuestionAnsweringSimple"),DSt.forEach(t),DSr=r(Pje," (XLNet model)"),Pje.forEach(t),ge.forEach(t),GSr=i(Ql),T(mC.$$.fragment,Ql),Ql.forEach(t),zl.forEach(t),_Ve=i(f),Ic=n(f,"H2",{class:!0});var wze=s(Ic);gC=n(wze,"A",{id:!0,class:!0,href:!0});var GSt=s(gC);ZMe=n(GSt,"SPAN",{});var OSt=s(ZMe);T(Mx.$$.fragment,OSt),OSt.forEach(t),GSt.forEach(t),OSr=i(wze),eEe=n(wze,"SPAN",{});var VSt=s(eEe);VSr=r(VSt,"TFAutoModelForVision2Seq"),VSt.forEach(t),wze.forEach(t),uVe=i(f),mr=n(f,"DIV",{class:!0});var Wl=s(mr);T(Ex.$$.fragment,Wl),XSr=i(Wl),Nc=n(Wl,"P",{});var qre=s(Nc);zSr=r(qre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),AK=n(qre,"A",{href:!0});var XSt=s(AK);QSr=r(XSt,"from_pretrained()"),XSt.forEach(t),WSr=r(qre," class method or the "),LK=n(qre,"A",{href:!0});var zSt=s(LK);HSr=r(zSt,"from_config()"),zSt.forEach(t),USr=r(qre,` class
method.`),qre.forEach(t),JSr=i(Wl),Cx=n(Wl,"P",{});var Aze=s(Cx);YSr=r(Aze,"This class cannot be instantiated directly using "),oEe=n(Aze,"CODE",{});var QSt=s(oEe);KSr=r(QSt,"__init__()"),QSt.forEach(t),ZSr=r(Aze," (throws an error)."),Aze.forEach(t),eRr=i(Wl),Ot=n(Wl,"DIV",{class:!0});var Y6=s(Ot);T(wx.$$.fragment,Y6),oRr=i(Y6),rEe=n(Y6,"P",{});var WSt=s(rEe);rRr=r(WSt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),WSt.forEach(t),tRr=i(Y6),qc=n(Y6,"P",{});var jre=s(qc);aRr=r(jre,`Note:
Loading a model from its configuration file does `),tEe=n(jre,"STRONG",{});var HSt=s(tEe);nRr=r(HSt,"not"),HSt.forEach(t),sRr=r(jre,` load the model weights. It only affects the
model\u2019s configuration. Use `),yK=n(jre,"A",{href:!0});var USt=s(yK);lRr=r(USt,"from_pretrained()"),USt.forEach(t),iRr=r(jre," to load the model weights."),jre.forEach(t),dRr=i(Y6),T(hC.$$.fragment,Y6),Y6.forEach(t),cRr=i(Wl),Dr=n(Wl,"DIV",{class:!0});var Hl=s(Dr);T(Ax.$$.fragment,Hl),fRr=i(Hl),aEe=n(Hl,"P",{});var JSt=s(aEe);mRr=r(JSt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),JSt.forEach(t),gRr=i(Hl),bn=n(Hl,"P",{});var K6=s(bn);hRr=r(K6,"The model class to instantiate is selected based on the "),nEe=n(K6,"CODE",{});var YSt=s(nEe);pRr=r(YSt,"model_type"),YSt.forEach(t),_Rr=r(K6,` property of the config object (either
passed as an argument or loaded from `),sEe=n(K6,"CODE",{});var KSt=s(sEe);uRr=r(KSt,"pretrained_model_name_or_path"),KSt.forEach(t),bRr=r(K6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lEe=n(K6,"CODE",{});var ZSt=s(lEe);vRr=r(ZSt,"pretrained_model_name_or_path"),ZSt.forEach(t),FRr=r(K6,":"),K6.forEach(t),TRr=i(Hl),iEe=n(Hl,"UL",{});var eRt=s(iEe);pC=n(eRt,"LI",{});var Bje=s(pC);dEe=n(Bje,"STRONG",{});var oRt=s(dEe);MRr=r(oRt,"vision-encoder-decoder"),oRt.forEach(t),ERr=r(Bje," \u2014 "),xK=n(Bje,"A",{href:!0});var rRt=s(xK);CRr=r(rRt,"TFVisionEncoderDecoderModel"),rRt.forEach(t),wRr=r(Bje," (Vision Encoder decoder model)"),Bje.forEach(t),eRt.forEach(t),ARr=i(Hl),T(_C.$$.fragment,Hl),Hl.forEach(t),Wl.forEach(t),bVe=i(f),jc=n(f,"H2",{class:!0});var Lze=s(jc);uC=n(Lze,"A",{id:!0,class:!0,href:!0});var tRt=s(uC);cEe=n(tRt,"SPAN",{});var aRt=s(cEe);T(Lx.$$.fragment,aRt),aRt.forEach(t),tRt.forEach(t),LRr=i(Lze),fEe=n(Lze,"SPAN",{});var nRt=s(fEe);yRr=r(nRt,"TFAutoModelForSpeechSeq2Seq"),nRt.forEach(t),Lze.forEach(t),vVe=i(f),gr=n(f,"DIV",{class:!0});var Ul=s(gr);T(yx.$$.fragment,Ul),xRr=i(Ul),Dc=n(Ul,"P",{});var Dre=s(Dc);$Rr=r(Dre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),$K=n(Dre,"A",{href:!0});var sRt=s($K);kRr=r(sRt,"from_pretrained()"),sRt.forEach(t),SRr=r(Dre," class method or the "),kK=n(Dre,"A",{href:!0});var lRt=s(kK);RRr=r(lRt,"from_config()"),lRt.forEach(t),PRr=r(Dre,` class
method.`),Dre.forEach(t),BRr=i(Ul),xx=n(Ul,"P",{});var yze=s(xx);IRr=r(yze,"This class cannot be instantiated directly using "),mEe=n(yze,"CODE",{});var iRt=s(mEe);NRr=r(iRt,"__init__()"),iRt.forEach(t),qRr=r(yze," (throws an error)."),yze.forEach(t),jRr=i(Ul),Vt=n(Ul,"DIV",{class:!0});var Z6=s(Vt);T($x.$$.fragment,Z6),DRr=i(Z6),gEe=n(Z6,"P",{});var dRt=s(gEe);GRr=r(dRt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),dRt.forEach(t),ORr=i(Z6),Gc=n(Z6,"P",{});var Gre=s(Gc);VRr=r(Gre,`Note:
Loading a model from its configuration file does `),hEe=n(Gre,"STRONG",{});var cRt=s(hEe);XRr=r(cRt,"not"),cRt.forEach(t),zRr=r(Gre,` load the model weights. It only affects the
model\u2019s configuration. Use `),SK=n(Gre,"A",{href:!0});var fRt=s(SK);QRr=r(fRt,"from_pretrained()"),fRt.forEach(t),WRr=r(Gre," to load the model weights."),Gre.forEach(t),HRr=i(Z6),T(bC.$$.fragment,Z6),Z6.forEach(t),URr=i(Ul),Gr=n(Ul,"DIV",{class:!0});var Jl=s(Gr);T(kx.$$.fragment,Jl),JRr=i(Jl),pEe=n(Jl,"P",{});var mRt=s(pEe);YRr=r(mRt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),mRt.forEach(t),KRr=i(Jl),vn=n(Jl,"P",{});var eL=s(vn);ZRr=r(eL,"The model class to instantiate is selected based on the "),_Ee=n(eL,"CODE",{});var gRt=s(_Ee);ePr=r(gRt,"model_type"),gRt.forEach(t),oPr=r(eL,` property of the config object (either
passed as an argument or loaded from `),uEe=n(eL,"CODE",{});var hRt=s(uEe);rPr=r(hRt,"pretrained_model_name_or_path"),hRt.forEach(t),tPr=r(eL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bEe=n(eL,"CODE",{});var pRt=s(bEe);aPr=r(pRt,"pretrained_model_name_or_path"),pRt.forEach(t),nPr=r(eL,":"),eL.forEach(t),sPr=i(Jl),vEe=n(Jl,"UL",{});var _Rt=s(vEe);vC=n(_Rt,"LI",{});var Ije=s(vC);FEe=n(Ije,"STRONG",{});var uRt=s(FEe);lPr=r(uRt,"speech_to_text"),uRt.forEach(t),iPr=r(Ije," \u2014 "),RK=n(Ije,"A",{href:!0});var bRt=s(RK);dPr=r(bRt,"TFSpeech2TextForConditionalGeneration"),bRt.forEach(t),cPr=r(Ije," (Speech2Text model)"),Ije.forEach(t),_Rt.forEach(t),fPr=i(Jl),T(FC.$$.fragment,Jl),Jl.forEach(t),Ul.forEach(t),FVe=i(f),Oc=n(f,"H2",{class:!0});var xze=s(Oc);TC=n(xze,"A",{id:!0,class:!0,href:!0});var vRt=s(TC);TEe=n(vRt,"SPAN",{});var FRt=s(TEe);T(Sx.$$.fragment,FRt),FRt.forEach(t),vRt.forEach(t),mPr=i(xze),MEe=n(xze,"SPAN",{});var TRt=s(MEe);gPr=r(TRt,"FlaxAutoModel"),TRt.forEach(t),xze.forEach(t),TVe=i(f),hr=n(f,"DIV",{class:!0});var Yl=s(hr);T(Rx.$$.fragment,Yl),hPr=i(Yl),Vc=n(Yl,"P",{});var Ore=s(Vc);pPr=r(Ore,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),PK=n(Ore,"A",{href:!0});var MRt=s(PK);_Pr=r(MRt,"from_pretrained()"),MRt.forEach(t),uPr=r(Ore," class method or the "),BK=n(Ore,"A",{href:!0});var ERt=s(BK);bPr=r(ERt,"from_config()"),ERt.forEach(t),vPr=r(Ore,` class
method.`),Ore.forEach(t),FPr=i(Yl),Px=n(Yl,"P",{});var $ze=s(Px);TPr=r($ze,"This class cannot be instantiated directly using "),EEe=n($ze,"CODE",{});var CRt=s(EEe);MPr=r(CRt,"__init__()"),CRt.forEach(t),EPr=r($ze," (throws an error)."),$ze.forEach(t),CPr=i(Yl),Xt=n(Yl,"DIV",{class:!0});var oL=s(Xt);T(Bx.$$.fragment,oL),wPr=i(oL),CEe=n(oL,"P",{});var wRt=s(CEe);APr=r(wRt,"Instantiates one of the base model classes of the library from a configuration."),wRt.forEach(t),LPr=i(oL),Xc=n(oL,"P",{});var Vre=s(Xc);yPr=r(Vre,`Note:
Loading a model from its configuration file does `),wEe=n(Vre,"STRONG",{});var ARt=s(wEe);xPr=r(ARt,"not"),ARt.forEach(t),$Pr=r(Vre,` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=n(Vre,"A",{href:!0});var LRt=s(IK);kPr=r(LRt,"from_pretrained()"),LRt.forEach(t),SPr=r(Vre," to load the model weights."),Vre.forEach(t),RPr=i(oL),T(MC.$$.fragment,oL),oL.forEach(t),PPr=i(Yl),Or=n(Yl,"DIV",{class:!0});var Kl=s(Or);T(Ix.$$.fragment,Kl),BPr=i(Kl),AEe=n(Kl,"P",{});var yRt=s(AEe);IPr=r(yRt,"Instantiate one of the base model classes of the library from a pretrained model."),yRt.forEach(t),NPr=i(Kl),Fn=n(Kl,"P",{});var rL=s(Fn);qPr=r(rL,"The model class to instantiate is selected based on the "),LEe=n(rL,"CODE",{});var xRt=s(LEe);jPr=r(xRt,"model_type"),xRt.forEach(t),DPr=r(rL,` property of the config object (either
passed as an argument or loaded from `),yEe=n(rL,"CODE",{});var $Rt=s(yEe);GPr=r($Rt,"pretrained_model_name_or_path"),$Rt.forEach(t),OPr=r(rL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xEe=n(rL,"CODE",{});var kRt=s(xEe);VPr=r(kRt,"pretrained_model_name_or_path"),kRt.forEach(t),XPr=r(rL,":"),rL.forEach(t),zPr=i(Kl),oe=n(Kl,"UL",{});var ae=s(oe);EC=n(ae,"LI",{});var Nje=s(EC);$Ee=n(Nje,"STRONG",{});var SRt=s($Ee);QPr=r(SRt,"albert"),SRt.forEach(t),WPr=r(Nje," \u2014 "),NK=n(Nje,"A",{href:!0});var RRt=s(NK);HPr=r(RRt,"FlaxAlbertModel"),RRt.forEach(t),UPr=r(Nje," (ALBERT model)"),Nje.forEach(t),JPr=i(ae),CC=n(ae,"LI",{});var qje=s(CC);kEe=n(qje,"STRONG",{});var PRt=s(kEe);YPr=r(PRt,"bart"),PRt.forEach(t),KPr=r(qje," \u2014 "),qK=n(qje,"A",{href:!0});var BRt=s(qK);ZPr=r(BRt,"FlaxBartModel"),BRt.forEach(t),eBr=r(qje," (BART model)"),qje.forEach(t),oBr=i(ae),wC=n(ae,"LI",{});var jje=s(wC);SEe=n(jje,"STRONG",{});var IRt=s(SEe);rBr=r(IRt,"beit"),IRt.forEach(t),tBr=r(jje," \u2014 "),jK=n(jje,"A",{href:!0});var NRt=s(jK);aBr=r(NRt,"FlaxBeitModel"),NRt.forEach(t),nBr=r(jje," (BEiT model)"),jje.forEach(t),sBr=i(ae),AC=n(ae,"LI",{});var Dje=s(AC);REe=n(Dje,"STRONG",{});var qRt=s(REe);lBr=r(qRt,"bert"),qRt.forEach(t),iBr=r(Dje," \u2014 "),DK=n(Dje,"A",{href:!0});var jRt=s(DK);dBr=r(jRt,"FlaxBertModel"),jRt.forEach(t),cBr=r(Dje," (BERT model)"),Dje.forEach(t),fBr=i(ae),LC=n(ae,"LI",{});var Gje=s(LC);PEe=n(Gje,"STRONG",{});var DRt=s(PEe);mBr=r(DRt,"big_bird"),DRt.forEach(t),gBr=r(Gje," \u2014 "),GK=n(Gje,"A",{href:!0});var GRt=s(GK);hBr=r(GRt,"FlaxBigBirdModel"),GRt.forEach(t),pBr=r(Gje," (BigBird model)"),Gje.forEach(t),_Br=i(ae),yC=n(ae,"LI",{});var Oje=s(yC);BEe=n(Oje,"STRONG",{});var ORt=s(BEe);uBr=r(ORt,"blenderbot"),ORt.forEach(t),bBr=r(Oje," \u2014 "),OK=n(Oje,"A",{href:!0});var VRt=s(OK);vBr=r(VRt,"FlaxBlenderbotModel"),VRt.forEach(t),FBr=r(Oje," (Blenderbot model)"),Oje.forEach(t),TBr=i(ae),xC=n(ae,"LI",{});var Vje=s(xC);IEe=n(Vje,"STRONG",{});var XRt=s(IEe);MBr=r(XRt,"blenderbot-small"),XRt.forEach(t),EBr=r(Vje," \u2014 "),VK=n(Vje,"A",{href:!0});var zRt=s(VK);CBr=r(zRt,"FlaxBlenderbotSmallModel"),zRt.forEach(t),wBr=r(Vje," (BlenderbotSmall model)"),Vje.forEach(t),ABr=i(ae),$C=n(ae,"LI",{});var Xje=s($C);NEe=n(Xje,"STRONG",{});var QRt=s(NEe);LBr=r(QRt,"clip"),QRt.forEach(t),yBr=r(Xje," \u2014 "),XK=n(Xje,"A",{href:!0});var WRt=s(XK);xBr=r(WRt,"FlaxCLIPModel"),WRt.forEach(t),$Br=r(Xje," (CLIP model)"),Xje.forEach(t),kBr=i(ae),kC=n(ae,"LI",{});var zje=s(kC);qEe=n(zje,"STRONG",{});var HRt=s(qEe);SBr=r(HRt,"distilbert"),HRt.forEach(t),RBr=r(zje," \u2014 "),zK=n(zje,"A",{href:!0});var URt=s(zK);PBr=r(URt,"FlaxDistilBertModel"),URt.forEach(t),BBr=r(zje," (DistilBERT model)"),zje.forEach(t),IBr=i(ae),SC=n(ae,"LI",{});var Qje=s(SC);jEe=n(Qje,"STRONG",{});var JRt=s(jEe);NBr=r(JRt,"electra"),JRt.forEach(t),qBr=r(Qje," \u2014 "),QK=n(Qje,"A",{href:!0});var YRt=s(QK);jBr=r(YRt,"FlaxElectraModel"),YRt.forEach(t),DBr=r(Qje," (ELECTRA model)"),Qje.forEach(t),GBr=i(ae),RC=n(ae,"LI",{});var Wje=s(RC);DEe=n(Wje,"STRONG",{});var KRt=s(DEe);OBr=r(KRt,"gpt2"),KRt.forEach(t),VBr=r(Wje," \u2014 "),WK=n(Wje,"A",{href:!0});var ZRt=s(WK);XBr=r(ZRt,"FlaxGPT2Model"),ZRt.forEach(t),zBr=r(Wje," (OpenAI GPT-2 model)"),Wje.forEach(t),QBr=i(ae),PC=n(ae,"LI",{});var Hje=s(PC);GEe=n(Hje,"STRONG",{});var ePt=s(GEe);WBr=r(ePt,"gpt_neo"),ePt.forEach(t),HBr=r(Hje," \u2014 "),HK=n(Hje,"A",{href:!0});var oPt=s(HK);UBr=r(oPt,"FlaxGPTNeoModel"),oPt.forEach(t),JBr=r(Hje," (GPT Neo model)"),Hje.forEach(t),YBr=i(ae),BC=n(ae,"LI",{});var Uje=s(BC);OEe=n(Uje,"STRONG",{});var rPt=s(OEe);KBr=r(rPt,"gptj"),rPt.forEach(t),ZBr=r(Uje," \u2014 "),UK=n(Uje,"A",{href:!0});var tPt=s(UK);eIr=r(tPt,"FlaxGPTJModel"),tPt.forEach(t),oIr=r(Uje," (GPT-J model)"),Uje.forEach(t),rIr=i(ae),IC=n(ae,"LI",{});var Jje=s(IC);VEe=n(Jje,"STRONG",{});var aPt=s(VEe);tIr=r(aPt,"longt5"),aPt.forEach(t),aIr=r(Jje," \u2014 "),JK=n(Jje,"A",{href:!0});var nPt=s(JK);nIr=r(nPt,"FlaxLongT5Model"),nPt.forEach(t),sIr=r(Jje," (LongT5 model)"),Jje.forEach(t),lIr=i(ae),NC=n(ae,"LI",{});var Yje=s(NC);XEe=n(Yje,"STRONG",{});var sPt=s(XEe);iIr=r(sPt,"marian"),sPt.forEach(t),dIr=r(Yje," \u2014 "),YK=n(Yje,"A",{href:!0});var lPt=s(YK);cIr=r(lPt,"FlaxMarianModel"),lPt.forEach(t),fIr=r(Yje," (Marian model)"),Yje.forEach(t),mIr=i(ae),qC=n(ae,"LI",{});var Kje=s(qC);zEe=n(Kje,"STRONG",{});var iPt=s(zEe);gIr=r(iPt,"mbart"),iPt.forEach(t),hIr=r(Kje," \u2014 "),KK=n(Kje,"A",{href:!0});var dPt=s(KK);pIr=r(dPt,"FlaxMBartModel"),dPt.forEach(t),_Ir=r(Kje," (mBART model)"),Kje.forEach(t),uIr=i(ae),jC=n(ae,"LI",{});var Zje=s(jC);QEe=n(Zje,"STRONG",{});var cPt=s(QEe);bIr=r(cPt,"mt5"),cPt.forEach(t),vIr=r(Zje," \u2014 "),ZK=n(Zje,"A",{href:!0});var fPt=s(ZK);FIr=r(fPt,"FlaxMT5Model"),fPt.forEach(t),TIr=r(Zje," (MT5 model)"),Zje.forEach(t),MIr=i(ae),DC=n(ae,"LI",{});var eDe=s(DC);WEe=n(eDe,"STRONG",{});var mPt=s(WEe);EIr=r(mPt,"opt"),mPt.forEach(t),CIr=r(eDe," \u2014 "),eZ=n(eDe,"A",{href:!0});var gPt=s(eZ);wIr=r(gPt,"FlaxOPTModel"),gPt.forEach(t),AIr=r(eDe," (OPT model)"),eDe.forEach(t),LIr=i(ae),GC=n(ae,"LI",{});var oDe=s(GC);HEe=n(oDe,"STRONG",{});var hPt=s(HEe);yIr=r(hPt,"pegasus"),hPt.forEach(t),xIr=r(oDe," \u2014 "),oZ=n(oDe,"A",{href:!0});var pPt=s(oZ);$Ir=r(pPt,"FlaxPegasusModel"),pPt.forEach(t),kIr=r(oDe," (Pegasus model)"),oDe.forEach(t),SIr=i(ae),OC=n(ae,"LI",{});var rDe=s(OC);UEe=n(rDe,"STRONG",{});var _Pt=s(UEe);RIr=r(_Pt,"roberta"),_Pt.forEach(t),PIr=r(rDe," \u2014 "),rZ=n(rDe,"A",{href:!0});var uPt=s(rZ);BIr=r(uPt,"FlaxRobertaModel"),uPt.forEach(t),IIr=r(rDe," (RoBERTa model)"),rDe.forEach(t),NIr=i(ae),VC=n(ae,"LI",{});var tDe=s(VC);JEe=n(tDe,"STRONG",{});var bPt=s(JEe);qIr=r(bPt,"roformer"),bPt.forEach(t),jIr=r(tDe," \u2014 "),tZ=n(tDe,"A",{href:!0});var vPt=s(tZ);DIr=r(vPt,"FlaxRoFormerModel"),vPt.forEach(t),GIr=r(tDe," (RoFormer model)"),tDe.forEach(t),OIr=i(ae),XC=n(ae,"LI",{});var aDe=s(XC);YEe=n(aDe,"STRONG",{});var FPt=s(YEe);VIr=r(FPt,"t5"),FPt.forEach(t),XIr=r(aDe," \u2014 "),aZ=n(aDe,"A",{href:!0});var TPt=s(aZ);zIr=r(TPt,"FlaxT5Model"),TPt.forEach(t),QIr=r(aDe," (T5 model)"),aDe.forEach(t),WIr=i(ae),zC=n(ae,"LI",{});var nDe=s(zC);KEe=n(nDe,"STRONG",{});var MPt=s(KEe);HIr=r(MPt,"vision-text-dual-encoder"),MPt.forEach(t),UIr=r(nDe," \u2014 "),nZ=n(nDe,"A",{href:!0});var EPt=s(nZ);JIr=r(EPt,"FlaxVisionTextDualEncoderModel"),EPt.forEach(t),YIr=r(nDe," (VisionTextDualEncoder model)"),nDe.forEach(t),KIr=i(ae),QC=n(ae,"LI",{});var sDe=s(QC);ZEe=n(sDe,"STRONG",{});var CPt=s(ZEe);ZIr=r(CPt,"vit"),CPt.forEach(t),eNr=r(sDe," \u2014 "),sZ=n(sDe,"A",{href:!0});var wPt=s(sZ);oNr=r(wPt,"FlaxViTModel"),wPt.forEach(t),rNr=r(sDe," (ViT model)"),sDe.forEach(t),tNr=i(ae),WC=n(ae,"LI",{});var lDe=s(WC);e4e=n(lDe,"STRONG",{});var APt=s(e4e);aNr=r(APt,"wav2vec2"),APt.forEach(t),nNr=r(lDe," \u2014 "),lZ=n(lDe,"A",{href:!0});var LPt=s(lZ);sNr=r(LPt,"FlaxWav2Vec2Model"),LPt.forEach(t),lNr=r(lDe," (Wav2Vec2 model)"),lDe.forEach(t),iNr=i(ae),HC=n(ae,"LI",{});var iDe=s(HC);o4e=n(iDe,"STRONG",{});var yPt=s(o4e);dNr=r(yPt,"xglm"),yPt.forEach(t),cNr=r(iDe," \u2014 "),iZ=n(iDe,"A",{href:!0});var xPt=s(iZ);fNr=r(xPt,"FlaxXGLMModel"),xPt.forEach(t),mNr=r(iDe," (XGLM model)"),iDe.forEach(t),gNr=i(ae),UC=n(ae,"LI",{});var dDe=s(UC);r4e=n(dDe,"STRONG",{});var $Pt=s(r4e);hNr=r($Pt,"xlm-roberta"),$Pt.forEach(t),pNr=r(dDe," \u2014 "),dZ=n(dDe,"A",{href:!0});var kPt=s(dZ);_Nr=r(kPt,"FlaxXLMRobertaModel"),kPt.forEach(t),uNr=r(dDe," (XLM-RoBERTa model)"),dDe.forEach(t),ae.forEach(t),bNr=i(Kl),T(JC.$$.fragment,Kl),Kl.forEach(t),Yl.forEach(t),MVe=i(f),zc=n(f,"H2",{class:!0});var kze=s(zc);YC=n(kze,"A",{id:!0,class:!0,href:!0});var SPt=s(YC);t4e=n(SPt,"SPAN",{});var RPt=s(t4e);T(Nx.$$.fragment,RPt),RPt.forEach(t),SPt.forEach(t),vNr=i(kze),a4e=n(kze,"SPAN",{});var PPt=s(a4e);FNr=r(PPt,"FlaxAutoModelForCausalLM"),PPt.forEach(t),kze.forEach(t),EVe=i(f),pr=n(f,"DIV",{class:!0});var Zl=s(pr);T(qx.$$.fragment,Zl),TNr=i(Zl),Qc=n(Zl,"P",{});var Xre=s(Qc);MNr=r(Xre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),cZ=n(Xre,"A",{href:!0});var BPt=s(cZ);ENr=r(BPt,"from_pretrained()"),BPt.forEach(t),CNr=r(Xre," class method or the "),fZ=n(Xre,"A",{href:!0});var IPt=s(fZ);wNr=r(IPt,"from_config()"),IPt.forEach(t),ANr=r(Xre,` class
method.`),Xre.forEach(t),LNr=i(Zl),jx=n(Zl,"P",{});var Sze=s(jx);yNr=r(Sze,"This class cannot be instantiated directly using "),n4e=n(Sze,"CODE",{});var NPt=s(n4e);xNr=r(NPt,"__init__()"),NPt.forEach(t),$Nr=r(Sze," (throws an error)."),Sze.forEach(t),kNr=i(Zl),zt=n(Zl,"DIV",{class:!0});var tL=s(zt);T(Dx.$$.fragment,tL),SNr=i(tL),s4e=n(tL,"P",{});var qPt=s(s4e);RNr=r(qPt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),qPt.forEach(t),PNr=i(tL),Wc=n(tL,"P",{});var zre=s(Wc);BNr=r(zre,`Note:
Loading a model from its configuration file does `),l4e=n(zre,"STRONG",{});var jPt=s(l4e);INr=r(jPt,"not"),jPt.forEach(t),NNr=r(zre,` load the model weights. It only affects the
model\u2019s configuration. Use `),mZ=n(zre,"A",{href:!0});var DPt=s(mZ);qNr=r(DPt,"from_pretrained()"),DPt.forEach(t),jNr=r(zre," to load the model weights."),zre.forEach(t),DNr=i(tL),T(KC.$$.fragment,tL),tL.forEach(t),GNr=i(Zl),Vr=n(Zl,"DIV",{class:!0});var ei=s(Vr);T(Gx.$$.fragment,ei),ONr=i(ei),i4e=n(ei,"P",{});var GPt=s(i4e);VNr=r(GPt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),GPt.forEach(t),XNr=i(ei),Tn=n(ei,"P",{});var aL=s(Tn);zNr=r(aL,"The model class to instantiate is selected based on the "),d4e=n(aL,"CODE",{});var OPt=s(d4e);QNr=r(OPt,"model_type"),OPt.forEach(t),WNr=r(aL,` property of the config object (either
passed as an argument or loaded from `),c4e=n(aL,"CODE",{});var VPt=s(c4e);HNr=r(VPt,"pretrained_model_name_or_path"),VPt.forEach(t),UNr=r(aL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f4e=n(aL,"CODE",{});var XPt=s(f4e);JNr=r(XPt,"pretrained_model_name_or_path"),XPt.forEach(t),YNr=r(aL,":"),aL.forEach(t),KNr=i(ei),xe=n(ei,"UL",{});var Ne=s(xe);ZC=n(Ne,"LI",{});var cDe=s(ZC);m4e=n(cDe,"STRONG",{});var zPt=s(m4e);ZNr=r(zPt,"bart"),zPt.forEach(t),eqr=r(cDe," \u2014 "),gZ=n(cDe,"A",{href:!0});var QPt=s(gZ);oqr=r(QPt,"FlaxBartForCausalLM"),QPt.forEach(t),rqr=r(cDe," (BART model)"),cDe.forEach(t),tqr=i(Ne),e0=n(Ne,"LI",{});var fDe=s(e0);g4e=n(fDe,"STRONG",{});var WPt=s(g4e);aqr=r(WPt,"bert"),WPt.forEach(t),nqr=r(fDe," \u2014 "),hZ=n(fDe,"A",{href:!0});var HPt=s(hZ);sqr=r(HPt,"FlaxBertForCausalLM"),HPt.forEach(t),lqr=r(fDe," (BERT model)"),fDe.forEach(t),iqr=i(Ne),o0=n(Ne,"LI",{});var mDe=s(o0);h4e=n(mDe,"STRONG",{});var UPt=s(h4e);dqr=r(UPt,"big_bird"),UPt.forEach(t),cqr=r(mDe," \u2014 "),pZ=n(mDe,"A",{href:!0});var JPt=s(pZ);fqr=r(JPt,"FlaxBigBirdForCausalLM"),JPt.forEach(t),mqr=r(mDe," (BigBird model)"),mDe.forEach(t),gqr=i(Ne),r0=n(Ne,"LI",{});var gDe=s(r0);p4e=n(gDe,"STRONG",{});var YPt=s(p4e);hqr=r(YPt,"electra"),YPt.forEach(t),pqr=r(gDe," \u2014 "),_Z=n(gDe,"A",{href:!0});var KPt=s(_Z);_qr=r(KPt,"FlaxElectraForCausalLM"),KPt.forEach(t),uqr=r(gDe," (ELECTRA model)"),gDe.forEach(t),bqr=i(Ne),t0=n(Ne,"LI",{});var hDe=s(t0);_4e=n(hDe,"STRONG",{});var ZPt=s(_4e);vqr=r(ZPt,"gpt2"),ZPt.forEach(t),Fqr=r(hDe," \u2014 "),uZ=n(hDe,"A",{href:!0});var eBt=s(uZ);Tqr=r(eBt,"FlaxGPT2LMHeadModel"),eBt.forEach(t),Mqr=r(hDe," (OpenAI GPT-2 model)"),hDe.forEach(t),Eqr=i(Ne),a0=n(Ne,"LI",{});var pDe=s(a0);u4e=n(pDe,"STRONG",{});var oBt=s(u4e);Cqr=r(oBt,"gpt_neo"),oBt.forEach(t),wqr=r(pDe," \u2014 "),bZ=n(pDe,"A",{href:!0});var rBt=s(bZ);Aqr=r(rBt,"FlaxGPTNeoForCausalLM"),rBt.forEach(t),Lqr=r(pDe," (GPT Neo model)"),pDe.forEach(t),yqr=i(Ne),n0=n(Ne,"LI",{});var _De=s(n0);b4e=n(_De,"STRONG",{});var tBt=s(b4e);xqr=r(tBt,"gptj"),tBt.forEach(t),$qr=r(_De," \u2014 "),vZ=n(_De,"A",{href:!0});var aBt=s(vZ);kqr=r(aBt,"FlaxGPTJForCausalLM"),aBt.forEach(t),Sqr=r(_De," (GPT-J model)"),_De.forEach(t),Rqr=i(Ne),s0=n(Ne,"LI",{});var uDe=s(s0);v4e=n(uDe,"STRONG",{});var nBt=s(v4e);Pqr=r(nBt,"opt"),nBt.forEach(t),Bqr=r(uDe," \u2014 "),FZ=n(uDe,"A",{href:!0});var sBt=s(FZ);Iqr=r(sBt,"FlaxOPTForCausalLM"),sBt.forEach(t),Nqr=r(uDe," (OPT model)"),uDe.forEach(t),qqr=i(Ne),l0=n(Ne,"LI",{});var bDe=s(l0);F4e=n(bDe,"STRONG",{});var lBt=s(F4e);jqr=r(lBt,"roberta"),lBt.forEach(t),Dqr=r(bDe," \u2014 "),TZ=n(bDe,"A",{href:!0});var iBt=s(TZ);Gqr=r(iBt,"FlaxRobertaForCausalLM"),iBt.forEach(t),Oqr=r(bDe," (RoBERTa model)"),bDe.forEach(t),Vqr=i(Ne),i0=n(Ne,"LI",{});var vDe=s(i0);T4e=n(vDe,"STRONG",{});var dBt=s(T4e);Xqr=r(dBt,"xglm"),dBt.forEach(t),zqr=r(vDe," \u2014 "),MZ=n(vDe,"A",{href:!0});var cBt=s(MZ);Qqr=r(cBt,"FlaxXGLMForCausalLM"),cBt.forEach(t),Wqr=r(vDe," (XGLM model)"),vDe.forEach(t),Ne.forEach(t),Hqr=i(ei),T(d0.$$.fragment,ei),ei.forEach(t),Zl.forEach(t),CVe=i(f),Hc=n(f,"H2",{class:!0});var Rze=s(Hc);c0=n(Rze,"A",{id:!0,class:!0,href:!0});var fBt=s(c0);M4e=n(fBt,"SPAN",{});var mBt=s(M4e);T(Ox.$$.fragment,mBt),mBt.forEach(t),fBt.forEach(t),Uqr=i(Rze),E4e=n(Rze,"SPAN",{});var gBt=s(E4e);Jqr=r(gBt,"FlaxAutoModelForPreTraining"),gBt.forEach(t),Rze.forEach(t),wVe=i(f),_r=n(f,"DIV",{class:!0});var oi=s(_r);T(Vx.$$.fragment,oi),Yqr=i(oi),Uc=n(oi,"P",{});var Qre=s(Uc);Kqr=r(Qre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),EZ=n(Qre,"A",{href:!0});var hBt=s(EZ);Zqr=r(hBt,"from_pretrained()"),hBt.forEach(t),ejr=r(Qre," class method or the "),CZ=n(Qre,"A",{href:!0});var pBt=s(CZ);ojr=r(pBt,"from_config()"),pBt.forEach(t),rjr=r(Qre,` class
method.`),Qre.forEach(t),tjr=i(oi),Xx=n(oi,"P",{});var Pze=s(Xx);ajr=r(Pze,"This class cannot be instantiated directly using "),C4e=n(Pze,"CODE",{});var _Bt=s(C4e);njr=r(_Bt,"__init__()"),_Bt.forEach(t),sjr=r(Pze," (throws an error)."),Pze.forEach(t),ljr=i(oi),Qt=n(oi,"DIV",{class:!0});var nL=s(Qt);T(zx.$$.fragment,nL),ijr=i(nL),w4e=n(nL,"P",{});var uBt=s(w4e);djr=r(uBt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),uBt.forEach(t),cjr=i(nL),Jc=n(nL,"P",{});var Wre=s(Jc);fjr=r(Wre,`Note:
Loading a model from its configuration file does `),A4e=n(Wre,"STRONG",{});var bBt=s(A4e);mjr=r(bBt,"not"),bBt.forEach(t),gjr=r(Wre,` load the model weights. It only affects the
model\u2019s configuration. Use `),wZ=n(Wre,"A",{href:!0});var vBt=s(wZ);hjr=r(vBt,"from_pretrained()"),vBt.forEach(t),pjr=r(Wre," to load the model weights."),Wre.forEach(t),_jr=i(nL),T(f0.$$.fragment,nL),nL.forEach(t),ujr=i(oi),Xr=n(oi,"DIV",{class:!0});var ri=s(Xr);T(Qx.$$.fragment,ri),bjr=i(ri),L4e=n(ri,"P",{});var FBt=s(L4e);vjr=r(FBt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),FBt.forEach(t),Fjr=i(ri),Mn=n(ri,"P",{});var sL=s(Mn);Tjr=r(sL,"The model class to instantiate is selected based on the "),y4e=n(sL,"CODE",{});var TBt=s(y4e);Mjr=r(TBt,"model_type"),TBt.forEach(t),Ejr=r(sL,` property of the config object (either
passed as an argument or loaded from `),x4e=n(sL,"CODE",{});var MBt=s(x4e);Cjr=r(MBt,"pretrained_model_name_or_path"),MBt.forEach(t),wjr=r(sL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$4e=n(sL,"CODE",{});var EBt=s($4e);Ajr=r(EBt,"pretrained_model_name_or_path"),EBt.forEach(t),Ljr=r(sL,":"),sL.forEach(t),yjr=i(ri),Ee=n(ri,"UL",{});var we=s(Ee);m0=n(we,"LI",{});var FDe=s(m0);k4e=n(FDe,"STRONG",{});var CBt=s(k4e);xjr=r(CBt,"albert"),CBt.forEach(t),$jr=r(FDe," \u2014 "),AZ=n(FDe,"A",{href:!0});var wBt=s(AZ);kjr=r(wBt,"FlaxAlbertForPreTraining"),wBt.forEach(t),Sjr=r(FDe," (ALBERT model)"),FDe.forEach(t),Rjr=i(we),g0=n(we,"LI",{});var TDe=s(g0);S4e=n(TDe,"STRONG",{});var ABt=s(S4e);Pjr=r(ABt,"bart"),ABt.forEach(t),Bjr=r(TDe," \u2014 "),LZ=n(TDe,"A",{href:!0});var LBt=s(LZ);Ijr=r(LBt,"FlaxBartForConditionalGeneration"),LBt.forEach(t),Njr=r(TDe," (BART model)"),TDe.forEach(t),qjr=i(we),h0=n(we,"LI",{});var MDe=s(h0);R4e=n(MDe,"STRONG",{});var yBt=s(R4e);jjr=r(yBt,"bert"),yBt.forEach(t),Djr=r(MDe," \u2014 "),yZ=n(MDe,"A",{href:!0});var xBt=s(yZ);Gjr=r(xBt,"FlaxBertForPreTraining"),xBt.forEach(t),Ojr=r(MDe," (BERT model)"),MDe.forEach(t),Vjr=i(we),p0=n(we,"LI",{});var EDe=s(p0);P4e=n(EDe,"STRONG",{});var $Bt=s(P4e);Xjr=r($Bt,"big_bird"),$Bt.forEach(t),zjr=r(EDe," \u2014 "),xZ=n(EDe,"A",{href:!0});var kBt=s(xZ);Qjr=r(kBt,"FlaxBigBirdForPreTraining"),kBt.forEach(t),Wjr=r(EDe," (BigBird model)"),EDe.forEach(t),Hjr=i(we),_0=n(we,"LI",{});var CDe=s(_0);B4e=n(CDe,"STRONG",{});var SBt=s(B4e);Ujr=r(SBt,"electra"),SBt.forEach(t),Jjr=r(CDe," \u2014 "),$Z=n(CDe,"A",{href:!0});var RBt=s($Z);Yjr=r(RBt,"FlaxElectraForPreTraining"),RBt.forEach(t),Kjr=r(CDe," (ELECTRA model)"),CDe.forEach(t),Zjr=i(we),u0=n(we,"LI",{});var wDe=s(u0);I4e=n(wDe,"STRONG",{});var PBt=s(I4e);eDr=r(PBt,"longt5"),PBt.forEach(t),oDr=r(wDe," \u2014 "),kZ=n(wDe,"A",{href:!0});var BBt=s(kZ);rDr=r(BBt,"FlaxLongT5ForConditionalGeneration"),BBt.forEach(t),tDr=r(wDe," (LongT5 model)"),wDe.forEach(t),aDr=i(we),b0=n(we,"LI",{});var ADe=s(b0);N4e=n(ADe,"STRONG",{});var IBt=s(N4e);nDr=r(IBt,"mbart"),IBt.forEach(t),sDr=r(ADe," \u2014 "),SZ=n(ADe,"A",{href:!0});var NBt=s(SZ);lDr=r(NBt,"FlaxMBartForConditionalGeneration"),NBt.forEach(t),iDr=r(ADe," (mBART model)"),ADe.forEach(t),dDr=i(we),v0=n(we,"LI",{});var LDe=s(v0);q4e=n(LDe,"STRONG",{});var qBt=s(q4e);cDr=r(qBt,"mt5"),qBt.forEach(t),fDr=r(LDe," \u2014 "),RZ=n(LDe,"A",{href:!0});var jBt=s(RZ);mDr=r(jBt,"FlaxMT5ForConditionalGeneration"),jBt.forEach(t),gDr=r(LDe," (MT5 model)"),LDe.forEach(t),hDr=i(we),F0=n(we,"LI",{});var yDe=s(F0);j4e=n(yDe,"STRONG",{});var DBt=s(j4e);pDr=r(DBt,"roberta"),DBt.forEach(t),_Dr=r(yDe," \u2014 "),PZ=n(yDe,"A",{href:!0});var GBt=s(PZ);uDr=r(GBt,"FlaxRobertaForMaskedLM"),GBt.forEach(t),bDr=r(yDe," (RoBERTa model)"),yDe.forEach(t),vDr=i(we),T0=n(we,"LI",{});var xDe=s(T0);D4e=n(xDe,"STRONG",{});var OBt=s(D4e);FDr=r(OBt,"roformer"),OBt.forEach(t),TDr=r(xDe," \u2014 "),BZ=n(xDe,"A",{href:!0});var VBt=s(BZ);MDr=r(VBt,"FlaxRoFormerForMaskedLM"),VBt.forEach(t),EDr=r(xDe," (RoFormer model)"),xDe.forEach(t),CDr=i(we),M0=n(we,"LI",{});var $De=s(M0);G4e=n($De,"STRONG",{});var XBt=s(G4e);wDr=r(XBt,"t5"),XBt.forEach(t),ADr=r($De," \u2014 "),IZ=n($De,"A",{href:!0});var zBt=s(IZ);LDr=r(zBt,"FlaxT5ForConditionalGeneration"),zBt.forEach(t),yDr=r($De," (T5 model)"),$De.forEach(t),xDr=i(we),E0=n(we,"LI",{});var kDe=s(E0);O4e=n(kDe,"STRONG",{});var QBt=s(O4e);$Dr=r(QBt,"wav2vec2"),QBt.forEach(t),kDr=r(kDe," \u2014 "),NZ=n(kDe,"A",{href:!0});var WBt=s(NZ);SDr=r(WBt,"FlaxWav2Vec2ForPreTraining"),WBt.forEach(t),RDr=r(kDe," (Wav2Vec2 model)"),kDe.forEach(t),PDr=i(we),C0=n(we,"LI",{});var SDe=s(C0);V4e=n(SDe,"STRONG",{});var HBt=s(V4e);BDr=r(HBt,"xlm-roberta"),HBt.forEach(t),IDr=r(SDe," \u2014 "),qZ=n(SDe,"A",{href:!0});var UBt=s(qZ);NDr=r(UBt,"FlaxXLMRobertaForMaskedLM"),UBt.forEach(t),qDr=r(SDe," (XLM-RoBERTa model)"),SDe.forEach(t),we.forEach(t),jDr=i(ri),T(w0.$$.fragment,ri),ri.forEach(t),oi.forEach(t),AVe=i(f),Yc=n(f,"H2",{class:!0});var Bze=s(Yc);A0=n(Bze,"A",{id:!0,class:!0,href:!0});var JBt=s(A0);X4e=n(JBt,"SPAN",{});var YBt=s(X4e);T(Wx.$$.fragment,YBt),YBt.forEach(t),JBt.forEach(t),DDr=i(Bze),z4e=n(Bze,"SPAN",{});var KBt=s(z4e);GDr=r(KBt,"FlaxAutoModelForMaskedLM"),KBt.forEach(t),Bze.forEach(t),LVe=i(f),ur=n(f,"DIV",{class:!0});var ti=s(ur);T(Hx.$$.fragment,ti),ODr=i(ti),Kc=n(ti,"P",{});var Hre=s(Kc);VDr=r(Hre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),jZ=n(Hre,"A",{href:!0});var ZBt=s(jZ);XDr=r(ZBt,"from_pretrained()"),ZBt.forEach(t),zDr=r(Hre," class method or the "),DZ=n(Hre,"A",{href:!0});var eIt=s(DZ);QDr=r(eIt,"from_config()"),eIt.forEach(t),WDr=r(Hre,` class
method.`),Hre.forEach(t),HDr=i(ti),Ux=n(ti,"P",{});var Ize=s(Ux);UDr=r(Ize,"This class cannot be instantiated directly using "),Q4e=n(Ize,"CODE",{});var oIt=s(Q4e);JDr=r(oIt,"__init__()"),oIt.forEach(t),YDr=r(Ize," (throws an error)."),Ize.forEach(t),KDr=i(ti),Wt=n(ti,"DIV",{class:!0});var lL=s(Wt);T(Jx.$$.fragment,lL),ZDr=i(lL),W4e=n(lL,"P",{});var rIt=s(W4e);eGr=r(rIt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),rIt.forEach(t),oGr=i(lL),Zc=n(lL,"P",{});var Ure=s(Zc);rGr=r(Ure,`Note:
Loading a model from its configuration file does `),H4e=n(Ure,"STRONG",{});var tIt=s(H4e);tGr=r(tIt,"not"),tIt.forEach(t),aGr=r(Ure,` load the model weights. It only affects the
model\u2019s configuration. Use `),GZ=n(Ure,"A",{href:!0});var aIt=s(GZ);nGr=r(aIt,"from_pretrained()"),aIt.forEach(t),sGr=r(Ure," to load the model weights."),Ure.forEach(t),lGr=i(lL),T(L0.$$.fragment,lL),lL.forEach(t),iGr=i(ti),zr=n(ti,"DIV",{class:!0});var ai=s(zr);T(Yx.$$.fragment,ai),dGr=i(ai),U4e=n(ai,"P",{});var nIt=s(U4e);cGr=r(nIt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),nIt.forEach(t),fGr=i(ai),En=n(ai,"P",{});var iL=s(En);mGr=r(iL,"The model class to instantiate is selected based on the "),J4e=n(iL,"CODE",{});var sIt=s(J4e);gGr=r(sIt,"model_type"),sIt.forEach(t),hGr=r(iL,` property of the config object (either
passed as an argument or loaded from `),Y4e=n(iL,"CODE",{});var lIt=s(Y4e);pGr=r(lIt,"pretrained_model_name_or_path"),lIt.forEach(t),_Gr=r(iL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K4e=n(iL,"CODE",{});var iIt=s(K4e);uGr=r(iIt,"pretrained_model_name_or_path"),iIt.forEach(t),bGr=r(iL,":"),iL.forEach(t),vGr=i(ai),$e=n(ai,"UL",{});var qe=s($e);y0=n(qe,"LI",{});var RDe=s(y0);Z4e=n(RDe,"STRONG",{});var dIt=s(Z4e);FGr=r(dIt,"albert"),dIt.forEach(t),TGr=r(RDe," \u2014 "),OZ=n(RDe,"A",{href:!0});var cIt=s(OZ);MGr=r(cIt,"FlaxAlbertForMaskedLM"),cIt.forEach(t),EGr=r(RDe," (ALBERT model)"),RDe.forEach(t),CGr=i(qe),x0=n(qe,"LI",{});var PDe=s(x0);eCe=n(PDe,"STRONG",{});var fIt=s(eCe);wGr=r(fIt,"bart"),fIt.forEach(t),AGr=r(PDe," \u2014 "),VZ=n(PDe,"A",{href:!0});var mIt=s(VZ);LGr=r(mIt,"FlaxBartForConditionalGeneration"),mIt.forEach(t),yGr=r(PDe," (BART model)"),PDe.forEach(t),xGr=i(qe),$0=n(qe,"LI",{});var BDe=s($0);oCe=n(BDe,"STRONG",{});var gIt=s(oCe);$Gr=r(gIt,"bert"),gIt.forEach(t),kGr=r(BDe," \u2014 "),XZ=n(BDe,"A",{href:!0});var hIt=s(XZ);SGr=r(hIt,"FlaxBertForMaskedLM"),hIt.forEach(t),RGr=r(BDe," (BERT model)"),BDe.forEach(t),PGr=i(qe),k0=n(qe,"LI",{});var IDe=s(k0);rCe=n(IDe,"STRONG",{});var pIt=s(rCe);BGr=r(pIt,"big_bird"),pIt.forEach(t),IGr=r(IDe," \u2014 "),zZ=n(IDe,"A",{href:!0});var _It=s(zZ);NGr=r(_It,"FlaxBigBirdForMaskedLM"),_It.forEach(t),qGr=r(IDe," (BigBird model)"),IDe.forEach(t),jGr=i(qe),S0=n(qe,"LI",{});var NDe=s(S0);tCe=n(NDe,"STRONG",{});var uIt=s(tCe);DGr=r(uIt,"distilbert"),uIt.forEach(t),GGr=r(NDe," \u2014 "),QZ=n(NDe,"A",{href:!0});var bIt=s(QZ);OGr=r(bIt,"FlaxDistilBertForMaskedLM"),bIt.forEach(t),VGr=r(NDe," (DistilBERT model)"),NDe.forEach(t),XGr=i(qe),R0=n(qe,"LI",{});var qDe=s(R0);aCe=n(qDe,"STRONG",{});var vIt=s(aCe);zGr=r(vIt,"electra"),vIt.forEach(t),QGr=r(qDe," \u2014 "),WZ=n(qDe,"A",{href:!0});var FIt=s(WZ);WGr=r(FIt,"FlaxElectraForMaskedLM"),FIt.forEach(t),HGr=r(qDe," (ELECTRA model)"),qDe.forEach(t),UGr=i(qe),P0=n(qe,"LI",{});var jDe=s(P0);nCe=n(jDe,"STRONG",{});var TIt=s(nCe);JGr=r(TIt,"mbart"),TIt.forEach(t),YGr=r(jDe," \u2014 "),HZ=n(jDe,"A",{href:!0});var MIt=s(HZ);KGr=r(MIt,"FlaxMBartForConditionalGeneration"),MIt.forEach(t),ZGr=r(jDe," (mBART model)"),jDe.forEach(t),eOr=i(qe),B0=n(qe,"LI",{});var DDe=s(B0);sCe=n(DDe,"STRONG",{});var EIt=s(sCe);oOr=r(EIt,"roberta"),EIt.forEach(t),rOr=r(DDe," \u2014 "),UZ=n(DDe,"A",{href:!0});var CIt=s(UZ);tOr=r(CIt,"FlaxRobertaForMaskedLM"),CIt.forEach(t),aOr=r(DDe," (RoBERTa model)"),DDe.forEach(t),nOr=i(qe),I0=n(qe,"LI",{});var GDe=s(I0);lCe=n(GDe,"STRONG",{});var wIt=s(lCe);sOr=r(wIt,"roformer"),wIt.forEach(t),lOr=r(GDe," \u2014 "),JZ=n(GDe,"A",{href:!0});var AIt=s(JZ);iOr=r(AIt,"FlaxRoFormerForMaskedLM"),AIt.forEach(t),dOr=r(GDe," (RoFormer model)"),GDe.forEach(t),cOr=i(qe),N0=n(qe,"LI",{});var ODe=s(N0);iCe=n(ODe,"STRONG",{});var LIt=s(iCe);fOr=r(LIt,"xlm-roberta"),LIt.forEach(t),mOr=r(ODe," \u2014 "),YZ=n(ODe,"A",{href:!0});var yIt=s(YZ);gOr=r(yIt,"FlaxXLMRobertaForMaskedLM"),yIt.forEach(t),hOr=r(ODe," (XLM-RoBERTa model)"),ODe.forEach(t),qe.forEach(t),pOr=i(ai),T(q0.$$.fragment,ai),ai.forEach(t),ti.forEach(t),yVe=i(f),ef=n(f,"H2",{class:!0});var Nze=s(ef);j0=n(Nze,"A",{id:!0,class:!0,href:!0});var xIt=s(j0);dCe=n(xIt,"SPAN",{});var $It=s(dCe);T(Kx.$$.fragment,$It),$It.forEach(t),xIt.forEach(t),_Or=i(Nze),cCe=n(Nze,"SPAN",{});var kIt=s(cCe);uOr=r(kIt,"FlaxAutoModelForSeq2SeqLM"),kIt.forEach(t),Nze.forEach(t),xVe=i(f),br=n(f,"DIV",{class:!0});var ni=s(br);T(Zx.$$.fragment,ni),bOr=i(ni),of=n(ni,"P",{});var Jre=s(of);vOr=r(Jre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),KZ=n(Jre,"A",{href:!0});var SIt=s(KZ);FOr=r(SIt,"from_pretrained()"),SIt.forEach(t),TOr=r(Jre," class method or the "),ZZ=n(Jre,"A",{href:!0});var RIt=s(ZZ);MOr=r(RIt,"from_config()"),RIt.forEach(t),EOr=r(Jre,` class
method.`),Jre.forEach(t),COr=i(ni),e$=n(ni,"P",{});var qze=s(e$);wOr=r(qze,"This class cannot be instantiated directly using "),fCe=n(qze,"CODE",{});var PIt=s(fCe);AOr=r(PIt,"__init__()"),PIt.forEach(t),LOr=r(qze," (throws an error)."),qze.forEach(t),yOr=i(ni),Ht=n(ni,"DIV",{class:!0});var dL=s(Ht);T(o$.$$.fragment,dL),xOr=i(dL),mCe=n(dL,"P",{});var BIt=s(mCe);$Or=r(BIt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),BIt.forEach(t),kOr=i(dL),rf=n(dL,"P",{});var Yre=s(rf);SOr=r(Yre,`Note:
Loading a model from its configuration file does `),gCe=n(Yre,"STRONG",{});var IIt=s(gCe);ROr=r(IIt,"not"),IIt.forEach(t),POr=r(Yre,` load the model weights. It only affects the
model\u2019s configuration. Use `),eee=n(Yre,"A",{href:!0});var NIt=s(eee);BOr=r(NIt,"from_pretrained()"),NIt.forEach(t),IOr=r(Yre," to load the model weights."),Yre.forEach(t),NOr=i(dL),T(D0.$$.fragment,dL),dL.forEach(t),qOr=i(ni),Qr=n(ni,"DIV",{class:!0});var si=s(Qr);T(r$.$$.fragment,si),jOr=i(si),hCe=n(si,"P",{});var qIt=s(hCe);DOr=r(qIt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),qIt.forEach(t),GOr=i(si),Cn=n(si,"P",{});var cL=s(Cn);OOr=r(cL,"The model class to instantiate is selected based on the "),pCe=n(cL,"CODE",{});var jIt=s(pCe);VOr=r(jIt,"model_type"),jIt.forEach(t),XOr=r(cL,` property of the config object (either
passed as an argument or loaded from `),_Ce=n(cL,"CODE",{});var DIt=s(_Ce);zOr=r(DIt,"pretrained_model_name_or_path"),DIt.forEach(t),QOr=r(cL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uCe=n(cL,"CODE",{});var GIt=s(uCe);WOr=r(GIt,"pretrained_model_name_or_path"),GIt.forEach(t),HOr=r(cL,":"),cL.forEach(t),UOr=i(si),ke=n(si,"UL",{});var je=s(ke);G0=n(je,"LI",{});var VDe=s(G0);bCe=n(VDe,"STRONG",{});var OIt=s(bCe);JOr=r(OIt,"bart"),OIt.forEach(t),YOr=r(VDe," \u2014 "),oee=n(VDe,"A",{href:!0});var VIt=s(oee);KOr=r(VIt,"FlaxBartForConditionalGeneration"),VIt.forEach(t),ZOr=r(VDe," (BART model)"),VDe.forEach(t),eVr=i(je),O0=n(je,"LI",{});var XDe=s(O0);vCe=n(XDe,"STRONG",{});var XIt=s(vCe);oVr=r(XIt,"blenderbot"),XIt.forEach(t),rVr=r(XDe," \u2014 "),ree=n(XDe,"A",{href:!0});var zIt=s(ree);tVr=r(zIt,"FlaxBlenderbotForConditionalGeneration"),zIt.forEach(t),aVr=r(XDe," (Blenderbot model)"),XDe.forEach(t),nVr=i(je),V0=n(je,"LI",{});var zDe=s(V0);FCe=n(zDe,"STRONG",{});var QIt=s(FCe);sVr=r(QIt,"blenderbot-small"),QIt.forEach(t),lVr=r(zDe," \u2014 "),tee=n(zDe,"A",{href:!0});var WIt=s(tee);iVr=r(WIt,"FlaxBlenderbotSmallForConditionalGeneration"),WIt.forEach(t),dVr=r(zDe," (BlenderbotSmall model)"),zDe.forEach(t),cVr=i(je),X0=n(je,"LI",{});var QDe=s(X0);TCe=n(QDe,"STRONG",{});var HIt=s(TCe);fVr=r(HIt,"encoder-decoder"),HIt.forEach(t),mVr=r(QDe," \u2014 "),aee=n(QDe,"A",{href:!0});var UIt=s(aee);gVr=r(UIt,"FlaxEncoderDecoderModel"),UIt.forEach(t),hVr=r(QDe," (Encoder decoder model)"),QDe.forEach(t),pVr=i(je),z0=n(je,"LI",{});var WDe=s(z0);MCe=n(WDe,"STRONG",{});var JIt=s(MCe);_Vr=r(JIt,"longt5"),JIt.forEach(t),uVr=r(WDe," \u2014 "),nee=n(WDe,"A",{href:!0});var YIt=s(nee);bVr=r(YIt,"FlaxLongT5ForConditionalGeneration"),YIt.forEach(t),vVr=r(WDe," (LongT5 model)"),WDe.forEach(t),FVr=i(je),Q0=n(je,"LI",{});var HDe=s(Q0);ECe=n(HDe,"STRONG",{});var KIt=s(ECe);TVr=r(KIt,"marian"),KIt.forEach(t),MVr=r(HDe," \u2014 "),see=n(HDe,"A",{href:!0});var ZIt=s(see);EVr=r(ZIt,"FlaxMarianMTModel"),ZIt.forEach(t),CVr=r(HDe," (Marian model)"),HDe.forEach(t),wVr=i(je),W0=n(je,"LI",{});var UDe=s(W0);CCe=n(UDe,"STRONG",{});var eNt=s(CCe);AVr=r(eNt,"mbart"),eNt.forEach(t),LVr=r(UDe," \u2014 "),lee=n(UDe,"A",{href:!0});var oNt=s(lee);yVr=r(oNt,"FlaxMBartForConditionalGeneration"),oNt.forEach(t),xVr=r(UDe," (mBART model)"),UDe.forEach(t),$Vr=i(je),H0=n(je,"LI",{});var JDe=s(H0);wCe=n(JDe,"STRONG",{});var rNt=s(wCe);kVr=r(rNt,"mt5"),rNt.forEach(t),SVr=r(JDe," \u2014 "),iee=n(JDe,"A",{href:!0});var tNt=s(iee);RVr=r(tNt,"FlaxMT5ForConditionalGeneration"),tNt.forEach(t),PVr=r(JDe," (MT5 model)"),JDe.forEach(t),BVr=i(je),U0=n(je,"LI",{});var YDe=s(U0);ACe=n(YDe,"STRONG",{});var aNt=s(ACe);IVr=r(aNt,"pegasus"),aNt.forEach(t),NVr=r(YDe," \u2014 "),dee=n(YDe,"A",{href:!0});var nNt=s(dee);qVr=r(nNt,"FlaxPegasusForConditionalGeneration"),nNt.forEach(t),jVr=r(YDe," (Pegasus model)"),YDe.forEach(t),DVr=i(je),J0=n(je,"LI",{});var KDe=s(J0);LCe=n(KDe,"STRONG",{});var sNt=s(LCe);GVr=r(sNt,"t5"),sNt.forEach(t),OVr=r(KDe," \u2014 "),cee=n(KDe,"A",{href:!0});var lNt=s(cee);VVr=r(lNt,"FlaxT5ForConditionalGeneration"),lNt.forEach(t),XVr=r(KDe," (T5 model)"),KDe.forEach(t),je.forEach(t),zVr=i(si),T(Y0.$$.fragment,si),si.forEach(t),ni.forEach(t),$Ve=i(f),tf=n(f,"H2",{class:!0});var jze=s(tf);K0=n(jze,"A",{id:!0,class:!0,href:!0});var iNt=s(K0);yCe=n(iNt,"SPAN",{});var dNt=s(yCe);T(t$.$$.fragment,dNt),dNt.forEach(t),iNt.forEach(t),QVr=i(jze),xCe=n(jze,"SPAN",{});var cNt=s(xCe);WVr=r(cNt,"FlaxAutoModelForSequenceClassification"),cNt.forEach(t),jze.forEach(t),kVe=i(f),vr=n(f,"DIV",{class:!0});var li=s(vr);T(a$.$$.fragment,li),HVr=i(li),af=n(li,"P",{});var Kre=s(af);UVr=r(Kre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),fee=n(Kre,"A",{href:!0});var fNt=s(fee);JVr=r(fNt,"from_pretrained()"),fNt.forEach(t),YVr=r(Kre," class method or the "),mee=n(Kre,"A",{href:!0});var mNt=s(mee);KVr=r(mNt,"from_config()"),mNt.forEach(t),ZVr=r(Kre,` class
method.`),Kre.forEach(t),eXr=i(li),n$=n(li,"P",{});var Dze=s(n$);oXr=r(Dze,"This class cannot be instantiated directly using "),$Ce=n(Dze,"CODE",{});var gNt=s($Ce);rXr=r(gNt,"__init__()"),gNt.forEach(t),tXr=r(Dze," (throws an error)."),Dze.forEach(t),aXr=i(li),Ut=n(li,"DIV",{class:!0});var fL=s(Ut);T(s$.$$.fragment,fL),nXr=i(fL),kCe=n(fL,"P",{});var hNt=s(kCe);sXr=r(hNt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),hNt.forEach(t),lXr=i(fL),nf=n(fL,"P",{});var Zre=s(nf);iXr=r(Zre,`Note:
Loading a model from its configuration file does `),SCe=n(Zre,"STRONG",{});var pNt=s(SCe);dXr=r(pNt,"not"),pNt.forEach(t),cXr=r(Zre,` load the model weights. It only affects the
model\u2019s configuration. Use `),gee=n(Zre,"A",{href:!0});var _Nt=s(gee);fXr=r(_Nt,"from_pretrained()"),_Nt.forEach(t),mXr=r(Zre," to load the model weights."),Zre.forEach(t),gXr=i(fL),T(Z0.$$.fragment,fL),fL.forEach(t),hXr=i(li),Wr=n(li,"DIV",{class:!0});var ii=s(Wr);T(l$.$$.fragment,ii),pXr=i(ii),RCe=n(ii,"P",{});var uNt=s(RCe);_Xr=r(uNt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),uNt.forEach(t),uXr=i(ii),wn=n(ii,"P",{});var mL=s(wn);bXr=r(mL,"The model class to instantiate is selected based on the "),PCe=n(mL,"CODE",{});var bNt=s(PCe);vXr=r(bNt,"model_type"),bNt.forEach(t),FXr=r(mL,` property of the config object (either
passed as an argument or loaded from `),BCe=n(mL,"CODE",{});var vNt=s(BCe);TXr=r(vNt,"pretrained_model_name_or_path"),vNt.forEach(t),MXr=r(mL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ICe=n(mL,"CODE",{});var FNt=s(ICe);EXr=r(FNt,"pretrained_model_name_or_path"),FNt.forEach(t),CXr=r(mL,":"),mL.forEach(t),wXr=i(ii),Se=n(ii,"UL",{});var De=s(Se);ew=n(De,"LI",{});var ZDe=s(ew);NCe=n(ZDe,"STRONG",{});var TNt=s(NCe);AXr=r(TNt,"albert"),TNt.forEach(t),LXr=r(ZDe," \u2014 "),hee=n(ZDe,"A",{href:!0});var MNt=s(hee);yXr=r(MNt,"FlaxAlbertForSequenceClassification"),MNt.forEach(t),xXr=r(ZDe," (ALBERT model)"),ZDe.forEach(t),$Xr=i(De),ow=n(De,"LI",{});var eGe=s(ow);qCe=n(eGe,"STRONG",{});var ENt=s(qCe);kXr=r(ENt,"bart"),ENt.forEach(t),SXr=r(eGe," \u2014 "),pee=n(eGe,"A",{href:!0});var CNt=s(pee);RXr=r(CNt,"FlaxBartForSequenceClassification"),CNt.forEach(t),PXr=r(eGe," (BART model)"),eGe.forEach(t),BXr=i(De),rw=n(De,"LI",{});var oGe=s(rw);jCe=n(oGe,"STRONG",{});var wNt=s(jCe);IXr=r(wNt,"bert"),wNt.forEach(t),NXr=r(oGe," \u2014 "),_ee=n(oGe,"A",{href:!0});var ANt=s(_ee);qXr=r(ANt,"FlaxBertForSequenceClassification"),ANt.forEach(t),jXr=r(oGe," (BERT model)"),oGe.forEach(t),DXr=i(De),tw=n(De,"LI",{});var rGe=s(tw);DCe=n(rGe,"STRONG",{});var LNt=s(DCe);GXr=r(LNt,"big_bird"),LNt.forEach(t),OXr=r(rGe," \u2014 "),uee=n(rGe,"A",{href:!0});var yNt=s(uee);VXr=r(yNt,"FlaxBigBirdForSequenceClassification"),yNt.forEach(t),XXr=r(rGe," (BigBird model)"),rGe.forEach(t),zXr=i(De),aw=n(De,"LI",{});var tGe=s(aw);GCe=n(tGe,"STRONG",{});var xNt=s(GCe);QXr=r(xNt,"distilbert"),xNt.forEach(t),WXr=r(tGe," \u2014 "),bee=n(tGe,"A",{href:!0});var $Nt=s(bee);HXr=r($Nt,"FlaxDistilBertForSequenceClassification"),$Nt.forEach(t),UXr=r(tGe," (DistilBERT model)"),tGe.forEach(t),JXr=i(De),nw=n(De,"LI",{});var aGe=s(nw);OCe=n(aGe,"STRONG",{});var kNt=s(OCe);YXr=r(kNt,"electra"),kNt.forEach(t),KXr=r(aGe," \u2014 "),vee=n(aGe,"A",{href:!0});var SNt=s(vee);ZXr=r(SNt,"FlaxElectraForSequenceClassification"),SNt.forEach(t),ezr=r(aGe," (ELECTRA model)"),aGe.forEach(t),ozr=i(De),sw=n(De,"LI",{});var nGe=s(sw);VCe=n(nGe,"STRONG",{});var RNt=s(VCe);rzr=r(RNt,"mbart"),RNt.forEach(t),tzr=r(nGe," \u2014 "),Fee=n(nGe,"A",{href:!0});var PNt=s(Fee);azr=r(PNt,"FlaxMBartForSequenceClassification"),PNt.forEach(t),nzr=r(nGe," (mBART model)"),nGe.forEach(t),szr=i(De),lw=n(De,"LI",{});var sGe=s(lw);XCe=n(sGe,"STRONG",{});var BNt=s(XCe);lzr=r(BNt,"roberta"),BNt.forEach(t),izr=r(sGe," \u2014 "),Tee=n(sGe,"A",{href:!0});var INt=s(Tee);dzr=r(INt,"FlaxRobertaForSequenceClassification"),INt.forEach(t),czr=r(sGe," (RoBERTa model)"),sGe.forEach(t),fzr=i(De),iw=n(De,"LI",{});var lGe=s(iw);zCe=n(lGe,"STRONG",{});var NNt=s(zCe);mzr=r(NNt,"roformer"),NNt.forEach(t),gzr=r(lGe," \u2014 "),Mee=n(lGe,"A",{href:!0});var qNt=s(Mee);hzr=r(qNt,"FlaxRoFormerForSequenceClassification"),qNt.forEach(t),pzr=r(lGe," (RoFormer model)"),lGe.forEach(t),_zr=i(De),dw=n(De,"LI",{});var iGe=s(dw);QCe=n(iGe,"STRONG",{});var jNt=s(QCe);uzr=r(jNt,"xlm-roberta"),jNt.forEach(t),bzr=r(iGe," \u2014 "),Eee=n(iGe,"A",{href:!0});var DNt=s(Eee);vzr=r(DNt,"FlaxXLMRobertaForSequenceClassification"),DNt.forEach(t),Fzr=r(iGe," (XLM-RoBERTa model)"),iGe.forEach(t),De.forEach(t),Tzr=i(ii),T(cw.$$.fragment,ii),ii.forEach(t),li.forEach(t),SVe=i(f),sf=n(f,"H2",{class:!0});var Gze=s(sf);fw=n(Gze,"A",{id:!0,class:!0,href:!0});var GNt=s(fw);WCe=n(GNt,"SPAN",{});var ONt=s(WCe);T(i$.$$.fragment,ONt),ONt.forEach(t),GNt.forEach(t),Mzr=i(Gze),HCe=n(Gze,"SPAN",{});var VNt=s(HCe);Ezr=r(VNt,"FlaxAutoModelForQuestionAnswering"),VNt.forEach(t),Gze.forEach(t),RVe=i(f),Fr=n(f,"DIV",{class:!0});var di=s(Fr);T(d$.$$.fragment,di),Czr=i(di),lf=n(di,"P",{});var ete=s(lf);wzr=r(ete,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Cee=n(ete,"A",{href:!0});var XNt=s(Cee);Azr=r(XNt,"from_pretrained()"),XNt.forEach(t),Lzr=r(ete," class method or the "),wee=n(ete,"A",{href:!0});var zNt=s(wee);yzr=r(zNt,"from_config()"),zNt.forEach(t),xzr=r(ete,` class
method.`),ete.forEach(t),$zr=i(di),c$=n(di,"P",{});var Oze=s(c$);kzr=r(Oze,"This class cannot be instantiated directly using "),UCe=n(Oze,"CODE",{});var QNt=s(UCe);Szr=r(QNt,"__init__()"),QNt.forEach(t),Rzr=r(Oze," (throws an error)."),Oze.forEach(t),Pzr=i(di),Jt=n(di,"DIV",{class:!0});var gL=s(Jt);T(f$.$$.fragment,gL),Bzr=i(gL),JCe=n(gL,"P",{});var WNt=s(JCe);Izr=r(WNt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),WNt.forEach(t),Nzr=i(gL),df=n(gL,"P",{});var ote=s(df);qzr=r(ote,`Note:
Loading a model from its configuration file does `),YCe=n(ote,"STRONG",{});var HNt=s(YCe);jzr=r(HNt,"not"),HNt.forEach(t),Dzr=r(ote,` load the model weights. It only affects the
model\u2019s configuration. Use `),Aee=n(ote,"A",{href:!0});var UNt=s(Aee);Gzr=r(UNt,"from_pretrained()"),UNt.forEach(t),Ozr=r(ote," to load the model weights."),ote.forEach(t),Vzr=i(gL),T(mw.$$.fragment,gL),gL.forEach(t),Xzr=i(di),Hr=n(di,"DIV",{class:!0});var ci=s(Hr);T(m$.$$.fragment,ci),zzr=i(ci),KCe=n(ci,"P",{});var JNt=s(KCe);Qzr=r(JNt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),JNt.forEach(t),Wzr=i(ci),An=n(ci,"P",{});var hL=s(An);Hzr=r(hL,"The model class to instantiate is selected based on the "),ZCe=n(hL,"CODE",{});var YNt=s(ZCe);Uzr=r(YNt,"model_type"),YNt.forEach(t),Jzr=r(hL,` property of the config object (either
passed as an argument or loaded from `),e0e=n(hL,"CODE",{});var KNt=s(e0e);Yzr=r(KNt,"pretrained_model_name_or_path"),KNt.forEach(t),Kzr=r(hL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o0e=n(hL,"CODE",{});var ZNt=s(o0e);Zzr=r(ZNt,"pretrained_model_name_or_path"),ZNt.forEach(t),eQr=r(hL,":"),hL.forEach(t),oQr=i(ci),Re=n(ci,"UL",{});var Ge=s(Re);gw=n(Ge,"LI",{});var dGe=s(gw);r0e=n(dGe,"STRONG",{});var eqt=s(r0e);rQr=r(eqt,"albert"),eqt.forEach(t),tQr=r(dGe," \u2014 "),Lee=n(dGe,"A",{href:!0});var oqt=s(Lee);aQr=r(oqt,"FlaxAlbertForQuestionAnswering"),oqt.forEach(t),nQr=r(dGe," (ALBERT model)"),dGe.forEach(t),sQr=i(Ge),hw=n(Ge,"LI",{});var cGe=s(hw);t0e=n(cGe,"STRONG",{});var rqt=s(t0e);lQr=r(rqt,"bart"),rqt.forEach(t),iQr=r(cGe," \u2014 "),yee=n(cGe,"A",{href:!0});var tqt=s(yee);dQr=r(tqt,"FlaxBartForQuestionAnswering"),tqt.forEach(t),cQr=r(cGe," (BART model)"),cGe.forEach(t),fQr=i(Ge),pw=n(Ge,"LI",{});var fGe=s(pw);a0e=n(fGe,"STRONG",{});var aqt=s(a0e);mQr=r(aqt,"bert"),aqt.forEach(t),gQr=r(fGe," \u2014 "),xee=n(fGe,"A",{href:!0});var nqt=s(xee);hQr=r(nqt,"FlaxBertForQuestionAnswering"),nqt.forEach(t),pQr=r(fGe," (BERT model)"),fGe.forEach(t),_Qr=i(Ge),_w=n(Ge,"LI",{});var mGe=s(_w);n0e=n(mGe,"STRONG",{});var sqt=s(n0e);uQr=r(sqt,"big_bird"),sqt.forEach(t),bQr=r(mGe," \u2014 "),$ee=n(mGe,"A",{href:!0});var lqt=s($ee);vQr=r(lqt,"FlaxBigBirdForQuestionAnswering"),lqt.forEach(t),FQr=r(mGe," (BigBird model)"),mGe.forEach(t),TQr=i(Ge),uw=n(Ge,"LI",{});var gGe=s(uw);s0e=n(gGe,"STRONG",{});var iqt=s(s0e);MQr=r(iqt,"distilbert"),iqt.forEach(t),EQr=r(gGe," \u2014 "),kee=n(gGe,"A",{href:!0});var dqt=s(kee);CQr=r(dqt,"FlaxDistilBertForQuestionAnswering"),dqt.forEach(t),wQr=r(gGe," (DistilBERT model)"),gGe.forEach(t),AQr=i(Ge),bw=n(Ge,"LI",{});var hGe=s(bw);l0e=n(hGe,"STRONG",{});var cqt=s(l0e);LQr=r(cqt,"electra"),cqt.forEach(t),yQr=r(hGe," \u2014 "),See=n(hGe,"A",{href:!0});var fqt=s(See);xQr=r(fqt,"FlaxElectraForQuestionAnswering"),fqt.forEach(t),$Qr=r(hGe," (ELECTRA model)"),hGe.forEach(t),kQr=i(Ge),vw=n(Ge,"LI",{});var pGe=s(vw);i0e=n(pGe,"STRONG",{});var mqt=s(i0e);SQr=r(mqt,"mbart"),mqt.forEach(t),RQr=r(pGe," \u2014 "),Ree=n(pGe,"A",{href:!0});var gqt=s(Ree);PQr=r(gqt,"FlaxMBartForQuestionAnswering"),gqt.forEach(t),BQr=r(pGe," (mBART model)"),pGe.forEach(t),IQr=i(Ge),Fw=n(Ge,"LI",{});var _Ge=s(Fw);d0e=n(_Ge,"STRONG",{});var hqt=s(d0e);NQr=r(hqt,"roberta"),hqt.forEach(t),qQr=r(_Ge," \u2014 "),Pee=n(_Ge,"A",{href:!0});var pqt=s(Pee);jQr=r(pqt,"FlaxRobertaForQuestionAnswering"),pqt.forEach(t),DQr=r(_Ge," (RoBERTa model)"),_Ge.forEach(t),GQr=i(Ge),Tw=n(Ge,"LI",{});var uGe=s(Tw);c0e=n(uGe,"STRONG",{});var _qt=s(c0e);OQr=r(_qt,"roformer"),_qt.forEach(t),VQr=r(uGe," \u2014 "),Bee=n(uGe,"A",{href:!0});var uqt=s(Bee);XQr=r(uqt,"FlaxRoFormerForQuestionAnswering"),uqt.forEach(t),zQr=r(uGe," (RoFormer model)"),uGe.forEach(t),QQr=i(Ge),Mw=n(Ge,"LI",{});var bGe=s(Mw);f0e=n(bGe,"STRONG",{});var bqt=s(f0e);WQr=r(bqt,"xlm-roberta"),bqt.forEach(t),HQr=r(bGe," \u2014 "),Iee=n(bGe,"A",{href:!0});var vqt=s(Iee);UQr=r(vqt,"FlaxXLMRobertaForQuestionAnswering"),vqt.forEach(t),JQr=r(bGe," (XLM-RoBERTa model)"),bGe.forEach(t),Ge.forEach(t),YQr=i(ci),T(Ew.$$.fragment,ci),ci.forEach(t),di.forEach(t),PVe=i(f),cf=n(f,"H2",{class:!0});var Vze=s(cf);Cw=n(Vze,"A",{id:!0,class:!0,href:!0});var Fqt=s(Cw);m0e=n(Fqt,"SPAN",{});var Tqt=s(m0e);T(g$.$$.fragment,Tqt),Tqt.forEach(t),Fqt.forEach(t),KQr=i(Vze),g0e=n(Vze,"SPAN",{});var Mqt=s(g0e);ZQr=r(Mqt,"FlaxAutoModelForTokenClassification"),Mqt.forEach(t),Vze.forEach(t),BVe=i(f),Tr=n(f,"DIV",{class:!0});var fi=s(Tr);T(h$.$$.fragment,fi),eWr=i(fi),ff=n(fi,"P",{});var rte=s(ff);oWr=r(rte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Nee=n(rte,"A",{href:!0});var Eqt=s(Nee);rWr=r(Eqt,"from_pretrained()"),Eqt.forEach(t),tWr=r(rte," class method or the "),qee=n(rte,"A",{href:!0});var Cqt=s(qee);aWr=r(Cqt,"from_config()"),Cqt.forEach(t),nWr=r(rte,` class
method.`),rte.forEach(t),sWr=i(fi),p$=n(fi,"P",{});var Xze=s(p$);lWr=r(Xze,"This class cannot be instantiated directly using "),h0e=n(Xze,"CODE",{});var wqt=s(h0e);iWr=r(wqt,"__init__()"),wqt.forEach(t),dWr=r(Xze," (throws an error)."),Xze.forEach(t),cWr=i(fi),Yt=n(fi,"DIV",{class:!0});var pL=s(Yt);T(_$.$$.fragment,pL),fWr=i(pL),p0e=n(pL,"P",{});var Aqt=s(p0e);mWr=r(Aqt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Aqt.forEach(t),gWr=i(pL),mf=n(pL,"P",{});var tte=s(mf);hWr=r(tte,`Note:
Loading a model from its configuration file does `),_0e=n(tte,"STRONG",{});var Lqt=s(_0e);pWr=r(Lqt,"not"),Lqt.forEach(t),_Wr=r(tte,` load the model weights. It only affects the
model\u2019s configuration. Use `),jee=n(tte,"A",{href:!0});var yqt=s(jee);uWr=r(yqt,"from_pretrained()"),yqt.forEach(t),bWr=r(tte," to load the model weights."),tte.forEach(t),vWr=i(pL),T(ww.$$.fragment,pL),pL.forEach(t),FWr=i(fi),Ur=n(fi,"DIV",{class:!0});var mi=s(Ur);T(u$.$$.fragment,mi),TWr=i(mi),u0e=n(mi,"P",{});var xqt=s(u0e);MWr=r(xqt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),xqt.forEach(t),EWr=i(mi),Ln=n(mi,"P",{});var _L=s(Ln);CWr=r(_L,"The model class to instantiate is selected based on the "),b0e=n(_L,"CODE",{});var $qt=s(b0e);wWr=r($qt,"model_type"),$qt.forEach(t),AWr=r(_L,` property of the config object (either
passed as an argument or loaded from `),v0e=n(_L,"CODE",{});var kqt=s(v0e);LWr=r(kqt,"pretrained_model_name_or_path"),kqt.forEach(t),yWr=r(_L,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F0e=n(_L,"CODE",{});var Sqt=s(F0e);xWr=r(Sqt,"pretrained_model_name_or_path"),Sqt.forEach(t),$Wr=r(_L,":"),_L.forEach(t),kWr=i(mi),Ve=n(mi,"UL",{});var To=s(Ve);Aw=n(To,"LI",{});var vGe=s(Aw);T0e=n(vGe,"STRONG",{});var Rqt=s(T0e);SWr=r(Rqt,"albert"),Rqt.forEach(t),RWr=r(vGe," \u2014 "),Dee=n(vGe,"A",{href:!0});var Pqt=s(Dee);PWr=r(Pqt,"FlaxAlbertForTokenClassification"),Pqt.forEach(t),BWr=r(vGe," (ALBERT model)"),vGe.forEach(t),IWr=i(To),Lw=n(To,"LI",{});var FGe=s(Lw);M0e=n(FGe,"STRONG",{});var Bqt=s(M0e);NWr=r(Bqt,"bert"),Bqt.forEach(t),qWr=r(FGe," \u2014 "),Gee=n(FGe,"A",{href:!0});var Iqt=s(Gee);jWr=r(Iqt,"FlaxBertForTokenClassification"),Iqt.forEach(t),DWr=r(FGe," (BERT model)"),FGe.forEach(t),GWr=i(To),yw=n(To,"LI",{});var TGe=s(yw);E0e=n(TGe,"STRONG",{});var Nqt=s(E0e);OWr=r(Nqt,"big_bird"),Nqt.forEach(t),VWr=r(TGe," \u2014 "),Oee=n(TGe,"A",{href:!0});var qqt=s(Oee);XWr=r(qqt,"FlaxBigBirdForTokenClassification"),qqt.forEach(t),zWr=r(TGe," (BigBird model)"),TGe.forEach(t),QWr=i(To),xw=n(To,"LI",{});var MGe=s(xw);C0e=n(MGe,"STRONG",{});var jqt=s(C0e);WWr=r(jqt,"distilbert"),jqt.forEach(t),HWr=r(MGe," \u2014 "),Vee=n(MGe,"A",{href:!0});var Dqt=s(Vee);UWr=r(Dqt,"FlaxDistilBertForTokenClassification"),Dqt.forEach(t),JWr=r(MGe," (DistilBERT model)"),MGe.forEach(t),YWr=i(To),$w=n(To,"LI",{});var EGe=s($w);w0e=n(EGe,"STRONG",{});var Gqt=s(w0e);KWr=r(Gqt,"electra"),Gqt.forEach(t),ZWr=r(EGe," \u2014 "),Xee=n(EGe,"A",{href:!0});var Oqt=s(Xee);eHr=r(Oqt,"FlaxElectraForTokenClassification"),Oqt.forEach(t),oHr=r(EGe," (ELECTRA model)"),EGe.forEach(t),rHr=i(To),kw=n(To,"LI",{});var CGe=s(kw);A0e=n(CGe,"STRONG",{});var Vqt=s(A0e);tHr=r(Vqt,"roberta"),Vqt.forEach(t),aHr=r(CGe," \u2014 "),zee=n(CGe,"A",{href:!0});var Xqt=s(zee);nHr=r(Xqt,"FlaxRobertaForTokenClassification"),Xqt.forEach(t),sHr=r(CGe," (RoBERTa model)"),CGe.forEach(t),lHr=i(To),Sw=n(To,"LI",{});var wGe=s(Sw);L0e=n(wGe,"STRONG",{});var zqt=s(L0e);iHr=r(zqt,"roformer"),zqt.forEach(t),dHr=r(wGe," \u2014 "),Qee=n(wGe,"A",{href:!0});var Qqt=s(Qee);cHr=r(Qqt,"FlaxRoFormerForTokenClassification"),Qqt.forEach(t),fHr=r(wGe," (RoFormer model)"),wGe.forEach(t),mHr=i(To),Rw=n(To,"LI",{});var AGe=s(Rw);y0e=n(AGe,"STRONG",{});var Wqt=s(y0e);gHr=r(Wqt,"xlm-roberta"),Wqt.forEach(t),hHr=r(AGe," \u2014 "),Wee=n(AGe,"A",{href:!0});var Hqt=s(Wee);pHr=r(Hqt,"FlaxXLMRobertaForTokenClassification"),Hqt.forEach(t),_Hr=r(AGe," (XLM-RoBERTa model)"),AGe.forEach(t),To.forEach(t),uHr=i(mi),T(Pw.$$.fragment,mi),mi.forEach(t),fi.forEach(t),IVe=i(f),gf=n(f,"H2",{class:!0});var zze=s(gf);Bw=n(zze,"A",{id:!0,class:!0,href:!0});var Uqt=s(Bw);x0e=n(Uqt,"SPAN",{});var Jqt=s(x0e);T(b$.$$.fragment,Jqt),Jqt.forEach(t),Uqt.forEach(t),bHr=i(zze),$0e=n(zze,"SPAN",{});var Yqt=s($0e);vHr=r(Yqt,"FlaxAutoModelForMultipleChoice"),Yqt.forEach(t),zze.forEach(t),NVe=i(f),Mr=n(f,"DIV",{class:!0});var gi=s(Mr);T(v$.$$.fragment,gi),FHr=i(gi),hf=n(gi,"P",{});var ate=s(hf);THr=r(ate,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Hee=n(ate,"A",{href:!0});var Kqt=s(Hee);MHr=r(Kqt,"from_pretrained()"),Kqt.forEach(t),EHr=r(ate," class method or the "),Uee=n(ate,"A",{href:!0});var Zqt=s(Uee);CHr=r(Zqt,"from_config()"),Zqt.forEach(t),wHr=r(ate,` class
method.`),ate.forEach(t),AHr=i(gi),F$=n(gi,"P",{});var Qze=s(F$);LHr=r(Qze,"This class cannot be instantiated directly using "),k0e=n(Qze,"CODE",{});var ejt=s(k0e);yHr=r(ejt,"__init__()"),ejt.forEach(t),xHr=r(Qze," (throws an error)."),Qze.forEach(t),$Hr=i(gi),Kt=n(gi,"DIV",{class:!0});var uL=s(Kt);T(T$.$$.fragment,uL),kHr=i(uL),S0e=n(uL,"P",{});var ojt=s(S0e);SHr=r(ojt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),ojt.forEach(t),RHr=i(uL),pf=n(uL,"P",{});var nte=s(pf);PHr=r(nte,`Note:
Loading a model from its configuration file does `),R0e=n(nte,"STRONG",{});var rjt=s(R0e);BHr=r(rjt,"not"),rjt.forEach(t),IHr=r(nte,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jee=n(nte,"A",{href:!0});var tjt=s(Jee);NHr=r(tjt,"from_pretrained()"),tjt.forEach(t),qHr=r(nte," to load the model weights."),nte.forEach(t),jHr=i(uL),T(Iw.$$.fragment,uL),uL.forEach(t),DHr=i(gi),Jr=n(gi,"DIV",{class:!0});var hi=s(Jr);T(M$.$$.fragment,hi),GHr=i(hi),P0e=n(hi,"P",{});var ajt=s(P0e);OHr=r(ajt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),ajt.forEach(t),VHr=i(hi),yn=n(hi,"P",{});var bL=s(yn);XHr=r(bL,"The model class to instantiate is selected based on the "),B0e=n(bL,"CODE",{});var njt=s(B0e);zHr=r(njt,"model_type"),njt.forEach(t),QHr=r(bL,` property of the config object (either
passed as an argument or loaded from `),I0e=n(bL,"CODE",{});var sjt=s(I0e);WHr=r(sjt,"pretrained_model_name_or_path"),sjt.forEach(t),HHr=r(bL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N0e=n(bL,"CODE",{});var ljt=s(N0e);UHr=r(ljt,"pretrained_model_name_or_path"),ljt.forEach(t),JHr=r(bL,":"),bL.forEach(t),YHr=i(hi),Xe=n(hi,"UL",{});var Mo=s(Xe);Nw=n(Mo,"LI",{});var LGe=s(Nw);q0e=n(LGe,"STRONG",{});var ijt=s(q0e);KHr=r(ijt,"albert"),ijt.forEach(t),ZHr=r(LGe," \u2014 "),Yee=n(LGe,"A",{href:!0});var djt=s(Yee);eUr=r(djt,"FlaxAlbertForMultipleChoice"),djt.forEach(t),oUr=r(LGe," (ALBERT model)"),LGe.forEach(t),rUr=i(Mo),qw=n(Mo,"LI",{});var yGe=s(qw);j0e=n(yGe,"STRONG",{});var cjt=s(j0e);tUr=r(cjt,"bert"),cjt.forEach(t),aUr=r(yGe," \u2014 "),Kee=n(yGe,"A",{href:!0});var fjt=s(Kee);nUr=r(fjt,"FlaxBertForMultipleChoice"),fjt.forEach(t),sUr=r(yGe," (BERT model)"),yGe.forEach(t),lUr=i(Mo),jw=n(Mo,"LI",{});var xGe=s(jw);D0e=n(xGe,"STRONG",{});var mjt=s(D0e);iUr=r(mjt,"big_bird"),mjt.forEach(t),dUr=r(xGe," \u2014 "),Zee=n(xGe,"A",{href:!0});var gjt=s(Zee);cUr=r(gjt,"FlaxBigBirdForMultipleChoice"),gjt.forEach(t),fUr=r(xGe," (BigBird model)"),xGe.forEach(t),mUr=i(Mo),Dw=n(Mo,"LI",{});var $Ge=s(Dw);G0e=n($Ge,"STRONG",{});var hjt=s(G0e);gUr=r(hjt,"distilbert"),hjt.forEach(t),hUr=r($Ge," \u2014 "),eoe=n($Ge,"A",{href:!0});var pjt=s(eoe);pUr=r(pjt,"FlaxDistilBertForMultipleChoice"),pjt.forEach(t),_Ur=r($Ge," (DistilBERT model)"),$Ge.forEach(t),uUr=i(Mo),Gw=n(Mo,"LI",{});var kGe=s(Gw);O0e=n(kGe,"STRONG",{});var _jt=s(O0e);bUr=r(_jt,"electra"),_jt.forEach(t),vUr=r(kGe," \u2014 "),ooe=n(kGe,"A",{href:!0});var ujt=s(ooe);FUr=r(ujt,"FlaxElectraForMultipleChoice"),ujt.forEach(t),TUr=r(kGe," (ELECTRA model)"),kGe.forEach(t),MUr=i(Mo),Ow=n(Mo,"LI",{});var SGe=s(Ow);V0e=n(SGe,"STRONG",{});var bjt=s(V0e);EUr=r(bjt,"roberta"),bjt.forEach(t),CUr=r(SGe," \u2014 "),roe=n(SGe,"A",{href:!0});var vjt=s(roe);wUr=r(vjt,"FlaxRobertaForMultipleChoice"),vjt.forEach(t),AUr=r(SGe," (RoBERTa model)"),SGe.forEach(t),LUr=i(Mo),Vw=n(Mo,"LI",{});var RGe=s(Vw);X0e=n(RGe,"STRONG",{});var Fjt=s(X0e);yUr=r(Fjt,"roformer"),Fjt.forEach(t),xUr=r(RGe," \u2014 "),toe=n(RGe,"A",{href:!0});var Tjt=s(toe);$Ur=r(Tjt,"FlaxRoFormerForMultipleChoice"),Tjt.forEach(t),kUr=r(RGe," (RoFormer model)"),RGe.forEach(t),SUr=i(Mo),Xw=n(Mo,"LI",{});var PGe=s(Xw);z0e=n(PGe,"STRONG",{});var Mjt=s(z0e);RUr=r(Mjt,"xlm-roberta"),Mjt.forEach(t),PUr=r(PGe," \u2014 "),aoe=n(PGe,"A",{href:!0});var Ejt=s(aoe);BUr=r(Ejt,"FlaxXLMRobertaForMultipleChoice"),Ejt.forEach(t),IUr=r(PGe," (XLM-RoBERTa model)"),PGe.forEach(t),Mo.forEach(t),NUr=i(hi),T(zw.$$.fragment,hi),hi.forEach(t),gi.forEach(t),qVe=i(f),_f=n(f,"H2",{class:!0});var Wze=s(_f);Qw=n(Wze,"A",{id:!0,class:!0,href:!0});var Cjt=s(Qw);Q0e=n(Cjt,"SPAN",{});var wjt=s(Q0e);T(E$.$$.fragment,wjt),wjt.forEach(t),Cjt.forEach(t),qUr=i(Wze),W0e=n(Wze,"SPAN",{});var Ajt=s(W0e);jUr=r(Ajt,"FlaxAutoModelForNextSentencePrediction"),Ajt.forEach(t),Wze.forEach(t),jVe=i(f),Er=n(f,"DIV",{class:!0});var pi=s(Er);T(C$.$$.fragment,pi),DUr=i(pi),uf=n(pi,"P",{});var ste=s(uf);GUr=r(ste,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),noe=n(ste,"A",{href:!0});var Ljt=s(noe);OUr=r(Ljt,"from_pretrained()"),Ljt.forEach(t),VUr=r(ste," class method or the "),soe=n(ste,"A",{href:!0});var yjt=s(soe);XUr=r(yjt,"from_config()"),yjt.forEach(t),zUr=r(ste,` class
method.`),ste.forEach(t),QUr=i(pi),w$=n(pi,"P",{});var Hze=s(w$);WUr=r(Hze,"This class cannot be instantiated directly using "),H0e=n(Hze,"CODE",{});var xjt=s(H0e);HUr=r(xjt,"__init__()"),xjt.forEach(t),UUr=r(Hze," (throws an error)."),Hze.forEach(t),JUr=i(pi),Zt=n(pi,"DIV",{class:!0});var vL=s(Zt);T(A$.$$.fragment,vL),YUr=i(vL),U0e=n(vL,"P",{});var $jt=s(U0e);KUr=r($jt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),$jt.forEach(t),ZUr=i(vL),bf=n(vL,"P",{});var lte=s(bf);eJr=r(lte,`Note:
Loading a model from its configuration file does `),J0e=n(lte,"STRONG",{});var kjt=s(J0e);oJr=r(kjt,"not"),kjt.forEach(t),rJr=r(lte,` load the model weights. It only affects the
model\u2019s configuration. Use `),loe=n(lte,"A",{href:!0});var Sjt=s(loe);tJr=r(Sjt,"from_pretrained()"),Sjt.forEach(t),aJr=r(lte," to load the model weights."),lte.forEach(t),nJr=i(vL),T(Ww.$$.fragment,vL),vL.forEach(t),sJr=i(pi),Yr=n(pi,"DIV",{class:!0});var _i=s(Yr);T(L$.$$.fragment,_i),lJr=i(_i),Y0e=n(_i,"P",{});var Rjt=s(Y0e);iJr=r(Rjt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Rjt.forEach(t),dJr=i(_i),xn=n(_i,"P",{});var FL=s(xn);cJr=r(FL,"The model class to instantiate is selected based on the "),K0e=n(FL,"CODE",{});var Pjt=s(K0e);fJr=r(Pjt,"model_type"),Pjt.forEach(t),mJr=r(FL,` property of the config object (either
passed as an argument or loaded from `),Z0e=n(FL,"CODE",{});var Bjt=s(Z0e);gJr=r(Bjt,"pretrained_model_name_or_path"),Bjt.forEach(t),hJr=r(FL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ewe=n(FL,"CODE",{});var Ijt=s(ewe);pJr=r(Ijt,"pretrained_model_name_or_path"),Ijt.forEach(t),_Jr=r(FL,":"),FL.forEach(t),uJr=i(_i),owe=n(_i,"UL",{});var Njt=s(owe);Hw=n(Njt,"LI",{});var BGe=s(Hw);rwe=n(BGe,"STRONG",{});var qjt=s(rwe);bJr=r(qjt,"bert"),qjt.forEach(t),vJr=r(BGe," \u2014 "),ioe=n(BGe,"A",{href:!0});var jjt=s(ioe);FJr=r(jjt,"FlaxBertForNextSentencePrediction"),jjt.forEach(t),TJr=r(BGe," (BERT model)"),BGe.forEach(t),Njt.forEach(t),MJr=i(_i),T(Uw.$$.fragment,_i),_i.forEach(t),pi.forEach(t),DVe=i(f),vf=n(f,"H2",{class:!0});var Uze=s(vf);Jw=n(Uze,"A",{id:!0,class:!0,href:!0});var Djt=s(Jw);twe=n(Djt,"SPAN",{});var Gjt=s(twe);T(y$.$$.fragment,Gjt),Gjt.forEach(t),Djt.forEach(t),EJr=i(Uze),awe=n(Uze,"SPAN",{});var Ojt=s(awe);CJr=r(Ojt,"FlaxAutoModelForImageClassification"),Ojt.forEach(t),Uze.forEach(t),GVe=i(f),Cr=n(f,"DIV",{class:!0});var ui=s(Cr);T(x$.$$.fragment,ui),wJr=i(ui),Ff=n(ui,"P",{});var ite=s(Ff);AJr=r(ite,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),doe=n(ite,"A",{href:!0});var Vjt=s(doe);LJr=r(Vjt,"from_pretrained()"),Vjt.forEach(t),yJr=r(ite," class method or the "),coe=n(ite,"A",{href:!0});var Xjt=s(coe);xJr=r(Xjt,"from_config()"),Xjt.forEach(t),$Jr=r(ite,` class
method.`),ite.forEach(t),kJr=i(ui),$$=n(ui,"P",{});var Jze=s($$);SJr=r(Jze,"This class cannot be instantiated directly using "),nwe=n(Jze,"CODE",{});var zjt=s(nwe);RJr=r(zjt,"__init__()"),zjt.forEach(t),PJr=r(Jze," (throws an error)."),Jze.forEach(t),BJr=i(ui),ea=n(ui,"DIV",{class:!0});var TL=s(ea);T(k$.$$.fragment,TL),IJr=i(TL),swe=n(TL,"P",{});var Qjt=s(swe);NJr=r(Qjt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Qjt.forEach(t),qJr=i(TL),Tf=n(TL,"P",{});var dte=s(Tf);jJr=r(dte,`Note:
Loading a model from its configuration file does `),lwe=n(dte,"STRONG",{});var Wjt=s(lwe);DJr=r(Wjt,"not"),Wjt.forEach(t),GJr=r(dte,` load the model weights. It only affects the
model\u2019s configuration. Use `),foe=n(dte,"A",{href:!0});var Hjt=s(foe);OJr=r(Hjt,"from_pretrained()"),Hjt.forEach(t),VJr=r(dte," to load the model weights."),dte.forEach(t),XJr=i(TL),T(Yw.$$.fragment,TL),TL.forEach(t),zJr=i(ui),Kr=n(ui,"DIV",{class:!0});var bi=s(Kr);T(S$.$$.fragment,bi),QJr=i(bi),iwe=n(bi,"P",{});var Ujt=s(iwe);WJr=r(Ujt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Ujt.forEach(t),HJr=i(bi),$n=n(bi,"P",{});var ML=s($n);UJr=r(ML,"The model class to instantiate is selected based on the "),dwe=n(ML,"CODE",{});var Jjt=s(dwe);JJr=r(Jjt,"model_type"),Jjt.forEach(t),YJr=r(ML,` property of the config object (either
passed as an argument or loaded from `),cwe=n(ML,"CODE",{});var Yjt=s(cwe);KJr=r(Yjt,"pretrained_model_name_or_path"),Yjt.forEach(t),ZJr=r(ML,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fwe=n(ML,"CODE",{});var Kjt=s(fwe);eYr=r(Kjt,"pretrained_model_name_or_path"),Kjt.forEach(t),oYr=r(ML,":"),ML.forEach(t),rYr=i(bi),R$=n(bi,"UL",{});var Yze=s(R$);Kw=n(Yze,"LI",{});var IGe=s(Kw);mwe=n(IGe,"STRONG",{});var Zjt=s(mwe);tYr=r(Zjt,"beit"),Zjt.forEach(t),aYr=r(IGe," \u2014 "),moe=n(IGe,"A",{href:!0});var eDt=s(moe);nYr=r(eDt,"FlaxBeitForImageClassification"),eDt.forEach(t),sYr=r(IGe," (BEiT model)"),IGe.forEach(t),lYr=i(Yze),Zw=n(Yze,"LI",{});var NGe=s(Zw);gwe=n(NGe,"STRONG",{});var oDt=s(gwe);iYr=r(oDt,"vit"),oDt.forEach(t),dYr=r(NGe," \u2014 "),goe=n(NGe,"A",{href:!0});var rDt=s(goe);cYr=r(rDt,"FlaxViTForImageClassification"),rDt.forEach(t),fYr=r(NGe," (ViT model)"),NGe.forEach(t),Yze.forEach(t),mYr=i(bi),T(eA.$$.fragment,bi),bi.forEach(t),ui.forEach(t),OVe=i(f),Mf=n(f,"H2",{class:!0});var Kze=s(Mf);oA=n(Kze,"A",{id:!0,class:!0,href:!0});var tDt=s(oA);hwe=n(tDt,"SPAN",{});var aDt=s(hwe);T(P$.$$.fragment,aDt),aDt.forEach(t),tDt.forEach(t),gYr=i(Kze),pwe=n(Kze,"SPAN",{});var nDt=s(pwe);hYr=r(nDt,"FlaxAutoModelForVision2Seq"),nDt.forEach(t),Kze.forEach(t),VVe=i(f),wr=n(f,"DIV",{class:!0});var vi=s(wr);T(B$.$$.fragment,vi),pYr=i(vi),Ef=n(vi,"P",{});var cte=s(Ef);_Yr=r(cte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),hoe=n(cte,"A",{href:!0});var sDt=s(hoe);uYr=r(sDt,"from_pretrained()"),sDt.forEach(t),bYr=r(cte," class method or the "),poe=n(cte,"A",{href:!0});var lDt=s(poe);vYr=r(lDt,"from_config()"),lDt.forEach(t),FYr=r(cte,` class
method.`),cte.forEach(t),TYr=i(vi),I$=n(vi,"P",{});var Zze=s(I$);MYr=r(Zze,"This class cannot be instantiated directly using "),_we=n(Zze,"CODE",{});var iDt=s(_we);EYr=r(iDt,"__init__()"),iDt.forEach(t),CYr=r(Zze," (throws an error)."),Zze.forEach(t),wYr=i(vi),oa=n(vi,"DIV",{class:!0});var EL=s(oa);T(N$.$$.fragment,EL),AYr=i(EL),uwe=n(EL,"P",{});var dDt=s(uwe);LYr=r(dDt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),dDt.forEach(t),yYr=i(EL),Cf=n(EL,"P",{});var fte=s(Cf);xYr=r(fte,`Note:
Loading a model from its configuration file does `),bwe=n(fte,"STRONG",{});var cDt=s(bwe);$Yr=r(cDt,"not"),cDt.forEach(t),kYr=r(fte,` load the model weights. It only affects the
model\u2019s configuration. Use `),_oe=n(fte,"A",{href:!0});var fDt=s(_oe);SYr=r(fDt,"from_pretrained()"),fDt.forEach(t),RYr=r(fte," to load the model weights."),fte.forEach(t),PYr=i(EL),T(rA.$$.fragment,EL),EL.forEach(t),BYr=i(vi),Zr=n(vi,"DIV",{class:!0});var Fi=s(Zr);T(q$.$$.fragment,Fi),IYr=i(Fi),vwe=n(Fi,"P",{});var mDt=s(vwe);NYr=r(mDt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),mDt.forEach(t),qYr=i(Fi),kn=n(Fi,"P",{});var CL=s(kn);jYr=r(CL,"The model class to instantiate is selected based on the "),Fwe=n(CL,"CODE",{});var gDt=s(Fwe);DYr=r(gDt,"model_type"),gDt.forEach(t),GYr=r(CL,` property of the config object (either
passed as an argument or loaded from `),Twe=n(CL,"CODE",{});var hDt=s(Twe);OYr=r(hDt,"pretrained_model_name_or_path"),hDt.forEach(t),VYr=r(CL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mwe=n(CL,"CODE",{});var pDt=s(Mwe);XYr=r(pDt,"pretrained_model_name_or_path"),pDt.forEach(t),zYr=r(CL,":"),CL.forEach(t),QYr=i(Fi),Ewe=n(Fi,"UL",{});var _Dt=s(Ewe);tA=n(_Dt,"LI",{});var qGe=s(tA);Cwe=n(qGe,"STRONG",{});var uDt=s(Cwe);WYr=r(uDt,"vision-encoder-decoder"),uDt.forEach(t),HYr=r(qGe," \u2014 "),uoe=n(qGe,"A",{href:!0});var bDt=s(uoe);UYr=r(bDt,"FlaxVisionEncoderDecoderModel"),bDt.forEach(t),JYr=r(qGe," (Vision Encoder decoder model)"),qGe.forEach(t),_Dt.forEach(t),YYr=i(Fi),T(aA.$$.fragment,Fi),Fi.forEach(t),vi.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(COt)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(Rn,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.AutoConfig"),c(Bn,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.AutoModel"),c(In,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.AutoTokenizer"),c(Li,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertModel"),c(Sf,"id","extending-the-auto-classes"),c(Sf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Sf,"href","#extending-the-auto-classes"),c(yi,"class","relative group"),c(Pf,"id","transformers.AutoConfig"),c(Pf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Pf,"href","#transformers.AutoConfig"),c(xi,"class","relative group"),c(iS,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(dS,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertConfig"),c(cS,"href","/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartConfig"),c(fS,"href","/docs/transformers/pr_17573/en/model_doc/beit#transformers.BeitConfig"),c(mS,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertConfig"),c(gS,"href","/docs/transformers/pr_17573/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(hS,"href","/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdConfig"),c(pS,"href","/docs/transformers/pr_17573/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(_S,"href","/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(uS,"href","/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(bS,"href","/docs/transformers/pr_17573/en/model_doc/bloom#transformers.BloomConfig"),c(vS,"href","/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertConfig"),c(FS,"href","/docs/transformers/pr_17573/en/model_doc/canine#transformers.CanineConfig"),c(TS,"href","/docs/transformers/pr_17573/en/model_doc/clip#transformers.CLIPConfig"),c(MS,"href","/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertConfig"),c(ES,"href","/docs/transformers/pr_17573/en/model_doc/convnext#transformers.ConvNextConfig"),c(CS,"href","/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.CTRLConfig"),c(wS,"href","/docs/transformers/pr_17573/en/model_doc/cvt#transformers.CvtConfig"),c(AS,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(LS,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(yS,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(xS,"href","/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaConfig"),c($S,"href","/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(kS,"href","/docs/transformers/pr_17573/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(SS,"href","/docs/transformers/pr_17573/en/model_doc/deit#transformers.DeiTConfig"),c(RS,"href","/docs/transformers/pr_17573/en/model_doc/detr#transformers.DetrConfig"),c(PS,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertConfig"),c(BS,"href","/docs/transformers/pr_17573/en/model_doc/dpr#transformers.DPRConfig"),c(IS,"href","/docs/transformers/pr_17573/en/model_doc/dpt#transformers.DPTConfig"),c(NS,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraConfig"),c(qS,"href","/docs/transformers/pr_17573/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(jS,"href","/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertConfig"),c(DS,"href","/docs/transformers/pr_17573/en/model_doc/flava#transformers.FlavaConfig"),c(GS,"href","/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetConfig"),c(OS,"href","/docs/transformers/pr_17573/en/model_doc/fsmt#transformers.FSMTConfig"),c(VS,"href","/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelConfig"),c(XS,"href","/docs/transformers/pr_17573/en/model_doc/glpn#transformers.GLPNConfig"),c(zS,"href","/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2Config"),c(QS,"href","/docs/transformers/pr_17573/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(WS,"href","/docs/transformers/pr_17573/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(HS,"href","/docs/transformers/pr_17573/en/model_doc/gptj#transformers.GPTJConfig"),c(US,"href","/docs/transformers/pr_17573/en/model_doc/hubert#transformers.HubertConfig"),c(JS,"href","/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertConfig"),c(YS,"href","/docs/transformers/pr_17573/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(KS,"href","/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(ZS,"href","/docs/transformers/pr_17573/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(eR,"href","/docs/transformers/pr_17573/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(oR,"href","/docs/transformers/pr_17573/en/model_doc/led#transformers.LEDConfig"),c(rR,"href","/docs/transformers/pr_17573/en/model_doc/levit#transformers.LevitConfig"),c(tR,"href","/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerConfig"),c(aR,"href","/docs/transformers/pr_17573/en/model_doc/longt5#transformers.LongT5Config"),c(nR,"href","/docs/transformers/pr_17573/en/model_doc/luke#transformers.LukeConfig"),c(sR,"href","/docs/transformers/pr_17573/en/model_doc/lxmert#transformers.LxmertConfig"),c(lR,"href","/docs/transformers/pr_17573/en/model_doc/m2m_100#transformers.M2M100Config"),c(iR,"href","/docs/transformers/pr_17573/en/model_doc/marian#transformers.MarianConfig"),c(dR,"href","/docs/transformers/pr_17573/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(cR,"href","/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartConfig"),c(fR,"href","/docs/transformers/pr_17573/en/model_doc/mctct#transformers.MCTCTConfig"),c(mR,"href","/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(gR,"href","/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(hR,"href","/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetConfig"),c(pR,"href","/docs/transformers/pr_17573/en/model_doc/mt5#transformers.MT5Config"),c(_R,"href","/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaConfig"),c(uR,"href","/docs/transformers/pr_17573/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(bR,"href","/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(vR,"href","/docs/transformers/pr_17573/en/model_doc/opt#transformers.OPTConfig"),c(FR,"href","/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.PegasusConfig"),c(TR,"href","/docs/transformers/pr_17573/en/model_doc/perceiver#transformers.PerceiverConfig"),c(MR,"href","/docs/transformers/pr_17573/en/model_doc/plbart#transformers.PLBartConfig"),c(ER,"href","/docs/transformers/pr_17573/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(CR,"href","/docs/transformers/pr_17573/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(wR,"href","/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(AR,"href","/docs/transformers/pr_17573/en/model_doc/rag#transformers.RagConfig"),c(LR,"href","/docs/transformers/pr_17573/en/model_doc/realm#transformers.RealmConfig"),c(yR,"href","/docs/transformers/pr_17573/en/model_doc/reformer#transformers.ReformerConfig"),c(xR,"href","/docs/transformers/pr_17573/en/model_doc/regnet#transformers.RegNetConfig"),c($R,"href","/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertConfig"),c(kR,"href","/docs/transformers/pr_17573/en/model_doc/resnet#transformers.ResNetConfig"),c(SR,"href","/docs/transformers/pr_17573/en/model_doc/retribert#transformers.RetriBertConfig"),c(RR,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaConfig"),c(PR,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerConfig"),c(BR,"href","/docs/transformers/pr_17573/en/model_doc/segformer#transformers.SegformerConfig"),c(IR,"href","/docs/transformers/pr_17573/en/model_doc/sew#transformers.SEWConfig"),c(NR,"href","/docs/transformers/pr_17573/en/model_doc/sew-d#transformers.SEWDConfig"),c(qR,"href","/docs/transformers/pr_17573/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(jR,"href","/docs/transformers/pr_17573/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(DR,"href","/docs/transformers/pr_17573/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(GR,"href","/docs/transformers/pr_17573/en/model_doc/splinter#transformers.SplinterConfig"),c(OR,"href","/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(VR,"href","/docs/transformers/pr_17573/en/model_doc/swin#transformers.SwinConfig"),c(XR,"href","/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5Config"),c(zR,"href","/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasConfig"),c(QR,"href","/docs/transformers/pr_17573/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(WR,"href","/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(HR,"href","/docs/transformers/pr_17573/en/model_doc/trocr#transformers.TrOCRConfig"),c(UR,"href","/docs/transformers/pr_17573/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(JR,"href","/docs/transformers/pr_17573/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(YR,"href","/docs/transformers/pr_17573/en/model_doc/van#transformers.VanConfig"),c(KR,"href","/docs/transformers/pr_17573/en/model_doc/vilt#transformers.ViltConfig"),c(ZR,"href","/docs/transformers/pr_17573/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(eP,"href","/docs/transformers/pr_17573/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(oP,"href","/docs/transformers/pr_17573/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(rP,"href","/docs/transformers/pr_17573/en/model_doc/vit#transformers.ViTConfig"),c(tP,"href","/docs/transformers/pr_17573/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(aP,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(nP,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(sP,"href","/docs/transformers/pr_17573/en/model_doc/wavlm#transformers.WavLMConfig"),c(lP,"href","/docs/transformers/pr_17573/en/model_doc/xglm#transformers.XGLMConfig"),c(iP,"href","/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMConfig"),c(dP,"href","/docs/transformers/pr_17573/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(cP,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(fP,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(mP,"href","/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetConfig"),c(gP,"href","/docs/transformers/pr_17573/en/model_doc/yolos#transformers.YolosConfig"),c(hP,"href","/docs/transformers/pr_17573/en/model_doc/yoso#transformers.YosoConfig"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Og,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vg,"id","transformers.AutoTokenizer"),c(Vg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Vg,"href","#transformers.AutoTokenizer"),c(ki,"class","relative group"),c(pP,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(_P,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertTokenizer"),c(uP,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(bP,"href","/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartTokenizer"),c(vP,"href","/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartTokenizerFast"),c(FP,"href","/docs/transformers/pr_17573/en/model_doc/barthez#transformers.BarthezTokenizer"),c(TP,"href","/docs/transformers/pr_17573/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(MP,"href","/docs/transformers/pr_17573/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(EP,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertTokenizer"),c(CP,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertTokenizerFast"),c(wP,"href","/docs/transformers/pr_17573/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(AP,"href","/docs/transformers/pr_17573/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(LP,"href","/docs/transformers/pr_17573/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(yP,"href","/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(xP,"href","/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c($P,"href","/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(kP,"href","/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(SP,"href","/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(RP,"href","/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(PP,"href","/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(BP,"href","/docs/transformers/pr_17573/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(IP,"href","/docs/transformers/pr_17573/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(NP,"href","/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertTokenizer"),c(qP,"href","/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(jP,"href","/docs/transformers/pr_17573/en/model_doc/canine#transformers.CanineTokenizer"),c(DP,"href","/docs/transformers/pr_17573/en/model_doc/clip#transformers.CLIPTokenizer"),c(GP,"href","/docs/transformers/pr_17573/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(OP,"href","/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(VP,"href","/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(XP,"href","/docs/transformers/pr_17573/en/model_doc/cpm#transformers.CpmTokenizer"),c(zP,"href","/docs/transformers/pr_17573/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(QP,"href","/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(WP,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaTokenizer"),c(HP,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(UP,"href","/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaTokenizer"),c(JP,"href","/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(YP,"href","/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(KP,"href","/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(ZP,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(eB,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(oB,"href","/docs/transformers/pr_17573/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(rB,"href","/docs/transformers/pr_17573/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(tB,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraTokenizer"),c(aB,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(nB,"href","/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(sB,"href","/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetTokenizer"),c(lB,"href","/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(iB,"href","/docs/transformers/pr_17573/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(dB,"href","/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelTokenizer"),c(cB,"href","/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(fB,"href","/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(mB,"href","/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(gB,"href","/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(hB,"href","/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(pB,"href","/docs/transformers/pr_17573/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(_B,"href","/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(uB,"href","/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(bB,"href","/docs/transformers/pr_17573/en/model_doc/herbert#transformers.HerbertTokenizer"),c(vB,"href","/docs/transformers/pr_17573/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(FB,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(TB,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaTokenizer"),c(MB,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(EB,"href","/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(CB,"href","/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(wB,"href","/docs/transformers/pr_17573/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(AB,"href","/docs/transformers/pr_17573/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(LB,"href","/docs/transformers/pr_17573/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(yB,"href","/docs/transformers/pr_17573/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(xB,"href","/docs/transformers/pr_17573/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c($B,"href","/docs/transformers/pr_17573/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(kB,"href","/docs/transformers/pr_17573/en/model_doc/led#transformers.LEDTokenizer"),c(SB,"href","/docs/transformers/pr_17573/en/model_doc/led#transformers.LEDTokenizerFast"),c(RB,"href","/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerTokenizer"),c(PB,"href","/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(BB,"href","/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5Tokenizer"),c(IB,"href","/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5TokenizerFast"),c(NB,"href","/docs/transformers/pr_17573/en/model_doc/luke#transformers.LukeTokenizer"),c(qB,"href","/docs/transformers/pr_17573/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(jB,"href","/docs/transformers/pr_17573/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(DB,"href","/docs/transformers/pr_17573/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(GB,"href","/docs/transformers/pr_17573/en/model_doc/marian#transformers.MarianTokenizer"),c(OB,"href","/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartTokenizer"),c(VB,"href","/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(XB,"href","/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(zB,"href","/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(QB,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertTokenizer"),c(WB,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertTokenizerFast"),c(HB,"href","/docs/transformers/pr_17573/en/model_doc/mluke#transformers.MLukeTokenizer"),c(UB,"href","/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(JB,"href","/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(YB,"href","/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(KB,"href","/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(ZB,"href","/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5Tokenizer"),c(eI,"href","/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5TokenizerFast"),c(oI,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertTokenizer"),c(rI,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertTokenizerFast"),c(tI,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertTokenizer"),c(aI,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(nI,"href","/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(sI,"href","/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(lI,"href","/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(iI,"href","/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(dI,"href","/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(cI,"href","/docs/transformers/pr_17573/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(fI,"href","/docs/transformers/pr_17573/en/model_doc/phobert#transformers.PhobertTokenizer"),c(mI,"href","/docs/transformers/pr_17573/en/model_doc/plbart#transformers.PLBartTokenizer"),c(gI,"href","/docs/transformers/pr_17573/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(hI,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertTokenizer"),c(pI,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertTokenizerFast"),c(_I,"href","/docs/transformers/pr_17573/en/model_doc/rag#transformers.RagTokenizer"),c(uI,"href","/docs/transformers/pr_17573/en/model_doc/realm#transformers.RealmTokenizer"),c(bI,"href","/docs/transformers/pr_17573/en/model_doc/realm#transformers.RealmTokenizerFast"),c(vI,"href","/docs/transformers/pr_17573/en/model_doc/reformer#transformers.ReformerTokenizer"),c(FI,"href","/docs/transformers/pr_17573/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(TI,"href","/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertTokenizer"),c(MI,"href","/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(EI,"href","/docs/transformers/pr_17573/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(CI,"href","/docs/transformers/pr_17573/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(wI,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaTokenizer"),c(AI,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(LI,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(yI,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(xI,"href","/docs/transformers/pr_17573/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c($I,"href","/docs/transformers/pr_17573/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(kI,"href","/docs/transformers/pr_17573/en/model_doc/splinter#transformers.SplinterTokenizer"),c(SI,"href","/docs/transformers/pr_17573/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(RI,"href","/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(PI,"href","/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(BI,"href","/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5Tokenizer"),c(II,"href","/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5TokenizerFast"),c(NI,"href","/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasTokenizer"),c(qI,"href","/docs/transformers/pr_17573/en/model_doc/tapex#transformers.TapexTokenizer"),c(jI,"href","/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(DI,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertTokenizer"),c(GI,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertTokenizerFast"),c(OI,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertTokenizer"),c(VI,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertTokenizerFast"),c(XI,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(zI,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(QI,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(WI,"href","/docs/transformers/pr_17573/en/model_doc/xglm#transformers.XGLMTokenizer"),c(HI,"href","/docs/transformers/pr_17573/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(UI,"href","/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMTokenizer"),c(JI,"href","/docs/transformers/pr_17573/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(YI,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(KI,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(ZI,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaTokenizer"),c(eN,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(oN,"href","/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(rN,"href","/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(tN,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertTokenizer"),c(aN,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ch,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wh,"id","transformers.AutoFeatureExtractor"),c(wh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(wh,"href","#transformers.AutoFeatureExtractor"),c(Si,"class","relative group"),c(nN,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(sN,"href","/docs/transformers/pr_17573/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(lN,"href","/docs/transformers/pr_17573/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(iN,"href","/docs/transformers/pr_17573/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(dN,"href","/docs/transformers/pr_17573/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(cN,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(fN,"href","/docs/transformers/pr_17573/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(mN,"href","/docs/transformers/pr_17573/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(gN,"href","/docs/transformers/pr_17573/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(hN,"href","/docs/transformers/pr_17573/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(pN,"href","/docs/transformers/pr_17573/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(_N,"href","/docs/transformers/pr_17573/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(uN,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(bN,"href","/docs/transformers/pr_17573/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(vN,"href","/docs/transformers/pr_17573/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(FN,"href","/docs/transformers/pr_17573/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(TN,"href","/docs/transformers/pr_17573/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(MN,"href","/docs/transformers/pr_17573/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(EN,"href","/docs/transformers/pr_17573/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(CN,"href","/docs/transformers/pr_17573/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(wN,"href","/docs/transformers/pr_17573/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(AN,"href","/docs/transformers/pr_17573/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(LN,"href","/docs/transformers/pr_17573/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(yN,"href","/docs/transformers/pr_17573/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(xN,"href","/docs/transformers/pr_17573/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c($N,"href","/docs/transformers/pr_17573/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(kN,"href","/docs/transformers/pr_17573/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(SN,"href","/docs/transformers/pr_17573/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(RN,"href","/docs/transformers/pr_17573/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(PN,"href","/docs/transformers/pr_17573/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(BN,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(IN,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(NN,"href","/docs/transformers/pr_17573/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lp,"id","transformers.AutoProcessor"),c(lp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lp,"href","#transformers.AutoProcessor"),c(Ri,"class","relative group"),c(qN,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(jN,"href","/docs/transformers/pr_17573/en/model_doc/clip#transformers.CLIPProcessor"),c(DN,"href","/docs/transformers/pr_17573/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(GN,"href","/docs/transformers/pr_17573/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(ON,"href","/docs/transformers/pr_17573/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(VN,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(XN,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(zN,"href","/docs/transformers/pr_17573/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(QN,"href","/docs/transformers/pr_17573/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(WN,"href","/docs/transformers/pr_17573/en/model_doc/trocr#transformers.TrOCRProcessor"),c(HN,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(UN,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(JN,"href","/docs/transformers/pr_17573/en/model_doc/vilt#transformers.ViltProcessor"),c(YN,"href","/docs/transformers/pr_17573/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(KN,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(ZN,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(eq,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yp,"id","transformers.AutoModel"),c(yp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yp,"href","#transformers.AutoModel"),c(Bi,"class","relative group"),c(oq,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rq,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tq,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aq,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertModel"),c(nq,"href","/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartModel"),c(sq,"href","/docs/transformers/pr_17573/en/model_doc/beit#transformers.BeitModel"),c(lq,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertModel"),c(iq,"href","/docs/transformers/pr_17573/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(dq,"href","/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdModel"),c(cq,"href","/docs/transformers/pr_17573/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(fq,"href","/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(mq,"href","/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(gq,"href","/docs/transformers/pr_17573/en/model_doc/bloom#transformers.BloomModel"),c(hq,"href","/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertModel"),c(pq,"href","/docs/transformers/pr_17573/en/model_doc/canine#transformers.CanineModel"),c(_q,"href","/docs/transformers/pr_17573/en/model_doc/clip#transformers.CLIPModel"),c(uq,"href","/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertModel"),c(bq,"href","/docs/transformers/pr_17573/en/model_doc/convnext#transformers.ConvNextModel"),c(vq,"href","/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.CTRLModel"),c(Fq,"href","/docs/transformers/pr_17573/en/model_doc/cvt#transformers.CvtModel"),c(Tq,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(Mq,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(Eq,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(Cq,"href","/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaModel"),c(wq,"href","/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(Aq,"href","/docs/transformers/pr_17573/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(Lq,"href","/docs/transformers/pr_17573/en/model_doc/deit#transformers.DeiTModel"),c(yq,"href","/docs/transformers/pr_17573/en/model_doc/detr#transformers.DetrModel"),c(xq,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertModel"),c($q,"href","/docs/transformers/pr_17573/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(kq,"href","/docs/transformers/pr_17573/en/model_doc/dpt#transformers.DPTModel"),c(Sq,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraModel"),c(Rq,"href","/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertModel"),c(Pq,"href","/docs/transformers/pr_17573/en/model_doc/flava#transformers.FlavaModel"),c(Bq,"href","/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetModel"),c(Iq,"href","/docs/transformers/pr_17573/en/model_doc/fsmt#transformers.FSMTModel"),c(Nq,"href","/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelModel"),c(qq,"href","/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelBaseModel"),c(jq,"href","/docs/transformers/pr_17573/en/model_doc/glpn#transformers.GLPNModel"),c(Dq,"href","/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2Model"),c(Gq,"href","/docs/transformers/pr_17573/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(Oq,"href","/docs/transformers/pr_17573/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(Vq,"href","/docs/transformers/pr_17573/en/model_doc/gptj#transformers.GPTJModel"),c(Xq,"href","/docs/transformers/pr_17573/en/model_doc/hubert#transformers.HubertModel"),c(zq,"href","/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertModel"),c(Qq,"href","/docs/transformers/pr_17573/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(Wq,"href","/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(Hq,"href","/docs/transformers/pr_17573/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(Uq,"href","/docs/transformers/pr_17573/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(Jq,"href","/docs/transformers/pr_17573/en/model_doc/led#transformers.LEDModel"),c(Yq,"href","/docs/transformers/pr_17573/en/model_doc/levit#transformers.LevitModel"),c(Kq,"href","/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerModel"),c(Zq,"href","/docs/transformers/pr_17573/en/model_doc/longt5#transformers.LongT5Model"),c(ej,"href","/docs/transformers/pr_17573/en/model_doc/luke#transformers.LukeModel"),c(oj,"href","/docs/transformers/pr_17573/en/model_doc/lxmert#transformers.LxmertModel"),c(rj,"href","/docs/transformers/pr_17573/en/model_doc/m2m_100#transformers.M2M100Model"),c(tj,"href","/docs/transformers/pr_17573/en/model_doc/marian#transformers.MarianModel"),c(aj,"href","/docs/transformers/pr_17573/en/model_doc/maskformer#transformers.MaskFormerModel"),c(nj,"href","/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartModel"),c(sj,"href","/docs/transformers/pr_17573/en/model_doc/mctct#transformers.MCTCTModel"),c(lj,"href","/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(ij,"href","/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertModel"),c(dj,"href","/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetModel"),c(cj,"href","/docs/transformers/pr_17573/en/model_doc/mt5#transformers.MT5Model"),c(fj,"href","/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaModel"),c(mj,"href","/docs/transformers/pr_17573/en/model_doc/nystromformer#transformers.NystromformerModel"),c(gj,"href","/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(hj,"href","/docs/transformers/pr_17573/en/model_doc/opt#transformers.OPTModel"),c(pj,"href","/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.PegasusModel"),c(_j,"href","/docs/transformers/pr_17573/en/model_doc/perceiver#transformers.PerceiverModel"),c(uj,"href","/docs/transformers/pr_17573/en/model_doc/plbart#transformers.PLBartModel"),c(bj,"href","/docs/transformers/pr_17573/en/model_doc/poolformer#transformers.PoolFormerModel"),c(vj,"href","/docs/transformers/pr_17573/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(Fj,"href","/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertModel"),c(Tj,"href","/docs/transformers/pr_17573/en/model_doc/reformer#transformers.ReformerModel"),c(Mj,"href","/docs/transformers/pr_17573/en/model_doc/regnet#transformers.RegNetModel"),c(Ej,"href","/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertModel"),c(Cj,"href","/docs/transformers/pr_17573/en/model_doc/resnet#transformers.ResNetModel"),c(wj,"href","/docs/transformers/pr_17573/en/model_doc/retribert#transformers.RetriBertModel"),c(Aj,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaModel"),c(Lj,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerModel"),c(yj,"href","/docs/transformers/pr_17573/en/model_doc/segformer#transformers.SegformerModel"),c(xj,"href","/docs/transformers/pr_17573/en/model_doc/sew#transformers.SEWModel"),c($j,"href","/docs/transformers/pr_17573/en/model_doc/sew-d#transformers.SEWDModel"),c(kj,"href","/docs/transformers/pr_17573/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(Sj,"href","/docs/transformers/pr_17573/en/model_doc/splinter#transformers.SplinterModel"),c(Rj,"href","/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(Pj,"href","/docs/transformers/pr_17573/en/model_doc/swin#transformers.SwinModel"),c(Bj,"href","/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5Model"),c(Ij,"href","/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasModel"),c(Nj,"href","/docs/transformers/pr_17573/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(qj,"href","/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(jj,"href","/docs/transformers/pr_17573/en/model_doc/unispeech#transformers.UniSpeechModel"),c(Dj,"href","/docs/transformers/pr_17573/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(Gj,"href","/docs/transformers/pr_17573/en/model_doc/van#transformers.VanModel"),c(Oj,"href","/docs/transformers/pr_17573/en/model_doc/vilt#transformers.ViltModel"),c(Vj,"href","/docs/transformers/pr_17573/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(Xj,"href","/docs/transformers/pr_17573/en/model_doc/visual_bert#transformers.VisualBertModel"),c(zj,"href","/docs/transformers/pr_17573/en/model_doc/vit#transformers.ViTModel"),c(Qj,"href","/docs/transformers/pr_17573/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(Wj,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(Hj,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(Uj,"href","/docs/transformers/pr_17573/en/model_doc/wavlm#transformers.WavLMModel"),c(Jj,"href","/docs/transformers/pr_17573/en/model_doc/xglm#transformers.XGLMModel"),c(Yj,"href","/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMModel"),c(Kj,"href","/docs/transformers/pr_17573/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(Zj,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(eD,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(oD,"href","/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetModel"),c(rD,"href","/docs/transformers/pr_17573/en/model_doc/yolos#transformers.YolosModel"),c(tD,"href","/docs/transformers/pr_17573/en/model_doc/yoso#transformers.YosoModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($u,"id","transformers.AutoModelForPreTraining"),c($u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($u,"href","#transformers.AutoModelForPreTraining"),c(qi,"class","relative group"),c(aD,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nD,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sD,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lD,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertForPreTraining"),c(iD,"href","/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(dD,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertForPreTraining"),c(cD,"href","/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(fD,"href","/docs/transformers/pr_17573/en/model_doc/bloom#transformers.BloomForCausalLM"),c(mD,"href","/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(gD,"href","/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(hD,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(pD,"href","/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(_D,"href","/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(uD,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(bD,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraForPreTraining"),c(vD,"href","/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(FD,"href","/docs/transformers/pr_17573/en/model_doc/flava#transformers.FlavaForPreTraining"),c(TD,"href","/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetForPreTraining"),c(MD,"href","/docs/transformers/pr_17573/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(ED,"href","/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(CD,"href","/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(wD,"href","/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(AD,"href","/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(LD,"href","/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(yD,"href","/docs/transformers/pr_17573/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(xD,"href","/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c($D,"href","/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(kD,"href","/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(SD,"href","/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(RD,"href","/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(PD,"href","/docs/transformers/pr_17573/en/model_doc/retribert#transformers.RetriBertModel"),c(BD,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(ID,"href","/docs/transformers/pr_17573/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(ND,"href","/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(qD,"href","/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(jD,"href","/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(DD,"href","/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(GD,"href","/docs/transformers/pr_17573/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(OD,"href","/docs/transformers/pr_17573/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(VD,"href","/docs/transformers/pr_17573/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(XD,"href","/docs/transformers/pr_17573/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(zD,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(QD,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(WD,"href","/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(HD,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(UD,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(JD,"href","/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C1,"id","transformers.AutoModelForCausalLM"),c(C1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C1,"href","#transformers.AutoModelForCausalLM"),c(Gi,"class","relative group"),c(YD,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KD,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ZD,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eG,"href","/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartForCausalLM"),c(oG,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertLMHeadModel"),c(rG,"href","/docs/transformers/pr_17573/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(tG,"href","/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(aG,"href","/docs/transformers/pr_17573/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(nG,"href","/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(sG,"href","/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(lG,"href","/docs/transformers/pr_17573/en/model_doc/bloom#transformers.BloomForCausalLM"),c(iG,"href","/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(dG,"href","/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(cG,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(fG,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraForCausalLM"),c(mG,"href","/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(gG,"href","/docs/transformers/pr_17573/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(hG,"href","/docs/transformers/pr_17573/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(pG,"href","/docs/transformers/pr_17573/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(_G,"href","/docs/transformers/pr_17573/en/model_doc/marian#transformers.MarianForCausalLM"),c(uG,"href","/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartForCausalLM"),c(bG,"href","/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(vG,"href","/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(FG,"href","/docs/transformers/pr_17573/en/model_doc/opt#transformers.OPTForCausalLM"),c(TG,"href","/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(MG,"href","/docs/transformers/pr_17573/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(EG,"href","/docs/transformers/pr_17573/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(CG,"href","/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(wG,"href","/docs/transformers/pr_17573/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(AG,"href","/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(LG,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(yG,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(xG,"href","/docs/transformers/pr_17573/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c($G,"href","/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(kG,"href","/docs/transformers/pr_17573/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(SG,"href","/docs/transformers/pr_17573/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(RG,"href","/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(PG,"href","/docs/transformers/pr_17573/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(BG,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(IG,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(NG,"href","/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m7,"id","transformers.AutoModelForMaskedLM"),c(m7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m7,"href","#transformers.AutoModelForMaskedLM"),c(Xi,"class","relative group"),c(qG,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jG,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DG,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GG,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(OG,"href","/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(VG,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertForMaskedLM"),c(XG,"href","/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(zG,"href","/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(QG,"href","/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(WG,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(HG,"href","/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(UG,"href","/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(JG,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(YG,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(KG,"href","/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(ZG,"href","/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(eO,"href","/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(oO,"href","/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(rO,"href","/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(tO,"href","/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(aO,"href","/docs/transformers/pr_17573/en/model_doc/luke#transformers.LukeForMaskedLM"),c(nO,"href","/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(sO,"href","/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(lO,"href","/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(iO,"href","/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(dO,"href","/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(cO,"href","/docs/transformers/pr_17573/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(fO,"href","/docs/transformers/pr_17573/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(mO,"href","/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(gO,"href","/docs/transformers/pr_17573/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(hO,"href","/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(pO,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(_O,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(uO,"href","/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(bO,"href","/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(vO,"href","/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(FO,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(TO,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(MO,"href","/docs/transformers/pr_17573/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z7,"id","transformers.AutoModelForSeq2SeqLM"),c(Z7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z7,"href","#transformers.AutoModelForSeq2SeqLM"),c(Wi,"class","relative group"),c(EO,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CO,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wO,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AO,"href","/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(LO,"href","/docs/transformers/pr_17573/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(yO,"href","/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(xO,"href","/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c($O,"href","/docs/transformers/pr_17573/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(kO,"href","/docs/transformers/pr_17573/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(SO,"href","/docs/transformers/pr_17573/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(RO,"href","/docs/transformers/pr_17573/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(PO,"href","/docs/transformers/pr_17573/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(BO,"href","/docs/transformers/pr_17573/en/model_doc/marian#transformers.MarianMTModel"),c(IO,"href","/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(NO,"href","/docs/transformers/pr_17573/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(qO,"href","/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(jO,"href","/docs/transformers/pr_17573/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(DO,"href","/docs/transformers/pr_17573/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(GO,"href","/docs/transformers/pr_17573/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(OO,"href","/docs/transformers/pr_17573/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(F2,"id","transformers.AutoModelForSequenceClassification"),c(F2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(F2,"href","#transformers.AutoModelForSequenceClassification"),c(Ji,"class","relative group"),c(VO,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(XO,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zO,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QO,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(WO,"href","/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartForSequenceClassification"),c(HO,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertForSequenceClassification"),c(UO,"href","/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(JO,"href","/docs/transformers/pr_17573/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(YO,"href","/docs/transformers/pr_17573/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(KO,"href","/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(ZO,"href","/docs/transformers/pr_17573/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(eV,"href","/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(oV,"href","/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(rV,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(tV,"href","/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(aV,"href","/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(nV,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(sV,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(lV,"href","/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(iV,"href","/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(dV,"href","/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(cV,"href","/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(fV,"href","/docs/transformers/pr_17573/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(mV,"href","/docs/transformers/pr_17573/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(gV,"href","/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(hV,"href","/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(pV,"href","/docs/transformers/pr_17573/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(_V,"href","/docs/transformers/pr_17573/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(uV,"href","/docs/transformers/pr_17573/en/model_doc/led#transformers.LEDForSequenceClassification"),c(bV,"href","/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(vV,"href","/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(FV,"href","/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(TV,"href","/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(MV,"href","/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(EV,"href","/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(CV,"href","/docs/transformers/pr_17573/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(wV,"href","/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(AV,"href","/docs/transformers/pr_17573/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(LV,"href","/docs/transformers/pr_17573/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(yV,"href","/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(xV,"href","/docs/transformers/pr_17573/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c($V,"href","/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(kV,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(SV,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(RV,"href","/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(PV,"href","/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(BV,"href","/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(IV,"href","/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(NV,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(qV,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(jV,"href","/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(DV,"href","/docs/transformers/pr_17573/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vb,"id","transformers.AutoModelForMultipleChoice"),c(vb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(vb,"href","#transformers.AutoModelForMultipleChoice"),c(Zi,"class","relative group"),c(GV,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OV,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VV,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XV,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(zV,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertForMultipleChoice"),c(QV,"href","/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(WV,"href","/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(HV,"href","/docs/transformers/pr_17573/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(UV,"href","/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(JV,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(YV,"href","/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(KV,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(ZV,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(eX,"href","/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(oX,"href","/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(rX,"href","/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(tX,"href","/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(aX,"href","/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(nX,"href","/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(sX,"href","/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(lX,"href","/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(iX,"href","/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c(dX,"href","/docs/transformers/pr_17573/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(cX,"href","/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(fX,"href","/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(mX,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(gX,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(hX,"href","/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(pX,"href","/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(_X,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(uX,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(bX,"href","/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(vX,"href","/docs/transformers/pr_17573/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zb,"id","transformers.AutoModelForNextSentencePrediction"),c(Zb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Zb,"href","#transformers.AutoModelForNextSentencePrediction"),c(rd,"class","relative group"),c(FX,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TX,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MX,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EX,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(CX,"href","/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(wX,"href","/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(AX,"href","/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(LX,"href","/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(yX,"href","/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(d5,"id","transformers.AutoModelForTokenClassification"),c(d5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(d5,"href","#transformers.AutoModelForTokenClassification"),c(nd,"class","relative group"),c(xX,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($X,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kX,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SX,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(RX,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertForTokenClassification"),c(PX,"href","/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(BX,"href","/docs/transformers/pr_17573/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(IX,"href","/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(NX,"href","/docs/transformers/pr_17573/en/model_doc/canine#transformers.CanineForTokenClassification"),c(qX,"href","/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(jX,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(DX,"href","/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(GX,"href","/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(OX,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(VX,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(XX,"href","/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(zX,"href","/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(QX,"href","/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(WX,"href","/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(HX,"href","/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(UX,"href","/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(JX,"href","/docs/transformers/pr_17573/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(YX,"href","/docs/transformers/pr_17573/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(KX,"href","/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(ZX,"href","/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(ez,"href","/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(oz,"href","/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(rz,"href","/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c(tz,"href","/docs/transformers/pr_17573/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(az,"href","/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(nz,"href","/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(sz,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(lz,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(iz,"href","/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(dz,"href","/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(cz,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(fz,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(mz,"href","/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(gz,"href","/docs/transformers/pr_17573/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(U5,"id","transformers.AutoModelForQuestionAnswering"),c(U5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(U5,"href","#transformers.AutoModelForQuestionAnswering"),c(id,"class","relative group"),c(hz,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pz,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_z,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uz,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(bz,"href","/docs/transformers/pr_17573/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(vz,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(Fz,"href","/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(Tz,"href","/docs/transformers/pr_17573/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(Mz,"href","/docs/transformers/pr_17573/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(Ez,"href","/docs/transformers/pr_17573/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(Cz,"href","/docs/transformers/pr_17573/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(wz,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(Az,"href","/docs/transformers/pr_17573/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(Lz,"href","/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(yz,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(xz,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c($z,"href","/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(kz,"href","/docs/transformers/pr_17573/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(Sz,"href","/docs/transformers/pr_17573/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(Rz,"href","/docs/transformers/pr_17573/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(Pz,"href","/docs/transformers/pr_17573/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(Bz,"href","/docs/transformers/pr_17573/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(Iz,"href","/docs/transformers/pr_17573/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(Nz,"href","/docs/transformers/pr_17573/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(qz,"href","/docs/transformers/pr_17573/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(jz,"href","/docs/transformers/pr_17573/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(Dz,"href","/docs/transformers/pr_17573/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(Gz,"href","/docs/transformers/pr_17573/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(Oz,"href","/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(Vz,"href","/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(Xz,"href","/docs/transformers/pr_17573/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(zz,"href","/docs/transformers/pr_17573/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(Qz,"href","/docs/transformers/pr_17573/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(Wz,"href","/docs/transformers/pr_17573/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(Hz,"href","/docs/transformers/pr_17573/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(Uz,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(Jz,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(Yz,"href","/docs/transformers/pr_17573/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(Kz,"href","/docs/transformers/pr_17573/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(Zz,"href","/docs/transformers/pr_17573/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(eQ,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(oQ,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(rQ,"href","/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(tQ,"href","/docs/transformers/pr_17573/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Dv,"id","transformers.AutoModelForTableQuestionAnswering"),c(Dv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Dv,"href","#transformers.AutoModelForTableQuestionAnswering"),c(fd,"class","relative group"),c(aQ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nQ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sQ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lQ,"href","/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zv,"id","transformers.AutoModelForImageClassification"),c(zv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zv,"href","#transformers.AutoModelForImageClassification"),c(hd,"class","relative group"),c(iQ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dQ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cQ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fQ,"href","/docs/transformers/pr_17573/en/model_doc/beit#transformers.BeitForImageClassification"),c(mQ,"href","/docs/transformers/pr_17573/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(gQ,"href","/docs/transformers/pr_17573/en/model_doc/cvt#transformers.CvtForImageClassification"),c(hQ,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(pQ,"href","/docs/transformers/pr_17573/en/model_doc/deit#transformers.DeiTForImageClassification"),c(_Q,"href","/docs/transformers/pr_17573/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(uQ,"href","/docs/transformers/pr_17573/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(bQ,"href","/docs/transformers/pr_17573/en/model_doc/levit#transformers.LevitForImageClassification"),c(vQ,"href","/docs/transformers/pr_17573/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(FQ,"href","/docs/transformers/pr_17573/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(TQ,"href","/docs/transformers/pr_17573/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(MQ,"href","/docs/transformers/pr_17573/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(EQ,"href","/docs/transformers/pr_17573/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(CQ,"href","/docs/transformers/pr_17573/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(wQ,"href","/docs/transformers/pr_17573/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(AQ,"href","/docs/transformers/pr_17573/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(LQ,"href","/docs/transformers/pr_17573/en/model_doc/swin#transformers.SwinForImageClassification"),c(yQ,"href","/docs/transformers/pr_17573/en/model_doc/van#transformers.VanForImageClassification"),c(xQ,"href","/docs/transformers/pr_17573/en/model_doc/vit#transformers.ViTForImageClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(l3,"id","transformers.AutoModelForVision2Seq"),c(l3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(l3,"href","#transformers.AutoModelForVision2Seq"),c(ud,"class","relative group"),c($Q,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kQ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SQ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RQ,"href","/docs/transformers/pr_17573/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m3,"id","transformers.AutoModelForVisualQuestionAnswering"),c(m3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m3,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(Fd,"class","relative group"),c(PQ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BQ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IQ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NQ,"href","/docs/transformers/pr_17573/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(u3,"id","transformers.AutoModelForAudioClassification"),c(u3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(u3,"href","#transformers.AutoModelForAudioClassification"),c(Ed,"class","relative group"),c(qQ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jQ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DQ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GQ,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(OQ,"href","/docs/transformers/pr_17573/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(VQ,"href","/docs/transformers/pr_17573/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(XQ,"href","/docs/transformers/pr_17573/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(zQ,"href","/docs/transformers/pr_17573/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(QQ,"href","/docs/transformers/pr_17573/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(WQ,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(HQ,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(UQ,"href","/docs/transformers/pr_17573/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($3,"id","transformers.AutoModelForAudioFrameClassification"),c($3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($3,"href","#transformers.AutoModelForAudioFrameClassification"),c(Ad,"class","relative group"),c(JQ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(YQ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(KQ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZQ,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(eW,"href","/docs/transformers/pr_17573/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(oW,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(rW,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(tW,"href","/docs/transformers/pr_17573/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(j3,"id","transformers.AutoModelForCTC"),c(j3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(j3,"href","#transformers.AutoModelForCTC"),c(xd,"class","relative group"),c(aW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lW,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(iW,"href","/docs/transformers/pr_17573/en/model_doc/hubert#transformers.HubertForCTC"),c(dW,"href","/docs/transformers/pr_17573/en/model_doc/mctct#transformers.MCTCTForCTC"),c(cW,"href","/docs/transformers/pr_17573/en/model_doc/sew#transformers.SEWForCTC"),c(fW,"href","/docs/transformers/pr_17573/en/model_doc/sew-d#transformers.SEWDForCTC"),c(mW,"href","/docs/transformers/pr_17573/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(gW,"href","/docs/transformers/pr_17573/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(hW,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(pW,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(_W,"href","/docs/transformers/pr_17573/en/model_doc/wavlm#transformers.WavLMForCTC"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z3,"id","transformers.AutoModelForSpeechSeq2Seq"),c(Z3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z3,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Sd,"class","relative group"),c(uW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FW,"href","/docs/transformers/pr_17573/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(TW,"href","/docs/transformers/pr_17573/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nF,"id","transformers.AutoModelForAudioXVector"),c(nF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(nF,"href","#transformers.AutoModelForAudioXVector"),c(Bd,"class","relative group"),c(MW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(EW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(CW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wW,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(AW,"href","/docs/transformers/pr_17573/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(LW,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(yW,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(xW,"href","/docs/transformers/pr_17573/en/model_doc/wavlm#transformers.WavLMForXVector"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hF,"id","transformers.AutoModelForMaskedImageModeling"),c(hF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hF,"href","#transformers.AutoModelForMaskedImageModeling"),c(qd,"class","relative group"),c($W,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RW,"href","/docs/transformers/pr_17573/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(PW,"href","/docs/transformers/pr_17573/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(BW,"href","/docs/transformers/pr_17573/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TF,"id","transformers.AutoModelForObjectDetection"),c(TF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(TF,"href","#transformers.AutoModelForObjectDetection"),c(Od,"class","relative group"),c(IW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jW,"href","/docs/transformers/pr_17573/en/model_doc/detr#transformers.DetrForObjectDetection"),c(DW,"href","/docs/transformers/pr_17573/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LF,"id","transformers.AutoModelForImageSegmentation"),c(LF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(LF,"href","#transformers.AutoModelForImageSegmentation"),c(zd,"class","relative group"),c(GW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XW,"href","/docs/transformers/pr_17573/en/model_doc/detr#transformers.DetrForSegmentation"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SF,"id","transformers.AutoModelForSemanticSegmentation"),c(SF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(SF,"href","#transformers.AutoModelForSemanticSegmentation"),c(Hd,"class","relative group"),c(zW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HW,"href","/docs/transformers/pr_17573/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(UW,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(JW,"href","/docs/transformers/pr_17573/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(YW,"href","/docs/transformers/pr_17573/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DF,"id","transformers.AutoModelForInstanceSegmentation"),c(DF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DF,"href","#transformers.AutoModelForInstanceSegmentation"),c(Yd,"class","relative group"),c(KW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZW,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eH,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oH,"href","/docs/transformers/pr_17573/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zF,"id","transformers.TFAutoModel"),c(zF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zF,"href","#transformers.TFAutoModel"),c(ec,"class","relative group"),c(rH,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tH,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aH,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nH,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.TFAlbertModel"),c(sH,"href","/docs/transformers/pr_17573/en/model_doc/bart#transformers.TFBartModel"),c(lH,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.TFBertModel"),c(iH,"href","/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(dH,"href","/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(cH,"href","/docs/transformers/pr_17573/en/model_doc/camembert#transformers.TFCamembertModel"),c(fH,"href","/docs/transformers/pr_17573/en/model_doc/clip#transformers.TFCLIPModel"),c(mH,"href","/docs/transformers/pr_17573/en/model_doc/convbert#transformers.TFConvBertModel"),c(gH,"href","/docs/transformers/pr_17573/en/model_doc/convnext#transformers.TFConvNextModel"),c(hH,"href","/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.TFCTRLModel"),c(pH,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(_H,"href","/docs/transformers/pr_17573/en/model_doc/deberta#transformers.TFDebertaModel"),c(uH,"href","/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(bH,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(vH,"href","/docs/transformers/pr_17573/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(FH,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.TFElectraModel"),c(TH,"href","/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(MH,"href","/docs/transformers/pr_17573/en/model_doc/funnel#transformers.TFFunnelModel"),c(EH,"href","/docs/transformers/pr_17573/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(CH,"href","/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.TFGPT2Model"),c(wH,"href","/docs/transformers/pr_17573/en/model_doc/gptj#transformers.TFGPTJModel"),c(AH,"href","/docs/transformers/pr_17573/en/model_doc/hubert#transformers.TFHubertModel"),c(LH,"href","/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(yH,"href","/docs/transformers/pr_17573/en/model_doc/led#transformers.TFLEDModel"),c(xH,"href","/docs/transformers/pr_17573/en/model_doc/longformer#transformers.TFLongformerModel"),c($H,"href","/docs/transformers/pr_17573/en/model_doc/lxmert#transformers.TFLxmertModel"),c(kH,"href","/docs/transformers/pr_17573/en/model_doc/marian#transformers.TFMarianModel"),c(SH,"href","/docs/transformers/pr_17573/en/model_doc/mbart#transformers.TFMBartModel"),c(RH,"href","/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(PH,"href","/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.TFMPNetModel"),c(BH,"href","/docs/transformers/pr_17573/en/model_doc/mt5#transformers.TFMT5Model"),c(IH,"href","/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(NH,"href","/docs/transformers/pr_17573/en/model_doc/opt#transformers.TFOPTModel"),c(qH,"href","/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.TFPegasusModel"),c(jH,"href","/docs/transformers/pr_17573/en/model_doc/rembert#transformers.TFRemBertModel"),c(DH,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.TFRobertaModel"),c(GH,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.TFRoFormerModel"),c(OH,"href","/docs/transformers/pr_17573/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(VH,"href","/docs/transformers/pr_17573/en/model_doc/swin#transformers.TFSwinModel"),c(XH,"href","/docs/transformers/pr_17573/en/model_doc/t5#transformers.TFT5Model"),c(zH,"href","/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TFTapasModel"),c(QH,"href","/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(WH,"href","/docs/transformers/pr_17573/en/model_doc/vit#transformers.TFViTModel"),c(HH,"href","/docs/transformers/pr_17573/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(UH,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(JH,"href","/docs/transformers/pr_17573/en/model_doc/xlm#transformers.TFXLMModel"),c(YH,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(KH,"href","/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.TFXLNetModel"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DT,"id","transformers.TFAutoModelForPreTraining"),c(DT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DT,"href","#transformers.TFAutoModelForPreTraining"),c(tc,"class","relative group"),c(ZH,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eU,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oU,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rU,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(tU,"href","/docs/transformers/pr_17573/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(aU,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.TFBertForPreTraining"),c(nU,"href","/docs/transformers/pr_17573/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(sU,"href","/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(lU,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(iU,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(dU,"href","/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(cU,"href","/docs/transformers/pr_17573/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(fU,"href","/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(mU,"href","/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(gU,"href","/docs/transformers/pr_17573/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(hU,"href","/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(pU,"href","/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(_U,"href","/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(uU,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(bU,"href","/docs/transformers/pr_17573/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(vU,"href","/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(FU,"href","/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(TU,"href","/docs/transformers/pr_17573/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(MU,"href","/docs/transformers/pr_17573/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(EU,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(CU,"href","/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mM,"id","transformers.TFAutoModelForCausalLM"),c(mM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mM,"href","#transformers.TFAutoModelForCausalLM"),c(sc,"class","relative group"),c(wU,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AU,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LU,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yU,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(xU,"href","/docs/transformers/pr_17573/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c($U,"href","/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(kU,"href","/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(SU,"href","/docs/transformers/pr_17573/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(RU,"href","/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(PU,"href","/docs/transformers/pr_17573/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(BU,"href","/docs/transformers/pr_17573/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(IU,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(NU,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(qU,"href","/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(jU,"href","/docs/transformers/pr_17573/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(DU,"href","/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yM,"id","transformers.TFAutoModelForImageClassification"),c(yM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yM,"href","#transformers.TFAutoModelForImageClassification"),c(dc,"class","relative group"),c(GU,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OU,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VU,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XU,"href","/docs/transformers/pr_17573/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(zU,"href","/docs/transformers/pr_17573/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(QU,"href","/docs/transformers/pr_17573/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(WU,"href","/docs/transformers/pr_17573/en/model_doc/vit#transformers.TFViTForImageClassification"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BM,"id","transformers.TFAutoModelForMaskedLM"),c(BM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(BM,"href","#transformers.TFAutoModelForMaskedLM"),c(mc,"class","relative group"),c(HU,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UU,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JU,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YU,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(KU,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(ZU,"href","/docs/transformers/pr_17573/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(eJ,"href","/docs/transformers/pr_17573/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(oJ,"href","/docs/transformers/pr_17573/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(rJ,"href","/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(tJ,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(aJ,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(nJ,"href","/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(sJ,"href","/docs/transformers/pr_17573/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(lJ,"href","/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(iJ,"href","/docs/transformers/pr_17573/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(dJ,"href","/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(cJ,"href","/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(fJ,"href","/docs/transformers/pr_17573/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(mJ,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(gJ,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(hJ,"href","/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(pJ,"href","/docs/transformers/pr_17573/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(_J,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aE,"id","transformers.TFAutoModelForSeq2SeqLM"),c(aE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aE,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(pc,"class","relative group"),c(uJ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bJ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vJ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FJ,"href","/docs/transformers/pr_17573/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(TJ,"href","/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(MJ,"href","/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(EJ,"href","/docs/transformers/pr_17573/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(CJ,"href","/docs/transformers/pr_17573/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(wJ,"href","/docs/transformers/pr_17573/en/model_doc/marian#transformers.TFMarianMTModel"),c(AJ,"href","/docs/transformers/pr_17573/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(LJ,"href","/docs/transformers/pr_17573/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(yJ,"href","/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(xJ,"href","/docs/transformers/pr_17573/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uE,"id","transformers.TFAutoModelForSequenceClassification"),c(uE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uE,"href","#transformers.TFAutoModelForSequenceClassification"),c(bc,"class","relative group"),c($J,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kJ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SJ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RJ,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(PJ,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(BJ,"href","/docs/transformers/pr_17573/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(IJ,"href","/docs/transformers/pr_17573/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(NJ,"href","/docs/transformers/pr_17573/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(qJ,"href","/docs/transformers/pr_17573/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(jJ,"href","/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(DJ,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(GJ,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(OJ,"href","/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(VJ,"href","/docs/transformers/pr_17573/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(XJ,"href","/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(zJ,"href","/docs/transformers/pr_17573/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(QJ,"href","/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(WJ,"href","/docs/transformers/pr_17573/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(HJ,"href","/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(UJ,"href","/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(JJ,"href","/docs/transformers/pr_17573/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(YJ,"href","/docs/transformers/pr_17573/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(KJ,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(ZJ,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(eY,"href","/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(oY,"href","/docs/transformers/pr_17573/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(rY,"href","/docs/transformers/pr_17573/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(tY,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(aY,"href","/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QE,"id","transformers.TFAutoModelForMultipleChoice"),c(QE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(QE,"href","#transformers.TFAutoModelForMultipleChoice"),c(Tc,"class","relative group"),c(nY,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sY,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lY,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iY,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(dY,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(cY,"href","/docs/transformers/pr_17573/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(fY,"href","/docs/transformers/pr_17573/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(mY,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(gY,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(hY,"href","/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(pY,"href","/docs/transformers/pr_17573/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(_Y,"href","/docs/transformers/pr_17573/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(uY,"href","/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(bY,"href","/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(vY,"href","/docs/transformers/pr_17573/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(FY,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(TY,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(MY,"href","/docs/transformers/pr_17573/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(EY,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(CY,"href","/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m4,"id","transformers.TFAutoModelForNextSentencePrediction"),c(m4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m4,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(Cc,"class","relative group"),c(wY,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AY,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LY,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yY,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(xY,"href","/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(u4,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(u4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(u4,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(Lc,"class","relative group"),c($Y,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kY,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SY,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RY,"href","/docs/transformers/pr_17573/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(T4,"id","transformers.TFAutoModelForTokenClassification"),c(T4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(T4,"href","#transformers.TFAutoModelForTokenClassification"),c($c,"class","relative group"),c(PY,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BY,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IY,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NY,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(qY,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(jY,"href","/docs/transformers/pr_17573/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(DY,"href","/docs/transformers/pr_17573/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(GY,"href","/docs/transformers/pr_17573/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(OY,"href","/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(VY,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(XY,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(zY,"href","/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(QY,"href","/docs/transformers/pr_17573/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(WY,"href","/docs/transformers/pr_17573/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(HY,"href","/docs/transformers/pr_17573/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(UY,"href","/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(JY,"href","/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(YY,"href","/docs/transformers/pr_17573/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(KY,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(ZY,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(eK,"href","/docs/transformers/pr_17573/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(oK,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(rK,"href","/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(X4,"id","transformers.TFAutoModelForQuestionAnswering"),c(X4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(X4,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Rc,"class","relative group"),c(tK,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aK,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nK,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sK,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(lK,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(iK,"href","/docs/transformers/pr_17573/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(dK,"href","/docs/transformers/pr_17573/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(cK,"href","/docs/transformers/pr_17573/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(fK,"href","/docs/transformers/pr_17573/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(mK,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(gK,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(hK,"href","/docs/transformers/pr_17573/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(pK,"href","/docs/transformers/pr_17573/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(_K,"href","/docs/transformers/pr_17573/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(uK,"href","/docs/transformers/pr_17573/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(bK,"href","/docs/transformers/pr_17573/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(vK,"href","/docs/transformers/pr_17573/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(FK,"href","/docs/transformers/pr_17573/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(TK,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(MK,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(EK,"href","/docs/transformers/pr_17573/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(CK,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(wK,"href","/docs/transformers/pr_17573/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gC,"id","transformers.TFAutoModelForVision2Seq"),c(gC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(gC,"href","#transformers.TFAutoModelForVision2Seq"),c(Ic,"class","relative group"),c(AK,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LK,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yK,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xK,"href","/docs/transformers/pr_17573/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uC,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(uC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uC,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(jc,"class","relative group"),c($K,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kK,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SK,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RK,"href","/docs/transformers/pr_17573/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TC,"id","transformers.FlaxAutoModel"),c(TC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(TC,"href","#transformers.FlaxAutoModel"),c(Oc,"class","relative group"),c(PK,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BK,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IK,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NK,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.FlaxAlbertModel"),c(qK,"href","/docs/transformers/pr_17573/en/model_doc/bart#transformers.FlaxBartModel"),c(jK,"href","/docs/transformers/pr_17573/en/model_doc/beit#transformers.FlaxBeitModel"),c(DK,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.FlaxBertModel"),c(GK,"href","/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(OK,"href","/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(VK,"href","/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(XK,"href","/docs/transformers/pr_17573/en/model_doc/clip#transformers.FlaxCLIPModel"),c(zK,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(QK,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.FlaxElectraModel"),c(WK,"href","/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(HK,"href","/docs/transformers/pr_17573/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(UK,"href","/docs/transformers/pr_17573/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(JK,"href","/docs/transformers/pr_17573/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(YK,"href","/docs/transformers/pr_17573/en/model_doc/marian#transformers.FlaxMarianModel"),c(KK,"href","/docs/transformers/pr_17573/en/model_doc/mbart#transformers.FlaxMBartModel"),c(ZK,"href","/docs/transformers/pr_17573/en/model_doc/mt5#transformers.FlaxMT5Model"),c(eZ,"href","/docs/transformers/pr_17573/en/model_doc/opt#transformers.FlaxOPTModel"),c(oZ,"href","/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(rZ,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(tZ,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(aZ,"href","/docs/transformers/pr_17573/en/model_doc/t5#transformers.FlaxT5Model"),c(nZ,"href","/docs/transformers/pr_17573/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(sZ,"href","/docs/transformers/pr_17573/en/model_doc/vit#transformers.FlaxViTModel"),c(lZ,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(iZ,"href","/docs/transformers/pr_17573/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(dZ,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YC,"id","transformers.FlaxAutoModelForCausalLM"),c(YC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(YC,"href","#transformers.FlaxAutoModelForCausalLM"),c(zc,"class","relative group"),c(cZ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fZ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mZ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gZ,"href","/docs/transformers/pr_17573/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(hZ,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(pZ,"href","/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(_Z,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(uZ,"href","/docs/transformers/pr_17573/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(bZ,"href","/docs/transformers/pr_17573/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(vZ,"href","/docs/transformers/pr_17573/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(FZ,"href","/docs/transformers/pr_17573/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(TZ,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(MZ,"href","/docs/transformers/pr_17573/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(c0,"id","transformers.FlaxAutoModelForPreTraining"),c(c0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(c0,"href","#transformers.FlaxAutoModelForPreTraining"),c(Hc,"class","relative group"),c(EZ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CZ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wZ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AZ,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(LZ,"href","/docs/transformers/pr_17573/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(yZ,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(xZ,"href","/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c($Z,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(kZ,"href","/docs/transformers/pr_17573/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(SZ,"href","/docs/transformers/pr_17573/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(RZ,"href","/docs/transformers/pr_17573/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(PZ,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(BZ,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(IZ,"href","/docs/transformers/pr_17573/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(NZ,"href","/docs/transformers/pr_17573/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(qZ,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(A0,"id","transformers.FlaxAutoModelForMaskedLM"),c(A0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(A0,"href","#transformers.FlaxAutoModelForMaskedLM"),c(Yc,"class","relative group"),c(jZ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(DZ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(GZ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OZ,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(VZ,"href","/docs/transformers/pr_17573/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(XZ,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(zZ,"href","/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(QZ,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(WZ,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(HZ,"href","/docs/transformers/pr_17573/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(UZ,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(JZ,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(YZ,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(j0,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(j0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(j0,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(ef,"class","relative group"),c(KZ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZZ,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eee,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oee,"href","/docs/transformers/pr_17573/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(ree,"href","/docs/transformers/pr_17573/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(tee,"href","/docs/transformers/pr_17573/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(aee,"href","/docs/transformers/pr_17573/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(nee,"href","/docs/transformers/pr_17573/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(see,"href","/docs/transformers/pr_17573/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(lee,"href","/docs/transformers/pr_17573/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(iee,"href","/docs/transformers/pr_17573/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(dee,"href","/docs/transformers/pr_17573/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(cee,"href","/docs/transformers/pr_17573/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(K0,"id","transformers.FlaxAutoModelForSequenceClassification"),c(K0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(K0,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(tf,"class","relative group"),c(fee,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mee,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gee,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hee,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(pee,"href","/docs/transformers/pr_17573/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(_ee,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(uee,"href","/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(bee,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(vee,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(Fee,"href","/docs/transformers/pr_17573/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(Tee,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(Mee,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(Eee,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fw,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(fw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fw,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(sf,"class","relative group"),c(Cee,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wee,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Aee,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lee,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(yee,"href","/docs/transformers/pr_17573/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(xee,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c($ee,"href","/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(kee,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(See,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(Ree,"href","/docs/transformers/pr_17573/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(Pee,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(Bee,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(Iee,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cw,"id","transformers.FlaxAutoModelForTokenClassification"),c(Cw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Cw,"href","#transformers.FlaxAutoModelForTokenClassification"),c(cf,"class","relative group"),c(Nee,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qee,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jee,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Dee,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(Gee,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(Oee,"href","/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(Vee,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(Xee,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(zee,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(Qee,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(Wee,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bw,"id","transformers.FlaxAutoModelForMultipleChoice"),c(Bw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Bw,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(gf,"class","relative group"),c(Hee,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Uee,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Jee,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yee,"href","/docs/transformers/pr_17573/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(Kee,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(Zee,"href","/docs/transformers/pr_17573/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(eoe,"href","/docs/transformers/pr_17573/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(ooe,"href","/docs/transformers/pr_17573/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(roe,"href","/docs/transformers/pr_17573/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(toe,"href","/docs/transformers/pr_17573/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(aoe,"href","/docs/transformers/pr_17573/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qw,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(Qw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Qw,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(_f,"class","relative group"),c(noe,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(soe,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(loe,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ioe,"href","/docs/transformers/pr_17573/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jw,"id","transformers.FlaxAutoModelForImageClassification"),c(Jw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Jw,"href","#transformers.FlaxAutoModelForImageClassification"),c(vf,"class","relative group"),c(doe,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(coe,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(foe,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(moe,"href","/docs/transformers/pr_17573/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(goe,"href","/docs/transformers/pr_17573/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oA,"id","transformers.FlaxAutoModelForVision2Seq"),c(oA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oA,"href","#transformers.FlaxAutoModelForVision2Seq"),c(Mf,"class","relative group"),c(hoe,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(poe,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_oe,"href","/docs/transformers/pr_17573/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uoe,"href","/docs/transformers/pr_17573/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,u){e(document.head,g),b(f,v,u),b(f,p,u),e(p,m),e(m,_),M(d,_,null),e(p,h),e(p,Eo),e(Eo,Ti),b(f,yf,u),b(f,at,u),e(at,Mi),e(at,Ei),e(Ei,wL),e(at,xf),b(f,Oe,u),b(f,Qe,u),e(Qe,Ci),e(Qe,Rn),e(Rn,AL),e(Qe,Pn),e(Qe,Bn),e(Bn,LL),e(Qe,wi),e(Qe,In),e(In,yL),e(Qe,Ai),b(f,$f,u),M(xa,f,u),b(f,We,u),b(f,Ae,u),e(Ae,rS),e(Ae,Li),e(Li,tS),e(Ae,aS),b(f,Co,u),b(f,$a,u),e($a,nS),e($a,kf),e(kf,sS),e($a,eQe),b(f,jGe,u),b(f,yi,u),e(yi,Sf),e(Sf,mte),M(xL,mte,null),e(yi,oQe),e(yi,gte),e(gte,rQe),b(f,DGe,u),b(f,Nn,u),e(Nn,tQe),e(Nn,hte),e(hte,aQe),e(Nn,nQe),e(Nn,pte),e(pte,sQe),e(Nn,lQe),b(f,GGe,u),M($L,f,u),b(f,OGe,u),b(f,lS,u),e(lS,iQe),b(f,VGe,u),M(Rf,f,u),b(f,XGe,u),b(f,xi,u),e(xi,Pf),e(Pf,_te),M(kL,_te,null),e(xi,dQe),e(xi,ute),e(ute,cQe),b(f,zGe,u),b(f,wo,u),M(SL,wo,null),e(wo,fQe),e(wo,RL),e(RL,mQe),e(RL,iS),e(iS,gQe),e(RL,hQe),e(wo,pQe),e(wo,PL),e(PL,_Qe),e(PL,bte),e(bte,uQe),e(PL,bQe),e(wo,vQe),e(wo,Ar),M(BL,Ar,null),e(Ar,FQe),e(Ar,vte),e(vte,TQe),e(Ar,MQe),e(Ar,$i),e($i,EQe),e($i,Fte),e(Fte,CQe),e($i,wQe),e($i,Tte),e(Tte,AQe),e($i,LQe),e(Ar,yQe),e(Ar,A),e(A,Bf),e(Bf,Mte),e(Mte,xQe),e(Bf,$Qe),e(Bf,dS),e(dS,kQe),e(Bf,SQe),e(A,RQe),e(A,If),e(If,Ete),e(Ete,PQe),e(If,BQe),e(If,cS),e(cS,IQe),e(If,NQe),e(A,qQe),e(A,Nf),e(Nf,Cte),e(Cte,jQe),e(Nf,DQe),e(Nf,fS),e(fS,GQe),e(Nf,OQe),e(A,VQe),e(A,qf),e(qf,wte),e(wte,XQe),e(qf,zQe),e(qf,mS),e(mS,QQe),e(qf,WQe),e(A,HQe),e(A,jf),e(jf,Ate),e(Ate,UQe),e(jf,JQe),e(jf,gS),e(gS,YQe),e(jf,KQe),e(A,ZQe),e(A,Df),e(Df,Lte),e(Lte,eWe),e(Df,oWe),e(Df,hS),e(hS,rWe),e(Df,tWe),e(A,aWe),e(A,Gf),e(Gf,yte),e(yte,nWe),e(Gf,sWe),e(Gf,pS),e(pS,lWe),e(Gf,iWe),e(A,dWe),e(A,Of),e(Of,xte),e(xte,cWe),e(Of,fWe),e(Of,_S),e(_S,mWe),e(Of,gWe),e(A,hWe),e(A,Vf),e(Vf,$te),e($te,pWe),e(Vf,_We),e(Vf,uS),e(uS,uWe),e(Vf,bWe),e(A,vWe),e(A,Xf),e(Xf,kte),e(kte,FWe),e(Xf,TWe),e(Xf,bS),e(bS,MWe),e(Xf,EWe),e(A,CWe),e(A,zf),e(zf,Ste),e(Ste,wWe),e(zf,AWe),e(zf,vS),e(vS,LWe),e(zf,yWe),e(A,xWe),e(A,Qf),e(Qf,Rte),e(Rte,$We),e(Qf,kWe),e(Qf,FS),e(FS,SWe),e(Qf,RWe),e(A,PWe),e(A,Wf),e(Wf,Pte),e(Pte,BWe),e(Wf,IWe),e(Wf,TS),e(TS,NWe),e(Wf,qWe),e(A,jWe),e(A,Hf),e(Hf,Bte),e(Bte,DWe),e(Hf,GWe),e(Hf,MS),e(MS,OWe),e(Hf,VWe),e(A,XWe),e(A,Uf),e(Uf,Ite),e(Ite,zWe),e(Uf,QWe),e(Uf,ES),e(ES,WWe),e(Uf,HWe),e(A,UWe),e(A,Jf),e(Jf,Nte),e(Nte,JWe),e(Jf,YWe),e(Jf,CS),e(CS,KWe),e(Jf,ZWe),e(A,eHe),e(A,Yf),e(Yf,qte),e(qte,oHe),e(Yf,rHe),e(Yf,wS),e(wS,tHe),e(Yf,aHe),e(A,nHe),e(A,Kf),e(Kf,jte),e(jte,sHe),e(Kf,lHe),e(Kf,AS),e(AS,iHe),e(Kf,dHe),e(A,cHe),e(A,Zf),e(Zf,Dte),e(Dte,fHe),e(Zf,mHe),e(Zf,LS),e(LS,gHe),e(Zf,hHe),e(A,pHe),e(A,em),e(em,Gte),e(Gte,_He),e(em,uHe),e(em,yS),e(yS,bHe),e(em,vHe),e(A,FHe),e(A,om),e(om,Ote),e(Ote,THe),e(om,MHe),e(om,xS),e(xS,EHe),e(om,CHe),e(A,wHe),e(A,rm),e(rm,Vte),e(Vte,AHe),e(rm,LHe),e(rm,$S),e($S,yHe),e(rm,xHe),e(A,$He),e(A,tm),e(tm,Xte),e(Xte,kHe),e(tm,SHe),e(tm,kS),e(kS,RHe),e(tm,PHe),e(A,BHe),e(A,am),e(am,zte),e(zte,IHe),e(am,NHe),e(am,SS),e(SS,qHe),e(am,jHe),e(A,DHe),e(A,nm),e(nm,Qte),e(Qte,GHe),e(nm,OHe),e(nm,RS),e(RS,VHe),e(nm,XHe),e(A,zHe),e(A,sm),e(sm,Wte),e(Wte,QHe),e(sm,WHe),e(sm,PS),e(PS,HHe),e(sm,UHe),e(A,JHe),e(A,lm),e(lm,Hte),e(Hte,YHe),e(lm,KHe),e(lm,BS),e(BS,ZHe),e(lm,eUe),e(A,oUe),e(A,im),e(im,Ute),e(Ute,rUe),e(im,tUe),e(im,IS),e(IS,aUe),e(im,nUe),e(A,sUe),e(A,dm),e(dm,Jte),e(Jte,lUe),e(dm,iUe),e(dm,NS),e(NS,dUe),e(dm,cUe),e(A,fUe),e(A,cm),e(cm,Yte),e(Yte,mUe),e(cm,gUe),e(cm,qS),e(qS,hUe),e(cm,pUe),e(A,_Ue),e(A,fm),e(fm,Kte),e(Kte,uUe),e(fm,bUe),e(fm,jS),e(jS,vUe),e(fm,FUe),e(A,TUe),e(A,mm),e(mm,Zte),e(Zte,MUe),e(mm,EUe),e(mm,DS),e(DS,CUe),e(mm,wUe),e(A,AUe),e(A,gm),e(gm,eae),e(eae,LUe),e(gm,yUe),e(gm,GS),e(GS,xUe),e(gm,$Ue),e(A,kUe),e(A,hm),e(hm,oae),e(oae,SUe),e(hm,RUe),e(hm,OS),e(OS,PUe),e(hm,BUe),e(A,IUe),e(A,pm),e(pm,rae),e(rae,NUe),e(pm,qUe),e(pm,VS),e(VS,jUe),e(pm,DUe),e(A,GUe),e(A,_m),e(_m,tae),e(tae,OUe),e(_m,VUe),e(_m,XS),e(XS,XUe),e(_m,zUe),e(A,QUe),e(A,um),e(um,aae),e(aae,WUe),e(um,HUe),e(um,zS),e(zS,UUe),e(um,JUe),e(A,YUe),e(A,bm),e(bm,nae),e(nae,KUe),e(bm,ZUe),e(bm,QS),e(QS,eJe),e(bm,oJe),e(A,rJe),e(A,vm),e(vm,sae),e(sae,tJe),e(vm,aJe),e(vm,WS),e(WS,nJe),e(vm,sJe),e(A,lJe),e(A,Fm),e(Fm,lae),e(lae,iJe),e(Fm,dJe),e(Fm,HS),e(HS,cJe),e(Fm,fJe),e(A,mJe),e(A,Tm),e(Tm,iae),e(iae,gJe),e(Tm,hJe),e(Tm,US),e(US,pJe),e(Tm,_Je),e(A,uJe),e(A,Mm),e(Mm,dae),e(dae,bJe),e(Mm,vJe),e(Mm,JS),e(JS,FJe),e(Mm,TJe),e(A,MJe),e(A,Em),e(Em,cae),e(cae,EJe),e(Em,CJe),e(Em,YS),e(YS,wJe),e(Em,AJe),e(A,LJe),e(A,Cm),e(Cm,fae),e(fae,yJe),e(Cm,xJe),e(Cm,KS),e(KS,$Je),e(Cm,kJe),e(A,SJe),e(A,wm),e(wm,mae),e(mae,RJe),e(wm,PJe),e(wm,ZS),e(ZS,BJe),e(wm,IJe),e(A,NJe),e(A,Am),e(Am,gae),e(gae,qJe),e(Am,jJe),e(Am,eR),e(eR,DJe),e(Am,GJe),e(A,OJe),e(A,Lm),e(Lm,hae),e(hae,VJe),e(Lm,XJe),e(Lm,oR),e(oR,zJe),e(Lm,QJe),e(A,WJe),e(A,ym),e(ym,pae),e(pae,HJe),e(ym,UJe),e(ym,rR),e(rR,JJe),e(ym,YJe),e(A,KJe),e(A,xm),e(xm,_ae),e(_ae,ZJe),e(xm,eYe),e(xm,tR),e(tR,oYe),e(xm,rYe),e(A,tYe),e(A,$m),e($m,uae),e(uae,aYe),e($m,nYe),e($m,aR),e(aR,sYe),e($m,lYe),e(A,iYe),e(A,km),e(km,bae),e(bae,dYe),e(km,cYe),e(km,nR),e(nR,fYe),e(km,mYe),e(A,gYe),e(A,Sm),e(Sm,vae),e(vae,hYe),e(Sm,pYe),e(Sm,sR),e(sR,_Ye),e(Sm,uYe),e(A,bYe),e(A,Rm),e(Rm,Fae),e(Fae,vYe),e(Rm,FYe),e(Rm,lR),e(lR,TYe),e(Rm,MYe),e(A,EYe),e(A,Pm),e(Pm,Tae),e(Tae,CYe),e(Pm,wYe),e(Pm,iR),e(iR,AYe),e(Pm,LYe),e(A,yYe),e(A,Bm),e(Bm,Mae),e(Mae,xYe),e(Bm,$Ye),e(Bm,dR),e(dR,kYe),e(Bm,SYe),e(A,RYe),e(A,Im),e(Im,Eae),e(Eae,PYe),e(Im,BYe),e(Im,cR),e(cR,IYe),e(Im,NYe),e(A,qYe),e(A,Nm),e(Nm,Cae),e(Cae,jYe),e(Nm,DYe),e(Nm,fR),e(fR,GYe),e(Nm,OYe),e(A,VYe),e(A,qm),e(qm,wae),e(wae,XYe),e(qm,zYe),e(qm,mR),e(mR,QYe),e(qm,WYe),e(A,HYe),e(A,jm),e(jm,Aae),e(Aae,UYe),e(jm,JYe),e(jm,gR),e(gR,YYe),e(jm,KYe),e(A,ZYe),e(A,Dm),e(Dm,Lae),e(Lae,eKe),e(Dm,oKe),e(Dm,hR),e(hR,rKe),e(Dm,tKe),e(A,aKe),e(A,Gm),e(Gm,yae),e(yae,nKe),e(Gm,sKe),e(Gm,pR),e(pR,lKe),e(Gm,iKe),e(A,dKe),e(A,Om),e(Om,xae),e(xae,cKe),e(Om,fKe),e(Om,_R),e(_R,mKe),e(Om,gKe),e(A,hKe),e(A,Vm),e(Vm,$ae),e($ae,pKe),e(Vm,_Ke),e(Vm,uR),e(uR,uKe),e(Vm,bKe),e(A,vKe),e(A,Xm),e(Xm,kae),e(kae,FKe),e(Xm,TKe),e(Xm,bR),e(bR,MKe),e(Xm,EKe),e(A,CKe),e(A,zm),e(zm,Sae),e(Sae,wKe),e(zm,AKe),e(zm,vR),e(vR,LKe),e(zm,yKe),e(A,xKe),e(A,Qm),e(Qm,Rae),e(Rae,$Ke),e(Qm,kKe),e(Qm,FR),e(FR,SKe),e(Qm,RKe),e(A,PKe),e(A,Wm),e(Wm,Pae),e(Pae,BKe),e(Wm,IKe),e(Wm,TR),e(TR,NKe),e(Wm,qKe),e(A,jKe),e(A,Hm),e(Hm,Bae),e(Bae,DKe),e(Hm,GKe),e(Hm,MR),e(MR,OKe),e(Hm,VKe),e(A,XKe),e(A,Um),e(Um,Iae),e(Iae,zKe),e(Um,QKe),e(Um,ER),e(ER,WKe),e(Um,HKe),e(A,UKe),e(A,Jm),e(Jm,Nae),e(Nae,JKe),e(Jm,YKe),e(Jm,CR),e(CR,KKe),e(Jm,ZKe),e(A,eZe),e(A,Ym),e(Ym,qae),e(qae,oZe),e(Ym,rZe),e(Ym,wR),e(wR,tZe),e(Ym,aZe),e(A,nZe),e(A,Km),e(Km,jae),e(jae,sZe),e(Km,lZe),e(Km,AR),e(AR,iZe),e(Km,dZe),e(A,cZe),e(A,Zm),e(Zm,Dae),e(Dae,fZe),e(Zm,mZe),e(Zm,LR),e(LR,gZe),e(Zm,hZe),e(A,pZe),e(A,eg),e(eg,Gae),e(Gae,_Ze),e(eg,uZe),e(eg,yR),e(yR,bZe),e(eg,vZe),e(A,FZe),e(A,og),e(og,Oae),e(Oae,TZe),e(og,MZe),e(og,xR),e(xR,EZe),e(og,CZe),e(A,wZe),e(A,rg),e(rg,Vae),e(Vae,AZe),e(rg,LZe),e(rg,$R),e($R,yZe),e(rg,xZe),e(A,$Ze),e(A,tg),e(tg,Xae),e(Xae,kZe),e(tg,SZe),e(tg,kR),e(kR,RZe),e(tg,PZe),e(A,BZe),e(A,ag),e(ag,zae),e(zae,IZe),e(ag,NZe),e(ag,SR),e(SR,qZe),e(ag,jZe),e(A,DZe),e(A,ng),e(ng,Qae),e(Qae,GZe),e(ng,OZe),e(ng,RR),e(RR,VZe),e(ng,XZe),e(A,zZe),e(A,sg),e(sg,Wae),e(Wae,QZe),e(sg,WZe),e(sg,PR),e(PR,HZe),e(sg,UZe),e(A,JZe),e(A,lg),e(lg,Hae),e(Hae,YZe),e(lg,KZe),e(lg,BR),e(BR,ZZe),e(lg,eeo),e(A,oeo),e(A,ig),e(ig,Uae),e(Uae,reo),e(ig,teo),e(ig,IR),e(IR,aeo),e(ig,neo),e(A,seo),e(A,dg),e(dg,Jae),e(Jae,leo),e(dg,ieo),e(dg,NR),e(NR,deo),e(dg,ceo),e(A,feo),e(A,cg),e(cg,Yae),e(Yae,meo),e(cg,geo),e(cg,qR),e(qR,heo),e(cg,peo),e(A,_eo),e(A,fg),e(fg,Kae),e(Kae,ueo),e(fg,beo),e(fg,jR),e(jR,veo),e(fg,Feo),e(A,Teo),e(A,mg),e(mg,Zae),e(Zae,Meo),e(mg,Eeo),e(mg,DR),e(DR,Ceo),e(mg,weo),e(A,Aeo),e(A,gg),e(gg,ene),e(ene,Leo),e(gg,yeo),e(gg,GR),e(GR,xeo),e(gg,$eo),e(A,keo),e(A,hg),e(hg,one),e(one,Seo),e(hg,Reo),e(hg,OR),e(OR,Peo),e(hg,Beo),e(A,Ieo),e(A,pg),e(pg,rne),e(rne,Neo),e(pg,qeo),e(pg,VR),e(VR,jeo),e(pg,Deo),e(A,Geo),e(A,_g),e(_g,tne),e(tne,Oeo),e(_g,Veo),e(_g,XR),e(XR,Xeo),e(_g,zeo),e(A,Qeo),e(A,ug),e(ug,ane),e(ane,Weo),e(ug,Heo),e(ug,zR),e(zR,Ueo),e(ug,Jeo),e(A,Yeo),e(A,bg),e(bg,nne),e(nne,Keo),e(bg,Zeo),e(bg,QR),e(QR,eoo),e(bg,ooo),e(A,roo),e(A,vg),e(vg,sne),e(sne,too),e(vg,aoo),e(vg,WR),e(WR,noo),e(vg,soo),e(A,loo),e(A,Fg),e(Fg,lne),e(lne,ioo),e(Fg,doo),e(Fg,HR),e(HR,coo),e(Fg,foo),e(A,moo),e(A,Tg),e(Tg,ine),e(ine,goo),e(Tg,hoo),e(Tg,UR),e(UR,poo),e(Tg,_oo),e(A,uoo),e(A,Mg),e(Mg,dne),e(dne,boo),e(Mg,voo),e(Mg,JR),e(JR,Foo),e(Mg,Too),e(A,Moo),e(A,Eg),e(Eg,cne),e(cne,Eoo),e(Eg,Coo),e(Eg,YR),e(YR,woo),e(Eg,Aoo),e(A,Loo),e(A,Cg),e(Cg,fne),e(fne,yoo),e(Cg,xoo),e(Cg,KR),e(KR,$oo),e(Cg,koo),e(A,Soo),e(A,wg),e(wg,mne),e(mne,Roo),e(wg,Poo),e(wg,ZR),e(ZR,Boo),e(wg,Ioo),e(A,Noo),e(A,Ag),e(Ag,gne),e(gne,qoo),e(Ag,joo),e(Ag,eP),e(eP,Doo),e(Ag,Goo),e(A,Ooo),e(A,Lg),e(Lg,hne),e(hne,Voo),e(Lg,Xoo),e(Lg,oP),e(oP,zoo),e(Lg,Qoo),e(A,Woo),e(A,yg),e(yg,pne),e(pne,Hoo),e(yg,Uoo),e(yg,rP),e(rP,Joo),e(yg,Yoo),e(A,Koo),e(A,xg),e(xg,_ne),e(_ne,Zoo),e(xg,ero),e(xg,tP),e(tP,oro),e(xg,rro),e(A,tro),e(A,$g),e($g,une),e(une,aro),e($g,nro),e($g,aP),e(aP,sro),e($g,lro),e(A,iro),e(A,kg),e(kg,bne),e(bne,dro),e(kg,cro),e(kg,nP),e(nP,fro),e(kg,mro),e(A,gro),e(A,Sg),e(Sg,vne),e(vne,hro),e(Sg,pro),e(Sg,sP),e(sP,_ro),e(Sg,uro),e(A,bro),e(A,Rg),e(Rg,Fne),e(Fne,vro),e(Rg,Fro),e(Rg,lP),e(lP,Tro),e(Rg,Mro),e(A,Ero),e(A,Pg),e(Pg,Tne),e(Tne,Cro),e(Pg,wro),e(Pg,iP),e(iP,Aro),e(Pg,Lro),e(A,yro),e(A,Bg),e(Bg,Mne),e(Mne,xro),e(Bg,$ro),e(Bg,dP),e(dP,kro),e(Bg,Sro),e(A,Rro),e(A,Ig),e(Ig,Ene),e(Ene,Pro),e(Ig,Bro),e(Ig,cP),e(cP,Iro),e(Ig,Nro),e(A,qro),e(A,Ng),e(Ng,Cne),e(Cne,jro),e(Ng,Dro),e(Ng,fP),e(fP,Gro),e(Ng,Oro),e(A,Vro),e(A,qg),e(qg,wne),e(wne,Xro),e(qg,zro),e(qg,mP),e(mP,Qro),e(qg,Wro),e(A,Hro),e(A,jg),e(jg,Ane),e(Ane,Uro),e(jg,Jro),e(jg,gP),e(gP,Yro),e(jg,Kro),e(A,Zro),e(A,Dg),e(Dg,Lne),e(Lne,eto),e(Dg,oto),e(Dg,hP),e(hP,rto),e(Dg,tto),e(Ar,ato),M(Gg,Ar,null),e(wo,nto),e(wo,Og),M(IL,Og,null),e(Og,sto),e(Og,yne),e(yne,lto),b(f,QGe,u),b(f,ki,u),e(ki,Vg),e(Vg,xne),M(NL,xne,null),e(ki,ito),e(ki,$ne),e($ne,dto),b(f,WGe,u),b(f,Ao,u),M(qL,Ao,null),e(Ao,cto),e(Ao,jL),e(jL,fto),e(jL,pP),e(pP,mto),e(jL,gto),e(Ao,hto),e(Ao,DL),e(DL,pto),e(DL,kne),e(kne,_to),e(DL,uto),e(Ao,bto),e(Ao,Lr),M(GL,Lr,null),e(Lr,vto),e(Lr,Sne),e(Sne,Fto),e(Lr,Tto),e(Lr,ka),e(ka,Mto),e(ka,Rne),e(Rne,Eto),e(ka,Cto),e(ka,Pne),e(Pne,wto),e(ka,Ato),e(ka,Bne),e(Bne,Lto),e(ka,yto),e(Lr,xto),e(Lr,k),e(k,qn),e(qn,Ine),e(Ine,$to),e(qn,kto),e(qn,_P),e(_P,Sto),e(qn,Rto),e(qn,uP),e(uP,Pto),e(qn,Bto),e(k,Ito),e(k,jn),e(jn,Nne),e(Nne,Nto),e(jn,qto),e(jn,bP),e(bP,jto),e(jn,Dto),e(jn,vP),e(vP,Gto),e(jn,Oto),e(k,Vto),e(k,Dn),e(Dn,qne),e(qne,Xto),e(Dn,zto),e(Dn,FP),e(FP,Qto),e(Dn,Wto),e(Dn,TP),e(TP,Hto),e(Dn,Uto),e(k,Jto),e(k,Xg),e(Xg,jne),e(jne,Yto),e(Xg,Kto),e(Xg,MP),e(MP,Zto),e(Xg,eao),e(k,oao),e(k,Gn),e(Gn,Dne),e(Dne,rao),e(Gn,tao),e(Gn,EP),e(EP,aao),e(Gn,nao),e(Gn,CP),e(CP,sao),e(Gn,lao),e(k,iao),e(k,zg),e(zg,Gne),e(Gne,dao),e(zg,cao),e(zg,wP),e(wP,fao),e(zg,mao),e(k,gao),e(k,Qg),e(Qg,One),e(One,hao),e(Qg,pao),e(Qg,AP),e(AP,_ao),e(Qg,uao),e(k,bao),e(k,Wg),e(Wg,Vne),e(Vne,vao),e(Wg,Fao),e(Wg,LP),e(LP,Tao),e(Wg,Mao),e(k,Eao),e(k,On),e(On,Xne),e(Xne,Cao),e(On,wao),e(On,yP),e(yP,Aao),e(On,Lao),e(On,xP),e(xP,yao),e(On,xao),e(k,$ao),e(k,Vn),e(Vn,zne),e(zne,kao),e(Vn,Sao),e(Vn,$P),e($P,Rao),e(Vn,Pao),e(Vn,kP),e(kP,Bao),e(Vn,Iao),e(k,Nao),e(k,Xn),e(Xn,Qne),e(Qne,qao),e(Xn,jao),e(Xn,SP),e(SP,Dao),e(Xn,Gao),e(Xn,RP),e(RP,Oao),e(Xn,Vao),e(k,Xao),e(k,Hg),e(Hg,Wne),e(Wne,zao),e(Hg,Qao),e(Hg,PP),e(PP,Wao),e(Hg,Hao),e(k,Uao),e(k,Ug),e(Ug,Hne),e(Hne,Jao),e(Ug,Yao),e(Ug,BP),e(BP,Kao),e(Ug,Zao),e(k,eno),e(k,Jg),e(Jg,Une),e(Une,ono),e(Jg,rno),e(Jg,IP),e(IP,tno),e(Jg,ano),e(k,nno),e(k,zn),e(zn,Jne),e(Jne,sno),e(zn,lno),e(zn,NP),e(NP,ino),e(zn,dno),e(zn,qP),e(qP,cno),e(zn,fno),e(k,mno),e(k,Yg),e(Yg,Yne),e(Yne,gno),e(Yg,hno),e(Yg,jP),e(jP,pno),e(Yg,_no),e(k,uno),e(k,Qn),e(Qn,Kne),e(Kne,bno),e(Qn,vno),e(Qn,DP),e(DP,Fno),e(Qn,Tno),e(Qn,GP),e(GP,Mno),e(Qn,Eno),e(k,Cno),e(k,Wn),e(Wn,Zne),e(Zne,wno),e(Wn,Ano),e(Wn,OP),e(OP,Lno),e(Wn,yno),e(Wn,VP),e(VP,xno),e(Wn,$no),e(k,kno),e(k,Hn),e(Hn,ese),e(ese,Sno),e(Hn,Rno),e(Hn,XP),e(XP,Pno),e(Hn,Bno),e(Hn,zP),e(zP,Ino),e(Hn,Nno),e(k,qno),e(k,Kg),e(Kg,ose),e(ose,jno),e(Kg,Dno),e(Kg,QP),e(QP,Gno),e(Kg,Ono),e(k,Vno),e(k,Un),e(Un,rse),e(rse,Xno),e(Un,zno),e(Un,WP),e(WP,Qno),e(Un,Wno),e(Un,HP),e(HP,Hno),e(Un,Uno),e(k,Jno),e(k,Jn),e(Jn,tse),e(tse,Yno),e(Jn,Kno),e(Jn,UP),e(UP,Zno),e(Jn,eso),e(Jn,JP),e(JP,oso),e(Jn,rso),e(k,tso),e(k,Yn),e(Yn,ase),e(ase,aso),e(Yn,nso),e(Yn,YP),e(YP,sso),e(Yn,lso),e(Yn,KP),e(KP,iso),e(Yn,dso),e(k,cso),e(k,Kn),e(Kn,nse),e(nse,fso),e(Kn,mso),e(Kn,ZP),e(ZP,gso),e(Kn,hso),e(Kn,eB),e(eB,pso),e(Kn,_so),e(k,uso),e(k,Zn),e(Zn,sse),e(sse,bso),e(Zn,vso),e(Zn,oB),e(oB,Fso),e(Zn,Tso),e(Zn,rB),e(rB,Mso),e(Zn,Eso),e(k,Cso),e(k,es),e(es,lse),e(lse,wso),e(es,Aso),e(es,tB),e(tB,Lso),e(es,yso),e(es,aB),e(aB,xso),e(es,$so),e(k,kso),e(k,Zg),e(Zg,ise),e(ise,Sso),e(Zg,Rso),e(Zg,nB),e(nB,Pso),e(Zg,Bso),e(k,Iso),e(k,os),e(os,dse),e(dse,Nso),e(os,qso),e(os,sB),e(sB,jso),e(os,Dso),e(os,lB),e(lB,Gso),e(os,Oso),e(k,Vso),e(k,eh),e(eh,cse),e(cse,Xso),e(eh,zso),e(eh,iB),e(iB,Qso),e(eh,Wso),e(k,Hso),e(k,rs),e(rs,fse),e(fse,Uso),e(rs,Jso),e(rs,dB),e(dB,Yso),e(rs,Kso),e(rs,cB),e(cB,Zso),e(rs,elo),e(k,olo),e(k,ts),e(ts,mse),e(mse,rlo),e(ts,tlo),e(ts,fB),e(fB,alo),e(ts,nlo),e(ts,mB),e(mB,slo),e(ts,llo),e(k,ilo),e(k,as),e(as,gse),e(gse,dlo),e(as,clo),e(as,gB),e(gB,flo),e(as,mlo),e(as,hB),e(hB,glo),e(as,hlo),e(k,plo),e(k,oh),e(oh,hse),e(hse,_lo),e(oh,ulo),e(oh,pB),e(pB,blo),e(oh,vlo),e(k,Flo),e(k,ns),e(ns,pse),e(pse,Tlo),e(ns,Mlo),e(ns,_B),e(_B,Elo),e(ns,Clo),e(ns,uB),e(uB,wlo),e(ns,Alo),e(k,Llo),e(k,ss),e(ss,_se),e(_se,ylo),e(ss,xlo),e(ss,bB),e(bB,$lo),e(ss,klo),e(ss,vB),e(vB,Slo),e(ss,Rlo),e(k,Plo),e(k,rh),e(rh,use),e(use,Blo),e(rh,Ilo),e(rh,FB),e(FB,Nlo),e(rh,qlo),e(k,jlo),e(k,ls),e(ls,bse),e(bse,Dlo),e(ls,Glo),e(ls,TB),e(TB,Olo),e(ls,Vlo),e(ls,MB),e(MB,Xlo),e(ls,zlo),e(k,Qlo),e(k,is),e(is,vse),e(vse,Wlo),e(is,Hlo),e(is,EB),e(EB,Ulo),e(is,Jlo),e(is,CB),e(CB,Ylo),e(is,Klo),e(k,Zlo),e(k,ds),e(ds,Fse),e(Fse,eio),e(ds,oio),e(ds,wB),e(wB,rio),e(ds,tio),e(ds,AB),e(AB,aio),e(ds,nio),e(k,sio),e(k,cs),e(cs,Tse),e(Tse,lio),e(cs,iio),e(cs,LB),e(LB,dio),e(cs,cio),e(cs,yB),e(yB,fio),e(cs,mio),e(k,gio),e(k,fs),e(fs,Mse),e(Mse,hio),e(fs,pio),e(fs,xB),e(xB,_io),e(fs,uio),e(fs,$B),e($B,bio),e(fs,vio),e(k,Fio),e(k,ms),e(ms,Ese),e(Ese,Tio),e(ms,Mio),e(ms,kB),e(kB,Eio),e(ms,Cio),e(ms,SB),e(SB,wio),e(ms,Aio),e(k,Lio),e(k,gs),e(gs,Cse),e(Cse,yio),e(gs,xio),e(gs,RB),e(RB,$io),e(gs,kio),e(gs,PB),e(PB,Sio),e(gs,Rio),e(k,Pio),e(k,hs),e(hs,wse),e(wse,Bio),e(hs,Iio),e(hs,BB),e(BB,Nio),e(hs,qio),e(hs,IB),e(IB,jio),e(hs,Dio),e(k,Gio),e(k,th),e(th,Ase),e(Ase,Oio),e(th,Vio),e(th,NB),e(NB,Xio),e(th,zio),e(k,Qio),e(k,ps),e(ps,Lse),e(Lse,Wio),e(ps,Hio),e(ps,qB),e(qB,Uio),e(ps,Jio),e(ps,jB),e(jB,Yio),e(ps,Kio),e(k,Zio),e(k,ah),e(ah,yse),e(yse,edo),e(ah,odo),e(ah,DB),e(DB,rdo),e(ah,tdo),e(k,ado),e(k,nh),e(nh,xse),e(xse,ndo),e(nh,sdo),e(nh,GB),e(GB,ldo),e(nh,ido),e(k,ddo),e(k,_s),e(_s,$se),e($se,cdo),e(_s,fdo),e(_s,OB),e(OB,mdo),e(_s,gdo),e(_s,VB),e(VB,hdo),e(_s,pdo),e(k,_do),e(k,us),e(us,kse),e(kse,udo),e(us,bdo),e(us,XB),e(XB,vdo),e(us,Fdo),e(us,zB),e(zB,Tdo),e(us,Mdo),e(k,Edo),e(k,bs),e(bs,Sse),e(Sse,Cdo),e(bs,wdo),e(bs,QB),e(QB,Ado),e(bs,Ldo),e(bs,WB),e(WB,ydo),e(bs,xdo),e(k,$do),e(k,sh),e(sh,Rse),e(Rse,kdo),e(sh,Sdo),e(sh,HB),e(HB,Rdo),e(sh,Pdo),e(k,Bdo),e(k,vs),e(vs,Pse),e(Pse,Ido),e(vs,Ndo),e(vs,UB),e(UB,qdo),e(vs,jdo),e(vs,JB),e(JB,Ddo),e(vs,Gdo),e(k,Odo),e(k,Fs),e(Fs,Bse),e(Bse,Vdo),e(Fs,Xdo),e(Fs,YB),e(YB,zdo),e(Fs,Qdo),e(Fs,KB),e(KB,Wdo),e(Fs,Hdo),e(k,Udo),e(k,Ts),e(Ts,Ise),e(Ise,Jdo),e(Ts,Ydo),e(Ts,ZB),e(ZB,Kdo),e(Ts,Zdo),e(Ts,eI),e(eI,eco),e(Ts,oco),e(k,rco),e(k,Ms),e(Ms,Nse),e(Nse,tco),e(Ms,aco),e(Ms,oI),e(oI,nco),e(Ms,sco),e(Ms,rI),e(rI,lco),e(Ms,ico),e(k,dco),e(k,Es),e(Es,qse),e(qse,cco),e(Es,fco),e(Es,tI),e(tI,mco),e(Es,gco),e(Es,aI),e(aI,hco),e(Es,pco),e(k,_co),e(k,Cs),e(Cs,jse),e(jse,uco),e(Cs,bco),e(Cs,nI),e(nI,vco),e(Cs,Fco),e(Cs,sI),e(sI,Tco),e(Cs,Mco),e(k,Eco),e(k,lh),e(lh,Dse),e(Dse,Cco),e(lh,wco),e(lh,lI),e(lI,Aco),e(lh,Lco),e(k,yco),e(k,ws),e(ws,Gse),e(Gse,xco),e(ws,$co),e(ws,iI),e(iI,kco),e(ws,Sco),e(ws,dI),e(dI,Rco),e(ws,Pco),e(k,Bco),e(k,ih),e(ih,Ose),e(Ose,Ico),e(ih,Nco),e(ih,cI),e(cI,qco),e(ih,jco),e(k,Dco),e(k,dh),e(dh,Vse),e(Vse,Gco),e(dh,Oco),e(dh,fI),e(fI,Vco),e(dh,Xco),e(k,zco),e(k,ch),e(ch,Xse),e(Xse,Qco),e(ch,Wco),e(ch,mI),e(mI,Hco),e(ch,Uco),e(k,Jco),e(k,fh),e(fh,zse),e(zse,Yco),e(fh,Kco),e(fh,gI),e(gI,Zco),e(fh,efo),e(k,ofo),e(k,As),e(As,Qse),e(Qse,rfo),e(As,tfo),e(As,hI),e(hI,afo),e(As,nfo),e(As,pI),e(pI,sfo),e(As,lfo),e(k,ifo),e(k,mh),e(mh,Wse),e(Wse,dfo),e(mh,cfo),e(mh,_I),e(_I,ffo),e(mh,mfo),e(k,gfo),e(k,Ls),e(Ls,Hse),e(Hse,hfo),e(Ls,pfo),e(Ls,uI),e(uI,_fo),e(Ls,ufo),e(Ls,bI),e(bI,bfo),e(Ls,vfo),e(k,Ffo),e(k,ys),e(ys,Use),e(Use,Tfo),e(ys,Mfo),e(ys,vI),e(vI,Efo),e(ys,Cfo),e(ys,FI),e(FI,wfo),e(ys,Afo),e(k,Lfo),e(k,xs),e(xs,Jse),e(Jse,yfo),e(xs,xfo),e(xs,TI),e(TI,$fo),e(xs,kfo),e(xs,MI),e(MI,Sfo),e(xs,Rfo),e(k,Pfo),e(k,$s),e($s,Yse),e(Yse,Bfo),e($s,Ifo),e($s,EI),e(EI,Nfo),e($s,qfo),e($s,CI),e(CI,jfo),e($s,Dfo),e(k,Gfo),e(k,ks),e(ks,Kse),e(Kse,Ofo),e(ks,Vfo),e(ks,wI),e(wI,Xfo),e(ks,zfo),e(ks,AI),e(AI,Qfo),e(ks,Wfo),e(k,Hfo),e(k,Ss),e(Ss,Zse),e(Zse,Ufo),e(Ss,Jfo),e(Ss,LI),e(LI,Yfo),e(Ss,Kfo),e(Ss,yI),e(yI,Zfo),e(Ss,emo),e(k,omo),e(k,gh),e(gh,ele),e(ele,rmo),e(gh,tmo),e(gh,xI),e(xI,amo),e(gh,nmo),e(k,smo),e(k,hh),e(hh,ole),e(ole,lmo),e(hh,imo),e(hh,$I),e($I,dmo),e(hh,cmo),e(k,fmo),e(k,Rs),e(Rs,rle),e(rle,mmo),e(Rs,gmo),e(Rs,kI),e(kI,hmo),e(Rs,pmo),e(Rs,SI),e(SI,_mo),e(Rs,umo),e(k,bmo),e(k,Ps),e(Ps,tle),e(tle,vmo),e(Ps,Fmo),e(Ps,RI),e(RI,Tmo),e(Ps,Mmo),e(Ps,PI),e(PI,Emo),e(Ps,Cmo),e(k,wmo),e(k,Bs),e(Bs,ale),e(ale,Amo),e(Bs,Lmo),e(Bs,BI),e(BI,ymo),e(Bs,xmo),e(Bs,II),e(II,$mo),e(Bs,kmo),e(k,Smo),e(k,ph),e(ph,nle),e(nle,Rmo),e(ph,Pmo),e(ph,NI),e(NI,Bmo),e(ph,Imo),e(k,Nmo),e(k,_h),e(_h,sle),e(sle,qmo),e(_h,jmo),e(_h,qI),e(qI,Dmo),e(_h,Gmo),e(k,Omo),e(k,uh),e(uh,lle),e(lle,Vmo),e(uh,Xmo),e(uh,jI),e(jI,zmo),e(uh,Qmo),e(k,Wmo),e(k,Is),e(Is,ile),e(ile,Hmo),e(Is,Umo),e(Is,DI),e(DI,Jmo),e(Is,Ymo),e(Is,GI),e(GI,Kmo),e(Is,Zmo),e(k,ego),e(k,Ns),e(Ns,dle),e(dle,ogo),e(Ns,rgo),e(Ns,OI),e(OI,tgo),e(Ns,ago),e(Ns,VI),e(VI,ngo),e(Ns,sgo),e(k,lgo),e(k,bh),e(bh,cle),e(cle,igo),e(bh,dgo),e(bh,XI),e(XI,cgo),e(bh,fgo),e(k,mgo),e(k,vh),e(vh,fle),e(fle,ggo),e(vh,hgo),e(vh,zI),e(zI,pgo),e(vh,_go),e(k,ugo),e(k,Fh),e(Fh,mle),e(mle,bgo),e(Fh,vgo),e(Fh,QI),e(QI,Fgo),e(Fh,Tgo),e(k,Mgo),e(k,qs),e(qs,gle),e(gle,Ego),e(qs,Cgo),e(qs,WI),e(WI,wgo),e(qs,Ago),e(qs,HI),e(HI,Lgo),e(qs,ygo),e(k,xgo),e(k,Th),e(Th,hle),e(hle,$go),e(Th,kgo),e(Th,UI),e(UI,Sgo),e(Th,Rgo),e(k,Pgo),e(k,Mh),e(Mh,ple),e(ple,Bgo),e(Mh,Igo),e(Mh,JI),e(JI,Ngo),e(Mh,qgo),e(k,jgo),e(k,js),e(js,_le),e(_le,Dgo),e(js,Ggo),e(js,YI),e(YI,Ogo),e(js,Vgo),e(js,KI),e(KI,Xgo),e(js,zgo),e(k,Qgo),e(k,Ds),e(Ds,ule),e(ule,Wgo),e(Ds,Hgo),e(Ds,ZI),e(ZI,Ugo),e(Ds,Jgo),e(Ds,eN),e(eN,Ygo),e(Ds,Kgo),e(k,Zgo),e(k,Gs),e(Gs,ble),e(ble,eho),e(Gs,oho),e(Gs,oN),e(oN,rho),e(Gs,tho),e(Gs,rN),e(rN,aho),e(Gs,nho),e(k,sho),e(k,Os),e(Os,vle),e(vle,lho),e(Os,iho),e(Os,tN),e(tN,dho),e(Os,cho),e(Os,aN),e(aN,fho),e(Os,mho),e(Lr,gho),M(Eh,Lr,null),e(Ao,hho),e(Ao,Ch),M(OL,Ch,null),e(Ch,pho),e(Ch,Fle),e(Fle,_ho),b(f,HGe,u),b(f,Si,u),e(Si,wh),e(wh,Tle),M(VL,Tle,null),e(Si,uho),e(Si,Mle),e(Mle,bho),b(f,UGe,u),b(f,Lo,u),M(XL,Lo,null),e(Lo,vho),e(Lo,zL),e(zL,Fho),e(zL,nN),e(nN,Tho),e(zL,Mho),e(Lo,Eho),e(Lo,QL),e(QL,Cho),e(QL,Ele),e(Ele,who),e(QL,Aho),e(Lo,Lho),e(Lo,He),M(WL,He,null),e(He,yho),e(He,Cle),e(Cle,xho),e(He,$ho),e(He,Sa),e(Sa,kho),e(Sa,wle),e(wle,Sho),e(Sa,Rho),e(Sa,Ale),e(Ale,Pho),e(Sa,Bho),e(Sa,Lle),e(Lle,Iho),e(Sa,Nho),e(He,qho),e(He,Y),e(Y,Ah),e(Ah,yle),e(yle,jho),e(Ah,Dho),e(Ah,sN),e(sN,Gho),e(Ah,Oho),e(Y,Vho),e(Y,Lh),e(Lh,xle),e(xle,Xho),e(Lh,zho),e(Lh,lN),e(lN,Qho),e(Lh,Who),e(Y,Hho),e(Y,yh),e(yh,$le),e($le,Uho),e(yh,Jho),e(yh,iN),e(iN,Yho),e(yh,Kho),e(Y,Zho),e(Y,xh),e(xh,kle),e(kle,epo),e(xh,opo),e(xh,dN),e(dN,rpo),e(xh,tpo),e(Y,apo),e(Y,$h),e($h,Sle),e(Sle,npo),e($h,spo),e($h,cN),e(cN,lpo),e($h,ipo),e(Y,dpo),e(Y,kh),e(kh,Rle),e(Rle,cpo),e(kh,fpo),e(kh,fN),e(fN,mpo),e(kh,gpo),e(Y,hpo),e(Y,Sh),e(Sh,Ple),e(Ple,ppo),e(Sh,_po),e(Sh,mN),e(mN,upo),e(Sh,bpo),e(Y,vpo),e(Y,Rh),e(Rh,Ble),e(Ble,Fpo),e(Rh,Tpo),e(Rh,gN),e(gN,Mpo),e(Rh,Epo),e(Y,Cpo),e(Y,Ph),e(Ph,Ile),e(Ile,wpo),e(Ph,Apo),e(Ph,hN),e(hN,Lpo),e(Ph,ypo),e(Y,xpo),e(Y,Bh),e(Bh,Nle),e(Nle,$po),e(Bh,kpo),e(Bh,pN),e(pN,Spo),e(Bh,Rpo),e(Y,Ppo),e(Y,Ih),e(Ih,qle),e(qle,Bpo),e(Ih,Ipo),e(Ih,_N),e(_N,Npo),e(Ih,qpo),e(Y,jpo),e(Y,Nh),e(Nh,jle),e(jle,Dpo),e(Nh,Gpo),e(Nh,uN),e(uN,Opo),e(Nh,Vpo),e(Y,Xpo),e(Y,qh),e(qh,Dle),e(Dle,zpo),e(qh,Qpo),e(qh,bN),e(bN,Wpo),e(qh,Hpo),e(Y,Upo),e(Y,jh),e(jh,Gle),e(Gle,Jpo),e(jh,Ypo),e(jh,vN),e(vN,Kpo),e(jh,Zpo),e(Y,e_o),e(Y,Dh),e(Dh,Ole),e(Ole,o_o),e(Dh,r_o),e(Dh,FN),e(FN,t_o),e(Dh,a_o),e(Y,n_o),e(Y,Gh),e(Gh,Vle),e(Vle,s_o),e(Gh,l_o),e(Gh,TN),e(TN,i_o),e(Gh,d_o),e(Y,c_o),e(Y,Oh),e(Oh,Xle),e(Xle,f_o),e(Oh,m_o),e(Oh,MN),e(MN,g_o),e(Oh,h_o),e(Y,p_o),e(Y,Vh),e(Vh,zle),e(zle,__o),e(Vh,u_o),e(Vh,EN),e(EN,b_o),e(Vh,v_o),e(Y,F_o),e(Y,Xh),e(Xh,Qle),e(Qle,T_o),e(Xh,M_o),e(Xh,CN),e(CN,E_o),e(Xh,C_o),e(Y,w_o),e(Y,zh),e(zh,Wle),e(Wle,A_o),e(zh,L_o),e(zh,wN),e(wN,y_o),e(zh,x_o),e(Y,$_o),e(Y,Qh),e(Qh,Hle),e(Hle,k_o),e(Qh,S_o),e(Qh,AN),e(AN,R_o),e(Qh,P_o),e(Y,B_o),e(Y,Wh),e(Wh,Ule),e(Ule,I_o),e(Wh,N_o),e(Wh,LN),e(LN,q_o),e(Wh,j_o),e(Y,D_o),e(Y,Hh),e(Hh,Jle),e(Jle,G_o),e(Hh,O_o),e(Hh,yN),e(yN,V_o),e(Hh,X_o),e(Y,z_o),e(Y,Uh),e(Uh,Yle),e(Yle,Q_o),e(Uh,W_o),e(Uh,xN),e(xN,H_o),e(Uh,U_o),e(Y,J_o),e(Y,Jh),e(Jh,Kle),e(Kle,Y_o),e(Jh,K_o),e(Jh,$N),e($N,Z_o),e(Jh,euo),e(Y,ouo),e(Y,Yh),e(Yh,Zle),e(Zle,ruo),e(Yh,tuo),e(Yh,kN),e(kN,auo),e(Yh,nuo),e(Y,suo),e(Y,Kh),e(Kh,eie),e(eie,luo),e(Kh,iuo),e(Kh,SN),e(SN,duo),e(Kh,cuo),e(Y,fuo),e(Y,Zh),e(Zh,oie),e(oie,muo),e(Zh,guo),e(Zh,RN),e(RN,huo),e(Zh,puo),e(Y,_uo),e(Y,ep),e(ep,rie),e(rie,uuo),e(ep,buo),e(ep,PN),e(PN,vuo),e(ep,Fuo),e(Y,Tuo),e(Y,op),e(op,tie),e(tie,Muo),e(op,Euo),e(op,BN),e(BN,Cuo),e(op,wuo),e(Y,Auo),e(Y,rp),e(rp,aie),e(aie,Luo),e(rp,yuo),e(rp,IN),e(IN,xuo),e(rp,$uo),e(Y,kuo),e(Y,tp),e(tp,nie),e(nie,Suo),e(tp,Ruo),e(tp,NN),e(NN,Puo),e(tp,Buo),e(He,Iuo),M(ap,He,null),e(He,Nuo),M(np,He,null),e(Lo,quo),e(Lo,sp),M(HL,sp,null),e(sp,juo),e(sp,sie),e(sie,Duo),b(f,JGe,u),b(f,Ri,u),e(Ri,lp),e(lp,lie),M(UL,lie,null),e(Ri,Guo),e(Ri,iie),e(iie,Ouo),b(f,YGe,u),b(f,yo,u),M(JL,yo,null),e(yo,Vuo),e(yo,YL),e(YL,Xuo),e(YL,qN),e(qN,zuo),e(YL,Quo),e(yo,Wuo),e(yo,KL),e(KL,Huo),e(KL,die),e(die,Uuo),e(KL,Juo),e(yo,Yuo),e(yo,Ue),M(ZL,Ue,null),e(Ue,Kuo),e(Ue,cie),e(cie,Zuo),e(Ue,e1o),e(Ue,Pi),e(Pi,o1o),e(Pi,fie),e(fie,r1o),e(Pi,t1o),e(Pi,mie),e(mie,a1o),e(Pi,n1o),e(Ue,s1o),e(Ue,he),e(he,ip),e(ip,gie),e(gie,l1o),e(ip,i1o),e(ip,jN),e(jN,d1o),e(ip,c1o),e(he,f1o),e(he,dp),e(dp,hie),e(hie,m1o),e(dp,g1o),e(dp,pie),e(pie,h1o),e(dp,p1o),e(he,_1o),e(he,cp),e(cp,_ie),e(_ie,u1o),e(cp,b1o),e(cp,DN),e(DN,v1o),e(cp,F1o),e(he,T1o),e(he,fp),e(fp,uie),e(uie,M1o),e(fp,E1o),e(fp,GN),e(GN,C1o),e(fp,w1o),e(he,A1o),e(he,mp),e(mp,bie),e(bie,L1o),e(mp,y1o),e(mp,ON),e(ON,x1o),e(mp,$1o),e(he,k1o),e(he,gp),e(gp,vie),e(vie,S1o),e(gp,R1o),e(gp,VN),e(VN,P1o),e(gp,B1o),e(he,I1o),e(he,hp),e(hp,Fie),e(Fie,N1o),e(hp,q1o),e(hp,XN),e(XN,j1o),e(hp,D1o),e(he,G1o),e(he,pp),e(pp,Tie),e(Tie,O1o),e(pp,V1o),e(pp,zN),e(zN,X1o),e(pp,z1o),e(he,Q1o),e(he,_p),e(_p,Mie),e(Mie,W1o),e(_p,H1o),e(_p,QN),e(QN,U1o),e(_p,J1o),e(he,Y1o),e(he,up),e(up,Eie),e(Eie,K1o),e(up,Z1o),e(up,WN),e(WN,e7o),e(up,o7o),e(he,r7o),e(he,bp),e(bp,Cie),e(Cie,t7o),e(bp,a7o),e(bp,HN),e(HN,n7o),e(bp,s7o),e(he,l7o),e(he,vp),e(vp,wie),e(wie,i7o),e(vp,d7o),e(vp,UN),e(UN,c7o),e(vp,f7o),e(he,m7o),e(he,Fp),e(Fp,Aie),e(Aie,g7o),e(Fp,h7o),e(Fp,JN),e(JN,p7o),e(Fp,_7o),e(he,u7o),e(he,Tp),e(Tp,Lie),e(Lie,b7o),e(Tp,v7o),e(Tp,YN),e(YN,F7o),e(Tp,T7o),e(he,M7o),e(he,Mp),e(Mp,yie),e(yie,E7o),e(Mp,C7o),e(Mp,KN),e(KN,w7o),e(Mp,A7o),e(he,L7o),e(he,Ep),e(Ep,xie),e(xie,y7o),e(Ep,x7o),e(Ep,ZN),e(ZN,$7o),e(Ep,k7o),e(he,S7o),e(he,Cp),e(Cp,$ie),e($ie,R7o),e(Cp,P7o),e(Cp,eq),e(eq,B7o),e(Cp,I7o),e(Ue,N7o),M(wp,Ue,null),e(Ue,q7o),M(Ap,Ue,null),e(yo,j7o),e(yo,Lp),M(ey,Lp,null),e(Lp,D7o),e(Lp,kie),e(kie,G7o),b(f,KGe,u),b(f,Bi,u),e(Bi,yp),e(yp,Sie),M(oy,Sie,null),e(Bi,O7o),e(Bi,Rie),e(Rie,V7o),b(f,ZGe,u),b(f,xo,u),M(ry,xo,null),e(xo,X7o),e(xo,Ii),e(Ii,z7o),e(Ii,oq),e(oq,Q7o),e(Ii,W7o),e(Ii,rq),e(rq,H7o),e(Ii,U7o),e(xo,J7o),e(xo,ty),e(ty,Y7o),e(ty,Pie),e(Pie,K7o),e(ty,Z7o),e(xo,e2o),e(xo,nt),M(ay,nt,null),e(nt,o2o),e(nt,Bie),e(Bie,r2o),e(nt,t2o),e(nt,Ni),e(Ni,a2o),e(Ni,Iie),e(Iie,n2o),e(Ni,s2o),e(Ni,tq),e(tq,l2o),e(Ni,i2o),e(nt,d2o),M(xp,nt,null),e(xo,c2o),e(xo,Je),M(ny,Je,null),e(Je,f2o),e(Je,Nie),e(Nie,m2o),e(Je,g2o),e(Je,Ra),e(Ra,h2o),e(Ra,qie),e(qie,p2o),e(Ra,_2o),e(Ra,jie),e(jie,u2o),e(Ra,b2o),e(Ra,Die),e(Die,v2o),e(Ra,F2o),e(Je,T2o),e(Je,y),e(y,$p),e($p,Gie),e(Gie,M2o),e($p,E2o),e($p,aq),e(aq,C2o),e($p,w2o),e(y,A2o),e(y,kp),e(kp,Oie),e(Oie,L2o),e(kp,y2o),e(kp,nq),e(nq,x2o),e(kp,$2o),e(y,k2o),e(y,Sp),e(Sp,Vie),e(Vie,S2o),e(Sp,R2o),e(Sp,sq),e(sq,P2o),e(Sp,B2o),e(y,I2o),e(y,Rp),e(Rp,Xie),e(Xie,N2o),e(Rp,q2o),e(Rp,lq),e(lq,j2o),e(Rp,D2o),e(y,G2o),e(y,Pp),e(Pp,zie),e(zie,O2o),e(Pp,V2o),e(Pp,iq),e(iq,X2o),e(Pp,z2o),e(y,Q2o),e(y,Bp),e(Bp,Qie),e(Qie,W2o),e(Bp,H2o),e(Bp,dq),e(dq,U2o),e(Bp,J2o),e(y,Y2o),e(y,Ip),e(Ip,Wie),e(Wie,K2o),e(Ip,Z2o),e(Ip,cq),e(cq,ebo),e(Ip,obo),e(y,rbo),e(y,Np),e(Np,Hie),e(Hie,tbo),e(Np,abo),e(Np,fq),e(fq,nbo),e(Np,sbo),e(y,lbo),e(y,qp),e(qp,Uie),e(Uie,ibo),e(qp,dbo),e(qp,mq),e(mq,cbo),e(qp,fbo),e(y,mbo),e(y,jp),e(jp,Jie),e(Jie,gbo),e(jp,hbo),e(jp,gq),e(gq,pbo),e(jp,_bo),e(y,ubo),e(y,Dp),e(Dp,Yie),e(Yie,bbo),e(Dp,vbo),e(Dp,hq),e(hq,Fbo),e(Dp,Tbo),e(y,Mbo),e(y,Gp),e(Gp,Kie),e(Kie,Ebo),e(Gp,Cbo),e(Gp,pq),e(pq,wbo),e(Gp,Abo),e(y,Lbo),e(y,Op),e(Op,Zie),e(Zie,ybo),e(Op,xbo),e(Op,_q),e(_q,$bo),e(Op,kbo),e(y,Sbo),e(y,Vp),e(Vp,ede),e(ede,Rbo),e(Vp,Pbo),e(Vp,uq),e(uq,Bbo),e(Vp,Ibo),e(y,Nbo),e(y,Xp),e(Xp,ode),e(ode,qbo),e(Xp,jbo),e(Xp,bq),e(bq,Dbo),e(Xp,Gbo),e(y,Obo),e(y,zp),e(zp,rde),e(rde,Vbo),e(zp,Xbo),e(zp,vq),e(vq,zbo),e(zp,Qbo),e(y,Wbo),e(y,Qp),e(Qp,tde),e(tde,Hbo),e(Qp,Ubo),e(Qp,Fq),e(Fq,Jbo),e(Qp,Ybo),e(y,Kbo),e(y,Wp),e(Wp,ade),e(ade,Zbo),e(Wp,e5o),e(Wp,Tq),e(Tq,o5o),e(Wp,r5o),e(y,t5o),e(y,Hp),e(Hp,nde),e(nde,a5o),e(Hp,n5o),e(Hp,Mq),e(Mq,s5o),e(Hp,l5o),e(y,i5o),e(y,Up),e(Up,sde),e(sde,d5o),e(Up,c5o),e(Up,Eq),e(Eq,f5o),e(Up,m5o),e(y,g5o),e(y,Jp),e(Jp,lde),e(lde,h5o),e(Jp,p5o),e(Jp,Cq),e(Cq,_5o),e(Jp,u5o),e(y,b5o),e(y,Yp),e(Yp,ide),e(ide,v5o),e(Yp,F5o),e(Yp,wq),e(wq,T5o),e(Yp,M5o),e(y,E5o),e(y,Kp),e(Kp,dde),e(dde,C5o),e(Kp,w5o),e(Kp,Aq),e(Aq,A5o),e(Kp,L5o),e(y,y5o),e(y,Zp),e(Zp,cde),e(cde,x5o),e(Zp,$5o),e(Zp,Lq),e(Lq,k5o),e(Zp,S5o),e(y,R5o),e(y,e_),e(e_,fde),e(fde,P5o),e(e_,B5o),e(e_,yq),e(yq,I5o),e(e_,N5o),e(y,q5o),e(y,o_),e(o_,mde),e(mde,j5o),e(o_,D5o),e(o_,xq),e(xq,G5o),e(o_,O5o),e(y,V5o),e(y,r_),e(r_,gde),e(gde,X5o),e(r_,z5o),e(r_,$q),e($q,Q5o),e(r_,W5o),e(y,H5o),e(y,t_),e(t_,hde),e(hde,U5o),e(t_,J5o),e(t_,kq),e(kq,Y5o),e(t_,K5o),e(y,Z5o),e(y,a_),e(a_,pde),e(pde,evo),e(a_,ovo),e(a_,Sq),e(Sq,rvo),e(a_,tvo),e(y,avo),e(y,n_),e(n_,_de),e(_de,nvo),e(n_,svo),e(n_,Rq),e(Rq,lvo),e(n_,ivo),e(y,dvo),e(y,s_),e(s_,ude),e(ude,cvo),e(s_,fvo),e(s_,Pq),e(Pq,mvo),e(s_,gvo),e(y,hvo),e(y,l_),e(l_,bde),e(bde,pvo),e(l_,_vo),e(l_,Bq),e(Bq,uvo),e(l_,bvo),e(y,vvo),e(y,i_),e(i_,vde),e(vde,Fvo),e(i_,Tvo),e(i_,Iq),e(Iq,Mvo),e(i_,Evo),e(y,Cvo),e(y,Vs),e(Vs,Fde),e(Fde,wvo),e(Vs,Avo),e(Vs,Nq),e(Nq,Lvo),e(Vs,yvo),e(Vs,qq),e(qq,xvo),e(Vs,$vo),e(y,kvo),e(y,d_),e(d_,Tde),e(Tde,Svo),e(d_,Rvo),e(d_,jq),e(jq,Pvo),e(d_,Bvo),e(y,Ivo),e(y,c_),e(c_,Mde),e(Mde,Nvo),e(c_,qvo),e(c_,Dq),e(Dq,jvo),e(c_,Dvo),e(y,Gvo),e(y,f_),e(f_,Ede),e(Ede,Ovo),e(f_,Vvo),e(f_,Gq),e(Gq,Xvo),e(f_,zvo),e(y,Qvo),e(y,m_),e(m_,Cde),e(Cde,Wvo),e(m_,Hvo),e(m_,Oq),e(Oq,Uvo),e(m_,Jvo),e(y,Yvo),e(y,g_),e(g_,wde),e(wde,Kvo),e(g_,Zvo),e(g_,Vq),e(Vq,e3o),e(g_,o3o),e(y,r3o),e(y,h_),e(h_,Ade),e(Ade,t3o),e(h_,a3o),e(h_,Xq),e(Xq,n3o),e(h_,s3o),e(y,l3o),e(y,p_),e(p_,Lde),e(Lde,i3o),e(p_,d3o),e(p_,zq),e(zq,c3o),e(p_,f3o),e(y,m3o),e(y,__),e(__,yde),e(yde,g3o),e(__,h3o),e(__,Qq),e(Qq,p3o),e(__,_3o),e(y,u3o),e(y,u_),e(u_,xde),e(xde,b3o),e(u_,v3o),e(u_,Wq),e(Wq,F3o),e(u_,T3o),e(y,M3o),e(y,b_),e(b_,$de),e($de,E3o),e(b_,C3o),e(b_,Hq),e(Hq,w3o),e(b_,A3o),e(y,L3o),e(y,v_),e(v_,kde),e(kde,y3o),e(v_,x3o),e(v_,Uq),e(Uq,$3o),e(v_,k3o),e(y,S3o),e(y,F_),e(F_,Sde),e(Sde,R3o),e(F_,P3o),e(F_,Jq),e(Jq,B3o),e(F_,I3o),e(y,N3o),e(y,T_),e(T_,Rde),e(Rde,q3o),e(T_,j3o),e(T_,Yq),e(Yq,D3o),e(T_,G3o),e(y,O3o),e(y,M_),e(M_,Pde),e(Pde,V3o),e(M_,X3o),e(M_,Kq),e(Kq,z3o),e(M_,Q3o),e(y,W3o),e(y,E_),e(E_,Bde),e(Bde,H3o),e(E_,U3o),e(E_,Zq),e(Zq,J3o),e(E_,Y3o),e(y,K3o),e(y,C_),e(C_,Ide),e(Ide,Z3o),e(C_,eFo),e(C_,ej),e(ej,oFo),e(C_,rFo),e(y,tFo),e(y,w_),e(w_,Nde),e(Nde,aFo),e(w_,nFo),e(w_,oj),e(oj,sFo),e(w_,lFo),e(y,iFo),e(y,A_),e(A_,qde),e(qde,dFo),e(A_,cFo),e(A_,rj),e(rj,fFo),e(A_,mFo),e(y,gFo),e(y,L_),e(L_,jde),e(jde,hFo),e(L_,pFo),e(L_,tj),e(tj,_Fo),e(L_,uFo),e(y,bFo),e(y,y_),e(y_,Dde),e(Dde,vFo),e(y_,FFo),e(y_,aj),e(aj,TFo),e(y_,MFo),e(y,EFo),e(y,x_),e(x_,Gde),e(Gde,CFo),e(x_,wFo),e(x_,nj),e(nj,AFo),e(x_,LFo),e(y,yFo),e(y,$_),e($_,Ode),e(Ode,xFo),e($_,$Fo),e($_,sj),e(sj,kFo),e($_,SFo),e(y,RFo),e(y,k_),e(k_,Vde),e(Vde,PFo),e(k_,BFo),e(k_,lj),e(lj,IFo),e(k_,NFo),e(y,qFo),e(y,S_),e(S_,Xde),e(Xde,jFo),e(S_,DFo),e(S_,ij),e(ij,GFo),e(S_,OFo),e(y,VFo),e(y,R_),e(R_,zde),e(zde,XFo),e(R_,zFo),e(R_,dj),e(dj,QFo),e(R_,WFo),e(y,HFo),e(y,P_),e(P_,Qde),e(Qde,UFo),e(P_,JFo),e(P_,cj),e(cj,YFo),e(P_,KFo),e(y,ZFo),e(y,B_),e(B_,Wde),e(Wde,eTo),e(B_,oTo),e(B_,fj),e(fj,rTo),e(B_,tTo),e(y,aTo),e(y,I_),e(I_,Hde),e(Hde,nTo),e(I_,sTo),e(I_,mj),e(mj,lTo),e(I_,iTo),e(y,dTo),e(y,N_),e(N_,Ude),e(Ude,cTo),e(N_,fTo),e(N_,gj),e(gj,mTo),e(N_,gTo),e(y,hTo),e(y,q_),e(q_,Jde),e(Jde,pTo),e(q_,_To),e(q_,hj),e(hj,uTo),e(q_,bTo),e(y,vTo),e(y,j_),e(j_,Yde),e(Yde,FTo),e(j_,TTo),e(j_,pj),e(pj,MTo),e(j_,ETo),e(y,CTo),e(y,D_),e(D_,Kde),e(Kde,wTo),e(D_,ATo),e(D_,_j),e(_j,LTo),e(D_,yTo),e(y,xTo),e(y,G_),e(G_,Zde),e(Zde,$To),e(G_,kTo),e(G_,uj),e(uj,STo),e(G_,RTo),e(y,PTo),e(y,O_),e(O_,ece),e(ece,BTo),e(O_,ITo),e(O_,bj),e(bj,NTo),e(O_,qTo),e(y,jTo),e(y,V_),e(V_,oce),e(oce,DTo),e(V_,GTo),e(V_,vj),e(vj,OTo),e(V_,VTo),e(y,XTo),e(y,X_),e(X_,rce),e(rce,zTo),e(X_,QTo),e(X_,Fj),e(Fj,WTo),e(X_,HTo),e(y,UTo),e(y,z_),e(z_,tce),e(tce,JTo),e(z_,YTo),e(z_,Tj),e(Tj,KTo),e(z_,ZTo),e(y,eMo),e(y,Q_),e(Q_,ace),e(ace,oMo),e(Q_,rMo),e(Q_,Mj),e(Mj,tMo),e(Q_,aMo),e(y,nMo),e(y,W_),e(W_,nce),e(nce,sMo),e(W_,lMo),e(W_,Ej),e(Ej,iMo),e(W_,dMo),e(y,cMo),e(y,H_),e(H_,sce),e(sce,fMo),e(H_,mMo),e(H_,Cj),e(Cj,gMo),e(H_,hMo),e(y,pMo),e(y,U_),e(U_,lce),e(lce,_Mo),e(U_,uMo),e(U_,wj),e(wj,bMo),e(U_,vMo),e(y,FMo),e(y,J_),e(J_,ice),e(ice,TMo),e(J_,MMo),e(J_,Aj),e(Aj,EMo),e(J_,CMo),e(y,wMo),e(y,Y_),e(Y_,dce),e(dce,AMo),e(Y_,LMo),e(Y_,Lj),e(Lj,yMo),e(Y_,xMo),e(y,$Mo),e(y,K_),e(K_,cce),e(cce,kMo),e(K_,SMo),e(K_,yj),e(yj,RMo),e(K_,PMo),e(y,BMo),e(y,Z_),e(Z_,fce),e(fce,IMo),e(Z_,NMo),e(Z_,xj),e(xj,qMo),e(Z_,jMo),e(y,DMo),e(y,eu),e(eu,mce),e(mce,GMo),e(eu,OMo),e(eu,$j),e($j,VMo),e(eu,XMo),e(y,zMo),e(y,ou),e(ou,gce),e(gce,QMo),e(ou,WMo),e(ou,kj),e(kj,HMo),e(ou,UMo),e(y,JMo),e(y,ru),e(ru,hce),e(hce,YMo),e(ru,KMo),e(ru,Sj),e(Sj,ZMo),e(ru,eEo),e(y,oEo),e(y,tu),e(tu,pce),e(pce,rEo),e(tu,tEo),e(tu,Rj),e(Rj,aEo),e(tu,nEo),e(y,sEo),e(y,au),e(au,_ce),e(_ce,lEo),e(au,iEo),e(au,Pj),e(Pj,dEo),e(au,cEo),e(y,fEo),e(y,nu),e(nu,uce),e(uce,mEo),e(nu,gEo),e(nu,Bj),e(Bj,hEo),e(nu,pEo),e(y,_Eo),e(y,su),e(su,bce),e(bce,uEo),e(su,bEo),e(su,Ij),e(Ij,vEo),e(su,FEo),e(y,TEo),e(y,lu),e(lu,vce),e(vce,MEo),e(lu,EEo),e(lu,Nj),e(Nj,CEo),e(lu,wEo),e(y,AEo),e(y,iu),e(iu,Fce),e(Fce,LEo),e(iu,yEo),e(iu,qj),e(qj,xEo),e(iu,$Eo),e(y,kEo),e(y,du),e(du,Tce),e(Tce,SEo),e(du,REo),e(du,jj),e(jj,PEo),e(du,BEo),e(y,IEo),e(y,cu),e(cu,Mce),e(Mce,NEo),e(cu,qEo),e(cu,Dj),e(Dj,jEo),e(cu,DEo),e(y,GEo),e(y,fu),e(fu,Ece),e(Ece,OEo),e(fu,VEo),e(fu,Gj),e(Gj,XEo),e(fu,zEo),e(y,QEo),e(y,mu),e(mu,Cce),e(Cce,WEo),e(mu,HEo),e(mu,Oj),e(Oj,UEo),e(mu,JEo),e(y,YEo),e(y,gu),e(gu,wce),e(wce,KEo),e(gu,ZEo),e(gu,Vj),e(Vj,e4o),e(gu,o4o),e(y,r4o),e(y,hu),e(hu,Ace),e(Ace,t4o),e(hu,a4o),e(hu,Xj),e(Xj,n4o),e(hu,s4o),e(y,l4o),e(y,pu),e(pu,Lce),e(Lce,i4o),e(pu,d4o),e(pu,zj),e(zj,c4o),e(pu,f4o),e(y,m4o),e(y,_u),e(_u,yce),e(yce,g4o),e(_u,h4o),e(_u,Qj),e(Qj,p4o),e(_u,_4o),e(y,u4o),e(y,uu),e(uu,xce),e(xce,b4o),e(uu,v4o),e(uu,Wj),e(Wj,F4o),e(uu,T4o),e(y,M4o),e(y,bu),e(bu,$ce),e($ce,E4o),e(bu,C4o),e(bu,Hj),e(Hj,w4o),e(bu,A4o),e(y,L4o),e(y,vu),e(vu,kce),e(kce,y4o),e(vu,x4o),e(vu,Uj),e(Uj,$4o),e(vu,k4o),e(y,S4o),e(y,Fu),e(Fu,Sce),e(Sce,R4o),e(Fu,P4o),e(Fu,Jj),e(Jj,B4o),e(Fu,I4o),e(y,N4o),e(y,Tu),e(Tu,Rce),e(Rce,q4o),e(Tu,j4o),e(Tu,Yj),e(Yj,D4o),e(Tu,G4o),e(y,O4o),e(y,Mu),e(Mu,Pce),e(Pce,V4o),e(Mu,X4o),e(Mu,Kj),e(Kj,z4o),e(Mu,Q4o),e(y,W4o),e(y,Eu),e(Eu,Bce),e(Bce,H4o),e(Eu,U4o),e(Eu,Zj),e(Zj,J4o),e(Eu,Y4o),e(y,K4o),e(y,Cu),e(Cu,Ice),e(Ice,Z4o),e(Cu,eCo),e(Cu,eD),e(eD,oCo),e(Cu,rCo),e(y,tCo),e(y,wu),e(wu,Nce),e(Nce,aCo),e(wu,nCo),e(wu,oD),e(oD,sCo),e(wu,lCo),e(y,iCo),e(y,Au),e(Au,qce),e(qce,dCo),e(Au,cCo),e(Au,rD),e(rD,fCo),e(Au,mCo),e(y,gCo),e(y,Lu),e(Lu,jce),e(jce,hCo),e(Lu,pCo),e(Lu,tD),e(tD,_Co),e(Lu,uCo),e(Je,bCo),e(Je,yu),e(yu,vCo),e(yu,Dce),e(Dce,FCo),e(yu,TCo),e(yu,Gce),e(Gce,MCo),e(Je,ECo),M(xu,Je,null),b(f,eOe,u),b(f,qi,u),e(qi,$u),e($u,Oce),M(sy,Oce,null),e(qi,CCo),e(qi,Vce),e(Vce,wCo),b(f,oOe,u),b(f,$o,u),M(ly,$o,null),e($o,ACo),e($o,ji),e(ji,LCo),e(ji,aD),e(aD,yCo),e(ji,xCo),e(ji,nD),e(nD,$Co),e(ji,kCo),e($o,SCo),e($o,iy),e(iy,RCo),e(iy,Xce),e(Xce,PCo),e(iy,BCo),e($o,ICo),e($o,st),M(dy,st,null),e(st,NCo),e(st,zce),e(zce,qCo),e(st,jCo),e(st,Di),e(Di,DCo),e(Di,Qce),e(Qce,GCo),e(Di,OCo),e(Di,sD),e(sD,VCo),e(Di,XCo),e(st,zCo),M(ku,st,null),e($o,QCo),e($o,Ye),M(cy,Ye,null),e(Ye,WCo),e(Ye,Wce),e(Wce,HCo),e(Ye,UCo),e(Ye,Pa),e(Pa,JCo),e(Pa,Hce),e(Hce,YCo),e(Pa,KCo),e(Pa,Uce),e(Uce,ZCo),e(Pa,e0o),e(Pa,Jce),e(Jce,o0o),e(Pa,r0o),e(Ye,t0o),e(Ye,G),e(G,Su),e(Su,Yce),e(Yce,a0o),e(Su,n0o),e(Su,lD),e(lD,s0o),e(Su,l0o),e(G,i0o),e(G,Ru),e(Ru,Kce),e(Kce,d0o),e(Ru,c0o),e(Ru,iD),e(iD,f0o),e(Ru,m0o),e(G,g0o),e(G,Pu),e(Pu,Zce),e(Zce,h0o),e(Pu,p0o),e(Pu,dD),e(dD,_0o),e(Pu,u0o),e(G,b0o),e(G,Bu),e(Bu,efe),e(efe,v0o),e(Bu,F0o),e(Bu,cD),e(cD,T0o),e(Bu,M0o),e(G,E0o),e(G,Iu),e(Iu,ofe),e(ofe,C0o),e(Iu,w0o),e(Iu,fD),e(fD,A0o),e(Iu,L0o),e(G,y0o),e(G,Nu),e(Nu,rfe),e(rfe,x0o),e(Nu,$0o),e(Nu,mD),e(mD,k0o),e(Nu,S0o),e(G,R0o),e(G,qu),e(qu,tfe),e(tfe,P0o),e(qu,B0o),e(qu,gD),e(gD,I0o),e(qu,N0o),e(G,q0o),e(G,ju),e(ju,afe),e(afe,j0o),e(ju,D0o),e(ju,hD),e(hD,G0o),e(ju,O0o),e(G,V0o),e(G,Du),e(Du,nfe),e(nfe,X0o),e(Du,z0o),e(Du,pD),e(pD,Q0o),e(Du,W0o),e(G,H0o),e(G,Gu),e(Gu,sfe),e(sfe,U0o),e(Gu,J0o),e(Gu,_D),e(_D,Y0o),e(Gu,K0o),e(G,Z0o),e(G,Ou),e(Ou,lfe),e(lfe,ewo),e(Ou,owo),e(Ou,uD),e(uD,rwo),e(Ou,two),e(G,awo),e(G,Vu),e(Vu,ife),e(ife,nwo),e(Vu,swo),e(Vu,bD),e(bD,lwo),e(Vu,iwo),e(G,dwo),e(G,Xu),e(Xu,dfe),e(dfe,cwo),e(Xu,fwo),e(Xu,vD),e(vD,mwo),e(Xu,gwo),e(G,hwo),e(G,zu),e(zu,cfe),e(cfe,pwo),e(zu,_wo),e(zu,FD),e(FD,uwo),e(zu,bwo),e(G,vwo),e(G,Qu),e(Qu,ffe),e(ffe,Fwo),e(Qu,Two),e(Qu,TD),e(TD,Mwo),e(Qu,Ewo),e(G,Cwo),e(G,Wu),e(Wu,mfe),e(mfe,wwo),e(Wu,Awo),e(Wu,MD),e(MD,Lwo),e(Wu,ywo),e(G,xwo),e(G,Hu),e(Hu,gfe),e(gfe,$wo),e(Hu,kwo),e(Hu,ED),e(ED,Swo),e(Hu,Rwo),e(G,Pwo),e(G,Uu),e(Uu,hfe),e(hfe,Bwo),e(Uu,Iwo),e(Uu,CD),e(CD,Nwo),e(Uu,qwo),e(G,jwo),e(G,Ju),e(Ju,pfe),e(pfe,Dwo),e(Ju,Gwo),e(Ju,wD),e(wD,Owo),e(Ju,Vwo),e(G,Xwo),e(G,Yu),e(Yu,_fe),e(_fe,zwo),e(Yu,Qwo),e(Yu,AD),e(AD,Wwo),e(Yu,Hwo),e(G,Uwo),e(G,Ku),e(Ku,ufe),e(ufe,Jwo),e(Ku,Ywo),e(Ku,LD),e(LD,Kwo),e(Ku,Zwo),e(G,eAo),e(G,Zu),e(Zu,bfe),e(bfe,oAo),e(Zu,rAo),e(Zu,yD),e(yD,tAo),e(Zu,aAo),e(G,nAo),e(G,e1),e(e1,vfe),e(vfe,sAo),e(e1,lAo),e(e1,xD),e(xD,iAo),e(e1,dAo),e(G,cAo),e(G,o1),e(o1,Ffe),e(Ffe,fAo),e(o1,mAo),e(o1,$D),e($D,gAo),e(o1,hAo),e(G,pAo),e(G,r1),e(r1,Tfe),e(Tfe,_Ao),e(r1,uAo),e(r1,kD),e(kD,bAo),e(r1,vAo),e(G,FAo),e(G,t1),e(t1,Mfe),e(Mfe,TAo),e(t1,MAo),e(t1,SD),e(SD,EAo),e(t1,CAo),e(G,wAo),e(G,a1),e(a1,Efe),e(Efe,AAo),e(a1,LAo),e(a1,RD),e(RD,yAo),e(a1,xAo),e(G,$Ao),e(G,n1),e(n1,Cfe),e(Cfe,kAo),e(n1,SAo),e(n1,PD),e(PD,RAo),e(n1,PAo),e(G,BAo),e(G,s1),e(s1,wfe),e(wfe,IAo),e(s1,NAo),e(s1,BD),e(BD,qAo),e(s1,jAo),e(G,DAo),e(G,l1),e(l1,Afe),e(Afe,GAo),e(l1,OAo),e(l1,ID),e(ID,VAo),e(l1,XAo),e(G,zAo),e(G,i1),e(i1,Lfe),e(Lfe,QAo),e(i1,WAo),e(i1,ND),e(ND,HAo),e(i1,UAo),e(G,JAo),e(G,d1),e(d1,yfe),e(yfe,YAo),e(d1,KAo),e(d1,qD),e(qD,ZAo),e(d1,e6o),e(G,o6o),e(G,c1),e(c1,xfe),e(xfe,r6o),e(c1,t6o),e(c1,jD),e(jD,a6o),e(c1,n6o),e(G,s6o),e(G,f1),e(f1,$fe),e($fe,l6o),e(f1,i6o),e(f1,DD),e(DD,d6o),e(f1,c6o),e(G,f6o),e(G,m1),e(m1,kfe),e(kfe,m6o),e(m1,g6o),e(m1,GD),e(GD,h6o),e(m1,p6o),e(G,_6o),e(G,g1),e(g1,Sfe),e(Sfe,u6o),e(g1,b6o),e(g1,OD),e(OD,v6o),e(g1,F6o),e(G,T6o),e(G,h1),e(h1,Rfe),e(Rfe,M6o),e(h1,E6o),e(h1,VD),e(VD,C6o),e(h1,w6o),e(G,A6o),e(G,p1),e(p1,Pfe),e(Pfe,L6o),e(p1,y6o),e(p1,XD),e(XD,x6o),e(p1,$6o),e(G,k6o),e(G,_1),e(_1,Bfe),e(Bfe,S6o),e(_1,R6o),e(_1,zD),e(zD,P6o),e(_1,B6o),e(G,I6o),e(G,u1),e(u1,Ife),e(Ife,N6o),e(u1,q6o),e(u1,QD),e(QD,j6o),e(u1,D6o),e(G,G6o),e(G,b1),e(b1,Nfe),e(Nfe,O6o),e(b1,V6o),e(b1,WD),e(WD,X6o),e(b1,z6o),e(G,Q6o),e(G,v1),e(v1,qfe),e(qfe,W6o),e(v1,H6o),e(v1,HD),e(HD,U6o),e(v1,J6o),e(G,Y6o),e(G,F1),e(F1,jfe),e(jfe,K6o),e(F1,Z6o),e(F1,UD),e(UD,eLo),e(F1,oLo),e(G,rLo),e(G,T1),e(T1,Dfe),e(Dfe,tLo),e(T1,aLo),e(T1,JD),e(JD,nLo),e(T1,sLo),e(Ye,lLo),e(Ye,M1),e(M1,iLo),e(M1,Gfe),e(Gfe,dLo),e(M1,cLo),e(M1,Ofe),e(Ofe,fLo),e(Ye,mLo),M(E1,Ye,null),b(f,rOe,u),b(f,Gi,u),e(Gi,C1),e(C1,Vfe),M(fy,Vfe,null),e(Gi,gLo),e(Gi,Xfe),e(Xfe,hLo),b(f,tOe,u),b(f,ko,u),M(my,ko,null),e(ko,pLo),e(ko,Oi),e(Oi,_Lo),e(Oi,YD),e(YD,uLo),e(Oi,bLo),e(Oi,KD),e(KD,vLo),e(Oi,FLo),e(ko,TLo),e(ko,gy),e(gy,MLo),e(gy,zfe),e(zfe,ELo),e(gy,CLo),e(ko,wLo),e(ko,lt),M(hy,lt,null),e(lt,ALo),e(lt,Qfe),e(Qfe,LLo),e(lt,yLo),e(lt,Vi),e(Vi,xLo),e(Vi,Wfe),e(Wfe,$Lo),e(Vi,kLo),e(Vi,ZD),e(ZD,SLo),e(Vi,RLo),e(lt,PLo),M(w1,lt,null),e(ko,BLo),e(ko,Ke),M(py,Ke,null),e(Ke,ILo),e(Ke,Hfe),e(Hfe,NLo),e(Ke,qLo),e(Ke,Ba),e(Ba,jLo),e(Ba,Ufe),e(Ufe,DLo),e(Ba,GLo),e(Ba,Jfe),e(Jfe,OLo),e(Ba,VLo),e(Ba,Yfe),e(Yfe,XLo),e(Ba,zLo),e(Ke,QLo),e(Ke,z),e(z,A1),e(A1,Kfe),e(Kfe,WLo),e(A1,HLo),e(A1,eG),e(eG,ULo),e(A1,JLo),e(z,YLo),e(z,L1),e(L1,Zfe),e(Zfe,KLo),e(L1,ZLo),e(L1,oG),e(oG,eyo),e(L1,oyo),e(z,ryo),e(z,y1),e(y1,eme),e(eme,tyo),e(y1,ayo),e(y1,rG),e(rG,nyo),e(y1,syo),e(z,lyo),e(z,x1),e(x1,ome),e(ome,iyo),e(x1,dyo),e(x1,tG),e(tG,cyo),e(x1,fyo),e(z,myo),e(z,$1),e($1,rme),e(rme,gyo),e($1,hyo),e($1,aG),e(aG,pyo),e($1,_yo),e(z,uyo),e(z,k1),e(k1,tme),e(tme,byo),e(k1,vyo),e(k1,nG),e(nG,Fyo),e(k1,Tyo),e(z,Myo),e(z,S1),e(S1,ame),e(ame,Eyo),e(S1,Cyo),e(S1,sG),e(sG,wyo),e(S1,Ayo),e(z,Lyo),e(z,R1),e(R1,nme),e(nme,yyo),e(R1,xyo),e(R1,lG),e(lG,$yo),e(R1,kyo),e(z,Syo),e(z,P1),e(P1,sme),e(sme,Ryo),e(P1,Pyo),e(P1,iG),e(iG,Byo),e(P1,Iyo),e(z,Nyo),e(z,B1),e(B1,lme),e(lme,qyo),e(B1,jyo),e(B1,dG),e(dG,Dyo),e(B1,Gyo),e(z,Oyo),e(z,I1),e(I1,ime),e(ime,Vyo),e(I1,Xyo),e(I1,cG),e(cG,zyo),e(I1,Qyo),e(z,Wyo),e(z,N1),e(N1,dme),e(dme,Hyo),e(N1,Uyo),e(N1,fG),e(fG,Jyo),e(N1,Yyo),e(z,Kyo),e(z,q1),e(q1,cme),e(cme,Zyo),e(q1,e8o),e(q1,mG),e(mG,o8o),e(q1,r8o),e(z,t8o),e(z,j1),e(j1,fme),e(fme,a8o),e(j1,n8o),e(j1,gG),e(gG,s8o),e(j1,l8o),e(z,i8o),e(z,D1),e(D1,mme),e(mme,d8o),e(D1,c8o),e(D1,hG),e(hG,f8o),e(D1,m8o),e(z,g8o),e(z,G1),e(G1,gme),e(gme,h8o),e(G1,p8o),e(G1,pG),e(pG,_8o),e(G1,u8o),e(z,b8o),e(z,O1),e(O1,hme),e(hme,v8o),e(O1,F8o),e(O1,_G),e(_G,T8o),e(O1,M8o),e(z,E8o),e(z,V1),e(V1,pme),e(pme,C8o),e(V1,w8o),e(V1,uG),e(uG,A8o),e(V1,L8o),e(z,y8o),e(z,X1),e(X1,_me),e(_me,x8o),e(X1,$8o),e(X1,bG),e(bG,k8o),e(X1,S8o),e(z,R8o),e(z,z1),e(z1,ume),e(ume,P8o),e(z1,B8o),e(z1,vG),e(vG,I8o),e(z1,N8o),e(z,q8o),e(z,Q1),e(Q1,bme),e(bme,j8o),e(Q1,D8o),e(Q1,FG),e(FG,G8o),e(Q1,O8o),e(z,V8o),e(z,W1),e(W1,vme),e(vme,X8o),e(W1,z8o),e(W1,TG),e(TG,Q8o),e(W1,W8o),e(z,H8o),e(z,H1),e(H1,Fme),e(Fme,U8o),e(H1,J8o),e(H1,MG),e(MG,Y8o),e(H1,K8o),e(z,Z8o),e(z,U1),e(U1,Tme),e(Tme,e9o),e(U1,o9o),e(U1,EG),e(EG,r9o),e(U1,t9o),e(z,a9o),e(z,J1),e(J1,Mme),e(Mme,n9o),e(J1,s9o),e(J1,CG),e(CG,l9o),e(J1,i9o),e(z,d9o),e(z,Y1),e(Y1,Eme),e(Eme,c9o),e(Y1,f9o),e(Y1,wG),e(wG,m9o),e(Y1,g9o),e(z,h9o),e(z,K1),e(K1,Cme),e(Cme,p9o),e(K1,_9o),e(K1,AG),e(AG,u9o),e(K1,b9o),e(z,v9o),e(z,Z1),e(Z1,wme),e(wme,F9o),e(Z1,T9o),e(Z1,LG),e(LG,M9o),e(Z1,E9o),e(z,C9o),e(z,e7),e(e7,Ame),e(Ame,w9o),e(e7,A9o),e(e7,yG),e(yG,L9o),e(e7,y9o),e(z,x9o),e(z,o7),e(o7,Lme),e(Lme,$9o),e(o7,k9o),e(o7,xG),e(xG,S9o),e(o7,R9o),e(z,P9o),e(z,r7),e(r7,yme),e(yme,B9o),e(r7,I9o),e(r7,$G),e($G,N9o),e(r7,q9o),e(z,j9o),e(z,t7),e(t7,xme),e(xme,D9o),e(t7,G9o),e(t7,kG),e(kG,O9o),e(t7,V9o),e(z,X9o),e(z,a7),e(a7,$me),e($me,z9o),e(a7,Q9o),e(a7,SG),e(SG,W9o),e(a7,H9o),e(z,U9o),e(z,n7),e(n7,kme),e(kme,J9o),e(n7,Y9o),e(n7,RG),e(RG,K9o),e(n7,Z9o),e(z,exo),e(z,s7),e(s7,Sme),e(Sme,oxo),e(s7,rxo),e(s7,PG),e(PG,txo),e(s7,axo),e(z,nxo),e(z,l7),e(l7,Rme),e(Rme,sxo),e(l7,lxo),e(l7,BG),e(BG,ixo),e(l7,dxo),e(z,cxo),e(z,i7),e(i7,Pme),e(Pme,fxo),e(i7,mxo),e(i7,IG),e(IG,gxo),e(i7,hxo),e(z,pxo),e(z,d7),e(d7,Bme),e(Bme,_xo),e(d7,uxo),e(d7,NG),e(NG,bxo),e(d7,vxo),e(Ke,Fxo),e(Ke,c7),e(c7,Txo),e(c7,Ime),e(Ime,Mxo),e(c7,Exo),e(c7,Nme),e(Nme,Cxo),e(Ke,wxo),M(f7,Ke,null),b(f,aOe,u),b(f,Xi,u),e(Xi,m7),e(m7,qme),M(_y,qme,null),e(Xi,Axo),e(Xi,jme),e(jme,Lxo),b(f,nOe,u),b(f,So,u),M(uy,So,null),e(So,yxo),e(So,zi),e(zi,xxo),e(zi,qG),e(qG,$xo),e(zi,kxo),e(zi,jG),e(jG,Sxo),e(zi,Rxo),e(So,Pxo),e(So,by),e(by,Bxo),e(by,Dme),e(Dme,Ixo),e(by,Nxo),e(So,qxo),e(So,it),M(vy,it,null),e(it,jxo),e(it,Gme),e(Gme,Dxo),e(it,Gxo),e(it,Qi),e(Qi,Oxo),e(Qi,Ome),e(Ome,Vxo),e(Qi,Xxo),e(Qi,DG),e(DG,zxo),e(Qi,Qxo),e(it,Wxo),M(g7,it,null),e(So,Hxo),e(So,Ze),M(Fy,Ze,null),e(Ze,Uxo),e(Ze,Vme),e(Vme,Jxo),e(Ze,Yxo),e(Ze,Ia),e(Ia,Kxo),e(Ia,Xme),e(Xme,Zxo),e(Ia,e$o),e(Ia,zme),e(zme,o$o),e(Ia,r$o),e(Ia,Qme),e(Qme,t$o),e(Ia,a$o),e(Ze,n$o),e(Ze,Q),e(Q,h7),e(h7,Wme),e(Wme,s$o),e(h7,l$o),e(h7,GG),e(GG,i$o),e(h7,d$o),e(Q,c$o),e(Q,p7),e(p7,Hme),e(Hme,f$o),e(p7,m$o),e(p7,OG),e(OG,g$o),e(p7,h$o),e(Q,p$o),e(Q,_7),e(_7,Ume),e(Ume,_$o),e(_7,u$o),e(_7,VG),e(VG,b$o),e(_7,v$o),e(Q,F$o),e(Q,u7),e(u7,Jme),e(Jme,T$o),e(u7,M$o),e(u7,XG),e(XG,E$o),e(u7,C$o),e(Q,w$o),e(Q,b7),e(b7,Yme),e(Yme,A$o),e(b7,L$o),e(b7,zG),e(zG,y$o),e(b7,x$o),e(Q,$$o),e(Q,v7),e(v7,Kme),e(Kme,k$o),e(v7,S$o),e(v7,QG),e(QG,R$o),e(v7,P$o),e(Q,B$o),e(Q,F7),e(F7,Zme),e(Zme,I$o),e(F7,N$o),e(F7,WG),e(WG,q$o),e(F7,j$o),e(Q,D$o),e(Q,T7),e(T7,ege),e(ege,G$o),e(T7,O$o),e(T7,HG),e(HG,V$o),e(T7,X$o),e(Q,z$o),e(Q,M7),e(M7,oge),e(oge,Q$o),e(M7,W$o),e(M7,UG),e(UG,H$o),e(M7,U$o),e(Q,J$o),e(Q,E7),e(E7,rge),e(rge,Y$o),e(E7,K$o),e(E7,JG),e(JG,Z$o),e(E7,eko),e(Q,oko),e(Q,C7),e(C7,tge),e(tge,rko),e(C7,tko),e(C7,YG),e(YG,ako),e(C7,nko),e(Q,sko),e(Q,w7),e(w7,age),e(age,lko),e(w7,iko),e(w7,KG),e(KG,dko),e(w7,cko),e(Q,fko),e(Q,A7),e(A7,nge),e(nge,mko),e(A7,gko),e(A7,ZG),e(ZG,hko),e(A7,pko),e(Q,_ko),e(Q,L7),e(L7,sge),e(sge,uko),e(L7,bko),e(L7,eO),e(eO,vko),e(L7,Fko),e(Q,Tko),e(Q,y7),e(y7,lge),e(lge,Mko),e(y7,Eko),e(y7,oO),e(oO,Cko),e(y7,wko),e(Q,Ako),e(Q,x7),e(x7,ige),e(ige,Lko),e(x7,yko),e(x7,rO),e(rO,xko),e(x7,$ko),e(Q,kko),e(Q,$7),e($7,dge),e(dge,Sko),e($7,Rko),e($7,tO),e(tO,Pko),e($7,Bko),e(Q,Iko),e(Q,k7),e(k7,cge),e(cge,Nko),e(k7,qko),e(k7,aO),e(aO,jko),e(k7,Dko),e(Q,Gko),e(Q,S7),e(S7,fge),e(fge,Oko),e(S7,Vko),e(S7,nO),e(nO,Xko),e(S7,zko),e(Q,Qko),e(Q,R7),e(R7,mge),e(mge,Wko),e(R7,Hko),e(R7,sO),e(sO,Uko),e(R7,Jko),e(Q,Yko),e(Q,P7),e(P7,gge),e(gge,Kko),e(P7,Zko),e(P7,lO),e(lO,eSo),e(P7,oSo),e(Q,rSo),e(Q,B7),e(B7,hge),e(hge,tSo),e(B7,aSo),e(B7,iO),e(iO,nSo),e(B7,sSo),e(Q,lSo),e(Q,I7),e(I7,pge),e(pge,iSo),e(I7,dSo),e(I7,dO),e(dO,cSo),e(I7,fSo),e(Q,mSo),e(Q,N7),e(N7,_ge),e(_ge,gSo),e(N7,hSo),e(N7,cO),e(cO,pSo),e(N7,_So),e(Q,uSo),e(Q,q7),e(q7,uge),e(uge,bSo),e(q7,vSo),e(q7,fO),e(fO,FSo),e(q7,TSo),e(Q,MSo),e(Q,j7),e(j7,bge),e(bge,ESo),e(j7,CSo),e(j7,mO),e(mO,wSo),e(j7,ASo),e(Q,LSo),e(Q,D7),e(D7,vge),e(vge,ySo),e(D7,xSo),e(D7,gO),e(gO,$So),e(D7,kSo),e(Q,SSo),e(Q,G7),e(G7,Fge),e(Fge,RSo),e(G7,PSo),e(G7,hO),e(hO,BSo),e(G7,ISo),e(Q,NSo),e(Q,O7),e(O7,Tge),e(Tge,qSo),e(O7,jSo),e(O7,pO),e(pO,DSo),e(O7,GSo),e(Q,OSo),e(Q,V7),e(V7,Mge),e(Mge,VSo),e(V7,XSo),e(V7,_O),e(_O,zSo),e(V7,QSo),e(Q,WSo),e(Q,X7),e(X7,Ege),e(Ege,HSo),e(X7,USo),e(X7,uO),e(uO,JSo),e(X7,YSo),e(Q,KSo),e(Q,z7),e(z7,Cge),e(Cge,ZSo),e(z7,eRo),e(z7,bO),e(bO,oRo),e(z7,rRo),e(Q,tRo),e(Q,Q7),e(Q7,wge),e(wge,aRo),e(Q7,nRo),e(Q7,Age),e(Age,sRo),e(Q7,lRo),e(Q,iRo),e(Q,W7),e(W7,Lge),e(Lge,dRo),e(W7,cRo),e(W7,vO),e(vO,fRo),e(W7,mRo),e(Q,gRo),e(Q,H7),e(H7,yge),e(yge,hRo),e(H7,pRo),e(H7,FO),e(FO,_Ro),e(H7,uRo),e(Q,bRo),e(Q,U7),e(U7,xge),e(xge,vRo),e(U7,FRo),e(U7,TO),e(TO,TRo),e(U7,MRo),e(Q,ERo),e(Q,J7),e(J7,$ge),e($ge,CRo),e(J7,wRo),e(J7,MO),e(MO,ARo),e(J7,LRo),e(Ze,yRo),e(Ze,Y7),e(Y7,xRo),e(Y7,kge),e(kge,$Ro),e(Y7,kRo),e(Y7,Sge),e(Sge,SRo),e(Ze,RRo),M(K7,Ze,null),b(f,sOe,u),b(f,Wi,u),e(Wi,Z7),e(Z7,Rge),M(Ty,Rge,null),e(Wi,PRo),e(Wi,Pge),e(Pge,BRo),b(f,lOe,u),b(f,Ro,u),M(My,Ro,null),e(Ro,IRo),e(Ro,Hi),e(Hi,NRo),e(Hi,EO),e(EO,qRo),e(Hi,jRo),e(Hi,CO),e(CO,DRo),e(Hi,GRo),e(Ro,ORo),e(Ro,Ey),e(Ey,VRo),e(Ey,Bge),e(Bge,XRo),e(Ey,zRo),e(Ro,QRo),e(Ro,dt),M(Cy,dt,null),e(dt,WRo),e(dt,Ige),e(Ige,HRo),e(dt,URo),e(dt,Ui),e(Ui,JRo),e(Ui,Nge),e(Nge,YRo),e(Ui,KRo),e(Ui,wO),e(wO,ZRo),e(Ui,ePo),e(dt,oPo),M(e2,dt,null),e(Ro,rPo),e(Ro,eo),M(wy,eo,null),e(eo,tPo),e(eo,qge),e(qge,aPo),e(eo,nPo),e(eo,Na),e(Na,sPo),e(Na,jge),e(jge,lPo),e(Na,iPo),e(Na,Dge),e(Dge,dPo),e(Na,cPo),e(Na,Gge),e(Gge,fPo),e(Na,mPo),e(eo,gPo),e(eo,pe),e(pe,o2),e(o2,Oge),e(Oge,hPo),e(o2,pPo),e(o2,AO),e(AO,_Po),e(o2,uPo),e(pe,bPo),e(pe,r2),e(r2,Vge),e(Vge,vPo),e(r2,FPo),e(r2,LO),e(LO,TPo),e(r2,MPo),e(pe,EPo),e(pe,t2),e(t2,Xge),e(Xge,CPo),e(t2,wPo),e(t2,yO),e(yO,APo),e(t2,LPo),e(pe,yPo),e(pe,a2),e(a2,zge),e(zge,xPo),e(a2,$Po),e(a2,xO),e(xO,kPo),e(a2,SPo),e(pe,RPo),e(pe,n2),e(n2,Qge),e(Qge,PPo),e(n2,BPo),e(n2,$O),e($O,IPo),e(n2,NPo),e(pe,qPo),e(pe,s2),e(s2,Wge),e(Wge,jPo),e(s2,DPo),e(s2,kO),e(kO,GPo),e(s2,OPo),e(pe,VPo),e(pe,l2),e(l2,Hge),e(Hge,XPo),e(l2,zPo),e(l2,SO),e(SO,QPo),e(l2,WPo),e(pe,HPo),e(pe,i2),e(i2,Uge),e(Uge,UPo),e(i2,JPo),e(i2,RO),e(RO,YPo),e(i2,KPo),e(pe,ZPo),e(pe,d2),e(d2,Jge),e(Jge,eBo),e(d2,oBo),e(d2,PO),e(PO,rBo),e(d2,tBo),e(pe,aBo),e(pe,c2),e(c2,Yge),e(Yge,nBo),e(c2,sBo),e(c2,BO),e(BO,lBo),e(c2,iBo),e(pe,dBo),e(pe,f2),e(f2,Kge),e(Kge,cBo),e(f2,fBo),e(f2,IO),e(IO,mBo),e(f2,gBo),e(pe,hBo),e(pe,m2),e(m2,Zge),e(Zge,pBo),e(m2,_Bo),e(m2,NO),e(NO,uBo),e(m2,bBo),e(pe,vBo),e(pe,g2),e(g2,ehe),e(ehe,FBo),e(g2,TBo),e(g2,qO),e(qO,MBo),e(g2,EBo),e(pe,CBo),e(pe,h2),e(h2,ohe),e(ohe,wBo),e(h2,ABo),e(h2,jO),e(jO,LBo),e(h2,yBo),e(pe,xBo),e(pe,p2),e(p2,rhe),e(rhe,$Bo),e(p2,kBo),e(p2,DO),e(DO,SBo),e(p2,RBo),e(pe,PBo),e(pe,_2),e(_2,the),e(the,BBo),e(_2,IBo),e(_2,GO),e(GO,NBo),e(_2,qBo),e(pe,jBo),e(pe,u2),e(u2,ahe),e(ahe,DBo),e(u2,GBo),e(u2,OO),e(OO,OBo),e(u2,VBo),e(eo,XBo),e(eo,b2),e(b2,zBo),e(b2,nhe),e(nhe,QBo),e(b2,WBo),e(b2,she),e(she,HBo),e(eo,UBo),M(v2,eo,null),b(f,iOe,u),b(f,Ji,u),e(Ji,F2),e(F2,lhe),M(Ay,lhe,null),e(Ji,JBo),e(Ji,ihe),e(ihe,YBo),b(f,dOe,u),b(f,Po,u),M(Ly,Po,null),e(Po,KBo),e(Po,Yi),e(Yi,ZBo),e(Yi,VO),e(VO,eIo),e(Yi,oIo),e(Yi,XO),e(XO,rIo),e(Yi,tIo),e(Po,aIo),e(Po,yy),e(yy,nIo),e(yy,dhe),e(dhe,sIo),e(yy,lIo),e(Po,iIo),e(Po,ct),M(xy,ct,null),e(ct,dIo),e(ct,che),e(che,cIo),e(ct,fIo),e(ct,Ki),e(Ki,mIo),e(Ki,fhe),e(fhe,gIo),e(Ki,hIo),e(Ki,zO),e(zO,pIo),e(Ki,_Io),e(ct,uIo),M(T2,ct,null),e(Po,bIo),e(Po,oo),M($y,oo,null),e(oo,vIo),e(oo,mhe),e(mhe,FIo),e(oo,TIo),e(oo,qa),e(qa,MIo),e(qa,ghe),e(ghe,EIo),e(qa,CIo),e(qa,hhe),e(hhe,wIo),e(qa,AIo),e(qa,phe),e(phe,LIo),e(qa,yIo),e(oo,xIo),e(oo,N),e(N,M2),e(M2,_he),e(_he,$Io),e(M2,kIo),e(M2,QO),e(QO,SIo),e(M2,RIo),e(N,PIo),e(N,E2),e(E2,uhe),e(uhe,BIo),e(E2,IIo),e(E2,WO),e(WO,NIo),e(E2,qIo),e(N,jIo),e(N,C2),e(C2,bhe),e(bhe,DIo),e(C2,GIo),e(C2,HO),e(HO,OIo),e(C2,VIo),e(N,XIo),e(N,w2),e(w2,vhe),e(vhe,zIo),e(w2,QIo),e(w2,UO),e(UO,WIo),e(w2,HIo),e(N,UIo),e(N,A2),e(A2,Fhe),e(Fhe,JIo),e(A2,YIo),e(A2,JO),e(JO,KIo),e(A2,ZIo),e(N,eNo),e(N,L2),e(L2,The),e(The,oNo),e(L2,rNo),e(L2,YO),e(YO,tNo),e(L2,aNo),e(N,nNo),e(N,y2),e(y2,Mhe),e(Mhe,sNo),e(y2,lNo),e(y2,KO),e(KO,iNo),e(y2,dNo),e(N,cNo),e(N,x2),e(x2,Ehe),e(Ehe,fNo),e(x2,mNo),e(x2,ZO),e(ZO,gNo),e(x2,hNo),e(N,pNo),e(N,$2),e($2,Che),e(Che,_No),e($2,uNo),e($2,eV),e(eV,bNo),e($2,vNo),e(N,FNo),e(N,k2),e(k2,whe),e(whe,TNo),e(k2,MNo),e(k2,oV),e(oV,ENo),e(k2,CNo),e(N,wNo),e(N,S2),e(S2,Ahe),e(Ahe,ANo),e(S2,LNo),e(S2,rV),e(rV,yNo),e(S2,xNo),e(N,$No),e(N,R2),e(R2,Lhe),e(Lhe,kNo),e(R2,SNo),e(R2,tV),e(tV,RNo),e(R2,PNo),e(N,BNo),e(N,P2),e(P2,yhe),e(yhe,INo),e(P2,NNo),e(P2,aV),e(aV,qNo),e(P2,jNo),e(N,DNo),e(N,B2),e(B2,xhe),e(xhe,GNo),e(B2,ONo),e(B2,nV),e(nV,VNo),e(B2,XNo),e(N,zNo),e(N,I2),e(I2,$he),e($he,QNo),e(I2,WNo),e(I2,sV),e(sV,HNo),e(I2,UNo),e(N,JNo),e(N,N2),e(N2,khe),e(khe,YNo),e(N2,KNo),e(N2,lV),e(lV,ZNo),e(N2,eqo),e(N,oqo),e(N,q2),e(q2,She),e(She,rqo),e(q2,tqo),e(q2,iV),e(iV,aqo),e(q2,nqo),e(N,sqo),e(N,j2),e(j2,Rhe),e(Rhe,lqo),e(j2,iqo),e(j2,dV),e(dV,dqo),e(j2,cqo),e(N,fqo),e(N,D2),e(D2,Phe),e(Phe,mqo),e(D2,gqo),e(D2,cV),e(cV,hqo),e(D2,pqo),e(N,_qo),e(N,G2),e(G2,Bhe),e(Bhe,uqo),e(G2,bqo),e(G2,fV),e(fV,vqo),e(G2,Fqo),e(N,Tqo),e(N,O2),e(O2,Ihe),e(Ihe,Mqo),e(O2,Eqo),e(O2,mV),e(mV,Cqo),e(O2,wqo),e(N,Aqo),e(N,V2),e(V2,Nhe),e(Nhe,Lqo),e(V2,yqo),e(V2,gV),e(gV,xqo),e(V2,$qo),e(N,kqo),e(N,X2),e(X2,qhe),e(qhe,Sqo),e(X2,Rqo),e(X2,hV),e(hV,Pqo),e(X2,Bqo),e(N,Iqo),e(N,z2),e(z2,jhe),e(jhe,Nqo),e(z2,qqo),e(z2,pV),e(pV,jqo),e(z2,Dqo),e(N,Gqo),e(N,Q2),e(Q2,Dhe),e(Dhe,Oqo),e(Q2,Vqo),e(Q2,_V),e(_V,Xqo),e(Q2,zqo),e(N,Qqo),e(N,W2),e(W2,Ghe),e(Ghe,Wqo),e(W2,Hqo),e(W2,uV),e(uV,Uqo),e(W2,Jqo),e(N,Yqo),e(N,H2),e(H2,Ohe),e(Ohe,Kqo),e(H2,Zqo),e(H2,bV),e(bV,ejo),e(H2,ojo),e(N,rjo),e(N,U2),e(U2,Vhe),e(Vhe,tjo),e(U2,ajo),e(U2,vV),e(vV,njo),e(U2,sjo),e(N,ljo),e(N,J2),e(J2,Xhe),e(Xhe,ijo),e(J2,djo),e(J2,FV),e(FV,cjo),e(J2,fjo),e(N,mjo),e(N,Y2),e(Y2,zhe),e(zhe,gjo),e(Y2,hjo),e(Y2,TV),e(TV,pjo),e(Y2,_jo),e(N,ujo),e(N,K2),e(K2,Qhe),e(Qhe,bjo),e(K2,vjo),e(K2,MV),e(MV,Fjo),e(K2,Tjo),e(N,Mjo),e(N,Z2),e(Z2,Whe),e(Whe,Ejo),e(Z2,Cjo),e(Z2,EV),e(EV,wjo),e(Z2,Ajo),e(N,Ljo),e(N,eb),e(eb,Hhe),e(Hhe,yjo),e(eb,xjo),e(eb,CV),e(CV,$jo),e(eb,kjo),e(N,Sjo),e(N,ob),e(ob,Uhe),e(Uhe,Rjo),e(ob,Pjo),e(ob,wV),e(wV,Bjo),e(ob,Ijo),e(N,Njo),e(N,rb),e(rb,Jhe),e(Jhe,qjo),e(rb,jjo),e(rb,AV),e(AV,Djo),e(rb,Gjo),e(N,Ojo),e(N,tb),e(tb,Yhe),e(Yhe,Vjo),e(tb,Xjo),e(tb,LV),e(LV,zjo),e(tb,Qjo),e(N,Wjo),e(N,ab),e(ab,Khe),e(Khe,Hjo),e(ab,Ujo),e(ab,yV),e(yV,Jjo),e(ab,Yjo),e(N,Kjo),e(N,nb),e(nb,Zhe),e(Zhe,Zjo),e(nb,eDo),e(nb,xV),e(xV,oDo),e(nb,rDo),e(N,tDo),e(N,sb),e(sb,epe),e(epe,aDo),e(sb,nDo),e(sb,$V),e($V,sDo),e(sb,lDo),e(N,iDo),e(N,lb),e(lb,ope),e(ope,dDo),e(lb,cDo),e(lb,kV),e(kV,fDo),e(lb,mDo),e(N,gDo),e(N,ib),e(ib,rpe),e(rpe,hDo),e(ib,pDo),e(ib,SV),e(SV,_Do),e(ib,uDo),e(N,bDo),e(N,db),e(db,tpe),e(tpe,vDo),e(db,FDo),e(db,RV),e(RV,TDo),e(db,MDo),e(N,EDo),e(N,cb),e(cb,ape),e(ape,CDo),e(cb,wDo),e(cb,PV),e(PV,ADo),e(cb,LDo),e(N,yDo),e(N,fb),e(fb,npe),e(npe,xDo),e(fb,$Do),e(fb,BV),e(BV,kDo),e(fb,SDo),e(N,RDo),e(N,mb),e(mb,spe),e(spe,PDo),e(mb,BDo),e(mb,IV),e(IV,IDo),e(mb,NDo),e(N,qDo),e(N,gb),e(gb,lpe),e(lpe,jDo),e(gb,DDo),e(gb,NV),e(NV,GDo),e(gb,ODo),e(N,VDo),e(N,hb),e(hb,ipe),e(ipe,XDo),e(hb,zDo),e(hb,qV),e(qV,QDo),e(hb,WDo),e(N,HDo),e(N,pb),e(pb,dpe),e(dpe,UDo),e(pb,JDo),e(pb,jV),e(jV,YDo),e(pb,KDo),e(N,ZDo),e(N,_b),e(_b,cpe),e(cpe,eGo),e(_b,oGo),e(_b,DV),e(DV,rGo),e(_b,tGo),e(oo,aGo),e(oo,ub),e(ub,nGo),e(ub,fpe),e(fpe,sGo),e(ub,lGo),e(ub,mpe),e(mpe,iGo),e(oo,dGo),M(bb,oo,null),b(f,cOe,u),b(f,Zi,u),e(Zi,vb),e(vb,gpe),M(ky,gpe,null),e(Zi,cGo),e(Zi,hpe),e(hpe,fGo),b(f,fOe,u),b(f,Bo,u),M(Sy,Bo,null),e(Bo,mGo),e(Bo,ed),e(ed,gGo),e(ed,GV),e(GV,hGo),e(ed,pGo),e(ed,OV),e(OV,_Go),e(ed,uGo),e(Bo,bGo),e(Bo,Ry),e(Ry,vGo),e(Ry,ppe),e(ppe,FGo),e(Ry,TGo),e(Bo,MGo),e(Bo,ft),M(Py,ft,null),e(ft,EGo),e(ft,_pe),e(_pe,CGo),e(ft,wGo),e(ft,od),e(od,AGo),e(od,upe),e(upe,LGo),e(od,yGo),e(od,VV),e(VV,xGo),e(od,$Go),e(ft,kGo),M(Fb,ft,null),e(Bo,SGo),e(Bo,ro),M(By,ro,null),e(ro,RGo),e(ro,bpe),e(bpe,PGo),e(ro,BGo),e(ro,ja),e(ja,IGo),e(ja,vpe),e(vpe,NGo),e(ja,qGo),e(ja,Fpe),e(Fpe,jGo),e(ja,DGo),e(ja,Tpe),e(Tpe,GGo),e(ja,OGo),e(ro,VGo),e(ro,Z),e(Z,Tb),e(Tb,Mpe),e(Mpe,XGo),e(Tb,zGo),e(Tb,XV),e(XV,QGo),e(Tb,WGo),e(Z,HGo),e(Z,Mb),e(Mb,Epe),e(Epe,UGo),e(Mb,JGo),e(Mb,zV),e(zV,YGo),e(Mb,KGo),e(Z,ZGo),e(Z,Eb),e(Eb,Cpe),e(Cpe,eOo),e(Eb,oOo),e(Eb,QV),e(QV,rOo),e(Eb,tOo),e(Z,aOo),e(Z,Cb),e(Cb,wpe),e(wpe,nOo),e(Cb,sOo),e(Cb,WV),e(WV,lOo),e(Cb,iOo),e(Z,dOo),e(Z,wb),e(wb,Ape),e(Ape,cOo),e(wb,fOo),e(wb,HV),e(HV,mOo),e(wb,gOo),e(Z,hOo),e(Z,Ab),e(Ab,Lpe),e(Lpe,pOo),e(Ab,_Oo),e(Ab,UV),e(UV,uOo),e(Ab,bOo),e(Z,vOo),e(Z,Lb),e(Lb,ype),e(ype,FOo),e(Lb,TOo),e(Lb,JV),e(JV,MOo),e(Lb,EOo),e(Z,COo),e(Z,yb),e(yb,xpe),e(xpe,wOo),e(yb,AOo),e(yb,YV),e(YV,LOo),e(yb,yOo),e(Z,xOo),e(Z,xb),e(xb,$pe),e($pe,$Oo),e(xb,kOo),e(xb,KV),e(KV,SOo),e(xb,ROo),e(Z,POo),e(Z,$b),e($b,kpe),e(kpe,BOo),e($b,IOo),e($b,ZV),e(ZV,NOo),e($b,qOo),e(Z,jOo),e(Z,kb),e(kb,Spe),e(Spe,DOo),e(kb,GOo),e(kb,eX),e(eX,OOo),e(kb,VOo),e(Z,XOo),e(Z,Sb),e(Sb,Rpe),e(Rpe,zOo),e(Sb,QOo),e(Sb,oX),e(oX,WOo),e(Sb,HOo),e(Z,UOo),e(Z,Rb),e(Rb,Ppe),e(Ppe,JOo),e(Rb,YOo),e(Rb,rX),e(rX,KOo),e(Rb,ZOo),e(Z,eVo),e(Z,Pb),e(Pb,Bpe),e(Bpe,oVo),e(Pb,rVo),e(Pb,tX),e(tX,tVo),e(Pb,aVo),e(Z,nVo),e(Z,Bb),e(Bb,Ipe),e(Ipe,sVo),e(Bb,lVo),e(Bb,aX),e(aX,iVo),e(Bb,dVo),e(Z,cVo),e(Z,Ib),e(Ib,Npe),e(Npe,fVo),e(Ib,mVo),e(Ib,nX),e(nX,gVo),e(Ib,hVo),e(Z,pVo),e(Z,Nb),e(Nb,qpe),e(qpe,_Vo),e(Nb,uVo),e(Nb,sX),e(sX,bVo),e(Nb,vVo),e(Z,FVo),e(Z,qb),e(qb,jpe),e(jpe,TVo),e(qb,MVo),e(qb,lX),e(lX,EVo),e(qb,CVo),e(Z,wVo),e(Z,jb),e(jb,Dpe),e(Dpe,AVo),e(jb,LVo),e(jb,iX),e(iX,yVo),e(jb,xVo),e(Z,$Vo),e(Z,Db),e(Db,Gpe),e(Gpe,kVo),e(Db,SVo),e(Db,dX),e(dX,RVo),e(Db,PVo),e(Z,BVo),e(Z,Gb),e(Gb,Ope),e(Ope,IVo),e(Gb,NVo),e(Gb,cX),e(cX,qVo),e(Gb,jVo),e(Z,DVo),e(Z,Ob),e(Ob,Vpe),e(Vpe,GVo),e(Ob,OVo),e(Ob,fX),e(fX,VVo),e(Ob,XVo),e(Z,zVo),e(Z,Vb),e(Vb,Xpe),e(Xpe,QVo),e(Vb,WVo),e(Vb,mX),e(mX,HVo),e(Vb,UVo),e(Z,JVo),e(Z,Xb),e(Xb,zpe),e(zpe,YVo),e(Xb,KVo),e(Xb,gX),e(gX,ZVo),e(Xb,eXo),e(Z,oXo),e(Z,zb),e(zb,Qpe),e(Qpe,rXo),e(zb,tXo),e(zb,hX),e(hX,aXo),e(zb,nXo),e(Z,sXo),e(Z,Qb),e(Qb,Wpe),e(Wpe,lXo),e(Qb,iXo),e(Qb,pX),e(pX,dXo),e(Qb,cXo),e(Z,fXo),e(Z,Wb),e(Wb,Hpe),e(Hpe,mXo),e(Wb,gXo),e(Wb,_X),e(_X,hXo),e(Wb,pXo),e(Z,_Xo),e(Z,Hb),e(Hb,Upe),e(Upe,uXo),e(Hb,bXo),e(Hb,uX),e(uX,vXo),e(Hb,FXo),e(Z,TXo),e(Z,Ub),e(Ub,Jpe),e(Jpe,MXo),e(Ub,EXo),e(Ub,bX),e(bX,CXo),e(Ub,wXo),e(Z,AXo),e(Z,Jb),e(Jb,Ype),e(Ype,LXo),e(Jb,yXo),e(Jb,vX),e(vX,xXo),e(Jb,$Xo),e(ro,kXo),e(ro,Yb),e(Yb,SXo),e(Yb,Kpe),e(Kpe,RXo),e(Yb,PXo),e(Yb,Zpe),e(Zpe,BXo),e(ro,IXo),M(Kb,ro,null),b(f,mOe,u),b(f,rd,u),e(rd,Zb),e(Zb,e_e),M(Iy,e_e,null),e(rd,NXo),e(rd,o_e),e(o_e,qXo),b(f,gOe,u),b(f,Io,u),M(Ny,Io,null),e(Io,jXo),e(Io,td),e(td,DXo),e(td,FX),e(FX,GXo),e(td,OXo),e(td,TX),e(TX,VXo),e(td,XXo),e(Io,zXo),e(Io,qy),e(qy,QXo),e(qy,r_e),e(r_e,WXo),e(qy,HXo),e(Io,UXo),e(Io,mt),M(jy,mt,null),e(mt,JXo),e(mt,t_e),e(t_e,YXo),e(mt,KXo),e(mt,ad),e(ad,ZXo),e(ad,a_e),e(a_e,ezo),e(ad,ozo),e(ad,MX),e(MX,rzo),e(ad,tzo),e(mt,azo),M(e5,mt,null),e(Io,nzo),e(Io,to),M(Dy,to,null),e(to,szo),e(to,n_e),e(n_e,lzo),e(to,izo),e(to,Da),e(Da,dzo),e(Da,s_e),e(s_e,czo),e(Da,fzo),e(Da,l_e),e(l_e,mzo),e(Da,gzo),e(Da,i_e),e(i_e,hzo),e(Da,pzo),e(to,_zo),e(to,No),e(No,o5),e(o5,d_e),e(d_e,uzo),e(o5,bzo),e(o5,EX),e(EX,vzo),e(o5,Fzo),e(No,Tzo),e(No,r5),e(r5,c_e),e(c_e,Mzo),e(r5,Ezo),e(r5,CX),e(CX,Czo),e(r5,wzo),e(No,Azo),e(No,t5),e(t5,f_e),e(f_e,Lzo),e(t5,yzo),e(t5,wX),e(wX,xzo),e(t5,$zo),e(No,kzo),e(No,a5),e(a5,m_e),e(m_e,Szo),e(a5,Rzo),e(a5,AX),e(AX,Pzo),e(a5,Bzo),e(No,Izo),e(No,n5),e(n5,g_e),e(g_e,Nzo),e(n5,qzo),e(n5,LX),e(LX,jzo),e(n5,Dzo),e(No,Gzo),e(No,s5),e(s5,h_e),e(h_e,Ozo),e(s5,Vzo),e(s5,yX),e(yX,Xzo),e(s5,zzo),e(to,Qzo),e(to,l5),e(l5,Wzo),e(l5,p_e),e(p_e,Hzo),e(l5,Uzo),e(l5,__e),e(__e,Jzo),e(to,Yzo),M(i5,to,null),b(f,hOe,u),b(f,nd,u),e(nd,d5),e(d5,u_e),M(Gy,u_e,null),e(nd,Kzo),e(nd,b_e),e(b_e,Zzo),b(f,pOe,u),b(f,qo,u),M(Oy,qo,null),e(qo,eQo),e(qo,sd),e(sd,oQo),e(sd,xX),e(xX,rQo),e(sd,tQo),e(sd,$X),e($X,aQo),e(sd,nQo),e(qo,sQo),e(qo,Vy),e(Vy,lQo),e(Vy,v_e),e(v_e,iQo),e(Vy,dQo),e(qo,cQo),e(qo,gt),M(Xy,gt,null),e(gt,fQo),e(gt,F_e),e(F_e,mQo),e(gt,gQo),e(gt,ld),e(ld,hQo),e(ld,T_e),e(T_e,pQo),e(ld,_Qo),e(ld,kX),e(kX,uQo),e(ld,bQo),e(gt,vQo),M(c5,gt,null),e(qo,FQo),e(qo,ao),M(zy,ao,null),e(ao,TQo),e(ao,M_e),e(M_e,MQo),e(ao,EQo),e(ao,Ga),e(Ga,CQo),e(Ga,E_e),e(E_e,wQo),e(Ga,AQo),e(Ga,C_e),e(C_e,LQo),e(Ga,yQo),e(Ga,w_e),e(w_e,xQo),e(Ga,$Qo),e(ao,kQo),e(ao,H),e(H,f5),e(f5,A_e),e(A_e,SQo),e(f5,RQo),e(f5,SX),e(SX,PQo),e(f5,BQo),e(H,IQo),e(H,m5),e(m5,L_e),e(L_e,NQo),e(m5,qQo),e(m5,RX),e(RX,jQo),e(m5,DQo),e(H,GQo),e(H,g5),e(g5,y_e),e(y_e,OQo),e(g5,VQo),e(g5,PX),e(PX,XQo),e(g5,zQo),e(H,QQo),e(H,h5),e(h5,x_e),e(x_e,WQo),e(h5,HQo),e(h5,BX),e(BX,UQo),e(h5,JQo),e(H,YQo),e(H,p5),e(p5,$_e),e($_e,KQo),e(p5,ZQo),e(p5,IX),e(IX,eWo),e(p5,oWo),e(H,rWo),e(H,_5),e(_5,k_e),e(k_e,tWo),e(_5,aWo),e(_5,NX),e(NX,nWo),e(_5,sWo),e(H,lWo),e(H,u5),e(u5,S_e),e(S_e,iWo),e(u5,dWo),e(u5,qX),e(qX,cWo),e(u5,fWo),e(H,mWo),e(H,b5),e(b5,R_e),e(R_e,gWo),e(b5,hWo),e(b5,jX),e(jX,pWo),e(b5,_Wo),e(H,uWo),e(H,v5),e(v5,P_e),e(P_e,bWo),e(v5,vWo),e(v5,DX),e(DX,FWo),e(v5,TWo),e(H,MWo),e(H,F5),e(F5,B_e),e(B_e,EWo),e(F5,CWo),e(F5,GX),e(GX,wWo),e(F5,AWo),e(H,LWo),e(H,T5),e(T5,I_e),e(I_e,yWo),e(T5,xWo),e(T5,OX),e(OX,$Wo),e(T5,kWo),e(H,SWo),e(H,M5),e(M5,N_e),e(N_e,RWo),e(M5,PWo),e(M5,VX),e(VX,BWo),e(M5,IWo),e(H,NWo),e(H,E5),e(E5,q_e),e(q_e,qWo),e(E5,jWo),e(E5,XX),e(XX,DWo),e(E5,GWo),e(H,OWo),e(H,C5),e(C5,j_e),e(j_e,VWo),e(C5,XWo),e(C5,zX),e(zX,zWo),e(C5,QWo),e(H,WWo),e(H,w5),e(w5,D_e),e(D_e,HWo),e(w5,UWo),e(w5,QX),e(QX,JWo),e(w5,YWo),e(H,KWo),e(H,A5),e(A5,G_e),e(G_e,ZWo),e(A5,eHo),e(A5,WX),e(WX,oHo),e(A5,rHo),e(H,tHo),e(H,L5),e(L5,O_e),e(O_e,aHo),e(L5,nHo),e(L5,HX),e(HX,sHo),e(L5,lHo),e(H,iHo),e(H,y5),e(y5,V_e),e(V_e,dHo),e(y5,cHo),e(y5,UX),e(UX,fHo),e(y5,mHo),e(H,gHo),e(H,x5),e(x5,X_e),e(X_e,hHo),e(x5,pHo),e(x5,JX),e(JX,_Ho),e(x5,uHo),e(H,bHo),e(H,$5),e($5,z_e),e(z_e,vHo),e($5,FHo),e($5,YX),e(YX,THo),e($5,MHo),e(H,EHo),e(H,k5),e(k5,Q_e),e(Q_e,CHo),e(k5,wHo),e(k5,KX),e(KX,AHo),e(k5,LHo),e(H,yHo),e(H,S5),e(S5,W_e),e(W_e,xHo),e(S5,$Ho),e(S5,ZX),e(ZX,kHo),e(S5,SHo),e(H,RHo),e(H,R5),e(R5,H_e),e(H_e,PHo),e(R5,BHo),e(R5,ez),e(ez,IHo),e(R5,NHo),e(H,qHo),e(H,P5),e(P5,U_e),e(U_e,jHo),e(P5,DHo),e(P5,oz),e(oz,GHo),e(P5,OHo),e(H,VHo),e(H,B5),e(B5,J_e),e(J_e,XHo),e(B5,zHo),e(B5,rz),e(rz,QHo),e(B5,WHo),e(H,HHo),e(H,I5),e(I5,Y_e),e(Y_e,UHo),e(I5,JHo),e(I5,tz),e(tz,YHo),e(I5,KHo),e(H,ZHo),e(H,N5),e(N5,K_e),e(K_e,eUo),e(N5,oUo),e(N5,az),e(az,rUo),e(N5,tUo),e(H,aUo),e(H,q5),e(q5,Z_e),e(Z_e,nUo),e(q5,sUo),e(q5,nz),e(nz,lUo),e(q5,iUo),e(H,dUo),e(H,j5),e(j5,eue),e(eue,cUo),e(j5,fUo),e(j5,sz),e(sz,mUo),e(j5,gUo),e(H,hUo),e(H,D5),e(D5,oue),e(oue,pUo),e(D5,_Uo),e(D5,lz),e(lz,uUo),e(D5,bUo),e(H,vUo),e(H,G5),e(G5,rue),e(rue,FUo),e(G5,TUo),e(G5,iz),e(iz,MUo),e(G5,EUo),e(H,CUo),e(H,O5),e(O5,tue),e(tue,wUo),e(O5,AUo),e(O5,dz),e(dz,LUo),e(O5,yUo),e(H,xUo),e(H,V5),e(V5,aue),e(aue,$Uo),e(V5,kUo),e(V5,cz),e(cz,SUo),e(V5,RUo),e(H,PUo),e(H,X5),e(X5,nue),e(nue,BUo),e(X5,IUo),e(X5,fz),e(fz,NUo),e(X5,qUo),e(H,jUo),e(H,z5),e(z5,sue),e(sue,DUo),e(z5,GUo),e(z5,mz),e(mz,OUo),e(z5,VUo),e(H,XUo),e(H,Q5),e(Q5,lue),e(lue,zUo),e(Q5,QUo),e(Q5,gz),e(gz,WUo),e(Q5,HUo),e(ao,UUo),e(ao,W5),e(W5,JUo),e(W5,iue),e(iue,YUo),e(W5,KUo),e(W5,due),e(due,ZUo),e(ao,eJo),M(H5,ao,null),b(f,_Oe,u),b(f,id,u),e(id,U5),e(U5,cue),M(Qy,cue,null),e(id,oJo),e(id,fue),e(fue,rJo),b(f,uOe,u),b(f,jo,u),M(Wy,jo,null),e(jo,tJo),e(jo,dd),e(dd,aJo),e(dd,hz),e(hz,nJo),e(dd,sJo),e(dd,pz),e(pz,lJo),e(dd,iJo),e(jo,dJo),e(jo,Hy),e(Hy,cJo),e(Hy,mue),e(mue,fJo),e(Hy,mJo),e(jo,gJo),e(jo,ht),M(Uy,ht,null),e(ht,hJo),e(ht,gue),e(gue,pJo),e(ht,_Jo),e(ht,cd),e(cd,uJo),e(cd,hue),e(hue,bJo),e(cd,vJo),e(cd,_z),e(_z,FJo),e(cd,TJo),e(ht,MJo),M(J5,ht,null),e(jo,EJo),e(jo,no),M(Jy,no,null),e(no,CJo),e(no,pue),e(pue,wJo),e(no,AJo),e(no,Oa),e(Oa,LJo),e(Oa,_ue),e(_ue,yJo),e(Oa,xJo),e(Oa,uue),e(uue,$Jo),e(Oa,kJo),e(Oa,bue),e(bue,SJo),e(Oa,RJo),e(no,PJo),e(no,V),e(V,Y5),e(Y5,vue),e(vue,BJo),e(Y5,IJo),e(Y5,uz),e(uz,NJo),e(Y5,qJo),e(V,jJo),e(V,K5),e(K5,Fue),e(Fue,DJo),e(K5,GJo),e(K5,bz),e(bz,OJo),e(K5,VJo),e(V,XJo),e(V,Z5),e(Z5,Tue),e(Tue,zJo),e(Z5,QJo),e(Z5,vz),e(vz,WJo),e(Z5,HJo),e(V,UJo),e(V,ev),e(ev,Mue),e(Mue,JJo),e(ev,YJo),e(ev,Fz),e(Fz,KJo),e(ev,ZJo),e(V,eYo),e(V,ov),e(ov,Eue),e(Eue,oYo),e(ov,rYo),e(ov,Tz),e(Tz,tYo),e(ov,aYo),e(V,nYo),e(V,rv),e(rv,Cue),e(Cue,sYo),e(rv,lYo),e(rv,Mz),e(Mz,iYo),e(rv,dYo),e(V,cYo),e(V,tv),e(tv,wue),e(wue,fYo),e(tv,mYo),e(tv,Ez),e(Ez,gYo),e(tv,hYo),e(V,pYo),e(V,av),e(av,Aue),e(Aue,_Yo),e(av,uYo),e(av,Cz),e(Cz,bYo),e(av,vYo),e(V,FYo),e(V,nv),e(nv,Lue),e(Lue,TYo),e(nv,MYo),e(nv,wz),e(wz,EYo),e(nv,CYo),e(V,wYo),e(V,sv),e(sv,yue),e(yue,AYo),e(sv,LYo),e(sv,Az),e(Az,yYo),e(sv,xYo),e(V,$Yo),e(V,lv),e(lv,xue),e(xue,kYo),e(lv,SYo),e(lv,Lz),e(Lz,RYo),e(lv,PYo),e(V,BYo),e(V,iv),e(iv,$ue),e($ue,IYo),e(iv,NYo),e(iv,yz),e(yz,qYo),e(iv,jYo),e(V,DYo),e(V,dv),e(dv,kue),e(kue,GYo),e(dv,OYo),e(dv,xz),e(xz,VYo),e(dv,XYo),e(V,zYo),e(V,cv),e(cv,Sue),e(Sue,QYo),e(cv,WYo),e(cv,$z),e($z,HYo),e(cv,UYo),e(V,JYo),e(V,fv),e(fv,Rue),e(Rue,YYo),e(fv,KYo),e(fv,kz),e(kz,ZYo),e(fv,eKo),e(V,oKo),e(V,mv),e(mv,Pue),e(Pue,rKo),e(mv,tKo),e(mv,Sz),e(Sz,aKo),e(mv,nKo),e(V,sKo),e(V,gv),e(gv,Bue),e(Bue,lKo),e(gv,iKo),e(gv,Rz),e(Rz,dKo),e(gv,cKo),e(V,fKo),e(V,hv),e(hv,Iue),e(Iue,mKo),e(hv,gKo),e(hv,Pz),e(Pz,hKo),e(hv,pKo),e(V,_Ko),e(V,pv),e(pv,Nue),e(Nue,uKo),e(pv,bKo),e(pv,Bz),e(Bz,vKo),e(pv,FKo),e(V,TKo),e(V,_v),e(_v,que),e(que,MKo),e(_v,EKo),e(_v,Iz),e(Iz,CKo),e(_v,wKo),e(V,AKo),e(V,uv),e(uv,jue),e(jue,LKo),e(uv,yKo),e(uv,Nz),e(Nz,xKo),e(uv,$Ko),e(V,kKo),e(V,bv),e(bv,Due),e(Due,SKo),e(bv,RKo),e(bv,qz),e(qz,PKo),e(bv,BKo),e(V,IKo),e(V,vv),e(vv,Gue),e(Gue,NKo),e(vv,qKo),e(vv,jz),e(jz,jKo),e(vv,DKo),e(V,GKo),e(V,Fv),e(Fv,Oue),e(Oue,OKo),e(Fv,VKo),e(Fv,Dz),e(Dz,XKo),e(Fv,zKo),e(V,QKo),e(V,Tv),e(Tv,Vue),e(Vue,WKo),e(Tv,HKo),e(Tv,Gz),e(Gz,UKo),e(Tv,JKo),e(V,YKo),e(V,Mv),e(Mv,Xue),e(Xue,KKo),e(Mv,ZKo),e(Mv,Oz),e(Oz,eZo),e(Mv,oZo),e(V,rZo),e(V,Ev),e(Ev,zue),e(zue,tZo),e(Ev,aZo),e(Ev,Vz),e(Vz,nZo),e(Ev,sZo),e(V,lZo),e(V,Cv),e(Cv,Que),e(Que,iZo),e(Cv,dZo),e(Cv,Xz),e(Xz,cZo),e(Cv,fZo),e(V,mZo),e(V,wv),e(wv,Wue),e(Wue,gZo),e(wv,hZo),e(wv,zz),e(zz,pZo),e(wv,_Zo),e(V,uZo),e(V,Av),e(Av,Hue),e(Hue,bZo),e(Av,vZo),e(Av,Qz),e(Qz,FZo),e(Av,TZo),e(V,MZo),e(V,Lv),e(Lv,Uue),e(Uue,EZo),e(Lv,CZo),e(Lv,Wz),e(Wz,wZo),e(Lv,AZo),e(V,LZo),e(V,yv),e(yv,Jue),e(Jue,yZo),e(yv,xZo),e(yv,Hz),e(Hz,$Zo),e(yv,kZo),e(V,SZo),e(V,xv),e(xv,Yue),e(Yue,RZo),e(xv,PZo),e(xv,Uz),e(Uz,BZo),e(xv,IZo),e(V,NZo),e(V,$v),e($v,Kue),e(Kue,qZo),e($v,jZo),e($v,Jz),e(Jz,DZo),e($v,GZo),e(V,OZo),e(V,kv),e(kv,Zue),e(Zue,VZo),e(kv,XZo),e(kv,Yz),e(Yz,zZo),e(kv,QZo),e(V,WZo),e(V,Sv),e(Sv,e1e),e(e1e,HZo),e(Sv,UZo),e(Sv,Kz),e(Kz,JZo),e(Sv,YZo),e(V,KZo),e(V,Rv),e(Rv,o1e),e(o1e,ZZo),e(Rv,eer),e(Rv,Zz),e(Zz,oer),e(Rv,rer),e(V,ter),e(V,Pv),e(Pv,r1e),e(r1e,aer),e(Pv,ner),e(Pv,eQ),e(eQ,ser),e(Pv,ler),e(V,ier),e(V,Bv),e(Bv,t1e),e(t1e,der),e(Bv,cer),e(Bv,oQ),e(oQ,fer),e(Bv,mer),e(V,ger),e(V,Iv),e(Iv,a1e),e(a1e,her),e(Iv,per),e(Iv,rQ),e(rQ,_er),e(Iv,uer),e(V,ber),e(V,Nv),e(Nv,n1e),e(n1e,ver),e(Nv,Fer),e(Nv,tQ),e(tQ,Ter),e(Nv,Mer),e(no,Eer),e(no,qv),e(qv,Cer),e(qv,s1e),e(s1e,wer),e(qv,Aer),e(qv,l1e),e(l1e,Ler),e(no,yer),M(jv,no,null),b(f,bOe,u),b(f,fd,u),e(fd,Dv),e(Dv,i1e),M(Yy,i1e,null),e(fd,xer),e(fd,d1e),e(d1e,$er),b(f,vOe,u),b(f,Do,u),M(Ky,Do,null),e(Do,ker),e(Do,md),e(md,Ser),e(md,aQ),e(aQ,Rer),e(md,Per),e(md,nQ),e(nQ,Ber),e(md,Ier),e(Do,Ner),e(Do,Zy),e(Zy,qer),e(Zy,c1e),e(c1e,jer),e(Zy,Der),e(Do,Ger),e(Do,pt),M(e8,pt,null),e(pt,Oer),e(pt,f1e),e(f1e,Ver),e(pt,Xer),e(pt,gd),e(gd,zer),e(gd,m1e),e(m1e,Qer),e(gd,Wer),e(gd,sQ),e(sQ,Her),e(gd,Uer),e(pt,Jer),M(Gv,pt,null),e(Do,Yer),e(Do,so),M(o8,so,null),e(so,Ker),e(so,g1e),e(g1e,Zer),e(so,eor),e(so,Va),e(Va,oor),e(Va,h1e),e(h1e,ror),e(Va,tor),e(Va,p1e),e(p1e,aor),e(Va,nor),e(Va,_1e),e(_1e,sor),e(Va,lor),e(so,ior),e(so,u1e),e(u1e,Ov),e(Ov,b1e),e(b1e,dor),e(Ov,cor),e(Ov,lQ),e(lQ,mor),e(Ov,gor),e(so,hor),e(so,Vv),e(Vv,por),e(Vv,v1e),e(v1e,_or),e(Vv,uor),e(Vv,F1e),e(F1e,bor),e(so,vor),M(Xv,so,null),b(f,FOe,u),b(f,hd,u),e(hd,zv),e(zv,T1e),M(r8,T1e,null),e(hd,For),e(hd,M1e),e(M1e,Tor),b(f,TOe,u),b(f,Go,u),M(t8,Go,null),e(Go,Mor),e(Go,pd),e(pd,Eor),e(pd,iQ),e(iQ,Cor),e(pd,wor),e(pd,dQ),e(dQ,Aor),e(pd,Lor),e(Go,yor),e(Go,a8),e(a8,xor),e(a8,E1e),e(E1e,$or),e(a8,kor),e(Go,Sor),e(Go,_t),M(n8,_t,null),e(_t,Ror),e(_t,C1e),e(C1e,Por),e(_t,Bor),e(_t,_d),e(_d,Ior),e(_d,w1e),e(w1e,Nor),e(_d,qor),e(_d,cQ),e(cQ,jor),e(_d,Dor),e(_t,Gor),M(Qv,_t,null),e(Go,Oor),e(Go,lo),M(s8,lo,null),e(lo,Vor),e(lo,A1e),e(A1e,Xor),e(lo,zor),e(lo,Xa),e(Xa,Qor),e(Xa,L1e),e(L1e,Wor),e(Xa,Hor),e(Xa,y1e),e(y1e,Uor),e(Xa,Jor),e(Xa,x1e),e(x1e,Yor),e(Xa,Kor),e(lo,Zor),e(lo,Fe),e(Fe,Wv),e(Wv,$1e),e($1e,err),e(Wv,orr),e(Wv,fQ),e(fQ,rrr),e(Wv,trr),e(Fe,arr),e(Fe,Hv),e(Hv,k1e),e(k1e,nrr),e(Hv,srr),e(Hv,mQ),e(mQ,lrr),e(Hv,irr),e(Fe,drr),e(Fe,Uv),e(Uv,S1e),e(S1e,crr),e(Uv,frr),e(Uv,gQ),e(gQ,mrr),e(Uv,grr),e(Fe,hrr),e(Fe,Jv),e(Jv,R1e),e(R1e,prr),e(Jv,_rr),e(Jv,hQ),e(hQ,urr),e(Jv,brr),e(Fe,vrr),e(Fe,Xs),e(Xs,P1e),e(P1e,Frr),e(Xs,Trr),e(Xs,pQ),e(pQ,Mrr),e(Xs,Err),e(Xs,_Q),e(_Q,Crr),e(Xs,wrr),e(Fe,Arr),e(Fe,Yv),e(Yv,B1e),e(B1e,Lrr),e(Yv,yrr),e(Yv,uQ),e(uQ,xrr),e(Yv,$rr),e(Fe,krr),e(Fe,zs),e(zs,I1e),e(I1e,Srr),e(zs,Rrr),e(zs,bQ),e(bQ,Prr),e(zs,Brr),e(zs,vQ),e(vQ,Irr),e(zs,Nrr),e(Fe,qrr),e(Fe,ut),e(ut,N1e),e(N1e,jrr),e(ut,Drr),e(ut,FQ),e(FQ,Grr),e(ut,Orr),e(ut,TQ),e(TQ,Vrr),e(ut,Xrr),e(ut,MQ),e(MQ,zrr),e(ut,Qrr),e(Fe,Wrr),e(Fe,Kv),e(Kv,q1e),e(q1e,Hrr),e(Kv,Urr),e(Kv,EQ),e(EQ,Jrr),e(Kv,Yrr),e(Fe,Krr),e(Fe,Zv),e(Zv,j1e),e(j1e,Zrr),e(Zv,etr),e(Zv,CQ),e(CQ,otr),e(Zv,rtr),e(Fe,ttr),e(Fe,e3),e(e3,D1e),e(D1e,atr),e(e3,ntr),e(e3,wQ),e(wQ,str),e(e3,ltr),e(Fe,itr),e(Fe,o3),e(o3,G1e),e(G1e,dtr),e(o3,ctr),e(o3,AQ),e(AQ,ftr),e(o3,mtr),e(Fe,gtr),e(Fe,r3),e(r3,O1e),e(O1e,htr),e(r3,ptr),e(r3,LQ),e(LQ,_tr),e(r3,utr),e(Fe,btr),e(Fe,t3),e(t3,V1e),e(V1e,vtr),e(t3,Ftr),e(t3,yQ),e(yQ,Ttr),e(t3,Mtr),e(Fe,Etr),e(Fe,a3),e(a3,X1e),e(X1e,Ctr),e(a3,wtr),e(a3,xQ),e(xQ,Atr),e(a3,Ltr),e(lo,ytr),e(lo,n3),e(n3,xtr),e(n3,z1e),e(z1e,$tr),e(n3,ktr),e(n3,Q1e),e(Q1e,Str),e(lo,Rtr),M(s3,lo,null),b(f,MOe,u),b(f,ud,u),e(ud,l3),e(l3,W1e),M(l8,W1e,null),e(ud,Ptr),e(ud,H1e),e(H1e,Btr),b(f,EOe,u),b(f,Oo,u),M(i8,Oo,null),e(Oo,Itr),e(Oo,bd),e(bd,Ntr),e(bd,$Q),e($Q,qtr),e(bd,jtr),e(bd,kQ),e(kQ,Dtr),e(bd,Gtr),e(Oo,Otr),e(Oo,d8),e(d8,Vtr),e(d8,U1e),e(U1e,Xtr),e(d8,ztr),e(Oo,Qtr),e(Oo,bt),M(c8,bt,null),e(bt,Wtr),e(bt,J1e),e(J1e,Htr),e(bt,Utr),e(bt,vd),e(vd,Jtr),e(vd,Y1e),e(Y1e,Ytr),e(vd,Ktr),e(vd,SQ),e(SQ,Ztr),e(vd,ear),e(bt,oar),M(i3,bt,null),e(Oo,rar),e(Oo,io),M(f8,io,null),e(io,tar),e(io,K1e),e(K1e,aar),e(io,nar),e(io,za),e(za,sar),e(za,Z1e),e(Z1e,lar),e(za,iar),e(za,e7e),e(e7e,dar),e(za,car),e(za,o7e),e(o7e,far),e(za,mar),e(io,gar),e(io,r7e),e(r7e,d3),e(d3,t7e),e(t7e,har),e(d3,par),e(d3,RQ),e(RQ,_ar),e(d3,uar),e(io,bar),e(io,c3),e(c3,Far),e(c3,a7e),e(a7e,Tar),e(c3,Mar),e(c3,n7e),e(n7e,Ear),e(io,Car),M(f3,io,null),b(f,COe,u),b(f,Fd,u),e(Fd,m3),e(m3,s7e),M(m8,s7e,null),e(Fd,war),e(Fd,l7e),e(l7e,Aar),b(f,wOe,u),b(f,Vo,u),M(g8,Vo,null),e(Vo,Lar),e(Vo,Td),e(Td,yar),e(Td,PQ),e(PQ,xar),e(Td,$ar),e(Td,BQ),e(BQ,kar),e(Td,Sar),e(Vo,Rar),e(Vo,h8),e(h8,Par),e(h8,i7e),e(i7e,Bar),e(h8,Iar),e(Vo,Nar),e(Vo,vt),M(p8,vt,null),e(vt,qar),e(vt,d7e),e(d7e,jar),e(vt,Dar),e(vt,Md),e(Md,Gar),e(Md,c7e),e(c7e,Oar),e(Md,Var),e(Md,IQ),e(IQ,Xar),e(Md,zar),e(vt,Qar),M(g3,vt,null),e(Vo,War),e(Vo,co),M(_8,co,null),e(co,Har),e(co,f7e),e(f7e,Uar),e(co,Jar),e(co,Qa),e(Qa,Yar),e(Qa,m7e),e(m7e,Kar),e(Qa,Zar),e(Qa,g7e),e(g7e,enr),e(Qa,onr),e(Qa,h7e),e(h7e,rnr),e(Qa,tnr),e(co,anr),e(co,p7e),e(p7e,h3),e(h3,_7e),e(_7e,nnr),e(h3,snr),e(h3,NQ),e(NQ,lnr),e(h3,inr),e(co,dnr),e(co,p3),e(p3,cnr),e(p3,u7e),e(u7e,fnr),e(p3,mnr),e(p3,b7e),e(b7e,gnr),e(co,hnr),M(_3,co,null),b(f,AOe,u),b(f,Ed,u),e(Ed,u3),e(u3,v7e),M(u8,v7e,null),e(Ed,pnr),e(Ed,F7e),e(F7e,_nr),b(f,LOe,u),b(f,Xo,u),M(b8,Xo,null),e(Xo,unr),e(Xo,Cd),e(Cd,bnr),e(Cd,qQ),e(qQ,vnr),e(Cd,Fnr),e(Cd,jQ),e(jQ,Tnr),e(Cd,Mnr),e(Xo,Enr),e(Xo,v8),e(v8,Cnr),e(v8,T7e),e(T7e,wnr),e(v8,Anr),e(Xo,Lnr),e(Xo,Ft),M(F8,Ft,null),e(Ft,ynr),e(Ft,M7e),e(M7e,xnr),e(Ft,$nr),e(Ft,wd),e(wd,knr),e(wd,E7e),e(E7e,Snr),e(wd,Rnr),e(wd,DQ),e(DQ,Pnr),e(wd,Bnr),e(Ft,Inr),M(b3,Ft,null),e(Xo,Nnr),e(Xo,fo),M(T8,fo,null),e(fo,qnr),e(fo,C7e),e(C7e,jnr),e(fo,Dnr),e(fo,Wa),e(Wa,Gnr),e(Wa,w7e),e(w7e,Onr),e(Wa,Vnr),e(Wa,A7e),e(A7e,Xnr),e(Wa,znr),e(Wa,L7e),e(L7e,Qnr),e(Wa,Wnr),e(fo,Hnr),e(fo,Pe),e(Pe,v3),e(v3,y7e),e(y7e,Unr),e(v3,Jnr),e(v3,GQ),e(GQ,Ynr),e(v3,Knr),e(Pe,Znr),e(Pe,F3),e(F3,x7e),e(x7e,esr),e(F3,osr),e(F3,OQ),e(OQ,rsr),e(F3,tsr),e(Pe,asr),e(Pe,T3),e(T3,$7e),e($7e,nsr),e(T3,ssr),e(T3,VQ),e(VQ,lsr),e(T3,isr),e(Pe,dsr),e(Pe,M3),e(M3,k7e),e(k7e,csr),e(M3,fsr),e(M3,XQ),e(XQ,msr),e(M3,gsr),e(Pe,hsr),e(Pe,E3),e(E3,S7e),e(S7e,psr),e(E3,_sr),e(E3,zQ),e(zQ,usr),e(E3,bsr),e(Pe,vsr),e(Pe,C3),e(C3,R7e),e(R7e,Fsr),e(C3,Tsr),e(C3,QQ),e(QQ,Msr),e(C3,Esr),e(Pe,Csr),e(Pe,w3),e(w3,P7e),e(P7e,wsr),e(w3,Asr),e(w3,WQ),e(WQ,Lsr),e(w3,ysr),e(Pe,xsr),e(Pe,A3),e(A3,B7e),e(B7e,$sr),e(A3,ksr),e(A3,HQ),e(HQ,Ssr),e(A3,Rsr),e(Pe,Psr),e(Pe,L3),e(L3,I7e),e(I7e,Bsr),e(L3,Isr),e(L3,UQ),e(UQ,Nsr),e(L3,qsr),e(fo,jsr),e(fo,y3),e(y3,Dsr),e(y3,N7e),e(N7e,Gsr),e(y3,Osr),e(y3,q7e),e(q7e,Vsr),e(fo,Xsr),M(x3,fo,null),b(f,yOe,u),b(f,Ad,u),e(Ad,$3),e($3,j7e),M(M8,j7e,null),e(Ad,zsr),e(Ad,D7e),e(D7e,Qsr),b(f,xOe,u),b(f,zo,u),M(E8,zo,null),e(zo,Wsr),e(zo,Ld),e(Ld,Hsr),e(Ld,JQ),e(JQ,Usr),e(Ld,Jsr),e(Ld,YQ),e(YQ,Ysr),e(Ld,Ksr),e(zo,Zsr),e(zo,C8),e(C8,elr),e(C8,G7e),e(G7e,olr),e(C8,rlr),e(zo,tlr),e(zo,Tt),M(w8,Tt,null),e(Tt,alr),e(Tt,O7e),e(O7e,nlr),e(Tt,slr),e(Tt,yd),e(yd,llr),e(yd,V7e),e(V7e,ilr),e(yd,dlr),e(yd,KQ),e(KQ,clr),e(yd,flr),e(Tt,mlr),M(k3,Tt,null),e(zo,glr),e(zo,mo),M(A8,mo,null),e(mo,hlr),e(mo,X7e),e(X7e,plr),e(mo,_lr),e(mo,Ha),e(Ha,ulr),e(Ha,z7e),e(z7e,blr),e(Ha,vlr),e(Ha,Q7e),e(Q7e,Flr),e(Ha,Tlr),e(Ha,W7e),e(W7e,Mlr),e(Ha,Elr),e(mo,Clr),e(mo,et),e(et,S3),e(S3,H7e),e(H7e,wlr),e(S3,Alr),e(S3,ZQ),e(ZQ,Llr),e(S3,ylr),e(et,xlr),e(et,R3),e(R3,U7e),e(U7e,$lr),e(R3,klr),e(R3,eW),e(eW,Slr),e(R3,Rlr),e(et,Plr),e(et,P3),e(P3,J7e),e(J7e,Blr),e(P3,Ilr),e(P3,oW),e(oW,Nlr),e(P3,qlr),e(et,jlr),e(et,B3),e(B3,Y7e),e(Y7e,Dlr),e(B3,Glr),e(B3,rW),e(rW,Olr),e(B3,Vlr),e(et,Xlr),e(et,I3),e(I3,K7e),e(K7e,zlr),e(I3,Qlr),e(I3,tW),e(tW,Wlr),e(I3,Hlr),e(mo,Ulr),e(mo,N3),e(N3,Jlr),e(N3,Z7e),e(Z7e,Ylr),e(N3,Klr),e(N3,e2e),e(e2e,Zlr),e(mo,eir),M(q3,mo,null),b(f,$Oe,u),b(f,xd,u),e(xd,j3),e(j3,o2e),M(L8,o2e,null),e(xd,oir),e(xd,r2e),e(r2e,rir),b(f,kOe,u),b(f,Qo,u),M(y8,Qo,null),e(Qo,tir),e(Qo,$d),e($d,air),e($d,aW),e(aW,nir),e($d,sir),e($d,nW),e(nW,lir),e($d,iir),e(Qo,dir),e(Qo,x8),e(x8,cir),e(x8,t2e),e(t2e,fir),e(x8,mir),e(Qo,gir),e(Qo,Mt),M($8,Mt,null),e(Mt,hir),e(Mt,a2e),e(a2e,pir),e(Mt,_ir),e(Mt,kd),e(kd,uir),e(kd,n2e),e(n2e,bir),e(kd,vir),e(kd,sW),e(sW,Fir),e(kd,Tir),e(Mt,Mir),M(D3,Mt,null),e(Qo,Eir),e(Qo,go),M(k8,go,null),e(go,Cir),e(go,s2e),e(s2e,wir),e(go,Air),e(go,Ua),e(Ua,Lir),e(Ua,l2e),e(l2e,yir),e(Ua,xir),e(Ua,i2e),e(i2e,$ir),e(Ua,kir),e(Ua,d2e),e(d2e,Sir),e(Ua,Rir),e(go,Pir),e(go,Le),e(Le,G3),e(G3,c2e),e(c2e,Bir),e(G3,Iir),e(G3,lW),e(lW,Nir),e(G3,qir),e(Le,jir),e(Le,O3),e(O3,f2e),e(f2e,Dir),e(O3,Gir),e(O3,iW),e(iW,Oir),e(O3,Vir),e(Le,Xir),e(Le,V3),e(V3,m2e),e(m2e,zir),e(V3,Qir),e(V3,dW),e(dW,Wir),e(V3,Hir),e(Le,Uir),e(Le,X3),e(X3,g2e),e(g2e,Jir),e(X3,Yir),e(X3,cW),e(cW,Kir),e(X3,Zir),e(Le,edr),e(Le,z3),e(z3,h2e),e(h2e,odr),e(z3,rdr),e(z3,fW),e(fW,tdr),e(z3,adr),e(Le,ndr),e(Le,Q3),e(Q3,p2e),e(p2e,sdr),e(Q3,ldr),e(Q3,mW),e(mW,idr),e(Q3,ddr),e(Le,cdr),e(Le,W3),e(W3,_2e),e(_2e,fdr),e(W3,mdr),e(W3,gW),e(gW,gdr),e(W3,hdr),e(Le,pdr),e(Le,H3),e(H3,u2e),e(u2e,_dr),e(H3,udr),e(H3,hW),e(hW,bdr),e(H3,vdr),e(Le,Fdr),e(Le,U3),e(U3,b2e),e(b2e,Tdr),e(U3,Mdr),e(U3,pW),e(pW,Edr),e(U3,Cdr),e(Le,wdr),e(Le,J3),e(J3,v2e),e(v2e,Adr),e(J3,Ldr),e(J3,_W),e(_W,ydr),e(J3,xdr),e(go,$dr),e(go,Y3),e(Y3,kdr),e(Y3,F2e),e(F2e,Sdr),e(Y3,Rdr),e(Y3,T2e),e(T2e,Pdr),e(go,Bdr),M(K3,go,null),b(f,SOe,u),b(f,Sd,u),e(Sd,Z3),e(Z3,M2e),M(S8,M2e,null),e(Sd,Idr),e(Sd,E2e),e(E2e,Ndr),b(f,ROe,u),b(f,Wo,u),M(R8,Wo,null),e(Wo,qdr),e(Wo,Rd),e(Rd,jdr),e(Rd,uW),e(uW,Ddr),e(Rd,Gdr),e(Rd,bW),e(bW,Odr),e(Rd,Vdr),e(Wo,Xdr),e(Wo,P8),e(P8,zdr),e(P8,C2e),e(C2e,Qdr),e(P8,Wdr),e(Wo,Hdr),e(Wo,Et),M(B8,Et,null),e(Et,Udr),e(Et,w2e),e(w2e,Jdr),e(Et,Ydr),e(Et,Pd),e(Pd,Kdr),e(Pd,A2e),e(A2e,Zdr),e(Pd,ecr),e(Pd,vW),e(vW,ocr),e(Pd,rcr),e(Et,tcr),M(eF,Et,null),e(Wo,acr),e(Wo,ho),M(I8,ho,null),e(ho,ncr),e(ho,L2e),e(L2e,scr),e(ho,lcr),e(ho,Ja),e(Ja,icr),e(Ja,y2e),e(y2e,dcr),e(Ja,ccr),e(Ja,x2e),e(x2e,fcr),e(Ja,mcr),e(Ja,$2e),e($2e,gcr),e(Ja,hcr),e(ho,pcr),e(ho,N8),e(N8,oF),e(oF,k2e),e(k2e,_cr),e(oF,ucr),e(oF,FW),e(FW,bcr),e(oF,vcr),e(N8,Fcr),e(N8,rF),e(rF,S2e),e(S2e,Tcr),e(rF,Mcr),e(rF,TW),e(TW,Ecr),e(rF,Ccr),e(ho,wcr),e(ho,tF),e(tF,Acr),e(tF,R2e),e(R2e,Lcr),e(tF,ycr),e(tF,P2e),e(P2e,xcr),e(ho,$cr),M(aF,ho,null),b(f,POe,u),b(f,Bd,u),e(Bd,nF),e(nF,B2e),M(q8,B2e,null),e(Bd,kcr),e(Bd,I2e),e(I2e,Scr),b(f,BOe,u),b(f,Ho,u),M(j8,Ho,null),e(Ho,Rcr),e(Ho,Id),e(Id,Pcr),e(Id,MW),e(MW,Bcr),e(Id,Icr),e(Id,EW),e(EW,Ncr),e(Id,qcr),e(Ho,jcr),e(Ho,D8),e(D8,Dcr),e(D8,N2e),e(N2e,Gcr),e(D8,Ocr),e(Ho,Vcr),e(Ho,Ct),M(G8,Ct,null),e(Ct,Xcr),e(Ct,q2e),e(q2e,zcr),e(Ct,Qcr),e(Ct,Nd),e(Nd,Wcr),e(Nd,j2e),e(j2e,Hcr),e(Nd,Ucr),e(Nd,CW),e(CW,Jcr),e(Nd,Ycr),e(Ct,Kcr),M(sF,Ct,null),e(Ho,Zcr),e(Ho,po),M(O8,po,null),e(po,efr),e(po,D2e),e(D2e,ofr),e(po,rfr),e(po,Ya),e(Ya,tfr),e(Ya,G2e),e(G2e,afr),e(Ya,nfr),e(Ya,O2e),e(O2e,sfr),e(Ya,lfr),e(Ya,V2e),e(V2e,ifr),e(Ya,dfr),e(po,cfr),e(po,ot),e(ot,lF),e(lF,X2e),e(X2e,ffr),e(lF,mfr),e(lF,wW),e(wW,gfr),e(lF,hfr),e(ot,pfr),e(ot,iF),e(iF,z2e),e(z2e,_fr),e(iF,ufr),e(iF,AW),e(AW,bfr),e(iF,vfr),e(ot,Ffr),e(ot,dF),e(dF,Q2e),e(Q2e,Tfr),e(dF,Mfr),e(dF,LW),e(LW,Efr),e(dF,Cfr),e(ot,wfr),e(ot,cF),e(cF,W2e),e(W2e,Afr),e(cF,Lfr),e(cF,yW),e(yW,yfr),e(cF,xfr),e(ot,$fr),e(ot,fF),e(fF,H2e),e(H2e,kfr),e(fF,Sfr),e(fF,xW),e(xW,Rfr),e(fF,Pfr),e(po,Bfr),e(po,mF),e(mF,Ifr),e(mF,U2e),e(U2e,Nfr),e(mF,qfr),e(mF,J2e),e(J2e,jfr),e(po,Dfr),M(gF,po,null),b(f,IOe,u),b(f,qd,u),e(qd,hF),e(hF,Y2e),M(V8,Y2e,null),e(qd,Gfr),e(qd,K2e),e(K2e,Ofr),b(f,NOe,u),b(f,Uo,u),M(X8,Uo,null),e(Uo,Vfr),e(Uo,jd),e(jd,Xfr),e(jd,$W),e($W,zfr),e(jd,Qfr),e(jd,kW),e(kW,Wfr),e(jd,Hfr),e(Uo,Ufr),e(Uo,z8),e(z8,Jfr),e(z8,Z2e),e(Z2e,Yfr),e(z8,Kfr),e(Uo,Zfr),e(Uo,wt),M(Q8,wt,null),e(wt,emr),e(wt,ebe),e(ebe,omr),e(wt,rmr),e(wt,Dd),e(Dd,tmr),e(Dd,obe),e(obe,amr),e(Dd,nmr),e(Dd,SW),e(SW,smr),e(Dd,lmr),e(wt,imr),M(pF,wt,null),e(Uo,dmr),e(Uo,_o),M(W8,_o,null),e(_o,cmr),e(_o,rbe),e(rbe,fmr),e(_o,mmr),e(_o,Ka),e(Ka,gmr),e(Ka,tbe),e(tbe,hmr),e(Ka,pmr),e(Ka,abe),e(abe,_mr),e(Ka,umr),e(Ka,nbe),e(nbe,bmr),e(Ka,vmr),e(_o,Fmr),e(_o,Gd),e(Gd,_F),e(_F,sbe),e(sbe,Tmr),e(_F,Mmr),e(_F,RW),e(RW,Emr),e(_F,Cmr),e(Gd,wmr),e(Gd,uF),e(uF,lbe),e(lbe,Amr),e(uF,Lmr),e(uF,PW),e(PW,ymr),e(uF,xmr),e(Gd,$mr),e(Gd,bF),e(bF,ibe),e(ibe,kmr),e(bF,Smr),e(bF,BW),e(BW,Rmr),e(bF,Pmr),e(_o,Bmr),e(_o,vF),e(vF,Imr),e(vF,dbe),e(dbe,Nmr),e(vF,qmr),e(vF,cbe),e(cbe,jmr),e(_o,Dmr),M(FF,_o,null),b(f,qOe,u),b(f,Od,u),e(Od,TF),e(TF,fbe),M(H8,fbe,null),e(Od,Gmr),e(Od,mbe),e(mbe,Omr),b(f,jOe,u),b(f,Jo,u),M(U8,Jo,null),e(Jo,Vmr),e(Jo,Vd),e(Vd,Xmr),e(Vd,IW),e(IW,zmr),e(Vd,Qmr),e(Vd,NW),e(NW,Wmr),e(Vd,Hmr),e(Jo,Umr),e(Jo,J8),e(J8,Jmr),e(J8,gbe),e(gbe,Ymr),e(J8,Kmr),e(Jo,Zmr),e(Jo,At),M(Y8,At,null),e(At,egr),e(At,hbe),e(hbe,ogr),e(At,rgr),e(At,Xd),e(Xd,tgr),e(Xd,pbe),e(pbe,agr),e(Xd,ngr),e(Xd,qW),e(qW,sgr),e(Xd,lgr),e(At,igr),M(MF,At,null),e(Jo,dgr),e(Jo,uo),M(K8,uo,null),e(uo,cgr),e(uo,_be),e(_be,fgr),e(uo,mgr),e(uo,Za),e(Za,ggr),e(Za,ube),e(ube,hgr),e(Za,pgr),e(Za,bbe),e(bbe,_gr),e(Za,ugr),e(Za,vbe),e(vbe,bgr),e(Za,vgr),e(uo,Fgr),e(uo,Z8),e(Z8,EF),e(EF,Fbe),e(Fbe,Tgr),e(EF,Mgr),e(EF,jW),e(jW,Egr),e(EF,Cgr),e(Z8,wgr),e(Z8,CF),e(CF,Tbe),e(Tbe,Agr),e(CF,Lgr),e(CF,DW),e(DW,ygr),e(CF,xgr),e(uo,$gr),e(uo,wF),e(wF,kgr),e(wF,Mbe),e(Mbe,Sgr),e(wF,Rgr),e(wF,Ebe),e(Ebe,Pgr),e(uo,Bgr),M(AF,uo,null),b(f,DOe,u),b(f,zd,u),e(zd,LF),e(LF,Cbe),M(e9,Cbe,null),e(zd,Igr),e(zd,wbe),e(wbe,Ngr),b(f,GOe,u),b(f,Yo,u),M(o9,Yo,null),e(Yo,qgr),e(Yo,Qd),e(Qd,jgr),e(Qd,GW),e(GW,Dgr),e(Qd,Ggr),e(Qd,OW),e(OW,Ogr),e(Qd,Vgr),e(Yo,Xgr),e(Yo,r9),e(r9,zgr),e(r9,Abe),e(Abe,Qgr),e(r9,Wgr),e(Yo,Hgr),e(Yo,Lt),M(t9,Lt,null),e(Lt,Ugr),e(Lt,Lbe),e(Lbe,Jgr),e(Lt,Ygr),e(Lt,Wd),e(Wd,Kgr),e(Wd,ybe),e(ybe,Zgr),e(Wd,ehr),e(Wd,VW),e(VW,ohr),e(Wd,rhr),e(Lt,thr),M(yF,Lt,null),e(Yo,ahr),e(Yo,bo),M(a9,bo,null),e(bo,nhr),e(bo,xbe),e(xbe,shr),e(bo,lhr),e(bo,en),e(en,ihr),e(en,$be),e($be,dhr),e(en,chr),e(en,kbe),e(kbe,fhr),e(en,mhr),e(en,Sbe),e(Sbe,ghr),e(en,hhr),e(bo,phr),e(bo,Rbe),e(Rbe,xF),e(xF,Pbe),e(Pbe,_hr),e(xF,uhr),e(xF,XW),e(XW,bhr),e(xF,vhr),e(bo,Fhr),e(bo,$F),e($F,Thr),e($F,Bbe),e(Bbe,Mhr),e($F,Ehr),e($F,Ibe),e(Ibe,Chr),e(bo,whr),M(kF,bo,null),b(f,OOe,u),b(f,Hd,u),e(Hd,SF),e(SF,Nbe),M(n9,Nbe,null),e(Hd,Ahr),e(Hd,qbe),e(qbe,Lhr),b(f,VOe,u),b(f,Ko,u),M(s9,Ko,null),e(Ko,yhr),e(Ko,Ud),e(Ud,xhr),e(Ud,zW),e(zW,$hr),e(Ud,khr),e(Ud,QW),e(QW,Shr),e(Ud,Rhr),e(Ko,Phr),e(Ko,l9),e(l9,Bhr),e(l9,jbe),e(jbe,Ihr),e(l9,Nhr),e(Ko,qhr),e(Ko,yt),M(i9,yt,null),e(yt,jhr),e(yt,Dbe),e(Dbe,Dhr),e(yt,Ghr),e(yt,Jd),e(Jd,Ohr),e(Jd,Gbe),e(Gbe,Vhr),e(Jd,Xhr),e(Jd,WW),e(WW,zhr),e(Jd,Qhr),e(yt,Whr),M(RF,yt,null),e(Ko,Hhr),e(Ko,vo),M(d9,vo,null),e(vo,Uhr),e(vo,Obe),e(Obe,Jhr),e(vo,Yhr),e(vo,on),e(on,Khr),e(on,Vbe),e(Vbe,Zhr),e(on,epr),e(on,Xbe),e(Xbe,opr),e(on,rpr),e(on,zbe),e(zbe,tpr),e(on,apr),e(vo,npr),e(vo,rn),e(rn,PF),e(PF,Qbe),e(Qbe,spr),e(PF,lpr),e(PF,HW),e(HW,ipr),e(PF,dpr),e(rn,cpr),e(rn,BF),e(BF,Wbe),e(Wbe,fpr),e(BF,mpr),e(BF,UW),e(UW,gpr),e(BF,hpr),e(rn,ppr),e(rn,IF),e(IF,Hbe),e(Hbe,_pr),e(IF,upr),e(IF,JW),e(JW,bpr),e(IF,vpr),e(rn,Fpr),e(rn,NF),e(NF,Ube),e(Ube,Tpr),e(NF,Mpr),e(NF,YW),e(YW,Epr),e(NF,Cpr),e(vo,wpr),e(vo,qF),e(qF,Apr),e(qF,Jbe),e(Jbe,Lpr),e(qF,ypr),e(qF,Ybe),e(Ybe,xpr),e(vo,$pr),M(jF,vo,null),b(f,XOe,u),b(f,Yd,u),e(Yd,DF),e(DF,Kbe),M(c9,Kbe,null),e(Yd,kpr),e(Yd,Zbe),e(Zbe,Spr),b(f,zOe,u),b(f,Zo,u),M(f9,Zo,null),e(Zo,Rpr),e(Zo,Kd),e(Kd,Ppr),e(Kd,KW),e(KW,Bpr),e(Kd,Ipr),e(Kd,ZW),e(ZW,Npr),e(Kd,qpr),e(Zo,jpr),e(Zo,m9),e(m9,Dpr),e(m9,e5e),e(e5e,Gpr),e(m9,Opr),e(Zo,Vpr),e(Zo,xt),M(g9,xt,null),e(xt,Xpr),e(xt,o5e),e(o5e,zpr),e(xt,Qpr),e(xt,Zd),e(Zd,Wpr),e(Zd,r5e),e(r5e,Hpr),e(Zd,Upr),e(Zd,eH),e(eH,Jpr),e(Zd,Ypr),e(xt,Kpr),M(GF,xt,null),e(Zo,Zpr),e(Zo,Fo),M(h9,Fo,null),e(Fo,e_r),e(Fo,t5e),e(t5e,o_r),e(Fo,r_r),e(Fo,tn),e(tn,t_r),e(tn,a5e),e(a5e,a_r),e(tn,n_r),e(tn,n5e),e(n5e,s_r),e(tn,l_r),e(tn,s5e),e(s5e,i_r),e(tn,d_r),e(Fo,c_r),e(Fo,l5e),e(l5e,OF),e(OF,i5e),e(i5e,f_r),e(OF,m_r),e(OF,oH),e(oH,g_r),e(OF,h_r),e(Fo,p_r),e(Fo,VF),e(VF,__r),e(VF,d5e),e(d5e,u_r),e(VF,b_r),e(VF,c5e),e(c5e,v_r),e(Fo,F_r),M(XF,Fo,null),b(f,QOe,u),b(f,ec,u),e(ec,zF),e(zF,f5e),M(p9,f5e,null),e(ec,T_r),e(ec,m5e),e(m5e,M_r),b(f,WOe,u),b(f,er,u),M(_9,er,null),e(er,E_r),e(er,oc),e(oc,C_r),e(oc,rH),e(rH,w_r),e(oc,A_r),e(oc,tH),e(tH,L_r),e(oc,y_r),e(er,x_r),e(er,u9),e(u9,$_r),e(u9,g5e),e(g5e,k_r),e(u9,S_r),e(er,R_r),e(er,$t),M(b9,$t,null),e($t,P_r),e($t,h5e),e(h5e,B_r),e($t,I_r),e($t,rc),e(rc,N_r),e(rc,p5e),e(p5e,q_r),e(rc,j_r),e(rc,aH),e(aH,D_r),e(rc,G_r),e($t,O_r),M(QF,$t,null),e(er,V_r),e(er,yr),M(v9,yr,null),e(yr,X_r),e(yr,_5e),e(_5e,z_r),e(yr,Q_r),e(yr,an),e(an,W_r),e(an,u5e),e(u5e,H_r),e(an,U_r),e(an,b5e),e(b5e,J_r),e(an,Y_r),e(an,v5e),e(v5e,K_r),e(an,Z_r),e(yr,eur),e(yr,j),e(j,WF),e(WF,F5e),e(F5e,our),e(WF,rur),e(WF,nH),e(nH,tur),e(WF,aur),e(j,nur),e(j,HF),e(HF,T5e),e(T5e,sur),e(HF,lur),e(HF,sH),e(sH,iur),e(HF,dur),e(j,cur),e(j,UF),e(UF,M5e),e(M5e,fur),e(UF,mur),e(UF,lH),e(lH,gur),e(UF,hur),e(j,pur),e(j,JF),e(JF,E5e),e(E5e,_ur),e(JF,uur),e(JF,iH),e(iH,bur),e(JF,vur),e(j,Fur),e(j,YF),e(YF,C5e),e(C5e,Tur),e(YF,Mur),e(YF,dH),e(dH,Eur),e(YF,Cur),e(j,wur),e(j,KF),e(KF,w5e),e(w5e,Aur),e(KF,Lur),e(KF,cH),e(cH,yur),e(KF,xur),e(j,$ur),e(j,ZF),e(ZF,A5e),e(A5e,kur),e(ZF,Sur),e(ZF,fH),e(fH,Rur),e(ZF,Pur),e(j,Bur),e(j,eT),e(eT,L5e),e(L5e,Iur),e(eT,Nur),e(eT,mH),e(mH,qur),e(eT,jur),e(j,Dur),e(j,oT),e(oT,y5e),e(y5e,Gur),e(oT,Our),e(oT,gH),e(gH,Vur),e(oT,Xur),e(j,zur),e(j,rT),e(rT,x5e),e(x5e,Qur),e(rT,Wur),e(rT,hH),e(hH,Hur),e(rT,Uur),e(j,Jur),e(j,tT),e(tT,$5e),e($5e,Yur),e(tT,Kur),e(tT,pH),e(pH,Zur),e(tT,e1r),e(j,o1r),e(j,aT),e(aT,k5e),e(k5e,r1r),e(aT,t1r),e(aT,_H),e(_H,a1r),e(aT,n1r),e(j,s1r),e(j,nT),e(nT,S5e),e(S5e,l1r),e(nT,i1r),e(nT,uH),e(uH,d1r),e(nT,c1r),e(j,f1r),e(j,sT),e(sT,R5e),e(R5e,m1r),e(sT,g1r),e(sT,bH),e(bH,h1r),e(sT,p1r),e(j,_1r),e(j,lT),e(lT,P5e),e(P5e,u1r),e(lT,b1r),e(lT,vH),e(vH,v1r),e(lT,F1r),e(j,T1r),e(j,iT),e(iT,B5e),e(B5e,M1r),e(iT,E1r),e(iT,FH),e(FH,C1r),e(iT,w1r),e(j,A1r),e(j,dT),e(dT,I5e),e(I5e,L1r),e(dT,y1r),e(dT,TH),e(TH,x1r),e(dT,$1r),e(j,k1r),e(j,Qs),e(Qs,N5e),e(N5e,S1r),e(Qs,R1r),e(Qs,MH),e(MH,P1r),e(Qs,B1r),e(Qs,EH),e(EH,I1r),e(Qs,N1r),e(j,q1r),e(j,cT),e(cT,q5e),e(q5e,j1r),e(cT,D1r),e(cT,CH),e(CH,G1r),e(cT,O1r),e(j,V1r),e(j,fT),e(fT,j5e),e(j5e,X1r),e(fT,z1r),e(fT,wH),e(wH,Q1r),e(fT,W1r),e(j,H1r),e(j,mT),e(mT,D5e),e(D5e,U1r),e(mT,J1r),e(mT,AH),e(AH,Y1r),e(mT,K1r),e(j,Z1r),e(j,gT),e(gT,G5e),e(G5e,e7r),e(gT,o7r),e(gT,LH),e(LH,r7r),e(gT,t7r),e(j,a7r),e(j,hT),e(hT,O5e),e(O5e,n7r),e(hT,s7r),e(hT,yH),e(yH,l7r),e(hT,i7r),e(j,d7r),e(j,pT),e(pT,V5e),e(V5e,c7r),e(pT,f7r),e(pT,xH),e(xH,m7r),e(pT,g7r),e(j,h7r),e(j,_T),e(_T,X5e),e(X5e,p7r),e(_T,_7r),e(_T,$H),e($H,u7r),e(_T,b7r),e(j,v7r),e(j,uT),e(uT,z5e),e(z5e,F7r),e(uT,T7r),e(uT,kH),e(kH,M7r),e(uT,E7r),e(j,C7r),e(j,bT),e(bT,Q5e),e(Q5e,w7r),e(bT,A7r),e(bT,SH),e(SH,L7r),e(bT,y7r),e(j,x7r),e(j,vT),e(vT,W5e),e(W5e,$7r),e(vT,k7r),e(vT,RH),e(RH,S7r),e(vT,R7r),e(j,P7r),e(j,FT),e(FT,H5e),e(H5e,B7r),e(FT,I7r),e(FT,PH),e(PH,N7r),e(FT,q7r),e(j,j7r),e(j,TT),e(TT,U5e),e(U5e,D7r),e(TT,G7r),e(TT,BH),e(BH,O7r),e(TT,V7r),e(j,X7r),e(j,MT),e(MT,J5e),e(J5e,z7r),e(MT,Q7r),e(MT,IH),e(IH,W7r),e(MT,H7r),e(j,U7r),e(j,ET),e(ET,Y5e),e(Y5e,J7r),e(ET,Y7r),e(ET,NH),e(NH,K7r),e(ET,Z7r),e(j,e2r),e(j,CT),e(CT,K5e),e(K5e,o2r),e(CT,r2r),e(CT,qH),e(qH,t2r),e(CT,a2r),e(j,n2r),e(j,wT),e(wT,Z5e),e(Z5e,s2r),e(wT,l2r),e(wT,jH),e(jH,i2r),e(wT,d2r),e(j,c2r),e(j,AT),e(AT,eve),e(eve,f2r),e(AT,m2r),e(AT,DH),e(DH,g2r),e(AT,h2r),e(j,p2r),e(j,LT),e(LT,ove),e(ove,_2r),e(LT,u2r),e(LT,GH),e(GH,b2r),e(LT,v2r),e(j,F2r),e(j,yT),e(yT,rve),e(rve,T2r),e(yT,M2r),e(yT,OH),e(OH,E2r),e(yT,C2r),e(j,w2r),e(j,xT),e(xT,tve),e(tve,A2r),e(xT,L2r),e(xT,VH),e(VH,y2r),e(xT,x2r),e(j,$2r),e(j,$T),e($T,ave),e(ave,k2r),e($T,S2r),e($T,XH),e(XH,R2r),e($T,P2r),e(j,B2r),e(j,kT),e(kT,nve),e(nve,I2r),e(kT,N2r),e(kT,zH),e(zH,q2r),e(kT,j2r),e(j,D2r),e(j,ST),e(ST,sve),e(sve,G2r),e(ST,O2r),e(ST,QH),e(QH,V2r),e(ST,X2r),e(j,z2r),e(j,RT),e(RT,lve),e(lve,Q2r),e(RT,W2r),e(RT,WH),e(WH,H2r),e(RT,U2r),e(j,J2r),e(j,PT),e(PT,ive),e(ive,Y2r),e(PT,K2r),e(PT,HH),e(HH,Z2r),e(PT,ebr),e(j,obr),e(j,BT),e(BT,dve),e(dve,rbr),e(BT,tbr),e(BT,UH),e(UH,abr),e(BT,nbr),e(j,sbr),e(j,IT),e(IT,cve),e(cve,lbr),e(IT,ibr),e(IT,JH),e(JH,dbr),e(IT,cbr),e(j,fbr),e(j,NT),e(NT,fve),e(fve,mbr),e(NT,gbr),e(NT,YH),e(YH,hbr),e(NT,pbr),e(j,_br),e(j,qT),e(qT,mve),e(mve,ubr),e(qT,bbr),e(qT,KH),e(KH,vbr),e(qT,Fbr),e(yr,Tbr),M(jT,yr,null),b(f,HOe,u),b(f,tc,u),e(tc,DT),e(DT,gve),M(F9,gve,null),e(tc,Mbr),e(tc,hve),e(hve,Ebr),b(f,UOe,u),b(f,or,u),M(T9,or,null),e(or,Cbr),e(or,ac),e(ac,wbr),e(ac,ZH),e(ZH,Abr),e(ac,Lbr),e(ac,eU),e(eU,ybr),e(ac,xbr),e(or,$br),e(or,M9),e(M9,kbr),e(M9,pve),e(pve,Sbr),e(M9,Rbr),e(or,Pbr),e(or,kt),M(E9,kt,null),e(kt,Bbr),e(kt,_ve),e(_ve,Ibr),e(kt,Nbr),e(kt,nc),e(nc,qbr),e(nc,uve),e(uve,jbr),e(nc,Dbr),e(nc,oU),e(oU,Gbr),e(nc,Obr),e(kt,Vbr),M(GT,kt,null),e(or,Xbr),e(or,xr),M(C9,xr,null),e(xr,zbr),e(xr,bve),e(bve,Qbr),e(xr,Wbr),e(xr,nn),e(nn,Hbr),e(nn,vve),e(vve,Ubr),e(nn,Jbr),e(nn,Fve),e(Fve,Ybr),e(nn,Kbr),e(nn,Tve),e(Tve,Zbr),e(nn,e5r),e(xr,o5r),e(xr,se),e(se,OT),e(OT,Mve),e(Mve,r5r),e(OT,t5r),e(OT,rU),e(rU,a5r),e(OT,n5r),e(se,s5r),e(se,VT),e(VT,Eve),e(Eve,l5r),e(VT,i5r),e(VT,tU),e(tU,d5r),e(VT,c5r),e(se,f5r),e(se,XT),e(XT,Cve),e(Cve,m5r),e(XT,g5r),e(XT,aU),e(aU,h5r),e(XT,p5r),e(se,_5r),e(se,zT),e(zT,wve),e(wve,u5r),e(zT,b5r),e(zT,nU),e(nU,v5r),e(zT,F5r),e(se,T5r),e(se,QT),e(QT,Ave),e(Ave,M5r),e(QT,E5r),e(QT,sU),e(sU,C5r),e(QT,w5r),e(se,A5r),e(se,WT),e(WT,Lve),e(Lve,L5r),e(WT,y5r),e(WT,lU),e(lU,x5r),e(WT,$5r),e(se,k5r),e(se,HT),e(HT,yve),e(yve,S5r),e(HT,R5r),e(HT,iU),e(iU,P5r),e(HT,B5r),e(se,I5r),e(se,UT),e(UT,xve),e(xve,N5r),e(UT,q5r),e(UT,dU),e(dU,j5r),e(UT,D5r),e(se,G5r),e(se,JT),e(JT,$ve),e($ve,O5r),e(JT,V5r),e(JT,cU),e(cU,X5r),e(JT,z5r),e(se,Q5r),e(se,YT),e(YT,kve),e(kve,W5r),e(YT,H5r),e(YT,fU),e(fU,U5r),e(YT,J5r),e(se,Y5r),e(se,KT),e(KT,Sve),e(Sve,K5r),e(KT,Z5r),e(KT,mU),e(mU,evr),e(KT,ovr),e(se,rvr),e(se,ZT),e(ZT,Rve),e(Rve,tvr),e(ZT,avr),e(ZT,gU),e(gU,nvr),e(ZT,svr),e(se,lvr),e(se,eM),e(eM,Pve),e(Pve,ivr),e(eM,dvr),e(eM,hU),e(hU,cvr),e(eM,fvr),e(se,mvr),e(se,oM),e(oM,Bve),e(Bve,gvr),e(oM,hvr),e(oM,pU),e(pU,pvr),e(oM,_vr),e(se,uvr),e(se,rM),e(rM,Ive),e(Ive,bvr),e(rM,vvr),e(rM,_U),e(_U,Fvr),e(rM,Tvr),e(se,Mvr),e(se,tM),e(tM,Nve),e(Nve,Evr),e(tM,Cvr),e(tM,uU),e(uU,wvr),e(tM,Avr),e(se,Lvr),e(se,aM),e(aM,qve),e(qve,yvr),e(aM,xvr),e(aM,bU),e(bU,$vr),e(aM,kvr),e(se,Svr),e(se,nM),e(nM,jve),e(jve,Rvr),e(nM,Pvr),e(nM,vU),e(vU,Bvr),e(nM,Ivr),e(se,Nvr),e(se,sM),e(sM,Dve),e(Dve,qvr),e(sM,jvr),e(sM,FU),e(FU,Dvr),e(sM,Gvr),e(se,Ovr),e(se,lM),e(lM,Gve),e(Gve,Vvr),e(lM,Xvr),e(lM,TU),e(TU,zvr),e(lM,Qvr),e(se,Wvr),e(se,iM),e(iM,Ove),e(Ove,Hvr),e(iM,Uvr),e(iM,MU),e(MU,Jvr),e(iM,Yvr),e(se,Kvr),e(se,dM),e(dM,Vve),e(Vve,Zvr),e(dM,e3r),e(dM,EU),e(EU,o3r),e(dM,r3r),e(se,t3r),e(se,cM),e(cM,Xve),e(Xve,a3r),e(cM,n3r),e(cM,CU),e(CU,s3r),e(cM,l3r),e(xr,i3r),M(fM,xr,null),b(f,JOe,u),b(f,sc,u),e(sc,mM),e(mM,zve),M(w9,zve,null),e(sc,d3r),e(sc,Qve),e(Qve,c3r),b(f,YOe,u),b(f,rr,u),M(A9,rr,null),e(rr,f3r),e(rr,lc),e(lc,m3r),e(lc,wU),e(wU,g3r),e(lc,h3r),e(lc,AU),e(AU,p3r),e(lc,_3r),e(rr,u3r),e(rr,L9),e(L9,b3r),e(L9,Wve),e(Wve,v3r),e(L9,F3r),e(rr,T3r),e(rr,St),M(y9,St,null),e(St,M3r),e(St,Hve),e(Hve,E3r),e(St,C3r),e(St,ic),e(ic,w3r),e(ic,Uve),e(Uve,A3r),e(ic,L3r),e(ic,LU),e(LU,y3r),e(ic,x3r),e(St,$3r),M(gM,St,null),e(rr,k3r),e(rr,$r),M(x9,$r,null),e($r,S3r),e($r,Jve),e(Jve,R3r),e($r,P3r),e($r,sn),e(sn,B3r),e(sn,Yve),e(Yve,I3r),e(sn,N3r),e(sn,Kve),e(Kve,q3r),e(sn,j3r),e(sn,Zve),e(Zve,D3r),e(sn,G3r),e($r,O3r),e($r,Me),e(Me,hM),e(hM,e3e),e(e3e,V3r),e(hM,X3r),e(hM,yU),e(yU,z3r),e(hM,Q3r),e(Me,W3r),e(Me,pM),e(pM,o3e),e(o3e,H3r),e(pM,U3r),e(pM,xU),e(xU,J3r),e(pM,Y3r),e(Me,K3r),e(Me,_M),e(_M,r3e),e(r3e,Z3r),e(_M,eFr),e(_M,$U),e($U,oFr),e(_M,rFr),e(Me,tFr),e(Me,uM),e(uM,t3e),e(t3e,aFr),e(uM,nFr),e(uM,kU),e(kU,sFr),e(uM,lFr),e(Me,iFr),e(Me,bM),e(bM,a3e),e(a3e,dFr),e(bM,cFr),e(bM,SU),e(SU,fFr),e(bM,mFr),e(Me,gFr),e(Me,vM),e(vM,n3e),e(n3e,hFr),e(vM,pFr),e(vM,RU),e(RU,_Fr),e(vM,uFr),e(Me,bFr),e(Me,FM),e(FM,s3e),e(s3e,vFr),e(FM,FFr),e(FM,PU),e(PU,TFr),e(FM,MFr),e(Me,EFr),e(Me,TM),e(TM,l3e),e(l3e,CFr),e(TM,wFr),e(TM,BU),e(BU,AFr),e(TM,LFr),e(Me,yFr),e(Me,MM),e(MM,i3e),e(i3e,xFr),e(MM,$Fr),e(MM,IU),e(IU,kFr),e(MM,SFr),e(Me,RFr),e(Me,EM),e(EM,d3e),e(d3e,PFr),e(EM,BFr),e(EM,NU),e(NU,IFr),e(EM,NFr),e(Me,qFr),e(Me,CM),e(CM,c3e),e(c3e,jFr),e(CM,DFr),e(CM,qU),e(qU,GFr),e(CM,OFr),e(Me,VFr),e(Me,wM),e(wM,f3e),e(f3e,XFr),e(wM,zFr),e(wM,jU),e(jU,QFr),e(wM,WFr),e(Me,HFr),e(Me,AM),e(AM,m3e),e(m3e,UFr),e(AM,JFr),e(AM,DU),e(DU,YFr),e(AM,KFr),e($r,ZFr),M(LM,$r,null),b(f,KOe,u),b(f,dc,u),e(dc,yM),e(yM,g3e),M($9,g3e,null),e(dc,eTr),e(dc,h3e),e(h3e,oTr),b(f,ZOe,u),b(f,tr,u),M(k9,tr,null),e(tr,rTr),e(tr,cc),e(cc,tTr),e(cc,GU),e(GU,aTr),e(cc,nTr),e(cc,OU),e(OU,sTr),e(cc,lTr),e(tr,iTr),e(tr,S9),e(S9,dTr),e(S9,p3e),e(p3e,cTr),e(S9,fTr),e(tr,mTr),e(tr,Rt),M(R9,Rt,null),e(Rt,gTr),e(Rt,_3e),e(_3e,hTr),e(Rt,pTr),e(Rt,fc),e(fc,_Tr),e(fc,u3e),e(u3e,uTr),e(fc,bTr),e(fc,VU),e(VU,vTr),e(fc,FTr),e(Rt,TTr),M(xM,Rt,null),e(tr,MTr),e(tr,kr),M(P9,kr,null),e(kr,ETr),e(kr,b3e),e(b3e,CTr),e(kr,wTr),e(kr,ln),e(ln,ATr),e(ln,v3e),e(v3e,LTr),e(ln,yTr),e(ln,F3e),e(F3e,xTr),e(ln,$Tr),e(ln,T3e),e(T3e,kTr),e(ln,STr),e(kr,RTr),e(kr,dn),e(dn,$M),e($M,M3e),e(M3e,PTr),e($M,BTr),e($M,XU),e(XU,ITr),e($M,NTr),e(dn,qTr),e(dn,kM),e(kM,E3e),e(E3e,jTr),e(kM,DTr),e(kM,zU),e(zU,GTr),e(kM,OTr),e(dn,VTr),e(dn,SM),e(SM,C3e),e(C3e,XTr),e(SM,zTr),e(SM,QU),e(QU,QTr),e(SM,WTr),e(dn,HTr),e(dn,RM),e(RM,w3e),e(w3e,UTr),e(RM,JTr),e(RM,WU),e(WU,YTr),e(RM,KTr),e(kr,ZTr),M(PM,kr,null),b(f,eVe,u),b(f,mc,u),e(mc,BM),e(BM,A3e),M(B9,A3e,null),e(mc,eMr),e(mc,L3e),e(L3e,oMr),b(f,oVe,u),b(f,ar,u),M(I9,ar,null),e(ar,rMr),e(ar,gc),e(gc,tMr),e(gc,HU),e(HU,aMr),e(gc,nMr),e(gc,UU),e(UU,sMr),e(gc,lMr),e(ar,iMr),e(ar,N9),e(N9,dMr),e(N9,y3e),e(y3e,cMr),e(N9,fMr),e(ar,mMr),e(ar,Pt),M(q9,Pt,null),e(Pt,gMr),e(Pt,x3e),e(x3e,hMr),e(Pt,pMr),e(Pt,hc),e(hc,_Mr),e(hc,$3e),e($3e,uMr),e(hc,bMr),e(hc,JU),e(JU,vMr),e(hc,FMr),e(Pt,TMr),M(IM,Pt,null),e(ar,MMr),e(ar,Sr),M(j9,Sr,null),e(Sr,EMr),e(Sr,k3e),e(k3e,CMr),e(Sr,wMr),e(Sr,cn),e(cn,AMr),e(cn,S3e),e(S3e,LMr),e(cn,yMr),e(cn,R3e),e(R3e,xMr),e(cn,$Mr),e(cn,P3e),e(P3e,kMr),e(cn,SMr),e(Sr,RMr),e(Sr,ie),e(ie,NM),e(NM,B3e),e(B3e,PMr),e(NM,BMr),e(NM,YU),e(YU,IMr),e(NM,NMr),e(ie,qMr),e(ie,qM),e(qM,I3e),e(I3e,jMr),e(qM,DMr),e(qM,KU),e(KU,GMr),e(qM,OMr),e(ie,VMr),e(ie,jM),e(jM,N3e),e(N3e,XMr),e(jM,zMr),e(jM,ZU),e(ZU,QMr),e(jM,WMr),e(ie,HMr),e(ie,DM),e(DM,q3e),e(q3e,UMr),e(DM,JMr),e(DM,eJ),e(eJ,YMr),e(DM,KMr),e(ie,ZMr),e(ie,GM),e(GM,j3e),e(j3e,eEr),e(GM,oEr),e(GM,oJ),e(oJ,rEr),e(GM,tEr),e(ie,aEr),e(ie,OM),e(OM,D3e),e(D3e,nEr),e(OM,sEr),e(OM,rJ),e(rJ,lEr),e(OM,iEr),e(ie,dEr),e(ie,VM),e(VM,G3e),e(G3e,cEr),e(VM,fEr),e(VM,tJ),e(tJ,mEr),e(VM,gEr),e(ie,hEr),e(ie,XM),e(XM,O3e),e(O3e,pEr),e(XM,_Er),e(XM,aJ),e(aJ,uEr),e(XM,bEr),e(ie,vEr),e(ie,zM),e(zM,V3e),e(V3e,FEr),e(zM,TEr),e(zM,nJ),e(nJ,MEr),e(zM,EEr),e(ie,CEr),e(ie,QM),e(QM,X3e),e(X3e,wEr),e(QM,AEr),e(QM,sJ),e(sJ,LEr),e(QM,yEr),e(ie,xEr),e(ie,WM),e(WM,z3e),e(z3e,$Er),e(WM,kEr),e(WM,lJ),e(lJ,SEr),e(WM,REr),e(ie,PEr),e(ie,HM),e(HM,Q3e),e(Q3e,BEr),e(HM,IEr),e(HM,iJ),e(iJ,NEr),e(HM,qEr),e(ie,jEr),e(ie,UM),e(UM,W3e),e(W3e,DEr),e(UM,GEr),e(UM,dJ),e(dJ,OEr),e(UM,VEr),e(ie,XEr),e(ie,JM),e(JM,H3e),e(H3e,zEr),e(JM,QEr),e(JM,cJ),e(cJ,WEr),e(JM,HEr),e(ie,UEr),e(ie,YM),e(YM,U3e),e(U3e,JEr),e(YM,YEr),e(YM,fJ),e(fJ,KEr),e(YM,ZEr),e(ie,e4r),e(ie,KM),e(KM,J3e),e(J3e,o4r),e(KM,r4r),e(KM,mJ),e(mJ,t4r),e(KM,a4r),e(ie,n4r),e(ie,ZM),e(ZM,Y3e),e(Y3e,s4r),e(ZM,l4r),e(ZM,gJ),e(gJ,i4r),e(ZM,d4r),e(ie,c4r),e(ie,eE),e(eE,K3e),e(K3e,f4r),e(eE,m4r),e(eE,hJ),e(hJ,g4r),e(eE,h4r),e(ie,p4r),e(ie,oE),e(oE,Z3e),e(Z3e,_4r),e(oE,u4r),e(oE,pJ),e(pJ,b4r),e(oE,v4r),e(ie,F4r),e(ie,rE),e(rE,eFe),e(eFe,T4r),e(rE,M4r),e(rE,_J),e(_J,E4r),e(rE,C4r),e(Sr,w4r),M(tE,Sr,null),b(f,rVe,u),b(f,pc,u),e(pc,aE),e(aE,oFe),M(D9,oFe,null),e(pc,A4r),e(pc,rFe),e(rFe,L4r),b(f,tVe,u),b(f,nr,u),M(G9,nr,null),e(nr,y4r),e(nr,_c),e(_c,x4r),e(_c,uJ),e(uJ,$4r),e(_c,k4r),e(_c,bJ),e(bJ,S4r),e(_c,R4r),e(nr,P4r),e(nr,O9),e(O9,B4r),e(O9,tFe),e(tFe,I4r),e(O9,N4r),e(nr,q4r),e(nr,Bt),M(V9,Bt,null),e(Bt,j4r),e(Bt,aFe),e(aFe,D4r),e(Bt,G4r),e(Bt,uc),e(uc,O4r),e(uc,nFe),e(nFe,V4r),e(uc,X4r),e(uc,vJ),e(vJ,z4r),e(uc,Q4r),e(Bt,W4r),M(nE,Bt,null),e(nr,H4r),e(nr,Rr),M(X9,Rr,null),e(Rr,U4r),e(Rr,sFe),e(sFe,J4r),e(Rr,Y4r),e(Rr,fn),e(fn,K4r),e(fn,lFe),e(lFe,Z4r),e(fn,eCr),e(fn,iFe),e(iFe,oCr),e(fn,rCr),e(fn,dFe),e(dFe,tCr),e(fn,aCr),e(Rr,nCr),e(Rr,ye),e(ye,sE),e(sE,cFe),e(cFe,sCr),e(sE,lCr),e(sE,FJ),e(FJ,iCr),e(sE,dCr),e(ye,cCr),e(ye,lE),e(lE,fFe),e(fFe,fCr),e(lE,mCr),e(lE,TJ),e(TJ,gCr),e(lE,hCr),e(ye,pCr),e(ye,iE),e(iE,mFe),e(mFe,_Cr),e(iE,uCr),e(iE,MJ),e(MJ,bCr),e(iE,vCr),e(ye,FCr),e(ye,dE),e(dE,gFe),e(gFe,TCr),e(dE,MCr),e(dE,EJ),e(EJ,ECr),e(dE,CCr),e(ye,wCr),e(ye,cE),e(cE,hFe),e(hFe,ACr),e(cE,LCr),e(cE,CJ),e(CJ,yCr),e(cE,xCr),e(ye,$Cr),e(ye,fE),e(fE,pFe),e(pFe,kCr),e(fE,SCr),e(fE,wJ),e(wJ,RCr),e(fE,PCr),e(ye,BCr),e(ye,mE),e(mE,_Fe),e(_Fe,ICr),e(mE,NCr),e(mE,AJ),e(AJ,qCr),e(mE,jCr),e(ye,DCr),e(ye,gE),e(gE,uFe),e(uFe,GCr),e(gE,OCr),e(gE,LJ),e(LJ,VCr),e(gE,XCr),e(ye,zCr),e(ye,hE),e(hE,bFe),e(bFe,QCr),e(hE,WCr),e(hE,yJ),e(yJ,HCr),e(hE,UCr),e(ye,JCr),e(ye,pE),e(pE,vFe),e(vFe,YCr),e(pE,KCr),e(pE,xJ),e(xJ,ZCr),e(pE,e0r),e(Rr,o0r),M(_E,Rr,null),b(f,aVe,u),b(f,bc,u),e(bc,uE),e(uE,FFe),M(z9,FFe,null),e(bc,r0r),e(bc,TFe),e(TFe,t0r),b(f,nVe,u),b(f,sr,u),M(Q9,sr,null),e(sr,a0r),e(sr,vc),e(vc,n0r),e(vc,$J),e($J,s0r),e(vc,l0r),e(vc,kJ),e(kJ,i0r),e(vc,d0r),e(sr,c0r),e(sr,W9),e(W9,f0r),e(W9,MFe),e(MFe,m0r),e(W9,g0r),e(sr,h0r),e(sr,It),M(H9,It,null),e(It,p0r),e(It,EFe),e(EFe,_0r),e(It,u0r),e(It,Fc),e(Fc,b0r),e(Fc,CFe),e(CFe,v0r),e(Fc,F0r),e(Fc,SJ),e(SJ,T0r),e(Fc,M0r),e(It,E0r),M(bE,It,null),e(sr,C0r),e(sr,Pr),M(U9,Pr,null),e(Pr,w0r),e(Pr,wFe),e(wFe,A0r),e(Pr,L0r),e(Pr,mn),e(mn,y0r),e(mn,AFe),e(AFe,x0r),e(mn,$0r),e(mn,LFe),e(LFe,k0r),e(mn,S0r),e(mn,yFe),e(yFe,R0r),e(mn,P0r),e(Pr,B0r),e(Pr,te),e(te,vE),e(vE,xFe),e(xFe,I0r),e(vE,N0r),e(vE,RJ),e(RJ,q0r),e(vE,j0r),e(te,D0r),e(te,FE),e(FE,$Fe),e($Fe,G0r),e(FE,O0r),e(FE,PJ),e(PJ,V0r),e(FE,X0r),e(te,z0r),e(te,TE),e(TE,kFe),e(kFe,Q0r),e(TE,W0r),e(TE,BJ),e(BJ,H0r),e(TE,U0r),e(te,J0r),e(te,ME),e(ME,SFe),e(SFe,Y0r),e(ME,K0r),e(ME,IJ),e(IJ,Z0r),e(ME,ewr),e(te,owr),e(te,EE),e(EE,RFe),e(RFe,rwr),e(EE,twr),e(EE,NJ),e(NJ,awr),e(EE,nwr),e(te,swr),e(te,CE),e(CE,PFe),e(PFe,lwr),e(CE,iwr),e(CE,qJ),e(qJ,dwr),e(CE,cwr),e(te,fwr),e(te,wE),e(wE,BFe),e(BFe,mwr),e(wE,gwr),e(wE,jJ),e(jJ,hwr),e(wE,pwr),e(te,_wr),e(te,AE),e(AE,IFe),e(IFe,uwr),e(AE,bwr),e(AE,DJ),e(DJ,vwr),e(AE,Fwr),e(te,Twr),e(te,LE),e(LE,NFe),e(NFe,Mwr),e(LE,Ewr),e(LE,GJ),e(GJ,Cwr),e(LE,wwr),e(te,Awr),e(te,yE),e(yE,qFe),e(qFe,Lwr),e(yE,ywr),e(yE,OJ),e(OJ,xwr),e(yE,$wr),e(te,kwr),e(te,xE),e(xE,jFe),e(jFe,Swr),e(xE,Rwr),e(xE,VJ),e(VJ,Pwr),e(xE,Bwr),e(te,Iwr),e(te,$E),e($E,DFe),e(DFe,Nwr),e($E,qwr),e($E,XJ),e(XJ,jwr),e($E,Dwr),e(te,Gwr),e(te,kE),e(kE,GFe),e(GFe,Owr),e(kE,Vwr),e(kE,zJ),e(zJ,Xwr),e(kE,zwr),e(te,Qwr),e(te,SE),e(SE,OFe),e(OFe,Wwr),e(SE,Hwr),e(SE,QJ),e(QJ,Uwr),e(SE,Jwr),e(te,Ywr),e(te,RE),e(RE,VFe),e(VFe,Kwr),e(RE,Zwr),e(RE,WJ),e(WJ,eAr),e(RE,oAr),e(te,rAr),e(te,PE),e(PE,XFe),e(XFe,tAr),e(PE,aAr),e(PE,HJ),e(HJ,nAr),e(PE,sAr),e(te,lAr),e(te,BE),e(BE,zFe),e(zFe,iAr),e(BE,dAr),e(BE,UJ),e(UJ,cAr),e(BE,fAr),e(te,mAr),e(te,IE),e(IE,QFe),e(QFe,gAr),e(IE,hAr),e(IE,JJ),e(JJ,pAr),e(IE,_Ar),e(te,uAr),e(te,NE),e(NE,WFe),e(WFe,bAr),e(NE,vAr),e(NE,YJ),e(YJ,FAr),e(NE,TAr),e(te,MAr),e(te,qE),e(qE,HFe),e(HFe,EAr),e(qE,CAr),e(qE,KJ),e(KJ,wAr),e(qE,AAr),e(te,LAr),e(te,jE),e(jE,UFe),e(UFe,yAr),e(jE,xAr),e(jE,ZJ),e(ZJ,$Ar),e(jE,kAr),e(te,SAr),e(te,DE),e(DE,JFe),e(JFe,RAr),e(DE,PAr),e(DE,eY),e(eY,BAr),e(DE,IAr),e(te,NAr),e(te,GE),e(GE,YFe),e(YFe,qAr),e(GE,jAr),e(GE,oY),e(oY,DAr),e(GE,GAr),e(te,OAr),e(te,OE),e(OE,KFe),e(KFe,VAr),e(OE,XAr),e(OE,rY),e(rY,zAr),e(OE,QAr),e(te,WAr),e(te,VE),e(VE,ZFe),e(ZFe,HAr),e(VE,UAr),e(VE,tY),e(tY,JAr),e(VE,YAr),e(te,KAr),e(te,XE),e(XE,eTe),e(eTe,ZAr),e(XE,e6r),e(XE,aY),e(aY,o6r),e(XE,r6r),e(Pr,t6r),M(zE,Pr,null),b(f,sVe,u),b(f,Tc,u),e(Tc,QE),e(QE,oTe),M(J9,oTe,null),e(Tc,a6r),e(Tc,rTe),e(rTe,n6r),b(f,lVe,u),b(f,lr,u),M(Y9,lr,null),e(lr,s6r),e(lr,Mc),e(Mc,l6r),e(Mc,nY),e(nY,i6r),e(Mc,d6r),e(Mc,sY),e(sY,c6r),e(Mc,f6r),e(lr,m6r),e(lr,K9),e(K9,g6r),e(K9,tTe),e(tTe,h6r),e(K9,p6r),e(lr,_6r),e(lr,Nt),M(Z9,Nt,null),e(Nt,u6r),e(Nt,aTe),e(aTe,b6r),e(Nt,v6r),e(Nt,Ec),e(Ec,F6r),e(Ec,nTe),e(nTe,T6r),e(Ec,M6r),e(Ec,lY),e(lY,E6r),e(Ec,C6r),e(Nt,w6r),M(WE,Nt,null),e(lr,A6r),e(lr,Br),M(ex,Br,null),e(Br,L6r),e(Br,sTe),e(sTe,y6r),e(Br,x6r),e(Br,gn),e(gn,$6r),e(gn,lTe),e(lTe,k6r),e(gn,S6r),e(gn,iTe),e(iTe,R6r),e(gn,P6r),e(gn,dTe),e(dTe,B6r),e(gn,I6r),e(Br,N6r),e(Br,_e),e(_e,HE),e(HE,cTe),e(cTe,q6r),e(HE,j6r),e(HE,iY),e(iY,D6r),e(HE,G6r),e(_e,O6r),e(_e,UE),e(UE,fTe),e(fTe,V6r),e(UE,X6r),e(UE,dY),e(dY,z6r),e(UE,Q6r),e(_e,W6r),e(_e,JE),e(JE,mTe),e(mTe,H6r),e(JE,U6r),e(JE,cY),e(cY,J6r),e(JE,Y6r),e(_e,K6r),e(_e,YE),e(YE,gTe),e(gTe,Z6r),e(YE,eLr),e(YE,fY),e(fY,oLr),e(YE,rLr),e(_e,tLr),e(_e,KE),e(KE,hTe),e(hTe,aLr),e(KE,nLr),e(KE,mY),e(mY,sLr),e(KE,lLr),e(_e,iLr),e(_e,ZE),e(ZE,pTe),e(pTe,dLr),e(ZE,cLr),e(ZE,gY),e(gY,fLr),e(ZE,mLr),e(_e,gLr),e(_e,e4),e(e4,_Te),e(_Te,hLr),e(e4,pLr),e(e4,hY),e(hY,_Lr),e(e4,uLr),e(_e,bLr),e(_e,o4),e(o4,uTe),e(uTe,vLr),e(o4,FLr),e(o4,pY),e(pY,TLr),e(o4,MLr),e(_e,ELr),e(_e,r4),e(r4,bTe),e(bTe,CLr),e(r4,wLr),e(r4,_Y),e(_Y,ALr),e(r4,LLr),e(_e,yLr),e(_e,t4),e(t4,vTe),e(vTe,xLr),e(t4,$Lr),e(t4,uY),e(uY,kLr),e(t4,SLr),e(_e,RLr),e(_e,a4),e(a4,FTe),e(FTe,PLr),e(a4,BLr),e(a4,bY),e(bY,ILr),e(a4,NLr),e(_e,qLr),e(_e,n4),e(n4,TTe),e(TTe,jLr),e(n4,DLr),e(n4,vY),e(vY,GLr),e(n4,OLr),e(_e,VLr),e(_e,s4),e(s4,MTe),e(MTe,XLr),e(s4,zLr),e(s4,FY),e(FY,QLr),e(s4,WLr),e(_e,HLr),e(_e,l4),e(l4,ETe),e(ETe,ULr),e(l4,JLr),e(l4,TY),e(TY,YLr),e(l4,KLr),e(_e,ZLr),e(_e,i4),e(i4,CTe),e(CTe,eyr),e(i4,oyr),e(i4,MY),e(MY,ryr),e(i4,tyr),e(_e,ayr),e(_e,d4),e(d4,wTe),e(wTe,nyr),e(d4,syr),e(d4,EY),e(EY,lyr),e(d4,iyr),e(_e,dyr),e(_e,c4),e(c4,ATe),e(ATe,cyr),e(c4,fyr),e(c4,CY),e(CY,myr),e(c4,gyr),e(Br,hyr),M(f4,Br,null),b(f,iVe,u),b(f,Cc,u),e(Cc,m4),e(m4,LTe),M(ox,LTe,null),e(Cc,pyr),e(Cc,yTe),e(yTe,_yr),b(f,dVe,u),b(f,ir,u),M(rx,ir,null),e(ir,uyr),e(ir,wc),e(wc,byr),e(wc,wY),e(wY,vyr),e(wc,Fyr),e(wc,AY),e(AY,Tyr),e(wc,Myr),e(ir,Eyr),e(ir,tx),e(tx,Cyr),e(tx,xTe),e(xTe,wyr),e(tx,Ayr),e(ir,Lyr),e(ir,qt),M(ax,qt,null),e(qt,yyr),e(qt,$Te),e($Te,xyr),e(qt,$yr),e(qt,Ac),e(Ac,kyr),e(Ac,kTe),e(kTe,Syr),e(Ac,Ryr),e(Ac,LY),e(LY,Pyr),e(Ac,Byr),e(qt,Iyr),M(g4,qt,null),e(ir,Nyr),e(ir,Ir),M(nx,Ir,null),e(Ir,qyr),e(Ir,STe),e(STe,jyr),e(Ir,Dyr),e(Ir,hn),e(hn,Gyr),e(hn,RTe),e(RTe,Oyr),e(hn,Vyr),e(hn,PTe),e(PTe,Xyr),e(hn,zyr),e(hn,BTe),e(BTe,Qyr),e(hn,Wyr),e(Ir,Hyr),e(Ir,sx),e(sx,h4),e(h4,ITe),e(ITe,Uyr),e(h4,Jyr),e(h4,yY),e(yY,Yyr),e(h4,Kyr),e(sx,Zyr),e(sx,p4),e(p4,NTe),e(NTe,e8r),e(p4,o8r),e(p4,xY),e(xY,r8r),e(p4,t8r),e(Ir,a8r),M(_4,Ir,null),b(f,cVe,u),b(f,Lc,u),e(Lc,u4),e(u4,qTe),M(lx,qTe,null),e(Lc,n8r),e(Lc,jTe),e(jTe,s8r),b(f,fVe,u),b(f,dr,u),M(ix,dr,null),e(dr,l8r),e(dr,yc),e(yc,i8r),e(yc,$Y),e($Y,d8r),e(yc,c8r),e(yc,kY),e(kY,f8r),e(yc,m8r),e(dr,g8r),e(dr,dx),e(dx,h8r),e(dx,DTe),e(DTe,p8r),e(dx,_8r),e(dr,u8r),e(dr,jt),M(cx,jt,null),e(jt,b8r),e(jt,GTe),e(GTe,v8r),e(jt,F8r),e(jt,xc),e(xc,T8r),e(xc,OTe),e(OTe,M8r),e(xc,E8r),e(xc,SY),e(SY,C8r),e(xc,w8r),e(jt,A8r),M(b4,jt,null),e(dr,L8r),e(dr,Nr),M(fx,Nr,null),e(Nr,y8r),e(Nr,VTe),e(VTe,x8r),e(Nr,$8r),e(Nr,pn),e(pn,k8r),e(pn,XTe),e(XTe,S8r),e(pn,R8r),e(pn,zTe),e(zTe,P8r),e(pn,B8r),e(pn,QTe),e(QTe,I8r),e(pn,N8r),e(Nr,q8r),e(Nr,WTe),e(WTe,v4),e(v4,HTe),e(HTe,j8r),e(v4,D8r),e(v4,RY),e(RY,G8r),e(v4,O8r),e(Nr,V8r),M(F4,Nr,null),b(f,mVe,u),b(f,$c,u),e($c,T4),e(T4,UTe),M(mx,UTe,null),e($c,X8r),e($c,JTe),e(JTe,z8r),b(f,gVe,u),b(f,cr,u),M(gx,cr,null),e(cr,Q8r),e(cr,kc),e(kc,W8r),e(kc,PY),e(PY,H8r),e(kc,U8r),e(kc,BY),e(BY,J8r),e(kc,Y8r),e(cr,K8r),e(cr,hx),e(hx,Z8r),e(hx,YTe),e(YTe,e9r),e(hx,o9r),e(cr,r9r),e(cr,Dt),M(px,Dt,null),e(Dt,t9r),e(Dt,KTe),e(KTe,a9r),e(Dt,n9r),e(Dt,Sc),e(Sc,s9r),e(Sc,ZTe),e(ZTe,l9r),e(Sc,i9r),e(Sc,IY),e(IY,d9r),e(Sc,c9r),e(Dt,f9r),M(M4,Dt,null),e(cr,m9r),e(cr,qr),M(_x,qr,null),e(qr,g9r),e(qr,eMe),e(eMe,h9r),e(qr,p9r),e(qr,_n),e(_n,_9r),e(_n,oMe),e(oMe,u9r),e(_n,b9r),e(_n,rMe),e(rMe,v9r),e(_n,F9r),e(_n,tMe),e(tMe,T9r),e(_n,M9r),e(qr,E9r),e(qr,de),e(de,E4),e(E4,aMe),e(aMe,C9r),e(E4,w9r),e(E4,NY),e(NY,A9r),e(E4,L9r),e(de,y9r),e(de,C4),e(C4,nMe),e(nMe,x9r),e(C4,$9r),e(C4,qY),e(qY,k9r),e(C4,S9r),e(de,R9r),e(de,w4),e(w4,sMe),e(sMe,P9r),e(w4,B9r),e(w4,jY),e(jY,I9r),e(w4,N9r),e(de,q9r),e(de,A4),e(A4,lMe),e(lMe,j9r),e(A4,D9r),e(A4,DY),e(DY,G9r),e(A4,O9r),e(de,V9r),e(de,L4),e(L4,iMe),e(iMe,X9r),e(L4,z9r),e(L4,GY),e(GY,Q9r),e(L4,W9r),e(de,H9r),e(de,y4),e(y4,dMe),e(dMe,U9r),e(y4,J9r),e(y4,OY),e(OY,Y9r),e(y4,K9r),e(de,Z9r),e(de,x4),e(x4,cMe),e(cMe,exr),e(x4,oxr),e(x4,VY),e(VY,rxr),e(x4,txr),e(de,axr),e(de,$4),e($4,fMe),e(fMe,nxr),e($4,sxr),e($4,XY),e(XY,lxr),e($4,ixr),e(de,dxr),e(de,k4),e(k4,mMe),e(mMe,cxr),e(k4,fxr),e(k4,zY),e(zY,mxr),e(k4,gxr),e(de,hxr),e(de,S4),e(S4,gMe),e(gMe,pxr),e(S4,_xr),e(S4,QY),e(QY,uxr),e(S4,bxr),e(de,vxr),e(de,R4),e(R4,hMe),e(hMe,Fxr),e(R4,Txr),e(R4,WY),e(WY,Mxr),e(R4,Exr),e(de,Cxr),e(de,P4),e(P4,pMe),e(pMe,wxr),e(P4,Axr),e(P4,HY),e(HY,Lxr),e(P4,yxr),e(de,xxr),e(de,B4),e(B4,_Me),e(_Me,$xr),e(B4,kxr),e(B4,UY),e(UY,Sxr),e(B4,Rxr),e(de,Pxr),e(de,I4),e(I4,uMe),e(uMe,Bxr),e(I4,Ixr),e(I4,JY),e(JY,Nxr),e(I4,qxr),e(de,jxr),e(de,N4),e(N4,bMe),e(bMe,Dxr),e(N4,Gxr),e(N4,YY),e(YY,Oxr),e(N4,Vxr),e(de,Xxr),e(de,q4),e(q4,vMe),e(vMe,zxr),e(q4,Qxr),e(q4,KY),e(KY,Wxr),e(q4,Hxr),e(de,Uxr),e(de,j4),e(j4,FMe),e(FMe,Jxr),e(j4,Yxr),e(j4,ZY),e(ZY,Kxr),e(j4,Zxr),e(de,e$r),e(de,D4),e(D4,TMe),e(TMe,o$r),e(D4,r$r),e(D4,eK),e(eK,t$r),e(D4,a$r),e(de,n$r),e(de,G4),e(G4,MMe),e(MMe,s$r),e(G4,l$r),e(G4,oK),e(oK,i$r),e(G4,d$r),e(de,c$r),e(de,O4),e(O4,EMe),e(EMe,f$r),e(O4,m$r),e(O4,rK),e(rK,g$r),e(O4,h$r),e(qr,p$r),M(V4,qr,null),b(f,hVe,u),b(f,Rc,u),e(Rc,X4),e(X4,CMe),M(ux,CMe,null),e(Rc,_$r),e(Rc,wMe),e(wMe,u$r),b(f,pVe,u),b(f,fr,u),M(bx,fr,null),e(fr,b$r),e(fr,Pc),e(Pc,v$r),e(Pc,tK),e(tK,F$r),e(Pc,T$r),e(Pc,aK),e(aK,M$r),e(Pc,E$r),e(fr,C$r),e(fr,vx),e(vx,w$r),e(vx,AMe),e(AMe,A$r),e(vx,L$r),e(fr,y$r),e(fr,Gt),M(Fx,Gt,null),e(Gt,x$r),e(Gt,LMe),e(LMe,$$r),e(Gt,k$r),e(Gt,Bc),e(Bc,S$r),e(Bc,yMe),e(yMe,R$r),e(Bc,P$r),e(Bc,nK),e(nK,B$r),e(Bc,I$r),e(Gt,N$r),M(z4,Gt,null),e(fr,q$r),e(fr,jr),M(Tx,jr,null),e(jr,j$r),e(jr,xMe),e(xMe,D$r),e(jr,G$r),e(jr,un),e(un,O$r),e(un,$Me),e($Me,V$r),e(un,X$r),e(un,kMe),e(kMe,z$r),e(un,Q$r),e(un,SMe),e(SMe,W$r),e(un,H$r),e(jr,U$r),e(jr,ce),e(ce,Q4),e(Q4,RMe),e(RMe,J$r),e(Q4,Y$r),e(Q4,sK),e(sK,K$r),e(Q4,Z$r),e(ce,ekr),e(ce,W4),e(W4,PMe),e(PMe,okr),e(W4,rkr),e(W4,lK),e(lK,tkr),e(W4,akr),e(ce,nkr),e(ce,H4),e(H4,BMe),e(BMe,skr),e(H4,lkr),e(H4,iK),e(iK,ikr),e(H4,dkr),e(ce,ckr),e(ce,U4),e(U4,IMe),e(IMe,fkr),e(U4,mkr),e(U4,dK),e(dK,gkr),e(U4,hkr),e(ce,pkr),e(ce,J4),e(J4,NMe),e(NMe,_kr),e(J4,ukr),e(J4,cK),e(cK,bkr),e(J4,vkr),e(ce,Fkr),e(ce,Y4),e(Y4,qMe),e(qMe,Tkr),e(Y4,Mkr),e(Y4,fK),e(fK,Ekr),e(Y4,Ckr),e(ce,wkr),e(ce,K4),e(K4,jMe),e(jMe,Akr),e(K4,Lkr),e(K4,mK),e(mK,ykr),e(K4,xkr),e(ce,$kr),e(ce,Z4),e(Z4,DMe),e(DMe,kkr),e(Z4,Skr),e(Z4,gK),e(gK,Rkr),e(Z4,Pkr),e(ce,Bkr),e(ce,eC),e(eC,GMe),e(GMe,Ikr),e(eC,Nkr),e(eC,hK),e(hK,qkr),e(eC,jkr),e(ce,Dkr),e(ce,oC),e(oC,OMe),e(OMe,Gkr),e(oC,Okr),e(oC,pK),e(pK,Vkr),e(oC,Xkr),e(ce,zkr),e(ce,rC),e(rC,VMe),e(VMe,Qkr),e(rC,Wkr),e(rC,_K),e(_K,Hkr),e(rC,Ukr),e(ce,Jkr),e(ce,tC),e(tC,XMe),e(XMe,Ykr),e(tC,Kkr),e(tC,uK),e(uK,Zkr),e(tC,eSr),e(ce,oSr),e(ce,aC),e(aC,zMe),e(zMe,rSr),e(aC,tSr),e(aC,bK),e(bK,aSr),e(aC,nSr),e(ce,sSr),e(ce,nC),e(nC,QMe),e(QMe,lSr),e(nC,iSr),e(nC,vK),e(vK,dSr),e(nC,cSr),e(ce,fSr),e(ce,sC),e(sC,WMe),e(WMe,mSr),e(sC,gSr),e(sC,FK),e(FK,hSr),e(sC,pSr),e(ce,_Sr),e(ce,lC),e(lC,HMe),e(HMe,uSr),e(lC,bSr),e(lC,TK),e(TK,vSr),e(lC,FSr),e(ce,TSr),e(ce,iC),e(iC,UMe),e(UMe,MSr),e(iC,ESr),e(iC,MK),e(MK,CSr),e(iC,wSr),e(ce,ASr),e(ce,dC),e(dC,JMe),e(JMe,LSr),e(dC,ySr),e(dC,EK),e(EK,xSr),e(dC,$Sr),e(ce,kSr),e(ce,cC),e(cC,YMe),e(YMe,SSr),e(cC,RSr),e(cC,CK),e(CK,PSr),e(cC,BSr),e(ce,ISr),e(ce,fC),e(fC,KMe),e(KMe,NSr),e(fC,qSr),e(fC,wK),e(wK,jSr),e(fC,DSr),e(jr,GSr),M(mC,jr,null),b(f,_Ve,u),b(f,Ic,u),e(Ic,gC),e(gC,ZMe),M(Mx,ZMe,null),e(Ic,OSr),e(Ic,eEe),e(eEe,VSr),b(f,uVe,u),b(f,mr,u),M(Ex,mr,null),e(mr,XSr),e(mr,Nc),e(Nc,zSr),e(Nc,AK),e(AK,QSr),e(Nc,WSr),e(Nc,LK),e(LK,HSr),e(Nc,USr),e(mr,JSr),e(mr,Cx),e(Cx,YSr),e(Cx,oEe),e(oEe,KSr),e(Cx,ZSr),e(mr,eRr),e(mr,Ot),M(wx,Ot,null),e(Ot,oRr),e(Ot,rEe),e(rEe,rRr),e(Ot,tRr),e(Ot,qc),e(qc,aRr),e(qc,tEe),e(tEe,nRr),e(qc,sRr),e(qc,yK),e(yK,lRr),e(qc,iRr),e(Ot,dRr),M(hC,Ot,null),e(mr,cRr),e(mr,Dr),M(Ax,Dr,null),e(Dr,fRr),e(Dr,aEe),e(aEe,mRr),e(Dr,gRr),e(Dr,bn),e(bn,hRr),e(bn,nEe),e(nEe,pRr),e(bn,_Rr),e(bn,sEe),e(sEe,uRr),e(bn,bRr),e(bn,lEe),e(lEe,vRr),e(bn,FRr),e(Dr,TRr),e(Dr,iEe),e(iEe,pC),e(pC,dEe),e(dEe,MRr),e(pC,ERr),e(pC,xK),e(xK,CRr),e(pC,wRr),e(Dr,ARr),M(_C,Dr,null),b(f,bVe,u),b(f,jc,u),e(jc,uC),e(uC,cEe),M(Lx,cEe,null),e(jc,LRr),e(jc,fEe),e(fEe,yRr),b(f,vVe,u),b(f,gr,u),M(yx,gr,null),e(gr,xRr),e(gr,Dc),e(Dc,$Rr),e(Dc,$K),e($K,kRr),e(Dc,SRr),e(Dc,kK),e(kK,RRr),e(Dc,PRr),e(gr,BRr),e(gr,xx),e(xx,IRr),e(xx,mEe),e(mEe,NRr),e(xx,qRr),e(gr,jRr),e(gr,Vt),M($x,Vt,null),e(Vt,DRr),e(Vt,gEe),e(gEe,GRr),e(Vt,ORr),e(Vt,Gc),e(Gc,VRr),e(Gc,hEe),e(hEe,XRr),e(Gc,zRr),e(Gc,SK),e(SK,QRr),e(Gc,WRr),e(Vt,HRr),M(bC,Vt,null),e(gr,URr),e(gr,Gr),M(kx,Gr,null),e(Gr,JRr),e(Gr,pEe),e(pEe,YRr),e(Gr,KRr),e(Gr,vn),e(vn,ZRr),e(vn,_Ee),e(_Ee,ePr),e(vn,oPr),e(vn,uEe),e(uEe,rPr),e(vn,tPr),e(vn,bEe),e(bEe,aPr),e(vn,nPr),e(Gr,sPr),e(Gr,vEe),e(vEe,vC),e(vC,FEe),e(FEe,lPr),e(vC,iPr),e(vC,RK),e(RK,dPr),e(vC,cPr),e(Gr,fPr),M(FC,Gr,null),b(f,FVe,u),b(f,Oc,u),e(Oc,TC),e(TC,TEe),M(Sx,TEe,null),e(Oc,mPr),e(Oc,MEe),e(MEe,gPr),b(f,TVe,u),b(f,hr,u),M(Rx,hr,null),e(hr,hPr),e(hr,Vc),e(Vc,pPr),e(Vc,PK),e(PK,_Pr),e(Vc,uPr),e(Vc,BK),e(BK,bPr),e(Vc,vPr),e(hr,FPr),e(hr,Px),e(Px,TPr),e(Px,EEe),e(EEe,MPr),e(Px,EPr),e(hr,CPr),e(hr,Xt),M(Bx,Xt,null),e(Xt,wPr),e(Xt,CEe),e(CEe,APr),e(Xt,LPr),e(Xt,Xc),e(Xc,yPr),e(Xc,wEe),e(wEe,xPr),e(Xc,$Pr),e(Xc,IK),e(IK,kPr),e(Xc,SPr),e(Xt,RPr),M(MC,Xt,null),e(hr,PPr),e(hr,Or),M(Ix,Or,null),e(Or,BPr),e(Or,AEe),e(AEe,IPr),e(Or,NPr),e(Or,Fn),e(Fn,qPr),e(Fn,LEe),e(LEe,jPr),e(Fn,DPr),e(Fn,yEe),e(yEe,GPr),e(Fn,OPr),e(Fn,xEe),e(xEe,VPr),e(Fn,XPr),e(Or,zPr),e(Or,oe),e(oe,EC),e(EC,$Ee),e($Ee,QPr),e(EC,WPr),e(EC,NK),e(NK,HPr),e(EC,UPr),e(oe,JPr),e(oe,CC),e(CC,kEe),e(kEe,YPr),e(CC,KPr),e(CC,qK),e(qK,ZPr),e(CC,eBr),e(oe,oBr),e(oe,wC),e(wC,SEe),e(SEe,rBr),e(wC,tBr),e(wC,jK),e(jK,aBr),e(wC,nBr),e(oe,sBr),e(oe,AC),e(AC,REe),e(REe,lBr),e(AC,iBr),e(AC,DK),e(DK,dBr),e(AC,cBr),e(oe,fBr),e(oe,LC),e(LC,PEe),e(PEe,mBr),e(LC,gBr),e(LC,GK),e(GK,hBr),e(LC,pBr),e(oe,_Br),e(oe,yC),e(yC,BEe),e(BEe,uBr),e(yC,bBr),e(yC,OK),e(OK,vBr),e(yC,FBr),e(oe,TBr),e(oe,xC),e(xC,IEe),e(IEe,MBr),e(xC,EBr),e(xC,VK),e(VK,CBr),e(xC,wBr),e(oe,ABr),e(oe,$C),e($C,NEe),e(NEe,LBr),e($C,yBr),e($C,XK),e(XK,xBr),e($C,$Br),e(oe,kBr),e(oe,kC),e(kC,qEe),e(qEe,SBr),e(kC,RBr),e(kC,zK),e(zK,PBr),e(kC,BBr),e(oe,IBr),e(oe,SC),e(SC,jEe),e(jEe,NBr),e(SC,qBr),e(SC,QK),e(QK,jBr),e(SC,DBr),e(oe,GBr),e(oe,RC),e(RC,DEe),e(DEe,OBr),e(RC,VBr),e(RC,WK),e(WK,XBr),e(RC,zBr),e(oe,QBr),e(oe,PC),e(PC,GEe),e(GEe,WBr),e(PC,HBr),e(PC,HK),e(HK,UBr),e(PC,JBr),e(oe,YBr),e(oe,BC),e(BC,OEe),e(OEe,KBr),e(BC,ZBr),e(BC,UK),e(UK,eIr),e(BC,oIr),e(oe,rIr),e(oe,IC),e(IC,VEe),e(VEe,tIr),e(IC,aIr),e(IC,JK),e(JK,nIr),e(IC,sIr),e(oe,lIr),e(oe,NC),e(NC,XEe),e(XEe,iIr),e(NC,dIr),e(NC,YK),e(YK,cIr),e(NC,fIr),e(oe,mIr),e(oe,qC),e(qC,zEe),e(zEe,gIr),e(qC,hIr),e(qC,KK),e(KK,pIr),e(qC,_Ir),e(oe,uIr),e(oe,jC),e(jC,QEe),e(QEe,bIr),e(jC,vIr),e(jC,ZK),e(ZK,FIr),e(jC,TIr),e(oe,MIr),e(oe,DC),e(DC,WEe),e(WEe,EIr),e(DC,CIr),e(DC,eZ),e(eZ,wIr),e(DC,AIr),e(oe,LIr),e(oe,GC),e(GC,HEe),e(HEe,yIr),e(GC,xIr),e(GC,oZ),e(oZ,$Ir),e(GC,kIr),e(oe,SIr),e(oe,OC),e(OC,UEe),e(UEe,RIr),e(OC,PIr),e(OC,rZ),e(rZ,BIr),e(OC,IIr),e(oe,NIr),e(oe,VC),e(VC,JEe),e(JEe,qIr),e(VC,jIr),e(VC,tZ),e(tZ,DIr),e(VC,GIr),e(oe,OIr),e(oe,XC),e(XC,YEe),e(YEe,VIr),e(XC,XIr),e(XC,aZ),e(aZ,zIr),e(XC,QIr),e(oe,WIr),e(oe,zC),e(zC,KEe),e(KEe,HIr),e(zC,UIr),e(zC,nZ),e(nZ,JIr),e(zC,YIr),e(oe,KIr),e(oe,QC),e(QC,ZEe),e(ZEe,ZIr),e(QC,eNr),e(QC,sZ),e(sZ,oNr),e(QC,rNr),e(oe,tNr),e(oe,WC),e(WC,e4e),e(e4e,aNr),e(WC,nNr),e(WC,lZ),e(lZ,sNr),e(WC,lNr),e(oe,iNr),e(oe,HC),e(HC,o4e),e(o4e,dNr),e(HC,cNr),e(HC,iZ),e(iZ,fNr),e(HC,mNr),e(oe,gNr),e(oe,UC),e(UC,r4e),e(r4e,hNr),e(UC,pNr),e(UC,dZ),e(dZ,_Nr),e(UC,uNr),e(Or,bNr),M(JC,Or,null),b(f,MVe,u),b(f,zc,u),e(zc,YC),e(YC,t4e),M(Nx,t4e,null),e(zc,vNr),e(zc,a4e),e(a4e,FNr),b(f,EVe,u),b(f,pr,u),M(qx,pr,null),e(pr,TNr),e(pr,Qc),e(Qc,MNr),e(Qc,cZ),e(cZ,ENr),e(Qc,CNr),e(Qc,fZ),e(fZ,wNr),e(Qc,ANr),e(pr,LNr),e(pr,jx),e(jx,yNr),e(jx,n4e),e(n4e,xNr),e(jx,$Nr),e(pr,kNr),e(pr,zt),M(Dx,zt,null),e(zt,SNr),e(zt,s4e),e(s4e,RNr),e(zt,PNr),e(zt,Wc),e(Wc,BNr),e(Wc,l4e),e(l4e,INr),e(Wc,NNr),e(Wc,mZ),e(mZ,qNr),e(Wc,jNr),e(zt,DNr),M(KC,zt,null),e(pr,GNr),e(pr,Vr),M(Gx,Vr,null),e(Vr,ONr),e(Vr,i4e),e(i4e,VNr),e(Vr,XNr),e(Vr,Tn),e(Tn,zNr),e(Tn,d4e),e(d4e,QNr),e(Tn,WNr),e(Tn,c4e),e(c4e,HNr),e(Tn,UNr),e(Tn,f4e),e(f4e,JNr),e(Tn,YNr),e(Vr,KNr),e(Vr,xe),e(xe,ZC),e(ZC,m4e),e(m4e,ZNr),e(ZC,eqr),e(ZC,gZ),e(gZ,oqr),e(ZC,rqr),e(xe,tqr),e(xe,e0),e(e0,g4e),e(g4e,aqr),e(e0,nqr),e(e0,hZ),e(hZ,sqr),e(e0,lqr),e(xe,iqr),e(xe,o0),e(o0,h4e),e(h4e,dqr),e(o0,cqr),e(o0,pZ),e(pZ,fqr),e(o0,mqr),e(xe,gqr),e(xe,r0),e(r0,p4e),e(p4e,hqr),e(r0,pqr),e(r0,_Z),e(_Z,_qr),e(r0,uqr),e(xe,bqr),e(xe,t0),e(t0,_4e),e(_4e,vqr),e(t0,Fqr),e(t0,uZ),e(uZ,Tqr),e(t0,Mqr),e(xe,Eqr),e(xe,a0),e(a0,u4e),e(u4e,Cqr),e(a0,wqr),e(a0,bZ),e(bZ,Aqr),e(a0,Lqr),e(xe,yqr),e(xe,n0),e(n0,b4e),e(b4e,xqr),e(n0,$qr),e(n0,vZ),e(vZ,kqr),e(n0,Sqr),e(xe,Rqr),e(xe,s0),e(s0,v4e),e(v4e,Pqr),e(s0,Bqr),e(s0,FZ),e(FZ,Iqr),e(s0,Nqr),e(xe,qqr),e(xe,l0),e(l0,F4e),e(F4e,jqr),e(l0,Dqr),e(l0,TZ),e(TZ,Gqr),e(l0,Oqr),e(xe,Vqr),e(xe,i0),e(i0,T4e),e(T4e,Xqr),e(i0,zqr),e(i0,MZ),e(MZ,Qqr),e(i0,Wqr),e(Vr,Hqr),M(d0,Vr,null),b(f,CVe,u),b(f,Hc,u),e(Hc,c0),e(c0,M4e),M(Ox,M4e,null),e(Hc,Uqr),e(Hc,E4e),e(E4e,Jqr),b(f,wVe,u),b(f,_r,u),M(Vx,_r,null),e(_r,Yqr),e(_r,Uc),e(Uc,Kqr),e(Uc,EZ),e(EZ,Zqr),e(Uc,ejr),e(Uc,CZ),e(CZ,ojr),e(Uc,rjr),e(_r,tjr),e(_r,Xx),e(Xx,ajr),e(Xx,C4e),e(C4e,njr),e(Xx,sjr),e(_r,ljr),e(_r,Qt),M(zx,Qt,null),e(Qt,ijr),e(Qt,w4e),e(w4e,djr),e(Qt,cjr),e(Qt,Jc),e(Jc,fjr),e(Jc,A4e),e(A4e,mjr),e(Jc,gjr),e(Jc,wZ),e(wZ,hjr),e(Jc,pjr),e(Qt,_jr),M(f0,Qt,null),e(_r,ujr),e(_r,Xr),M(Qx,Xr,null),e(Xr,bjr),e(Xr,L4e),e(L4e,vjr),e(Xr,Fjr),e(Xr,Mn),e(Mn,Tjr),e(Mn,y4e),e(y4e,Mjr),e(Mn,Ejr),e(Mn,x4e),e(x4e,Cjr),e(Mn,wjr),e(Mn,$4e),e($4e,Ajr),e(Mn,Ljr),e(Xr,yjr),e(Xr,Ee),e(Ee,m0),e(m0,k4e),e(k4e,xjr),e(m0,$jr),e(m0,AZ),e(AZ,kjr),e(m0,Sjr),e(Ee,Rjr),e(Ee,g0),e(g0,S4e),e(S4e,Pjr),e(g0,Bjr),e(g0,LZ),e(LZ,Ijr),e(g0,Njr),e(Ee,qjr),e(Ee,h0),e(h0,R4e),e(R4e,jjr),e(h0,Djr),e(h0,yZ),e(yZ,Gjr),e(h0,Ojr),e(Ee,Vjr),e(Ee,p0),e(p0,P4e),e(P4e,Xjr),e(p0,zjr),e(p0,xZ),e(xZ,Qjr),e(p0,Wjr),e(Ee,Hjr),e(Ee,_0),e(_0,B4e),e(B4e,Ujr),e(_0,Jjr),e(_0,$Z),e($Z,Yjr),e(_0,Kjr),e(Ee,Zjr),e(Ee,u0),e(u0,I4e),e(I4e,eDr),e(u0,oDr),e(u0,kZ),e(kZ,rDr),e(u0,tDr),e(Ee,aDr),e(Ee,b0),e(b0,N4e),e(N4e,nDr),e(b0,sDr),e(b0,SZ),e(SZ,lDr),e(b0,iDr),e(Ee,dDr),e(Ee,v0),e(v0,q4e),e(q4e,cDr),e(v0,fDr),e(v0,RZ),e(RZ,mDr),e(v0,gDr),e(Ee,hDr),e(Ee,F0),e(F0,j4e),e(j4e,pDr),e(F0,_Dr),e(F0,PZ),e(PZ,uDr),e(F0,bDr),e(Ee,vDr),e(Ee,T0),e(T0,D4e),e(D4e,FDr),e(T0,TDr),e(T0,BZ),e(BZ,MDr),e(T0,EDr),e(Ee,CDr),e(Ee,M0),e(M0,G4e),e(G4e,wDr),e(M0,ADr),e(M0,IZ),e(IZ,LDr),e(M0,yDr),e(Ee,xDr),e(Ee,E0),e(E0,O4e),e(O4e,$Dr),e(E0,kDr),e(E0,NZ),e(NZ,SDr),e(E0,RDr),e(Ee,PDr),e(Ee,C0),e(C0,V4e),e(V4e,BDr),e(C0,IDr),e(C0,qZ),e(qZ,NDr),e(C0,qDr),e(Xr,jDr),M(w0,Xr,null),b(f,AVe,u),b(f,Yc,u),e(Yc,A0),e(A0,X4e),M(Wx,X4e,null),e(Yc,DDr),e(Yc,z4e),e(z4e,GDr),b(f,LVe,u),b(f,ur,u),M(Hx,ur,null),e(ur,ODr),e(ur,Kc),e(Kc,VDr),e(Kc,jZ),e(jZ,XDr),e(Kc,zDr),e(Kc,DZ),e(DZ,QDr),e(Kc,WDr),e(ur,HDr),e(ur,Ux),e(Ux,UDr),e(Ux,Q4e),e(Q4e,JDr),e(Ux,YDr),e(ur,KDr),e(ur,Wt),M(Jx,Wt,null),e(Wt,ZDr),e(Wt,W4e),e(W4e,eGr),e(Wt,oGr),e(Wt,Zc),e(Zc,rGr),e(Zc,H4e),e(H4e,tGr),e(Zc,aGr),e(Zc,GZ),e(GZ,nGr),e(Zc,sGr),e(Wt,lGr),M(L0,Wt,null),e(ur,iGr),e(ur,zr),M(Yx,zr,null),e(zr,dGr),e(zr,U4e),e(U4e,cGr),e(zr,fGr),e(zr,En),e(En,mGr),e(En,J4e),e(J4e,gGr),e(En,hGr),e(En,Y4e),e(Y4e,pGr),e(En,_Gr),e(En,K4e),e(K4e,uGr),e(En,bGr),e(zr,vGr),e(zr,$e),e($e,y0),e(y0,Z4e),e(Z4e,FGr),e(y0,TGr),e(y0,OZ),e(OZ,MGr),e(y0,EGr),e($e,CGr),e($e,x0),e(x0,eCe),e(eCe,wGr),e(x0,AGr),e(x0,VZ),e(VZ,LGr),e(x0,yGr),e($e,xGr),e($e,$0),e($0,oCe),e(oCe,$Gr),e($0,kGr),e($0,XZ),e(XZ,SGr),e($0,RGr),e($e,PGr),e($e,k0),e(k0,rCe),e(rCe,BGr),e(k0,IGr),e(k0,zZ),e(zZ,NGr),e(k0,qGr),e($e,jGr),e($e,S0),e(S0,tCe),e(tCe,DGr),e(S0,GGr),e(S0,QZ),e(QZ,OGr),e(S0,VGr),e($e,XGr),e($e,R0),e(R0,aCe),e(aCe,zGr),e(R0,QGr),e(R0,WZ),e(WZ,WGr),e(R0,HGr),e($e,UGr),e($e,P0),e(P0,nCe),e(nCe,JGr),e(P0,YGr),e(P0,HZ),e(HZ,KGr),e(P0,ZGr),e($e,eOr),e($e,B0),e(B0,sCe),e(sCe,oOr),e(B0,rOr),e(B0,UZ),e(UZ,tOr),e(B0,aOr),e($e,nOr),e($e,I0),e(I0,lCe),e(lCe,sOr),e(I0,lOr),e(I0,JZ),e(JZ,iOr),e(I0,dOr),e($e,cOr),e($e,N0),e(N0,iCe),e(iCe,fOr),e(N0,mOr),e(N0,YZ),e(YZ,gOr),e(N0,hOr),e(zr,pOr),M(q0,zr,null),b(f,yVe,u),b(f,ef,u),e(ef,j0),e(j0,dCe),M(Kx,dCe,null),e(ef,_Or),e(ef,cCe),e(cCe,uOr),b(f,xVe,u),b(f,br,u),M(Zx,br,null),e(br,bOr),e(br,of),e(of,vOr),e(of,KZ),e(KZ,FOr),e(of,TOr),e(of,ZZ),e(ZZ,MOr),e(of,EOr),e(br,COr),e(br,e$),e(e$,wOr),e(e$,fCe),e(fCe,AOr),e(e$,LOr),e(br,yOr),e(br,Ht),M(o$,Ht,null),e(Ht,xOr),e(Ht,mCe),e(mCe,$Or),e(Ht,kOr),e(Ht,rf),e(rf,SOr),e(rf,gCe),e(gCe,ROr),e(rf,POr),e(rf,eee),e(eee,BOr),e(rf,IOr),e(Ht,NOr),M(D0,Ht,null),e(br,qOr),e(br,Qr),M(r$,Qr,null),e(Qr,jOr),e(Qr,hCe),e(hCe,DOr),e(Qr,GOr),e(Qr,Cn),e(Cn,OOr),e(Cn,pCe),e(pCe,VOr),e(Cn,XOr),e(Cn,_Ce),e(_Ce,zOr),e(Cn,QOr),e(Cn,uCe),e(uCe,WOr),e(Cn,HOr),e(Qr,UOr),e(Qr,ke),e(ke,G0),e(G0,bCe),e(bCe,JOr),e(G0,YOr),e(G0,oee),e(oee,KOr),e(G0,ZOr),e(ke,eVr),e(ke,O0),e(O0,vCe),e(vCe,oVr),e(O0,rVr),e(O0,ree),e(ree,tVr),e(O0,aVr),e(ke,nVr),e(ke,V0),e(V0,FCe),e(FCe,sVr),e(V0,lVr),e(V0,tee),e(tee,iVr),e(V0,dVr),e(ke,cVr),e(ke,X0),e(X0,TCe),e(TCe,fVr),e(X0,mVr),e(X0,aee),e(aee,gVr),e(X0,hVr),e(ke,pVr),e(ke,z0),e(z0,MCe),e(MCe,_Vr),e(z0,uVr),e(z0,nee),e(nee,bVr),e(z0,vVr),e(ke,FVr),e(ke,Q0),e(Q0,ECe),e(ECe,TVr),e(Q0,MVr),e(Q0,see),e(see,EVr),e(Q0,CVr),e(ke,wVr),e(ke,W0),e(W0,CCe),e(CCe,AVr),e(W0,LVr),e(W0,lee),e(lee,yVr),e(W0,xVr),e(ke,$Vr),e(ke,H0),e(H0,wCe),e(wCe,kVr),e(H0,SVr),e(H0,iee),e(iee,RVr),e(H0,PVr),e(ke,BVr),e(ke,U0),e(U0,ACe),e(ACe,IVr),e(U0,NVr),e(U0,dee),e(dee,qVr),e(U0,jVr),e(ke,DVr),e(ke,J0),e(J0,LCe),e(LCe,GVr),e(J0,OVr),e(J0,cee),e(cee,VVr),e(J0,XVr),e(Qr,zVr),M(Y0,Qr,null),b(f,$Ve,u),b(f,tf,u),e(tf,K0),e(K0,yCe),M(t$,yCe,null),e(tf,QVr),e(tf,xCe),e(xCe,WVr),b(f,kVe,u),b(f,vr,u),M(a$,vr,null),e(vr,HVr),e(vr,af),e(af,UVr),e(af,fee),e(fee,JVr),e(af,YVr),e(af,mee),e(mee,KVr),e(af,ZVr),e(vr,eXr),e(vr,n$),e(n$,oXr),e(n$,$Ce),e($Ce,rXr),e(n$,tXr),e(vr,aXr),e(vr,Ut),M(s$,Ut,null),e(Ut,nXr),e(Ut,kCe),e(kCe,sXr),e(Ut,lXr),e(Ut,nf),e(nf,iXr),e(nf,SCe),e(SCe,dXr),e(nf,cXr),e(nf,gee),e(gee,fXr),e(nf,mXr),e(Ut,gXr),M(Z0,Ut,null),e(vr,hXr),e(vr,Wr),M(l$,Wr,null),e(Wr,pXr),e(Wr,RCe),e(RCe,_Xr),e(Wr,uXr),e(Wr,wn),e(wn,bXr),e(wn,PCe),e(PCe,vXr),e(wn,FXr),e(wn,BCe),e(BCe,TXr),e(wn,MXr),e(wn,ICe),e(ICe,EXr),e(wn,CXr),e(Wr,wXr),e(Wr,Se),e(Se,ew),e(ew,NCe),e(NCe,AXr),e(ew,LXr),e(ew,hee),e(hee,yXr),e(ew,xXr),e(Se,$Xr),e(Se,ow),e(ow,qCe),e(qCe,kXr),e(ow,SXr),e(ow,pee),e(pee,RXr),e(ow,PXr),e(Se,BXr),e(Se,rw),e(rw,jCe),e(jCe,IXr),e(rw,NXr),e(rw,_ee),e(_ee,qXr),e(rw,jXr),e(Se,DXr),e(Se,tw),e(tw,DCe),e(DCe,GXr),e(tw,OXr),e(tw,uee),e(uee,VXr),e(tw,XXr),e(Se,zXr),e(Se,aw),e(aw,GCe),e(GCe,QXr),e(aw,WXr),e(aw,bee),e(bee,HXr),e(aw,UXr),e(Se,JXr),e(Se,nw),e(nw,OCe),e(OCe,YXr),e(nw,KXr),e(nw,vee),e(vee,ZXr),e(nw,ezr),e(Se,ozr),e(Se,sw),e(sw,VCe),e(VCe,rzr),e(sw,tzr),e(sw,Fee),e(Fee,azr),e(sw,nzr),e(Se,szr),e(Se,lw),e(lw,XCe),e(XCe,lzr),e(lw,izr),e(lw,Tee),e(Tee,dzr),e(lw,czr),e(Se,fzr),e(Se,iw),e(iw,zCe),e(zCe,mzr),e(iw,gzr),e(iw,Mee),e(Mee,hzr),e(iw,pzr),e(Se,_zr),e(Se,dw),e(dw,QCe),e(QCe,uzr),e(dw,bzr),e(dw,Eee),e(Eee,vzr),e(dw,Fzr),e(Wr,Tzr),M(cw,Wr,null),b(f,SVe,u),b(f,sf,u),e(sf,fw),e(fw,WCe),M(i$,WCe,null),e(sf,Mzr),e(sf,HCe),e(HCe,Ezr),b(f,RVe,u),b(f,Fr,u),M(d$,Fr,null),e(Fr,Czr),e(Fr,lf),e(lf,wzr),e(lf,Cee),e(Cee,Azr),e(lf,Lzr),e(lf,wee),e(wee,yzr),e(lf,xzr),e(Fr,$zr),e(Fr,c$),e(c$,kzr),e(c$,UCe),e(UCe,Szr),e(c$,Rzr),e(Fr,Pzr),e(Fr,Jt),M(f$,Jt,null),e(Jt,Bzr),e(Jt,JCe),e(JCe,Izr),e(Jt,Nzr),e(Jt,df),e(df,qzr),e(df,YCe),e(YCe,jzr),e(df,Dzr),e(df,Aee),e(Aee,Gzr),e(df,Ozr),e(Jt,Vzr),M(mw,Jt,null),e(Fr,Xzr),e(Fr,Hr),M(m$,Hr,null),e(Hr,zzr),e(Hr,KCe),e(KCe,Qzr),e(Hr,Wzr),e(Hr,An),e(An,Hzr),e(An,ZCe),e(ZCe,Uzr),e(An,Jzr),e(An,e0e),e(e0e,Yzr),e(An,Kzr),e(An,o0e),e(o0e,Zzr),e(An,eQr),e(Hr,oQr),e(Hr,Re),e(Re,gw),e(gw,r0e),e(r0e,rQr),e(gw,tQr),e(gw,Lee),e(Lee,aQr),e(gw,nQr),e(Re,sQr),e(Re,hw),e(hw,t0e),e(t0e,lQr),e(hw,iQr),e(hw,yee),e(yee,dQr),e(hw,cQr),e(Re,fQr),e(Re,pw),e(pw,a0e),e(a0e,mQr),e(pw,gQr),e(pw,xee),e(xee,hQr),e(pw,pQr),e(Re,_Qr),e(Re,_w),e(_w,n0e),e(n0e,uQr),e(_w,bQr),e(_w,$ee),e($ee,vQr),e(_w,FQr),e(Re,TQr),e(Re,uw),e(uw,s0e),e(s0e,MQr),e(uw,EQr),e(uw,kee),e(kee,CQr),e(uw,wQr),e(Re,AQr),e(Re,bw),e(bw,l0e),e(l0e,LQr),e(bw,yQr),e(bw,See),e(See,xQr),e(bw,$Qr),e(Re,kQr),e(Re,vw),e(vw,i0e),e(i0e,SQr),e(vw,RQr),e(vw,Ree),e(Ree,PQr),e(vw,BQr),e(Re,IQr),e(Re,Fw),e(Fw,d0e),e(d0e,NQr),e(Fw,qQr),e(Fw,Pee),e(Pee,jQr),e(Fw,DQr),e(Re,GQr),e(Re,Tw),e(Tw,c0e),e(c0e,OQr),e(Tw,VQr),e(Tw,Bee),e(Bee,XQr),e(Tw,zQr),e(Re,QQr),e(Re,Mw),e(Mw,f0e),e(f0e,WQr),e(Mw,HQr),e(Mw,Iee),e(Iee,UQr),e(Mw,JQr),e(Hr,YQr),M(Ew,Hr,null),b(f,PVe,u),b(f,cf,u),e(cf,Cw),e(Cw,m0e),M(g$,m0e,null),e(cf,KQr),e(cf,g0e),e(g0e,ZQr),b(f,BVe,u),b(f,Tr,u),M(h$,Tr,null),e(Tr,eWr),e(Tr,ff),e(ff,oWr),e(ff,Nee),e(Nee,rWr),e(ff,tWr),e(ff,qee),e(qee,aWr),e(ff,nWr),e(Tr,sWr),e(Tr,p$),e(p$,lWr),e(p$,h0e),e(h0e,iWr),e(p$,dWr),e(Tr,cWr),e(Tr,Yt),M(_$,Yt,null),e(Yt,fWr),e(Yt,p0e),e(p0e,mWr),e(Yt,gWr),e(Yt,mf),e(mf,hWr),e(mf,_0e),e(_0e,pWr),e(mf,_Wr),e(mf,jee),e(jee,uWr),e(mf,bWr),e(Yt,vWr),M(ww,Yt,null),e(Tr,FWr),e(Tr,Ur),M(u$,Ur,null),e(Ur,TWr),e(Ur,u0e),e(u0e,MWr),e(Ur,EWr),e(Ur,Ln),e(Ln,CWr),e(Ln,b0e),e(b0e,wWr),e(Ln,AWr),e(Ln,v0e),e(v0e,LWr),e(Ln,yWr),e(Ln,F0e),e(F0e,xWr),e(Ln,$Wr),e(Ur,kWr),e(Ur,Ve),e(Ve,Aw),e(Aw,T0e),e(T0e,SWr),e(Aw,RWr),e(Aw,Dee),e(Dee,PWr),e(Aw,BWr),e(Ve,IWr),e(Ve,Lw),e(Lw,M0e),e(M0e,NWr),e(Lw,qWr),e(Lw,Gee),e(Gee,jWr),e(Lw,DWr),e(Ve,GWr),e(Ve,yw),e(yw,E0e),e(E0e,OWr),e(yw,VWr),e(yw,Oee),e(Oee,XWr),e(yw,zWr),e(Ve,QWr),e(Ve,xw),e(xw,C0e),e(C0e,WWr),e(xw,HWr),e(xw,Vee),e(Vee,UWr),e(xw,JWr),e(Ve,YWr),e(Ve,$w),e($w,w0e),e(w0e,KWr),e($w,ZWr),e($w,Xee),e(Xee,eHr),e($w,oHr),e(Ve,rHr),e(Ve,kw),e(kw,A0e),e(A0e,tHr),e(kw,aHr),e(kw,zee),e(zee,nHr),e(kw,sHr),e(Ve,lHr),e(Ve,Sw),e(Sw,L0e),e(L0e,iHr),e(Sw,dHr),e(Sw,Qee),e(Qee,cHr),e(Sw,fHr),e(Ve,mHr),e(Ve,Rw),e(Rw,y0e),e(y0e,gHr),e(Rw,hHr),e(Rw,Wee),e(Wee,pHr),e(Rw,_Hr),e(Ur,uHr),M(Pw,Ur,null),b(f,IVe,u),b(f,gf,u),e(gf,Bw),e(Bw,x0e),M(b$,x0e,null),e(gf,bHr),e(gf,$0e),e($0e,vHr),b(f,NVe,u),b(f,Mr,u),M(v$,Mr,null),e(Mr,FHr),e(Mr,hf),e(hf,THr),e(hf,Hee),e(Hee,MHr),e(hf,EHr),e(hf,Uee),e(Uee,CHr),e(hf,wHr),e(Mr,AHr),e(Mr,F$),e(F$,LHr),e(F$,k0e),e(k0e,yHr),e(F$,xHr),e(Mr,$Hr),e(Mr,Kt),M(T$,Kt,null),e(Kt,kHr),e(Kt,S0e),e(S0e,SHr),e(Kt,RHr),e(Kt,pf),e(pf,PHr),e(pf,R0e),e(R0e,BHr),e(pf,IHr),e(pf,Jee),e(Jee,NHr),e(pf,qHr),e(Kt,jHr),M(Iw,Kt,null),e(Mr,DHr),e(Mr,Jr),M(M$,Jr,null),e(Jr,GHr),e(Jr,P0e),e(P0e,OHr),e(Jr,VHr),e(Jr,yn),e(yn,XHr),e(yn,B0e),e(B0e,zHr),e(yn,QHr),e(yn,I0e),e(I0e,WHr),e(yn,HHr),e(yn,N0e),e(N0e,UHr),e(yn,JHr),e(Jr,YHr),e(Jr,Xe),e(Xe,Nw),e(Nw,q0e),e(q0e,KHr),e(Nw,ZHr),e(Nw,Yee),e(Yee,eUr),e(Nw,oUr),e(Xe,rUr),e(Xe,qw),e(qw,j0e),e(j0e,tUr),e(qw,aUr),e(qw,Kee),e(Kee,nUr),e(qw,sUr),e(Xe,lUr),e(Xe,jw),e(jw,D0e),e(D0e,iUr),e(jw,dUr),e(jw,Zee),e(Zee,cUr),e(jw,fUr),e(Xe,mUr),e(Xe,Dw),e(Dw,G0e),e(G0e,gUr),e(Dw,hUr),e(Dw,eoe),e(eoe,pUr),e(Dw,_Ur),e(Xe,uUr),e(Xe,Gw),e(Gw,O0e),e(O0e,bUr),e(Gw,vUr),e(Gw,ooe),e(ooe,FUr),e(Gw,TUr),e(Xe,MUr),e(Xe,Ow),e(Ow,V0e),e(V0e,EUr),e(Ow,CUr),e(Ow,roe),e(roe,wUr),e(Ow,AUr),e(Xe,LUr),e(Xe,Vw),e(Vw,X0e),e(X0e,yUr),e(Vw,xUr),e(Vw,toe),e(toe,$Ur),e(Vw,kUr),e(Xe,SUr),e(Xe,Xw),e(Xw,z0e),e(z0e,RUr),e(Xw,PUr),e(Xw,aoe),e(aoe,BUr),e(Xw,IUr),e(Jr,NUr),M(zw,Jr,null),b(f,qVe,u),b(f,_f,u),e(_f,Qw),e(Qw,Q0e),M(E$,Q0e,null),e(_f,qUr),e(_f,W0e),e(W0e,jUr),b(f,jVe,u),b(f,Er,u),M(C$,Er,null),e(Er,DUr),e(Er,uf),e(uf,GUr),e(uf,noe),e(noe,OUr),e(uf,VUr),e(uf,soe),e(soe,XUr),e(uf,zUr),e(Er,QUr),e(Er,w$),e(w$,WUr),e(w$,H0e),e(H0e,HUr),e(w$,UUr),e(Er,JUr),e(Er,Zt),M(A$,Zt,null),e(Zt,YUr),e(Zt,U0e),e(U0e,KUr),e(Zt,ZUr),e(Zt,bf),e(bf,eJr),e(bf,J0e),e(J0e,oJr),e(bf,rJr),e(bf,loe),e(loe,tJr),e(bf,aJr),e(Zt,nJr),M(Ww,Zt,null),e(Er,sJr),e(Er,Yr),M(L$,Yr,null),e(Yr,lJr),e(Yr,Y0e),e(Y0e,iJr),e(Yr,dJr),e(Yr,xn),e(xn,cJr),e(xn,K0e),e(K0e,fJr),e(xn,mJr),e(xn,Z0e),e(Z0e,gJr),e(xn,hJr),e(xn,ewe),e(ewe,pJr),e(xn,_Jr),e(Yr,uJr),e(Yr,owe),e(owe,Hw),e(Hw,rwe),e(rwe,bJr),e(Hw,vJr),e(Hw,ioe),e(ioe,FJr),e(Hw,TJr),e(Yr,MJr),M(Uw,Yr,null),b(f,DVe,u),b(f,vf,u),e(vf,Jw),e(Jw,twe),M(y$,twe,null),e(vf,EJr),e(vf,awe),e(awe,CJr),b(f,GVe,u),b(f,Cr,u),M(x$,Cr,null),e(Cr,wJr),e(Cr,Ff),e(Ff,AJr),e(Ff,doe),e(doe,LJr),e(Ff,yJr),e(Ff,coe),e(coe,xJr),e(Ff,$Jr),e(Cr,kJr),e(Cr,$$),e($$,SJr),e($$,nwe),e(nwe,RJr),e($$,PJr),e(Cr,BJr),e(Cr,ea),M(k$,ea,null),e(ea,IJr),e(ea,swe),e(swe,NJr),e(ea,qJr),e(ea,Tf),e(Tf,jJr),e(Tf,lwe),e(lwe,DJr),e(Tf,GJr),e(Tf,foe),e(foe,OJr),e(Tf,VJr),e(ea,XJr),M(Yw,ea,null),e(Cr,zJr),e(Cr,Kr),M(S$,Kr,null),e(Kr,QJr),e(Kr,iwe),e(iwe,WJr),e(Kr,HJr),e(Kr,$n),e($n,UJr),e($n,dwe),e(dwe,JJr),e($n,YJr),e($n,cwe),e(cwe,KJr),e($n,ZJr),e($n,fwe),e(fwe,eYr),e($n,oYr),e(Kr,rYr),e(Kr,R$),e(R$,Kw),e(Kw,mwe),e(mwe,tYr),e(Kw,aYr),e(Kw,moe),e(moe,nYr),e(Kw,sYr),e(R$,lYr),e(R$,Zw),e(Zw,gwe),e(gwe,iYr),e(Zw,dYr),e(Zw,goe),e(goe,cYr),e(Zw,fYr),e(Kr,mYr),M(eA,Kr,null),b(f,OVe,u),b(f,Mf,u),e(Mf,oA),e(oA,hwe),M(P$,hwe,null),e(Mf,gYr),e(Mf,pwe),e(pwe,hYr),b(f,VVe,u),b(f,wr,u),M(B$,wr,null),e(wr,pYr),e(wr,Ef),e(Ef,_Yr),e(Ef,hoe),e(hoe,uYr),e(Ef,bYr),e(Ef,poe),e(poe,vYr),e(Ef,FYr),e(wr,TYr),e(wr,I$),e(I$,MYr),e(I$,_we),e(_we,EYr),e(I$,CYr),e(wr,wYr),e(wr,oa),M(N$,oa,null),e(oa,AYr),e(oa,uwe),e(uwe,LYr),e(oa,yYr),e(oa,Cf),e(Cf,xYr),e(Cf,bwe),e(bwe,$Yr),e(Cf,kYr),e(Cf,_oe),e(_oe,SYr),e(Cf,RYr),e(oa,PYr),M(rA,oa,null),e(wr,BYr),e(wr,Zr),M(q$,Zr,null),e(Zr,IYr),e(Zr,vwe),e(vwe,NYr),e(Zr,qYr),e(Zr,kn),e(kn,jYr),e(kn,Fwe),e(Fwe,DYr),e(kn,GYr),e(kn,Twe),e(Twe,OYr),e(kn,VYr),e(kn,Mwe),e(Mwe,XYr),e(kn,zYr),e(Zr,QYr),e(Zr,Ewe),e(Ewe,tA),e(tA,Cwe),e(Cwe,WYr),e(tA,HYr),e(tA,uoe),e(uoe,UYr),e(tA,JYr),e(Zr,YYr),M(aA,Zr,null),XVe=!0},p(f,[u]){const j$={};u&2&&(j$.$$scope={dirty:u,ctx:f}),Rf.$set(j$);const wwe={};u&2&&(wwe.$$scope={dirty:u,ctx:f}),Gg.$set(wwe);const Awe={};u&2&&(Awe.$$scope={dirty:u,ctx:f}),Eh.$set(Awe);const Lwe={};u&2&&(Lwe.$$scope={dirty:u,ctx:f}),ap.$set(Lwe);const D$={};u&2&&(D$.$$scope={dirty:u,ctx:f}),np.$set(D$);const ywe={};u&2&&(ywe.$$scope={dirty:u,ctx:f}),wp.$set(ywe);const Sn={};u&2&&(Sn.$$scope={dirty:u,ctx:f}),Ap.$set(Sn);const xwe={};u&2&&(xwe.$$scope={dirty:u,ctx:f}),xp.$set(xwe);const $we={};u&2&&($we.$$scope={dirty:u,ctx:f}),xu.$set($we);const kwe={};u&2&&(kwe.$$scope={dirty:u,ctx:f}),ku.$set(kwe);const G$={};u&2&&(G$.$$scope={dirty:u,ctx:f}),E1.$set(G$);const Swe={};u&2&&(Swe.$$scope={dirty:u,ctx:f}),w1.$set(Swe);const O$={};u&2&&(O$.$$scope={dirty:u,ctx:f}),f7.$set(O$);const Rwe={};u&2&&(Rwe.$$scope={dirty:u,ctx:f}),g7.$set(Rwe);const V$={};u&2&&(V$.$$scope={dirty:u,ctx:f}),K7.$set(V$);const Pwe={};u&2&&(Pwe.$$scope={dirty:u,ctx:f}),e2.$set(Pwe);const Bwe={};u&2&&(Bwe.$$scope={dirty:u,ctx:f}),v2.$set(Bwe);const Iwe={};u&2&&(Iwe.$$scope={dirty:u,ctx:f}),T2.$set(Iwe);const wf={};u&2&&(wf.$$scope={dirty:u,ctx:f}),bb.$set(wf);const Nwe={};u&2&&(Nwe.$$scope={dirty:u,ctx:f}),Fb.$set(Nwe);const qwe={};u&2&&(qwe.$$scope={dirty:u,ctx:f}),Kb.$set(qwe);const jwe={};u&2&&(jwe.$$scope={dirty:u,ctx:f}),e5.$set(jwe);const X$={};u&2&&(X$.$$scope={dirty:u,ctx:f}),i5.$set(X$);const Dwe={};u&2&&(Dwe.$$scope={dirty:u,ctx:f}),c5.$set(Dwe);const Gwe={};u&2&&(Gwe.$$scope={dirty:u,ctx:f}),H5.$set(Gwe);const Owe={};u&2&&(Owe.$$scope={dirty:u,ctx:f}),J5.$set(Owe);const rt={};u&2&&(rt.$$scope={dirty:u,ctx:f}),jv.$set(rt);const z$={};u&2&&(z$.$$scope={dirty:u,ctx:f}),Gv.$set(z$);const Vwe={};u&2&&(Vwe.$$scope={dirty:u,ctx:f}),Xv.$set(Vwe);const Q$={};u&2&&(Q$.$$scope={dirty:u,ctx:f}),Qv.$set(Q$);const Xwe={};u&2&&(Xwe.$$scope={dirty:u,ctx:f}),s3.$set(Xwe);const tt={};u&2&&(tt.$$scope={dirty:u,ctx:f}),i3.$set(tt);const zwe={};u&2&&(zwe.$$scope={dirty:u,ctx:f}),f3.$set(zwe);const Af={};u&2&&(Af.$$scope={dirty:u,ctx:f}),g3.$set(Af);const Qwe={};u&2&&(Qwe.$$scope={dirty:u,ctx:f}),_3.$set(Qwe);const Wwe={};u&2&&(Wwe.$$scope={dirty:u,ctx:f}),b3.$set(Wwe);const L={};u&2&&(L.$$scope={dirty:u,ctx:f}),x3.$set(L);const nA={};u&2&&(nA.$$scope={dirty:u,ctx:f}),k3.$set(nA);const Hwe={};u&2&&(Hwe.$$scope={dirty:u,ctx:f}),q3.$set(Hwe);const Uwe={};u&2&&(Uwe.$$scope={dirty:u,ctx:f}),D3.$set(Uwe);const sA={};u&2&&(sA.$$scope={dirty:u,ctx:f}),K3.$set(sA);const Jwe={};u&2&&(Jwe.$$scope={dirty:u,ctx:f}),eF.$set(Jwe);const Ywe={};u&2&&(Ywe.$$scope={dirty:u,ctx:f}),aF.$set(Ywe);const lA={};u&2&&(lA.$$scope={dirty:u,ctx:f}),sF.$set(lA);const Kwe={};u&2&&(Kwe.$$scope={dirty:u,ctx:f}),gF.$set(Kwe);const Zwe={};u&2&&(Zwe.$$scope={dirty:u,ctx:f}),pF.$set(Zwe);const iA={};u&2&&(iA.$$scope={dirty:u,ctx:f}),FF.$set(iA);const eAe={};u&2&&(eAe.$$scope={dirty:u,ctx:f}),MF.$set(eAe);const oAe={};u&2&&(oAe.$$scope={dirty:u,ctx:f}),AF.$set(oAe);const dA={};u&2&&(dA.$$scope={dirty:u,ctx:f}),yF.$set(dA);const rAe={};u&2&&(rAe.$$scope={dirty:u,ctx:f}),kF.$set(rAe);const tAe={};u&2&&(tAe.$$scope={dirty:u,ctx:f}),RF.$set(tAe);const cA={};u&2&&(cA.$$scope={dirty:u,ctx:f}),jF.$set(cA);const aAe={};u&2&&(aAe.$$scope={dirty:u,ctx:f}),GF.$set(aAe);const nAe={};u&2&&(nAe.$$scope={dirty:u,ctx:f}),XF.$set(nAe);const fA={};u&2&&(fA.$$scope={dirty:u,ctx:f}),QF.$set(fA);const sAe={};u&2&&(sAe.$$scope={dirty:u,ctx:f}),jT.$set(sAe);const lAe={};u&2&&(lAe.$$scope={dirty:u,ctx:f}),GT.$set(lAe);const mA={};u&2&&(mA.$$scope={dirty:u,ctx:f}),fM.$set(mA);const iAe={};u&2&&(iAe.$$scope={dirty:u,ctx:f}),gM.$set(iAe);const dAe={};u&2&&(dAe.$$scope={dirty:u,ctx:f}),LM.$set(dAe);const gA={};u&2&&(gA.$$scope={dirty:u,ctx:f}),xM.$set(gA);const cAe={};u&2&&(cAe.$$scope={dirty:u,ctx:f}),PM.$set(cAe);const fAe={};u&2&&(fAe.$$scope={dirty:u,ctx:f}),IM.$set(fAe);const hA={};u&2&&(hA.$$scope={dirty:u,ctx:f}),tE.$set(hA);const mAe={};u&2&&(mAe.$$scope={dirty:u,ctx:f}),nE.$set(mAe);const gAe={};u&2&&(gAe.$$scope={dirty:u,ctx:f}),_E.$set(gAe);const pA={};u&2&&(pA.$$scope={dirty:u,ctx:f}),bE.$set(pA);const hAe={};u&2&&(hAe.$$scope={dirty:u,ctx:f}),zE.$set(hAe);const pAe={};u&2&&(pAe.$$scope={dirty:u,ctx:f}),WE.$set(pAe);const _A={};u&2&&(_A.$$scope={dirty:u,ctx:f}),f4.$set(_A);const _Ae={};u&2&&(_Ae.$$scope={dirty:u,ctx:f}),g4.$set(_Ae);const uAe={};u&2&&(uAe.$$scope={dirty:u,ctx:f}),_4.$set(uAe);const uA={};u&2&&(uA.$$scope={dirty:u,ctx:f}),b4.$set(uA);const bAe={};u&2&&(bAe.$$scope={dirty:u,ctx:f}),F4.$set(bAe);const vAe={};u&2&&(vAe.$$scope={dirty:u,ctx:f}),M4.$set(vAe);const bA={};u&2&&(bA.$$scope={dirty:u,ctx:f}),V4.$set(bA);const FAe={};u&2&&(FAe.$$scope={dirty:u,ctx:f}),z4.$set(FAe);const TAe={};u&2&&(TAe.$$scope={dirty:u,ctx:f}),mC.$set(TAe);const vA={};u&2&&(vA.$$scope={dirty:u,ctx:f}),hC.$set(vA);const MAe={};u&2&&(MAe.$$scope={dirty:u,ctx:f}),_C.$set(MAe);const EAe={};u&2&&(EAe.$$scope={dirty:u,ctx:f}),bC.$set(EAe);const FA={};u&2&&(FA.$$scope={dirty:u,ctx:f}),FC.$set(FA);const CAe={};u&2&&(CAe.$$scope={dirty:u,ctx:f}),MC.$set(CAe);const wAe={};u&2&&(wAe.$$scope={dirty:u,ctx:f}),JC.$set(wAe);const TA={};u&2&&(TA.$$scope={dirty:u,ctx:f}),KC.$set(TA);const AAe={};u&2&&(AAe.$$scope={dirty:u,ctx:f}),d0.$set(AAe);const LAe={};u&2&&(LAe.$$scope={dirty:u,ctx:f}),f0.$set(LAe);const MA={};u&2&&(MA.$$scope={dirty:u,ctx:f}),w0.$set(MA);const yAe={};u&2&&(yAe.$$scope={dirty:u,ctx:f}),L0.$set(yAe);const xAe={};u&2&&(xAe.$$scope={dirty:u,ctx:f}),q0.$set(xAe);const EA={};u&2&&(EA.$$scope={dirty:u,ctx:f}),D0.$set(EA);const $Ae={};u&2&&($Ae.$$scope={dirty:u,ctx:f}),Y0.$set($Ae);const kAe={};u&2&&(kAe.$$scope={dirty:u,ctx:f}),Z0.$set(kAe);const CA={};u&2&&(CA.$$scope={dirty:u,ctx:f}),cw.$set(CA);const SAe={};u&2&&(SAe.$$scope={dirty:u,ctx:f}),mw.$set(SAe);const RAe={};u&2&&(RAe.$$scope={dirty:u,ctx:f}),Ew.$set(RAe);const wA={};u&2&&(wA.$$scope={dirty:u,ctx:f}),ww.$set(wA);const PAe={};u&2&&(PAe.$$scope={dirty:u,ctx:f}),Pw.$set(PAe);const BAe={};u&2&&(BAe.$$scope={dirty:u,ctx:f}),Iw.$set(BAe);const AA={};u&2&&(AA.$$scope={dirty:u,ctx:f}),zw.$set(AA);const IAe={};u&2&&(IAe.$$scope={dirty:u,ctx:f}),Ww.$set(IAe);const NAe={};u&2&&(NAe.$$scope={dirty:u,ctx:f}),Uw.$set(NAe);const LA={};u&2&&(LA.$$scope={dirty:u,ctx:f}),Yw.$set(LA);const qAe={};u&2&&(qAe.$$scope={dirty:u,ctx:f}),eA.$set(qAe);const jAe={};u&2&&(jAe.$$scope={dirty:u,ctx:f}),rA.$set(jAe);const yA={};u&2&&(yA.$$scope={dirty:u,ctx:f}),aA.$set(yA)},i(f){XVe||(E(d.$$.fragment,f),E(xa.$$.fragment,f),E(xL.$$.fragment,f),E($L.$$.fragment,f),E(Rf.$$.fragment,f),E(kL.$$.fragment,f),E(SL.$$.fragment,f),E(BL.$$.fragment,f),E(Gg.$$.fragment,f),E(IL.$$.fragment,f),E(NL.$$.fragment,f),E(qL.$$.fragment,f),E(GL.$$.fragment,f),E(Eh.$$.fragment,f),E(OL.$$.fragment,f),E(VL.$$.fragment,f),E(XL.$$.fragment,f),E(WL.$$.fragment,f),E(ap.$$.fragment,f),E(np.$$.fragment,f),E(HL.$$.fragment,f),E(UL.$$.fragment,f),E(JL.$$.fragment,f),E(ZL.$$.fragment,f),E(wp.$$.fragment,f),E(Ap.$$.fragment,f),E(ey.$$.fragment,f),E(oy.$$.fragment,f),E(ry.$$.fragment,f),E(ay.$$.fragment,f),E(xp.$$.fragment,f),E(ny.$$.fragment,f),E(xu.$$.fragment,f),E(sy.$$.fragment,f),E(ly.$$.fragment,f),E(dy.$$.fragment,f),E(ku.$$.fragment,f),E(cy.$$.fragment,f),E(E1.$$.fragment,f),E(fy.$$.fragment,f),E(my.$$.fragment,f),E(hy.$$.fragment,f),E(w1.$$.fragment,f),E(py.$$.fragment,f),E(f7.$$.fragment,f),E(_y.$$.fragment,f),E(uy.$$.fragment,f),E(vy.$$.fragment,f),E(g7.$$.fragment,f),E(Fy.$$.fragment,f),E(K7.$$.fragment,f),E(Ty.$$.fragment,f),E(My.$$.fragment,f),E(Cy.$$.fragment,f),E(e2.$$.fragment,f),E(wy.$$.fragment,f),E(v2.$$.fragment,f),E(Ay.$$.fragment,f),E(Ly.$$.fragment,f),E(xy.$$.fragment,f),E(T2.$$.fragment,f),E($y.$$.fragment,f),E(bb.$$.fragment,f),E(ky.$$.fragment,f),E(Sy.$$.fragment,f),E(Py.$$.fragment,f),E(Fb.$$.fragment,f),E(By.$$.fragment,f),E(Kb.$$.fragment,f),E(Iy.$$.fragment,f),E(Ny.$$.fragment,f),E(jy.$$.fragment,f),E(e5.$$.fragment,f),E(Dy.$$.fragment,f),E(i5.$$.fragment,f),E(Gy.$$.fragment,f),E(Oy.$$.fragment,f),E(Xy.$$.fragment,f),E(c5.$$.fragment,f),E(zy.$$.fragment,f),E(H5.$$.fragment,f),E(Qy.$$.fragment,f),E(Wy.$$.fragment,f),E(Uy.$$.fragment,f),E(J5.$$.fragment,f),E(Jy.$$.fragment,f),E(jv.$$.fragment,f),E(Yy.$$.fragment,f),E(Ky.$$.fragment,f),E(e8.$$.fragment,f),E(Gv.$$.fragment,f),E(o8.$$.fragment,f),E(Xv.$$.fragment,f),E(r8.$$.fragment,f),E(t8.$$.fragment,f),E(n8.$$.fragment,f),E(Qv.$$.fragment,f),E(s8.$$.fragment,f),E(s3.$$.fragment,f),E(l8.$$.fragment,f),E(i8.$$.fragment,f),E(c8.$$.fragment,f),E(i3.$$.fragment,f),E(f8.$$.fragment,f),E(f3.$$.fragment,f),E(m8.$$.fragment,f),E(g8.$$.fragment,f),E(p8.$$.fragment,f),E(g3.$$.fragment,f),E(_8.$$.fragment,f),E(_3.$$.fragment,f),E(u8.$$.fragment,f),E(b8.$$.fragment,f),E(F8.$$.fragment,f),E(b3.$$.fragment,f),E(T8.$$.fragment,f),E(x3.$$.fragment,f),E(M8.$$.fragment,f),E(E8.$$.fragment,f),E(w8.$$.fragment,f),E(k3.$$.fragment,f),E(A8.$$.fragment,f),E(q3.$$.fragment,f),E(L8.$$.fragment,f),E(y8.$$.fragment,f),E($8.$$.fragment,f),E(D3.$$.fragment,f),E(k8.$$.fragment,f),E(K3.$$.fragment,f),E(S8.$$.fragment,f),E(R8.$$.fragment,f),E(B8.$$.fragment,f),E(eF.$$.fragment,f),E(I8.$$.fragment,f),E(aF.$$.fragment,f),E(q8.$$.fragment,f),E(j8.$$.fragment,f),E(G8.$$.fragment,f),E(sF.$$.fragment,f),E(O8.$$.fragment,f),E(gF.$$.fragment,f),E(V8.$$.fragment,f),E(X8.$$.fragment,f),E(Q8.$$.fragment,f),E(pF.$$.fragment,f),E(W8.$$.fragment,f),E(FF.$$.fragment,f),E(H8.$$.fragment,f),E(U8.$$.fragment,f),E(Y8.$$.fragment,f),E(MF.$$.fragment,f),E(K8.$$.fragment,f),E(AF.$$.fragment,f),E(e9.$$.fragment,f),E(o9.$$.fragment,f),E(t9.$$.fragment,f),E(yF.$$.fragment,f),E(a9.$$.fragment,f),E(kF.$$.fragment,f),E(n9.$$.fragment,f),E(s9.$$.fragment,f),E(i9.$$.fragment,f),E(RF.$$.fragment,f),E(d9.$$.fragment,f),E(jF.$$.fragment,f),E(c9.$$.fragment,f),E(f9.$$.fragment,f),E(g9.$$.fragment,f),E(GF.$$.fragment,f),E(h9.$$.fragment,f),E(XF.$$.fragment,f),E(p9.$$.fragment,f),E(_9.$$.fragment,f),E(b9.$$.fragment,f),E(QF.$$.fragment,f),E(v9.$$.fragment,f),E(jT.$$.fragment,f),E(F9.$$.fragment,f),E(T9.$$.fragment,f),E(E9.$$.fragment,f),E(GT.$$.fragment,f),E(C9.$$.fragment,f),E(fM.$$.fragment,f),E(w9.$$.fragment,f),E(A9.$$.fragment,f),E(y9.$$.fragment,f),E(gM.$$.fragment,f),E(x9.$$.fragment,f),E(LM.$$.fragment,f),E($9.$$.fragment,f),E(k9.$$.fragment,f),E(R9.$$.fragment,f),E(xM.$$.fragment,f),E(P9.$$.fragment,f),E(PM.$$.fragment,f),E(B9.$$.fragment,f),E(I9.$$.fragment,f),E(q9.$$.fragment,f),E(IM.$$.fragment,f),E(j9.$$.fragment,f),E(tE.$$.fragment,f),E(D9.$$.fragment,f),E(G9.$$.fragment,f),E(V9.$$.fragment,f),E(nE.$$.fragment,f),E(X9.$$.fragment,f),E(_E.$$.fragment,f),E(z9.$$.fragment,f),E(Q9.$$.fragment,f),E(H9.$$.fragment,f),E(bE.$$.fragment,f),E(U9.$$.fragment,f),E(zE.$$.fragment,f),E(J9.$$.fragment,f),E(Y9.$$.fragment,f),E(Z9.$$.fragment,f),E(WE.$$.fragment,f),E(ex.$$.fragment,f),E(f4.$$.fragment,f),E(ox.$$.fragment,f),E(rx.$$.fragment,f),E(ax.$$.fragment,f),E(g4.$$.fragment,f),E(nx.$$.fragment,f),E(_4.$$.fragment,f),E(lx.$$.fragment,f),E(ix.$$.fragment,f),E(cx.$$.fragment,f),E(b4.$$.fragment,f),E(fx.$$.fragment,f),E(F4.$$.fragment,f),E(mx.$$.fragment,f),E(gx.$$.fragment,f),E(px.$$.fragment,f),E(M4.$$.fragment,f),E(_x.$$.fragment,f),E(V4.$$.fragment,f),E(ux.$$.fragment,f),E(bx.$$.fragment,f),E(Fx.$$.fragment,f),E(z4.$$.fragment,f),E(Tx.$$.fragment,f),E(mC.$$.fragment,f),E(Mx.$$.fragment,f),E(Ex.$$.fragment,f),E(wx.$$.fragment,f),E(hC.$$.fragment,f),E(Ax.$$.fragment,f),E(_C.$$.fragment,f),E(Lx.$$.fragment,f),E(yx.$$.fragment,f),E($x.$$.fragment,f),E(bC.$$.fragment,f),E(kx.$$.fragment,f),E(FC.$$.fragment,f),E(Sx.$$.fragment,f),E(Rx.$$.fragment,f),E(Bx.$$.fragment,f),E(MC.$$.fragment,f),E(Ix.$$.fragment,f),E(JC.$$.fragment,f),E(Nx.$$.fragment,f),E(qx.$$.fragment,f),E(Dx.$$.fragment,f),E(KC.$$.fragment,f),E(Gx.$$.fragment,f),E(d0.$$.fragment,f),E(Ox.$$.fragment,f),E(Vx.$$.fragment,f),E(zx.$$.fragment,f),E(f0.$$.fragment,f),E(Qx.$$.fragment,f),E(w0.$$.fragment,f),E(Wx.$$.fragment,f),E(Hx.$$.fragment,f),E(Jx.$$.fragment,f),E(L0.$$.fragment,f),E(Yx.$$.fragment,f),E(q0.$$.fragment,f),E(Kx.$$.fragment,f),E(Zx.$$.fragment,f),E(o$.$$.fragment,f),E(D0.$$.fragment,f),E(r$.$$.fragment,f),E(Y0.$$.fragment,f),E(t$.$$.fragment,f),E(a$.$$.fragment,f),E(s$.$$.fragment,f),E(Z0.$$.fragment,f),E(l$.$$.fragment,f),E(cw.$$.fragment,f),E(i$.$$.fragment,f),E(d$.$$.fragment,f),E(f$.$$.fragment,f),E(mw.$$.fragment,f),E(m$.$$.fragment,f),E(Ew.$$.fragment,f),E(g$.$$.fragment,f),E(h$.$$.fragment,f),E(_$.$$.fragment,f),E(ww.$$.fragment,f),E(u$.$$.fragment,f),E(Pw.$$.fragment,f),E(b$.$$.fragment,f),E(v$.$$.fragment,f),E(T$.$$.fragment,f),E(Iw.$$.fragment,f),E(M$.$$.fragment,f),E(zw.$$.fragment,f),E(E$.$$.fragment,f),E(C$.$$.fragment,f),E(A$.$$.fragment,f),E(Ww.$$.fragment,f),E(L$.$$.fragment,f),E(Uw.$$.fragment,f),E(y$.$$.fragment,f),E(x$.$$.fragment,f),E(k$.$$.fragment,f),E(Yw.$$.fragment,f),E(S$.$$.fragment,f),E(eA.$$.fragment,f),E(P$.$$.fragment,f),E(B$.$$.fragment,f),E(N$.$$.fragment,f),E(rA.$$.fragment,f),E(q$.$$.fragment,f),E(aA.$$.fragment,f),XVe=!0)},o(f){C(d.$$.fragment,f),C(xa.$$.fragment,f),C(xL.$$.fragment,f),C($L.$$.fragment,f),C(Rf.$$.fragment,f),C(kL.$$.fragment,f),C(SL.$$.fragment,f),C(BL.$$.fragment,f),C(Gg.$$.fragment,f),C(IL.$$.fragment,f),C(NL.$$.fragment,f),C(qL.$$.fragment,f),C(GL.$$.fragment,f),C(Eh.$$.fragment,f),C(OL.$$.fragment,f),C(VL.$$.fragment,f),C(XL.$$.fragment,f),C(WL.$$.fragment,f),C(ap.$$.fragment,f),C(np.$$.fragment,f),C(HL.$$.fragment,f),C(UL.$$.fragment,f),C(JL.$$.fragment,f),C(ZL.$$.fragment,f),C(wp.$$.fragment,f),C(Ap.$$.fragment,f),C(ey.$$.fragment,f),C(oy.$$.fragment,f),C(ry.$$.fragment,f),C(ay.$$.fragment,f),C(xp.$$.fragment,f),C(ny.$$.fragment,f),C(xu.$$.fragment,f),C(sy.$$.fragment,f),C(ly.$$.fragment,f),C(dy.$$.fragment,f),C(ku.$$.fragment,f),C(cy.$$.fragment,f),C(E1.$$.fragment,f),C(fy.$$.fragment,f),C(my.$$.fragment,f),C(hy.$$.fragment,f),C(w1.$$.fragment,f),C(py.$$.fragment,f),C(f7.$$.fragment,f),C(_y.$$.fragment,f),C(uy.$$.fragment,f),C(vy.$$.fragment,f),C(g7.$$.fragment,f),C(Fy.$$.fragment,f),C(K7.$$.fragment,f),C(Ty.$$.fragment,f),C(My.$$.fragment,f),C(Cy.$$.fragment,f),C(e2.$$.fragment,f),C(wy.$$.fragment,f),C(v2.$$.fragment,f),C(Ay.$$.fragment,f),C(Ly.$$.fragment,f),C(xy.$$.fragment,f),C(T2.$$.fragment,f),C($y.$$.fragment,f),C(bb.$$.fragment,f),C(ky.$$.fragment,f),C(Sy.$$.fragment,f),C(Py.$$.fragment,f),C(Fb.$$.fragment,f),C(By.$$.fragment,f),C(Kb.$$.fragment,f),C(Iy.$$.fragment,f),C(Ny.$$.fragment,f),C(jy.$$.fragment,f),C(e5.$$.fragment,f),C(Dy.$$.fragment,f),C(i5.$$.fragment,f),C(Gy.$$.fragment,f),C(Oy.$$.fragment,f),C(Xy.$$.fragment,f),C(c5.$$.fragment,f),C(zy.$$.fragment,f),C(H5.$$.fragment,f),C(Qy.$$.fragment,f),C(Wy.$$.fragment,f),C(Uy.$$.fragment,f),C(J5.$$.fragment,f),C(Jy.$$.fragment,f),C(jv.$$.fragment,f),C(Yy.$$.fragment,f),C(Ky.$$.fragment,f),C(e8.$$.fragment,f),C(Gv.$$.fragment,f),C(o8.$$.fragment,f),C(Xv.$$.fragment,f),C(r8.$$.fragment,f),C(t8.$$.fragment,f),C(n8.$$.fragment,f),C(Qv.$$.fragment,f),C(s8.$$.fragment,f),C(s3.$$.fragment,f),C(l8.$$.fragment,f),C(i8.$$.fragment,f),C(c8.$$.fragment,f),C(i3.$$.fragment,f),C(f8.$$.fragment,f),C(f3.$$.fragment,f),C(m8.$$.fragment,f),C(g8.$$.fragment,f),C(p8.$$.fragment,f),C(g3.$$.fragment,f),C(_8.$$.fragment,f),C(_3.$$.fragment,f),C(u8.$$.fragment,f),C(b8.$$.fragment,f),C(F8.$$.fragment,f),C(b3.$$.fragment,f),C(T8.$$.fragment,f),C(x3.$$.fragment,f),C(M8.$$.fragment,f),C(E8.$$.fragment,f),C(w8.$$.fragment,f),C(k3.$$.fragment,f),C(A8.$$.fragment,f),C(q3.$$.fragment,f),C(L8.$$.fragment,f),C(y8.$$.fragment,f),C($8.$$.fragment,f),C(D3.$$.fragment,f),C(k8.$$.fragment,f),C(K3.$$.fragment,f),C(S8.$$.fragment,f),C(R8.$$.fragment,f),C(B8.$$.fragment,f),C(eF.$$.fragment,f),C(I8.$$.fragment,f),C(aF.$$.fragment,f),C(q8.$$.fragment,f),C(j8.$$.fragment,f),C(G8.$$.fragment,f),C(sF.$$.fragment,f),C(O8.$$.fragment,f),C(gF.$$.fragment,f),C(V8.$$.fragment,f),C(X8.$$.fragment,f),C(Q8.$$.fragment,f),C(pF.$$.fragment,f),C(W8.$$.fragment,f),C(FF.$$.fragment,f),C(H8.$$.fragment,f),C(U8.$$.fragment,f),C(Y8.$$.fragment,f),C(MF.$$.fragment,f),C(K8.$$.fragment,f),C(AF.$$.fragment,f),C(e9.$$.fragment,f),C(o9.$$.fragment,f),C(t9.$$.fragment,f),C(yF.$$.fragment,f),C(a9.$$.fragment,f),C(kF.$$.fragment,f),C(n9.$$.fragment,f),C(s9.$$.fragment,f),C(i9.$$.fragment,f),C(RF.$$.fragment,f),C(d9.$$.fragment,f),C(jF.$$.fragment,f),C(c9.$$.fragment,f),C(f9.$$.fragment,f),C(g9.$$.fragment,f),C(GF.$$.fragment,f),C(h9.$$.fragment,f),C(XF.$$.fragment,f),C(p9.$$.fragment,f),C(_9.$$.fragment,f),C(b9.$$.fragment,f),C(QF.$$.fragment,f),C(v9.$$.fragment,f),C(jT.$$.fragment,f),C(F9.$$.fragment,f),C(T9.$$.fragment,f),C(E9.$$.fragment,f),C(GT.$$.fragment,f),C(C9.$$.fragment,f),C(fM.$$.fragment,f),C(w9.$$.fragment,f),C(A9.$$.fragment,f),C(y9.$$.fragment,f),C(gM.$$.fragment,f),C(x9.$$.fragment,f),C(LM.$$.fragment,f),C($9.$$.fragment,f),C(k9.$$.fragment,f),C(R9.$$.fragment,f),C(xM.$$.fragment,f),C(P9.$$.fragment,f),C(PM.$$.fragment,f),C(B9.$$.fragment,f),C(I9.$$.fragment,f),C(q9.$$.fragment,f),C(IM.$$.fragment,f),C(j9.$$.fragment,f),C(tE.$$.fragment,f),C(D9.$$.fragment,f),C(G9.$$.fragment,f),C(V9.$$.fragment,f),C(nE.$$.fragment,f),C(X9.$$.fragment,f),C(_E.$$.fragment,f),C(z9.$$.fragment,f),C(Q9.$$.fragment,f),C(H9.$$.fragment,f),C(bE.$$.fragment,f),C(U9.$$.fragment,f),C(zE.$$.fragment,f),C(J9.$$.fragment,f),C(Y9.$$.fragment,f),C(Z9.$$.fragment,f),C(WE.$$.fragment,f),C(ex.$$.fragment,f),C(f4.$$.fragment,f),C(ox.$$.fragment,f),C(rx.$$.fragment,f),C(ax.$$.fragment,f),C(g4.$$.fragment,f),C(nx.$$.fragment,f),C(_4.$$.fragment,f),C(lx.$$.fragment,f),C(ix.$$.fragment,f),C(cx.$$.fragment,f),C(b4.$$.fragment,f),C(fx.$$.fragment,f),C(F4.$$.fragment,f),C(mx.$$.fragment,f),C(gx.$$.fragment,f),C(px.$$.fragment,f),C(M4.$$.fragment,f),C(_x.$$.fragment,f),C(V4.$$.fragment,f),C(ux.$$.fragment,f),C(bx.$$.fragment,f),C(Fx.$$.fragment,f),C(z4.$$.fragment,f),C(Tx.$$.fragment,f),C(mC.$$.fragment,f),C(Mx.$$.fragment,f),C(Ex.$$.fragment,f),C(wx.$$.fragment,f),C(hC.$$.fragment,f),C(Ax.$$.fragment,f),C(_C.$$.fragment,f),C(Lx.$$.fragment,f),C(yx.$$.fragment,f),C($x.$$.fragment,f),C(bC.$$.fragment,f),C(kx.$$.fragment,f),C(FC.$$.fragment,f),C(Sx.$$.fragment,f),C(Rx.$$.fragment,f),C(Bx.$$.fragment,f),C(MC.$$.fragment,f),C(Ix.$$.fragment,f),C(JC.$$.fragment,f),C(Nx.$$.fragment,f),C(qx.$$.fragment,f),C(Dx.$$.fragment,f),C(KC.$$.fragment,f),C(Gx.$$.fragment,f),C(d0.$$.fragment,f),C(Ox.$$.fragment,f),C(Vx.$$.fragment,f),C(zx.$$.fragment,f),C(f0.$$.fragment,f),C(Qx.$$.fragment,f),C(w0.$$.fragment,f),C(Wx.$$.fragment,f),C(Hx.$$.fragment,f),C(Jx.$$.fragment,f),C(L0.$$.fragment,f),C(Yx.$$.fragment,f),C(q0.$$.fragment,f),C(Kx.$$.fragment,f),C(Zx.$$.fragment,f),C(o$.$$.fragment,f),C(D0.$$.fragment,f),C(r$.$$.fragment,f),C(Y0.$$.fragment,f),C(t$.$$.fragment,f),C(a$.$$.fragment,f),C(s$.$$.fragment,f),C(Z0.$$.fragment,f),C(l$.$$.fragment,f),C(cw.$$.fragment,f),C(i$.$$.fragment,f),C(d$.$$.fragment,f),C(f$.$$.fragment,f),C(mw.$$.fragment,f),C(m$.$$.fragment,f),C(Ew.$$.fragment,f),C(g$.$$.fragment,f),C(h$.$$.fragment,f),C(_$.$$.fragment,f),C(ww.$$.fragment,f),C(u$.$$.fragment,f),C(Pw.$$.fragment,f),C(b$.$$.fragment,f),C(v$.$$.fragment,f),C(T$.$$.fragment,f),C(Iw.$$.fragment,f),C(M$.$$.fragment,f),C(zw.$$.fragment,f),C(E$.$$.fragment,f),C(C$.$$.fragment,f),C(A$.$$.fragment,f),C(Ww.$$.fragment,f),C(L$.$$.fragment,f),C(Uw.$$.fragment,f),C(y$.$$.fragment,f),C(x$.$$.fragment,f),C(k$.$$.fragment,f),C(Yw.$$.fragment,f),C(S$.$$.fragment,f),C(eA.$$.fragment,f),C(P$.$$.fragment,f),C(B$.$$.fragment,f),C(N$.$$.fragment,f),C(rA.$$.fragment,f),C(q$.$$.fragment,f),C(aA.$$.fragment,f),XVe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(yf),f&&t(at),f&&t(Oe),f&&t(Qe),f&&t($f),w(xa,f),f&&t(We),f&&t(Ae),f&&t(Co),f&&t($a),f&&t(jGe),f&&t(yi),w(xL),f&&t(DGe),f&&t(Nn),f&&t(GGe),w($L,f),f&&t(OGe),f&&t(lS),f&&t(VGe),w(Rf,f),f&&t(XGe),f&&t(xi),w(kL),f&&t(zGe),f&&t(wo),w(SL),w(BL),w(Gg),w(IL),f&&t(QGe),f&&t(ki),w(NL),f&&t(WGe),f&&t(Ao),w(qL),w(GL),w(Eh),w(OL),f&&t(HGe),f&&t(Si),w(VL),f&&t(UGe),f&&t(Lo),w(XL),w(WL),w(ap),w(np),w(HL),f&&t(JGe),f&&t(Ri),w(UL),f&&t(YGe),f&&t(yo),w(JL),w(ZL),w(wp),w(Ap),w(ey),f&&t(KGe),f&&t(Bi),w(oy),f&&t(ZGe),f&&t(xo),w(ry),w(ay),w(xp),w(ny),w(xu),f&&t(eOe),f&&t(qi),w(sy),f&&t(oOe),f&&t($o),w(ly),w(dy),w(ku),w(cy),w(E1),f&&t(rOe),f&&t(Gi),w(fy),f&&t(tOe),f&&t(ko),w(my),w(hy),w(w1),w(py),w(f7),f&&t(aOe),f&&t(Xi),w(_y),f&&t(nOe),f&&t(So),w(uy),w(vy),w(g7),w(Fy),w(K7),f&&t(sOe),f&&t(Wi),w(Ty),f&&t(lOe),f&&t(Ro),w(My),w(Cy),w(e2),w(wy),w(v2),f&&t(iOe),f&&t(Ji),w(Ay),f&&t(dOe),f&&t(Po),w(Ly),w(xy),w(T2),w($y),w(bb),f&&t(cOe),f&&t(Zi),w(ky),f&&t(fOe),f&&t(Bo),w(Sy),w(Py),w(Fb),w(By),w(Kb),f&&t(mOe),f&&t(rd),w(Iy),f&&t(gOe),f&&t(Io),w(Ny),w(jy),w(e5),w(Dy),w(i5),f&&t(hOe),f&&t(nd),w(Gy),f&&t(pOe),f&&t(qo),w(Oy),w(Xy),w(c5),w(zy),w(H5),f&&t(_Oe),f&&t(id),w(Qy),f&&t(uOe),f&&t(jo),w(Wy),w(Uy),w(J5),w(Jy),w(jv),f&&t(bOe),f&&t(fd),w(Yy),f&&t(vOe),f&&t(Do),w(Ky),w(e8),w(Gv),w(o8),w(Xv),f&&t(FOe),f&&t(hd),w(r8),f&&t(TOe),f&&t(Go),w(t8),w(n8),w(Qv),w(s8),w(s3),f&&t(MOe),f&&t(ud),w(l8),f&&t(EOe),f&&t(Oo),w(i8),w(c8),w(i3),w(f8),w(f3),f&&t(COe),f&&t(Fd),w(m8),f&&t(wOe),f&&t(Vo),w(g8),w(p8),w(g3),w(_8),w(_3),f&&t(AOe),f&&t(Ed),w(u8),f&&t(LOe),f&&t(Xo),w(b8),w(F8),w(b3),w(T8),w(x3),f&&t(yOe),f&&t(Ad),w(M8),f&&t(xOe),f&&t(zo),w(E8),w(w8),w(k3),w(A8),w(q3),f&&t($Oe),f&&t(xd),w(L8),f&&t(kOe),f&&t(Qo),w(y8),w($8),w(D3),w(k8),w(K3),f&&t(SOe),f&&t(Sd),w(S8),f&&t(ROe),f&&t(Wo),w(R8),w(B8),w(eF),w(I8),w(aF),f&&t(POe),f&&t(Bd),w(q8),f&&t(BOe),f&&t(Ho),w(j8),w(G8),w(sF),w(O8),w(gF),f&&t(IOe),f&&t(qd),w(V8),f&&t(NOe),f&&t(Uo),w(X8),w(Q8),w(pF),w(W8),w(FF),f&&t(qOe),f&&t(Od),w(H8),f&&t(jOe),f&&t(Jo),w(U8),w(Y8),w(MF),w(K8),w(AF),f&&t(DOe),f&&t(zd),w(e9),f&&t(GOe),f&&t(Yo),w(o9),w(t9),w(yF),w(a9),w(kF),f&&t(OOe),f&&t(Hd),w(n9),f&&t(VOe),f&&t(Ko),w(s9),w(i9),w(RF),w(d9),w(jF),f&&t(XOe),f&&t(Yd),w(c9),f&&t(zOe),f&&t(Zo),w(f9),w(g9),w(GF),w(h9),w(XF),f&&t(QOe),f&&t(ec),w(p9),f&&t(WOe),f&&t(er),w(_9),w(b9),w(QF),w(v9),w(jT),f&&t(HOe),f&&t(tc),w(F9),f&&t(UOe),f&&t(or),w(T9),w(E9),w(GT),w(C9),w(fM),f&&t(JOe),f&&t(sc),w(w9),f&&t(YOe),f&&t(rr),w(A9),w(y9),w(gM),w(x9),w(LM),f&&t(KOe),f&&t(dc),w($9),f&&t(ZOe),f&&t(tr),w(k9),w(R9),w(xM),w(P9),w(PM),f&&t(eVe),f&&t(mc),w(B9),f&&t(oVe),f&&t(ar),w(I9),w(q9),w(IM),w(j9),w(tE),f&&t(rVe),f&&t(pc),w(D9),f&&t(tVe),f&&t(nr),w(G9),w(V9),w(nE),w(X9),w(_E),f&&t(aVe),f&&t(bc),w(z9),f&&t(nVe),f&&t(sr),w(Q9),w(H9),w(bE),w(U9),w(zE),f&&t(sVe),f&&t(Tc),w(J9),f&&t(lVe),f&&t(lr),w(Y9),w(Z9),w(WE),w(ex),w(f4),f&&t(iVe),f&&t(Cc),w(ox),f&&t(dVe),f&&t(ir),w(rx),w(ax),w(g4),w(nx),w(_4),f&&t(cVe),f&&t(Lc),w(lx),f&&t(fVe),f&&t(dr),w(ix),w(cx),w(b4),w(fx),w(F4),f&&t(mVe),f&&t($c),w(mx),f&&t(gVe),f&&t(cr),w(gx),w(px),w(M4),w(_x),w(V4),f&&t(hVe),f&&t(Rc),w(ux),f&&t(pVe),f&&t(fr),w(bx),w(Fx),w(z4),w(Tx),w(mC),f&&t(_Ve),f&&t(Ic),w(Mx),f&&t(uVe),f&&t(mr),w(Ex),w(wx),w(hC),w(Ax),w(_C),f&&t(bVe),f&&t(jc),w(Lx),f&&t(vVe),f&&t(gr),w(yx),w($x),w(bC),w(kx),w(FC),f&&t(FVe),f&&t(Oc),w(Sx),f&&t(TVe),f&&t(hr),w(Rx),w(Bx),w(MC),w(Ix),w(JC),f&&t(MVe),f&&t(zc),w(Nx),f&&t(EVe),f&&t(pr),w(qx),w(Dx),w(KC),w(Gx),w(d0),f&&t(CVe),f&&t(Hc),w(Ox),f&&t(wVe),f&&t(_r),w(Vx),w(zx),w(f0),w(Qx),w(w0),f&&t(AVe),f&&t(Yc),w(Wx),f&&t(LVe),f&&t(ur),w(Hx),w(Jx),w(L0),w(Yx),w(q0),f&&t(yVe),f&&t(ef),w(Kx),f&&t(xVe),f&&t(br),w(Zx),w(o$),w(D0),w(r$),w(Y0),f&&t($Ve),f&&t(tf),w(t$),f&&t(kVe),f&&t(vr),w(a$),w(s$),w(Z0),w(l$),w(cw),f&&t(SVe),f&&t(sf),w(i$),f&&t(RVe),f&&t(Fr),w(d$),w(f$),w(mw),w(m$),w(Ew),f&&t(PVe),f&&t(cf),w(g$),f&&t(BVe),f&&t(Tr),w(h$),w(_$),w(ww),w(u$),w(Pw),f&&t(IVe),f&&t(gf),w(b$),f&&t(NVe),f&&t(Mr),w(v$),w(T$),w(Iw),w(M$),w(zw),f&&t(qVe),f&&t(_f),w(E$),f&&t(jVe),f&&t(Er),w(C$),w(A$),w(Ww),w(L$),w(Uw),f&&t(DVe),f&&t(vf),w(y$),f&&t(GVe),f&&t(Cr),w(x$),w(k$),w(Yw),w(S$),w(eA),f&&t(OVe),f&&t(Mf),w(P$),f&&t(VVe),f&&t(wr),w(B$),w(N$),w(rA),w(q$),w(aA)}}}const COt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function wOt(x){return EDt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class SOt extends vDt{constructor(g){super();FDt(this,g,wOt,EOt,TDt,{})}}export{SOt as default,COt as metadata};
