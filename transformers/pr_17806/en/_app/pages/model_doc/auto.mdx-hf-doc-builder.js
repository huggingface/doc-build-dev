import{S as mVt,i as gVt,s as hVt,e as a,k as l,w as F,t as o,M as pVt,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as _Vt,L as I}from"../../chunks/vendor-hf-doc-builder.js";import{T as uet}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as re}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function uVt($){let g,v,p,m,_,d,h,Eo,wi,Sf,nt,Ai,Li,qA,Rf,Oe,We,yi,Pn,jA,Bn,In,DA,xi,Nn,GA,$i,Pf,ka;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),_=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Eo=o(`, make sure its
`),wi=a("code"),Sf=o("model_type"),nt=o(" attribute is set to the same key you use when registering the config (here "),Ai=a("code"),Li=o('"new-model"'),qA=o(")."),Rf=l(),Oe=a("p"),We=o("Likewise, if your "),yi=a("code"),Pn=o("NewModel"),jA=o(" is a subclass of "),Bn=a("a"),In=o("PreTrainedModel"),DA=o(`, make sure its
`),xi=a("code"),Nn=o("config_class"),GA=o(` attribute is set to the same class you use when registering the model (here
`),$i=a("code"),Pf=o("NewModelConfig"),ka=o(")."),this.h()},l(Qe){g=n(Qe,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var bS=s(p);m=r(bS,"NewModelConfig"),bS.forEach(t),_=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var ki=s(d);h=r(ki,"PretrainedConfig"),ki.forEach(t),Eo=r(Ae,`, make sure its
`),wi=n(Ae,"CODE",{});var vS=s(wi);Sf=r(vS,"model_type"),vS.forEach(t),nt=r(Ae," attribute is set to the same key you use when registering the config (here "),Ai=n(Ae,"CODE",{});var FS=s(Ai);Li=r(FS,'"new-model"'),FS.forEach(t),qA=r(Ae,")."),Ae.forEach(t),Rf=i(Qe),Oe=n(Qe,"P",{});var Co=s(Oe);We=r(Co,"Likewise, if your "),yi=n(Co,"CODE",{});var Sa=s(yi);Pn=r(Sa,"NewModel"),Sa.forEach(t),jA=r(Co," is a subclass of "),Bn=n(Co,"A",{href:!0});var TS=s(Bn);In=r(TS,"PreTrainedModel"),TS.forEach(t),DA=r(Co,`, make sure its
`),xi=n(Co,"CODE",{});var Bf=s(xi);Nn=r(Bf,"config_class"),Bf.forEach(t),GA=r(Co,` attribute is set to the same class you use when registering the model (here
`),$i=n(Co,"CODE",{});var MS=s($i);Pf=r(MS,"NewModelConfig"),MS.forEach(t),ka=r(Co,")."),Co.forEach(t),this.h()},h(){c(Bn,"href","/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel")},m(Qe,Ae){b(Qe,g,Ae),e(g,v),e(g,p),e(p,m),e(g,_),e(g,d),e(d,h),e(g,Eo),e(g,wi),e(wi,Sf),e(g,nt),e(g,Ai),e(Ai,Li),e(g,qA),b(Qe,Rf,Ae),b(Qe,Oe,Ae),e(Oe,We),e(Oe,yi),e(yi,Pn),e(Oe,jA),e(Oe,Bn),e(Bn,In),e(Oe,DA),e(Oe,xi),e(xi,Nn),e(Oe,GA),e(Oe,$i),e($i,Pf),e(Oe,ka)},d(Qe){Qe&&t(g),Qe&&t(Rf),Qe&&t(Oe)}}}function bVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FVt($){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function TVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MVt($){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function EVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function AVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $Vt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function OVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function UVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZVt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Xt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function EXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function AXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $Xt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function OXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function UXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZXt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ezt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ozt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function azt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function szt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function izt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function czt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _zt($){let g,v,p,m,_,d,h,Eo,wi,Sf,nt,Ai,Li,qA,Rf,Oe,We,yi,Pn,jA,Bn,In,DA,xi,Nn,GA,$i,Pf,ka,Qe,Ae,bS,ki,vS,FS,Co,Sa,TS,Bf,MS,oQe,DOe,Si,If,Xte,OA,rQe,zte,tQe,GOe,qn,aQe,Wte,nQe,sQe,Qte,lQe,iQe,OOe,VA,VOe,ES,dQe,XOe,Nf,zOe,Ri,qf,Hte,XA,cQe,Ute,fQe,WOe,wo,zA,mQe,WA,gQe,CS,hQe,pQe,_Qe,QA,uQe,Jte,bQe,vQe,FQe,Lr,HA,TQe,Yte,MQe,EQe,Pi,CQe,Kte,wQe,AQe,Zte,LQe,yQe,xQe,A,jf,eae,$Qe,kQe,wS,SQe,RQe,PQe,Df,oae,BQe,IQe,AS,NQe,qQe,jQe,Gf,rae,DQe,GQe,LS,OQe,VQe,XQe,Of,tae,zQe,WQe,yS,QQe,HQe,UQe,Vf,aae,JQe,YQe,xS,KQe,ZQe,eHe,Xf,nae,oHe,rHe,$S,tHe,aHe,nHe,zf,sae,sHe,lHe,kS,iHe,dHe,cHe,Wf,lae,fHe,mHe,SS,gHe,hHe,pHe,Qf,iae,_He,uHe,RS,bHe,vHe,FHe,Hf,dae,THe,MHe,PS,EHe,CHe,wHe,Uf,cae,AHe,LHe,BS,yHe,xHe,$He,Jf,fae,kHe,SHe,IS,RHe,PHe,BHe,Yf,mae,IHe,NHe,NS,qHe,jHe,DHe,Kf,gae,GHe,OHe,qS,VHe,XHe,zHe,Zf,hae,WHe,QHe,jS,HHe,UHe,JHe,em,pae,YHe,KHe,DS,ZHe,eUe,oUe,om,_ae,rUe,tUe,GS,aUe,nUe,sUe,rm,uae,lUe,iUe,OS,dUe,cUe,fUe,tm,bae,mUe,gUe,VS,hUe,pUe,_Ue,am,vae,uUe,bUe,XS,vUe,FUe,TUe,nm,Fae,MUe,EUe,zS,CUe,wUe,AUe,sm,Tae,LUe,yUe,WS,xUe,$Ue,kUe,lm,Mae,SUe,RUe,QS,PUe,BUe,IUe,im,Eae,NUe,qUe,HS,jUe,DUe,GUe,dm,Cae,OUe,VUe,US,XUe,zUe,WUe,cm,wae,QUe,HUe,JS,UUe,JUe,YUe,fm,Aae,KUe,ZUe,YS,eJe,oJe,rJe,mm,Lae,tJe,aJe,KS,nJe,sJe,lJe,gm,yae,iJe,dJe,ZS,cJe,fJe,mJe,hm,xae,gJe,hJe,eR,pJe,_Je,uJe,pm,$ae,bJe,vJe,oR,FJe,TJe,MJe,_m,kae,EJe,CJe,rR,wJe,AJe,LJe,um,Sae,yJe,xJe,tR,$Je,kJe,SJe,bm,Rae,RJe,PJe,aR,BJe,IJe,NJe,vm,Pae,qJe,jJe,nR,DJe,GJe,OJe,Fm,Bae,VJe,XJe,sR,zJe,WJe,QJe,Tm,Iae,HJe,UJe,lR,JJe,YJe,KJe,Mm,Nae,ZJe,eYe,iR,oYe,rYe,tYe,Em,qae,aYe,nYe,dR,sYe,lYe,iYe,Cm,jae,dYe,cYe,cR,fYe,mYe,gYe,wm,Dae,hYe,pYe,fR,_Ye,uYe,bYe,Am,Gae,vYe,FYe,mR,TYe,MYe,EYe,Lm,Oae,CYe,wYe,gR,AYe,LYe,yYe,ym,Vae,xYe,$Ye,hR,kYe,SYe,RYe,xm,Xae,PYe,BYe,pR,IYe,NYe,qYe,$m,zae,jYe,DYe,_R,GYe,OYe,VYe,km,Wae,XYe,zYe,uR,WYe,QYe,HYe,Sm,Qae,UYe,JYe,bR,YYe,KYe,ZYe,Rm,Hae,eKe,oKe,vR,rKe,tKe,aKe,Pm,Uae,nKe,sKe,FR,lKe,iKe,dKe,Bm,Jae,cKe,fKe,TR,mKe,gKe,hKe,Im,Yae,pKe,_Ke,MR,uKe,bKe,vKe,Nm,Kae,FKe,TKe,ER,MKe,EKe,CKe,qm,Zae,wKe,AKe,CR,LKe,yKe,xKe,jm,ene,$Ke,kKe,wR,SKe,RKe,PKe,Dm,one,BKe,IKe,AR,NKe,qKe,jKe,Gm,rne,DKe,GKe,LR,OKe,VKe,XKe,Om,tne,zKe,WKe,yR,QKe,HKe,UKe,Vm,ane,JKe,YKe,xR,KKe,ZKe,eZe,Xm,nne,oZe,rZe,$R,tZe,aZe,nZe,zm,sne,sZe,lZe,kR,iZe,dZe,cZe,Wm,lne,fZe,mZe,SR,gZe,hZe,pZe,Qm,ine,_Ze,uZe,RR,bZe,vZe,FZe,Hm,dne,TZe,MZe,PR,EZe,CZe,wZe,Um,cne,AZe,LZe,BR,yZe,xZe,$Ze,Jm,fne,kZe,SZe,IR,RZe,PZe,BZe,Ym,mne,IZe,NZe,NR,qZe,jZe,DZe,Km,gne,GZe,OZe,qR,VZe,XZe,zZe,Zm,hne,WZe,QZe,jR,HZe,UZe,JZe,eg,pne,YZe,KZe,DR,ZZe,eeo,oeo,og,_ne,reo,teo,GR,aeo,neo,seo,rg,une,leo,ieo,OR,deo,ceo,feo,tg,bne,meo,geo,VR,heo,peo,_eo,ag,vne,ueo,beo,XR,veo,Feo,Teo,ng,Fne,Meo,Eeo,zR,Ceo,weo,Aeo,sg,Tne,Leo,yeo,WR,xeo,$eo,keo,lg,Mne,Seo,Reo,QR,Peo,Beo,Ieo,ig,Ene,Neo,qeo,HR,jeo,Deo,Geo,dg,Cne,Oeo,Veo,UR,Xeo,zeo,Weo,cg,wne,Qeo,Heo,JR,Ueo,Jeo,Yeo,fg,Ane,Keo,Zeo,YR,eoo,ooo,roo,mg,Lne,too,aoo,KR,noo,soo,loo,gg,yne,ioo,doo,ZR,coo,foo,moo,hg,xne,goo,hoo,eP,poo,_oo,uoo,pg,$ne,boo,voo,oP,Foo,Too,Moo,_g,kne,Eoo,Coo,rP,woo,Aoo,Loo,ug,Sne,yoo,xoo,tP,$oo,koo,Soo,bg,Rne,Roo,Poo,aP,Boo,Ioo,Noo,vg,Pne,qoo,joo,nP,Doo,Goo,Ooo,Fg,Bne,Voo,Xoo,sP,zoo,Woo,Qoo,Tg,Ine,Hoo,Uoo,lP,Joo,Yoo,Koo,Mg,Nne,Zoo,ero,iP,oro,rro,tro,Eg,qne,aro,nro,dP,sro,lro,iro,Cg,jne,dro,cro,cP,fro,mro,gro,wg,Dne,hro,pro,fP,_ro,uro,bro,Ag,Gne,vro,Fro,mP,Tro,Mro,Ero,Lg,One,Cro,wro,gP,Aro,Lro,yro,yg,Vne,xro,$ro,hP,kro,Sro,Rro,xg,Xne,Pro,Bro,pP,Iro,Nro,qro,$g,zne,jro,Dro,_P,Gro,Oro,Vro,kg,Wne,Xro,zro,uP,Wro,Qro,Hro,Sg,Qne,Uro,Jro,bP,Yro,Kro,Zro,Rg,Hne,eto,oto,vP,rto,tto,ato,Pg,Une,nto,sto,FP,lto,ito,dto,Bg,Jne,cto,fto,TP,mto,gto,hto,Ig,Yne,pto,_to,MP,uto,bto,vto,Ng,Kne,Fto,Tto,EP,Mto,Eto,Cto,qg,Zne,wto,Ato,CP,Lto,yto,xto,jg,ese,$to,kto,wP,Sto,Rto,Pto,Dg,ose,Bto,Ito,AP,Nto,qto,jto,Gg,rse,Dto,Gto,LP,Oto,Vto,Xto,Og,tse,zto,Wto,yP,Qto,Hto,Uto,Vg,ase,Jto,Yto,xP,Kto,Zto,eao,Xg,nse,oao,rao,$P,tao,aao,nao,zg,sse,sao,lao,kP,iao,dao,cao,Wg,lse,fao,mao,SP,gao,hao,pao,Qg,_ao,Hg,UA,uao,ise,bao,QOe,Bi,Ug,dse,JA,vao,cse,Fao,HOe,Ao,YA,Tao,KA,Mao,RP,Eao,Cao,wao,ZA,Aao,fse,Lao,yao,xao,yr,eL,$ao,mse,kao,Sao,Ra,Rao,gse,Pao,Bao,hse,Iao,Nao,pse,qao,jao,Dao,k,jn,_se,Gao,Oao,PP,Vao,Xao,BP,zao,Wao,Qao,Dn,use,Hao,Uao,IP,Jao,Yao,NP,Kao,Zao,eno,Gn,bse,ono,rno,qP,tno,ano,jP,nno,sno,lno,Jg,vse,ino,dno,DP,cno,fno,mno,On,Fse,gno,hno,GP,pno,_no,OP,uno,bno,vno,Yg,Tse,Fno,Tno,VP,Mno,Eno,Cno,Kg,Mse,wno,Ano,XP,Lno,yno,xno,Zg,Ese,$no,kno,zP,Sno,Rno,Pno,Vn,Cse,Bno,Ino,WP,Nno,qno,QP,jno,Dno,Gno,Xn,wse,Ono,Vno,HP,Xno,zno,UP,Wno,Qno,Hno,zn,Ase,Uno,Jno,JP,Yno,Kno,YP,Zno,eso,oso,eh,Lse,rso,tso,KP,aso,nso,sso,oh,yse,lso,iso,ZP,dso,cso,fso,rh,xse,mso,gso,eB,hso,pso,_so,Wn,$se,uso,bso,oB,vso,Fso,rB,Tso,Mso,Eso,th,kse,Cso,wso,tB,Aso,Lso,yso,Qn,Sse,xso,$so,aB,kso,Sso,nB,Rso,Pso,Bso,Hn,Rse,Iso,Nso,sB,qso,jso,lB,Dso,Gso,Oso,Un,Pse,Vso,Xso,iB,zso,Wso,dB,Qso,Hso,Uso,Jn,Bse,Jso,Yso,cB,Kso,Zso,fB,elo,olo,rlo,ah,Ise,tlo,alo,mB,nlo,slo,llo,Yn,Nse,ilo,dlo,gB,clo,flo,hB,mlo,glo,hlo,Kn,qse,plo,_lo,pB,ulo,blo,_B,vlo,Flo,Tlo,Zn,jse,Mlo,Elo,uB,Clo,wlo,bB,Alo,Llo,ylo,es,Dse,xlo,$lo,vB,klo,Slo,FB,Rlo,Plo,Blo,os,Gse,Ilo,Nlo,TB,qlo,jlo,MB,Dlo,Glo,Olo,rs,Ose,Vlo,Xlo,EB,zlo,Wlo,CB,Qlo,Hlo,Ulo,nh,Vse,Jlo,Ylo,wB,Klo,Zlo,eio,ts,Xse,oio,rio,AB,tio,aio,LB,nio,sio,lio,sh,zse,iio,dio,yB,cio,fio,mio,as,Wse,gio,hio,xB,pio,_io,$B,uio,bio,vio,ns,Qse,Fio,Tio,kB,Mio,Eio,SB,Cio,wio,Aio,ss,Hse,Lio,yio,RB,xio,$io,PB,kio,Sio,Rio,lh,Use,Pio,Bio,BB,Iio,Nio,qio,ls,Jse,jio,Dio,IB,Gio,Oio,NB,Vio,Xio,zio,is,Yse,Wio,Qio,qB,Hio,Uio,jB,Jio,Yio,Kio,ds,Kse,Zio,edo,DB,odo,rdo,GB,tdo,ado,ndo,ih,Zse,sdo,ldo,OB,ido,ddo,cdo,cs,ele,fdo,mdo,VB,gdo,hdo,XB,pdo,_do,udo,fs,ole,bdo,vdo,zB,Fdo,Tdo,WB,Mdo,Edo,Cdo,ms,rle,wdo,Ado,QB,Ldo,ydo,HB,xdo,$do,kdo,gs,tle,Sdo,Rdo,UB,Pdo,Bdo,JB,Ido,Ndo,qdo,hs,ale,jdo,Ddo,YB,Gdo,Odo,KB,Vdo,Xdo,zdo,ps,nle,Wdo,Qdo,ZB,Hdo,Udo,eI,Jdo,Ydo,Kdo,_s,sle,Zdo,eco,oI,oco,rco,rI,tco,aco,nco,us,lle,sco,lco,tI,ico,dco,aI,cco,fco,mco,dh,ile,gco,hco,nI,pco,_co,uco,bs,dle,bco,vco,sI,Fco,Tco,lI,Mco,Eco,Cco,ch,cle,wco,Aco,iI,Lco,yco,xco,fh,fle,$co,kco,dI,Sco,Rco,Pco,vs,mle,Bco,Ico,cI,Nco,qco,fI,jco,Dco,Gco,Fs,gle,Oco,Vco,mI,Xco,zco,gI,Wco,Qco,Hco,Ts,hle,Uco,Jco,hI,Yco,Kco,pI,Zco,efo,ofo,mh,ple,rfo,tfo,_I,afo,nfo,sfo,Ms,_le,lfo,ifo,uI,dfo,cfo,bI,ffo,mfo,gfo,Es,ule,hfo,pfo,vI,_fo,ufo,FI,bfo,vfo,Ffo,Cs,ble,Tfo,Mfo,TI,Efo,Cfo,MI,wfo,Afo,Lfo,ws,vle,yfo,xfo,EI,$fo,kfo,CI,Sfo,Rfo,Pfo,As,Fle,Bfo,Ifo,wI,Nfo,qfo,AI,jfo,Dfo,Gfo,Ls,Tle,Ofo,Vfo,LI,Xfo,zfo,yI,Wfo,Qfo,Hfo,gh,Mle,Ufo,Jfo,xI,Yfo,Kfo,Zfo,ys,Ele,emo,omo,$I,rmo,tmo,kI,amo,nmo,smo,hh,Cle,lmo,imo,SI,dmo,cmo,fmo,ph,wle,mmo,gmo,RI,hmo,pmo,_mo,_h,Ale,umo,bmo,PI,vmo,Fmo,Tmo,uh,Lle,Mmo,Emo,BI,Cmo,wmo,Amo,xs,yle,Lmo,ymo,II,xmo,$mo,NI,kmo,Smo,Rmo,bh,xle,Pmo,Bmo,qI,Imo,Nmo,qmo,$s,$le,jmo,Dmo,jI,Gmo,Omo,DI,Vmo,Xmo,zmo,ks,kle,Wmo,Qmo,GI,Hmo,Umo,OI,Jmo,Ymo,Kmo,Ss,Sle,Zmo,ego,VI,ogo,rgo,XI,tgo,ago,ngo,Rs,Rle,sgo,lgo,zI,igo,dgo,WI,cgo,fgo,mgo,Ps,Ple,ggo,hgo,QI,pgo,_go,HI,ugo,bgo,vgo,Bs,Ble,Fgo,Tgo,UI,Mgo,Ego,JI,Cgo,wgo,Ago,vh,Ile,Lgo,ygo,YI,xgo,$go,kgo,Fh,Nle,Sgo,Rgo,KI,Pgo,Bgo,Igo,Is,qle,Ngo,qgo,ZI,jgo,Dgo,eN,Ggo,Ogo,Vgo,Ns,jle,Xgo,zgo,oN,Wgo,Qgo,rN,Hgo,Ugo,Jgo,qs,Dle,Ygo,Kgo,tN,Zgo,eho,aN,oho,rho,tho,Th,Gle,aho,nho,nN,sho,lho,iho,Mh,Ole,dho,cho,sN,fho,mho,gho,Eh,Vle,hho,pho,lN,_ho,uho,bho,js,Xle,vho,Fho,iN,Tho,Mho,dN,Eho,Cho,who,Ds,zle,Aho,Lho,cN,yho,xho,fN,$ho,kho,Sho,Ch,Wle,Rho,Pho,mN,Bho,Iho,Nho,wh,Qle,qho,jho,gN,Dho,Gho,Oho,Ah,Hle,Vho,Xho,hN,zho,Who,Qho,Gs,Ule,Hho,Uho,pN,Jho,Yho,_N,Kho,Zho,epo,Lh,Jle,opo,rpo,uN,tpo,apo,npo,yh,Yle,spo,lpo,bN,ipo,dpo,cpo,Os,Kle,fpo,mpo,vN,gpo,hpo,FN,ppo,_po,upo,Vs,Zle,bpo,vpo,TN,Fpo,Tpo,MN,Mpo,Epo,Cpo,Xs,eie,wpo,Apo,EN,Lpo,ypo,CN,xpo,$po,kpo,zs,oie,Spo,Rpo,wN,Ppo,Bpo,AN,Ipo,Npo,qpo,xh,jpo,$h,oL,Dpo,rie,Gpo,UOe,Ii,kh,tie,rL,Opo,aie,Vpo,JOe,Lo,tL,Xpo,aL,zpo,LN,Wpo,Qpo,Hpo,nL,Upo,nie,Jpo,Ypo,Kpo,He,sL,Zpo,sie,e_o,o_o,Pa,r_o,lie,t_o,a_o,iie,n_o,s_o,die,l_o,i_o,d_o,Y,Sh,cie,c_o,f_o,yN,m_o,g_o,h_o,Rh,fie,p_o,__o,xN,u_o,b_o,v_o,Ph,mie,F_o,T_o,$N,M_o,E_o,C_o,Bh,gie,w_o,A_o,kN,L_o,y_o,x_o,Ih,hie,$_o,k_o,SN,S_o,R_o,P_o,Nh,pie,B_o,I_o,RN,N_o,q_o,j_o,qh,_ie,D_o,G_o,PN,O_o,V_o,X_o,jh,uie,z_o,W_o,BN,Q_o,H_o,U_o,Dh,bie,J_o,Y_o,IN,K_o,Z_o,euo,Gh,vie,ouo,ruo,NN,tuo,auo,nuo,Oh,Fie,suo,luo,qN,iuo,duo,cuo,Vh,Tie,fuo,muo,jN,guo,huo,puo,Xh,Mie,_uo,uuo,DN,buo,vuo,Fuo,zh,Eie,Tuo,Muo,GN,Euo,Cuo,wuo,Wh,Cie,Auo,Luo,ON,yuo,xuo,$uo,Qh,wie,kuo,Suo,VN,Ruo,Puo,Buo,Hh,Aie,Iuo,Nuo,XN,quo,juo,Duo,Uh,Lie,Guo,Ouo,zN,Vuo,Xuo,zuo,Jh,yie,Wuo,Quo,WN,Huo,Uuo,Juo,Yh,xie,Yuo,Kuo,QN,Zuo,e1o,o1o,Kh,$ie,r1o,t1o,HN,a1o,n1o,s1o,Zh,kie,l1o,i1o,UN,d1o,c1o,f1o,ep,Sie,m1o,g1o,JN,h1o,p1o,_1o,op,Rie,u1o,b1o,YN,v1o,F1o,T1o,rp,Pie,M1o,E1o,KN,C1o,w1o,A1o,tp,Bie,L1o,y1o,ZN,x1o,$1o,k1o,ap,Iie,S1o,R1o,eq,P1o,B1o,I1o,np,Nie,N1o,q1o,oq,j1o,D1o,G1o,sp,qie,O1o,V1o,rq,X1o,z1o,W1o,lp,jie,Q1o,H1o,tq,U1o,J1o,Y1o,ip,Die,K1o,Z1o,aq,e2o,o2o,r2o,dp,Gie,t2o,a2o,nq,n2o,s2o,l2o,cp,Oie,i2o,d2o,sq,c2o,f2o,m2o,fp,g2o,mp,h2o,gp,lL,p2o,Vie,_2o,YOe,Ni,hp,Xie,iL,u2o,zie,b2o,KOe,yo,dL,v2o,cL,F2o,lq,T2o,M2o,E2o,fL,C2o,Wie,w2o,A2o,L2o,Ue,mL,y2o,Qie,x2o,$2o,qi,k2o,Hie,S2o,R2o,Uie,P2o,B2o,I2o,he,pp,Jie,N2o,q2o,iq,j2o,D2o,G2o,_p,Yie,O2o,V2o,Kie,X2o,z2o,W2o,up,Zie,Q2o,H2o,dq,U2o,J2o,Y2o,bp,ede,K2o,Z2o,cq,ebo,obo,rbo,vp,ode,tbo,abo,fq,nbo,sbo,lbo,Fp,rde,ibo,dbo,mq,cbo,fbo,mbo,Tp,tde,gbo,hbo,gq,pbo,_bo,ubo,Mp,ade,bbo,vbo,hq,Fbo,Tbo,Mbo,Ep,nde,Ebo,Cbo,pq,wbo,Abo,Lbo,Cp,sde,ybo,xbo,_q,$bo,kbo,Sbo,wp,lde,Rbo,Pbo,uq,Bbo,Ibo,Nbo,Ap,ide,qbo,jbo,bq,Dbo,Gbo,Obo,Lp,dde,Vbo,Xbo,vq,zbo,Wbo,Qbo,yp,cde,Hbo,Ubo,Fq,Jbo,Ybo,Kbo,xp,fde,Zbo,evo,Tq,ovo,rvo,tvo,$p,mde,avo,nvo,Mq,svo,lvo,ivo,kp,gde,dvo,cvo,Eq,fvo,mvo,gvo,Sp,hde,hvo,pvo,Cq,_vo,uvo,bvo,Rp,vvo,Pp,Fvo,Bp,gL,Tvo,pde,Mvo,ZOe,ji,Ip,_de,hL,Evo,ude,Cvo,eVe,xo,pL,wvo,Di,Avo,wq,Lvo,yvo,Aq,xvo,$vo,kvo,_L,Svo,bde,Rvo,Pvo,Bvo,st,uL,Ivo,vde,Nvo,qvo,Gi,jvo,Fde,Dvo,Gvo,Lq,Ovo,Vvo,Xvo,Np,zvo,Je,bL,Wvo,Tde,Qvo,Hvo,Ba,Uvo,Mde,Jvo,Yvo,Ede,Kvo,Zvo,Cde,e0o,o0o,r0o,y,qp,wde,t0o,a0o,yq,n0o,s0o,l0o,jp,Ade,i0o,d0o,xq,c0o,f0o,m0o,Dp,Lde,g0o,h0o,$q,p0o,_0o,u0o,Gp,yde,b0o,v0o,kq,F0o,T0o,M0o,Op,xde,E0o,C0o,Sq,w0o,A0o,L0o,Vp,$de,y0o,x0o,Rq,$0o,k0o,S0o,Xp,kde,R0o,P0o,Pq,B0o,I0o,N0o,zp,Sde,q0o,j0o,Bq,D0o,G0o,O0o,Wp,Rde,V0o,X0o,Iq,z0o,W0o,Q0o,Qp,Pde,H0o,U0o,Nq,J0o,Y0o,K0o,Hp,Bde,Z0o,eFo,qq,oFo,rFo,tFo,Up,Ide,aFo,nFo,jq,sFo,lFo,iFo,Jp,Nde,dFo,cFo,Dq,fFo,mFo,gFo,Yp,qde,hFo,pFo,Gq,_Fo,uFo,bFo,Kp,jde,vFo,FFo,Oq,TFo,MFo,EFo,Zp,Dde,CFo,wFo,Vq,AFo,LFo,yFo,e_,Gde,xFo,$Fo,Xq,kFo,SFo,RFo,o_,Ode,PFo,BFo,zq,IFo,NFo,qFo,r_,Vde,jFo,DFo,Wq,GFo,OFo,VFo,t_,Xde,XFo,zFo,Qq,WFo,QFo,HFo,a_,zde,UFo,JFo,Hq,YFo,KFo,ZFo,n_,Wde,e6o,o6o,Uq,r6o,t6o,a6o,s_,Qde,n6o,s6o,Jq,l6o,i6o,d6o,l_,Hde,c6o,f6o,Yq,m6o,g6o,h6o,i_,Ude,p6o,_6o,Kq,u6o,b6o,v6o,d_,Jde,F6o,T6o,Zq,M6o,E6o,C6o,c_,Yde,w6o,A6o,ej,L6o,y6o,x6o,f_,Kde,$6o,k6o,oj,S6o,R6o,P6o,m_,Zde,B6o,I6o,rj,N6o,q6o,j6o,g_,ece,D6o,G6o,tj,O6o,V6o,X6o,h_,oce,z6o,W6o,aj,Q6o,H6o,U6o,p_,rce,J6o,Y6o,nj,K6o,Z6o,eTo,__,tce,oTo,rTo,sj,tTo,aTo,nTo,u_,ace,sTo,lTo,lj,iTo,dTo,cTo,Ws,nce,fTo,mTo,ij,gTo,hTo,dj,pTo,_To,uTo,b_,sce,bTo,vTo,cj,FTo,TTo,MTo,v_,lce,ETo,CTo,fj,wTo,ATo,LTo,F_,ice,yTo,xTo,mj,$To,kTo,STo,T_,dce,RTo,PTo,gj,BTo,ITo,NTo,M_,cce,qTo,jTo,hj,DTo,GTo,OTo,E_,fce,VTo,XTo,pj,zTo,WTo,QTo,C_,mce,HTo,UTo,_j,JTo,YTo,KTo,w_,gce,ZTo,e7o,uj,o7o,r7o,t7o,A_,hce,a7o,n7o,bj,s7o,l7o,i7o,L_,pce,d7o,c7o,vj,f7o,m7o,g7o,y_,_ce,h7o,p7o,Fj,_7o,u7o,b7o,x_,uce,v7o,F7o,Tj,T7o,M7o,E7o,$_,bce,C7o,w7o,Mj,A7o,L7o,y7o,k_,vce,x7o,$7o,Ej,k7o,S7o,R7o,S_,Fce,P7o,B7o,Cj,I7o,N7o,q7o,R_,Tce,j7o,D7o,wj,G7o,O7o,V7o,P_,Mce,X7o,z7o,Aj,W7o,Q7o,H7o,B_,Ece,U7o,J7o,Lj,Y7o,K7o,Z7o,I_,Cce,e8o,o8o,yj,r8o,t8o,a8o,N_,wce,n8o,s8o,xj,l8o,i8o,d8o,q_,Ace,c8o,f8o,$j,m8o,g8o,h8o,j_,Lce,p8o,_8o,kj,u8o,b8o,v8o,D_,yce,F8o,T8o,Sj,M8o,E8o,C8o,G_,xce,w8o,A8o,Rj,L8o,y8o,x8o,O_,$ce,$8o,k8o,Pj,S8o,R8o,P8o,V_,kce,B8o,I8o,Bj,N8o,q8o,j8o,X_,Sce,D8o,G8o,Ij,O8o,V8o,X8o,z_,Rce,z8o,W8o,Nj,Q8o,H8o,U8o,W_,Pce,J8o,Y8o,qj,K8o,Z8o,eMo,Q_,Bce,oMo,rMo,jj,tMo,aMo,nMo,H_,Ice,sMo,lMo,Dj,iMo,dMo,cMo,U_,Nce,fMo,mMo,Gj,gMo,hMo,pMo,J_,qce,_Mo,uMo,Oj,bMo,vMo,FMo,Y_,jce,TMo,MMo,Vj,EMo,CMo,wMo,K_,Dce,AMo,LMo,Xj,yMo,xMo,$Mo,Z_,Gce,kMo,SMo,zj,RMo,PMo,BMo,eu,Oce,IMo,NMo,Wj,qMo,jMo,DMo,ou,Vce,GMo,OMo,Qj,VMo,XMo,zMo,ru,Xce,WMo,QMo,Hj,HMo,UMo,JMo,tu,zce,YMo,KMo,Uj,ZMo,e4o,o4o,au,Wce,r4o,t4o,Jj,a4o,n4o,s4o,nu,Qce,l4o,i4o,Yj,d4o,c4o,f4o,su,Hce,m4o,g4o,Kj,h4o,p4o,_4o,lu,Uce,u4o,b4o,Zj,v4o,F4o,T4o,iu,Jce,M4o,E4o,eD,C4o,w4o,A4o,du,Yce,L4o,y4o,oD,x4o,$4o,k4o,cu,Kce,S4o,R4o,rD,P4o,B4o,I4o,fu,Zce,N4o,q4o,tD,j4o,D4o,G4o,mu,efe,O4o,V4o,aD,X4o,z4o,W4o,gu,ofe,Q4o,H4o,nD,U4o,J4o,Y4o,hu,rfe,K4o,Z4o,sD,eEo,oEo,rEo,pu,tfe,tEo,aEo,lD,nEo,sEo,lEo,_u,afe,iEo,dEo,iD,cEo,fEo,mEo,uu,nfe,gEo,hEo,dD,pEo,_Eo,uEo,bu,sfe,bEo,vEo,cD,FEo,TEo,MEo,vu,lfe,EEo,CEo,fD,wEo,AEo,LEo,Fu,ife,yEo,xEo,mD,$Eo,kEo,SEo,Tu,dfe,REo,PEo,gD,BEo,IEo,NEo,Mu,cfe,qEo,jEo,hD,DEo,GEo,OEo,Eu,ffe,VEo,XEo,pD,zEo,WEo,QEo,Cu,mfe,HEo,UEo,_D,JEo,YEo,KEo,wu,gfe,ZEo,eCo,uD,oCo,rCo,tCo,Au,hfe,aCo,nCo,bD,sCo,lCo,iCo,Lu,pfe,dCo,cCo,vD,fCo,mCo,gCo,yu,_fe,hCo,pCo,FD,_Co,uCo,bCo,xu,ufe,vCo,FCo,TD,TCo,MCo,ECo,$u,bfe,CCo,wCo,MD,ACo,LCo,yCo,ku,vfe,xCo,$Co,ED,kCo,SCo,RCo,Su,Ffe,PCo,BCo,CD,ICo,NCo,qCo,Ru,Tfe,jCo,DCo,wD,GCo,OCo,VCo,Pu,Mfe,XCo,zCo,AD,WCo,QCo,HCo,Bu,Efe,UCo,JCo,LD,YCo,KCo,ZCo,Iu,Cfe,e3o,o3o,yD,r3o,t3o,a3o,Nu,wfe,n3o,s3o,xD,l3o,i3o,d3o,qu,c3o,Afe,f3o,m3o,Lfe,g3o,h3o,ju,oVe,Oi,Du,yfe,vL,p3o,xfe,_3o,rVe,$o,FL,u3o,Vi,b3o,$D,v3o,F3o,kD,T3o,M3o,E3o,TL,C3o,$fe,w3o,A3o,L3o,lt,ML,y3o,kfe,x3o,$3o,Xi,k3o,Sfe,S3o,R3o,SD,P3o,B3o,I3o,Gu,N3o,Ye,EL,q3o,Rfe,j3o,D3o,Ia,G3o,Pfe,O3o,V3o,Bfe,X3o,z3o,Ife,W3o,Q3o,H3o,G,Ou,Nfe,U3o,J3o,RD,Y3o,K3o,Z3o,Vu,qfe,e5o,o5o,PD,r5o,t5o,a5o,Xu,jfe,n5o,s5o,BD,l5o,i5o,d5o,zu,Dfe,c5o,f5o,ID,m5o,g5o,h5o,Wu,Gfe,p5o,_5o,ND,u5o,b5o,v5o,Qu,Ofe,F5o,T5o,qD,M5o,E5o,C5o,Hu,Vfe,w5o,A5o,jD,L5o,y5o,x5o,Uu,Xfe,$5o,k5o,DD,S5o,R5o,P5o,Ju,zfe,B5o,I5o,GD,N5o,q5o,j5o,Yu,Wfe,D5o,G5o,OD,O5o,V5o,X5o,Ku,Qfe,z5o,W5o,VD,Q5o,H5o,U5o,Zu,Hfe,J5o,Y5o,XD,K5o,Z5o,ewo,e1,Ufe,owo,rwo,zD,two,awo,nwo,o1,Jfe,swo,lwo,WD,iwo,dwo,cwo,r1,Yfe,fwo,mwo,QD,gwo,hwo,pwo,t1,Kfe,_wo,uwo,HD,bwo,vwo,Fwo,a1,Zfe,Two,Mwo,UD,Ewo,Cwo,wwo,n1,eme,Awo,Lwo,JD,ywo,xwo,$wo,s1,ome,kwo,Swo,YD,Rwo,Pwo,Bwo,l1,rme,Iwo,Nwo,KD,qwo,jwo,Dwo,i1,tme,Gwo,Owo,ZD,Vwo,Xwo,zwo,d1,ame,Wwo,Qwo,eG,Hwo,Uwo,Jwo,c1,nme,Ywo,Kwo,oG,Zwo,eAo,oAo,f1,sme,rAo,tAo,rG,aAo,nAo,sAo,m1,lme,lAo,iAo,tG,dAo,cAo,fAo,g1,ime,mAo,gAo,aG,hAo,pAo,_Ao,h1,dme,uAo,bAo,nG,vAo,FAo,TAo,p1,cme,MAo,EAo,sG,CAo,wAo,AAo,_1,fme,LAo,yAo,lG,xAo,$Ao,kAo,u1,mme,SAo,RAo,iG,PAo,BAo,IAo,b1,gme,NAo,qAo,dG,jAo,DAo,GAo,v1,hme,OAo,VAo,cG,XAo,zAo,WAo,F1,pme,QAo,HAo,fG,UAo,JAo,YAo,T1,_me,KAo,ZAo,mG,eLo,oLo,rLo,M1,ume,tLo,aLo,gG,nLo,sLo,lLo,E1,bme,iLo,dLo,hG,cLo,fLo,mLo,C1,vme,gLo,hLo,pG,pLo,_Lo,uLo,w1,Fme,bLo,vLo,_G,FLo,TLo,MLo,A1,Tme,ELo,CLo,uG,wLo,ALo,LLo,L1,Mme,yLo,xLo,bG,$Lo,kLo,SLo,y1,Eme,RLo,PLo,vG,BLo,ILo,NLo,x1,Cme,qLo,jLo,FG,DLo,GLo,OLo,$1,wme,VLo,XLo,TG,zLo,WLo,QLo,k1,Ame,HLo,ULo,MG,JLo,YLo,KLo,S1,ZLo,Lme,eyo,oyo,yme,ryo,tyo,R1,tVe,zi,P1,xme,CL,ayo,$me,nyo,aVe,ko,wL,syo,Wi,lyo,EG,iyo,dyo,CG,cyo,fyo,myo,AL,gyo,kme,hyo,pyo,_yo,it,LL,uyo,Sme,byo,vyo,Qi,Fyo,Rme,Tyo,Myo,wG,Eyo,Cyo,wyo,B1,Ayo,Ke,yL,Lyo,Pme,yyo,xyo,Na,$yo,Bme,kyo,Syo,Ime,Ryo,Pyo,Nme,Byo,Iyo,Nyo,z,I1,qme,qyo,jyo,AG,Dyo,Gyo,Oyo,N1,jme,Vyo,Xyo,LG,zyo,Wyo,Qyo,q1,Dme,Hyo,Uyo,yG,Jyo,Yyo,Kyo,j1,Gme,Zyo,e9o,xG,o9o,r9o,t9o,D1,Ome,a9o,n9o,$G,s9o,l9o,i9o,G1,Vme,d9o,c9o,kG,f9o,m9o,g9o,O1,Xme,h9o,p9o,SG,_9o,u9o,b9o,V1,zme,v9o,F9o,RG,T9o,M9o,E9o,X1,Wme,C9o,w9o,PG,A9o,L9o,y9o,z1,Qme,x9o,$9o,BG,k9o,S9o,R9o,W1,Hme,P9o,B9o,IG,I9o,N9o,q9o,Q1,Ume,j9o,D9o,NG,G9o,O9o,V9o,H1,Jme,X9o,z9o,qG,W9o,Q9o,H9o,U1,Yme,U9o,J9o,jG,Y9o,K9o,Z9o,J1,Kme,exo,oxo,DG,rxo,txo,axo,Y1,Zme,nxo,sxo,GG,lxo,ixo,dxo,K1,ege,cxo,fxo,OG,mxo,gxo,hxo,Z1,oge,pxo,_xo,VG,uxo,bxo,vxo,e2,rge,Fxo,Txo,XG,Mxo,Exo,Cxo,o2,tge,wxo,Axo,zG,Lxo,yxo,xxo,r2,age,$xo,kxo,WG,Sxo,Rxo,Pxo,t2,nge,Bxo,Ixo,QG,Nxo,qxo,jxo,a2,sge,Dxo,Gxo,HG,Oxo,Vxo,Xxo,n2,lge,zxo,Wxo,UG,Qxo,Hxo,Uxo,s2,ige,Jxo,Yxo,JG,Kxo,Zxo,e$o,l2,dge,o$o,r$o,YG,t$o,a$o,n$o,i2,cge,s$o,l$o,KG,i$o,d$o,c$o,d2,fge,f$o,m$o,ZG,g$o,h$o,p$o,c2,mge,_$o,u$o,eO,b$o,v$o,F$o,f2,gge,T$o,M$o,oO,E$o,C$o,w$o,m2,hge,A$o,L$o,rO,y$o,x$o,$$o,g2,pge,k$o,S$o,tO,R$o,P$o,B$o,h2,_ge,I$o,N$o,aO,q$o,j$o,D$o,p2,uge,G$o,O$o,nO,V$o,X$o,z$o,_2,bge,W$o,Q$o,sO,H$o,U$o,J$o,u2,vge,Y$o,K$o,lO,Z$o,eko,oko,b2,Fge,rko,tko,iO,ako,nko,sko,v2,Tge,lko,iko,dO,dko,cko,fko,F2,Mge,mko,gko,cO,hko,pko,_ko,T2,uko,Ege,bko,vko,Cge,Fko,Tko,M2,nVe,Hi,E2,wge,xL,Mko,Age,Eko,sVe,So,$L,Cko,Ui,wko,fO,Ako,Lko,mO,yko,xko,$ko,kL,kko,Lge,Sko,Rko,Pko,dt,SL,Bko,yge,Iko,Nko,Ji,qko,xge,jko,Dko,gO,Gko,Oko,Vko,C2,Xko,Ze,RL,zko,$ge,Wko,Qko,qa,Hko,kge,Uko,Jko,Sge,Yko,Kko,Rge,Zko,eSo,oSo,Q,w2,Pge,rSo,tSo,hO,aSo,nSo,sSo,A2,Bge,lSo,iSo,pO,dSo,cSo,fSo,L2,Ige,mSo,gSo,_O,hSo,pSo,_So,y2,Nge,uSo,bSo,uO,vSo,FSo,TSo,x2,qge,MSo,ESo,bO,CSo,wSo,ASo,$2,jge,LSo,ySo,vO,xSo,$So,kSo,k2,Dge,SSo,RSo,FO,PSo,BSo,ISo,S2,Gge,NSo,qSo,TO,jSo,DSo,GSo,R2,Oge,OSo,VSo,MO,XSo,zSo,WSo,P2,Vge,QSo,HSo,EO,USo,JSo,YSo,B2,Xge,KSo,ZSo,CO,eRo,oRo,rRo,I2,zge,tRo,aRo,wO,nRo,sRo,lRo,N2,Wge,iRo,dRo,AO,cRo,fRo,mRo,q2,Qge,gRo,hRo,LO,pRo,_Ro,uRo,j2,Hge,bRo,vRo,yO,FRo,TRo,MRo,D2,Uge,ERo,CRo,xO,wRo,ARo,LRo,G2,Jge,yRo,xRo,$O,$Ro,kRo,SRo,O2,Yge,RRo,PRo,kO,BRo,IRo,NRo,V2,Kge,qRo,jRo,SO,DRo,GRo,ORo,X2,Zge,VRo,XRo,RO,zRo,WRo,QRo,z2,ehe,HRo,URo,PO,JRo,YRo,KRo,W2,ohe,ZRo,ePo,BO,oPo,rPo,tPo,Q2,rhe,aPo,nPo,IO,sPo,lPo,iPo,H2,the,dPo,cPo,NO,fPo,mPo,gPo,U2,ahe,hPo,pPo,qO,_Po,uPo,bPo,J2,nhe,vPo,FPo,jO,TPo,MPo,EPo,Y2,she,CPo,wPo,DO,APo,LPo,yPo,K2,lhe,xPo,$Po,GO,kPo,SPo,RPo,Z2,ihe,PPo,BPo,OO,IPo,NPo,qPo,eb,dhe,jPo,DPo,VO,GPo,OPo,VPo,ob,che,XPo,zPo,XO,WPo,QPo,HPo,rb,fhe,UPo,JPo,zO,YPo,KPo,ZPo,tb,mhe,eBo,oBo,ghe,rBo,tBo,aBo,ab,hhe,nBo,sBo,WO,lBo,iBo,dBo,nb,phe,cBo,fBo,QO,mBo,gBo,hBo,sb,_he,pBo,_Bo,HO,uBo,bBo,vBo,lb,uhe,FBo,TBo,UO,MBo,EBo,CBo,ib,wBo,bhe,ABo,LBo,vhe,yBo,xBo,db,lVe,Yi,cb,Fhe,PL,$Bo,The,kBo,iVe,Ro,BL,SBo,Ki,RBo,JO,PBo,BBo,YO,IBo,NBo,qBo,IL,jBo,Mhe,DBo,GBo,OBo,ct,NL,VBo,Ehe,XBo,zBo,Zi,WBo,Che,QBo,HBo,KO,UBo,JBo,YBo,fb,KBo,eo,qL,ZBo,whe,eIo,oIo,ja,rIo,Ahe,tIo,aIo,Lhe,nIo,sIo,yhe,lIo,iIo,dIo,pe,mb,xhe,cIo,fIo,ZO,mIo,gIo,hIo,gb,$he,pIo,_Io,eV,uIo,bIo,vIo,hb,khe,FIo,TIo,oV,MIo,EIo,CIo,pb,She,wIo,AIo,rV,LIo,yIo,xIo,_b,Rhe,$Io,kIo,tV,SIo,RIo,PIo,ub,Phe,BIo,IIo,aV,NIo,qIo,jIo,bb,Bhe,DIo,GIo,nV,OIo,VIo,XIo,vb,Ihe,zIo,WIo,sV,QIo,HIo,UIo,Fb,Nhe,JIo,YIo,lV,KIo,ZIo,eNo,Tb,qhe,oNo,rNo,iV,tNo,aNo,nNo,Mb,jhe,sNo,lNo,dV,iNo,dNo,cNo,Eb,Dhe,fNo,mNo,cV,gNo,hNo,pNo,Cb,Ghe,_No,uNo,fV,bNo,vNo,FNo,wb,Ohe,TNo,MNo,mV,ENo,CNo,wNo,Ab,Vhe,ANo,LNo,gV,yNo,xNo,$No,Lb,Xhe,kNo,SNo,hV,RNo,PNo,BNo,yb,zhe,INo,NNo,pV,qNo,jNo,DNo,xb,GNo,Whe,ONo,VNo,Qhe,XNo,zNo,$b,dVe,ed,kb,Hhe,jL,WNo,Uhe,QNo,cVe,Po,DL,HNo,od,UNo,_V,JNo,YNo,uV,KNo,ZNo,eqo,GL,oqo,Jhe,rqo,tqo,aqo,ft,OL,nqo,Yhe,sqo,lqo,rd,iqo,Khe,dqo,cqo,bV,fqo,mqo,gqo,Sb,hqo,oo,VL,pqo,Zhe,_qo,uqo,Da,bqo,epe,vqo,Fqo,ope,Tqo,Mqo,rpe,Eqo,Cqo,wqo,N,Rb,tpe,Aqo,Lqo,vV,yqo,xqo,$qo,Pb,ape,kqo,Sqo,FV,Rqo,Pqo,Bqo,Bb,npe,Iqo,Nqo,TV,qqo,jqo,Dqo,Ib,spe,Gqo,Oqo,MV,Vqo,Xqo,zqo,Nb,lpe,Wqo,Qqo,EV,Hqo,Uqo,Jqo,qb,ipe,Yqo,Kqo,CV,Zqo,ejo,ojo,jb,dpe,rjo,tjo,wV,ajo,njo,sjo,Db,cpe,ljo,ijo,AV,djo,cjo,fjo,Gb,fpe,mjo,gjo,LV,hjo,pjo,_jo,Ob,mpe,ujo,bjo,yV,vjo,Fjo,Tjo,Vb,gpe,Mjo,Ejo,xV,Cjo,wjo,Ajo,Xb,hpe,Ljo,yjo,$V,xjo,$jo,kjo,zb,ppe,Sjo,Rjo,kV,Pjo,Bjo,Ijo,Wb,_pe,Njo,qjo,SV,jjo,Djo,Gjo,Qb,upe,Ojo,Vjo,RV,Xjo,zjo,Wjo,Hb,bpe,Qjo,Hjo,PV,Ujo,Jjo,Yjo,Ub,vpe,Kjo,Zjo,BV,eDo,oDo,rDo,Jb,Fpe,tDo,aDo,IV,nDo,sDo,lDo,Yb,Tpe,iDo,dDo,NV,cDo,fDo,mDo,Kb,Mpe,gDo,hDo,qV,pDo,_Do,uDo,Zb,Epe,bDo,vDo,jV,FDo,TDo,MDo,ev,Cpe,EDo,CDo,DV,wDo,ADo,LDo,ov,wpe,yDo,xDo,GV,$Do,kDo,SDo,rv,Ape,RDo,PDo,OV,BDo,IDo,NDo,tv,Lpe,qDo,jDo,VV,DDo,GDo,ODo,av,ype,VDo,XDo,XV,zDo,WDo,QDo,nv,xpe,HDo,UDo,zV,JDo,YDo,KDo,sv,$pe,ZDo,eGo,WV,oGo,rGo,tGo,lv,kpe,aGo,nGo,QV,sGo,lGo,iGo,iv,Spe,dGo,cGo,HV,fGo,mGo,gGo,dv,Rpe,hGo,pGo,UV,_Go,uGo,bGo,cv,Ppe,vGo,FGo,JV,TGo,MGo,EGo,fv,Bpe,CGo,wGo,YV,AGo,LGo,yGo,mv,Ipe,xGo,$Go,KV,kGo,SGo,RGo,gv,Npe,PGo,BGo,ZV,IGo,NGo,qGo,hv,qpe,jGo,DGo,eX,GGo,OGo,VGo,pv,jpe,XGo,zGo,oX,WGo,QGo,HGo,_v,Dpe,UGo,JGo,rX,YGo,KGo,ZGo,uv,Gpe,eOo,oOo,tX,rOo,tOo,aOo,bv,Ope,nOo,sOo,aX,lOo,iOo,dOo,vv,Vpe,cOo,fOo,nX,mOo,gOo,hOo,Fv,Xpe,pOo,_Oo,sX,uOo,bOo,vOo,Tv,zpe,FOo,TOo,lX,MOo,EOo,COo,Mv,Wpe,wOo,AOo,iX,LOo,yOo,xOo,Ev,Qpe,$Oo,kOo,dX,SOo,ROo,POo,Cv,Hpe,BOo,IOo,cX,NOo,qOo,jOo,wv,Upe,DOo,GOo,fX,OOo,VOo,XOo,Av,Jpe,zOo,WOo,mX,QOo,HOo,UOo,Lv,Ype,JOo,YOo,gX,KOo,ZOo,eVo,yv,oVo,Kpe,rVo,tVo,Zpe,aVo,nVo,xv,fVe,td,$v,e_e,XL,sVo,o_e,lVo,mVe,Bo,zL,iVo,ad,dVo,hX,cVo,fVo,pX,mVo,gVo,hVo,WL,pVo,r_e,_Vo,uVo,bVo,mt,QL,vVo,t_e,FVo,TVo,nd,MVo,a_e,EVo,CVo,_X,wVo,AVo,LVo,kv,yVo,ro,HL,xVo,n_e,$Vo,kVo,Ga,SVo,s_e,RVo,PVo,l_e,BVo,IVo,i_e,NVo,qVo,jVo,Z,Sv,d_e,DVo,GVo,uX,OVo,VVo,XVo,Rv,c_e,zVo,WVo,bX,QVo,HVo,UVo,Pv,f_e,JVo,YVo,vX,KVo,ZVo,eXo,Bv,m_e,oXo,rXo,FX,tXo,aXo,nXo,Iv,g_e,sXo,lXo,TX,iXo,dXo,cXo,Nv,h_e,fXo,mXo,MX,gXo,hXo,pXo,qv,p_e,_Xo,uXo,EX,bXo,vXo,FXo,jv,__e,TXo,MXo,CX,EXo,CXo,wXo,Dv,u_e,AXo,LXo,wX,yXo,xXo,$Xo,Gv,b_e,kXo,SXo,AX,RXo,PXo,BXo,Ov,v_e,IXo,NXo,LX,qXo,jXo,DXo,Vv,F_e,GXo,OXo,yX,VXo,XXo,zXo,Xv,T_e,WXo,QXo,xX,HXo,UXo,JXo,zv,M_e,YXo,KXo,$X,ZXo,ezo,ozo,Wv,E_e,rzo,tzo,kX,azo,nzo,szo,Qv,C_e,lzo,izo,SX,dzo,czo,fzo,Hv,w_e,mzo,gzo,RX,hzo,pzo,_zo,Uv,A_e,uzo,bzo,PX,vzo,Fzo,Tzo,Jv,L_e,Mzo,Ezo,BX,Czo,wzo,Azo,Yv,y_e,Lzo,yzo,IX,xzo,$zo,kzo,Kv,x_e,Szo,Rzo,NX,Pzo,Bzo,Izo,Zv,$_e,Nzo,qzo,qX,jzo,Dzo,Gzo,e0,k_e,Ozo,Vzo,jX,Xzo,zzo,Wzo,o0,S_e,Qzo,Hzo,DX,Uzo,Jzo,Yzo,r0,R_e,Kzo,Zzo,GX,eWo,oWo,rWo,t0,P_e,tWo,aWo,OX,nWo,sWo,lWo,a0,B_e,iWo,dWo,VX,cWo,fWo,mWo,n0,I_e,gWo,hWo,XX,pWo,_Wo,uWo,s0,N_e,bWo,vWo,zX,FWo,TWo,MWo,l0,q_e,EWo,CWo,WX,wWo,AWo,LWo,i0,yWo,j_e,xWo,$Wo,D_e,kWo,SWo,d0,gVe,sd,c0,G_e,UL,RWo,O_e,PWo,hVe,Io,JL,BWo,ld,IWo,QX,NWo,qWo,HX,jWo,DWo,GWo,YL,OWo,V_e,VWo,XWo,zWo,gt,KL,WWo,X_e,QWo,HWo,id,UWo,z_e,JWo,YWo,UX,KWo,ZWo,eQo,f0,oQo,to,ZL,rQo,W_e,tQo,aQo,Oa,nQo,Q_e,sQo,lQo,H_e,iQo,dQo,U_e,cQo,fQo,mQo,No,m0,J_e,gQo,hQo,JX,pQo,_Qo,uQo,g0,Y_e,bQo,vQo,YX,FQo,TQo,MQo,h0,K_e,EQo,CQo,KX,wQo,AQo,LQo,p0,Z_e,yQo,xQo,ZX,$Qo,kQo,SQo,_0,eue,RQo,PQo,ez,BQo,IQo,NQo,u0,oue,qQo,jQo,oz,DQo,GQo,OQo,b0,VQo,rue,XQo,zQo,tue,WQo,QQo,v0,pVe,dd,F0,aue,ey,HQo,nue,UQo,_Ve,qo,oy,JQo,cd,YQo,rz,KQo,ZQo,tz,eHo,oHo,rHo,ry,tHo,sue,aHo,nHo,sHo,ht,ty,lHo,lue,iHo,dHo,fd,cHo,iue,fHo,mHo,az,gHo,hHo,pHo,T0,_Ho,ao,ay,uHo,due,bHo,vHo,Va,FHo,cue,THo,MHo,fue,EHo,CHo,mue,wHo,AHo,LHo,H,M0,gue,yHo,xHo,nz,$Ho,kHo,SHo,E0,hue,RHo,PHo,sz,BHo,IHo,NHo,C0,pue,qHo,jHo,lz,DHo,GHo,OHo,w0,_ue,VHo,XHo,iz,zHo,WHo,QHo,A0,uue,HHo,UHo,dz,JHo,YHo,KHo,L0,bue,ZHo,eUo,cz,oUo,rUo,tUo,y0,vue,aUo,nUo,fz,sUo,lUo,iUo,x0,Fue,dUo,cUo,mz,fUo,mUo,gUo,$0,Tue,hUo,pUo,gz,_Uo,uUo,bUo,k0,Mue,vUo,FUo,hz,TUo,MUo,EUo,S0,Eue,CUo,wUo,pz,AUo,LUo,yUo,R0,Cue,xUo,$Uo,_z,kUo,SUo,RUo,P0,wue,PUo,BUo,uz,IUo,NUo,qUo,B0,Aue,jUo,DUo,bz,GUo,OUo,VUo,I0,Lue,XUo,zUo,vz,WUo,QUo,HUo,N0,yue,UUo,JUo,Fz,YUo,KUo,ZUo,q0,xue,eJo,oJo,Tz,rJo,tJo,aJo,j0,$ue,nJo,sJo,Mz,lJo,iJo,dJo,D0,kue,cJo,fJo,Ez,mJo,gJo,hJo,G0,Sue,pJo,_Jo,Cz,uJo,bJo,vJo,O0,Rue,FJo,TJo,wz,MJo,EJo,CJo,V0,Pue,wJo,AJo,Az,LJo,yJo,xJo,X0,Bue,$Jo,kJo,Lz,SJo,RJo,PJo,z0,Iue,BJo,IJo,yz,NJo,qJo,jJo,W0,Nue,DJo,GJo,xz,OJo,VJo,XJo,Q0,que,zJo,WJo,$z,QJo,HJo,UJo,H0,jue,JJo,YJo,kz,KJo,ZJo,eYo,U0,Due,oYo,rYo,Sz,tYo,aYo,nYo,J0,Gue,sYo,lYo,Rz,iYo,dYo,cYo,Y0,Oue,fYo,mYo,Pz,gYo,hYo,pYo,K0,Vue,_Yo,uYo,Bz,bYo,vYo,FYo,Z0,Xue,TYo,MYo,Iz,EYo,CYo,wYo,eF,zue,AYo,LYo,Nz,yYo,xYo,$Yo,oF,Wue,kYo,SYo,qz,RYo,PYo,BYo,rF,Que,IYo,NYo,jz,qYo,jYo,DYo,tF,Hue,GYo,OYo,Dz,VYo,XYo,zYo,aF,WYo,Uue,QYo,HYo,Jue,UYo,JYo,nF,uVe,md,sF,Yue,ny,YYo,Kue,KYo,bVe,jo,sy,ZYo,gd,eKo,Gz,oKo,rKo,Oz,tKo,aKo,nKo,ly,sKo,Zue,lKo,iKo,dKo,pt,iy,cKo,e1e,fKo,mKo,hd,gKo,o1e,hKo,pKo,Vz,_Ko,uKo,bKo,lF,vKo,no,dy,FKo,r1e,TKo,MKo,Xa,EKo,t1e,CKo,wKo,a1e,AKo,LKo,n1e,yKo,xKo,$Ko,V,iF,s1e,kKo,SKo,Xz,RKo,PKo,BKo,dF,l1e,IKo,NKo,zz,qKo,jKo,DKo,cF,i1e,GKo,OKo,Wz,VKo,XKo,zKo,fF,d1e,WKo,QKo,Qz,HKo,UKo,JKo,mF,c1e,YKo,KKo,Hz,ZKo,eZo,oZo,gF,f1e,rZo,tZo,Uz,aZo,nZo,sZo,hF,m1e,lZo,iZo,Jz,dZo,cZo,fZo,pF,g1e,mZo,gZo,Yz,hZo,pZo,_Zo,_F,h1e,uZo,bZo,Kz,vZo,FZo,TZo,uF,p1e,MZo,EZo,Zz,CZo,wZo,AZo,bF,_1e,LZo,yZo,eW,xZo,$Zo,kZo,vF,u1e,SZo,RZo,oW,PZo,BZo,IZo,FF,b1e,NZo,qZo,rW,jZo,DZo,GZo,TF,v1e,OZo,VZo,tW,XZo,zZo,WZo,MF,F1e,QZo,HZo,aW,UZo,JZo,YZo,EF,T1e,KZo,ZZo,nW,eer,oer,rer,CF,M1e,ter,aer,sW,ner,ser,ler,wF,E1e,ier,der,lW,cer,fer,mer,AF,C1e,ger,her,iW,per,_er,uer,LF,w1e,ber,ver,dW,Fer,Ter,Mer,yF,A1e,Eer,Cer,cW,wer,Aer,Ler,xF,L1e,yer,xer,fW,$er,ker,Ser,$F,y1e,Rer,Per,mW,Ber,Ier,Ner,kF,x1e,qer,jer,gW,Der,Ger,Oer,SF,$1e,Ver,Xer,hW,zer,Wer,Qer,RF,k1e,Her,Uer,pW,Jer,Yer,Ker,PF,S1e,Zer,eor,_W,oor,ror,tor,BF,R1e,aor,nor,uW,sor,lor,ior,IF,P1e,dor,cor,bW,mor,gor,hor,NF,B1e,por,_or,vW,uor,bor,vor,qF,I1e,For,Tor,FW,Mor,Eor,Cor,jF,N1e,wor,Aor,TW,Lor,yor,xor,DF,q1e,$or,kor,MW,Sor,Ror,Por,GF,j1e,Bor,Ior,EW,Nor,qor,jor,OF,D1e,Dor,Gor,CW,Oor,Vor,Xor,VF,G1e,zor,Wor,wW,Qor,Hor,Uor,XF,O1e,Jor,Yor,AW,Kor,Zor,err,zF,V1e,orr,rrr,LW,trr,arr,nrr,WF,X1e,srr,lrr,yW,irr,drr,crr,QF,z1e,frr,mrr,xW,grr,hrr,prr,HF,W1e,_rr,urr,$W,brr,vrr,Frr,UF,Trr,Q1e,Mrr,Err,H1e,Crr,wrr,JF,vVe,pd,YF,U1e,cy,Arr,J1e,Lrr,FVe,Do,fy,yrr,_d,xrr,kW,$rr,krr,SW,Srr,Rrr,Prr,my,Brr,Y1e,Irr,Nrr,qrr,_t,gy,jrr,K1e,Drr,Grr,ud,Orr,Z1e,Vrr,Xrr,RW,zrr,Wrr,Qrr,KF,Hrr,so,hy,Urr,e2e,Jrr,Yrr,za,Krr,o2e,Zrr,etr,r2e,otr,rtr,t2e,ttr,atr,ntr,a2e,ZF,n2e,str,ltr,PW,itr,dtr,ctr,e6,ftr,s2e,mtr,gtr,l2e,htr,ptr,o6,TVe,bd,r6,i2e,py,_tr,d2e,utr,MVe,Go,_y,btr,vd,vtr,BW,Ftr,Ttr,IW,Mtr,Etr,Ctr,uy,wtr,c2e,Atr,Ltr,ytr,ut,by,xtr,f2e,$tr,ktr,Fd,Str,m2e,Rtr,Ptr,NW,Btr,Itr,Ntr,t6,qtr,lo,vy,jtr,g2e,Dtr,Gtr,Wa,Otr,h2e,Vtr,Xtr,p2e,ztr,Wtr,_2e,Qtr,Htr,Utr,Fe,a6,u2e,Jtr,Ytr,qW,Ktr,Ztr,ear,n6,b2e,oar,rar,jW,tar,aar,nar,s6,v2e,sar,lar,DW,iar,dar,car,l6,F2e,far,mar,GW,gar,har,par,Qs,T2e,_ar,uar,OW,bar,Far,VW,Tar,Mar,Ear,i6,M2e,Car,war,XW,Aar,Lar,yar,Hs,E2e,xar,$ar,zW,kar,Sar,WW,Rar,Par,Bar,bt,C2e,Iar,Nar,QW,qar,jar,HW,Dar,Gar,UW,Oar,Var,Xar,d6,w2e,zar,War,JW,Qar,Har,Uar,c6,A2e,Jar,Yar,YW,Kar,Zar,enr,f6,L2e,onr,rnr,KW,tnr,anr,nnr,m6,y2e,snr,lnr,ZW,inr,dnr,cnr,g6,x2e,fnr,mnr,eQ,gnr,hnr,pnr,h6,$2e,_nr,unr,oQ,bnr,vnr,Fnr,p6,k2e,Tnr,Mnr,rQ,Enr,Cnr,wnr,_6,Anr,S2e,Lnr,ynr,R2e,xnr,$nr,u6,EVe,Td,b6,P2e,Fy,knr,B2e,Snr,CVe,Oo,Ty,Rnr,Md,Pnr,tQ,Bnr,Inr,aQ,Nnr,qnr,jnr,My,Dnr,I2e,Gnr,Onr,Vnr,vt,Ey,Xnr,N2e,znr,Wnr,Ed,Qnr,q2e,Hnr,Unr,nQ,Jnr,Ynr,Knr,v6,Znr,io,Cy,esr,j2e,osr,rsr,Qa,tsr,D2e,asr,nsr,G2e,ssr,lsr,O2e,isr,dsr,csr,V2e,F6,X2e,fsr,msr,sQ,gsr,hsr,psr,T6,_sr,z2e,usr,bsr,W2e,vsr,Fsr,M6,wVe,Cd,E6,Q2e,wy,Tsr,H2e,Msr,AVe,Vo,Ay,Esr,wd,Csr,lQ,wsr,Asr,iQ,Lsr,ysr,xsr,Ly,$sr,U2e,ksr,Ssr,Rsr,Ft,yy,Psr,J2e,Bsr,Isr,Ad,Nsr,Y2e,qsr,jsr,dQ,Dsr,Gsr,Osr,C6,Vsr,co,xy,Xsr,K2e,zsr,Wsr,Ha,Qsr,Z2e,Hsr,Usr,ebe,Jsr,Ysr,obe,Ksr,Zsr,elr,rbe,w6,tbe,olr,rlr,cQ,tlr,alr,nlr,A6,slr,abe,llr,ilr,nbe,dlr,clr,L6,LVe,Ld,y6,sbe,$y,flr,lbe,mlr,yVe,Xo,ky,glr,yd,hlr,fQ,plr,_lr,mQ,ulr,blr,vlr,Sy,Flr,ibe,Tlr,Mlr,Elr,Tt,Ry,Clr,dbe,wlr,Alr,xd,Llr,cbe,ylr,xlr,gQ,$lr,klr,Slr,x6,Rlr,fo,Py,Plr,fbe,Blr,Ilr,Ua,Nlr,mbe,qlr,jlr,gbe,Dlr,Glr,hbe,Olr,Vlr,Xlr,Pe,$6,pbe,zlr,Wlr,hQ,Qlr,Hlr,Ulr,k6,_be,Jlr,Ylr,pQ,Klr,Zlr,eir,S6,ube,oir,rir,_Q,tir,air,nir,R6,bbe,sir,lir,uQ,iir,dir,cir,P6,vbe,fir,mir,bQ,gir,hir,pir,B6,Fbe,_ir,uir,vQ,bir,vir,Fir,I6,Tbe,Tir,Mir,FQ,Eir,Cir,wir,N6,Mbe,Air,Lir,TQ,yir,xir,$ir,q6,Ebe,kir,Sir,MQ,Rir,Pir,Bir,j6,Iir,Cbe,Nir,qir,wbe,jir,Dir,D6,xVe,$d,G6,Abe,By,Gir,Lbe,Oir,$Ve,zo,Iy,Vir,kd,Xir,EQ,zir,Wir,CQ,Qir,Hir,Uir,Ny,Jir,ybe,Yir,Kir,Zir,Mt,qy,edr,xbe,odr,rdr,Sd,tdr,$be,adr,ndr,wQ,sdr,ldr,idr,O6,ddr,mo,jy,cdr,kbe,fdr,mdr,Ja,gdr,Sbe,hdr,pdr,Rbe,_dr,udr,Pbe,bdr,vdr,Fdr,ot,V6,Bbe,Tdr,Mdr,AQ,Edr,Cdr,wdr,X6,Ibe,Adr,Ldr,LQ,ydr,xdr,$dr,z6,Nbe,kdr,Sdr,yQ,Rdr,Pdr,Bdr,W6,qbe,Idr,Ndr,xQ,qdr,jdr,Ddr,Q6,jbe,Gdr,Odr,$Q,Vdr,Xdr,zdr,H6,Wdr,Dbe,Qdr,Hdr,Gbe,Udr,Jdr,U6,kVe,Rd,J6,Obe,Dy,Ydr,Vbe,Kdr,SVe,Wo,Gy,Zdr,Pd,ecr,kQ,ocr,rcr,SQ,tcr,acr,ncr,Oy,scr,Xbe,lcr,icr,dcr,Et,Vy,ccr,zbe,fcr,mcr,Bd,gcr,Wbe,hcr,pcr,RQ,_cr,ucr,bcr,Y6,vcr,go,Xy,Fcr,Qbe,Tcr,Mcr,Ya,Ecr,Hbe,Ccr,wcr,Ube,Acr,Lcr,Jbe,ycr,xcr,$cr,Le,K6,Ybe,kcr,Scr,PQ,Rcr,Pcr,Bcr,Z6,Kbe,Icr,Ncr,BQ,qcr,jcr,Dcr,eT,Zbe,Gcr,Ocr,IQ,Vcr,Xcr,zcr,oT,eve,Wcr,Qcr,NQ,Hcr,Ucr,Jcr,rT,ove,Ycr,Kcr,qQ,Zcr,efr,ofr,tT,rve,rfr,tfr,jQ,afr,nfr,sfr,aT,tve,lfr,ifr,DQ,dfr,cfr,ffr,nT,ave,mfr,gfr,GQ,hfr,pfr,_fr,sT,nve,ufr,bfr,OQ,vfr,Ffr,Tfr,lT,sve,Mfr,Efr,VQ,Cfr,wfr,Afr,iT,Lfr,lve,yfr,xfr,ive,$fr,kfr,dT,RVe,Id,cT,dve,zy,Sfr,cve,Rfr,PVe,Qo,Wy,Pfr,Nd,Bfr,XQ,Ifr,Nfr,zQ,qfr,jfr,Dfr,Qy,Gfr,fve,Ofr,Vfr,Xfr,Ct,Hy,zfr,mve,Wfr,Qfr,qd,Hfr,gve,Ufr,Jfr,WQ,Yfr,Kfr,Zfr,fT,emr,ho,Uy,omr,hve,rmr,tmr,Ka,amr,pve,nmr,smr,_ve,lmr,imr,uve,dmr,cmr,fmr,Jy,mT,bve,mmr,gmr,QQ,hmr,pmr,_mr,gT,vve,umr,bmr,HQ,vmr,Fmr,Tmr,hT,Mmr,Fve,Emr,Cmr,Tve,wmr,Amr,pT,BVe,jd,_T,Mve,Yy,Lmr,Eve,ymr,IVe,Ho,Ky,xmr,Dd,$mr,UQ,kmr,Smr,JQ,Rmr,Pmr,Bmr,Zy,Imr,Cve,Nmr,qmr,jmr,wt,e9,Dmr,wve,Gmr,Omr,Gd,Vmr,Ave,Xmr,zmr,YQ,Wmr,Qmr,Hmr,uT,Umr,po,o9,Jmr,Lve,Ymr,Kmr,Za,Zmr,yve,egr,ogr,xve,rgr,tgr,$ve,agr,ngr,sgr,rt,bT,kve,lgr,igr,KQ,dgr,cgr,fgr,vT,Sve,mgr,ggr,ZQ,hgr,pgr,_gr,FT,Rve,ugr,bgr,eH,vgr,Fgr,Tgr,TT,Pve,Mgr,Egr,oH,Cgr,wgr,Agr,MT,Bve,Lgr,ygr,rH,xgr,$gr,kgr,ET,Sgr,Ive,Rgr,Pgr,Nve,Bgr,Igr,CT,NVe,Od,wT,qve,r9,Ngr,jve,qgr,qVe,Uo,t9,jgr,Vd,Dgr,tH,Ggr,Ogr,aH,Vgr,Xgr,zgr,a9,Wgr,Dve,Qgr,Hgr,Ugr,At,n9,Jgr,Gve,Ygr,Kgr,Xd,Zgr,Ove,ehr,ohr,nH,rhr,thr,ahr,AT,nhr,_o,s9,shr,Vve,lhr,ihr,en,dhr,Xve,chr,fhr,zve,mhr,ghr,Wve,hhr,phr,_hr,zd,LT,Qve,uhr,bhr,sH,vhr,Fhr,Thr,yT,Hve,Mhr,Ehr,lH,Chr,whr,Ahr,xT,Uve,Lhr,yhr,iH,xhr,$hr,khr,$T,Shr,Jve,Rhr,Phr,Yve,Bhr,Ihr,kT,jVe,Wd,ST,Kve,l9,Nhr,Zve,qhr,DVe,Jo,i9,jhr,Qd,Dhr,dH,Ghr,Ohr,cH,Vhr,Xhr,zhr,d9,Whr,e0e,Qhr,Hhr,Uhr,Lt,c9,Jhr,o0e,Yhr,Khr,Hd,Zhr,r0e,epr,opr,fH,rpr,tpr,apr,RT,npr,uo,f9,spr,t0e,lpr,ipr,on,dpr,a0e,cpr,fpr,n0e,mpr,gpr,s0e,hpr,ppr,_pr,m9,PT,l0e,upr,bpr,mH,vpr,Fpr,Tpr,BT,i0e,Mpr,Epr,gH,Cpr,wpr,Apr,IT,Lpr,d0e,ypr,xpr,c0e,$pr,kpr,NT,GVe,Ud,qT,f0e,g9,Spr,m0e,Rpr,OVe,Yo,h9,Ppr,Jd,Bpr,hH,Ipr,Npr,pH,qpr,jpr,Dpr,p9,Gpr,g0e,Opr,Vpr,Xpr,yt,_9,zpr,h0e,Wpr,Qpr,Yd,Hpr,p0e,Upr,Jpr,_H,Ypr,Kpr,Zpr,jT,e_r,bo,u9,o_r,_0e,r_r,t_r,rn,a_r,u0e,n_r,s_r,b0e,l_r,i_r,v0e,d_r,c_r,f_r,F0e,DT,T0e,m_r,g_r,uH,h_r,p_r,__r,GT,u_r,M0e,b_r,v_r,E0e,F_r,T_r,OT,VVe,Kd,VT,C0e,b9,M_r,w0e,E_r,XVe,Ko,v9,C_r,Zd,w_r,bH,A_r,L_r,vH,y_r,x_r,$_r,F9,k_r,A0e,S_r,R_r,P_r,xt,T9,B_r,L0e,I_r,N_r,ec,q_r,y0e,j_r,D_r,FH,G_r,O_r,V_r,XT,X_r,vo,M9,z_r,x0e,W_r,Q_r,tn,H_r,$0e,U_r,J_r,k0e,Y_r,K_r,S0e,Z_r,eur,our,an,zT,R0e,rur,tur,TH,aur,nur,sur,WT,P0e,lur,iur,MH,dur,cur,fur,QT,B0e,mur,gur,EH,hur,pur,_ur,HT,I0e,uur,bur,CH,vur,Fur,Tur,UT,Mur,N0e,Eur,Cur,q0e,wur,Aur,JT,zVe,oc,YT,j0e,E9,Lur,D0e,yur,WVe,Zo,C9,xur,rc,$ur,wH,kur,Sur,AH,Rur,Pur,Bur,w9,Iur,G0e,Nur,qur,jur,$t,A9,Dur,O0e,Gur,Our,tc,Vur,V0e,Xur,zur,LH,Wur,Qur,Hur,KT,Uur,Fo,L9,Jur,X0e,Yur,Kur,nn,Zur,z0e,e1r,o1r,W0e,r1r,t1r,Q0e,a1r,n1r,s1r,H0e,ZT,U0e,l1r,i1r,yH,d1r,c1r,f1r,e7,m1r,J0e,g1r,h1r,Y0e,p1r,_1r,o7,QVe,ac,r7,K0e,y9,u1r,Z0e,b1r,HVe,er,x9,v1r,nc,F1r,xH,T1r,M1r,$H,E1r,C1r,w1r,$9,A1r,eFe,L1r,y1r,x1r,kt,k9,$1r,oFe,k1r,S1r,sc,R1r,rFe,P1r,B1r,kH,I1r,N1r,q1r,t7,j1r,xr,S9,D1r,tFe,G1r,O1r,sn,V1r,aFe,X1r,z1r,nFe,W1r,Q1r,sFe,H1r,U1r,J1r,q,a7,lFe,Y1r,K1r,SH,Z1r,e2r,o2r,n7,iFe,r2r,t2r,RH,a2r,n2r,s2r,s7,dFe,l2r,i2r,PH,d2r,c2r,f2r,l7,cFe,m2r,g2r,BH,h2r,p2r,_2r,i7,fFe,u2r,b2r,IH,v2r,F2r,T2r,d7,mFe,M2r,E2r,NH,C2r,w2r,A2r,c7,gFe,L2r,y2r,qH,x2r,$2r,k2r,f7,hFe,S2r,R2r,jH,P2r,B2r,I2r,m7,pFe,N2r,q2r,DH,j2r,D2r,G2r,g7,_Fe,O2r,V2r,GH,X2r,z2r,W2r,h7,uFe,Q2r,H2r,OH,U2r,J2r,Y2r,p7,bFe,K2r,Z2r,VH,ebr,obr,rbr,_7,vFe,tbr,abr,XH,nbr,sbr,lbr,u7,FFe,ibr,dbr,zH,cbr,fbr,mbr,b7,TFe,gbr,hbr,WH,pbr,_br,ubr,v7,MFe,bbr,vbr,QH,Fbr,Tbr,Mbr,F7,EFe,Ebr,Cbr,HH,wbr,Abr,Lbr,T7,CFe,ybr,xbr,UH,$br,kbr,Sbr,Us,wFe,Rbr,Pbr,JH,Bbr,Ibr,YH,Nbr,qbr,jbr,M7,AFe,Dbr,Gbr,KH,Obr,Vbr,Xbr,E7,LFe,zbr,Wbr,ZH,Qbr,Hbr,Ubr,C7,yFe,Jbr,Ybr,eU,Kbr,Zbr,evr,w7,xFe,ovr,rvr,oU,tvr,avr,nvr,A7,$Fe,svr,lvr,rU,ivr,dvr,cvr,L7,kFe,fvr,mvr,tU,gvr,hvr,pvr,y7,SFe,_vr,uvr,aU,bvr,vvr,Fvr,x7,RFe,Tvr,Mvr,nU,Evr,Cvr,wvr,$7,PFe,Avr,Lvr,sU,yvr,xvr,$vr,k7,BFe,kvr,Svr,lU,Rvr,Pvr,Bvr,S7,IFe,Ivr,Nvr,iU,qvr,jvr,Dvr,R7,NFe,Gvr,Ovr,dU,Vvr,Xvr,zvr,P7,qFe,Wvr,Qvr,cU,Hvr,Uvr,Jvr,B7,jFe,Yvr,Kvr,fU,Zvr,e0r,o0r,I7,DFe,r0r,t0r,mU,a0r,n0r,s0r,N7,GFe,l0r,i0r,gU,d0r,c0r,f0r,q7,OFe,m0r,g0r,hU,h0r,p0r,_0r,j7,VFe,u0r,b0r,pU,v0r,F0r,T0r,D7,XFe,M0r,E0r,_U,C0r,w0r,A0r,G7,zFe,L0r,y0r,uU,x0r,$0r,k0r,O7,WFe,S0r,R0r,bU,P0r,B0r,I0r,V7,QFe,N0r,q0r,vU,j0r,D0r,G0r,X7,HFe,O0r,V0r,FU,X0r,z0r,W0r,z7,UFe,Q0r,H0r,TU,U0r,J0r,Y0r,W7,JFe,K0r,Z0r,MU,eFr,oFr,rFr,Q7,YFe,tFr,aFr,EU,nFr,sFr,lFr,H7,KFe,iFr,dFr,CU,cFr,fFr,mFr,U7,ZFe,gFr,hFr,wU,pFr,_Fr,uFr,J7,e6e,bFr,vFr,AU,FFr,TFr,MFr,Y7,o6e,EFr,CFr,LU,wFr,AFr,LFr,K7,UVe,lc,Z7,r6e,R9,yFr,t6e,xFr,JVe,or,P9,$Fr,ic,kFr,yU,SFr,RFr,xU,PFr,BFr,IFr,B9,NFr,a6e,qFr,jFr,DFr,St,I9,GFr,n6e,OFr,VFr,dc,XFr,s6e,zFr,WFr,$U,QFr,HFr,UFr,e8,JFr,$r,N9,YFr,l6e,KFr,ZFr,ln,e6r,i6e,o6r,r6r,d6e,t6r,a6r,c6e,n6r,s6r,l6r,se,o8,f6e,i6r,d6r,kU,c6r,f6r,m6r,r8,m6e,g6r,h6r,SU,p6r,_6r,u6r,t8,g6e,b6r,v6r,RU,F6r,T6r,M6r,a8,h6e,E6r,C6r,PU,w6r,A6r,L6r,n8,p6e,y6r,x6r,BU,$6r,k6r,S6r,s8,_6e,R6r,P6r,IU,B6r,I6r,N6r,l8,u6e,q6r,j6r,NU,D6r,G6r,O6r,i8,b6e,V6r,X6r,qU,z6r,W6r,Q6r,d8,v6e,H6r,U6r,jU,J6r,Y6r,K6r,c8,F6e,Z6r,eTr,DU,oTr,rTr,tTr,f8,T6e,aTr,nTr,GU,sTr,lTr,iTr,m8,M6e,dTr,cTr,OU,fTr,mTr,gTr,g8,E6e,hTr,pTr,VU,_Tr,uTr,bTr,h8,C6e,vTr,FTr,XU,TTr,MTr,ETr,p8,w6e,CTr,wTr,zU,ATr,LTr,yTr,_8,A6e,xTr,$Tr,WU,kTr,STr,RTr,u8,L6e,PTr,BTr,QU,ITr,NTr,qTr,b8,y6e,jTr,DTr,HU,GTr,OTr,VTr,v8,x6e,XTr,zTr,UU,WTr,QTr,HTr,F8,$6e,UTr,JTr,JU,YTr,KTr,ZTr,T8,k6e,e7r,o7r,YU,r7r,t7r,a7r,M8,S6e,n7r,s7r,KU,l7r,i7r,d7r,E8,R6e,c7r,f7r,ZU,m7r,g7r,h7r,C8,YVe,cc,w8,P6e,q9,p7r,B6e,_7r,KVe,rr,j9,u7r,fc,b7r,eJ,v7r,F7r,oJ,T7r,M7r,E7r,D9,C7r,I6e,w7r,A7r,L7r,Rt,G9,y7r,N6e,x7r,$7r,mc,k7r,q6e,S7r,R7r,rJ,P7r,B7r,I7r,A8,N7r,kr,O9,q7r,j6e,j7r,D7r,dn,G7r,D6e,O7r,V7r,G6e,X7r,z7r,O6e,W7r,Q7r,H7r,Me,L8,V6e,U7r,J7r,tJ,Y7r,K7r,Z7r,y8,X6e,e8r,o8r,aJ,r8r,t8r,a8r,x8,z6e,n8r,s8r,nJ,l8r,i8r,d8r,$8,W6e,c8r,f8r,sJ,m8r,g8r,h8r,k8,Q6e,p8r,_8r,lJ,u8r,b8r,v8r,S8,H6e,F8r,T8r,iJ,M8r,E8r,C8r,R8,U6e,w8r,A8r,dJ,L8r,y8r,x8r,P8,J6e,$8r,k8r,cJ,S8r,R8r,P8r,B8,Y6e,B8r,I8r,fJ,N8r,q8r,j8r,I8,K6e,D8r,G8r,mJ,O8r,V8r,X8r,N8,Z6e,z8r,W8r,gJ,Q8r,H8r,U8r,q8,eTe,J8r,Y8r,hJ,K8r,Z8r,eMr,j8,oTe,oMr,rMr,pJ,tMr,aMr,nMr,D8,ZVe,gc,G8,rTe,V9,sMr,tTe,lMr,eXe,tr,X9,iMr,hc,dMr,_J,cMr,fMr,uJ,mMr,gMr,hMr,z9,pMr,aTe,_Mr,uMr,bMr,Pt,W9,vMr,nTe,FMr,TMr,pc,MMr,sTe,EMr,CMr,bJ,wMr,AMr,LMr,O8,yMr,Sr,Q9,xMr,lTe,$Mr,kMr,cn,SMr,iTe,RMr,PMr,dTe,BMr,IMr,cTe,NMr,qMr,jMr,ar,V8,fTe,DMr,GMr,vJ,OMr,VMr,XMr,X8,mTe,zMr,WMr,FJ,QMr,HMr,UMr,Js,gTe,JMr,YMr,TJ,KMr,ZMr,MJ,e4r,o4r,r4r,z8,hTe,t4r,a4r,EJ,n4r,s4r,l4r,W8,pTe,i4r,d4r,CJ,c4r,f4r,m4r,Q8,_Te,g4r,h4r,wJ,p4r,_4r,u4r,H8,oXe,_c,U8,uTe,H9,b4r,bTe,v4r,rXe,nr,U9,F4r,uc,T4r,AJ,M4r,E4r,LJ,C4r,w4r,A4r,J9,L4r,vTe,y4r,x4r,$4r,Bt,Y9,k4r,FTe,S4r,R4r,bc,P4r,TTe,B4r,I4r,yJ,N4r,q4r,j4r,J8,D4r,Rr,K9,G4r,MTe,O4r,V4r,fn,X4r,ETe,z4r,W4r,CTe,Q4r,H4r,wTe,U4r,J4r,Y4r,ie,Y8,ATe,K4r,Z4r,xJ,eEr,oEr,rEr,K8,LTe,tEr,aEr,$J,nEr,sEr,lEr,Z8,yTe,iEr,dEr,kJ,cEr,fEr,mEr,eM,xTe,gEr,hEr,SJ,pEr,_Er,uEr,oM,$Te,bEr,vEr,RJ,FEr,TEr,MEr,rM,kTe,EEr,CEr,PJ,wEr,AEr,LEr,tM,STe,yEr,xEr,BJ,$Er,kEr,SEr,aM,RTe,REr,PEr,IJ,BEr,IEr,NEr,nM,PTe,qEr,jEr,NJ,DEr,GEr,OEr,sM,BTe,VEr,XEr,qJ,zEr,WEr,QEr,lM,ITe,HEr,UEr,jJ,JEr,YEr,KEr,iM,NTe,ZEr,eCr,DJ,oCr,rCr,tCr,dM,qTe,aCr,nCr,GJ,sCr,lCr,iCr,cM,jTe,dCr,cCr,OJ,fCr,mCr,gCr,fM,DTe,hCr,pCr,VJ,_Cr,uCr,bCr,mM,GTe,vCr,FCr,XJ,TCr,MCr,ECr,gM,OTe,CCr,wCr,zJ,ACr,LCr,yCr,hM,VTe,xCr,$Cr,WJ,kCr,SCr,RCr,pM,XTe,PCr,BCr,QJ,ICr,NCr,qCr,_M,zTe,jCr,DCr,HJ,GCr,OCr,VCr,uM,tXe,vc,bM,WTe,Z9,XCr,QTe,zCr,aXe,sr,ex,WCr,Fc,QCr,UJ,HCr,UCr,JJ,JCr,YCr,KCr,ox,ZCr,HTe,e3r,o3r,r3r,It,rx,t3r,UTe,a3r,n3r,Tc,s3r,JTe,l3r,i3r,YJ,d3r,c3r,f3r,vM,m3r,Pr,tx,g3r,YTe,h3r,p3r,mn,_3r,KTe,u3r,b3r,ZTe,v3r,F3r,e7e,T3r,M3r,E3r,ye,FM,o7e,C3r,w3r,KJ,A3r,L3r,y3r,TM,r7e,x3r,$3r,ZJ,k3r,S3r,R3r,MM,t7e,P3r,B3r,eY,I3r,N3r,q3r,EM,a7e,j3r,D3r,oY,G3r,O3r,V3r,CM,n7e,X3r,z3r,rY,W3r,Q3r,H3r,wM,s7e,U3r,J3r,tY,Y3r,K3r,Z3r,AM,l7e,e5r,o5r,aY,r5r,t5r,a5r,LM,i7e,n5r,s5r,nY,l5r,i5r,d5r,yM,d7e,c5r,f5r,sY,m5r,g5r,h5r,xM,c7e,p5r,_5r,lY,u5r,b5r,v5r,$M,nXe,Mc,kM,f7e,ax,F5r,m7e,T5r,sXe,lr,nx,M5r,Ec,E5r,iY,C5r,w5r,dY,A5r,L5r,y5r,sx,x5r,g7e,$5r,k5r,S5r,Nt,lx,R5r,h7e,P5r,B5r,Cc,I5r,p7e,N5r,q5r,cY,j5r,D5r,G5r,SM,O5r,Br,ix,V5r,_7e,X5r,z5r,gn,W5r,u7e,Q5r,H5r,b7e,U5r,J5r,v7e,Y5r,K5r,Z5r,te,RM,F7e,ewr,owr,fY,rwr,twr,awr,PM,T7e,nwr,swr,mY,lwr,iwr,dwr,BM,M7e,cwr,fwr,gY,mwr,gwr,hwr,IM,E7e,pwr,_wr,hY,uwr,bwr,vwr,NM,C7e,Fwr,Twr,pY,Mwr,Ewr,Cwr,qM,w7e,wwr,Awr,_Y,Lwr,ywr,xwr,jM,A7e,$wr,kwr,uY,Swr,Rwr,Pwr,DM,L7e,Bwr,Iwr,bY,Nwr,qwr,jwr,GM,y7e,Dwr,Gwr,vY,Owr,Vwr,Xwr,OM,x7e,zwr,Wwr,FY,Qwr,Hwr,Uwr,VM,$7e,Jwr,Ywr,TY,Kwr,Zwr,eAr,XM,k7e,oAr,rAr,MY,tAr,aAr,nAr,zM,S7e,sAr,lAr,EY,iAr,dAr,cAr,WM,R7e,fAr,mAr,CY,gAr,hAr,pAr,QM,P7e,_Ar,uAr,wY,bAr,vAr,FAr,HM,B7e,TAr,MAr,AY,EAr,CAr,wAr,UM,I7e,AAr,LAr,LY,yAr,xAr,$Ar,JM,N7e,kAr,SAr,yY,RAr,PAr,BAr,YM,q7e,IAr,NAr,xY,qAr,jAr,DAr,KM,j7e,GAr,OAr,$Y,VAr,XAr,zAr,ZM,D7e,WAr,QAr,kY,HAr,UAr,JAr,e4,G7e,YAr,KAr,SY,ZAr,eLr,oLr,o4,O7e,rLr,tLr,RY,aLr,nLr,sLr,r4,V7e,lLr,iLr,PY,dLr,cLr,fLr,t4,X7e,mLr,gLr,BY,hLr,pLr,_Lr,a4,z7e,uLr,bLr,IY,vLr,FLr,TLr,n4,lXe,wc,s4,W7e,dx,MLr,Q7e,ELr,iXe,ir,cx,CLr,Ac,wLr,NY,ALr,LLr,qY,yLr,xLr,$Lr,fx,kLr,H7e,SLr,RLr,PLr,qt,mx,BLr,U7e,ILr,NLr,Lc,qLr,J7e,jLr,DLr,jY,GLr,OLr,VLr,l4,XLr,Ir,gx,zLr,Y7e,WLr,QLr,hn,HLr,K7e,ULr,JLr,Z7e,YLr,KLr,e8e,ZLr,eyr,oyr,_e,i4,o8e,ryr,tyr,DY,ayr,nyr,syr,d4,r8e,lyr,iyr,GY,dyr,cyr,fyr,c4,t8e,myr,gyr,OY,hyr,pyr,_yr,f4,a8e,uyr,byr,VY,vyr,Fyr,Tyr,m4,n8e,Myr,Eyr,XY,Cyr,wyr,Ayr,g4,s8e,Lyr,yyr,zY,xyr,$yr,kyr,h4,l8e,Syr,Ryr,WY,Pyr,Byr,Iyr,p4,i8e,Nyr,qyr,QY,jyr,Dyr,Gyr,_4,d8e,Oyr,Vyr,HY,Xyr,zyr,Wyr,u4,c8e,Qyr,Hyr,UY,Uyr,Jyr,Yyr,b4,f8e,Kyr,Zyr,JY,e9r,o9r,r9r,v4,m8e,t9r,a9r,YY,n9r,s9r,l9r,F4,g8e,i9r,d9r,KY,c9r,f9r,m9r,T4,h8e,g9r,h9r,ZY,p9r,_9r,u9r,M4,p8e,b9r,v9r,eK,F9r,T9r,M9r,E4,_8e,E9r,C9r,oK,w9r,A9r,L9r,C4,u8e,y9r,x9r,rK,$9r,k9r,S9r,w4,dXe,yc,A4,b8e,hx,R9r,v8e,P9r,cXe,dr,px,B9r,xc,I9r,tK,N9r,q9r,aK,j9r,D9r,G9r,_x,O9r,F8e,V9r,X9r,z9r,jt,ux,W9r,T8e,Q9r,H9r,$c,U9r,M8e,J9r,Y9r,nK,K9r,Z9r,exr,L4,oxr,Nr,bx,rxr,E8e,txr,axr,pn,nxr,C8e,sxr,lxr,w8e,ixr,dxr,A8e,cxr,fxr,mxr,vx,y4,L8e,gxr,hxr,sK,pxr,_xr,uxr,x4,y8e,bxr,vxr,lK,Fxr,Txr,Mxr,$4,fXe,kc,k4,x8e,Fx,Exr,$8e,Cxr,mXe,cr,Tx,wxr,Sc,Axr,iK,Lxr,yxr,dK,xxr,$xr,kxr,Mx,Sxr,k8e,Rxr,Pxr,Bxr,Dt,Ex,Ixr,S8e,Nxr,qxr,Rc,jxr,R8e,Dxr,Gxr,cK,Oxr,Vxr,Xxr,S4,zxr,qr,Cx,Wxr,P8e,Qxr,Hxr,_n,Uxr,B8e,Jxr,Yxr,I8e,Kxr,Zxr,N8e,e$r,o$r,r$r,q8e,R4,j8e,t$r,a$r,fK,n$r,s$r,l$r,P4,gXe,Pc,B4,D8e,wx,i$r,G8e,d$r,hXe,fr,Ax,c$r,Bc,f$r,mK,m$r,g$r,gK,h$r,p$r,_$r,Lx,u$r,O8e,b$r,v$r,F$r,Gt,yx,T$r,V8e,M$r,E$r,Ic,C$r,X8e,w$r,A$r,hK,L$r,y$r,x$r,I4,$$r,jr,xx,k$r,z8e,S$r,R$r,un,P$r,W8e,B$r,I$r,Q8e,N$r,q$r,H8e,j$r,D$r,G$r,de,N4,U8e,O$r,V$r,pK,X$r,z$r,W$r,q4,J8e,Q$r,H$r,_K,U$r,J$r,Y$r,j4,Y8e,K$r,Z$r,uK,ekr,okr,rkr,D4,K8e,tkr,akr,bK,nkr,skr,lkr,G4,Z8e,ikr,dkr,vK,ckr,fkr,mkr,O4,eMe,gkr,hkr,FK,pkr,_kr,ukr,V4,oMe,bkr,vkr,TK,Fkr,Tkr,Mkr,X4,rMe,Ekr,Ckr,MK,wkr,Akr,Lkr,z4,tMe,ykr,xkr,EK,$kr,kkr,Skr,W4,aMe,Rkr,Pkr,CK,Bkr,Ikr,Nkr,Q4,nMe,qkr,jkr,wK,Dkr,Gkr,Okr,H4,sMe,Vkr,Xkr,AK,zkr,Wkr,Qkr,U4,lMe,Hkr,Ukr,LK,Jkr,Ykr,Kkr,J4,iMe,Zkr,eSr,yK,oSr,rSr,tSr,Y4,dMe,aSr,nSr,xK,sSr,lSr,iSr,K4,cMe,dSr,cSr,$K,fSr,mSr,gSr,Z4,fMe,hSr,pSr,kK,_Sr,uSr,bSr,eE,mMe,vSr,FSr,SK,TSr,MSr,ESr,oE,gMe,CSr,wSr,RK,ASr,LSr,ySr,rE,hMe,xSr,$Sr,PK,kSr,SSr,RSr,tE,pXe,Nc,aE,pMe,$x,PSr,_Me,BSr,_Xe,mr,kx,ISr,qc,NSr,BK,qSr,jSr,IK,DSr,GSr,OSr,Sx,VSr,uMe,XSr,zSr,WSr,Ot,Rx,QSr,bMe,HSr,USr,jc,JSr,vMe,YSr,KSr,NK,ZSr,eRr,oRr,nE,rRr,Dr,Px,tRr,FMe,aRr,nRr,bn,sRr,TMe,lRr,iRr,MMe,dRr,cRr,EMe,fRr,mRr,gRr,ce,sE,CMe,hRr,pRr,qK,_Rr,uRr,bRr,lE,wMe,vRr,FRr,jK,TRr,MRr,ERr,iE,AMe,CRr,wRr,DK,ARr,LRr,yRr,dE,LMe,xRr,$Rr,GK,kRr,SRr,RRr,cE,yMe,PRr,BRr,OK,IRr,NRr,qRr,fE,xMe,jRr,DRr,VK,GRr,ORr,VRr,mE,$Me,XRr,zRr,XK,WRr,QRr,HRr,gE,kMe,URr,JRr,zK,YRr,KRr,ZRr,hE,SMe,ePr,oPr,WK,rPr,tPr,aPr,pE,RMe,nPr,sPr,QK,lPr,iPr,dPr,_E,PMe,cPr,fPr,HK,mPr,gPr,hPr,uE,BMe,pPr,_Pr,UK,uPr,bPr,vPr,bE,IMe,FPr,TPr,JK,MPr,EPr,CPr,vE,NMe,wPr,APr,YK,LPr,yPr,xPr,FE,qMe,$Pr,kPr,KK,SPr,RPr,PPr,TE,jMe,BPr,IPr,ZK,NPr,qPr,jPr,ME,DMe,DPr,GPr,eZ,OPr,VPr,XPr,EE,GMe,zPr,WPr,oZ,QPr,HPr,UPr,CE,OMe,JPr,YPr,rZ,KPr,ZPr,eBr,wE,VMe,oBr,rBr,tZ,tBr,aBr,nBr,AE,uXe,Dc,LE,XMe,Bx,sBr,zMe,lBr,bXe,gr,Ix,iBr,Gc,dBr,aZ,cBr,fBr,nZ,mBr,gBr,hBr,Nx,pBr,WMe,_Br,uBr,bBr,Vt,qx,vBr,QMe,FBr,TBr,Oc,MBr,HMe,EBr,CBr,sZ,wBr,ABr,LBr,yE,yBr,Gr,jx,xBr,UMe,$Br,kBr,vn,SBr,JMe,RBr,PBr,YMe,BBr,IBr,KMe,NBr,qBr,jBr,ZMe,xE,e4e,DBr,GBr,lZ,OBr,VBr,XBr,$E,vXe,Vc,kE,o4e,Dx,zBr,r4e,WBr,FXe,hr,Gx,QBr,Xc,HBr,iZ,UBr,JBr,dZ,YBr,KBr,ZBr,Ox,eIr,t4e,oIr,rIr,tIr,Xt,Vx,aIr,a4e,nIr,sIr,zc,lIr,n4e,iIr,dIr,cZ,cIr,fIr,mIr,SE,gIr,Or,Xx,hIr,s4e,pIr,_Ir,Fn,uIr,l4e,bIr,vIr,i4e,FIr,TIr,d4e,MIr,EIr,CIr,c4e,RE,f4e,wIr,AIr,fZ,LIr,yIr,xIr,PE,TXe,Wc,BE,m4e,zx,$Ir,g4e,kIr,MXe,pr,Wx,SIr,Qc,RIr,mZ,PIr,BIr,gZ,IIr,NIr,qIr,Qx,jIr,h4e,DIr,GIr,OIr,zt,Hx,VIr,p4e,XIr,zIr,Hc,WIr,_4e,QIr,HIr,hZ,UIr,JIr,YIr,IE,KIr,Vr,Ux,ZIr,u4e,eNr,oNr,Tn,rNr,b4e,tNr,aNr,v4e,nNr,sNr,F4e,lNr,iNr,dNr,oe,NE,T4e,cNr,fNr,pZ,mNr,gNr,hNr,qE,M4e,pNr,_Nr,_Z,uNr,bNr,vNr,jE,E4e,FNr,TNr,uZ,MNr,ENr,CNr,DE,C4e,wNr,ANr,bZ,LNr,yNr,xNr,GE,w4e,$Nr,kNr,vZ,SNr,RNr,PNr,OE,A4e,BNr,INr,FZ,NNr,qNr,jNr,VE,L4e,DNr,GNr,TZ,ONr,VNr,XNr,XE,y4e,zNr,WNr,MZ,QNr,HNr,UNr,zE,x4e,JNr,YNr,EZ,KNr,ZNr,eqr,WE,$4e,oqr,rqr,CZ,tqr,aqr,nqr,QE,k4e,sqr,lqr,wZ,iqr,dqr,cqr,HE,S4e,fqr,mqr,AZ,gqr,hqr,pqr,UE,R4e,_qr,uqr,LZ,bqr,vqr,Fqr,JE,P4e,Tqr,Mqr,yZ,Eqr,Cqr,wqr,YE,B4e,Aqr,Lqr,xZ,yqr,xqr,$qr,KE,I4e,kqr,Sqr,$Z,Rqr,Pqr,Bqr,ZE,N4e,Iqr,Nqr,kZ,qqr,jqr,Dqr,eC,q4e,Gqr,Oqr,SZ,Vqr,Xqr,zqr,oC,j4e,Wqr,Qqr,RZ,Hqr,Uqr,Jqr,rC,D4e,Yqr,Kqr,PZ,Zqr,ejr,ojr,tC,G4e,rjr,tjr,BZ,ajr,njr,sjr,aC,O4e,ljr,ijr,IZ,djr,cjr,fjr,nC,V4e,mjr,gjr,NZ,hjr,pjr,_jr,sC,X4e,ujr,bjr,qZ,vjr,Fjr,Tjr,lC,z4e,Mjr,Ejr,jZ,Cjr,wjr,Ajr,iC,W4e,Ljr,yjr,DZ,xjr,$jr,kjr,dC,Q4e,Sjr,Rjr,GZ,Pjr,Bjr,Ijr,cC,EXe,Uc,fC,H4e,Jx,Njr,U4e,qjr,CXe,_r,Yx,jjr,Jc,Djr,OZ,Gjr,Ojr,VZ,Vjr,Xjr,zjr,Kx,Wjr,J4e,Qjr,Hjr,Ujr,Wt,Zx,Jjr,Y4e,Yjr,Kjr,Yc,Zjr,K4e,eDr,oDr,XZ,rDr,tDr,aDr,mC,nDr,Xr,e$,sDr,Z4e,lDr,iDr,Mn,dDr,eEe,cDr,fDr,oEe,mDr,gDr,rEe,hDr,pDr,_Dr,xe,gC,tEe,uDr,bDr,zZ,vDr,FDr,TDr,hC,aEe,MDr,EDr,WZ,CDr,wDr,ADr,pC,nEe,LDr,yDr,QZ,xDr,$Dr,kDr,_C,sEe,SDr,RDr,HZ,PDr,BDr,IDr,uC,lEe,NDr,qDr,UZ,jDr,DDr,GDr,bC,iEe,ODr,VDr,JZ,XDr,zDr,WDr,vC,dEe,QDr,HDr,YZ,UDr,JDr,YDr,FC,cEe,KDr,ZDr,KZ,eGr,oGr,rGr,TC,fEe,tGr,aGr,ZZ,nGr,sGr,lGr,MC,mEe,iGr,dGr,eee,cGr,fGr,mGr,EC,wXe,Kc,CC,gEe,o$,gGr,hEe,hGr,AXe,ur,r$,pGr,Zc,_Gr,oee,uGr,bGr,ree,vGr,FGr,TGr,t$,MGr,pEe,EGr,CGr,wGr,Qt,a$,AGr,_Ee,LGr,yGr,ef,xGr,uEe,$Gr,kGr,tee,SGr,RGr,PGr,wC,BGr,zr,n$,IGr,bEe,NGr,qGr,En,jGr,vEe,DGr,GGr,FEe,OGr,VGr,TEe,XGr,zGr,WGr,Ee,AC,MEe,QGr,HGr,aee,UGr,JGr,YGr,LC,EEe,KGr,ZGr,nee,eOr,oOr,rOr,yC,CEe,tOr,aOr,see,nOr,sOr,lOr,xC,wEe,iOr,dOr,lee,cOr,fOr,mOr,$C,AEe,gOr,hOr,iee,pOr,_Or,uOr,kC,LEe,bOr,vOr,dee,FOr,TOr,MOr,SC,yEe,EOr,COr,cee,wOr,AOr,LOr,RC,xEe,yOr,xOr,fee,$Or,kOr,SOr,PC,$Ee,ROr,POr,mee,BOr,IOr,NOr,BC,kEe,qOr,jOr,gee,DOr,GOr,OOr,IC,SEe,VOr,XOr,hee,zOr,WOr,QOr,NC,REe,HOr,UOr,pee,JOr,YOr,KOr,qC,PEe,ZOr,eVr,_ee,oVr,rVr,tVr,jC,LXe,of,DC,BEe,s$,aVr,IEe,nVr,yXe,br,l$,sVr,rf,lVr,uee,iVr,dVr,bee,cVr,fVr,mVr,i$,gVr,NEe,hVr,pVr,_Vr,Ht,d$,uVr,qEe,bVr,vVr,tf,FVr,jEe,TVr,MVr,vee,EVr,CVr,wVr,GC,AVr,Wr,c$,LVr,DEe,yVr,xVr,Cn,$Vr,GEe,kVr,SVr,OEe,RVr,PVr,VEe,BVr,IVr,NVr,$e,OC,XEe,qVr,jVr,Fee,DVr,GVr,OVr,VC,zEe,VVr,XVr,Tee,zVr,WVr,QVr,XC,WEe,HVr,UVr,Mee,JVr,YVr,KVr,zC,QEe,ZVr,eXr,Eee,oXr,rXr,tXr,WC,HEe,aXr,nXr,Cee,sXr,lXr,iXr,QC,UEe,dXr,cXr,wee,fXr,mXr,gXr,HC,JEe,hXr,pXr,Aee,_Xr,uXr,bXr,UC,YEe,vXr,FXr,Lee,TXr,MXr,EXr,JC,KEe,CXr,wXr,yee,AXr,LXr,yXr,YC,ZEe,xXr,$Xr,xee,kXr,SXr,RXr,KC,xXe,af,ZC,eCe,f$,PXr,oCe,BXr,$Xe,vr,m$,IXr,nf,NXr,$ee,qXr,jXr,kee,DXr,GXr,OXr,g$,VXr,rCe,XXr,zXr,WXr,Ut,h$,QXr,tCe,HXr,UXr,sf,JXr,aCe,YXr,KXr,See,ZXr,ezr,ozr,e3,rzr,Qr,p$,tzr,nCe,azr,nzr,wn,szr,sCe,lzr,izr,lCe,dzr,czr,iCe,fzr,mzr,gzr,ke,o3,dCe,hzr,pzr,Ree,_zr,uzr,bzr,r3,cCe,vzr,Fzr,Pee,Tzr,Mzr,Ezr,t3,fCe,Czr,wzr,Bee,Azr,Lzr,yzr,a3,mCe,xzr,$zr,Iee,kzr,Szr,Rzr,n3,gCe,Pzr,Bzr,Nee,Izr,Nzr,qzr,s3,hCe,jzr,Dzr,qee,Gzr,Ozr,Vzr,l3,pCe,Xzr,zzr,jee,Wzr,Qzr,Hzr,i3,_Ce,Uzr,Jzr,Dee,Yzr,Kzr,Zzr,d3,uCe,eWr,oWr,Gee,rWr,tWr,aWr,c3,bCe,nWr,sWr,Oee,lWr,iWr,dWr,f3,kXe,lf,m3,vCe,_$,cWr,FCe,fWr,SXe,Fr,u$,mWr,df,gWr,Vee,hWr,pWr,Xee,_Wr,uWr,bWr,b$,vWr,TCe,FWr,TWr,MWr,Jt,v$,EWr,MCe,CWr,wWr,cf,AWr,ECe,LWr,yWr,zee,xWr,$Wr,kWr,g3,SWr,Hr,F$,RWr,CCe,PWr,BWr,An,IWr,wCe,NWr,qWr,ACe,jWr,DWr,LCe,GWr,OWr,VWr,Se,h3,yCe,XWr,zWr,Wee,WWr,QWr,HWr,p3,xCe,UWr,JWr,Qee,YWr,KWr,ZWr,_3,$Ce,eQr,oQr,Hee,rQr,tQr,aQr,u3,kCe,nQr,sQr,Uee,lQr,iQr,dQr,b3,SCe,cQr,fQr,Jee,mQr,gQr,hQr,v3,RCe,pQr,_Qr,Yee,uQr,bQr,vQr,F3,PCe,FQr,TQr,Kee,MQr,EQr,CQr,T3,BCe,wQr,AQr,Zee,LQr,yQr,xQr,M3,ICe,$Qr,kQr,eoe,SQr,RQr,PQr,E3,NCe,BQr,IQr,ooe,NQr,qQr,jQr,C3,RXe,ff,w3,qCe,T$,DQr,jCe,GQr,PXe,Tr,M$,OQr,mf,VQr,roe,XQr,zQr,toe,WQr,QQr,HQr,E$,UQr,DCe,JQr,YQr,KQr,Yt,C$,ZQr,GCe,eHr,oHr,gf,rHr,OCe,tHr,aHr,aoe,nHr,sHr,lHr,A3,iHr,Ur,w$,dHr,VCe,cHr,fHr,Ln,mHr,XCe,gHr,hHr,zCe,pHr,_Hr,WCe,uHr,bHr,vHr,Re,L3,QCe,FHr,THr,noe,MHr,EHr,CHr,y3,HCe,wHr,AHr,soe,LHr,yHr,xHr,x3,UCe,$Hr,kHr,loe,SHr,RHr,PHr,$3,JCe,BHr,IHr,ioe,NHr,qHr,jHr,k3,YCe,DHr,GHr,doe,OHr,VHr,XHr,S3,KCe,zHr,WHr,coe,QHr,HHr,UHr,R3,ZCe,JHr,YHr,foe,KHr,ZHr,eUr,P3,e3e,oUr,rUr,moe,tUr,aUr,nUr,B3,o3e,sUr,lUr,goe,iUr,dUr,cUr,I3,r3e,fUr,mUr,hoe,gUr,hUr,pUr,N3,BXe,hf,q3,t3e,A$,_Ur,a3e,uUr,IXe,Mr,L$,bUr,pf,vUr,poe,FUr,TUr,_oe,MUr,EUr,CUr,y$,wUr,n3e,AUr,LUr,yUr,Kt,x$,xUr,s3e,$Ur,kUr,_f,SUr,l3e,RUr,PUr,uoe,BUr,IUr,NUr,j3,qUr,Jr,$$,jUr,i3e,DUr,GUr,yn,OUr,d3e,VUr,XUr,c3e,zUr,WUr,f3e,QUr,HUr,UUr,Ve,D3,m3e,JUr,YUr,boe,KUr,ZUr,eJr,G3,g3e,oJr,rJr,voe,tJr,aJr,nJr,O3,h3e,sJr,lJr,Foe,iJr,dJr,cJr,V3,p3e,fJr,mJr,Toe,gJr,hJr,pJr,X3,_3e,_Jr,uJr,Moe,bJr,vJr,FJr,z3,u3e,TJr,MJr,Eoe,EJr,CJr,wJr,W3,b3e,AJr,LJr,Coe,yJr,xJr,$Jr,Q3,v3e,kJr,SJr,woe,RJr,PJr,BJr,H3,NXe,uf,U3,F3e,k$,IJr,T3e,NJr,qXe,Er,S$,qJr,bf,jJr,Aoe,DJr,GJr,Loe,OJr,VJr,XJr,R$,zJr,M3e,WJr,QJr,HJr,Zt,P$,UJr,E3e,JJr,YJr,vf,KJr,C3e,ZJr,eYr,yoe,oYr,rYr,tYr,J3,aYr,Yr,B$,nYr,w3e,sYr,lYr,xn,iYr,A3e,dYr,cYr,L3e,fYr,mYr,y3e,gYr,hYr,pYr,Xe,Y3,x3e,_Yr,uYr,xoe,bYr,vYr,FYr,K3,$3e,TYr,MYr,$oe,EYr,CYr,wYr,Z3,k3e,AYr,LYr,koe,yYr,xYr,$Yr,e5,S3e,kYr,SYr,Soe,RYr,PYr,BYr,o5,R3e,IYr,NYr,Roe,qYr,jYr,DYr,r5,P3e,GYr,OYr,Poe,VYr,XYr,zYr,t5,B3e,WYr,QYr,Boe,HYr,UYr,JYr,a5,I3e,YYr,KYr,Ioe,ZYr,eKr,oKr,n5,jXe,Ff,s5,N3e,I$,rKr,q3e,tKr,DXe,Cr,N$,aKr,Tf,nKr,Noe,sKr,lKr,qoe,iKr,dKr,cKr,q$,fKr,j3e,mKr,gKr,hKr,ea,j$,pKr,D3e,_Kr,uKr,Mf,bKr,G3e,vKr,FKr,joe,TKr,MKr,EKr,l5,CKr,Kr,D$,wKr,O3e,AKr,LKr,$n,yKr,V3e,xKr,$Kr,X3e,kKr,SKr,z3e,RKr,PKr,BKr,W3e,i5,Q3e,IKr,NKr,Doe,qKr,jKr,DKr,d5,GXe,Ef,c5,H3e,G$,GKr,U3e,OKr,OXe,wr,O$,VKr,Cf,XKr,Goe,zKr,WKr,Ooe,QKr,HKr,UKr,V$,JKr,J3e,YKr,KKr,ZKr,oa,X$,eZr,Y3e,oZr,rZr,wf,tZr,K3e,aZr,nZr,Voe,sZr,lZr,iZr,f5,dZr,Zr,z$,cZr,Z3e,fZr,mZr,kn,gZr,e5e,hZr,pZr,o5e,_Zr,uZr,r5e,bZr,vZr,FZr,W$,m5,t5e,TZr,MZr,Xoe,EZr,CZr,wZr,g5,a5e,AZr,LZr,zoe,yZr,xZr,$Zr,h5,VXe,Af,p5,n5e,Q$,kZr,s5e,SZr,XXe,Ar,H$,RZr,Lf,PZr,Woe,BZr,IZr,Qoe,NZr,qZr,jZr,U$,DZr,l5e,GZr,OZr,VZr,ra,J$,XZr,i5e,zZr,WZr,yf,QZr,d5e,HZr,UZr,Hoe,JZr,YZr,KZr,_5,ZZr,et,Y$,eet,c5e,oet,ret,Sn,tet,f5e,aet,net,m5e,set,iet,g5e,det,cet,fet,h5e,u5,p5e,met,get,Uoe,het,pet,_et,b5,zXe;return d=new re({}),ka=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),OA=new re({}),VA=new P({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Nf=new uet({props:{warning:!0,$$slots:{default:[uVt]},$$scope:{ctx:$}}}),XA=new re({}),zA=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/configuration_auto.py#L604"}}),HA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/configuration_auto.py#L627"}}),Qg=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[bVt]},$$scope:{ctx:$}}}),UA=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/configuration_auto.py#L750"}}),JA=new re({}),YA=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/tokenization_auto.py#L402"}}),eL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17806/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/tokenization_auto.py#L416"}}),xh=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[vVt]},$$scope:{ctx:$}}}),oL=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/tokenization_auto.py#L615"}}),rL=new re({}),tL=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/feature_extraction_auto.py#L194"}}),sL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17806/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/feature_extraction_auto.py#L208"}}),fp=new uet({props:{$$slots:{default:[FVt]},$$scope:{ctx:$}}}),mp=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[TVt]},$$scope:{ctx:$}}}),lL=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/feature_extraction_auto.py#L335"}}),iL=new re({}),dL=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/processing_auto.py#L89"}}),mL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/processing_auto.py#L103"}}),Rp=new uet({props:{$$slots:{default:[MVt]},$$scope:{ctx:$}}}),Pp=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[EVt]},$$scope:{ctx:$}}}),gL=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/processing_auto.py#L256"}}),hL=new re({}),pL=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L771"}}),uL=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),Np=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[CVt]},$$scope:{ctx:$}}}),bL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),ju=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[wVt]},$$scope:{ctx:$}}}),vL=new re({}),FL=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L778"}}),ML=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),Gu=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[AVt]},$$scope:{ctx:$}}}),EL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),R1=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[LVt]},$$scope:{ctx:$}}}),CL=new re({}),wL=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L793"}}),LL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),B1=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[yVt]},$$scope:{ctx:$}}}),yL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),M2=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[xVt]},$$scope:{ctx:$}}}),xL=new re({}),$L=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L800"}}),SL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),C2=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[$Vt]},$$scope:{ctx:$}}}),RL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),db=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[kVt]},$$scope:{ctx:$}}}),PL=new re({}),BL=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L807"}}),NL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),fb=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[SVt]},$$scope:{ctx:$}}}),qL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),$b=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[RVt]},$$scope:{ctx:$}}}),jL=new re({}),DL=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L816"}}),OL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),Sb=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[PVt]},$$scope:{ctx:$}}}),VL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),xv=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[BVt]},$$scope:{ctx:$}}}),XL=new re({}),zL=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L861"}}),QL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),kv=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[IVt]},$$scope:{ctx:$}}}),HL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),d0=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[NVt]},$$scope:{ctx:$}}}),UL=new re({}),JL=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L868"}}),KL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),f0=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[qVt]},$$scope:{ctx:$}}}),ZL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),v0=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[jVt]},$$scope:{ctx:$}}}),ey=new re({}),oy=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L854"}}),ty=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),T0=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[DVt]},$$scope:{ctx:$}}}),ay=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),nF=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[GVt]},$$scope:{ctx:$}}}),ny=new re({}),sy=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L825"}}),iy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),lF=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[OVt]},$$scope:{ctx:$}}}),dy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),JF=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[VVt]},$$scope:{ctx:$}}}),cy=new re({}),fy=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L832"}}),gy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),KF=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[XVt]},$$scope:{ctx:$}}}),hy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),o6=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[zVt]},$$scope:{ctx:$}}}),py=new re({}),_y=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L877"}}),by=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17806/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/pr_17806/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17806/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17806/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),t6=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[WVt]},$$scope:{ctx:$}}}),vy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),u6=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[QVt]},$$scope:{ctx:$}}}),Fy=new re({}),Ty=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L916"}}),Ey=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),v6=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[HVt]},$$scope:{ctx:$}}}),Cy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),M6=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[UVt]},$$scope:{ctx:$}}}),wy=new re({}),Ay=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L843"}}),yy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),C6=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[JVt]},$$scope:{ctx:$}}}),xy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),L6=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[YVt]},$$scope:{ctx:$}}}),$y=new re({}),ky=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L923"}}),Ry=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),x6=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[KVt]},$$scope:{ctx:$}}}),Py=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),D6=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[ZVt]},$$scope:{ctx:$}}}),By=new re({}),Iy=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L946"}}),qy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),O6=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[eXt]},$$scope:{ctx:$}}}),jy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),U6=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[oXt]},$$scope:{ctx:$}}}),Dy=new re({}),Gy=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L930"}}),Vy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),Y6=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[rXt]},$$scope:{ctx:$}}}),Xy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),dT=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[tXt]},$$scope:{ctx:$}}}),zy=new re({}),Wy=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L937"}}),Hy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),fT=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[aXt]},$$scope:{ctx:$}}}),Uy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),pT=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[nXt]},$$scope:{ctx:$}}}),Yy=new re({}),Ky=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L955"}}),e9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),uT=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[sXt]},$$scope:{ctx:$}}}),o9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),CT=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[lXt]},$$scope:{ctx:$}}}),r9=new re({}),t9=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L962"}}),n9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),AT=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[iXt]},$$scope:{ctx:$}}}),s9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),kT=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[dXt]},$$scope:{ctx:$}}}),l9=new re({}),i9=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L909"}}),c9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),RT=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[cXt]},$$scope:{ctx:$}}}),f9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),NT=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[fXt]},$$scope:{ctx:$}}}),g9=new re({}),h9=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L884"}}),_9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),jT=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[mXt]},$$scope:{ctx:$}}}),u9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),OT=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[gXt]},$$scope:{ctx:$}}}),b9=new re({}),v9=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L891"}}),T9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),XT=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[hXt]},$$scope:{ctx:$}}}),M9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),JT=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[pXt]},$$scope:{ctx:$}}}),E9=new re({}),C9=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_auto.py#L900"}}),A9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),KT=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[_Xt]},$$scope:{ctx:$}}}),L9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),o7=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[uXt]},$$scope:{ctx:$}}}),y9=new re({}),x9=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_tf_auto.py#L411"}}),k9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),t7=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[bXt]},$$scope:{ctx:$}}}),S9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),K7=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[vXt]},$$scope:{ctx:$}}}),R9=new re({}),P9=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_tf_auto.py#L418"}}),I9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),e8=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[FXt]},$$scope:{ctx:$}}}),N9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),C8=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[TXt]},$$scope:{ctx:$}}}),q9=new re({}),j9=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_tf_auto.py#L433"}}),G9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),A8=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[MXt]},$$scope:{ctx:$}}}),O9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),D8=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[EXt]},$$scope:{ctx:$}}}),V9=new re({}),X9=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_tf_auto.py#L449"}}),W9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/pr_17806/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),O8=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[CXt]},$$scope:{ctx:$}}}),Q9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),H8=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[wXt]},$$scope:{ctx:$}}}),H9=new re({}),U9=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_tf_auto.py#L474"}}),Y9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),J8=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[AXt]},$$scope:{ctx:$}}}),K9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),uM=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[LXt]},$$scope:{ctx:$}}}),Z9=new re({}),ex=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_tf_auto.py#L481"}}),rx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),vM=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[yXt]},$$scope:{ctx:$}}}),tx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),$M=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[xXt]},$$scope:{ctx:$}}}),ax=new re({}),nx=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_tf_auto.py#L490"}}),lx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),SM=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[$Xt]},$$scope:{ctx:$}}}),ix=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),n4=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[kXt]},$$scope:{ctx:$}}}),dx=new re({}),cx=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_tf_auto.py#L526"}}),mx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),l4=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[SXt]},$$scope:{ctx:$}}}),gx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),w4=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[RXt]},$$scope:{ctx:$}}}),hx=new re({}),px=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_tf_auto.py#L533"}}),ux=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),L4=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[PXt]},$$scope:{ctx:$}}}),bx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),$4=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[BXt]},$$scope:{ctx:$}}}),Fx=new re({}),Tx=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_tf_auto.py#L506"}}),Ex=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),S4=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[IXt]},$$scope:{ctx:$}}}),Cx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),P4=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[NXt]},$$scope:{ctx:$}}}),wx=new re({}),Ax=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_tf_auto.py#L517"}}),yx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),I4=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[qXt]},$$scope:{ctx:$}}}),xx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),tE=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[jXt]},$$scope:{ctx:$}}}),$x=new re({}),kx=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_tf_auto.py#L499"}}),Rx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),nE=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[DXt]},$$scope:{ctx:$}}}),Px=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),AE=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[GXt]},$$scope:{ctx:$}}}),Bx=new re({}),Ix=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_tf_auto.py#L467"}}),qx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),yE=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[OXt]},$$scope:{ctx:$}}}),jx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),$E=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[VXt]},$$scope:{ctx:$}}}),Dx=new re({}),Gx=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_tf_auto.py#L542"}}),Vx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),SE=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[XXt]},$$scope:{ctx:$}}}),Xx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),PE=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[zXt]},$$scope:{ctx:$}}}),zx=new re({}),Wx=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),Hx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),IE=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[WXt]},$$scope:{ctx:$}}}),Ux=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),cC=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[QXt]},$$scope:{ctx:$}}}),Jx=new re({}),Yx=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),Zx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),mC=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[HXt]},$$scope:{ctx:$}}}),e$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),EC=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[UXt]},$$scope:{ctx:$}}}),o$=new re({}),r$=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),a$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),wC=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[JXt]},$$scope:{ctx:$}}}),n$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),jC=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[YXt]},$$scope:{ctx:$}}}),s$=new re({}),l$=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),d$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),GC=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[KXt]},$$scope:{ctx:$}}}),c$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),KC=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[ZXt]},$$scope:{ctx:$}}}),f$=new re({}),m$=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),h$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),e3=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[ezt]},$$scope:{ctx:$}}}),p$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),f3=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[ozt]},$$scope:{ctx:$}}}),_$=new re({}),u$=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),v$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),g3=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[rzt]},$$scope:{ctx:$}}}),F$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),C3=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[tzt]},$$scope:{ctx:$}}}),T$=new re({}),M$=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),C$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),A3=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[azt]},$$scope:{ctx:$}}}),w$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),N3=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[nzt]},$$scope:{ctx:$}}}),A$=new re({}),L$=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),x$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),j3=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[szt]},$$scope:{ctx:$}}}),$$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),H3=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[lzt]},$$scope:{ctx:$}}}),k$=new re({}),S$=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),P$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),J3=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[izt]},$$scope:{ctx:$}}}),B$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),n5=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[dzt]},$$scope:{ctx:$}}}),I$=new re({}),N$=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),j$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),l5=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[czt]},$$scope:{ctx:$}}}),D$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),d5=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[fzt]},$$scope:{ctx:$}}}),G$=new re({}),O$=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),X$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17806/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),f5=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[mzt]},$$scope:{ctx:$}}}),z$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),h5=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[gzt]},$$scope:{ctx:$}}}),Q$=new re({}),H$=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),J$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17806/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17806/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L389"}}),_5=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[hzt]},$$scope:{ctx:$}}}),Y$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17806/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17806/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17806/src/transformers/models/auto/auto_factory.py#L417"}}),b5=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[pzt]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),_=a("span"),F(d.$$.fragment),h=l(),Eo=a("span"),wi=o("Auto Classes"),Sf=l(),nt=a("p"),Ai=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Li=a("code"),qA=o("from_pretrained()"),Rf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Oe=l(),We=a("p"),yi=o("Instantiating one of "),Pn=a("a"),jA=o("AutoConfig"),Bn=o(", "),In=a("a"),DA=o("AutoModel"),xi=o(`, and
`),Nn=a("a"),GA=o("AutoTokenizer"),$i=o(" will directly create a class of the relevant architecture. For instance"),Pf=l(),F(ka.$$.fragment),Qe=l(),Ae=a("p"),bS=o("will create a model that is an instance of "),ki=a("a"),vS=o("BertModel"),FS=o("."),Co=l(),Sa=a("p"),TS=o("There is one class of "),Bf=a("code"),MS=o("AutoModel"),oQe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),DOe=l(),Si=a("h2"),If=a("a"),Xte=a("span"),F(OA.$$.fragment),rQe=l(),zte=a("span"),tQe=o("Extending the Auto Classes"),GOe=l(),qn=a("p"),aQe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Wte=a("code"),nQe=o("NewModel"),sQe=o(", make sure you have a "),Qte=a("code"),lQe=o("NewModelConfig"),iQe=o(` then you can add those to the auto
classes like this:`),OOe=l(),F(VA.$$.fragment),VOe=l(),ES=a("p"),dQe=o("You will then be able to use the auto classes like you would usually do!"),XOe=l(),F(Nf.$$.fragment),zOe=l(),Ri=a("h2"),qf=a("a"),Hte=a("span"),F(XA.$$.fragment),cQe=l(),Ute=a("span"),fQe=o("AutoConfig"),WOe=l(),wo=a("div"),F(zA.$$.fragment),mQe=l(),WA=a("p"),gQe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),CS=a("a"),hQe=o("from_pretrained()"),pQe=o(" class method."),_Qe=l(),QA=a("p"),uQe=o("This class cannot be instantiated directly using "),Jte=a("code"),bQe=o("__init__()"),vQe=o(" (throws an error)."),FQe=l(),Lr=a("div"),F(HA.$$.fragment),TQe=l(),Yte=a("p"),MQe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),EQe=l(),Pi=a("p"),CQe=o("The configuration class to instantiate is selected based on the "),Kte=a("code"),wQe=o("model_type"),AQe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Zte=a("code"),LQe=o("pretrained_model_name_or_path"),yQe=o(":"),xQe=l(),A=a("ul"),jf=a("li"),eae=a("strong"),$Qe=o("albert"),kQe=o(" \u2014 "),wS=a("a"),SQe=o("AlbertConfig"),RQe=o(" (ALBERT model)"),PQe=l(),Df=a("li"),oae=a("strong"),BQe=o("bart"),IQe=o(" \u2014 "),AS=a("a"),NQe=o("BartConfig"),qQe=o(" (BART model)"),jQe=l(),Gf=a("li"),rae=a("strong"),DQe=o("beit"),GQe=o(" \u2014 "),LS=a("a"),OQe=o("BeitConfig"),VQe=o(" (BEiT model)"),XQe=l(),Of=a("li"),tae=a("strong"),zQe=o("bert"),WQe=o(" \u2014 "),yS=a("a"),QQe=o("BertConfig"),HQe=o(" (BERT model)"),UQe=l(),Vf=a("li"),aae=a("strong"),JQe=o("bert-generation"),YQe=o(" \u2014 "),xS=a("a"),KQe=o("BertGenerationConfig"),ZQe=o(" (Bert Generation model)"),eHe=l(),Xf=a("li"),nae=a("strong"),oHe=o("big_bird"),rHe=o(" \u2014 "),$S=a("a"),tHe=o("BigBirdConfig"),aHe=o(" (BigBird model)"),nHe=l(),zf=a("li"),sae=a("strong"),sHe=o("bigbird_pegasus"),lHe=o(" \u2014 "),kS=a("a"),iHe=o("BigBirdPegasusConfig"),dHe=o(" (BigBird-Pegasus model)"),cHe=l(),Wf=a("li"),lae=a("strong"),fHe=o("blenderbot"),mHe=o(" \u2014 "),SS=a("a"),gHe=o("BlenderbotConfig"),hHe=o(" (Blenderbot model)"),pHe=l(),Qf=a("li"),iae=a("strong"),_He=o("blenderbot-small"),uHe=o(" \u2014 "),RS=a("a"),bHe=o("BlenderbotSmallConfig"),vHe=o(" (BlenderbotSmall model)"),FHe=l(),Hf=a("li"),dae=a("strong"),THe=o("bloom"),MHe=o(" \u2014 "),PS=a("a"),EHe=o("BloomConfig"),CHe=o(" (BLOOM model)"),wHe=l(),Uf=a("li"),cae=a("strong"),AHe=o("camembert"),LHe=o(" \u2014 "),BS=a("a"),yHe=o("CamembertConfig"),xHe=o(" (CamemBERT model)"),$He=l(),Jf=a("li"),fae=a("strong"),kHe=o("canine"),SHe=o(" \u2014 "),IS=a("a"),RHe=o("CanineConfig"),PHe=o(" (CANINE model)"),BHe=l(),Yf=a("li"),mae=a("strong"),IHe=o("clip"),NHe=o(" \u2014 "),NS=a("a"),qHe=o("CLIPConfig"),jHe=o(" (CLIP model)"),DHe=l(),Kf=a("li"),gae=a("strong"),GHe=o("codegen"),OHe=o(" \u2014 "),qS=a("a"),VHe=o("CodeGenConfig"),XHe=o(" (CodeGen model)"),zHe=l(),Zf=a("li"),hae=a("strong"),WHe=o("convbert"),QHe=o(" \u2014 "),jS=a("a"),HHe=o("ConvBertConfig"),UHe=o(" (ConvBERT model)"),JHe=l(),em=a("li"),pae=a("strong"),YHe=o("convnext"),KHe=o(" \u2014 "),DS=a("a"),ZHe=o("ConvNextConfig"),eUe=o(" (ConvNeXT model)"),oUe=l(),om=a("li"),_ae=a("strong"),rUe=o("ctrl"),tUe=o(" \u2014 "),GS=a("a"),aUe=o("CTRLConfig"),nUe=o(" (CTRL model)"),sUe=l(),rm=a("li"),uae=a("strong"),lUe=o("cvt"),iUe=o(" \u2014 "),OS=a("a"),dUe=o("CvtConfig"),cUe=o(" (CvT model)"),fUe=l(),tm=a("li"),bae=a("strong"),mUe=o("data2vec-audio"),gUe=o(" \u2014 "),VS=a("a"),hUe=o("Data2VecAudioConfig"),pUe=o(" (Data2VecAudio model)"),_Ue=l(),am=a("li"),vae=a("strong"),uUe=o("data2vec-text"),bUe=o(" \u2014 "),XS=a("a"),vUe=o("Data2VecTextConfig"),FUe=o(" (Data2VecText model)"),TUe=l(),nm=a("li"),Fae=a("strong"),MUe=o("data2vec-vision"),EUe=o(" \u2014 "),zS=a("a"),CUe=o("Data2VecVisionConfig"),wUe=o(" (Data2VecVision model)"),AUe=l(),sm=a("li"),Tae=a("strong"),LUe=o("deberta"),yUe=o(" \u2014 "),WS=a("a"),xUe=o("DebertaConfig"),$Ue=o(" (DeBERTa model)"),kUe=l(),lm=a("li"),Mae=a("strong"),SUe=o("deberta-v2"),RUe=o(" \u2014 "),QS=a("a"),PUe=o("DebertaV2Config"),BUe=o(" (DeBERTa-v2 model)"),IUe=l(),im=a("li"),Eae=a("strong"),NUe=o("decision_transformer"),qUe=o(" \u2014 "),HS=a("a"),jUe=o("DecisionTransformerConfig"),DUe=o(" (Decision Transformer model)"),GUe=l(),dm=a("li"),Cae=a("strong"),OUe=o("deit"),VUe=o(" \u2014 "),US=a("a"),XUe=o("DeiTConfig"),zUe=o(" (DeiT model)"),WUe=l(),cm=a("li"),wae=a("strong"),QUe=o("detr"),HUe=o(" \u2014 "),JS=a("a"),UUe=o("DetrConfig"),JUe=o(" (DETR model)"),YUe=l(),fm=a("li"),Aae=a("strong"),KUe=o("distilbert"),ZUe=o(" \u2014 "),YS=a("a"),eJe=o("DistilBertConfig"),oJe=o(" (DistilBERT model)"),rJe=l(),mm=a("li"),Lae=a("strong"),tJe=o("dpr"),aJe=o(" \u2014 "),KS=a("a"),nJe=o("DPRConfig"),sJe=o(" (DPR model)"),lJe=l(),gm=a("li"),yae=a("strong"),iJe=o("dpt"),dJe=o(" \u2014 "),ZS=a("a"),cJe=o("DPTConfig"),fJe=o(" (DPT model)"),mJe=l(),hm=a("li"),xae=a("strong"),gJe=o("electra"),hJe=o(" \u2014 "),eR=a("a"),pJe=o("ElectraConfig"),_Je=o(" (ELECTRA model)"),uJe=l(),pm=a("li"),$ae=a("strong"),bJe=o("encoder-decoder"),vJe=o(" \u2014 "),oR=a("a"),FJe=o("EncoderDecoderConfig"),TJe=o(" (Encoder decoder model)"),MJe=l(),_m=a("li"),kae=a("strong"),EJe=o("flaubert"),CJe=o(" \u2014 "),rR=a("a"),wJe=o("FlaubertConfig"),AJe=o(" (FlauBERT model)"),LJe=l(),um=a("li"),Sae=a("strong"),yJe=o("flava"),xJe=o(" \u2014 "),tR=a("a"),$Je=o("FlavaConfig"),kJe=o(" (FLAVA model)"),SJe=l(),bm=a("li"),Rae=a("strong"),RJe=o("fnet"),PJe=o(" \u2014 "),aR=a("a"),BJe=o("FNetConfig"),IJe=o(" (FNet model)"),NJe=l(),vm=a("li"),Pae=a("strong"),qJe=o("fsmt"),jJe=o(" \u2014 "),nR=a("a"),DJe=o("FSMTConfig"),GJe=o(" (FairSeq Machine-Translation model)"),OJe=l(),Fm=a("li"),Bae=a("strong"),VJe=o("funnel"),XJe=o(" \u2014 "),sR=a("a"),zJe=o("FunnelConfig"),WJe=o(" (Funnel Transformer model)"),QJe=l(),Tm=a("li"),Iae=a("strong"),HJe=o("glpn"),UJe=o(" \u2014 "),lR=a("a"),JJe=o("GLPNConfig"),YJe=o(" (GLPN model)"),KJe=l(),Mm=a("li"),Nae=a("strong"),ZJe=o("gpt2"),eYe=o(" \u2014 "),iR=a("a"),oYe=o("GPT2Config"),rYe=o(" (OpenAI GPT-2 model)"),tYe=l(),Em=a("li"),qae=a("strong"),aYe=o("gpt_neo"),nYe=o(" \u2014 "),dR=a("a"),sYe=o("GPTNeoConfig"),lYe=o(" (GPT Neo model)"),iYe=l(),Cm=a("li"),jae=a("strong"),dYe=o("gpt_neox"),cYe=o(" \u2014 "),cR=a("a"),fYe=o("GPTNeoXConfig"),mYe=o(" (GPT NeoX model)"),gYe=l(),wm=a("li"),Dae=a("strong"),hYe=o("gptj"),pYe=o(" \u2014 "),fR=a("a"),_Ye=o("GPTJConfig"),uYe=o(" (GPT-J model)"),bYe=l(),Am=a("li"),Gae=a("strong"),vYe=o("groupvit"),FYe=o(" \u2014 "),mR=a("a"),TYe=o("GroupViTConfig"),MYe=o(" (GroupViT model)"),EYe=l(),Lm=a("li"),Oae=a("strong"),CYe=o("hubert"),wYe=o(" \u2014 "),gR=a("a"),AYe=o("HubertConfig"),LYe=o(" (Hubert model)"),yYe=l(),ym=a("li"),Vae=a("strong"),xYe=o("ibert"),$Ye=o(" \u2014 "),hR=a("a"),kYe=o("IBertConfig"),SYe=o(" (I-BERT model)"),RYe=l(),xm=a("li"),Xae=a("strong"),PYe=o("imagegpt"),BYe=o(" \u2014 "),pR=a("a"),IYe=o("ImageGPTConfig"),NYe=o(" (ImageGPT model)"),qYe=l(),$m=a("li"),zae=a("strong"),jYe=o("layoutlm"),DYe=o(" \u2014 "),_R=a("a"),GYe=o("LayoutLMConfig"),OYe=o(" (LayoutLM model)"),VYe=l(),km=a("li"),Wae=a("strong"),XYe=o("layoutlmv2"),zYe=o(" \u2014 "),uR=a("a"),WYe=o("LayoutLMv2Config"),QYe=o(" (LayoutLMv2 model)"),HYe=l(),Sm=a("li"),Qae=a("strong"),UYe=o("layoutlmv3"),JYe=o(" \u2014 "),bR=a("a"),YYe=o("LayoutLMv3Config"),KYe=o(" (LayoutLMv3 model)"),ZYe=l(),Rm=a("li"),Hae=a("strong"),eKe=o("led"),oKe=o(" \u2014 "),vR=a("a"),rKe=o("LEDConfig"),tKe=o(" (LED model)"),aKe=l(),Pm=a("li"),Uae=a("strong"),nKe=o("levit"),sKe=o(" \u2014 "),FR=a("a"),lKe=o("LevitConfig"),iKe=o(" (LeViT model)"),dKe=l(),Bm=a("li"),Jae=a("strong"),cKe=o("longformer"),fKe=o(" \u2014 "),TR=a("a"),mKe=o("LongformerConfig"),gKe=o(" (Longformer model)"),hKe=l(),Im=a("li"),Yae=a("strong"),pKe=o("longt5"),_Ke=o(" \u2014 "),MR=a("a"),uKe=o("LongT5Config"),bKe=o(" (LongT5 model)"),vKe=l(),Nm=a("li"),Kae=a("strong"),FKe=o("luke"),TKe=o(" \u2014 "),ER=a("a"),MKe=o("LukeConfig"),EKe=o(" (LUKE model)"),CKe=l(),qm=a("li"),Zae=a("strong"),wKe=o("lxmert"),AKe=o(" \u2014 "),CR=a("a"),LKe=o("LxmertConfig"),yKe=o(" (LXMERT model)"),xKe=l(),jm=a("li"),ene=a("strong"),$Ke=o("m2m_100"),kKe=o(" \u2014 "),wR=a("a"),SKe=o("M2M100Config"),RKe=o(" (M2M100 model)"),PKe=l(),Dm=a("li"),one=a("strong"),BKe=o("marian"),IKe=o(" \u2014 "),AR=a("a"),NKe=o("MarianConfig"),qKe=o(" (Marian model)"),jKe=l(),Gm=a("li"),rne=a("strong"),DKe=o("maskformer"),GKe=o(" \u2014 "),LR=a("a"),OKe=o("MaskFormerConfig"),VKe=o(" (MaskFormer model)"),XKe=l(),Om=a("li"),tne=a("strong"),zKe=o("mbart"),WKe=o(" \u2014 "),yR=a("a"),QKe=o("MBartConfig"),HKe=o(" (mBART model)"),UKe=l(),Vm=a("li"),ane=a("strong"),JKe=o("mctct"),YKe=o(" \u2014 "),xR=a("a"),KKe=o("MCTCTConfig"),ZKe=o(" (M-CTC-T model)"),eZe=l(),Xm=a("li"),nne=a("strong"),oZe=o("megatron-bert"),rZe=o(" \u2014 "),$R=a("a"),tZe=o("MegatronBertConfig"),aZe=o(" (Megatron-BERT model)"),nZe=l(),zm=a("li"),sne=a("strong"),sZe=o("mobilebert"),lZe=o(" \u2014 "),kR=a("a"),iZe=o("MobileBertConfig"),dZe=o(" (MobileBERT model)"),cZe=l(),Wm=a("li"),lne=a("strong"),fZe=o("mpnet"),mZe=o(" \u2014 "),SR=a("a"),gZe=o("MPNetConfig"),hZe=o(" (MPNet model)"),pZe=l(),Qm=a("li"),ine=a("strong"),_Ze=o("mt5"),uZe=o(" \u2014 "),RR=a("a"),bZe=o("MT5Config"),vZe=o(" (MT5 model)"),FZe=l(),Hm=a("li"),dne=a("strong"),TZe=o("nezha"),MZe=o(" \u2014 "),PR=a("a"),EZe=o("NezhaConfig"),CZe=o(" (Nezha model)"),wZe=l(),Um=a("li"),cne=a("strong"),AZe=o("nystromformer"),LZe=o(" \u2014 "),BR=a("a"),yZe=o("NystromformerConfig"),xZe=o(" (Nystr\xF6mformer model)"),$Ze=l(),Jm=a("li"),fne=a("strong"),kZe=o("openai-gpt"),SZe=o(" \u2014 "),IR=a("a"),RZe=o("OpenAIGPTConfig"),PZe=o(" (OpenAI GPT model)"),BZe=l(),Ym=a("li"),mne=a("strong"),IZe=o("opt"),NZe=o(" \u2014 "),NR=a("a"),qZe=o("OPTConfig"),jZe=o(" (OPT model)"),DZe=l(),Km=a("li"),gne=a("strong"),GZe=o("pegasus"),OZe=o(" \u2014 "),qR=a("a"),VZe=o("PegasusConfig"),XZe=o(" (Pegasus model)"),zZe=l(),Zm=a("li"),hne=a("strong"),WZe=o("perceiver"),QZe=o(" \u2014 "),jR=a("a"),HZe=o("PerceiverConfig"),UZe=o(" (Perceiver model)"),JZe=l(),eg=a("li"),pne=a("strong"),YZe=o("plbart"),KZe=o(" \u2014 "),DR=a("a"),ZZe=o("PLBartConfig"),eeo=o(" (PLBart model)"),oeo=l(),og=a("li"),_ne=a("strong"),reo=o("poolformer"),teo=o(" \u2014 "),GR=a("a"),aeo=o("PoolFormerConfig"),neo=o(" (PoolFormer model)"),seo=l(),rg=a("li"),une=a("strong"),leo=o("prophetnet"),ieo=o(" \u2014 "),OR=a("a"),deo=o("ProphetNetConfig"),ceo=o(" (ProphetNet model)"),feo=l(),tg=a("li"),bne=a("strong"),meo=o("qdqbert"),geo=o(" \u2014 "),VR=a("a"),heo=o("QDQBertConfig"),peo=o(" (QDQBert model)"),_eo=l(),ag=a("li"),vne=a("strong"),ueo=o("rag"),beo=o(" \u2014 "),XR=a("a"),veo=o("RagConfig"),Feo=o(" (RAG model)"),Teo=l(),ng=a("li"),Fne=a("strong"),Meo=o("realm"),Eeo=o(" \u2014 "),zR=a("a"),Ceo=o("RealmConfig"),weo=o(" (REALM model)"),Aeo=l(),sg=a("li"),Tne=a("strong"),Leo=o("reformer"),yeo=o(" \u2014 "),WR=a("a"),xeo=o("ReformerConfig"),$eo=o(" (Reformer model)"),keo=l(),lg=a("li"),Mne=a("strong"),Seo=o("regnet"),Reo=o(" \u2014 "),QR=a("a"),Peo=o("RegNetConfig"),Beo=o(" (RegNet model)"),Ieo=l(),ig=a("li"),Ene=a("strong"),Neo=o("rembert"),qeo=o(" \u2014 "),HR=a("a"),jeo=o("RemBertConfig"),Deo=o(" (RemBERT model)"),Geo=l(),dg=a("li"),Cne=a("strong"),Oeo=o("resnet"),Veo=o(" \u2014 "),UR=a("a"),Xeo=o("ResNetConfig"),zeo=o(" (ResNet model)"),Weo=l(),cg=a("li"),wne=a("strong"),Qeo=o("retribert"),Heo=o(" \u2014 "),JR=a("a"),Ueo=o("RetriBertConfig"),Jeo=o(" (RetriBERT model)"),Yeo=l(),fg=a("li"),Ane=a("strong"),Keo=o("roberta"),Zeo=o(" \u2014 "),YR=a("a"),eoo=o("RobertaConfig"),ooo=o(" (RoBERTa model)"),roo=l(),mg=a("li"),Lne=a("strong"),too=o("roformer"),aoo=o(" \u2014 "),KR=a("a"),noo=o("RoFormerConfig"),soo=o(" (RoFormer model)"),loo=l(),gg=a("li"),yne=a("strong"),ioo=o("segformer"),doo=o(" \u2014 "),ZR=a("a"),coo=o("SegformerConfig"),foo=o(" (SegFormer model)"),moo=l(),hg=a("li"),xne=a("strong"),goo=o("sew"),hoo=o(" \u2014 "),eP=a("a"),poo=o("SEWConfig"),_oo=o(" (SEW model)"),uoo=l(),pg=a("li"),$ne=a("strong"),boo=o("sew-d"),voo=o(" \u2014 "),oP=a("a"),Foo=o("SEWDConfig"),Too=o(" (SEW-D model)"),Moo=l(),_g=a("li"),kne=a("strong"),Eoo=o("speech-encoder-decoder"),Coo=o(" \u2014 "),rP=a("a"),woo=o("SpeechEncoderDecoderConfig"),Aoo=o(" (Speech Encoder decoder model)"),Loo=l(),ug=a("li"),Sne=a("strong"),yoo=o("speech_to_text"),xoo=o(" \u2014 "),tP=a("a"),$oo=o("Speech2TextConfig"),koo=o(" (Speech2Text model)"),Soo=l(),bg=a("li"),Rne=a("strong"),Roo=o("speech_to_text_2"),Poo=o(" \u2014 "),aP=a("a"),Boo=o("Speech2Text2Config"),Ioo=o(" (Speech2Text2 model)"),Noo=l(),vg=a("li"),Pne=a("strong"),qoo=o("splinter"),joo=o(" \u2014 "),nP=a("a"),Doo=o("SplinterConfig"),Goo=o(" (Splinter model)"),Ooo=l(),Fg=a("li"),Bne=a("strong"),Voo=o("squeezebert"),Xoo=o(" \u2014 "),sP=a("a"),zoo=o("SqueezeBertConfig"),Woo=o(" (SqueezeBERT model)"),Qoo=l(),Tg=a("li"),Ine=a("strong"),Hoo=o("swin"),Uoo=o(" \u2014 "),lP=a("a"),Joo=o("SwinConfig"),Yoo=o(" (Swin Transformer model)"),Koo=l(),Mg=a("li"),Nne=a("strong"),Zoo=o("t5"),ero=o(" \u2014 "),iP=a("a"),oro=o("T5Config"),rro=o(" (T5 model)"),tro=l(),Eg=a("li"),qne=a("strong"),aro=o("tapas"),nro=o(" \u2014 "),dP=a("a"),sro=o("TapasConfig"),lro=o(" (TAPAS model)"),iro=l(),Cg=a("li"),jne=a("strong"),dro=o("trajectory_transformer"),cro=o(" \u2014 "),cP=a("a"),fro=o("TrajectoryTransformerConfig"),mro=o(" (Trajectory Transformer model)"),gro=l(),wg=a("li"),Dne=a("strong"),hro=o("transfo-xl"),pro=o(" \u2014 "),fP=a("a"),_ro=o("TransfoXLConfig"),uro=o(" (Transformer-XL model)"),bro=l(),Ag=a("li"),Gne=a("strong"),vro=o("trocr"),Fro=o(" \u2014 "),mP=a("a"),Tro=o("TrOCRConfig"),Mro=o(" (TrOCR model)"),Ero=l(),Lg=a("li"),One=a("strong"),Cro=o("unispeech"),wro=o(" \u2014 "),gP=a("a"),Aro=o("UniSpeechConfig"),Lro=o(" (UniSpeech model)"),yro=l(),yg=a("li"),Vne=a("strong"),xro=o("unispeech-sat"),$ro=o(" \u2014 "),hP=a("a"),kro=o("UniSpeechSatConfig"),Sro=o(" (UniSpeechSat model)"),Rro=l(),xg=a("li"),Xne=a("strong"),Pro=o("van"),Bro=o(" \u2014 "),pP=a("a"),Iro=o("VanConfig"),Nro=o(" (VAN model)"),qro=l(),$g=a("li"),zne=a("strong"),jro=o("vilt"),Dro=o(" \u2014 "),_P=a("a"),Gro=o("ViltConfig"),Oro=o(" (ViLT model)"),Vro=l(),kg=a("li"),Wne=a("strong"),Xro=o("vision-encoder-decoder"),zro=o(" \u2014 "),uP=a("a"),Wro=o("VisionEncoderDecoderConfig"),Qro=o(" (Vision Encoder decoder model)"),Hro=l(),Sg=a("li"),Qne=a("strong"),Uro=o("vision-text-dual-encoder"),Jro=o(" \u2014 "),bP=a("a"),Yro=o("VisionTextDualEncoderConfig"),Kro=o(" (VisionTextDualEncoder model)"),Zro=l(),Rg=a("li"),Hne=a("strong"),eto=o("visual_bert"),oto=o(" \u2014 "),vP=a("a"),rto=o("VisualBertConfig"),tto=o(" (VisualBERT model)"),ato=l(),Pg=a("li"),Une=a("strong"),nto=o("vit"),sto=o(" \u2014 "),FP=a("a"),lto=o("ViTConfig"),ito=o(" (ViT model)"),dto=l(),Bg=a("li"),Jne=a("strong"),cto=o("vit_mae"),fto=o(" \u2014 "),TP=a("a"),mto=o("ViTMAEConfig"),gto=o(" (ViTMAE model)"),hto=l(),Ig=a("li"),Yne=a("strong"),pto=o("wav2vec2"),_to=o(" \u2014 "),MP=a("a"),uto=o("Wav2Vec2Config"),bto=o(" (Wav2Vec2 model)"),vto=l(),Ng=a("li"),Kne=a("strong"),Fto=o("wav2vec2-conformer"),Tto=o(" \u2014 "),EP=a("a"),Mto=o("Wav2Vec2ConformerConfig"),Eto=o(" (Wav2Vec2-Conformer model)"),Cto=l(),qg=a("li"),Zne=a("strong"),wto=o("wavlm"),Ato=o(" \u2014 "),CP=a("a"),Lto=o("WavLMConfig"),yto=o(" (WavLM model)"),xto=l(),jg=a("li"),ese=a("strong"),$to=o("xglm"),kto=o(" \u2014 "),wP=a("a"),Sto=o("XGLMConfig"),Rto=o(" (XGLM model)"),Pto=l(),Dg=a("li"),ose=a("strong"),Bto=o("xlm"),Ito=o(" \u2014 "),AP=a("a"),Nto=o("XLMConfig"),qto=o(" (XLM model)"),jto=l(),Gg=a("li"),rse=a("strong"),Dto=o("xlm-prophetnet"),Gto=o(" \u2014 "),LP=a("a"),Oto=o("XLMProphetNetConfig"),Vto=o(" (XLM-ProphetNet model)"),Xto=l(),Og=a("li"),tse=a("strong"),zto=o("xlm-roberta"),Wto=o(" \u2014 "),yP=a("a"),Qto=o("XLMRobertaConfig"),Hto=o(" (XLM-RoBERTa model)"),Uto=l(),Vg=a("li"),ase=a("strong"),Jto=o("xlm-roberta-xl"),Yto=o(" \u2014 "),xP=a("a"),Kto=o("XLMRobertaXLConfig"),Zto=o(" (XLM-RoBERTa-XL model)"),eao=l(),Xg=a("li"),nse=a("strong"),oao=o("xlnet"),rao=o(" \u2014 "),$P=a("a"),tao=o("XLNetConfig"),aao=o(" (XLNet model)"),nao=l(),zg=a("li"),sse=a("strong"),sao=o("yolos"),lao=o(" \u2014 "),kP=a("a"),iao=o("YolosConfig"),dao=o(" (YOLOS model)"),cao=l(),Wg=a("li"),lse=a("strong"),fao=o("yoso"),mao=o(" \u2014 "),SP=a("a"),gao=o("YosoConfig"),hao=o(" (YOSO model)"),pao=l(),F(Qg.$$.fragment),_ao=l(),Hg=a("div"),F(UA.$$.fragment),uao=l(),ise=a("p"),bao=o("Register a new configuration for this class."),QOe=l(),Bi=a("h2"),Ug=a("a"),dse=a("span"),F(JA.$$.fragment),vao=l(),cse=a("span"),Fao=o("AutoTokenizer"),HOe=l(),Ao=a("div"),F(YA.$$.fragment),Tao=l(),KA=a("p"),Mao=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),RP=a("a"),Eao=o("AutoTokenizer.from_pretrained()"),Cao=o(" class method."),wao=l(),ZA=a("p"),Aao=o("This class cannot be instantiated directly using "),fse=a("code"),Lao=o("__init__()"),yao=o(" (throws an error)."),xao=l(),yr=a("div"),F(eL.$$.fragment),$ao=l(),mse=a("p"),kao=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Sao=l(),Ra=a("p"),Rao=o("The tokenizer class to instantiate is selected based on the "),gse=a("code"),Pao=o("model_type"),Bao=o(` property of the config object (either
passed as an argument or loaded from `),hse=a("code"),Iao=o("pretrained_model_name_or_path"),Nao=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pse=a("code"),qao=o("pretrained_model_name_or_path"),jao=o(":"),Dao=l(),k=a("ul"),jn=a("li"),_se=a("strong"),Gao=o("albert"),Oao=o(" \u2014 "),PP=a("a"),Vao=o("AlbertTokenizer"),Xao=o(" or "),BP=a("a"),zao=o("AlbertTokenizerFast"),Wao=o(" (ALBERT model)"),Qao=l(),Dn=a("li"),use=a("strong"),Hao=o("bart"),Uao=o(" \u2014 "),IP=a("a"),Jao=o("BartTokenizer"),Yao=o(" or "),NP=a("a"),Kao=o("BartTokenizerFast"),Zao=o(" (BART model)"),eno=l(),Gn=a("li"),bse=a("strong"),ono=o("barthez"),rno=o(" \u2014 "),qP=a("a"),tno=o("BarthezTokenizer"),ano=o(" or "),jP=a("a"),nno=o("BarthezTokenizerFast"),sno=o(" (BARThez model)"),lno=l(),Jg=a("li"),vse=a("strong"),ino=o("bartpho"),dno=o(" \u2014 "),DP=a("a"),cno=o("BartphoTokenizer"),fno=o(" (BARTpho model)"),mno=l(),On=a("li"),Fse=a("strong"),gno=o("bert"),hno=o(" \u2014 "),GP=a("a"),pno=o("BertTokenizer"),_no=o(" or "),OP=a("a"),uno=o("BertTokenizerFast"),bno=o(" (BERT model)"),vno=l(),Yg=a("li"),Tse=a("strong"),Fno=o("bert-generation"),Tno=o(" \u2014 "),VP=a("a"),Mno=o("BertGenerationTokenizer"),Eno=o(" (Bert Generation model)"),Cno=l(),Kg=a("li"),Mse=a("strong"),wno=o("bert-japanese"),Ano=o(" \u2014 "),XP=a("a"),Lno=o("BertJapaneseTokenizer"),yno=o(" (BertJapanese model)"),xno=l(),Zg=a("li"),Ese=a("strong"),$no=o("bertweet"),kno=o(" \u2014 "),zP=a("a"),Sno=o("BertweetTokenizer"),Rno=o(" (BERTweet model)"),Pno=l(),Vn=a("li"),Cse=a("strong"),Bno=o("big_bird"),Ino=o(" \u2014 "),WP=a("a"),Nno=o("BigBirdTokenizer"),qno=o(" or "),QP=a("a"),jno=o("BigBirdTokenizerFast"),Dno=o(" (BigBird model)"),Gno=l(),Xn=a("li"),wse=a("strong"),Ono=o("bigbird_pegasus"),Vno=o(" \u2014 "),HP=a("a"),Xno=o("PegasusTokenizer"),zno=o(" or "),UP=a("a"),Wno=o("PegasusTokenizerFast"),Qno=o(" (BigBird-Pegasus model)"),Hno=l(),zn=a("li"),Ase=a("strong"),Uno=o("blenderbot"),Jno=o(" \u2014 "),JP=a("a"),Yno=o("BlenderbotTokenizer"),Kno=o(" or "),YP=a("a"),Zno=o("BlenderbotTokenizerFast"),eso=o(" (Blenderbot model)"),oso=l(),eh=a("li"),Lse=a("strong"),rso=o("blenderbot-small"),tso=o(" \u2014 "),KP=a("a"),aso=o("BlenderbotSmallTokenizer"),nso=o(" (BlenderbotSmall model)"),sso=l(),oh=a("li"),yse=a("strong"),lso=o("bloom"),iso=o(" \u2014 "),ZP=a("a"),dso=o("BloomTokenizerFast"),cso=o(" (BLOOM model)"),fso=l(),rh=a("li"),xse=a("strong"),mso=o("byt5"),gso=o(" \u2014 "),eB=a("a"),hso=o("ByT5Tokenizer"),pso=o(" (ByT5 model)"),_so=l(),Wn=a("li"),$se=a("strong"),uso=o("camembert"),bso=o(" \u2014 "),oB=a("a"),vso=o("CamembertTokenizer"),Fso=o(" or "),rB=a("a"),Tso=o("CamembertTokenizerFast"),Mso=o(" (CamemBERT model)"),Eso=l(),th=a("li"),kse=a("strong"),Cso=o("canine"),wso=o(" \u2014 "),tB=a("a"),Aso=o("CanineTokenizer"),Lso=o(" (CANINE model)"),yso=l(),Qn=a("li"),Sse=a("strong"),xso=o("clip"),$so=o(" \u2014 "),aB=a("a"),kso=o("CLIPTokenizer"),Sso=o(" or "),nB=a("a"),Rso=o("CLIPTokenizerFast"),Pso=o(" (CLIP model)"),Bso=l(),Hn=a("li"),Rse=a("strong"),Iso=o("codegen"),Nso=o(" \u2014 "),sB=a("a"),qso=o("CodeGenTokenizer"),jso=o(" or "),lB=a("a"),Dso=o("CodeGenTokenizerFast"),Gso=o(" (CodeGen model)"),Oso=l(),Un=a("li"),Pse=a("strong"),Vso=o("convbert"),Xso=o(" \u2014 "),iB=a("a"),zso=o("ConvBertTokenizer"),Wso=o(" or "),dB=a("a"),Qso=o("ConvBertTokenizerFast"),Hso=o(" (ConvBERT model)"),Uso=l(),Jn=a("li"),Bse=a("strong"),Jso=o("cpm"),Yso=o(" \u2014 "),cB=a("a"),Kso=o("CpmTokenizer"),Zso=o(" or "),fB=a("a"),elo=o("CpmTokenizerFast"),olo=o(" (CPM model)"),rlo=l(),ah=a("li"),Ise=a("strong"),tlo=o("ctrl"),alo=o(" \u2014 "),mB=a("a"),nlo=o("CTRLTokenizer"),slo=o(" (CTRL model)"),llo=l(),Yn=a("li"),Nse=a("strong"),ilo=o("data2vec-text"),dlo=o(" \u2014 "),gB=a("a"),clo=o("RobertaTokenizer"),flo=o(" or "),hB=a("a"),mlo=o("RobertaTokenizerFast"),glo=o(" (Data2VecText model)"),hlo=l(),Kn=a("li"),qse=a("strong"),plo=o("deberta"),_lo=o(" \u2014 "),pB=a("a"),ulo=o("DebertaTokenizer"),blo=o(" or "),_B=a("a"),vlo=o("DebertaTokenizerFast"),Flo=o(" (DeBERTa model)"),Tlo=l(),Zn=a("li"),jse=a("strong"),Mlo=o("deberta-v2"),Elo=o(" \u2014 "),uB=a("a"),Clo=o("DebertaV2Tokenizer"),wlo=o(" or "),bB=a("a"),Alo=o("DebertaV2TokenizerFast"),Llo=o(" (DeBERTa-v2 model)"),ylo=l(),es=a("li"),Dse=a("strong"),xlo=o("distilbert"),$lo=o(" \u2014 "),vB=a("a"),klo=o("DistilBertTokenizer"),Slo=o(" or "),FB=a("a"),Rlo=o("DistilBertTokenizerFast"),Plo=o(" (DistilBERT model)"),Blo=l(),os=a("li"),Gse=a("strong"),Ilo=o("dpr"),Nlo=o(" \u2014 "),TB=a("a"),qlo=o("DPRQuestionEncoderTokenizer"),jlo=o(" or "),MB=a("a"),Dlo=o("DPRQuestionEncoderTokenizerFast"),Glo=o(" (DPR model)"),Olo=l(),rs=a("li"),Ose=a("strong"),Vlo=o("electra"),Xlo=o(" \u2014 "),EB=a("a"),zlo=o("ElectraTokenizer"),Wlo=o(" or "),CB=a("a"),Qlo=o("ElectraTokenizerFast"),Hlo=o(" (ELECTRA model)"),Ulo=l(),nh=a("li"),Vse=a("strong"),Jlo=o("flaubert"),Ylo=o(" \u2014 "),wB=a("a"),Klo=o("FlaubertTokenizer"),Zlo=o(" (FlauBERT model)"),eio=l(),ts=a("li"),Xse=a("strong"),oio=o("fnet"),rio=o(" \u2014 "),AB=a("a"),tio=o("FNetTokenizer"),aio=o(" or "),LB=a("a"),nio=o("FNetTokenizerFast"),sio=o(" (FNet model)"),lio=l(),sh=a("li"),zse=a("strong"),iio=o("fsmt"),dio=o(" \u2014 "),yB=a("a"),cio=o("FSMTTokenizer"),fio=o(" (FairSeq Machine-Translation model)"),mio=l(),as=a("li"),Wse=a("strong"),gio=o("funnel"),hio=o(" \u2014 "),xB=a("a"),pio=o("FunnelTokenizer"),_io=o(" or "),$B=a("a"),uio=o("FunnelTokenizerFast"),bio=o(" (Funnel Transformer model)"),vio=l(),ns=a("li"),Qse=a("strong"),Fio=o("gpt2"),Tio=o(" \u2014 "),kB=a("a"),Mio=o("GPT2Tokenizer"),Eio=o(" or "),SB=a("a"),Cio=o("GPT2TokenizerFast"),wio=o(" (OpenAI GPT-2 model)"),Aio=l(),ss=a("li"),Hse=a("strong"),Lio=o("gpt_neo"),yio=o(" \u2014 "),RB=a("a"),xio=o("GPT2Tokenizer"),$io=o(" or "),PB=a("a"),kio=o("GPT2TokenizerFast"),Sio=o(" (GPT Neo model)"),Rio=l(),lh=a("li"),Use=a("strong"),Pio=o("gpt_neox"),Bio=o(" \u2014 "),BB=a("a"),Iio=o("GPTNeoXTokenizerFast"),Nio=o(" (GPT NeoX model)"),qio=l(),ls=a("li"),Jse=a("strong"),jio=o("gptj"),Dio=o(" \u2014 "),IB=a("a"),Gio=o("GPT2Tokenizer"),Oio=o(" or "),NB=a("a"),Vio=o("GPT2TokenizerFast"),Xio=o(" (GPT-J model)"),zio=l(),is=a("li"),Yse=a("strong"),Wio=o("groupvit"),Qio=o(" \u2014 "),qB=a("a"),Hio=o("CLIPTokenizer"),Uio=o(" or "),jB=a("a"),Jio=o("CLIPTokenizerFast"),Yio=o(" (GroupViT model)"),Kio=l(),ds=a("li"),Kse=a("strong"),Zio=o("herbert"),edo=o(" \u2014 "),DB=a("a"),odo=o("HerbertTokenizer"),rdo=o(" or "),GB=a("a"),tdo=o("HerbertTokenizerFast"),ado=o(" (HerBERT model)"),ndo=l(),ih=a("li"),Zse=a("strong"),sdo=o("hubert"),ldo=o(" \u2014 "),OB=a("a"),ido=o("Wav2Vec2CTCTokenizer"),ddo=o(" (Hubert model)"),cdo=l(),cs=a("li"),ele=a("strong"),fdo=o("ibert"),mdo=o(" \u2014 "),VB=a("a"),gdo=o("RobertaTokenizer"),hdo=o(" or "),XB=a("a"),pdo=o("RobertaTokenizerFast"),_do=o(" (I-BERT model)"),udo=l(),fs=a("li"),ole=a("strong"),bdo=o("layoutlm"),vdo=o(" \u2014 "),zB=a("a"),Fdo=o("LayoutLMTokenizer"),Tdo=o(" or "),WB=a("a"),Mdo=o("LayoutLMTokenizerFast"),Edo=o(" (LayoutLM model)"),Cdo=l(),ms=a("li"),rle=a("strong"),wdo=o("layoutlmv2"),Ado=o(" \u2014 "),QB=a("a"),Ldo=o("LayoutLMv2Tokenizer"),ydo=o(" or "),HB=a("a"),xdo=o("LayoutLMv2TokenizerFast"),$do=o(" (LayoutLMv2 model)"),kdo=l(),gs=a("li"),tle=a("strong"),Sdo=o("layoutlmv3"),Rdo=o(" \u2014 "),UB=a("a"),Pdo=o("LayoutLMv3Tokenizer"),Bdo=o(" or "),JB=a("a"),Ido=o("LayoutLMv3TokenizerFast"),Ndo=o(" (LayoutLMv3 model)"),qdo=l(),hs=a("li"),ale=a("strong"),jdo=o("layoutxlm"),Ddo=o(" \u2014 "),YB=a("a"),Gdo=o("LayoutXLMTokenizer"),Odo=o(" or "),KB=a("a"),Vdo=o("LayoutXLMTokenizerFast"),Xdo=o(" (LayoutXLM model)"),zdo=l(),ps=a("li"),nle=a("strong"),Wdo=o("led"),Qdo=o(" \u2014 "),ZB=a("a"),Hdo=o("LEDTokenizer"),Udo=o(" or "),eI=a("a"),Jdo=o("LEDTokenizerFast"),Ydo=o(" (LED model)"),Kdo=l(),_s=a("li"),sle=a("strong"),Zdo=o("longformer"),eco=o(" \u2014 "),oI=a("a"),oco=o("LongformerTokenizer"),rco=o(" or "),rI=a("a"),tco=o("LongformerTokenizerFast"),aco=o(" (Longformer model)"),nco=l(),us=a("li"),lle=a("strong"),sco=o("longt5"),lco=o(" \u2014 "),tI=a("a"),ico=o("T5Tokenizer"),dco=o(" or "),aI=a("a"),cco=o("T5TokenizerFast"),fco=o(" (LongT5 model)"),mco=l(),dh=a("li"),ile=a("strong"),gco=o("luke"),hco=o(" \u2014 "),nI=a("a"),pco=o("LukeTokenizer"),_co=o(" (LUKE model)"),uco=l(),bs=a("li"),dle=a("strong"),bco=o("lxmert"),vco=o(" \u2014 "),sI=a("a"),Fco=o("LxmertTokenizer"),Tco=o(" or "),lI=a("a"),Mco=o("LxmertTokenizerFast"),Eco=o(" (LXMERT model)"),Cco=l(),ch=a("li"),cle=a("strong"),wco=o("m2m_100"),Aco=o(" \u2014 "),iI=a("a"),Lco=o("M2M100Tokenizer"),yco=o(" (M2M100 model)"),xco=l(),fh=a("li"),fle=a("strong"),$co=o("marian"),kco=o(" \u2014 "),dI=a("a"),Sco=o("MarianTokenizer"),Rco=o(" (Marian model)"),Pco=l(),vs=a("li"),mle=a("strong"),Bco=o("mbart"),Ico=o(" \u2014 "),cI=a("a"),Nco=o("MBartTokenizer"),qco=o(" or "),fI=a("a"),jco=o("MBartTokenizerFast"),Dco=o(" (mBART model)"),Gco=l(),Fs=a("li"),gle=a("strong"),Oco=o("mbart50"),Vco=o(" \u2014 "),mI=a("a"),Xco=o("MBart50Tokenizer"),zco=o(" or "),gI=a("a"),Wco=o("MBart50TokenizerFast"),Qco=o(" (mBART-50 model)"),Hco=l(),Ts=a("li"),hle=a("strong"),Uco=o("megatron-bert"),Jco=o(" \u2014 "),hI=a("a"),Yco=o("BertTokenizer"),Kco=o(" or "),pI=a("a"),Zco=o("BertTokenizerFast"),efo=o(" (Megatron-BERT model)"),ofo=l(),mh=a("li"),ple=a("strong"),rfo=o("mluke"),tfo=o(" \u2014 "),_I=a("a"),afo=o("MLukeTokenizer"),nfo=o(" (mLUKE model)"),sfo=l(),Ms=a("li"),_le=a("strong"),lfo=o("mobilebert"),ifo=o(" \u2014 "),uI=a("a"),dfo=o("MobileBertTokenizer"),cfo=o(" or "),bI=a("a"),ffo=o("MobileBertTokenizerFast"),mfo=o(" (MobileBERT model)"),gfo=l(),Es=a("li"),ule=a("strong"),hfo=o("mpnet"),pfo=o(" \u2014 "),vI=a("a"),_fo=o("MPNetTokenizer"),ufo=o(" or "),FI=a("a"),bfo=o("MPNetTokenizerFast"),vfo=o(" (MPNet model)"),Ffo=l(),Cs=a("li"),ble=a("strong"),Tfo=o("mt5"),Mfo=o(" \u2014 "),TI=a("a"),Efo=o("MT5Tokenizer"),Cfo=o(" or "),MI=a("a"),wfo=o("MT5TokenizerFast"),Afo=o(" (MT5 model)"),Lfo=l(),ws=a("li"),vle=a("strong"),yfo=o("nezha"),xfo=o(" \u2014 "),EI=a("a"),$fo=o("BertTokenizer"),kfo=o(" or "),CI=a("a"),Sfo=o("BertTokenizerFast"),Rfo=o(" (Nezha model)"),Pfo=l(),As=a("li"),Fle=a("strong"),Bfo=o("nystromformer"),Ifo=o(" \u2014 "),wI=a("a"),Nfo=o("AlbertTokenizer"),qfo=o(" or "),AI=a("a"),jfo=o("AlbertTokenizerFast"),Dfo=o(" (Nystr\xF6mformer model)"),Gfo=l(),Ls=a("li"),Tle=a("strong"),Ofo=o("openai-gpt"),Vfo=o(" \u2014 "),LI=a("a"),Xfo=o("OpenAIGPTTokenizer"),zfo=o(" or "),yI=a("a"),Wfo=o("OpenAIGPTTokenizerFast"),Qfo=o(" (OpenAI GPT model)"),Hfo=l(),gh=a("li"),Mle=a("strong"),Ufo=o("opt"),Jfo=o(" \u2014 "),xI=a("a"),Yfo=o("GPT2Tokenizer"),Kfo=o(" (OPT model)"),Zfo=l(),ys=a("li"),Ele=a("strong"),emo=o("pegasus"),omo=o(" \u2014 "),$I=a("a"),rmo=o("PegasusTokenizer"),tmo=o(" or "),kI=a("a"),amo=o("PegasusTokenizerFast"),nmo=o(" (Pegasus model)"),smo=l(),hh=a("li"),Cle=a("strong"),lmo=o("perceiver"),imo=o(" \u2014 "),SI=a("a"),dmo=o("PerceiverTokenizer"),cmo=o(" (Perceiver model)"),fmo=l(),ph=a("li"),wle=a("strong"),mmo=o("phobert"),gmo=o(" \u2014 "),RI=a("a"),hmo=o("PhobertTokenizer"),pmo=o(" (PhoBERT model)"),_mo=l(),_h=a("li"),Ale=a("strong"),umo=o("plbart"),bmo=o(" \u2014 "),PI=a("a"),vmo=o("PLBartTokenizer"),Fmo=o(" (PLBart model)"),Tmo=l(),uh=a("li"),Lle=a("strong"),Mmo=o("prophetnet"),Emo=o(" \u2014 "),BI=a("a"),Cmo=o("ProphetNetTokenizer"),wmo=o(" (ProphetNet model)"),Amo=l(),xs=a("li"),yle=a("strong"),Lmo=o("qdqbert"),ymo=o(" \u2014 "),II=a("a"),xmo=o("BertTokenizer"),$mo=o(" or "),NI=a("a"),kmo=o("BertTokenizerFast"),Smo=o(" (QDQBert model)"),Rmo=l(),bh=a("li"),xle=a("strong"),Pmo=o("rag"),Bmo=o(" \u2014 "),qI=a("a"),Imo=o("RagTokenizer"),Nmo=o(" (RAG model)"),qmo=l(),$s=a("li"),$le=a("strong"),jmo=o("realm"),Dmo=o(" \u2014 "),jI=a("a"),Gmo=o("RealmTokenizer"),Omo=o(" or "),DI=a("a"),Vmo=o("RealmTokenizerFast"),Xmo=o(" (REALM model)"),zmo=l(),ks=a("li"),kle=a("strong"),Wmo=o("reformer"),Qmo=o(" \u2014 "),GI=a("a"),Hmo=o("ReformerTokenizer"),Umo=o(" or "),OI=a("a"),Jmo=o("ReformerTokenizerFast"),Ymo=o(" (Reformer model)"),Kmo=l(),Ss=a("li"),Sle=a("strong"),Zmo=o("rembert"),ego=o(" \u2014 "),VI=a("a"),ogo=o("RemBertTokenizer"),rgo=o(" or "),XI=a("a"),tgo=o("RemBertTokenizerFast"),ago=o(" (RemBERT model)"),ngo=l(),Rs=a("li"),Rle=a("strong"),sgo=o("retribert"),lgo=o(" \u2014 "),zI=a("a"),igo=o("RetriBertTokenizer"),dgo=o(" or "),WI=a("a"),cgo=o("RetriBertTokenizerFast"),fgo=o(" (RetriBERT model)"),mgo=l(),Ps=a("li"),Ple=a("strong"),ggo=o("roberta"),hgo=o(" \u2014 "),QI=a("a"),pgo=o("RobertaTokenizer"),_go=o(" or "),HI=a("a"),ugo=o("RobertaTokenizerFast"),bgo=o(" (RoBERTa model)"),vgo=l(),Bs=a("li"),Ble=a("strong"),Fgo=o("roformer"),Tgo=o(" \u2014 "),UI=a("a"),Mgo=o("RoFormerTokenizer"),Ego=o(" or "),JI=a("a"),Cgo=o("RoFormerTokenizerFast"),wgo=o(" (RoFormer model)"),Ago=l(),vh=a("li"),Ile=a("strong"),Lgo=o("speech_to_text"),ygo=o(" \u2014 "),YI=a("a"),xgo=o("Speech2TextTokenizer"),$go=o(" (Speech2Text model)"),kgo=l(),Fh=a("li"),Nle=a("strong"),Sgo=o("speech_to_text_2"),Rgo=o(" \u2014 "),KI=a("a"),Pgo=o("Speech2Text2Tokenizer"),Bgo=o(" (Speech2Text2 model)"),Igo=l(),Is=a("li"),qle=a("strong"),Ngo=o("splinter"),qgo=o(" \u2014 "),ZI=a("a"),jgo=o("SplinterTokenizer"),Dgo=o(" or "),eN=a("a"),Ggo=o("SplinterTokenizerFast"),Ogo=o(" (Splinter model)"),Vgo=l(),Ns=a("li"),jle=a("strong"),Xgo=o("squeezebert"),zgo=o(" \u2014 "),oN=a("a"),Wgo=o("SqueezeBertTokenizer"),Qgo=o(" or "),rN=a("a"),Hgo=o("SqueezeBertTokenizerFast"),Ugo=o(" (SqueezeBERT model)"),Jgo=l(),qs=a("li"),Dle=a("strong"),Ygo=o("t5"),Kgo=o(" \u2014 "),tN=a("a"),Zgo=o("T5Tokenizer"),eho=o(" or "),aN=a("a"),oho=o("T5TokenizerFast"),rho=o(" (T5 model)"),tho=l(),Th=a("li"),Gle=a("strong"),aho=o("tapas"),nho=o(" \u2014 "),nN=a("a"),sho=o("TapasTokenizer"),lho=o(" (TAPAS model)"),iho=l(),Mh=a("li"),Ole=a("strong"),dho=o("tapex"),cho=o(" \u2014 "),sN=a("a"),fho=o("TapexTokenizer"),mho=o(" (TAPEX model)"),gho=l(),Eh=a("li"),Vle=a("strong"),hho=o("transfo-xl"),pho=o(" \u2014 "),lN=a("a"),_ho=o("TransfoXLTokenizer"),uho=o(" (Transformer-XL model)"),bho=l(),js=a("li"),Xle=a("strong"),vho=o("vilt"),Fho=o(" \u2014 "),iN=a("a"),Tho=o("BertTokenizer"),Mho=o(" or "),dN=a("a"),Eho=o("BertTokenizerFast"),Cho=o(" (ViLT model)"),who=l(),Ds=a("li"),zle=a("strong"),Aho=o("visual_bert"),Lho=o(" \u2014 "),cN=a("a"),yho=o("BertTokenizer"),xho=o(" or "),fN=a("a"),$ho=o("BertTokenizerFast"),kho=o(" (VisualBERT model)"),Sho=l(),Ch=a("li"),Wle=a("strong"),Rho=o("wav2vec2"),Pho=o(" \u2014 "),mN=a("a"),Bho=o("Wav2Vec2CTCTokenizer"),Iho=o(" (Wav2Vec2 model)"),Nho=l(),wh=a("li"),Qle=a("strong"),qho=o("wav2vec2-conformer"),jho=o(" \u2014 "),gN=a("a"),Dho=o("Wav2Vec2CTCTokenizer"),Gho=o(" (Wav2Vec2-Conformer model)"),Oho=l(),Ah=a("li"),Hle=a("strong"),Vho=o("wav2vec2_phoneme"),Xho=o(" \u2014 "),hN=a("a"),zho=o("Wav2Vec2PhonemeCTCTokenizer"),Who=o(" (Wav2Vec2Phoneme model)"),Qho=l(),Gs=a("li"),Ule=a("strong"),Hho=o("xglm"),Uho=o(" \u2014 "),pN=a("a"),Jho=o("XGLMTokenizer"),Yho=o(" or "),_N=a("a"),Kho=o("XGLMTokenizerFast"),Zho=o(" (XGLM model)"),epo=l(),Lh=a("li"),Jle=a("strong"),opo=o("xlm"),rpo=o(" \u2014 "),uN=a("a"),tpo=o("XLMTokenizer"),apo=o(" (XLM model)"),npo=l(),yh=a("li"),Yle=a("strong"),spo=o("xlm-prophetnet"),lpo=o(" \u2014 "),bN=a("a"),ipo=o("XLMProphetNetTokenizer"),dpo=o(" (XLM-ProphetNet model)"),cpo=l(),Os=a("li"),Kle=a("strong"),fpo=o("xlm-roberta"),mpo=o(" \u2014 "),vN=a("a"),gpo=o("XLMRobertaTokenizer"),hpo=o(" or "),FN=a("a"),ppo=o("XLMRobertaTokenizerFast"),_po=o(" (XLM-RoBERTa model)"),upo=l(),Vs=a("li"),Zle=a("strong"),bpo=o("xlm-roberta-xl"),vpo=o(" \u2014 "),TN=a("a"),Fpo=o("RobertaTokenizer"),Tpo=o(" or "),MN=a("a"),Mpo=o("RobertaTokenizerFast"),Epo=o(" (XLM-RoBERTa-XL model)"),Cpo=l(),Xs=a("li"),eie=a("strong"),wpo=o("xlnet"),Apo=o(" \u2014 "),EN=a("a"),Lpo=o("XLNetTokenizer"),ypo=o(" or "),CN=a("a"),xpo=o("XLNetTokenizerFast"),$po=o(" (XLNet model)"),kpo=l(),zs=a("li"),oie=a("strong"),Spo=o("yoso"),Rpo=o(" \u2014 "),wN=a("a"),Ppo=o("AlbertTokenizer"),Bpo=o(" or "),AN=a("a"),Ipo=o("AlbertTokenizerFast"),Npo=o(" (YOSO model)"),qpo=l(),F(xh.$$.fragment),jpo=l(),$h=a("div"),F(oL.$$.fragment),Dpo=l(),rie=a("p"),Gpo=o("Register a new tokenizer in this mapping."),UOe=l(),Ii=a("h2"),kh=a("a"),tie=a("span"),F(rL.$$.fragment),Opo=l(),aie=a("span"),Vpo=o("AutoFeatureExtractor"),JOe=l(),Lo=a("div"),F(tL.$$.fragment),Xpo=l(),aL=a("p"),zpo=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),LN=a("a"),Wpo=o("AutoFeatureExtractor.from_pretrained()"),Qpo=o(" class method."),Hpo=l(),nL=a("p"),Upo=o("This class cannot be instantiated directly using "),nie=a("code"),Jpo=o("__init__()"),Ypo=o(" (throws an error)."),Kpo=l(),He=a("div"),F(sL.$$.fragment),Zpo=l(),sie=a("p"),e_o=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),o_o=l(),Pa=a("p"),r_o=o("The feature extractor class to instantiate is selected based on the "),lie=a("code"),t_o=o("model_type"),a_o=o(` property of the config object
(either passed as an argument or loaded from `),iie=a("code"),n_o=o("pretrained_model_name_or_path"),s_o=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),die=a("code"),l_o=o("pretrained_model_name_or_path"),i_o=o(":"),d_o=l(),Y=a("ul"),Sh=a("li"),cie=a("strong"),c_o=o("beit"),f_o=o(" \u2014 "),yN=a("a"),m_o=o("BeitFeatureExtractor"),g_o=o(" (BEiT model)"),h_o=l(),Rh=a("li"),fie=a("strong"),p_o=o("clip"),__o=o(" \u2014 "),xN=a("a"),u_o=o("CLIPFeatureExtractor"),b_o=o(" (CLIP model)"),v_o=l(),Ph=a("li"),mie=a("strong"),F_o=o("convnext"),T_o=o(" \u2014 "),$N=a("a"),M_o=o("ConvNextFeatureExtractor"),E_o=o(" (ConvNeXT model)"),C_o=l(),Bh=a("li"),gie=a("strong"),w_o=o("cvt"),A_o=o(" \u2014 "),kN=a("a"),L_o=o("ConvNextFeatureExtractor"),y_o=o(" (CvT model)"),x_o=l(),Ih=a("li"),hie=a("strong"),$_o=o("data2vec-audio"),k_o=o(" \u2014 "),SN=a("a"),S_o=o("Wav2Vec2FeatureExtractor"),R_o=o(" (Data2VecAudio model)"),P_o=l(),Nh=a("li"),pie=a("strong"),B_o=o("data2vec-vision"),I_o=o(" \u2014 "),RN=a("a"),N_o=o("BeitFeatureExtractor"),q_o=o(" (Data2VecVision model)"),j_o=l(),qh=a("li"),_ie=a("strong"),D_o=o("deit"),G_o=o(" \u2014 "),PN=a("a"),O_o=o("DeiTFeatureExtractor"),V_o=o(" (DeiT model)"),X_o=l(),jh=a("li"),uie=a("strong"),z_o=o("detr"),W_o=o(" \u2014 "),BN=a("a"),Q_o=o("DetrFeatureExtractor"),H_o=o(" (DETR model)"),U_o=l(),Dh=a("li"),bie=a("strong"),J_o=o("dpt"),Y_o=o(" \u2014 "),IN=a("a"),K_o=o("DPTFeatureExtractor"),Z_o=o(" (DPT model)"),euo=l(),Gh=a("li"),vie=a("strong"),ouo=o("flava"),ruo=o(" \u2014 "),NN=a("a"),tuo=o("FlavaFeatureExtractor"),auo=o(" (FLAVA model)"),nuo=l(),Oh=a("li"),Fie=a("strong"),suo=o("glpn"),luo=o(" \u2014 "),qN=a("a"),iuo=o("GLPNFeatureExtractor"),duo=o(" (GLPN model)"),cuo=l(),Vh=a("li"),Tie=a("strong"),fuo=o("groupvit"),muo=o(" \u2014 "),jN=a("a"),guo=o("CLIPFeatureExtractor"),huo=o(" (GroupViT model)"),puo=l(),Xh=a("li"),Mie=a("strong"),_uo=o("hubert"),uuo=o(" \u2014 "),DN=a("a"),buo=o("Wav2Vec2FeatureExtractor"),vuo=o(" (Hubert model)"),Fuo=l(),zh=a("li"),Eie=a("strong"),Tuo=o("imagegpt"),Muo=o(" \u2014 "),GN=a("a"),Euo=o("ImageGPTFeatureExtractor"),Cuo=o(" (ImageGPT model)"),wuo=l(),Wh=a("li"),Cie=a("strong"),Auo=o("layoutlmv2"),Luo=o(" \u2014 "),ON=a("a"),yuo=o("LayoutLMv2FeatureExtractor"),xuo=o(" (LayoutLMv2 model)"),$uo=l(),Qh=a("li"),wie=a("strong"),kuo=o("layoutlmv3"),Suo=o(" \u2014 "),VN=a("a"),Ruo=o("LayoutLMv3FeatureExtractor"),Puo=o(" (LayoutLMv3 model)"),Buo=l(),Hh=a("li"),Aie=a("strong"),Iuo=o("levit"),Nuo=o(" \u2014 "),XN=a("a"),quo=o("LevitFeatureExtractor"),juo=o(" (LeViT model)"),Duo=l(),Uh=a("li"),Lie=a("strong"),Guo=o("maskformer"),Ouo=o(" \u2014 "),zN=a("a"),Vuo=o("MaskFormerFeatureExtractor"),Xuo=o(" (MaskFormer model)"),zuo=l(),Jh=a("li"),yie=a("strong"),Wuo=o("mctct"),Quo=o(" \u2014 "),WN=a("a"),Huo=o("MCTCTFeatureExtractor"),Uuo=o(" (M-CTC-T model)"),Juo=l(),Yh=a("li"),xie=a("strong"),Yuo=o("perceiver"),Kuo=o(" \u2014 "),QN=a("a"),Zuo=o("PerceiverFeatureExtractor"),e1o=o(" (Perceiver model)"),o1o=l(),Kh=a("li"),$ie=a("strong"),r1o=o("poolformer"),t1o=o(" \u2014 "),HN=a("a"),a1o=o("PoolFormerFeatureExtractor"),n1o=o(" (PoolFormer model)"),s1o=l(),Zh=a("li"),kie=a("strong"),l1o=o("regnet"),i1o=o(" \u2014 "),UN=a("a"),d1o=o("ConvNextFeatureExtractor"),c1o=o(" (RegNet model)"),f1o=l(),ep=a("li"),Sie=a("strong"),m1o=o("resnet"),g1o=o(" \u2014 "),JN=a("a"),h1o=o("ConvNextFeatureExtractor"),p1o=o(" (ResNet model)"),_1o=l(),op=a("li"),Rie=a("strong"),u1o=o("segformer"),b1o=o(" \u2014 "),YN=a("a"),v1o=o("SegformerFeatureExtractor"),F1o=o(" (SegFormer model)"),T1o=l(),rp=a("li"),Pie=a("strong"),M1o=o("speech_to_text"),E1o=o(" \u2014 "),KN=a("a"),C1o=o("Speech2TextFeatureExtractor"),w1o=o(" (Speech2Text model)"),A1o=l(),tp=a("li"),Bie=a("strong"),L1o=o("swin"),y1o=o(" \u2014 "),ZN=a("a"),x1o=o("ViTFeatureExtractor"),$1o=o(" (Swin Transformer model)"),k1o=l(),ap=a("li"),Iie=a("strong"),S1o=o("van"),R1o=o(" \u2014 "),eq=a("a"),P1o=o("ConvNextFeatureExtractor"),B1o=o(" (VAN model)"),I1o=l(),np=a("li"),Nie=a("strong"),N1o=o("vilt"),q1o=o(" \u2014 "),oq=a("a"),j1o=o("ViltFeatureExtractor"),D1o=o(" (ViLT model)"),G1o=l(),sp=a("li"),qie=a("strong"),O1o=o("vit"),V1o=o(" \u2014 "),rq=a("a"),X1o=o("ViTFeatureExtractor"),z1o=o(" (ViT model)"),W1o=l(),lp=a("li"),jie=a("strong"),Q1o=o("vit_mae"),H1o=o(" \u2014 "),tq=a("a"),U1o=o("ViTFeatureExtractor"),J1o=o(" (ViTMAE model)"),Y1o=l(),ip=a("li"),Die=a("strong"),K1o=o("wav2vec2"),Z1o=o(" \u2014 "),aq=a("a"),e2o=o("Wav2Vec2FeatureExtractor"),o2o=o(" (Wav2Vec2 model)"),r2o=l(),dp=a("li"),Gie=a("strong"),t2o=o("wav2vec2-conformer"),a2o=o(" \u2014 "),nq=a("a"),n2o=o("Wav2Vec2FeatureExtractor"),s2o=o(" (Wav2Vec2-Conformer model)"),l2o=l(),cp=a("li"),Oie=a("strong"),i2o=o("yolos"),d2o=o(" \u2014 "),sq=a("a"),c2o=o("YolosFeatureExtractor"),f2o=o(" (YOLOS model)"),m2o=l(),F(fp.$$.fragment),g2o=l(),F(mp.$$.fragment),h2o=l(),gp=a("div"),F(lL.$$.fragment),p2o=l(),Vie=a("p"),_2o=o("Register a new feature extractor for this class."),YOe=l(),Ni=a("h2"),hp=a("a"),Xie=a("span"),F(iL.$$.fragment),u2o=l(),zie=a("span"),b2o=o("AutoProcessor"),KOe=l(),yo=a("div"),F(dL.$$.fragment),v2o=l(),cL=a("p"),F2o=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),lq=a("a"),T2o=o("AutoProcessor.from_pretrained()"),M2o=o(" class method."),E2o=l(),fL=a("p"),C2o=o("This class cannot be instantiated directly using "),Wie=a("code"),w2o=o("__init__()"),A2o=o(" (throws an error)."),L2o=l(),Ue=a("div"),F(mL.$$.fragment),y2o=l(),Qie=a("p"),x2o=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),$2o=l(),qi=a("p"),k2o=o("The processor class to instantiate is selected based on the "),Hie=a("code"),S2o=o("model_type"),R2o=o(` property of the config object (either
passed as an argument or loaded from `),Uie=a("code"),P2o=o("pretrained_model_name_or_path"),B2o=o(" if possible):"),I2o=l(),he=a("ul"),pp=a("li"),Jie=a("strong"),N2o=o("clip"),q2o=o(" \u2014 "),iq=a("a"),j2o=o("CLIPProcessor"),D2o=o(" (CLIP model)"),G2o=l(),_p=a("li"),Yie=a("strong"),O2o=o("flava"),V2o=o(" \u2014 "),Kie=a("code"),X2o=o("FLAVAProcessor"),z2o=o(" (FLAVA model)"),W2o=l(),up=a("li"),Zie=a("strong"),Q2o=o("groupvit"),H2o=o(" \u2014 "),dq=a("a"),U2o=o("CLIPProcessor"),J2o=o(" (GroupViT model)"),Y2o=l(),bp=a("li"),ede=a("strong"),K2o=o("layoutlmv2"),Z2o=o(" \u2014 "),cq=a("a"),ebo=o("LayoutLMv2Processor"),obo=o(" (LayoutLMv2 model)"),rbo=l(),vp=a("li"),ode=a("strong"),tbo=o("layoutlmv3"),abo=o(" \u2014 "),fq=a("a"),nbo=o("LayoutLMv3Processor"),sbo=o(" (LayoutLMv3 model)"),lbo=l(),Fp=a("li"),rde=a("strong"),ibo=o("layoutxlm"),dbo=o(" \u2014 "),mq=a("a"),cbo=o("LayoutXLMProcessor"),fbo=o(" (LayoutXLM model)"),mbo=l(),Tp=a("li"),tde=a("strong"),gbo=o("sew"),hbo=o(" \u2014 "),gq=a("a"),pbo=o("Wav2Vec2Processor"),_bo=o(" (SEW model)"),ubo=l(),Mp=a("li"),ade=a("strong"),bbo=o("sew-d"),vbo=o(" \u2014 "),hq=a("a"),Fbo=o("Wav2Vec2Processor"),Tbo=o(" (SEW-D model)"),Mbo=l(),Ep=a("li"),nde=a("strong"),Ebo=o("speech_to_text"),Cbo=o(" \u2014 "),pq=a("a"),wbo=o("Speech2TextProcessor"),Abo=o(" (Speech2Text model)"),Lbo=l(),Cp=a("li"),sde=a("strong"),ybo=o("speech_to_text_2"),xbo=o(" \u2014 "),_q=a("a"),$bo=o("Speech2Text2Processor"),kbo=o(" (Speech2Text2 model)"),Sbo=l(),wp=a("li"),lde=a("strong"),Rbo=o("trocr"),Pbo=o(" \u2014 "),uq=a("a"),Bbo=o("TrOCRProcessor"),Ibo=o(" (TrOCR model)"),Nbo=l(),Ap=a("li"),ide=a("strong"),qbo=o("unispeech"),jbo=o(" \u2014 "),bq=a("a"),Dbo=o("Wav2Vec2Processor"),Gbo=o(" (UniSpeech model)"),Obo=l(),Lp=a("li"),dde=a("strong"),Vbo=o("unispeech-sat"),Xbo=o(" \u2014 "),vq=a("a"),zbo=o("Wav2Vec2Processor"),Wbo=o(" (UniSpeechSat model)"),Qbo=l(),yp=a("li"),cde=a("strong"),Hbo=o("vilt"),Ubo=o(" \u2014 "),Fq=a("a"),Jbo=o("ViltProcessor"),Ybo=o(" (ViLT model)"),Kbo=l(),xp=a("li"),fde=a("strong"),Zbo=o("vision-text-dual-encoder"),evo=o(" \u2014 "),Tq=a("a"),ovo=o("VisionTextDualEncoderProcessor"),rvo=o(" (VisionTextDualEncoder model)"),tvo=l(),$p=a("li"),mde=a("strong"),avo=o("wav2vec2"),nvo=o(" \u2014 "),Mq=a("a"),svo=o("Wav2Vec2Processor"),lvo=o(" (Wav2Vec2 model)"),ivo=l(),kp=a("li"),gde=a("strong"),dvo=o("wav2vec2-conformer"),cvo=o(" \u2014 "),Eq=a("a"),fvo=o("Wav2Vec2Processor"),mvo=o(" (Wav2Vec2-Conformer model)"),gvo=l(),Sp=a("li"),hde=a("strong"),hvo=o("wavlm"),pvo=o(" \u2014 "),Cq=a("a"),_vo=o("Wav2Vec2Processor"),uvo=o(" (WavLM model)"),bvo=l(),F(Rp.$$.fragment),vvo=l(),F(Pp.$$.fragment),Fvo=l(),Bp=a("div"),F(gL.$$.fragment),Tvo=l(),pde=a("p"),Mvo=o("Register a new processor for this class."),ZOe=l(),ji=a("h2"),Ip=a("a"),_de=a("span"),F(hL.$$.fragment),Evo=l(),ude=a("span"),Cvo=o("AutoModel"),eVe=l(),xo=a("div"),F(pL.$$.fragment),wvo=l(),Di=a("p"),Avo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),wq=a("a"),Lvo=o("from_pretrained()"),yvo=o(" class method or the "),Aq=a("a"),xvo=o("from_config()"),$vo=o(` class
method.`),kvo=l(),_L=a("p"),Svo=o("This class cannot be instantiated directly using "),bde=a("code"),Rvo=o("__init__()"),Pvo=o(" (throws an error)."),Bvo=l(),st=a("div"),F(uL.$$.fragment),Ivo=l(),vde=a("p"),Nvo=o("Instantiates one of the base model classes of the library from a configuration."),qvo=l(),Gi=a("p"),jvo=o(`Note:
Loading a model from its configuration file does `),Fde=a("strong"),Dvo=o("not"),Gvo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Lq=a("a"),Ovo=o("from_pretrained()"),Vvo=o(" to load the model weights."),Xvo=l(),F(Np.$$.fragment),zvo=l(),Je=a("div"),F(bL.$$.fragment),Wvo=l(),Tde=a("p"),Qvo=o("Instantiate one of the base model classes of the library from a pretrained model."),Hvo=l(),Ba=a("p"),Uvo=o("The model class to instantiate is selected based on the "),Mde=a("code"),Jvo=o("model_type"),Yvo=o(` property of the config object (either
passed as an argument or loaded from `),Ede=a("code"),Kvo=o("pretrained_model_name_or_path"),Zvo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cde=a("code"),e0o=o("pretrained_model_name_or_path"),o0o=o(":"),r0o=l(),y=a("ul"),qp=a("li"),wde=a("strong"),t0o=o("albert"),a0o=o(" \u2014 "),yq=a("a"),n0o=o("AlbertModel"),s0o=o(" (ALBERT model)"),l0o=l(),jp=a("li"),Ade=a("strong"),i0o=o("bart"),d0o=o(" \u2014 "),xq=a("a"),c0o=o("BartModel"),f0o=o(" (BART model)"),m0o=l(),Dp=a("li"),Lde=a("strong"),g0o=o("beit"),h0o=o(" \u2014 "),$q=a("a"),p0o=o("BeitModel"),_0o=o(" (BEiT model)"),u0o=l(),Gp=a("li"),yde=a("strong"),b0o=o("bert"),v0o=o(" \u2014 "),kq=a("a"),F0o=o("BertModel"),T0o=o(" (BERT model)"),M0o=l(),Op=a("li"),xde=a("strong"),E0o=o("bert-generation"),C0o=o(" \u2014 "),Sq=a("a"),w0o=o("BertGenerationEncoder"),A0o=o(" (Bert Generation model)"),L0o=l(),Vp=a("li"),$de=a("strong"),y0o=o("big_bird"),x0o=o(" \u2014 "),Rq=a("a"),$0o=o("BigBirdModel"),k0o=o(" (BigBird model)"),S0o=l(),Xp=a("li"),kde=a("strong"),R0o=o("bigbird_pegasus"),P0o=o(" \u2014 "),Pq=a("a"),B0o=o("BigBirdPegasusModel"),I0o=o(" (BigBird-Pegasus model)"),N0o=l(),zp=a("li"),Sde=a("strong"),q0o=o("blenderbot"),j0o=o(" \u2014 "),Bq=a("a"),D0o=o("BlenderbotModel"),G0o=o(" (Blenderbot model)"),O0o=l(),Wp=a("li"),Rde=a("strong"),V0o=o("blenderbot-small"),X0o=o(" \u2014 "),Iq=a("a"),z0o=o("BlenderbotSmallModel"),W0o=o(" (BlenderbotSmall model)"),Q0o=l(),Qp=a("li"),Pde=a("strong"),H0o=o("bloom"),U0o=o(" \u2014 "),Nq=a("a"),J0o=o("BloomModel"),Y0o=o(" (BLOOM model)"),K0o=l(),Hp=a("li"),Bde=a("strong"),Z0o=o("camembert"),eFo=o(" \u2014 "),qq=a("a"),oFo=o("CamembertModel"),rFo=o(" (CamemBERT model)"),tFo=l(),Up=a("li"),Ide=a("strong"),aFo=o("canine"),nFo=o(" \u2014 "),jq=a("a"),sFo=o("CanineModel"),lFo=o(" (CANINE model)"),iFo=l(),Jp=a("li"),Nde=a("strong"),dFo=o("clip"),cFo=o(" \u2014 "),Dq=a("a"),fFo=o("CLIPModel"),mFo=o(" (CLIP model)"),gFo=l(),Yp=a("li"),qde=a("strong"),hFo=o("codegen"),pFo=o(" \u2014 "),Gq=a("a"),_Fo=o("CodeGenModel"),uFo=o(" (CodeGen model)"),bFo=l(),Kp=a("li"),jde=a("strong"),vFo=o("convbert"),FFo=o(" \u2014 "),Oq=a("a"),TFo=o("ConvBertModel"),MFo=o(" (ConvBERT model)"),EFo=l(),Zp=a("li"),Dde=a("strong"),CFo=o("convnext"),wFo=o(" \u2014 "),Vq=a("a"),AFo=o("ConvNextModel"),LFo=o(" (ConvNeXT model)"),yFo=l(),e_=a("li"),Gde=a("strong"),xFo=o("ctrl"),$Fo=o(" \u2014 "),Xq=a("a"),kFo=o("CTRLModel"),SFo=o(" (CTRL model)"),RFo=l(),o_=a("li"),Ode=a("strong"),PFo=o("cvt"),BFo=o(" \u2014 "),zq=a("a"),IFo=o("CvtModel"),NFo=o(" (CvT model)"),qFo=l(),r_=a("li"),Vde=a("strong"),jFo=o("data2vec-audio"),DFo=o(" \u2014 "),Wq=a("a"),GFo=o("Data2VecAudioModel"),OFo=o(" (Data2VecAudio model)"),VFo=l(),t_=a("li"),Xde=a("strong"),XFo=o("data2vec-text"),zFo=o(" \u2014 "),Qq=a("a"),WFo=o("Data2VecTextModel"),QFo=o(" (Data2VecText model)"),HFo=l(),a_=a("li"),zde=a("strong"),UFo=o("data2vec-vision"),JFo=o(" \u2014 "),Hq=a("a"),YFo=o("Data2VecVisionModel"),KFo=o(" (Data2VecVision model)"),ZFo=l(),n_=a("li"),Wde=a("strong"),e6o=o("deberta"),o6o=o(" \u2014 "),Uq=a("a"),r6o=o("DebertaModel"),t6o=o(" (DeBERTa model)"),a6o=l(),s_=a("li"),Qde=a("strong"),n6o=o("deberta-v2"),s6o=o(" \u2014 "),Jq=a("a"),l6o=o("DebertaV2Model"),i6o=o(" (DeBERTa-v2 model)"),d6o=l(),l_=a("li"),Hde=a("strong"),c6o=o("decision_transformer"),f6o=o(" \u2014 "),Yq=a("a"),m6o=o("DecisionTransformerModel"),g6o=o(" (Decision Transformer model)"),h6o=l(),i_=a("li"),Ude=a("strong"),p6o=o("deit"),_6o=o(" \u2014 "),Kq=a("a"),u6o=o("DeiTModel"),b6o=o(" (DeiT model)"),v6o=l(),d_=a("li"),Jde=a("strong"),F6o=o("detr"),T6o=o(" \u2014 "),Zq=a("a"),M6o=o("DetrModel"),E6o=o(" (DETR model)"),C6o=l(),c_=a("li"),Yde=a("strong"),w6o=o("distilbert"),A6o=o(" \u2014 "),ej=a("a"),L6o=o("DistilBertModel"),y6o=o(" (DistilBERT model)"),x6o=l(),f_=a("li"),Kde=a("strong"),$6o=o("dpr"),k6o=o(" \u2014 "),oj=a("a"),S6o=o("DPRQuestionEncoder"),R6o=o(" (DPR model)"),P6o=l(),m_=a("li"),Zde=a("strong"),B6o=o("dpt"),I6o=o(" \u2014 "),rj=a("a"),N6o=o("DPTModel"),q6o=o(" (DPT model)"),j6o=l(),g_=a("li"),ece=a("strong"),D6o=o("electra"),G6o=o(" \u2014 "),tj=a("a"),O6o=o("ElectraModel"),V6o=o(" (ELECTRA model)"),X6o=l(),h_=a("li"),oce=a("strong"),z6o=o("flaubert"),W6o=o(" \u2014 "),aj=a("a"),Q6o=o("FlaubertModel"),H6o=o(" (FlauBERT model)"),U6o=l(),p_=a("li"),rce=a("strong"),J6o=o("flava"),Y6o=o(" \u2014 "),nj=a("a"),K6o=o("FlavaModel"),Z6o=o(" (FLAVA model)"),eTo=l(),__=a("li"),tce=a("strong"),oTo=o("fnet"),rTo=o(" \u2014 "),sj=a("a"),tTo=o("FNetModel"),aTo=o(" (FNet model)"),nTo=l(),u_=a("li"),ace=a("strong"),sTo=o("fsmt"),lTo=o(" \u2014 "),lj=a("a"),iTo=o("FSMTModel"),dTo=o(" (FairSeq Machine-Translation model)"),cTo=l(),Ws=a("li"),nce=a("strong"),fTo=o("funnel"),mTo=o(" \u2014 "),ij=a("a"),gTo=o("FunnelModel"),hTo=o(" or "),dj=a("a"),pTo=o("FunnelBaseModel"),_To=o(" (Funnel Transformer model)"),uTo=l(),b_=a("li"),sce=a("strong"),bTo=o("glpn"),vTo=o(" \u2014 "),cj=a("a"),FTo=o("GLPNModel"),TTo=o(" (GLPN model)"),MTo=l(),v_=a("li"),lce=a("strong"),ETo=o("gpt2"),CTo=o(" \u2014 "),fj=a("a"),wTo=o("GPT2Model"),ATo=o(" (OpenAI GPT-2 model)"),LTo=l(),F_=a("li"),ice=a("strong"),yTo=o("gpt_neo"),xTo=o(" \u2014 "),mj=a("a"),$To=o("GPTNeoModel"),kTo=o(" (GPT Neo model)"),STo=l(),T_=a("li"),dce=a("strong"),RTo=o("gpt_neox"),PTo=o(" \u2014 "),gj=a("a"),BTo=o("GPTNeoXModel"),ITo=o(" (GPT NeoX model)"),NTo=l(),M_=a("li"),cce=a("strong"),qTo=o("gptj"),jTo=o(" \u2014 "),hj=a("a"),DTo=o("GPTJModel"),GTo=o(" (GPT-J model)"),OTo=l(),E_=a("li"),fce=a("strong"),VTo=o("groupvit"),XTo=o(" \u2014 "),pj=a("a"),zTo=o("GroupViTModel"),WTo=o(" (GroupViT model)"),QTo=l(),C_=a("li"),mce=a("strong"),HTo=o("hubert"),UTo=o(" \u2014 "),_j=a("a"),JTo=o("HubertModel"),YTo=o(" (Hubert model)"),KTo=l(),w_=a("li"),gce=a("strong"),ZTo=o("ibert"),e7o=o(" \u2014 "),uj=a("a"),o7o=o("IBertModel"),r7o=o(" (I-BERT model)"),t7o=l(),A_=a("li"),hce=a("strong"),a7o=o("imagegpt"),n7o=o(" \u2014 "),bj=a("a"),s7o=o("ImageGPTModel"),l7o=o(" (ImageGPT model)"),i7o=l(),L_=a("li"),pce=a("strong"),d7o=o("layoutlm"),c7o=o(" \u2014 "),vj=a("a"),f7o=o("LayoutLMModel"),m7o=o(" (LayoutLM model)"),g7o=l(),y_=a("li"),_ce=a("strong"),h7o=o("layoutlmv2"),p7o=o(" \u2014 "),Fj=a("a"),_7o=o("LayoutLMv2Model"),u7o=o(" (LayoutLMv2 model)"),b7o=l(),x_=a("li"),uce=a("strong"),v7o=o("layoutlmv3"),F7o=o(" \u2014 "),Tj=a("a"),T7o=o("LayoutLMv3Model"),M7o=o(" (LayoutLMv3 model)"),E7o=l(),$_=a("li"),bce=a("strong"),C7o=o("led"),w7o=o(" \u2014 "),Mj=a("a"),A7o=o("LEDModel"),L7o=o(" (LED model)"),y7o=l(),k_=a("li"),vce=a("strong"),x7o=o("levit"),$7o=o(" \u2014 "),Ej=a("a"),k7o=o("LevitModel"),S7o=o(" (LeViT model)"),R7o=l(),S_=a("li"),Fce=a("strong"),P7o=o("longformer"),B7o=o(" \u2014 "),Cj=a("a"),I7o=o("LongformerModel"),N7o=o(" (Longformer model)"),q7o=l(),R_=a("li"),Tce=a("strong"),j7o=o("longt5"),D7o=o(" \u2014 "),wj=a("a"),G7o=o("LongT5Model"),O7o=o(" (LongT5 model)"),V7o=l(),P_=a("li"),Mce=a("strong"),X7o=o("luke"),z7o=o(" \u2014 "),Aj=a("a"),W7o=o("LukeModel"),Q7o=o(" (LUKE model)"),H7o=l(),B_=a("li"),Ece=a("strong"),U7o=o("lxmert"),J7o=o(" \u2014 "),Lj=a("a"),Y7o=o("LxmertModel"),K7o=o(" (LXMERT model)"),Z7o=l(),I_=a("li"),Cce=a("strong"),e8o=o("m2m_100"),o8o=o(" \u2014 "),yj=a("a"),r8o=o("M2M100Model"),t8o=o(" (M2M100 model)"),a8o=l(),N_=a("li"),wce=a("strong"),n8o=o("marian"),s8o=o(" \u2014 "),xj=a("a"),l8o=o("MarianModel"),i8o=o(" (Marian model)"),d8o=l(),q_=a("li"),Ace=a("strong"),c8o=o("maskformer"),f8o=o(" \u2014 "),$j=a("a"),m8o=o("MaskFormerModel"),g8o=o(" (MaskFormer model)"),h8o=l(),j_=a("li"),Lce=a("strong"),p8o=o("mbart"),_8o=o(" \u2014 "),kj=a("a"),u8o=o("MBartModel"),b8o=o(" (mBART model)"),v8o=l(),D_=a("li"),yce=a("strong"),F8o=o("mctct"),T8o=o(" \u2014 "),Sj=a("a"),M8o=o("MCTCTModel"),E8o=o(" (M-CTC-T model)"),C8o=l(),G_=a("li"),xce=a("strong"),w8o=o("megatron-bert"),A8o=o(" \u2014 "),Rj=a("a"),L8o=o("MegatronBertModel"),y8o=o(" (Megatron-BERT model)"),x8o=l(),O_=a("li"),$ce=a("strong"),$8o=o("mobilebert"),k8o=o(" \u2014 "),Pj=a("a"),S8o=o("MobileBertModel"),R8o=o(" (MobileBERT model)"),P8o=l(),V_=a("li"),kce=a("strong"),B8o=o("mpnet"),I8o=o(" \u2014 "),Bj=a("a"),N8o=o("MPNetModel"),q8o=o(" (MPNet model)"),j8o=l(),X_=a("li"),Sce=a("strong"),D8o=o("mt5"),G8o=o(" \u2014 "),Ij=a("a"),O8o=o("MT5Model"),V8o=o(" (MT5 model)"),X8o=l(),z_=a("li"),Rce=a("strong"),z8o=o("nezha"),W8o=o(" \u2014 "),Nj=a("a"),Q8o=o("NezhaModel"),H8o=o(" (Nezha model)"),U8o=l(),W_=a("li"),Pce=a("strong"),J8o=o("nystromformer"),Y8o=o(" \u2014 "),qj=a("a"),K8o=o("NystromformerModel"),Z8o=o(" (Nystr\xF6mformer model)"),eMo=l(),Q_=a("li"),Bce=a("strong"),oMo=o("openai-gpt"),rMo=o(" \u2014 "),jj=a("a"),tMo=o("OpenAIGPTModel"),aMo=o(" (OpenAI GPT model)"),nMo=l(),H_=a("li"),Ice=a("strong"),sMo=o("opt"),lMo=o(" \u2014 "),Dj=a("a"),iMo=o("OPTModel"),dMo=o(" (OPT model)"),cMo=l(),U_=a("li"),Nce=a("strong"),fMo=o("pegasus"),mMo=o(" \u2014 "),Gj=a("a"),gMo=o("PegasusModel"),hMo=o(" (Pegasus model)"),pMo=l(),J_=a("li"),qce=a("strong"),_Mo=o("perceiver"),uMo=o(" \u2014 "),Oj=a("a"),bMo=o("PerceiverModel"),vMo=o(" (Perceiver model)"),FMo=l(),Y_=a("li"),jce=a("strong"),TMo=o("plbart"),MMo=o(" \u2014 "),Vj=a("a"),EMo=o("PLBartModel"),CMo=o(" (PLBart model)"),wMo=l(),K_=a("li"),Dce=a("strong"),AMo=o("poolformer"),LMo=o(" \u2014 "),Xj=a("a"),yMo=o("PoolFormerModel"),xMo=o(" (PoolFormer model)"),$Mo=l(),Z_=a("li"),Gce=a("strong"),kMo=o("prophetnet"),SMo=o(" \u2014 "),zj=a("a"),RMo=o("ProphetNetModel"),PMo=o(" (ProphetNet model)"),BMo=l(),eu=a("li"),Oce=a("strong"),IMo=o("qdqbert"),NMo=o(" \u2014 "),Wj=a("a"),qMo=o("QDQBertModel"),jMo=o(" (QDQBert model)"),DMo=l(),ou=a("li"),Vce=a("strong"),GMo=o("reformer"),OMo=o(" \u2014 "),Qj=a("a"),VMo=o("ReformerModel"),XMo=o(" (Reformer model)"),zMo=l(),ru=a("li"),Xce=a("strong"),WMo=o("regnet"),QMo=o(" \u2014 "),Hj=a("a"),HMo=o("RegNetModel"),UMo=o(" (RegNet model)"),JMo=l(),tu=a("li"),zce=a("strong"),YMo=o("rembert"),KMo=o(" \u2014 "),Uj=a("a"),ZMo=o("RemBertModel"),e4o=o(" (RemBERT model)"),o4o=l(),au=a("li"),Wce=a("strong"),r4o=o("resnet"),t4o=o(" \u2014 "),Jj=a("a"),a4o=o("ResNetModel"),n4o=o(" (ResNet model)"),s4o=l(),nu=a("li"),Qce=a("strong"),l4o=o("retribert"),i4o=o(" \u2014 "),Yj=a("a"),d4o=o("RetriBertModel"),c4o=o(" (RetriBERT model)"),f4o=l(),su=a("li"),Hce=a("strong"),m4o=o("roberta"),g4o=o(" \u2014 "),Kj=a("a"),h4o=o("RobertaModel"),p4o=o(" (RoBERTa model)"),_4o=l(),lu=a("li"),Uce=a("strong"),u4o=o("roformer"),b4o=o(" \u2014 "),Zj=a("a"),v4o=o("RoFormerModel"),F4o=o(" (RoFormer model)"),T4o=l(),iu=a("li"),Jce=a("strong"),M4o=o("segformer"),E4o=o(" \u2014 "),eD=a("a"),C4o=o("SegformerModel"),w4o=o(" (SegFormer model)"),A4o=l(),du=a("li"),Yce=a("strong"),L4o=o("sew"),y4o=o(" \u2014 "),oD=a("a"),x4o=o("SEWModel"),$4o=o(" (SEW model)"),k4o=l(),cu=a("li"),Kce=a("strong"),S4o=o("sew-d"),R4o=o(" \u2014 "),rD=a("a"),P4o=o("SEWDModel"),B4o=o(" (SEW-D model)"),I4o=l(),fu=a("li"),Zce=a("strong"),N4o=o("speech_to_text"),q4o=o(" \u2014 "),tD=a("a"),j4o=o("Speech2TextModel"),D4o=o(" (Speech2Text model)"),G4o=l(),mu=a("li"),efe=a("strong"),O4o=o("splinter"),V4o=o(" \u2014 "),aD=a("a"),X4o=o("SplinterModel"),z4o=o(" (Splinter model)"),W4o=l(),gu=a("li"),ofe=a("strong"),Q4o=o("squeezebert"),H4o=o(" \u2014 "),nD=a("a"),U4o=o("SqueezeBertModel"),J4o=o(" (SqueezeBERT model)"),Y4o=l(),hu=a("li"),rfe=a("strong"),K4o=o("swin"),Z4o=o(" \u2014 "),sD=a("a"),eEo=o("SwinModel"),oEo=o(" (Swin Transformer model)"),rEo=l(),pu=a("li"),tfe=a("strong"),tEo=o("t5"),aEo=o(" \u2014 "),lD=a("a"),nEo=o("T5Model"),sEo=o(" (T5 model)"),lEo=l(),_u=a("li"),afe=a("strong"),iEo=o("tapas"),dEo=o(" \u2014 "),iD=a("a"),cEo=o("TapasModel"),fEo=o(" (TAPAS model)"),mEo=l(),uu=a("li"),nfe=a("strong"),gEo=o("trajectory_transformer"),hEo=o(" \u2014 "),dD=a("a"),pEo=o("TrajectoryTransformerModel"),_Eo=o(" (Trajectory Transformer model)"),uEo=l(),bu=a("li"),sfe=a("strong"),bEo=o("transfo-xl"),vEo=o(" \u2014 "),cD=a("a"),FEo=o("TransfoXLModel"),TEo=o(" (Transformer-XL model)"),MEo=l(),vu=a("li"),lfe=a("strong"),EEo=o("unispeech"),CEo=o(" \u2014 "),fD=a("a"),wEo=o("UniSpeechModel"),AEo=o(" (UniSpeech model)"),LEo=l(),Fu=a("li"),ife=a("strong"),yEo=o("unispeech-sat"),xEo=o(" \u2014 "),mD=a("a"),$Eo=o("UniSpeechSatModel"),kEo=o(" (UniSpeechSat model)"),SEo=l(),Tu=a("li"),dfe=a("strong"),REo=o("van"),PEo=o(" \u2014 "),gD=a("a"),BEo=o("VanModel"),IEo=o(" (VAN model)"),NEo=l(),Mu=a("li"),cfe=a("strong"),qEo=o("vilt"),jEo=o(" \u2014 "),hD=a("a"),DEo=o("ViltModel"),GEo=o(" (ViLT model)"),OEo=l(),Eu=a("li"),ffe=a("strong"),VEo=o("vision-text-dual-encoder"),XEo=o(" \u2014 "),pD=a("a"),zEo=o("VisionTextDualEncoderModel"),WEo=o(" (VisionTextDualEncoder model)"),QEo=l(),Cu=a("li"),mfe=a("strong"),HEo=o("visual_bert"),UEo=o(" \u2014 "),_D=a("a"),JEo=o("VisualBertModel"),YEo=o(" (VisualBERT model)"),KEo=l(),wu=a("li"),gfe=a("strong"),ZEo=o("vit"),eCo=o(" \u2014 "),uD=a("a"),oCo=o("ViTModel"),rCo=o(" (ViT model)"),tCo=l(),Au=a("li"),hfe=a("strong"),aCo=o("vit_mae"),nCo=o(" \u2014 "),bD=a("a"),sCo=o("ViTMAEModel"),lCo=o(" (ViTMAE model)"),iCo=l(),Lu=a("li"),pfe=a("strong"),dCo=o("wav2vec2"),cCo=o(" \u2014 "),vD=a("a"),fCo=o("Wav2Vec2Model"),mCo=o(" (Wav2Vec2 model)"),gCo=l(),yu=a("li"),_fe=a("strong"),hCo=o("wav2vec2-conformer"),pCo=o(" \u2014 "),FD=a("a"),_Co=o("Wav2Vec2ConformerModel"),uCo=o(" (Wav2Vec2-Conformer model)"),bCo=l(),xu=a("li"),ufe=a("strong"),vCo=o("wavlm"),FCo=o(" \u2014 "),TD=a("a"),TCo=o("WavLMModel"),MCo=o(" (WavLM model)"),ECo=l(),$u=a("li"),bfe=a("strong"),CCo=o("xglm"),wCo=o(" \u2014 "),MD=a("a"),ACo=o("XGLMModel"),LCo=o(" (XGLM model)"),yCo=l(),ku=a("li"),vfe=a("strong"),xCo=o("xlm"),$Co=o(" \u2014 "),ED=a("a"),kCo=o("XLMModel"),SCo=o(" (XLM model)"),RCo=l(),Su=a("li"),Ffe=a("strong"),PCo=o("xlm-prophetnet"),BCo=o(" \u2014 "),CD=a("a"),ICo=o("XLMProphetNetModel"),NCo=o(" (XLM-ProphetNet model)"),qCo=l(),Ru=a("li"),Tfe=a("strong"),jCo=o("xlm-roberta"),DCo=o(" \u2014 "),wD=a("a"),GCo=o("XLMRobertaModel"),OCo=o(" (XLM-RoBERTa model)"),VCo=l(),Pu=a("li"),Mfe=a("strong"),XCo=o("xlm-roberta-xl"),zCo=o(" \u2014 "),AD=a("a"),WCo=o("XLMRobertaXLModel"),QCo=o(" (XLM-RoBERTa-XL model)"),HCo=l(),Bu=a("li"),Efe=a("strong"),UCo=o("xlnet"),JCo=o(" \u2014 "),LD=a("a"),YCo=o("XLNetModel"),KCo=o(" (XLNet model)"),ZCo=l(),Iu=a("li"),Cfe=a("strong"),e3o=o("yolos"),o3o=o(" \u2014 "),yD=a("a"),r3o=o("YolosModel"),t3o=o(" (YOLOS model)"),a3o=l(),Nu=a("li"),wfe=a("strong"),n3o=o("yoso"),s3o=o(" \u2014 "),xD=a("a"),l3o=o("YosoModel"),i3o=o(" (YOSO model)"),d3o=l(),qu=a("p"),c3o=o("The model is set in evaluation mode by default using "),Afe=a("code"),f3o=o("model.eval()"),m3o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lfe=a("code"),g3o=o("model.train()"),h3o=l(),F(ju.$$.fragment),oVe=l(),Oi=a("h2"),Du=a("a"),yfe=a("span"),F(vL.$$.fragment),p3o=l(),xfe=a("span"),_3o=o("AutoModelForPreTraining"),rVe=l(),$o=a("div"),F(FL.$$.fragment),u3o=l(),Vi=a("p"),b3o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),$D=a("a"),v3o=o("from_pretrained()"),F3o=o(" class method or the "),kD=a("a"),T3o=o("from_config()"),M3o=o(` class
method.`),E3o=l(),TL=a("p"),C3o=o("This class cannot be instantiated directly using "),$fe=a("code"),w3o=o("__init__()"),A3o=o(" (throws an error)."),L3o=l(),lt=a("div"),F(ML.$$.fragment),y3o=l(),kfe=a("p"),x3o=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),$3o=l(),Xi=a("p"),k3o=o(`Note:
Loading a model from its configuration file does `),Sfe=a("strong"),S3o=o("not"),R3o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SD=a("a"),P3o=o("from_pretrained()"),B3o=o(" to load the model weights."),I3o=l(),F(Gu.$$.fragment),N3o=l(),Ye=a("div"),F(EL.$$.fragment),q3o=l(),Rfe=a("p"),j3o=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),D3o=l(),Ia=a("p"),G3o=o("The model class to instantiate is selected based on the "),Pfe=a("code"),O3o=o("model_type"),V3o=o(` property of the config object (either
passed as an argument or loaded from `),Bfe=a("code"),X3o=o("pretrained_model_name_or_path"),z3o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ife=a("code"),W3o=o("pretrained_model_name_or_path"),Q3o=o(":"),H3o=l(),G=a("ul"),Ou=a("li"),Nfe=a("strong"),U3o=o("albert"),J3o=o(" \u2014 "),RD=a("a"),Y3o=o("AlbertForPreTraining"),K3o=o(" (ALBERT model)"),Z3o=l(),Vu=a("li"),qfe=a("strong"),e5o=o("bart"),o5o=o(" \u2014 "),PD=a("a"),r5o=o("BartForConditionalGeneration"),t5o=o(" (BART model)"),a5o=l(),Xu=a("li"),jfe=a("strong"),n5o=o("bert"),s5o=o(" \u2014 "),BD=a("a"),l5o=o("BertForPreTraining"),i5o=o(" (BERT model)"),d5o=l(),zu=a("li"),Dfe=a("strong"),c5o=o("big_bird"),f5o=o(" \u2014 "),ID=a("a"),m5o=o("BigBirdForPreTraining"),g5o=o(" (BigBird model)"),h5o=l(),Wu=a("li"),Gfe=a("strong"),p5o=o("bloom"),_5o=o(" \u2014 "),ND=a("a"),u5o=o("BloomForCausalLM"),b5o=o(" (BLOOM model)"),v5o=l(),Qu=a("li"),Ofe=a("strong"),F5o=o("camembert"),T5o=o(" \u2014 "),qD=a("a"),M5o=o("CamembertForMaskedLM"),E5o=o(" (CamemBERT model)"),C5o=l(),Hu=a("li"),Vfe=a("strong"),w5o=o("ctrl"),A5o=o(" \u2014 "),jD=a("a"),L5o=o("CTRLLMHeadModel"),y5o=o(" (CTRL model)"),x5o=l(),Uu=a("li"),Xfe=a("strong"),$5o=o("data2vec-text"),k5o=o(" \u2014 "),DD=a("a"),S5o=o("Data2VecTextForMaskedLM"),R5o=o(" (Data2VecText model)"),P5o=l(),Ju=a("li"),zfe=a("strong"),B5o=o("deberta"),I5o=o(" \u2014 "),GD=a("a"),N5o=o("DebertaForMaskedLM"),q5o=o(" (DeBERTa model)"),j5o=l(),Yu=a("li"),Wfe=a("strong"),D5o=o("deberta-v2"),G5o=o(" \u2014 "),OD=a("a"),O5o=o("DebertaV2ForMaskedLM"),V5o=o(" (DeBERTa-v2 model)"),X5o=l(),Ku=a("li"),Qfe=a("strong"),z5o=o("distilbert"),W5o=o(" \u2014 "),VD=a("a"),Q5o=o("DistilBertForMaskedLM"),H5o=o(" (DistilBERT model)"),U5o=l(),Zu=a("li"),Hfe=a("strong"),J5o=o("electra"),Y5o=o(" \u2014 "),XD=a("a"),K5o=o("ElectraForPreTraining"),Z5o=o(" (ELECTRA model)"),ewo=l(),e1=a("li"),Ufe=a("strong"),owo=o("flaubert"),rwo=o(" \u2014 "),zD=a("a"),two=o("FlaubertWithLMHeadModel"),awo=o(" (FlauBERT model)"),nwo=l(),o1=a("li"),Jfe=a("strong"),swo=o("flava"),lwo=o(" \u2014 "),WD=a("a"),iwo=o("FlavaForPreTraining"),dwo=o(" (FLAVA model)"),cwo=l(),r1=a("li"),Yfe=a("strong"),fwo=o("fnet"),mwo=o(" \u2014 "),QD=a("a"),gwo=o("FNetForPreTraining"),hwo=o(" (FNet model)"),pwo=l(),t1=a("li"),Kfe=a("strong"),_wo=o("fsmt"),uwo=o(" \u2014 "),HD=a("a"),bwo=o("FSMTForConditionalGeneration"),vwo=o(" (FairSeq Machine-Translation model)"),Fwo=l(),a1=a("li"),Zfe=a("strong"),Two=o("funnel"),Mwo=o(" \u2014 "),UD=a("a"),Ewo=o("FunnelForPreTraining"),Cwo=o(" (Funnel Transformer model)"),wwo=l(),n1=a("li"),eme=a("strong"),Awo=o("gpt2"),Lwo=o(" \u2014 "),JD=a("a"),ywo=o("GPT2LMHeadModel"),xwo=o(" (OpenAI GPT-2 model)"),$wo=l(),s1=a("li"),ome=a("strong"),kwo=o("ibert"),Swo=o(" \u2014 "),YD=a("a"),Rwo=o("IBertForMaskedLM"),Pwo=o(" (I-BERT model)"),Bwo=l(),l1=a("li"),rme=a("strong"),Iwo=o("layoutlm"),Nwo=o(" \u2014 "),KD=a("a"),qwo=o("LayoutLMForMaskedLM"),jwo=o(" (LayoutLM model)"),Dwo=l(),i1=a("li"),tme=a("strong"),Gwo=o("longformer"),Owo=o(" \u2014 "),ZD=a("a"),Vwo=o("LongformerForMaskedLM"),Xwo=o(" (Longformer model)"),zwo=l(),d1=a("li"),ame=a("strong"),Wwo=o("lxmert"),Qwo=o(" \u2014 "),eG=a("a"),Hwo=o("LxmertForPreTraining"),Uwo=o(" (LXMERT model)"),Jwo=l(),c1=a("li"),nme=a("strong"),Ywo=o("megatron-bert"),Kwo=o(" \u2014 "),oG=a("a"),Zwo=o("MegatronBertForPreTraining"),eAo=o(" (Megatron-BERT model)"),oAo=l(),f1=a("li"),sme=a("strong"),rAo=o("mobilebert"),tAo=o(" \u2014 "),rG=a("a"),aAo=o("MobileBertForPreTraining"),nAo=o(" (MobileBERT model)"),sAo=l(),m1=a("li"),lme=a("strong"),lAo=o("mpnet"),iAo=o(" \u2014 "),tG=a("a"),dAo=o("MPNetForMaskedLM"),cAo=o(" (MPNet model)"),fAo=l(),g1=a("li"),ime=a("strong"),mAo=o("nezha"),gAo=o(" \u2014 "),aG=a("a"),hAo=o("NezhaForPreTraining"),pAo=o(" (Nezha model)"),_Ao=l(),h1=a("li"),dme=a("strong"),uAo=o("openai-gpt"),bAo=o(" \u2014 "),nG=a("a"),vAo=o("OpenAIGPTLMHeadModel"),FAo=o(" (OpenAI GPT model)"),TAo=l(),p1=a("li"),cme=a("strong"),MAo=o("retribert"),EAo=o(" \u2014 "),sG=a("a"),CAo=o("RetriBertModel"),wAo=o(" (RetriBERT model)"),AAo=l(),_1=a("li"),fme=a("strong"),LAo=o("roberta"),yAo=o(" \u2014 "),lG=a("a"),xAo=o("RobertaForMaskedLM"),$Ao=o(" (RoBERTa model)"),kAo=l(),u1=a("li"),mme=a("strong"),SAo=o("splinter"),RAo=o(" \u2014 "),iG=a("a"),PAo=o("SplinterForPreTraining"),BAo=o(" (Splinter model)"),IAo=l(),b1=a("li"),gme=a("strong"),NAo=o("squeezebert"),qAo=o(" \u2014 "),dG=a("a"),jAo=o("SqueezeBertForMaskedLM"),DAo=o(" (SqueezeBERT model)"),GAo=l(),v1=a("li"),hme=a("strong"),OAo=o("t5"),VAo=o(" \u2014 "),cG=a("a"),XAo=o("T5ForConditionalGeneration"),zAo=o(" (T5 model)"),WAo=l(),F1=a("li"),pme=a("strong"),QAo=o("tapas"),HAo=o(" \u2014 "),fG=a("a"),UAo=o("TapasForMaskedLM"),JAo=o(" (TAPAS model)"),YAo=l(),T1=a("li"),_me=a("strong"),KAo=o("transfo-xl"),ZAo=o(" \u2014 "),mG=a("a"),eLo=o("TransfoXLLMHeadModel"),oLo=o(" (Transformer-XL model)"),rLo=l(),M1=a("li"),ume=a("strong"),tLo=o("unispeech"),aLo=o(" \u2014 "),gG=a("a"),nLo=o("UniSpeechForPreTraining"),sLo=o(" (UniSpeech model)"),lLo=l(),E1=a("li"),bme=a("strong"),iLo=o("unispeech-sat"),dLo=o(" \u2014 "),hG=a("a"),cLo=o("UniSpeechSatForPreTraining"),fLo=o(" (UniSpeechSat model)"),mLo=l(),C1=a("li"),vme=a("strong"),gLo=o("visual_bert"),hLo=o(" \u2014 "),pG=a("a"),pLo=o("VisualBertForPreTraining"),_Lo=o(" (VisualBERT model)"),uLo=l(),w1=a("li"),Fme=a("strong"),bLo=o("vit_mae"),vLo=o(" \u2014 "),_G=a("a"),FLo=o("ViTMAEForPreTraining"),TLo=o(" (ViTMAE model)"),MLo=l(),A1=a("li"),Tme=a("strong"),ELo=o("wav2vec2"),CLo=o(" \u2014 "),uG=a("a"),wLo=o("Wav2Vec2ForPreTraining"),ALo=o(" (Wav2Vec2 model)"),LLo=l(),L1=a("li"),Mme=a("strong"),yLo=o("wav2vec2-conformer"),xLo=o(" \u2014 "),bG=a("a"),$Lo=o("Wav2Vec2ConformerForPreTraining"),kLo=o(" (Wav2Vec2-Conformer model)"),SLo=l(),y1=a("li"),Eme=a("strong"),RLo=o("xlm"),PLo=o(" \u2014 "),vG=a("a"),BLo=o("XLMWithLMHeadModel"),ILo=o(" (XLM model)"),NLo=l(),x1=a("li"),Cme=a("strong"),qLo=o("xlm-roberta"),jLo=o(" \u2014 "),FG=a("a"),DLo=o("XLMRobertaForMaskedLM"),GLo=o(" (XLM-RoBERTa model)"),OLo=l(),$1=a("li"),wme=a("strong"),VLo=o("xlm-roberta-xl"),XLo=o(" \u2014 "),TG=a("a"),zLo=o("XLMRobertaXLForMaskedLM"),WLo=o(" (XLM-RoBERTa-XL model)"),QLo=l(),k1=a("li"),Ame=a("strong"),HLo=o("xlnet"),ULo=o(" \u2014 "),MG=a("a"),JLo=o("XLNetLMHeadModel"),YLo=o(" (XLNet model)"),KLo=l(),S1=a("p"),ZLo=o("The model is set in evaluation mode by default using "),Lme=a("code"),eyo=o("model.eval()"),oyo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yme=a("code"),ryo=o("model.train()"),tyo=l(),F(R1.$$.fragment),tVe=l(),zi=a("h2"),P1=a("a"),xme=a("span"),F(CL.$$.fragment),ayo=l(),$me=a("span"),nyo=o("AutoModelForCausalLM"),aVe=l(),ko=a("div"),F(wL.$$.fragment),syo=l(),Wi=a("p"),lyo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),EG=a("a"),iyo=o("from_pretrained()"),dyo=o(" class method or the "),CG=a("a"),cyo=o("from_config()"),fyo=o(` class
method.`),myo=l(),AL=a("p"),gyo=o("This class cannot be instantiated directly using "),kme=a("code"),hyo=o("__init__()"),pyo=o(" (throws an error)."),_yo=l(),it=a("div"),F(LL.$$.fragment),uyo=l(),Sme=a("p"),byo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),vyo=l(),Qi=a("p"),Fyo=o(`Note:
Loading a model from its configuration file does `),Rme=a("strong"),Tyo=o("not"),Myo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wG=a("a"),Eyo=o("from_pretrained()"),Cyo=o(" to load the model weights."),wyo=l(),F(B1.$$.fragment),Ayo=l(),Ke=a("div"),F(yL.$$.fragment),Lyo=l(),Pme=a("p"),yyo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),xyo=l(),Na=a("p"),$yo=o("The model class to instantiate is selected based on the "),Bme=a("code"),kyo=o("model_type"),Syo=o(` property of the config object (either
passed as an argument or loaded from `),Ime=a("code"),Ryo=o("pretrained_model_name_or_path"),Pyo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nme=a("code"),Byo=o("pretrained_model_name_or_path"),Iyo=o(":"),Nyo=l(),z=a("ul"),I1=a("li"),qme=a("strong"),qyo=o("bart"),jyo=o(" \u2014 "),AG=a("a"),Dyo=o("BartForCausalLM"),Gyo=o(" (BART model)"),Oyo=l(),N1=a("li"),jme=a("strong"),Vyo=o("bert"),Xyo=o(" \u2014 "),LG=a("a"),zyo=o("BertLMHeadModel"),Wyo=o(" (BERT model)"),Qyo=l(),q1=a("li"),Dme=a("strong"),Hyo=o("bert-generation"),Uyo=o(" \u2014 "),yG=a("a"),Jyo=o("BertGenerationDecoder"),Yyo=o(" (Bert Generation model)"),Kyo=l(),j1=a("li"),Gme=a("strong"),Zyo=o("big_bird"),e9o=o(" \u2014 "),xG=a("a"),o9o=o("BigBirdForCausalLM"),r9o=o(" (BigBird model)"),t9o=l(),D1=a("li"),Ome=a("strong"),a9o=o("bigbird_pegasus"),n9o=o(" \u2014 "),$G=a("a"),s9o=o("BigBirdPegasusForCausalLM"),l9o=o(" (BigBird-Pegasus model)"),i9o=l(),G1=a("li"),Vme=a("strong"),d9o=o("blenderbot"),c9o=o(" \u2014 "),kG=a("a"),f9o=o("BlenderbotForCausalLM"),m9o=o(" (Blenderbot model)"),g9o=l(),O1=a("li"),Xme=a("strong"),h9o=o("blenderbot-small"),p9o=o(" \u2014 "),SG=a("a"),_9o=o("BlenderbotSmallForCausalLM"),u9o=o(" (BlenderbotSmall model)"),b9o=l(),V1=a("li"),zme=a("strong"),v9o=o("bloom"),F9o=o(" \u2014 "),RG=a("a"),T9o=o("BloomForCausalLM"),M9o=o(" (BLOOM model)"),E9o=l(),X1=a("li"),Wme=a("strong"),C9o=o("camembert"),w9o=o(" \u2014 "),PG=a("a"),A9o=o("CamembertForCausalLM"),L9o=o(" (CamemBERT model)"),y9o=l(),z1=a("li"),Qme=a("strong"),x9o=o("codegen"),$9o=o(" \u2014 "),BG=a("a"),k9o=o("CodeGenForCausalLM"),S9o=o(" (CodeGen model)"),R9o=l(),W1=a("li"),Hme=a("strong"),P9o=o("ctrl"),B9o=o(" \u2014 "),IG=a("a"),I9o=o("CTRLLMHeadModel"),N9o=o(" (CTRL model)"),q9o=l(),Q1=a("li"),Ume=a("strong"),j9o=o("data2vec-text"),D9o=o(" \u2014 "),NG=a("a"),G9o=o("Data2VecTextForCausalLM"),O9o=o(" (Data2VecText model)"),V9o=l(),H1=a("li"),Jme=a("strong"),X9o=o("electra"),z9o=o(" \u2014 "),qG=a("a"),W9o=o("ElectraForCausalLM"),Q9o=o(" (ELECTRA model)"),H9o=l(),U1=a("li"),Yme=a("strong"),U9o=o("gpt2"),J9o=o(" \u2014 "),jG=a("a"),Y9o=o("GPT2LMHeadModel"),K9o=o(" (OpenAI GPT-2 model)"),Z9o=l(),J1=a("li"),Kme=a("strong"),exo=o("gpt_neo"),oxo=o(" \u2014 "),DG=a("a"),rxo=o("GPTNeoForCausalLM"),txo=o(" (GPT Neo model)"),axo=l(),Y1=a("li"),Zme=a("strong"),nxo=o("gpt_neox"),sxo=o(" \u2014 "),GG=a("a"),lxo=o("GPTNeoXForCausalLM"),ixo=o(" (GPT NeoX model)"),dxo=l(),K1=a("li"),ege=a("strong"),cxo=o("gptj"),fxo=o(" \u2014 "),OG=a("a"),mxo=o("GPTJForCausalLM"),gxo=o(" (GPT-J model)"),hxo=l(),Z1=a("li"),oge=a("strong"),pxo=o("marian"),_xo=o(" \u2014 "),VG=a("a"),uxo=o("MarianForCausalLM"),bxo=o(" (Marian model)"),vxo=l(),e2=a("li"),rge=a("strong"),Fxo=o("mbart"),Txo=o(" \u2014 "),XG=a("a"),Mxo=o("MBartForCausalLM"),Exo=o(" (mBART model)"),Cxo=l(),o2=a("li"),tge=a("strong"),wxo=o("megatron-bert"),Axo=o(" \u2014 "),zG=a("a"),Lxo=o("MegatronBertForCausalLM"),yxo=o(" (Megatron-BERT model)"),xxo=l(),r2=a("li"),age=a("strong"),$xo=o("openai-gpt"),kxo=o(" \u2014 "),WG=a("a"),Sxo=o("OpenAIGPTLMHeadModel"),Rxo=o(" (OpenAI GPT model)"),Pxo=l(),t2=a("li"),nge=a("strong"),Bxo=o("opt"),Ixo=o(" \u2014 "),QG=a("a"),Nxo=o("OPTForCausalLM"),qxo=o(" (OPT model)"),jxo=l(),a2=a("li"),sge=a("strong"),Dxo=o("pegasus"),Gxo=o(" \u2014 "),HG=a("a"),Oxo=o("PegasusForCausalLM"),Vxo=o(" (Pegasus model)"),Xxo=l(),n2=a("li"),lge=a("strong"),zxo=o("plbart"),Wxo=o(" \u2014 "),UG=a("a"),Qxo=o("PLBartForCausalLM"),Hxo=o(" (PLBart model)"),Uxo=l(),s2=a("li"),ige=a("strong"),Jxo=o("prophetnet"),Yxo=o(" \u2014 "),JG=a("a"),Kxo=o("ProphetNetForCausalLM"),Zxo=o(" (ProphetNet model)"),e$o=l(),l2=a("li"),dge=a("strong"),o$o=o("qdqbert"),r$o=o(" \u2014 "),YG=a("a"),t$o=o("QDQBertLMHeadModel"),a$o=o(" (QDQBert model)"),n$o=l(),i2=a("li"),cge=a("strong"),s$o=o("reformer"),l$o=o(" \u2014 "),KG=a("a"),i$o=o("ReformerModelWithLMHead"),d$o=o(" (Reformer model)"),c$o=l(),d2=a("li"),fge=a("strong"),f$o=o("rembert"),m$o=o(" \u2014 "),ZG=a("a"),g$o=o("RemBertForCausalLM"),h$o=o(" (RemBERT model)"),p$o=l(),c2=a("li"),mge=a("strong"),_$o=o("roberta"),u$o=o(" \u2014 "),eO=a("a"),b$o=o("RobertaForCausalLM"),v$o=o(" (RoBERTa model)"),F$o=l(),f2=a("li"),gge=a("strong"),T$o=o("roformer"),M$o=o(" \u2014 "),oO=a("a"),E$o=o("RoFormerForCausalLM"),C$o=o(" (RoFormer model)"),w$o=l(),m2=a("li"),hge=a("strong"),A$o=o("speech_to_text_2"),L$o=o(" \u2014 "),rO=a("a"),y$o=o("Speech2Text2ForCausalLM"),x$o=o(" (Speech2Text2 model)"),$$o=l(),g2=a("li"),pge=a("strong"),k$o=o("transfo-xl"),S$o=o(" \u2014 "),tO=a("a"),R$o=o("TransfoXLLMHeadModel"),P$o=o(" (Transformer-XL model)"),B$o=l(),h2=a("li"),_ge=a("strong"),I$o=o("trocr"),N$o=o(" \u2014 "),aO=a("a"),q$o=o("TrOCRForCausalLM"),j$o=o(" (TrOCR model)"),D$o=l(),p2=a("li"),uge=a("strong"),G$o=o("xglm"),O$o=o(" \u2014 "),nO=a("a"),V$o=o("XGLMForCausalLM"),X$o=o(" (XGLM model)"),z$o=l(),_2=a("li"),bge=a("strong"),W$o=o("xlm"),Q$o=o(" \u2014 "),sO=a("a"),H$o=o("XLMWithLMHeadModel"),U$o=o(" (XLM model)"),J$o=l(),u2=a("li"),vge=a("strong"),Y$o=o("xlm-prophetnet"),K$o=o(" \u2014 "),lO=a("a"),Z$o=o("XLMProphetNetForCausalLM"),eko=o(" (XLM-ProphetNet model)"),oko=l(),b2=a("li"),Fge=a("strong"),rko=o("xlm-roberta"),tko=o(" \u2014 "),iO=a("a"),ako=o("XLMRobertaForCausalLM"),nko=o(" (XLM-RoBERTa model)"),sko=l(),v2=a("li"),Tge=a("strong"),lko=o("xlm-roberta-xl"),iko=o(" \u2014 "),dO=a("a"),dko=o("XLMRobertaXLForCausalLM"),cko=o(" (XLM-RoBERTa-XL model)"),fko=l(),F2=a("li"),Mge=a("strong"),mko=o("xlnet"),gko=o(" \u2014 "),cO=a("a"),hko=o("XLNetLMHeadModel"),pko=o(" (XLNet model)"),_ko=l(),T2=a("p"),uko=o("The model is set in evaluation mode by default using "),Ege=a("code"),bko=o("model.eval()"),vko=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cge=a("code"),Fko=o("model.train()"),Tko=l(),F(M2.$$.fragment),nVe=l(),Hi=a("h2"),E2=a("a"),wge=a("span"),F(xL.$$.fragment),Mko=l(),Age=a("span"),Eko=o("AutoModelForMaskedLM"),sVe=l(),So=a("div"),F($L.$$.fragment),Cko=l(),Ui=a("p"),wko=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),fO=a("a"),Ako=o("from_pretrained()"),Lko=o(" class method or the "),mO=a("a"),yko=o("from_config()"),xko=o(` class
method.`),$ko=l(),kL=a("p"),kko=o("This class cannot be instantiated directly using "),Lge=a("code"),Sko=o("__init__()"),Rko=o(" (throws an error)."),Pko=l(),dt=a("div"),F(SL.$$.fragment),Bko=l(),yge=a("p"),Iko=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Nko=l(),Ji=a("p"),qko=o(`Note:
Loading a model from its configuration file does `),xge=a("strong"),jko=o("not"),Dko=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gO=a("a"),Gko=o("from_pretrained()"),Oko=o(" to load the model weights."),Vko=l(),F(C2.$$.fragment),Xko=l(),Ze=a("div"),F(RL.$$.fragment),zko=l(),$ge=a("p"),Wko=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Qko=l(),qa=a("p"),Hko=o("The model class to instantiate is selected based on the "),kge=a("code"),Uko=o("model_type"),Jko=o(` property of the config object (either
passed as an argument or loaded from `),Sge=a("code"),Yko=o("pretrained_model_name_or_path"),Kko=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rge=a("code"),Zko=o("pretrained_model_name_or_path"),eSo=o(":"),oSo=l(),Q=a("ul"),w2=a("li"),Pge=a("strong"),rSo=o("albert"),tSo=o(" \u2014 "),hO=a("a"),aSo=o("AlbertForMaskedLM"),nSo=o(" (ALBERT model)"),sSo=l(),A2=a("li"),Bge=a("strong"),lSo=o("bart"),iSo=o(" \u2014 "),pO=a("a"),dSo=o("BartForConditionalGeneration"),cSo=o(" (BART model)"),fSo=l(),L2=a("li"),Ige=a("strong"),mSo=o("bert"),gSo=o(" \u2014 "),_O=a("a"),hSo=o("BertForMaskedLM"),pSo=o(" (BERT model)"),_So=l(),y2=a("li"),Nge=a("strong"),uSo=o("big_bird"),bSo=o(" \u2014 "),uO=a("a"),vSo=o("BigBirdForMaskedLM"),FSo=o(" (BigBird model)"),TSo=l(),x2=a("li"),qge=a("strong"),MSo=o("camembert"),ESo=o(" \u2014 "),bO=a("a"),CSo=o("CamembertForMaskedLM"),wSo=o(" (CamemBERT model)"),ASo=l(),$2=a("li"),jge=a("strong"),LSo=o("convbert"),ySo=o(" \u2014 "),vO=a("a"),xSo=o("ConvBertForMaskedLM"),$So=o(" (ConvBERT model)"),kSo=l(),k2=a("li"),Dge=a("strong"),SSo=o("data2vec-text"),RSo=o(" \u2014 "),FO=a("a"),PSo=o("Data2VecTextForMaskedLM"),BSo=o(" (Data2VecText model)"),ISo=l(),S2=a("li"),Gge=a("strong"),NSo=o("deberta"),qSo=o(" \u2014 "),TO=a("a"),jSo=o("DebertaForMaskedLM"),DSo=o(" (DeBERTa model)"),GSo=l(),R2=a("li"),Oge=a("strong"),OSo=o("deberta-v2"),VSo=o(" \u2014 "),MO=a("a"),XSo=o("DebertaV2ForMaskedLM"),zSo=o(" (DeBERTa-v2 model)"),WSo=l(),P2=a("li"),Vge=a("strong"),QSo=o("distilbert"),HSo=o(" \u2014 "),EO=a("a"),USo=o("DistilBertForMaskedLM"),JSo=o(" (DistilBERT model)"),YSo=l(),B2=a("li"),Xge=a("strong"),KSo=o("electra"),ZSo=o(" \u2014 "),CO=a("a"),eRo=o("ElectraForMaskedLM"),oRo=o(" (ELECTRA model)"),rRo=l(),I2=a("li"),zge=a("strong"),tRo=o("flaubert"),aRo=o(" \u2014 "),wO=a("a"),nRo=o("FlaubertWithLMHeadModel"),sRo=o(" (FlauBERT model)"),lRo=l(),N2=a("li"),Wge=a("strong"),iRo=o("fnet"),dRo=o(" \u2014 "),AO=a("a"),cRo=o("FNetForMaskedLM"),fRo=o(" (FNet model)"),mRo=l(),q2=a("li"),Qge=a("strong"),gRo=o("funnel"),hRo=o(" \u2014 "),LO=a("a"),pRo=o("FunnelForMaskedLM"),_Ro=o(" (Funnel Transformer model)"),uRo=l(),j2=a("li"),Hge=a("strong"),bRo=o("ibert"),vRo=o(" \u2014 "),yO=a("a"),FRo=o("IBertForMaskedLM"),TRo=o(" (I-BERT model)"),MRo=l(),D2=a("li"),Uge=a("strong"),ERo=o("layoutlm"),CRo=o(" \u2014 "),xO=a("a"),wRo=o("LayoutLMForMaskedLM"),ARo=o(" (LayoutLM model)"),LRo=l(),G2=a("li"),Jge=a("strong"),yRo=o("longformer"),xRo=o(" \u2014 "),$O=a("a"),$Ro=o("LongformerForMaskedLM"),kRo=o(" (Longformer model)"),SRo=l(),O2=a("li"),Yge=a("strong"),RRo=o("luke"),PRo=o(" \u2014 "),kO=a("a"),BRo=o("LukeForMaskedLM"),IRo=o(" (LUKE model)"),NRo=l(),V2=a("li"),Kge=a("strong"),qRo=o("mbart"),jRo=o(" \u2014 "),SO=a("a"),DRo=o("MBartForConditionalGeneration"),GRo=o(" (mBART model)"),ORo=l(),X2=a("li"),Zge=a("strong"),VRo=o("megatron-bert"),XRo=o(" \u2014 "),RO=a("a"),zRo=o("MegatronBertForMaskedLM"),WRo=o(" (Megatron-BERT model)"),QRo=l(),z2=a("li"),ehe=a("strong"),HRo=o("mobilebert"),URo=o(" \u2014 "),PO=a("a"),JRo=o("MobileBertForMaskedLM"),YRo=o(" (MobileBERT model)"),KRo=l(),W2=a("li"),ohe=a("strong"),ZRo=o("mpnet"),ePo=o(" \u2014 "),BO=a("a"),oPo=o("MPNetForMaskedLM"),rPo=o(" (MPNet model)"),tPo=l(),Q2=a("li"),rhe=a("strong"),aPo=o("nezha"),nPo=o(" \u2014 "),IO=a("a"),sPo=o("NezhaForMaskedLM"),lPo=o(" (Nezha model)"),iPo=l(),H2=a("li"),the=a("strong"),dPo=o("nystromformer"),cPo=o(" \u2014 "),NO=a("a"),fPo=o("NystromformerForMaskedLM"),mPo=o(" (Nystr\xF6mformer model)"),gPo=l(),U2=a("li"),ahe=a("strong"),hPo=o("perceiver"),pPo=o(" \u2014 "),qO=a("a"),_Po=o("PerceiverForMaskedLM"),uPo=o(" (Perceiver model)"),bPo=l(),J2=a("li"),nhe=a("strong"),vPo=o("qdqbert"),FPo=o(" \u2014 "),jO=a("a"),TPo=o("QDQBertForMaskedLM"),MPo=o(" (QDQBert model)"),EPo=l(),Y2=a("li"),she=a("strong"),CPo=o("reformer"),wPo=o(" \u2014 "),DO=a("a"),APo=o("ReformerForMaskedLM"),LPo=o(" (Reformer model)"),yPo=l(),K2=a("li"),lhe=a("strong"),xPo=o("rembert"),$Po=o(" \u2014 "),GO=a("a"),kPo=o("RemBertForMaskedLM"),SPo=o(" (RemBERT model)"),RPo=l(),Z2=a("li"),ihe=a("strong"),PPo=o("roberta"),BPo=o(" \u2014 "),OO=a("a"),IPo=o("RobertaForMaskedLM"),NPo=o(" (RoBERTa model)"),qPo=l(),eb=a("li"),dhe=a("strong"),jPo=o("roformer"),DPo=o(" \u2014 "),VO=a("a"),GPo=o("RoFormerForMaskedLM"),OPo=o(" (RoFormer model)"),VPo=l(),ob=a("li"),che=a("strong"),XPo=o("squeezebert"),zPo=o(" \u2014 "),XO=a("a"),WPo=o("SqueezeBertForMaskedLM"),QPo=o(" (SqueezeBERT model)"),HPo=l(),rb=a("li"),fhe=a("strong"),UPo=o("tapas"),JPo=o(" \u2014 "),zO=a("a"),YPo=o("TapasForMaskedLM"),KPo=o(" (TAPAS model)"),ZPo=l(),tb=a("li"),mhe=a("strong"),eBo=o("wav2vec2"),oBo=o(" \u2014 "),ghe=a("code"),rBo=o("Wav2Vec2ForMaskedLM"),tBo=o(" (Wav2Vec2 model)"),aBo=l(),ab=a("li"),hhe=a("strong"),nBo=o("xlm"),sBo=o(" \u2014 "),WO=a("a"),lBo=o("XLMWithLMHeadModel"),iBo=o(" (XLM model)"),dBo=l(),nb=a("li"),phe=a("strong"),cBo=o("xlm-roberta"),fBo=o(" \u2014 "),QO=a("a"),mBo=o("XLMRobertaForMaskedLM"),gBo=o(" (XLM-RoBERTa model)"),hBo=l(),sb=a("li"),_he=a("strong"),pBo=o("xlm-roberta-xl"),_Bo=o(" \u2014 "),HO=a("a"),uBo=o("XLMRobertaXLForMaskedLM"),bBo=o(" (XLM-RoBERTa-XL model)"),vBo=l(),lb=a("li"),uhe=a("strong"),FBo=o("yoso"),TBo=o(" \u2014 "),UO=a("a"),MBo=o("YosoForMaskedLM"),EBo=o(" (YOSO model)"),CBo=l(),ib=a("p"),wBo=o("The model is set in evaluation mode by default using "),bhe=a("code"),ABo=o("model.eval()"),LBo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vhe=a("code"),yBo=o("model.train()"),xBo=l(),F(db.$$.fragment),lVe=l(),Yi=a("h2"),cb=a("a"),Fhe=a("span"),F(PL.$$.fragment),$Bo=l(),The=a("span"),kBo=o("AutoModelForSeq2SeqLM"),iVe=l(),Ro=a("div"),F(BL.$$.fragment),SBo=l(),Ki=a("p"),RBo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),JO=a("a"),PBo=o("from_pretrained()"),BBo=o(" class method or the "),YO=a("a"),IBo=o("from_config()"),NBo=o(` class
method.`),qBo=l(),IL=a("p"),jBo=o("This class cannot be instantiated directly using "),Mhe=a("code"),DBo=o("__init__()"),GBo=o(" (throws an error)."),OBo=l(),ct=a("div"),F(NL.$$.fragment),VBo=l(),Ehe=a("p"),XBo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),zBo=l(),Zi=a("p"),WBo=o(`Note:
Loading a model from its configuration file does `),Che=a("strong"),QBo=o("not"),HBo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KO=a("a"),UBo=o("from_pretrained()"),JBo=o(" to load the model weights."),YBo=l(),F(fb.$$.fragment),KBo=l(),eo=a("div"),F(qL.$$.fragment),ZBo=l(),whe=a("p"),eIo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),oIo=l(),ja=a("p"),rIo=o("The model class to instantiate is selected based on the "),Ahe=a("code"),tIo=o("model_type"),aIo=o(` property of the config object (either
passed as an argument or loaded from `),Lhe=a("code"),nIo=o("pretrained_model_name_or_path"),sIo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yhe=a("code"),lIo=o("pretrained_model_name_or_path"),iIo=o(":"),dIo=l(),pe=a("ul"),mb=a("li"),xhe=a("strong"),cIo=o("bart"),fIo=o(" \u2014 "),ZO=a("a"),mIo=o("BartForConditionalGeneration"),gIo=o(" (BART model)"),hIo=l(),gb=a("li"),$he=a("strong"),pIo=o("bigbird_pegasus"),_Io=o(" \u2014 "),eV=a("a"),uIo=o("BigBirdPegasusForConditionalGeneration"),bIo=o(" (BigBird-Pegasus model)"),vIo=l(),hb=a("li"),khe=a("strong"),FIo=o("blenderbot"),TIo=o(" \u2014 "),oV=a("a"),MIo=o("BlenderbotForConditionalGeneration"),EIo=o(" (Blenderbot model)"),CIo=l(),pb=a("li"),She=a("strong"),wIo=o("blenderbot-small"),AIo=o(" \u2014 "),rV=a("a"),LIo=o("BlenderbotSmallForConditionalGeneration"),yIo=o(" (BlenderbotSmall model)"),xIo=l(),_b=a("li"),Rhe=a("strong"),$Io=o("encoder-decoder"),kIo=o(" \u2014 "),tV=a("a"),SIo=o("EncoderDecoderModel"),RIo=o(" (Encoder decoder model)"),PIo=l(),ub=a("li"),Phe=a("strong"),BIo=o("fsmt"),IIo=o(" \u2014 "),aV=a("a"),NIo=o("FSMTForConditionalGeneration"),qIo=o(" (FairSeq Machine-Translation model)"),jIo=l(),bb=a("li"),Bhe=a("strong"),DIo=o("led"),GIo=o(" \u2014 "),nV=a("a"),OIo=o("LEDForConditionalGeneration"),VIo=o(" (LED model)"),XIo=l(),vb=a("li"),Ihe=a("strong"),zIo=o("longt5"),WIo=o(" \u2014 "),sV=a("a"),QIo=o("LongT5ForConditionalGeneration"),HIo=o(" (LongT5 model)"),UIo=l(),Fb=a("li"),Nhe=a("strong"),JIo=o("m2m_100"),YIo=o(" \u2014 "),lV=a("a"),KIo=o("M2M100ForConditionalGeneration"),ZIo=o(" (M2M100 model)"),eNo=l(),Tb=a("li"),qhe=a("strong"),oNo=o("marian"),rNo=o(" \u2014 "),iV=a("a"),tNo=o("MarianMTModel"),aNo=o(" (Marian model)"),nNo=l(),Mb=a("li"),jhe=a("strong"),sNo=o("mbart"),lNo=o(" \u2014 "),dV=a("a"),iNo=o("MBartForConditionalGeneration"),dNo=o(" (mBART model)"),cNo=l(),Eb=a("li"),Dhe=a("strong"),fNo=o("mt5"),mNo=o(" \u2014 "),cV=a("a"),gNo=o("MT5ForConditionalGeneration"),hNo=o(" (MT5 model)"),pNo=l(),Cb=a("li"),Ghe=a("strong"),_No=o("pegasus"),uNo=o(" \u2014 "),fV=a("a"),bNo=o("PegasusForConditionalGeneration"),vNo=o(" (Pegasus model)"),FNo=l(),wb=a("li"),Ohe=a("strong"),TNo=o("plbart"),MNo=o(" \u2014 "),mV=a("a"),ENo=o("PLBartForConditionalGeneration"),CNo=o(" (PLBart model)"),wNo=l(),Ab=a("li"),Vhe=a("strong"),ANo=o("prophetnet"),LNo=o(" \u2014 "),gV=a("a"),yNo=o("ProphetNetForConditionalGeneration"),xNo=o(" (ProphetNet model)"),$No=l(),Lb=a("li"),Xhe=a("strong"),kNo=o("t5"),SNo=o(" \u2014 "),hV=a("a"),RNo=o("T5ForConditionalGeneration"),PNo=o(" (T5 model)"),BNo=l(),yb=a("li"),zhe=a("strong"),INo=o("xlm-prophetnet"),NNo=o(" \u2014 "),pV=a("a"),qNo=o("XLMProphetNetForConditionalGeneration"),jNo=o(" (XLM-ProphetNet model)"),DNo=l(),xb=a("p"),GNo=o("The model is set in evaluation mode by default using "),Whe=a("code"),ONo=o("model.eval()"),VNo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Qhe=a("code"),XNo=o("model.train()"),zNo=l(),F($b.$$.fragment),dVe=l(),ed=a("h2"),kb=a("a"),Hhe=a("span"),F(jL.$$.fragment),WNo=l(),Uhe=a("span"),QNo=o("AutoModelForSequenceClassification"),cVe=l(),Po=a("div"),F(DL.$$.fragment),HNo=l(),od=a("p"),UNo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),_V=a("a"),JNo=o("from_pretrained()"),YNo=o(" class method or the "),uV=a("a"),KNo=o("from_config()"),ZNo=o(` class
method.`),eqo=l(),GL=a("p"),oqo=o("This class cannot be instantiated directly using "),Jhe=a("code"),rqo=o("__init__()"),tqo=o(" (throws an error)."),aqo=l(),ft=a("div"),F(OL.$$.fragment),nqo=l(),Yhe=a("p"),sqo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),lqo=l(),rd=a("p"),iqo=o(`Note:
Loading a model from its configuration file does `),Khe=a("strong"),dqo=o("not"),cqo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bV=a("a"),fqo=o("from_pretrained()"),mqo=o(" to load the model weights."),gqo=l(),F(Sb.$$.fragment),hqo=l(),oo=a("div"),F(VL.$$.fragment),pqo=l(),Zhe=a("p"),_qo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),uqo=l(),Da=a("p"),bqo=o("The model class to instantiate is selected based on the "),epe=a("code"),vqo=o("model_type"),Fqo=o(` property of the config object (either
passed as an argument or loaded from `),ope=a("code"),Tqo=o("pretrained_model_name_or_path"),Mqo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rpe=a("code"),Eqo=o("pretrained_model_name_or_path"),Cqo=o(":"),wqo=l(),N=a("ul"),Rb=a("li"),tpe=a("strong"),Aqo=o("albert"),Lqo=o(" \u2014 "),vV=a("a"),yqo=o("AlbertForSequenceClassification"),xqo=o(" (ALBERT model)"),$qo=l(),Pb=a("li"),ape=a("strong"),kqo=o("bart"),Sqo=o(" \u2014 "),FV=a("a"),Rqo=o("BartForSequenceClassification"),Pqo=o(" (BART model)"),Bqo=l(),Bb=a("li"),npe=a("strong"),Iqo=o("bert"),Nqo=o(" \u2014 "),TV=a("a"),qqo=o("BertForSequenceClassification"),jqo=o(" (BERT model)"),Dqo=l(),Ib=a("li"),spe=a("strong"),Gqo=o("big_bird"),Oqo=o(" \u2014 "),MV=a("a"),Vqo=o("BigBirdForSequenceClassification"),Xqo=o(" (BigBird model)"),zqo=l(),Nb=a("li"),lpe=a("strong"),Wqo=o("bigbird_pegasus"),Qqo=o(" \u2014 "),EV=a("a"),Hqo=o("BigBirdPegasusForSequenceClassification"),Uqo=o(" (BigBird-Pegasus model)"),Jqo=l(),qb=a("li"),ipe=a("strong"),Yqo=o("bloom"),Kqo=o(" \u2014 "),CV=a("a"),Zqo=o("BloomForSequenceClassification"),ejo=o(" (BLOOM model)"),ojo=l(),jb=a("li"),dpe=a("strong"),rjo=o("camembert"),tjo=o(" \u2014 "),wV=a("a"),ajo=o("CamembertForSequenceClassification"),njo=o(" (CamemBERT model)"),sjo=l(),Db=a("li"),cpe=a("strong"),ljo=o("canine"),ijo=o(" \u2014 "),AV=a("a"),djo=o("CanineForSequenceClassification"),cjo=o(" (CANINE model)"),fjo=l(),Gb=a("li"),fpe=a("strong"),mjo=o("convbert"),gjo=o(" \u2014 "),LV=a("a"),hjo=o("ConvBertForSequenceClassification"),pjo=o(" (ConvBERT model)"),_jo=l(),Ob=a("li"),mpe=a("strong"),ujo=o("ctrl"),bjo=o(" \u2014 "),yV=a("a"),vjo=o("CTRLForSequenceClassification"),Fjo=o(" (CTRL model)"),Tjo=l(),Vb=a("li"),gpe=a("strong"),Mjo=o("data2vec-text"),Ejo=o(" \u2014 "),xV=a("a"),Cjo=o("Data2VecTextForSequenceClassification"),wjo=o(" (Data2VecText model)"),Ajo=l(),Xb=a("li"),hpe=a("strong"),Ljo=o("deberta"),yjo=o(" \u2014 "),$V=a("a"),xjo=o("DebertaForSequenceClassification"),$jo=o(" (DeBERTa model)"),kjo=l(),zb=a("li"),ppe=a("strong"),Sjo=o("deberta-v2"),Rjo=o(" \u2014 "),kV=a("a"),Pjo=o("DebertaV2ForSequenceClassification"),Bjo=o(" (DeBERTa-v2 model)"),Ijo=l(),Wb=a("li"),_pe=a("strong"),Njo=o("distilbert"),qjo=o(" \u2014 "),SV=a("a"),jjo=o("DistilBertForSequenceClassification"),Djo=o(" (DistilBERT model)"),Gjo=l(),Qb=a("li"),upe=a("strong"),Ojo=o("electra"),Vjo=o(" \u2014 "),RV=a("a"),Xjo=o("ElectraForSequenceClassification"),zjo=o(" (ELECTRA model)"),Wjo=l(),Hb=a("li"),bpe=a("strong"),Qjo=o("flaubert"),Hjo=o(" \u2014 "),PV=a("a"),Ujo=o("FlaubertForSequenceClassification"),Jjo=o(" (FlauBERT model)"),Yjo=l(),Ub=a("li"),vpe=a("strong"),Kjo=o("fnet"),Zjo=o(" \u2014 "),BV=a("a"),eDo=o("FNetForSequenceClassification"),oDo=o(" (FNet model)"),rDo=l(),Jb=a("li"),Fpe=a("strong"),tDo=o("funnel"),aDo=o(" \u2014 "),IV=a("a"),nDo=o("FunnelForSequenceClassification"),sDo=o(" (Funnel Transformer model)"),lDo=l(),Yb=a("li"),Tpe=a("strong"),iDo=o("gpt2"),dDo=o(" \u2014 "),NV=a("a"),cDo=o("GPT2ForSequenceClassification"),fDo=o(" (OpenAI GPT-2 model)"),mDo=l(),Kb=a("li"),Mpe=a("strong"),gDo=o("gpt_neo"),hDo=o(" \u2014 "),qV=a("a"),pDo=o("GPTNeoForSequenceClassification"),_Do=o(" (GPT Neo model)"),uDo=l(),Zb=a("li"),Epe=a("strong"),bDo=o("gptj"),vDo=o(" \u2014 "),jV=a("a"),FDo=o("GPTJForSequenceClassification"),TDo=o(" (GPT-J model)"),MDo=l(),ev=a("li"),Cpe=a("strong"),EDo=o("ibert"),CDo=o(" \u2014 "),DV=a("a"),wDo=o("IBertForSequenceClassification"),ADo=o(" (I-BERT model)"),LDo=l(),ov=a("li"),wpe=a("strong"),yDo=o("layoutlm"),xDo=o(" \u2014 "),GV=a("a"),$Do=o("LayoutLMForSequenceClassification"),kDo=o(" (LayoutLM model)"),SDo=l(),rv=a("li"),Ape=a("strong"),RDo=o("layoutlmv2"),PDo=o(" \u2014 "),OV=a("a"),BDo=o("LayoutLMv2ForSequenceClassification"),IDo=o(" (LayoutLMv2 model)"),NDo=l(),tv=a("li"),Lpe=a("strong"),qDo=o("layoutlmv3"),jDo=o(" \u2014 "),VV=a("a"),DDo=o("LayoutLMv3ForSequenceClassification"),GDo=o(" (LayoutLMv3 model)"),ODo=l(),av=a("li"),ype=a("strong"),VDo=o("led"),XDo=o(" \u2014 "),XV=a("a"),zDo=o("LEDForSequenceClassification"),WDo=o(" (LED model)"),QDo=l(),nv=a("li"),xpe=a("strong"),HDo=o("longformer"),UDo=o(" \u2014 "),zV=a("a"),JDo=o("LongformerForSequenceClassification"),YDo=o(" (Longformer model)"),KDo=l(),sv=a("li"),$pe=a("strong"),ZDo=o("mbart"),eGo=o(" \u2014 "),WV=a("a"),oGo=o("MBartForSequenceClassification"),rGo=o(" (mBART model)"),tGo=l(),lv=a("li"),kpe=a("strong"),aGo=o("megatron-bert"),nGo=o(" \u2014 "),QV=a("a"),sGo=o("MegatronBertForSequenceClassification"),lGo=o(" (Megatron-BERT model)"),iGo=l(),iv=a("li"),Spe=a("strong"),dGo=o("mobilebert"),cGo=o(" \u2014 "),HV=a("a"),fGo=o("MobileBertForSequenceClassification"),mGo=o(" (MobileBERT model)"),gGo=l(),dv=a("li"),Rpe=a("strong"),hGo=o("mpnet"),pGo=o(" \u2014 "),UV=a("a"),_Go=o("MPNetForSequenceClassification"),uGo=o(" (MPNet model)"),bGo=l(),cv=a("li"),Ppe=a("strong"),vGo=o("nezha"),FGo=o(" \u2014 "),JV=a("a"),TGo=o("NezhaForSequenceClassification"),MGo=o(" (Nezha model)"),EGo=l(),fv=a("li"),Bpe=a("strong"),CGo=o("nystromformer"),wGo=o(" \u2014 "),YV=a("a"),AGo=o("NystromformerForSequenceClassification"),LGo=o(" (Nystr\xF6mformer model)"),yGo=l(),mv=a("li"),Ipe=a("strong"),xGo=o("openai-gpt"),$Go=o(" \u2014 "),KV=a("a"),kGo=o("OpenAIGPTForSequenceClassification"),SGo=o(" (OpenAI GPT model)"),RGo=l(),gv=a("li"),Npe=a("strong"),PGo=o("perceiver"),BGo=o(" \u2014 "),ZV=a("a"),IGo=o("PerceiverForSequenceClassification"),NGo=o(" (Perceiver model)"),qGo=l(),hv=a("li"),qpe=a("strong"),jGo=o("plbart"),DGo=o(" \u2014 "),eX=a("a"),GGo=o("PLBartForSequenceClassification"),OGo=o(" (PLBart model)"),VGo=l(),pv=a("li"),jpe=a("strong"),XGo=o("qdqbert"),zGo=o(" \u2014 "),oX=a("a"),WGo=o("QDQBertForSequenceClassification"),QGo=o(" (QDQBert model)"),HGo=l(),_v=a("li"),Dpe=a("strong"),UGo=o("reformer"),JGo=o(" \u2014 "),rX=a("a"),YGo=o("ReformerForSequenceClassification"),KGo=o(" (Reformer model)"),ZGo=l(),uv=a("li"),Gpe=a("strong"),eOo=o("rembert"),oOo=o(" \u2014 "),tX=a("a"),rOo=o("RemBertForSequenceClassification"),tOo=o(" (RemBERT model)"),aOo=l(),bv=a("li"),Ope=a("strong"),nOo=o("roberta"),sOo=o(" \u2014 "),aX=a("a"),lOo=o("RobertaForSequenceClassification"),iOo=o(" (RoBERTa model)"),dOo=l(),vv=a("li"),Vpe=a("strong"),cOo=o("roformer"),fOo=o(" \u2014 "),nX=a("a"),mOo=o("RoFormerForSequenceClassification"),gOo=o(" (RoFormer model)"),hOo=l(),Fv=a("li"),Xpe=a("strong"),pOo=o("squeezebert"),_Oo=o(" \u2014 "),sX=a("a"),uOo=o("SqueezeBertForSequenceClassification"),bOo=o(" (SqueezeBERT model)"),vOo=l(),Tv=a("li"),zpe=a("strong"),FOo=o("tapas"),TOo=o(" \u2014 "),lX=a("a"),MOo=o("TapasForSequenceClassification"),EOo=o(" (TAPAS model)"),COo=l(),Mv=a("li"),Wpe=a("strong"),wOo=o("transfo-xl"),AOo=o(" \u2014 "),iX=a("a"),LOo=o("TransfoXLForSequenceClassification"),yOo=o(" (Transformer-XL model)"),xOo=l(),Ev=a("li"),Qpe=a("strong"),$Oo=o("xlm"),kOo=o(" \u2014 "),dX=a("a"),SOo=o("XLMForSequenceClassification"),ROo=o(" (XLM model)"),POo=l(),Cv=a("li"),Hpe=a("strong"),BOo=o("xlm-roberta"),IOo=o(" \u2014 "),cX=a("a"),NOo=o("XLMRobertaForSequenceClassification"),qOo=o(" (XLM-RoBERTa model)"),jOo=l(),wv=a("li"),Upe=a("strong"),DOo=o("xlm-roberta-xl"),GOo=o(" \u2014 "),fX=a("a"),OOo=o("XLMRobertaXLForSequenceClassification"),VOo=o(" (XLM-RoBERTa-XL model)"),XOo=l(),Av=a("li"),Jpe=a("strong"),zOo=o("xlnet"),WOo=o(" \u2014 "),mX=a("a"),QOo=o("XLNetForSequenceClassification"),HOo=o(" (XLNet model)"),UOo=l(),Lv=a("li"),Ype=a("strong"),JOo=o("yoso"),YOo=o(" \u2014 "),gX=a("a"),KOo=o("YosoForSequenceClassification"),ZOo=o(" (YOSO model)"),eVo=l(),yv=a("p"),oVo=o("The model is set in evaluation mode by default using "),Kpe=a("code"),rVo=o("model.eval()"),tVo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Zpe=a("code"),aVo=o("model.train()"),nVo=l(),F(xv.$$.fragment),fVe=l(),td=a("h2"),$v=a("a"),e_e=a("span"),F(XL.$$.fragment),sVo=l(),o_e=a("span"),lVo=o("AutoModelForMultipleChoice"),mVe=l(),Bo=a("div"),F(zL.$$.fragment),iVo=l(),ad=a("p"),dVo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),hX=a("a"),cVo=o("from_pretrained()"),fVo=o(" class method or the "),pX=a("a"),mVo=o("from_config()"),gVo=o(` class
method.`),hVo=l(),WL=a("p"),pVo=o("This class cannot be instantiated directly using "),r_e=a("code"),_Vo=o("__init__()"),uVo=o(" (throws an error)."),bVo=l(),mt=a("div"),F(QL.$$.fragment),vVo=l(),t_e=a("p"),FVo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),TVo=l(),nd=a("p"),MVo=o(`Note:
Loading a model from its configuration file does `),a_e=a("strong"),EVo=o("not"),CVo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_X=a("a"),wVo=o("from_pretrained()"),AVo=o(" to load the model weights."),LVo=l(),F(kv.$$.fragment),yVo=l(),ro=a("div"),F(HL.$$.fragment),xVo=l(),n_e=a("p"),$Vo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),kVo=l(),Ga=a("p"),SVo=o("The model class to instantiate is selected based on the "),s_e=a("code"),RVo=o("model_type"),PVo=o(` property of the config object (either
passed as an argument or loaded from `),l_e=a("code"),BVo=o("pretrained_model_name_or_path"),IVo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i_e=a("code"),NVo=o("pretrained_model_name_or_path"),qVo=o(":"),jVo=l(),Z=a("ul"),Sv=a("li"),d_e=a("strong"),DVo=o("albert"),GVo=o(" \u2014 "),uX=a("a"),OVo=o("AlbertForMultipleChoice"),VVo=o(" (ALBERT model)"),XVo=l(),Rv=a("li"),c_e=a("strong"),zVo=o("bert"),WVo=o(" \u2014 "),bX=a("a"),QVo=o("BertForMultipleChoice"),HVo=o(" (BERT model)"),UVo=l(),Pv=a("li"),f_e=a("strong"),JVo=o("big_bird"),YVo=o(" \u2014 "),vX=a("a"),KVo=o("BigBirdForMultipleChoice"),ZVo=o(" (BigBird model)"),eXo=l(),Bv=a("li"),m_e=a("strong"),oXo=o("camembert"),rXo=o(" \u2014 "),FX=a("a"),tXo=o("CamembertForMultipleChoice"),aXo=o(" (CamemBERT model)"),nXo=l(),Iv=a("li"),g_e=a("strong"),sXo=o("canine"),lXo=o(" \u2014 "),TX=a("a"),iXo=o("CanineForMultipleChoice"),dXo=o(" (CANINE model)"),cXo=l(),Nv=a("li"),h_e=a("strong"),fXo=o("convbert"),mXo=o(" \u2014 "),MX=a("a"),gXo=o("ConvBertForMultipleChoice"),hXo=o(" (ConvBERT model)"),pXo=l(),qv=a("li"),p_e=a("strong"),_Xo=o("data2vec-text"),uXo=o(" \u2014 "),EX=a("a"),bXo=o("Data2VecTextForMultipleChoice"),vXo=o(" (Data2VecText model)"),FXo=l(),jv=a("li"),__e=a("strong"),TXo=o("deberta-v2"),MXo=o(" \u2014 "),CX=a("a"),EXo=o("DebertaV2ForMultipleChoice"),CXo=o(" (DeBERTa-v2 model)"),wXo=l(),Dv=a("li"),u_e=a("strong"),AXo=o("distilbert"),LXo=o(" \u2014 "),wX=a("a"),yXo=o("DistilBertForMultipleChoice"),xXo=o(" (DistilBERT model)"),$Xo=l(),Gv=a("li"),b_e=a("strong"),kXo=o("electra"),SXo=o(" \u2014 "),AX=a("a"),RXo=o("ElectraForMultipleChoice"),PXo=o(" (ELECTRA model)"),BXo=l(),Ov=a("li"),v_e=a("strong"),IXo=o("flaubert"),NXo=o(" \u2014 "),LX=a("a"),qXo=o("FlaubertForMultipleChoice"),jXo=o(" (FlauBERT model)"),DXo=l(),Vv=a("li"),F_e=a("strong"),GXo=o("fnet"),OXo=o(" \u2014 "),yX=a("a"),VXo=o("FNetForMultipleChoice"),XXo=o(" (FNet model)"),zXo=l(),Xv=a("li"),T_e=a("strong"),WXo=o("funnel"),QXo=o(" \u2014 "),xX=a("a"),HXo=o("FunnelForMultipleChoice"),UXo=o(" (Funnel Transformer model)"),JXo=l(),zv=a("li"),M_e=a("strong"),YXo=o("ibert"),KXo=o(" \u2014 "),$X=a("a"),ZXo=o("IBertForMultipleChoice"),ezo=o(" (I-BERT model)"),ozo=l(),Wv=a("li"),E_e=a("strong"),rzo=o("longformer"),tzo=o(" \u2014 "),kX=a("a"),azo=o("LongformerForMultipleChoice"),nzo=o(" (Longformer model)"),szo=l(),Qv=a("li"),C_e=a("strong"),lzo=o("megatron-bert"),izo=o(" \u2014 "),SX=a("a"),dzo=o("MegatronBertForMultipleChoice"),czo=o(" (Megatron-BERT model)"),fzo=l(),Hv=a("li"),w_e=a("strong"),mzo=o("mobilebert"),gzo=o(" \u2014 "),RX=a("a"),hzo=o("MobileBertForMultipleChoice"),pzo=o(" (MobileBERT model)"),_zo=l(),Uv=a("li"),A_e=a("strong"),uzo=o("mpnet"),bzo=o(" \u2014 "),PX=a("a"),vzo=o("MPNetForMultipleChoice"),Fzo=o(" (MPNet model)"),Tzo=l(),Jv=a("li"),L_e=a("strong"),Mzo=o("nezha"),Ezo=o(" \u2014 "),BX=a("a"),Czo=o("NezhaForMultipleChoice"),wzo=o(" (Nezha model)"),Azo=l(),Yv=a("li"),y_e=a("strong"),Lzo=o("nystromformer"),yzo=o(" \u2014 "),IX=a("a"),xzo=o("NystromformerForMultipleChoice"),$zo=o(" (Nystr\xF6mformer model)"),kzo=l(),Kv=a("li"),x_e=a("strong"),Szo=o("qdqbert"),Rzo=o(" \u2014 "),NX=a("a"),Pzo=o("QDQBertForMultipleChoice"),Bzo=o(" (QDQBert model)"),Izo=l(),Zv=a("li"),$_e=a("strong"),Nzo=o("rembert"),qzo=o(" \u2014 "),qX=a("a"),jzo=o("RemBertForMultipleChoice"),Dzo=o(" (RemBERT model)"),Gzo=l(),e0=a("li"),k_e=a("strong"),Ozo=o("roberta"),Vzo=o(" \u2014 "),jX=a("a"),Xzo=o("RobertaForMultipleChoice"),zzo=o(" (RoBERTa model)"),Wzo=l(),o0=a("li"),S_e=a("strong"),Qzo=o("roformer"),Hzo=o(" \u2014 "),DX=a("a"),Uzo=o("RoFormerForMultipleChoice"),Jzo=o(" (RoFormer model)"),Yzo=l(),r0=a("li"),R_e=a("strong"),Kzo=o("squeezebert"),Zzo=o(" \u2014 "),GX=a("a"),eWo=o("SqueezeBertForMultipleChoice"),oWo=o(" (SqueezeBERT model)"),rWo=l(),t0=a("li"),P_e=a("strong"),tWo=o("xlm"),aWo=o(" \u2014 "),OX=a("a"),nWo=o("XLMForMultipleChoice"),sWo=o(" (XLM model)"),lWo=l(),a0=a("li"),B_e=a("strong"),iWo=o("xlm-roberta"),dWo=o(" \u2014 "),VX=a("a"),cWo=o("XLMRobertaForMultipleChoice"),fWo=o(" (XLM-RoBERTa model)"),mWo=l(),n0=a("li"),I_e=a("strong"),gWo=o("xlm-roberta-xl"),hWo=o(" \u2014 "),XX=a("a"),pWo=o("XLMRobertaXLForMultipleChoice"),_Wo=o(" (XLM-RoBERTa-XL model)"),uWo=l(),s0=a("li"),N_e=a("strong"),bWo=o("xlnet"),vWo=o(" \u2014 "),zX=a("a"),FWo=o("XLNetForMultipleChoice"),TWo=o(" (XLNet model)"),MWo=l(),l0=a("li"),q_e=a("strong"),EWo=o("yoso"),CWo=o(" \u2014 "),WX=a("a"),wWo=o("YosoForMultipleChoice"),AWo=o(" (YOSO model)"),LWo=l(),i0=a("p"),yWo=o("The model is set in evaluation mode by default using "),j_e=a("code"),xWo=o("model.eval()"),$Wo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),D_e=a("code"),kWo=o("model.train()"),SWo=l(),F(d0.$$.fragment),gVe=l(),sd=a("h2"),c0=a("a"),G_e=a("span"),F(UL.$$.fragment),RWo=l(),O_e=a("span"),PWo=o("AutoModelForNextSentencePrediction"),hVe=l(),Io=a("div"),F(JL.$$.fragment),BWo=l(),ld=a("p"),IWo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),QX=a("a"),NWo=o("from_pretrained()"),qWo=o(" class method or the "),HX=a("a"),jWo=o("from_config()"),DWo=o(` class
method.`),GWo=l(),YL=a("p"),OWo=o("This class cannot be instantiated directly using "),V_e=a("code"),VWo=o("__init__()"),XWo=o(" (throws an error)."),zWo=l(),gt=a("div"),F(KL.$$.fragment),WWo=l(),X_e=a("p"),QWo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),HWo=l(),id=a("p"),UWo=o(`Note:
Loading a model from its configuration file does `),z_e=a("strong"),JWo=o("not"),YWo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),UX=a("a"),KWo=o("from_pretrained()"),ZWo=o(" to load the model weights."),eQo=l(),F(f0.$$.fragment),oQo=l(),to=a("div"),F(ZL.$$.fragment),rQo=l(),W_e=a("p"),tQo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),aQo=l(),Oa=a("p"),nQo=o("The model class to instantiate is selected based on the "),Q_e=a("code"),sQo=o("model_type"),lQo=o(` property of the config object (either
passed as an argument or loaded from `),H_e=a("code"),iQo=o("pretrained_model_name_or_path"),dQo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U_e=a("code"),cQo=o("pretrained_model_name_or_path"),fQo=o(":"),mQo=l(),No=a("ul"),m0=a("li"),J_e=a("strong"),gQo=o("bert"),hQo=o(" \u2014 "),JX=a("a"),pQo=o("BertForNextSentencePrediction"),_Qo=o(" (BERT model)"),uQo=l(),g0=a("li"),Y_e=a("strong"),bQo=o("fnet"),vQo=o(" \u2014 "),YX=a("a"),FQo=o("FNetForNextSentencePrediction"),TQo=o(" (FNet model)"),MQo=l(),h0=a("li"),K_e=a("strong"),EQo=o("megatron-bert"),CQo=o(" \u2014 "),KX=a("a"),wQo=o("MegatronBertForNextSentencePrediction"),AQo=o(" (Megatron-BERT model)"),LQo=l(),p0=a("li"),Z_e=a("strong"),yQo=o("mobilebert"),xQo=o(" \u2014 "),ZX=a("a"),$Qo=o("MobileBertForNextSentencePrediction"),kQo=o(" (MobileBERT model)"),SQo=l(),_0=a("li"),eue=a("strong"),RQo=o("nezha"),PQo=o(" \u2014 "),ez=a("a"),BQo=o("NezhaForNextSentencePrediction"),IQo=o(" (Nezha model)"),NQo=l(),u0=a("li"),oue=a("strong"),qQo=o("qdqbert"),jQo=o(" \u2014 "),oz=a("a"),DQo=o("QDQBertForNextSentencePrediction"),GQo=o(" (QDQBert model)"),OQo=l(),b0=a("p"),VQo=o("The model is set in evaluation mode by default using "),rue=a("code"),XQo=o("model.eval()"),zQo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tue=a("code"),WQo=o("model.train()"),QQo=l(),F(v0.$$.fragment),pVe=l(),dd=a("h2"),F0=a("a"),aue=a("span"),F(ey.$$.fragment),HQo=l(),nue=a("span"),UQo=o("AutoModelForTokenClassification"),_Ve=l(),qo=a("div"),F(oy.$$.fragment),JQo=l(),cd=a("p"),YQo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),rz=a("a"),KQo=o("from_pretrained()"),ZQo=o(" class method or the "),tz=a("a"),eHo=o("from_config()"),oHo=o(` class
method.`),rHo=l(),ry=a("p"),tHo=o("This class cannot be instantiated directly using "),sue=a("code"),aHo=o("__init__()"),nHo=o(" (throws an error)."),sHo=l(),ht=a("div"),F(ty.$$.fragment),lHo=l(),lue=a("p"),iHo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),dHo=l(),fd=a("p"),cHo=o(`Note:
Loading a model from its configuration file does `),iue=a("strong"),fHo=o("not"),mHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),az=a("a"),gHo=o("from_pretrained()"),hHo=o(" to load the model weights."),pHo=l(),F(T0.$$.fragment),_Ho=l(),ao=a("div"),F(ay.$$.fragment),uHo=l(),due=a("p"),bHo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),vHo=l(),Va=a("p"),FHo=o("The model class to instantiate is selected based on the "),cue=a("code"),THo=o("model_type"),MHo=o(` property of the config object (either
passed as an argument or loaded from `),fue=a("code"),EHo=o("pretrained_model_name_or_path"),CHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mue=a("code"),wHo=o("pretrained_model_name_or_path"),AHo=o(":"),LHo=l(),H=a("ul"),M0=a("li"),gue=a("strong"),yHo=o("albert"),xHo=o(" \u2014 "),nz=a("a"),$Ho=o("AlbertForTokenClassification"),kHo=o(" (ALBERT model)"),SHo=l(),E0=a("li"),hue=a("strong"),RHo=o("bert"),PHo=o(" \u2014 "),sz=a("a"),BHo=o("BertForTokenClassification"),IHo=o(" (BERT model)"),NHo=l(),C0=a("li"),pue=a("strong"),qHo=o("big_bird"),jHo=o(" \u2014 "),lz=a("a"),DHo=o("BigBirdForTokenClassification"),GHo=o(" (BigBird model)"),OHo=l(),w0=a("li"),_ue=a("strong"),VHo=o("bloom"),XHo=o(" \u2014 "),iz=a("a"),zHo=o("BloomForTokenClassification"),WHo=o(" (BLOOM model)"),QHo=l(),A0=a("li"),uue=a("strong"),HHo=o("camembert"),UHo=o(" \u2014 "),dz=a("a"),JHo=o("CamembertForTokenClassification"),YHo=o(" (CamemBERT model)"),KHo=l(),L0=a("li"),bue=a("strong"),ZHo=o("canine"),eUo=o(" \u2014 "),cz=a("a"),oUo=o("CanineForTokenClassification"),rUo=o(" (CANINE model)"),tUo=l(),y0=a("li"),vue=a("strong"),aUo=o("convbert"),nUo=o(" \u2014 "),fz=a("a"),sUo=o("ConvBertForTokenClassification"),lUo=o(" (ConvBERT model)"),iUo=l(),x0=a("li"),Fue=a("strong"),dUo=o("data2vec-text"),cUo=o(" \u2014 "),mz=a("a"),fUo=o("Data2VecTextForTokenClassification"),mUo=o(" (Data2VecText model)"),gUo=l(),$0=a("li"),Tue=a("strong"),hUo=o("deberta"),pUo=o(" \u2014 "),gz=a("a"),_Uo=o("DebertaForTokenClassification"),uUo=o(" (DeBERTa model)"),bUo=l(),k0=a("li"),Mue=a("strong"),vUo=o("deberta-v2"),FUo=o(" \u2014 "),hz=a("a"),TUo=o("DebertaV2ForTokenClassification"),MUo=o(" (DeBERTa-v2 model)"),EUo=l(),S0=a("li"),Eue=a("strong"),CUo=o("distilbert"),wUo=o(" \u2014 "),pz=a("a"),AUo=o("DistilBertForTokenClassification"),LUo=o(" (DistilBERT model)"),yUo=l(),R0=a("li"),Cue=a("strong"),xUo=o("electra"),$Uo=o(" \u2014 "),_z=a("a"),kUo=o("ElectraForTokenClassification"),SUo=o(" (ELECTRA model)"),RUo=l(),P0=a("li"),wue=a("strong"),PUo=o("flaubert"),BUo=o(" \u2014 "),uz=a("a"),IUo=o("FlaubertForTokenClassification"),NUo=o(" (FlauBERT model)"),qUo=l(),B0=a("li"),Aue=a("strong"),jUo=o("fnet"),DUo=o(" \u2014 "),bz=a("a"),GUo=o("FNetForTokenClassification"),OUo=o(" (FNet model)"),VUo=l(),I0=a("li"),Lue=a("strong"),XUo=o("funnel"),zUo=o(" \u2014 "),vz=a("a"),WUo=o("FunnelForTokenClassification"),QUo=o(" (Funnel Transformer model)"),HUo=l(),N0=a("li"),yue=a("strong"),UUo=o("gpt2"),JUo=o(" \u2014 "),Fz=a("a"),YUo=o("GPT2ForTokenClassification"),KUo=o(" (OpenAI GPT-2 model)"),ZUo=l(),q0=a("li"),xue=a("strong"),eJo=o("ibert"),oJo=o(" \u2014 "),Tz=a("a"),rJo=o("IBertForTokenClassification"),tJo=o(" (I-BERT model)"),aJo=l(),j0=a("li"),$ue=a("strong"),nJo=o("layoutlm"),sJo=o(" \u2014 "),Mz=a("a"),lJo=o("LayoutLMForTokenClassification"),iJo=o(" (LayoutLM model)"),dJo=l(),D0=a("li"),kue=a("strong"),cJo=o("layoutlmv2"),fJo=o(" \u2014 "),Ez=a("a"),mJo=o("LayoutLMv2ForTokenClassification"),gJo=o(" (LayoutLMv2 model)"),hJo=l(),G0=a("li"),Sue=a("strong"),pJo=o("layoutlmv3"),_Jo=o(" \u2014 "),Cz=a("a"),uJo=o("LayoutLMv3ForTokenClassification"),bJo=o(" (LayoutLMv3 model)"),vJo=l(),O0=a("li"),Rue=a("strong"),FJo=o("longformer"),TJo=o(" \u2014 "),wz=a("a"),MJo=o("LongformerForTokenClassification"),EJo=o(" (Longformer model)"),CJo=l(),V0=a("li"),Pue=a("strong"),wJo=o("megatron-bert"),AJo=o(" \u2014 "),Az=a("a"),LJo=o("MegatronBertForTokenClassification"),yJo=o(" (Megatron-BERT model)"),xJo=l(),X0=a("li"),Bue=a("strong"),$Jo=o("mobilebert"),kJo=o(" \u2014 "),Lz=a("a"),SJo=o("MobileBertForTokenClassification"),RJo=o(" (MobileBERT model)"),PJo=l(),z0=a("li"),Iue=a("strong"),BJo=o("mpnet"),IJo=o(" \u2014 "),yz=a("a"),NJo=o("MPNetForTokenClassification"),qJo=o(" (MPNet model)"),jJo=l(),W0=a("li"),Nue=a("strong"),DJo=o("nezha"),GJo=o(" \u2014 "),xz=a("a"),OJo=o("NezhaForTokenClassification"),VJo=o(" (Nezha model)"),XJo=l(),Q0=a("li"),que=a("strong"),zJo=o("nystromformer"),WJo=o(" \u2014 "),$z=a("a"),QJo=o("NystromformerForTokenClassification"),HJo=o(" (Nystr\xF6mformer model)"),UJo=l(),H0=a("li"),jue=a("strong"),JJo=o("qdqbert"),YJo=o(" \u2014 "),kz=a("a"),KJo=o("QDQBertForTokenClassification"),ZJo=o(" (QDQBert model)"),eYo=l(),U0=a("li"),Due=a("strong"),oYo=o("rembert"),rYo=o(" \u2014 "),Sz=a("a"),tYo=o("RemBertForTokenClassification"),aYo=o(" (RemBERT model)"),nYo=l(),J0=a("li"),Gue=a("strong"),sYo=o("roberta"),lYo=o(" \u2014 "),Rz=a("a"),iYo=o("RobertaForTokenClassification"),dYo=o(" (RoBERTa model)"),cYo=l(),Y0=a("li"),Oue=a("strong"),fYo=o("roformer"),mYo=o(" \u2014 "),Pz=a("a"),gYo=o("RoFormerForTokenClassification"),hYo=o(" (RoFormer model)"),pYo=l(),K0=a("li"),Vue=a("strong"),_Yo=o("squeezebert"),uYo=o(" \u2014 "),Bz=a("a"),bYo=o("SqueezeBertForTokenClassification"),vYo=o(" (SqueezeBERT model)"),FYo=l(),Z0=a("li"),Xue=a("strong"),TYo=o("xlm"),MYo=o(" \u2014 "),Iz=a("a"),EYo=o("XLMForTokenClassification"),CYo=o(" (XLM model)"),wYo=l(),eF=a("li"),zue=a("strong"),AYo=o("xlm-roberta"),LYo=o(" \u2014 "),Nz=a("a"),yYo=o("XLMRobertaForTokenClassification"),xYo=o(" (XLM-RoBERTa model)"),$Yo=l(),oF=a("li"),Wue=a("strong"),kYo=o("xlm-roberta-xl"),SYo=o(" \u2014 "),qz=a("a"),RYo=o("XLMRobertaXLForTokenClassification"),PYo=o(" (XLM-RoBERTa-XL model)"),BYo=l(),rF=a("li"),Que=a("strong"),IYo=o("xlnet"),NYo=o(" \u2014 "),jz=a("a"),qYo=o("XLNetForTokenClassification"),jYo=o(" (XLNet model)"),DYo=l(),tF=a("li"),Hue=a("strong"),GYo=o("yoso"),OYo=o(" \u2014 "),Dz=a("a"),VYo=o("YosoForTokenClassification"),XYo=o(" (YOSO model)"),zYo=l(),aF=a("p"),WYo=o("The model is set in evaluation mode by default using "),Uue=a("code"),QYo=o("model.eval()"),HYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jue=a("code"),UYo=o("model.train()"),JYo=l(),F(nF.$$.fragment),uVe=l(),md=a("h2"),sF=a("a"),Yue=a("span"),F(ny.$$.fragment),YYo=l(),Kue=a("span"),KYo=o("AutoModelForQuestionAnswering"),bVe=l(),jo=a("div"),F(sy.$$.fragment),ZYo=l(),gd=a("p"),eKo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Gz=a("a"),oKo=o("from_pretrained()"),rKo=o(" class method or the "),Oz=a("a"),tKo=o("from_config()"),aKo=o(` class
method.`),nKo=l(),ly=a("p"),sKo=o("This class cannot be instantiated directly using "),Zue=a("code"),lKo=o("__init__()"),iKo=o(" (throws an error)."),dKo=l(),pt=a("div"),F(iy.$$.fragment),cKo=l(),e1e=a("p"),fKo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),mKo=l(),hd=a("p"),gKo=o(`Note:
Loading a model from its configuration file does `),o1e=a("strong"),hKo=o("not"),pKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Vz=a("a"),_Ko=o("from_pretrained()"),uKo=o(" to load the model weights."),bKo=l(),F(lF.$$.fragment),vKo=l(),no=a("div"),F(dy.$$.fragment),FKo=l(),r1e=a("p"),TKo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),MKo=l(),Xa=a("p"),EKo=o("The model class to instantiate is selected based on the "),t1e=a("code"),CKo=o("model_type"),wKo=o(` property of the config object (either
passed as an argument or loaded from `),a1e=a("code"),AKo=o("pretrained_model_name_or_path"),LKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n1e=a("code"),yKo=o("pretrained_model_name_or_path"),xKo=o(":"),$Ko=l(),V=a("ul"),iF=a("li"),s1e=a("strong"),kKo=o("albert"),SKo=o(" \u2014 "),Xz=a("a"),RKo=o("AlbertForQuestionAnswering"),PKo=o(" (ALBERT model)"),BKo=l(),dF=a("li"),l1e=a("strong"),IKo=o("bart"),NKo=o(" \u2014 "),zz=a("a"),qKo=o("BartForQuestionAnswering"),jKo=o(" (BART model)"),DKo=l(),cF=a("li"),i1e=a("strong"),GKo=o("bert"),OKo=o(" \u2014 "),Wz=a("a"),VKo=o("BertForQuestionAnswering"),XKo=o(" (BERT model)"),zKo=l(),fF=a("li"),d1e=a("strong"),WKo=o("big_bird"),QKo=o(" \u2014 "),Qz=a("a"),HKo=o("BigBirdForQuestionAnswering"),UKo=o(" (BigBird model)"),JKo=l(),mF=a("li"),c1e=a("strong"),YKo=o("bigbird_pegasus"),KKo=o(" \u2014 "),Hz=a("a"),ZKo=o("BigBirdPegasusForQuestionAnswering"),eZo=o(" (BigBird-Pegasus model)"),oZo=l(),gF=a("li"),f1e=a("strong"),rZo=o("camembert"),tZo=o(" \u2014 "),Uz=a("a"),aZo=o("CamembertForQuestionAnswering"),nZo=o(" (CamemBERT model)"),sZo=l(),hF=a("li"),m1e=a("strong"),lZo=o("canine"),iZo=o(" \u2014 "),Jz=a("a"),dZo=o("CanineForQuestionAnswering"),cZo=o(" (CANINE model)"),fZo=l(),pF=a("li"),g1e=a("strong"),mZo=o("convbert"),gZo=o(" \u2014 "),Yz=a("a"),hZo=o("ConvBertForQuestionAnswering"),pZo=o(" (ConvBERT model)"),_Zo=l(),_F=a("li"),h1e=a("strong"),uZo=o("data2vec-text"),bZo=o(" \u2014 "),Kz=a("a"),vZo=o("Data2VecTextForQuestionAnswering"),FZo=o(" (Data2VecText model)"),TZo=l(),uF=a("li"),p1e=a("strong"),MZo=o("deberta"),EZo=o(" \u2014 "),Zz=a("a"),CZo=o("DebertaForQuestionAnswering"),wZo=o(" (DeBERTa model)"),AZo=l(),bF=a("li"),_1e=a("strong"),LZo=o("deberta-v2"),yZo=o(" \u2014 "),eW=a("a"),xZo=o("DebertaV2ForQuestionAnswering"),$Zo=o(" (DeBERTa-v2 model)"),kZo=l(),vF=a("li"),u1e=a("strong"),SZo=o("distilbert"),RZo=o(" \u2014 "),oW=a("a"),PZo=o("DistilBertForQuestionAnswering"),BZo=o(" (DistilBERT model)"),IZo=l(),FF=a("li"),b1e=a("strong"),NZo=o("electra"),qZo=o(" \u2014 "),rW=a("a"),jZo=o("ElectraForQuestionAnswering"),DZo=o(" (ELECTRA model)"),GZo=l(),TF=a("li"),v1e=a("strong"),OZo=o("flaubert"),VZo=o(" \u2014 "),tW=a("a"),XZo=o("FlaubertForQuestionAnsweringSimple"),zZo=o(" (FlauBERT model)"),WZo=l(),MF=a("li"),F1e=a("strong"),QZo=o("fnet"),HZo=o(" \u2014 "),aW=a("a"),UZo=o("FNetForQuestionAnswering"),JZo=o(" (FNet model)"),YZo=l(),EF=a("li"),T1e=a("strong"),KZo=o("funnel"),ZZo=o(" \u2014 "),nW=a("a"),eer=o("FunnelForQuestionAnswering"),oer=o(" (Funnel Transformer model)"),rer=l(),CF=a("li"),M1e=a("strong"),ter=o("gptj"),aer=o(" \u2014 "),sW=a("a"),ner=o("GPTJForQuestionAnswering"),ser=o(" (GPT-J model)"),ler=l(),wF=a("li"),E1e=a("strong"),ier=o("ibert"),der=o(" \u2014 "),lW=a("a"),cer=o("IBertForQuestionAnswering"),fer=o(" (I-BERT model)"),mer=l(),AF=a("li"),C1e=a("strong"),ger=o("layoutlmv2"),her=o(" \u2014 "),iW=a("a"),per=o("LayoutLMv2ForQuestionAnswering"),_er=o(" (LayoutLMv2 model)"),uer=l(),LF=a("li"),w1e=a("strong"),ber=o("layoutlmv3"),ver=o(" \u2014 "),dW=a("a"),Fer=o("LayoutLMv3ForQuestionAnswering"),Ter=o(" (LayoutLMv3 model)"),Mer=l(),yF=a("li"),A1e=a("strong"),Eer=o("led"),Cer=o(" \u2014 "),cW=a("a"),wer=o("LEDForQuestionAnswering"),Aer=o(" (LED model)"),Ler=l(),xF=a("li"),L1e=a("strong"),yer=o("longformer"),xer=o(" \u2014 "),fW=a("a"),$er=o("LongformerForQuestionAnswering"),ker=o(" (Longformer model)"),Ser=l(),$F=a("li"),y1e=a("strong"),Rer=o("lxmert"),Per=o(" \u2014 "),mW=a("a"),Ber=o("LxmertForQuestionAnswering"),Ier=o(" (LXMERT model)"),Ner=l(),kF=a("li"),x1e=a("strong"),qer=o("mbart"),jer=o(" \u2014 "),gW=a("a"),Der=o("MBartForQuestionAnswering"),Ger=o(" (mBART model)"),Oer=l(),SF=a("li"),$1e=a("strong"),Ver=o("megatron-bert"),Xer=o(" \u2014 "),hW=a("a"),zer=o("MegatronBertForQuestionAnswering"),Wer=o(" (Megatron-BERT model)"),Qer=l(),RF=a("li"),k1e=a("strong"),Her=o("mobilebert"),Uer=o(" \u2014 "),pW=a("a"),Jer=o("MobileBertForQuestionAnswering"),Yer=o(" (MobileBERT model)"),Ker=l(),PF=a("li"),S1e=a("strong"),Zer=o("mpnet"),eor=o(" \u2014 "),_W=a("a"),oor=o("MPNetForQuestionAnswering"),ror=o(" (MPNet model)"),tor=l(),BF=a("li"),R1e=a("strong"),aor=o("nezha"),nor=o(" \u2014 "),uW=a("a"),sor=o("NezhaForQuestionAnswering"),lor=o(" (Nezha model)"),ior=l(),IF=a("li"),P1e=a("strong"),dor=o("nystromformer"),cor=o(" \u2014 "),bW=a("a"),mor=o("NystromformerForQuestionAnswering"),gor=o(" (Nystr\xF6mformer model)"),hor=l(),NF=a("li"),B1e=a("strong"),por=o("qdqbert"),_or=o(" \u2014 "),vW=a("a"),uor=o("QDQBertForQuestionAnswering"),bor=o(" (QDQBert model)"),vor=l(),qF=a("li"),I1e=a("strong"),For=o("reformer"),Tor=o(" \u2014 "),FW=a("a"),Mor=o("ReformerForQuestionAnswering"),Eor=o(" (Reformer model)"),Cor=l(),jF=a("li"),N1e=a("strong"),wor=o("rembert"),Aor=o(" \u2014 "),TW=a("a"),Lor=o("RemBertForQuestionAnswering"),yor=o(" (RemBERT model)"),xor=l(),DF=a("li"),q1e=a("strong"),$or=o("roberta"),kor=o(" \u2014 "),MW=a("a"),Sor=o("RobertaForQuestionAnswering"),Ror=o(" (RoBERTa model)"),Por=l(),GF=a("li"),j1e=a("strong"),Bor=o("roformer"),Ior=o(" \u2014 "),EW=a("a"),Nor=o("RoFormerForQuestionAnswering"),qor=o(" (RoFormer model)"),jor=l(),OF=a("li"),D1e=a("strong"),Dor=o("splinter"),Gor=o(" \u2014 "),CW=a("a"),Oor=o("SplinterForQuestionAnswering"),Vor=o(" (Splinter model)"),Xor=l(),VF=a("li"),G1e=a("strong"),zor=o("squeezebert"),Wor=o(" \u2014 "),wW=a("a"),Qor=o("SqueezeBertForQuestionAnswering"),Hor=o(" (SqueezeBERT model)"),Uor=l(),XF=a("li"),O1e=a("strong"),Jor=o("xlm"),Yor=o(" \u2014 "),AW=a("a"),Kor=o("XLMForQuestionAnsweringSimple"),Zor=o(" (XLM model)"),err=l(),zF=a("li"),V1e=a("strong"),orr=o("xlm-roberta"),rrr=o(" \u2014 "),LW=a("a"),trr=o("XLMRobertaForQuestionAnswering"),arr=o(" (XLM-RoBERTa model)"),nrr=l(),WF=a("li"),X1e=a("strong"),srr=o("xlm-roberta-xl"),lrr=o(" \u2014 "),yW=a("a"),irr=o("XLMRobertaXLForQuestionAnswering"),drr=o(" (XLM-RoBERTa-XL model)"),crr=l(),QF=a("li"),z1e=a("strong"),frr=o("xlnet"),mrr=o(" \u2014 "),xW=a("a"),grr=o("XLNetForQuestionAnsweringSimple"),hrr=o(" (XLNet model)"),prr=l(),HF=a("li"),W1e=a("strong"),_rr=o("yoso"),urr=o(" \u2014 "),$W=a("a"),brr=o("YosoForQuestionAnswering"),vrr=o(" (YOSO model)"),Frr=l(),UF=a("p"),Trr=o("The model is set in evaluation mode by default using "),Q1e=a("code"),Mrr=o("model.eval()"),Err=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),H1e=a("code"),Crr=o("model.train()"),wrr=l(),F(JF.$$.fragment),vVe=l(),pd=a("h2"),YF=a("a"),U1e=a("span"),F(cy.$$.fragment),Arr=l(),J1e=a("span"),Lrr=o("AutoModelForTableQuestionAnswering"),FVe=l(),Do=a("div"),F(fy.$$.fragment),yrr=l(),_d=a("p"),xrr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),kW=a("a"),$rr=o("from_pretrained()"),krr=o(" class method or the "),SW=a("a"),Srr=o("from_config()"),Rrr=o(` class
method.`),Prr=l(),my=a("p"),Brr=o("This class cannot be instantiated directly using "),Y1e=a("code"),Irr=o("__init__()"),Nrr=o(" (throws an error)."),qrr=l(),_t=a("div"),F(gy.$$.fragment),jrr=l(),K1e=a("p"),Drr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Grr=l(),ud=a("p"),Orr=o(`Note:
Loading a model from its configuration file does `),Z1e=a("strong"),Vrr=o("not"),Xrr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RW=a("a"),zrr=o("from_pretrained()"),Wrr=o(" to load the model weights."),Qrr=l(),F(KF.$$.fragment),Hrr=l(),so=a("div"),F(hy.$$.fragment),Urr=l(),e2e=a("p"),Jrr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Yrr=l(),za=a("p"),Krr=o("The model class to instantiate is selected based on the "),o2e=a("code"),Zrr=o("model_type"),etr=o(` property of the config object (either
passed as an argument or loaded from `),r2e=a("code"),otr=o("pretrained_model_name_or_path"),rtr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t2e=a("code"),ttr=o("pretrained_model_name_or_path"),atr=o(":"),ntr=l(),a2e=a("ul"),ZF=a("li"),n2e=a("strong"),str=o("tapas"),ltr=o(" \u2014 "),PW=a("a"),itr=o("TapasForQuestionAnswering"),dtr=o(" (TAPAS model)"),ctr=l(),e6=a("p"),ftr=o("The model is set in evaluation mode by default using "),s2e=a("code"),mtr=o("model.eval()"),gtr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l2e=a("code"),htr=o("model.train()"),ptr=l(),F(o6.$$.fragment),TVe=l(),bd=a("h2"),r6=a("a"),i2e=a("span"),F(py.$$.fragment),_tr=l(),d2e=a("span"),utr=o("AutoModelForImageClassification"),MVe=l(),Go=a("div"),F(_y.$$.fragment),btr=l(),vd=a("p"),vtr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),BW=a("a"),Ftr=o("from_pretrained()"),Ttr=o(" class method or the "),IW=a("a"),Mtr=o("from_config()"),Etr=o(` class
method.`),Ctr=l(),uy=a("p"),wtr=o("This class cannot be instantiated directly using "),c2e=a("code"),Atr=o("__init__()"),Ltr=o(" (throws an error)."),ytr=l(),ut=a("div"),F(by.$$.fragment),xtr=l(),f2e=a("p"),$tr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),ktr=l(),Fd=a("p"),Str=o(`Note:
Loading a model from its configuration file does `),m2e=a("strong"),Rtr=o("not"),Ptr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),NW=a("a"),Btr=o("from_pretrained()"),Itr=o(" to load the model weights."),Ntr=l(),F(t6.$$.fragment),qtr=l(),lo=a("div"),F(vy.$$.fragment),jtr=l(),g2e=a("p"),Dtr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Gtr=l(),Wa=a("p"),Otr=o("The model class to instantiate is selected based on the "),h2e=a("code"),Vtr=o("model_type"),Xtr=o(` property of the config object (either
passed as an argument or loaded from `),p2e=a("code"),ztr=o("pretrained_model_name_or_path"),Wtr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_2e=a("code"),Qtr=o("pretrained_model_name_or_path"),Htr=o(":"),Utr=l(),Fe=a("ul"),a6=a("li"),u2e=a("strong"),Jtr=o("beit"),Ytr=o(" \u2014 "),qW=a("a"),Ktr=o("BeitForImageClassification"),Ztr=o(" (BEiT model)"),ear=l(),n6=a("li"),b2e=a("strong"),oar=o("convnext"),rar=o(" \u2014 "),jW=a("a"),tar=o("ConvNextForImageClassification"),aar=o(" (ConvNeXT model)"),nar=l(),s6=a("li"),v2e=a("strong"),sar=o("cvt"),lar=o(" \u2014 "),DW=a("a"),iar=o("CvtForImageClassification"),dar=o(" (CvT model)"),car=l(),l6=a("li"),F2e=a("strong"),far=o("data2vec-vision"),mar=o(" \u2014 "),GW=a("a"),gar=o("Data2VecVisionForImageClassification"),har=o(" (Data2VecVision model)"),par=l(),Qs=a("li"),T2e=a("strong"),_ar=o("deit"),uar=o(" \u2014 "),OW=a("a"),bar=o("DeiTForImageClassification"),Far=o(" or "),VW=a("a"),Tar=o("DeiTForImageClassificationWithTeacher"),Mar=o(" (DeiT model)"),Ear=l(),i6=a("li"),M2e=a("strong"),Car=o("imagegpt"),war=o(" \u2014 "),XW=a("a"),Aar=o("ImageGPTForImageClassification"),Lar=o(" (ImageGPT model)"),yar=l(),Hs=a("li"),E2e=a("strong"),xar=o("levit"),$ar=o(" \u2014 "),zW=a("a"),kar=o("LevitForImageClassification"),Sar=o(" or "),WW=a("a"),Rar=o("LevitForImageClassificationWithTeacher"),Par=o(" (LeViT model)"),Bar=l(),bt=a("li"),C2e=a("strong"),Iar=o("perceiver"),Nar=o(" \u2014 "),QW=a("a"),qar=o("PerceiverForImageClassificationLearned"),jar=o(" or "),HW=a("a"),Dar=o("PerceiverForImageClassificationFourier"),Gar=o(" or "),UW=a("a"),Oar=o("PerceiverForImageClassificationConvProcessing"),Var=o(" (Perceiver model)"),Xar=l(),d6=a("li"),w2e=a("strong"),zar=o("poolformer"),War=o(" \u2014 "),JW=a("a"),Qar=o("PoolFormerForImageClassification"),Har=o(" (PoolFormer model)"),Uar=l(),c6=a("li"),A2e=a("strong"),Jar=o("regnet"),Yar=o(" \u2014 "),YW=a("a"),Kar=o("RegNetForImageClassification"),Zar=o(" (RegNet model)"),enr=l(),f6=a("li"),L2e=a("strong"),onr=o("resnet"),rnr=o(" \u2014 "),KW=a("a"),tnr=o("ResNetForImageClassification"),anr=o(" (ResNet model)"),nnr=l(),m6=a("li"),y2e=a("strong"),snr=o("segformer"),lnr=o(" \u2014 "),ZW=a("a"),inr=o("SegformerForImageClassification"),dnr=o(" (SegFormer model)"),cnr=l(),g6=a("li"),x2e=a("strong"),fnr=o("swin"),mnr=o(" \u2014 "),eQ=a("a"),gnr=o("SwinForImageClassification"),hnr=o(" (Swin Transformer model)"),pnr=l(),h6=a("li"),$2e=a("strong"),_nr=o("van"),unr=o(" \u2014 "),oQ=a("a"),bnr=o("VanForImageClassification"),vnr=o(" (VAN model)"),Fnr=l(),p6=a("li"),k2e=a("strong"),Tnr=o("vit"),Mnr=o(" \u2014 "),rQ=a("a"),Enr=o("ViTForImageClassification"),Cnr=o(" (ViT model)"),wnr=l(),_6=a("p"),Anr=o("The model is set in evaluation mode by default using "),S2e=a("code"),Lnr=o("model.eval()"),ynr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),R2e=a("code"),xnr=o("model.train()"),$nr=l(),F(u6.$$.fragment),EVe=l(),Td=a("h2"),b6=a("a"),P2e=a("span"),F(Fy.$$.fragment),knr=l(),B2e=a("span"),Snr=o("AutoModelForVision2Seq"),CVe=l(),Oo=a("div"),F(Ty.$$.fragment),Rnr=l(),Md=a("p"),Pnr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),tQ=a("a"),Bnr=o("from_pretrained()"),Inr=o(" class method or the "),aQ=a("a"),Nnr=o("from_config()"),qnr=o(` class
method.`),jnr=l(),My=a("p"),Dnr=o("This class cannot be instantiated directly using "),I2e=a("code"),Gnr=o("__init__()"),Onr=o(" (throws an error)."),Vnr=l(),vt=a("div"),F(Ey.$$.fragment),Xnr=l(),N2e=a("p"),znr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Wnr=l(),Ed=a("p"),Qnr=o(`Note:
Loading a model from its configuration file does `),q2e=a("strong"),Hnr=o("not"),Unr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nQ=a("a"),Jnr=o("from_pretrained()"),Ynr=o(" to load the model weights."),Knr=l(),F(v6.$$.fragment),Znr=l(),io=a("div"),F(Cy.$$.fragment),esr=l(),j2e=a("p"),osr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),rsr=l(),Qa=a("p"),tsr=o("The model class to instantiate is selected based on the "),D2e=a("code"),asr=o("model_type"),nsr=o(` property of the config object (either
passed as an argument or loaded from `),G2e=a("code"),ssr=o("pretrained_model_name_or_path"),lsr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O2e=a("code"),isr=o("pretrained_model_name_or_path"),dsr=o(":"),csr=l(),V2e=a("ul"),F6=a("li"),X2e=a("strong"),fsr=o("vision-encoder-decoder"),msr=o(" \u2014 "),sQ=a("a"),gsr=o("VisionEncoderDecoderModel"),hsr=o(" (Vision Encoder decoder model)"),psr=l(),T6=a("p"),_sr=o("The model is set in evaluation mode by default using "),z2e=a("code"),usr=o("model.eval()"),bsr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),W2e=a("code"),vsr=o("model.train()"),Fsr=l(),F(M6.$$.fragment),wVe=l(),Cd=a("h2"),E6=a("a"),Q2e=a("span"),F(wy.$$.fragment),Tsr=l(),H2e=a("span"),Msr=o("AutoModelForVisualQuestionAnswering"),AVe=l(),Vo=a("div"),F(Ay.$$.fragment),Esr=l(),wd=a("p"),Csr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),lQ=a("a"),wsr=o("from_pretrained()"),Asr=o(" class method or the "),iQ=a("a"),Lsr=o("from_config()"),ysr=o(` class
method.`),xsr=l(),Ly=a("p"),$sr=o("This class cannot be instantiated directly using "),U2e=a("code"),ksr=o("__init__()"),Ssr=o(" (throws an error)."),Rsr=l(),Ft=a("div"),F(yy.$$.fragment),Psr=l(),J2e=a("p"),Bsr=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Isr=l(),Ad=a("p"),Nsr=o(`Note:
Loading a model from its configuration file does `),Y2e=a("strong"),qsr=o("not"),jsr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dQ=a("a"),Dsr=o("from_pretrained()"),Gsr=o(" to load the model weights."),Osr=l(),F(C6.$$.fragment),Vsr=l(),co=a("div"),F(xy.$$.fragment),Xsr=l(),K2e=a("p"),zsr=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),Wsr=l(),Ha=a("p"),Qsr=o("The model class to instantiate is selected based on the "),Z2e=a("code"),Hsr=o("model_type"),Usr=o(` property of the config object (either
passed as an argument or loaded from `),ebe=a("code"),Jsr=o("pretrained_model_name_or_path"),Ysr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),obe=a("code"),Ksr=o("pretrained_model_name_or_path"),Zsr=o(":"),elr=l(),rbe=a("ul"),w6=a("li"),tbe=a("strong"),olr=o("vilt"),rlr=o(" \u2014 "),cQ=a("a"),tlr=o("ViltForQuestionAnswering"),alr=o(" (ViLT model)"),nlr=l(),A6=a("p"),slr=o("The model is set in evaluation mode by default using "),abe=a("code"),llr=o("model.eval()"),ilr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nbe=a("code"),dlr=o("model.train()"),clr=l(),F(L6.$$.fragment),LVe=l(),Ld=a("h2"),y6=a("a"),sbe=a("span"),F($y.$$.fragment),flr=l(),lbe=a("span"),mlr=o("AutoModelForAudioClassification"),yVe=l(),Xo=a("div"),F(ky.$$.fragment),glr=l(),yd=a("p"),hlr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),fQ=a("a"),plr=o("from_pretrained()"),_lr=o(" class method or the "),mQ=a("a"),ulr=o("from_config()"),blr=o(` class
method.`),vlr=l(),Sy=a("p"),Flr=o("This class cannot be instantiated directly using "),ibe=a("code"),Tlr=o("__init__()"),Mlr=o(" (throws an error)."),Elr=l(),Tt=a("div"),F(Ry.$$.fragment),Clr=l(),dbe=a("p"),wlr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),Alr=l(),xd=a("p"),Llr=o(`Note:
Loading a model from its configuration file does `),cbe=a("strong"),ylr=o("not"),xlr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gQ=a("a"),$lr=o("from_pretrained()"),klr=o(" to load the model weights."),Slr=l(),F(x6.$$.fragment),Rlr=l(),fo=a("div"),F(Py.$$.fragment),Plr=l(),fbe=a("p"),Blr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Ilr=l(),Ua=a("p"),Nlr=o("The model class to instantiate is selected based on the "),mbe=a("code"),qlr=o("model_type"),jlr=o(` property of the config object (either
passed as an argument or loaded from `),gbe=a("code"),Dlr=o("pretrained_model_name_or_path"),Glr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hbe=a("code"),Olr=o("pretrained_model_name_or_path"),Vlr=o(":"),Xlr=l(),Pe=a("ul"),$6=a("li"),pbe=a("strong"),zlr=o("data2vec-audio"),Wlr=o(" \u2014 "),hQ=a("a"),Qlr=o("Data2VecAudioForSequenceClassification"),Hlr=o(" (Data2VecAudio model)"),Ulr=l(),k6=a("li"),_be=a("strong"),Jlr=o("hubert"),Ylr=o(" \u2014 "),pQ=a("a"),Klr=o("HubertForSequenceClassification"),Zlr=o(" (Hubert model)"),eir=l(),S6=a("li"),ube=a("strong"),oir=o("sew"),rir=o(" \u2014 "),_Q=a("a"),tir=o("SEWForSequenceClassification"),air=o(" (SEW model)"),nir=l(),R6=a("li"),bbe=a("strong"),sir=o("sew-d"),lir=o(" \u2014 "),uQ=a("a"),iir=o("SEWDForSequenceClassification"),dir=o(" (SEW-D model)"),cir=l(),P6=a("li"),vbe=a("strong"),fir=o("unispeech"),mir=o(" \u2014 "),bQ=a("a"),gir=o("UniSpeechForSequenceClassification"),hir=o(" (UniSpeech model)"),pir=l(),B6=a("li"),Fbe=a("strong"),_ir=o("unispeech-sat"),uir=o(" \u2014 "),vQ=a("a"),bir=o("UniSpeechSatForSequenceClassification"),vir=o(" (UniSpeechSat model)"),Fir=l(),I6=a("li"),Tbe=a("strong"),Tir=o("wav2vec2"),Mir=o(" \u2014 "),FQ=a("a"),Eir=o("Wav2Vec2ForSequenceClassification"),Cir=o(" (Wav2Vec2 model)"),wir=l(),N6=a("li"),Mbe=a("strong"),Air=o("wav2vec2-conformer"),Lir=o(" \u2014 "),TQ=a("a"),yir=o("Wav2Vec2ConformerForSequenceClassification"),xir=o(" (Wav2Vec2-Conformer model)"),$ir=l(),q6=a("li"),Ebe=a("strong"),kir=o("wavlm"),Sir=o(" \u2014 "),MQ=a("a"),Rir=o("WavLMForSequenceClassification"),Pir=o(" (WavLM model)"),Bir=l(),j6=a("p"),Iir=o("The model is set in evaluation mode by default using "),Cbe=a("code"),Nir=o("model.eval()"),qir=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),wbe=a("code"),jir=o("model.train()"),Dir=l(),F(D6.$$.fragment),xVe=l(),$d=a("h2"),G6=a("a"),Abe=a("span"),F(By.$$.fragment),Gir=l(),Lbe=a("span"),Oir=o("AutoModelForAudioFrameClassification"),$Ve=l(),zo=a("div"),F(Iy.$$.fragment),Vir=l(),kd=a("p"),Xir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),EQ=a("a"),zir=o("from_pretrained()"),Wir=o(" class method or the "),CQ=a("a"),Qir=o("from_config()"),Hir=o(` class
method.`),Uir=l(),Ny=a("p"),Jir=o("This class cannot be instantiated directly using "),ybe=a("code"),Yir=o("__init__()"),Kir=o(" (throws an error)."),Zir=l(),Mt=a("div"),F(qy.$$.fragment),edr=l(),xbe=a("p"),odr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),rdr=l(),Sd=a("p"),tdr=o(`Note:
Loading a model from its configuration file does `),$be=a("strong"),adr=o("not"),ndr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wQ=a("a"),sdr=o("from_pretrained()"),ldr=o(" to load the model weights."),idr=l(),F(O6.$$.fragment),ddr=l(),mo=a("div"),F(jy.$$.fragment),cdr=l(),kbe=a("p"),fdr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),mdr=l(),Ja=a("p"),gdr=o("The model class to instantiate is selected based on the "),Sbe=a("code"),hdr=o("model_type"),pdr=o(` property of the config object (either
passed as an argument or loaded from `),Rbe=a("code"),_dr=o("pretrained_model_name_or_path"),udr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Pbe=a("code"),bdr=o("pretrained_model_name_or_path"),vdr=o(":"),Fdr=l(),ot=a("ul"),V6=a("li"),Bbe=a("strong"),Tdr=o("data2vec-audio"),Mdr=o(" \u2014 "),AQ=a("a"),Edr=o("Data2VecAudioForAudioFrameClassification"),Cdr=o(" (Data2VecAudio model)"),wdr=l(),X6=a("li"),Ibe=a("strong"),Adr=o("unispeech-sat"),Ldr=o(" \u2014 "),LQ=a("a"),ydr=o("UniSpeechSatForAudioFrameClassification"),xdr=o(" (UniSpeechSat model)"),$dr=l(),z6=a("li"),Nbe=a("strong"),kdr=o("wav2vec2"),Sdr=o(" \u2014 "),yQ=a("a"),Rdr=o("Wav2Vec2ForAudioFrameClassification"),Pdr=o(" (Wav2Vec2 model)"),Bdr=l(),W6=a("li"),qbe=a("strong"),Idr=o("wav2vec2-conformer"),Ndr=o(" \u2014 "),xQ=a("a"),qdr=o("Wav2Vec2ConformerForAudioFrameClassification"),jdr=o(" (Wav2Vec2-Conformer model)"),Ddr=l(),Q6=a("li"),jbe=a("strong"),Gdr=o("wavlm"),Odr=o(" \u2014 "),$Q=a("a"),Vdr=o("WavLMForAudioFrameClassification"),Xdr=o(" (WavLM model)"),zdr=l(),H6=a("p"),Wdr=o("The model is set in evaluation mode by default using "),Dbe=a("code"),Qdr=o("model.eval()"),Hdr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gbe=a("code"),Udr=o("model.train()"),Jdr=l(),F(U6.$$.fragment),kVe=l(),Rd=a("h2"),J6=a("a"),Obe=a("span"),F(Dy.$$.fragment),Ydr=l(),Vbe=a("span"),Kdr=o("AutoModelForCTC"),SVe=l(),Wo=a("div"),F(Gy.$$.fragment),Zdr=l(),Pd=a("p"),ecr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),kQ=a("a"),ocr=o("from_pretrained()"),rcr=o(" class method or the "),SQ=a("a"),tcr=o("from_config()"),acr=o(` class
method.`),ncr=l(),Oy=a("p"),scr=o("This class cannot be instantiated directly using "),Xbe=a("code"),lcr=o("__init__()"),icr=o(" (throws an error)."),dcr=l(),Et=a("div"),F(Vy.$$.fragment),ccr=l(),zbe=a("p"),fcr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),mcr=l(),Bd=a("p"),gcr=o(`Note:
Loading a model from its configuration file does `),Wbe=a("strong"),hcr=o("not"),pcr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RQ=a("a"),_cr=o("from_pretrained()"),ucr=o(" to load the model weights."),bcr=l(),F(Y6.$$.fragment),vcr=l(),go=a("div"),F(Xy.$$.fragment),Fcr=l(),Qbe=a("p"),Tcr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Mcr=l(),Ya=a("p"),Ecr=o("The model class to instantiate is selected based on the "),Hbe=a("code"),Ccr=o("model_type"),wcr=o(` property of the config object (either
passed as an argument or loaded from `),Ube=a("code"),Acr=o("pretrained_model_name_or_path"),Lcr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jbe=a("code"),ycr=o("pretrained_model_name_or_path"),xcr=o(":"),$cr=l(),Le=a("ul"),K6=a("li"),Ybe=a("strong"),kcr=o("data2vec-audio"),Scr=o(" \u2014 "),PQ=a("a"),Rcr=o("Data2VecAudioForCTC"),Pcr=o(" (Data2VecAudio model)"),Bcr=l(),Z6=a("li"),Kbe=a("strong"),Icr=o("hubert"),Ncr=o(" \u2014 "),BQ=a("a"),qcr=o("HubertForCTC"),jcr=o(" (Hubert model)"),Dcr=l(),eT=a("li"),Zbe=a("strong"),Gcr=o("mctct"),Ocr=o(" \u2014 "),IQ=a("a"),Vcr=o("MCTCTForCTC"),Xcr=o(" (M-CTC-T model)"),zcr=l(),oT=a("li"),eve=a("strong"),Wcr=o("sew"),Qcr=o(" \u2014 "),NQ=a("a"),Hcr=o("SEWForCTC"),Ucr=o(" (SEW model)"),Jcr=l(),rT=a("li"),ove=a("strong"),Ycr=o("sew-d"),Kcr=o(" \u2014 "),qQ=a("a"),Zcr=o("SEWDForCTC"),efr=o(" (SEW-D model)"),ofr=l(),tT=a("li"),rve=a("strong"),rfr=o("unispeech"),tfr=o(" \u2014 "),jQ=a("a"),afr=o("UniSpeechForCTC"),nfr=o(" (UniSpeech model)"),sfr=l(),aT=a("li"),tve=a("strong"),lfr=o("unispeech-sat"),ifr=o(" \u2014 "),DQ=a("a"),dfr=o("UniSpeechSatForCTC"),cfr=o(" (UniSpeechSat model)"),ffr=l(),nT=a("li"),ave=a("strong"),mfr=o("wav2vec2"),gfr=o(" \u2014 "),GQ=a("a"),hfr=o("Wav2Vec2ForCTC"),pfr=o(" (Wav2Vec2 model)"),_fr=l(),sT=a("li"),nve=a("strong"),ufr=o("wav2vec2-conformer"),bfr=o(" \u2014 "),OQ=a("a"),vfr=o("Wav2Vec2ConformerForCTC"),Ffr=o(" (Wav2Vec2-Conformer model)"),Tfr=l(),lT=a("li"),sve=a("strong"),Mfr=o("wavlm"),Efr=o(" \u2014 "),VQ=a("a"),Cfr=o("WavLMForCTC"),wfr=o(" (WavLM model)"),Afr=l(),iT=a("p"),Lfr=o("The model is set in evaluation mode by default using "),lve=a("code"),yfr=o("model.eval()"),xfr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ive=a("code"),$fr=o("model.train()"),kfr=l(),F(dT.$$.fragment),RVe=l(),Id=a("h2"),cT=a("a"),dve=a("span"),F(zy.$$.fragment),Sfr=l(),cve=a("span"),Rfr=o("AutoModelForSpeechSeq2Seq"),PVe=l(),Qo=a("div"),F(Wy.$$.fragment),Pfr=l(),Nd=a("p"),Bfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),XQ=a("a"),Ifr=o("from_pretrained()"),Nfr=o(" class method or the "),zQ=a("a"),qfr=o("from_config()"),jfr=o(` class
method.`),Dfr=l(),Qy=a("p"),Gfr=o("This class cannot be instantiated directly using "),fve=a("code"),Ofr=o("__init__()"),Vfr=o(" (throws an error)."),Xfr=l(),Ct=a("div"),F(Hy.$$.fragment),zfr=l(),mve=a("p"),Wfr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Qfr=l(),qd=a("p"),Hfr=o(`Note:
Loading a model from its configuration file does `),gve=a("strong"),Ufr=o("not"),Jfr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WQ=a("a"),Yfr=o("from_pretrained()"),Kfr=o(" to load the model weights."),Zfr=l(),F(fT.$$.fragment),emr=l(),ho=a("div"),F(Uy.$$.fragment),omr=l(),hve=a("p"),rmr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),tmr=l(),Ka=a("p"),amr=o("The model class to instantiate is selected based on the "),pve=a("code"),nmr=o("model_type"),smr=o(` property of the config object (either
passed as an argument or loaded from `),_ve=a("code"),lmr=o("pretrained_model_name_or_path"),imr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uve=a("code"),dmr=o("pretrained_model_name_or_path"),cmr=o(":"),fmr=l(),Jy=a("ul"),mT=a("li"),bve=a("strong"),mmr=o("speech-encoder-decoder"),gmr=o(" \u2014 "),QQ=a("a"),hmr=o("SpeechEncoderDecoderModel"),pmr=o(" (Speech Encoder decoder model)"),_mr=l(),gT=a("li"),vve=a("strong"),umr=o("speech_to_text"),bmr=o(" \u2014 "),HQ=a("a"),vmr=o("Speech2TextForConditionalGeneration"),Fmr=o(" (Speech2Text model)"),Tmr=l(),hT=a("p"),Mmr=o("The model is set in evaluation mode by default using "),Fve=a("code"),Emr=o("model.eval()"),Cmr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Tve=a("code"),wmr=o("model.train()"),Amr=l(),F(pT.$$.fragment),BVe=l(),jd=a("h2"),_T=a("a"),Mve=a("span"),F(Yy.$$.fragment),Lmr=l(),Eve=a("span"),ymr=o("AutoModelForAudioXVector"),IVe=l(),Ho=a("div"),F(Ky.$$.fragment),xmr=l(),Dd=a("p"),$mr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),UQ=a("a"),kmr=o("from_pretrained()"),Smr=o(" class method or the "),JQ=a("a"),Rmr=o("from_config()"),Pmr=o(` class
method.`),Bmr=l(),Zy=a("p"),Imr=o("This class cannot be instantiated directly using "),Cve=a("code"),Nmr=o("__init__()"),qmr=o(" (throws an error)."),jmr=l(),wt=a("div"),F(e9.$$.fragment),Dmr=l(),wve=a("p"),Gmr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Omr=l(),Gd=a("p"),Vmr=o(`Note:
Loading a model from its configuration file does `),Ave=a("strong"),Xmr=o("not"),zmr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YQ=a("a"),Wmr=o("from_pretrained()"),Qmr=o(" to load the model weights."),Hmr=l(),F(uT.$$.fragment),Umr=l(),po=a("div"),F(o9.$$.fragment),Jmr=l(),Lve=a("p"),Ymr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Kmr=l(),Za=a("p"),Zmr=o("The model class to instantiate is selected based on the "),yve=a("code"),egr=o("model_type"),ogr=o(` property of the config object (either
passed as an argument or loaded from `),xve=a("code"),rgr=o("pretrained_model_name_or_path"),tgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$ve=a("code"),agr=o("pretrained_model_name_or_path"),ngr=o(":"),sgr=l(),rt=a("ul"),bT=a("li"),kve=a("strong"),lgr=o("data2vec-audio"),igr=o(" \u2014 "),KQ=a("a"),dgr=o("Data2VecAudioForXVector"),cgr=o(" (Data2VecAudio model)"),fgr=l(),vT=a("li"),Sve=a("strong"),mgr=o("unispeech-sat"),ggr=o(" \u2014 "),ZQ=a("a"),hgr=o("UniSpeechSatForXVector"),pgr=o(" (UniSpeechSat model)"),_gr=l(),FT=a("li"),Rve=a("strong"),ugr=o("wav2vec2"),bgr=o(" \u2014 "),eH=a("a"),vgr=o("Wav2Vec2ForXVector"),Fgr=o(" (Wav2Vec2 model)"),Tgr=l(),TT=a("li"),Pve=a("strong"),Mgr=o("wav2vec2-conformer"),Egr=o(" \u2014 "),oH=a("a"),Cgr=o("Wav2Vec2ConformerForXVector"),wgr=o(" (Wav2Vec2-Conformer model)"),Agr=l(),MT=a("li"),Bve=a("strong"),Lgr=o("wavlm"),ygr=o(" \u2014 "),rH=a("a"),xgr=o("WavLMForXVector"),$gr=o(" (WavLM model)"),kgr=l(),ET=a("p"),Sgr=o("The model is set in evaluation mode by default using "),Ive=a("code"),Rgr=o("model.eval()"),Pgr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nve=a("code"),Bgr=o("model.train()"),Igr=l(),F(CT.$$.fragment),NVe=l(),Od=a("h2"),wT=a("a"),qve=a("span"),F(r9.$$.fragment),Ngr=l(),jve=a("span"),qgr=o("AutoModelForMaskedImageModeling"),qVe=l(),Uo=a("div"),F(t9.$$.fragment),jgr=l(),Vd=a("p"),Dgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),tH=a("a"),Ggr=o("from_pretrained()"),Ogr=o(" class method or the "),aH=a("a"),Vgr=o("from_config()"),Xgr=o(` class
method.`),zgr=l(),a9=a("p"),Wgr=o("This class cannot be instantiated directly using "),Dve=a("code"),Qgr=o("__init__()"),Hgr=o(" (throws an error)."),Ugr=l(),At=a("div"),F(n9.$$.fragment),Jgr=l(),Gve=a("p"),Ygr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Kgr=l(),Xd=a("p"),Zgr=o(`Note:
Loading a model from its configuration file does `),Ove=a("strong"),ehr=o("not"),ohr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nH=a("a"),rhr=o("from_pretrained()"),thr=o(" to load the model weights."),ahr=l(),F(AT.$$.fragment),nhr=l(),_o=a("div"),F(s9.$$.fragment),shr=l(),Vve=a("p"),lhr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),ihr=l(),en=a("p"),dhr=o("The model class to instantiate is selected based on the "),Xve=a("code"),chr=o("model_type"),fhr=o(` property of the config object (either
passed as an argument or loaded from `),zve=a("code"),mhr=o("pretrained_model_name_or_path"),ghr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wve=a("code"),hhr=o("pretrained_model_name_or_path"),phr=o(":"),_hr=l(),zd=a("ul"),LT=a("li"),Qve=a("strong"),uhr=o("deit"),bhr=o(" \u2014 "),sH=a("a"),vhr=o("DeiTForMaskedImageModeling"),Fhr=o(" (DeiT model)"),Thr=l(),yT=a("li"),Hve=a("strong"),Mhr=o("swin"),Ehr=o(" \u2014 "),lH=a("a"),Chr=o("SwinForMaskedImageModeling"),whr=o(" (Swin Transformer model)"),Ahr=l(),xT=a("li"),Uve=a("strong"),Lhr=o("vit"),yhr=o(" \u2014 "),iH=a("a"),xhr=o("ViTForMaskedImageModeling"),$hr=o(" (ViT model)"),khr=l(),$T=a("p"),Shr=o("The model is set in evaluation mode by default using "),Jve=a("code"),Rhr=o("model.eval()"),Phr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yve=a("code"),Bhr=o("model.train()"),Ihr=l(),F(kT.$$.fragment),jVe=l(),Wd=a("h2"),ST=a("a"),Kve=a("span"),F(l9.$$.fragment),Nhr=l(),Zve=a("span"),qhr=o("AutoModelForObjectDetection"),DVe=l(),Jo=a("div"),F(i9.$$.fragment),jhr=l(),Qd=a("p"),Dhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),dH=a("a"),Ghr=o("from_pretrained()"),Ohr=o(" class method or the "),cH=a("a"),Vhr=o("from_config()"),Xhr=o(` class
method.`),zhr=l(),d9=a("p"),Whr=o("This class cannot be instantiated directly using "),e0e=a("code"),Qhr=o("__init__()"),Hhr=o(" (throws an error)."),Uhr=l(),Lt=a("div"),F(c9.$$.fragment),Jhr=l(),o0e=a("p"),Yhr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Khr=l(),Hd=a("p"),Zhr=o(`Note:
Loading a model from its configuration file does `),r0e=a("strong"),epr=o("not"),opr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fH=a("a"),rpr=o("from_pretrained()"),tpr=o(" to load the model weights."),apr=l(),F(RT.$$.fragment),npr=l(),uo=a("div"),F(f9.$$.fragment),spr=l(),t0e=a("p"),lpr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),ipr=l(),on=a("p"),dpr=o("The model class to instantiate is selected based on the "),a0e=a("code"),cpr=o("model_type"),fpr=o(` property of the config object (either
passed as an argument or loaded from `),n0e=a("code"),mpr=o("pretrained_model_name_or_path"),gpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s0e=a("code"),hpr=o("pretrained_model_name_or_path"),ppr=o(":"),_pr=l(),m9=a("ul"),PT=a("li"),l0e=a("strong"),upr=o("detr"),bpr=o(" \u2014 "),mH=a("a"),vpr=o("DetrForObjectDetection"),Fpr=o(" (DETR model)"),Tpr=l(),BT=a("li"),i0e=a("strong"),Mpr=o("yolos"),Epr=o(" \u2014 "),gH=a("a"),Cpr=o("YolosForObjectDetection"),wpr=o(" (YOLOS model)"),Apr=l(),IT=a("p"),Lpr=o("The model is set in evaluation mode by default using "),d0e=a("code"),ypr=o("model.eval()"),xpr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c0e=a("code"),$pr=o("model.train()"),kpr=l(),F(NT.$$.fragment),GVe=l(),Ud=a("h2"),qT=a("a"),f0e=a("span"),F(g9.$$.fragment),Spr=l(),m0e=a("span"),Rpr=o("AutoModelForImageSegmentation"),OVe=l(),Yo=a("div"),F(h9.$$.fragment),Ppr=l(),Jd=a("p"),Bpr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),hH=a("a"),Ipr=o("from_pretrained()"),Npr=o(" class method or the "),pH=a("a"),qpr=o("from_config()"),jpr=o(` class
method.`),Dpr=l(),p9=a("p"),Gpr=o("This class cannot be instantiated directly using "),g0e=a("code"),Opr=o("__init__()"),Vpr=o(" (throws an error)."),Xpr=l(),yt=a("div"),F(_9.$$.fragment),zpr=l(),h0e=a("p"),Wpr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Qpr=l(),Yd=a("p"),Hpr=o(`Note:
Loading a model from its configuration file does `),p0e=a("strong"),Upr=o("not"),Jpr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_H=a("a"),Ypr=o("from_pretrained()"),Kpr=o(" to load the model weights."),Zpr=l(),F(jT.$$.fragment),e_r=l(),bo=a("div"),F(u9.$$.fragment),o_r=l(),_0e=a("p"),r_r=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),t_r=l(),rn=a("p"),a_r=o("The model class to instantiate is selected based on the "),u0e=a("code"),n_r=o("model_type"),s_r=o(` property of the config object (either
passed as an argument or loaded from `),b0e=a("code"),l_r=o("pretrained_model_name_or_path"),i_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v0e=a("code"),d_r=o("pretrained_model_name_or_path"),c_r=o(":"),f_r=l(),F0e=a("ul"),DT=a("li"),T0e=a("strong"),m_r=o("detr"),g_r=o(" \u2014 "),uH=a("a"),h_r=o("DetrForSegmentation"),p_r=o(" (DETR model)"),__r=l(),GT=a("p"),u_r=o("The model is set in evaluation mode by default using "),M0e=a("code"),b_r=o("model.eval()"),v_r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),E0e=a("code"),F_r=o("model.train()"),T_r=l(),F(OT.$$.fragment),VVe=l(),Kd=a("h2"),VT=a("a"),C0e=a("span"),F(b9.$$.fragment),M_r=l(),w0e=a("span"),E_r=o("AutoModelForSemanticSegmentation"),XVe=l(),Ko=a("div"),F(v9.$$.fragment),C_r=l(),Zd=a("p"),w_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),bH=a("a"),A_r=o("from_pretrained()"),L_r=o(" class method or the "),vH=a("a"),y_r=o("from_config()"),x_r=o(` class
method.`),$_r=l(),F9=a("p"),k_r=o("This class cannot be instantiated directly using "),A0e=a("code"),S_r=o("__init__()"),R_r=o(" (throws an error)."),P_r=l(),xt=a("div"),F(T9.$$.fragment),B_r=l(),L0e=a("p"),I_r=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),N_r=l(),ec=a("p"),q_r=o(`Note:
Loading a model from its configuration file does `),y0e=a("strong"),j_r=o("not"),D_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),FH=a("a"),G_r=o("from_pretrained()"),O_r=o(" to load the model weights."),V_r=l(),F(XT.$$.fragment),X_r=l(),vo=a("div"),F(M9.$$.fragment),z_r=l(),x0e=a("p"),W_r=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Q_r=l(),tn=a("p"),H_r=o("The model class to instantiate is selected based on the "),$0e=a("code"),U_r=o("model_type"),J_r=o(` property of the config object (either
passed as an argument or loaded from `),k0e=a("code"),Y_r=o("pretrained_model_name_or_path"),K_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S0e=a("code"),Z_r=o("pretrained_model_name_or_path"),eur=o(":"),our=l(),an=a("ul"),zT=a("li"),R0e=a("strong"),rur=o("beit"),tur=o(" \u2014 "),TH=a("a"),aur=o("BeitForSemanticSegmentation"),nur=o(" (BEiT model)"),sur=l(),WT=a("li"),P0e=a("strong"),lur=o("data2vec-vision"),iur=o(" \u2014 "),MH=a("a"),dur=o("Data2VecVisionForSemanticSegmentation"),cur=o(" (Data2VecVision model)"),fur=l(),QT=a("li"),B0e=a("strong"),mur=o("dpt"),gur=o(" \u2014 "),EH=a("a"),hur=o("DPTForSemanticSegmentation"),pur=o(" (DPT model)"),_ur=l(),HT=a("li"),I0e=a("strong"),uur=o("segformer"),bur=o(" \u2014 "),CH=a("a"),vur=o("SegformerForSemanticSegmentation"),Fur=o(" (SegFormer model)"),Tur=l(),UT=a("p"),Mur=o("The model is set in evaluation mode by default using "),N0e=a("code"),Eur=o("model.eval()"),Cur=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q0e=a("code"),wur=o("model.train()"),Aur=l(),F(JT.$$.fragment),zVe=l(),oc=a("h2"),YT=a("a"),j0e=a("span"),F(E9.$$.fragment),Lur=l(),D0e=a("span"),yur=o("AutoModelForInstanceSegmentation"),WVe=l(),Zo=a("div"),F(C9.$$.fragment),xur=l(),rc=a("p"),$ur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),wH=a("a"),kur=o("from_pretrained()"),Sur=o(" class method or the "),AH=a("a"),Rur=o("from_config()"),Pur=o(` class
method.`),Bur=l(),w9=a("p"),Iur=o("This class cannot be instantiated directly using "),G0e=a("code"),Nur=o("__init__()"),qur=o(" (throws an error)."),jur=l(),$t=a("div"),F(A9.$$.fragment),Dur=l(),O0e=a("p"),Gur=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Our=l(),tc=a("p"),Vur=o(`Note:
Loading a model from its configuration file does `),V0e=a("strong"),Xur=o("not"),zur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LH=a("a"),Wur=o("from_pretrained()"),Qur=o(" to load the model weights."),Hur=l(),F(KT.$$.fragment),Uur=l(),Fo=a("div"),F(L9.$$.fragment),Jur=l(),X0e=a("p"),Yur=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Kur=l(),nn=a("p"),Zur=o("The model class to instantiate is selected based on the "),z0e=a("code"),e1r=o("model_type"),o1r=o(` property of the config object (either
passed as an argument or loaded from `),W0e=a("code"),r1r=o("pretrained_model_name_or_path"),t1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q0e=a("code"),a1r=o("pretrained_model_name_or_path"),n1r=o(":"),s1r=l(),H0e=a("ul"),ZT=a("li"),U0e=a("strong"),l1r=o("maskformer"),i1r=o(" \u2014 "),yH=a("a"),d1r=o("MaskFormerForInstanceSegmentation"),c1r=o(" (MaskFormer model)"),f1r=l(),e7=a("p"),m1r=o("The model is set in evaluation mode by default using "),J0e=a("code"),g1r=o("model.eval()"),h1r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Y0e=a("code"),p1r=o("model.train()"),_1r=l(),F(o7.$$.fragment),QVe=l(),ac=a("h2"),r7=a("a"),K0e=a("span"),F(y9.$$.fragment),u1r=l(),Z0e=a("span"),b1r=o("TFAutoModel"),HVe=l(),er=a("div"),F(x9.$$.fragment),v1r=l(),nc=a("p"),F1r=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),xH=a("a"),T1r=o("from_pretrained()"),M1r=o(" class method or the "),$H=a("a"),E1r=o("from_config()"),C1r=o(` class
method.`),w1r=l(),$9=a("p"),A1r=o("This class cannot be instantiated directly using "),eFe=a("code"),L1r=o("__init__()"),y1r=o(" (throws an error)."),x1r=l(),kt=a("div"),F(k9.$$.fragment),$1r=l(),oFe=a("p"),k1r=o("Instantiates one of the base model classes of the library from a configuration."),S1r=l(),sc=a("p"),R1r=o(`Note:
Loading a model from its configuration file does `),rFe=a("strong"),P1r=o("not"),B1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kH=a("a"),I1r=o("from_pretrained()"),N1r=o(" to load the model weights."),q1r=l(),F(t7.$$.fragment),j1r=l(),xr=a("div"),F(S9.$$.fragment),D1r=l(),tFe=a("p"),G1r=o("Instantiate one of the base model classes of the library from a pretrained model."),O1r=l(),sn=a("p"),V1r=o("The model class to instantiate is selected based on the "),aFe=a("code"),X1r=o("model_type"),z1r=o(` property of the config object (either
passed as an argument or loaded from `),nFe=a("code"),W1r=o("pretrained_model_name_or_path"),Q1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sFe=a("code"),H1r=o("pretrained_model_name_or_path"),U1r=o(":"),J1r=l(),q=a("ul"),a7=a("li"),lFe=a("strong"),Y1r=o("albert"),K1r=o(" \u2014 "),SH=a("a"),Z1r=o("TFAlbertModel"),e2r=o(" (ALBERT model)"),o2r=l(),n7=a("li"),iFe=a("strong"),r2r=o("bart"),t2r=o(" \u2014 "),RH=a("a"),a2r=o("TFBartModel"),n2r=o(" (BART model)"),s2r=l(),s7=a("li"),dFe=a("strong"),l2r=o("bert"),i2r=o(" \u2014 "),PH=a("a"),d2r=o("TFBertModel"),c2r=o(" (BERT model)"),f2r=l(),l7=a("li"),cFe=a("strong"),m2r=o("blenderbot"),g2r=o(" \u2014 "),BH=a("a"),h2r=o("TFBlenderbotModel"),p2r=o(" (Blenderbot model)"),_2r=l(),i7=a("li"),fFe=a("strong"),u2r=o("blenderbot-small"),b2r=o(" \u2014 "),IH=a("a"),v2r=o("TFBlenderbotSmallModel"),F2r=o(" (BlenderbotSmall model)"),T2r=l(),d7=a("li"),mFe=a("strong"),M2r=o("camembert"),E2r=o(" \u2014 "),NH=a("a"),C2r=o("TFCamembertModel"),w2r=o(" (CamemBERT model)"),A2r=l(),c7=a("li"),gFe=a("strong"),L2r=o("clip"),y2r=o(" \u2014 "),qH=a("a"),x2r=o("TFCLIPModel"),$2r=o(" (CLIP model)"),k2r=l(),f7=a("li"),hFe=a("strong"),S2r=o("convbert"),R2r=o(" \u2014 "),jH=a("a"),P2r=o("TFConvBertModel"),B2r=o(" (ConvBERT model)"),I2r=l(),m7=a("li"),pFe=a("strong"),N2r=o("convnext"),q2r=o(" \u2014 "),DH=a("a"),j2r=o("TFConvNextModel"),D2r=o(" (ConvNeXT model)"),G2r=l(),g7=a("li"),_Fe=a("strong"),O2r=o("ctrl"),V2r=o(" \u2014 "),GH=a("a"),X2r=o("TFCTRLModel"),z2r=o(" (CTRL model)"),W2r=l(),h7=a("li"),uFe=a("strong"),Q2r=o("data2vec-vision"),H2r=o(" \u2014 "),OH=a("a"),U2r=o("TFData2VecVisionModel"),J2r=o(" (Data2VecVision model)"),Y2r=l(),p7=a("li"),bFe=a("strong"),K2r=o("deberta"),Z2r=o(" \u2014 "),VH=a("a"),ebr=o("TFDebertaModel"),obr=o(" (DeBERTa model)"),rbr=l(),_7=a("li"),vFe=a("strong"),tbr=o("deberta-v2"),abr=o(" \u2014 "),XH=a("a"),nbr=o("TFDebertaV2Model"),sbr=o(" (DeBERTa-v2 model)"),lbr=l(),u7=a("li"),FFe=a("strong"),ibr=o("deit"),dbr=o(" \u2014 "),zH=a("a"),cbr=o("TFDeiTModel"),fbr=o(" (DeiT model)"),mbr=l(),b7=a("li"),TFe=a("strong"),gbr=o("distilbert"),hbr=o(" \u2014 "),WH=a("a"),pbr=o("TFDistilBertModel"),_br=o(" (DistilBERT model)"),ubr=l(),v7=a("li"),MFe=a("strong"),bbr=o("dpr"),vbr=o(" \u2014 "),QH=a("a"),Fbr=o("TFDPRQuestionEncoder"),Tbr=o(" (DPR model)"),Mbr=l(),F7=a("li"),EFe=a("strong"),Ebr=o("electra"),Cbr=o(" \u2014 "),HH=a("a"),wbr=o("TFElectraModel"),Abr=o(" (ELECTRA model)"),Lbr=l(),T7=a("li"),CFe=a("strong"),ybr=o("flaubert"),xbr=o(" \u2014 "),UH=a("a"),$br=o("TFFlaubertModel"),kbr=o(" (FlauBERT model)"),Sbr=l(),Us=a("li"),wFe=a("strong"),Rbr=o("funnel"),Pbr=o(" \u2014 "),JH=a("a"),Bbr=o("TFFunnelModel"),Ibr=o(" or "),YH=a("a"),Nbr=o("TFFunnelBaseModel"),qbr=o(" (Funnel Transformer model)"),jbr=l(),M7=a("li"),AFe=a("strong"),Dbr=o("gpt2"),Gbr=o(" \u2014 "),KH=a("a"),Obr=o("TFGPT2Model"),Vbr=o(" (OpenAI GPT-2 model)"),Xbr=l(),E7=a("li"),LFe=a("strong"),zbr=o("gptj"),Wbr=o(" \u2014 "),ZH=a("a"),Qbr=o("TFGPTJModel"),Hbr=o(" (GPT-J model)"),Ubr=l(),C7=a("li"),yFe=a("strong"),Jbr=o("hubert"),Ybr=o(" \u2014 "),eU=a("a"),Kbr=o("TFHubertModel"),Zbr=o(" (Hubert model)"),evr=l(),w7=a("li"),xFe=a("strong"),ovr=o("layoutlm"),rvr=o(" \u2014 "),oU=a("a"),tvr=o("TFLayoutLMModel"),avr=o(" (LayoutLM model)"),nvr=l(),A7=a("li"),$Fe=a("strong"),svr=o("led"),lvr=o(" \u2014 "),rU=a("a"),ivr=o("TFLEDModel"),dvr=o(" (LED model)"),cvr=l(),L7=a("li"),kFe=a("strong"),fvr=o("longformer"),mvr=o(" \u2014 "),tU=a("a"),gvr=o("TFLongformerModel"),hvr=o(" (Longformer model)"),pvr=l(),y7=a("li"),SFe=a("strong"),_vr=o("lxmert"),uvr=o(" \u2014 "),aU=a("a"),bvr=o("TFLxmertModel"),vvr=o(" (LXMERT model)"),Fvr=l(),x7=a("li"),RFe=a("strong"),Tvr=o("marian"),Mvr=o(" \u2014 "),nU=a("a"),Evr=o("TFMarianModel"),Cvr=o(" (Marian model)"),wvr=l(),$7=a("li"),PFe=a("strong"),Avr=o("mbart"),Lvr=o(" \u2014 "),sU=a("a"),yvr=o("TFMBartModel"),xvr=o(" (mBART model)"),$vr=l(),k7=a("li"),BFe=a("strong"),kvr=o("mobilebert"),Svr=o(" \u2014 "),lU=a("a"),Rvr=o("TFMobileBertModel"),Pvr=o(" (MobileBERT model)"),Bvr=l(),S7=a("li"),IFe=a("strong"),Ivr=o("mpnet"),Nvr=o(" \u2014 "),iU=a("a"),qvr=o("TFMPNetModel"),jvr=o(" (MPNet model)"),Dvr=l(),R7=a("li"),NFe=a("strong"),Gvr=o("mt5"),Ovr=o(" \u2014 "),dU=a("a"),Vvr=o("TFMT5Model"),Xvr=o(" (MT5 model)"),zvr=l(),P7=a("li"),qFe=a("strong"),Wvr=o("openai-gpt"),Qvr=o(" \u2014 "),cU=a("a"),Hvr=o("TFOpenAIGPTModel"),Uvr=o(" (OpenAI GPT model)"),Jvr=l(),B7=a("li"),jFe=a("strong"),Yvr=o("opt"),Kvr=o(" \u2014 "),fU=a("a"),Zvr=o("TFOPTModel"),e0r=o(" (OPT model)"),o0r=l(),I7=a("li"),DFe=a("strong"),r0r=o("pegasus"),t0r=o(" \u2014 "),mU=a("a"),a0r=o("TFPegasusModel"),n0r=o(" (Pegasus model)"),s0r=l(),N7=a("li"),GFe=a("strong"),l0r=o("regnet"),i0r=o(" \u2014 "),gU=a("a"),d0r=o("TFRegNetModel"),c0r=o(" (RegNet model)"),f0r=l(),q7=a("li"),OFe=a("strong"),m0r=o("rembert"),g0r=o(" \u2014 "),hU=a("a"),h0r=o("TFRemBertModel"),p0r=o(" (RemBERT model)"),_0r=l(),j7=a("li"),VFe=a("strong"),u0r=o("roberta"),b0r=o(" \u2014 "),pU=a("a"),v0r=o("TFRobertaModel"),F0r=o(" (RoBERTa model)"),T0r=l(),D7=a("li"),XFe=a("strong"),M0r=o("roformer"),E0r=o(" \u2014 "),_U=a("a"),C0r=o("TFRoFormerModel"),w0r=o(" (RoFormer model)"),A0r=l(),G7=a("li"),zFe=a("strong"),L0r=o("speech_to_text"),y0r=o(" \u2014 "),uU=a("a"),x0r=o("TFSpeech2TextModel"),$0r=o(" (Speech2Text model)"),k0r=l(),O7=a("li"),WFe=a("strong"),S0r=o("swin"),R0r=o(" \u2014 "),bU=a("a"),P0r=o("TFSwinModel"),B0r=o(" (Swin Transformer model)"),I0r=l(),V7=a("li"),QFe=a("strong"),N0r=o("t5"),q0r=o(" \u2014 "),vU=a("a"),j0r=o("TFT5Model"),D0r=o(" (T5 model)"),G0r=l(),X7=a("li"),HFe=a("strong"),O0r=o("tapas"),V0r=o(" \u2014 "),FU=a("a"),X0r=o("TFTapasModel"),z0r=o(" (TAPAS model)"),W0r=l(),z7=a("li"),UFe=a("strong"),Q0r=o("transfo-xl"),H0r=o(" \u2014 "),TU=a("a"),U0r=o("TFTransfoXLModel"),J0r=o(" (Transformer-XL model)"),Y0r=l(),W7=a("li"),JFe=a("strong"),K0r=o("vit"),Z0r=o(" \u2014 "),MU=a("a"),eFr=o("TFViTModel"),oFr=o(" (ViT model)"),rFr=l(),Q7=a("li"),YFe=a("strong"),tFr=o("vit_mae"),aFr=o(" \u2014 "),EU=a("a"),nFr=o("TFViTMAEModel"),sFr=o(" (ViTMAE model)"),lFr=l(),H7=a("li"),KFe=a("strong"),iFr=o("wav2vec2"),dFr=o(" \u2014 "),CU=a("a"),cFr=o("TFWav2Vec2Model"),fFr=o(" (Wav2Vec2 model)"),mFr=l(),U7=a("li"),ZFe=a("strong"),gFr=o("xlm"),hFr=o(" \u2014 "),wU=a("a"),pFr=o("TFXLMModel"),_Fr=o(" (XLM model)"),uFr=l(),J7=a("li"),e6e=a("strong"),bFr=o("xlm-roberta"),vFr=o(" \u2014 "),AU=a("a"),FFr=o("TFXLMRobertaModel"),TFr=o(" (XLM-RoBERTa model)"),MFr=l(),Y7=a("li"),o6e=a("strong"),EFr=o("xlnet"),CFr=o(" \u2014 "),LU=a("a"),wFr=o("TFXLNetModel"),AFr=o(" (XLNet model)"),LFr=l(),F(K7.$$.fragment),UVe=l(),lc=a("h2"),Z7=a("a"),r6e=a("span"),F(R9.$$.fragment),yFr=l(),t6e=a("span"),xFr=o("TFAutoModelForPreTraining"),JVe=l(),or=a("div"),F(P9.$$.fragment),$Fr=l(),ic=a("p"),kFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),yU=a("a"),SFr=o("from_pretrained()"),RFr=o(" class method or the "),xU=a("a"),PFr=o("from_config()"),BFr=o(` class
method.`),IFr=l(),B9=a("p"),NFr=o("This class cannot be instantiated directly using "),a6e=a("code"),qFr=o("__init__()"),jFr=o(" (throws an error)."),DFr=l(),St=a("div"),F(I9.$$.fragment),GFr=l(),n6e=a("p"),OFr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),VFr=l(),dc=a("p"),XFr=o(`Note:
Loading a model from its configuration file does `),s6e=a("strong"),zFr=o("not"),WFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$U=a("a"),QFr=o("from_pretrained()"),HFr=o(" to load the model weights."),UFr=l(),F(e8.$$.fragment),JFr=l(),$r=a("div"),F(N9.$$.fragment),YFr=l(),l6e=a("p"),KFr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),ZFr=l(),ln=a("p"),e6r=o("The model class to instantiate is selected based on the "),i6e=a("code"),o6r=o("model_type"),r6r=o(` property of the config object (either
passed as an argument or loaded from `),d6e=a("code"),t6r=o("pretrained_model_name_or_path"),a6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c6e=a("code"),n6r=o("pretrained_model_name_or_path"),s6r=o(":"),l6r=l(),se=a("ul"),o8=a("li"),f6e=a("strong"),i6r=o("albert"),d6r=o(" \u2014 "),kU=a("a"),c6r=o("TFAlbertForPreTraining"),f6r=o(" (ALBERT model)"),m6r=l(),r8=a("li"),m6e=a("strong"),g6r=o("bart"),h6r=o(" \u2014 "),SU=a("a"),p6r=o("TFBartForConditionalGeneration"),_6r=o(" (BART model)"),u6r=l(),t8=a("li"),g6e=a("strong"),b6r=o("bert"),v6r=o(" \u2014 "),RU=a("a"),F6r=o("TFBertForPreTraining"),T6r=o(" (BERT model)"),M6r=l(),a8=a("li"),h6e=a("strong"),E6r=o("camembert"),C6r=o(" \u2014 "),PU=a("a"),w6r=o("TFCamembertForMaskedLM"),A6r=o(" (CamemBERT model)"),L6r=l(),n8=a("li"),p6e=a("strong"),y6r=o("ctrl"),x6r=o(" \u2014 "),BU=a("a"),$6r=o("TFCTRLLMHeadModel"),k6r=o(" (CTRL model)"),S6r=l(),s8=a("li"),_6e=a("strong"),R6r=o("distilbert"),P6r=o(" \u2014 "),IU=a("a"),B6r=o("TFDistilBertForMaskedLM"),I6r=o(" (DistilBERT model)"),N6r=l(),l8=a("li"),u6e=a("strong"),q6r=o("electra"),j6r=o(" \u2014 "),NU=a("a"),D6r=o("TFElectraForPreTraining"),G6r=o(" (ELECTRA model)"),O6r=l(),i8=a("li"),b6e=a("strong"),V6r=o("flaubert"),X6r=o(" \u2014 "),qU=a("a"),z6r=o("TFFlaubertWithLMHeadModel"),W6r=o(" (FlauBERT model)"),Q6r=l(),d8=a("li"),v6e=a("strong"),H6r=o("funnel"),U6r=o(" \u2014 "),jU=a("a"),J6r=o("TFFunnelForPreTraining"),Y6r=o(" (Funnel Transformer model)"),K6r=l(),c8=a("li"),F6e=a("strong"),Z6r=o("gpt2"),eTr=o(" \u2014 "),DU=a("a"),oTr=o("TFGPT2LMHeadModel"),rTr=o(" (OpenAI GPT-2 model)"),tTr=l(),f8=a("li"),T6e=a("strong"),aTr=o("layoutlm"),nTr=o(" \u2014 "),GU=a("a"),sTr=o("TFLayoutLMForMaskedLM"),lTr=o(" (LayoutLM model)"),iTr=l(),m8=a("li"),M6e=a("strong"),dTr=o("lxmert"),cTr=o(" \u2014 "),OU=a("a"),fTr=o("TFLxmertForPreTraining"),mTr=o(" (LXMERT model)"),gTr=l(),g8=a("li"),E6e=a("strong"),hTr=o("mobilebert"),pTr=o(" \u2014 "),VU=a("a"),_Tr=o("TFMobileBertForPreTraining"),uTr=o(" (MobileBERT model)"),bTr=l(),h8=a("li"),C6e=a("strong"),vTr=o("mpnet"),FTr=o(" \u2014 "),XU=a("a"),TTr=o("TFMPNetForMaskedLM"),MTr=o(" (MPNet model)"),ETr=l(),p8=a("li"),w6e=a("strong"),CTr=o("openai-gpt"),wTr=o(" \u2014 "),zU=a("a"),ATr=o("TFOpenAIGPTLMHeadModel"),LTr=o(" (OpenAI GPT model)"),yTr=l(),_8=a("li"),A6e=a("strong"),xTr=o("roberta"),$Tr=o(" \u2014 "),WU=a("a"),kTr=o("TFRobertaForMaskedLM"),STr=o(" (RoBERTa model)"),RTr=l(),u8=a("li"),L6e=a("strong"),PTr=o("t5"),BTr=o(" \u2014 "),QU=a("a"),ITr=o("TFT5ForConditionalGeneration"),NTr=o(" (T5 model)"),qTr=l(),b8=a("li"),y6e=a("strong"),jTr=o("tapas"),DTr=o(" \u2014 "),HU=a("a"),GTr=o("TFTapasForMaskedLM"),OTr=o(" (TAPAS model)"),VTr=l(),v8=a("li"),x6e=a("strong"),XTr=o("transfo-xl"),zTr=o(" \u2014 "),UU=a("a"),WTr=o("TFTransfoXLLMHeadModel"),QTr=o(" (Transformer-XL model)"),HTr=l(),F8=a("li"),$6e=a("strong"),UTr=o("vit_mae"),JTr=o(" \u2014 "),JU=a("a"),YTr=o("TFViTMAEForPreTraining"),KTr=o(" (ViTMAE model)"),ZTr=l(),T8=a("li"),k6e=a("strong"),e7r=o("xlm"),o7r=o(" \u2014 "),YU=a("a"),r7r=o("TFXLMWithLMHeadModel"),t7r=o(" (XLM model)"),a7r=l(),M8=a("li"),S6e=a("strong"),n7r=o("xlm-roberta"),s7r=o(" \u2014 "),KU=a("a"),l7r=o("TFXLMRobertaForMaskedLM"),i7r=o(" (XLM-RoBERTa model)"),d7r=l(),E8=a("li"),R6e=a("strong"),c7r=o("xlnet"),f7r=o(" \u2014 "),ZU=a("a"),m7r=o("TFXLNetLMHeadModel"),g7r=o(" (XLNet model)"),h7r=l(),F(C8.$$.fragment),YVe=l(),cc=a("h2"),w8=a("a"),P6e=a("span"),F(q9.$$.fragment),p7r=l(),B6e=a("span"),_7r=o("TFAutoModelForCausalLM"),KVe=l(),rr=a("div"),F(j9.$$.fragment),u7r=l(),fc=a("p"),b7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),eJ=a("a"),v7r=o("from_pretrained()"),F7r=o(" class method or the "),oJ=a("a"),T7r=o("from_config()"),M7r=o(` class
method.`),E7r=l(),D9=a("p"),C7r=o("This class cannot be instantiated directly using "),I6e=a("code"),w7r=o("__init__()"),A7r=o(" (throws an error)."),L7r=l(),Rt=a("div"),F(G9.$$.fragment),y7r=l(),N6e=a("p"),x7r=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),$7r=l(),mc=a("p"),k7r=o(`Note:
Loading a model from its configuration file does `),q6e=a("strong"),S7r=o("not"),R7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rJ=a("a"),P7r=o("from_pretrained()"),B7r=o(" to load the model weights."),I7r=l(),F(A8.$$.fragment),N7r=l(),kr=a("div"),F(O9.$$.fragment),q7r=l(),j6e=a("p"),j7r=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),D7r=l(),dn=a("p"),G7r=o("The model class to instantiate is selected based on the "),D6e=a("code"),O7r=o("model_type"),V7r=o(` property of the config object (either
passed as an argument or loaded from `),G6e=a("code"),X7r=o("pretrained_model_name_or_path"),z7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O6e=a("code"),W7r=o("pretrained_model_name_or_path"),Q7r=o(":"),H7r=l(),Me=a("ul"),L8=a("li"),V6e=a("strong"),U7r=o("bert"),J7r=o(" \u2014 "),tJ=a("a"),Y7r=o("TFBertLMHeadModel"),K7r=o(" (BERT model)"),Z7r=l(),y8=a("li"),X6e=a("strong"),e8r=o("camembert"),o8r=o(" \u2014 "),aJ=a("a"),r8r=o("TFCamembertForCausalLM"),t8r=o(" (CamemBERT model)"),a8r=l(),x8=a("li"),z6e=a("strong"),n8r=o("ctrl"),s8r=o(" \u2014 "),nJ=a("a"),l8r=o("TFCTRLLMHeadModel"),i8r=o(" (CTRL model)"),d8r=l(),$8=a("li"),W6e=a("strong"),c8r=o("gpt2"),f8r=o(" \u2014 "),sJ=a("a"),m8r=o("TFGPT2LMHeadModel"),g8r=o(" (OpenAI GPT-2 model)"),h8r=l(),k8=a("li"),Q6e=a("strong"),p8r=o("gptj"),_8r=o(" \u2014 "),lJ=a("a"),u8r=o("TFGPTJForCausalLM"),b8r=o(" (GPT-J model)"),v8r=l(),S8=a("li"),H6e=a("strong"),F8r=o("openai-gpt"),T8r=o(" \u2014 "),iJ=a("a"),M8r=o("TFOpenAIGPTLMHeadModel"),E8r=o(" (OpenAI GPT model)"),C8r=l(),R8=a("li"),U6e=a("strong"),w8r=o("opt"),A8r=o(" \u2014 "),dJ=a("a"),L8r=o("TFOPTForCausalLM"),y8r=o(" (OPT model)"),x8r=l(),P8=a("li"),J6e=a("strong"),$8r=o("rembert"),k8r=o(" \u2014 "),cJ=a("a"),S8r=o("TFRemBertForCausalLM"),R8r=o(" (RemBERT model)"),P8r=l(),B8=a("li"),Y6e=a("strong"),B8r=o("roberta"),I8r=o(" \u2014 "),fJ=a("a"),N8r=o("TFRobertaForCausalLM"),q8r=o(" (RoBERTa model)"),j8r=l(),I8=a("li"),K6e=a("strong"),D8r=o("roformer"),G8r=o(" \u2014 "),mJ=a("a"),O8r=o("TFRoFormerForCausalLM"),V8r=o(" (RoFormer model)"),X8r=l(),N8=a("li"),Z6e=a("strong"),z8r=o("transfo-xl"),W8r=o(" \u2014 "),gJ=a("a"),Q8r=o("TFTransfoXLLMHeadModel"),H8r=o(" (Transformer-XL model)"),U8r=l(),q8=a("li"),eTe=a("strong"),J8r=o("xlm"),Y8r=o(" \u2014 "),hJ=a("a"),K8r=o("TFXLMWithLMHeadModel"),Z8r=o(" (XLM model)"),eMr=l(),j8=a("li"),oTe=a("strong"),oMr=o("xlnet"),rMr=o(" \u2014 "),pJ=a("a"),tMr=o("TFXLNetLMHeadModel"),aMr=o(" (XLNet model)"),nMr=l(),F(D8.$$.fragment),ZVe=l(),gc=a("h2"),G8=a("a"),rTe=a("span"),F(V9.$$.fragment),sMr=l(),tTe=a("span"),lMr=o("TFAutoModelForImageClassification"),eXe=l(),tr=a("div"),F(X9.$$.fragment),iMr=l(),hc=a("p"),dMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),_J=a("a"),cMr=o("from_pretrained()"),fMr=o(" class method or the "),uJ=a("a"),mMr=o("from_config()"),gMr=o(` class
method.`),hMr=l(),z9=a("p"),pMr=o("This class cannot be instantiated directly using "),aTe=a("code"),_Mr=o("__init__()"),uMr=o(" (throws an error)."),bMr=l(),Pt=a("div"),F(W9.$$.fragment),vMr=l(),nTe=a("p"),FMr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),TMr=l(),pc=a("p"),MMr=o(`Note:
Loading a model from its configuration file does `),sTe=a("strong"),EMr=o("not"),CMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bJ=a("a"),wMr=o("from_pretrained()"),AMr=o(" to load the model weights."),LMr=l(),F(O8.$$.fragment),yMr=l(),Sr=a("div"),F(Q9.$$.fragment),xMr=l(),lTe=a("p"),$Mr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),kMr=l(),cn=a("p"),SMr=o("The model class to instantiate is selected based on the "),iTe=a("code"),RMr=o("model_type"),PMr=o(` property of the config object (either
passed as an argument or loaded from `),dTe=a("code"),BMr=o("pretrained_model_name_or_path"),IMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cTe=a("code"),NMr=o("pretrained_model_name_or_path"),qMr=o(":"),jMr=l(),ar=a("ul"),V8=a("li"),fTe=a("strong"),DMr=o("convnext"),GMr=o(" \u2014 "),vJ=a("a"),OMr=o("TFConvNextForImageClassification"),VMr=o(" (ConvNeXT model)"),XMr=l(),X8=a("li"),mTe=a("strong"),zMr=o("data2vec-vision"),WMr=o(" \u2014 "),FJ=a("a"),QMr=o("TFData2VecVisionForImageClassification"),HMr=o(" (Data2VecVision model)"),UMr=l(),Js=a("li"),gTe=a("strong"),JMr=o("deit"),YMr=o(" \u2014 "),TJ=a("a"),KMr=o("TFDeiTForImageClassification"),ZMr=o(" or "),MJ=a("a"),e4r=o("TFDeiTForImageClassificationWithTeacher"),o4r=o(" (DeiT model)"),r4r=l(),z8=a("li"),hTe=a("strong"),t4r=o("regnet"),a4r=o(" \u2014 "),EJ=a("a"),n4r=o("TFRegNetForImageClassification"),s4r=o(" (RegNet model)"),l4r=l(),W8=a("li"),pTe=a("strong"),i4r=o("swin"),d4r=o(" \u2014 "),CJ=a("a"),c4r=o("TFSwinForImageClassification"),f4r=o(" (Swin Transformer model)"),m4r=l(),Q8=a("li"),_Te=a("strong"),g4r=o("vit"),h4r=o(" \u2014 "),wJ=a("a"),p4r=o("TFViTForImageClassification"),_4r=o(" (ViT model)"),u4r=l(),F(H8.$$.fragment),oXe=l(),_c=a("h2"),U8=a("a"),uTe=a("span"),F(H9.$$.fragment),b4r=l(),bTe=a("span"),v4r=o("TFAutoModelForMaskedLM"),rXe=l(),nr=a("div"),F(U9.$$.fragment),F4r=l(),uc=a("p"),T4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),AJ=a("a"),M4r=o("from_pretrained()"),E4r=o(" class method or the "),LJ=a("a"),C4r=o("from_config()"),w4r=o(` class
method.`),A4r=l(),J9=a("p"),L4r=o("This class cannot be instantiated directly using "),vTe=a("code"),y4r=o("__init__()"),x4r=o(" (throws an error)."),$4r=l(),Bt=a("div"),F(Y9.$$.fragment),k4r=l(),FTe=a("p"),S4r=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),R4r=l(),bc=a("p"),P4r=o(`Note:
Loading a model from its configuration file does `),TTe=a("strong"),B4r=o("not"),I4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yJ=a("a"),N4r=o("from_pretrained()"),q4r=o(" to load the model weights."),j4r=l(),F(J8.$$.fragment),D4r=l(),Rr=a("div"),F(K9.$$.fragment),G4r=l(),MTe=a("p"),O4r=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),V4r=l(),fn=a("p"),X4r=o("The model class to instantiate is selected based on the "),ETe=a("code"),z4r=o("model_type"),W4r=o(` property of the config object (either
passed as an argument or loaded from `),CTe=a("code"),Q4r=o("pretrained_model_name_or_path"),H4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wTe=a("code"),U4r=o("pretrained_model_name_or_path"),J4r=o(":"),Y4r=l(),ie=a("ul"),Y8=a("li"),ATe=a("strong"),K4r=o("albert"),Z4r=o(" \u2014 "),xJ=a("a"),eEr=o("TFAlbertForMaskedLM"),oEr=o(" (ALBERT model)"),rEr=l(),K8=a("li"),LTe=a("strong"),tEr=o("bert"),aEr=o(" \u2014 "),$J=a("a"),nEr=o("TFBertForMaskedLM"),sEr=o(" (BERT model)"),lEr=l(),Z8=a("li"),yTe=a("strong"),iEr=o("camembert"),dEr=o(" \u2014 "),kJ=a("a"),cEr=o("TFCamembertForMaskedLM"),fEr=o(" (CamemBERT model)"),mEr=l(),eM=a("li"),xTe=a("strong"),gEr=o("convbert"),hEr=o(" \u2014 "),SJ=a("a"),pEr=o("TFConvBertForMaskedLM"),_Er=o(" (ConvBERT model)"),uEr=l(),oM=a("li"),$Te=a("strong"),bEr=o("deberta"),vEr=o(" \u2014 "),RJ=a("a"),FEr=o("TFDebertaForMaskedLM"),TEr=o(" (DeBERTa model)"),MEr=l(),rM=a("li"),kTe=a("strong"),EEr=o("deberta-v2"),CEr=o(" \u2014 "),PJ=a("a"),wEr=o("TFDebertaV2ForMaskedLM"),AEr=o(" (DeBERTa-v2 model)"),LEr=l(),tM=a("li"),STe=a("strong"),yEr=o("distilbert"),xEr=o(" \u2014 "),BJ=a("a"),$Er=o("TFDistilBertForMaskedLM"),kEr=o(" (DistilBERT model)"),SEr=l(),aM=a("li"),RTe=a("strong"),REr=o("electra"),PEr=o(" \u2014 "),IJ=a("a"),BEr=o("TFElectraForMaskedLM"),IEr=o(" (ELECTRA model)"),NEr=l(),nM=a("li"),PTe=a("strong"),qEr=o("flaubert"),jEr=o(" \u2014 "),NJ=a("a"),DEr=o("TFFlaubertWithLMHeadModel"),GEr=o(" (FlauBERT model)"),OEr=l(),sM=a("li"),BTe=a("strong"),VEr=o("funnel"),XEr=o(" \u2014 "),qJ=a("a"),zEr=o("TFFunnelForMaskedLM"),WEr=o(" (Funnel Transformer model)"),QEr=l(),lM=a("li"),ITe=a("strong"),HEr=o("layoutlm"),UEr=o(" \u2014 "),jJ=a("a"),JEr=o("TFLayoutLMForMaskedLM"),YEr=o(" (LayoutLM model)"),KEr=l(),iM=a("li"),NTe=a("strong"),ZEr=o("longformer"),eCr=o(" \u2014 "),DJ=a("a"),oCr=o("TFLongformerForMaskedLM"),rCr=o(" (Longformer model)"),tCr=l(),dM=a("li"),qTe=a("strong"),aCr=o("mobilebert"),nCr=o(" \u2014 "),GJ=a("a"),sCr=o("TFMobileBertForMaskedLM"),lCr=o(" (MobileBERT model)"),iCr=l(),cM=a("li"),jTe=a("strong"),dCr=o("mpnet"),cCr=o(" \u2014 "),OJ=a("a"),fCr=o("TFMPNetForMaskedLM"),mCr=o(" (MPNet model)"),gCr=l(),fM=a("li"),DTe=a("strong"),hCr=o("rembert"),pCr=o(" \u2014 "),VJ=a("a"),_Cr=o("TFRemBertForMaskedLM"),uCr=o(" (RemBERT model)"),bCr=l(),mM=a("li"),GTe=a("strong"),vCr=o("roberta"),FCr=o(" \u2014 "),XJ=a("a"),TCr=o("TFRobertaForMaskedLM"),MCr=o(" (RoBERTa model)"),ECr=l(),gM=a("li"),OTe=a("strong"),CCr=o("roformer"),wCr=o(" \u2014 "),zJ=a("a"),ACr=o("TFRoFormerForMaskedLM"),LCr=o(" (RoFormer model)"),yCr=l(),hM=a("li"),VTe=a("strong"),xCr=o("tapas"),$Cr=o(" \u2014 "),WJ=a("a"),kCr=o("TFTapasForMaskedLM"),SCr=o(" (TAPAS model)"),RCr=l(),pM=a("li"),XTe=a("strong"),PCr=o("xlm"),BCr=o(" \u2014 "),QJ=a("a"),ICr=o("TFXLMWithLMHeadModel"),NCr=o(" (XLM model)"),qCr=l(),_M=a("li"),zTe=a("strong"),jCr=o("xlm-roberta"),DCr=o(" \u2014 "),HJ=a("a"),GCr=o("TFXLMRobertaForMaskedLM"),OCr=o(" (XLM-RoBERTa model)"),VCr=l(),F(uM.$$.fragment),tXe=l(),vc=a("h2"),bM=a("a"),WTe=a("span"),F(Z9.$$.fragment),XCr=l(),QTe=a("span"),zCr=o("TFAutoModelForSeq2SeqLM"),aXe=l(),sr=a("div"),F(ex.$$.fragment),WCr=l(),Fc=a("p"),QCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),UJ=a("a"),HCr=o("from_pretrained()"),UCr=o(" class method or the "),JJ=a("a"),JCr=o("from_config()"),YCr=o(` class
method.`),KCr=l(),ox=a("p"),ZCr=o("This class cannot be instantiated directly using "),HTe=a("code"),e3r=o("__init__()"),o3r=o(" (throws an error)."),r3r=l(),It=a("div"),F(rx.$$.fragment),t3r=l(),UTe=a("p"),a3r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),n3r=l(),Tc=a("p"),s3r=o(`Note:
Loading a model from its configuration file does `),JTe=a("strong"),l3r=o("not"),i3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YJ=a("a"),d3r=o("from_pretrained()"),c3r=o(" to load the model weights."),f3r=l(),F(vM.$$.fragment),m3r=l(),Pr=a("div"),F(tx.$$.fragment),g3r=l(),YTe=a("p"),h3r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),p3r=l(),mn=a("p"),_3r=o("The model class to instantiate is selected based on the "),KTe=a("code"),u3r=o("model_type"),b3r=o(` property of the config object (either
passed as an argument or loaded from `),ZTe=a("code"),v3r=o("pretrained_model_name_or_path"),F3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e7e=a("code"),T3r=o("pretrained_model_name_or_path"),M3r=o(":"),E3r=l(),ye=a("ul"),FM=a("li"),o7e=a("strong"),C3r=o("bart"),w3r=o(" \u2014 "),KJ=a("a"),A3r=o("TFBartForConditionalGeneration"),L3r=o(" (BART model)"),y3r=l(),TM=a("li"),r7e=a("strong"),x3r=o("blenderbot"),$3r=o(" \u2014 "),ZJ=a("a"),k3r=o("TFBlenderbotForConditionalGeneration"),S3r=o(" (Blenderbot model)"),R3r=l(),MM=a("li"),t7e=a("strong"),P3r=o("blenderbot-small"),B3r=o(" \u2014 "),eY=a("a"),I3r=o("TFBlenderbotSmallForConditionalGeneration"),N3r=o(" (BlenderbotSmall model)"),q3r=l(),EM=a("li"),a7e=a("strong"),j3r=o("encoder-decoder"),D3r=o(" \u2014 "),oY=a("a"),G3r=o("TFEncoderDecoderModel"),O3r=o(" (Encoder decoder model)"),V3r=l(),CM=a("li"),n7e=a("strong"),X3r=o("led"),z3r=o(" \u2014 "),rY=a("a"),W3r=o("TFLEDForConditionalGeneration"),Q3r=o(" (LED model)"),H3r=l(),wM=a("li"),s7e=a("strong"),U3r=o("marian"),J3r=o(" \u2014 "),tY=a("a"),Y3r=o("TFMarianMTModel"),K3r=o(" (Marian model)"),Z3r=l(),AM=a("li"),l7e=a("strong"),e5r=o("mbart"),o5r=o(" \u2014 "),aY=a("a"),r5r=o("TFMBartForConditionalGeneration"),t5r=o(" (mBART model)"),a5r=l(),LM=a("li"),i7e=a("strong"),n5r=o("mt5"),s5r=o(" \u2014 "),nY=a("a"),l5r=o("TFMT5ForConditionalGeneration"),i5r=o(" (MT5 model)"),d5r=l(),yM=a("li"),d7e=a("strong"),c5r=o("pegasus"),f5r=o(" \u2014 "),sY=a("a"),m5r=o("TFPegasusForConditionalGeneration"),g5r=o(" (Pegasus model)"),h5r=l(),xM=a("li"),c7e=a("strong"),p5r=o("t5"),_5r=o(" \u2014 "),lY=a("a"),u5r=o("TFT5ForConditionalGeneration"),b5r=o(" (T5 model)"),v5r=l(),F($M.$$.fragment),nXe=l(),Mc=a("h2"),kM=a("a"),f7e=a("span"),F(ax.$$.fragment),F5r=l(),m7e=a("span"),T5r=o("TFAutoModelForSequenceClassification"),sXe=l(),lr=a("div"),F(nx.$$.fragment),M5r=l(),Ec=a("p"),E5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),iY=a("a"),C5r=o("from_pretrained()"),w5r=o(" class method or the "),dY=a("a"),A5r=o("from_config()"),L5r=o(` class
method.`),y5r=l(),sx=a("p"),x5r=o("This class cannot be instantiated directly using "),g7e=a("code"),$5r=o("__init__()"),k5r=o(" (throws an error)."),S5r=l(),Nt=a("div"),F(lx.$$.fragment),R5r=l(),h7e=a("p"),P5r=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),B5r=l(),Cc=a("p"),I5r=o(`Note:
Loading a model from its configuration file does `),p7e=a("strong"),N5r=o("not"),q5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cY=a("a"),j5r=o("from_pretrained()"),D5r=o(" to load the model weights."),G5r=l(),F(SM.$$.fragment),O5r=l(),Br=a("div"),F(ix.$$.fragment),V5r=l(),_7e=a("p"),X5r=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),z5r=l(),gn=a("p"),W5r=o("The model class to instantiate is selected based on the "),u7e=a("code"),Q5r=o("model_type"),H5r=o(` property of the config object (either
passed as an argument or loaded from `),b7e=a("code"),U5r=o("pretrained_model_name_or_path"),J5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v7e=a("code"),Y5r=o("pretrained_model_name_or_path"),K5r=o(":"),Z5r=l(),te=a("ul"),RM=a("li"),F7e=a("strong"),ewr=o("albert"),owr=o(" \u2014 "),fY=a("a"),rwr=o("TFAlbertForSequenceClassification"),twr=o(" (ALBERT model)"),awr=l(),PM=a("li"),T7e=a("strong"),nwr=o("bert"),swr=o(" \u2014 "),mY=a("a"),lwr=o("TFBertForSequenceClassification"),iwr=o(" (BERT model)"),dwr=l(),BM=a("li"),M7e=a("strong"),cwr=o("camembert"),fwr=o(" \u2014 "),gY=a("a"),mwr=o("TFCamembertForSequenceClassification"),gwr=o(" (CamemBERT model)"),hwr=l(),IM=a("li"),E7e=a("strong"),pwr=o("convbert"),_wr=o(" \u2014 "),hY=a("a"),uwr=o("TFConvBertForSequenceClassification"),bwr=o(" (ConvBERT model)"),vwr=l(),NM=a("li"),C7e=a("strong"),Fwr=o("ctrl"),Twr=o(" \u2014 "),pY=a("a"),Mwr=o("TFCTRLForSequenceClassification"),Ewr=o(" (CTRL model)"),Cwr=l(),qM=a("li"),w7e=a("strong"),wwr=o("deberta"),Awr=o(" \u2014 "),_Y=a("a"),Lwr=o("TFDebertaForSequenceClassification"),ywr=o(" (DeBERTa model)"),xwr=l(),jM=a("li"),A7e=a("strong"),$wr=o("deberta-v2"),kwr=o(" \u2014 "),uY=a("a"),Swr=o("TFDebertaV2ForSequenceClassification"),Rwr=o(" (DeBERTa-v2 model)"),Pwr=l(),DM=a("li"),L7e=a("strong"),Bwr=o("distilbert"),Iwr=o(" \u2014 "),bY=a("a"),Nwr=o("TFDistilBertForSequenceClassification"),qwr=o(" (DistilBERT model)"),jwr=l(),GM=a("li"),y7e=a("strong"),Dwr=o("electra"),Gwr=o(" \u2014 "),vY=a("a"),Owr=o("TFElectraForSequenceClassification"),Vwr=o(" (ELECTRA model)"),Xwr=l(),OM=a("li"),x7e=a("strong"),zwr=o("flaubert"),Wwr=o(" \u2014 "),FY=a("a"),Qwr=o("TFFlaubertForSequenceClassification"),Hwr=o(" (FlauBERT model)"),Uwr=l(),VM=a("li"),$7e=a("strong"),Jwr=o("funnel"),Ywr=o(" \u2014 "),TY=a("a"),Kwr=o("TFFunnelForSequenceClassification"),Zwr=o(" (Funnel Transformer model)"),eAr=l(),XM=a("li"),k7e=a("strong"),oAr=o("gpt2"),rAr=o(" \u2014 "),MY=a("a"),tAr=o("TFGPT2ForSequenceClassification"),aAr=o(" (OpenAI GPT-2 model)"),nAr=l(),zM=a("li"),S7e=a("strong"),sAr=o("gptj"),lAr=o(" \u2014 "),EY=a("a"),iAr=o("TFGPTJForSequenceClassification"),dAr=o(" (GPT-J model)"),cAr=l(),WM=a("li"),R7e=a("strong"),fAr=o("layoutlm"),mAr=o(" \u2014 "),CY=a("a"),gAr=o("TFLayoutLMForSequenceClassification"),hAr=o(" (LayoutLM model)"),pAr=l(),QM=a("li"),P7e=a("strong"),_Ar=o("longformer"),uAr=o(" \u2014 "),wY=a("a"),bAr=o("TFLongformerForSequenceClassification"),vAr=o(" (Longformer model)"),FAr=l(),HM=a("li"),B7e=a("strong"),TAr=o("mobilebert"),MAr=o(" \u2014 "),AY=a("a"),EAr=o("TFMobileBertForSequenceClassification"),CAr=o(" (MobileBERT model)"),wAr=l(),UM=a("li"),I7e=a("strong"),AAr=o("mpnet"),LAr=o(" \u2014 "),LY=a("a"),yAr=o("TFMPNetForSequenceClassification"),xAr=o(" (MPNet model)"),$Ar=l(),JM=a("li"),N7e=a("strong"),kAr=o("openai-gpt"),SAr=o(" \u2014 "),yY=a("a"),RAr=o("TFOpenAIGPTForSequenceClassification"),PAr=o(" (OpenAI GPT model)"),BAr=l(),YM=a("li"),q7e=a("strong"),IAr=o("rembert"),NAr=o(" \u2014 "),xY=a("a"),qAr=o("TFRemBertForSequenceClassification"),jAr=o(" (RemBERT model)"),DAr=l(),KM=a("li"),j7e=a("strong"),GAr=o("roberta"),OAr=o(" \u2014 "),$Y=a("a"),VAr=o("TFRobertaForSequenceClassification"),XAr=o(" (RoBERTa model)"),zAr=l(),ZM=a("li"),D7e=a("strong"),WAr=o("roformer"),QAr=o(" \u2014 "),kY=a("a"),HAr=o("TFRoFormerForSequenceClassification"),UAr=o(" (RoFormer model)"),JAr=l(),e4=a("li"),G7e=a("strong"),YAr=o("tapas"),KAr=o(" \u2014 "),SY=a("a"),ZAr=o("TFTapasForSequenceClassification"),eLr=o(" (TAPAS model)"),oLr=l(),o4=a("li"),O7e=a("strong"),rLr=o("transfo-xl"),tLr=o(" \u2014 "),RY=a("a"),aLr=o("TFTransfoXLForSequenceClassification"),nLr=o(" (Transformer-XL model)"),sLr=l(),r4=a("li"),V7e=a("strong"),lLr=o("xlm"),iLr=o(" \u2014 "),PY=a("a"),dLr=o("TFXLMForSequenceClassification"),cLr=o(" (XLM model)"),fLr=l(),t4=a("li"),X7e=a("strong"),mLr=o("xlm-roberta"),gLr=o(" \u2014 "),BY=a("a"),hLr=o("TFXLMRobertaForSequenceClassification"),pLr=o(" (XLM-RoBERTa model)"),_Lr=l(),a4=a("li"),z7e=a("strong"),uLr=o("xlnet"),bLr=o(" \u2014 "),IY=a("a"),vLr=o("TFXLNetForSequenceClassification"),FLr=o(" (XLNet model)"),TLr=l(),F(n4.$$.fragment),lXe=l(),wc=a("h2"),s4=a("a"),W7e=a("span"),F(dx.$$.fragment),MLr=l(),Q7e=a("span"),ELr=o("TFAutoModelForMultipleChoice"),iXe=l(),ir=a("div"),F(cx.$$.fragment),CLr=l(),Ac=a("p"),wLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),NY=a("a"),ALr=o("from_pretrained()"),LLr=o(" class method or the "),qY=a("a"),yLr=o("from_config()"),xLr=o(` class
method.`),$Lr=l(),fx=a("p"),kLr=o("This class cannot be instantiated directly using "),H7e=a("code"),SLr=o("__init__()"),RLr=o(" (throws an error)."),PLr=l(),qt=a("div"),F(mx.$$.fragment),BLr=l(),U7e=a("p"),ILr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),NLr=l(),Lc=a("p"),qLr=o(`Note:
Loading a model from its configuration file does `),J7e=a("strong"),jLr=o("not"),DLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jY=a("a"),GLr=o("from_pretrained()"),OLr=o(" to load the model weights."),VLr=l(),F(l4.$$.fragment),XLr=l(),Ir=a("div"),F(gx.$$.fragment),zLr=l(),Y7e=a("p"),WLr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),QLr=l(),hn=a("p"),HLr=o("The model class to instantiate is selected based on the "),K7e=a("code"),ULr=o("model_type"),JLr=o(` property of the config object (either
passed as an argument or loaded from `),Z7e=a("code"),YLr=o("pretrained_model_name_or_path"),KLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e8e=a("code"),ZLr=o("pretrained_model_name_or_path"),eyr=o(":"),oyr=l(),_e=a("ul"),i4=a("li"),o8e=a("strong"),ryr=o("albert"),tyr=o(" \u2014 "),DY=a("a"),ayr=o("TFAlbertForMultipleChoice"),nyr=o(" (ALBERT model)"),syr=l(),d4=a("li"),r8e=a("strong"),lyr=o("bert"),iyr=o(" \u2014 "),GY=a("a"),dyr=o("TFBertForMultipleChoice"),cyr=o(" (BERT model)"),fyr=l(),c4=a("li"),t8e=a("strong"),myr=o("camembert"),gyr=o(" \u2014 "),OY=a("a"),hyr=o("TFCamembertForMultipleChoice"),pyr=o(" (CamemBERT model)"),_yr=l(),f4=a("li"),a8e=a("strong"),uyr=o("convbert"),byr=o(" \u2014 "),VY=a("a"),vyr=o("TFConvBertForMultipleChoice"),Fyr=o(" (ConvBERT model)"),Tyr=l(),m4=a("li"),n8e=a("strong"),Myr=o("distilbert"),Eyr=o(" \u2014 "),XY=a("a"),Cyr=o("TFDistilBertForMultipleChoice"),wyr=o(" (DistilBERT model)"),Ayr=l(),g4=a("li"),s8e=a("strong"),Lyr=o("electra"),yyr=o(" \u2014 "),zY=a("a"),xyr=o("TFElectraForMultipleChoice"),$yr=o(" (ELECTRA model)"),kyr=l(),h4=a("li"),l8e=a("strong"),Syr=o("flaubert"),Ryr=o(" \u2014 "),WY=a("a"),Pyr=o("TFFlaubertForMultipleChoice"),Byr=o(" (FlauBERT model)"),Iyr=l(),p4=a("li"),i8e=a("strong"),Nyr=o("funnel"),qyr=o(" \u2014 "),QY=a("a"),jyr=o("TFFunnelForMultipleChoice"),Dyr=o(" (Funnel Transformer model)"),Gyr=l(),_4=a("li"),d8e=a("strong"),Oyr=o("longformer"),Vyr=o(" \u2014 "),HY=a("a"),Xyr=o("TFLongformerForMultipleChoice"),zyr=o(" (Longformer model)"),Wyr=l(),u4=a("li"),c8e=a("strong"),Qyr=o("mobilebert"),Hyr=o(" \u2014 "),UY=a("a"),Uyr=o("TFMobileBertForMultipleChoice"),Jyr=o(" (MobileBERT model)"),Yyr=l(),b4=a("li"),f8e=a("strong"),Kyr=o("mpnet"),Zyr=o(" \u2014 "),JY=a("a"),e9r=o("TFMPNetForMultipleChoice"),o9r=o(" (MPNet model)"),r9r=l(),v4=a("li"),m8e=a("strong"),t9r=o("rembert"),a9r=o(" \u2014 "),YY=a("a"),n9r=o("TFRemBertForMultipleChoice"),s9r=o(" (RemBERT model)"),l9r=l(),F4=a("li"),g8e=a("strong"),i9r=o("roberta"),d9r=o(" \u2014 "),KY=a("a"),c9r=o("TFRobertaForMultipleChoice"),f9r=o(" (RoBERTa model)"),m9r=l(),T4=a("li"),h8e=a("strong"),g9r=o("roformer"),h9r=o(" \u2014 "),ZY=a("a"),p9r=o("TFRoFormerForMultipleChoice"),_9r=o(" (RoFormer model)"),u9r=l(),M4=a("li"),p8e=a("strong"),b9r=o("xlm"),v9r=o(" \u2014 "),eK=a("a"),F9r=o("TFXLMForMultipleChoice"),T9r=o(" (XLM model)"),M9r=l(),E4=a("li"),_8e=a("strong"),E9r=o("xlm-roberta"),C9r=o(" \u2014 "),oK=a("a"),w9r=o("TFXLMRobertaForMultipleChoice"),A9r=o(" (XLM-RoBERTa model)"),L9r=l(),C4=a("li"),u8e=a("strong"),y9r=o("xlnet"),x9r=o(" \u2014 "),rK=a("a"),$9r=o("TFXLNetForMultipleChoice"),k9r=o(" (XLNet model)"),S9r=l(),F(w4.$$.fragment),dXe=l(),yc=a("h2"),A4=a("a"),b8e=a("span"),F(hx.$$.fragment),R9r=l(),v8e=a("span"),P9r=o("TFAutoModelForNextSentencePrediction"),cXe=l(),dr=a("div"),F(px.$$.fragment),B9r=l(),xc=a("p"),I9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),tK=a("a"),N9r=o("from_pretrained()"),q9r=o(" class method or the "),aK=a("a"),j9r=o("from_config()"),D9r=o(` class
method.`),G9r=l(),_x=a("p"),O9r=o("This class cannot be instantiated directly using "),F8e=a("code"),V9r=o("__init__()"),X9r=o(" (throws an error)."),z9r=l(),jt=a("div"),F(ux.$$.fragment),W9r=l(),T8e=a("p"),Q9r=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),H9r=l(),$c=a("p"),U9r=o(`Note:
Loading a model from its configuration file does `),M8e=a("strong"),J9r=o("not"),Y9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=a("a"),K9r=o("from_pretrained()"),Z9r=o(" to load the model weights."),exr=l(),F(L4.$$.fragment),oxr=l(),Nr=a("div"),F(bx.$$.fragment),rxr=l(),E8e=a("p"),txr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),axr=l(),pn=a("p"),nxr=o("The model class to instantiate is selected based on the "),C8e=a("code"),sxr=o("model_type"),lxr=o(` property of the config object (either
passed as an argument or loaded from `),w8e=a("code"),ixr=o("pretrained_model_name_or_path"),dxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A8e=a("code"),cxr=o("pretrained_model_name_or_path"),fxr=o(":"),mxr=l(),vx=a("ul"),y4=a("li"),L8e=a("strong"),gxr=o("bert"),hxr=o(" \u2014 "),sK=a("a"),pxr=o("TFBertForNextSentencePrediction"),_xr=o(" (BERT model)"),uxr=l(),x4=a("li"),y8e=a("strong"),bxr=o("mobilebert"),vxr=o(" \u2014 "),lK=a("a"),Fxr=o("TFMobileBertForNextSentencePrediction"),Txr=o(" (MobileBERT model)"),Mxr=l(),F($4.$$.fragment),fXe=l(),kc=a("h2"),k4=a("a"),x8e=a("span"),F(Fx.$$.fragment),Exr=l(),$8e=a("span"),Cxr=o("TFAutoModelForTableQuestionAnswering"),mXe=l(),cr=a("div"),F(Tx.$$.fragment),wxr=l(),Sc=a("p"),Axr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),iK=a("a"),Lxr=o("from_pretrained()"),yxr=o(" class method or the "),dK=a("a"),xxr=o("from_config()"),$xr=o(` class
method.`),kxr=l(),Mx=a("p"),Sxr=o("This class cannot be instantiated directly using "),k8e=a("code"),Rxr=o("__init__()"),Pxr=o(" (throws an error)."),Bxr=l(),Dt=a("div"),F(Ex.$$.fragment),Ixr=l(),S8e=a("p"),Nxr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),qxr=l(),Rc=a("p"),jxr=o(`Note:
Loading a model from its configuration file does `),R8e=a("strong"),Dxr=o("not"),Gxr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cK=a("a"),Oxr=o("from_pretrained()"),Vxr=o(" to load the model weights."),Xxr=l(),F(S4.$$.fragment),zxr=l(),qr=a("div"),F(Cx.$$.fragment),Wxr=l(),P8e=a("p"),Qxr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Hxr=l(),_n=a("p"),Uxr=o("The model class to instantiate is selected based on the "),B8e=a("code"),Jxr=o("model_type"),Yxr=o(` property of the config object (either
passed as an argument or loaded from `),I8e=a("code"),Kxr=o("pretrained_model_name_or_path"),Zxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N8e=a("code"),e$r=o("pretrained_model_name_or_path"),o$r=o(":"),r$r=l(),q8e=a("ul"),R4=a("li"),j8e=a("strong"),t$r=o("tapas"),a$r=o(" \u2014 "),fK=a("a"),n$r=o("TFTapasForQuestionAnswering"),s$r=o(" (TAPAS model)"),l$r=l(),F(P4.$$.fragment),gXe=l(),Pc=a("h2"),B4=a("a"),D8e=a("span"),F(wx.$$.fragment),i$r=l(),G8e=a("span"),d$r=o("TFAutoModelForTokenClassification"),hXe=l(),fr=a("div"),F(Ax.$$.fragment),c$r=l(),Bc=a("p"),f$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),mK=a("a"),m$r=o("from_pretrained()"),g$r=o(" class method or the "),gK=a("a"),h$r=o("from_config()"),p$r=o(` class
method.`),_$r=l(),Lx=a("p"),u$r=o("This class cannot be instantiated directly using "),O8e=a("code"),b$r=o("__init__()"),v$r=o(" (throws an error)."),F$r=l(),Gt=a("div"),F(yx.$$.fragment),T$r=l(),V8e=a("p"),M$r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),E$r=l(),Ic=a("p"),C$r=o(`Note:
Loading a model from its configuration file does `),X8e=a("strong"),w$r=o("not"),A$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hK=a("a"),L$r=o("from_pretrained()"),y$r=o(" to load the model weights."),x$r=l(),F(I4.$$.fragment),$$r=l(),jr=a("div"),F(xx.$$.fragment),k$r=l(),z8e=a("p"),S$r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),R$r=l(),un=a("p"),P$r=o("The model class to instantiate is selected based on the "),W8e=a("code"),B$r=o("model_type"),I$r=o(` property of the config object (either
passed as an argument or loaded from `),Q8e=a("code"),N$r=o("pretrained_model_name_or_path"),q$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H8e=a("code"),j$r=o("pretrained_model_name_or_path"),D$r=o(":"),G$r=l(),de=a("ul"),N4=a("li"),U8e=a("strong"),O$r=o("albert"),V$r=o(" \u2014 "),pK=a("a"),X$r=o("TFAlbertForTokenClassification"),z$r=o(" (ALBERT model)"),W$r=l(),q4=a("li"),J8e=a("strong"),Q$r=o("bert"),H$r=o(" \u2014 "),_K=a("a"),U$r=o("TFBertForTokenClassification"),J$r=o(" (BERT model)"),Y$r=l(),j4=a("li"),Y8e=a("strong"),K$r=o("camembert"),Z$r=o(" \u2014 "),uK=a("a"),ekr=o("TFCamembertForTokenClassification"),okr=o(" (CamemBERT model)"),rkr=l(),D4=a("li"),K8e=a("strong"),tkr=o("convbert"),akr=o(" \u2014 "),bK=a("a"),nkr=o("TFConvBertForTokenClassification"),skr=o(" (ConvBERT model)"),lkr=l(),G4=a("li"),Z8e=a("strong"),ikr=o("deberta"),dkr=o(" \u2014 "),vK=a("a"),ckr=o("TFDebertaForTokenClassification"),fkr=o(" (DeBERTa model)"),mkr=l(),O4=a("li"),eMe=a("strong"),gkr=o("deberta-v2"),hkr=o(" \u2014 "),FK=a("a"),pkr=o("TFDebertaV2ForTokenClassification"),_kr=o(" (DeBERTa-v2 model)"),ukr=l(),V4=a("li"),oMe=a("strong"),bkr=o("distilbert"),vkr=o(" \u2014 "),TK=a("a"),Fkr=o("TFDistilBertForTokenClassification"),Tkr=o(" (DistilBERT model)"),Mkr=l(),X4=a("li"),rMe=a("strong"),Ekr=o("electra"),Ckr=o(" \u2014 "),MK=a("a"),wkr=o("TFElectraForTokenClassification"),Akr=o(" (ELECTRA model)"),Lkr=l(),z4=a("li"),tMe=a("strong"),ykr=o("flaubert"),xkr=o(" \u2014 "),EK=a("a"),$kr=o("TFFlaubertForTokenClassification"),kkr=o(" (FlauBERT model)"),Skr=l(),W4=a("li"),aMe=a("strong"),Rkr=o("funnel"),Pkr=o(" \u2014 "),CK=a("a"),Bkr=o("TFFunnelForTokenClassification"),Ikr=o(" (Funnel Transformer model)"),Nkr=l(),Q4=a("li"),nMe=a("strong"),qkr=o("layoutlm"),jkr=o(" \u2014 "),wK=a("a"),Dkr=o("TFLayoutLMForTokenClassification"),Gkr=o(" (LayoutLM model)"),Okr=l(),H4=a("li"),sMe=a("strong"),Vkr=o("longformer"),Xkr=o(" \u2014 "),AK=a("a"),zkr=o("TFLongformerForTokenClassification"),Wkr=o(" (Longformer model)"),Qkr=l(),U4=a("li"),lMe=a("strong"),Hkr=o("mobilebert"),Ukr=o(" \u2014 "),LK=a("a"),Jkr=o("TFMobileBertForTokenClassification"),Ykr=o(" (MobileBERT model)"),Kkr=l(),J4=a("li"),iMe=a("strong"),Zkr=o("mpnet"),eSr=o(" \u2014 "),yK=a("a"),oSr=o("TFMPNetForTokenClassification"),rSr=o(" (MPNet model)"),tSr=l(),Y4=a("li"),dMe=a("strong"),aSr=o("rembert"),nSr=o(" \u2014 "),xK=a("a"),sSr=o("TFRemBertForTokenClassification"),lSr=o(" (RemBERT model)"),iSr=l(),K4=a("li"),cMe=a("strong"),dSr=o("roberta"),cSr=o(" \u2014 "),$K=a("a"),fSr=o("TFRobertaForTokenClassification"),mSr=o(" (RoBERTa model)"),gSr=l(),Z4=a("li"),fMe=a("strong"),hSr=o("roformer"),pSr=o(" \u2014 "),kK=a("a"),_Sr=o("TFRoFormerForTokenClassification"),uSr=o(" (RoFormer model)"),bSr=l(),eE=a("li"),mMe=a("strong"),vSr=o("xlm"),FSr=o(" \u2014 "),SK=a("a"),TSr=o("TFXLMForTokenClassification"),MSr=o(" (XLM model)"),ESr=l(),oE=a("li"),gMe=a("strong"),CSr=o("xlm-roberta"),wSr=o(" \u2014 "),RK=a("a"),ASr=o("TFXLMRobertaForTokenClassification"),LSr=o(" (XLM-RoBERTa model)"),ySr=l(),rE=a("li"),hMe=a("strong"),xSr=o("xlnet"),$Sr=o(" \u2014 "),PK=a("a"),kSr=o("TFXLNetForTokenClassification"),SSr=o(" (XLNet model)"),RSr=l(),F(tE.$$.fragment),pXe=l(),Nc=a("h2"),aE=a("a"),pMe=a("span"),F($x.$$.fragment),PSr=l(),_Me=a("span"),BSr=o("TFAutoModelForQuestionAnswering"),_Xe=l(),mr=a("div"),F(kx.$$.fragment),ISr=l(),qc=a("p"),NSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),BK=a("a"),qSr=o("from_pretrained()"),jSr=o(" class method or the "),IK=a("a"),DSr=o("from_config()"),GSr=o(` class
method.`),OSr=l(),Sx=a("p"),VSr=o("This class cannot be instantiated directly using "),uMe=a("code"),XSr=o("__init__()"),zSr=o(" (throws an error)."),WSr=l(),Ot=a("div"),F(Rx.$$.fragment),QSr=l(),bMe=a("p"),HSr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),USr=l(),jc=a("p"),JSr=o(`Note:
Loading a model from its configuration file does `),vMe=a("strong"),YSr=o("not"),KSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),NK=a("a"),ZSr=o("from_pretrained()"),eRr=o(" to load the model weights."),oRr=l(),F(nE.$$.fragment),rRr=l(),Dr=a("div"),F(Px.$$.fragment),tRr=l(),FMe=a("p"),aRr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),nRr=l(),bn=a("p"),sRr=o("The model class to instantiate is selected based on the "),TMe=a("code"),lRr=o("model_type"),iRr=o(` property of the config object (either
passed as an argument or loaded from `),MMe=a("code"),dRr=o("pretrained_model_name_or_path"),cRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EMe=a("code"),fRr=o("pretrained_model_name_or_path"),mRr=o(":"),gRr=l(),ce=a("ul"),sE=a("li"),CMe=a("strong"),hRr=o("albert"),pRr=o(" \u2014 "),qK=a("a"),_Rr=o("TFAlbertForQuestionAnswering"),uRr=o(" (ALBERT model)"),bRr=l(),lE=a("li"),wMe=a("strong"),vRr=o("bert"),FRr=o(" \u2014 "),jK=a("a"),TRr=o("TFBertForQuestionAnswering"),MRr=o(" (BERT model)"),ERr=l(),iE=a("li"),AMe=a("strong"),CRr=o("camembert"),wRr=o(" \u2014 "),DK=a("a"),ARr=o("TFCamembertForQuestionAnswering"),LRr=o(" (CamemBERT model)"),yRr=l(),dE=a("li"),LMe=a("strong"),xRr=o("convbert"),$Rr=o(" \u2014 "),GK=a("a"),kRr=o("TFConvBertForQuestionAnswering"),SRr=o(" (ConvBERT model)"),RRr=l(),cE=a("li"),yMe=a("strong"),PRr=o("deberta"),BRr=o(" \u2014 "),OK=a("a"),IRr=o("TFDebertaForQuestionAnswering"),NRr=o(" (DeBERTa model)"),qRr=l(),fE=a("li"),xMe=a("strong"),jRr=o("deberta-v2"),DRr=o(" \u2014 "),VK=a("a"),GRr=o("TFDebertaV2ForQuestionAnswering"),ORr=o(" (DeBERTa-v2 model)"),VRr=l(),mE=a("li"),$Me=a("strong"),XRr=o("distilbert"),zRr=o(" \u2014 "),XK=a("a"),WRr=o("TFDistilBertForQuestionAnswering"),QRr=o(" (DistilBERT model)"),HRr=l(),gE=a("li"),kMe=a("strong"),URr=o("electra"),JRr=o(" \u2014 "),zK=a("a"),YRr=o("TFElectraForQuestionAnswering"),KRr=o(" (ELECTRA model)"),ZRr=l(),hE=a("li"),SMe=a("strong"),ePr=o("flaubert"),oPr=o(" \u2014 "),WK=a("a"),rPr=o("TFFlaubertForQuestionAnsweringSimple"),tPr=o(" (FlauBERT model)"),aPr=l(),pE=a("li"),RMe=a("strong"),nPr=o("funnel"),sPr=o(" \u2014 "),QK=a("a"),lPr=o("TFFunnelForQuestionAnswering"),iPr=o(" (Funnel Transformer model)"),dPr=l(),_E=a("li"),PMe=a("strong"),cPr=o("gptj"),fPr=o(" \u2014 "),HK=a("a"),mPr=o("TFGPTJForQuestionAnswering"),gPr=o(" (GPT-J model)"),hPr=l(),uE=a("li"),BMe=a("strong"),pPr=o("longformer"),_Pr=o(" \u2014 "),UK=a("a"),uPr=o("TFLongformerForQuestionAnswering"),bPr=o(" (Longformer model)"),vPr=l(),bE=a("li"),IMe=a("strong"),FPr=o("mobilebert"),TPr=o(" \u2014 "),JK=a("a"),MPr=o("TFMobileBertForQuestionAnswering"),EPr=o(" (MobileBERT model)"),CPr=l(),vE=a("li"),NMe=a("strong"),wPr=o("mpnet"),APr=o(" \u2014 "),YK=a("a"),LPr=o("TFMPNetForQuestionAnswering"),yPr=o(" (MPNet model)"),xPr=l(),FE=a("li"),qMe=a("strong"),$Pr=o("rembert"),kPr=o(" \u2014 "),KK=a("a"),SPr=o("TFRemBertForQuestionAnswering"),RPr=o(" (RemBERT model)"),PPr=l(),TE=a("li"),jMe=a("strong"),BPr=o("roberta"),IPr=o(" \u2014 "),ZK=a("a"),NPr=o("TFRobertaForQuestionAnswering"),qPr=o(" (RoBERTa model)"),jPr=l(),ME=a("li"),DMe=a("strong"),DPr=o("roformer"),GPr=o(" \u2014 "),eZ=a("a"),OPr=o("TFRoFormerForQuestionAnswering"),VPr=o(" (RoFormer model)"),XPr=l(),EE=a("li"),GMe=a("strong"),zPr=o("xlm"),WPr=o(" \u2014 "),oZ=a("a"),QPr=o("TFXLMForQuestionAnsweringSimple"),HPr=o(" (XLM model)"),UPr=l(),CE=a("li"),OMe=a("strong"),JPr=o("xlm-roberta"),YPr=o(" \u2014 "),rZ=a("a"),KPr=o("TFXLMRobertaForQuestionAnswering"),ZPr=o(" (XLM-RoBERTa model)"),eBr=l(),wE=a("li"),VMe=a("strong"),oBr=o("xlnet"),rBr=o(" \u2014 "),tZ=a("a"),tBr=o("TFXLNetForQuestionAnsweringSimple"),aBr=o(" (XLNet model)"),nBr=l(),F(AE.$$.fragment),uXe=l(),Dc=a("h2"),LE=a("a"),XMe=a("span"),F(Bx.$$.fragment),sBr=l(),zMe=a("span"),lBr=o("TFAutoModelForVision2Seq"),bXe=l(),gr=a("div"),F(Ix.$$.fragment),iBr=l(),Gc=a("p"),dBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),aZ=a("a"),cBr=o("from_pretrained()"),fBr=o(" class method or the "),nZ=a("a"),mBr=o("from_config()"),gBr=o(` class
method.`),hBr=l(),Nx=a("p"),pBr=o("This class cannot be instantiated directly using "),WMe=a("code"),_Br=o("__init__()"),uBr=o(" (throws an error)."),bBr=l(),Vt=a("div"),F(qx.$$.fragment),vBr=l(),QMe=a("p"),FBr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),TBr=l(),Oc=a("p"),MBr=o(`Note:
Loading a model from its configuration file does `),HMe=a("strong"),EBr=o("not"),CBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sZ=a("a"),wBr=o("from_pretrained()"),ABr=o(" to load the model weights."),LBr=l(),F(yE.$$.fragment),yBr=l(),Gr=a("div"),F(jx.$$.fragment),xBr=l(),UMe=a("p"),$Br=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),kBr=l(),vn=a("p"),SBr=o("The model class to instantiate is selected based on the "),JMe=a("code"),RBr=o("model_type"),PBr=o(` property of the config object (either
passed as an argument or loaded from `),YMe=a("code"),BBr=o("pretrained_model_name_or_path"),IBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KMe=a("code"),NBr=o("pretrained_model_name_or_path"),qBr=o(":"),jBr=l(),ZMe=a("ul"),xE=a("li"),e4e=a("strong"),DBr=o("vision-encoder-decoder"),GBr=o(" \u2014 "),lZ=a("a"),OBr=o("TFVisionEncoderDecoderModel"),VBr=o(" (Vision Encoder decoder model)"),XBr=l(),F($E.$$.fragment),vXe=l(),Vc=a("h2"),kE=a("a"),o4e=a("span"),F(Dx.$$.fragment),zBr=l(),r4e=a("span"),WBr=o("TFAutoModelForSpeechSeq2Seq"),FXe=l(),hr=a("div"),F(Gx.$$.fragment),QBr=l(),Xc=a("p"),HBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),iZ=a("a"),UBr=o("from_pretrained()"),JBr=o(" class method or the "),dZ=a("a"),YBr=o("from_config()"),KBr=o(` class
method.`),ZBr=l(),Ox=a("p"),eIr=o("This class cannot be instantiated directly using "),t4e=a("code"),oIr=o("__init__()"),rIr=o(" (throws an error)."),tIr=l(),Xt=a("div"),F(Vx.$$.fragment),aIr=l(),a4e=a("p"),nIr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),sIr=l(),zc=a("p"),lIr=o(`Note:
Loading a model from its configuration file does `),n4e=a("strong"),iIr=o("not"),dIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cZ=a("a"),cIr=o("from_pretrained()"),fIr=o(" to load the model weights."),mIr=l(),F(SE.$$.fragment),gIr=l(),Or=a("div"),F(Xx.$$.fragment),hIr=l(),s4e=a("p"),pIr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),_Ir=l(),Fn=a("p"),uIr=o("The model class to instantiate is selected based on the "),l4e=a("code"),bIr=o("model_type"),vIr=o(` property of the config object (either
passed as an argument or loaded from `),i4e=a("code"),FIr=o("pretrained_model_name_or_path"),TIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d4e=a("code"),MIr=o("pretrained_model_name_or_path"),EIr=o(":"),CIr=l(),c4e=a("ul"),RE=a("li"),f4e=a("strong"),wIr=o("speech_to_text"),AIr=o(" \u2014 "),fZ=a("a"),LIr=o("TFSpeech2TextForConditionalGeneration"),yIr=o(" (Speech2Text model)"),xIr=l(),F(PE.$$.fragment),TXe=l(),Wc=a("h2"),BE=a("a"),m4e=a("span"),F(zx.$$.fragment),$Ir=l(),g4e=a("span"),kIr=o("FlaxAutoModel"),MXe=l(),pr=a("div"),F(Wx.$$.fragment),SIr=l(),Qc=a("p"),RIr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),mZ=a("a"),PIr=o("from_pretrained()"),BIr=o(" class method or the "),gZ=a("a"),IIr=o("from_config()"),NIr=o(` class
method.`),qIr=l(),Qx=a("p"),jIr=o("This class cannot be instantiated directly using "),h4e=a("code"),DIr=o("__init__()"),GIr=o(" (throws an error)."),OIr=l(),zt=a("div"),F(Hx.$$.fragment),VIr=l(),p4e=a("p"),XIr=o("Instantiates one of the base model classes of the library from a configuration."),zIr=l(),Hc=a("p"),WIr=o(`Note:
Loading a model from its configuration file does `),_4e=a("strong"),QIr=o("not"),HIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hZ=a("a"),UIr=o("from_pretrained()"),JIr=o(" to load the model weights."),YIr=l(),F(IE.$$.fragment),KIr=l(),Vr=a("div"),F(Ux.$$.fragment),ZIr=l(),u4e=a("p"),eNr=o("Instantiate one of the base model classes of the library from a pretrained model."),oNr=l(),Tn=a("p"),rNr=o("The model class to instantiate is selected based on the "),b4e=a("code"),tNr=o("model_type"),aNr=o(` property of the config object (either
passed as an argument or loaded from `),v4e=a("code"),nNr=o("pretrained_model_name_or_path"),sNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F4e=a("code"),lNr=o("pretrained_model_name_or_path"),iNr=o(":"),dNr=l(),oe=a("ul"),NE=a("li"),T4e=a("strong"),cNr=o("albert"),fNr=o(" \u2014 "),pZ=a("a"),mNr=o("FlaxAlbertModel"),gNr=o(" (ALBERT model)"),hNr=l(),qE=a("li"),M4e=a("strong"),pNr=o("bart"),_Nr=o(" \u2014 "),_Z=a("a"),uNr=o("FlaxBartModel"),bNr=o(" (BART model)"),vNr=l(),jE=a("li"),E4e=a("strong"),FNr=o("beit"),TNr=o(" \u2014 "),uZ=a("a"),MNr=o("FlaxBeitModel"),ENr=o(" (BEiT model)"),CNr=l(),DE=a("li"),C4e=a("strong"),wNr=o("bert"),ANr=o(" \u2014 "),bZ=a("a"),LNr=o("FlaxBertModel"),yNr=o(" (BERT model)"),xNr=l(),GE=a("li"),w4e=a("strong"),$Nr=o("big_bird"),kNr=o(" \u2014 "),vZ=a("a"),SNr=o("FlaxBigBirdModel"),RNr=o(" (BigBird model)"),PNr=l(),OE=a("li"),A4e=a("strong"),BNr=o("blenderbot"),INr=o(" \u2014 "),FZ=a("a"),NNr=o("FlaxBlenderbotModel"),qNr=o(" (Blenderbot model)"),jNr=l(),VE=a("li"),L4e=a("strong"),DNr=o("blenderbot-small"),GNr=o(" \u2014 "),TZ=a("a"),ONr=o("FlaxBlenderbotSmallModel"),VNr=o(" (BlenderbotSmall model)"),XNr=l(),XE=a("li"),y4e=a("strong"),zNr=o("clip"),WNr=o(" \u2014 "),MZ=a("a"),QNr=o("FlaxCLIPModel"),HNr=o(" (CLIP model)"),UNr=l(),zE=a("li"),x4e=a("strong"),JNr=o("distilbert"),YNr=o(" \u2014 "),EZ=a("a"),KNr=o("FlaxDistilBertModel"),ZNr=o(" (DistilBERT model)"),eqr=l(),WE=a("li"),$4e=a("strong"),oqr=o("electra"),rqr=o(" \u2014 "),CZ=a("a"),tqr=o("FlaxElectraModel"),aqr=o(" (ELECTRA model)"),nqr=l(),QE=a("li"),k4e=a("strong"),sqr=o("gpt2"),lqr=o(" \u2014 "),wZ=a("a"),iqr=o("FlaxGPT2Model"),dqr=o(" (OpenAI GPT-2 model)"),cqr=l(),HE=a("li"),S4e=a("strong"),fqr=o("gpt_neo"),mqr=o(" \u2014 "),AZ=a("a"),gqr=o("FlaxGPTNeoModel"),hqr=o(" (GPT Neo model)"),pqr=l(),UE=a("li"),R4e=a("strong"),_qr=o("gptj"),uqr=o(" \u2014 "),LZ=a("a"),bqr=o("FlaxGPTJModel"),vqr=o(" (GPT-J model)"),Fqr=l(),JE=a("li"),P4e=a("strong"),Tqr=o("longt5"),Mqr=o(" \u2014 "),yZ=a("a"),Eqr=o("FlaxLongT5Model"),Cqr=o(" (LongT5 model)"),wqr=l(),YE=a("li"),B4e=a("strong"),Aqr=o("marian"),Lqr=o(" \u2014 "),xZ=a("a"),yqr=o("FlaxMarianModel"),xqr=o(" (Marian model)"),$qr=l(),KE=a("li"),I4e=a("strong"),kqr=o("mbart"),Sqr=o(" \u2014 "),$Z=a("a"),Rqr=o("FlaxMBartModel"),Pqr=o(" (mBART model)"),Bqr=l(),ZE=a("li"),N4e=a("strong"),Iqr=o("mt5"),Nqr=o(" \u2014 "),kZ=a("a"),qqr=o("FlaxMT5Model"),jqr=o(" (MT5 model)"),Dqr=l(),eC=a("li"),q4e=a("strong"),Gqr=o("opt"),Oqr=o(" \u2014 "),SZ=a("a"),Vqr=o("FlaxOPTModel"),Xqr=o(" (OPT model)"),zqr=l(),oC=a("li"),j4e=a("strong"),Wqr=o("pegasus"),Qqr=o(" \u2014 "),RZ=a("a"),Hqr=o("FlaxPegasusModel"),Uqr=o(" (Pegasus model)"),Jqr=l(),rC=a("li"),D4e=a("strong"),Yqr=o("roberta"),Kqr=o(" \u2014 "),PZ=a("a"),Zqr=o("FlaxRobertaModel"),ejr=o(" (RoBERTa model)"),ojr=l(),tC=a("li"),G4e=a("strong"),rjr=o("roformer"),tjr=o(" \u2014 "),BZ=a("a"),ajr=o("FlaxRoFormerModel"),njr=o(" (RoFormer model)"),sjr=l(),aC=a("li"),O4e=a("strong"),ljr=o("t5"),ijr=o(" \u2014 "),IZ=a("a"),djr=o("FlaxT5Model"),cjr=o(" (T5 model)"),fjr=l(),nC=a("li"),V4e=a("strong"),mjr=o("vision-text-dual-encoder"),gjr=o(" \u2014 "),NZ=a("a"),hjr=o("FlaxVisionTextDualEncoderModel"),pjr=o(" (VisionTextDualEncoder model)"),_jr=l(),sC=a("li"),X4e=a("strong"),ujr=o("vit"),bjr=o(" \u2014 "),qZ=a("a"),vjr=o("FlaxViTModel"),Fjr=o(" (ViT model)"),Tjr=l(),lC=a("li"),z4e=a("strong"),Mjr=o("wav2vec2"),Ejr=o(" \u2014 "),jZ=a("a"),Cjr=o("FlaxWav2Vec2Model"),wjr=o(" (Wav2Vec2 model)"),Ajr=l(),iC=a("li"),W4e=a("strong"),Ljr=o("xglm"),yjr=o(" \u2014 "),DZ=a("a"),xjr=o("FlaxXGLMModel"),$jr=o(" (XGLM model)"),kjr=l(),dC=a("li"),Q4e=a("strong"),Sjr=o("xlm-roberta"),Rjr=o(" \u2014 "),GZ=a("a"),Pjr=o("FlaxXLMRobertaModel"),Bjr=o(" (XLM-RoBERTa model)"),Ijr=l(),F(cC.$$.fragment),EXe=l(),Uc=a("h2"),fC=a("a"),H4e=a("span"),F(Jx.$$.fragment),Njr=l(),U4e=a("span"),qjr=o("FlaxAutoModelForCausalLM"),CXe=l(),_r=a("div"),F(Yx.$$.fragment),jjr=l(),Jc=a("p"),Djr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),OZ=a("a"),Gjr=o("from_pretrained()"),Ojr=o(" class method or the "),VZ=a("a"),Vjr=o("from_config()"),Xjr=o(` class
method.`),zjr=l(),Kx=a("p"),Wjr=o("This class cannot be instantiated directly using "),J4e=a("code"),Qjr=o("__init__()"),Hjr=o(" (throws an error)."),Ujr=l(),Wt=a("div"),F(Zx.$$.fragment),Jjr=l(),Y4e=a("p"),Yjr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Kjr=l(),Yc=a("p"),Zjr=o(`Note:
Loading a model from its configuration file does `),K4e=a("strong"),eDr=o("not"),oDr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XZ=a("a"),rDr=o("from_pretrained()"),tDr=o(" to load the model weights."),aDr=l(),F(mC.$$.fragment),nDr=l(),Xr=a("div"),F(e$.$$.fragment),sDr=l(),Z4e=a("p"),lDr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),iDr=l(),Mn=a("p"),dDr=o("The model class to instantiate is selected based on the "),eEe=a("code"),cDr=o("model_type"),fDr=o(` property of the config object (either
passed as an argument or loaded from `),oEe=a("code"),mDr=o("pretrained_model_name_or_path"),gDr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rEe=a("code"),hDr=o("pretrained_model_name_or_path"),pDr=o(":"),_Dr=l(),xe=a("ul"),gC=a("li"),tEe=a("strong"),uDr=o("bart"),bDr=o(" \u2014 "),zZ=a("a"),vDr=o("FlaxBartForCausalLM"),FDr=o(" (BART model)"),TDr=l(),hC=a("li"),aEe=a("strong"),MDr=o("bert"),EDr=o(" \u2014 "),WZ=a("a"),CDr=o("FlaxBertForCausalLM"),wDr=o(" (BERT model)"),ADr=l(),pC=a("li"),nEe=a("strong"),LDr=o("big_bird"),yDr=o(" \u2014 "),QZ=a("a"),xDr=o("FlaxBigBirdForCausalLM"),$Dr=o(" (BigBird model)"),kDr=l(),_C=a("li"),sEe=a("strong"),SDr=o("electra"),RDr=o(" \u2014 "),HZ=a("a"),PDr=o("FlaxElectraForCausalLM"),BDr=o(" (ELECTRA model)"),IDr=l(),uC=a("li"),lEe=a("strong"),NDr=o("gpt2"),qDr=o(" \u2014 "),UZ=a("a"),jDr=o("FlaxGPT2LMHeadModel"),DDr=o(" (OpenAI GPT-2 model)"),GDr=l(),bC=a("li"),iEe=a("strong"),ODr=o("gpt_neo"),VDr=o(" \u2014 "),JZ=a("a"),XDr=o("FlaxGPTNeoForCausalLM"),zDr=o(" (GPT Neo model)"),WDr=l(),vC=a("li"),dEe=a("strong"),QDr=o("gptj"),HDr=o(" \u2014 "),YZ=a("a"),UDr=o("FlaxGPTJForCausalLM"),JDr=o(" (GPT-J model)"),YDr=l(),FC=a("li"),cEe=a("strong"),KDr=o("opt"),ZDr=o(" \u2014 "),KZ=a("a"),eGr=o("FlaxOPTForCausalLM"),oGr=o(" (OPT model)"),rGr=l(),TC=a("li"),fEe=a("strong"),tGr=o("roberta"),aGr=o(" \u2014 "),ZZ=a("a"),nGr=o("FlaxRobertaForCausalLM"),sGr=o(" (RoBERTa model)"),lGr=l(),MC=a("li"),mEe=a("strong"),iGr=o("xglm"),dGr=o(" \u2014 "),eee=a("a"),cGr=o("FlaxXGLMForCausalLM"),fGr=o(" (XGLM model)"),mGr=l(),F(EC.$$.fragment),wXe=l(),Kc=a("h2"),CC=a("a"),gEe=a("span"),F(o$.$$.fragment),gGr=l(),hEe=a("span"),hGr=o("FlaxAutoModelForPreTraining"),AXe=l(),ur=a("div"),F(r$.$$.fragment),pGr=l(),Zc=a("p"),_Gr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),oee=a("a"),uGr=o("from_pretrained()"),bGr=o(" class method or the "),ree=a("a"),vGr=o("from_config()"),FGr=o(` class
method.`),TGr=l(),t$=a("p"),MGr=o("This class cannot be instantiated directly using "),pEe=a("code"),EGr=o("__init__()"),CGr=o(" (throws an error)."),wGr=l(),Qt=a("div"),F(a$.$$.fragment),AGr=l(),_Ee=a("p"),LGr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),yGr=l(),ef=a("p"),xGr=o(`Note:
Loading a model from its configuration file does `),uEe=a("strong"),$Gr=o("not"),kGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tee=a("a"),SGr=o("from_pretrained()"),RGr=o(" to load the model weights."),PGr=l(),F(wC.$$.fragment),BGr=l(),zr=a("div"),F(n$.$$.fragment),IGr=l(),bEe=a("p"),NGr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),qGr=l(),En=a("p"),jGr=o("The model class to instantiate is selected based on the "),vEe=a("code"),DGr=o("model_type"),GGr=o(` property of the config object (either
passed as an argument or loaded from `),FEe=a("code"),OGr=o("pretrained_model_name_or_path"),VGr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TEe=a("code"),XGr=o("pretrained_model_name_or_path"),zGr=o(":"),WGr=l(),Ee=a("ul"),AC=a("li"),MEe=a("strong"),QGr=o("albert"),HGr=o(" \u2014 "),aee=a("a"),UGr=o("FlaxAlbertForPreTraining"),JGr=o(" (ALBERT model)"),YGr=l(),LC=a("li"),EEe=a("strong"),KGr=o("bart"),ZGr=o(" \u2014 "),nee=a("a"),eOr=o("FlaxBartForConditionalGeneration"),oOr=o(" (BART model)"),rOr=l(),yC=a("li"),CEe=a("strong"),tOr=o("bert"),aOr=o(" \u2014 "),see=a("a"),nOr=o("FlaxBertForPreTraining"),sOr=o(" (BERT model)"),lOr=l(),xC=a("li"),wEe=a("strong"),iOr=o("big_bird"),dOr=o(" \u2014 "),lee=a("a"),cOr=o("FlaxBigBirdForPreTraining"),fOr=o(" (BigBird model)"),mOr=l(),$C=a("li"),AEe=a("strong"),gOr=o("electra"),hOr=o(" \u2014 "),iee=a("a"),pOr=o("FlaxElectraForPreTraining"),_Or=o(" (ELECTRA model)"),uOr=l(),kC=a("li"),LEe=a("strong"),bOr=o("longt5"),vOr=o(" \u2014 "),dee=a("a"),FOr=o("FlaxLongT5ForConditionalGeneration"),TOr=o(" (LongT5 model)"),MOr=l(),SC=a("li"),yEe=a("strong"),EOr=o("mbart"),COr=o(" \u2014 "),cee=a("a"),wOr=o("FlaxMBartForConditionalGeneration"),AOr=o(" (mBART model)"),LOr=l(),RC=a("li"),xEe=a("strong"),yOr=o("mt5"),xOr=o(" \u2014 "),fee=a("a"),$Or=o("FlaxMT5ForConditionalGeneration"),kOr=o(" (MT5 model)"),SOr=l(),PC=a("li"),$Ee=a("strong"),ROr=o("roberta"),POr=o(" \u2014 "),mee=a("a"),BOr=o("FlaxRobertaForMaskedLM"),IOr=o(" (RoBERTa model)"),NOr=l(),BC=a("li"),kEe=a("strong"),qOr=o("roformer"),jOr=o(" \u2014 "),gee=a("a"),DOr=o("FlaxRoFormerForMaskedLM"),GOr=o(" (RoFormer model)"),OOr=l(),IC=a("li"),SEe=a("strong"),VOr=o("t5"),XOr=o(" \u2014 "),hee=a("a"),zOr=o("FlaxT5ForConditionalGeneration"),WOr=o(" (T5 model)"),QOr=l(),NC=a("li"),REe=a("strong"),HOr=o("wav2vec2"),UOr=o(" \u2014 "),pee=a("a"),JOr=o("FlaxWav2Vec2ForPreTraining"),YOr=o(" (Wav2Vec2 model)"),KOr=l(),qC=a("li"),PEe=a("strong"),ZOr=o("xlm-roberta"),eVr=o(" \u2014 "),_ee=a("a"),oVr=o("FlaxXLMRobertaForMaskedLM"),rVr=o(" (XLM-RoBERTa model)"),tVr=l(),F(jC.$$.fragment),LXe=l(),of=a("h2"),DC=a("a"),BEe=a("span"),F(s$.$$.fragment),aVr=l(),IEe=a("span"),nVr=o("FlaxAutoModelForMaskedLM"),yXe=l(),br=a("div"),F(l$.$$.fragment),sVr=l(),rf=a("p"),lVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),uee=a("a"),iVr=o("from_pretrained()"),dVr=o(" class method or the "),bee=a("a"),cVr=o("from_config()"),fVr=o(` class
method.`),mVr=l(),i$=a("p"),gVr=o("This class cannot be instantiated directly using "),NEe=a("code"),hVr=o("__init__()"),pVr=o(" (throws an error)."),_Vr=l(),Ht=a("div"),F(d$.$$.fragment),uVr=l(),qEe=a("p"),bVr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),vVr=l(),tf=a("p"),FVr=o(`Note:
Loading a model from its configuration file does `),jEe=a("strong"),TVr=o("not"),MVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vee=a("a"),EVr=o("from_pretrained()"),CVr=o(" to load the model weights."),wVr=l(),F(GC.$$.fragment),AVr=l(),Wr=a("div"),F(c$.$$.fragment),LVr=l(),DEe=a("p"),yVr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),xVr=l(),Cn=a("p"),$Vr=o("The model class to instantiate is selected based on the "),GEe=a("code"),kVr=o("model_type"),SVr=o(` property of the config object (either
passed as an argument or loaded from `),OEe=a("code"),RVr=o("pretrained_model_name_or_path"),PVr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VEe=a("code"),BVr=o("pretrained_model_name_or_path"),IVr=o(":"),NVr=l(),$e=a("ul"),OC=a("li"),XEe=a("strong"),qVr=o("albert"),jVr=o(" \u2014 "),Fee=a("a"),DVr=o("FlaxAlbertForMaskedLM"),GVr=o(" (ALBERT model)"),OVr=l(),VC=a("li"),zEe=a("strong"),VVr=o("bart"),XVr=o(" \u2014 "),Tee=a("a"),zVr=o("FlaxBartForConditionalGeneration"),WVr=o(" (BART model)"),QVr=l(),XC=a("li"),WEe=a("strong"),HVr=o("bert"),UVr=o(" \u2014 "),Mee=a("a"),JVr=o("FlaxBertForMaskedLM"),YVr=o(" (BERT model)"),KVr=l(),zC=a("li"),QEe=a("strong"),ZVr=o("big_bird"),eXr=o(" \u2014 "),Eee=a("a"),oXr=o("FlaxBigBirdForMaskedLM"),rXr=o(" (BigBird model)"),tXr=l(),WC=a("li"),HEe=a("strong"),aXr=o("distilbert"),nXr=o(" \u2014 "),Cee=a("a"),sXr=o("FlaxDistilBertForMaskedLM"),lXr=o(" (DistilBERT model)"),iXr=l(),QC=a("li"),UEe=a("strong"),dXr=o("electra"),cXr=o(" \u2014 "),wee=a("a"),fXr=o("FlaxElectraForMaskedLM"),mXr=o(" (ELECTRA model)"),gXr=l(),HC=a("li"),JEe=a("strong"),hXr=o("mbart"),pXr=o(" \u2014 "),Aee=a("a"),_Xr=o("FlaxMBartForConditionalGeneration"),uXr=o(" (mBART model)"),bXr=l(),UC=a("li"),YEe=a("strong"),vXr=o("roberta"),FXr=o(" \u2014 "),Lee=a("a"),TXr=o("FlaxRobertaForMaskedLM"),MXr=o(" (RoBERTa model)"),EXr=l(),JC=a("li"),KEe=a("strong"),CXr=o("roformer"),wXr=o(" \u2014 "),yee=a("a"),AXr=o("FlaxRoFormerForMaskedLM"),LXr=o(" (RoFormer model)"),yXr=l(),YC=a("li"),ZEe=a("strong"),xXr=o("xlm-roberta"),$Xr=o(" \u2014 "),xee=a("a"),kXr=o("FlaxXLMRobertaForMaskedLM"),SXr=o(" (XLM-RoBERTa model)"),RXr=l(),F(KC.$$.fragment),xXe=l(),af=a("h2"),ZC=a("a"),eCe=a("span"),F(f$.$$.fragment),PXr=l(),oCe=a("span"),BXr=o("FlaxAutoModelForSeq2SeqLM"),$Xe=l(),vr=a("div"),F(m$.$$.fragment),IXr=l(),nf=a("p"),NXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),$ee=a("a"),qXr=o("from_pretrained()"),jXr=o(" class method or the "),kee=a("a"),DXr=o("from_config()"),GXr=o(` class
method.`),OXr=l(),g$=a("p"),VXr=o("This class cannot be instantiated directly using "),rCe=a("code"),XXr=o("__init__()"),zXr=o(" (throws an error)."),WXr=l(),Ut=a("div"),F(h$.$$.fragment),QXr=l(),tCe=a("p"),HXr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),UXr=l(),sf=a("p"),JXr=o(`Note:
Loading a model from its configuration file does `),aCe=a("strong"),YXr=o("not"),KXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),See=a("a"),ZXr=o("from_pretrained()"),ezr=o(" to load the model weights."),ozr=l(),F(e3.$$.fragment),rzr=l(),Qr=a("div"),F(p$.$$.fragment),tzr=l(),nCe=a("p"),azr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),nzr=l(),wn=a("p"),szr=o("The model class to instantiate is selected based on the "),sCe=a("code"),lzr=o("model_type"),izr=o(` property of the config object (either
passed as an argument or loaded from `),lCe=a("code"),dzr=o("pretrained_model_name_or_path"),czr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iCe=a("code"),fzr=o("pretrained_model_name_or_path"),mzr=o(":"),gzr=l(),ke=a("ul"),o3=a("li"),dCe=a("strong"),hzr=o("bart"),pzr=o(" \u2014 "),Ree=a("a"),_zr=o("FlaxBartForConditionalGeneration"),uzr=o(" (BART model)"),bzr=l(),r3=a("li"),cCe=a("strong"),vzr=o("blenderbot"),Fzr=o(" \u2014 "),Pee=a("a"),Tzr=o("FlaxBlenderbotForConditionalGeneration"),Mzr=o(" (Blenderbot model)"),Ezr=l(),t3=a("li"),fCe=a("strong"),Czr=o("blenderbot-small"),wzr=o(" \u2014 "),Bee=a("a"),Azr=o("FlaxBlenderbotSmallForConditionalGeneration"),Lzr=o(" (BlenderbotSmall model)"),yzr=l(),a3=a("li"),mCe=a("strong"),xzr=o("encoder-decoder"),$zr=o(" \u2014 "),Iee=a("a"),kzr=o("FlaxEncoderDecoderModel"),Szr=o(" (Encoder decoder model)"),Rzr=l(),n3=a("li"),gCe=a("strong"),Pzr=o("longt5"),Bzr=o(" \u2014 "),Nee=a("a"),Izr=o("FlaxLongT5ForConditionalGeneration"),Nzr=o(" (LongT5 model)"),qzr=l(),s3=a("li"),hCe=a("strong"),jzr=o("marian"),Dzr=o(" \u2014 "),qee=a("a"),Gzr=o("FlaxMarianMTModel"),Ozr=o(" (Marian model)"),Vzr=l(),l3=a("li"),pCe=a("strong"),Xzr=o("mbart"),zzr=o(" \u2014 "),jee=a("a"),Wzr=o("FlaxMBartForConditionalGeneration"),Qzr=o(" (mBART model)"),Hzr=l(),i3=a("li"),_Ce=a("strong"),Uzr=o("mt5"),Jzr=o(" \u2014 "),Dee=a("a"),Yzr=o("FlaxMT5ForConditionalGeneration"),Kzr=o(" (MT5 model)"),Zzr=l(),d3=a("li"),uCe=a("strong"),eWr=o("pegasus"),oWr=o(" \u2014 "),Gee=a("a"),rWr=o("FlaxPegasusForConditionalGeneration"),tWr=o(" (Pegasus model)"),aWr=l(),c3=a("li"),bCe=a("strong"),nWr=o("t5"),sWr=o(" \u2014 "),Oee=a("a"),lWr=o("FlaxT5ForConditionalGeneration"),iWr=o(" (T5 model)"),dWr=l(),F(f3.$$.fragment),kXe=l(),lf=a("h2"),m3=a("a"),vCe=a("span"),F(_$.$$.fragment),cWr=l(),FCe=a("span"),fWr=o("FlaxAutoModelForSequenceClassification"),SXe=l(),Fr=a("div"),F(u$.$$.fragment),mWr=l(),df=a("p"),gWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Vee=a("a"),hWr=o("from_pretrained()"),pWr=o(" class method or the "),Xee=a("a"),_Wr=o("from_config()"),uWr=o(` class
method.`),bWr=l(),b$=a("p"),vWr=o("This class cannot be instantiated directly using "),TCe=a("code"),FWr=o("__init__()"),TWr=o(" (throws an error)."),MWr=l(),Jt=a("div"),F(v$.$$.fragment),EWr=l(),MCe=a("p"),CWr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),wWr=l(),cf=a("p"),AWr=o(`Note:
Loading a model from its configuration file does `),ECe=a("strong"),LWr=o("not"),yWr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zee=a("a"),xWr=o("from_pretrained()"),$Wr=o(" to load the model weights."),kWr=l(),F(g3.$$.fragment),SWr=l(),Hr=a("div"),F(F$.$$.fragment),RWr=l(),CCe=a("p"),PWr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),BWr=l(),An=a("p"),IWr=o("The model class to instantiate is selected based on the "),wCe=a("code"),NWr=o("model_type"),qWr=o(` property of the config object (either
passed as an argument or loaded from `),ACe=a("code"),jWr=o("pretrained_model_name_or_path"),DWr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LCe=a("code"),GWr=o("pretrained_model_name_or_path"),OWr=o(":"),VWr=l(),Se=a("ul"),h3=a("li"),yCe=a("strong"),XWr=o("albert"),zWr=o(" \u2014 "),Wee=a("a"),WWr=o("FlaxAlbertForSequenceClassification"),QWr=o(" (ALBERT model)"),HWr=l(),p3=a("li"),xCe=a("strong"),UWr=o("bart"),JWr=o(" \u2014 "),Qee=a("a"),YWr=o("FlaxBartForSequenceClassification"),KWr=o(" (BART model)"),ZWr=l(),_3=a("li"),$Ce=a("strong"),eQr=o("bert"),oQr=o(" \u2014 "),Hee=a("a"),rQr=o("FlaxBertForSequenceClassification"),tQr=o(" (BERT model)"),aQr=l(),u3=a("li"),kCe=a("strong"),nQr=o("big_bird"),sQr=o(" \u2014 "),Uee=a("a"),lQr=o("FlaxBigBirdForSequenceClassification"),iQr=o(" (BigBird model)"),dQr=l(),b3=a("li"),SCe=a("strong"),cQr=o("distilbert"),fQr=o(" \u2014 "),Jee=a("a"),mQr=o("FlaxDistilBertForSequenceClassification"),gQr=o(" (DistilBERT model)"),hQr=l(),v3=a("li"),RCe=a("strong"),pQr=o("electra"),_Qr=o(" \u2014 "),Yee=a("a"),uQr=o("FlaxElectraForSequenceClassification"),bQr=o(" (ELECTRA model)"),vQr=l(),F3=a("li"),PCe=a("strong"),FQr=o("mbart"),TQr=o(" \u2014 "),Kee=a("a"),MQr=o("FlaxMBartForSequenceClassification"),EQr=o(" (mBART model)"),CQr=l(),T3=a("li"),BCe=a("strong"),wQr=o("roberta"),AQr=o(" \u2014 "),Zee=a("a"),LQr=o("FlaxRobertaForSequenceClassification"),yQr=o(" (RoBERTa model)"),xQr=l(),M3=a("li"),ICe=a("strong"),$Qr=o("roformer"),kQr=o(" \u2014 "),eoe=a("a"),SQr=o("FlaxRoFormerForSequenceClassification"),RQr=o(" (RoFormer model)"),PQr=l(),E3=a("li"),NCe=a("strong"),BQr=o("xlm-roberta"),IQr=o(" \u2014 "),ooe=a("a"),NQr=o("FlaxXLMRobertaForSequenceClassification"),qQr=o(" (XLM-RoBERTa model)"),jQr=l(),F(C3.$$.fragment),RXe=l(),ff=a("h2"),w3=a("a"),qCe=a("span"),F(T$.$$.fragment),DQr=l(),jCe=a("span"),GQr=o("FlaxAutoModelForQuestionAnswering"),PXe=l(),Tr=a("div"),F(M$.$$.fragment),OQr=l(),mf=a("p"),VQr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),roe=a("a"),XQr=o("from_pretrained()"),zQr=o(" class method or the "),toe=a("a"),WQr=o("from_config()"),QQr=o(` class
method.`),HQr=l(),E$=a("p"),UQr=o("This class cannot be instantiated directly using "),DCe=a("code"),JQr=o("__init__()"),YQr=o(" (throws an error)."),KQr=l(),Yt=a("div"),F(C$.$$.fragment),ZQr=l(),GCe=a("p"),eHr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),oHr=l(),gf=a("p"),rHr=o(`Note:
Loading a model from its configuration file does `),OCe=a("strong"),tHr=o("not"),aHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aoe=a("a"),nHr=o("from_pretrained()"),sHr=o(" to load the model weights."),lHr=l(),F(A3.$$.fragment),iHr=l(),Ur=a("div"),F(w$.$$.fragment),dHr=l(),VCe=a("p"),cHr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),fHr=l(),Ln=a("p"),mHr=o("The model class to instantiate is selected based on the "),XCe=a("code"),gHr=o("model_type"),hHr=o(` property of the config object (either
passed as an argument or loaded from `),zCe=a("code"),pHr=o("pretrained_model_name_or_path"),_Hr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WCe=a("code"),uHr=o("pretrained_model_name_or_path"),bHr=o(":"),vHr=l(),Re=a("ul"),L3=a("li"),QCe=a("strong"),FHr=o("albert"),THr=o(" \u2014 "),noe=a("a"),MHr=o("FlaxAlbertForQuestionAnswering"),EHr=o(" (ALBERT model)"),CHr=l(),y3=a("li"),HCe=a("strong"),wHr=o("bart"),AHr=o(" \u2014 "),soe=a("a"),LHr=o("FlaxBartForQuestionAnswering"),yHr=o(" (BART model)"),xHr=l(),x3=a("li"),UCe=a("strong"),$Hr=o("bert"),kHr=o(" \u2014 "),loe=a("a"),SHr=o("FlaxBertForQuestionAnswering"),RHr=o(" (BERT model)"),PHr=l(),$3=a("li"),JCe=a("strong"),BHr=o("big_bird"),IHr=o(" \u2014 "),ioe=a("a"),NHr=o("FlaxBigBirdForQuestionAnswering"),qHr=o(" (BigBird model)"),jHr=l(),k3=a("li"),YCe=a("strong"),DHr=o("distilbert"),GHr=o(" \u2014 "),doe=a("a"),OHr=o("FlaxDistilBertForQuestionAnswering"),VHr=o(" (DistilBERT model)"),XHr=l(),S3=a("li"),KCe=a("strong"),zHr=o("electra"),WHr=o(" \u2014 "),coe=a("a"),QHr=o("FlaxElectraForQuestionAnswering"),HHr=o(" (ELECTRA model)"),UHr=l(),R3=a("li"),ZCe=a("strong"),JHr=o("mbart"),YHr=o(" \u2014 "),foe=a("a"),KHr=o("FlaxMBartForQuestionAnswering"),ZHr=o(" (mBART model)"),eUr=l(),P3=a("li"),e3e=a("strong"),oUr=o("roberta"),rUr=o(" \u2014 "),moe=a("a"),tUr=o("FlaxRobertaForQuestionAnswering"),aUr=o(" (RoBERTa model)"),nUr=l(),B3=a("li"),o3e=a("strong"),sUr=o("roformer"),lUr=o(" \u2014 "),goe=a("a"),iUr=o("FlaxRoFormerForQuestionAnswering"),dUr=o(" (RoFormer model)"),cUr=l(),I3=a("li"),r3e=a("strong"),fUr=o("xlm-roberta"),mUr=o(" \u2014 "),hoe=a("a"),gUr=o("FlaxXLMRobertaForQuestionAnswering"),hUr=o(" (XLM-RoBERTa model)"),pUr=l(),F(N3.$$.fragment),BXe=l(),hf=a("h2"),q3=a("a"),t3e=a("span"),F(A$.$$.fragment),_Ur=l(),a3e=a("span"),uUr=o("FlaxAutoModelForTokenClassification"),IXe=l(),Mr=a("div"),F(L$.$$.fragment),bUr=l(),pf=a("p"),vUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),poe=a("a"),FUr=o("from_pretrained()"),TUr=o(" class method or the "),_oe=a("a"),MUr=o("from_config()"),EUr=o(` class
method.`),CUr=l(),y$=a("p"),wUr=o("This class cannot be instantiated directly using "),n3e=a("code"),AUr=o("__init__()"),LUr=o(" (throws an error)."),yUr=l(),Kt=a("div"),F(x$.$$.fragment),xUr=l(),s3e=a("p"),$Ur=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),kUr=l(),_f=a("p"),SUr=o(`Note:
Loading a model from its configuration file does `),l3e=a("strong"),RUr=o("not"),PUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uoe=a("a"),BUr=o("from_pretrained()"),IUr=o(" to load the model weights."),NUr=l(),F(j3.$$.fragment),qUr=l(),Jr=a("div"),F($$.$$.fragment),jUr=l(),i3e=a("p"),DUr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),GUr=l(),yn=a("p"),OUr=o("The model class to instantiate is selected based on the "),d3e=a("code"),VUr=o("model_type"),XUr=o(` property of the config object (either
passed as an argument or loaded from `),c3e=a("code"),zUr=o("pretrained_model_name_or_path"),WUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f3e=a("code"),QUr=o("pretrained_model_name_or_path"),HUr=o(":"),UUr=l(),Ve=a("ul"),D3=a("li"),m3e=a("strong"),JUr=o("albert"),YUr=o(" \u2014 "),boe=a("a"),KUr=o("FlaxAlbertForTokenClassification"),ZUr=o(" (ALBERT model)"),eJr=l(),G3=a("li"),g3e=a("strong"),oJr=o("bert"),rJr=o(" \u2014 "),voe=a("a"),tJr=o("FlaxBertForTokenClassification"),aJr=o(" (BERT model)"),nJr=l(),O3=a("li"),h3e=a("strong"),sJr=o("big_bird"),lJr=o(" \u2014 "),Foe=a("a"),iJr=o("FlaxBigBirdForTokenClassification"),dJr=o(" (BigBird model)"),cJr=l(),V3=a("li"),p3e=a("strong"),fJr=o("distilbert"),mJr=o(" \u2014 "),Toe=a("a"),gJr=o("FlaxDistilBertForTokenClassification"),hJr=o(" (DistilBERT model)"),pJr=l(),X3=a("li"),_3e=a("strong"),_Jr=o("electra"),uJr=o(" \u2014 "),Moe=a("a"),bJr=o("FlaxElectraForTokenClassification"),vJr=o(" (ELECTRA model)"),FJr=l(),z3=a("li"),u3e=a("strong"),TJr=o("roberta"),MJr=o(" \u2014 "),Eoe=a("a"),EJr=o("FlaxRobertaForTokenClassification"),CJr=o(" (RoBERTa model)"),wJr=l(),W3=a("li"),b3e=a("strong"),AJr=o("roformer"),LJr=o(" \u2014 "),Coe=a("a"),yJr=o("FlaxRoFormerForTokenClassification"),xJr=o(" (RoFormer model)"),$Jr=l(),Q3=a("li"),v3e=a("strong"),kJr=o("xlm-roberta"),SJr=o(" \u2014 "),woe=a("a"),RJr=o("FlaxXLMRobertaForTokenClassification"),PJr=o(" (XLM-RoBERTa model)"),BJr=l(),F(H3.$$.fragment),NXe=l(),uf=a("h2"),U3=a("a"),F3e=a("span"),F(k$.$$.fragment),IJr=l(),T3e=a("span"),NJr=o("FlaxAutoModelForMultipleChoice"),qXe=l(),Er=a("div"),F(S$.$$.fragment),qJr=l(),bf=a("p"),jJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Aoe=a("a"),DJr=o("from_pretrained()"),GJr=o(" class method or the "),Loe=a("a"),OJr=o("from_config()"),VJr=o(` class
method.`),XJr=l(),R$=a("p"),zJr=o("This class cannot be instantiated directly using "),M3e=a("code"),WJr=o("__init__()"),QJr=o(" (throws an error)."),HJr=l(),Zt=a("div"),F(P$.$$.fragment),UJr=l(),E3e=a("p"),JJr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),YJr=l(),vf=a("p"),KJr=o(`Note:
Loading a model from its configuration file does `),C3e=a("strong"),ZJr=o("not"),eYr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yoe=a("a"),oYr=o("from_pretrained()"),rYr=o(" to load the model weights."),tYr=l(),F(J3.$$.fragment),aYr=l(),Yr=a("div"),F(B$.$$.fragment),nYr=l(),w3e=a("p"),sYr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),lYr=l(),xn=a("p"),iYr=o("The model class to instantiate is selected based on the "),A3e=a("code"),dYr=o("model_type"),cYr=o(` property of the config object (either
passed as an argument or loaded from `),L3e=a("code"),fYr=o("pretrained_model_name_or_path"),mYr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y3e=a("code"),gYr=o("pretrained_model_name_or_path"),hYr=o(":"),pYr=l(),Xe=a("ul"),Y3=a("li"),x3e=a("strong"),_Yr=o("albert"),uYr=o(" \u2014 "),xoe=a("a"),bYr=o("FlaxAlbertForMultipleChoice"),vYr=o(" (ALBERT model)"),FYr=l(),K3=a("li"),$3e=a("strong"),TYr=o("bert"),MYr=o(" \u2014 "),$oe=a("a"),EYr=o("FlaxBertForMultipleChoice"),CYr=o(" (BERT model)"),wYr=l(),Z3=a("li"),k3e=a("strong"),AYr=o("big_bird"),LYr=o(" \u2014 "),koe=a("a"),yYr=o("FlaxBigBirdForMultipleChoice"),xYr=o(" (BigBird model)"),$Yr=l(),e5=a("li"),S3e=a("strong"),kYr=o("distilbert"),SYr=o(" \u2014 "),Soe=a("a"),RYr=o("FlaxDistilBertForMultipleChoice"),PYr=o(" (DistilBERT model)"),BYr=l(),o5=a("li"),R3e=a("strong"),IYr=o("electra"),NYr=o(" \u2014 "),Roe=a("a"),qYr=o("FlaxElectraForMultipleChoice"),jYr=o(" (ELECTRA model)"),DYr=l(),r5=a("li"),P3e=a("strong"),GYr=o("roberta"),OYr=o(" \u2014 "),Poe=a("a"),VYr=o("FlaxRobertaForMultipleChoice"),XYr=o(" (RoBERTa model)"),zYr=l(),t5=a("li"),B3e=a("strong"),WYr=o("roformer"),QYr=o(" \u2014 "),Boe=a("a"),HYr=o("FlaxRoFormerForMultipleChoice"),UYr=o(" (RoFormer model)"),JYr=l(),a5=a("li"),I3e=a("strong"),YYr=o("xlm-roberta"),KYr=o(" \u2014 "),Ioe=a("a"),ZYr=o("FlaxXLMRobertaForMultipleChoice"),eKr=o(" (XLM-RoBERTa model)"),oKr=l(),F(n5.$$.fragment),jXe=l(),Ff=a("h2"),s5=a("a"),N3e=a("span"),F(I$.$$.fragment),rKr=l(),q3e=a("span"),tKr=o("FlaxAutoModelForNextSentencePrediction"),DXe=l(),Cr=a("div"),F(N$.$$.fragment),aKr=l(),Tf=a("p"),nKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Noe=a("a"),sKr=o("from_pretrained()"),lKr=o(" class method or the "),qoe=a("a"),iKr=o("from_config()"),dKr=o(` class
method.`),cKr=l(),q$=a("p"),fKr=o("This class cannot be instantiated directly using "),j3e=a("code"),mKr=o("__init__()"),gKr=o(" (throws an error)."),hKr=l(),ea=a("div"),F(j$.$$.fragment),pKr=l(),D3e=a("p"),_Kr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),uKr=l(),Mf=a("p"),bKr=o(`Note:
Loading a model from its configuration file does `),G3e=a("strong"),vKr=o("not"),FKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),joe=a("a"),TKr=o("from_pretrained()"),MKr=o(" to load the model weights."),EKr=l(),F(l5.$$.fragment),CKr=l(),Kr=a("div"),F(D$.$$.fragment),wKr=l(),O3e=a("p"),AKr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),LKr=l(),$n=a("p"),yKr=o("The model class to instantiate is selected based on the "),V3e=a("code"),xKr=o("model_type"),$Kr=o(` property of the config object (either
passed as an argument or loaded from `),X3e=a("code"),kKr=o("pretrained_model_name_or_path"),SKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z3e=a("code"),RKr=o("pretrained_model_name_or_path"),PKr=o(":"),BKr=l(),W3e=a("ul"),i5=a("li"),Q3e=a("strong"),IKr=o("bert"),NKr=o(" \u2014 "),Doe=a("a"),qKr=o("FlaxBertForNextSentencePrediction"),jKr=o(" (BERT model)"),DKr=l(),F(d5.$$.fragment),GXe=l(),Ef=a("h2"),c5=a("a"),H3e=a("span"),F(G$.$$.fragment),GKr=l(),U3e=a("span"),OKr=o("FlaxAutoModelForImageClassification"),OXe=l(),wr=a("div"),F(O$.$$.fragment),VKr=l(),Cf=a("p"),XKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Goe=a("a"),zKr=o("from_pretrained()"),WKr=o(" class method or the "),Ooe=a("a"),QKr=o("from_config()"),HKr=o(` class
method.`),UKr=l(),V$=a("p"),JKr=o("This class cannot be instantiated directly using "),J3e=a("code"),YKr=o("__init__()"),KKr=o(" (throws an error)."),ZKr=l(),oa=a("div"),F(X$.$$.fragment),eZr=l(),Y3e=a("p"),oZr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),rZr=l(),wf=a("p"),tZr=o(`Note:
Loading a model from its configuration file does `),K3e=a("strong"),aZr=o("not"),nZr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Voe=a("a"),sZr=o("from_pretrained()"),lZr=o(" to load the model weights."),iZr=l(),F(f5.$$.fragment),dZr=l(),Zr=a("div"),F(z$.$$.fragment),cZr=l(),Z3e=a("p"),fZr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),mZr=l(),kn=a("p"),gZr=o("The model class to instantiate is selected based on the "),e5e=a("code"),hZr=o("model_type"),pZr=o(` property of the config object (either
passed as an argument or loaded from `),o5e=a("code"),_Zr=o("pretrained_model_name_or_path"),uZr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r5e=a("code"),bZr=o("pretrained_model_name_or_path"),vZr=o(":"),FZr=l(),W$=a("ul"),m5=a("li"),t5e=a("strong"),TZr=o("beit"),MZr=o(" \u2014 "),Xoe=a("a"),EZr=o("FlaxBeitForImageClassification"),CZr=o(" (BEiT model)"),wZr=l(),g5=a("li"),a5e=a("strong"),AZr=o("vit"),LZr=o(" \u2014 "),zoe=a("a"),yZr=o("FlaxViTForImageClassification"),xZr=o(" (ViT model)"),$Zr=l(),F(h5.$$.fragment),VXe=l(),Af=a("h2"),p5=a("a"),n5e=a("span"),F(Q$.$$.fragment),kZr=l(),s5e=a("span"),SZr=o("FlaxAutoModelForVision2Seq"),XXe=l(),Ar=a("div"),F(H$.$$.fragment),RZr=l(),Lf=a("p"),PZr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Woe=a("a"),BZr=o("from_pretrained()"),IZr=o(" class method or the "),Qoe=a("a"),NZr=o("from_config()"),qZr=o(` class
method.`),jZr=l(),U$=a("p"),DZr=o("This class cannot be instantiated directly using "),l5e=a("code"),GZr=o("__init__()"),OZr=o(" (throws an error)."),VZr=l(),ra=a("div"),F(J$.$$.fragment),XZr=l(),i5e=a("p"),zZr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),WZr=l(),yf=a("p"),QZr=o(`Note:
Loading a model from its configuration file does `),d5e=a("strong"),HZr=o("not"),UZr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Hoe=a("a"),JZr=o("from_pretrained()"),YZr=o(" to load the model weights."),KZr=l(),F(_5.$$.fragment),ZZr=l(),et=a("div"),F(Y$.$$.fragment),eet=l(),c5e=a("p"),oet=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),ret=l(),Sn=a("p"),tet=o("The model class to instantiate is selected based on the "),f5e=a("code"),aet=o("model_type"),net=o(` property of the config object (either
passed as an argument or loaded from `),m5e=a("code"),set=o("pretrained_model_name_or_path"),iet=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g5e=a("code"),det=o("pretrained_model_name_or_path"),cet=o(":"),fet=l(),h5e=a("ul"),u5=a("li"),p5e=a("strong"),met=o("vision-encoder-decoder"),get=o(" \u2014 "),Uoe=a("a"),het=o("FlaxVisionEncoderDecoderModel"),pet=o(" (Vision Encoder decoder model)"),_et=l(),F(b5.$$.fragment),this.h()},l(f){const u=pVt('[data-svelte="svelte-1phssyn"]',document.head);g=n(u,"META",{name:!0,content:!0}),u.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var K$=s(p);m=n(K$,"A",{id:!0,class:!0,href:!0});var _5e=s(m);_=n(_5e,"SPAN",{});var u5e=s(_);T(d.$$.fragment,u5e),u5e.forEach(t),_5e.forEach(t),h=i(K$),Eo=n(K$,"SPAN",{});var b5e=s(Eo);wi=r(b5e,"Auto Classes"),b5e.forEach(t),K$.forEach(t),Sf=i(f),nt=n(f,"P",{});var Z$=s(nt);Ai=r(Z$,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Li=n(Z$,"CODE",{});var v5e=s(Li);qA=r(v5e,"from_pretrained()"),v5e.forEach(t),Rf=r(Z$,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Z$.forEach(t),Oe=i(f),We=n(f,"P",{});var Rn=s(We);yi=r(Rn,"Instantiating one of "),Pn=n(Rn,"A",{href:!0});var F5e=s(Pn);jA=r(F5e,"AutoConfig"),F5e.forEach(t),Bn=r(Rn,", "),In=n(Rn,"A",{href:!0});var T5e=s(In);DA=r(T5e,"AutoModel"),T5e.forEach(t),xi=r(Rn,`, and
`),Nn=n(Rn,"A",{href:!0});var M5e=s(Nn);GA=r(M5e,"AutoTokenizer"),M5e.forEach(t),$i=r(Rn," will directly create a class of the relevant architecture. For instance"),Rn.forEach(t),Pf=i(f),T(ka.$$.fragment,f),Qe=i(f),Ae=n(f,"P",{});var ek=s(Ae);bS=r(ek,"will create a model that is an instance of "),ki=n(ek,"A",{href:!0});var E5e=s(ki);vS=r(E5e,"BertModel"),E5e.forEach(t),FS=r(ek,"."),ek.forEach(t),Co=i(f),Sa=n(f,"P",{});var ok=s(Sa);TS=r(ok,"There is one class of "),Bf=n(ok,"CODE",{});var C5e=s(Bf);MS=r(C5e,"AutoModel"),C5e.forEach(t),oQe=r(ok," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),ok.forEach(t),DOe=i(f),Si=n(f,"H2",{class:!0});var rk=s(Si);If=n(rk,"A",{id:!0,class:!0,href:!0});var w5e=s(If);Xte=n(w5e,"SPAN",{});var A5e=s(Xte);T(OA.$$.fragment,A5e),A5e.forEach(t),w5e.forEach(t),rQe=i(rk),zte=n(rk,"SPAN",{});var L5e=s(zte);tQe=r(L5e,"Extending the Auto Classes"),L5e.forEach(t),rk.forEach(t),GOe=i(f),qn=n(f,"P",{});var xf=s(qn);aQe=r(xf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Wte=n(xf,"CODE",{});var y5e=s(Wte);nQe=r(y5e,"NewModel"),y5e.forEach(t),sQe=r(xf,", make sure you have a "),Qte=n(xf,"CODE",{});var x5e=s(Qte);lQe=r(x5e,"NewModelConfig"),x5e.forEach(t),iQe=r(xf,` then you can add those to the auto
classes like this:`),xf.forEach(t),OOe=i(f),T(VA.$$.fragment,f),VOe=i(f),ES=n(f,"P",{});var $5e=s(ES);dQe=r($5e,"You will then be able to use the auto classes like you would usually do!"),$5e.forEach(t),XOe=i(f),T(Nf.$$.fragment,f),zOe=i(f),Ri=n(f,"H2",{class:!0});var tk=s(Ri);qf=n(tk,"A",{id:!0,class:!0,href:!0});var k5e=s(qf);Hte=n(k5e,"SPAN",{});var S5e=s(Hte);T(XA.$$.fragment,S5e),S5e.forEach(t),k5e.forEach(t),cQe=i(tk),Ute=n(tk,"SPAN",{});var R5e=s(Ute);fQe=r(R5e,"AutoConfig"),R5e.forEach(t),tk.forEach(t),WOe=i(f),wo=n(f,"DIV",{class:!0});var tt=s(wo);T(zA.$$.fragment,tt),mQe=i(tt),WA=n(tt,"P",{});var ak=s(WA);gQe=r(ak,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),CS=n(ak,"A",{href:!0});var P5e=s(CS);hQe=r(P5e,"from_pretrained()"),P5e.forEach(t),pQe=r(ak," class method."),ak.forEach(t),_Qe=i(tt),QA=n(tt,"P",{});var nk=s(QA);uQe=r(nk,"This class cannot be instantiated directly using "),Jte=n(nk,"CODE",{});var B5e=s(Jte);bQe=r(B5e,"__init__()"),B5e.forEach(t),vQe=r(nk," (throws an error)."),nk.forEach(t),FQe=i(tt),Lr=n(tt,"DIV",{class:!0});var at=s(Lr);T(HA.$$.fragment,at),TQe=i(at),Yte=n(at,"P",{});var I5e=s(Yte);MQe=r(I5e,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),I5e.forEach(t),EQe=i(at),Pi=n(at,"P",{});var $f=s(Pi);CQe=r($f,"The configuration class to instantiate is selected based on the "),Kte=n($f,"CODE",{});var N5e=s(Kte);wQe=r(N5e,"model_type"),N5e.forEach(t),AQe=r($f,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Zte=n($f,"CODE",{});var q5e=s(Zte);LQe=r(q5e,"pretrained_model_name_or_path"),q5e.forEach(t),yQe=r($f,":"),$f.forEach(t),xQe=i(at),A=n(at,"UL",{});var L=s(A);jf=n(L,"LI",{});var v5=s(jf);eae=n(v5,"STRONG",{});var j5e=s(eae);$Qe=r(j5e,"albert"),j5e.forEach(t),kQe=r(v5," \u2014 "),wS=n(v5,"A",{href:!0});var D5e=s(wS);SQe=r(D5e,"AlbertConfig"),D5e.forEach(t),RQe=r(v5," (ALBERT model)"),v5.forEach(t),PQe=i(L),Df=n(L,"LI",{});var F5=s(Df);oae=n(F5,"STRONG",{});var G5e=s(oae);BQe=r(G5e,"bart"),G5e.forEach(t),IQe=r(F5," \u2014 "),AS=n(F5,"A",{href:!0});var O5e=s(AS);NQe=r(O5e,"BartConfig"),O5e.forEach(t),qQe=r(F5," (BART model)"),F5.forEach(t),jQe=i(L),Gf=n(L,"LI",{});var T5=s(Gf);rae=n(T5,"STRONG",{});var V5e=s(rae);DQe=r(V5e,"beit"),V5e.forEach(t),GQe=r(T5," \u2014 "),LS=n(T5,"A",{href:!0});var X5e=s(LS);OQe=r(X5e,"BeitConfig"),X5e.forEach(t),VQe=r(T5," (BEiT model)"),T5.forEach(t),XQe=i(L),Of=n(L,"LI",{});var M5=s(Of);tae=n(M5,"STRONG",{});var z5e=s(tae);zQe=r(z5e,"bert"),z5e.forEach(t),WQe=r(M5," \u2014 "),yS=n(M5,"A",{href:!0});var W5e=s(yS);QQe=r(W5e,"BertConfig"),W5e.forEach(t),HQe=r(M5," (BERT model)"),M5.forEach(t),UQe=i(L),Vf=n(L,"LI",{});var E5=s(Vf);aae=n(E5,"STRONG",{});var Q5e=s(aae);JQe=r(Q5e,"bert-generation"),Q5e.forEach(t),YQe=r(E5," \u2014 "),xS=n(E5,"A",{href:!0});var H5e=s(xS);KQe=r(H5e,"BertGenerationConfig"),H5e.forEach(t),ZQe=r(E5," (Bert Generation model)"),E5.forEach(t),eHe=i(L),Xf=n(L,"LI",{});var C5=s(Xf);nae=n(C5,"STRONG",{});var U5e=s(nae);oHe=r(U5e,"big_bird"),U5e.forEach(t),rHe=r(C5," \u2014 "),$S=n(C5,"A",{href:!0});var J5e=s($S);tHe=r(J5e,"BigBirdConfig"),J5e.forEach(t),aHe=r(C5," (BigBird model)"),C5.forEach(t),nHe=i(L),zf=n(L,"LI",{});var w5=s(zf);sae=n(w5,"STRONG",{});var Y5e=s(sae);sHe=r(Y5e,"bigbird_pegasus"),Y5e.forEach(t),lHe=r(w5," \u2014 "),kS=n(w5,"A",{href:!0});var K5e=s(kS);iHe=r(K5e,"BigBirdPegasusConfig"),K5e.forEach(t),dHe=r(w5," (BigBird-Pegasus model)"),w5.forEach(t),cHe=i(L),Wf=n(L,"LI",{});var A5=s(Wf);lae=n(A5,"STRONG",{});var Z5e=s(lae);fHe=r(Z5e,"blenderbot"),Z5e.forEach(t),mHe=r(A5," \u2014 "),SS=n(A5,"A",{href:!0});var ewe=s(SS);gHe=r(ewe,"BlenderbotConfig"),ewe.forEach(t),hHe=r(A5," (Blenderbot model)"),A5.forEach(t),pHe=i(L),Qf=n(L,"LI",{});var L5=s(Qf);iae=n(L5,"STRONG",{});var owe=s(iae);_He=r(owe,"blenderbot-small"),owe.forEach(t),uHe=r(L5," \u2014 "),RS=n(L5,"A",{href:!0});var rwe=s(RS);bHe=r(rwe,"BlenderbotSmallConfig"),rwe.forEach(t),vHe=r(L5," (BlenderbotSmall model)"),L5.forEach(t),FHe=i(L),Hf=n(L,"LI",{});var y5=s(Hf);dae=n(y5,"STRONG",{});var twe=s(dae);THe=r(twe,"bloom"),twe.forEach(t),MHe=r(y5," \u2014 "),PS=n(y5,"A",{href:!0});var awe=s(PS);EHe=r(awe,"BloomConfig"),awe.forEach(t),CHe=r(y5," (BLOOM model)"),y5.forEach(t),wHe=i(L),Uf=n(L,"LI",{});var x5=s(Uf);cae=n(x5,"STRONG",{});var nwe=s(cae);AHe=r(nwe,"camembert"),nwe.forEach(t),LHe=r(x5," \u2014 "),BS=n(x5,"A",{href:!0});var swe=s(BS);yHe=r(swe,"CamembertConfig"),swe.forEach(t),xHe=r(x5," (CamemBERT model)"),x5.forEach(t),$He=i(L),Jf=n(L,"LI",{});var $5=s(Jf);fae=n($5,"STRONG",{});var lwe=s(fae);kHe=r(lwe,"canine"),lwe.forEach(t),SHe=r($5," \u2014 "),IS=n($5,"A",{href:!0});var iwe=s(IS);RHe=r(iwe,"CanineConfig"),iwe.forEach(t),PHe=r($5," (CANINE model)"),$5.forEach(t),BHe=i(L),Yf=n(L,"LI",{});var k5=s(Yf);mae=n(k5,"STRONG",{});var dwe=s(mae);IHe=r(dwe,"clip"),dwe.forEach(t),NHe=r(k5," \u2014 "),NS=n(k5,"A",{href:!0});var cwe=s(NS);qHe=r(cwe,"CLIPConfig"),cwe.forEach(t),jHe=r(k5," (CLIP model)"),k5.forEach(t),DHe=i(L),Kf=n(L,"LI",{});var S5=s(Kf);gae=n(S5,"STRONG",{});var fwe=s(gae);GHe=r(fwe,"codegen"),fwe.forEach(t),OHe=r(S5," \u2014 "),qS=n(S5,"A",{href:!0});var mwe=s(qS);VHe=r(mwe,"CodeGenConfig"),mwe.forEach(t),XHe=r(S5," (CodeGen model)"),S5.forEach(t),zHe=i(L),Zf=n(L,"LI",{});var R5=s(Zf);hae=n(R5,"STRONG",{});var gwe=s(hae);WHe=r(gwe,"convbert"),gwe.forEach(t),QHe=r(R5," \u2014 "),jS=n(R5,"A",{href:!0});var hwe=s(jS);HHe=r(hwe,"ConvBertConfig"),hwe.forEach(t),UHe=r(R5," (ConvBERT model)"),R5.forEach(t),JHe=i(L),em=n(L,"LI",{});var P5=s(em);pae=n(P5,"STRONG",{});var pwe=s(pae);YHe=r(pwe,"convnext"),pwe.forEach(t),KHe=r(P5," \u2014 "),DS=n(P5,"A",{href:!0});var _we=s(DS);ZHe=r(_we,"ConvNextConfig"),_we.forEach(t),eUe=r(P5," (ConvNeXT model)"),P5.forEach(t),oUe=i(L),om=n(L,"LI",{});var B5=s(om);_ae=n(B5,"STRONG",{});var uwe=s(_ae);rUe=r(uwe,"ctrl"),uwe.forEach(t),tUe=r(B5," \u2014 "),GS=n(B5,"A",{href:!0});var bwe=s(GS);aUe=r(bwe,"CTRLConfig"),bwe.forEach(t),nUe=r(B5," (CTRL model)"),B5.forEach(t),sUe=i(L),rm=n(L,"LI",{});var I5=s(rm);uae=n(I5,"STRONG",{});var vwe=s(uae);lUe=r(vwe,"cvt"),vwe.forEach(t),iUe=r(I5," \u2014 "),OS=n(I5,"A",{href:!0});var Fwe=s(OS);dUe=r(Fwe,"CvtConfig"),Fwe.forEach(t),cUe=r(I5," (CvT model)"),I5.forEach(t),fUe=i(L),tm=n(L,"LI",{});var N5=s(tm);bae=n(N5,"STRONG",{});var Twe=s(bae);mUe=r(Twe,"data2vec-audio"),Twe.forEach(t),gUe=r(N5," \u2014 "),VS=n(N5,"A",{href:!0});var Mwe=s(VS);hUe=r(Mwe,"Data2VecAudioConfig"),Mwe.forEach(t),pUe=r(N5," (Data2VecAudio model)"),N5.forEach(t),_Ue=i(L),am=n(L,"LI",{});var q5=s(am);vae=n(q5,"STRONG",{});var Ewe=s(vae);uUe=r(Ewe,"data2vec-text"),Ewe.forEach(t),bUe=r(q5," \u2014 "),XS=n(q5,"A",{href:!0});var Cwe=s(XS);vUe=r(Cwe,"Data2VecTextConfig"),Cwe.forEach(t),FUe=r(q5," (Data2VecText model)"),q5.forEach(t),TUe=i(L),nm=n(L,"LI",{});var j5=s(nm);Fae=n(j5,"STRONG",{});var wwe=s(Fae);MUe=r(wwe,"data2vec-vision"),wwe.forEach(t),EUe=r(j5," \u2014 "),zS=n(j5,"A",{href:!0});var Awe=s(zS);CUe=r(Awe,"Data2VecVisionConfig"),Awe.forEach(t),wUe=r(j5," (Data2VecVision model)"),j5.forEach(t),AUe=i(L),sm=n(L,"LI",{});var D5=s(sm);Tae=n(D5,"STRONG",{});var Lwe=s(Tae);LUe=r(Lwe,"deberta"),Lwe.forEach(t),yUe=r(D5," \u2014 "),WS=n(D5,"A",{href:!0});var ywe=s(WS);xUe=r(ywe,"DebertaConfig"),ywe.forEach(t),$Ue=r(D5," (DeBERTa model)"),D5.forEach(t),kUe=i(L),lm=n(L,"LI",{});var G5=s(lm);Mae=n(G5,"STRONG",{});var xwe=s(Mae);SUe=r(xwe,"deberta-v2"),xwe.forEach(t),RUe=r(G5," \u2014 "),QS=n(G5,"A",{href:!0});var $we=s(QS);PUe=r($we,"DebertaV2Config"),$we.forEach(t),BUe=r(G5," (DeBERTa-v2 model)"),G5.forEach(t),IUe=i(L),im=n(L,"LI",{});var O5=s(im);Eae=n(O5,"STRONG",{});var bet=s(Eae);NUe=r(bet,"decision_transformer"),bet.forEach(t),qUe=r(O5," \u2014 "),HS=n(O5,"A",{href:!0});var vet=s(HS);jUe=r(vet,"DecisionTransformerConfig"),vet.forEach(t),DUe=r(O5," (Decision Transformer model)"),O5.forEach(t),GUe=i(L),dm=n(L,"LI",{});var kwe=s(dm);Cae=n(kwe,"STRONG",{});var Fet=s(Cae);OUe=r(Fet,"deit"),Fet.forEach(t),VUe=r(kwe," \u2014 "),US=n(kwe,"A",{href:!0});var Tet=s(US);XUe=r(Tet,"DeiTConfig"),Tet.forEach(t),zUe=r(kwe," (DeiT model)"),kwe.forEach(t),WUe=i(L),cm=n(L,"LI",{});var Swe=s(cm);wae=n(Swe,"STRONG",{});var Met=s(wae);QUe=r(Met,"detr"),Met.forEach(t),HUe=r(Swe," \u2014 "),JS=n(Swe,"A",{href:!0});var Eet=s(JS);UUe=r(Eet,"DetrConfig"),Eet.forEach(t),JUe=r(Swe," (DETR model)"),Swe.forEach(t),YUe=i(L),fm=n(L,"LI",{});var Rwe=s(fm);Aae=n(Rwe,"STRONG",{});var Cet=s(Aae);KUe=r(Cet,"distilbert"),Cet.forEach(t),ZUe=r(Rwe," \u2014 "),YS=n(Rwe,"A",{href:!0});var wet=s(YS);eJe=r(wet,"DistilBertConfig"),wet.forEach(t),oJe=r(Rwe," (DistilBERT model)"),Rwe.forEach(t),rJe=i(L),mm=n(L,"LI",{});var Pwe=s(mm);Lae=n(Pwe,"STRONG",{});var Aet=s(Lae);tJe=r(Aet,"dpr"),Aet.forEach(t),aJe=r(Pwe," \u2014 "),KS=n(Pwe,"A",{href:!0});var Let=s(KS);nJe=r(Let,"DPRConfig"),Let.forEach(t),sJe=r(Pwe," (DPR model)"),Pwe.forEach(t),lJe=i(L),gm=n(L,"LI",{});var Bwe=s(gm);yae=n(Bwe,"STRONG",{});var yet=s(yae);iJe=r(yet,"dpt"),yet.forEach(t),dJe=r(Bwe," \u2014 "),ZS=n(Bwe,"A",{href:!0});var xet=s(ZS);cJe=r(xet,"DPTConfig"),xet.forEach(t),fJe=r(Bwe," (DPT model)"),Bwe.forEach(t),mJe=i(L),hm=n(L,"LI",{});var Iwe=s(hm);xae=n(Iwe,"STRONG",{});var $et=s(xae);gJe=r($et,"electra"),$et.forEach(t),hJe=r(Iwe," \u2014 "),eR=n(Iwe,"A",{href:!0});var ket=s(eR);pJe=r(ket,"ElectraConfig"),ket.forEach(t),_Je=r(Iwe," (ELECTRA model)"),Iwe.forEach(t),uJe=i(L),pm=n(L,"LI",{});var Nwe=s(pm);$ae=n(Nwe,"STRONG",{});var Set=s($ae);bJe=r(Set,"encoder-decoder"),Set.forEach(t),vJe=r(Nwe," \u2014 "),oR=n(Nwe,"A",{href:!0});var Ret=s(oR);FJe=r(Ret,"EncoderDecoderConfig"),Ret.forEach(t),TJe=r(Nwe," (Encoder decoder model)"),Nwe.forEach(t),MJe=i(L),_m=n(L,"LI",{});var qwe=s(_m);kae=n(qwe,"STRONG",{});var Pet=s(kae);EJe=r(Pet,"flaubert"),Pet.forEach(t),CJe=r(qwe," \u2014 "),rR=n(qwe,"A",{href:!0});var Bet=s(rR);wJe=r(Bet,"FlaubertConfig"),Bet.forEach(t),AJe=r(qwe," (FlauBERT model)"),qwe.forEach(t),LJe=i(L),um=n(L,"LI",{});var jwe=s(um);Sae=n(jwe,"STRONG",{});var Iet=s(Sae);yJe=r(Iet,"flava"),Iet.forEach(t),xJe=r(jwe," \u2014 "),tR=n(jwe,"A",{href:!0});var Net=s(tR);$Je=r(Net,"FlavaConfig"),Net.forEach(t),kJe=r(jwe," (FLAVA model)"),jwe.forEach(t),SJe=i(L),bm=n(L,"LI",{});var Dwe=s(bm);Rae=n(Dwe,"STRONG",{});var qet=s(Rae);RJe=r(qet,"fnet"),qet.forEach(t),PJe=r(Dwe," \u2014 "),aR=n(Dwe,"A",{href:!0});var jet=s(aR);BJe=r(jet,"FNetConfig"),jet.forEach(t),IJe=r(Dwe," (FNet model)"),Dwe.forEach(t),NJe=i(L),vm=n(L,"LI",{});var Gwe=s(vm);Pae=n(Gwe,"STRONG",{});var Det=s(Pae);qJe=r(Det,"fsmt"),Det.forEach(t),jJe=r(Gwe," \u2014 "),nR=n(Gwe,"A",{href:!0});var Get=s(nR);DJe=r(Get,"FSMTConfig"),Get.forEach(t),GJe=r(Gwe," (FairSeq Machine-Translation model)"),Gwe.forEach(t),OJe=i(L),Fm=n(L,"LI",{});var Owe=s(Fm);Bae=n(Owe,"STRONG",{});var Oet=s(Bae);VJe=r(Oet,"funnel"),Oet.forEach(t),XJe=r(Owe," \u2014 "),sR=n(Owe,"A",{href:!0});var Vet=s(sR);zJe=r(Vet,"FunnelConfig"),Vet.forEach(t),WJe=r(Owe," (Funnel Transformer model)"),Owe.forEach(t),QJe=i(L),Tm=n(L,"LI",{});var Vwe=s(Tm);Iae=n(Vwe,"STRONG",{});var Xet=s(Iae);HJe=r(Xet,"glpn"),Xet.forEach(t),UJe=r(Vwe," \u2014 "),lR=n(Vwe,"A",{href:!0});var zet=s(lR);JJe=r(zet,"GLPNConfig"),zet.forEach(t),YJe=r(Vwe," (GLPN model)"),Vwe.forEach(t),KJe=i(L),Mm=n(L,"LI",{});var Xwe=s(Mm);Nae=n(Xwe,"STRONG",{});var Wet=s(Nae);ZJe=r(Wet,"gpt2"),Wet.forEach(t),eYe=r(Xwe," \u2014 "),iR=n(Xwe,"A",{href:!0});var Qet=s(iR);oYe=r(Qet,"GPT2Config"),Qet.forEach(t),rYe=r(Xwe," (OpenAI GPT-2 model)"),Xwe.forEach(t),tYe=i(L),Em=n(L,"LI",{});var zwe=s(Em);qae=n(zwe,"STRONG",{});var Het=s(qae);aYe=r(Het,"gpt_neo"),Het.forEach(t),nYe=r(zwe," \u2014 "),dR=n(zwe,"A",{href:!0});var Uet=s(dR);sYe=r(Uet,"GPTNeoConfig"),Uet.forEach(t),lYe=r(zwe," (GPT Neo model)"),zwe.forEach(t),iYe=i(L),Cm=n(L,"LI",{});var Wwe=s(Cm);jae=n(Wwe,"STRONG",{});var Jet=s(jae);dYe=r(Jet,"gpt_neox"),Jet.forEach(t),cYe=r(Wwe," \u2014 "),cR=n(Wwe,"A",{href:!0});var Yet=s(cR);fYe=r(Yet,"GPTNeoXConfig"),Yet.forEach(t),mYe=r(Wwe," (GPT NeoX model)"),Wwe.forEach(t),gYe=i(L),wm=n(L,"LI",{});var Qwe=s(wm);Dae=n(Qwe,"STRONG",{});var Ket=s(Dae);hYe=r(Ket,"gptj"),Ket.forEach(t),pYe=r(Qwe," \u2014 "),fR=n(Qwe,"A",{href:!0});var Zet=s(fR);_Ye=r(Zet,"GPTJConfig"),Zet.forEach(t),uYe=r(Qwe," (GPT-J model)"),Qwe.forEach(t),bYe=i(L),Am=n(L,"LI",{});var Hwe=s(Am);Gae=n(Hwe,"STRONG",{});var eot=s(Gae);vYe=r(eot,"groupvit"),eot.forEach(t),FYe=r(Hwe," \u2014 "),mR=n(Hwe,"A",{href:!0});var oot=s(mR);TYe=r(oot,"GroupViTConfig"),oot.forEach(t),MYe=r(Hwe," (GroupViT model)"),Hwe.forEach(t),EYe=i(L),Lm=n(L,"LI",{});var Uwe=s(Lm);Oae=n(Uwe,"STRONG",{});var rot=s(Oae);CYe=r(rot,"hubert"),rot.forEach(t),wYe=r(Uwe," \u2014 "),gR=n(Uwe,"A",{href:!0});var tot=s(gR);AYe=r(tot,"HubertConfig"),tot.forEach(t),LYe=r(Uwe," (Hubert model)"),Uwe.forEach(t),yYe=i(L),ym=n(L,"LI",{});var Jwe=s(ym);Vae=n(Jwe,"STRONG",{});var aot=s(Vae);xYe=r(aot,"ibert"),aot.forEach(t),$Ye=r(Jwe," \u2014 "),hR=n(Jwe,"A",{href:!0});var not=s(hR);kYe=r(not,"IBertConfig"),not.forEach(t),SYe=r(Jwe," (I-BERT model)"),Jwe.forEach(t),RYe=i(L),xm=n(L,"LI",{});var Ywe=s(xm);Xae=n(Ywe,"STRONG",{});var sot=s(Xae);PYe=r(sot,"imagegpt"),sot.forEach(t),BYe=r(Ywe," \u2014 "),pR=n(Ywe,"A",{href:!0});var lot=s(pR);IYe=r(lot,"ImageGPTConfig"),lot.forEach(t),NYe=r(Ywe," (ImageGPT model)"),Ywe.forEach(t),qYe=i(L),$m=n(L,"LI",{});var Kwe=s($m);zae=n(Kwe,"STRONG",{});var iot=s(zae);jYe=r(iot,"layoutlm"),iot.forEach(t),DYe=r(Kwe," \u2014 "),_R=n(Kwe,"A",{href:!0});var dot=s(_R);GYe=r(dot,"LayoutLMConfig"),dot.forEach(t),OYe=r(Kwe," (LayoutLM model)"),Kwe.forEach(t),VYe=i(L),km=n(L,"LI",{});var Zwe=s(km);Wae=n(Zwe,"STRONG",{});var cot=s(Wae);XYe=r(cot,"layoutlmv2"),cot.forEach(t),zYe=r(Zwe," \u2014 "),uR=n(Zwe,"A",{href:!0});var fot=s(uR);WYe=r(fot,"LayoutLMv2Config"),fot.forEach(t),QYe=r(Zwe," (LayoutLMv2 model)"),Zwe.forEach(t),HYe=i(L),Sm=n(L,"LI",{});var eAe=s(Sm);Qae=n(eAe,"STRONG",{});var mot=s(Qae);UYe=r(mot,"layoutlmv3"),mot.forEach(t),JYe=r(eAe," \u2014 "),bR=n(eAe,"A",{href:!0});var got=s(bR);YYe=r(got,"LayoutLMv3Config"),got.forEach(t),KYe=r(eAe," (LayoutLMv3 model)"),eAe.forEach(t),ZYe=i(L),Rm=n(L,"LI",{});var oAe=s(Rm);Hae=n(oAe,"STRONG",{});var hot=s(Hae);eKe=r(hot,"led"),hot.forEach(t),oKe=r(oAe," \u2014 "),vR=n(oAe,"A",{href:!0});var pot=s(vR);rKe=r(pot,"LEDConfig"),pot.forEach(t),tKe=r(oAe," (LED model)"),oAe.forEach(t),aKe=i(L),Pm=n(L,"LI",{});var rAe=s(Pm);Uae=n(rAe,"STRONG",{});var _ot=s(Uae);nKe=r(_ot,"levit"),_ot.forEach(t),sKe=r(rAe," \u2014 "),FR=n(rAe,"A",{href:!0});var uot=s(FR);lKe=r(uot,"LevitConfig"),uot.forEach(t),iKe=r(rAe," (LeViT model)"),rAe.forEach(t),dKe=i(L),Bm=n(L,"LI",{});var tAe=s(Bm);Jae=n(tAe,"STRONG",{});var bot=s(Jae);cKe=r(bot,"longformer"),bot.forEach(t),fKe=r(tAe," \u2014 "),TR=n(tAe,"A",{href:!0});var vot=s(TR);mKe=r(vot,"LongformerConfig"),vot.forEach(t),gKe=r(tAe," (Longformer model)"),tAe.forEach(t),hKe=i(L),Im=n(L,"LI",{});var aAe=s(Im);Yae=n(aAe,"STRONG",{});var Fot=s(Yae);pKe=r(Fot,"longt5"),Fot.forEach(t),_Ke=r(aAe," \u2014 "),MR=n(aAe,"A",{href:!0});var Tot=s(MR);uKe=r(Tot,"LongT5Config"),Tot.forEach(t),bKe=r(aAe," (LongT5 model)"),aAe.forEach(t),vKe=i(L),Nm=n(L,"LI",{});var nAe=s(Nm);Kae=n(nAe,"STRONG",{});var Mot=s(Kae);FKe=r(Mot,"luke"),Mot.forEach(t),TKe=r(nAe," \u2014 "),ER=n(nAe,"A",{href:!0});var Eot=s(ER);MKe=r(Eot,"LukeConfig"),Eot.forEach(t),EKe=r(nAe," (LUKE model)"),nAe.forEach(t),CKe=i(L),qm=n(L,"LI",{});var sAe=s(qm);Zae=n(sAe,"STRONG",{});var Cot=s(Zae);wKe=r(Cot,"lxmert"),Cot.forEach(t),AKe=r(sAe," \u2014 "),CR=n(sAe,"A",{href:!0});var wot=s(CR);LKe=r(wot,"LxmertConfig"),wot.forEach(t),yKe=r(sAe," (LXMERT model)"),sAe.forEach(t),xKe=i(L),jm=n(L,"LI",{});var lAe=s(jm);ene=n(lAe,"STRONG",{});var Aot=s(ene);$Ke=r(Aot,"m2m_100"),Aot.forEach(t),kKe=r(lAe," \u2014 "),wR=n(lAe,"A",{href:!0});var Lot=s(wR);SKe=r(Lot,"M2M100Config"),Lot.forEach(t),RKe=r(lAe," (M2M100 model)"),lAe.forEach(t),PKe=i(L),Dm=n(L,"LI",{});var iAe=s(Dm);one=n(iAe,"STRONG",{});var yot=s(one);BKe=r(yot,"marian"),yot.forEach(t),IKe=r(iAe," \u2014 "),AR=n(iAe,"A",{href:!0});var xot=s(AR);NKe=r(xot,"MarianConfig"),xot.forEach(t),qKe=r(iAe," (Marian model)"),iAe.forEach(t),jKe=i(L),Gm=n(L,"LI",{});var dAe=s(Gm);rne=n(dAe,"STRONG",{});var $ot=s(rne);DKe=r($ot,"maskformer"),$ot.forEach(t),GKe=r(dAe," \u2014 "),LR=n(dAe,"A",{href:!0});var kot=s(LR);OKe=r(kot,"MaskFormerConfig"),kot.forEach(t),VKe=r(dAe," (MaskFormer model)"),dAe.forEach(t),XKe=i(L),Om=n(L,"LI",{});var cAe=s(Om);tne=n(cAe,"STRONG",{});var Sot=s(tne);zKe=r(Sot,"mbart"),Sot.forEach(t),WKe=r(cAe," \u2014 "),yR=n(cAe,"A",{href:!0});var Rot=s(yR);QKe=r(Rot,"MBartConfig"),Rot.forEach(t),HKe=r(cAe," (mBART model)"),cAe.forEach(t),UKe=i(L),Vm=n(L,"LI",{});var fAe=s(Vm);ane=n(fAe,"STRONG",{});var Pot=s(ane);JKe=r(Pot,"mctct"),Pot.forEach(t),YKe=r(fAe," \u2014 "),xR=n(fAe,"A",{href:!0});var Bot=s(xR);KKe=r(Bot,"MCTCTConfig"),Bot.forEach(t),ZKe=r(fAe," (M-CTC-T model)"),fAe.forEach(t),eZe=i(L),Xm=n(L,"LI",{});var mAe=s(Xm);nne=n(mAe,"STRONG",{});var Iot=s(nne);oZe=r(Iot,"megatron-bert"),Iot.forEach(t),rZe=r(mAe," \u2014 "),$R=n(mAe,"A",{href:!0});var Not=s($R);tZe=r(Not,"MegatronBertConfig"),Not.forEach(t),aZe=r(mAe," (Megatron-BERT model)"),mAe.forEach(t),nZe=i(L),zm=n(L,"LI",{});var gAe=s(zm);sne=n(gAe,"STRONG",{});var qot=s(sne);sZe=r(qot,"mobilebert"),qot.forEach(t),lZe=r(gAe," \u2014 "),kR=n(gAe,"A",{href:!0});var jot=s(kR);iZe=r(jot,"MobileBertConfig"),jot.forEach(t),dZe=r(gAe," (MobileBERT model)"),gAe.forEach(t),cZe=i(L),Wm=n(L,"LI",{});var hAe=s(Wm);lne=n(hAe,"STRONG",{});var Dot=s(lne);fZe=r(Dot,"mpnet"),Dot.forEach(t),mZe=r(hAe," \u2014 "),SR=n(hAe,"A",{href:!0});var Got=s(SR);gZe=r(Got,"MPNetConfig"),Got.forEach(t),hZe=r(hAe," (MPNet model)"),hAe.forEach(t),pZe=i(L),Qm=n(L,"LI",{});var pAe=s(Qm);ine=n(pAe,"STRONG",{});var Oot=s(ine);_Ze=r(Oot,"mt5"),Oot.forEach(t),uZe=r(pAe," \u2014 "),RR=n(pAe,"A",{href:!0});var Vot=s(RR);bZe=r(Vot,"MT5Config"),Vot.forEach(t),vZe=r(pAe," (MT5 model)"),pAe.forEach(t),FZe=i(L),Hm=n(L,"LI",{});var _Ae=s(Hm);dne=n(_Ae,"STRONG",{});var Xot=s(dne);TZe=r(Xot,"nezha"),Xot.forEach(t),MZe=r(_Ae," \u2014 "),PR=n(_Ae,"A",{href:!0});var zot=s(PR);EZe=r(zot,"NezhaConfig"),zot.forEach(t),CZe=r(_Ae," (Nezha model)"),_Ae.forEach(t),wZe=i(L),Um=n(L,"LI",{});var uAe=s(Um);cne=n(uAe,"STRONG",{});var Wot=s(cne);AZe=r(Wot,"nystromformer"),Wot.forEach(t),LZe=r(uAe," \u2014 "),BR=n(uAe,"A",{href:!0});var Qot=s(BR);yZe=r(Qot,"NystromformerConfig"),Qot.forEach(t),xZe=r(uAe," (Nystr\xF6mformer model)"),uAe.forEach(t),$Ze=i(L),Jm=n(L,"LI",{});var bAe=s(Jm);fne=n(bAe,"STRONG",{});var Hot=s(fne);kZe=r(Hot,"openai-gpt"),Hot.forEach(t),SZe=r(bAe," \u2014 "),IR=n(bAe,"A",{href:!0});var Uot=s(IR);RZe=r(Uot,"OpenAIGPTConfig"),Uot.forEach(t),PZe=r(bAe," (OpenAI GPT model)"),bAe.forEach(t),BZe=i(L),Ym=n(L,"LI",{});var vAe=s(Ym);mne=n(vAe,"STRONG",{});var Jot=s(mne);IZe=r(Jot,"opt"),Jot.forEach(t),NZe=r(vAe," \u2014 "),NR=n(vAe,"A",{href:!0});var Yot=s(NR);qZe=r(Yot,"OPTConfig"),Yot.forEach(t),jZe=r(vAe," (OPT model)"),vAe.forEach(t),DZe=i(L),Km=n(L,"LI",{});var FAe=s(Km);gne=n(FAe,"STRONG",{});var Kot=s(gne);GZe=r(Kot,"pegasus"),Kot.forEach(t),OZe=r(FAe," \u2014 "),qR=n(FAe,"A",{href:!0});var Zot=s(qR);VZe=r(Zot,"PegasusConfig"),Zot.forEach(t),XZe=r(FAe," (Pegasus model)"),FAe.forEach(t),zZe=i(L),Zm=n(L,"LI",{});var TAe=s(Zm);hne=n(TAe,"STRONG",{});var ert=s(hne);WZe=r(ert,"perceiver"),ert.forEach(t),QZe=r(TAe," \u2014 "),jR=n(TAe,"A",{href:!0});var ort=s(jR);HZe=r(ort,"PerceiverConfig"),ort.forEach(t),UZe=r(TAe," (Perceiver model)"),TAe.forEach(t),JZe=i(L),eg=n(L,"LI",{});var MAe=s(eg);pne=n(MAe,"STRONG",{});var rrt=s(pne);YZe=r(rrt,"plbart"),rrt.forEach(t),KZe=r(MAe," \u2014 "),DR=n(MAe,"A",{href:!0});var trt=s(DR);ZZe=r(trt,"PLBartConfig"),trt.forEach(t),eeo=r(MAe," (PLBart model)"),MAe.forEach(t),oeo=i(L),og=n(L,"LI",{});var EAe=s(og);_ne=n(EAe,"STRONG",{});var art=s(_ne);reo=r(art,"poolformer"),art.forEach(t),teo=r(EAe," \u2014 "),GR=n(EAe,"A",{href:!0});var nrt=s(GR);aeo=r(nrt,"PoolFormerConfig"),nrt.forEach(t),neo=r(EAe," (PoolFormer model)"),EAe.forEach(t),seo=i(L),rg=n(L,"LI",{});var CAe=s(rg);une=n(CAe,"STRONG",{});var srt=s(une);leo=r(srt,"prophetnet"),srt.forEach(t),ieo=r(CAe," \u2014 "),OR=n(CAe,"A",{href:!0});var lrt=s(OR);deo=r(lrt,"ProphetNetConfig"),lrt.forEach(t),ceo=r(CAe," (ProphetNet model)"),CAe.forEach(t),feo=i(L),tg=n(L,"LI",{});var wAe=s(tg);bne=n(wAe,"STRONG",{});var irt=s(bne);meo=r(irt,"qdqbert"),irt.forEach(t),geo=r(wAe," \u2014 "),VR=n(wAe,"A",{href:!0});var drt=s(VR);heo=r(drt,"QDQBertConfig"),drt.forEach(t),peo=r(wAe," (QDQBert model)"),wAe.forEach(t),_eo=i(L),ag=n(L,"LI",{});var AAe=s(ag);vne=n(AAe,"STRONG",{});var crt=s(vne);ueo=r(crt,"rag"),crt.forEach(t),beo=r(AAe," \u2014 "),XR=n(AAe,"A",{href:!0});var frt=s(XR);veo=r(frt,"RagConfig"),frt.forEach(t),Feo=r(AAe," (RAG model)"),AAe.forEach(t),Teo=i(L),ng=n(L,"LI",{});var LAe=s(ng);Fne=n(LAe,"STRONG",{});var mrt=s(Fne);Meo=r(mrt,"realm"),mrt.forEach(t),Eeo=r(LAe," \u2014 "),zR=n(LAe,"A",{href:!0});var grt=s(zR);Ceo=r(grt,"RealmConfig"),grt.forEach(t),weo=r(LAe," (REALM model)"),LAe.forEach(t),Aeo=i(L),sg=n(L,"LI",{});var yAe=s(sg);Tne=n(yAe,"STRONG",{});var hrt=s(Tne);Leo=r(hrt,"reformer"),hrt.forEach(t),yeo=r(yAe," \u2014 "),WR=n(yAe,"A",{href:!0});var prt=s(WR);xeo=r(prt,"ReformerConfig"),prt.forEach(t),$eo=r(yAe," (Reformer model)"),yAe.forEach(t),keo=i(L),lg=n(L,"LI",{});var xAe=s(lg);Mne=n(xAe,"STRONG",{});var _rt=s(Mne);Seo=r(_rt,"regnet"),_rt.forEach(t),Reo=r(xAe," \u2014 "),QR=n(xAe,"A",{href:!0});var urt=s(QR);Peo=r(urt,"RegNetConfig"),urt.forEach(t),Beo=r(xAe," (RegNet model)"),xAe.forEach(t),Ieo=i(L),ig=n(L,"LI",{});var $Ae=s(ig);Ene=n($Ae,"STRONG",{});var brt=s(Ene);Neo=r(brt,"rembert"),brt.forEach(t),qeo=r($Ae," \u2014 "),HR=n($Ae,"A",{href:!0});var vrt=s(HR);jeo=r(vrt,"RemBertConfig"),vrt.forEach(t),Deo=r($Ae," (RemBERT model)"),$Ae.forEach(t),Geo=i(L),dg=n(L,"LI",{});var kAe=s(dg);Cne=n(kAe,"STRONG",{});var Frt=s(Cne);Oeo=r(Frt,"resnet"),Frt.forEach(t),Veo=r(kAe," \u2014 "),UR=n(kAe,"A",{href:!0});var Trt=s(UR);Xeo=r(Trt,"ResNetConfig"),Trt.forEach(t),zeo=r(kAe," (ResNet model)"),kAe.forEach(t),Weo=i(L),cg=n(L,"LI",{});var SAe=s(cg);wne=n(SAe,"STRONG",{});var Mrt=s(wne);Qeo=r(Mrt,"retribert"),Mrt.forEach(t),Heo=r(SAe," \u2014 "),JR=n(SAe,"A",{href:!0});var Ert=s(JR);Ueo=r(Ert,"RetriBertConfig"),Ert.forEach(t),Jeo=r(SAe," (RetriBERT model)"),SAe.forEach(t),Yeo=i(L),fg=n(L,"LI",{});var RAe=s(fg);Ane=n(RAe,"STRONG",{});var Crt=s(Ane);Keo=r(Crt,"roberta"),Crt.forEach(t),Zeo=r(RAe," \u2014 "),YR=n(RAe,"A",{href:!0});var wrt=s(YR);eoo=r(wrt,"RobertaConfig"),wrt.forEach(t),ooo=r(RAe," (RoBERTa model)"),RAe.forEach(t),roo=i(L),mg=n(L,"LI",{});var PAe=s(mg);Lne=n(PAe,"STRONG",{});var Art=s(Lne);too=r(Art,"roformer"),Art.forEach(t),aoo=r(PAe," \u2014 "),KR=n(PAe,"A",{href:!0});var Lrt=s(KR);noo=r(Lrt,"RoFormerConfig"),Lrt.forEach(t),soo=r(PAe," (RoFormer model)"),PAe.forEach(t),loo=i(L),gg=n(L,"LI",{});var BAe=s(gg);yne=n(BAe,"STRONG",{});var yrt=s(yne);ioo=r(yrt,"segformer"),yrt.forEach(t),doo=r(BAe," \u2014 "),ZR=n(BAe,"A",{href:!0});var xrt=s(ZR);coo=r(xrt,"SegformerConfig"),xrt.forEach(t),foo=r(BAe," (SegFormer model)"),BAe.forEach(t),moo=i(L),hg=n(L,"LI",{});var IAe=s(hg);xne=n(IAe,"STRONG",{});var $rt=s(xne);goo=r($rt,"sew"),$rt.forEach(t),hoo=r(IAe," \u2014 "),eP=n(IAe,"A",{href:!0});var krt=s(eP);poo=r(krt,"SEWConfig"),krt.forEach(t),_oo=r(IAe," (SEW model)"),IAe.forEach(t),uoo=i(L),pg=n(L,"LI",{});var NAe=s(pg);$ne=n(NAe,"STRONG",{});var Srt=s($ne);boo=r(Srt,"sew-d"),Srt.forEach(t),voo=r(NAe," \u2014 "),oP=n(NAe,"A",{href:!0});var Rrt=s(oP);Foo=r(Rrt,"SEWDConfig"),Rrt.forEach(t),Too=r(NAe," (SEW-D model)"),NAe.forEach(t),Moo=i(L),_g=n(L,"LI",{});var qAe=s(_g);kne=n(qAe,"STRONG",{});var Prt=s(kne);Eoo=r(Prt,"speech-encoder-decoder"),Prt.forEach(t),Coo=r(qAe," \u2014 "),rP=n(qAe,"A",{href:!0});var Brt=s(rP);woo=r(Brt,"SpeechEncoderDecoderConfig"),Brt.forEach(t),Aoo=r(qAe," (Speech Encoder decoder model)"),qAe.forEach(t),Loo=i(L),ug=n(L,"LI",{});var jAe=s(ug);Sne=n(jAe,"STRONG",{});var Irt=s(Sne);yoo=r(Irt,"speech_to_text"),Irt.forEach(t),xoo=r(jAe," \u2014 "),tP=n(jAe,"A",{href:!0});var Nrt=s(tP);$oo=r(Nrt,"Speech2TextConfig"),Nrt.forEach(t),koo=r(jAe," (Speech2Text model)"),jAe.forEach(t),Soo=i(L),bg=n(L,"LI",{});var DAe=s(bg);Rne=n(DAe,"STRONG",{});var qrt=s(Rne);Roo=r(qrt,"speech_to_text_2"),qrt.forEach(t),Poo=r(DAe," \u2014 "),aP=n(DAe,"A",{href:!0});var jrt=s(aP);Boo=r(jrt,"Speech2Text2Config"),jrt.forEach(t),Ioo=r(DAe," (Speech2Text2 model)"),DAe.forEach(t),Noo=i(L),vg=n(L,"LI",{});var GAe=s(vg);Pne=n(GAe,"STRONG",{});var Drt=s(Pne);qoo=r(Drt,"splinter"),Drt.forEach(t),joo=r(GAe," \u2014 "),nP=n(GAe,"A",{href:!0});var Grt=s(nP);Doo=r(Grt,"SplinterConfig"),Grt.forEach(t),Goo=r(GAe," (Splinter model)"),GAe.forEach(t),Ooo=i(L),Fg=n(L,"LI",{});var OAe=s(Fg);Bne=n(OAe,"STRONG",{});var Ort=s(Bne);Voo=r(Ort,"squeezebert"),Ort.forEach(t),Xoo=r(OAe," \u2014 "),sP=n(OAe,"A",{href:!0});var Vrt=s(sP);zoo=r(Vrt,"SqueezeBertConfig"),Vrt.forEach(t),Woo=r(OAe," (SqueezeBERT model)"),OAe.forEach(t),Qoo=i(L),Tg=n(L,"LI",{});var VAe=s(Tg);Ine=n(VAe,"STRONG",{});var Xrt=s(Ine);Hoo=r(Xrt,"swin"),Xrt.forEach(t),Uoo=r(VAe," \u2014 "),lP=n(VAe,"A",{href:!0});var zrt=s(lP);Joo=r(zrt,"SwinConfig"),zrt.forEach(t),Yoo=r(VAe," (Swin Transformer model)"),VAe.forEach(t),Koo=i(L),Mg=n(L,"LI",{});var XAe=s(Mg);Nne=n(XAe,"STRONG",{});var Wrt=s(Nne);Zoo=r(Wrt,"t5"),Wrt.forEach(t),ero=r(XAe," \u2014 "),iP=n(XAe,"A",{href:!0});var Qrt=s(iP);oro=r(Qrt,"T5Config"),Qrt.forEach(t),rro=r(XAe," (T5 model)"),XAe.forEach(t),tro=i(L),Eg=n(L,"LI",{});var zAe=s(Eg);qne=n(zAe,"STRONG",{});var Hrt=s(qne);aro=r(Hrt,"tapas"),Hrt.forEach(t),nro=r(zAe," \u2014 "),dP=n(zAe,"A",{href:!0});var Urt=s(dP);sro=r(Urt,"TapasConfig"),Urt.forEach(t),lro=r(zAe," (TAPAS model)"),zAe.forEach(t),iro=i(L),Cg=n(L,"LI",{});var WAe=s(Cg);jne=n(WAe,"STRONG",{});var Jrt=s(jne);dro=r(Jrt,"trajectory_transformer"),Jrt.forEach(t),cro=r(WAe," \u2014 "),cP=n(WAe,"A",{href:!0});var Yrt=s(cP);fro=r(Yrt,"TrajectoryTransformerConfig"),Yrt.forEach(t),mro=r(WAe," (Trajectory Transformer model)"),WAe.forEach(t),gro=i(L),wg=n(L,"LI",{});var QAe=s(wg);Dne=n(QAe,"STRONG",{});var Krt=s(Dne);hro=r(Krt,"transfo-xl"),Krt.forEach(t),pro=r(QAe," \u2014 "),fP=n(QAe,"A",{href:!0});var Zrt=s(fP);_ro=r(Zrt,"TransfoXLConfig"),Zrt.forEach(t),uro=r(QAe," (Transformer-XL model)"),QAe.forEach(t),bro=i(L),Ag=n(L,"LI",{});var HAe=s(Ag);Gne=n(HAe,"STRONG",{});var ett=s(Gne);vro=r(ett,"trocr"),ett.forEach(t),Fro=r(HAe," \u2014 "),mP=n(HAe,"A",{href:!0});var ott=s(mP);Tro=r(ott,"TrOCRConfig"),ott.forEach(t),Mro=r(HAe," (TrOCR model)"),HAe.forEach(t),Ero=i(L),Lg=n(L,"LI",{});var UAe=s(Lg);One=n(UAe,"STRONG",{});var rtt=s(One);Cro=r(rtt,"unispeech"),rtt.forEach(t),wro=r(UAe," \u2014 "),gP=n(UAe,"A",{href:!0});var ttt=s(gP);Aro=r(ttt,"UniSpeechConfig"),ttt.forEach(t),Lro=r(UAe," (UniSpeech model)"),UAe.forEach(t),yro=i(L),yg=n(L,"LI",{});var JAe=s(yg);Vne=n(JAe,"STRONG",{});var att=s(Vne);xro=r(att,"unispeech-sat"),att.forEach(t),$ro=r(JAe," \u2014 "),hP=n(JAe,"A",{href:!0});var ntt=s(hP);kro=r(ntt,"UniSpeechSatConfig"),ntt.forEach(t),Sro=r(JAe," (UniSpeechSat model)"),JAe.forEach(t),Rro=i(L),xg=n(L,"LI",{});var YAe=s(xg);Xne=n(YAe,"STRONG",{});var stt=s(Xne);Pro=r(stt,"van"),stt.forEach(t),Bro=r(YAe," \u2014 "),pP=n(YAe,"A",{href:!0});var ltt=s(pP);Iro=r(ltt,"VanConfig"),ltt.forEach(t),Nro=r(YAe," (VAN model)"),YAe.forEach(t),qro=i(L),$g=n(L,"LI",{});var KAe=s($g);zne=n(KAe,"STRONG",{});var itt=s(zne);jro=r(itt,"vilt"),itt.forEach(t),Dro=r(KAe," \u2014 "),_P=n(KAe,"A",{href:!0});var dtt=s(_P);Gro=r(dtt,"ViltConfig"),dtt.forEach(t),Oro=r(KAe," (ViLT model)"),KAe.forEach(t),Vro=i(L),kg=n(L,"LI",{});var ZAe=s(kg);Wne=n(ZAe,"STRONG",{});var ctt=s(Wne);Xro=r(ctt,"vision-encoder-decoder"),ctt.forEach(t),zro=r(ZAe," \u2014 "),uP=n(ZAe,"A",{href:!0});var ftt=s(uP);Wro=r(ftt,"VisionEncoderDecoderConfig"),ftt.forEach(t),Qro=r(ZAe," (Vision Encoder decoder model)"),ZAe.forEach(t),Hro=i(L),Sg=n(L,"LI",{});var eLe=s(Sg);Qne=n(eLe,"STRONG",{});var mtt=s(Qne);Uro=r(mtt,"vision-text-dual-encoder"),mtt.forEach(t),Jro=r(eLe," \u2014 "),bP=n(eLe,"A",{href:!0});var gtt=s(bP);Yro=r(gtt,"VisionTextDualEncoderConfig"),gtt.forEach(t),Kro=r(eLe," (VisionTextDualEncoder model)"),eLe.forEach(t),Zro=i(L),Rg=n(L,"LI",{});var oLe=s(Rg);Hne=n(oLe,"STRONG",{});var htt=s(Hne);eto=r(htt,"visual_bert"),htt.forEach(t),oto=r(oLe," \u2014 "),vP=n(oLe,"A",{href:!0});var ptt=s(vP);rto=r(ptt,"VisualBertConfig"),ptt.forEach(t),tto=r(oLe," (VisualBERT model)"),oLe.forEach(t),ato=i(L),Pg=n(L,"LI",{});var rLe=s(Pg);Une=n(rLe,"STRONG",{});var _tt=s(Une);nto=r(_tt,"vit"),_tt.forEach(t),sto=r(rLe," \u2014 "),FP=n(rLe,"A",{href:!0});var utt=s(FP);lto=r(utt,"ViTConfig"),utt.forEach(t),ito=r(rLe," (ViT model)"),rLe.forEach(t),dto=i(L),Bg=n(L,"LI",{});var tLe=s(Bg);Jne=n(tLe,"STRONG",{});var btt=s(Jne);cto=r(btt,"vit_mae"),btt.forEach(t),fto=r(tLe," \u2014 "),TP=n(tLe,"A",{href:!0});var vtt=s(TP);mto=r(vtt,"ViTMAEConfig"),vtt.forEach(t),gto=r(tLe," (ViTMAE model)"),tLe.forEach(t),hto=i(L),Ig=n(L,"LI",{});var aLe=s(Ig);Yne=n(aLe,"STRONG",{});var Ftt=s(Yne);pto=r(Ftt,"wav2vec2"),Ftt.forEach(t),_to=r(aLe," \u2014 "),MP=n(aLe,"A",{href:!0});var Ttt=s(MP);uto=r(Ttt,"Wav2Vec2Config"),Ttt.forEach(t),bto=r(aLe," (Wav2Vec2 model)"),aLe.forEach(t),vto=i(L),Ng=n(L,"LI",{});var nLe=s(Ng);Kne=n(nLe,"STRONG",{});var Mtt=s(Kne);Fto=r(Mtt,"wav2vec2-conformer"),Mtt.forEach(t),Tto=r(nLe," \u2014 "),EP=n(nLe,"A",{href:!0});var Ett=s(EP);Mto=r(Ett,"Wav2Vec2ConformerConfig"),Ett.forEach(t),Eto=r(nLe," (Wav2Vec2-Conformer model)"),nLe.forEach(t),Cto=i(L),qg=n(L,"LI",{});var sLe=s(qg);Zne=n(sLe,"STRONG",{});var Ctt=s(Zne);wto=r(Ctt,"wavlm"),Ctt.forEach(t),Ato=r(sLe," \u2014 "),CP=n(sLe,"A",{href:!0});var wtt=s(CP);Lto=r(wtt,"WavLMConfig"),wtt.forEach(t),yto=r(sLe," (WavLM model)"),sLe.forEach(t),xto=i(L),jg=n(L,"LI",{});var lLe=s(jg);ese=n(lLe,"STRONG",{});var Att=s(ese);$to=r(Att,"xglm"),Att.forEach(t),kto=r(lLe," \u2014 "),wP=n(lLe,"A",{href:!0});var Ltt=s(wP);Sto=r(Ltt,"XGLMConfig"),Ltt.forEach(t),Rto=r(lLe," (XGLM model)"),lLe.forEach(t),Pto=i(L),Dg=n(L,"LI",{});var iLe=s(Dg);ose=n(iLe,"STRONG",{});var ytt=s(ose);Bto=r(ytt,"xlm"),ytt.forEach(t),Ito=r(iLe," \u2014 "),AP=n(iLe,"A",{href:!0});var xtt=s(AP);Nto=r(xtt,"XLMConfig"),xtt.forEach(t),qto=r(iLe," (XLM model)"),iLe.forEach(t),jto=i(L),Gg=n(L,"LI",{});var dLe=s(Gg);rse=n(dLe,"STRONG",{});var $tt=s(rse);Dto=r($tt,"xlm-prophetnet"),$tt.forEach(t),Gto=r(dLe," \u2014 "),LP=n(dLe,"A",{href:!0});var ktt=s(LP);Oto=r(ktt,"XLMProphetNetConfig"),ktt.forEach(t),Vto=r(dLe," (XLM-ProphetNet model)"),dLe.forEach(t),Xto=i(L),Og=n(L,"LI",{});var cLe=s(Og);tse=n(cLe,"STRONG",{});var Stt=s(tse);zto=r(Stt,"xlm-roberta"),Stt.forEach(t),Wto=r(cLe," \u2014 "),yP=n(cLe,"A",{href:!0});var Rtt=s(yP);Qto=r(Rtt,"XLMRobertaConfig"),Rtt.forEach(t),Hto=r(cLe," (XLM-RoBERTa model)"),cLe.forEach(t),Uto=i(L),Vg=n(L,"LI",{});var fLe=s(Vg);ase=n(fLe,"STRONG",{});var Ptt=s(ase);Jto=r(Ptt,"xlm-roberta-xl"),Ptt.forEach(t),Yto=r(fLe," \u2014 "),xP=n(fLe,"A",{href:!0});var Btt=s(xP);Kto=r(Btt,"XLMRobertaXLConfig"),Btt.forEach(t),Zto=r(fLe," (XLM-RoBERTa-XL model)"),fLe.forEach(t),eao=i(L),Xg=n(L,"LI",{});var mLe=s(Xg);nse=n(mLe,"STRONG",{});var Itt=s(nse);oao=r(Itt,"xlnet"),Itt.forEach(t),rao=r(mLe," \u2014 "),$P=n(mLe,"A",{href:!0});var Ntt=s($P);tao=r(Ntt,"XLNetConfig"),Ntt.forEach(t),aao=r(mLe," (XLNet model)"),mLe.forEach(t),nao=i(L),zg=n(L,"LI",{});var gLe=s(zg);sse=n(gLe,"STRONG",{});var qtt=s(sse);sao=r(qtt,"yolos"),qtt.forEach(t),lao=r(gLe," \u2014 "),kP=n(gLe,"A",{href:!0});var jtt=s(kP);iao=r(jtt,"YolosConfig"),jtt.forEach(t),dao=r(gLe," (YOLOS model)"),gLe.forEach(t),cao=i(L),Wg=n(L,"LI",{});var hLe=s(Wg);lse=n(hLe,"STRONG",{});var Dtt=s(lse);fao=r(Dtt,"yoso"),Dtt.forEach(t),mao=r(hLe," \u2014 "),SP=n(hLe,"A",{href:!0});var Gtt=s(SP);gao=r(Gtt,"YosoConfig"),Gtt.forEach(t),hao=r(hLe," (YOSO model)"),hLe.forEach(t),L.forEach(t),pao=i(at),T(Qg.$$.fragment,at),at.forEach(t),_ao=i(tt),Hg=n(tt,"DIV",{class:!0});var WXe=s(Hg);T(UA.$$.fragment,WXe),uao=i(WXe),ise=n(WXe,"P",{});var Ott=s(ise);bao=r(Ott,"Register a new configuration for this class."),Ott.forEach(t),WXe.forEach(t),tt.forEach(t),QOe=i(f),Bi=n(f,"H2",{class:!0});var QXe=s(Bi);Ug=n(QXe,"A",{id:!0,class:!0,href:!0});var Vtt=s(Ug);dse=n(Vtt,"SPAN",{});var Xtt=s(dse);T(JA.$$.fragment,Xtt),Xtt.forEach(t),Vtt.forEach(t),vao=i(QXe),cse=n(QXe,"SPAN",{});var ztt=s(cse);Fao=r(ztt,"AutoTokenizer"),ztt.forEach(t),QXe.forEach(t),HOe=i(f),Ao=n(f,"DIV",{class:!0});var Ys=s(Ao);T(YA.$$.fragment,Ys),Tao=i(Ys),KA=n(Ys,"P",{});var HXe=s(KA);Mao=r(HXe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),RP=n(HXe,"A",{href:!0});var Wtt=s(RP);Eao=r(Wtt,"AutoTokenizer.from_pretrained()"),Wtt.forEach(t),Cao=r(HXe," class method."),HXe.forEach(t),wao=i(Ys),ZA=n(Ys,"P",{});var UXe=s(ZA);Aao=r(UXe,"This class cannot be instantiated directly using "),fse=n(UXe,"CODE",{});var Qtt=s(fse);Lao=r(Qtt,"__init__()"),Qtt.forEach(t),yao=r(UXe," (throws an error)."),UXe.forEach(t),xao=i(Ys),yr=n(Ys,"DIV",{class:!0});var Ks=s(yr);T(eL.$$.fragment,Ks),$ao=i(Ks),mse=n(Ks,"P",{});var Htt=s(mse);kao=r(Htt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Htt.forEach(t),Sao=i(Ks),Ra=n(Ks,"P",{});var V5=s(Ra);Rao=r(V5,"The tokenizer class to instantiate is selected based on the "),gse=n(V5,"CODE",{});var Utt=s(gse);Pao=r(Utt,"model_type"),Utt.forEach(t),Bao=r(V5,` property of the config object (either
passed as an argument or loaded from `),hse=n(V5,"CODE",{});var Jtt=s(hse);Iao=r(Jtt,"pretrained_model_name_or_path"),Jtt.forEach(t),Nao=r(V5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pse=n(V5,"CODE",{});var Ytt=s(pse);qao=r(Ytt,"pretrained_model_name_or_path"),Ytt.forEach(t),jao=r(V5,":"),V5.forEach(t),Dao=i(Ks),k=n(Ks,"UL",{});var S=s(k);jn=n(S,"LI",{});var sk=s(jn);_se=n(sk,"STRONG",{});var Ktt=s(_se);Gao=r(Ktt,"albert"),Ktt.forEach(t),Oao=r(sk," \u2014 "),PP=n(sk,"A",{href:!0});var Ztt=s(PP);Vao=r(Ztt,"AlbertTokenizer"),Ztt.forEach(t),Xao=r(sk," or "),BP=n(sk,"A",{href:!0});var eat=s(BP);zao=r(eat,"AlbertTokenizerFast"),eat.forEach(t),Wao=r(sk," (ALBERT model)"),sk.forEach(t),Qao=i(S),Dn=n(S,"LI",{});var lk=s(Dn);use=n(lk,"STRONG",{});var oat=s(use);Hao=r(oat,"bart"),oat.forEach(t),Uao=r(lk," \u2014 "),IP=n(lk,"A",{href:!0});var rat=s(IP);Jao=r(rat,"BartTokenizer"),rat.forEach(t),Yao=r(lk," or "),NP=n(lk,"A",{href:!0});var tat=s(NP);Kao=r(tat,"BartTokenizerFast"),tat.forEach(t),Zao=r(lk," (BART model)"),lk.forEach(t),eno=i(S),Gn=n(S,"LI",{});var ik=s(Gn);bse=n(ik,"STRONG",{});var aat=s(bse);ono=r(aat,"barthez"),aat.forEach(t),rno=r(ik," \u2014 "),qP=n(ik,"A",{href:!0});var nat=s(qP);tno=r(nat,"BarthezTokenizer"),nat.forEach(t),ano=r(ik," or "),jP=n(ik,"A",{href:!0});var sat=s(jP);nno=r(sat,"BarthezTokenizerFast"),sat.forEach(t),sno=r(ik," (BARThez model)"),ik.forEach(t),lno=i(S),Jg=n(S,"LI",{});var pLe=s(Jg);vse=n(pLe,"STRONG",{});var lat=s(vse);ino=r(lat,"bartpho"),lat.forEach(t),dno=r(pLe," \u2014 "),DP=n(pLe,"A",{href:!0});var iat=s(DP);cno=r(iat,"BartphoTokenizer"),iat.forEach(t),fno=r(pLe," (BARTpho model)"),pLe.forEach(t),mno=i(S),On=n(S,"LI",{});var dk=s(On);Fse=n(dk,"STRONG",{});var dat=s(Fse);gno=r(dat,"bert"),dat.forEach(t),hno=r(dk," \u2014 "),GP=n(dk,"A",{href:!0});var cat=s(GP);pno=r(cat,"BertTokenizer"),cat.forEach(t),_no=r(dk," or "),OP=n(dk,"A",{href:!0});var fat=s(OP);uno=r(fat,"BertTokenizerFast"),fat.forEach(t),bno=r(dk," (BERT model)"),dk.forEach(t),vno=i(S),Yg=n(S,"LI",{});var _Le=s(Yg);Tse=n(_Le,"STRONG",{});var mat=s(Tse);Fno=r(mat,"bert-generation"),mat.forEach(t),Tno=r(_Le," \u2014 "),VP=n(_Le,"A",{href:!0});var gat=s(VP);Mno=r(gat,"BertGenerationTokenizer"),gat.forEach(t),Eno=r(_Le," (Bert Generation model)"),_Le.forEach(t),Cno=i(S),Kg=n(S,"LI",{});var uLe=s(Kg);Mse=n(uLe,"STRONG",{});var hat=s(Mse);wno=r(hat,"bert-japanese"),hat.forEach(t),Ano=r(uLe," \u2014 "),XP=n(uLe,"A",{href:!0});var pat=s(XP);Lno=r(pat,"BertJapaneseTokenizer"),pat.forEach(t),yno=r(uLe," (BertJapanese model)"),uLe.forEach(t),xno=i(S),Zg=n(S,"LI",{});var bLe=s(Zg);Ese=n(bLe,"STRONG",{});var _at=s(Ese);$no=r(_at,"bertweet"),_at.forEach(t),kno=r(bLe," \u2014 "),zP=n(bLe,"A",{href:!0});var uat=s(zP);Sno=r(uat,"BertweetTokenizer"),uat.forEach(t),Rno=r(bLe," (BERTweet model)"),bLe.forEach(t),Pno=i(S),Vn=n(S,"LI",{});var ck=s(Vn);Cse=n(ck,"STRONG",{});var bat=s(Cse);Bno=r(bat,"big_bird"),bat.forEach(t),Ino=r(ck," \u2014 "),WP=n(ck,"A",{href:!0});var vat=s(WP);Nno=r(vat,"BigBirdTokenizer"),vat.forEach(t),qno=r(ck," or "),QP=n(ck,"A",{href:!0});var Fat=s(QP);jno=r(Fat,"BigBirdTokenizerFast"),Fat.forEach(t),Dno=r(ck," (BigBird model)"),ck.forEach(t),Gno=i(S),Xn=n(S,"LI",{});var fk=s(Xn);wse=n(fk,"STRONG",{});var Tat=s(wse);Ono=r(Tat,"bigbird_pegasus"),Tat.forEach(t),Vno=r(fk," \u2014 "),HP=n(fk,"A",{href:!0});var Mat=s(HP);Xno=r(Mat,"PegasusTokenizer"),Mat.forEach(t),zno=r(fk," or "),UP=n(fk,"A",{href:!0});var Eat=s(UP);Wno=r(Eat,"PegasusTokenizerFast"),Eat.forEach(t),Qno=r(fk," (BigBird-Pegasus model)"),fk.forEach(t),Hno=i(S),zn=n(S,"LI",{});var mk=s(zn);Ase=n(mk,"STRONG",{});var Cat=s(Ase);Uno=r(Cat,"blenderbot"),Cat.forEach(t),Jno=r(mk," \u2014 "),JP=n(mk,"A",{href:!0});var wat=s(JP);Yno=r(wat,"BlenderbotTokenizer"),wat.forEach(t),Kno=r(mk," or "),YP=n(mk,"A",{href:!0});var Aat=s(YP);Zno=r(Aat,"BlenderbotTokenizerFast"),Aat.forEach(t),eso=r(mk," (Blenderbot model)"),mk.forEach(t),oso=i(S),eh=n(S,"LI",{});var vLe=s(eh);Lse=n(vLe,"STRONG",{});var Lat=s(Lse);rso=r(Lat,"blenderbot-small"),Lat.forEach(t),tso=r(vLe," \u2014 "),KP=n(vLe,"A",{href:!0});var yat=s(KP);aso=r(yat,"BlenderbotSmallTokenizer"),yat.forEach(t),nso=r(vLe," (BlenderbotSmall model)"),vLe.forEach(t),sso=i(S),oh=n(S,"LI",{});var FLe=s(oh);yse=n(FLe,"STRONG",{});var xat=s(yse);lso=r(xat,"bloom"),xat.forEach(t),iso=r(FLe," \u2014 "),ZP=n(FLe,"A",{href:!0});var $at=s(ZP);dso=r($at,"BloomTokenizerFast"),$at.forEach(t),cso=r(FLe," (BLOOM model)"),FLe.forEach(t),fso=i(S),rh=n(S,"LI",{});var TLe=s(rh);xse=n(TLe,"STRONG",{});var kat=s(xse);mso=r(kat,"byt5"),kat.forEach(t),gso=r(TLe," \u2014 "),eB=n(TLe,"A",{href:!0});var Sat=s(eB);hso=r(Sat,"ByT5Tokenizer"),Sat.forEach(t),pso=r(TLe," (ByT5 model)"),TLe.forEach(t),_so=i(S),Wn=n(S,"LI",{});var gk=s(Wn);$se=n(gk,"STRONG",{});var Rat=s($se);uso=r(Rat,"camembert"),Rat.forEach(t),bso=r(gk," \u2014 "),oB=n(gk,"A",{href:!0});var Pat=s(oB);vso=r(Pat,"CamembertTokenizer"),Pat.forEach(t),Fso=r(gk," or "),rB=n(gk,"A",{href:!0});var Bat=s(rB);Tso=r(Bat,"CamembertTokenizerFast"),Bat.forEach(t),Mso=r(gk," (CamemBERT model)"),gk.forEach(t),Eso=i(S),th=n(S,"LI",{});var MLe=s(th);kse=n(MLe,"STRONG",{});var Iat=s(kse);Cso=r(Iat,"canine"),Iat.forEach(t),wso=r(MLe," \u2014 "),tB=n(MLe,"A",{href:!0});var Nat=s(tB);Aso=r(Nat,"CanineTokenizer"),Nat.forEach(t),Lso=r(MLe," (CANINE model)"),MLe.forEach(t),yso=i(S),Qn=n(S,"LI",{});var hk=s(Qn);Sse=n(hk,"STRONG",{});var qat=s(Sse);xso=r(qat,"clip"),qat.forEach(t),$so=r(hk," \u2014 "),aB=n(hk,"A",{href:!0});var jat=s(aB);kso=r(jat,"CLIPTokenizer"),jat.forEach(t),Sso=r(hk," or "),nB=n(hk,"A",{href:!0});var Dat=s(nB);Rso=r(Dat,"CLIPTokenizerFast"),Dat.forEach(t),Pso=r(hk," (CLIP model)"),hk.forEach(t),Bso=i(S),Hn=n(S,"LI",{});var pk=s(Hn);Rse=n(pk,"STRONG",{});var Gat=s(Rse);Iso=r(Gat,"codegen"),Gat.forEach(t),Nso=r(pk," \u2014 "),sB=n(pk,"A",{href:!0});var Oat=s(sB);qso=r(Oat,"CodeGenTokenizer"),Oat.forEach(t),jso=r(pk," or "),lB=n(pk,"A",{href:!0});var Vat=s(lB);Dso=r(Vat,"CodeGenTokenizerFast"),Vat.forEach(t),Gso=r(pk," (CodeGen model)"),pk.forEach(t),Oso=i(S),Un=n(S,"LI",{});var _k=s(Un);Pse=n(_k,"STRONG",{});var Xat=s(Pse);Vso=r(Xat,"convbert"),Xat.forEach(t),Xso=r(_k," \u2014 "),iB=n(_k,"A",{href:!0});var zat=s(iB);zso=r(zat,"ConvBertTokenizer"),zat.forEach(t),Wso=r(_k," or "),dB=n(_k,"A",{href:!0});var Wat=s(dB);Qso=r(Wat,"ConvBertTokenizerFast"),Wat.forEach(t),Hso=r(_k," (ConvBERT model)"),_k.forEach(t),Uso=i(S),Jn=n(S,"LI",{});var uk=s(Jn);Bse=n(uk,"STRONG",{});var Qat=s(Bse);Jso=r(Qat,"cpm"),Qat.forEach(t),Yso=r(uk," \u2014 "),cB=n(uk,"A",{href:!0});var Hat=s(cB);Kso=r(Hat,"CpmTokenizer"),Hat.forEach(t),Zso=r(uk," or "),fB=n(uk,"A",{href:!0});var Uat=s(fB);elo=r(Uat,"CpmTokenizerFast"),Uat.forEach(t),olo=r(uk," (CPM model)"),uk.forEach(t),rlo=i(S),ah=n(S,"LI",{});var ELe=s(ah);Ise=n(ELe,"STRONG",{});var Jat=s(Ise);tlo=r(Jat,"ctrl"),Jat.forEach(t),alo=r(ELe," \u2014 "),mB=n(ELe,"A",{href:!0});var Yat=s(mB);nlo=r(Yat,"CTRLTokenizer"),Yat.forEach(t),slo=r(ELe," (CTRL model)"),ELe.forEach(t),llo=i(S),Yn=n(S,"LI",{});var bk=s(Yn);Nse=n(bk,"STRONG",{});var Kat=s(Nse);ilo=r(Kat,"data2vec-text"),Kat.forEach(t),dlo=r(bk," \u2014 "),gB=n(bk,"A",{href:!0});var Zat=s(gB);clo=r(Zat,"RobertaTokenizer"),Zat.forEach(t),flo=r(bk," or "),hB=n(bk,"A",{href:!0});var ent=s(hB);mlo=r(ent,"RobertaTokenizerFast"),ent.forEach(t),glo=r(bk," (Data2VecText model)"),bk.forEach(t),hlo=i(S),Kn=n(S,"LI",{});var vk=s(Kn);qse=n(vk,"STRONG",{});var ont=s(qse);plo=r(ont,"deberta"),ont.forEach(t),_lo=r(vk," \u2014 "),pB=n(vk,"A",{href:!0});var rnt=s(pB);ulo=r(rnt,"DebertaTokenizer"),rnt.forEach(t),blo=r(vk," or "),_B=n(vk,"A",{href:!0});var tnt=s(_B);vlo=r(tnt,"DebertaTokenizerFast"),tnt.forEach(t),Flo=r(vk," (DeBERTa model)"),vk.forEach(t),Tlo=i(S),Zn=n(S,"LI",{});var Fk=s(Zn);jse=n(Fk,"STRONG",{});var ant=s(jse);Mlo=r(ant,"deberta-v2"),ant.forEach(t),Elo=r(Fk," \u2014 "),uB=n(Fk,"A",{href:!0});var nnt=s(uB);Clo=r(nnt,"DebertaV2Tokenizer"),nnt.forEach(t),wlo=r(Fk," or "),bB=n(Fk,"A",{href:!0});var snt=s(bB);Alo=r(snt,"DebertaV2TokenizerFast"),snt.forEach(t),Llo=r(Fk," (DeBERTa-v2 model)"),Fk.forEach(t),ylo=i(S),es=n(S,"LI",{});var Tk=s(es);Dse=n(Tk,"STRONG",{});var lnt=s(Dse);xlo=r(lnt,"distilbert"),lnt.forEach(t),$lo=r(Tk," \u2014 "),vB=n(Tk,"A",{href:!0});var int=s(vB);klo=r(int,"DistilBertTokenizer"),int.forEach(t),Slo=r(Tk," or "),FB=n(Tk,"A",{href:!0});var dnt=s(FB);Rlo=r(dnt,"DistilBertTokenizerFast"),dnt.forEach(t),Plo=r(Tk," (DistilBERT model)"),Tk.forEach(t),Blo=i(S),os=n(S,"LI",{});var Mk=s(os);Gse=n(Mk,"STRONG",{});var cnt=s(Gse);Ilo=r(cnt,"dpr"),cnt.forEach(t),Nlo=r(Mk," \u2014 "),TB=n(Mk,"A",{href:!0});var fnt=s(TB);qlo=r(fnt,"DPRQuestionEncoderTokenizer"),fnt.forEach(t),jlo=r(Mk," or "),MB=n(Mk,"A",{href:!0});var mnt=s(MB);Dlo=r(mnt,"DPRQuestionEncoderTokenizerFast"),mnt.forEach(t),Glo=r(Mk," (DPR model)"),Mk.forEach(t),Olo=i(S),rs=n(S,"LI",{});var Ek=s(rs);Ose=n(Ek,"STRONG",{});var gnt=s(Ose);Vlo=r(gnt,"electra"),gnt.forEach(t),Xlo=r(Ek," \u2014 "),EB=n(Ek,"A",{href:!0});var hnt=s(EB);zlo=r(hnt,"ElectraTokenizer"),hnt.forEach(t),Wlo=r(Ek," or "),CB=n(Ek,"A",{href:!0});var pnt=s(CB);Qlo=r(pnt,"ElectraTokenizerFast"),pnt.forEach(t),Hlo=r(Ek," (ELECTRA model)"),Ek.forEach(t),Ulo=i(S),nh=n(S,"LI",{});var CLe=s(nh);Vse=n(CLe,"STRONG",{});var _nt=s(Vse);Jlo=r(_nt,"flaubert"),_nt.forEach(t),Ylo=r(CLe," \u2014 "),wB=n(CLe,"A",{href:!0});var unt=s(wB);Klo=r(unt,"FlaubertTokenizer"),unt.forEach(t),Zlo=r(CLe," (FlauBERT model)"),CLe.forEach(t),eio=i(S),ts=n(S,"LI",{});var Ck=s(ts);Xse=n(Ck,"STRONG",{});var bnt=s(Xse);oio=r(bnt,"fnet"),bnt.forEach(t),rio=r(Ck," \u2014 "),AB=n(Ck,"A",{href:!0});var vnt=s(AB);tio=r(vnt,"FNetTokenizer"),vnt.forEach(t),aio=r(Ck," or "),LB=n(Ck,"A",{href:!0});var Fnt=s(LB);nio=r(Fnt,"FNetTokenizerFast"),Fnt.forEach(t),sio=r(Ck," (FNet model)"),Ck.forEach(t),lio=i(S),sh=n(S,"LI",{});var wLe=s(sh);zse=n(wLe,"STRONG",{});var Tnt=s(zse);iio=r(Tnt,"fsmt"),Tnt.forEach(t),dio=r(wLe," \u2014 "),yB=n(wLe,"A",{href:!0});var Mnt=s(yB);cio=r(Mnt,"FSMTTokenizer"),Mnt.forEach(t),fio=r(wLe," (FairSeq Machine-Translation model)"),wLe.forEach(t),mio=i(S),as=n(S,"LI",{});var wk=s(as);Wse=n(wk,"STRONG",{});var Ent=s(Wse);gio=r(Ent,"funnel"),Ent.forEach(t),hio=r(wk," \u2014 "),xB=n(wk,"A",{href:!0});var Cnt=s(xB);pio=r(Cnt,"FunnelTokenizer"),Cnt.forEach(t),_io=r(wk," or "),$B=n(wk,"A",{href:!0});var wnt=s($B);uio=r(wnt,"FunnelTokenizerFast"),wnt.forEach(t),bio=r(wk," (Funnel Transformer model)"),wk.forEach(t),vio=i(S),ns=n(S,"LI",{});var Ak=s(ns);Qse=n(Ak,"STRONG",{});var Ant=s(Qse);Fio=r(Ant,"gpt2"),Ant.forEach(t),Tio=r(Ak," \u2014 "),kB=n(Ak,"A",{href:!0});var Lnt=s(kB);Mio=r(Lnt,"GPT2Tokenizer"),Lnt.forEach(t),Eio=r(Ak," or "),SB=n(Ak,"A",{href:!0});var ynt=s(SB);Cio=r(ynt,"GPT2TokenizerFast"),ynt.forEach(t),wio=r(Ak," (OpenAI GPT-2 model)"),Ak.forEach(t),Aio=i(S),ss=n(S,"LI",{});var Lk=s(ss);Hse=n(Lk,"STRONG",{});var xnt=s(Hse);Lio=r(xnt,"gpt_neo"),xnt.forEach(t),yio=r(Lk," \u2014 "),RB=n(Lk,"A",{href:!0});var $nt=s(RB);xio=r($nt,"GPT2Tokenizer"),$nt.forEach(t),$io=r(Lk," or "),PB=n(Lk,"A",{href:!0});var knt=s(PB);kio=r(knt,"GPT2TokenizerFast"),knt.forEach(t),Sio=r(Lk," (GPT Neo model)"),Lk.forEach(t),Rio=i(S),lh=n(S,"LI",{});var ALe=s(lh);Use=n(ALe,"STRONG",{});var Snt=s(Use);Pio=r(Snt,"gpt_neox"),Snt.forEach(t),Bio=r(ALe," \u2014 "),BB=n(ALe,"A",{href:!0});var Rnt=s(BB);Iio=r(Rnt,"GPTNeoXTokenizerFast"),Rnt.forEach(t),Nio=r(ALe," (GPT NeoX model)"),ALe.forEach(t),qio=i(S),ls=n(S,"LI",{});var yk=s(ls);Jse=n(yk,"STRONG",{});var Pnt=s(Jse);jio=r(Pnt,"gptj"),Pnt.forEach(t),Dio=r(yk," \u2014 "),IB=n(yk,"A",{href:!0});var Bnt=s(IB);Gio=r(Bnt,"GPT2Tokenizer"),Bnt.forEach(t),Oio=r(yk," or "),NB=n(yk,"A",{href:!0});var Int=s(NB);Vio=r(Int,"GPT2TokenizerFast"),Int.forEach(t),Xio=r(yk," (GPT-J model)"),yk.forEach(t),zio=i(S),is=n(S,"LI",{});var xk=s(is);Yse=n(xk,"STRONG",{});var Nnt=s(Yse);Wio=r(Nnt,"groupvit"),Nnt.forEach(t),Qio=r(xk," \u2014 "),qB=n(xk,"A",{href:!0});var qnt=s(qB);Hio=r(qnt,"CLIPTokenizer"),qnt.forEach(t),Uio=r(xk," or "),jB=n(xk,"A",{href:!0});var jnt=s(jB);Jio=r(jnt,"CLIPTokenizerFast"),jnt.forEach(t),Yio=r(xk," (GroupViT model)"),xk.forEach(t),Kio=i(S),ds=n(S,"LI",{});var $k=s(ds);Kse=n($k,"STRONG",{});var Dnt=s(Kse);Zio=r(Dnt,"herbert"),Dnt.forEach(t),edo=r($k," \u2014 "),DB=n($k,"A",{href:!0});var Gnt=s(DB);odo=r(Gnt,"HerbertTokenizer"),Gnt.forEach(t),rdo=r($k," or "),GB=n($k,"A",{href:!0});var Ont=s(GB);tdo=r(Ont,"HerbertTokenizerFast"),Ont.forEach(t),ado=r($k," (HerBERT model)"),$k.forEach(t),ndo=i(S),ih=n(S,"LI",{});var LLe=s(ih);Zse=n(LLe,"STRONG",{});var Vnt=s(Zse);sdo=r(Vnt,"hubert"),Vnt.forEach(t),ldo=r(LLe," \u2014 "),OB=n(LLe,"A",{href:!0});var Xnt=s(OB);ido=r(Xnt,"Wav2Vec2CTCTokenizer"),Xnt.forEach(t),ddo=r(LLe," (Hubert model)"),LLe.forEach(t),cdo=i(S),cs=n(S,"LI",{});var kk=s(cs);ele=n(kk,"STRONG",{});var znt=s(ele);fdo=r(znt,"ibert"),znt.forEach(t),mdo=r(kk," \u2014 "),VB=n(kk,"A",{href:!0});var Wnt=s(VB);gdo=r(Wnt,"RobertaTokenizer"),Wnt.forEach(t),hdo=r(kk," or "),XB=n(kk,"A",{href:!0});var Qnt=s(XB);pdo=r(Qnt,"RobertaTokenizerFast"),Qnt.forEach(t),_do=r(kk," (I-BERT model)"),kk.forEach(t),udo=i(S),fs=n(S,"LI",{});var Sk=s(fs);ole=n(Sk,"STRONG",{});var Hnt=s(ole);bdo=r(Hnt,"layoutlm"),Hnt.forEach(t),vdo=r(Sk," \u2014 "),zB=n(Sk,"A",{href:!0});var Unt=s(zB);Fdo=r(Unt,"LayoutLMTokenizer"),Unt.forEach(t),Tdo=r(Sk," or "),WB=n(Sk,"A",{href:!0});var Jnt=s(WB);Mdo=r(Jnt,"LayoutLMTokenizerFast"),Jnt.forEach(t),Edo=r(Sk," (LayoutLM model)"),Sk.forEach(t),Cdo=i(S),ms=n(S,"LI",{});var Rk=s(ms);rle=n(Rk,"STRONG",{});var Ynt=s(rle);wdo=r(Ynt,"layoutlmv2"),Ynt.forEach(t),Ado=r(Rk," \u2014 "),QB=n(Rk,"A",{href:!0});var Knt=s(QB);Ldo=r(Knt,"LayoutLMv2Tokenizer"),Knt.forEach(t),ydo=r(Rk," or "),HB=n(Rk,"A",{href:!0});var Znt=s(HB);xdo=r(Znt,"LayoutLMv2TokenizerFast"),Znt.forEach(t),$do=r(Rk," (LayoutLMv2 model)"),Rk.forEach(t),kdo=i(S),gs=n(S,"LI",{});var Pk=s(gs);tle=n(Pk,"STRONG",{});var est=s(tle);Sdo=r(est,"layoutlmv3"),est.forEach(t),Rdo=r(Pk," \u2014 "),UB=n(Pk,"A",{href:!0});var ost=s(UB);Pdo=r(ost,"LayoutLMv3Tokenizer"),ost.forEach(t),Bdo=r(Pk," or "),JB=n(Pk,"A",{href:!0});var rst=s(JB);Ido=r(rst,"LayoutLMv3TokenizerFast"),rst.forEach(t),Ndo=r(Pk," (LayoutLMv3 model)"),Pk.forEach(t),qdo=i(S),hs=n(S,"LI",{});var Bk=s(hs);ale=n(Bk,"STRONG",{});var tst=s(ale);jdo=r(tst,"layoutxlm"),tst.forEach(t),Ddo=r(Bk," \u2014 "),YB=n(Bk,"A",{href:!0});var ast=s(YB);Gdo=r(ast,"LayoutXLMTokenizer"),ast.forEach(t),Odo=r(Bk," or "),KB=n(Bk,"A",{href:!0});var nst=s(KB);Vdo=r(nst,"LayoutXLMTokenizerFast"),nst.forEach(t),Xdo=r(Bk," (LayoutXLM model)"),Bk.forEach(t),zdo=i(S),ps=n(S,"LI",{});var Ik=s(ps);nle=n(Ik,"STRONG",{});var sst=s(nle);Wdo=r(sst,"led"),sst.forEach(t),Qdo=r(Ik," \u2014 "),ZB=n(Ik,"A",{href:!0});var lst=s(ZB);Hdo=r(lst,"LEDTokenizer"),lst.forEach(t),Udo=r(Ik," or "),eI=n(Ik,"A",{href:!0});var ist=s(eI);Jdo=r(ist,"LEDTokenizerFast"),ist.forEach(t),Ydo=r(Ik," (LED model)"),Ik.forEach(t),Kdo=i(S),_s=n(S,"LI",{});var Nk=s(_s);sle=n(Nk,"STRONG",{});var dst=s(sle);Zdo=r(dst,"longformer"),dst.forEach(t),eco=r(Nk," \u2014 "),oI=n(Nk,"A",{href:!0});var cst=s(oI);oco=r(cst,"LongformerTokenizer"),cst.forEach(t),rco=r(Nk," or "),rI=n(Nk,"A",{href:!0});var fst=s(rI);tco=r(fst,"LongformerTokenizerFast"),fst.forEach(t),aco=r(Nk," (Longformer model)"),Nk.forEach(t),nco=i(S),us=n(S,"LI",{});var qk=s(us);lle=n(qk,"STRONG",{});var mst=s(lle);sco=r(mst,"longt5"),mst.forEach(t),lco=r(qk," \u2014 "),tI=n(qk,"A",{href:!0});var gst=s(tI);ico=r(gst,"T5Tokenizer"),gst.forEach(t),dco=r(qk," or "),aI=n(qk,"A",{href:!0});var hst=s(aI);cco=r(hst,"T5TokenizerFast"),hst.forEach(t),fco=r(qk," (LongT5 model)"),qk.forEach(t),mco=i(S),dh=n(S,"LI",{});var yLe=s(dh);ile=n(yLe,"STRONG",{});var pst=s(ile);gco=r(pst,"luke"),pst.forEach(t),hco=r(yLe," \u2014 "),nI=n(yLe,"A",{href:!0});var _st=s(nI);pco=r(_st,"LukeTokenizer"),_st.forEach(t),_co=r(yLe," (LUKE model)"),yLe.forEach(t),uco=i(S),bs=n(S,"LI",{});var jk=s(bs);dle=n(jk,"STRONG",{});var ust=s(dle);bco=r(ust,"lxmert"),ust.forEach(t),vco=r(jk," \u2014 "),sI=n(jk,"A",{href:!0});var bst=s(sI);Fco=r(bst,"LxmertTokenizer"),bst.forEach(t),Tco=r(jk," or "),lI=n(jk,"A",{href:!0});var vst=s(lI);Mco=r(vst,"LxmertTokenizerFast"),vst.forEach(t),Eco=r(jk," (LXMERT model)"),jk.forEach(t),Cco=i(S),ch=n(S,"LI",{});var xLe=s(ch);cle=n(xLe,"STRONG",{});var Fst=s(cle);wco=r(Fst,"m2m_100"),Fst.forEach(t),Aco=r(xLe," \u2014 "),iI=n(xLe,"A",{href:!0});var Tst=s(iI);Lco=r(Tst,"M2M100Tokenizer"),Tst.forEach(t),yco=r(xLe," (M2M100 model)"),xLe.forEach(t),xco=i(S),fh=n(S,"LI",{});var $Le=s(fh);fle=n($Le,"STRONG",{});var Mst=s(fle);$co=r(Mst,"marian"),Mst.forEach(t),kco=r($Le," \u2014 "),dI=n($Le,"A",{href:!0});var Est=s(dI);Sco=r(Est,"MarianTokenizer"),Est.forEach(t),Rco=r($Le," (Marian model)"),$Le.forEach(t),Pco=i(S),vs=n(S,"LI",{});var Dk=s(vs);mle=n(Dk,"STRONG",{});var Cst=s(mle);Bco=r(Cst,"mbart"),Cst.forEach(t),Ico=r(Dk," \u2014 "),cI=n(Dk,"A",{href:!0});var wst=s(cI);Nco=r(wst,"MBartTokenizer"),wst.forEach(t),qco=r(Dk," or "),fI=n(Dk,"A",{href:!0});var Ast=s(fI);jco=r(Ast,"MBartTokenizerFast"),Ast.forEach(t),Dco=r(Dk," (mBART model)"),Dk.forEach(t),Gco=i(S),Fs=n(S,"LI",{});var Gk=s(Fs);gle=n(Gk,"STRONG",{});var Lst=s(gle);Oco=r(Lst,"mbart50"),Lst.forEach(t),Vco=r(Gk," \u2014 "),mI=n(Gk,"A",{href:!0});var yst=s(mI);Xco=r(yst,"MBart50Tokenizer"),yst.forEach(t),zco=r(Gk," or "),gI=n(Gk,"A",{href:!0});var xst=s(gI);Wco=r(xst,"MBart50TokenizerFast"),xst.forEach(t),Qco=r(Gk," (mBART-50 model)"),Gk.forEach(t),Hco=i(S),Ts=n(S,"LI",{});var Ok=s(Ts);hle=n(Ok,"STRONG",{});var $st=s(hle);Uco=r($st,"megatron-bert"),$st.forEach(t),Jco=r(Ok," \u2014 "),hI=n(Ok,"A",{href:!0});var kst=s(hI);Yco=r(kst,"BertTokenizer"),kst.forEach(t),Kco=r(Ok," or "),pI=n(Ok,"A",{href:!0});var Sst=s(pI);Zco=r(Sst,"BertTokenizerFast"),Sst.forEach(t),efo=r(Ok," (Megatron-BERT model)"),Ok.forEach(t),ofo=i(S),mh=n(S,"LI",{});var kLe=s(mh);ple=n(kLe,"STRONG",{});var Rst=s(ple);rfo=r(Rst,"mluke"),Rst.forEach(t),tfo=r(kLe," \u2014 "),_I=n(kLe,"A",{href:!0});var Pst=s(_I);afo=r(Pst,"MLukeTokenizer"),Pst.forEach(t),nfo=r(kLe," (mLUKE model)"),kLe.forEach(t),sfo=i(S),Ms=n(S,"LI",{});var Vk=s(Ms);_le=n(Vk,"STRONG",{});var Bst=s(_le);lfo=r(Bst,"mobilebert"),Bst.forEach(t),ifo=r(Vk," \u2014 "),uI=n(Vk,"A",{href:!0});var Ist=s(uI);dfo=r(Ist,"MobileBertTokenizer"),Ist.forEach(t),cfo=r(Vk," or "),bI=n(Vk,"A",{href:!0});var Nst=s(bI);ffo=r(Nst,"MobileBertTokenizerFast"),Nst.forEach(t),mfo=r(Vk," (MobileBERT model)"),Vk.forEach(t),gfo=i(S),Es=n(S,"LI",{});var Xk=s(Es);ule=n(Xk,"STRONG",{});var qst=s(ule);hfo=r(qst,"mpnet"),qst.forEach(t),pfo=r(Xk," \u2014 "),vI=n(Xk,"A",{href:!0});var jst=s(vI);_fo=r(jst,"MPNetTokenizer"),jst.forEach(t),ufo=r(Xk," or "),FI=n(Xk,"A",{href:!0});var Dst=s(FI);bfo=r(Dst,"MPNetTokenizerFast"),Dst.forEach(t),vfo=r(Xk," (MPNet model)"),Xk.forEach(t),Ffo=i(S),Cs=n(S,"LI",{});var zk=s(Cs);ble=n(zk,"STRONG",{});var Gst=s(ble);Tfo=r(Gst,"mt5"),Gst.forEach(t),Mfo=r(zk," \u2014 "),TI=n(zk,"A",{href:!0});var Ost=s(TI);Efo=r(Ost,"MT5Tokenizer"),Ost.forEach(t),Cfo=r(zk," or "),MI=n(zk,"A",{href:!0});var Vst=s(MI);wfo=r(Vst,"MT5TokenizerFast"),Vst.forEach(t),Afo=r(zk," (MT5 model)"),zk.forEach(t),Lfo=i(S),ws=n(S,"LI",{});var Wk=s(ws);vle=n(Wk,"STRONG",{});var Xst=s(vle);yfo=r(Xst,"nezha"),Xst.forEach(t),xfo=r(Wk," \u2014 "),EI=n(Wk,"A",{href:!0});var zst=s(EI);$fo=r(zst,"BertTokenizer"),zst.forEach(t),kfo=r(Wk," or "),CI=n(Wk,"A",{href:!0});var Wst=s(CI);Sfo=r(Wst,"BertTokenizerFast"),Wst.forEach(t),Rfo=r(Wk," (Nezha model)"),Wk.forEach(t),Pfo=i(S),As=n(S,"LI",{});var Qk=s(As);Fle=n(Qk,"STRONG",{});var Qst=s(Fle);Bfo=r(Qst,"nystromformer"),Qst.forEach(t),Ifo=r(Qk," \u2014 "),wI=n(Qk,"A",{href:!0});var Hst=s(wI);Nfo=r(Hst,"AlbertTokenizer"),Hst.forEach(t),qfo=r(Qk," or "),AI=n(Qk,"A",{href:!0});var Ust=s(AI);jfo=r(Ust,"AlbertTokenizerFast"),Ust.forEach(t),Dfo=r(Qk," (Nystr\xF6mformer model)"),Qk.forEach(t),Gfo=i(S),Ls=n(S,"LI",{});var Hk=s(Ls);Tle=n(Hk,"STRONG",{});var Jst=s(Tle);Ofo=r(Jst,"openai-gpt"),Jst.forEach(t),Vfo=r(Hk," \u2014 "),LI=n(Hk,"A",{href:!0});var Yst=s(LI);Xfo=r(Yst,"OpenAIGPTTokenizer"),Yst.forEach(t),zfo=r(Hk," or "),yI=n(Hk,"A",{href:!0});var Kst=s(yI);Wfo=r(Kst,"OpenAIGPTTokenizerFast"),Kst.forEach(t),Qfo=r(Hk," (OpenAI GPT model)"),Hk.forEach(t),Hfo=i(S),gh=n(S,"LI",{});var SLe=s(gh);Mle=n(SLe,"STRONG",{});var Zst=s(Mle);Ufo=r(Zst,"opt"),Zst.forEach(t),Jfo=r(SLe," \u2014 "),xI=n(SLe,"A",{href:!0});var elt=s(xI);Yfo=r(elt,"GPT2Tokenizer"),elt.forEach(t),Kfo=r(SLe," (OPT model)"),SLe.forEach(t),Zfo=i(S),ys=n(S,"LI",{});var Uk=s(ys);Ele=n(Uk,"STRONG",{});var olt=s(Ele);emo=r(olt,"pegasus"),olt.forEach(t),omo=r(Uk," \u2014 "),$I=n(Uk,"A",{href:!0});var rlt=s($I);rmo=r(rlt,"PegasusTokenizer"),rlt.forEach(t),tmo=r(Uk," or "),kI=n(Uk,"A",{href:!0});var tlt=s(kI);amo=r(tlt,"PegasusTokenizerFast"),tlt.forEach(t),nmo=r(Uk," (Pegasus model)"),Uk.forEach(t),smo=i(S),hh=n(S,"LI",{});var RLe=s(hh);Cle=n(RLe,"STRONG",{});var alt=s(Cle);lmo=r(alt,"perceiver"),alt.forEach(t),imo=r(RLe," \u2014 "),SI=n(RLe,"A",{href:!0});var nlt=s(SI);dmo=r(nlt,"PerceiverTokenizer"),nlt.forEach(t),cmo=r(RLe," (Perceiver model)"),RLe.forEach(t),fmo=i(S),ph=n(S,"LI",{});var PLe=s(ph);wle=n(PLe,"STRONG",{});var slt=s(wle);mmo=r(slt,"phobert"),slt.forEach(t),gmo=r(PLe," \u2014 "),RI=n(PLe,"A",{href:!0});var llt=s(RI);hmo=r(llt,"PhobertTokenizer"),llt.forEach(t),pmo=r(PLe," (PhoBERT model)"),PLe.forEach(t),_mo=i(S),_h=n(S,"LI",{});var BLe=s(_h);Ale=n(BLe,"STRONG",{});var ilt=s(Ale);umo=r(ilt,"plbart"),ilt.forEach(t),bmo=r(BLe," \u2014 "),PI=n(BLe,"A",{href:!0});var dlt=s(PI);vmo=r(dlt,"PLBartTokenizer"),dlt.forEach(t),Fmo=r(BLe," (PLBart model)"),BLe.forEach(t),Tmo=i(S),uh=n(S,"LI",{});var ILe=s(uh);Lle=n(ILe,"STRONG",{});var clt=s(Lle);Mmo=r(clt,"prophetnet"),clt.forEach(t),Emo=r(ILe," \u2014 "),BI=n(ILe,"A",{href:!0});var flt=s(BI);Cmo=r(flt,"ProphetNetTokenizer"),flt.forEach(t),wmo=r(ILe," (ProphetNet model)"),ILe.forEach(t),Amo=i(S),xs=n(S,"LI",{});var Jk=s(xs);yle=n(Jk,"STRONG",{});var mlt=s(yle);Lmo=r(mlt,"qdqbert"),mlt.forEach(t),ymo=r(Jk," \u2014 "),II=n(Jk,"A",{href:!0});var glt=s(II);xmo=r(glt,"BertTokenizer"),glt.forEach(t),$mo=r(Jk," or "),NI=n(Jk,"A",{href:!0});var hlt=s(NI);kmo=r(hlt,"BertTokenizerFast"),hlt.forEach(t),Smo=r(Jk," (QDQBert model)"),Jk.forEach(t),Rmo=i(S),bh=n(S,"LI",{});var NLe=s(bh);xle=n(NLe,"STRONG",{});var plt=s(xle);Pmo=r(plt,"rag"),plt.forEach(t),Bmo=r(NLe," \u2014 "),qI=n(NLe,"A",{href:!0});var _lt=s(qI);Imo=r(_lt,"RagTokenizer"),_lt.forEach(t),Nmo=r(NLe," (RAG model)"),NLe.forEach(t),qmo=i(S),$s=n(S,"LI",{});var Yk=s($s);$le=n(Yk,"STRONG",{});var ult=s($le);jmo=r(ult,"realm"),ult.forEach(t),Dmo=r(Yk," \u2014 "),jI=n(Yk,"A",{href:!0});var blt=s(jI);Gmo=r(blt,"RealmTokenizer"),blt.forEach(t),Omo=r(Yk," or "),DI=n(Yk,"A",{href:!0});var vlt=s(DI);Vmo=r(vlt,"RealmTokenizerFast"),vlt.forEach(t),Xmo=r(Yk," (REALM model)"),Yk.forEach(t),zmo=i(S),ks=n(S,"LI",{});var Kk=s(ks);kle=n(Kk,"STRONG",{});var Flt=s(kle);Wmo=r(Flt,"reformer"),Flt.forEach(t),Qmo=r(Kk," \u2014 "),GI=n(Kk,"A",{href:!0});var Tlt=s(GI);Hmo=r(Tlt,"ReformerTokenizer"),Tlt.forEach(t),Umo=r(Kk," or "),OI=n(Kk,"A",{href:!0});var Mlt=s(OI);Jmo=r(Mlt,"ReformerTokenizerFast"),Mlt.forEach(t),Ymo=r(Kk," (Reformer model)"),Kk.forEach(t),Kmo=i(S),Ss=n(S,"LI",{});var Zk=s(Ss);Sle=n(Zk,"STRONG",{});var Elt=s(Sle);Zmo=r(Elt,"rembert"),Elt.forEach(t),ego=r(Zk," \u2014 "),VI=n(Zk,"A",{href:!0});var Clt=s(VI);ogo=r(Clt,"RemBertTokenizer"),Clt.forEach(t),rgo=r(Zk," or "),XI=n(Zk,"A",{href:!0});var wlt=s(XI);tgo=r(wlt,"RemBertTokenizerFast"),wlt.forEach(t),ago=r(Zk," (RemBERT model)"),Zk.forEach(t),ngo=i(S),Rs=n(S,"LI",{});var eS=s(Rs);Rle=n(eS,"STRONG",{});var Alt=s(Rle);sgo=r(Alt,"retribert"),Alt.forEach(t),lgo=r(eS," \u2014 "),zI=n(eS,"A",{href:!0});var Llt=s(zI);igo=r(Llt,"RetriBertTokenizer"),Llt.forEach(t),dgo=r(eS," or "),WI=n(eS,"A",{href:!0});var ylt=s(WI);cgo=r(ylt,"RetriBertTokenizerFast"),ylt.forEach(t),fgo=r(eS," (RetriBERT model)"),eS.forEach(t),mgo=i(S),Ps=n(S,"LI",{});var oS=s(Ps);Ple=n(oS,"STRONG",{});var xlt=s(Ple);ggo=r(xlt,"roberta"),xlt.forEach(t),hgo=r(oS," \u2014 "),QI=n(oS,"A",{href:!0});var $lt=s(QI);pgo=r($lt,"RobertaTokenizer"),$lt.forEach(t),_go=r(oS," or "),HI=n(oS,"A",{href:!0});var klt=s(HI);ugo=r(klt,"RobertaTokenizerFast"),klt.forEach(t),bgo=r(oS," (RoBERTa model)"),oS.forEach(t),vgo=i(S),Bs=n(S,"LI",{});var rS=s(Bs);Ble=n(rS,"STRONG",{});var Slt=s(Ble);Fgo=r(Slt,"roformer"),Slt.forEach(t),Tgo=r(rS," \u2014 "),UI=n(rS,"A",{href:!0});var Rlt=s(UI);Mgo=r(Rlt,"RoFormerTokenizer"),Rlt.forEach(t),Ego=r(rS," or "),JI=n(rS,"A",{href:!0});var Plt=s(JI);Cgo=r(Plt,"RoFormerTokenizerFast"),Plt.forEach(t),wgo=r(rS," (RoFormer model)"),rS.forEach(t),Ago=i(S),vh=n(S,"LI",{});var qLe=s(vh);Ile=n(qLe,"STRONG",{});var Blt=s(Ile);Lgo=r(Blt,"speech_to_text"),Blt.forEach(t),ygo=r(qLe," \u2014 "),YI=n(qLe,"A",{href:!0});var Ilt=s(YI);xgo=r(Ilt,"Speech2TextTokenizer"),Ilt.forEach(t),$go=r(qLe," (Speech2Text model)"),qLe.forEach(t),kgo=i(S),Fh=n(S,"LI",{});var jLe=s(Fh);Nle=n(jLe,"STRONG",{});var Nlt=s(Nle);Sgo=r(Nlt,"speech_to_text_2"),Nlt.forEach(t),Rgo=r(jLe," \u2014 "),KI=n(jLe,"A",{href:!0});var qlt=s(KI);Pgo=r(qlt,"Speech2Text2Tokenizer"),qlt.forEach(t),Bgo=r(jLe," (Speech2Text2 model)"),jLe.forEach(t),Igo=i(S),Is=n(S,"LI",{});var tS=s(Is);qle=n(tS,"STRONG",{});var jlt=s(qle);Ngo=r(jlt,"splinter"),jlt.forEach(t),qgo=r(tS," \u2014 "),ZI=n(tS,"A",{href:!0});var Dlt=s(ZI);jgo=r(Dlt,"SplinterTokenizer"),Dlt.forEach(t),Dgo=r(tS," or "),eN=n(tS,"A",{href:!0});var Glt=s(eN);Ggo=r(Glt,"SplinterTokenizerFast"),Glt.forEach(t),Ogo=r(tS," (Splinter model)"),tS.forEach(t),Vgo=i(S),Ns=n(S,"LI",{});var aS=s(Ns);jle=n(aS,"STRONG",{});var Olt=s(jle);Xgo=r(Olt,"squeezebert"),Olt.forEach(t),zgo=r(aS," \u2014 "),oN=n(aS,"A",{href:!0});var Vlt=s(oN);Wgo=r(Vlt,"SqueezeBertTokenizer"),Vlt.forEach(t),Qgo=r(aS," or "),rN=n(aS,"A",{href:!0});var Xlt=s(rN);Hgo=r(Xlt,"SqueezeBertTokenizerFast"),Xlt.forEach(t),Ugo=r(aS," (SqueezeBERT model)"),aS.forEach(t),Jgo=i(S),qs=n(S,"LI",{});var nS=s(qs);Dle=n(nS,"STRONG",{});var zlt=s(Dle);Ygo=r(zlt,"t5"),zlt.forEach(t),Kgo=r(nS," \u2014 "),tN=n(nS,"A",{href:!0});var Wlt=s(tN);Zgo=r(Wlt,"T5Tokenizer"),Wlt.forEach(t),eho=r(nS," or "),aN=n(nS,"A",{href:!0});var Qlt=s(aN);oho=r(Qlt,"T5TokenizerFast"),Qlt.forEach(t),rho=r(nS," (T5 model)"),nS.forEach(t),tho=i(S),Th=n(S,"LI",{});var DLe=s(Th);Gle=n(DLe,"STRONG",{});var Hlt=s(Gle);aho=r(Hlt,"tapas"),Hlt.forEach(t),nho=r(DLe," \u2014 "),nN=n(DLe,"A",{href:!0});var Ult=s(nN);sho=r(Ult,"TapasTokenizer"),Ult.forEach(t),lho=r(DLe," (TAPAS model)"),DLe.forEach(t),iho=i(S),Mh=n(S,"LI",{});var GLe=s(Mh);Ole=n(GLe,"STRONG",{});var Jlt=s(Ole);dho=r(Jlt,"tapex"),Jlt.forEach(t),cho=r(GLe," \u2014 "),sN=n(GLe,"A",{href:!0});var Ylt=s(sN);fho=r(Ylt,"TapexTokenizer"),Ylt.forEach(t),mho=r(GLe," (TAPEX model)"),GLe.forEach(t),gho=i(S),Eh=n(S,"LI",{});var OLe=s(Eh);Vle=n(OLe,"STRONG",{});var Klt=s(Vle);hho=r(Klt,"transfo-xl"),Klt.forEach(t),pho=r(OLe," \u2014 "),lN=n(OLe,"A",{href:!0});var Zlt=s(lN);_ho=r(Zlt,"TransfoXLTokenizer"),Zlt.forEach(t),uho=r(OLe," (Transformer-XL model)"),OLe.forEach(t),bho=i(S),js=n(S,"LI",{});var sS=s(js);Xle=n(sS,"STRONG",{});var eit=s(Xle);vho=r(eit,"vilt"),eit.forEach(t),Fho=r(sS," \u2014 "),iN=n(sS,"A",{href:!0});var oit=s(iN);Tho=r(oit,"BertTokenizer"),oit.forEach(t),Mho=r(sS," or "),dN=n(sS,"A",{href:!0});var rit=s(dN);Eho=r(rit,"BertTokenizerFast"),rit.forEach(t),Cho=r(sS," (ViLT model)"),sS.forEach(t),who=i(S),Ds=n(S,"LI",{});var lS=s(Ds);zle=n(lS,"STRONG",{});var tit=s(zle);Aho=r(tit,"visual_bert"),tit.forEach(t),Lho=r(lS," \u2014 "),cN=n(lS,"A",{href:!0});var ait=s(cN);yho=r(ait,"BertTokenizer"),ait.forEach(t),xho=r(lS," or "),fN=n(lS,"A",{href:!0});var nit=s(fN);$ho=r(nit,"BertTokenizerFast"),nit.forEach(t),kho=r(lS," (VisualBERT model)"),lS.forEach(t),Sho=i(S),Ch=n(S,"LI",{});var VLe=s(Ch);Wle=n(VLe,"STRONG",{});var sit=s(Wle);Rho=r(sit,"wav2vec2"),sit.forEach(t),Pho=r(VLe," \u2014 "),mN=n(VLe,"A",{href:!0});var lit=s(mN);Bho=r(lit,"Wav2Vec2CTCTokenizer"),lit.forEach(t),Iho=r(VLe," (Wav2Vec2 model)"),VLe.forEach(t),Nho=i(S),wh=n(S,"LI",{});var XLe=s(wh);Qle=n(XLe,"STRONG",{});var iit=s(Qle);qho=r(iit,"wav2vec2-conformer"),iit.forEach(t),jho=r(XLe," \u2014 "),gN=n(XLe,"A",{href:!0});var dit=s(gN);Dho=r(dit,"Wav2Vec2CTCTokenizer"),dit.forEach(t),Gho=r(XLe," (Wav2Vec2-Conformer model)"),XLe.forEach(t),Oho=i(S),Ah=n(S,"LI",{});var zLe=s(Ah);Hle=n(zLe,"STRONG",{});var cit=s(Hle);Vho=r(cit,"wav2vec2_phoneme"),cit.forEach(t),Xho=r(zLe," \u2014 "),hN=n(zLe,"A",{href:!0});var fit=s(hN);zho=r(fit,"Wav2Vec2PhonemeCTCTokenizer"),fit.forEach(t),Who=r(zLe," (Wav2Vec2Phoneme model)"),zLe.forEach(t),Qho=i(S),Gs=n(S,"LI",{});var iS=s(Gs);Ule=n(iS,"STRONG",{});var mit=s(Ule);Hho=r(mit,"xglm"),mit.forEach(t),Uho=r(iS," \u2014 "),pN=n(iS,"A",{href:!0});var git=s(pN);Jho=r(git,"XGLMTokenizer"),git.forEach(t),Yho=r(iS," or "),_N=n(iS,"A",{href:!0});var hit=s(_N);Kho=r(hit,"XGLMTokenizerFast"),hit.forEach(t),Zho=r(iS," (XGLM model)"),iS.forEach(t),epo=i(S),Lh=n(S,"LI",{});var WLe=s(Lh);Jle=n(WLe,"STRONG",{});var pit=s(Jle);opo=r(pit,"xlm"),pit.forEach(t),rpo=r(WLe," \u2014 "),uN=n(WLe,"A",{href:!0});var _it=s(uN);tpo=r(_it,"XLMTokenizer"),_it.forEach(t),apo=r(WLe," (XLM model)"),WLe.forEach(t),npo=i(S),yh=n(S,"LI",{});var QLe=s(yh);Yle=n(QLe,"STRONG",{});var uit=s(Yle);spo=r(uit,"xlm-prophetnet"),uit.forEach(t),lpo=r(QLe," \u2014 "),bN=n(QLe,"A",{href:!0});var bit=s(bN);ipo=r(bit,"XLMProphetNetTokenizer"),bit.forEach(t),dpo=r(QLe," (XLM-ProphetNet model)"),QLe.forEach(t),cpo=i(S),Os=n(S,"LI",{});var dS=s(Os);Kle=n(dS,"STRONG",{});var vit=s(Kle);fpo=r(vit,"xlm-roberta"),vit.forEach(t),mpo=r(dS," \u2014 "),vN=n(dS,"A",{href:!0});var Fit=s(vN);gpo=r(Fit,"XLMRobertaTokenizer"),Fit.forEach(t),hpo=r(dS," or "),FN=n(dS,"A",{href:!0});var Tit=s(FN);ppo=r(Tit,"XLMRobertaTokenizerFast"),Tit.forEach(t),_po=r(dS," (XLM-RoBERTa model)"),dS.forEach(t),upo=i(S),Vs=n(S,"LI",{});var cS=s(Vs);Zle=n(cS,"STRONG",{});var Mit=s(Zle);bpo=r(Mit,"xlm-roberta-xl"),Mit.forEach(t),vpo=r(cS," \u2014 "),TN=n(cS,"A",{href:!0});var Eit=s(TN);Fpo=r(Eit,"RobertaTokenizer"),Eit.forEach(t),Tpo=r(cS," or "),MN=n(cS,"A",{href:!0});var Cit=s(MN);Mpo=r(Cit,"RobertaTokenizerFast"),Cit.forEach(t),Epo=r(cS," (XLM-RoBERTa-XL model)"),cS.forEach(t),Cpo=i(S),Xs=n(S,"LI",{});var fS=s(Xs);eie=n(fS,"STRONG",{});var wit=s(eie);wpo=r(wit,"xlnet"),wit.forEach(t),Apo=r(fS," \u2014 "),EN=n(fS,"A",{href:!0});var Ait=s(EN);Lpo=r(Ait,"XLNetTokenizer"),Ait.forEach(t),ypo=r(fS," or "),CN=n(fS,"A",{href:!0});var Lit=s(CN);xpo=r(Lit,"XLNetTokenizerFast"),Lit.forEach(t),$po=r(fS," (XLNet model)"),fS.forEach(t),kpo=i(S),zs=n(S,"LI",{});var mS=s(zs);oie=n(mS,"STRONG",{});var yit=s(oie);Spo=r(yit,"yoso"),yit.forEach(t),Rpo=r(mS," \u2014 "),wN=n(mS,"A",{href:!0});var xit=s(wN);Ppo=r(xit,"AlbertTokenizer"),xit.forEach(t),Bpo=r(mS," or "),AN=n(mS,"A",{href:!0});var $it=s(AN);Ipo=r($it,"AlbertTokenizerFast"),$it.forEach(t),Npo=r(mS," (YOSO model)"),mS.forEach(t),S.forEach(t),qpo=i(Ks),T(xh.$$.fragment,Ks),Ks.forEach(t),jpo=i(Ys),$h=n(Ys,"DIV",{class:!0});var JXe=s($h);T(oL.$$.fragment,JXe),Dpo=i(JXe),rie=n(JXe,"P",{});var kit=s(rie);Gpo=r(kit,"Register a new tokenizer in this mapping."),kit.forEach(t),JXe.forEach(t),Ys.forEach(t),UOe=i(f),Ii=n(f,"H2",{class:!0});var YXe=s(Ii);kh=n(YXe,"A",{id:!0,class:!0,href:!0});var Sit=s(kh);tie=n(Sit,"SPAN",{});var Rit=s(tie);T(rL.$$.fragment,Rit),Rit.forEach(t),Sit.forEach(t),Opo=i(YXe),aie=n(YXe,"SPAN",{});var Pit=s(aie);Vpo=r(Pit,"AutoFeatureExtractor"),Pit.forEach(t),YXe.forEach(t),JOe=i(f),Lo=n(f,"DIV",{class:!0});var Zs=s(Lo);T(tL.$$.fragment,Zs),Xpo=i(Zs),aL=n(Zs,"P",{});var KXe=s(aL);zpo=r(KXe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),LN=n(KXe,"A",{href:!0});var Bit=s(LN);Wpo=r(Bit,"AutoFeatureExtractor.from_pretrained()"),Bit.forEach(t),Qpo=r(KXe," class method."),KXe.forEach(t),Hpo=i(Zs),nL=n(Zs,"P",{});var ZXe=s(nL);Upo=r(ZXe,"This class cannot be instantiated directly using "),nie=n(ZXe,"CODE",{});var Iit=s(nie);Jpo=r(Iit,"__init__()"),Iit.forEach(t),Ypo=r(ZXe," (throws an error)."),ZXe.forEach(t),Kpo=i(Zs),He=n(Zs,"DIV",{class:!0});var ta=s(He);T(sL.$$.fragment,ta),Zpo=i(ta),sie=n(ta,"P",{});var Nit=s(sie);e_o=r(Nit,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Nit.forEach(t),o_o=i(ta),Pa=n(ta,"P",{});var X5=s(Pa);r_o=r(X5,"The feature extractor class to instantiate is selected based on the "),lie=n(X5,"CODE",{});var qit=s(lie);t_o=r(qit,"model_type"),qit.forEach(t),a_o=r(X5,` property of the config object
(either passed as an argument or loaded from `),iie=n(X5,"CODE",{});var jit=s(iie);n_o=r(jit,"pretrained_model_name_or_path"),jit.forEach(t),s_o=r(X5,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),die=n(X5,"CODE",{});var Dit=s(die);l_o=r(Dit,"pretrained_model_name_or_path"),Dit.forEach(t),i_o=r(X5,":"),X5.forEach(t),d_o=i(ta),Y=n(ta,"UL",{});var K=s(Y);Sh=n(K,"LI",{});var HLe=s(Sh);cie=n(HLe,"STRONG",{});var Git=s(cie);c_o=r(Git,"beit"),Git.forEach(t),f_o=r(HLe," \u2014 "),yN=n(HLe,"A",{href:!0});var Oit=s(yN);m_o=r(Oit,"BeitFeatureExtractor"),Oit.forEach(t),g_o=r(HLe," (BEiT model)"),HLe.forEach(t),h_o=i(K),Rh=n(K,"LI",{});var ULe=s(Rh);fie=n(ULe,"STRONG",{});var Vit=s(fie);p_o=r(Vit,"clip"),Vit.forEach(t),__o=r(ULe," \u2014 "),xN=n(ULe,"A",{href:!0});var Xit=s(xN);u_o=r(Xit,"CLIPFeatureExtractor"),Xit.forEach(t),b_o=r(ULe," (CLIP model)"),ULe.forEach(t),v_o=i(K),Ph=n(K,"LI",{});var JLe=s(Ph);mie=n(JLe,"STRONG",{});var zit=s(mie);F_o=r(zit,"convnext"),zit.forEach(t),T_o=r(JLe," \u2014 "),$N=n(JLe,"A",{href:!0});var Wit=s($N);M_o=r(Wit,"ConvNextFeatureExtractor"),Wit.forEach(t),E_o=r(JLe," (ConvNeXT model)"),JLe.forEach(t),C_o=i(K),Bh=n(K,"LI",{});var YLe=s(Bh);gie=n(YLe,"STRONG",{});var Qit=s(gie);w_o=r(Qit,"cvt"),Qit.forEach(t),A_o=r(YLe," \u2014 "),kN=n(YLe,"A",{href:!0});var Hit=s(kN);L_o=r(Hit,"ConvNextFeatureExtractor"),Hit.forEach(t),y_o=r(YLe," (CvT model)"),YLe.forEach(t),x_o=i(K),Ih=n(K,"LI",{});var KLe=s(Ih);hie=n(KLe,"STRONG",{});var Uit=s(hie);$_o=r(Uit,"data2vec-audio"),Uit.forEach(t),k_o=r(KLe," \u2014 "),SN=n(KLe,"A",{href:!0});var Jit=s(SN);S_o=r(Jit,"Wav2Vec2FeatureExtractor"),Jit.forEach(t),R_o=r(KLe," (Data2VecAudio model)"),KLe.forEach(t),P_o=i(K),Nh=n(K,"LI",{});var ZLe=s(Nh);pie=n(ZLe,"STRONG",{});var Yit=s(pie);B_o=r(Yit,"data2vec-vision"),Yit.forEach(t),I_o=r(ZLe," \u2014 "),RN=n(ZLe,"A",{href:!0});var Kit=s(RN);N_o=r(Kit,"BeitFeatureExtractor"),Kit.forEach(t),q_o=r(ZLe," (Data2VecVision model)"),ZLe.forEach(t),j_o=i(K),qh=n(K,"LI",{});var eye=s(qh);_ie=n(eye,"STRONG",{});var Zit=s(_ie);D_o=r(Zit,"deit"),Zit.forEach(t),G_o=r(eye," \u2014 "),PN=n(eye,"A",{href:!0});var edt=s(PN);O_o=r(edt,"DeiTFeatureExtractor"),edt.forEach(t),V_o=r(eye," (DeiT model)"),eye.forEach(t),X_o=i(K),jh=n(K,"LI",{});var oye=s(jh);uie=n(oye,"STRONG",{});var odt=s(uie);z_o=r(odt,"detr"),odt.forEach(t),W_o=r(oye," \u2014 "),BN=n(oye,"A",{href:!0});var rdt=s(BN);Q_o=r(rdt,"DetrFeatureExtractor"),rdt.forEach(t),H_o=r(oye," (DETR model)"),oye.forEach(t),U_o=i(K),Dh=n(K,"LI",{});var rye=s(Dh);bie=n(rye,"STRONG",{});var tdt=s(bie);J_o=r(tdt,"dpt"),tdt.forEach(t),Y_o=r(rye," \u2014 "),IN=n(rye,"A",{href:!0});var adt=s(IN);K_o=r(adt,"DPTFeatureExtractor"),adt.forEach(t),Z_o=r(rye," (DPT model)"),rye.forEach(t),euo=i(K),Gh=n(K,"LI",{});var tye=s(Gh);vie=n(tye,"STRONG",{});var ndt=s(vie);ouo=r(ndt,"flava"),ndt.forEach(t),ruo=r(tye," \u2014 "),NN=n(tye,"A",{href:!0});var sdt=s(NN);tuo=r(sdt,"FlavaFeatureExtractor"),sdt.forEach(t),auo=r(tye," (FLAVA model)"),tye.forEach(t),nuo=i(K),Oh=n(K,"LI",{});var aye=s(Oh);Fie=n(aye,"STRONG",{});var ldt=s(Fie);suo=r(ldt,"glpn"),ldt.forEach(t),luo=r(aye," \u2014 "),qN=n(aye,"A",{href:!0});var idt=s(qN);iuo=r(idt,"GLPNFeatureExtractor"),idt.forEach(t),duo=r(aye," (GLPN model)"),aye.forEach(t),cuo=i(K),Vh=n(K,"LI",{});var nye=s(Vh);Tie=n(nye,"STRONG",{});var ddt=s(Tie);fuo=r(ddt,"groupvit"),ddt.forEach(t),muo=r(nye," \u2014 "),jN=n(nye,"A",{href:!0});var cdt=s(jN);guo=r(cdt,"CLIPFeatureExtractor"),cdt.forEach(t),huo=r(nye," (GroupViT model)"),nye.forEach(t),puo=i(K),Xh=n(K,"LI",{});var sye=s(Xh);Mie=n(sye,"STRONG",{});var fdt=s(Mie);_uo=r(fdt,"hubert"),fdt.forEach(t),uuo=r(sye," \u2014 "),DN=n(sye,"A",{href:!0});var mdt=s(DN);buo=r(mdt,"Wav2Vec2FeatureExtractor"),mdt.forEach(t),vuo=r(sye," (Hubert model)"),sye.forEach(t),Fuo=i(K),zh=n(K,"LI",{});var lye=s(zh);Eie=n(lye,"STRONG",{});var gdt=s(Eie);Tuo=r(gdt,"imagegpt"),gdt.forEach(t),Muo=r(lye," \u2014 "),GN=n(lye,"A",{href:!0});var hdt=s(GN);Euo=r(hdt,"ImageGPTFeatureExtractor"),hdt.forEach(t),Cuo=r(lye," (ImageGPT model)"),lye.forEach(t),wuo=i(K),Wh=n(K,"LI",{});var iye=s(Wh);Cie=n(iye,"STRONG",{});var pdt=s(Cie);Auo=r(pdt,"layoutlmv2"),pdt.forEach(t),Luo=r(iye," \u2014 "),ON=n(iye,"A",{href:!0});var _dt=s(ON);yuo=r(_dt,"LayoutLMv2FeatureExtractor"),_dt.forEach(t),xuo=r(iye," (LayoutLMv2 model)"),iye.forEach(t),$uo=i(K),Qh=n(K,"LI",{});var dye=s(Qh);wie=n(dye,"STRONG",{});var udt=s(wie);kuo=r(udt,"layoutlmv3"),udt.forEach(t),Suo=r(dye," \u2014 "),VN=n(dye,"A",{href:!0});var bdt=s(VN);Ruo=r(bdt,"LayoutLMv3FeatureExtractor"),bdt.forEach(t),Puo=r(dye," (LayoutLMv3 model)"),dye.forEach(t),Buo=i(K),Hh=n(K,"LI",{});var cye=s(Hh);Aie=n(cye,"STRONG",{});var vdt=s(Aie);Iuo=r(vdt,"levit"),vdt.forEach(t),Nuo=r(cye," \u2014 "),XN=n(cye,"A",{href:!0});var Fdt=s(XN);quo=r(Fdt,"LevitFeatureExtractor"),Fdt.forEach(t),juo=r(cye," (LeViT model)"),cye.forEach(t),Duo=i(K),Uh=n(K,"LI",{});var fye=s(Uh);Lie=n(fye,"STRONG",{});var Tdt=s(Lie);Guo=r(Tdt,"maskformer"),Tdt.forEach(t),Ouo=r(fye," \u2014 "),zN=n(fye,"A",{href:!0});var Mdt=s(zN);Vuo=r(Mdt,"MaskFormerFeatureExtractor"),Mdt.forEach(t),Xuo=r(fye," (MaskFormer model)"),fye.forEach(t),zuo=i(K),Jh=n(K,"LI",{});var mye=s(Jh);yie=n(mye,"STRONG",{});var Edt=s(yie);Wuo=r(Edt,"mctct"),Edt.forEach(t),Quo=r(mye," \u2014 "),WN=n(mye,"A",{href:!0});var Cdt=s(WN);Huo=r(Cdt,"MCTCTFeatureExtractor"),Cdt.forEach(t),Uuo=r(mye," (M-CTC-T model)"),mye.forEach(t),Juo=i(K),Yh=n(K,"LI",{});var gye=s(Yh);xie=n(gye,"STRONG",{});var wdt=s(xie);Yuo=r(wdt,"perceiver"),wdt.forEach(t),Kuo=r(gye," \u2014 "),QN=n(gye,"A",{href:!0});var Adt=s(QN);Zuo=r(Adt,"PerceiverFeatureExtractor"),Adt.forEach(t),e1o=r(gye," (Perceiver model)"),gye.forEach(t),o1o=i(K),Kh=n(K,"LI",{});var hye=s(Kh);$ie=n(hye,"STRONG",{});var Ldt=s($ie);r1o=r(Ldt,"poolformer"),Ldt.forEach(t),t1o=r(hye," \u2014 "),HN=n(hye,"A",{href:!0});var ydt=s(HN);a1o=r(ydt,"PoolFormerFeatureExtractor"),ydt.forEach(t),n1o=r(hye," (PoolFormer model)"),hye.forEach(t),s1o=i(K),Zh=n(K,"LI",{});var pye=s(Zh);kie=n(pye,"STRONG",{});var xdt=s(kie);l1o=r(xdt,"regnet"),xdt.forEach(t),i1o=r(pye," \u2014 "),UN=n(pye,"A",{href:!0});var $dt=s(UN);d1o=r($dt,"ConvNextFeatureExtractor"),$dt.forEach(t),c1o=r(pye," (RegNet model)"),pye.forEach(t),f1o=i(K),ep=n(K,"LI",{});var _ye=s(ep);Sie=n(_ye,"STRONG",{});var kdt=s(Sie);m1o=r(kdt,"resnet"),kdt.forEach(t),g1o=r(_ye," \u2014 "),JN=n(_ye,"A",{href:!0});var Sdt=s(JN);h1o=r(Sdt,"ConvNextFeatureExtractor"),Sdt.forEach(t),p1o=r(_ye," (ResNet model)"),_ye.forEach(t),_1o=i(K),op=n(K,"LI",{});var uye=s(op);Rie=n(uye,"STRONG",{});var Rdt=s(Rie);u1o=r(Rdt,"segformer"),Rdt.forEach(t),b1o=r(uye," \u2014 "),YN=n(uye,"A",{href:!0});var Pdt=s(YN);v1o=r(Pdt,"SegformerFeatureExtractor"),Pdt.forEach(t),F1o=r(uye," (SegFormer model)"),uye.forEach(t),T1o=i(K),rp=n(K,"LI",{});var bye=s(rp);Pie=n(bye,"STRONG",{});var Bdt=s(Pie);M1o=r(Bdt,"speech_to_text"),Bdt.forEach(t),E1o=r(bye," \u2014 "),KN=n(bye,"A",{href:!0});var Idt=s(KN);C1o=r(Idt,"Speech2TextFeatureExtractor"),Idt.forEach(t),w1o=r(bye," (Speech2Text model)"),bye.forEach(t),A1o=i(K),tp=n(K,"LI",{});var vye=s(tp);Bie=n(vye,"STRONG",{});var Ndt=s(Bie);L1o=r(Ndt,"swin"),Ndt.forEach(t),y1o=r(vye," \u2014 "),ZN=n(vye,"A",{href:!0});var qdt=s(ZN);x1o=r(qdt,"ViTFeatureExtractor"),qdt.forEach(t),$1o=r(vye," (Swin Transformer model)"),vye.forEach(t),k1o=i(K),ap=n(K,"LI",{});var Fye=s(ap);Iie=n(Fye,"STRONG",{});var jdt=s(Iie);S1o=r(jdt,"van"),jdt.forEach(t),R1o=r(Fye," \u2014 "),eq=n(Fye,"A",{href:!0});var Ddt=s(eq);P1o=r(Ddt,"ConvNextFeatureExtractor"),Ddt.forEach(t),B1o=r(Fye," (VAN model)"),Fye.forEach(t),I1o=i(K),np=n(K,"LI",{});var Tye=s(np);Nie=n(Tye,"STRONG",{});var Gdt=s(Nie);N1o=r(Gdt,"vilt"),Gdt.forEach(t),q1o=r(Tye," \u2014 "),oq=n(Tye,"A",{href:!0});var Odt=s(oq);j1o=r(Odt,"ViltFeatureExtractor"),Odt.forEach(t),D1o=r(Tye," (ViLT model)"),Tye.forEach(t),G1o=i(K),sp=n(K,"LI",{});var Mye=s(sp);qie=n(Mye,"STRONG",{});var Vdt=s(qie);O1o=r(Vdt,"vit"),Vdt.forEach(t),V1o=r(Mye," \u2014 "),rq=n(Mye,"A",{href:!0});var Xdt=s(rq);X1o=r(Xdt,"ViTFeatureExtractor"),Xdt.forEach(t),z1o=r(Mye," (ViT model)"),Mye.forEach(t),W1o=i(K),lp=n(K,"LI",{});var Eye=s(lp);jie=n(Eye,"STRONG",{});var zdt=s(jie);Q1o=r(zdt,"vit_mae"),zdt.forEach(t),H1o=r(Eye," \u2014 "),tq=n(Eye,"A",{href:!0});var Wdt=s(tq);U1o=r(Wdt,"ViTFeatureExtractor"),Wdt.forEach(t),J1o=r(Eye," (ViTMAE model)"),Eye.forEach(t),Y1o=i(K),ip=n(K,"LI",{});var Cye=s(ip);Die=n(Cye,"STRONG",{});var Qdt=s(Die);K1o=r(Qdt,"wav2vec2"),Qdt.forEach(t),Z1o=r(Cye," \u2014 "),aq=n(Cye,"A",{href:!0});var Hdt=s(aq);e2o=r(Hdt,"Wav2Vec2FeatureExtractor"),Hdt.forEach(t),o2o=r(Cye," (Wav2Vec2 model)"),Cye.forEach(t),r2o=i(K),dp=n(K,"LI",{});var wye=s(dp);Gie=n(wye,"STRONG",{});var Udt=s(Gie);t2o=r(Udt,"wav2vec2-conformer"),Udt.forEach(t),a2o=r(wye," \u2014 "),nq=n(wye,"A",{href:!0});var Jdt=s(nq);n2o=r(Jdt,"Wav2Vec2FeatureExtractor"),Jdt.forEach(t),s2o=r(wye," (Wav2Vec2-Conformer model)"),wye.forEach(t),l2o=i(K),cp=n(K,"LI",{});var Aye=s(cp);Oie=n(Aye,"STRONG",{});var Ydt=s(Oie);i2o=r(Ydt,"yolos"),Ydt.forEach(t),d2o=r(Aye," \u2014 "),sq=n(Aye,"A",{href:!0});var Kdt=s(sq);c2o=r(Kdt,"YolosFeatureExtractor"),Kdt.forEach(t),f2o=r(Aye," (YOLOS model)"),Aye.forEach(t),K.forEach(t),m2o=i(ta),T(fp.$$.fragment,ta),g2o=i(ta),T(mp.$$.fragment,ta),ta.forEach(t),h2o=i(Zs),gp=n(Zs,"DIV",{class:!0});var eze=s(gp);T(lL.$$.fragment,eze),p2o=i(eze),Vie=n(eze,"P",{});var Zdt=s(Vie);_2o=r(Zdt,"Register a new feature extractor for this class."),Zdt.forEach(t),eze.forEach(t),Zs.forEach(t),YOe=i(f),Ni=n(f,"H2",{class:!0});var oze=s(Ni);hp=n(oze,"A",{id:!0,class:!0,href:!0});var ect=s(hp);Xie=n(ect,"SPAN",{});var oct=s(Xie);T(iL.$$.fragment,oct),oct.forEach(t),ect.forEach(t),u2o=i(oze),zie=n(oze,"SPAN",{});var rct=s(zie);b2o=r(rct,"AutoProcessor"),rct.forEach(t),oze.forEach(t),KOe=i(f),yo=n(f,"DIV",{class:!0});var el=s(yo);T(dL.$$.fragment,el),v2o=i(el),cL=n(el,"P",{});var rze=s(cL);F2o=r(rze,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),lq=n(rze,"A",{href:!0});var tct=s(lq);T2o=r(tct,"AutoProcessor.from_pretrained()"),tct.forEach(t),M2o=r(rze," class method."),rze.forEach(t),E2o=i(el),fL=n(el,"P",{});var tze=s(fL);C2o=r(tze,"This class cannot be instantiated directly using "),Wie=n(tze,"CODE",{});var act=s(Wie);w2o=r(act,"__init__()"),act.forEach(t),A2o=r(tze," (throws an error)."),tze.forEach(t),L2o=i(el),Ue=n(el,"DIV",{class:!0});var aa=s(Ue);T(mL.$$.fragment,aa),y2o=i(aa),Qie=n(aa,"P",{});var nct=s(Qie);x2o=r(nct,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),nct.forEach(t),$2o=i(aa),qi=n(aa,"P",{});var Joe=s(qi);k2o=r(Joe,"The processor class to instantiate is selected based on the "),Hie=n(Joe,"CODE",{});var sct=s(Hie);S2o=r(sct,"model_type"),sct.forEach(t),R2o=r(Joe,` property of the config object (either
passed as an argument or loaded from `),Uie=n(Joe,"CODE",{});var lct=s(Uie);P2o=r(lct,"pretrained_model_name_or_path"),lct.forEach(t),B2o=r(Joe," if possible):"),Joe.forEach(t),I2o=i(aa),he=n(aa,"UL",{});var ue=s(he);pp=n(ue,"LI",{});var Lye=s(pp);Jie=n(Lye,"STRONG",{});var ict=s(Jie);N2o=r(ict,"clip"),ict.forEach(t),q2o=r(Lye," \u2014 "),iq=n(Lye,"A",{href:!0});var dct=s(iq);j2o=r(dct,"CLIPProcessor"),dct.forEach(t),D2o=r(Lye," (CLIP model)"),Lye.forEach(t),G2o=i(ue),_p=n(ue,"LI",{});var yye=s(_p);Yie=n(yye,"STRONG",{});var cct=s(Yie);O2o=r(cct,"flava"),cct.forEach(t),V2o=r(yye," \u2014 "),Kie=n(yye,"CODE",{});var fct=s(Kie);X2o=r(fct,"FLAVAProcessor"),fct.forEach(t),z2o=r(yye," (FLAVA model)"),yye.forEach(t),W2o=i(ue),up=n(ue,"LI",{});var xye=s(up);Zie=n(xye,"STRONG",{});var mct=s(Zie);Q2o=r(mct,"groupvit"),mct.forEach(t),H2o=r(xye," \u2014 "),dq=n(xye,"A",{href:!0});var gct=s(dq);U2o=r(gct,"CLIPProcessor"),gct.forEach(t),J2o=r(xye," (GroupViT model)"),xye.forEach(t),Y2o=i(ue),bp=n(ue,"LI",{});var $ye=s(bp);ede=n($ye,"STRONG",{});var hct=s(ede);K2o=r(hct,"layoutlmv2"),hct.forEach(t),Z2o=r($ye," \u2014 "),cq=n($ye,"A",{href:!0});var pct=s(cq);ebo=r(pct,"LayoutLMv2Processor"),pct.forEach(t),obo=r($ye," (LayoutLMv2 model)"),$ye.forEach(t),rbo=i(ue),vp=n(ue,"LI",{});var kye=s(vp);ode=n(kye,"STRONG",{});var _ct=s(ode);tbo=r(_ct,"layoutlmv3"),_ct.forEach(t),abo=r(kye," \u2014 "),fq=n(kye,"A",{href:!0});var uct=s(fq);nbo=r(uct,"LayoutLMv3Processor"),uct.forEach(t),sbo=r(kye," (LayoutLMv3 model)"),kye.forEach(t),lbo=i(ue),Fp=n(ue,"LI",{});var Sye=s(Fp);rde=n(Sye,"STRONG",{});var bct=s(rde);ibo=r(bct,"layoutxlm"),bct.forEach(t),dbo=r(Sye," \u2014 "),mq=n(Sye,"A",{href:!0});var vct=s(mq);cbo=r(vct,"LayoutXLMProcessor"),vct.forEach(t),fbo=r(Sye," (LayoutXLM model)"),Sye.forEach(t),mbo=i(ue),Tp=n(ue,"LI",{});var Rye=s(Tp);tde=n(Rye,"STRONG",{});var Fct=s(tde);gbo=r(Fct,"sew"),Fct.forEach(t),hbo=r(Rye," \u2014 "),gq=n(Rye,"A",{href:!0});var Tct=s(gq);pbo=r(Tct,"Wav2Vec2Processor"),Tct.forEach(t),_bo=r(Rye," (SEW model)"),Rye.forEach(t),ubo=i(ue),Mp=n(ue,"LI",{});var Pye=s(Mp);ade=n(Pye,"STRONG",{});var Mct=s(ade);bbo=r(Mct,"sew-d"),Mct.forEach(t),vbo=r(Pye," \u2014 "),hq=n(Pye,"A",{href:!0});var Ect=s(hq);Fbo=r(Ect,"Wav2Vec2Processor"),Ect.forEach(t),Tbo=r(Pye," (SEW-D model)"),Pye.forEach(t),Mbo=i(ue),Ep=n(ue,"LI",{});var Bye=s(Ep);nde=n(Bye,"STRONG",{});var Cct=s(nde);Ebo=r(Cct,"speech_to_text"),Cct.forEach(t),Cbo=r(Bye," \u2014 "),pq=n(Bye,"A",{href:!0});var wct=s(pq);wbo=r(wct,"Speech2TextProcessor"),wct.forEach(t),Abo=r(Bye," (Speech2Text model)"),Bye.forEach(t),Lbo=i(ue),Cp=n(ue,"LI",{});var Iye=s(Cp);sde=n(Iye,"STRONG",{});var Act=s(sde);ybo=r(Act,"speech_to_text_2"),Act.forEach(t),xbo=r(Iye," \u2014 "),_q=n(Iye,"A",{href:!0});var Lct=s(_q);$bo=r(Lct,"Speech2Text2Processor"),Lct.forEach(t),kbo=r(Iye," (Speech2Text2 model)"),Iye.forEach(t),Sbo=i(ue),wp=n(ue,"LI",{});var Nye=s(wp);lde=n(Nye,"STRONG",{});var yct=s(lde);Rbo=r(yct,"trocr"),yct.forEach(t),Pbo=r(Nye," \u2014 "),uq=n(Nye,"A",{href:!0});var xct=s(uq);Bbo=r(xct,"TrOCRProcessor"),xct.forEach(t),Ibo=r(Nye," (TrOCR model)"),Nye.forEach(t),Nbo=i(ue),Ap=n(ue,"LI",{});var qye=s(Ap);ide=n(qye,"STRONG",{});var $ct=s(ide);qbo=r($ct,"unispeech"),$ct.forEach(t),jbo=r(qye," \u2014 "),bq=n(qye,"A",{href:!0});var kct=s(bq);Dbo=r(kct,"Wav2Vec2Processor"),kct.forEach(t),Gbo=r(qye," (UniSpeech model)"),qye.forEach(t),Obo=i(ue),Lp=n(ue,"LI",{});var jye=s(Lp);dde=n(jye,"STRONG",{});var Sct=s(dde);Vbo=r(Sct,"unispeech-sat"),Sct.forEach(t),Xbo=r(jye," \u2014 "),vq=n(jye,"A",{href:!0});var Rct=s(vq);zbo=r(Rct,"Wav2Vec2Processor"),Rct.forEach(t),Wbo=r(jye," (UniSpeechSat model)"),jye.forEach(t),Qbo=i(ue),yp=n(ue,"LI",{});var Dye=s(yp);cde=n(Dye,"STRONG",{});var Pct=s(cde);Hbo=r(Pct,"vilt"),Pct.forEach(t),Ubo=r(Dye," \u2014 "),Fq=n(Dye,"A",{href:!0});var Bct=s(Fq);Jbo=r(Bct,"ViltProcessor"),Bct.forEach(t),Ybo=r(Dye," (ViLT model)"),Dye.forEach(t),Kbo=i(ue),xp=n(ue,"LI",{});var Gye=s(xp);fde=n(Gye,"STRONG",{});var Ict=s(fde);Zbo=r(Ict,"vision-text-dual-encoder"),Ict.forEach(t),evo=r(Gye," \u2014 "),Tq=n(Gye,"A",{href:!0});var Nct=s(Tq);ovo=r(Nct,"VisionTextDualEncoderProcessor"),Nct.forEach(t),rvo=r(Gye," (VisionTextDualEncoder model)"),Gye.forEach(t),tvo=i(ue),$p=n(ue,"LI",{});var Oye=s($p);mde=n(Oye,"STRONG",{});var qct=s(mde);avo=r(qct,"wav2vec2"),qct.forEach(t),nvo=r(Oye," \u2014 "),Mq=n(Oye,"A",{href:!0});var jct=s(Mq);svo=r(jct,"Wav2Vec2Processor"),jct.forEach(t),lvo=r(Oye," (Wav2Vec2 model)"),Oye.forEach(t),ivo=i(ue),kp=n(ue,"LI",{});var Vye=s(kp);gde=n(Vye,"STRONG",{});var Dct=s(gde);dvo=r(Dct,"wav2vec2-conformer"),Dct.forEach(t),cvo=r(Vye," \u2014 "),Eq=n(Vye,"A",{href:!0});var Gct=s(Eq);fvo=r(Gct,"Wav2Vec2Processor"),Gct.forEach(t),mvo=r(Vye," (Wav2Vec2-Conformer model)"),Vye.forEach(t),gvo=i(ue),Sp=n(ue,"LI",{});var Xye=s(Sp);hde=n(Xye,"STRONG",{});var Oct=s(hde);hvo=r(Oct,"wavlm"),Oct.forEach(t),pvo=r(Xye," \u2014 "),Cq=n(Xye,"A",{href:!0});var Vct=s(Cq);_vo=r(Vct,"Wav2Vec2Processor"),Vct.forEach(t),uvo=r(Xye," (WavLM model)"),Xye.forEach(t),ue.forEach(t),bvo=i(aa),T(Rp.$$.fragment,aa),vvo=i(aa),T(Pp.$$.fragment,aa),aa.forEach(t),Fvo=i(el),Bp=n(el,"DIV",{class:!0});var aze=s(Bp);T(gL.$$.fragment,aze),Tvo=i(aze),pde=n(aze,"P",{});var Xct=s(pde);Mvo=r(Xct,"Register a new processor for this class."),Xct.forEach(t),aze.forEach(t),el.forEach(t),ZOe=i(f),ji=n(f,"H2",{class:!0});var nze=s(ji);Ip=n(nze,"A",{id:!0,class:!0,href:!0});var zct=s(Ip);_de=n(zct,"SPAN",{});var Wct=s(_de);T(hL.$$.fragment,Wct),Wct.forEach(t),zct.forEach(t),Evo=i(nze),ude=n(nze,"SPAN",{});var Qct=s(ude);Cvo=r(Qct,"AutoModel"),Qct.forEach(t),nze.forEach(t),eVe=i(f),xo=n(f,"DIV",{class:!0});var ol=s(xo);T(pL.$$.fragment,ol),wvo=i(ol),Di=n(ol,"P",{});var Yoe=s(Di);Avo=r(Yoe,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),wq=n(Yoe,"A",{href:!0});var Hct=s(wq);Lvo=r(Hct,"from_pretrained()"),Hct.forEach(t),yvo=r(Yoe," class method or the "),Aq=n(Yoe,"A",{href:!0});var Uct=s(Aq);xvo=r(Uct,"from_config()"),Uct.forEach(t),$vo=r(Yoe,` class
method.`),Yoe.forEach(t),kvo=i(ol),_L=n(ol,"P",{});var sze=s(_L);Svo=r(sze,"This class cannot be instantiated directly using "),bde=n(sze,"CODE",{});var Jct=s(bde);Rvo=r(Jct,"__init__()"),Jct.forEach(t),Pvo=r(sze," (throws an error)."),sze.forEach(t),Bvo=i(ol),st=n(ol,"DIV",{class:!0});var z5=s(st);T(uL.$$.fragment,z5),Ivo=i(z5),vde=n(z5,"P",{});var Yct=s(vde);Nvo=r(Yct,"Instantiates one of the base model classes of the library from a configuration."),Yct.forEach(t),qvo=i(z5),Gi=n(z5,"P",{});var Koe=s(Gi);jvo=r(Koe,`Note:
Loading a model from its configuration file does `),Fde=n(Koe,"STRONG",{});var Kct=s(Fde);Dvo=r(Kct,"not"),Kct.forEach(t),Gvo=r(Koe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Lq=n(Koe,"A",{href:!0});var Zct=s(Lq);Ovo=r(Zct,"from_pretrained()"),Zct.forEach(t),Vvo=r(Koe," to load the model weights."),Koe.forEach(t),Xvo=i(z5),T(Np.$$.fragment,z5),z5.forEach(t),zvo=i(ol),Je=n(ol,"DIV",{class:!0});var na=s(Je);T(bL.$$.fragment,na),Wvo=i(na),Tde=n(na,"P",{});var eft=s(Tde);Qvo=r(eft,"Instantiate one of the base model classes of the library from a pretrained model."),eft.forEach(t),Hvo=i(na),Ba=n(na,"P",{});var W5=s(Ba);Uvo=r(W5,"The model class to instantiate is selected based on the "),Mde=n(W5,"CODE",{});var oft=s(Mde);Jvo=r(oft,"model_type"),oft.forEach(t),Yvo=r(W5,` property of the config object (either
passed as an argument or loaded from `),Ede=n(W5,"CODE",{});var rft=s(Ede);Kvo=r(rft,"pretrained_model_name_or_path"),rft.forEach(t),Zvo=r(W5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cde=n(W5,"CODE",{});var tft=s(Cde);e0o=r(tft,"pretrained_model_name_or_path"),tft.forEach(t),o0o=r(W5,":"),W5.forEach(t),r0o=i(na),y=n(na,"UL",{});var x=s(y);qp=n(x,"LI",{});var zye=s(qp);wde=n(zye,"STRONG",{});var aft=s(wde);t0o=r(aft,"albert"),aft.forEach(t),a0o=r(zye," \u2014 "),yq=n(zye,"A",{href:!0});var nft=s(yq);n0o=r(nft,"AlbertModel"),nft.forEach(t),s0o=r(zye," (ALBERT model)"),zye.forEach(t),l0o=i(x),jp=n(x,"LI",{});var Wye=s(jp);Ade=n(Wye,"STRONG",{});var sft=s(Ade);i0o=r(sft,"bart"),sft.forEach(t),d0o=r(Wye," \u2014 "),xq=n(Wye,"A",{href:!0});var lft=s(xq);c0o=r(lft,"BartModel"),lft.forEach(t),f0o=r(Wye," (BART model)"),Wye.forEach(t),m0o=i(x),Dp=n(x,"LI",{});var Qye=s(Dp);Lde=n(Qye,"STRONG",{});var ift=s(Lde);g0o=r(ift,"beit"),ift.forEach(t),h0o=r(Qye," \u2014 "),$q=n(Qye,"A",{href:!0});var dft=s($q);p0o=r(dft,"BeitModel"),dft.forEach(t),_0o=r(Qye," (BEiT model)"),Qye.forEach(t),u0o=i(x),Gp=n(x,"LI",{});var Hye=s(Gp);yde=n(Hye,"STRONG",{});var cft=s(yde);b0o=r(cft,"bert"),cft.forEach(t),v0o=r(Hye," \u2014 "),kq=n(Hye,"A",{href:!0});var fft=s(kq);F0o=r(fft,"BertModel"),fft.forEach(t),T0o=r(Hye," (BERT model)"),Hye.forEach(t),M0o=i(x),Op=n(x,"LI",{});var Uye=s(Op);xde=n(Uye,"STRONG",{});var mft=s(xde);E0o=r(mft,"bert-generation"),mft.forEach(t),C0o=r(Uye," \u2014 "),Sq=n(Uye,"A",{href:!0});var gft=s(Sq);w0o=r(gft,"BertGenerationEncoder"),gft.forEach(t),A0o=r(Uye," (Bert Generation model)"),Uye.forEach(t),L0o=i(x),Vp=n(x,"LI",{});var Jye=s(Vp);$de=n(Jye,"STRONG",{});var hft=s($de);y0o=r(hft,"big_bird"),hft.forEach(t),x0o=r(Jye," \u2014 "),Rq=n(Jye,"A",{href:!0});var pft=s(Rq);$0o=r(pft,"BigBirdModel"),pft.forEach(t),k0o=r(Jye," (BigBird model)"),Jye.forEach(t),S0o=i(x),Xp=n(x,"LI",{});var Yye=s(Xp);kde=n(Yye,"STRONG",{});var _ft=s(kde);R0o=r(_ft,"bigbird_pegasus"),_ft.forEach(t),P0o=r(Yye," \u2014 "),Pq=n(Yye,"A",{href:!0});var uft=s(Pq);B0o=r(uft,"BigBirdPegasusModel"),uft.forEach(t),I0o=r(Yye," (BigBird-Pegasus model)"),Yye.forEach(t),N0o=i(x),zp=n(x,"LI",{});var Kye=s(zp);Sde=n(Kye,"STRONG",{});var bft=s(Sde);q0o=r(bft,"blenderbot"),bft.forEach(t),j0o=r(Kye," \u2014 "),Bq=n(Kye,"A",{href:!0});var vft=s(Bq);D0o=r(vft,"BlenderbotModel"),vft.forEach(t),G0o=r(Kye," (Blenderbot model)"),Kye.forEach(t),O0o=i(x),Wp=n(x,"LI",{});var Zye=s(Wp);Rde=n(Zye,"STRONG",{});var Fft=s(Rde);V0o=r(Fft,"blenderbot-small"),Fft.forEach(t),X0o=r(Zye," \u2014 "),Iq=n(Zye,"A",{href:!0});var Tft=s(Iq);z0o=r(Tft,"BlenderbotSmallModel"),Tft.forEach(t),W0o=r(Zye," (BlenderbotSmall model)"),Zye.forEach(t),Q0o=i(x),Qp=n(x,"LI",{});var e9e=s(Qp);Pde=n(e9e,"STRONG",{});var Mft=s(Pde);H0o=r(Mft,"bloom"),Mft.forEach(t),U0o=r(e9e," \u2014 "),Nq=n(e9e,"A",{href:!0});var Eft=s(Nq);J0o=r(Eft,"BloomModel"),Eft.forEach(t),Y0o=r(e9e," (BLOOM model)"),e9e.forEach(t),K0o=i(x),Hp=n(x,"LI",{});var o9e=s(Hp);Bde=n(o9e,"STRONG",{});var Cft=s(Bde);Z0o=r(Cft,"camembert"),Cft.forEach(t),eFo=r(o9e," \u2014 "),qq=n(o9e,"A",{href:!0});var wft=s(qq);oFo=r(wft,"CamembertModel"),wft.forEach(t),rFo=r(o9e," (CamemBERT model)"),o9e.forEach(t),tFo=i(x),Up=n(x,"LI",{});var r9e=s(Up);Ide=n(r9e,"STRONG",{});var Aft=s(Ide);aFo=r(Aft,"canine"),Aft.forEach(t),nFo=r(r9e," \u2014 "),jq=n(r9e,"A",{href:!0});var Lft=s(jq);sFo=r(Lft,"CanineModel"),Lft.forEach(t),lFo=r(r9e," (CANINE model)"),r9e.forEach(t),iFo=i(x),Jp=n(x,"LI",{});var t9e=s(Jp);Nde=n(t9e,"STRONG",{});var yft=s(Nde);dFo=r(yft,"clip"),yft.forEach(t),cFo=r(t9e," \u2014 "),Dq=n(t9e,"A",{href:!0});var xft=s(Dq);fFo=r(xft,"CLIPModel"),xft.forEach(t),mFo=r(t9e," (CLIP model)"),t9e.forEach(t),gFo=i(x),Yp=n(x,"LI",{});var a9e=s(Yp);qde=n(a9e,"STRONG",{});var $ft=s(qde);hFo=r($ft,"codegen"),$ft.forEach(t),pFo=r(a9e," \u2014 "),Gq=n(a9e,"A",{href:!0});var kft=s(Gq);_Fo=r(kft,"CodeGenModel"),kft.forEach(t),uFo=r(a9e," (CodeGen model)"),a9e.forEach(t),bFo=i(x),Kp=n(x,"LI",{});var n9e=s(Kp);jde=n(n9e,"STRONG",{});var Sft=s(jde);vFo=r(Sft,"convbert"),Sft.forEach(t),FFo=r(n9e," \u2014 "),Oq=n(n9e,"A",{href:!0});var Rft=s(Oq);TFo=r(Rft,"ConvBertModel"),Rft.forEach(t),MFo=r(n9e," (ConvBERT model)"),n9e.forEach(t),EFo=i(x),Zp=n(x,"LI",{});var s9e=s(Zp);Dde=n(s9e,"STRONG",{});var Pft=s(Dde);CFo=r(Pft,"convnext"),Pft.forEach(t),wFo=r(s9e," \u2014 "),Vq=n(s9e,"A",{href:!0});var Bft=s(Vq);AFo=r(Bft,"ConvNextModel"),Bft.forEach(t),LFo=r(s9e," (ConvNeXT model)"),s9e.forEach(t),yFo=i(x),e_=n(x,"LI",{});var l9e=s(e_);Gde=n(l9e,"STRONG",{});var Ift=s(Gde);xFo=r(Ift,"ctrl"),Ift.forEach(t),$Fo=r(l9e," \u2014 "),Xq=n(l9e,"A",{href:!0});var Nft=s(Xq);kFo=r(Nft,"CTRLModel"),Nft.forEach(t),SFo=r(l9e," (CTRL model)"),l9e.forEach(t),RFo=i(x),o_=n(x,"LI",{});var i9e=s(o_);Ode=n(i9e,"STRONG",{});var qft=s(Ode);PFo=r(qft,"cvt"),qft.forEach(t),BFo=r(i9e," \u2014 "),zq=n(i9e,"A",{href:!0});var jft=s(zq);IFo=r(jft,"CvtModel"),jft.forEach(t),NFo=r(i9e," (CvT model)"),i9e.forEach(t),qFo=i(x),r_=n(x,"LI",{});var d9e=s(r_);Vde=n(d9e,"STRONG",{});var Dft=s(Vde);jFo=r(Dft,"data2vec-audio"),Dft.forEach(t),DFo=r(d9e," \u2014 "),Wq=n(d9e,"A",{href:!0});var Gft=s(Wq);GFo=r(Gft,"Data2VecAudioModel"),Gft.forEach(t),OFo=r(d9e," (Data2VecAudio model)"),d9e.forEach(t),VFo=i(x),t_=n(x,"LI",{});var c9e=s(t_);Xde=n(c9e,"STRONG",{});var Oft=s(Xde);XFo=r(Oft,"data2vec-text"),Oft.forEach(t),zFo=r(c9e," \u2014 "),Qq=n(c9e,"A",{href:!0});var Vft=s(Qq);WFo=r(Vft,"Data2VecTextModel"),Vft.forEach(t),QFo=r(c9e," (Data2VecText model)"),c9e.forEach(t),HFo=i(x),a_=n(x,"LI",{});var f9e=s(a_);zde=n(f9e,"STRONG",{});var Xft=s(zde);UFo=r(Xft,"data2vec-vision"),Xft.forEach(t),JFo=r(f9e," \u2014 "),Hq=n(f9e,"A",{href:!0});var zft=s(Hq);YFo=r(zft,"Data2VecVisionModel"),zft.forEach(t),KFo=r(f9e," (Data2VecVision model)"),f9e.forEach(t),ZFo=i(x),n_=n(x,"LI",{});var m9e=s(n_);Wde=n(m9e,"STRONG",{});var Wft=s(Wde);e6o=r(Wft,"deberta"),Wft.forEach(t),o6o=r(m9e," \u2014 "),Uq=n(m9e,"A",{href:!0});var Qft=s(Uq);r6o=r(Qft,"DebertaModel"),Qft.forEach(t),t6o=r(m9e," (DeBERTa model)"),m9e.forEach(t),a6o=i(x),s_=n(x,"LI",{});var g9e=s(s_);Qde=n(g9e,"STRONG",{});var Hft=s(Qde);n6o=r(Hft,"deberta-v2"),Hft.forEach(t),s6o=r(g9e," \u2014 "),Jq=n(g9e,"A",{href:!0});var Uft=s(Jq);l6o=r(Uft,"DebertaV2Model"),Uft.forEach(t),i6o=r(g9e," (DeBERTa-v2 model)"),g9e.forEach(t),d6o=i(x),l_=n(x,"LI",{});var h9e=s(l_);Hde=n(h9e,"STRONG",{});var Jft=s(Hde);c6o=r(Jft,"decision_transformer"),Jft.forEach(t),f6o=r(h9e," \u2014 "),Yq=n(h9e,"A",{href:!0});var Yft=s(Yq);m6o=r(Yft,"DecisionTransformerModel"),Yft.forEach(t),g6o=r(h9e," (Decision Transformer model)"),h9e.forEach(t),h6o=i(x),i_=n(x,"LI",{});var p9e=s(i_);Ude=n(p9e,"STRONG",{});var Kft=s(Ude);p6o=r(Kft,"deit"),Kft.forEach(t),_6o=r(p9e," \u2014 "),Kq=n(p9e,"A",{href:!0});var Zft=s(Kq);u6o=r(Zft,"DeiTModel"),Zft.forEach(t),b6o=r(p9e," (DeiT model)"),p9e.forEach(t),v6o=i(x),d_=n(x,"LI",{});var _9e=s(d_);Jde=n(_9e,"STRONG",{});var emt=s(Jde);F6o=r(emt,"detr"),emt.forEach(t),T6o=r(_9e," \u2014 "),Zq=n(_9e,"A",{href:!0});var omt=s(Zq);M6o=r(omt,"DetrModel"),omt.forEach(t),E6o=r(_9e," (DETR model)"),_9e.forEach(t),C6o=i(x),c_=n(x,"LI",{});var u9e=s(c_);Yde=n(u9e,"STRONG",{});var rmt=s(Yde);w6o=r(rmt,"distilbert"),rmt.forEach(t),A6o=r(u9e," \u2014 "),ej=n(u9e,"A",{href:!0});var tmt=s(ej);L6o=r(tmt,"DistilBertModel"),tmt.forEach(t),y6o=r(u9e," (DistilBERT model)"),u9e.forEach(t),x6o=i(x),f_=n(x,"LI",{});var b9e=s(f_);Kde=n(b9e,"STRONG",{});var amt=s(Kde);$6o=r(amt,"dpr"),amt.forEach(t),k6o=r(b9e," \u2014 "),oj=n(b9e,"A",{href:!0});var nmt=s(oj);S6o=r(nmt,"DPRQuestionEncoder"),nmt.forEach(t),R6o=r(b9e," (DPR model)"),b9e.forEach(t),P6o=i(x),m_=n(x,"LI",{});var v9e=s(m_);Zde=n(v9e,"STRONG",{});var smt=s(Zde);B6o=r(smt,"dpt"),smt.forEach(t),I6o=r(v9e," \u2014 "),rj=n(v9e,"A",{href:!0});var lmt=s(rj);N6o=r(lmt,"DPTModel"),lmt.forEach(t),q6o=r(v9e," (DPT model)"),v9e.forEach(t),j6o=i(x),g_=n(x,"LI",{});var F9e=s(g_);ece=n(F9e,"STRONG",{});var imt=s(ece);D6o=r(imt,"electra"),imt.forEach(t),G6o=r(F9e," \u2014 "),tj=n(F9e,"A",{href:!0});var dmt=s(tj);O6o=r(dmt,"ElectraModel"),dmt.forEach(t),V6o=r(F9e," (ELECTRA model)"),F9e.forEach(t),X6o=i(x),h_=n(x,"LI",{});var T9e=s(h_);oce=n(T9e,"STRONG",{});var cmt=s(oce);z6o=r(cmt,"flaubert"),cmt.forEach(t),W6o=r(T9e," \u2014 "),aj=n(T9e,"A",{href:!0});var fmt=s(aj);Q6o=r(fmt,"FlaubertModel"),fmt.forEach(t),H6o=r(T9e," (FlauBERT model)"),T9e.forEach(t),U6o=i(x),p_=n(x,"LI",{});var M9e=s(p_);rce=n(M9e,"STRONG",{});var mmt=s(rce);J6o=r(mmt,"flava"),mmt.forEach(t),Y6o=r(M9e," \u2014 "),nj=n(M9e,"A",{href:!0});var gmt=s(nj);K6o=r(gmt,"FlavaModel"),gmt.forEach(t),Z6o=r(M9e," (FLAVA model)"),M9e.forEach(t),eTo=i(x),__=n(x,"LI",{});var E9e=s(__);tce=n(E9e,"STRONG",{});var hmt=s(tce);oTo=r(hmt,"fnet"),hmt.forEach(t),rTo=r(E9e," \u2014 "),sj=n(E9e,"A",{href:!0});var pmt=s(sj);tTo=r(pmt,"FNetModel"),pmt.forEach(t),aTo=r(E9e," (FNet model)"),E9e.forEach(t),nTo=i(x),u_=n(x,"LI",{});var C9e=s(u_);ace=n(C9e,"STRONG",{});var _mt=s(ace);sTo=r(_mt,"fsmt"),_mt.forEach(t),lTo=r(C9e," \u2014 "),lj=n(C9e,"A",{href:!0});var umt=s(lj);iTo=r(umt,"FSMTModel"),umt.forEach(t),dTo=r(C9e," (FairSeq Machine-Translation model)"),C9e.forEach(t),cTo=i(x),Ws=n(x,"LI",{});var gS=s(Ws);nce=n(gS,"STRONG",{});var bmt=s(nce);fTo=r(bmt,"funnel"),bmt.forEach(t),mTo=r(gS," \u2014 "),ij=n(gS,"A",{href:!0});var vmt=s(ij);gTo=r(vmt,"FunnelModel"),vmt.forEach(t),hTo=r(gS," or "),dj=n(gS,"A",{href:!0});var Fmt=s(dj);pTo=r(Fmt,"FunnelBaseModel"),Fmt.forEach(t),_To=r(gS," (Funnel Transformer model)"),gS.forEach(t),uTo=i(x),b_=n(x,"LI",{});var w9e=s(b_);sce=n(w9e,"STRONG",{});var Tmt=s(sce);bTo=r(Tmt,"glpn"),Tmt.forEach(t),vTo=r(w9e," \u2014 "),cj=n(w9e,"A",{href:!0});var Mmt=s(cj);FTo=r(Mmt,"GLPNModel"),Mmt.forEach(t),TTo=r(w9e," (GLPN model)"),w9e.forEach(t),MTo=i(x),v_=n(x,"LI",{});var A9e=s(v_);lce=n(A9e,"STRONG",{});var Emt=s(lce);ETo=r(Emt,"gpt2"),Emt.forEach(t),CTo=r(A9e," \u2014 "),fj=n(A9e,"A",{href:!0});var Cmt=s(fj);wTo=r(Cmt,"GPT2Model"),Cmt.forEach(t),ATo=r(A9e," (OpenAI GPT-2 model)"),A9e.forEach(t),LTo=i(x),F_=n(x,"LI",{});var L9e=s(F_);ice=n(L9e,"STRONG",{});var wmt=s(ice);yTo=r(wmt,"gpt_neo"),wmt.forEach(t),xTo=r(L9e," \u2014 "),mj=n(L9e,"A",{href:!0});var Amt=s(mj);$To=r(Amt,"GPTNeoModel"),Amt.forEach(t),kTo=r(L9e," (GPT Neo model)"),L9e.forEach(t),STo=i(x),T_=n(x,"LI",{});var y9e=s(T_);dce=n(y9e,"STRONG",{});var Lmt=s(dce);RTo=r(Lmt,"gpt_neox"),Lmt.forEach(t),PTo=r(y9e," \u2014 "),gj=n(y9e,"A",{href:!0});var ymt=s(gj);BTo=r(ymt,"GPTNeoXModel"),ymt.forEach(t),ITo=r(y9e," (GPT NeoX model)"),y9e.forEach(t),NTo=i(x),M_=n(x,"LI",{});var x9e=s(M_);cce=n(x9e,"STRONG",{});var xmt=s(cce);qTo=r(xmt,"gptj"),xmt.forEach(t),jTo=r(x9e," \u2014 "),hj=n(x9e,"A",{href:!0});var $mt=s(hj);DTo=r($mt,"GPTJModel"),$mt.forEach(t),GTo=r(x9e," (GPT-J model)"),x9e.forEach(t),OTo=i(x),E_=n(x,"LI",{});var $9e=s(E_);fce=n($9e,"STRONG",{});var kmt=s(fce);VTo=r(kmt,"groupvit"),kmt.forEach(t),XTo=r($9e," \u2014 "),pj=n($9e,"A",{href:!0});var Smt=s(pj);zTo=r(Smt,"GroupViTModel"),Smt.forEach(t),WTo=r($9e," (GroupViT model)"),$9e.forEach(t),QTo=i(x),C_=n(x,"LI",{});var k9e=s(C_);mce=n(k9e,"STRONG",{});var Rmt=s(mce);HTo=r(Rmt,"hubert"),Rmt.forEach(t),UTo=r(k9e," \u2014 "),_j=n(k9e,"A",{href:!0});var Pmt=s(_j);JTo=r(Pmt,"HubertModel"),Pmt.forEach(t),YTo=r(k9e," (Hubert model)"),k9e.forEach(t),KTo=i(x),w_=n(x,"LI",{});var S9e=s(w_);gce=n(S9e,"STRONG",{});var Bmt=s(gce);ZTo=r(Bmt,"ibert"),Bmt.forEach(t),e7o=r(S9e," \u2014 "),uj=n(S9e,"A",{href:!0});var Imt=s(uj);o7o=r(Imt,"IBertModel"),Imt.forEach(t),r7o=r(S9e," (I-BERT model)"),S9e.forEach(t),t7o=i(x),A_=n(x,"LI",{});var R9e=s(A_);hce=n(R9e,"STRONG",{});var Nmt=s(hce);a7o=r(Nmt,"imagegpt"),Nmt.forEach(t),n7o=r(R9e," \u2014 "),bj=n(R9e,"A",{href:!0});var qmt=s(bj);s7o=r(qmt,"ImageGPTModel"),qmt.forEach(t),l7o=r(R9e," (ImageGPT model)"),R9e.forEach(t),i7o=i(x),L_=n(x,"LI",{});var P9e=s(L_);pce=n(P9e,"STRONG",{});var jmt=s(pce);d7o=r(jmt,"layoutlm"),jmt.forEach(t),c7o=r(P9e," \u2014 "),vj=n(P9e,"A",{href:!0});var Dmt=s(vj);f7o=r(Dmt,"LayoutLMModel"),Dmt.forEach(t),m7o=r(P9e," (LayoutLM model)"),P9e.forEach(t),g7o=i(x),y_=n(x,"LI",{});var B9e=s(y_);_ce=n(B9e,"STRONG",{});var Gmt=s(_ce);h7o=r(Gmt,"layoutlmv2"),Gmt.forEach(t),p7o=r(B9e," \u2014 "),Fj=n(B9e,"A",{href:!0});var Omt=s(Fj);_7o=r(Omt,"LayoutLMv2Model"),Omt.forEach(t),u7o=r(B9e," (LayoutLMv2 model)"),B9e.forEach(t),b7o=i(x),x_=n(x,"LI",{});var I9e=s(x_);uce=n(I9e,"STRONG",{});var Vmt=s(uce);v7o=r(Vmt,"layoutlmv3"),Vmt.forEach(t),F7o=r(I9e," \u2014 "),Tj=n(I9e,"A",{href:!0});var Xmt=s(Tj);T7o=r(Xmt,"LayoutLMv3Model"),Xmt.forEach(t),M7o=r(I9e," (LayoutLMv3 model)"),I9e.forEach(t),E7o=i(x),$_=n(x,"LI",{});var N9e=s($_);bce=n(N9e,"STRONG",{});var zmt=s(bce);C7o=r(zmt,"led"),zmt.forEach(t),w7o=r(N9e," \u2014 "),Mj=n(N9e,"A",{href:!0});var Wmt=s(Mj);A7o=r(Wmt,"LEDModel"),Wmt.forEach(t),L7o=r(N9e," (LED model)"),N9e.forEach(t),y7o=i(x),k_=n(x,"LI",{});var q9e=s(k_);vce=n(q9e,"STRONG",{});var Qmt=s(vce);x7o=r(Qmt,"levit"),Qmt.forEach(t),$7o=r(q9e," \u2014 "),Ej=n(q9e,"A",{href:!0});var Hmt=s(Ej);k7o=r(Hmt,"LevitModel"),Hmt.forEach(t),S7o=r(q9e," (LeViT model)"),q9e.forEach(t),R7o=i(x),S_=n(x,"LI",{});var j9e=s(S_);Fce=n(j9e,"STRONG",{});var Umt=s(Fce);P7o=r(Umt,"longformer"),Umt.forEach(t),B7o=r(j9e," \u2014 "),Cj=n(j9e,"A",{href:!0});var Jmt=s(Cj);I7o=r(Jmt,"LongformerModel"),Jmt.forEach(t),N7o=r(j9e," (Longformer model)"),j9e.forEach(t),q7o=i(x),R_=n(x,"LI",{});var D9e=s(R_);Tce=n(D9e,"STRONG",{});var Ymt=s(Tce);j7o=r(Ymt,"longt5"),Ymt.forEach(t),D7o=r(D9e," \u2014 "),wj=n(D9e,"A",{href:!0});var Kmt=s(wj);G7o=r(Kmt,"LongT5Model"),Kmt.forEach(t),O7o=r(D9e," (LongT5 model)"),D9e.forEach(t),V7o=i(x),P_=n(x,"LI",{});var G9e=s(P_);Mce=n(G9e,"STRONG",{});var Zmt=s(Mce);X7o=r(Zmt,"luke"),Zmt.forEach(t),z7o=r(G9e," \u2014 "),Aj=n(G9e,"A",{href:!0});var egt=s(Aj);W7o=r(egt,"LukeModel"),egt.forEach(t),Q7o=r(G9e," (LUKE model)"),G9e.forEach(t),H7o=i(x),B_=n(x,"LI",{});var O9e=s(B_);Ece=n(O9e,"STRONG",{});var ogt=s(Ece);U7o=r(ogt,"lxmert"),ogt.forEach(t),J7o=r(O9e," \u2014 "),Lj=n(O9e,"A",{href:!0});var rgt=s(Lj);Y7o=r(rgt,"LxmertModel"),rgt.forEach(t),K7o=r(O9e," (LXMERT model)"),O9e.forEach(t),Z7o=i(x),I_=n(x,"LI",{});var V9e=s(I_);Cce=n(V9e,"STRONG",{});var tgt=s(Cce);e8o=r(tgt,"m2m_100"),tgt.forEach(t),o8o=r(V9e," \u2014 "),yj=n(V9e,"A",{href:!0});var agt=s(yj);r8o=r(agt,"M2M100Model"),agt.forEach(t),t8o=r(V9e," (M2M100 model)"),V9e.forEach(t),a8o=i(x),N_=n(x,"LI",{});var X9e=s(N_);wce=n(X9e,"STRONG",{});var ngt=s(wce);n8o=r(ngt,"marian"),ngt.forEach(t),s8o=r(X9e," \u2014 "),xj=n(X9e,"A",{href:!0});var sgt=s(xj);l8o=r(sgt,"MarianModel"),sgt.forEach(t),i8o=r(X9e," (Marian model)"),X9e.forEach(t),d8o=i(x),q_=n(x,"LI",{});var z9e=s(q_);Ace=n(z9e,"STRONG",{});var lgt=s(Ace);c8o=r(lgt,"maskformer"),lgt.forEach(t),f8o=r(z9e," \u2014 "),$j=n(z9e,"A",{href:!0});var igt=s($j);m8o=r(igt,"MaskFormerModel"),igt.forEach(t),g8o=r(z9e," (MaskFormer model)"),z9e.forEach(t),h8o=i(x),j_=n(x,"LI",{});var W9e=s(j_);Lce=n(W9e,"STRONG",{});var dgt=s(Lce);p8o=r(dgt,"mbart"),dgt.forEach(t),_8o=r(W9e," \u2014 "),kj=n(W9e,"A",{href:!0});var cgt=s(kj);u8o=r(cgt,"MBartModel"),cgt.forEach(t),b8o=r(W9e," (mBART model)"),W9e.forEach(t),v8o=i(x),D_=n(x,"LI",{});var Q9e=s(D_);yce=n(Q9e,"STRONG",{});var fgt=s(yce);F8o=r(fgt,"mctct"),fgt.forEach(t),T8o=r(Q9e," \u2014 "),Sj=n(Q9e,"A",{href:!0});var mgt=s(Sj);M8o=r(mgt,"MCTCTModel"),mgt.forEach(t),E8o=r(Q9e," (M-CTC-T model)"),Q9e.forEach(t),C8o=i(x),G_=n(x,"LI",{});var H9e=s(G_);xce=n(H9e,"STRONG",{});var ggt=s(xce);w8o=r(ggt,"megatron-bert"),ggt.forEach(t),A8o=r(H9e," \u2014 "),Rj=n(H9e,"A",{href:!0});var hgt=s(Rj);L8o=r(hgt,"MegatronBertModel"),hgt.forEach(t),y8o=r(H9e," (Megatron-BERT model)"),H9e.forEach(t),x8o=i(x),O_=n(x,"LI",{});var U9e=s(O_);$ce=n(U9e,"STRONG",{});var pgt=s($ce);$8o=r(pgt,"mobilebert"),pgt.forEach(t),k8o=r(U9e," \u2014 "),Pj=n(U9e,"A",{href:!0});var _gt=s(Pj);S8o=r(_gt,"MobileBertModel"),_gt.forEach(t),R8o=r(U9e," (MobileBERT model)"),U9e.forEach(t),P8o=i(x),V_=n(x,"LI",{});var J9e=s(V_);kce=n(J9e,"STRONG",{});var ugt=s(kce);B8o=r(ugt,"mpnet"),ugt.forEach(t),I8o=r(J9e," \u2014 "),Bj=n(J9e,"A",{href:!0});var bgt=s(Bj);N8o=r(bgt,"MPNetModel"),bgt.forEach(t),q8o=r(J9e," (MPNet model)"),J9e.forEach(t),j8o=i(x),X_=n(x,"LI",{});var Y9e=s(X_);Sce=n(Y9e,"STRONG",{});var vgt=s(Sce);D8o=r(vgt,"mt5"),vgt.forEach(t),G8o=r(Y9e," \u2014 "),Ij=n(Y9e,"A",{href:!0});var Fgt=s(Ij);O8o=r(Fgt,"MT5Model"),Fgt.forEach(t),V8o=r(Y9e," (MT5 model)"),Y9e.forEach(t),X8o=i(x),z_=n(x,"LI",{});var K9e=s(z_);Rce=n(K9e,"STRONG",{});var Tgt=s(Rce);z8o=r(Tgt,"nezha"),Tgt.forEach(t),W8o=r(K9e," \u2014 "),Nj=n(K9e,"A",{href:!0});var Mgt=s(Nj);Q8o=r(Mgt,"NezhaModel"),Mgt.forEach(t),H8o=r(K9e," (Nezha model)"),K9e.forEach(t),U8o=i(x),W_=n(x,"LI",{});var Z9e=s(W_);Pce=n(Z9e,"STRONG",{});var Egt=s(Pce);J8o=r(Egt,"nystromformer"),Egt.forEach(t),Y8o=r(Z9e," \u2014 "),qj=n(Z9e,"A",{href:!0});var Cgt=s(qj);K8o=r(Cgt,"NystromformerModel"),Cgt.forEach(t),Z8o=r(Z9e," (Nystr\xF6mformer model)"),Z9e.forEach(t),eMo=i(x),Q_=n(x,"LI",{});var exe=s(Q_);Bce=n(exe,"STRONG",{});var wgt=s(Bce);oMo=r(wgt,"openai-gpt"),wgt.forEach(t),rMo=r(exe," \u2014 "),jj=n(exe,"A",{href:!0});var Agt=s(jj);tMo=r(Agt,"OpenAIGPTModel"),Agt.forEach(t),aMo=r(exe," (OpenAI GPT model)"),exe.forEach(t),nMo=i(x),H_=n(x,"LI",{});var oxe=s(H_);Ice=n(oxe,"STRONG",{});var Lgt=s(Ice);sMo=r(Lgt,"opt"),Lgt.forEach(t),lMo=r(oxe," \u2014 "),Dj=n(oxe,"A",{href:!0});var ygt=s(Dj);iMo=r(ygt,"OPTModel"),ygt.forEach(t),dMo=r(oxe," (OPT model)"),oxe.forEach(t),cMo=i(x),U_=n(x,"LI",{});var rxe=s(U_);Nce=n(rxe,"STRONG",{});var xgt=s(Nce);fMo=r(xgt,"pegasus"),xgt.forEach(t),mMo=r(rxe," \u2014 "),Gj=n(rxe,"A",{href:!0});var $gt=s(Gj);gMo=r($gt,"PegasusModel"),$gt.forEach(t),hMo=r(rxe," (Pegasus model)"),rxe.forEach(t),pMo=i(x),J_=n(x,"LI",{});var txe=s(J_);qce=n(txe,"STRONG",{});var kgt=s(qce);_Mo=r(kgt,"perceiver"),kgt.forEach(t),uMo=r(txe," \u2014 "),Oj=n(txe,"A",{href:!0});var Sgt=s(Oj);bMo=r(Sgt,"PerceiverModel"),Sgt.forEach(t),vMo=r(txe," (Perceiver model)"),txe.forEach(t),FMo=i(x),Y_=n(x,"LI",{});var axe=s(Y_);jce=n(axe,"STRONG",{});var Rgt=s(jce);TMo=r(Rgt,"plbart"),Rgt.forEach(t),MMo=r(axe," \u2014 "),Vj=n(axe,"A",{href:!0});var Pgt=s(Vj);EMo=r(Pgt,"PLBartModel"),Pgt.forEach(t),CMo=r(axe," (PLBart model)"),axe.forEach(t),wMo=i(x),K_=n(x,"LI",{});var nxe=s(K_);Dce=n(nxe,"STRONG",{});var Bgt=s(Dce);AMo=r(Bgt,"poolformer"),Bgt.forEach(t),LMo=r(nxe," \u2014 "),Xj=n(nxe,"A",{href:!0});var Igt=s(Xj);yMo=r(Igt,"PoolFormerModel"),Igt.forEach(t),xMo=r(nxe," (PoolFormer model)"),nxe.forEach(t),$Mo=i(x),Z_=n(x,"LI",{});var sxe=s(Z_);Gce=n(sxe,"STRONG",{});var Ngt=s(Gce);kMo=r(Ngt,"prophetnet"),Ngt.forEach(t),SMo=r(sxe," \u2014 "),zj=n(sxe,"A",{href:!0});var qgt=s(zj);RMo=r(qgt,"ProphetNetModel"),qgt.forEach(t),PMo=r(sxe," (ProphetNet model)"),sxe.forEach(t),BMo=i(x),eu=n(x,"LI",{});var lxe=s(eu);Oce=n(lxe,"STRONG",{});var jgt=s(Oce);IMo=r(jgt,"qdqbert"),jgt.forEach(t),NMo=r(lxe," \u2014 "),Wj=n(lxe,"A",{href:!0});var Dgt=s(Wj);qMo=r(Dgt,"QDQBertModel"),Dgt.forEach(t),jMo=r(lxe," (QDQBert model)"),lxe.forEach(t),DMo=i(x),ou=n(x,"LI",{});var ixe=s(ou);Vce=n(ixe,"STRONG",{});var Ggt=s(Vce);GMo=r(Ggt,"reformer"),Ggt.forEach(t),OMo=r(ixe," \u2014 "),Qj=n(ixe,"A",{href:!0});var Ogt=s(Qj);VMo=r(Ogt,"ReformerModel"),Ogt.forEach(t),XMo=r(ixe," (Reformer model)"),ixe.forEach(t),zMo=i(x),ru=n(x,"LI",{});var dxe=s(ru);Xce=n(dxe,"STRONG",{});var Vgt=s(Xce);WMo=r(Vgt,"regnet"),Vgt.forEach(t),QMo=r(dxe," \u2014 "),Hj=n(dxe,"A",{href:!0});var Xgt=s(Hj);HMo=r(Xgt,"RegNetModel"),Xgt.forEach(t),UMo=r(dxe," (RegNet model)"),dxe.forEach(t),JMo=i(x),tu=n(x,"LI",{});var cxe=s(tu);zce=n(cxe,"STRONG",{});var zgt=s(zce);YMo=r(zgt,"rembert"),zgt.forEach(t),KMo=r(cxe," \u2014 "),Uj=n(cxe,"A",{href:!0});var Wgt=s(Uj);ZMo=r(Wgt,"RemBertModel"),Wgt.forEach(t),e4o=r(cxe," (RemBERT model)"),cxe.forEach(t),o4o=i(x),au=n(x,"LI",{});var fxe=s(au);Wce=n(fxe,"STRONG",{});var Qgt=s(Wce);r4o=r(Qgt,"resnet"),Qgt.forEach(t),t4o=r(fxe," \u2014 "),Jj=n(fxe,"A",{href:!0});var Hgt=s(Jj);a4o=r(Hgt,"ResNetModel"),Hgt.forEach(t),n4o=r(fxe," (ResNet model)"),fxe.forEach(t),s4o=i(x),nu=n(x,"LI",{});var mxe=s(nu);Qce=n(mxe,"STRONG",{});var Ugt=s(Qce);l4o=r(Ugt,"retribert"),Ugt.forEach(t),i4o=r(mxe," \u2014 "),Yj=n(mxe,"A",{href:!0});var Jgt=s(Yj);d4o=r(Jgt,"RetriBertModel"),Jgt.forEach(t),c4o=r(mxe," (RetriBERT model)"),mxe.forEach(t),f4o=i(x),su=n(x,"LI",{});var gxe=s(su);Hce=n(gxe,"STRONG",{});var Ygt=s(Hce);m4o=r(Ygt,"roberta"),Ygt.forEach(t),g4o=r(gxe," \u2014 "),Kj=n(gxe,"A",{href:!0});var Kgt=s(Kj);h4o=r(Kgt,"RobertaModel"),Kgt.forEach(t),p4o=r(gxe," (RoBERTa model)"),gxe.forEach(t),_4o=i(x),lu=n(x,"LI",{});var hxe=s(lu);Uce=n(hxe,"STRONG",{});var Zgt=s(Uce);u4o=r(Zgt,"roformer"),Zgt.forEach(t),b4o=r(hxe," \u2014 "),Zj=n(hxe,"A",{href:!0});var eht=s(Zj);v4o=r(eht,"RoFormerModel"),eht.forEach(t),F4o=r(hxe," (RoFormer model)"),hxe.forEach(t),T4o=i(x),iu=n(x,"LI",{});var pxe=s(iu);Jce=n(pxe,"STRONG",{});var oht=s(Jce);M4o=r(oht,"segformer"),oht.forEach(t),E4o=r(pxe," \u2014 "),eD=n(pxe,"A",{href:!0});var rht=s(eD);C4o=r(rht,"SegformerModel"),rht.forEach(t),w4o=r(pxe," (SegFormer model)"),pxe.forEach(t),A4o=i(x),du=n(x,"LI",{});var _xe=s(du);Yce=n(_xe,"STRONG",{});var tht=s(Yce);L4o=r(tht,"sew"),tht.forEach(t),y4o=r(_xe," \u2014 "),oD=n(_xe,"A",{href:!0});var aht=s(oD);x4o=r(aht,"SEWModel"),aht.forEach(t),$4o=r(_xe," (SEW model)"),_xe.forEach(t),k4o=i(x),cu=n(x,"LI",{});var uxe=s(cu);Kce=n(uxe,"STRONG",{});var nht=s(Kce);S4o=r(nht,"sew-d"),nht.forEach(t),R4o=r(uxe," \u2014 "),rD=n(uxe,"A",{href:!0});var sht=s(rD);P4o=r(sht,"SEWDModel"),sht.forEach(t),B4o=r(uxe," (SEW-D model)"),uxe.forEach(t),I4o=i(x),fu=n(x,"LI",{});var bxe=s(fu);Zce=n(bxe,"STRONG",{});var lht=s(Zce);N4o=r(lht,"speech_to_text"),lht.forEach(t),q4o=r(bxe," \u2014 "),tD=n(bxe,"A",{href:!0});var iht=s(tD);j4o=r(iht,"Speech2TextModel"),iht.forEach(t),D4o=r(bxe," (Speech2Text model)"),bxe.forEach(t),G4o=i(x),mu=n(x,"LI",{});var vxe=s(mu);efe=n(vxe,"STRONG",{});var dht=s(efe);O4o=r(dht,"splinter"),dht.forEach(t),V4o=r(vxe," \u2014 "),aD=n(vxe,"A",{href:!0});var cht=s(aD);X4o=r(cht,"SplinterModel"),cht.forEach(t),z4o=r(vxe," (Splinter model)"),vxe.forEach(t),W4o=i(x),gu=n(x,"LI",{});var Fxe=s(gu);ofe=n(Fxe,"STRONG",{});var fht=s(ofe);Q4o=r(fht,"squeezebert"),fht.forEach(t),H4o=r(Fxe," \u2014 "),nD=n(Fxe,"A",{href:!0});var mht=s(nD);U4o=r(mht,"SqueezeBertModel"),mht.forEach(t),J4o=r(Fxe," (SqueezeBERT model)"),Fxe.forEach(t),Y4o=i(x),hu=n(x,"LI",{});var Txe=s(hu);rfe=n(Txe,"STRONG",{});var ght=s(rfe);K4o=r(ght,"swin"),ght.forEach(t),Z4o=r(Txe," \u2014 "),sD=n(Txe,"A",{href:!0});var hht=s(sD);eEo=r(hht,"SwinModel"),hht.forEach(t),oEo=r(Txe," (Swin Transformer model)"),Txe.forEach(t),rEo=i(x),pu=n(x,"LI",{});var Mxe=s(pu);tfe=n(Mxe,"STRONG",{});var pht=s(tfe);tEo=r(pht,"t5"),pht.forEach(t),aEo=r(Mxe," \u2014 "),lD=n(Mxe,"A",{href:!0});var _ht=s(lD);nEo=r(_ht,"T5Model"),_ht.forEach(t),sEo=r(Mxe," (T5 model)"),Mxe.forEach(t),lEo=i(x),_u=n(x,"LI",{});var Exe=s(_u);afe=n(Exe,"STRONG",{});var uht=s(afe);iEo=r(uht,"tapas"),uht.forEach(t),dEo=r(Exe," \u2014 "),iD=n(Exe,"A",{href:!0});var bht=s(iD);cEo=r(bht,"TapasModel"),bht.forEach(t),fEo=r(Exe," (TAPAS model)"),Exe.forEach(t),mEo=i(x),uu=n(x,"LI",{});var Cxe=s(uu);nfe=n(Cxe,"STRONG",{});var vht=s(nfe);gEo=r(vht,"trajectory_transformer"),vht.forEach(t),hEo=r(Cxe," \u2014 "),dD=n(Cxe,"A",{href:!0});var Fht=s(dD);pEo=r(Fht,"TrajectoryTransformerModel"),Fht.forEach(t),_Eo=r(Cxe," (Trajectory Transformer model)"),Cxe.forEach(t),uEo=i(x),bu=n(x,"LI",{});var wxe=s(bu);sfe=n(wxe,"STRONG",{});var Tht=s(sfe);bEo=r(Tht,"transfo-xl"),Tht.forEach(t),vEo=r(wxe," \u2014 "),cD=n(wxe,"A",{href:!0});var Mht=s(cD);FEo=r(Mht,"TransfoXLModel"),Mht.forEach(t),TEo=r(wxe," (Transformer-XL model)"),wxe.forEach(t),MEo=i(x),vu=n(x,"LI",{});var Axe=s(vu);lfe=n(Axe,"STRONG",{});var Eht=s(lfe);EEo=r(Eht,"unispeech"),Eht.forEach(t),CEo=r(Axe," \u2014 "),fD=n(Axe,"A",{href:!0});var Cht=s(fD);wEo=r(Cht,"UniSpeechModel"),Cht.forEach(t),AEo=r(Axe," (UniSpeech model)"),Axe.forEach(t),LEo=i(x),Fu=n(x,"LI",{});var Lxe=s(Fu);ife=n(Lxe,"STRONG",{});var wht=s(ife);yEo=r(wht,"unispeech-sat"),wht.forEach(t),xEo=r(Lxe," \u2014 "),mD=n(Lxe,"A",{href:!0});var Aht=s(mD);$Eo=r(Aht,"UniSpeechSatModel"),Aht.forEach(t),kEo=r(Lxe," (UniSpeechSat model)"),Lxe.forEach(t),SEo=i(x),Tu=n(x,"LI",{});var yxe=s(Tu);dfe=n(yxe,"STRONG",{});var Lht=s(dfe);REo=r(Lht,"van"),Lht.forEach(t),PEo=r(yxe," \u2014 "),gD=n(yxe,"A",{href:!0});var yht=s(gD);BEo=r(yht,"VanModel"),yht.forEach(t),IEo=r(yxe," (VAN model)"),yxe.forEach(t),NEo=i(x),Mu=n(x,"LI",{});var xxe=s(Mu);cfe=n(xxe,"STRONG",{});var xht=s(cfe);qEo=r(xht,"vilt"),xht.forEach(t),jEo=r(xxe," \u2014 "),hD=n(xxe,"A",{href:!0});var $ht=s(hD);DEo=r($ht,"ViltModel"),$ht.forEach(t),GEo=r(xxe," (ViLT model)"),xxe.forEach(t),OEo=i(x),Eu=n(x,"LI",{});var $xe=s(Eu);ffe=n($xe,"STRONG",{});var kht=s(ffe);VEo=r(kht,"vision-text-dual-encoder"),kht.forEach(t),XEo=r($xe," \u2014 "),pD=n($xe,"A",{href:!0});var Sht=s(pD);zEo=r(Sht,"VisionTextDualEncoderModel"),Sht.forEach(t),WEo=r($xe," (VisionTextDualEncoder model)"),$xe.forEach(t),QEo=i(x),Cu=n(x,"LI",{});var kxe=s(Cu);mfe=n(kxe,"STRONG",{});var Rht=s(mfe);HEo=r(Rht,"visual_bert"),Rht.forEach(t),UEo=r(kxe," \u2014 "),_D=n(kxe,"A",{href:!0});var Pht=s(_D);JEo=r(Pht,"VisualBertModel"),Pht.forEach(t),YEo=r(kxe," (VisualBERT model)"),kxe.forEach(t),KEo=i(x),wu=n(x,"LI",{});var Sxe=s(wu);gfe=n(Sxe,"STRONG",{});var Bht=s(gfe);ZEo=r(Bht,"vit"),Bht.forEach(t),eCo=r(Sxe," \u2014 "),uD=n(Sxe,"A",{href:!0});var Iht=s(uD);oCo=r(Iht,"ViTModel"),Iht.forEach(t),rCo=r(Sxe," (ViT model)"),Sxe.forEach(t),tCo=i(x),Au=n(x,"LI",{});var Rxe=s(Au);hfe=n(Rxe,"STRONG",{});var Nht=s(hfe);aCo=r(Nht,"vit_mae"),Nht.forEach(t),nCo=r(Rxe," \u2014 "),bD=n(Rxe,"A",{href:!0});var qht=s(bD);sCo=r(qht,"ViTMAEModel"),qht.forEach(t),lCo=r(Rxe," (ViTMAE model)"),Rxe.forEach(t),iCo=i(x),Lu=n(x,"LI",{});var Pxe=s(Lu);pfe=n(Pxe,"STRONG",{});var jht=s(pfe);dCo=r(jht,"wav2vec2"),jht.forEach(t),cCo=r(Pxe," \u2014 "),vD=n(Pxe,"A",{href:!0});var Dht=s(vD);fCo=r(Dht,"Wav2Vec2Model"),Dht.forEach(t),mCo=r(Pxe," (Wav2Vec2 model)"),Pxe.forEach(t),gCo=i(x),yu=n(x,"LI",{});var Bxe=s(yu);_fe=n(Bxe,"STRONG",{});var Ght=s(_fe);hCo=r(Ght,"wav2vec2-conformer"),Ght.forEach(t),pCo=r(Bxe," \u2014 "),FD=n(Bxe,"A",{href:!0});var Oht=s(FD);_Co=r(Oht,"Wav2Vec2ConformerModel"),Oht.forEach(t),uCo=r(Bxe," (Wav2Vec2-Conformer model)"),Bxe.forEach(t),bCo=i(x),xu=n(x,"LI",{});var Ixe=s(xu);ufe=n(Ixe,"STRONG",{});var Vht=s(ufe);vCo=r(Vht,"wavlm"),Vht.forEach(t),FCo=r(Ixe," \u2014 "),TD=n(Ixe,"A",{href:!0});var Xht=s(TD);TCo=r(Xht,"WavLMModel"),Xht.forEach(t),MCo=r(Ixe," (WavLM model)"),Ixe.forEach(t),ECo=i(x),$u=n(x,"LI",{});var Nxe=s($u);bfe=n(Nxe,"STRONG",{});var zht=s(bfe);CCo=r(zht,"xglm"),zht.forEach(t),wCo=r(Nxe," \u2014 "),MD=n(Nxe,"A",{href:!0});var Wht=s(MD);ACo=r(Wht,"XGLMModel"),Wht.forEach(t),LCo=r(Nxe," (XGLM model)"),Nxe.forEach(t),yCo=i(x),ku=n(x,"LI",{});var qxe=s(ku);vfe=n(qxe,"STRONG",{});var Qht=s(vfe);xCo=r(Qht,"xlm"),Qht.forEach(t),$Co=r(qxe," \u2014 "),ED=n(qxe,"A",{href:!0});var Hht=s(ED);kCo=r(Hht,"XLMModel"),Hht.forEach(t),SCo=r(qxe," (XLM model)"),qxe.forEach(t),RCo=i(x),Su=n(x,"LI",{});var jxe=s(Su);Ffe=n(jxe,"STRONG",{});var Uht=s(Ffe);PCo=r(Uht,"xlm-prophetnet"),Uht.forEach(t),BCo=r(jxe," \u2014 "),CD=n(jxe,"A",{href:!0});var Jht=s(CD);ICo=r(Jht,"XLMProphetNetModel"),Jht.forEach(t),NCo=r(jxe," (XLM-ProphetNet model)"),jxe.forEach(t),qCo=i(x),Ru=n(x,"LI",{});var Dxe=s(Ru);Tfe=n(Dxe,"STRONG",{});var Yht=s(Tfe);jCo=r(Yht,"xlm-roberta"),Yht.forEach(t),DCo=r(Dxe," \u2014 "),wD=n(Dxe,"A",{href:!0});var Kht=s(wD);GCo=r(Kht,"XLMRobertaModel"),Kht.forEach(t),OCo=r(Dxe," (XLM-RoBERTa model)"),Dxe.forEach(t),VCo=i(x),Pu=n(x,"LI",{});var Gxe=s(Pu);Mfe=n(Gxe,"STRONG",{});var Zht=s(Mfe);XCo=r(Zht,"xlm-roberta-xl"),Zht.forEach(t),zCo=r(Gxe," \u2014 "),AD=n(Gxe,"A",{href:!0});var ept=s(AD);WCo=r(ept,"XLMRobertaXLModel"),ept.forEach(t),QCo=r(Gxe," (XLM-RoBERTa-XL model)"),Gxe.forEach(t),HCo=i(x),Bu=n(x,"LI",{});var Oxe=s(Bu);Efe=n(Oxe,"STRONG",{});var opt=s(Efe);UCo=r(opt,"xlnet"),opt.forEach(t),JCo=r(Oxe," \u2014 "),LD=n(Oxe,"A",{href:!0});var rpt=s(LD);YCo=r(rpt,"XLNetModel"),rpt.forEach(t),KCo=r(Oxe," (XLNet model)"),Oxe.forEach(t),ZCo=i(x),Iu=n(x,"LI",{});var Vxe=s(Iu);Cfe=n(Vxe,"STRONG",{});var tpt=s(Cfe);e3o=r(tpt,"yolos"),tpt.forEach(t),o3o=r(Vxe," \u2014 "),yD=n(Vxe,"A",{href:!0});var apt=s(yD);r3o=r(apt,"YolosModel"),apt.forEach(t),t3o=r(Vxe," (YOLOS model)"),Vxe.forEach(t),a3o=i(x),Nu=n(x,"LI",{});var Xxe=s(Nu);wfe=n(Xxe,"STRONG",{});var npt=s(wfe);n3o=r(npt,"yoso"),npt.forEach(t),s3o=r(Xxe," \u2014 "),xD=n(Xxe,"A",{href:!0});var spt=s(xD);l3o=r(spt,"YosoModel"),spt.forEach(t),i3o=r(Xxe," (YOSO model)"),Xxe.forEach(t),x.forEach(t),d3o=i(na),qu=n(na,"P",{});var zxe=s(qu);c3o=r(zxe,"The model is set in evaluation mode by default using "),Afe=n(zxe,"CODE",{});var lpt=s(Afe);f3o=r(lpt,"model.eval()"),lpt.forEach(t),m3o=r(zxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lfe=n(zxe,"CODE",{});var ipt=s(Lfe);g3o=r(ipt,"model.train()"),ipt.forEach(t),zxe.forEach(t),h3o=i(na),T(ju.$$.fragment,na),na.forEach(t),ol.forEach(t),oVe=i(f),Oi=n(f,"H2",{class:!0});var lze=s(Oi);Du=n(lze,"A",{id:!0,class:!0,href:!0});var dpt=s(Du);yfe=n(dpt,"SPAN",{});var cpt=s(yfe);T(vL.$$.fragment,cpt),cpt.forEach(t),dpt.forEach(t),p3o=i(lze),xfe=n(lze,"SPAN",{});var fpt=s(xfe);_3o=r(fpt,"AutoModelForPreTraining"),fpt.forEach(t),lze.forEach(t),rVe=i(f),$o=n(f,"DIV",{class:!0});var rl=s($o);T(FL.$$.fragment,rl),u3o=i(rl),Vi=n(rl,"P",{});var Zoe=s(Vi);b3o=r(Zoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),$D=n(Zoe,"A",{href:!0});var mpt=s($D);v3o=r(mpt,"from_pretrained()"),mpt.forEach(t),F3o=r(Zoe," class method or the "),kD=n(Zoe,"A",{href:!0});var gpt=s(kD);T3o=r(gpt,"from_config()"),gpt.forEach(t),M3o=r(Zoe,` class
method.`),Zoe.forEach(t),E3o=i(rl),TL=n(rl,"P",{});var ize=s(TL);C3o=r(ize,"This class cannot be instantiated directly using "),$fe=n(ize,"CODE",{});var hpt=s($fe);w3o=r(hpt,"__init__()"),hpt.forEach(t),A3o=r(ize," (throws an error)."),ize.forEach(t),L3o=i(rl),lt=n(rl,"DIV",{class:!0});var Q5=s(lt);T(ML.$$.fragment,Q5),y3o=i(Q5),kfe=n(Q5,"P",{});var ppt=s(kfe);x3o=r(ppt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),ppt.forEach(t),$3o=i(Q5),Xi=n(Q5,"P",{});var ere=s(Xi);k3o=r(ere,`Note:
Loading a model from its configuration file does `),Sfe=n(ere,"STRONG",{});var _pt=s(Sfe);S3o=r(_pt,"not"),_pt.forEach(t),R3o=r(ere,` load the model weights. It only affects the
model\u2019s configuration. Use `),SD=n(ere,"A",{href:!0});var upt=s(SD);P3o=r(upt,"from_pretrained()"),upt.forEach(t),B3o=r(ere," to load the model weights."),ere.forEach(t),I3o=i(Q5),T(Gu.$$.fragment,Q5),Q5.forEach(t),N3o=i(rl),Ye=n(rl,"DIV",{class:!0});var sa=s(Ye);T(EL.$$.fragment,sa),q3o=i(sa),Rfe=n(sa,"P",{});var bpt=s(Rfe);j3o=r(bpt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),bpt.forEach(t),D3o=i(sa),Ia=n(sa,"P",{});var H5=s(Ia);G3o=r(H5,"The model class to instantiate is selected based on the "),Pfe=n(H5,"CODE",{});var vpt=s(Pfe);O3o=r(vpt,"model_type"),vpt.forEach(t),V3o=r(H5,` property of the config object (either
passed as an argument or loaded from `),Bfe=n(H5,"CODE",{});var Fpt=s(Bfe);X3o=r(Fpt,"pretrained_model_name_or_path"),Fpt.forEach(t),z3o=r(H5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ife=n(H5,"CODE",{});var Tpt=s(Ife);W3o=r(Tpt,"pretrained_model_name_or_path"),Tpt.forEach(t),Q3o=r(H5,":"),H5.forEach(t),H3o=i(sa),G=n(sa,"UL",{});var O=s(G);Ou=n(O,"LI",{});var Wxe=s(Ou);Nfe=n(Wxe,"STRONG",{});var Mpt=s(Nfe);U3o=r(Mpt,"albert"),Mpt.forEach(t),J3o=r(Wxe," \u2014 "),RD=n(Wxe,"A",{href:!0});var Ept=s(RD);Y3o=r(Ept,"AlbertForPreTraining"),Ept.forEach(t),K3o=r(Wxe," (ALBERT model)"),Wxe.forEach(t),Z3o=i(O),Vu=n(O,"LI",{});var Qxe=s(Vu);qfe=n(Qxe,"STRONG",{});var Cpt=s(qfe);e5o=r(Cpt,"bart"),Cpt.forEach(t),o5o=r(Qxe," \u2014 "),PD=n(Qxe,"A",{href:!0});var wpt=s(PD);r5o=r(wpt,"BartForConditionalGeneration"),wpt.forEach(t),t5o=r(Qxe," (BART model)"),Qxe.forEach(t),a5o=i(O),Xu=n(O,"LI",{});var Hxe=s(Xu);jfe=n(Hxe,"STRONG",{});var Apt=s(jfe);n5o=r(Apt,"bert"),Apt.forEach(t),s5o=r(Hxe," \u2014 "),BD=n(Hxe,"A",{href:!0});var Lpt=s(BD);l5o=r(Lpt,"BertForPreTraining"),Lpt.forEach(t),i5o=r(Hxe," (BERT model)"),Hxe.forEach(t),d5o=i(O),zu=n(O,"LI",{});var Uxe=s(zu);Dfe=n(Uxe,"STRONG",{});var ypt=s(Dfe);c5o=r(ypt,"big_bird"),ypt.forEach(t),f5o=r(Uxe," \u2014 "),ID=n(Uxe,"A",{href:!0});var xpt=s(ID);m5o=r(xpt,"BigBirdForPreTraining"),xpt.forEach(t),g5o=r(Uxe," (BigBird model)"),Uxe.forEach(t),h5o=i(O),Wu=n(O,"LI",{});var Jxe=s(Wu);Gfe=n(Jxe,"STRONG",{});var $pt=s(Gfe);p5o=r($pt,"bloom"),$pt.forEach(t),_5o=r(Jxe," \u2014 "),ND=n(Jxe,"A",{href:!0});var kpt=s(ND);u5o=r(kpt,"BloomForCausalLM"),kpt.forEach(t),b5o=r(Jxe," (BLOOM model)"),Jxe.forEach(t),v5o=i(O),Qu=n(O,"LI",{});var Yxe=s(Qu);Ofe=n(Yxe,"STRONG",{});var Spt=s(Ofe);F5o=r(Spt,"camembert"),Spt.forEach(t),T5o=r(Yxe," \u2014 "),qD=n(Yxe,"A",{href:!0});var Rpt=s(qD);M5o=r(Rpt,"CamembertForMaskedLM"),Rpt.forEach(t),E5o=r(Yxe," (CamemBERT model)"),Yxe.forEach(t),C5o=i(O),Hu=n(O,"LI",{});var Kxe=s(Hu);Vfe=n(Kxe,"STRONG",{});var Ppt=s(Vfe);w5o=r(Ppt,"ctrl"),Ppt.forEach(t),A5o=r(Kxe," \u2014 "),jD=n(Kxe,"A",{href:!0});var Bpt=s(jD);L5o=r(Bpt,"CTRLLMHeadModel"),Bpt.forEach(t),y5o=r(Kxe," (CTRL model)"),Kxe.forEach(t),x5o=i(O),Uu=n(O,"LI",{});var Zxe=s(Uu);Xfe=n(Zxe,"STRONG",{});var Ipt=s(Xfe);$5o=r(Ipt,"data2vec-text"),Ipt.forEach(t),k5o=r(Zxe," \u2014 "),DD=n(Zxe,"A",{href:!0});var Npt=s(DD);S5o=r(Npt,"Data2VecTextForMaskedLM"),Npt.forEach(t),R5o=r(Zxe," (Data2VecText model)"),Zxe.forEach(t),P5o=i(O),Ju=n(O,"LI",{});var e$e=s(Ju);zfe=n(e$e,"STRONG",{});var qpt=s(zfe);B5o=r(qpt,"deberta"),qpt.forEach(t),I5o=r(e$e," \u2014 "),GD=n(e$e,"A",{href:!0});var jpt=s(GD);N5o=r(jpt,"DebertaForMaskedLM"),jpt.forEach(t),q5o=r(e$e," (DeBERTa model)"),e$e.forEach(t),j5o=i(O),Yu=n(O,"LI",{});var o$e=s(Yu);Wfe=n(o$e,"STRONG",{});var Dpt=s(Wfe);D5o=r(Dpt,"deberta-v2"),Dpt.forEach(t),G5o=r(o$e," \u2014 "),OD=n(o$e,"A",{href:!0});var Gpt=s(OD);O5o=r(Gpt,"DebertaV2ForMaskedLM"),Gpt.forEach(t),V5o=r(o$e," (DeBERTa-v2 model)"),o$e.forEach(t),X5o=i(O),Ku=n(O,"LI",{});var r$e=s(Ku);Qfe=n(r$e,"STRONG",{});var Opt=s(Qfe);z5o=r(Opt,"distilbert"),Opt.forEach(t),W5o=r(r$e," \u2014 "),VD=n(r$e,"A",{href:!0});var Vpt=s(VD);Q5o=r(Vpt,"DistilBertForMaskedLM"),Vpt.forEach(t),H5o=r(r$e," (DistilBERT model)"),r$e.forEach(t),U5o=i(O),Zu=n(O,"LI",{});var t$e=s(Zu);Hfe=n(t$e,"STRONG",{});var Xpt=s(Hfe);J5o=r(Xpt,"electra"),Xpt.forEach(t),Y5o=r(t$e," \u2014 "),XD=n(t$e,"A",{href:!0});var zpt=s(XD);K5o=r(zpt,"ElectraForPreTraining"),zpt.forEach(t),Z5o=r(t$e," (ELECTRA model)"),t$e.forEach(t),ewo=i(O),e1=n(O,"LI",{});var a$e=s(e1);Ufe=n(a$e,"STRONG",{});var Wpt=s(Ufe);owo=r(Wpt,"flaubert"),Wpt.forEach(t),rwo=r(a$e," \u2014 "),zD=n(a$e,"A",{href:!0});var Qpt=s(zD);two=r(Qpt,"FlaubertWithLMHeadModel"),Qpt.forEach(t),awo=r(a$e," (FlauBERT model)"),a$e.forEach(t),nwo=i(O),o1=n(O,"LI",{});var n$e=s(o1);Jfe=n(n$e,"STRONG",{});var Hpt=s(Jfe);swo=r(Hpt,"flava"),Hpt.forEach(t),lwo=r(n$e," \u2014 "),WD=n(n$e,"A",{href:!0});var Upt=s(WD);iwo=r(Upt,"FlavaForPreTraining"),Upt.forEach(t),dwo=r(n$e," (FLAVA model)"),n$e.forEach(t),cwo=i(O),r1=n(O,"LI",{});var s$e=s(r1);Yfe=n(s$e,"STRONG",{});var Jpt=s(Yfe);fwo=r(Jpt,"fnet"),Jpt.forEach(t),mwo=r(s$e," \u2014 "),QD=n(s$e,"A",{href:!0});var Ypt=s(QD);gwo=r(Ypt,"FNetForPreTraining"),Ypt.forEach(t),hwo=r(s$e," (FNet model)"),s$e.forEach(t),pwo=i(O),t1=n(O,"LI",{});var l$e=s(t1);Kfe=n(l$e,"STRONG",{});var Kpt=s(Kfe);_wo=r(Kpt,"fsmt"),Kpt.forEach(t),uwo=r(l$e," \u2014 "),HD=n(l$e,"A",{href:!0});var Zpt=s(HD);bwo=r(Zpt,"FSMTForConditionalGeneration"),Zpt.forEach(t),vwo=r(l$e," (FairSeq Machine-Translation model)"),l$e.forEach(t),Fwo=i(O),a1=n(O,"LI",{});var i$e=s(a1);Zfe=n(i$e,"STRONG",{});var e_t=s(Zfe);Two=r(e_t,"funnel"),e_t.forEach(t),Mwo=r(i$e," \u2014 "),UD=n(i$e,"A",{href:!0});var o_t=s(UD);Ewo=r(o_t,"FunnelForPreTraining"),o_t.forEach(t),Cwo=r(i$e," (Funnel Transformer model)"),i$e.forEach(t),wwo=i(O),n1=n(O,"LI",{});var d$e=s(n1);eme=n(d$e,"STRONG",{});var r_t=s(eme);Awo=r(r_t,"gpt2"),r_t.forEach(t),Lwo=r(d$e," \u2014 "),JD=n(d$e,"A",{href:!0});var t_t=s(JD);ywo=r(t_t,"GPT2LMHeadModel"),t_t.forEach(t),xwo=r(d$e," (OpenAI GPT-2 model)"),d$e.forEach(t),$wo=i(O),s1=n(O,"LI",{});var c$e=s(s1);ome=n(c$e,"STRONG",{});var a_t=s(ome);kwo=r(a_t,"ibert"),a_t.forEach(t),Swo=r(c$e," \u2014 "),YD=n(c$e,"A",{href:!0});var n_t=s(YD);Rwo=r(n_t,"IBertForMaskedLM"),n_t.forEach(t),Pwo=r(c$e," (I-BERT model)"),c$e.forEach(t),Bwo=i(O),l1=n(O,"LI",{});var f$e=s(l1);rme=n(f$e,"STRONG",{});var s_t=s(rme);Iwo=r(s_t,"layoutlm"),s_t.forEach(t),Nwo=r(f$e," \u2014 "),KD=n(f$e,"A",{href:!0});var l_t=s(KD);qwo=r(l_t,"LayoutLMForMaskedLM"),l_t.forEach(t),jwo=r(f$e," (LayoutLM model)"),f$e.forEach(t),Dwo=i(O),i1=n(O,"LI",{});var m$e=s(i1);tme=n(m$e,"STRONG",{});var i_t=s(tme);Gwo=r(i_t,"longformer"),i_t.forEach(t),Owo=r(m$e," \u2014 "),ZD=n(m$e,"A",{href:!0});var d_t=s(ZD);Vwo=r(d_t,"LongformerForMaskedLM"),d_t.forEach(t),Xwo=r(m$e," (Longformer model)"),m$e.forEach(t),zwo=i(O),d1=n(O,"LI",{});var g$e=s(d1);ame=n(g$e,"STRONG",{});var c_t=s(ame);Wwo=r(c_t,"lxmert"),c_t.forEach(t),Qwo=r(g$e," \u2014 "),eG=n(g$e,"A",{href:!0});var f_t=s(eG);Hwo=r(f_t,"LxmertForPreTraining"),f_t.forEach(t),Uwo=r(g$e," (LXMERT model)"),g$e.forEach(t),Jwo=i(O),c1=n(O,"LI",{});var h$e=s(c1);nme=n(h$e,"STRONG",{});var m_t=s(nme);Ywo=r(m_t,"megatron-bert"),m_t.forEach(t),Kwo=r(h$e," \u2014 "),oG=n(h$e,"A",{href:!0});var g_t=s(oG);Zwo=r(g_t,"MegatronBertForPreTraining"),g_t.forEach(t),eAo=r(h$e," (Megatron-BERT model)"),h$e.forEach(t),oAo=i(O),f1=n(O,"LI",{});var p$e=s(f1);sme=n(p$e,"STRONG",{});var h_t=s(sme);rAo=r(h_t,"mobilebert"),h_t.forEach(t),tAo=r(p$e," \u2014 "),rG=n(p$e,"A",{href:!0});var p_t=s(rG);aAo=r(p_t,"MobileBertForPreTraining"),p_t.forEach(t),nAo=r(p$e," (MobileBERT model)"),p$e.forEach(t),sAo=i(O),m1=n(O,"LI",{});var _$e=s(m1);lme=n(_$e,"STRONG",{});var __t=s(lme);lAo=r(__t,"mpnet"),__t.forEach(t),iAo=r(_$e," \u2014 "),tG=n(_$e,"A",{href:!0});var u_t=s(tG);dAo=r(u_t,"MPNetForMaskedLM"),u_t.forEach(t),cAo=r(_$e," (MPNet model)"),_$e.forEach(t),fAo=i(O),g1=n(O,"LI",{});var u$e=s(g1);ime=n(u$e,"STRONG",{});var b_t=s(ime);mAo=r(b_t,"nezha"),b_t.forEach(t),gAo=r(u$e," \u2014 "),aG=n(u$e,"A",{href:!0});var v_t=s(aG);hAo=r(v_t,"NezhaForPreTraining"),v_t.forEach(t),pAo=r(u$e," (Nezha model)"),u$e.forEach(t),_Ao=i(O),h1=n(O,"LI",{});var b$e=s(h1);dme=n(b$e,"STRONG",{});var F_t=s(dme);uAo=r(F_t,"openai-gpt"),F_t.forEach(t),bAo=r(b$e," \u2014 "),nG=n(b$e,"A",{href:!0});var T_t=s(nG);vAo=r(T_t,"OpenAIGPTLMHeadModel"),T_t.forEach(t),FAo=r(b$e," (OpenAI GPT model)"),b$e.forEach(t),TAo=i(O),p1=n(O,"LI",{});var v$e=s(p1);cme=n(v$e,"STRONG",{});var M_t=s(cme);MAo=r(M_t,"retribert"),M_t.forEach(t),EAo=r(v$e," \u2014 "),sG=n(v$e,"A",{href:!0});var E_t=s(sG);CAo=r(E_t,"RetriBertModel"),E_t.forEach(t),wAo=r(v$e," (RetriBERT model)"),v$e.forEach(t),AAo=i(O),_1=n(O,"LI",{});var F$e=s(_1);fme=n(F$e,"STRONG",{});var C_t=s(fme);LAo=r(C_t,"roberta"),C_t.forEach(t),yAo=r(F$e," \u2014 "),lG=n(F$e,"A",{href:!0});var w_t=s(lG);xAo=r(w_t,"RobertaForMaskedLM"),w_t.forEach(t),$Ao=r(F$e," (RoBERTa model)"),F$e.forEach(t),kAo=i(O),u1=n(O,"LI",{});var T$e=s(u1);mme=n(T$e,"STRONG",{});var A_t=s(mme);SAo=r(A_t,"splinter"),A_t.forEach(t),RAo=r(T$e," \u2014 "),iG=n(T$e,"A",{href:!0});var L_t=s(iG);PAo=r(L_t,"SplinterForPreTraining"),L_t.forEach(t),BAo=r(T$e," (Splinter model)"),T$e.forEach(t),IAo=i(O),b1=n(O,"LI",{});var M$e=s(b1);gme=n(M$e,"STRONG",{});var y_t=s(gme);NAo=r(y_t,"squeezebert"),y_t.forEach(t),qAo=r(M$e," \u2014 "),dG=n(M$e,"A",{href:!0});var x_t=s(dG);jAo=r(x_t,"SqueezeBertForMaskedLM"),x_t.forEach(t),DAo=r(M$e," (SqueezeBERT model)"),M$e.forEach(t),GAo=i(O),v1=n(O,"LI",{});var E$e=s(v1);hme=n(E$e,"STRONG",{});var $_t=s(hme);OAo=r($_t,"t5"),$_t.forEach(t),VAo=r(E$e," \u2014 "),cG=n(E$e,"A",{href:!0});var k_t=s(cG);XAo=r(k_t,"T5ForConditionalGeneration"),k_t.forEach(t),zAo=r(E$e," (T5 model)"),E$e.forEach(t),WAo=i(O),F1=n(O,"LI",{});var C$e=s(F1);pme=n(C$e,"STRONG",{});var S_t=s(pme);QAo=r(S_t,"tapas"),S_t.forEach(t),HAo=r(C$e," \u2014 "),fG=n(C$e,"A",{href:!0});var R_t=s(fG);UAo=r(R_t,"TapasForMaskedLM"),R_t.forEach(t),JAo=r(C$e," (TAPAS model)"),C$e.forEach(t),YAo=i(O),T1=n(O,"LI",{});var w$e=s(T1);_me=n(w$e,"STRONG",{});var P_t=s(_me);KAo=r(P_t,"transfo-xl"),P_t.forEach(t),ZAo=r(w$e," \u2014 "),mG=n(w$e,"A",{href:!0});var B_t=s(mG);eLo=r(B_t,"TransfoXLLMHeadModel"),B_t.forEach(t),oLo=r(w$e," (Transformer-XL model)"),w$e.forEach(t),rLo=i(O),M1=n(O,"LI",{});var A$e=s(M1);ume=n(A$e,"STRONG",{});var I_t=s(ume);tLo=r(I_t,"unispeech"),I_t.forEach(t),aLo=r(A$e," \u2014 "),gG=n(A$e,"A",{href:!0});var N_t=s(gG);nLo=r(N_t,"UniSpeechForPreTraining"),N_t.forEach(t),sLo=r(A$e," (UniSpeech model)"),A$e.forEach(t),lLo=i(O),E1=n(O,"LI",{});var L$e=s(E1);bme=n(L$e,"STRONG",{});var q_t=s(bme);iLo=r(q_t,"unispeech-sat"),q_t.forEach(t),dLo=r(L$e," \u2014 "),hG=n(L$e,"A",{href:!0});var j_t=s(hG);cLo=r(j_t,"UniSpeechSatForPreTraining"),j_t.forEach(t),fLo=r(L$e," (UniSpeechSat model)"),L$e.forEach(t),mLo=i(O),C1=n(O,"LI",{});var y$e=s(C1);vme=n(y$e,"STRONG",{});var D_t=s(vme);gLo=r(D_t,"visual_bert"),D_t.forEach(t),hLo=r(y$e," \u2014 "),pG=n(y$e,"A",{href:!0});var G_t=s(pG);pLo=r(G_t,"VisualBertForPreTraining"),G_t.forEach(t),_Lo=r(y$e," (VisualBERT model)"),y$e.forEach(t),uLo=i(O),w1=n(O,"LI",{});var x$e=s(w1);Fme=n(x$e,"STRONG",{});var O_t=s(Fme);bLo=r(O_t,"vit_mae"),O_t.forEach(t),vLo=r(x$e," \u2014 "),_G=n(x$e,"A",{href:!0});var V_t=s(_G);FLo=r(V_t,"ViTMAEForPreTraining"),V_t.forEach(t),TLo=r(x$e," (ViTMAE model)"),x$e.forEach(t),MLo=i(O),A1=n(O,"LI",{});var $$e=s(A1);Tme=n($$e,"STRONG",{});var X_t=s(Tme);ELo=r(X_t,"wav2vec2"),X_t.forEach(t),CLo=r($$e," \u2014 "),uG=n($$e,"A",{href:!0});var z_t=s(uG);wLo=r(z_t,"Wav2Vec2ForPreTraining"),z_t.forEach(t),ALo=r($$e," (Wav2Vec2 model)"),$$e.forEach(t),LLo=i(O),L1=n(O,"LI",{});var k$e=s(L1);Mme=n(k$e,"STRONG",{});var W_t=s(Mme);yLo=r(W_t,"wav2vec2-conformer"),W_t.forEach(t),xLo=r(k$e," \u2014 "),bG=n(k$e,"A",{href:!0});var Q_t=s(bG);$Lo=r(Q_t,"Wav2Vec2ConformerForPreTraining"),Q_t.forEach(t),kLo=r(k$e," (Wav2Vec2-Conformer model)"),k$e.forEach(t),SLo=i(O),y1=n(O,"LI",{});var S$e=s(y1);Eme=n(S$e,"STRONG",{});var H_t=s(Eme);RLo=r(H_t,"xlm"),H_t.forEach(t),PLo=r(S$e," \u2014 "),vG=n(S$e,"A",{href:!0});var U_t=s(vG);BLo=r(U_t,"XLMWithLMHeadModel"),U_t.forEach(t),ILo=r(S$e," (XLM model)"),S$e.forEach(t),NLo=i(O),x1=n(O,"LI",{});var R$e=s(x1);Cme=n(R$e,"STRONG",{});var J_t=s(Cme);qLo=r(J_t,"xlm-roberta"),J_t.forEach(t),jLo=r(R$e," \u2014 "),FG=n(R$e,"A",{href:!0});var Y_t=s(FG);DLo=r(Y_t,"XLMRobertaForMaskedLM"),Y_t.forEach(t),GLo=r(R$e," (XLM-RoBERTa model)"),R$e.forEach(t),OLo=i(O),$1=n(O,"LI",{});var P$e=s($1);wme=n(P$e,"STRONG",{});var K_t=s(wme);VLo=r(K_t,"xlm-roberta-xl"),K_t.forEach(t),XLo=r(P$e," \u2014 "),TG=n(P$e,"A",{href:!0});var Z_t=s(TG);zLo=r(Z_t,"XLMRobertaXLForMaskedLM"),Z_t.forEach(t),WLo=r(P$e," (XLM-RoBERTa-XL model)"),P$e.forEach(t),QLo=i(O),k1=n(O,"LI",{});var B$e=s(k1);Ame=n(B$e,"STRONG",{});var eut=s(Ame);HLo=r(eut,"xlnet"),eut.forEach(t),ULo=r(B$e," \u2014 "),MG=n(B$e,"A",{href:!0});var out=s(MG);JLo=r(out,"XLNetLMHeadModel"),out.forEach(t),YLo=r(B$e," (XLNet model)"),B$e.forEach(t),O.forEach(t),KLo=i(sa),S1=n(sa,"P",{});var I$e=s(S1);ZLo=r(I$e,"The model is set in evaluation mode by default using "),Lme=n(I$e,"CODE",{});var rut=s(Lme);eyo=r(rut,"model.eval()"),rut.forEach(t),oyo=r(I$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yme=n(I$e,"CODE",{});var tut=s(yme);ryo=r(tut,"model.train()"),tut.forEach(t),I$e.forEach(t),tyo=i(sa),T(R1.$$.fragment,sa),sa.forEach(t),rl.forEach(t),tVe=i(f),zi=n(f,"H2",{class:!0});var dze=s(zi);P1=n(dze,"A",{id:!0,class:!0,href:!0});var aut=s(P1);xme=n(aut,"SPAN",{});var nut=s(xme);T(CL.$$.fragment,nut),nut.forEach(t),aut.forEach(t),ayo=i(dze),$me=n(dze,"SPAN",{});var sut=s($me);nyo=r(sut,"AutoModelForCausalLM"),sut.forEach(t),dze.forEach(t),aVe=i(f),ko=n(f,"DIV",{class:!0});var tl=s(ko);T(wL.$$.fragment,tl),syo=i(tl),Wi=n(tl,"P",{});var ore=s(Wi);lyo=r(ore,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),EG=n(ore,"A",{href:!0});var lut=s(EG);iyo=r(lut,"from_pretrained()"),lut.forEach(t),dyo=r(ore," class method or the "),CG=n(ore,"A",{href:!0});var iut=s(CG);cyo=r(iut,"from_config()"),iut.forEach(t),fyo=r(ore,` class
method.`),ore.forEach(t),myo=i(tl),AL=n(tl,"P",{});var cze=s(AL);gyo=r(cze,"This class cannot be instantiated directly using "),kme=n(cze,"CODE",{});var dut=s(kme);hyo=r(dut,"__init__()"),dut.forEach(t),pyo=r(cze," (throws an error)."),cze.forEach(t),_yo=i(tl),it=n(tl,"DIV",{class:!0});var U5=s(it);T(LL.$$.fragment,U5),uyo=i(U5),Sme=n(U5,"P",{});var cut=s(Sme);byo=r(cut,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),cut.forEach(t),vyo=i(U5),Qi=n(U5,"P",{});var rre=s(Qi);Fyo=r(rre,`Note:
Loading a model from its configuration file does `),Rme=n(rre,"STRONG",{});var fut=s(Rme);Tyo=r(fut,"not"),fut.forEach(t),Myo=r(rre,` load the model weights. It only affects the
model\u2019s configuration. Use `),wG=n(rre,"A",{href:!0});var mut=s(wG);Eyo=r(mut,"from_pretrained()"),mut.forEach(t),Cyo=r(rre," to load the model weights."),rre.forEach(t),wyo=i(U5),T(B1.$$.fragment,U5),U5.forEach(t),Ayo=i(tl),Ke=n(tl,"DIV",{class:!0});var la=s(Ke);T(yL.$$.fragment,la),Lyo=i(la),Pme=n(la,"P",{});var gut=s(Pme);yyo=r(gut,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),gut.forEach(t),xyo=i(la),Na=n(la,"P",{});var J5=s(Na);$yo=r(J5,"The model class to instantiate is selected based on the "),Bme=n(J5,"CODE",{});var hut=s(Bme);kyo=r(hut,"model_type"),hut.forEach(t),Syo=r(J5,` property of the config object (either
passed as an argument or loaded from `),Ime=n(J5,"CODE",{});var put=s(Ime);Ryo=r(put,"pretrained_model_name_or_path"),put.forEach(t),Pyo=r(J5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nme=n(J5,"CODE",{});var _ut=s(Nme);Byo=r(_ut,"pretrained_model_name_or_path"),_ut.forEach(t),Iyo=r(J5,":"),J5.forEach(t),Nyo=i(la),z=n(la,"UL",{});var W=s(z);I1=n(W,"LI",{});var N$e=s(I1);qme=n(N$e,"STRONG",{});var uut=s(qme);qyo=r(uut,"bart"),uut.forEach(t),jyo=r(N$e," \u2014 "),AG=n(N$e,"A",{href:!0});var but=s(AG);Dyo=r(but,"BartForCausalLM"),but.forEach(t),Gyo=r(N$e," (BART model)"),N$e.forEach(t),Oyo=i(W),N1=n(W,"LI",{});var q$e=s(N1);jme=n(q$e,"STRONG",{});var vut=s(jme);Vyo=r(vut,"bert"),vut.forEach(t),Xyo=r(q$e," \u2014 "),LG=n(q$e,"A",{href:!0});var Fut=s(LG);zyo=r(Fut,"BertLMHeadModel"),Fut.forEach(t),Wyo=r(q$e," (BERT model)"),q$e.forEach(t),Qyo=i(W),q1=n(W,"LI",{});var j$e=s(q1);Dme=n(j$e,"STRONG",{});var Tut=s(Dme);Hyo=r(Tut,"bert-generation"),Tut.forEach(t),Uyo=r(j$e," \u2014 "),yG=n(j$e,"A",{href:!0});var Mut=s(yG);Jyo=r(Mut,"BertGenerationDecoder"),Mut.forEach(t),Yyo=r(j$e," (Bert Generation model)"),j$e.forEach(t),Kyo=i(W),j1=n(W,"LI",{});var D$e=s(j1);Gme=n(D$e,"STRONG",{});var Eut=s(Gme);Zyo=r(Eut,"big_bird"),Eut.forEach(t),e9o=r(D$e," \u2014 "),xG=n(D$e,"A",{href:!0});var Cut=s(xG);o9o=r(Cut,"BigBirdForCausalLM"),Cut.forEach(t),r9o=r(D$e," (BigBird model)"),D$e.forEach(t),t9o=i(W),D1=n(W,"LI",{});var G$e=s(D1);Ome=n(G$e,"STRONG",{});var wut=s(Ome);a9o=r(wut,"bigbird_pegasus"),wut.forEach(t),n9o=r(G$e," \u2014 "),$G=n(G$e,"A",{href:!0});var Aut=s($G);s9o=r(Aut,"BigBirdPegasusForCausalLM"),Aut.forEach(t),l9o=r(G$e," (BigBird-Pegasus model)"),G$e.forEach(t),i9o=i(W),G1=n(W,"LI",{});var O$e=s(G1);Vme=n(O$e,"STRONG",{});var Lut=s(Vme);d9o=r(Lut,"blenderbot"),Lut.forEach(t),c9o=r(O$e," \u2014 "),kG=n(O$e,"A",{href:!0});var yut=s(kG);f9o=r(yut,"BlenderbotForCausalLM"),yut.forEach(t),m9o=r(O$e," (Blenderbot model)"),O$e.forEach(t),g9o=i(W),O1=n(W,"LI",{});var V$e=s(O1);Xme=n(V$e,"STRONG",{});var xut=s(Xme);h9o=r(xut,"blenderbot-small"),xut.forEach(t),p9o=r(V$e," \u2014 "),SG=n(V$e,"A",{href:!0});var $ut=s(SG);_9o=r($ut,"BlenderbotSmallForCausalLM"),$ut.forEach(t),u9o=r(V$e," (BlenderbotSmall model)"),V$e.forEach(t),b9o=i(W),V1=n(W,"LI",{});var X$e=s(V1);zme=n(X$e,"STRONG",{});var kut=s(zme);v9o=r(kut,"bloom"),kut.forEach(t),F9o=r(X$e," \u2014 "),RG=n(X$e,"A",{href:!0});var Sut=s(RG);T9o=r(Sut,"BloomForCausalLM"),Sut.forEach(t),M9o=r(X$e," (BLOOM model)"),X$e.forEach(t),E9o=i(W),X1=n(W,"LI",{});var z$e=s(X1);Wme=n(z$e,"STRONG",{});var Rut=s(Wme);C9o=r(Rut,"camembert"),Rut.forEach(t),w9o=r(z$e," \u2014 "),PG=n(z$e,"A",{href:!0});var Put=s(PG);A9o=r(Put,"CamembertForCausalLM"),Put.forEach(t),L9o=r(z$e," (CamemBERT model)"),z$e.forEach(t),y9o=i(W),z1=n(W,"LI",{});var W$e=s(z1);Qme=n(W$e,"STRONG",{});var But=s(Qme);x9o=r(But,"codegen"),But.forEach(t),$9o=r(W$e," \u2014 "),BG=n(W$e,"A",{href:!0});var Iut=s(BG);k9o=r(Iut,"CodeGenForCausalLM"),Iut.forEach(t),S9o=r(W$e," (CodeGen model)"),W$e.forEach(t),R9o=i(W),W1=n(W,"LI",{});var Q$e=s(W1);Hme=n(Q$e,"STRONG",{});var Nut=s(Hme);P9o=r(Nut,"ctrl"),Nut.forEach(t),B9o=r(Q$e," \u2014 "),IG=n(Q$e,"A",{href:!0});var qut=s(IG);I9o=r(qut,"CTRLLMHeadModel"),qut.forEach(t),N9o=r(Q$e," (CTRL model)"),Q$e.forEach(t),q9o=i(W),Q1=n(W,"LI",{});var H$e=s(Q1);Ume=n(H$e,"STRONG",{});var jut=s(Ume);j9o=r(jut,"data2vec-text"),jut.forEach(t),D9o=r(H$e," \u2014 "),NG=n(H$e,"A",{href:!0});var Dut=s(NG);G9o=r(Dut,"Data2VecTextForCausalLM"),Dut.forEach(t),O9o=r(H$e," (Data2VecText model)"),H$e.forEach(t),V9o=i(W),H1=n(W,"LI",{});var U$e=s(H1);Jme=n(U$e,"STRONG",{});var Gut=s(Jme);X9o=r(Gut,"electra"),Gut.forEach(t),z9o=r(U$e," \u2014 "),qG=n(U$e,"A",{href:!0});var Out=s(qG);W9o=r(Out,"ElectraForCausalLM"),Out.forEach(t),Q9o=r(U$e," (ELECTRA model)"),U$e.forEach(t),H9o=i(W),U1=n(W,"LI",{});var J$e=s(U1);Yme=n(J$e,"STRONG",{});var Vut=s(Yme);U9o=r(Vut,"gpt2"),Vut.forEach(t),J9o=r(J$e," \u2014 "),jG=n(J$e,"A",{href:!0});var Xut=s(jG);Y9o=r(Xut,"GPT2LMHeadModel"),Xut.forEach(t),K9o=r(J$e," (OpenAI GPT-2 model)"),J$e.forEach(t),Z9o=i(W),J1=n(W,"LI",{});var Y$e=s(J1);Kme=n(Y$e,"STRONG",{});var zut=s(Kme);exo=r(zut,"gpt_neo"),zut.forEach(t),oxo=r(Y$e," \u2014 "),DG=n(Y$e,"A",{href:!0});var Wut=s(DG);rxo=r(Wut,"GPTNeoForCausalLM"),Wut.forEach(t),txo=r(Y$e," (GPT Neo model)"),Y$e.forEach(t),axo=i(W),Y1=n(W,"LI",{});var K$e=s(Y1);Zme=n(K$e,"STRONG",{});var Qut=s(Zme);nxo=r(Qut,"gpt_neox"),Qut.forEach(t),sxo=r(K$e," \u2014 "),GG=n(K$e,"A",{href:!0});var Hut=s(GG);lxo=r(Hut,"GPTNeoXForCausalLM"),Hut.forEach(t),ixo=r(K$e," (GPT NeoX model)"),K$e.forEach(t),dxo=i(W),K1=n(W,"LI",{});var Z$e=s(K1);ege=n(Z$e,"STRONG",{});var Uut=s(ege);cxo=r(Uut,"gptj"),Uut.forEach(t),fxo=r(Z$e," \u2014 "),OG=n(Z$e,"A",{href:!0});var Jut=s(OG);mxo=r(Jut,"GPTJForCausalLM"),Jut.forEach(t),gxo=r(Z$e," (GPT-J model)"),Z$e.forEach(t),hxo=i(W),Z1=n(W,"LI",{});var eke=s(Z1);oge=n(eke,"STRONG",{});var Yut=s(oge);pxo=r(Yut,"marian"),Yut.forEach(t),_xo=r(eke," \u2014 "),VG=n(eke,"A",{href:!0});var Kut=s(VG);uxo=r(Kut,"MarianForCausalLM"),Kut.forEach(t),bxo=r(eke," (Marian model)"),eke.forEach(t),vxo=i(W),e2=n(W,"LI",{});var oke=s(e2);rge=n(oke,"STRONG",{});var Zut=s(rge);Fxo=r(Zut,"mbart"),Zut.forEach(t),Txo=r(oke," \u2014 "),XG=n(oke,"A",{href:!0});var e1t=s(XG);Mxo=r(e1t,"MBartForCausalLM"),e1t.forEach(t),Exo=r(oke," (mBART model)"),oke.forEach(t),Cxo=i(W),o2=n(W,"LI",{});var rke=s(o2);tge=n(rke,"STRONG",{});var o1t=s(tge);wxo=r(o1t,"megatron-bert"),o1t.forEach(t),Axo=r(rke," \u2014 "),zG=n(rke,"A",{href:!0});var r1t=s(zG);Lxo=r(r1t,"MegatronBertForCausalLM"),r1t.forEach(t),yxo=r(rke," (Megatron-BERT model)"),rke.forEach(t),xxo=i(W),r2=n(W,"LI",{});var tke=s(r2);age=n(tke,"STRONG",{});var t1t=s(age);$xo=r(t1t,"openai-gpt"),t1t.forEach(t),kxo=r(tke," \u2014 "),WG=n(tke,"A",{href:!0});var a1t=s(WG);Sxo=r(a1t,"OpenAIGPTLMHeadModel"),a1t.forEach(t),Rxo=r(tke," (OpenAI GPT model)"),tke.forEach(t),Pxo=i(W),t2=n(W,"LI",{});var ake=s(t2);nge=n(ake,"STRONG",{});var n1t=s(nge);Bxo=r(n1t,"opt"),n1t.forEach(t),Ixo=r(ake," \u2014 "),QG=n(ake,"A",{href:!0});var s1t=s(QG);Nxo=r(s1t,"OPTForCausalLM"),s1t.forEach(t),qxo=r(ake," (OPT model)"),ake.forEach(t),jxo=i(W),a2=n(W,"LI",{});var nke=s(a2);sge=n(nke,"STRONG",{});var l1t=s(sge);Dxo=r(l1t,"pegasus"),l1t.forEach(t),Gxo=r(nke," \u2014 "),HG=n(nke,"A",{href:!0});var i1t=s(HG);Oxo=r(i1t,"PegasusForCausalLM"),i1t.forEach(t),Vxo=r(nke," (Pegasus model)"),nke.forEach(t),Xxo=i(W),n2=n(W,"LI",{});var ske=s(n2);lge=n(ske,"STRONG",{});var d1t=s(lge);zxo=r(d1t,"plbart"),d1t.forEach(t),Wxo=r(ske," \u2014 "),UG=n(ske,"A",{href:!0});var c1t=s(UG);Qxo=r(c1t,"PLBartForCausalLM"),c1t.forEach(t),Hxo=r(ske," (PLBart model)"),ske.forEach(t),Uxo=i(W),s2=n(W,"LI",{});var lke=s(s2);ige=n(lke,"STRONG",{});var f1t=s(ige);Jxo=r(f1t,"prophetnet"),f1t.forEach(t),Yxo=r(lke," \u2014 "),JG=n(lke,"A",{href:!0});var m1t=s(JG);Kxo=r(m1t,"ProphetNetForCausalLM"),m1t.forEach(t),Zxo=r(lke," (ProphetNet model)"),lke.forEach(t),e$o=i(W),l2=n(W,"LI",{});var ike=s(l2);dge=n(ike,"STRONG",{});var g1t=s(dge);o$o=r(g1t,"qdqbert"),g1t.forEach(t),r$o=r(ike," \u2014 "),YG=n(ike,"A",{href:!0});var h1t=s(YG);t$o=r(h1t,"QDQBertLMHeadModel"),h1t.forEach(t),a$o=r(ike," (QDQBert model)"),ike.forEach(t),n$o=i(W),i2=n(W,"LI",{});var dke=s(i2);cge=n(dke,"STRONG",{});var p1t=s(cge);s$o=r(p1t,"reformer"),p1t.forEach(t),l$o=r(dke," \u2014 "),KG=n(dke,"A",{href:!0});var _1t=s(KG);i$o=r(_1t,"ReformerModelWithLMHead"),_1t.forEach(t),d$o=r(dke," (Reformer model)"),dke.forEach(t),c$o=i(W),d2=n(W,"LI",{});var cke=s(d2);fge=n(cke,"STRONG",{});var u1t=s(fge);f$o=r(u1t,"rembert"),u1t.forEach(t),m$o=r(cke," \u2014 "),ZG=n(cke,"A",{href:!0});var b1t=s(ZG);g$o=r(b1t,"RemBertForCausalLM"),b1t.forEach(t),h$o=r(cke," (RemBERT model)"),cke.forEach(t),p$o=i(W),c2=n(W,"LI",{});var fke=s(c2);mge=n(fke,"STRONG",{});var v1t=s(mge);_$o=r(v1t,"roberta"),v1t.forEach(t),u$o=r(fke," \u2014 "),eO=n(fke,"A",{href:!0});var F1t=s(eO);b$o=r(F1t,"RobertaForCausalLM"),F1t.forEach(t),v$o=r(fke," (RoBERTa model)"),fke.forEach(t),F$o=i(W),f2=n(W,"LI",{});var mke=s(f2);gge=n(mke,"STRONG",{});var T1t=s(gge);T$o=r(T1t,"roformer"),T1t.forEach(t),M$o=r(mke," \u2014 "),oO=n(mke,"A",{href:!0});var M1t=s(oO);E$o=r(M1t,"RoFormerForCausalLM"),M1t.forEach(t),C$o=r(mke," (RoFormer model)"),mke.forEach(t),w$o=i(W),m2=n(W,"LI",{});var gke=s(m2);hge=n(gke,"STRONG",{});var E1t=s(hge);A$o=r(E1t,"speech_to_text_2"),E1t.forEach(t),L$o=r(gke," \u2014 "),rO=n(gke,"A",{href:!0});var C1t=s(rO);y$o=r(C1t,"Speech2Text2ForCausalLM"),C1t.forEach(t),x$o=r(gke," (Speech2Text2 model)"),gke.forEach(t),$$o=i(W),g2=n(W,"LI",{});var hke=s(g2);pge=n(hke,"STRONG",{});var w1t=s(pge);k$o=r(w1t,"transfo-xl"),w1t.forEach(t),S$o=r(hke," \u2014 "),tO=n(hke,"A",{href:!0});var A1t=s(tO);R$o=r(A1t,"TransfoXLLMHeadModel"),A1t.forEach(t),P$o=r(hke," (Transformer-XL model)"),hke.forEach(t),B$o=i(W),h2=n(W,"LI",{});var pke=s(h2);_ge=n(pke,"STRONG",{});var L1t=s(_ge);I$o=r(L1t,"trocr"),L1t.forEach(t),N$o=r(pke," \u2014 "),aO=n(pke,"A",{href:!0});var y1t=s(aO);q$o=r(y1t,"TrOCRForCausalLM"),y1t.forEach(t),j$o=r(pke," (TrOCR model)"),pke.forEach(t),D$o=i(W),p2=n(W,"LI",{});var _ke=s(p2);uge=n(_ke,"STRONG",{});var x1t=s(uge);G$o=r(x1t,"xglm"),x1t.forEach(t),O$o=r(_ke," \u2014 "),nO=n(_ke,"A",{href:!0});var $1t=s(nO);V$o=r($1t,"XGLMForCausalLM"),$1t.forEach(t),X$o=r(_ke," (XGLM model)"),_ke.forEach(t),z$o=i(W),_2=n(W,"LI",{});var uke=s(_2);bge=n(uke,"STRONG",{});var k1t=s(bge);W$o=r(k1t,"xlm"),k1t.forEach(t),Q$o=r(uke," \u2014 "),sO=n(uke,"A",{href:!0});var S1t=s(sO);H$o=r(S1t,"XLMWithLMHeadModel"),S1t.forEach(t),U$o=r(uke," (XLM model)"),uke.forEach(t),J$o=i(W),u2=n(W,"LI",{});var bke=s(u2);vge=n(bke,"STRONG",{});var R1t=s(vge);Y$o=r(R1t,"xlm-prophetnet"),R1t.forEach(t),K$o=r(bke," \u2014 "),lO=n(bke,"A",{href:!0});var P1t=s(lO);Z$o=r(P1t,"XLMProphetNetForCausalLM"),P1t.forEach(t),eko=r(bke," (XLM-ProphetNet model)"),bke.forEach(t),oko=i(W),b2=n(W,"LI",{});var vke=s(b2);Fge=n(vke,"STRONG",{});var B1t=s(Fge);rko=r(B1t,"xlm-roberta"),B1t.forEach(t),tko=r(vke," \u2014 "),iO=n(vke,"A",{href:!0});var I1t=s(iO);ako=r(I1t,"XLMRobertaForCausalLM"),I1t.forEach(t),nko=r(vke," (XLM-RoBERTa model)"),vke.forEach(t),sko=i(W),v2=n(W,"LI",{});var Fke=s(v2);Tge=n(Fke,"STRONG",{});var N1t=s(Tge);lko=r(N1t,"xlm-roberta-xl"),N1t.forEach(t),iko=r(Fke," \u2014 "),dO=n(Fke,"A",{href:!0});var q1t=s(dO);dko=r(q1t,"XLMRobertaXLForCausalLM"),q1t.forEach(t),cko=r(Fke," (XLM-RoBERTa-XL model)"),Fke.forEach(t),fko=i(W),F2=n(W,"LI",{});var Tke=s(F2);Mge=n(Tke,"STRONG",{});var j1t=s(Mge);mko=r(j1t,"xlnet"),j1t.forEach(t),gko=r(Tke," \u2014 "),cO=n(Tke,"A",{href:!0});var D1t=s(cO);hko=r(D1t,"XLNetLMHeadModel"),D1t.forEach(t),pko=r(Tke," (XLNet model)"),Tke.forEach(t),W.forEach(t),_ko=i(la),T2=n(la,"P",{});var Mke=s(T2);uko=r(Mke,"The model is set in evaluation mode by default using "),Ege=n(Mke,"CODE",{});var G1t=s(Ege);bko=r(G1t,"model.eval()"),G1t.forEach(t),vko=r(Mke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cge=n(Mke,"CODE",{});var O1t=s(Cge);Fko=r(O1t,"model.train()"),O1t.forEach(t),Mke.forEach(t),Tko=i(la),T(M2.$$.fragment,la),la.forEach(t),tl.forEach(t),nVe=i(f),Hi=n(f,"H2",{class:!0});var fze=s(Hi);E2=n(fze,"A",{id:!0,class:!0,href:!0});var V1t=s(E2);wge=n(V1t,"SPAN",{});var X1t=s(wge);T(xL.$$.fragment,X1t),X1t.forEach(t),V1t.forEach(t),Mko=i(fze),Age=n(fze,"SPAN",{});var z1t=s(Age);Eko=r(z1t,"AutoModelForMaskedLM"),z1t.forEach(t),fze.forEach(t),sVe=i(f),So=n(f,"DIV",{class:!0});var al=s(So);T($L.$$.fragment,al),Cko=i(al),Ui=n(al,"P",{});var tre=s(Ui);wko=r(tre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),fO=n(tre,"A",{href:!0});var W1t=s(fO);Ako=r(W1t,"from_pretrained()"),W1t.forEach(t),Lko=r(tre," class method or the "),mO=n(tre,"A",{href:!0});var Q1t=s(mO);yko=r(Q1t,"from_config()"),Q1t.forEach(t),xko=r(tre,` class
method.`),tre.forEach(t),$ko=i(al),kL=n(al,"P",{});var mze=s(kL);kko=r(mze,"This class cannot be instantiated directly using "),Lge=n(mze,"CODE",{});var H1t=s(Lge);Sko=r(H1t,"__init__()"),H1t.forEach(t),Rko=r(mze," (throws an error)."),mze.forEach(t),Pko=i(al),dt=n(al,"DIV",{class:!0});var Y5=s(dt);T(SL.$$.fragment,Y5),Bko=i(Y5),yge=n(Y5,"P",{});var U1t=s(yge);Iko=r(U1t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),U1t.forEach(t),Nko=i(Y5),Ji=n(Y5,"P",{});var are=s(Ji);qko=r(are,`Note:
Loading a model from its configuration file does `),xge=n(are,"STRONG",{});var J1t=s(xge);jko=r(J1t,"not"),J1t.forEach(t),Dko=r(are,` load the model weights. It only affects the
model\u2019s configuration. Use `),gO=n(are,"A",{href:!0});var Y1t=s(gO);Gko=r(Y1t,"from_pretrained()"),Y1t.forEach(t),Oko=r(are," to load the model weights."),are.forEach(t),Vko=i(Y5),T(C2.$$.fragment,Y5),Y5.forEach(t),Xko=i(al),Ze=n(al,"DIV",{class:!0});var ia=s(Ze);T(RL.$$.fragment,ia),zko=i(ia),$ge=n(ia,"P",{});var K1t=s($ge);Wko=r(K1t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),K1t.forEach(t),Qko=i(ia),qa=n(ia,"P",{});var K5=s(qa);Hko=r(K5,"The model class to instantiate is selected based on the "),kge=n(K5,"CODE",{});var Z1t=s(kge);Uko=r(Z1t,"model_type"),Z1t.forEach(t),Jko=r(K5,` property of the config object (either
passed as an argument or loaded from `),Sge=n(K5,"CODE",{});var e2t=s(Sge);Yko=r(e2t,"pretrained_model_name_or_path"),e2t.forEach(t),Kko=r(K5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rge=n(K5,"CODE",{});var o2t=s(Rge);Zko=r(o2t,"pretrained_model_name_or_path"),o2t.forEach(t),eSo=r(K5,":"),K5.forEach(t),oSo=i(ia),Q=n(ia,"UL",{});var U=s(Q);w2=n(U,"LI",{});var Eke=s(w2);Pge=n(Eke,"STRONG",{});var r2t=s(Pge);rSo=r(r2t,"albert"),r2t.forEach(t),tSo=r(Eke," \u2014 "),hO=n(Eke,"A",{href:!0});var t2t=s(hO);aSo=r(t2t,"AlbertForMaskedLM"),t2t.forEach(t),nSo=r(Eke," (ALBERT model)"),Eke.forEach(t),sSo=i(U),A2=n(U,"LI",{});var Cke=s(A2);Bge=n(Cke,"STRONG",{});var a2t=s(Bge);lSo=r(a2t,"bart"),a2t.forEach(t),iSo=r(Cke," \u2014 "),pO=n(Cke,"A",{href:!0});var n2t=s(pO);dSo=r(n2t,"BartForConditionalGeneration"),n2t.forEach(t),cSo=r(Cke," (BART model)"),Cke.forEach(t),fSo=i(U),L2=n(U,"LI",{});var wke=s(L2);Ige=n(wke,"STRONG",{});var s2t=s(Ige);mSo=r(s2t,"bert"),s2t.forEach(t),gSo=r(wke," \u2014 "),_O=n(wke,"A",{href:!0});var l2t=s(_O);hSo=r(l2t,"BertForMaskedLM"),l2t.forEach(t),pSo=r(wke," (BERT model)"),wke.forEach(t),_So=i(U),y2=n(U,"LI",{});var Ake=s(y2);Nge=n(Ake,"STRONG",{});var i2t=s(Nge);uSo=r(i2t,"big_bird"),i2t.forEach(t),bSo=r(Ake," \u2014 "),uO=n(Ake,"A",{href:!0});var d2t=s(uO);vSo=r(d2t,"BigBirdForMaskedLM"),d2t.forEach(t),FSo=r(Ake," (BigBird model)"),Ake.forEach(t),TSo=i(U),x2=n(U,"LI",{});var Lke=s(x2);qge=n(Lke,"STRONG",{});var c2t=s(qge);MSo=r(c2t,"camembert"),c2t.forEach(t),ESo=r(Lke," \u2014 "),bO=n(Lke,"A",{href:!0});var f2t=s(bO);CSo=r(f2t,"CamembertForMaskedLM"),f2t.forEach(t),wSo=r(Lke," (CamemBERT model)"),Lke.forEach(t),ASo=i(U),$2=n(U,"LI",{});var yke=s($2);jge=n(yke,"STRONG",{});var m2t=s(jge);LSo=r(m2t,"convbert"),m2t.forEach(t),ySo=r(yke," \u2014 "),vO=n(yke,"A",{href:!0});var g2t=s(vO);xSo=r(g2t,"ConvBertForMaskedLM"),g2t.forEach(t),$So=r(yke," (ConvBERT model)"),yke.forEach(t),kSo=i(U),k2=n(U,"LI",{});var xke=s(k2);Dge=n(xke,"STRONG",{});var h2t=s(Dge);SSo=r(h2t,"data2vec-text"),h2t.forEach(t),RSo=r(xke," \u2014 "),FO=n(xke,"A",{href:!0});var p2t=s(FO);PSo=r(p2t,"Data2VecTextForMaskedLM"),p2t.forEach(t),BSo=r(xke," (Data2VecText model)"),xke.forEach(t),ISo=i(U),S2=n(U,"LI",{});var $ke=s(S2);Gge=n($ke,"STRONG",{});var _2t=s(Gge);NSo=r(_2t,"deberta"),_2t.forEach(t),qSo=r($ke," \u2014 "),TO=n($ke,"A",{href:!0});var u2t=s(TO);jSo=r(u2t,"DebertaForMaskedLM"),u2t.forEach(t),DSo=r($ke," (DeBERTa model)"),$ke.forEach(t),GSo=i(U),R2=n(U,"LI",{});var kke=s(R2);Oge=n(kke,"STRONG",{});var b2t=s(Oge);OSo=r(b2t,"deberta-v2"),b2t.forEach(t),VSo=r(kke," \u2014 "),MO=n(kke,"A",{href:!0});var v2t=s(MO);XSo=r(v2t,"DebertaV2ForMaskedLM"),v2t.forEach(t),zSo=r(kke," (DeBERTa-v2 model)"),kke.forEach(t),WSo=i(U),P2=n(U,"LI",{});var Ske=s(P2);Vge=n(Ske,"STRONG",{});var F2t=s(Vge);QSo=r(F2t,"distilbert"),F2t.forEach(t),HSo=r(Ske," \u2014 "),EO=n(Ske,"A",{href:!0});var T2t=s(EO);USo=r(T2t,"DistilBertForMaskedLM"),T2t.forEach(t),JSo=r(Ske," (DistilBERT model)"),Ske.forEach(t),YSo=i(U),B2=n(U,"LI",{});var Rke=s(B2);Xge=n(Rke,"STRONG",{});var M2t=s(Xge);KSo=r(M2t,"electra"),M2t.forEach(t),ZSo=r(Rke," \u2014 "),CO=n(Rke,"A",{href:!0});var E2t=s(CO);eRo=r(E2t,"ElectraForMaskedLM"),E2t.forEach(t),oRo=r(Rke," (ELECTRA model)"),Rke.forEach(t),rRo=i(U),I2=n(U,"LI",{});var Pke=s(I2);zge=n(Pke,"STRONG",{});var C2t=s(zge);tRo=r(C2t,"flaubert"),C2t.forEach(t),aRo=r(Pke," \u2014 "),wO=n(Pke,"A",{href:!0});var w2t=s(wO);nRo=r(w2t,"FlaubertWithLMHeadModel"),w2t.forEach(t),sRo=r(Pke," (FlauBERT model)"),Pke.forEach(t),lRo=i(U),N2=n(U,"LI",{});var Bke=s(N2);Wge=n(Bke,"STRONG",{});var A2t=s(Wge);iRo=r(A2t,"fnet"),A2t.forEach(t),dRo=r(Bke," \u2014 "),AO=n(Bke,"A",{href:!0});var L2t=s(AO);cRo=r(L2t,"FNetForMaskedLM"),L2t.forEach(t),fRo=r(Bke," (FNet model)"),Bke.forEach(t),mRo=i(U),q2=n(U,"LI",{});var Ike=s(q2);Qge=n(Ike,"STRONG",{});var y2t=s(Qge);gRo=r(y2t,"funnel"),y2t.forEach(t),hRo=r(Ike," \u2014 "),LO=n(Ike,"A",{href:!0});var x2t=s(LO);pRo=r(x2t,"FunnelForMaskedLM"),x2t.forEach(t),_Ro=r(Ike," (Funnel Transformer model)"),Ike.forEach(t),uRo=i(U),j2=n(U,"LI",{});var Nke=s(j2);Hge=n(Nke,"STRONG",{});var $2t=s(Hge);bRo=r($2t,"ibert"),$2t.forEach(t),vRo=r(Nke," \u2014 "),yO=n(Nke,"A",{href:!0});var k2t=s(yO);FRo=r(k2t,"IBertForMaskedLM"),k2t.forEach(t),TRo=r(Nke," (I-BERT model)"),Nke.forEach(t),MRo=i(U),D2=n(U,"LI",{});var qke=s(D2);Uge=n(qke,"STRONG",{});var S2t=s(Uge);ERo=r(S2t,"layoutlm"),S2t.forEach(t),CRo=r(qke," \u2014 "),xO=n(qke,"A",{href:!0});var R2t=s(xO);wRo=r(R2t,"LayoutLMForMaskedLM"),R2t.forEach(t),ARo=r(qke," (LayoutLM model)"),qke.forEach(t),LRo=i(U),G2=n(U,"LI",{});var jke=s(G2);Jge=n(jke,"STRONG",{});var P2t=s(Jge);yRo=r(P2t,"longformer"),P2t.forEach(t),xRo=r(jke," \u2014 "),$O=n(jke,"A",{href:!0});var B2t=s($O);$Ro=r(B2t,"LongformerForMaskedLM"),B2t.forEach(t),kRo=r(jke," (Longformer model)"),jke.forEach(t),SRo=i(U),O2=n(U,"LI",{});var Dke=s(O2);Yge=n(Dke,"STRONG",{});var I2t=s(Yge);RRo=r(I2t,"luke"),I2t.forEach(t),PRo=r(Dke," \u2014 "),kO=n(Dke,"A",{href:!0});var N2t=s(kO);BRo=r(N2t,"LukeForMaskedLM"),N2t.forEach(t),IRo=r(Dke," (LUKE model)"),Dke.forEach(t),NRo=i(U),V2=n(U,"LI",{});var Gke=s(V2);Kge=n(Gke,"STRONG",{});var q2t=s(Kge);qRo=r(q2t,"mbart"),q2t.forEach(t),jRo=r(Gke," \u2014 "),SO=n(Gke,"A",{href:!0});var j2t=s(SO);DRo=r(j2t,"MBartForConditionalGeneration"),j2t.forEach(t),GRo=r(Gke," (mBART model)"),Gke.forEach(t),ORo=i(U),X2=n(U,"LI",{});var Oke=s(X2);Zge=n(Oke,"STRONG",{});var D2t=s(Zge);VRo=r(D2t,"megatron-bert"),D2t.forEach(t),XRo=r(Oke," \u2014 "),RO=n(Oke,"A",{href:!0});var G2t=s(RO);zRo=r(G2t,"MegatronBertForMaskedLM"),G2t.forEach(t),WRo=r(Oke," (Megatron-BERT model)"),Oke.forEach(t),QRo=i(U),z2=n(U,"LI",{});var Vke=s(z2);ehe=n(Vke,"STRONG",{});var O2t=s(ehe);HRo=r(O2t,"mobilebert"),O2t.forEach(t),URo=r(Vke," \u2014 "),PO=n(Vke,"A",{href:!0});var V2t=s(PO);JRo=r(V2t,"MobileBertForMaskedLM"),V2t.forEach(t),YRo=r(Vke," (MobileBERT model)"),Vke.forEach(t),KRo=i(U),W2=n(U,"LI",{});var Xke=s(W2);ohe=n(Xke,"STRONG",{});var X2t=s(ohe);ZRo=r(X2t,"mpnet"),X2t.forEach(t),ePo=r(Xke," \u2014 "),BO=n(Xke,"A",{href:!0});var z2t=s(BO);oPo=r(z2t,"MPNetForMaskedLM"),z2t.forEach(t),rPo=r(Xke," (MPNet model)"),Xke.forEach(t),tPo=i(U),Q2=n(U,"LI",{});var zke=s(Q2);rhe=n(zke,"STRONG",{});var W2t=s(rhe);aPo=r(W2t,"nezha"),W2t.forEach(t),nPo=r(zke," \u2014 "),IO=n(zke,"A",{href:!0});var Q2t=s(IO);sPo=r(Q2t,"NezhaForMaskedLM"),Q2t.forEach(t),lPo=r(zke," (Nezha model)"),zke.forEach(t),iPo=i(U),H2=n(U,"LI",{});var Wke=s(H2);the=n(Wke,"STRONG",{});var H2t=s(the);dPo=r(H2t,"nystromformer"),H2t.forEach(t),cPo=r(Wke," \u2014 "),NO=n(Wke,"A",{href:!0});var U2t=s(NO);fPo=r(U2t,"NystromformerForMaskedLM"),U2t.forEach(t),mPo=r(Wke," (Nystr\xF6mformer model)"),Wke.forEach(t),gPo=i(U),U2=n(U,"LI",{});var Qke=s(U2);ahe=n(Qke,"STRONG",{});var J2t=s(ahe);hPo=r(J2t,"perceiver"),J2t.forEach(t),pPo=r(Qke," \u2014 "),qO=n(Qke,"A",{href:!0});var Y2t=s(qO);_Po=r(Y2t,"PerceiverForMaskedLM"),Y2t.forEach(t),uPo=r(Qke," (Perceiver model)"),Qke.forEach(t),bPo=i(U),J2=n(U,"LI",{});var Hke=s(J2);nhe=n(Hke,"STRONG",{});var K2t=s(nhe);vPo=r(K2t,"qdqbert"),K2t.forEach(t),FPo=r(Hke," \u2014 "),jO=n(Hke,"A",{href:!0});var Z2t=s(jO);TPo=r(Z2t,"QDQBertForMaskedLM"),Z2t.forEach(t),MPo=r(Hke," (QDQBert model)"),Hke.forEach(t),EPo=i(U),Y2=n(U,"LI",{});var Uke=s(Y2);she=n(Uke,"STRONG",{});var ebt=s(she);CPo=r(ebt,"reformer"),ebt.forEach(t),wPo=r(Uke," \u2014 "),DO=n(Uke,"A",{href:!0});var obt=s(DO);APo=r(obt,"ReformerForMaskedLM"),obt.forEach(t),LPo=r(Uke," (Reformer model)"),Uke.forEach(t),yPo=i(U),K2=n(U,"LI",{});var Jke=s(K2);lhe=n(Jke,"STRONG",{});var rbt=s(lhe);xPo=r(rbt,"rembert"),rbt.forEach(t),$Po=r(Jke," \u2014 "),GO=n(Jke,"A",{href:!0});var tbt=s(GO);kPo=r(tbt,"RemBertForMaskedLM"),tbt.forEach(t),SPo=r(Jke," (RemBERT model)"),Jke.forEach(t),RPo=i(U),Z2=n(U,"LI",{});var Yke=s(Z2);ihe=n(Yke,"STRONG",{});var abt=s(ihe);PPo=r(abt,"roberta"),abt.forEach(t),BPo=r(Yke," \u2014 "),OO=n(Yke,"A",{href:!0});var nbt=s(OO);IPo=r(nbt,"RobertaForMaskedLM"),nbt.forEach(t),NPo=r(Yke," (RoBERTa model)"),Yke.forEach(t),qPo=i(U),eb=n(U,"LI",{});var Kke=s(eb);dhe=n(Kke,"STRONG",{});var sbt=s(dhe);jPo=r(sbt,"roformer"),sbt.forEach(t),DPo=r(Kke," \u2014 "),VO=n(Kke,"A",{href:!0});var lbt=s(VO);GPo=r(lbt,"RoFormerForMaskedLM"),lbt.forEach(t),OPo=r(Kke," (RoFormer model)"),Kke.forEach(t),VPo=i(U),ob=n(U,"LI",{});var Zke=s(ob);che=n(Zke,"STRONG",{});var ibt=s(che);XPo=r(ibt,"squeezebert"),ibt.forEach(t),zPo=r(Zke," \u2014 "),XO=n(Zke,"A",{href:!0});var dbt=s(XO);WPo=r(dbt,"SqueezeBertForMaskedLM"),dbt.forEach(t),QPo=r(Zke," (SqueezeBERT model)"),Zke.forEach(t),HPo=i(U),rb=n(U,"LI",{});var eSe=s(rb);fhe=n(eSe,"STRONG",{});var cbt=s(fhe);UPo=r(cbt,"tapas"),cbt.forEach(t),JPo=r(eSe," \u2014 "),zO=n(eSe,"A",{href:!0});var fbt=s(zO);YPo=r(fbt,"TapasForMaskedLM"),fbt.forEach(t),KPo=r(eSe," (TAPAS model)"),eSe.forEach(t),ZPo=i(U),tb=n(U,"LI",{});var oSe=s(tb);mhe=n(oSe,"STRONG",{});var mbt=s(mhe);eBo=r(mbt,"wav2vec2"),mbt.forEach(t),oBo=r(oSe," \u2014 "),ghe=n(oSe,"CODE",{});var gbt=s(ghe);rBo=r(gbt,"Wav2Vec2ForMaskedLM"),gbt.forEach(t),tBo=r(oSe," (Wav2Vec2 model)"),oSe.forEach(t),aBo=i(U),ab=n(U,"LI",{});var rSe=s(ab);hhe=n(rSe,"STRONG",{});var hbt=s(hhe);nBo=r(hbt,"xlm"),hbt.forEach(t),sBo=r(rSe," \u2014 "),WO=n(rSe,"A",{href:!0});var pbt=s(WO);lBo=r(pbt,"XLMWithLMHeadModel"),pbt.forEach(t),iBo=r(rSe," (XLM model)"),rSe.forEach(t),dBo=i(U),nb=n(U,"LI",{});var tSe=s(nb);phe=n(tSe,"STRONG",{});var _bt=s(phe);cBo=r(_bt,"xlm-roberta"),_bt.forEach(t),fBo=r(tSe," \u2014 "),QO=n(tSe,"A",{href:!0});var ubt=s(QO);mBo=r(ubt,"XLMRobertaForMaskedLM"),ubt.forEach(t),gBo=r(tSe," (XLM-RoBERTa model)"),tSe.forEach(t),hBo=i(U),sb=n(U,"LI",{});var aSe=s(sb);_he=n(aSe,"STRONG",{});var bbt=s(_he);pBo=r(bbt,"xlm-roberta-xl"),bbt.forEach(t),_Bo=r(aSe," \u2014 "),HO=n(aSe,"A",{href:!0});var vbt=s(HO);uBo=r(vbt,"XLMRobertaXLForMaskedLM"),vbt.forEach(t),bBo=r(aSe," (XLM-RoBERTa-XL model)"),aSe.forEach(t),vBo=i(U),lb=n(U,"LI",{});var nSe=s(lb);uhe=n(nSe,"STRONG",{});var Fbt=s(uhe);FBo=r(Fbt,"yoso"),Fbt.forEach(t),TBo=r(nSe," \u2014 "),UO=n(nSe,"A",{href:!0});var Tbt=s(UO);MBo=r(Tbt,"YosoForMaskedLM"),Tbt.forEach(t),EBo=r(nSe," (YOSO model)"),nSe.forEach(t),U.forEach(t),CBo=i(ia),ib=n(ia,"P",{});var sSe=s(ib);wBo=r(sSe,"The model is set in evaluation mode by default using "),bhe=n(sSe,"CODE",{});var Mbt=s(bhe);ABo=r(Mbt,"model.eval()"),Mbt.forEach(t),LBo=r(sSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vhe=n(sSe,"CODE",{});var Ebt=s(vhe);yBo=r(Ebt,"model.train()"),Ebt.forEach(t),sSe.forEach(t),xBo=i(ia),T(db.$$.fragment,ia),ia.forEach(t),al.forEach(t),lVe=i(f),Yi=n(f,"H2",{class:!0});var gze=s(Yi);cb=n(gze,"A",{id:!0,class:!0,href:!0});var Cbt=s(cb);Fhe=n(Cbt,"SPAN",{});var wbt=s(Fhe);T(PL.$$.fragment,wbt),wbt.forEach(t),Cbt.forEach(t),$Bo=i(gze),The=n(gze,"SPAN",{});var Abt=s(The);kBo=r(Abt,"AutoModelForSeq2SeqLM"),Abt.forEach(t),gze.forEach(t),iVe=i(f),Ro=n(f,"DIV",{class:!0});var nl=s(Ro);T(BL.$$.fragment,nl),SBo=i(nl),Ki=n(nl,"P",{});var nre=s(Ki);RBo=r(nre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),JO=n(nre,"A",{href:!0});var Lbt=s(JO);PBo=r(Lbt,"from_pretrained()"),Lbt.forEach(t),BBo=r(nre," class method or the "),YO=n(nre,"A",{href:!0});var ybt=s(YO);IBo=r(ybt,"from_config()"),ybt.forEach(t),NBo=r(nre,` class
method.`),nre.forEach(t),qBo=i(nl),IL=n(nl,"P",{});var hze=s(IL);jBo=r(hze,"This class cannot be instantiated directly using "),Mhe=n(hze,"CODE",{});var xbt=s(Mhe);DBo=r(xbt,"__init__()"),xbt.forEach(t),GBo=r(hze," (throws an error)."),hze.forEach(t),OBo=i(nl),ct=n(nl,"DIV",{class:!0});var Z5=s(ct);T(NL.$$.fragment,Z5),VBo=i(Z5),Ehe=n(Z5,"P",{});var $bt=s(Ehe);XBo=r($bt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),$bt.forEach(t),zBo=i(Z5),Zi=n(Z5,"P",{});var sre=s(Zi);WBo=r(sre,`Note:
Loading a model from its configuration file does `),Che=n(sre,"STRONG",{});var kbt=s(Che);QBo=r(kbt,"not"),kbt.forEach(t),HBo=r(sre,` load the model weights. It only affects the
model\u2019s configuration. Use `),KO=n(sre,"A",{href:!0});var Sbt=s(KO);UBo=r(Sbt,"from_pretrained()"),Sbt.forEach(t),JBo=r(sre," to load the model weights."),sre.forEach(t),YBo=i(Z5),T(fb.$$.fragment,Z5),Z5.forEach(t),KBo=i(nl),eo=n(nl,"DIV",{class:!0});var da=s(eo);T(qL.$$.fragment,da),ZBo=i(da),whe=n(da,"P",{});var Rbt=s(whe);eIo=r(Rbt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Rbt.forEach(t),oIo=i(da),ja=n(da,"P",{});var ew=s(ja);rIo=r(ew,"The model class to instantiate is selected based on the "),Ahe=n(ew,"CODE",{});var Pbt=s(Ahe);tIo=r(Pbt,"model_type"),Pbt.forEach(t),aIo=r(ew,` property of the config object (either
passed as an argument or loaded from `),Lhe=n(ew,"CODE",{});var Bbt=s(Lhe);nIo=r(Bbt,"pretrained_model_name_or_path"),Bbt.forEach(t),sIo=r(ew,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yhe=n(ew,"CODE",{});var Ibt=s(yhe);lIo=r(Ibt,"pretrained_model_name_or_path"),Ibt.forEach(t),iIo=r(ew,":"),ew.forEach(t),dIo=i(da),pe=n(da,"UL",{});var be=s(pe);mb=n(be,"LI",{});var lSe=s(mb);xhe=n(lSe,"STRONG",{});var Nbt=s(xhe);cIo=r(Nbt,"bart"),Nbt.forEach(t),fIo=r(lSe," \u2014 "),ZO=n(lSe,"A",{href:!0});var qbt=s(ZO);mIo=r(qbt,"BartForConditionalGeneration"),qbt.forEach(t),gIo=r(lSe," (BART model)"),lSe.forEach(t),hIo=i(be),gb=n(be,"LI",{});var iSe=s(gb);$he=n(iSe,"STRONG",{});var jbt=s($he);pIo=r(jbt,"bigbird_pegasus"),jbt.forEach(t),_Io=r(iSe," \u2014 "),eV=n(iSe,"A",{href:!0});var Dbt=s(eV);uIo=r(Dbt,"BigBirdPegasusForConditionalGeneration"),Dbt.forEach(t),bIo=r(iSe," (BigBird-Pegasus model)"),iSe.forEach(t),vIo=i(be),hb=n(be,"LI",{});var dSe=s(hb);khe=n(dSe,"STRONG",{});var Gbt=s(khe);FIo=r(Gbt,"blenderbot"),Gbt.forEach(t),TIo=r(dSe," \u2014 "),oV=n(dSe,"A",{href:!0});var Obt=s(oV);MIo=r(Obt,"BlenderbotForConditionalGeneration"),Obt.forEach(t),EIo=r(dSe," (Blenderbot model)"),dSe.forEach(t),CIo=i(be),pb=n(be,"LI",{});var cSe=s(pb);She=n(cSe,"STRONG",{});var Vbt=s(She);wIo=r(Vbt,"blenderbot-small"),Vbt.forEach(t),AIo=r(cSe," \u2014 "),rV=n(cSe,"A",{href:!0});var Xbt=s(rV);LIo=r(Xbt,"BlenderbotSmallForConditionalGeneration"),Xbt.forEach(t),yIo=r(cSe," (BlenderbotSmall model)"),cSe.forEach(t),xIo=i(be),_b=n(be,"LI",{});var fSe=s(_b);Rhe=n(fSe,"STRONG",{});var zbt=s(Rhe);$Io=r(zbt,"encoder-decoder"),zbt.forEach(t),kIo=r(fSe," \u2014 "),tV=n(fSe,"A",{href:!0});var Wbt=s(tV);SIo=r(Wbt,"EncoderDecoderModel"),Wbt.forEach(t),RIo=r(fSe," (Encoder decoder model)"),fSe.forEach(t),PIo=i(be),ub=n(be,"LI",{});var mSe=s(ub);Phe=n(mSe,"STRONG",{});var Qbt=s(Phe);BIo=r(Qbt,"fsmt"),Qbt.forEach(t),IIo=r(mSe," \u2014 "),aV=n(mSe,"A",{href:!0});var Hbt=s(aV);NIo=r(Hbt,"FSMTForConditionalGeneration"),Hbt.forEach(t),qIo=r(mSe," (FairSeq Machine-Translation model)"),mSe.forEach(t),jIo=i(be),bb=n(be,"LI",{});var gSe=s(bb);Bhe=n(gSe,"STRONG",{});var Ubt=s(Bhe);DIo=r(Ubt,"led"),Ubt.forEach(t),GIo=r(gSe," \u2014 "),nV=n(gSe,"A",{href:!0});var Jbt=s(nV);OIo=r(Jbt,"LEDForConditionalGeneration"),Jbt.forEach(t),VIo=r(gSe," (LED model)"),gSe.forEach(t),XIo=i(be),vb=n(be,"LI",{});var hSe=s(vb);Ihe=n(hSe,"STRONG",{});var Ybt=s(Ihe);zIo=r(Ybt,"longt5"),Ybt.forEach(t),WIo=r(hSe," \u2014 "),sV=n(hSe,"A",{href:!0});var Kbt=s(sV);QIo=r(Kbt,"LongT5ForConditionalGeneration"),Kbt.forEach(t),HIo=r(hSe," (LongT5 model)"),hSe.forEach(t),UIo=i(be),Fb=n(be,"LI",{});var pSe=s(Fb);Nhe=n(pSe,"STRONG",{});var Zbt=s(Nhe);JIo=r(Zbt,"m2m_100"),Zbt.forEach(t),YIo=r(pSe," \u2014 "),lV=n(pSe,"A",{href:!0});var evt=s(lV);KIo=r(evt,"M2M100ForConditionalGeneration"),evt.forEach(t),ZIo=r(pSe," (M2M100 model)"),pSe.forEach(t),eNo=i(be),Tb=n(be,"LI",{});var _Se=s(Tb);qhe=n(_Se,"STRONG",{});var ovt=s(qhe);oNo=r(ovt,"marian"),ovt.forEach(t),rNo=r(_Se," \u2014 "),iV=n(_Se,"A",{href:!0});var rvt=s(iV);tNo=r(rvt,"MarianMTModel"),rvt.forEach(t),aNo=r(_Se," (Marian model)"),_Se.forEach(t),nNo=i(be),Mb=n(be,"LI",{});var uSe=s(Mb);jhe=n(uSe,"STRONG",{});var tvt=s(jhe);sNo=r(tvt,"mbart"),tvt.forEach(t),lNo=r(uSe," \u2014 "),dV=n(uSe,"A",{href:!0});var avt=s(dV);iNo=r(avt,"MBartForConditionalGeneration"),avt.forEach(t),dNo=r(uSe," (mBART model)"),uSe.forEach(t),cNo=i(be),Eb=n(be,"LI",{});var bSe=s(Eb);Dhe=n(bSe,"STRONG",{});var nvt=s(Dhe);fNo=r(nvt,"mt5"),nvt.forEach(t),mNo=r(bSe," \u2014 "),cV=n(bSe,"A",{href:!0});var svt=s(cV);gNo=r(svt,"MT5ForConditionalGeneration"),svt.forEach(t),hNo=r(bSe," (MT5 model)"),bSe.forEach(t),pNo=i(be),Cb=n(be,"LI",{});var vSe=s(Cb);Ghe=n(vSe,"STRONG",{});var lvt=s(Ghe);_No=r(lvt,"pegasus"),lvt.forEach(t),uNo=r(vSe," \u2014 "),fV=n(vSe,"A",{href:!0});var ivt=s(fV);bNo=r(ivt,"PegasusForConditionalGeneration"),ivt.forEach(t),vNo=r(vSe," (Pegasus model)"),vSe.forEach(t),FNo=i(be),wb=n(be,"LI",{});var FSe=s(wb);Ohe=n(FSe,"STRONG",{});var dvt=s(Ohe);TNo=r(dvt,"plbart"),dvt.forEach(t),MNo=r(FSe," \u2014 "),mV=n(FSe,"A",{href:!0});var cvt=s(mV);ENo=r(cvt,"PLBartForConditionalGeneration"),cvt.forEach(t),CNo=r(FSe," (PLBart model)"),FSe.forEach(t),wNo=i(be),Ab=n(be,"LI",{});var TSe=s(Ab);Vhe=n(TSe,"STRONG",{});var fvt=s(Vhe);ANo=r(fvt,"prophetnet"),fvt.forEach(t),LNo=r(TSe," \u2014 "),gV=n(TSe,"A",{href:!0});var mvt=s(gV);yNo=r(mvt,"ProphetNetForConditionalGeneration"),mvt.forEach(t),xNo=r(TSe," (ProphetNet model)"),TSe.forEach(t),$No=i(be),Lb=n(be,"LI",{});var MSe=s(Lb);Xhe=n(MSe,"STRONG",{});var gvt=s(Xhe);kNo=r(gvt,"t5"),gvt.forEach(t),SNo=r(MSe," \u2014 "),hV=n(MSe,"A",{href:!0});var hvt=s(hV);RNo=r(hvt,"T5ForConditionalGeneration"),hvt.forEach(t),PNo=r(MSe," (T5 model)"),MSe.forEach(t),BNo=i(be),yb=n(be,"LI",{});var ESe=s(yb);zhe=n(ESe,"STRONG",{});var pvt=s(zhe);INo=r(pvt,"xlm-prophetnet"),pvt.forEach(t),NNo=r(ESe," \u2014 "),pV=n(ESe,"A",{href:!0});var _vt=s(pV);qNo=r(_vt,"XLMProphetNetForConditionalGeneration"),_vt.forEach(t),jNo=r(ESe," (XLM-ProphetNet model)"),ESe.forEach(t),be.forEach(t),DNo=i(da),xb=n(da,"P",{});var CSe=s(xb);GNo=r(CSe,"The model is set in evaluation mode by default using "),Whe=n(CSe,"CODE",{});var uvt=s(Whe);ONo=r(uvt,"model.eval()"),uvt.forEach(t),VNo=r(CSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Qhe=n(CSe,"CODE",{});var bvt=s(Qhe);XNo=r(bvt,"model.train()"),bvt.forEach(t),CSe.forEach(t),zNo=i(da),T($b.$$.fragment,da),da.forEach(t),nl.forEach(t),dVe=i(f),ed=n(f,"H2",{class:!0});var pze=s(ed);kb=n(pze,"A",{id:!0,class:!0,href:!0});var vvt=s(kb);Hhe=n(vvt,"SPAN",{});var Fvt=s(Hhe);T(jL.$$.fragment,Fvt),Fvt.forEach(t),vvt.forEach(t),WNo=i(pze),Uhe=n(pze,"SPAN",{});var Tvt=s(Uhe);QNo=r(Tvt,"AutoModelForSequenceClassification"),Tvt.forEach(t),pze.forEach(t),cVe=i(f),Po=n(f,"DIV",{class:!0});var sl=s(Po);T(DL.$$.fragment,sl),HNo=i(sl),od=n(sl,"P",{});var lre=s(od);UNo=r(lre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),_V=n(lre,"A",{href:!0});var Mvt=s(_V);JNo=r(Mvt,"from_pretrained()"),Mvt.forEach(t),YNo=r(lre," class method or the "),uV=n(lre,"A",{href:!0});var Evt=s(uV);KNo=r(Evt,"from_config()"),Evt.forEach(t),ZNo=r(lre,` class
method.`),lre.forEach(t),eqo=i(sl),GL=n(sl,"P",{});var _ze=s(GL);oqo=r(_ze,"This class cannot be instantiated directly using "),Jhe=n(_ze,"CODE",{});var Cvt=s(Jhe);rqo=r(Cvt,"__init__()"),Cvt.forEach(t),tqo=r(_ze," (throws an error)."),_ze.forEach(t),aqo=i(sl),ft=n(sl,"DIV",{class:!0});var ow=s(ft);T(OL.$$.fragment,ow),nqo=i(ow),Yhe=n(ow,"P",{});var wvt=s(Yhe);sqo=r(wvt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),wvt.forEach(t),lqo=i(ow),rd=n(ow,"P",{});var ire=s(rd);iqo=r(ire,`Note:
Loading a model from its configuration file does `),Khe=n(ire,"STRONG",{});var Avt=s(Khe);dqo=r(Avt,"not"),Avt.forEach(t),cqo=r(ire,` load the model weights. It only affects the
model\u2019s configuration. Use `),bV=n(ire,"A",{href:!0});var Lvt=s(bV);fqo=r(Lvt,"from_pretrained()"),Lvt.forEach(t),mqo=r(ire," to load the model weights."),ire.forEach(t),gqo=i(ow),T(Sb.$$.fragment,ow),ow.forEach(t),hqo=i(sl),oo=n(sl,"DIV",{class:!0});var ca=s(oo);T(VL.$$.fragment,ca),pqo=i(ca),Zhe=n(ca,"P",{});var yvt=s(Zhe);_qo=r(yvt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),yvt.forEach(t),uqo=i(ca),Da=n(ca,"P",{});var rw=s(Da);bqo=r(rw,"The model class to instantiate is selected based on the "),epe=n(rw,"CODE",{});var xvt=s(epe);vqo=r(xvt,"model_type"),xvt.forEach(t),Fqo=r(rw,` property of the config object (either
passed as an argument or loaded from `),ope=n(rw,"CODE",{});var $vt=s(ope);Tqo=r($vt,"pretrained_model_name_or_path"),$vt.forEach(t),Mqo=r(rw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rpe=n(rw,"CODE",{});var kvt=s(rpe);Eqo=r(kvt,"pretrained_model_name_or_path"),kvt.forEach(t),Cqo=r(rw,":"),rw.forEach(t),wqo=i(ca),N=n(ca,"UL",{});var j=s(N);Rb=n(j,"LI",{});var wSe=s(Rb);tpe=n(wSe,"STRONG",{});var Svt=s(tpe);Aqo=r(Svt,"albert"),Svt.forEach(t),Lqo=r(wSe," \u2014 "),vV=n(wSe,"A",{href:!0});var Rvt=s(vV);yqo=r(Rvt,"AlbertForSequenceClassification"),Rvt.forEach(t),xqo=r(wSe," (ALBERT model)"),wSe.forEach(t),$qo=i(j),Pb=n(j,"LI",{});var ASe=s(Pb);ape=n(ASe,"STRONG",{});var Pvt=s(ape);kqo=r(Pvt,"bart"),Pvt.forEach(t),Sqo=r(ASe," \u2014 "),FV=n(ASe,"A",{href:!0});var Bvt=s(FV);Rqo=r(Bvt,"BartForSequenceClassification"),Bvt.forEach(t),Pqo=r(ASe," (BART model)"),ASe.forEach(t),Bqo=i(j),Bb=n(j,"LI",{});var LSe=s(Bb);npe=n(LSe,"STRONG",{});var Ivt=s(npe);Iqo=r(Ivt,"bert"),Ivt.forEach(t),Nqo=r(LSe," \u2014 "),TV=n(LSe,"A",{href:!0});var Nvt=s(TV);qqo=r(Nvt,"BertForSequenceClassification"),Nvt.forEach(t),jqo=r(LSe," (BERT model)"),LSe.forEach(t),Dqo=i(j),Ib=n(j,"LI",{});var ySe=s(Ib);spe=n(ySe,"STRONG",{});var qvt=s(spe);Gqo=r(qvt,"big_bird"),qvt.forEach(t),Oqo=r(ySe," \u2014 "),MV=n(ySe,"A",{href:!0});var jvt=s(MV);Vqo=r(jvt,"BigBirdForSequenceClassification"),jvt.forEach(t),Xqo=r(ySe," (BigBird model)"),ySe.forEach(t),zqo=i(j),Nb=n(j,"LI",{});var xSe=s(Nb);lpe=n(xSe,"STRONG",{});var Dvt=s(lpe);Wqo=r(Dvt,"bigbird_pegasus"),Dvt.forEach(t),Qqo=r(xSe," \u2014 "),EV=n(xSe,"A",{href:!0});var Gvt=s(EV);Hqo=r(Gvt,"BigBirdPegasusForSequenceClassification"),Gvt.forEach(t),Uqo=r(xSe," (BigBird-Pegasus model)"),xSe.forEach(t),Jqo=i(j),qb=n(j,"LI",{});var $Se=s(qb);ipe=n($Se,"STRONG",{});var Ovt=s(ipe);Yqo=r(Ovt,"bloom"),Ovt.forEach(t),Kqo=r($Se," \u2014 "),CV=n($Se,"A",{href:!0});var Vvt=s(CV);Zqo=r(Vvt,"BloomForSequenceClassification"),Vvt.forEach(t),ejo=r($Se," (BLOOM model)"),$Se.forEach(t),ojo=i(j),jb=n(j,"LI",{});var kSe=s(jb);dpe=n(kSe,"STRONG",{});var Xvt=s(dpe);rjo=r(Xvt,"camembert"),Xvt.forEach(t),tjo=r(kSe," \u2014 "),wV=n(kSe,"A",{href:!0});var zvt=s(wV);ajo=r(zvt,"CamembertForSequenceClassification"),zvt.forEach(t),njo=r(kSe," (CamemBERT model)"),kSe.forEach(t),sjo=i(j),Db=n(j,"LI",{});var SSe=s(Db);cpe=n(SSe,"STRONG",{});var Wvt=s(cpe);ljo=r(Wvt,"canine"),Wvt.forEach(t),ijo=r(SSe," \u2014 "),AV=n(SSe,"A",{href:!0});var Qvt=s(AV);djo=r(Qvt,"CanineForSequenceClassification"),Qvt.forEach(t),cjo=r(SSe," (CANINE model)"),SSe.forEach(t),fjo=i(j),Gb=n(j,"LI",{});var RSe=s(Gb);fpe=n(RSe,"STRONG",{});var Hvt=s(fpe);mjo=r(Hvt,"convbert"),Hvt.forEach(t),gjo=r(RSe," \u2014 "),LV=n(RSe,"A",{href:!0});var Uvt=s(LV);hjo=r(Uvt,"ConvBertForSequenceClassification"),Uvt.forEach(t),pjo=r(RSe," (ConvBERT model)"),RSe.forEach(t),_jo=i(j),Ob=n(j,"LI",{});var PSe=s(Ob);mpe=n(PSe,"STRONG",{});var Jvt=s(mpe);ujo=r(Jvt,"ctrl"),Jvt.forEach(t),bjo=r(PSe," \u2014 "),yV=n(PSe,"A",{href:!0});var Yvt=s(yV);vjo=r(Yvt,"CTRLForSequenceClassification"),Yvt.forEach(t),Fjo=r(PSe," (CTRL model)"),PSe.forEach(t),Tjo=i(j),Vb=n(j,"LI",{});var BSe=s(Vb);gpe=n(BSe,"STRONG",{});var Kvt=s(gpe);Mjo=r(Kvt,"data2vec-text"),Kvt.forEach(t),Ejo=r(BSe," \u2014 "),xV=n(BSe,"A",{href:!0});var Zvt=s(xV);Cjo=r(Zvt,"Data2VecTextForSequenceClassification"),Zvt.forEach(t),wjo=r(BSe," (Data2VecText model)"),BSe.forEach(t),Ajo=i(j),Xb=n(j,"LI",{});var ISe=s(Xb);hpe=n(ISe,"STRONG",{});var e0t=s(hpe);Ljo=r(e0t,"deberta"),e0t.forEach(t),yjo=r(ISe," \u2014 "),$V=n(ISe,"A",{href:!0});var o0t=s($V);xjo=r(o0t,"DebertaForSequenceClassification"),o0t.forEach(t),$jo=r(ISe," (DeBERTa model)"),ISe.forEach(t),kjo=i(j),zb=n(j,"LI",{});var NSe=s(zb);ppe=n(NSe,"STRONG",{});var r0t=s(ppe);Sjo=r(r0t,"deberta-v2"),r0t.forEach(t),Rjo=r(NSe," \u2014 "),kV=n(NSe,"A",{href:!0});var t0t=s(kV);Pjo=r(t0t,"DebertaV2ForSequenceClassification"),t0t.forEach(t),Bjo=r(NSe," (DeBERTa-v2 model)"),NSe.forEach(t),Ijo=i(j),Wb=n(j,"LI",{});var qSe=s(Wb);_pe=n(qSe,"STRONG",{});var a0t=s(_pe);Njo=r(a0t,"distilbert"),a0t.forEach(t),qjo=r(qSe," \u2014 "),SV=n(qSe,"A",{href:!0});var n0t=s(SV);jjo=r(n0t,"DistilBertForSequenceClassification"),n0t.forEach(t),Djo=r(qSe," (DistilBERT model)"),qSe.forEach(t),Gjo=i(j),Qb=n(j,"LI",{});var jSe=s(Qb);upe=n(jSe,"STRONG",{});var s0t=s(upe);Ojo=r(s0t,"electra"),s0t.forEach(t),Vjo=r(jSe," \u2014 "),RV=n(jSe,"A",{href:!0});var l0t=s(RV);Xjo=r(l0t,"ElectraForSequenceClassification"),l0t.forEach(t),zjo=r(jSe," (ELECTRA model)"),jSe.forEach(t),Wjo=i(j),Hb=n(j,"LI",{});var DSe=s(Hb);bpe=n(DSe,"STRONG",{});var i0t=s(bpe);Qjo=r(i0t,"flaubert"),i0t.forEach(t),Hjo=r(DSe," \u2014 "),PV=n(DSe,"A",{href:!0});var d0t=s(PV);Ujo=r(d0t,"FlaubertForSequenceClassification"),d0t.forEach(t),Jjo=r(DSe," (FlauBERT model)"),DSe.forEach(t),Yjo=i(j),Ub=n(j,"LI",{});var GSe=s(Ub);vpe=n(GSe,"STRONG",{});var c0t=s(vpe);Kjo=r(c0t,"fnet"),c0t.forEach(t),Zjo=r(GSe," \u2014 "),BV=n(GSe,"A",{href:!0});var f0t=s(BV);eDo=r(f0t,"FNetForSequenceClassification"),f0t.forEach(t),oDo=r(GSe," (FNet model)"),GSe.forEach(t),rDo=i(j),Jb=n(j,"LI",{});var OSe=s(Jb);Fpe=n(OSe,"STRONG",{});var m0t=s(Fpe);tDo=r(m0t,"funnel"),m0t.forEach(t),aDo=r(OSe," \u2014 "),IV=n(OSe,"A",{href:!0});var g0t=s(IV);nDo=r(g0t,"FunnelForSequenceClassification"),g0t.forEach(t),sDo=r(OSe," (Funnel Transformer model)"),OSe.forEach(t),lDo=i(j),Yb=n(j,"LI",{});var VSe=s(Yb);Tpe=n(VSe,"STRONG",{});var h0t=s(Tpe);iDo=r(h0t,"gpt2"),h0t.forEach(t),dDo=r(VSe," \u2014 "),NV=n(VSe,"A",{href:!0});var p0t=s(NV);cDo=r(p0t,"GPT2ForSequenceClassification"),p0t.forEach(t),fDo=r(VSe," (OpenAI GPT-2 model)"),VSe.forEach(t),mDo=i(j),Kb=n(j,"LI",{});var XSe=s(Kb);Mpe=n(XSe,"STRONG",{});var _0t=s(Mpe);gDo=r(_0t,"gpt_neo"),_0t.forEach(t),hDo=r(XSe," \u2014 "),qV=n(XSe,"A",{href:!0});var u0t=s(qV);pDo=r(u0t,"GPTNeoForSequenceClassification"),u0t.forEach(t),_Do=r(XSe," (GPT Neo model)"),XSe.forEach(t),uDo=i(j),Zb=n(j,"LI",{});var zSe=s(Zb);Epe=n(zSe,"STRONG",{});var b0t=s(Epe);bDo=r(b0t,"gptj"),b0t.forEach(t),vDo=r(zSe," \u2014 "),jV=n(zSe,"A",{href:!0});var v0t=s(jV);FDo=r(v0t,"GPTJForSequenceClassification"),v0t.forEach(t),TDo=r(zSe," (GPT-J model)"),zSe.forEach(t),MDo=i(j),ev=n(j,"LI",{});var WSe=s(ev);Cpe=n(WSe,"STRONG",{});var F0t=s(Cpe);EDo=r(F0t,"ibert"),F0t.forEach(t),CDo=r(WSe," \u2014 "),DV=n(WSe,"A",{href:!0});var T0t=s(DV);wDo=r(T0t,"IBertForSequenceClassification"),T0t.forEach(t),ADo=r(WSe," (I-BERT model)"),WSe.forEach(t),LDo=i(j),ov=n(j,"LI",{});var QSe=s(ov);wpe=n(QSe,"STRONG",{});var M0t=s(wpe);yDo=r(M0t,"layoutlm"),M0t.forEach(t),xDo=r(QSe," \u2014 "),GV=n(QSe,"A",{href:!0});var E0t=s(GV);$Do=r(E0t,"LayoutLMForSequenceClassification"),E0t.forEach(t),kDo=r(QSe," (LayoutLM model)"),QSe.forEach(t),SDo=i(j),rv=n(j,"LI",{});var HSe=s(rv);Ape=n(HSe,"STRONG",{});var C0t=s(Ape);RDo=r(C0t,"layoutlmv2"),C0t.forEach(t),PDo=r(HSe," \u2014 "),OV=n(HSe,"A",{href:!0});var w0t=s(OV);BDo=r(w0t,"LayoutLMv2ForSequenceClassification"),w0t.forEach(t),IDo=r(HSe," (LayoutLMv2 model)"),HSe.forEach(t),NDo=i(j),tv=n(j,"LI",{});var USe=s(tv);Lpe=n(USe,"STRONG",{});var A0t=s(Lpe);qDo=r(A0t,"layoutlmv3"),A0t.forEach(t),jDo=r(USe," \u2014 "),VV=n(USe,"A",{href:!0});var L0t=s(VV);DDo=r(L0t,"LayoutLMv3ForSequenceClassification"),L0t.forEach(t),GDo=r(USe," (LayoutLMv3 model)"),USe.forEach(t),ODo=i(j),av=n(j,"LI",{});var JSe=s(av);ype=n(JSe,"STRONG",{});var y0t=s(ype);VDo=r(y0t,"led"),y0t.forEach(t),XDo=r(JSe," \u2014 "),XV=n(JSe,"A",{href:!0});var x0t=s(XV);zDo=r(x0t,"LEDForSequenceClassification"),x0t.forEach(t),WDo=r(JSe," (LED model)"),JSe.forEach(t),QDo=i(j),nv=n(j,"LI",{});var YSe=s(nv);xpe=n(YSe,"STRONG",{});var $0t=s(xpe);HDo=r($0t,"longformer"),$0t.forEach(t),UDo=r(YSe," \u2014 "),zV=n(YSe,"A",{href:!0});var k0t=s(zV);JDo=r(k0t,"LongformerForSequenceClassification"),k0t.forEach(t),YDo=r(YSe," (Longformer model)"),YSe.forEach(t),KDo=i(j),sv=n(j,"LI",{});var KSe=s(sv);$pe=n(KSe,"STRONG",{});var S0t=s($pe);ZDo=r(S0t,"mbart"),S0t.forEach(t),eGo=r(KSe," \u2014 "),WV=n(KSe,"A",{href:!0});var R0t=s(WV);oGo=r(R0t,"MBartForSequenceClassification"),R0t.forEach(t),rGo=r(KSe," (mBART model)"),KSe.forEach(t),tGo=i(j),lv=n(j,"LI",{});var ZSe=s(lv);kpe=n(ZSe,"STRONG",{});var P0t=s(kpe);aGo=r(P0t,"megatron-bert"),P0t.forEach(t),nGo=r(ZSe," \u2014 "),QV=n(ZSe,"A",{href:!0});var B0t=s(QV);sGo=r(B0t,"MegatronBertForSequenceClassification"),B0t.forEach(t),lGo=r(ZSe," (Megatron-BERT model)"),ZSe.forEach(t),iGo=i(j),iv=n(j,"LI",{});var eRe=s(iv);Spe=n(eRe,"STRONG",{});var I0t=s(Spe);dGo=r(I0t,"mobilebert"),I0t.forEach(t),cGo=r(eRe," \u2014 "),HV=n(eRe,"A",{href:!0});var N0t=s(HV);fGo=r(N0t,"MobileBertForSequenceClassification"),N0t.forEach(t),mGo=r(eRe," (MobileBERT model)"),eRe.forEach(t),gGo=i(j),dv=n(j,"LI",{});var oRe=s(dv);Rpe=n(oRe,"STRONG",{});var q0t=s(Rpe);hGo=r(q0t,"mpnet"),q0t.forEach(t),pGo=r(oRe," \u2014 "),UV=n(oRe,"A",{href:!0});var j0t=s(UV);_Go=r(j0t,"MPNetForSequenceClassification"),j0t.forEach(t),uGo=r(oRe," (MPNet model)"),oRe.forEach(t),bGo=i(j),cv=n(j,"LI",{});var rRe=s(cv);Ppe=n(rRe,"STRONG",{});var D0t=s(Ppe);vGo=r(D0t,"nezha"),D0t.forEach(t),FGo=r(rRe," \u2014 "),JV=n(rRe,"A",{href:!0});var G0t=s(JV);TGo=r(G0t,"NezhaForSequenceClassification"),G0t.forEach(t),MGo=r(rRe," (Nezha model)"),rRe.forEach(t),EGo=i(j),fv=n(j,"LI",{});var tRe=s(fv);Bpe=n(tRe,"STRONG",{});var O0t=s(Bpe);CGo=r(O0t,"nystromformer"),O0t.forEach(t),wGo=r(tRe," \u2014 "),YV=n(tRe,"A",{href:!0});var V0t=s(YV);AGo=r(V0t,"NystromformerForSequenceClassification"),V0t.forEach(t),LGo=r(tRe," (Nystr\xF6mformer model)"),tRe.forEach(t),yGo=i(j),mv=n(j,"LI",{});var aRe=s(mv);Ipe=n(aRe,"STRONG",{});var X0t=s(Ipe);xGo=r(X0t,"openai-gpt"),X0t.forEach(t),$Go=r(aRe," \u2014 "),KV=n(aRe,"A",{href:!0});var z0t=s(KV);kGo=r(z0t,"OpenAIGPTForSequenceClassification"),z0t.forEach(t),SGo=r(aRe," (OpenAI GPT model)"),aRe.forEach(t),RGo=i(j),gv=n(j,"LI",{});var nRe=s(gv);Npe=n(nRe,"STRONG",{});var W0t=s(Npe);PGo=r(W0t,"perceiver"),W0t.forEach(t),BGo=r(nRe," \u2014 "),ZV=n(nRe,"A",{href:!0});var Q0t=s(ZV);IGo=r(Q0t,"PerceiverForSequenceClassification"),Q0t.forEach(t),NGo=r(nRe," (Perceiver model)"),nRe.forEach(t),qGo=i(j),hv=n(j,"LI",{});var sRe=s(hv);qpe=n(sRe,"STRONG",{});var H0t=s(qpe);jGo=r(H0t,"plbart"),H0t.forEach(t),DGo=r(sRe," \u2014 "),eX=n(sRe,"A",{href:!0});var U0t=s(eX);GGo=r(U0t,"PLBartForSequenceClassification"),U0t.forEach(t),OGo=r(sRe," (PLBart model)"),sRe.forEach(t),VGo=i(j),pv=n(j,"LI",{});var lRe=s(pv);jpe=n(lRe,"STRONG",{});var J0t=s(jpe);XGo=r(J0t,"qdqbert"),J0t.forEach(t),zGo=r(lRe," \u2014 "),oX=n(lRe,"A",{href:!0});var Y0t=s(oX);WGo=r(Y0t,"QDQBertForSequenceClassification"),Y0t.forEach(t),QGo=r(lRe," (QDQBert model)"),lRe.forEach(t),HGo=i(j),_v=n(j,"LI",{});var iRe=s(_v);Dpe=n(iRe,"STRONG",{});var K0t=s(Dpe);UGo=r(K0t,"reformer"),K0t.forEach(t),JGo=r(iRe," \u2014 "),rX=n(iRe,"A",{href:!0});var Z0t=s(rX);YGo=r(Z0t,"ReformerForSequenceClassification"),Z0t.forEach(t),KGo=r(iRe," (Reformer model)"),iRe.forEach(t),ZGo=i(j),uv=n(j,"LI",{});var dRe=s(uv);Gpe=n(dRe,"STRONG",{});var eFt=s(Gpe);eOo=r(eFt,"rembert"),eFt.forEach(t),oOo=r(dRe," \u2014 "),tX=n(dRe,"A",{href:!0});var oFt=s(tX);rOo=r(oFt,"RemBertForSequenceClassification"),oFt.forEach(t),tOo=r(dRe," (RemBERT model)"),dRe.forEach(t),aOo=i(j),bv=n(j,"LI",{});var cRe=s(bv);Ope=n(cRe,"STRONG",{});var rFt=s(Ope);nOo=r(rFt,"roberta"),rFt.forEach(t),sOo=r(cRe," \u2014 "),aX=n(cRe,"A",{href:!0});var tFt=s(aX);lOo=r(tFt,"RobertaForSequenceClassification"),tFt.forEach(t),iOo=r(cRe," (RoBERTa model)"),cRe.forEach(t),dOo=i(j),vv=n(j,"LI",{});var fRe=s(vv);Vpe=n(fRe,"STRONG",{});var aFt=s(Vpe);cOo=r(aFt,"roformer"),aFt.forEach(t),fOo=r(fRe," \u2014 "),nX=n(fRe,"A",{href:!0});var nFt=s(nX);mOo=r(nFt,"RoFormerForSequenceClassification"),nFt.forEach(t),gOo=r(fRe," (RoFormer model)"),fRe.forEach(t),hOo=i(j),Fv=n(j,"LI",{});var mRe=s(Fv);Xpe=n(mRe,"STRONG",{});var sFt=s(Xpe);pOo=r(sFt,"squeezebert"),sFt.forEach(t),_Oo=r(mRe," \u2014 "),sX=n(mRe,"A",{href:!0});var lFt=s(sX);uOo=r(lFt,"SqueezeBertForSequenceClassification"),lFt.forEach(t),bOo=r(mRe," (SqueezeBERT model)"),mRe.forEach(t),vOo=i(j),Tv=n(j,"LI",{});var gRe=s(Tv);zpe=n(gRe,"STRONG",{});var iFt=s(zpe);FOo=r(iFt,"tapas"),iFt.forEach(t),TOo=r(gRe," \u2014 "),lX=n(gRe,"A",{href:!0});var dFt=s(lX);MOo=r(dFt,"TapasForSequenceClassification"),dFt.forEach(t),EOo=r(gRe," (TAPAS model)"),gRe.forEach(t),COo=i(j),Mv=n(j,"LI",{});var hRe=s(Mv);Wpe=n(hRe,"STRONG",{});var cFt=s(Wpe);wOo=r(cFt,"transfo-xl"),cFt.forEach(t),AOo=r(hRe," \u2014 "),iX=n(hRe,"A",{href:!0});var fFt=s(iX);LOo=r(fFt,"TransfoXLForSequenceClassification"),fFt.forEach(t),yOo=r(hRe," (Transformer-XL model)"),hRe.forEach(t),xOo=i(j),Ev=n(j,"LI",{});var pRe=s(Ev);Qpe=n(pRe,"STRONG",{});var mFt=s(Qpe);$Oo=r(mFt,"xlm"),mFt.forEach(t),kOo=r(pRe," \u2014 "),dX=n(pRe,"A",{href:!0});var gFt=s(dX);SOo=r(gFt,"XLMForSequenceClassification"),gFt.forEach(t),ROo=r(pRe," (XLM model)"),pRe.forEach(t),POo=i(j),Cv=n(j,"LI",{});var _Re=s(Cv);Hpe=n(_Re,"STRONG",{});var hFt=s(Hpe);BOo=r(hFt,"xlm-roberta"),hFt.forEach(t),IOo=r(_Re," \u2014 "),cX=n(_Re,"A",{href:!0});var pFt=s(cX);NOo=r(pFt,"XLMRobertaForSequenceClassification"),pFt.forEach(t),qOo=r(_Re," (XLM-RoBERTa model)"),_Re.forEach(t),jOo=i(j),wv=n(j,"LI",{});var uRe=s(wv);Upe=n(uRe,"STRONG",{});var _Ft=s(Upe);DOo=r(_Ft,"xlm-roberta-xl"),_Ft.forEach(t),GOo=r(uRe," \u2014 "),fX=n(uRe,"A",{href:!0});var uFt=s(fX);OOo=r(uFt,"XLMRobertaXLForSequenceClassification"),uFt.forEach(t),VOo=r(uRe," (XLM-RoBERTa-XL model)"),uRe.forEach(t),XOo=i(j),Av=n(j,"LI",{});var bRe=s(Av);Jpe=n(bRe,"STRONG",{});var bFt=s(Jpe);zOo=r(bFt,"xlnet"),bFt.forEach(t),WOo=r(bRe," \u2014 "),mX=n(bRe,"A",{href:!0});var vFt=s(mX);QOo=r(vFt,"XLNetForSequenceClassification"),vFt.forEach(t),HOo=r(bRe," (XLNet model)"),bRe.forEach(t),UOo=i(j),Lv=n(j,"LI",{});var vRe=s(Lv);Ype=n(vRe,"STRONG",{});var FFt=s(Ype);JOo=r(FFt,"yoso"),FFt.forEach(t),YOo=r(vRe," \u2014 "),gX=n(vRe,"A",{href:!0});var TFt=s(gX);KOo=r(TFt,"YosoForSequenceClassification"),TFt.forEach(t),ZOo=r(vRe," (YOSO model)"),vRe.forEach(t),j.forEach(t),eVo=i(ca),yv=n(ca,"P",{});var FRe=s(yv);oVo=r(FRe,"The model is set in evaluation mode by default using "),Kpe=n(FRe,"CODE",{});var MFt=s(Kpe);rVo=r(MFt,"model.eval()"),MFt.forEach(t),tVo=r(FRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Zpe=n(FRe,"CODE",{});var EFt=s(Zpe);aVo=r(EFt,"model.train()"),EFt.forEach(t),FRe.forEach(t),nVo=i(ca),T(xv.$$.fragment,ca),ca.forEach(t),sl.forEach(t),fVe=i(f),td=n(f,"H2",{class:!0});var uze=s(td);$v=n(uze,"A",{id:!0,class:!0,href:!0});var CFt=s($v);e_e=n(CFt,"SPAN",{});var wFt=s(e_e);T(XL.$$.fragment,wFt),wFt.forEach(t),CFt.forEach(t),sVo=i(uze),o_e=n(uze,"SPAN",{});var AFt=s(o_e);lVo=r(AFt,"AutoModelForMultipleChoice"),AFt.forEach(t),uze.forEach(t),mVe=i(f),Bo=n(f,"DIV",{class:!0});var ll=s(Bo);T(zL.$$.fragment,ll),iVo=i(ll),ad=n(ll,"P",{});var dre=s(ad);dVo=r(dre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),hX=n(dre,"A",{href:!0});var LFt=s(hX);cVo=r(LFt,"from_pretrained()"),LFt.forEach(t),fVo=r(dre," class method or the "),pX=n(dre,"A",{href:!0});var yFt=s(pX);mVo=r(yFt,"from_config()"),yFt.forEach(t),gVo=r(dre,` class
method.`),dre.forEach(t),hVo=i(ll),WL=n(ll,"P",{});var bze=s(WL);pVo=r(bze,"This class cannot be instantiated directly using "),r_e=n(bze,"CODE",{});var xFt=s(r_e);_Vo=r(xFt,"__init__()"),xFt.forEach(t),uVo=r(bze," (throws an error)."),bze.forEach(t),bVo=i(ll),mt=n(ll,"DIV",{class:!0});var tw=s(mt);T(QL.$$.fragment,tw),vVo=i(tw),t_e=n(tw,"P",{});var $Ft=s(t_e);FVo=r($Ft,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),$Ft.forEach(t),TVo=i(tw),nd=n(tw,"P",{});var cre=s(nd);MVo=r(cre,`Note:
Loading a model from its configuration file does `),a_e=n(cre,"STRONG",{});var kFt=s(a_e);EVo=r(kFt,"not"),kFt.forEach(t),CVo=r(cre,` load the model weights. It only affects the
model\u2019s configuration. Use `),_X=n(cre,"A",{href:!0});var SFt=s(_X);wVo=r(SFt,"from_pretrained()"),SFt.forEach(t),AVo=r(cre," to load the model weights."),cre.forEach(t),LVo=i(tw),T(kv.$$.fragment,tw),tw.forEach(t),yVo=i(ll),ro=n(ll,"DIV",{class:!0});var fa=s(ro);T(HL.$$.fragment,fa),xVo=i(fa),n_e=n(fa,"P",{});var RFt=s(n_e);$Vo=r(RFt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),RFt.forEach(t),kVo=i(fa),Ga=n(fa,"P",{});var aw=s(Ga);SVo=r(aw,"The model class to instantiate is selected based on the "),s_e=n(aw,"CODE",{});var PFt=s(s_e);RVo=r(PFt,"model_type"),PFt.forEach(t),PVo=r(aw,` property of the config object (either
passed as an argument or loaded from `),l_e=n(aw,"CODE",{});var BFt=s(l_e);BVo=r(BFt,"pretrained_model_name_or_path"),BFt.forEach(t),IVo=r(aw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i_e=n(aw,"CODE",{});var IFt=s(i_e);NVo=r(IFt,"pretrained_model_name_or_path"),IFt.forEach(t),qVo=r(aw,":"),aw.forEach(t),jVo=i(fa),Z=n(fa,"UL",{});var ee=s(Z);Sv=n(ee,"LI",{});var TRe=s(Sv);d_e=n(TRe,"STRONG",{});var NFt=s(d_e);DVo=r(NFt,"albert"),NFt.forEach(t),GVo=r(TRe," \u2014 "),uX=n(TRe,"A",{href:!0});var qFt=s(uX);OVo=r(qFt,"AlbertForMultipleChoice"),qFt.forEach(t),VVo=r(TRe," (ALBERT model)"),TRe.forEach(t),XVo=i(ee),Rv=n(ee,"LI",{});var MRe=s(Rv);c_e=n(MRe,"STRONG",{});var jFt=s(c_e);zVo=r(jFt,"bert"),jFt.forEach(t),WVo=r(MRe," \u2014 "),bX=n(MRe,"A",{href:!0});var DFt=s(bX);QVo=r(DFt,"BertForMultipleChoice"),DFt.forEach(t),HVo=r(MRe," (BERT model)"),MRe.forEach(t),UVo=i(ee),Pv=n(ee,"LI",{});var ERe=s(Pv);f_e=n(ERe,"STRONG",{});var GFt=s(f_e);JVo=r(GFt,"big_bird"),GFt.forEach(t),YVo=r(ERe," \u2014 "),vX=n(ERe,"A",{href:!0});var OFt=s(vX);KVo=r(OFt,"BigBirdForMultipleChoice"),OFt.forEach(t),ZVo=r(ERe," (BigBird model)"),ERe.forEach(t),eXo=i(ee),Bv=n(ee,"LI",{});var CRe=s(Bv);m_e=n(CRe,"STRONG",{});var VFt=s(m_e);oXo=r(VFt,"camembert"),VFt.forEach(t),rXo=r(CRe," \u2014 "),FX=n(CRe,"A",{href:!0});var XFt=s(FX);tXo=r(XFt,"CamembertForMultipleChoice"),XFt.forEach(t),aXo=r(CRe," (CamemBERT model)"),CRe.forEach(t),nXo=i(ee),Iv=n(ee,"LI",{});var wRe=s(Iv);g_e=n(wRe,"STRONG",{});var zFt=s(g_e);sXo=r(zFt,"canine"),zFt.forEach(t),lXo=r(wRe," \u2014 "),TX=n(wRe,"A",{href:!0});var WFt=s(TX);iXo=r(WFt,"CanineForMultipleChoice"),WFt.forEach(t),dXo=r(wRe," (CANINE model)"),wRe.forEach(t),cXo=i(ee),Nv=n(ee,"LI",{});var ARe=s(Nv);h_e=n(ARe,"STRONG",{});var QFt=s(h_e);fXo=r(QFt,"convbert"),QFt.forEach(t),mXo=r(ARe," \u2014 "),MX=n(ARe,"A",{href:!0});var HFt=s(MX);gXo=r(HFt,"ConvBertForMultipleChoice"),HFt.forEach(t),hXo=r(ARe," (ConvBERT model)"),ARe.forEach(t),pXo=i(ee),qv=n(ee,"LI",{});var LRe=s(qv);p_e=n(LRe,"STRONG",{});var UFt=s(p_e);_Xo=r(UFt,"data2vec-text"),UFt.forEach(t),uXo=r(LRe," \u2014 "),EX=n(LRe,"A",{href:!0});var JFt=s(EX);bXo=r(JFt,"Data2VecTextForMultipleChoice"),JFt.forEach(t),vXo=r(LRe," (Data2VecText model)"),LRe.forEach(t),FXo=i(ee),jv=n(ee,"LI",{});var yRe=s(jv);__e=n(yRe,"STRONG",{});var YFt=s(__e);TXo=r(YFt,"deberta-v2"),YFt.forEach(t),MXo=r(yRe," \u2014 "),CX=n(yRe,"A",{href:!0});var KFt=s(CX);EXo=r(KFt,"DebertaV2ForMultipleChoice"),KFt.forEach(t),CXo=r(yRe," (DeBERTa-v2 model)"),yRe.forEach(t),wXo=i(ee),Dv=n(ee,"LI",{});var xRe=s(Dv);u_e=n(xRe,"STRONG",{});var ZFt=s(u_e);AXo=r(ZFt,"distilbert"),ZFt.forEach(t),LXo=r(xRe," \u2014 "),wX=n(xRe,"A",{href:!0});var e6t=s(wX);yXo=r(e6t,"DistilBertForMultipleChoice"),e6t.forEach(t),xXo=r(xRe," (DistilBERT model)"),xRe.forEach(t),$Xo=i(ee),Gv=n(ee,"LI",{});var $Re=s(Gv);b_e=n($Re,"STRONG",{});var o6t=s(b_e);kXo=r(o6t,"electra"),o6t.forEach(t),SXo=r($Re," \u2014 "),AX=n($Re,"A",{href:!0});var r6t=s(AX);RXo=r(r6t,"ElectraForMultipleChoice"),r6t.forEach(t),PXo=r($Re," (ELECTRA model)"),$Re.forEach(t),BXo=i(ee),Ov=n(ee,"LI",{});var kRe=s(Ov);v_e=n(kRe,"STRONG",{});var t6t=s(v_e);IXo=r(t6t,"flaubert"),t6t.forEach(t),NXo=r(kRe," \u2014 "),LX=n(kRe,"A",{href:!0});var a6t=s(LX);qXo=r(a6t,"FlaubertForMultipleChoice"),a6t.forEach(t),jXo=r(kRe," (FlauBERT model)"),kRe.forEach(t),DXo=i(ee),Vv=n(ee,"LI",{});var SRe=s(Vv);F_e=n(SRe,"STRONG",{});var n6t=s(F_e);GXo=r(n6t,"fnet"),n6t.forEach(t),OXo=r(SRe," \u2014 "),yX=n(SRe,"A",{href:!0});var s6t=s(yX);VXo=r(s6t,"FNetForMultipleChoice"),s6t.forEach(t),XXo=r(SRe," (FNet model)"),SRe.forEach(t),zXo=i(ee),Xv=n(ee,"LI",{});var RRe=s(Xv);T_e=n(RRe,"STRONG",{});var l6t=s(T_e);WXo=r(l6t,"funnel"),l6t.forEach(t),QXo=r(RRe," \u2014 "),xX=n(RRe,"A",{href:!0});var i6t=s(xX);HXo=r(i6t,"FunnelForMultipleChoice"),i6t.forEach(t),UXo=r(RRe," (Funnel Transformer model)"),RRe.forEach(t),JXo=i(ee),zv=n(ee,"LI",{});var PRe=s(zv);M_e=n(PRe,"STRONG",{});var d6t=s(M_e);YXo=r(d6t,"ibert"),d6t.forEach(t),KXo=r(PRe," \u2014 "),$X=n(PRe,"A",{href:!0});var c6t=s($X);ZXo=r(c6t,"IBertForMultipleChoice"),c6t.forEach(t),ezo=r(PRe," (I-BERT model)"),PRe.forEach(t),ozo=i(ee),Wv=n(ee,"LI",{});var BRe=s(Wv);E_e=n(BRe,"STRONG",{});var f6t=s(E_e);rzo=r(f6t,"longformer"),f6t.forEach(t),tzo=r(BRe," \u2014 "),kX=n(BRe,"A",{href:!0});var m6t=s(kX);azo=r(m6t,"LongformerForMultipleChoice"),m6t.forEach(t),nzo=r(BRe," (Longformer model)"),BRe.forEach(t),szo=i(ee),Qv=n(ee,"LI",{});var IRe=s(Qv);C_e=n(IRe,"STRONG",{});var g6t=s(C_e);lzo=r(g6t,"megatron-bert"),g6t.forEach(t),izo=r(IRe," \u2014 "),SX=n(IRe,"A",{href:!0});var h6t=s(SX);dzo=r(h6t,"MegatronBertForMultipleChoice"),h6t.forEach(t),czo=r(IRe," (Megatron-BERT model)"),IRe.forEach(t),fzo=i(ee),Hv=n(ee,"LI",{});var NRe=s(Hv);w_e=n(NRe,"STRONG",{});var p6t=s(w_e);mzo=r(p6t,"mobilebert"),p6t.forEach(t),gzo=r(NRe," \u2014 "),RX=n(NRe,"A",{href:!0});var _6t=s(RX);hzo=r(_6t,"MobileBertForMultipleChoice"),_6t.forEach(t),pzo=r(NRe," (MobileBERT model)"),NRe.forEach(t),_zo=i(ee),Uv=n(ee,"LI",{});var qRe=s(Uv);A_e=n(qRe,"STRONG",{});var u6t=s(A_e);uzo=r(u6t,"mpnet"),u6t.forEach(t),bzo=r(qRe," \u2014 "),PX=n(qRe,"A",{href:!0});var b6t=s(PX);vzo=r(b6t,"MPNetForMultipleChoice"),b6t.forEach(t),Fzo=r(qRe," (MPNet model)"),qRe.forEach(t),Tzo=i(ee),Jv=n(ee,"LI",{});var jRe=s(Jv);L_e=n(jRe,"STRONG",{});var v6t=s(L_e);Mzo=r(v6t,"nezha"),v6t.forEach(t),Ezo=r(jRe," \u2014 "),BX=n(jRe,"A",{href:!0});var F6t=s(BX);Czo=r(F6t,"NezhaForMultipleChoice"),F6t.forEach(t),wzo=r(jRe," (Nezha model)"),jRe.forEach(t),Azo=i(ee),Yv=n(ee,"LI",{});var DRe=s(Yv);y_e=n(DRe,"STRONG",{});var T6t=s(y_e);Lzo=r(T6t,"nystromformer"),T6t.forEach(t),yzo=r(DRe," \u2014 "),IX=n(DRe,"A",{href:!0});var M6t=s(IX);xzo=r(M6t,"NystromformerForMultipleChoice"),M6t.forEach(t),$zo=r(DRe," (Nystr\xF6mformer model)"),DRe.forEach(t),kzo=i(ee),Kv=n(ee,"LI",{});var GRe=s(Kv);x_e=n(GRe,"STRONG",{});var E6t=s(x_e);Szo=r(E6t,"qdqbert"),E6t.forEach(t),Rzo=r(GRe," \u2014 "),NX=n(GRe,"A",{href:!0});var C6t=s(NX);Pzo=r(C6t,"QDQBertForMultipleChoice"),C6t.forEach(t),Bzo=r(GRe," (QDQBert model)"),GRe.forEach(t),Izo=i(ee),Zv=n(ee,"LI",{});var ORe=s(Zv);$_e=n(ORe,"STRONG",{});var w6t=s($_e);Nzo=r(w6t,"rembert"),w6t.forEach(t),qzo=r(ORe," \u2014 "),qX=n(ORe,"A",{href:!0});var A6t=s(qX);jzo=r(A6t,"RemBertForMultipleChoice"),A6t.forEach(t),Dzo=r(ORe," (RemBERT model)"),ORe.forEach(t),Gzo=i(ee),e0=n(ee,"LI",{});var VRe=s(e0);k_e=n(VRe,"STRONG",{});var L6t=s(k_e);Ozo=r(L6t,"roberta"),L6t.forEach(t),Vzo=r(VRe," \u2014 "),jX=n(VRe,"A",{href:!0});var y6t=s(jX);Xzo=r(y6t,"RobertaForMultipleChoice"),y6t.forEach(t),zzo=r(VRe," (RoBERTa model)"),VRe.forEach(t),Wzo=i(ee),o0=n(ee,"LI",{});var XRe=s(o0);S_e=n(XRe,"STRONG",{});var x6t=s(S_e);Qzo=r(x6t,"roformer"),x6t.forEach(t),Hzo=r(XRe," \u2014 "),DX=n(XRe,"A",{href:!0});var $6t=s(DX);Uzo=r($6t,"RoFormerForMultipleChoice"),$6t.forEach(t),Jzo=r(XRe," (RoFormer model)"),XRe.forEach(t),Yzo=i(ee),r0=n(ee,"LI",{});var zRe=s(r0);R_e=n(zRe,"STRONG",{});var k6t=s(R_e);Kzo=r(k6t,"squeezebert"),k6t.forEach(t),Zzo=r(zRe," \u2014 "),GX=n(zRe,"A",{href:!0});var S6t=s(GX);eWo=r(S6t,"SqueezeBertForMultipleChoice"),S6t.forEach(t),oWo=r(zRe," (SqueezeBERT model)"),zRe.forEach(t),rWo=i(ee),t0=n(ee,"LI",{});var WRe=s(t0);P_e=n(WRe,"STRONG",{});var R6t=s(P_e);tWo=r(R6t,"xlm"),R6t.forEach(t),aWo=r(WRe," \u2014 "),OX=n(WRe,"A",{href:!0});var P6t=s(OX);nWo=r(P6t,"XLMForMultipleChoice"),P6t.forEach(t),sWo=r(WRe," (XLM model)"),WRe.forEach(t),lWo=i(ee),a0=n(ee,"LI",{});var QRe=s(a0);B_e=n(QRe,"STRONG",{});var B6t=s(B_e);iWo=r(B6t,"xlm-roberta"),B6t.forEach(t),dWo=r(QRe," \u2014 "),VX=n(QRe,"A",{href:!0});var I6t=s(VX);cWo=r(I6t,"XLMRobertaForMultipleChoice"),I6t.forEach(t),fWo=r(QRe," (XLM-RoBERTa model)"),QRe.forEach(t),mWo=i(ee),n0=n(ee,"LI",{});var HRe=s(n0);I_e=n(HRe,"STRONG",{});var N6t=s(I_e);gWo=r(N6t,"xlm-roberta-xl"),N6t.forEach(t),hWo=r(HRe," \u2014 "),XX=n(HRe,"A",{href:!0});var q6t=s(XX);pWo=r(q6t,"XLMRobertaXLForMultipleChoice"),q6t.forEach(t),_Wo=r(HRe," (XLM-RoBERTa-XL model)"),HRe.forEach(t),uWo=i(ee),s0=n(ee,"LI",{});var URe=s(s0);N_e=n(URe,"STRONG",{});var j6t=s(N_e);bWo=r(j6t,"xlnet"),j6t.forEach(t),vWo=r(URe," \u2014 "),zX=n(URe,"A",{href:!0});var D6t=s(zX);FWo=r(D6t,"XLNetForMultipleChoice"),D6t.forEach(t),TWo=r(URe," (XLNet model)"),URe.forEach(t),MWo=i(ee),l0=n(ee,"LI",{});var JRe=s(l0);q_e=n(JRe,"STRONG",{});var G6t=s(q_e);EWo=r(G6t,"yoso"),G6t.forEach(t),CWo=r(JRe," \u2014 "),WX=n(JRe,"A",{href:!0});var O6t=s(WX);wWo=r(O6t,"YosoForMultipleChoice"),O6t.forEach(t),AWo=r(JRe," (YOSO model)"),JRe.forEach(t),ee.forEach(t),LWo=i(fa),i0=n(fa,"P",{});var YRe=s(i0);yWo=r(YRe,"The model is set in evaluation mode by default using "),j_e=n(YRe,"CODE",{});var V6t=s(j_e);xWo=r(V6t,"model.eval()"),V6t.forEach(t),$Wo=r(YRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),D_e=n(YRe,"CODE",{});var X6t=s(D_e);kWo=r(X6t,"model.train()"),X6t.forEach(t),YRe.forEach(t),SWo=i(fa),T(d0.$$.fragment,fa),fa.forEach(t),ll.forEach(t),gVe=i(f),sd=n(f,"H2",{class:!0});var vze=s(sd);c0=n(vze,"A",{id:!0,class:!0,href:!0});var z6t=s(c0);G_e=n(z6t,"SPAN",{});var W6t=s(G_e);T(UL.$$.fragment,W6t),W6t.forEach(t),z6t.forEach(t),RWo=i(vze),O_e=n(vze,"SPAN",{});var Q6t=s(O_e);PWo=r(Q6t,"AutoModelForNextSentencePrediction"),Q6t.forEach(t),vze.forEach(t),hVe=i(f),Io=n(f,"DIV",{class:!0});var il=s(Io);T(JL.$$.fragment,il),BWo=i(il),ld=n(il,"P",{});var fre=s(ld);IWo=r(fre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),QX=n(fre,"A",{href:!0});var H6t=s(QX);NWo=r(H6t,"from_pretrained()"),H6t.forEach(t),qWo=r(fre," class method or the "),HX=n(fre,"A",{href:!0});var U6t=s(HX);jWo=r(U6t,"from_config()"),U6t.forEach(t),DWo=r(fre,` class
method.`),fre.forEach(t),GWo=i(il),YL=n(il,"P",{});var Fze=s(YL);OWo=r(Fze,"This class cannot be instantiated directly using "),V_e=n(Fze,"CODE",{});var J6t=s(V_e);VWo=r(J6t,"__init__()"),J6t.forEach(t),XWo=r(Fze," (throws an error)."),Fze.forEach(t),zWo=i(il),gt=n(il,"DIV",{class:!0});var nw=s(gt);T(KL.$$.fragment,nw),WWo=i(nw),X_e=n(nw,"P",{});var Y6t=s(X_e);QWo=r(Y6t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Y6t.forEach(t),HWo=i(nw),id=n(nw,"P",{});var mre=s(id);UWo=r(mre,`Note:
Loading a model from its configuration file does `),z_e=n(mre,"STRONG",{});var K6t=s(z_e);JWo=r(K6t,"not"),K6t.forEach(t),YWo=r(mre,` load the model weights. It only affects the
model\u2019s configuration. Use `),UX=n(mre,"A",{href:!0});var Z6t=s(UX);KWo=r(Z6t,"from_pretrained()"),Z6t.forEach(t),ZWo=r(mre," to load the model weights."),mre.forEach(t),eQo=i(nw),T(f0.$$.fragment,nw),nw.forEach(t),oQo=i(il),to=n(il,"DIV",{class:!0});var ma=s(to);T(ZL.$$.fragment,ma),rQo=i(ma),W_e=n(ma,"P",{});var eTt=s(W_e);tQo=r(eTt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),eTt.forEach(t),aQo=i(ma),Oa=n(ma,"P",{});var sw=s(Oa);nQo=r(sw,"The model class to instantiate is selected based on the "),Q_e=n(sw,"CODE",{});var oTt=s(Q_e);sQo=r(oTt,"model_type"),oTt.forEach(t),lQo=r(sw,` property of the config object (either
passed as an argument or loaded from `),H_e=n(sw,"CODE",{});var rTt=s(H_e);iQo=r(rTt,"pretrained_model_name_or_path"),rTt.forEach(t),dQo=r(sw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U_e=n(sw,"CODE",{});var tTt=s(U_e);cQo=r(tTt,"pretrained_model_name_or_path"),tTt.forEach(t),fQo=r(sw,":"),sw.forEach(t),mQo=i(ma),No=n(ma,"UL",{});var ga=s(No);m0=n(ga,"LI",{});var KRe=s(m0);J_e=n(KRe,"STRONG",{});var aTt=s(J_e);gQo=r(aTt,"bert"),aTt.forEach(t),hQo=r(KRe," \u2014 "),JX=n(KRe,"A",{href:!0});var nTt=s(JX);pQo=r(nTt,"BertForNextSentencePrediction"),nTt.forEach(t),_Qo=r(KRe," (BERT model)"),KRe.forEach(t),uQo=i(ga),g0=n(ga,"LI",{});var ZRe=s(g0);Y_e=n(ZRe,"STRONG",{});var sTt=s(Y_e);bQo=r(sTt,"fnet"),sTt.forEach(t),vQo=r(ZRe," \u2014 "),YX=n(ZRe,"A",{href:!0});var lTt=s(YX);FQo=r(lTt,"FNetForNextSentencePrediction"),lTt.forEach(t),TQo=r(ZRe," (FNet model)"),ZRe.forEach(t),MQo=i(ga),h0=n(ga,"LI",{});var ePe=s(h0);K_e=n(ePe,"STRONG",{});var iTt=s(K_e);EQo=r(iTt,"megatron-bert"),iTt.forEach(t),CQo=r(ePe," \u2014 "),KX=n(ePe,"A",{href:!0});var dTt=s(KX);wQo=r(dTt,"MegatronBertForNextSentencePrediction"),dTt.forEach(t),AQo=r(ePe," (Megatron-BERT model)"),ePe.forEach(t),LQo=i(ga),p0=n(ga,"LI",{});var oPe=s(p0);Z_e=n(oPe,"STRONG",{});var cTt=s(Z_e);yQo=r(cTt,"mobilebert"),cTt.forEach(t),xQo=r(oPe," \u2014 "),ZX=n(oPe,"A",{href:!0});var fTt=s(ZX);$Qo=r(fTt,"MobileBertForNextSentencePrediction"),fTt.forEach(t),kQo=r(oPe," (MobileBERT model)"),oPe.forEach(t),SQo=i(ga),_0=n(ga,"LI",{});var rPe=s(_0);eue=n(rPe,"STRONG",{});var mTt=s(eue);RQo=r(mTt,"nezha"),mTt.forEach(t),PQo=r(rPe," \u2014 "),ez=n(rPe,"A",{href:!0});var gTt=s(ez);BQo=r(gTt,"NezhaForNextSentencePrediction"),gTt.forEach(t),IQo=r(rPe," (Nezha model)"),rPe.forEach(t),NQo=i(ga),u0=n(ga,"LI",{});var tPe=s(u0);oue=n(tPe,"STRONG",{});var hTt=s(oue);qQo=r(hTt,"qdqbert"),hTt.forEach(t),jQo=r(tPe," \u2014 "),oz=n(tPe,"A",{href:!0});var pTt=s(oz);DQo=r(pTt,"QDQBertForNextSentencePrediction"),pTt.forEach(t),GQo=r(tPe," (QDQBert model)"),tPe.forEach(t),ga.forEach(t),OQo=i(ma),b0=n(ma,"P",{});var aPe=s(b0);VQo=r(aPe,"The model is set in evaluation mode by default using "),rue=n(aPe,"CODE",{});var _Tt=s(rue);XQo=r(_Tt,"model.eval()"),_Tt.forEach(t),zQo=r(aPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tue=n(aPe,"CODE",{});var uTt=s(tue);WQo=r(uTt,"model.train()"),uTt.forEach(t),aPe.forEach(t),QQo=i(ma),T(v0.$$.fragment,ma),ma.forEach(t),il.forEach(t),pVe=i(f),dd=n(f,"H2",{class:!0});var Tze=s(dd);F0=n(Tze,"A",{id:!0,class:!0,href:!0});var bTt=s(F0);aue=n(bTt,"SPAN",{});var vTt=s(aue);T(ey.$$.fragment,vTt),vTt.forEach(t),bTt.forEach(t),HQo=i(Tze),nue=n(Tze,"SPAN",{});var FTt=s(nue);UQo=r(FTt,"AutoModelForTokenClassification"),FTt.forEach(t),Tze.forEach(t),_Ve=i(f),qo=n(f,"DIV",{class:!0});var dl=s(qo);T(oy.$$.fragment,dl),JQo=i(dl),cd=n(dl,"P",{});var gre=s(cd);YQo=r(gre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),rz=n(gre,"A",{href:!0});var TTt=s(rz);KQo=r(TTt,"from_pretrained()"),TTt.forEach(t),ZQo=r(gre," class method or the "),tz=n(gre,"A",{href:!0});var MTt=s(tz);eHo=r(MTt,"from_config()"),MTt.forEach(t),oHo=r(gre,` class
method.`),gre.forEach(t),rHo=i(dl),ry=n(dl,"P",{});var Mze=s(ry);tHo=r(Mze,"This class cannot be instantiated directly using "),sue=n(Mze,"CODE",{});var ETt=s(sue);aHo=r(ETt,"__init__()"),ETt.forEach(t),nHo=r(Mze," (throws an error)."),Mze.forEach(t),sHo=i(dl),ht=n(dl,"DIV",{class:!0});var lw=s(ht);T(ty.$$.fragment,lw),lHo=i(lw),lue=n(lw,"P",{});var CTt=s(lue);iHo=r(CTt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),CTt.forEach(t),dHo=i(lw),fd=n(lw,"P",{});var hre=s(fd);cHo=r(hre,`Note:
Loading a model from its configuration file does `),iue=n(hre,"STRONG",{});var wTt=s(iue);fHo=r(wTt,"not"),wTt.forEach(t),mHo=r(hre,` load the model weights. It only affects the
model\u2019s configuration. Use `),az=n(hre,"A",{href:!0});var ATt=s(az);gHo=r(ATt,"from_pretrained()"),ATt.forEach(t),hHo=r(hre," to load the model weights."),hre.forEach(t),pHo=i(lw),T(T0.$$.fragment,lw),lw.forEach(t),_Ho=i(dl),ao=n(dl,"DIV",{class:!0});var ha=s(ao);T(ay.$$.fragment,ha),uHo=i(ha),due=n(ha,"P",{});var LTt=s(due);bHo=r(LTt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),LTt.forEach(t),vHo=i(ha),Va=n(ha,"P",{});var iw=s(Va);FHo=r(iw,"The model class to instantiate is selected based on the "),cue=n(iw,"CODE",{});var yTt=s(cue);THo=r(yTt,"model_type"),yTt.forEach(t),MHo=r(iw,` property of the config object (either
passed as an argument or loaded from `),fue=n(iw,"CODE",{});var xTt=s(fue);EHo=r(xTt,"pretrained_model_name_or_path"),xTt.forEach(t),CHo=r(iw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mue=n(iw,"CODE",{});var $Tt=s(mue);wHo=r($Tt,"pretrained_model_name_or_path"),$Tt.forEach(t),AHo=r(iw,":"),iw.forEach(t),LHo=i(ha),H=n(ha,"UL",{});var J=s(H);M0=n(J,"LI",{});var nPe=s(M0);gue=n(nPe,"STRONG",{});var kTt=s(gue);yHo=r(kTt,"albert"),kTt.forEach(t),xHo=r(nPe," \u2014 "),nz=n(nPe,"A",{href:!0});var STt=s(nz);$Ho=r(STt,"AlbertForTokenClassification"),STt.forEach(t),kHo=r(nPe," (ALBERT model)"),nPe.forEach(t),SHo=i(J),E0=n(J,"LI",{});var sPe=s(E0);hue=n(sPe,"STRONG",{});var RTt=s(hue);RHo=r(RTt,"bert"),RTt.forEach(t),PHo=r(sPe," \u2014 "),sz=n(sPe,"A",{href:!0});var PTt=s(sz);BHo=r(PTt,"BertForTokenClassification"),PTt.forEach(t),IHo=r(sPe," (BERT model)"),sPe.forEach(t),NHo=i(J),C0=n(J,"LI",{});var lPe=s(C0);pue=n(lPe,"STRONG",{});var BTt=s(pue);qHo=r(BTt,"big_bird"),BTt.forEach(t),jHo=r(lPe," \u2014 "),lz=n(lPe,"A",{href:!0});var ITt=s(lz);DHo=r(ITt,"BigBirdForTokenClassification"),ITt.forEach(t),GHo=r(lPe," (BigBird model)"),lPe.forEach(t),OHo=i(J),w0=n(J,"LI",{});var iPe=s(w0);_ue=n(iPe,"STRONG",{});var NTt=s(_ue);VHo=r(NTt,"bloom"),NTt.forEach(t),XHo=r(iPe," \u2014 "),iz=n(iPe,"A",{href:!0});var qTt=s(iz);zHo=r(qTt,"BloomForTokenClassification"),qTt.forEach(t),WHo=r(iPe," (BLOOM model)"),iPe.forEach(t),QHo=i(J),A0=n(J,"LI",{});var dPe=s(A0);uue=n(dPe,"STRONG",{});var jTt=s(uue);HHo=r(jTt,"camembert"),jTt.forEach(t),UHo=r(dPe," \u2014 "),dz=n(dPe,"A",{href:!0});var DTt=s(dz);JHo=r(DTt,"CamembertForTokenClassification"),DTt.forEach(t),YHo=r(dPe," (CamemBERT model)"),dPe.forEach(t),KHo=i(J),L0=n(J,"LI",{});var cPe=s(L0);bue=n(cPe,"STRONG",{});var GTt=s(bue);ZHo=r(GTt,"canine"),GTt.forEach(t),eUo=r(cPe," \u2014 "),cz=n(cPe,"A",{href:!0});var OTt=s(cz);oUo=r(OTt,"CanineForTokenClassification"),OTt.forEach(t),rUo=r(cPe," (CANINE model)"),cPe.forEach(t),tUo=i(J),y0=n(J,"LI",{});var fPe=s(y0);vue=n(fPe,"STRONG",{});var VTt=s(vue);aUo=r(VTt,"convbert"),VTt.forEach(t),nUo=r(fPe," \u2014 "),fz=n(fPe,"A",{href:!0});var XTt=s(fz);sUo=r(XTt,"ConvBertForTokenClassification"),XTt.forEach(t),lUo=r(fPe," (ConvBERT model)"),fPe.forEach(t),iUo=i(J),x0=n(J,"LI",{});var mPe=s(x0);Fue=n(mPe,"STRONG",{});var zTt=s(Fue);dUo=r(zTt,"data2vec-text"),zTt.forEach(t),cUo=r(mPe," \u2014 "),mz=n(mPe,"A",{href:!0});var WTt=s(mz);fUo=r(WTt,"Data2VecTextForTokenClassification"),WTt.forEach(t),mUo=r(mPe," (Data2VecText model)"),mPe.forEach(t),gUo=i(J),$0=n(J,"LI",{});var gPe=s($0);Tue=n(gPe,"STRONG",{});var QTt=s(Tue);hUo=r(QTt,"deberta"),QTt.forEach(t),pUo=r(gPe," \u2014 "),gz=n(gPe,"A",{href:!0});var HTt=s(gz);_Uo=r(HTt,"DebertaForTokenClassification"),HTt.forEach(t),uUo=r(gPe," (DeBERTa model)"),gPe.forEach(t),bUo=i(J),k0=n(J,"LI",{});var hPe=s(k0);Mue=n(hPe,"STRONG",{});var UTt=s(Mue);vUo=r(UTt,"deberta-v2"),UTt.forEach(t),FUo=r(hPe," \u2014 "),hz=n(hPe,"A",{href:!0});var JTt=s(hz);TUo=r(JTt,"DebertaV2ForTokenClassification"),JTt.forEach(t),MUo=r(hPe," (DeBERTa-v2 model)"),hPe.forEach(t),EUo=i(J),S0=n(J,"LI",{});var pPe=s(S0);Eue=n(pPe,"STRONG",{});var YTt=s(Eue);CUo=r(YTt,"distilbert"),YTt.forEach(t),wUo=r(pPe," \u2014 "),pz=n(pPe,"A",{href:!0});var KTt=s(pz);AUo=r(KTt,"DistilBertForTokenClassification"),KTt.forEach(t),LUo=r(pPe," (DistilBERT model)"),pPe.forEach(t),yUo=i(J),R0=n(J,"LI",{});var _Pe=s(R0);Cue=n(_Pe,"STRONG",{});var ZTt=s(Cue);xUo=r(ZTt,"electra"),ZTt.forEach(t),$Uo=r(_Pe," \u2014 "),_z=n(_Pe,"A",{href:!0});var e7t=s(_z);kUo=r(e7t,"ElectraForTokenClassification"),e7t.forEach(t),SUo=r(_Pe," (ELECTRA model)"),_Pe.forEach(t),RUo=i(J),P0=n(J,"LI",{});var uPe=s(P0);wue=n(uPe,"STRONG",{});var o7t=s(wue);PUo=r(o7t,"flaubert"),o7t.forEach(t),BUo=r(uPe," \u2014 "),uz=n(uPe,"A",{href:!0});var r7t=s(uz);IUo=r(r7t,"FlaubertForTokenClassification"),r7t.forEach(t),NUo=r(uPe," (FlauBERT model)"),uPe.forEach(t),qUo=i(J),B0=n(J,"LI",{});var bPe=s(B0);Aue=n(bPe,"STRONG",{});var t7t=s(Aue);jUo=r(t7t,"fnet"),t7t.forEach(t),DUo=r(bPe," \u2014 "),bz=n(bPe,"A",{href:!0});var a7t=s(bz);GUo=r(a7t,"FNetForTokenClassification"),a7t.forEach(t),OUo=r(bPe," (FNet model)"),bPe.forEach(t),VUo=i(J),I0=n(J,"LI",{});var vPe=s(I0);Lue=n(vPe,"STRONG",{});var n7t=s(Lue);XUo=r(n7t,"funnel"),n7t.forEach(t),zUo=r(vPe," \u2014 "),vz=n(vPe,"A",{href:!0});var s7t=s(vz);WUo=r(s7t,"FunnelForTokenClassification"),s7t.forEach(t),QUo=r(vPe," (Funnel Transformer model)"),vPe.forEach(t),HUo=i(J),N0=n(J,"LI",{});var FPe=s(N0);yue=n(FPe,"STRONG",{});var l7t=s(yue);UUo=r(l7t,"gpt2"),l7t.forEach(t),JUo=r(FPe," \u2014 "),Fz=n(FPe,"A",{href:!0});var i7t=s(Fz);YUo=r(i7t,"GPT2ForTokenClassification"),i7t.forEach(t),KUo=r(FPe," (OpenAI GPT-2 model)"),FPe.forEach(t),ZUo=i(J),q0=n(J,"LI",{});var TPe=s(q0);xue=n(TPe,"STRONG",{});var d7t=s(xue);eJo=r(d7t,"ibert"),d7t.forEach(t),oJo=r(TPe," \u2014 "),Tz=n(TPe,"A",{href:!0});var c7t=s(Tz);rJo=r(c7t,"IBertForTokenClassification"),c7t.forEach(t),tJo=r(TPe," (I-BERT model)"),TPe.forEach(t),aJo=i(J),j0=n(J,"LI",{});var MPe=s(j0);$ue=n(MPe,"STRONG",{});var f7t=s($ue);nJo=r(f7t,"layoutlm"),f7t.forEach(t),sJo=r(MPe," \u2014 "),Mz=n(MPe,"A",{href:!0});var m7t=s(Mz);lJo=r(m7t,"LayoutLMForTokenClassification"),m7t.forEach(t),iJo=r(MPe," (LayoutLM model)"),MPe.forEach(t),dJo=i(J),D0=n(J,"LI",{});var EPe=s(D0);kue=n(EPe,"STRONG",{});var g7t=s(kue);cJo=r(g7t,"layoutlmv2"),g7t.forEach(t),fJo=r(EPe," \u2014 "),Ez=n(EPe,"A",{href:!0});var h7t=s(Ez);mJo=r(h7t,"LayoutLMv2ForTokenClassification"),h7t.forEach(t),gJo=r(EPe," (LayoutLMv2 model)"),EPe.forEach(t),hJo=i(J),G0=n(J,"LI",{});var CPe=s(G0);Sue=n(CPe,"STRONG",{});var p7t=s(Sue);pJo=r(p7t,"layoutlmv3"),p7t.forEach(t),_Jo=r(CPe," \u2014 "),Cz=n(CPe,"A",{href:!0});var _7t=s(Cz);uJo=r(_7t,"LayoutLMv3ForTokenClassification"),_7t.forEach(t),bJo=r(CPe," (LayoutLMv3 model)"),CPe.forEach(t),vJo=i(J),O0=n(J,"LI",{});var wPe=s(O0);Rue=n(wPe,"STRONG",{});var u7t=s(Rue);FJo=r(u7t,"longformer"),u7t.forEach(t),TJo=r(wPe," \u2014 "),wz=n(wPe,"A",{href:!0});var b7t=s(wz);MJo=r(b7t,"LongformerForTokenClassification"),b7t.forEach(t),EJo=r(wPe," (Longformer model)"),wPe.forEach(t),CJo=i(J),V0=n(J,"LI",{});var APe=s(V0);Pue=n(APe,"STRONG",{});var v7t=s(Pue);wJo=r(v7t,"megatron-bert"),v7t.forEach(t),AJo=r(APe," \u2014 "),Az=n(APe,"A",{href:!0});var F7t=s(Az);LJo=r(F7t,"MegatronBertForTokenClassification"),F7t.forEach(t),yJo=r(APe," (Megatron-BERT model)"),APe.forEach(t),xJo=i(J),X0=n(J,"LI",{});var LPe=s(X0);Bue=n(LPe,"STRONG",{});var T7t=s(Bue);$Jo=r(T7t,"mobilebert"),T7t.forEach(t),kJo=r(LPe," \u2014 "),Lz=n(LPe,"A",{href:!0});var M7t=s(Lz);SJo=r(M7t,"MobileBertForTokenClassification"),M7t.forEach(t),RJo=r(LPe," (MobileBERT model)"),LPe.forEach(t),PJo=i(J),z0=n(J,"LI",{});var yPe=s(z0);Iue=n(yPe,"STRONG",{});var E7t=s(Iue);BJo=r(E7t,"mpnet"),E7t.forEach(t),IJo=r(yPe," \u2014 "),yz=n(yPe,"A",{href:!0});var C7t=s(yz);NJo=r(C7t,"MPNetForTokenClassification"),C7t.forEach(t),qJo=r(yPe," (MPNet model)"),yPe.forEach(t),jJo=i(J),W0=n(J,"LI",{});var xPe=s(W0);Nue=n(xPe,"STRONG",{});var w7t=s(Nue);DJo=r(w7t,"nezha"),w7t.forEach(t),GJo=r(xPe," \u2014 "),xz=n(xPe,"A",{href:!0});var A7t=s(xz);OJo=r(A7t,"NezhaForTokenClassification"),A7t.forEach(t),VJo=r(xPe," (Nezha model)"),xPe.forEach(t),XJo=i(J),Q0=n(J,"LI",{});var $Pe=s(Q0);que=n($Pe,"STRONG",{});var L7t=s(que);zJo=r(L7t,"nystromformer"),L7t.forEach(t),WJo=r($Pe," \u2014 "),$z=n($Pe,"A",{href:!0});var y7t=s($z);QJo=r(y7t,"NystromformerForTokenClassification"),y7t.forEach(t),HJo=r($Pe," (Nystr\xF6mformer model)"),$Pe.forEach(t),UJo=i(J),H0=n(J,"LI",{});var kPe=s(H0);jue=n(kPe,"STRONG",{});var x7t=s(jue);JJo=r(x7t,"qdqbert"),x7t.forEach(t),YJo=r(kPe," \u2014 "),kz=n(kPe,"A",{href:!0});var $7t=s(kz);KJo=r($7t,"QDQBertForTokenClassification"),$7t.forEach(t),ZJo=r(kPe," (QDQBert model)"),kPe.forEach(t),eYo=i(J),U0=n(J,"LI",{});var SPe=s(U0);Due=n(SPe,"STRONG",{});var k7t=s(Due);oYo=r(k7t,"rembert"),k7t.forEach(t),rYo=r(SPe," \u2014 "),Sz=n(SPe,"A",{href:!0});var S7t=s(Sz);tYo=r(S7t,"RemBertForTokenClassification"),S7t.forEach(t),aYo=r(SPe," (RemBERT model)"),SPe.forEach(t),nYo=i(J),J0=n(J,"LI",{});var RPe=s(J0);Gue=n(RPe,"STRONG",{});var R7t=s(Gue);sYo=r(R7t,"roberta"),R7t.forEach(t),lYo=r(RPe," \u2014 "),Rz=n(RPe,"A",{href:!0});var P7t=s(Rz);iYo=r(P7t,"RobertaForTokenClassification"),P7t.forEach(t),dYo=r(RPe," (RoBERTa model)"),RPe.forEach(t),cYo=i(J),Y0=n(J,"LI",{});var PPe=s(Y0);Oue=n(PPe,"STRONG",{});var B7t=s(Oue);fYo=r(B7t,"roformer"),B7t.forEach(t),mYo=r(PPe," \u2014 "),Pz=n(PPe,"A",{href:!0});var I7t=s(Pz);gYo=r(I7t,"RoFormerForTokenClassification"),I7t.forEach(t),hYo=r(PPe," (RoFormer model)"),PPe.forEach(t),pYo=i(J),K0=n(J,"LI",{});var BPe=s(K0);Vue=n(BPe,"STRONG",{});var N7t=s(Vue);_Yo=r(N7t,"squeezebert"),N7t.forEach(t),uYo=r(BPe," \u2014 "),Bz=n(BPe,"A",{href:!0});var q7t=s(Bz);bYo=r(q7t,"SqueezeBertForTokenClassification"),q7t.forEach(t),vYo=r(BPe," (SqueezeBERT model)"),BPe.forEach(t),FYo=i(J),Z0=n(J,"LI",{});var IPe=s(Z0);Xue=n(IPe,"STRONG",{});var j7t=s(Xue);TYo=r(j7t,"xlm"),j7t.forEach(t),MYo=r(IPe," \u2014 "),Iz=n(IPe,"A",{href:!0});var D7t=s(Iz);EYo=r(D7t,"XLMForTokenClassification"),D7t.forEach(t),CYo=r(IPe," (XLM model)"),IPe.forEach(t),wYo=i(J),eF=n(J,"LI",{});var NPe=s(eF);zue=n(NPe,"STRONG",{});var G7t=s(zue);AYo=r(G7t,"xlm-roberta"),G7t.forEach(t),LYo=r(NPe," \u2014 "),Nz=n(NPe,"A",{href:!0});var O7t=s(Nz);yYo=r(O7t,"XLMRobertaForTokenClassification"),O7t.forEach(t),xYo=r(NPe," (XLM-RoBERTa model)"),NPe.forEach(t),$Yo=i(J),oF=n(J,"LI",{});var qPe=s(oF);Wue=n(qPe,"STRONG",{});var V7t=s(Wue);kYo=r(V7t,"xlm-roberta-xl"),V7t.forEach(t),SYo=r(qPe," \u2014 "),qz=n(qPe,"A",{href:!0});var X7t=s(qz);RYo=r(X7t,"XLMRobertaXLForTokenClassification"),X7t.forEach(t),PYo=r(qPe," (XLM-RoBERTa-XL model)"),qPe.forEach(t),BYo=i(J),rF=n(J,"LI",{});var jPe=s(rF);Que=n(jPe,"STRONG",{});var z7t=s(Que);IYo=r(z7t,"xlnet"),z7t.forEach(t),NYo=r(jPe," \u2014 "),jz=n(jPe,"A",{href:!0});var W7t=s(jz);qYo=r(W7t,"XLNetForTokenClassification"),W7t.forEach(t),jYo=r(jPe," (XLNet model)"),jPe.forEach(t),DYo=i(J),tF=n(J,"LI",{});var DPe=s(tF);Hue=n(DPe,"STRONG",{});var Q7t=s(Hue);GYo=r(Q7t,"yoso"),Q7t.forEach(t),OYo=r(DPe," \u2014 "),Dz=n(DPe,"A",{href:!0});var H7t=s(Dz);VYo=r(H7t,"YosoForTokenClassification"),H7t.forEach(t),XYo=r(DPe," (YOSO model)"),DPe.forEach(t),J.forEach(t),zYo=i(ha),aF=n(ha,"P",{});var GPe=s(aF);WYo=r(GPe,"The model is set in evaluation mode by default using "),Uue=n(GPe,"CODE",{});var U7t=s(Uue);QYo=r(U7t,"model.eval()"),U7t.forEach(t),HYo=r(GPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jue=n(GPe,"CODE",{});var J7t=s(Jue);UYo=r(J7t,"model.train()"),J7t.forEach(t),GPe.forEach(t),JYo=i(ha),T(nF.$$.fragment,ha),ha.forEach(t),dl.forEach(t),uVe=i(f),md=n(f,"H2",{class:!0});var Eze=s(md);sF=n(Eze,"A",{id:!0,class:!0,href:!0});var Y7t=s(sF);Yue=n(Y7t,"SPAN",{});var K7t=s(Yue);T(ny.$$.fragment,K7t),K7t.forEach(t),Y7t.forEach(t),YYo=i(Eze),Kue=n(Eze,"SPAN",{});var Z7t=s(Kue);KYo=r(Z7t,"AutoModelForQuestionAnswering"),Z7t.forEach(t),Eze.forEach(t),bVe=i(f),jo=n(f,"DIV",{class:!0});var cl=s(jo);T(sy.$$.fragment,cl),ZYo=i(cl),gd=n(cl,"P",{});var pre=s(gd);eKo=r(pre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Gz=n(pre,"A",{href:!0});var e8t=s(Gz);oKo=r(e8t,"from_pretrained()"),e8t.forEach(t),rKo=r(pre," class method or the "),Oz=n(pre,"A",{href:!0});var o8t=s(Oz);tKo=r(o8t,"from_config()"),o8t.forEach(t),aKo=r(pre,` class
method.`),pre.forEach(t),nKo=i(cl),ly=n(cl,"P",{});var Cze=s(ly);sKo=r(Cze,"This class cannot be instantiated directly using "),Zue=n(Cze,"CODE",{});var r8t=s(Zue);lKo=r(r8t,"__init__()"),r8t.forEach(t),iKo=r(Cze," (throws an error)."),Cze.forEach(t),dKo=i(cl),pt=n(cl,"DIV",{class:!0});var dw=s(pt);T(iy.$$.fragment,dw),cKo=i(dw),e1e=n(dw,"P",{});var t8t=s(e1e);fKo=r(t8t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),t8t.forEach(t),mKo=i(dw),hd=n(dw,"P",{});var _re=s(hd);gKo=r(_re,`Note:
Loading a model from its configuration file does `),o1e=n(_re,"STRONG",{});var a8t=s(o1e);hKo=r(a8t,"not"),a8t.forEach(t),pKo=r(_re,` load the model weights. It only affects the
model\u2019s configuration. Use `),Vz=n(_re,"A",{href:!0});var n8t=s(Vz);_Ko=r(n8t,"from_pretrained()"),n8t.forEach(t),uKo=r(_re," to load the model weights."),_re.forEach(t),bKo=i(dw),T(lF.$$.fragment,dw),dw.forEach(t),vKo=i(cl),no=n(cl,"DIV",{class:!0});var pa=s(no);T(dy.$$.fragment,pa),FKo=i(pa),r1e=n(pa,"P",{});var s8t=s(r1e);TKo=r(s8t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),s8t.forEach(t),MKo=i(pa),Xa=n(pa,"P",{});var cw=s(Xa);EKo=r(cw,"The model class to instantiate is selected based on the "),t1e=n(cw,"CODE",{});var l8t=s(t1e);CKo=r(l8t,"model_type"),l8t.forEach(t),wKo=r(cw,` property of the config object (either
passed as an argument or loaded from `),a1e=n(cw,"CODE",{});var i8t=s(a1e);AKo=r(i8t,"pretrained_model_name_or_path"),i8t.forEach(t),LKo=r(cw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n1e=n(cw,"CODE",{});var d8t=s(n1e);yKo=r(d8t,"pretrained_model_name_or_path"),d8t.forEach(t),xKo=r(cw,":"),cw.forEach(t),$Ko=i(pa),V=n(pa,"UL",{});var X=s(V);iF=n(X,"LI",{});var OPe=s(iF);s1e=n(OPe,"STRONG",{});var c8t=s(s1e);kKo=r(c8t,"albert"),c8t.forEach(t),SKo=r(OPe," \u2014 "),Xz=n(OPe,"A",{href:!0});var f8t=s(Xz);RKo=r(f8t,"AlbertForQuestionAnswering"),f8t.forEach(t),PKo=r(OPe," (ALBERT model)"),OPe.forEach(t),BKo=i(X),dF=n(X,"LI",{});var VPe=s(dF);l1e=n(VPe,"STRONG",{});var m8t=s(l1e);IKo=r(m8t,"bart"),m8t.forEach(t),NKo=r(VPe," \u2014 "),zz=n(VPe,"A",{href:!0});var g8t=s(zz);qKo=r(g8t,"BartForQuestionAnswering"),g8t.forEach(t),jKo=r(VPe," (BART model)"),VPe.forEach(t),DKo=i(X),cF=n(X,"LI",{});var XPe=s(cF);i1e=n(XPe,"STRONG",{});var h8t=s(i1e);GKo=r(h8t,"bert"),h8t.forEach(t),OKo=r(XPe," \u2014 "),Wz=n(XPe,"A",{href:!0});var p8t=s(Wz);VKo=r(p8t,"BertForQuestionAnswering"),p8t.forEach(t),XKo=r(XPe," (BERT model)"),XPe.forEach(t),zKo=i(X),fF=n(X,"LI",{});var zPe=s(fF);d1e=n(zPe,"STRONG",{});var _8t=s(d1e);WKo=r(_8t,"big_bird"),_8t.forEach(t),QKo=r(zPe," \u2014 "),Qz=n(zPe,"A",{href:!0});var u8t=s(Qz);HKo=r(u8t,"BigBirdForQuestionAnswering"),u8t.forEach(t),UKo=r(zPe," (BigBird model)"),zPe.forEach(t),JKo=i(X),mF=n(X,"LI",{});var WPe=s(mF);c1e=n(WPe,"STRONG",{});var b8t=s(c1e);YKo=r(b8t,"bigbird_pegasus"),b8t.forEach(t),KKo=r(WPe," \u2014 "),Hz=n(WPe,"A",{href:!0});var v8t=s(Hz);ZKo=r(v8t,"BigBirdPegasusForQuestionAnswering"),v8t.forEach(t),eZo=r(WPe," (BigBird-Pegasus model)"),WPe.forEach(t),oZo=i(X),gF=n(X,"LI",{});var QPe=s(gF);f1e=n(QPe,"STRONG",{});var F8t=s(f1e);rZo=r(F8t,"camembert"),F8t.forEach(t),tZo=r(QPe," \u2014 "),Uz=n(QPe,"A",{href:!0});var T8t=s(Uz);aZo=r(T8t,"CamembertForQuestionAnswering"),T8t.forEach(t),nZo=r(QPe," (CamemBERT model)"),QPe.forEach(t),sZo=i(X),hF=n(X,"LI",{});var HPe=s(hF);m1e=n(HPe,"STRONG",{});var M8t=s(m1e);lZo=r(M8t,"canine"),M8t.forEach(t),iZo=r(HPe," \u2014 "),Jz=n(HPe,"A",{href:!0});var E8t=s(Jz);dZo=r(E8t,"CanineForQuestionAnswering"),E8t.forEach(t),cZo=r(HPe," (CANINE model)"),HPe.forEach(t),fZo=i(X),pF=n(X,"LI",{});var UPe=s(pF);g1e=n(UPe,"STRONG",{});var C8t=s(g1e);mZo=r(C8t,"convbert"),C8t.forEach(t),gZo=r(UPe," \u2014 "),Yz=n(UPe,"A",{href:!0});var w8t=s(Yz);hZo=r(w8t,"ConvBertForQuestionAnswering"),w8t.forEach(t),pZo=r(UPe," (ConvBERT model)"),UPe.forEach(t),_Zo=i(X),_F=n(X,"LI",{});var JPe=s(_F);h1e=n(JPe,"STRONG",{});var A8t=s(h1e);uZo=r(A8t,"data2vec-text"),A8t.forEach(t),bZo=r(JPe," \u2014 "),Kz=n(JPe,"A",{href:!0});var L8t=s(Kz);vZo=r(L8t,"Data2VecTextForQuestionAnswering"),L8t.forEach(t),FZo=r(JPe," (Data2VecText model)"),JPe.forEach(t),TZo=i(X),uF=n(X,"LI",{});var YPe=s(uF);p1e=n(YPe,"STRONG",{});var y8t=s(p1e);MZo=r(y8t,"deberta"),y8t.forEach(t),EZo=r(YPe," \u2014 "),Zz=n(YPe,"A",{href:!0});var x8t=s(Zz);CZo=r(x8t,"DebertaForQuestionAnswering"),x8t.forEach(t),wZo=r(YPe," (DeBERTa model)"),YPe.forEach(t),AZo=i(X),bF=n(X,"LI",{});var KPe=s(bF);_1e=n(KPe,"STRONG",{});var $8t=s(_1e);LZo=r($8t,"deberta-v2"),$8t.forEach(t),yZo=r(KPe," \u2014 "),eW=n(KPe,"A",{href:!0});var k8t=s(eW);xZo=r(k8t,"DebertaV2ForQuestionAnswering"),k8t.forEach(t),$Zo=r(KPe," (DeBERTa-v2 model)"),KPe.forEach(t),kZo=i(X),vF=n(X,"LI",{});var ZPe=s(vF);u1e=n(ZPe,"STRONG",{});var S8t=s(u1e);SZo=r(S8t,"distilbert"),S8t.forEach(t),RZo=r(ZPe," \u2014 "),oW=n(ZPe,"A",{href:!0});var R8t=s(oW);PZo=r(R8t,"DistilBertForQuestionAnswering"),R8t.forEach(t),BZo=r(ZPe," (DistilBERT model)"),ZPe.forEach(t),IZo=i(X),FF=n(X,"LI",{});var eBe=s(FF);b1e=n(eBe,"STRONG",{});var P8t=s(b1e);NZo=r(P8t,"electra"),P8t.forEach(t),qZo=r(eBe," \u2014 "),rW=n(eBe,"A",{href:!0});var B8t=s(rW);jZo=r(B8t,"ElectraForQuestionAnswering"),B8t.forEach(t),DZo=r(eBe," (ELECTRA model)"),eBe.forEach(t),GZo=i(X),TF=n(X,"LI",{});var oBe=s(TF);v1e=n(oBe,"STRONG",{});var I8t=s(v1e);OZo=r(I8t,"flaubert"),I8t.forEach(t),VZo=r(oBe," \u2014 "),tW=n(oBe,"A",{href:!0});var N8t=s(tW);XZo=r(N8t,"FlaubertForQuestionAnsweringSimple"),N8t.forEach(t),zZo=r(oBe," (FlauBERT model)"),oBe.forEach(t),WZo=i(X),MF=n(X,"LI",{});var rBe=s(MF);F1e=n(rBe,"STRONG",{});var q8t=s(F1e);QZo=r(q8t,"fnet"),q8t.forEach(t),HZo=r(rBe," \u2014 "),aW=n(rBe,"A",{href:!0});var j8t=s(aW);UZo=r(j8t,"FNetForQuestionAnswering"),j8t.forEach(t),JZo=r(rBe," (FNet model)"),rBe.forEach(t),YZo=i(X),EF=n(X,"LI",{});var tBe=s(EF);T1e=n(tBe,"STRONG",{});var D8t=s(T1e);KZo=r(D8t,"funnel"),D8t.forEach(t),ZZo=r(tBe," \u2014 "),nW=n(tBe,"A",{href:!0});var G8t=s(nW);eer=r(G8t,"FunnelForQuestionAnswering"),G8t.forEach(t),oer=r(tBe," (Funnel Transformer model)"),tBe.forEach(t),rer=i(X),CF=n(X,"LI",{});var aBe=s(CF);M1e=n(aBe,"STRONG",{});var O8t=s(M1e);ter=r(O8t,"gptj"),O8t.forEach(t),aer=r(aBe," \u2014 "),sW=n(aBe,"A",{href:!0});var V8t=s(sW);ner=r(V8t,"GPTJForQuestionAnswering"),V8t.forEach(t),ser=r(aBe," (GPT-J model)"),aBe.forEach(t),ler=i(X),wF=n(X,"LI",{});var nBe=s(wF);E1e=n(nBe,"STRONG",{});var X8t=s(E1e);ier=r(X8t,"ibert"),X8t.forEach(t),der=r(nBe," \u2014 "),lW=n(nBe,"A",{href:!0});var z8t=s(lW);cer=r(z8t,"IBertForQuestionAnswering"),z8t.forEach(t),fer=r(nBe," (I-BERT model)"),nBe.forEach(t),mer=i(X),AF=n(X,"LI",{});var sBe=s(AF);C1e=n(sBe,"STRONG",{});var W8t=s(C1e);ger=r(W8t,"layoutlmv2"),W8t.forEach(t),her=r(sBe," \u2014 "),iW=n(sBe,"A",{href:!0});var Q8t=s(iW);per=r(Q8t,"LayoutLMv2ForQuestionAnswering"),Q8t.forEach(t),_er=r(sBe," (LayoutLMv2 model)"),sBe.forEach(t),uer=i(X),LF=n(X,"LI",{});var lBe=s(LF);w1e=n(lBe,"STRONG",{});var H8t=s(w1e);ber=r(H8t,"layoutlmv3"),H8t.forEach(t),ver=r(lBe," \u2014 "),dW=n(lBe,"A",{href:!0});var U8t=s(dW);Fer=r(U8t,"LayoutLMv3ForQuestionAnswering"),U8t.forEach(t),Ter=r(lBe," (LayoutLMv3 model)"),lBe.forEach(t),Mer=i(X),yF=n(X,"LI",{});var iBe=s(yF);A1e=n(iBe,"STRONG",{});var J8t=s(A1e);Eer=r(J8t,"led"),J8t.forEach(t),Cer=r(iBe," \u2014 "),cW=n(iBe,"A",{href:!0});var Y8t=s(cW);wer=r(Y8t,"LEDForQuestionAnswering"),Y8t.forEach(t),Aer=r(iBe," (LED model)"),iBe.forEach(t),Ler=i(X),xF=n(X,"LI",{});var dBe=s(xF);L1e=n(dBe,"STRONG",{});var K8t=s(L1e);yer=r(K8t,"longformer"),K8t.forEach(t),xer=r(dBe," \u2014 "),fW=n(dBe,"A",{href:!0});var Z8t=s(fW);$er=r(Z8t,"LongformerForQuestionAnswering"),Z8t.forEach(t),ker=r(dBe," (Longformer model)"),dBe.forEach(t),Ser=i(X),$F=n(X,"LI",{});var cBe=s($F);y1e=n(cBe,"STRONG",{});var eMt=s(y1e);Rer=r(eMt,"lxmert"),eMt.forEach(t),Per=r(cBe," \u2014 "),mW=n(cBe,"A",{href:!0});var oMt=s(mW);Ber=r(oMt,"LxmertForQuestionAnswering"),oMt.forEach(t),Ier=r(cBe," (LXMERT model)"),cBe.forEach(t),Ner=i(X),kF=n(X,"LI",{});var fBe=s(kF);x1e=n(fBe,"STRONG",{});var rMt=s(x1e);qer=r(rMt,"mbart"),rMt.forEach(t),jer=r(fBe," \u2014 "),gW=n(fBe,"A",{href:!0});var tMt=s(gW);Der=r(tMt,"MBartForQuestionAnswering"),tMt.forEach(t),Ger=r(fBe," (mBART model)"),fBe.forEach(t),Oer=i(X),SF=n(X,"LI",{});var mBe=s(SF);$1e=n(mBe,"STRONG",{});var aMt=s($1e);Ver=r(aMt,"megatron-bert"),aMt.forEach(t),Xer=r(mBe," \u2014 "),hW=n(mBe,"A",{href:!0});var nMt=s(hW);zer=r(nMt,"MegatronBertForQuestionAnswering"),nMt.forEach(t),Wer=r(mBe," (Megatron-BERT model)"),mBe.forEach(t),Qer=i(X),RF=n(X,"LI",{});var gBe=s(RF);k1e=n(gBe,"STRONG",{});var sMt=s(k1e);Her=r(sMt,"mobilebert"),sMt.forEach(t),Uer=r(gBe," \u2014 "),pW=n(gBe,"A",{href:!0});var lMt=s(pW);Jer=r(lMt,"MobileBertForQuestionAnswering"),lMt.forEach(t),Yer=r(gBe," (MobileBERT model)"),gBe.forEach(t),Ker=i(X),PF=n(X,"LI",{});var hBe=s(PF);S1e=n(hBe,"STRONG",{});var iMt=s(S1e);Zer=r(iMt,"mpnet"),iMt.forEach(t),eor=r(hBe," \u2014 "),_W=n(hBe,"A",{href:!0});var dMt=s(_W);oor=r(dMt,"MPNetForQuestionAnswering"),dMt.forEach(t),ror=r(hBe," (MPNet model)"),hBe.forEach(t),tor=i(X),BF=n(X,"LI",{});var pBe=s(BF);R1e=n(pBe,"STRONG",{});var cMt=s(R1e);aor=r(cMt,"nezha"),cMt.forEach(t),nor=r(pBe," \u2014 "),uW=n(pBe,"A",{href:!0});var fMt=s(uW);sor=r(fMt,"NezhaForQuestionAnswering"),fMt.forEach(t),lor=r(pBe," (Nezha model)"),pBe.forEach(t),ior=i(X),IF=n(X,"LI",{});var _Be=s(IF);P1e=n(_Be,"STRONG",{});var mMt=s(P1e);dor=r(mMt,"nystromformer"),mMt.forEach(t),cor=r(_Be," \u2014 "),bW=n(_Be,"A",{href:!0});var gMt=s(bW);mor=r(gMt,"NystromformerForQuestionAnswering"),gMt.forEach(t),gor=r(_Be," (Nystr\xF6mformer model)"),_Be.forEach(t),hor=i(X),NF=n(X,"LI",{});var uBe=s(NF);B1e=n(uBe,"STRONG",{});var hMt=s(B1e);por=r(hMt,"qdqbert"),hMt.forEach(t),_or=r(uBe," \u2014 "),vW=n(uBe,"A",{href:!0});var pMt=s(vW);uor=r(pMt,"QDQBertForQuestionAnswering"),pMt.forEach(t),bor=r(uBe," (QDQBert model)"),uBe.forEach(t),vor=i(X),qF=n(X,"LI",{});var bBe=s(qF);I1e=n(bBe,"STRONG",{});var _Mt=s(I1e);For=r(_Mt,"reformer"),_Mt.forEach(t),Tor=r(bBe," \u2014 "),FW=n(bBe,"A",{href:!0});var uMt=s(FW);Mor=r(uMt,"ReformerForQuestionAnswering"),uMt.forEach(t),Eor=r(bBe," (Reformer model)"),bBe.forEach(t),Cor=i(X),jF=n(X,"LI",{});var vBe=s(jF);N1e=n(vBe,"STRONG",{});var bMt=s(N1e);wor=r(bMt,"rembert"),bMt.forEach(t),Aor=r(vBe," \u2014 "),TW=n(vBe,"A",{href:!0});var vMt=s(TW);Lor=r(vMt,"RemBertForQuestionAnswering"),vMt.forEach(t),yor=r(vBe," (RemBERT model)"),vBe.forEach(t),xor=i(X),DF=n(X,"LI",{});var FBe=s(DF);q1e=n(FBe,"STRONG",{});var FMt=s(q1e);$or=r(FMt,"roberta"),FMt.forEach(t),kor=r(FBe," \u2014 "),MW=n(FBe,"A",{href:!0});var TMt=s(MW);Sor=r(TMt,"RobertaForQuestionAnswering"),TMt.forEach(t),Ror=r(FBe," (RoBERTa model)"),FBe.forEach(t),Por=i(X),GF=n(X,"LI",{});var TBe=s(GF);j1e=n(TBe,"STRONG",{});var MMt=s(j1e);Bor=r(MMt,"roformer"),MMt.forEach(t),Ior=r(TBe," \u2014 "),EW=n(TBe,"A",{href:!0});var EMt=s(EW);Nor=r(EMt,"RoFormerForQuestionAnswering"),EMt.forEach(t),qor=r(TBe," (RoFormer model)"),TBe.forEach(t),jor=i(X),OF=n(X,"LI",{});var MBe=s(OF);D1e=n(MBe,"STRONG",{});var CMt=s(D1e);Dor=r(CMt,"splinter"),CMt.forEach(t),Gor=r(MBe," \u2014 "),CW=n(MBe,"A",{href:!0});var wMt=s(CW);Oor=r(wMt,"SplinterForQuestionAnswering"),wMt.forEach(t),Vor=r(MBe," (Splinter model)"),MBe.forEach(t),Xor=i(X),VF=n(X,"LI",{});var EBe=s(VF);G1e=n(EBe,"STRONG",{});var AMt=s(G1e);zor=r(AMt,"squeezebert"),AMt.forEach(t),Wor=r(EBe," \u2014 "),wW=n(EBe,"A",{href:!0});var LMt=s(wW);Qor=r(LMt,"SqueezeBertForQuestionAnswering"),LMt.forEach(t),Hor=r(EBe," (SqueezeBERT model)"),EBe.forEach(t),Uor=i(X),XF=n(X,"LI",{});var CBe=s(XF);O1e=n(CBe,"STRONG",{});var yMt=s(O1e);Jor=r(yMt,"xlm"),yMt.forEach(t),Yor=r(CBe," \u2014 "),AW=n(CBe,"A",{href:!0});var xMt=s(AW);Kor=r(xMt,"XLMForQuestionAnsweringSimple"),xMt.forEach(t),Zor=r(CBe," (XLM model)"),CBe.forEach(t),err=i(X),zF=n(X,"LI",{});var wBe=s(zF);V1e=n(wBe,"STRONG",{});var $Mt=s(V1e);orr=r($Mt,"xlm-roberta"),$Mt.forEach(t),rrr=r(wBe," \u2014 "),LW=n(wBe,"A",{href:!0});var kMt=s(LW);trr=r(kMt,"XLMRobertaForQuestionAnswering"),kMt.forEach(t),arr=r(wBe," (XLM-RoBERTa model)"),wBe.forEach(t),nrr=i(X),WF=n(X,"LI",{});var ABe=s(WF);X1e=n(ABe,"STRONG",{});var SMt=s(X1e);srr=r(SMt,"xlm-roberta-xl"),SMt.forEach(t),lrr=r(ABe," \u2014 "),yW=n(ABe,"A",{href:!0});var RMt=s(yW);irr=r(RMt,"XLMRobertaXLForQuestionAnswering"),RMt.forEach(t),drr=r(ABe," (XLM-RoBERTa-XL model)"),ABe.forEach(t),crr=i(X),QF=n(X,"LI",{});var LBe=s(QF);z1e=n(LBe,"STRONG",{});var PMt=s(z1e);frr=r(PMt,"xlnet"),PMt.forEach(t),mrr=r(LBe," \u2014 "),xW=n(LBe,"A",{href:!0});var BMt=s(xW);grr=r(BMt,"XLNetForQuestionAnsweringSimple"),BMt.forEach(t),hrr=r(LBe," (XLNet model)"),LBe.forEach(t),prr=i(X),HF=n(X,"LI",{});var yBe=s(HF);W1e=n(yBe,"STRONG",{});var IMt=s(W1e);_rr=r(IMt,"yoso"),IMt.forEach(t),urr=r(yBe," \u2014 "),$W=n(yBe,"A",{href:!0});var NMt=s($W);brr=r(NMt,"YosoForQuestionAnswering"),NMt.forEach(t),vrr=r(yBe," (YOSO model)"),yBe.forEach(t),X.forEach(t),Frr=i(pa),UF=n(pa,"P",{});var xBe=s(UF);Trr=r(xBe,"The model is set in evaluation mode by default using "),Q1e=n(xBe,"CODE",{});var qMt=s(Q1e);Mrr=r(qMt,"model.eval()"),qMt.forEach(t),Err=r(xBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),H1e=n(xBe,"CODE",{});var jMt=s(H1e);Crr=r(jMt,"model.train()"),jMt.forEach(t),xBe.forEach(t),wrr=i(pa),T(JF.$$.fragment,pa),pa.forEach(t),cl.forEach(t),vVe=i(f),pd=n(f,"H2",{class:!0});var wze=s(pd);YF=n(wze,"A",{id:!0,class:!0,href:!0});var DMt=s(YF);U1e=n(DMt,"SPAN",{});var GMt=s(U1e);T(cy.$$.fragment,GMt),GMt.forEach(t),DMt.forEach(t),Arr=i(wze),J1e=n(wze,"SPAN",{});var OMt=s(J1e);Lrr=r(OMt,"AutoModelForTableQuestionAnswering"),OMt.forEach(t),wze.forEach(t),FVe=i(f),Do=n(f,"DIV",{class:!0});var fl=s(Do);T(fy.$$.fragment,fl),yrr=i(fl),_d=n(fl,"P",{});var ure=s(_d);xrr=r(ure,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),kW=n(ure,"A",{href:!0});var VMt=s(kW);$rr=r(VMt,"from_pretrained()"),VMt.forEach(t),krr=r(ure," class method or the "),SW=n(ure,"A",{href:!0});var XMt=s(SW);Srr=r(XMt,"from_config()"),XMt.forEach(t),Rrr=r(ure,` class
method.`),ure.forEach(t),Prr=i(fl),my=n(fl,"P",{});var Aze=s(my);Brr=r(Aze,"This class cannot be instantiated directly using "),Y1e=n(Aze,"CODE",{});var zMt=s(Y1e);Irr=r(zMt,"__init__()"),zMt.forEach(t),Nrr=r(Aze," (throws an error)."),Aze.forEach(t),qrr=i(fl),_t=n(fl,"DIV",{class:!0});var fw=s(_t);T(gy.$$.fragment,fw),jrr=i(fw),K1e=n(fw,"P",{});var WMt=s(K1e);Drr=r(WMt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),WMt.forEach(t),Grr=i(fw),ud=n(fw,"P",{});var bre=s(ud);Orr=r(bre,`Note:
Loading a model from its configuration file does `),Z1e=n(bre,"STRONG",{});var QMt=s(Z1e);Vrr=r(QMt,"not"),QMt.forEach(t),Xrr=r(bre,` load the model weights. It only affects the
model\u2019s configuration. Use `),RW=n(bre,"A",{href:!0});var HMt=s(RW);zrr=r(HMt,"from_pretrained()"),HMt.forEach(t),Wrr=r(bre," to load the model weights."),bre.forEach(t),Qrr=i(fw),T(KF.$$.fragment,fw),fw.forEach(t),Hrr=i(fl),so=n(fl,"DIV",{class:!0});var _a=s(so);T(hy.$$.fragment,_a),Urr=i(_a),e2e=n(_a,"P",{});var UMt=s(e2e);Jrr=r(UMt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),UMt.forEach(t),Yrr=i(_a),za=n(_a,"P",{});var mw=s(za);Krr=r(mw,"The model class to instantiate is selected based on the "),o2e=n(mw,"CODE",{});var JMt=s(o2e);Zrr=r(JMt,"model_type"),JMt.forEach(t),etr=r(mw,` property of the config object (either
passed as an argument or loaded from `),r2e=n(mw,"CODE",{});var YMt=s(r2e);otr=r(YMt,"pretrained_model_name_or_path"),YMt.forEach(t),rtr=r(mw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t2e=n(mw,"CODE",{});var KMt=s(t2e);ttr=r(KMt,"pretrained_model_name_or_path"),KMt.forEach(t),atr=r(mw,":"),mw.forEach(t),ntr=i(_a),a2e=n(_a,"UL",{});var ZMt=s(a2e);ZF=n(ZMt,"LI",{});var $Be=s(ZF);n2e=n($Be,"STRONG",{});var e4t=s(n2e);str=r(e4t,"tapas"),e4t.forEach(t),ltr=r($Be," \u2014 "),PW=n($Be,"A",{href:!0});var o4t=s(PW);itr=r(o4t,"TapasForQuestionAnswering"),o4t.forEach(t),dtr=r($Be," (TAPAS model)"),$Be.forEach(t),ZMt.forEach(t),ctr=i(_a),e6=n(_a,"P",{});var kBe=s(e6);ftr=r(kBe,"The model is set in evaluation mode by default using "),s2e=n(kBe,"CODE",{});var r4t=s(s2e);mtr=r(r4t,"model.eval()"),r4t.forEach(t),gtr=r(kBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l2e=n(kBe,"CODE",{});var t4t=s(l2e);htr=r(t4t,"model.train()"),t4t.forEach(t),kBe.forEach(t),ptr=i(_a),T(o6.$$.fragment,_a),_a.forEach(t),fl.forEach(t),TVe=i(f),bd=n(f,"H2",{class:!0});var Lze=s(bd);r6=n(Lze,"A",{id:!0,class:!0,href:!0});var a4t=s(r6);i2e=n(a4t,"SPAN",{});var n4t=s(i2e);T(py.$$.fragment,n4t),n4t.forEach(t),a4t.forEach(t),_tr=i(Lze),d2e=n(Lze,"SPAN",{});var s4t=s(d2e);utr=r(s4t,"AutoModelForImageClassification"),s4t.forEach(t),Lze.forEach(t),MVe=i(f),Go=n(f,"DIV",{class:!0});var ml=s(Go);T(_y.$$.fragment,ml),btr=i(ml),vd=n(ml,"P",{});var vre=s(vd);vtr=r(vre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),BW=n(vre,"A",{href:!0});var l4t=s(BW);Ftr=r(l4t,"from_pretrained()"),l4t.forEach(t),Ttr=r(vre," class method or the "),IW=n(vre,"A",{href:!0});var i4t=s(IW);Mtr=r(i4t,"from_config()"),i4t.forEach(t),Etr=r(vre,` class
method.`),vre.forEach(t),Ctr=i(ml),uy=n(ml,"P",{});var yze=s(uy);wtr=r(yze,"This class cannot be instantiated directly using "),c2e=n(yze,"CODE",{});var d4t=s(c2e);Atr=r(d4t,"__init__()"),d4t.forEach(t),Ltr=r(yze," (throws an error)."),yze.forEach(t),ytr=i(ml),ut=n(ml,"DIV",{class:!0});var gw=s(ut);T(by.$$.fragment,gw),xtr=i(gw),f2e=n(gw,"P",{});var c4t=s(f2e);$tr=r(c4t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),c4t.forEach(t),ktr=i(gw),Fd=n(gw,"P",{});var Fre=s(Fd);Str=r(Fre,`Note:
Loading a model from its configuration file does `),m2e=n(Fre,"STRONG",{});var f4t=s(m2e);Rtr=r(f4t,"not"),f4t.forEach(t),Ptr=r(Fre,` load the model weights. It only affects the
model\u2019s configuration. Use `),NW=n(Fre,"A",{href:!0});var m4t=s(NW);Btr=r(m4t,"from_pretrained()"),m4t.forEach(t),Itr=r(Fre," to load the model weights."),Fre.forEach(t),Ntr=i(gw),T(t6.$$.fragment,gw),gw.forEach(t),qtr=i(ml),lo=n(ml,"DIV",{class:!0});var ua=s(lo);T(vy.$$.fragment,ua),jtr=i(ua),g2e=n(ua,"P",{});var g4t=s(g2e);Dtr=r(g4t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),g4t.forEach(t),Gtr=i(ua),Wa=n(ua,"P",{});var hw=s(Wa);Otr=r(hw,"The model class to instantiate is selected based on the "),h2e=n(hw,"CODE",{});var h4t=s(h2e);Vtr=r(h4t,"model_type"),h4t.forEach(t),Xtr=r(hw,` property of the config object (either
passed as an argument or loaded from `),p2e=n(hw,"CODE",{});var p4t=s(p2e);ztr=r(p4t,"pretrained_model_name_or_path"),p4t.forEach(t),Wtr=r(hw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_2e=n(hw,"CODE",{});var _4t=s(_2e);Qtr=r(_4t,"pretrained_model_name_or_path"),_4t.forEach(t),Htr=r(hw,":"),hw.forEach(t),Utr=i(ua),Fe=n(ua,"UL",{});var Te=s(Fe);a6=n(Te,"LI",{});var SBe=s(a6);u2e=n(SBe,"STRONG",{});var u4t=s(u2e);Jtr=r(u4t,"beit"),u4t.forEach(t),Ytr=r(SBe," \u2014 "),qW=n(SBe,"A",{href:!0});var b4t=s(qW);Ktr=r(b4t,"BeitForImageClassification"),b4t.forEach(t),Ztr=r(SBe," (BEiT model)"),SBe.forEach(t),ear=i(Te),n6=n(Te,"LI",{});var RBe=s(n6);b2e=n(RBe,"STRONG",{});var v4t=s(b2e);oar=r(v4t,"convnext"),v4t.forEach(t),rar=r(RBe," \u2014 "),jW=n(RBe,"A",{href:!0});var F4t=s(jW);tar=r(F4t,"ConvNextForImageClassification"),F4t.forEach(t),aar=r(RBe," (ConvNeXT model)"),RBe.forEach(t),nar=i(Te),s6=n(Te,"LI",{});var PBe=s(s6);v2e=n(PBe,"STRONG",{});var T4t=s(v2e);sar=r(T4t,"cvt"),T4t.forEach(t),lar=r(PBe," \u2014 "),DW=n(PBe,"A",{href:!0});var M4t=s(DW);iar=r(M4t,"CvtForImageClassification"),M4t.forEach(t),dar=r(PBe," (CvT model)"),PBe.forEach(t),car=i(Te),l6=n(Te,"LI",{});var BBe=s(l6);F2e=n(BBe,"STRONG",{});var E4t=s(F2e);far=r(E4t,"data2vec-vision"),E4t.forEach(t),mar=r(BBe," \u2014 "),GW=n(BBe,"A",{href:!0});var C4t=s(GW);gar=r(C4t,"Data2VecVisionForImageClassification"),C4t.forEach(t),har=r(BBe," (Data2VecVision model)"),BBe.forEach(t),par=i(Te),Qs=n(Te,"LI",{});var hS=s(Qs);T2e=n(hS,"STRONG",{});var w4t=s(T2e);_ar=r(w4t,"deit"),w4t.forEach(t),uar=r(hS," \u2014 "),OW=n(hS,"A",{href:!0});var A4t=s(OW);bar=r(A4t,"DeiTForImageClassification"),A4t.forEach(t),Far=r(hS," or "),VW=n(hS,"A",{href:!0});var L4t=s(VW);Tar=r(L4t,"DeiTForImageClassificationWithTeacher"),L4t.forEach(t),Mar=r(hS," (DeiT model)"),hS.forEach(t),Ear=i(Te),i6=n(Te,"LI",{});var IBe=s(i6);M2e=n(IBe,"STRONG",{});var y4t=s(M2e);Car=r(y4t,"imagegpt"),y4t.forEach(t),war=r(IBe," \u2014 "),XW=n(IBe,"A",{href:!0});var x4t=s(XW);Aar=r(x4t,"ImageGPTForImageClassification"),x4t.forEach(t),Lar=r(IBe," (ImageGPT model)"),IBe.forEach(t),yar=i(Te),Hs=n(Te,"LI",{});var pS=s(Hs);E2e=n(pS,"STRONG",{});var $4t=s(E2e);xar=r($4t,"levit"),$4t.forEach(t),$ar=r(pS," \u2014 "),zW=n(pS,"A",{href:!0});var k4t=s(zW);kar=r(k4t,"LevitForImageClassification"),k4t.forEach(t),Sar=r(pS," or "),WW=n(pS,"A",{href:!0});var S4t=s(WW);Rar=r(S4t,"LevitForImageClassificationWithTeacher"),S4t.forEach(t),Par=r(pS," (LeViT model)"),pS.forEach(t),Bar=i(Te),bt=n(Te,"LI",{});var kf=s(bt);C2e=n(kf,"STRONG",{});var R4t=s(C2e);Iar=r(R4t,"perceiver"),R4t.forEach(t),Nar=r(kf," \u2014 "),QW=n(kf,"A",{href:!0});var P4t=s(QW);qar=r(P4t,"PerceiverForImageClassificationLearned"),P4t.forEach(t),jar=r(kf," or "),HW=n(kf,"A",{href:!0});var B4t=s(HW);Dar=r(B4t,"PerceiverForImageClassificationFourier"),B4t.forEach(t),Gar=r(kf," or "),UW=n(kf,"A",{href:!0});var I4t=s(UW);Oar=r(I4t,"PerceiverForImageClassificationConvProcessing"),I4t.forEach(t),Var=r(kf," (Perceiver model)"),kf.forEach(t),Xar=i(Te),d6=n(Te,"LI",{});var NBe=s(d6);w2e=n(NBe,"STRONG",{});var N4t=s(w2e);zar=r(N4t,"poolformer"),N4t.forEach(t),War=r(NBe," \u2014 "),JW=n(NBe,"A",{href:!0});var q4t=s(JW);Qar=r(q4t,"PoolFormerForImageClassification"),q4t.forEach(t),Har=r(NBe," (PoolFormer model)"),NBe.forEach(t),Uar=i(Te),c6=n(Te,"LI",{});var qBe=s(c6);A2e=n(qBe,"STRONG",{});var j4t=s(A2e);Jar=r(j4t,"regnet"),j4t.forEach(t),Yar=r(qBe," \u2014 "),YW=n(qBe,"A",{href:!0});var D4t=s(YW);Kar=r(D4t,"RegNetForImageClassification"),D4t.forEach(t),Zar=r(qBe," (RegNet model)"),qBe.forEach(t),enr=i(Te),f6=n(Te,"LI",{});var jBe=s(f6);L2e=n(jBe,"STRONG",{});var G4t=s(L2e);onr=r(G4t,"resnet"),G4t.forEach(t),rnr=r(jBe," \u2014 "),KW=n(jBe,"A",{href:!0});var O4t=s(KW);tnr=r(O4t,"ResNetForImageClassification"),O4t.forEach(t),anr=r(jBe," (ResNet model)"),jBe.forEach(t),nnr=i(Te),m6=n(Te,"LI",{});var DBe=s(m6);y2e=n(DBe,"STRONG",{});var V4t=s(y2e);snr=r(V4t,"segformer"),V4t.forEach(t),lnr=r(DBe," \u2014 "),ZW=n(DBe,"A",{href:!0});var X4t=s(ZW);inr=r(X4t,"SegformerForImageClassification"),X4t.forEach(t),dnr=r(DBe," (SegFormer model)"),DBe.forEach(t),cnr=i(Te),g6=n(Te,"LI",{});var GBe=s(g6);x2e=n(GBe,"STRONG",{});var z4t=s(x2e);fnr=r(z4t,"swin"),z4t.forEach(t),mnr=r(GBe," \u2014 "),eQ=n(GBe,"A",{href:!0});var W4t=s(eQ);gnr=r(W4t,"SwinForImageClassification"),W4t.forEach(t),hnr=r(GBe," (Swin Transformer model)"),GBe.forEach(t),pnr=i(Te),h6=n(Te,"LI",{});var OBe=s(h6);$2e=n(OBe,"STRONG",{});var Q4t=s($2e);_nr=r(Q4t,"van"),Q4t.forEach(t),unr=r(OBe," \u2014 "),oQ=n(OBe,"A",{href:!0});var H4t=s(oQ);bnr=r(H4t,"VanForImageClassification"),H4t.forEach(t),vnr=r(OBe," (VAN model)"),OBe.forEach(t),Fnr=i(Te),p6=n(Te,"LI",{});var VBe=s(p6);k2e=n(VBe,"STRONG",{});var U4t=s(k2e);Tnr=r(U4t,"vit"),U4t.forEach(t),Mnr=r(VBe," \u2014 "),rQ=n(VBe,"A",{href:!0});var J4t=s(rQ);Enr=r(J4t,"ViTForImageClassification"),J4t.forEach(t),Cnr=r(VBe," (ViT model)"),VBe.forEach(t),Te.forEach(t),wnr=i(ua),_6=n(ua,"P",{});var XBe=s(_6);Anr=r(XBe,"The model is set in evaluation mode by default using "),S2e=n(XBe,"CODE",{});var Y4t=s(S2e);Lnr=r(Y4t,"model.eval()"),Y4t.forEach(t),ynr=r(XBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),R2e=n(XBe,"CODE",{});var K4t=s(R2e);xnr=r(K4t,"model.train()"),K4t.forEach(t),XBe.forEach(t),$nr=i(ua),T(u6.$$.fragment,ua),ua.forEach(t),ml.forEach(t),EVe=i(f),Td=n(f,"H2",{class:!0});var xze=s(Td);b6=n(xze,"A",{id:!0,class:!0,href:!0});var Z4t=s(b6);P2e=n(Z4t,"SPAN",{});var eEt=s(P2e);T(Fy.$$.fragment,eEt),eEt.forEach(t),Z4t.forEach(t),knr=i(xze),B2e=n(xze,"SPAN",{});var oEt=s(B2e);Snr=r(oEt,"AutoModelForVision2Seq"),oEt.forEach(t),xze.forEach(t),CVe=i(f),Oo=n(f,"DIV",{class:!0});var gl=s(Oo);T(Ty.$$.fragment,gl),Rnr=i(gl),Md=n(gl,"P",{});var Tre=s(Md);Pnr=r(Tre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),tQ=n(Tre,"A",{href:!0});var rEt=s(tQ);Bnr=r(rEt,"from_pretrained()"),rEt.forEach(t),Inr=r(Tre," class method or the "),aQ=n(Tre,"A",{href:!0});var tEt=s(aQ);Nnr=r(tEt,"from_config()"),tEt.forEach(t),qnr=r(Tre,` class
method.`),Tre.forEach(t),jnr=i(gl),My=n(gl,"P",{});var $ze=s(My);Dnr=r($ze,"This class cannot be instantiated directly using "),I2e=n($ze,"CODE",{});var aEt=s(I2e);Gnr=r(aEt,"__init__()"),aEt.forEach(t),Onr=r($ze," (throws an error)."),$ze.forEach(t),Vnr=i(gl),vt=n(gl,"DIV",{class:!0});var pw=s(vt);T(Ey.$$.fragment,pw),Xnr=i(pw),N2e=n(pw,"P",{});var nEt=s(N2e);znr=r(nEt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),nEt.forEach(t),Wnr=i(pw),Ed=n(pw,"P",{});var Mre=s(Ed);Qnr=r(Mre,`Note:
Loading a model from its configuration file does `),q2e=n(Mre,"STRONG",{});var sEt=s(q2e);Hnr=r(sEt,"not"),sEt.forEach(t),Unr=r(Mre,` load the model weights. It only affects the
model\u2019s configuration. Use `),nQ=n(Mre,"A",{href:!0});var lEt=s(nQ);Jnr=r(lEt,"from_pretrained()"),lEt.forEach(t),Ynr=r(Mre," to load the model weights."),Mre.forEach(t),Knr=i(pw),T(v6.$$.fragment,pw),pw.forEach(t),Znr=i(gl),io=n(gl,"DIV",{class:!0});var ba=s(io);T(Cy.$$.fragment,ba),esr=i(ba),j2e=n(ba,"P",{});var iEt=s(j2e);osr=r(iEt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),iEt.forEach(t),rsr=i(ba),Qa=n(ba,"P",{});var _w=s(Qa);tsr=r(_w,"The model class to instantiate is selected based on the "),D2e=n(_w,"CODE",{});var dEt=s(D2e);asr=r(dEt,"model_type"),dEt.forEach(t),nsr=r(_w,` property of the config object (either
passed as an argument or loaded from `),G2e=n(_w,"CODE",{});var cEt=s(G2e);ssr=r(cEt,"pretrained_model_name_or_path"),cEt.forEach(t),lsr=r(_w,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O2e=n(_w,"CODE",{});var fEt=s(O2e);isr=r(fEt,"pretrained_model_name_or_path"),fEt.forEach(t),dsr=r(_w,":"),_w.forEach(t),csr=i(ba),V2e=n(ba,"UL",{});var mEt=s(V2e);F6=n(mEt,"LI",{});var zBe=s(F6);X2e=n(zBe,"STRONG",{});var gEt=s(X2e);fsr=r(gEt,"vision-encoder-decoder"),gEt.forEach(t),msr=r(zBe," \u2014 "),sQ=n(zBe,"A",{href:!0});var hEt=s(sQ);gsr=r(hEt,"VisionEncoderDecoderModel"),hEt.forEach(t),hsr=r(zBe," (Vision Encoder decoder model)"),zBe.forEach(t),mEt.forEach(t),psr=i(ba),T6=n(ba,"P",{});var WBe=s(T6);_sr=r(WBe,"The model is set in evaluation mode by default using "),z2e=n(WBe,"CODE",{});var pEt=s(z2e);usr=r(pEt,"model.eval()"),pEt.forEach(t),bsr=r(WBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),W2e=n(WBe,"CODE",{});var _Et=s(W2e);vsr=r(_Et,"model.train()"),_Et.forEach(t),WBe.forEach(t),Fsr=i(ba),T(M6.$$.fragment,ba),ba.forEach(t),gl.forEach(t),wVe=i(f),Cd=n(f,"H2",{class:!0});var kze=s(Cd);E6=n(kze,"A",{id:!0,class:!0,href:!0});var uEt=s(E6);Q2e=n(uEt,"SPAN",{});var bEt=s(Q2e);T(wy.$$.fragment,bEt),bEt.forEach(t),uEt.forEach(t),Tsr=i(kze),H2e=n(kze,"SPAN",{});var vEt=s(H2e);Msr=r(vEt,"AutoModelForVisualQuestionAnswering"),vEt.forEach(t),kze.forEach(t),AVe=i(f),Vo=n(f,"DIV",{class:!0});var hl=s(Vo);T(Ay.$$.fragment,hl),Esr=i(hl),wd=n(hl,"P",{});var Ere=s(wd);Csr=r(Ere,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),lQ=n(Ere,"A",{href:!0});var FEt=s(lQ);wsr=r(FEt,"from_pretrained()"),FEt.forEach(t),Asr=r(Ere," class method or the "),iQ=n(Ere,"A",{href:!0});var TEt=s(iQ);Lsr=r(TEt,"from_config()"),TEt.forEach(t),ysr=r(Ere,` class
method.`),Ere.forEach(t),xsr=i(hl),Ly=n(hl,"P",{});var Sze=s(Ly);$sr=r(Sze,"This class cannot be instantiated directly using "),U2e=n(Sze,"CODE",{});var MEt=s(U2e);ksr=r(MEt,"__init__()"),MEt.forEach(t),Ssr=r(Sze," (throws an error)."),Sze.forEach(t),Rsr=i(hl),Ft=n(hl,"DIV",{class:!0});var uw=s(Ft);T(yy.$$.fragment,uw),Psr=i(uw),J2e=n(uw,"P",{});var EEt=s(J2e);Bsr=r(EEt,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),EEt.forEach(t),Isr=i(uw),Ad=n(uw,"P",{});var Cre=s(Ad);Nsr=r(Cre,`Note:
Loading a model from its configuration file does `),Y2e=n(Cre,"STRONG",{});var CEt=s(Y2e);qsr=r(CEt,"not"),CEt.forEach(t),jsr=r(Cre,` load the model weights. It only affects the
model\u2019s configuration. Use `),dQ=n(Cre,"A",{href:!0});var wEt=s(dQ);Dsr=r(wEt,"from_pretrained()"),wEt.forEach(t),Gsr=r(Cre," to load the model weights."),Cre.forEach(t),Osr=i(uw),T(C6.$$.fragment,uw),uw.forEach(t),Vsr=i(hl),co=n(hl,"DIV",{class:!0});var va=s(co);T(xy.$$.fragment,va),Xsr=i(va),K2e=n(va,"P",{});var AEt=s(K2e);zsr=r(AEt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),AEt.forEach(t),Wsr=i(va),Ha=n(va,"P",{});var bw=s(Ha);Qsr=r(bw,"The model class to instantiate is selected based on the "),Z2e=n(bw,"CODE",{});var LEt=s(Z2e);Hsr=r(LEt,"model_type"),LEt.forEach(t),Usr=r(bw,` property of the config object (either
passed as an argument or loaded from `),ebe=n(bw,"CODE",{});var yEt=s(ebe);Jsr=r(yEt,"pretrained_model_name_or_path"),yEt.forEach(t),Ysr=r(bw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),obe=n(bw,"CODE",{});var xEt=s(obe);Ksr=r(xEt,"pretrained_model_name_or_path"),xEt.forEach(t),Zsr=r(bw,":"),bw.forEach(t),elr=i(va),rbe=n(va,"UL",{});var $Et=s(rbe);w6=n($Et,"LI",{});var QBe=s(w6);tbe=n(QBe,"STRONG",{});var kEt=s(tbe);olr=r(kEt,"vilt"),kEt.forEach(t),rlr=r(QBe," \u2014 "),cQ=n(QBe,"A",{href:!0});var SEt=s(cQ);tlr=r(SEt,"ViltForQuestionAnswering"),SEt.forEach(t),alr=r(QBe," (ViLT model)"),QBe.forEach(t),$Et.forEach(t),nlr=i(va),A6=n(va,"P",{});var HBe=s(A6);slr=r(HBe,"The model is set in evaluation mode by default using "),abe=n(HBe,"CODE",{});var REt=s(abe);llr=r(REt,"model.eval()"),REt.forEach(t),ilr=r(HBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nbe=n(HBe,"CODE",{});var PEt=s(nbe);dlr=r(PEt,"model.train()"),PEt.forEach(t),HBe.forEach(t),clr=i(va),T(L6.$$.fragment,va),va.forEach(t),hl.forEach(t),LVe=i(f),Ld=n(f,"H2",{class:!0});var Rze=s(Ld);y6=n(Rze,"A",{id:!0,class:!0,href:!0});var BEt=s(y6);sbe=n(BEt,"SPAN",{});var IEt=s(sbe);T($y.$$.fragment,IEt),IEt.forEach(t),BEt.forEach(t),flr=i(Rze),lbe=n(Rze,"SPAN",{});var NEt=s(lbe);mlr=r(NEt,"AutoModelForAudioClassification"),NEt.forEach(t),Rze.forEach(t),yVe=i(f),Xo=n(f,"DIV",{class:!0});var pl=s(Xo);T(ky.$$.fragment,pl),glr=i(pl),yd=n(pl,"P",{});var wre=s(yd);hlr=r(wre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),fQ=n(wre,"A",{href:!0});var qEt=s(fQ);plr=r(qEt,"from_pretrained()"),qEt.forEach(t),_lr=r(wre," class method or the "),mQ=n(wre,"A",{href:!0});var jEt=s(mQ);ulr=r(jEt,"from_config()"),jEt.forEach(t),blr=r(wre,` class
method.`),wre.forEach(t),vlr=i(pl),Sy=n(pl,"P",{});var Pze=s(Sy);Flr=r(Pze,"This class cannot be instantiated directly using "),ibe=n(Pze,"CODE",{});var DEt=s(ibe);Tlr=r(DEt,"__init__()"),DEt.forEach(t),Mlr=r(Pze," (throws an error)."),Pze.forEach(t),Elr=i(pl),Tt=n(pl,"DIV",{class:!0});var vw=s(Tt);T(Ry.$$.fragment,vw),Clr=i(vw),dbe=n(vw,"P",{});var GEt=s(dbe);wlr=r(GEt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),GEt.forEach(t),Alr=i(vw),xd=n(vw,"P",{});var Are=s(xd);Llr=r(Are,`Note:
Loading a model from its configuration file does `),cbe=n(Are,"STRONG",{});var OEt=s(cbe);ylr=r(OEt,"not"),OEt.forEach(t),xlr=r(Are,` load the model weights. It only affects the
model\u2019s configuration. Use `),gQ=n(Are,"A",{href:!0});var VEt=s(gQ);$lr=r(VEt,"from_pretrained()"),VEt.forEach(t),klr=r(Are," to load the model weights."),Are.forEach(t),Slr=i(vw),T(x6.$$.fragment,vw),vw.forEach(t),Rlr=i(pl),fo=n(pl,"DIV",{class:!0});var Fa=s(fo);T(Py.$$.fragment,Fa),Plr=i(Fa),fbe=n(Fa,"P",{});var XEt=s(fbe);Blr=r(XEt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),XEt.forEach(t),Ilr=i(Fa),Ua=n(Fa,"P",{});var Fw=s(Ua);Nlr=r(Fw,"The model class to instantiate is selected based on the "),mbe=n(Fw,"CODE",{});var zEt=s(mbe);qlr=r(zEt,"model_type"),zEt.forEach(t),jlr=r(Fw,` property of the config object (either
passed as an argument or loaded from `),gbe=n(Fw,"CODE",{});var WEt=s(gbe);Dlr=r(WEt,"pretrained_model_name_or_path"),WEt.forEach(t),Glr=r(Fw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hbe=n(Fw,"CODE",{});var QEt=s(hbe);Olr=r(QEt,"pretrained_model_name_or_path"),QEt.forEach(t),Vlr=r(Fw,":"),Fw.forEach(t),Xlr=i(Fa),Pe=n(Fa,"UL",{});var ze=s(Pe);$6=n(ze,"LI",{});var UBe=s($6);pbe=n(UBe,"STRONG",{});var HEt=s(pbe);zlr=r(HEt,"data2vec-audio"),HEt.forEach(t),Wlr=r(UBe," \u2014 "),hQ=n(UBe,"A",{href:!0});var UEt=s(hQ);Qlr=r(UEt,"Data2VecAudioForSequenceClassification"),UEt.forEach(t),Hlr=r(UBe," (Data2VecAudio model)"),UBe.forEach(t),Ulr=i(ze),k6=n(ze,"LI",{});var JBe=s(k6);_be=n(JBe,"STRONG",{});var JEt=s(_be);Jlr=r(JEt,"hubert"),JEt.forEach(t),Ylr=r(JBe," \u2014 "),pQ=n(JBe,"A",{href:!0});var YEt=s(pQ);Klr=r(YEt,"HubertForSequenceClassification"),YEt.forEach(t),Zlr=r(JBe," (Hubert model)"),JBe.forEach(t),eir=i(ze),S6=n(ze,"LI",{});var YBe=s(S6);ube=n(YBe,"STRONG",{});var KEt=s(ube);oir=r(KEt,"sew"),KEt.forEach(t),rir=r(YBe," \u2014 "),_Q=n(YBe,"A",{href:!0});var ZEt=s(_Q);tir=r(ZEt,"SEWForSequenceClassification"),ZEt.forEach(t),air=r(YBe," (SEW model)"),YBe.forEach(t),nir=i(ze),R6=n(ze,"LI",{});var KBe=s(R6);bbe=n(KBe,"STRONG",{});var eCt=s(bbe);sir=r(eCt,"sew-d"),eCt.forEach(t),lir=r(KBe," \u2014 "),uQ=n(KBe,"A",{href:!0});var oCt=s(uQ);iir=r(oCt,"SEWDForSequenceClassification"),oCt.forEach(t),dir=r(KBe," (SEW-D model)"),KBe.forEach(t),cir=i(ze),P6=n(ze,"LI",{});var ZBe=s(P6);vbe=n(ZBe,"STRONG",{});var rCt=s(vbe);fir=r(rCt,"unispeech"),rCt.forEach(t),mir=r(ZBe," \u2014 "),bQ=n(ZBe,"A",{href:!0});var tCt=s(bQ);gir=r(tCt,"UniSpeechForSequenceClassification"),tCt.forEach(t),hir=r(ZBe," (UniSpeech model)"),ZBe.forEach(t),pir=i(ze),B6=n(ze,"LI",{});var eIe=s(B6);Fbe=n(eIe,"STRONG",{});var aCt=s(Fbe);_ir=r(aCt,"unispeech-sat"),aCt.forEach(t),uir=r(eIe," \u2014 "),vQ=n(eIe,"A",{href:!0});var nCt=s(vQ);bir=r(nCt,"UniSpeechSatForSequenceClassification"),nCt.forEach(t),vir=r(eIe," (UniSpeechSat model)"),eIe.forEach(t),Fir=i(ze),I6=n(ze,"LI",{});var oIe=s(I6);Tbe=n(oIe,"STRONG",{});var sCt=s(Tbe);Tir=r(sCt,"wav2vec2"),sCt.forEach(t),Mir=r(oIe," \u2014 "),FQ=n(oIe,"A",{href:!0});var lCt=s(FQ);Eir=r(lCt,"Wav2Vec2ForSequenceClassification"),lCt.forEach(t),Cir=r(oIe," (Wav2Vec2 model)"),oIe.forEach(t),wir=i(ze),N6=n(ze,"LI",{});var rIe=s(N6);Mbe=n(rIe,"STRONG",{});var iCt=s(Mbe);Air=r(iCt,"wav2vec2-conformer"),iCt.forEach(t),Lir=r(rIe," \u2014 "),TQ=n(rIe,"A",{href:!0});var dCt=s(TQ);yir=r(dCt,"Wav2Vec2ConformerForSequenceClassification"),dCt.forEach(t),xir=r(rIe," (Wav2Vec2-Conformer model)"),rIe.forEach(t),$ir=i(ze),q6=n(ze,"LI",{});var tIe=s(q6);Ebe=n(tIe,"STRONG",{});var cCt=s(Ebe);kir=r(cCt,"wavlm"),cCt.forEach(t),Sir=r(tIe," \u2014 "),MQ=n(tIe,"A",{href:!0});var fCt=s(MQ);Rir=r(fCt,"WavLMForSequenceClassification"),fCt.forEach(t),Pir=r(tIe," (WavLM model)"),tIe.forEach(t),ze.forEach(t),Bir=i(Fa),j6=n(Fa,"P",{});var aIe=s(j6);Iir=r(aIe,"The model is set in evaluation mode by default using "),Cbe=n(aIe,"CODE",{});var mCt=s(Cbe);Nir=r(mCt,"model.eval()"),mCt.forEach(t),qir=r(aIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),wbe=n(aIe,"CODE",{});var gCt=s(wbe);jir=r(gCt,"model.train()"),gCt.forEach(t),aIe.forEach(t),Dir=i(Fa),T(D6.$$.fragment,Fa),Fa.forEach(t),pl.forEach(t),xVe=i(f),$d=n(f,"H2",{class:!0});var Bze=s($d);G6=n(Bze,"A",{id:!0,class:!0,href:!0});var hCt=s(G6);Abe=n(hCt,"SPAN",{});var pCt=s(Abe);T(By.$$.fragment,pCt),pCt.forEach(t),hCt.forEach(t),Gir=i(Bze),Lbe=n(Bze,"SPAN",{});var _Ct=s(Lbe);Oir=r(_Ct,"AutoModelForAudioFrameClassification"),_Ct.forEach(t),Bze.forEach(t),$Ve=i(f),zo=n(f,"DIV",{class:!0});var _l=s(zo);T(Iy.$$.fragment,_l),Vir=i(_l),kd=n(_l,"P",{});var Lre=s(kd);Xir=r(Lre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),EQ=n(Lre,"A",{href:!0});var uCt=s(EQ);zir=r(uCt,"from_pretrained()"),uCt.forEach(t),Wir=r(Lre," class method or the "),CQ=n(Lre,"A",{href:!0});var bCt=s(CQ);Qir=r(bCt,"from_config()"),bCt.forEach(t),Hir=r(Lre,` class
method.`),Lre.forEach(t),Uir=i(_l),Ny=n(_l,"P",{});var Ize=s(Ny);Jir=r(Ize,"This class cannot be instantiated directly using "),ybe=n(Ize,"CODE",{});var vCt=s(ybe);Yir=r(vCt,"__init__()"),vCt.forEach(t),Kir=r(Ize," (throws an error)."),Ize.forEach(t),Zir=i(_l),Mt=n(_l,"DIV",{class:!0});var Tw=s(Mt);T(qy.$$.fragment,Tw),edr=i(Tw),xbe=n(Tw,"P",{});var FCt=s(xbe);odr=r(FCt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),FCt.forEach(t),rdr=i(Tw),Sd=n(Tw,"P",{});var yre=s(Sd);tdr=r(yre,`Note:
Loading a model from its configuration file does `),$be=n(yre,"STRONG",{});var TCt=s($be);adr=r(TCt,"not"),TCt.forEach(t),ndr=r(yre,` load the model weights. It only affects the
model\u2019s configuration. Use `),wQ=n(yre,"A",{href:!0});var MCt=s(wQ);sdr=r(MCt,"from_pretrained()"),MCt.forEach(t),ldr=r(yre," to load the model weights."),yre.forEach(t),idr=i(Tw),T(O6.$$.fragment,Tw),Tw.forEach(t),ddr=i(_l),mo=n(_l,"DIV",{class:!0});var Ta=s(mo);T(jy.$$.fragment,Ta),cdr=i(Ta),kbe=n(Ta,"P",{});var ECt=s(kbe);fdr=r(ECt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),ECt.forEach(t),mdr=i(Ta),Ja=n(Ta,"P",{});var Mw=s(Ja);gdr=r(Mw,"The model class to instantiate is selected based on the "),Sbe=n(Mw,"CODE",{});var CCt=s(Sbe);hdr=r(CCt,"model_type"),CCt.forEach(t),pdr=r(Mw,` property of the config object (either
passed as an argument or loaded from `),Rbe=n(Mw,"CODE",{});var wCt=s(Rbe);_dr=r(wCt,"pretrained_model_name_or_path"),wCt.forEach(t),udr=r(Mw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Pbe=n(Mw,"CODE",{});var ACt=s(Pbe);bdr=r(ACt,"pretrained_model_name_or_path"),ACt.forEach(t),vdr=r(Mw,":"),Mw.forEach(t),Fdr=i(Ta),ot=n(Ta,"UL",{});var ul=s(ot);V6=n(ul,"LI",{});var nIe=s(V6);Bbe=n(nIe,"STRONG",{});var LCt=s(Bbe);Tdr=r(LCt,"data2vec-audio"),LCt.forEach(t),Mdr=r(nIe," \u2014 "),AQ=n(nIe,"A",{href:!0});var yCt=s(AQ);Edr=r(yCt,"Data2VecAudioForAudioFrameClassification"),yCt.forEach(t),Cdr=r(nIe," (Data2VecAudio model)"),nIe.forEach(t),wdr=i(ul),X6=n(ul,"LI",{});var sIe=s(X6);Ibe=n(sIe,"STRONG",{});var xCt=s(Ibe);Adr=r(xCt,"unispeech-sat"),xCt.forEach(t),Ldr=r(sIe," \u2014 "),LQ=n(sIe,"A",{href:!0});var $Ct=s(LQ);ydr=r($Ct,"UniSpeechSatForAudioFrameClassification"),$Ct.forEach(t),xdr=r(sIe," (UniSpeechSat model)"),sIe.forEach(t),$dr=i(ul),z6=n(ul,"LI",{});var lIe=s(z6);Nbe=n(lIe,"STRONG",{});var kCt=s(Nbe);kdr=r(kCt,"wav2vec2"),kCt.forEach(t),Sdr=r(lIe," \u2014 "),yQ=n(lIe,"A",{href:!0});var SCt=s(yQ);Rdr=r(SCt,"Wav2Vec2ForAudioFrameClassification"),SCt.forEach(t),Pdr=r(lIe," (Wav2Vec2 model)"),lIe.forEach(t),Bdr=i(ul),W6=n(ul,"LI",{});var iIe=s(W6);qbe=n(iIe,"STRONG",{});var RCt=s(qbe);Idr=r(RCt,"wav2vec2-conformer"),RCt.forEach(t),Ndr=r(iIe," \u2014 "),xQ=n(iIe,"A",{href:!0});var PCt=s(xQ);qdr=r(PCt,"Wav2Vec2ConformerForAudioFrameClassification"),PCt.forEach(t),jdr=r(iIe," (Wav2Vec2-Conformer model)"),iIe.forEach(t),Ddr=i(ul),Q6=n(ul,"LI",{});var dIe=s(Q6);jbe=n(dIe,"STRONG",{});var BCt=s(jbe);Gdr=r(BCt,"wavlm"),BCt.forEach(t),Odr=r(dIe," \u2014 "),$Q=n(dIe,"A",{href:!0});var ICt=s($Q);Vdr=r(ICt,"WavLMForAudioFrameClassification"),ICt.forEach(t),Xdr=r(dIe," (WavLM model)"),dIe.forEach(t),ul.forEach(t),zdr=i(Ta),H6=n(Ta,"P",{});var cIe=s(H6);Wdr=r(cIe,"The model is set in evaluation mode by default using "),Dbe=n(cIe,"CODE",{});var NCt=s(Dbe);Qdr=r(NCt,"model.eval()"),NCt.forEach(t),Hdr=r(cIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gbe=n(cIe,"CODE",{});var qCt=s(Gbe);Udr=r(qCt,"model.train()"),qCt.forEach(t),cIe.forEach(t),Jdr=i(Ta),T(U6.$$.fragment,Ta),Ta.forEach(t),_l.forEach(t),kVe=i(f),Rd=n(f,"H2",{class:!0});var Nze=s(Rd);J6=n(Nze,"A",{id:!0,class:!0,href:!0});var jCt=s(J6);Obe=n(jCt,"SPAN",{});var DCt=s(Obe);T(Dy.$$.fragment,DCt),DCt.forEach(t),jCt.forEach(t),Ydr=i(Nze),Vbe=n(Nze,"SPAN",{});var GCt=s(Vbe);Kdr=r(GCt,"AutoModelForCTC"),GCt.forEach(t),Nze.forEach(t),SVe=i(f),Wo=n(f,"DIV",{class:!0});var bl=s(Wo);T(Gy.$$.fragment,bl),Zdr=i(bl),Pd=n(bl,"P",{});var xre=s(Pd);ecr=r(xre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),kQ=n(xre,"A",{href:!0});var OCt=s(kQ);ocr=r(OCt,"from_pretrained()"),OCt.forEach(t),rcr=r(xre," class method or the "),SQ=n(xre,"A",{href:!0});var VCt=s(SQ);tcr=r(VCt,"from_config()"),VCt.forEach(t),acr=r(xre,` class
method.`),xre.forEach(t),ncr=i(bl),Oy=n(bl,"P",{});var qze=s(Oy);scr=r(qze,"This class cannot be instantiated directly using "),Xbe=n(qze,"CODE",{});var XCt=s(Xbe);lcr=r(XCt,"__init__()"),XCt.forEach(t),icr=r(qze," (throws an error)."),qze.forEach(t),dcr=i(bl),Et=n(bl,"DIV",{class:!0});var Ew=s(Et);T(Vy.$$.fragment,Ew),ccr=i(Ew),zbe=n(Ew,"P",{});var zCt=s(zbe);fcr=r(zCt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),zCt.forEach(t),mcr=i(Ew),Bd=n(Ew,"P",{});var $re=s(Bd);gcr=r($re,`Note:
Loading a model from its configuration file does `),Wbe=n($re,"STRONG",{});var WCt=s(Wbe);hcr=r(WCt,"not"),WCt.forEach(t),pcr=r($re,` load the model weights. It only affects the
model\u2019s configuration. Use `),RQ=n($re,"A",{href:!0});var QCt=s(RQ);_cr=r(QCt,"from_pretrained()"),QCt.forEach(t),ucr=r($re," to load the model weights."),$re.forEach(t),bcr=i(Ew),T(Y6.$$.fragment,Ew),Ew.forEach(t),vcr=i(bl),go=n(bl,"DIV",{class:!0});var Ma=s(go);T(Xy.$$.fragment,Ma),Fcr=i(Ma),Qbe=n(Ma,"P",{});var HCt=s(Qbe);Tcr=r(HCt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),HCt.forEach(t),Mcr=i(Ma),Ya=n(Ma,"P",{});var Cw=s(Ya);Ecr=r(Cw,"The model class to instantiate is selected based on the "),Hbe=n(Cw,"CODE",{});var UCt=s(Hbe);Ccr=r(UCt,"model_type"),UCt.forEach(t),wcr=r(Cw,` property of the config object (either
passed as an argument or loaded from `),Ube=n(Cw,"CODE",{});var JCt=s(Ube);Acr=r(JCt,"pretrained_model_name_or_path"),JCt.forEach(t),Lcr=r(Cw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jbe=n(Cw,"CODE",{});var YCt=s(Jbe);ycr=r(YCt,"pretrained_model_name_or_path"),YCt.forEach(t),xcr=r(Cw,":"),Cw.forEach(t),$cr=i(Ma),Le=n(Ma,"UL",{});var Be=s(Le);K6=n(Be,"LI",{});var fIe=s(K6);Ybe=n(fIe,"STRONG",{});var KCt=s(Ybe);kcr=r(KCt,"data2vec-audio"),KCt.forEach(t),Scr=r(fIe," \u2014 "),PQ=n(fIe,"A",{href:!0});var ZCt=s(PQ);Rcr=r(ZCt,"Data2VecAudioForCTC"),ZCt.forEach(t),Pcr=r(fIe," (Data2VecAudio model)"),fIe.forEach(t),Bcr=i(Be),Z6=n(Be,"LI",{});var mIe=s(Z6);Kbe=n(mIe,"STRONG",{});var e3t=s(Kbe);Icr=r(e3t,"hubert"),e3t.forEach(t),Ncr=r(mIe," \u2014 "),BQ=n(mIe,"A",{href:!0});var o3t=s(BQ);qcr=r(o3t,"HubertForCTC"),o3t.forEach(t),jcr=r(mIe," (Hubert model)"),mIe.forEach(t),Dcr=i(Be),eT=n(Be,"LI",{});var gIe=s(eT);Zbe=n(gIe,"STRONG",{});var r3t=s(Zbe);Gcr=r(r3t,"mctct"),r3t.forEach(t),Ocr=r(gIe," \u2014 "),IQ=n(gIe,"A",{href:!0});var t3t=s(IQ);Vcr=r(t3t,"MCTCTForCTC"),t3t.forEach(t),Xcr=r(gIe," (M-CTC-T model)"),gIe.forEach(t),zcr=i(Be),oT=n(Be,"LI",{});var hIe=s(oT);eve=n(hIe,"STRONG",{});var a3t=s(eve);Wcr=r(a3t,"sew"),a3t.forEach(t),Qcr=r(hIe," \u2014 "),NQ=n(hIe,"A",{href:!0});var n3t=s(NQ);Hcr=r(n3t,"SEWForCTC"),n3t.forEach(t),Ucr=r(hIe," (SEW model)"),hIe.forEach(t),Jcr=i(Be),rT=n(Be,"LI",{});var pIe=s(rT);ove=n(pIe,"STRONG",{});var s3t=s(ove);Ycr=r(s3t,"sew-d"),s3t.forEach(t),Kcr=r(pIe," \u2014 "),qQ=n(pIe,"A",{href:!0});var l3t=s(qQ);Zcr=r(l3t,"SEWDForCTC"),l3t.forEach(t),efr=r(pIe," (SEW-D model)"),pIe.forEach(t),ofr=i(Be),tT=n(Be,"LI",{});var _Ie=s(tT);rve=n(_Ie,"STRONG",{});var i3t=s(rve);rfr=r(i3t,"unispeech"),i3t.forEach(t),tfr=r(_Ie," \u2014 "),jQ=n(_Ie,"A",{href:!0});var d3t=s(jQ);afr=r(d3t,"UniSpeechForCTC"),d3t.forEach(t),nfr=r(_Ie," (UniSpeech model)"),_Ie.forEach(t),sfr=i(Be),aT=n(Be,"LI",{});var uIe=s(aT);tve=n(uIe,"STRONG",{});var c3t=s(tve);lfr=r(c3t,"unispeech-sat"),c3t.forEach(t),ifr=r(uIe," \u2014 "),DQ=n(uIe,"A",{href:!0});var f3t=s(DQ);dfr=r(f3t,"UniSpeechSatForCTC"),f3t.forEach(t),cfr=r(uIe," (UniSpeechSat model)"),uIe.forEach(t),ffr=i(Be),nT=n(Be,"LI",{});var bIe=s(nT);ave=n(bIe,"STRONG",{});var m3t=s(ave);mfr=r(m3t,"wav2vec2"),m3t.forEach(t),gfr=r(bIe," \u2014 "),GQ=n(bIe,"A",{href:!0});var g3t=s(GQ);hfr=r(g3t,"Wav2Vec2ForCTC"),g3t.forEach(t),pfr=r(bIe," (Wav2Vec2 model)"),bIe.forEach(t),_fr=i(Be),sT=n(Be,"LI",{});var vIe=s(sT);nve=n(vIe,"STRONG",{});var h3t=s(nve);ufr=r(h3t,"wav2vec2-conformer"),h3t.forEach(t),bfr=r(vIe," \u2014 "),OQ=n(vIe,"A",{href:!0});var p3t=s(OQ);vfr=r(p3t,"Wav2Vec2ConformerForCTC"),p3t.forEach(t),Ffr=r(vIe," (Wav2Vec2-Conformer model)"),vIe.forEach(t),Tfr=i(Be),lT=n(Be,"LI",{});var FIe=s(lT);sve=n(FIe,"STRONG",{});var _3t=s(sve);Mfr=r(_3t,"wavlm"),_3t.forEach(t),Efr=r(FIe," \u2014 "),VQ=n(FIe,"A",{href:!0});var u3t=s(VQ);Cfr=r(u3t,"WavLMForCTC"),u3t.forEach(t),wfr=r(FIe," (WavLM model)"),FIe.forEach(t),Be.forEach(t),Afr=i(Ma),iT=n(Ma,"P",{});var TIe=s(iT);Lfr=r(TIe,"The model is set in evaluation mode by default using "),lve=n(TIe,"CODE",{});var b3t=s(lve);yfr=r(b3t,"model.eval()"),b3t.forEach(t),xfr=r(TIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ive=n(TIe,"CODE",{});var v3t=s(ive);$fr=r(v3t,"model.train()"),v3t.forEach(t),TIe.forEach(t),kfr=i(Ma),T(dT.$$.fragment,Ma),Ma.forEach(t),bl.forEach(t),RVe=i(f),Id=n(f,"H2",{class:!0});var jze=s(Id);cT=n(jze,"A",{id:!0,class:!0,href:!0});var F3t=s(cT);dve=n(F3t,"SPAN",{});var T3t=s(dve);T(zy.$$.fragment,T3t),T3t.forEach(t),F3t.forEach(t),Sfr=i(jze),cve=n(jze,"SPAN",{});var M3t=s(cve);Rfr=r(M3t,"AutoModelForSpeechSeq2Seq"),M3t.forEach(t),jze.forEach(t),PVe=i(f),Qo=n(f,"DIV",{class:!0});var vl=s(Qo);T(Wy.$$.fragment,vl),Pfr=i(vl),Nd=n(vl,"P",{});var kre=s(Nd);Bfr=r(kre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),XQ=n(kre,"A",{href:!0});var E3t=s(XQ);Ifr=r(E3t,"from_pretrained()"),E3t.forEach(t),Nfr=r(kre," class method or the "),zQ=n(kre,"A",{href:!0});var C3t=s(zQ);qfr=r(C3t,"from_config()"),C3t.forEach(t),jfr=r(kre,` class
method.`),kre.forEach(t),Dfr=i(vl),Qy=n(vl,"P",{});var Dze=s(Qy);Gfr=r(Dze,"This class cannot be instantiated directly using "),fve=n(Dze,"CODE",{});var w3t=s(fve);Ofr=r(w3t,"__init__()"),w3t.forEach(t),Vfr=r(Dze," (throws an error)."),Dze.forEach(t),Xfr=i(vl),Ct=n(vl,"DIV",{class:!0});var ww=s(Ct);T(Hy.$$.fragment,ww),zfr=i(ww),mve=n(ww,"P",{});var A3t=s(mve);Wfr=r(A3t,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),A3t.forEach(t),Qfr=i(ww),qd=n(ww,"P",{});var Sre=s(qd);Hfr=r(Sre,`Note:
Loading a model from its configuration file does `),gve=n(Sre,"STRONG",{});var L3t=s(gve);Ufr=r(L3t,"not"),L3t.forEach(t),Jfr=r(Sre,` load the model weights. It only affects the
model\u2019s configuration. Use `),WQ=n(Sre,"A",{href:!0});var y3t=s(WQ);Yfr=r(y3t,"from_pretrained()"),y3t.forEach(t),Kfr=r(Sre," to load the model weights."),Sre.forEach(t),Zfr=i(ww),T(fT.$$.fragment,ww),ww.forEach(t),emr=i(vl),ho=n(vl,"DIV",{class:!0});var Ea=s(ho);T(Uy.$$.fragment,Ea),omr=i(Ea),hve=n(Ea,"P",{});var x3t=s(hve);rmr=r(x3t,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),x3t.forEach(t),tmr=i(Ea),Ka=n(Ea,"P",{});var Aw=s(Ka);amr=r(Aw,"The model class to instantiate is selected based on the "),pve=n(Aw,"CODE",{});var $3t=s(pve);nmr=r($3t,"model_type"),$3t.forEach(t),smr=r(Aw,` property of the config object (either
passed as an argument or loaded from `),_ve=n(Aw,"CODE",{});var k3t=s(_ve);lmr=r(k3t,"pretrained_model_name_or_path"),k3t.forEach(t),imr=r(Aw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uve=n(Aw,"CODE",{});var S3t=s(uve);dmr=r(S3t,"pretrained_model_name_or_path"),S3t.forEach(t),cmr=r(Aw,":"),Aw.forEach(t),fmr=i(Ea),Jy=n(Ea,"UL",{});var Gze=s(Jy);mT=n(Gze,"LI",{});var MIe=s(mT);bve=n(MIe,"STRONG",{});var R3t=s(bve);mmr=r(R3t,"speech-encoder-decoder"),R3t.forEach(t),gmr=r(MIe," \u2014 "),QQ=n(MIe,"A",{href:!0});var P3t=s(QQ);hmr=r(P3t,"SpeechEncoderDecoderModel"),P3t.forEach(t),pmr=r(MIe," (Speech Encoder decoder model)"),MIe.forEach(t),_mr=i(Gze),gT=n(Gze,"LI",{});var EIe=s(gT);vve=n(EIe,"STRONG",{});var B3t=s(vve);umr=r(B3t,"speech_to_text"),B3t.forEach(t),bmr=r(EIe," \u2014 "),HQ=n(EIe,"A",{href:!0});var I3t=s(HQ);vmr=r(I3t,"Speech2TextForConditionalGeneration"),I3t.forEach(t),Fmr=r(EIe," (Speech2Text model)"),EIe.forEach(t),Gze.forEach(t),Tmr=i(Ea),hT=n(Ea,"P",{});var CIe=s(hT);Mmr=r(CIe,"The model is set in evaluation mode by default using "),Fve=n(CIe,"CODE",{});var N3t=s(Fve);Emr=r(N3t,"model.eval()"),N3t.forEach(t),Cmr=r(CIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Tve=n(CIe,"CODE",{});var q3t=s(Tve);wmr=r(q3t,"model.train()"),q3t.forEach(t),CIe.forEach(t),Amr=i(Ea),T(pT.$$.fragment,Ea),Ea.forEach(t),vl.forEach(t),BVe=i(f),jd=n(f,"H2",{class:!0});var Oze=s(jd);_T=n(Oze,"A",{id:!0,class:!0,href:!0});var j3t=s(_T);Mve=n(j3t,"SPAN",{});var D3t=s(Mve);T(Yy.$$.fragment,D3t),D3t.forEach(t),j3t.forEach(t),Lmr=i(Oze),Eve=n(Oze,"SPAN",{});var G3t=s(Eve);ymr=r(G3t,"AutoModelForAudioXVector"),G3t.forEach(t),Oze.forEach(t),IVe=i(f),Ho=n(f,"DIV",{class:!0});var Fl=s(Ho);T(Ky.$$.fragment,Fl),xmr=i(Fl),Dd=n(Fl,"P",{});var Rre=s(Dd);$mr=r(Rre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),UQ=n(Rre,"A",{href:!0});var O3t=s(UQ);kmr=r(O3t,"from_pretrained()"),O3t.forEach(t),Smr=r(Rre," class method or the "),JQ=n(Rre,"A",{href:!0});var V3t=s(JQ);Rmr=r(V3t,"from_config()"),V3t.forEach(t),Pmr=r(Rre,` class
method.`),Rre.forEach(t),Bmr=i(Fl),Zy=n(Fl,"P",{});var Vze=s(Zy);Imr=r(Vze,"This class cannot be instantiated directly using "),Cve=n(Vze,"CODE",{});var X3t=s(Cve);Nmr=r(X3t,"__init__()"),X3t.forEach(t),qmr=r(Vze," (throws an error)."),Vze.forEach(t),jmr=i(Fl),wt=n(Fl,"DIV",{class:!0});var Lw=s(wt);T(e9.$$.fragment,Lw),Dmr=i(Lw),wve=n(Lw,"P",{});var z3t=s(wve);Gmr=r(z3t,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),z3t.forEach(t),Omr=i(Lw),Gd=n(Lw,"P",{});var Pre=s(Gd);Vmr=r(Pre,`Note:
Loading a model from its configuration file does `),Ave=n(Pre,"STRONG",{});var W3t=s(Ave);Xmr=r(W3t,"not"),W3t.forEach(t),zmr=r(Pre,` load the model weights. It only affects the
model\u2019s configuration. Use `),YQ=n(Pre,"A",{href:!0});var Q3t=s(YQ);Wmr=r(Q3t,"from_pretrained()"),Q3t.forEach(t),Qmr=r(Pre," to load the model weights."),Pre.forEach(t),Hmr=i(Lw),T(uT.$$.fragment,Lw),Lw.forEach(t),Umr=i(Fl),po=n(Fl,"DIV",{class:!0});var Ca=s(po);T(o9.$$.fragment,Ca),Jmr=i(Ca),Lve=n(Ca,"P",{});var H3t=s(Lve);Ymr=r(H3t,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),H3t.forEach(t),Kmr=i(Ca),Za=n(Ca,"P",{});var yw=s(Za);Zmr=r(yw,"The model class to instantiate is selected based on the "),yve=n(yw,"CODE",{});var U3t=s(yve);egr=r(U3t,"model_type"),U3t.forEach(t),ogr=r(yw,` property of the config object (either
passed as an argument or loaded from `),xve=n(yw,"CODE",{});var J3t=s(xve);rgr=r(J3t,"pretrained_model_name_or_path"),J3t.forEach(t),tgr=r(yw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$ve=n(yw,"CODE",{});var Y3t=s($ve);agr=r(Y3t,"pretrained_model_name_or_path"),Y3t.forEach(t),ngr=r(yw,":"),yw.forEach(t),sgr=i(Ca),rt=n(Ca,"UL",{});var Tl=s(rt);bT=n(Tl,"LI",{});var wIe=s(bT);kve=n(wIe,"STRONG",{});var K3t=s(kve);lgr=r(K3t,"data2vec-audio"),K3t.forEach(t),igr=r(wIe," \u2014 "),KQ=n(wIe,"A",{href:!0});var Z3t=s(KQ);dgr=r(Z3t,"Data2VecAudioForXVector"),Z3t.forEach(t),cgr=r(wIe," (Data2VecAudio model)"),wIe.forEach(t),fgr=i(Tl),vT=n(Tl,"LI",{});var AIe=s(vT);Sve=n(AIe,"STRONG",{});var e5t=s(Sve);mgr=r(e5t,"unispeech-sat"),e5t.forEach(t),ggr=r(AIe," \u2014 "),ZQ=n(AIe,"A",{href:!0});var o5t=s(ZQ);hgr=r(o5t,"UniSpeechSatForXVector"),o5t.forEach(t),pgr=r(AIe," (UniSpeechSat model)"),AIe.forEach(t),_gr=i(Tl),FT=n(Tl,"LI",{});var LIe=s(FT);Rve=n(LIe,"STRONG",{});var r5t=s(Rve);ugr=r(r5t,"wav2vec2"),r5t.forEach(t),bgr=r(LIe," \u2014 "),eH=n(LIe,"A",{href:!0});var t5t=s(eH);vgr=r(t5t,"Wav2Vec2ForXVector"),t5t.forEach(t),Fgr=r(LIe," (Wav2Vec2 model)"),LIe.forEach(t),Tgr=i(Tl),TT=n(Tl,"LI",{});var yIe=s(TT);Pve=n(yIe,"STRONG",{});var a5t=s(Pve);Mgr=r(a5t,"wav2vec2-conformer"),a5t.forEach(t),Egr=r(yIe," \u2014 "),oH=n(yIe,"A",{href:!0});var n5t=s(oH);Cgr=r(n5t,"Wav2Vec2ConformerForXVector"),n5t.forEach(t),wgr=r(yIe," (Wav2Vec2-Conformer model)"),yIe.forEach(t),Agr=i(Tl),MT=n(Tl,"LI",{});var xIe=s(MT);Bve=n(xIe,"STRONG",{});var s5t=s(Bve);Lgr=r(s5t,"wavlm"),s5t.forEach(t),ygr=r(xIe," \u2014 "),rH=n(xIe,"A",{href:!0});var l5t=s(rH);xgr=r(l5t,"WavLMForXVector"),l5t.forEach(t),$gr=r(xIe," (WavLM model)"),xIe.forEach(t),Tl.forEach(t),kgr=i(Ca),ET=n(Ca,"P",{});var $Ie=s(ET);Sgr=r($Ie,"The model is set in evaluation mode by default using "),Ive=n($Ie,"CODE",{});var i5t=s(Ive);Rgr=r(i5t,"model.eval()"),i5t.forEach(t),Pgr=r($Ie,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nve=n($Ie,"CODE",{});var d5t=s(Nve);Bgr=r(d5t,"model.train()"),d5t.forEach(t),$Ie.forEach(t),Igr=i(Ca),T(CT.$$.fragment,Ca),Ca.forEach(t),Fl.forEach(t),NVe=i(f),Od=n(f,"H2",{class:!0});var Xze=s(Od);wT=n(Xze,"A",{id:!0,class:!0,href:!0});var c5t=s(wT);qve=n(c5t,"SPAN",{});var f5t=s(qve);T(r9.$$.fragment,f5t),f5t.forEach(t),c5t.forEach(t),Ngr=i(Xze),jve=n(Xze,"SPAN",{});var m5t=s(jve);qgr=r(m5t,"AutoModelForMaskedImageModeling"),m5t.forEach(t),Xze.forEach(t),qVe=i(f),Uo=n(f,"DIV",{class:!0});var Ml=s(Uo);T(t9.$$.fragment,Ml),jgr=i(Ml),Vd=n(Ml,"P",{});var Bre=s(Vd);Dgr=r(Bre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),tH=n(Bre,"A",{href:!0});var g5t=s(tH);Ggr=r(g5t,"from_pretrained()"),g5t.forEach(t),Ogr=r(Bre," class method or the "),aH=n(Bre,"A",{href:!0});var h5t=s(aH);Vgr=r(h5t,"from_config()"),h5t.forEach(t),Xgr=r(Bre,` class
method.`),Bre.forEach(t),zgr=i(Ml),a9=n(Ml,"P",{});var zze=s(a9);Wgr=r(zze,"This class cannot be instantiated directly using "),Dve=n(zze,"CODE",{});var p5t=s(Dve);Qgr=r(p5t,"__init__()"),p5t.forEach(t),Hgr=r(zze," (throws an error)."),zze.forEach(t),Ugr=i(Ml),At=n(Ml,"DIV",{class:!0});var xw=s(At);T(n9.$$.fragment,xw),Jgr=i(xw),Gve=n(xw,"P",{});var _5t=s(Gve);Ygr=r(_5t,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),_5t.forEach(t),Kgr=i(xw),Xd=n(xw,"P",{});var Ire=s(Xd);Zgr=r(Ire,`Note:
Loading a model from its configuration file does `),Ove=n(Ire,"STRONG",{});var u5t=s(Ove);ehr=r(u5t,"not"),u5t.forEach(t),ohr=r(Ire,` load the model weights. It only affects the
model\u2019s configuration. Use `),nH=n(Ire,"A",{href:!0});var b5t=s(nH);rhr=r(b5t,"from_pretrained()"),b5t.forEach(t),thr=r(Ire," to load the model weights."),Ire.forEach(t),ahr=i(xw),T(AT.$$.fragment,xw),xw.forEach(t),nhr=i(Ml),_o=n(Ml,"DIV",{class:!0});var wa=s(_o);T(s9.$$.fragment,wa),shr=i(wa),Vve=n(wa,"P",{});var v5t=s(Vve);lhr=r(v5t,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),v5t.forEach(t),ihr=i(wa),en=n(wa,"P",{});var $w=s(en);dhr=r($w,"The model class to instantiate is selected based on the "),Xve=n($w,"CODE",{});var F5t=s(Xve);chr=r(F5t,"model_type"),F5t.forEach(t),fhr=r($w,` property of the config object (either
passed as an argument or loaded from `),zve=n($w,"CODE",{});var T5t=s(zve);mhr=r(T5t,"pretrained_model_name_or_path"),T5t.forEach(t),ghr=r($w,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wve=n($w,"CODE",{});var M5t=s(Wve);hhr=r(M5t,"pretrained_model_name_or_path"),M5t.forEach(t),phr=r($w,":"),$w.forEach(t),_hr=i(wa),zd=n(wa,"UL",{});var Nre=s(zd);LT=n(Nre,"LI",{});var kIe=s(LT);Qve=n(kIe,"STRONG",{});var E5t=s(Qve);uhr=r(E5t,"deit"),E5t.forEach(t),bhr=r(kIe," \u2014 "),sH=n(kIe,"A",{href:!0});var C5t=s(sH);vhr=r(C5t,"DeiTForMaskedImageModeling"),C5t.forEach(t),Fhr=r(kIe," (DeiT model)"),kIe.forEach(t),Thr=i(Nre),yT=n(Nre,"LI",{});var SIe=s(yT);Hve=n(SIe,"STRONG",{});var w5t=s(Hve);Mhr=r(w5t,"swin"),w5t.forEach(t),Ehr=r(SIe," \u2014 "),lH=n(SIe,"A",{href:!0});var A5t=s(lH);Chr=r(A5t,"SwinForMaskedImageModeling"),A5t.forEach(t),whr=r(SIe," (Swin Transformer model)"),SIe.forEach(t),Ahr=i(Nre),xT=n(Nre,"LI",{});var RIe=s(xT);Uve=n(RIe,"STRONG",{});var L5t=s(Uve);Lhr=r(L5t,"vit"),L5t.forEach(t),yhr=r(RIe," \u2014 "),iH=n(RIe,"A",{href:!0});var y5t=s(iH);xhr=r(y5t,"ViTForMaskedImageModeling"),y5t.forEach(t),$hr=r(RIe," (ViT model)"),RIe.forEach(t),Nre.forEach(t),khr=i(wa),$T=n(wa,"P",{});var PIe=s($T);Shr=r(PIe,"The model is set in evaluation mode by default using "),Jve=n(PIe,"CODE",{});var x5t=s(Jve);Rhr=r(x5t,"model.eval()"),x5t.forEach(t),Phr=r(PIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yve=n(PIe,"CODE",{});var $5t=s(Yve);Bhr=r($5t,"model.train()"),$5t.forEach(t),PIe.forEach(t),Ihr=i(wa),T(kT.$$.fragment,wa),wa.forEach(t),Ml.forEach(t),jVe=i(f),Wd=n(f,"H2",{class:!0});var Wze=s(Wd);ST=n(Wze,"A",{id:!0,class:!0,href:!0});var k5t=s(ST);Kve=n(k5t,"SPAN",{});var S5t=s(Kve);T(l9.$$.fragment,S5t),S5t.forEach(t),k5t.forEach(t),Nhr=i(Wze),Zve=n(Wze,"SPAN",{});var R5t=s(Zve);qhr=r(R5t,"AutoModelForObjectDetection"),R5t.forEach(t),Wze.forEach(t),DVe=i(f),Jo=n(f,"DIV",{class:!0});var El=s(Jo);T(i9.$$.fragment,El),jhr=i(El),Qd=n(El,"P",{});var qre=s(Qd);Dhr=r(qre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),dH=n(qre,"A",{href:!0});var P5t=s(dH);Ghr=r(P5t,"from_pretrained()"),P5t.forEach(t),Ohr=r(qre," class method or the "),cH=n(qre,"A",{href:!0});var B5t=s(cH);Vhr=r(B5t,"from_config()"),B5t.forEach(t),Xhr=r(qre,` class
method.`),qre.forEach(t),zhr=i(El),d9=n(El,"P",{});var Qze=s(d9);Whr=r(Qze,"This class cannot be instantiated directly using "),e0e=n(Qze,"CODE",{});var I5t=s(e0e);Qhr=r(I5t,"__init__()"),I5t.forEach(t),Hhr=r(Qze," (throws an error)."),Qze.forEach(t),Uhr=i(El),Lt=n(El,"DIV",{class:!0});var kw=s(Lt);T(c9.$$.fragment,kw),Jhr=i(kw),o0e=n(kw,"P",{});var N5t=s(o0e);Yhr=r(N5t,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),N5t.forEach(t),Khr=i(kw),Hd=n(kw,"P",{});var jre=s(Hd);Zhr=r(jre,`Note:
Loading a model from its configuration file does `),r0e=n(jre,"STRONG",{});var q5t=s(r0e);epr=r(q5t,"not"),q5t.forEach(t),opr=r(jre,` load the model weights. It only affects the
model\u2019s configuration. Use `),fH=n(jre,"A",{href:!0});var j5t=s(fH);rpr=r(j5t,"from_pretrained()"),j5t.forEach(t),tpr=r(jre," to load the model weights."),jre.forEach(t),apr=i(kw),T(RT.$$.fragment,kw),kw.forEach(t),npr=i(El),uo=n(El,"DIV",{class:!0});var Aa=s(uo);T(f9.$$.fragment,Aa),spr=i(Aa),t0e=n(Aa,"P",{});var D5t=s(t0e);lpr=r(D5t,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),D5t.forEach(t),ipr=i(Aa),on=n(Aa,"P",{});var Sw=s(on);dpr=r(Sw,"The model class to instantiate is selected based on the "),a0e=n(Sw,"CODE",{});var G5t=s(a0e);cpr=r(G5t,"model_type"),G5t.forEach(t),fpr=r(Sw,` property of the config object (either
passed as an argument or loaded from `),n0e=n(Sw,"CODE",{});var O5t=s(n0e);mpr=r(O5t,"pretrained_model_name_or_path"),O5t.forEach(t),gpr=r(Sw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s0e=n(Sw,"CODE",{});var V5t=s(s0e);hpr=r(V5t,"pretrained_model_name_or_path"),V5t.forEach(t),ppr=r(Sw,":"),Sw.forEach(t),_pr=i(Aa),m9=n(Aa,"UL",{});var Hze=s(m9);PT=n(Hze,"LI",{});var BIe=s(PT);l0e=n(BIe,"STRONG",{});var X5t=s(l0e);upr=r(X5t,"detr"),X5t.forEach(t),bpr=r(BIe," \u2014 "),mH=n(BIe,"A",{href:!0});var z5t=s(mH);vpr=r(z5t,"DetrForObjectDetection"),z5t.forEach(t),Fpr=r(BIe," (DETR model)"),BIe.forEach(t),Tpr=i(Hze),BT=n(Hze,"LI",{});var IIe=s(BT);i0e=n(IIe,"STRONG",{});var W5t=s(i0e);Mpr=r(W5t,"yolos"),W5t.forEach(t),Epr=r(IIe," \u2014 "),gH=n(IIe,"A",{href:!0});var Q5t=s(gH);Cpr=r(Q5t,"YolosForObjectDetection"),Q5t.forEach(t),wpr=r(IIe," (YOLOS model)"),IIe.forEach(t),Hze.forEach(t),Apr=i(Aa),IT=n(Aa,"P",{});var NIe=s(IT);Lpr=r(NIe,"The model is set in evaluation mode by default using "),d0e=n(NIe,"CODE",{});var H5t=s(d0e);ypr=r(H5t,"model.eval()"),H5t.forEach(t),xpr=r(NIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c0e=n(NIe,"CODE",{});var U5t=s(c0e);$pr=r(U5t,"model.train()"),U5t.forEach(t),NIe.forEach(t),kpr=i(Aa),T(NT.$$.fragment,Aa),Aa.forEach(t),El.forEach(t),GVe=i(f),Ud=n(f,"H2",{class:!0});var Uze=s(Ud);qT=n(Uze,"A",{id:!0,class:!0,href:!0});var J5t=s(qT);f0e=n(J5t,"SPAN",{});var Y5t=s(f0e);T(g9.$$.fragment,Y5t),Y5t.forEach(t),J5t.forEach(t),Spr=i(Uze),m0e=n(Uze,"SPAN",{});var K5t=s(m0e);Rpr=r(K5t,"AutoModelForImageSegmentation"),K5t.forEach(t),Uze.forEach(t),OVe=i(f),Yo=n(f,"DIV",{class:!0});var Cl=s(Yo);T(h9.$$.fragment,Cl),Ppr=i(Cl),Jd=n(Cl,"P",{});var Dre=s(Jd);Bpr=r(Dre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),hH=n(Dre,"A",{href:!0});var Z5t=s(hH);Ipr=r(Z5t,"from_pretrained()"),Z5t.forEach(t),Npr=r(Dre," class method or the "),pH=n(Dre,"A",{href:!0});var ewt=s(pH);qpr=r(ewt,"from_config()"),ewt.forEach(t),jpr=r(Dre,` class
method.`),Dre.forEach(t),Dpr=i(Cl),p9=n(Cl,"P",{});var Jze=s(p9);Gpr=r(Jze,"This class cannot be instantiated directly using "),g0e=n(Jze,"CODE",{});var owt=s(g0e);Opr=r(owt,"__init__()"),owt.forEach(t),Vpr=r(Jze," (throws an error)."),Jze.forEach(t),Xpr=i(Cl),yt=n(Cl,"DIV",{class:!0});var Rw=s(yt);T(_9.$$.fragment,Rw),zpr=i(Rw),h0e=n(Rw,"P",{});var rwt=s(h0e);Wpr=r(rwt,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),rwt.forEach(t),Qpr=i(Rw),Yd=n(Rw,"P",{});var Gre=s(Yd);Hpr=r(Gre,`Note:
Loading a model from its configuration file does `),p0e=n(Gre,"STRONG",{});var twt=s(p0e);Upr=r(twt,"not"),twt.forEach(t),Jpr=r(Gre,` load the model weights. It only affects the
model\u2019s configuration. Use `),_H=n(Gre,"A",{href:!0});var awt=s(_H);Ypr=r(awt,"from_pretrained()"),awt.forEach(t),Kpr=r(Gre," to load the model weights."),Gre.forEach(t),Zpr=i(Rw),T(jT.$$.fragment,Rw),Rw.forEach(t),e_r=i(Cl),bo=n(Cl,"DIV",{class:!0});var La=s(bo);T(u9.$$.fragment,La),o_r=i(La),_0e=n(La,"P",{});var nwt=s(_0e);r_r=r(nwt,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),nwt.forEach(t),t_r=i(La),rn=n(La,"P",{});var Pw=s(rn);a_r=r(Pw,"The model class to instantiate is selected based on the "),u0e=n(Pw,"CODE",{});var swt=s(u0e);n_r=r(swt,"model_type"),swt.forEach(t),s_r=r(Pw,` property of the config object (either
passed as an argument or loaded from `),b0e=n(Pw,"CODE",{});var lwt=s(b0e);l_r=r(lwt,"pretrained_model_name_or_path"),lwt.forEach(t),i_r=r(Pw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v0e=n(Pw,"CODE",{});var iwt=s(v0e);d_r=r(iwt,"pretrained_model_name_or_path"),iwt.forEach(t),c_r=r(Pw,":"),Pw.forEach(t),f_r=i(La),F0e=n(La,"UL",{});var dwt=s(F0e);DT=n(dwt,"LI",{});var qIe=s(DT);T0e=n(qIe,"STRONG",{});var cwt=s(T0e);m_r=r(cwt,"detr"),cwt.forEach(t),g_r=r(qIe," \u2014 "),uH=n(qIe,"A",{href:!0});var fwt=s(uH);h_r=r(fwt,"DetrForSegmentation"),fwt.forEach(t),p_r=r(qIe," (DETR model)"),qIe.forEach(t),dwt.forEach(t),__r=i(La),GT=n(La,"P",{});var jIe=s(GT);u_r=r(jIe,"The model is set in evaluation mode by default using "),M0e=n(jIe,"CODE",{});var mwt=s(M0e);b_r=r(mwt,"model.eval()"),mwt.forEach(t),v_r=r(jIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),E0e=n(jIe,"CODE",{});var gwt=s(E0e);F_r=r(gwt,"model.train()"),gwt.forEach(t),jIe.forEach(t),T_r=i(La),T(OT.$$.fragment,La),La.forEach(t),Cl.forEach(t),VVe=i(f),Kd=n(f,"H2",{class:!0});var Yze=s(Kd);VT=n(Yze,"A",{id:!0,class:!0,href:!0});var hwt=s(VT);C0e=n(hwt,"SPAN",{});var pwt=s(C0e);T(b9.$$.fragment,pwt),pwt.forEach(t),hwt.forEach(t),M_r=i(Yze),w0e=n(Yze,"SPAN",{});var _wt=s(w0e);E_r=r(_wt,"AutoModelForSemanticSegmentation"),_wt.forEach(t),Yze.forEach(t),XVe=i(f),Ko=n(f,"DIV",{class:!0});var wl=s(Ko);T(v9.$$.fragment,wl),C_r=i(wl),Zd=n(wl,"P",{});var Ore=s(Zd);w_r=r(Ore,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),bH=n(Ore,"A",{href:!0});var uwt=s(bH);A_r=r(uwt,"from_pretrained()"),uwt.forEach(t),L_r=r(Ore," class method or the "),vH=n(Ore,"A",{href:!0});var bwt=s(vH);y_r=r(bwt,"from_config()"),bwt.forEach(t),x_r=r(Ore,` class
method.`),Ore.forEach(t),$_r=i(wl),F9=n(wl,"P",{});var Kze=s(F9);k_r=r(Kze,"This class cannot be instantiated directly using "),A0e=n(Kze,"CODE",{});var vwt=s(A0e);S_r=r(vwt,"__init__()"),vwt.forEach(t),R_r=r(Kze," (throws an error)."),Kze.forEach(t),P_r=i(wl),xt=n(wl,"DIV",{class:!0});var Bw=s(xt);T(T9.$$.fragment,Bw),B_r=i(Bw),L0e=n(Bw,"P",{});var Fwt=s(L0e);I_r=r(Fwt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Fwt.forEach(t),N_r=i(Bw),ec=n(Bw,"P",{});var Vre=s(ec);q_r=r(Vre,`Note:
Loading a model from its configuration file does `),y0e=n(Vre,"STRONG",{});var Twt=s(y0e);j_r=r(Twt,"not"),Twt.forEach(t),D_r=r(Vre,` load the model weights. It only affects the
model\u2019s configuration. Use `),FH=n(Vre,"A",{href:!0});var Mwt=s(FH);G_r=r(Mwt,"from_pretrained()"),Mwt.forEach(t),O_r=r(Vre," to load the model weights."),Vre.forEach(t),V_r=i(Bw),T(XT.$$.fragment,Bw),Bw.forEach(t),X_r=i(wl),vo=n(wl,"DIV",{class:!0});var ya=s(vo);T(M9.$$.fragment,ya),z_r=i(ya),x0e=n(ya,"P",{});var Ewt=s(x0e);W_r=r(Ewt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Ewt.forEach(t),Q_r=i(ya),tn=n(ya,"P",{});var Iw=s(tn);H_r=r(Iw,"The model class to instantiate is selected based on the "),$0e=n(Iw,"CODE",{});var Cwt=s($0e);U_r=r(Cwt,"model_type"),Cwt.forEach(t),J_r=r(Iw,` property of the config object (either
passed as an argument or loaded from `),k0e=n(Iw,"CODE",{});var wwt=s(k0e);Y_r=r(wwt,"pretrained_model_name_or_path"),wwt.forEach(t),K_r=r(Iw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S0e=n(Iw,"CODE",{});var Awt=s(S0e);Z_r=r(Awt,"pretrained_model_name_or_path"),Awt.forEach(t),eur=r(Iw,":"),Iw.forEach(t),our=i(ya),an=n(ya,"UL",{});var Nw=s(an);zT=n(Nw,"LI",{});var DIe=s(zT);R0e=n(DIe,"STRONG",{});var Lwt=s(R0e);rur=r(Lwt,"beit"),Lwt.forEach(t),tur=r(DIe," \u2014 "),TH=n(DIe,"A",{href:!0});var ywt=s(TH);aur=r(ywt,"BeitForSemanticSegmentation"),ywt.forEach(t),nur=r(DIe," (BEiT model)"),DIe.forEach(t),sur=i(Nw),WT=n(Nw,"LI",{});var GIe=s(WT);P0e=n(GIe,"STRONG",{});var xwt=s(P0e);lur=r(xwt,"data2vec-vision"),xwt.forEach(t),iur=r(GIe," \u2014 "),MH=n(GIe,"A",{href:!0});var $wt=s(MH);dur=r($wt,"Data2VecVisionForSemanticSegmentation"),$wt.forEach(t),cur=r(GIe," (Data2VecVision model)"),GIe.forEach(t),fur=i(Nw),QT=n(Nw,"LI",{});var OIe=s(QT);B0e=n(OIe,"STRONG",{});var kwt=s(B0e);mur=r(kwt,"dpt"),kwt.forEach(t),gur=r(OIe," \u2014 "),EH=n(OIe,"A",{href:!0});var Swt=s(EH);hur=r(Swt,"DPTForSemanticSegmentation"),Swt.forEach(t),pur=r(OIe," (DPT model)"),OIe.forEach(t),_ur=i(Nw),HT=n(Nw,"LI",{});var VIe=s(HT);I0e=n(VIe,"STRONG",{});var Rwt=s(I0e);uur=r(Rwt,"segformer"),Rwt.forEach(t),bur=r(VIe," \u2014 "),CH=n(VIe,"A",{href:!0});var Pwt=s(CH);vur=r(Pwt,"SegformerForSemanticSegmentation"),Pwt.forEach(t),Fur=r(VIe," (SegFormer model)"),VIe.forEach(t),Nw.forEach(t),Tur=i(ya),UT=n(ya,"P",{});var XIe=s(UT);Mur=r(XIe,"The model is set in evaluation mode by default using "),N0e=n(XIe,"CODE",{});var Bwt=s(N0e);Eur=r(Bwt,"model.eval()"),Bwt.forEach(t),Cur=r(XIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q0e=n(XIe,"CODE",{});var Iwt=s(q0e);wur=r(Iwt,"model.train()"),Iwt.forEach(t),XIe.forEach(t),Aur=i(ya),T(JT.$$.fragment,ya),ya.forEach(t),wl.forEach(t),zVe=i(f),oc=n(f,"H2",{class:!0});var Zze=s(oc);YT=n(Zze,"A",{id:!0,class:!0,href:!0});var Nwt=s(YT);j0e=n(Nwt,"SPAN",{});var qwt=s(j0e);T(E9.$$.fragment,qwt),qwt.forEach(t),Nwt.forEach(t),Lur=i(Zze),D0e=n(Zze,"SPAN",{});var jwt=s(D0e);yur=r(jwt,"AutoModelForInstanceSegmentation"),jwt.forEach(t),Zze.forEach(t),WVe=i(f),Zo=n(f,"DIV",{class:!0});var Al=s(Zo);T(C9.$$.fragment,Al),xur=i(Al),rc=n(Al,"P",{});var Xre=s(rc);$ur=r(Xre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),wH=n(Xre,"A",{href:!0});var Dwt=s(wH);kur=r(Dwt,"from_pretrained()"),Dwt.forEach(t),Sur=r(Xre," class method or the "),AH=n(Xre,"A",{href:!0});var Gwt=s(AH);Rur=r(Gwt,"from_config()"),Gwt.forEach(t),Pur=r(Xre,` class
method.`),Xre.forEach(t),Bur=i(Al),w9=n(Al,"P",{});var eWe=s(w9);Iur=r(eWe,"This class cannot be instantiated directly using "),G0e=n(eWe,"CODE",{});var Owt=s(G0e);Nur=r(Owt,"__init__()"),Owt.forEach(t),qur=r(eWe," (throws an error)."),eWe.forEach(t),jur=i(Al),$t=n(Al,"DIV",{class:!0});var qw=s($t);T(A9.$$.fragment,qw),Dur=i(qw),O0e=n(qw,"P",{});var Vwt=s(O0e);Gur=r(Vwt,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Vwt.forEach(t),Our=i(qw),tc=n(qw,"P",{});var zre=s(tc);Vur=r(zre,`Note:
Loading a model from its configuration file does `),V0e=n(zre,"STRONG",{});var Xwt=s(V0e);Xur=r(Xwt,"not"),Xwt.forEach(t),zur=r(zre,` load the model weights. It only affects the
model\u2019s configuration. Use `),LH=n(zre,"A",{href:!0});var zwt=s(LH);Wur=r(zwt,"from_pretrained()"),zwt.forEach(t),Qur=r(zre," to load the model weights."),zre.forEach(t),Hur=i(qw),T(KT.$$.fragment,qw),qw.forEach(t),Uur=i(Al),Fo=n(Al,"DIV",{class:!0});var xa=s(Fo);T(L9.$$.fragment,xa),Jur=i(xa),X0e=n(xa,"P",{});var Wwt=s(X0e);Yur=r(Wwt,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Wwt.forEach(t),Kur=i(xa),nn=n(xa,"P",{});var jw=s(nn);Zur=r(jw,"The model class to instantiate is selected based on the "),z0e=n(jw,"CODE",{});var Qwt=s(z0e);e1r=r(Qwt,"model_type"),Qwt.forEach(t),o1r=r(jw,` property of the config object (either
passed as an argument or loaded from `),W0e=n(jw,"CODE",{});var Hwt=s(W0e);r1r=r(Hwt,"pretrained_model_name_or_path"),Hwt.forEach(t),t1r=r(jw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q0e=n(jw,"CODE",{});var Uwt=s(Q0e);a1r=r(Uwt,"pretrained_model_name_or_path"),Uwt.forEach(t),n1r=r(jw,":"),jw.forEach(t),s1r=i(xa),H0e=n(xa,"UL",{});var Jwt=s(H0e);ZT=n(Jwt,"LI",{});var zIe=s(ZT);U0e=n(zIe,"STRONG",{});var Ywt=s(U0e);l1r=r(Ywt,"maskformer"),Ywt.forEach(t),i1r=r(zIe," \u2014 "),yH=n(zIe,"A",{href:!0});var Kwt=s(yH);d1r=r(Kwt,"MaskFormerForInstanceSegmentation"),Kwt.forEach(t),c1r=r(zIe," (MaskFormer model)"),zIe.forEach(t),Jwt.forEach(t),f1r=i(xa),e7=n(xa,"P",{});var WIe=s(e7);m1r=r(WIe,"The model is set in evaluation mode by default using "),J0e=n(WIe,"CODE",{});var Zwt=s(J0e);g1r=r(Zwt,"model.eval()"),Zwt.forEach(t),h1r=r(WIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Y0e=n(WIe,"CODE",{});var eAt=s(Y0e);p1r=r(eAt,"model.train()"),eAt.forEach(t),WIe.forEach(t),_1r=i(xa),T(o7.$$.fragment,xa),xa.forEach(t),Al.forEach(t),QVe=i(f),ac=n(f,"H2",{class:!0});var oWe=s(ac);r7=n(oWe,"A",{id:!0,class:!0,href:!0});var oAt=s(r7);K0e=n(oAt,"SPAN",{});var rAt=s(K0e);T(y9.$$.fragment,rAt),rAt.forEach(t),oAt.forEach(t),u1r=i(oWe),Z0e=n(oWe,"SPAN",{});var tAt=s(Z0e);b1r=r(tAt,"TFAutoModel"),tAt.forEach(t),oWe.forEach(t),HVe=i(f),er=n(f,"DIV",{class:!0});var Ll=s(er);T(x9.$$.fragment,Ll),v1r=i(Ll),nc=n(Ll,"P",{});var Wre=s(nc);F1r=r(Wre,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),xH=n(Wre,"A",{href:!0});var aAt=s(xH);T1r=r(aAt,"from_pretrained()"),aAt.forEach(t),M1r=r(Wre," class method or the "),$H=n(Wre,"A",{href:!0});var nAt=s($H);E1r=r(nAt,"from_config()"),nAt.forEach(t),C1r=r(Wre,` class
method.`),Wre.forEach(t),w1r=i(Ll),$9=n(Ll,"P",{});var rWe=s($9);A1r=r(rWe,"This class cannot be instantiated directly using "),eFe=n(rWe,"CODE",{});var sAt=s(eFe);L1r=r(sAt,"__init__()"),sAt.forEach(t),y1r=r(rWe," (throws an error)."),rWe.forEach(t),x1r=i(Ll),kt=n(Ll,"DIV",{class:!0});var Dw=s(kt);T(k9.$$.fragment,Dw),$1r=i(Dw),oFe=n(Dw,"P",{});var lAt=s(oFe);k1r=r(lAt,"Instantiates one of the base model classes of the library from a configuration."),lAt.forEach(t),S1r=i(Dw),sc=n(Dw,"P",{});var Qre=s(sc);R1r=r(Qre,`Note:
Loading a model from its configuration file does `),rFe=n(Qre,"STRONG",{});var iAt=s(rFe);P1r=r(iAt,"not"),iAt.forEach(t),B1r=r(Qre,` load the model weights. It only affects the
model\u2019s configuration. Use `),kH=n(Qre,"A",{href:!0});var dAt=s(kH);I1r=r(dAt,"from_pretrained()"),dAt.forEach(t),N1r=r(Qre," to load the model weights."),Qre.forEach(t),q1r=i(Dw),T(t7.$$.fragment,Dw),Dw.forEach(t),j1r=i(Ll),xr=n(Ll,"DIV",{class:!0});var yl=s(xr);T(S9.$$.fragment,yl),D1r=i(yl),tFe=n(yl,"P",{});var cAt=s(tFe);G1r=r(cAt,"Instantiate one of the base model classes of the library from a pretrained model."),cAt.forEach(t),O1r=i(yl),sn=n(yl,"P",{});var Gw=s(sn);V1r=r(Gw,"The model class to instantiate is selected based on the "),aFe=n(Gw,"CODE",{});var fAt=s(aFe);X1r=r(fAt,"model_type"),fAt.forEach(t),z1r=r(Gw,` property of the config object (either
passed as an argument or loaded from `),nFe=n(Gw,"CODE",{});var mAt=s(nFe);W1r=r(mAt,"pretrained_model_name_or_path"),mAt.forEach(t),Q1r=r(Gw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sFe=n(Gw,"CODE",{});var gAt=s(sFe);H1r=r(gAt,"pretrained_model_name_or_path"),gAt.forEach(t),U1r=r(Gw,":"),Gw.forEach(t),J1r=i(yl),q=n(yl,"UL",{});var D=s(q);a7=n(D,"LI",{});var QIe=s(a7);lFe=n(QIe,"STRONG",{});var hAt=s(lFe);Y1r=r(hAt,"albert"),hAt.forEach(t),K1r=r(QIe," \u2014 "),SH=n(QIe,"A",{href:!0});var pAt=s(SH);Z1r=r(pAt,"TFAlbertModel"),pAt.forEach(t),e2r=r(QIe," (ALBERT model)"),QIe.forEach(t),o2r=i(D),n7=n(D,"LI",{});var HIe=s(n7);iFe=n(HIe,"STRONG",{});var _At=s(iFe);r2r=r(_At,"bart"),_At.forEach(t),t2r=r(HIe," \u2014 "),RH=n(HIe,"A",{href:!0});var uAt=s(RH);a2r=r(uAt,"TFBartModel"),uAt.forEach(t),n2r=r(HIe," (BART model)"),HIe.forEach(t),s2r=i(D),s7=n(D,"LI",{});var UIe=s(s7);dFe=n(UIe,"STRONG",{});var bAt=s(dFe);l2r=r(bAt,"bert"),bAt.forEach(t),i2r=r(UIe," \u2014 "),PH=n(UIe,"A",{href:!0});var vAt=s(PH);d2r=r(vAt,"TFBertModel"),vAt.forEach(t),c2r=r(UIe," (BERT model)"),UIe.forEach(t),f2r=i(D),l7=n(D,"LI",{});var JIe=s(l7);cFe=n(JIe,"STRONG",{});var FAt=s(cFe);m2r=r(FAt,"blenderbot"),FAt.forEach(t),g2r=r(JIe," \u2014 "),BH=n(JIe,"A",{href:!0});var TAt=s(BH);h2r=r(TAt,"TFBlenderbotModel"),TAt.forEach(t),p2r=r(JIe," (Blenderbot model)"),JIe.forEach(t),_2r=i(D),i7=n(D,"LI",{});var YIe=s(i7);fFe=n(YIe,"STRONG",{});var MAt=s(fFe);u2r=r(MAt,"blenderbot-small"),MAt.forEach(t),b2r=r(YIe," \u2014 "),IH=n(YIe,"A",{href:!0});var EAt=s(IH);v2r=r(EAt,"TFBlenderbotSmallModel"),EAt.forEach(t),F2r=r(YIe," (BlenderbotSmall model)"),YIe.forEach(t),T2r=i(D),d7=n(D,"LI",{});var KIe=s(d7);mFe=n(KIe,"STRONG",{});var CAt=s(mFe);M2r=r(CAt,"camembert"),CAt.forEach(t),E2r=r(KIe," \u2014 "),NH=n(KIe,"A",{href:!0});var wAt=s(NH);C2r=r(wAt,"TFCamembertModel"),wAt.forEach(t),w2r=r(KIe," (CamemBERT model)"),KIe.forEach(t),A2r=i(D),c7=n(D,"LI",{});var ZIe=s(c7);gFe=n(ZIe,"STRONG",{});var AAt=s(gFe);L2r=r(AAt,"clip"),AAt.forEach(t),y2r=r(ZIe," \u2014 "),qH=n(ZIe,"A",{href:!0});var LAt=s(qH);x2r=r(LAt,"TFCLIPModel"),LAt.forEach(t),$2r=r(ZIe," (CLIP model)"),ZIe.forEach(t),k2r=i(D),f7=n(D,"LI",{});var eNe=s(f7);hFe=n(eNe,"STRONG",{});var yAt=s(hFe);S2r=r(yAt,"convbert"),yAt.forEach(t),R2r=r(eNe," \u2014 "),jH=n(eNe,"A",{href:!0});var xAt=s(jH);P2r=r(xAt,"TFConvBertModel"),xAt.forEach(t),B2r=r(eNe," (ConvBERT model)"),eNe.forEach(t),I2r=i(D),m7=n(D,"LI",{});var oNe=s(m7);pFe=n(oNe,"STRONG",{});var $At=s(pFe);N2r=r($At,"convnext"),$At.forEach(t),q2r=r(oNe," \u2014 "),DH=n(oNe,"A",{href:!0});var kAt=s(DH);j2r=r(kAt,"TFConvNextModel"),kAt.forEach(t),D2r=r(oNe," (ConvNeXT model)"),oNe.forEach(t),G2r=i(D),g7=n(D,"LI",{});var rNe=s(g7);_Fe=n(rNe,"STRONG",{});var SAt=s(_Fe);O2r=r(SAt,"ctrl"),SAt.forEach(t),V2r=r(rNe," \u2014 "),GH=n(rNe,"A",{href:!0});var RAt=s(GH);X2r=r(RAt,"TFCTRLModel"),RAt.forEach(t),z2r=r(rNe," (CTRL model)"),rNe.forEach(t),W2r=i(D),h7=n(D,"LI",{});var tNe=s(h7);uFe=n(tNe,"STRONG",{});var PAt=s(uFe);Q2r=r(PAt,"data2vec-vision"),PAt.forEach(t),H2r=r(tNe," \u2014 "),OH=n(tNe,"A",{href:!0});var BAt=s(OH);U2r=r(BAt,"TFData2VecVisionModel"),BAt.forEach(t),J2r=r(tNe," (Data2VecVision model)"),tNe.forEach(t),Y2r=i(D),p7=n(D,"LI",{});var aNe=s(p7);bFe=n(aNe,"STRONG",{});var IAt=s(bFe);K2r=r(IAt,"deberta"),IAt.forEach(t),Z2r=r(aNe," \u2014 "),VH=n(aNe,"A",{href:!0});var NAt=s(VH);ebr=r(NAt,"TFDebertaModel"),NAt.forEach(t),obr=r(aNe," (DeBERTa model)"),aNe.forEach(t),rbr=i(D),_7=n(D,"LI",{});var nNe=s(_7);vFe=n(nNe,"STRONG",{});var qAt=s(vFe);tbr=r(qAt,"deberta-v2"),qAt.forEach(t),abr=r(nNe," \u2014 "),XH=n(nNe,"A",{href:!0});var jAt=s(XH);nbr=r(jAt,"TFDebertaV2Model"),jAt.forEach(t),sbr=r(nNe," (DeBERTa-v2 model)"),nNe.forEach(t),lbr=i(D),u7=n(D,"LI",{});var sNe=s(u7);FFe=n(sNe,"STRONG",{});var DAt=s(FFe);ibr=r(DAt,"deit"),DAt.forEach(t),dbr=r(sNe," \u2014 "),zH=n(sNe,"A",{href:!0});var GAt=s(zH);cbr=r(GAt,"TFDeiTModel"),GAt.forEach(t),fbr=r(sNe," (DeiT model)"),sNe.forEach(t),mbr=i(D),b7=n(D,"LI",{});var lNe=s(b7);TFe=n(lNe,"STRONG",{});var OAt=s(TFe);gbr=r(OAt,"distilbert"),OAt.forEach(t),hbr=r(lNe," \u2014 "),WH=n(lNe,"A",{href:!0});var VAt=s(WH);pbr=r(VAt,"TFDistilBertModel"),VAt.forEach(t),_br=r(lNe," (DistilBERT model)"),lNe.forEach(t),ubr=i(D),v7=n(D,"LI",{});var iNe=s(v7);MFe=n(iNe,"STRONG",{});var XAt=s(MFe);bbr=r(XAt,"dpr"),XAt.forEach(t),vbr=r(iNe," \u2014 "),QH=n(iNe,"A",{href:!0});var zAt=s(QH);Fbr=r(zAt,"TFDPRQuestionEncoder"),zAt.forEach(t),Tbr=r(iNe," (DPR model)"),iNe.forEach(t),Mbr=i(D),F7=n(D,"LI",{});var dNe=s(F7);EFe=n(dNe,"STRONG",{});var WAt=s(EFe);Ebr=r(WAt,"electra"),WAt.forEach(t),Cbr=r(dNe," \u2014 "),HH=n(dNe,"A",{href:!0});var QAt=s(HH);wbr=r(QAt,"TFElectraModel"),QAt.forEach(t),Abr=r(dNe," (ELECTRA model)"),dNe.forEach(t),Lbr=i(D),T7=n(D,"LI",{});var cNe=s(T7);CFe=n(cNe,"STRONG",{});var HAt=s(CFe);ybr=r(HAt,"flaubert"),HAt.forEach(t),xbr=r(cNe," \u2014 "),UH=n(cNe,"A",{href:!0});var UAt=s(UH);$br=r(UAt,"TFFlaubertModel"),UAt.forEach(t),kbr=r(cNe," (FlauBERT model)"),cNe.forEach(t),Sbr=i(D),Us=n(D,"LI",{});var _S=s(Us);wFe=n(_S,"STRONG",{});var JAt=s(wFe);Rbr=r(JAt,"funnel"),JAt.forEach(t),Pbr=r(_S," \u2014 "),JH=n(_S,"A",{href:!0});var YAt=s(JH);Bbr=r(YAt,"TFFunnelModel"),YAt.forEach(t),Ibr=r(_S," or "),YH=n(_S,"A",{href:!0});var KAt=s(YH);Nbr=r(KAt,"TFFunnelBaseModel"),KAt.forEach(t),qbr=r(_S," (Funnel Transformer model)"),_S.forEach(t),jbr=i(D),M7=n(D,"LI",{});var fNe=s(M7);AFe=n(fNe,"STRONG",{});var ZAt=s(AFe);Dbr=r(ZAt,"gpt2"),ZAt.forEach(t),Gbr=r(fNe," \u2014 "),KH=n(fNe,"A",{href:!0});var eLt=s(KH);Obr=r(eLt,"TFGPT2Model"),eLt.forEach(t),Vbr=r(fNe," (OpenAI GPT-2 model)"),fNe.forEach(t),Xbr=i(D),E7=n(D,"LI",{});var mNe=s(E7);LFe=n(mNe,"STRONG",{});var oLt=s(LFe);zbr=r(oLt,"gptj"),oLt.forEach(t),Wbr=r(mNe," \u2014 "),ZH=n(mNe,"A",{href:!0});var rLt=s(ZH);Qbr=r(rLt,"TFGPTJModel"),rLt.forEach(t),Hbr=r(mNe," (GPT-J model)"),mNe.forEach(t),Ubr=i(D),C7=n(D,"LI",{});var gNe=s(C7);yFe=n(gNe,"STRONG",{});var tLt=s(yFe);Jbr=r(tLt,"hubert"),tLt.forEach(t),Ybr=r(gNe," \u2014 "),eU=n(gNe,"A",{href:!0});var aLt=s(eU);Kbr=r(aLt,"TFHubertModel"),aLt.forEach(t),Zbr=r(gNe," (Hubert model)"),gNe.forEach(t),evr=i(D),w7=n(D,"LI",{});var hNe=s(w7);xFe=n(hNe,"STRONG",{});var nLt=s(xFe);ovr=r(nLt,"layoutlm"),nLt.forEach(t),rvr=r(hNe," \u2014 "),oU=n(hNe,"A",{href:!0});var sLt=s(oU);tvr=r(sLt,"TFLayoutLMModel"),sLt.forEach(t),avr=r(hNe," (LayoutLM model)"),hNe.forEach(t),nvr=i(D),A7=n(D,"LI",{});var pNe=s(A7);$Fe=n(pNe,"STRONG",{});var lLt=s($Fe);svr=r(lLt,"led"),lLt.forEach(t),lvr=r(pNe," \u2014 "),rU=n(pNe,"A",{href:!0});var iLt=s(rU);ivr=r(iLt,"TFLEDModel"),iLt.forEach(t),dvr=r(pNe," (LED model)"),pNe.forEach(t),cvr=i(D),L7=n(D,"LI",{});var _Ne=s(L7);kFe=n(_Ne,"STRONG",{});var dLt=s(kFe);fvr=r(dLt,"longformer"),dLt.forEach(t),mvr=r(_Ne," \u2014 "),tU=n(_Ne,"A",{href:!0});var cLt=s(tU);gvr=r(cLt,"TFLongformerModel"),cLt.forEach(t),hvr=r(_Ne," (Longformer model)"),_Ne.forEach(t),pvr=i(D),y7=n(D,"LI",{});var uNe=s(y7);SFe=n(uNe,"STRONG",{});var fLt=s(SFe);_vr=r(fLt,"lxmert"),fLt.forEach(t),uvr=r(uNe," \u2014 "),aU=n(uNe,"A",{href:!0});var mLt=s(aU);bvr=r(mLt,"TFLxmertModel"),mLt.forEach(t),vvr=r(uNe," (LXMERT model)"),uNe.forEach(t),Fvr=i(D),x7=n(D,"LI",{});var bNe=s(x7);RFe=n(bNe,"STRONG",{});var gLt=s(RFe);Tvr=r(gLt,"marian"),gLt.forEach(t),Mvr=r(bNe," \u2014 "),nU=n(bNe,"A",{href:!0});var hLt=s(nU);Evr=r(hLt,"TFMarianModel"),hLt.forEach(t),Cvr=r(bNe," (Marian model)"),bNe.forEach(t),wvr=i(D),$7=n(D,"LI",{});var vNe=s($7);PFe=n(vNe,"STRONG",{});var pLt=s(PFe);Avr=r(pLt,"mbart"),pLt.forEach(t),Lvr=r(vNe," \u2014 "),sU=n(vNe,"A",{href:!0});var _Lt=s(sU);yvr=r(_Lt,"TFMBartModel"),_Lt.forEach(t),xvr=r(vNe," (mBART model)"),vNe.forEach(t),$vr=i(D),k7=n(D,"LI",{});var FNe=s(k7);BFe=n(FNe,"STRONG",{});var uLt=s(BFe);kvr=r(uLt,"mobilebert"),uLt.forEach(t),Svr=r(FNe," \u2014 "),lU=n(FNe,"A",{href:!0});var bLt=s(lU);Rvr=r(bLt,"TFMobileBertModel"),bLt.forEach(t),Pvr=r(FNe," (MobileBERT model)"),FNe.forEach(t),Bvr=i(D),S7=n(D,"LI",{});var TNe=s(S7);IFe=n(TNe,"STRONG",{});var vLt=s(IFe);Ivr=r(vLt,"mpnet"),vLt.forEach(t),Nvr=r(TNe," \u2014 "),iU=n(TNe,"A",{href:!0});var FLt=s(iU);qvr=r(FLt,"TFMPNetModel"),FLt.forEach(t),jvr=r(TNe," (MPNet model)"),TNe.forEach(t),Dvr=i(D),R7=n(D,"LI",{});var MNe=s(R7);NFe=n(MNe,"STRONG",{});var TLt=s(NFe);Gvr=r(TLt,"mt5"),TLt.forEach(t),Ovr=r(MNe," \u2014 "),dU=n(MNe,"A",{href:!0});var MLt=s(dU);Vvr=r(MLt,"TFMT5Model"),MLt.forEach(t),Xvr=r(MNe," (MT5 model)"),MNe.forEach(t),zvr=i(D),P7=n(D,"LI",{});var ENe=s(P7);qFe=n(ENe,"STRONG",{});var ELt=s(qFe);Wvr=r(ELt,"openai-gpt"),ELt.forEach(t),Qvr=r(ENe," \u2014 "),cU=n(ENe,"A",{href:!0});var CLt=s(cU);Hvr=r(CLt,"TFOpenAIGPTModel"),CLt.forEach(t),Uvr=r(ENe," (OpenAI GPT model)"),ENe.forEach(t),Jvr=i(D),B7=n(D,"LI",{});var CNe=s(B7);jFe=n(CNe,"STRONG",{});var wLt=s(jFe);Yvr=r(wLt,"opt"),wLt.forEach(t),Kvr=r(CNe," \u2014 "),fU=n(CNe,"A",{href:!0});var ALt=s(fU);Zvr=r(ALt,"TFOPTModel"),ALt.forEach(t),e0r=r(CNe," (OPT model)"),CNe.forEach(t),o0r=i(D),I7=n(D,"LI",{});var wNe=s(I7);DFe=n(wNe,"STRONG",{});var LLt=s(DFe);r0r=r(LLt,"pegasus"),LLt.forEach(t),t0r=r(wNe," \u2014 "),mU=n(wNe,"A",{href:!0});var yLt=s(mU);a0r=r(yLt,"TFPegasusModel"),yLt.forEach(t),n0r=r(wNe," (Pegasus model)"),wNe.forEach(t),s0r=i(D),N7=n(D,"LI",{});var ANe=s(N7);GFe=n(ANe,"STRONG",{});var xLt=s(GFe);l0r=r(xLt,"regnet"),xLt.forEach(t),i0r=r(ANe," \u2014 "),gU=n(ANe,"A",{href:!0});var $Lt=s(gU);d0r=r($Lt,"TFRegNetModel"),$Lt.forEach(t),c0r=r(ANe," (RegNet model)"),ANe.forEach(t),f0r=i(D),q7=n(D,"LI",{});var LNe=s(q7);OFe=n(LNe,"STRONG",{});var kLt=s(OFe);m0r=r(kLt,"rembert"),kLt.forEach(t),g0r=r(LNe," \u2014 "),hU=n(LNe,"A",{href:!0});var SLt=s(hU);h0r=r(SLt,"TFRemBertModel"),SLt.forEach(t),p0r=r(LNe," (RemBERT model)"),LNe.forEach(t),_0r=i(D),j7=n(D,"LI",{});var yNe=s(j7);VFe=n(yNe,"STRONG",{});var RLt=s(VFe);u0r=r(RLt,"roberta"),RLt.forEach(t),b0r=r(yNe," \u2014 "),pU=n(yNe,"A",{href:!0});var PLt=s(pU);v0r=r(PLt,"TFRobertaModel"),PLt.forEach(t),F0r=r(yNe," (RoBERTa model)"),yNe.forEach(t),T0r=i(D),D7=n(D,"LI",{});var xNe=s(D7);XFe=n(xNe,"STRONG",{});var BLt=s(XFe);M0r=r(BLt,"roformer"),BLt.forEach(t),E0r=r(xNe," \u2014 "),_U=n(xNe,"A",{href:!0});var ILt=s(_U);C0r=r(ILt,"TFRoFormerModel"),ILt.forEach(t),w0r=r(xNe," (RoFormer model)"),xNe.forEach(t),A0r=i(D),G7=n(D,"LI",{});var $Ne=s(G7);zFe=n($Ne,"STRONG",{});var NLt=s(zFe);L0r=r(NLt,"speech_to_text"),NLt.forEach(t),y0r=r($Ne," \u2014 "),uU=n($Ne,"A",{href:!0});var qLt=s(uU);x0r=r(qLt,"TFSpeech2TextModel"),qLt.forEach(t),$0r=r($Ne," (Speech2Text model)"),$Ne.forEach(t),k0r=i(D),O7=n(D,"LI",{});var kNe=s(O7);WFe=n(kNe,"STRONG",{});var jLt=s(WFe);S0r=r(jLt,"swin"),jLt.forEach(t),R0r=r(kNe," \u2014 "),bU=n(kNe,"A",{href:!0});var DLt=s(bU);P0r=r(DLt,"TFSwinModel"),DLt.forEach(t),B0r=r(kNe," (Swin Transformer model)"),kNe.forEach(t),I0r=i(D),V7=n(D,"LI",{});var SNe=s(V7);QFe=n(SNe,"STRONG",{});var GLt=s(QFe);N0r=r(GLt,"t5"),GLt.forEach(t),q0r=r(SNe," \u2014 "),vU=n(SNe,"A",{href:!0});var OLt=s(vU);j0r=r(OLt,"TFT5Model"),OLt.forEach(t),D0r=r(SNe," (T5 model)"),SNe.forEach(t),G0r=i(D),X7=n(D,"LI",{});var RNe=s(X7);HFe=n(RNe,"STRONG",{});var VLt=s(HFe);O0r=r(VLt,"tapas"),VLt.forEach(t),V0r=r(RNe," \u2014 "),FU=n(RNe,"A",{href:!0});var XLt=s(FU);X0r=r(XLt,"TFTapasModel"),XLt.forEach(t),z0r=r(RNe," (TAPAS model)"),RNe.forEach(t),W0r=i(D),z7=n(D,"LI",{});var PNe=s(z7);UFe=n(PNe,"STRONG",{});var zLt=s(UFe);Q0r=r(zLt,"transfo-xl"),zLt.forEach(t),H0r=r(PNe," \u2014 "),TU=n(PNe,"A",{href:!0});var WLt=s(TU);U0r=r(WLt,"TFTransfoXLModel"),WLt.forEach(t),J0r=r(PNe," (Transformer-XL model)"),PNe.forEach(t),Y0r=i(D),W7=n(D,"LI",{});var BNe=s(W7);JFe=n(BNe,"STRONG",{});var QLt=s(JFe);K0r=r(QLt,"vit"),QLt.forEach(t),Z0r=r(BNe," \u2014 "),MU=n(BNe,"A",{href:!0});var HLt=s(MU);eFr=r(HLt,"TFViTModel"),HLt.forEach(t),oFr=r(BNe," (ViT model)"),BNe.forEach(t),rFr=i(D),Q7=n(D,"LI",{});var INe=s(Q7);YFe=n(INe,"STRONG",{});var ULt=s(YFe);tFr=r(ULt,"vit_mae"),ULt.forEach(t),aFr=r(INe," \u2014 "),EU=n(INe,"A",{href:!0});var JLt=s(EU);nFr=r(JLt,"TFViTMAEModel"),JLt.forEach(t),sFr=r(INe," (ViTMAE model)"),INe.forEach(t),lFr=i(D),H7=n(D,"LI",{});var NNe=s(H7);KFe=n(NNe,"STRONG",{});var YLt=s(KFe);iFr=r(YLt,"wav2vec2"),YLt.forEach(t),dFr=r(NNe," \u2014 "),CU=n(NNe,"A",{href:!0});var KLt=s(CU);cFr=r(KLt,"TFWav2Vec2Model"),KLt.forEach(t),fFr=r(NNe," (Wav2Vec2 model)"),NNe.forEach(t),mFr=i(D),U7=n(D,"LI",{});var qNe=s(U7);ZFe=n(qNe,"STRONG",{});var ZLt=s(ZFe);gFr=r(ZLt,"xlm"),ZLt.forEach(t),hFr=r(qNe," \u2014 "),wU=n(qNe,"A",{href:!0});var eyt=s(wU);pFr=r(eyt,"TFXLMModel"),eyt.forEach(t),_Fr=r(qNe," (XLM model)"),qNe.forEach(t),uFr=i(D),J7=n(D,"LI",{});var jNe=s(J7);e6e=n(jNe,"STRONG",{});var oyt=s(e6e);bFr=r(oyt,"xlm-roberta"),oyt.forEach(t),vFr=r(jNe," \u2014 "),AU=n(jNe,"A",{href:!0});var ryt=s(AU);FFr=r(ryt,"TFXLMRobertaModel"),ryt.forEach(t),TFr=r(jNe," (XLM-RoBERTa model)"),jNe.forEach(t),MFr=i(D),Y7=n(D,"LI",{});var DNe=s(Y7);o6e=n(DNe,"STRONG",{});var tyt=s(o6e);EFr=r(tyt,"xlnet"),tyt.forEach(t),CFr=r(DNe," \u2014 "),LU=n(DNe,"A",{href:!0});var ayt=s(LU);wFr=r(ayt,"TFXLNetModel"),ayt.forEach(t),AFr=r(DNe," (XLNet model)"),DNe.forEach(t),D.forEach(t),LFr=i(yl),T(K7.$$.fragment,yl),yl.forEach(t),Ll.forEach(t),UVe=i(f),lc=n(f,"H2",{class:!0});var tWe=s(lc);Z7=n(tWe,"A",{id:!0,class:!0,href:!0});var nyt=s(Z7);r6e=n(nyt,"SPAN",{});var syt=s(r6e);T(R9.$$.fragment,syt),syt.forEach(t),nyt.forEach(t),yFr=i(tWe),t6e=n(tWe,"SPAN",{});var lyt=s(t6e);xFr=r(lyt,"TFAutoModelForPreTraining"),lyt.forEach(t),tWe.forEach(t),JVe=i(f),or=n(f,"DIV",{class:!0});var xl=s(or);T(P9.$$.fragment,xl),$Fr=i(xl),ic=n(xl,"P",{});var Hre=s(ic);kFr=r(Hre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),yU=n(Hre,"A",{href:!0});var iyt=s(yU);SFr=r(iyt,"from_pretrained()"),iyt.forEach(t),RFr=r(Hre," class method or the "),xU=n(Hre,"A",{href:!0});var dyt=s(xU);PFr=r(dyt,"from_config()"),dyt.forEach(t),BFr=r(Hre,` class
method.`),Hre.forEach(t),IFr=i(xl),B9=n(xl,"P",{});var aWe=s(B9);NFr=r(aWe,"This class cannot be instantiated directly using "),a6e=n(aWe,"CODE",{});var cyt=s(a6e);qFr=r(cyt,"__init__()"),cyt.forEach(t),jFr=r(aWe," (throws an error)."),aWe.forEach(t),DFr=i(xl),St=n(xl,"DIV",{class:!0});var Ow=s(St);T(I9.$$.fragment,Ow),GFr=i(Ow),n6e=n(Ow,"P",{});var fyt=s(n6e);OFr=r(fyt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),fyt.forEach(t),VFr=i(Ow),dc=n(Ow,"P",{});var Ure=s(dc);XFr=r(Ure,`Note:
Loading a model from its configuration file does `),s6e=n(Ure,"STRONG",{});var myt=s(s6e);zFr=r(myt,"not"),myt.forEach(t),WFr=r(Ure,` load the model weights. It only affects the
model\u2019s configuration. Use `),$U=n(Ure,"A",{href:!0});var gyt=s($U);QFr=r(gyt,"from_pretrained()"),gyt.forEach(t),HFr=r(Ure," to load the model weights."),Ure.forEach(t),UFr=i(Ow),T(e8.$$.fragment,Ow),Ow.forEach(t),JFr=i(xl),$r=n(xl,"DIV",{class:!0});var $l=s($r);T(N9.$$.fragment,$l),YFr=i($l),l6e=n($l,"P",{});var hyt=s(l6e);KFr=r(hyt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),hyt.forEach(t),ZFr=i($l),ln=n($l,"P",{});var Vw=s(ln);e6r=r(Vw,"The model class to instantiate is selected based on the "),i6e=n(Vw,"CODE",{});var pyt=s(i6e);o6r=r(pyt,"model_type"),pyt.forEach(t),r6r=r(Vw,` property of the config object (either
passed as an argument or loaded from `),d6e=n(Vw,"CODE",{});var _yt=s(d6e);t6r=r(_yt,"pretrained_model_name_or_path"),_yt.forEach(t),a6r=r(Vw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c6e=n(Vw,"CODE",{});var uyt=s(c6e);n6r=r(uyt,"pretrained_model_name_or_path"),uyt.forEach(t),s6r=r(Vw,":"),Vw.forEach(t),l6r=i($l),se=n($l,"UL",{});var le=s(se);o8=n(le,"LI",{});var GNe=s(o8);f6e=n(GNe,"STRONG",{});var byt=s(f6e);i6r=r(byt,"albert"),byt.forEach(t),d6r=r(GNe," \u2014 "),kU=n(GNe,"A",{href:!0});var vyt=s(kU);c6r=r(vyt,"TFAlbertForPreTraining"),vyt.forEach(t),f6r=r(GNe," (ALBERT model)"),GNe.forEach(t),m6r=i(le),r8=n(le,"LI",{});var ONe=s(r8);m6e=n(ONe,"STRONG",{});var Fyt=s(m6e);g6r=r(Fyt,"bart"),Fyt.forEach(t),h6r=r(ONe," \u2014 "),SU=n(ONe,"A",{href:!0});var Tyt=s(SU);p6r=r(Tyt,"TFBartForConditionalGeneration"),Tyt.forEach(t),_6r=r(ONe," (BART model)"),ONe.forEach(t),u6r=i(le),t8=n(le,"LI",{});var VNe=s(t8);g6e=n(VNe,"STRONG",{});var Myt=s(g6e);b6r=r(Myt,"bert"),Myt.forEach(t),v6r=r(VNe," \u2014 "),RU=n(VNe,"A",{href:!0});var Eyt=s(RU);F6r=r(Eyt,"TFBertForPreTraining"),Eyt.forEach(t),T6r=r(VNe," (BERT model)"),VNe.forEach(t),M6r=i(le),a8=n(le,"LI",{});var XNe=s(a8);h6e=n(XNe,"STRONG",{});var Cyt=s(h6e);E6r=r(Cyt,"camembert"),Cyt.forEach(t),C6r=r(XNe," \u2014 "),PU=n(XNe,"A",{href:!0});var wyt=s(PU);w6r=r(wyt,"TFCamembertForMaskedLM"),wyt.forEach(t),A6r=r(XNe," (CamemBERT model)"),XNe.forEach(t),L6r=i(le),n8=n(le,"LI",{});var zNe=s(n8);p6e=n(zNe,"STRONG",{});var Ayt=s(p6e);y6r=r(Ayt,"ctrl"),Ayt.forEach(t),x6r=r(zNe," \u2014 "),BU=n(zNe,"A",{href:!0});var Lyt=s(BU);$6r=r(Lyt,"TFCTRLLMHeadModel"),Lyt.forEach(t),k6r=r(zNe," (CTRL model)"),zNe.forEach(t),S6r=i(le),s8=n(le,"LI",{});var WNe=s(s8);_6e=n(WNe,"STRONG",{});var yyt=s(_6e);R6r=r(yyt,"distilbert"),yyt.forEach(t),P6r=r(WNe," \u2014 "),IU=n(WNe,"A",{href:!0});var xyt=s(IU);B6r=r(xyt,"TFDistilBertForMaskedLM"),xyt.forEach(t),I6r=r(WNe," (DistilBERT model)"),WNe.forEach(t),N6r=i(le),l8=n(le,"LI",{});var QNe=s(l8);u6e=n(QNe,"STRONG",{});var $yt=s(u6e);q6r=r($yt,"electra"),$yt.forEach(t),j6r=r(QNe," \u2014 "),NU=n(QNe,"A",{href:!0});var kyt=s(NU);D6r=r(kyt,"TFElectraForPreTraining"),kyt.forEach(t),G6r=r(QNe," (ELECTRA model)"),QNe.forEach(t),O6r=i(le),i8=n(le,"LI",{});var HNe=s(i8);b6e=n(HNe,"STRONG",{});var Syt=s(b6e);V6r=r(Syt,"flaubert"),Syt.forEach(t),X6r=r(HNe," \u2014 "),qU=n(HNe,"A",{href:!0});var Ryt=s(qU);z6r=r(Ryt,"TFFlaubertWithLMHeadModel"),Ryt.forEach(t),W6r=r(HNe," (FlauBERT model)"),HNe.forEach(t),Q6r=i(le),d8=n(le,"LI",{});var UNe=s(d8);v6e=n(UNe,"STRONG",{});var Pyt=s(v6e);H6r=r(Pyt,"funnel"),Pyt.forEach(t),U6r=r(UNe," \u2014 "),jU=n(UNe,"A",{href:!0});var Byt=s(jU);J6r=r(Byt,"TFFunnelForPreTraining"),Byt.forEach(t),Y6r=r(UNe," (Funnel Transformer model)"),UNe.forEach(t),K6r=i(le),c8=n(le,"LI",{});var JNe=s(c8);F6e=n(JNe,"STRONG",{});var Iyt=s(F6e);Z6r=r(Iyt,"gpt2"),Iyt.forEach(t),eTr=r(JNe," \u2014 "),DU=n(JNe,"A",{href:!0});var Nyt=s(DU);oTr=r(Nyt,"TFGPT2LMHeadModel"),Nyt.forEach(t),rTr=r(JNe," (OpenAI GPT-2 model)"),JNe.forEach(t),tTr=i(le),f8=n(le,"LI",{});var YNe=s(f8);T6e=n(YNe,"STRONG",{});var qyt=s(T6e);aTr=r(qyt,"layoutlm"),qyt.forEach(t),nTr=r(YNe," \u2014 "),GU=n(YNe,"A",{href:!0});var jyt=s(GU);sTr=r(jyt,"TFLayoutLMForMaskedLM"),jyt.forEach(t),lTr=r(YNe," (LayoutLM model)"),YNe.forEach(t),iTr=i(le),m8=n(le,"LI",{});var KNe=s(m8);M6e=n(KNe,"STRONG",{});var Dyt=s(M6e);dTr=r(Dyt,"lxmert"),Dyt.forEach(t),cTr=r(KNe," \u2014 "),OU=n(KNe,"A",{href:!0});var Gyt=s(OU);fTr=r(Gyt,"TFLxmertForPreTraining"),Gyt.forEach(t),mTr=r(KNe," (LXMERT model)"),KNe.forEach(t),gTr=i(le),g8=n(le,"LI",{});var ZNe=s(g8);E6e=n(ZNe,"STRONG",{});var Oyt=s(E6e);hTr=r(Oyt,"mobilebert"),Oyt.forEach(t),pTr=r(ZNe," \u2014 "),VU=n(ZNe,"A",{href:!0});var Vyt=s(VU);_Tr=r(Vyt,"TFMobileBertForPreTraining"),Vyt.forEach(t),uTr=r(ZNe," (MobileBERT model)"),ZNe.forEach(t),bTr=i(le),h8=n(le,"LI",{});var eqe=s(h8);C6e=n(eqe,"STRONG",{});var Xyt=s(C6e);vTr=r(Xyt,"mpnet"),Xyt.forEach(t),FTr=r(eqe," \u2014 "),XU=n(eqe,"A",{href:!0});var zyt=s(XU);TTr=r(zyt,"TFMPNetForMaskedLM"),zyt.forEach(t),MTr=r(eqe," (MPNet model)"),eqe.forEach(t),ETr=i(le),p8=n(le,"LI",{});var oqe=s(p8);w6e=n(oqe,"STRONG",{});var Wyt=s(w6e);CTr=r(Wyt,"openai-gpt"),Wyt.forEach(t),wTr=r(oqe," \u2014 "),zU=n(oqe,"A",{href:!0});var Qyt=s(zU);ATr=r(Qyt,"TFOpenAIGPTLMHeadModel"),Qyt.forEach(t),LTr=r(oqe," (OpenAI GPT model)"),oqe.forEach(t),yTr=i(le),_8=n(le,"LI",{});var rqe=s(_8);A6e=n(rqe,"STRONG",{});var Hyt=s(A6e);xTr=r(Hyt,"roberta"),Hyt.forEach(t),$Tr=r(rqe," \u2014 "),WU=n(rqe,"A",{href:!0});var Uyt=s(WU);kTr=r(Uyt,"TFRobertaForMaskedLM"),Uyt.forEach(t),STr=r(rqe," (RoBERTa model)"),rqe.forEach(t),RTr=i(le),u8=n(le,"LI",{});var tqe=s(u8);L6e=n(tqe,"STRONG",{});var Jyt=s(L6e);PTr=r(Jyt,"t5"),Jyt.forEach(t),BTr=r(tqe," \u2014 "),QU=n(tqe,"A",{href:!0});var Yyt=s(QU);ITr=r(Yyt,"TFT5ForConditionalGeneration"),Yyt.forEach(t),NTr=r(tqe," (T5 model)"),tqe.forEach(t),qTr=i(le),b8=n(le,"LI",{});var aqe=s(b8);y6e=n(aqe,"STRONG",{});var Kyt=s(y6e);jTr=r(Kyt,"tapas"),Kyt.forEach(t),DTr=r(aqe," \u2014 "),HU=n(aqe,"A",{href:!0});var Zyt=s(HU);GTr=r(Zyt,"TFTapasForMaskedLM"),Zyt.forEach(t),OTr=r(aqe," (TAPAS model)"),aqe.forEach(t),VTr=i(le),v8=n(le,"LI",{});var nqe=s(v8);x6e=n(nqe,"STRONG",{});var e9t=s(x6e);XTr=r(e9t,"transfo-xl"),e9t.forEach(t),zTr=r(nqe," \u2014 "),UU=n(nqe,"A",{href:!0});var o9t=s(UU);WTr=r(o9t,"TFTransfoXLLMHeadModel"),o9t.forEach(t),QTr=r(nqe," (Transformer-XL model)"),nqe.forEach(t),HTr=i(le),F8=n(le,"LI",{});var sqe=s(F8);$6e=n(sqe,"STRONG",{});var r9t=s($6e);UTr=r(r9t,"vit_mae"),r9t.forEach(t),JTr=r(sqe," \u2014 "),JU=n(sqe,"A",{href:!0});var t9t=s(JU);YTr=r(t9t,"TFViTMAEForPreTraining"),t9t.forEach(t),KTr=r(sqe," (ViTMAE model)"),sqe.forEach(t),ZTr=i(le),T8=n(le,"LI",{});var lqe=s(T8);k6e=n(lqe,"STRONG",{});var a9t=s(k6e);e7r=r(a9t,"xlm"),a9t.forEach(t),o7r=r(lqe," \u2014 "),YU=n(lqe,"A",{href:!0});var n9t=s(YU);r7r=r(n9t,"TFXLMWithLMHeadModel"),n9t.forEach(t),t7r=r(lqe," (XLM model)"),lqe.forEach(t),a7r=i(le),M8=n(le,"LI",{});var iqe=s(M8);S6e=n(iqe,"STRONG",{});var s9t=s(S6e);n7r=r(s9t,"xlm-roberta"),s9t.forEach(t),s7r=r(iqe," \u2014 "),KU=n(iqe,"A",{href:!0});var l9t=s(KU);l7r=r(l9t,"TFXLMRobertaForMaskedLM"),l9t.forEach(t),i7r=r(iqe," (XLM-RoBERTa model)"),iqe.forEach(t),d7r=i(le),E8=n(le,"LI",{});var dqe=s(E8);R6e=n(dqe,"STRONG",{});var i9t=s(R6e);c7r=r(i9t,"xlnet"),i9t.forEach(t),f7r=r(dqe," \u2014 "),ZU=n(dqe,"A",{href:!0});var d9t=s(ZU);m7r=r(d9t,"TFXLNetLMHeadModel"),d9t.forEach(t),g7r=r(dqe," (XLNet model)"),dqe.forEach(t),le.forEach(t),h7r=i($l),T(C8.$$.fragment,$l),$l.forEach(t),xl.forEach(t),YVe=i(f),cc=n(f,"H2",{class:!0});var nWe=s(cc);w8=n(nWe,"A",{id:!0,class:!0,href:!0});var c9t=s(w8);P6e=n(c9t,"SPAN",{});var f9t=s(P6e);T(q9.$$.fragment,f9t),f9t.forEach(t),c9t.forEach(t),p7r=i(nWe),B6e=n(nWe,"SPAN",{});var m9t=s(B6e);_7r=r(m9t,"TFAutoModelForCausalLM"),m9t.forEach(t),nWe.forEach(t),KVe=i(f),rr=n(f,"DIV",{class:!0});var kl=s(rr);T(j9.$$.fragment,kl),u7r=i(kl),fc=n(kl,"P",{});var Jre=s(fc);b7r=r(Jre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),eJ=n(Jre,"A",{href:!0});var g9t=s(eJ);v7r=r(g9t,"from_pretrained()"),g9t.forEach(t),F7r=r(Jre," class method or the "),oJ=n(Jre,"A",{href:!0});var h9t=s(oJ);T7r=r(h9t,"from_config()"),h9t.forEach(t),M7r=r(Jre,` class
method.`),Jre.forEach(t),E7r=i(kl),D9=n(kl,"P",{});var sWe=s(D9);C7r=r(sWe,"This class cannot be instantiated directly using "),I6e=n(sWe,"CODE",{});var p9t=s(I6e);w7r=r(p9t,"__init__()"),p9t.forEach(t),A7r=r(sWe," (throws an error)."),sWe.forEach(t),L7r=i(kl),Rt=n(kl,"DIV",{class:!0});var Xw=s(Rt);T(G9.$$.fragment,Xw),y7r=i(Xw),N6e=n(Xw,"P",{});var _9t=s(N6e);x7r=r(_9t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),_9t.forEach(t),$7r=i(Xw),mc=n(Xw,"P",{});var Yre=s(mc);k7r=r(Yre,`Note:
Loading a model from its configuration file does `),q6e=n(Yre,"STRONG",{});var u9t=s(q6e);S7r=r(u9t,"not"),u9t.forEach(t),R7r=r(Yre,` load the model weights. It only affects the
model\u2019s configuration. Use `),rJ=n(Yre,"A",{href:!0});var b9t=s(rJ);P7r=r(b9t,"from_pretrained()"),b9t.forEach(t),B7r=r(Yre," to load the model weights."),Yre.forEach(t),I7r=i(Xw),T(A8.$$.fragment,Xw),Xw.forEach(t),N7r=i(kl),kr=n(kl,"DIV",{class:!0});var Sl=s(kr);T(O9.$$.fragment,Sl),q7r=i(Sl),j6e=n(Sl,"P",{});var v9t=s(j6e);j7r=r(v9t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),v9t.forEach(t),D7r=i(Sl),dn=n(Sl,"P",{});var zw=s(dn);G7r=r(zw,"The model class to instantiate is selected based on the "),D6e=n(zw,"CODE",{});var F9t=s(D6e);O7r=r(F9t,"model_type"),F9t.forEach(t),V7r=r(zw,` property of the config object (either
passed as an argument or loaded from `),G6e=n(zw,"CODE",{});var T9t=s(G6e);X7r=r(T9t,"pretrained_model_name_or_path"),T9t.forEach(t),z7r=r(zw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O6e=n(zw,"CODE",{});var M9t=s(O6e);W7r=r(M9t,"pretrained_model_name_or_path"),M9t.forEach(t),Q7r=r(zw,":"),zw.forEach(t),H7r=i(Sl),Me=n(Sl,"UL",{});var Ce=s(Me);L8=n(Ce,"LI",{});var cqe=s(L8);V6e=n(cqe,"STRONG",{});var E9t=s(V6e);U7r=r(E9t,"bert"),E9t.forEach(t),J7r=r(cqe," \u2014 "),tJ=n(cqe,"A",{href:!0});var C9t=s(tJ);Y7r=r(C9t,"TFBertLMHeadModel"),C9t.forEach(t),K7r=r(cqe," (BERT model)"),cqe.forEach(t),Z7r=i(Ce),y8=n(Ce,"LI",{});var fqe=s(y8);X6e=n(fqe,"STRONG",{});var w9t=s(X6e);e8r=r(w9t,"camembert"),w9t.forEach(t),o8r=r(fqe," \u2014 "),aJ=n(fqe,"A",{href:!0});var A9t=s(aJ);r8r=r(A9t,"TFCamembertForCausalLM"),A9t.forEach(t),t8r=r(fqe," (CamemBERT model)"),fqe.forEach(t),a8r=i(Ce),x8=n(Ce,"LI",{});var mqe=s(x8);z6e=n(mqe,"STRONG",{});var L9t=s(z6e);n8r=r(L9t,"ctrl"),L9t.forEach(t),s8r=r(mqe," \u2014 "),nJ=n(mqe,"A",{href:!0});var y9t=s(nJ);l8r=r(y9t,"TFCTRLLMHeadModel"),y9t.forEach(t),i8r=r(mqe," (CTRL model)"),mqe.forEach(t),d8r=i(Ce),$8=n(Ce,"LI",{});var gqe=s($8);W6e=n(gqe,"STRONG",{});var x9t=s(W6e);c8r=r(x9t,"gpt2"),x9t.forEach(t),f8r=r(gqe," \u2014 "),sJ=n(gqe,"A",{href:!0});var $9t=s(sJ);m8r=r($9t,"TFGPT2LMHeadModel"),$9t.forEach(t),g8r=r(gqe," (OpenAI GPT-2 model)"),gqe.forEach(t),h8r=i(Ce),k8=n(Ce,"LI",{});var hqe=s(k8);Q6e=n(hqe,"STRONG",{});var k9t=s(Q6e);p8r=r(k9t,"gptj"),k9t.forEach(t),_8r=r(hqe," \u2014 "),lJ=n(hqe,"A",{href:!0});var S9t=s(lJ);u8r=r(S9t,"TFGPTJForCausalLM"),S9t.forEach(t),b8r=r(hqe," (GPT-J model)"),hqe.forEach(t),v8r=i(Ce),S8=n(Ce,"LI",{});var pqe=s(S8);H6e=n(pqe,"STRONG",{});var R9t=s(H6e);F8r=r(R9t,"openai-gpt"),R9t.forEach(t),T8r=r(pqe," \u2014 "),iJ=n(pqe,"A",{href:!0});var P9t=s(iJ);M8r=r(P9t,"TFOpenAIGPTLMHeadModel"),P9t.forEach(t),E8r=r(pqe," (OpenAI GPT model)"),pqe.forEach(t),C8r=i(Ce),R8=n(Ce,"LI",{});var _qe=s(R8);U6e=n(_qe,"STRONG",{});var B9t=s(U6e);w8r=r(B9t,"opt"),B9t.forEach(t),A8r=r(_qe," \u2014 "),dJ=n(_qe,"A",{href:!0});var I9t=s(dJ);L8r=r(I9t,"TFOPTForCausalLM"),I9t.forEach(t),y8r=r(_qe," (OPT model)"),_qe.forEach(t),x8r=i(Ce),P8=n(Ce,"LI",{});var uqe=s(P8);J6e=n(uqe,"STRONG",{});var N9t=s(J6e);$8r=r(N9t,"rembert"),N9t.forEach(t),k8r=r(uqe," \u2014 "),cJ=n(uqe,"A",{href:!0});var q9t=s(cJ);S8r=r(q9t,"TFRemBertForCausalLM"),q9t.forEach(t),R8r=r(uqe," (RemBERT model)"),uqe.forEach(t),P8r=i(Ce),B8=n(Ce,"LI",{});var bqe=s(B8);Y6e=n(bqe,"STRONG",{});var j9t=s(Y6e);B8r=r(j9t,"roberta"),j9t.forEach(t),I8r=r(bqe," \u2014 "),fJ=n(bqe,"A",{href:!0});var D9t=s(fJ);N8r=r(D9t,"TFRobertaForCausalLM"),D9t.forEach(t),q8r=r(bqe," (RoBERTa model)"),bqe.forEach(t),j8r=i(Ce),I8=n(Ce,"LI",{});var vqe=s(I8);K6e=n(vqe,"STRONG",{});var G9t=s(K6e);D8r=r(G9t,"roformer"),G9t.forEach(t),G8r=r(vqe," \u2014 "),mJ=n(vqe,"A",{href:!0});var O9t=s(mJ);O8r=r(O9t,"TFRoFormerForCausalLM"),O9t.forEach(t),V8r=r(vqe," (RoFormer model)"),vqe.forEach(t),X8r=i(Ce),N8=n(Ce,"LI",{});var Fqe=s(N8);Z6e=n(Fqe,"STRONG",{});var V9t=s(Z6e);z8r=r(V9t,"transfo-xl"),V9t.forEach(t),W8r=r(Fqe," \u2014 "),gJ=n(Fqe,"A",{href:!0});var X9t=s(gJ);Q8r=r(X9t,"TFTransfoXLLMHeadModel"),X9t.forEach(t),H8r=r(Fqe," (Transformer-XL model)"),Fqe.forEach(t),U8r=i(Ce),q8=n(Ce,"LI",{});var Tqe=s(q8);eTe=n(Tqe,"STRONG",{});var z9t=s(eTe);J8r=r(z9t,"xlm"),z9t.forEach(t),Y8r=r(Tqe," \u2014 "),hJ=n(Tqe,"A",{href:!0});var W9t=s(hJ);K8r=r(W9t,"TFXLMWithLMHeadModel"),W9t.forEach(t),Z8r=r(Tqe," (XLM model)"),Tqe.forEach(t),eMr=i(Ce),j8=n(Ce,"LI",{});var Mqe=s(j8);oTe=n(Mqe,"STRONG",{});var Q9t=s(oTe);oMr=r(Q9t,"xlnet"),Q9t.forEach(t),rMr=r(Mqe," \u2014 "),pJ=n(Mqe,"A",{href:!0});var H9t=s(pJ);tMr=r(H9t,"TFXLNetLMHeadModel"),H9t.forEach(t),aMr=r(Mqe," (XLNet model)"),Mqe.forEach(t),Ce.forEach(t),nMr=i(Sl),T(D8.$$.fragment,Sl),Sl.forEach(t),kl.forEach(t),ZVe=i(f),gc=n(f,"H2",{class:!0});var lWe=s(gc);G8=n(lWe,"A",{id:!0,class:!0,href:!0});var U9t=s(G8);rTe=n(U9t,"SPAN",{});var J9t=s(rTe);T(V9.$$.fragment,J9t),J9t.forEach(t),U9t.forEach(t),sMr=i(lWe),tTe=n(lWe,"SPAN",{});var Y9t=s(tTe);lMr=r(Y9t,"TFAutoModelForImageClassification"),Y9t.forEach(t),lWe.forEach(t),eXe=i(f),tr=n(f,"DIV",{class:!0});var Rl=s(tr);T(X9.$$.fragment,Rl),iMr=i(Rl),hc=n(Rl,"P",{});var Kre=s(hc);dMr=r(Kre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),_J=n(Kre,"A",{href:!0});var K9t=s(_J);cMr=r(K9t,"from_pretrained()"),K9t.forEach(t),fMr=r(Kre," class method or the "),uJ=n(Kre,"A",{href:!0});var Z9t=s(uJ);mMr=r(Z9t,"from_config()"),Z9t.forEach(t),gMr=r(Kre,` class
method.`),Kre.forEach(t),hMr=i(Rl),z9=n(Rl,"P",{});var iWe=s(z9);pMr=r(iWe,"This class cannot be instantiated directly using "),aTe=n(iWe,"CODE",{});var ext=s(aTe);_Mr=r(ext,"__init__()"),ext.forEach(t),uMr=r(iWe," (throws an error)."),iWe.forEach(t),bMr=i(Rl),Pt=n(Rl,"DIV",{class:!0});var Ww=s(Pt);T(W9.$$.fragment,Ww),vMr=i(Ww),nTe=n(Ww,"P",{});var oxt=s(nTe);FMr=r(oxt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),oxt.forEach(t),TMr=i(Ww),pc=n(Ww,"P",{});var Zre=s(pc);MMr=r(Zre,`Note:
Loading a model from its configuration file does `),sTe=n(Zre,"STRONG",{});var rxt=s(sTe);EMr=r(rxt,"not"),rxt.forEach(t),CMr=r(Zre,` load the model weights. It only affects the
model\u2019s configuration. Use `),bJ=n(Zre,"A",{href:!0});var txt=s(bJ);wMr=r(txt,"from_pretrained()"),txt.forEach(t),AMr=r(Zre," to load the model weights."),Zre.forEach(t),LMr=i(Ww),T(O8.$$.fragment,Ww),Ww.forEach(t),yMr=i(Rl),Sr=n(Rl,"DIV",{class:!0});var Pl=s(Sr);T(Q9.$$.fragment,Pl),xMr=i(Pl),lTe=n(Pl,"P",{});var axt=s(lTe);$Mr=r(axt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),axt.forEach(t),kMr=i(Pl),cn=n(Pl,"P",{});var Qw=s(cn);SMr=r(Qw,"The model class to instantiate is selected based on the "),iTe=n(Qw,"CODE",{});var nxt=s(iTe);RMr=r(nxt,"model_type"),nxt.forEach(t),PMr=r(Qw,` property of the config object (either
passed as an argument or loaded from `),dTe=n(Qw,"CODE",{});var sxt=s(dTe);BMr=r(sxt,"pretrained_model_name_or_path"),sxt.forEach(t),IMr=r(Qw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cTe=n(Qw,"CODE",{});var lxt=s(cTe);NMr=r(lxt,"pretrained_model_name_or_path"),lxt.forEach(t),qMr=r(Qw,":"),Qw.forEach(t),jMr=i(Pl),ar=n(Pl,"UL",{});var $a=s(ar);V8=n($a,"LI",{});var Eqe=s(V8);fTe=n(Eqe,"STRONG",{});var ixt=s(fTe);DMr=r(ixt,"convnext"),ixt.forEach(t),GMr=r(Eqe," \u2014 "),vJ=n(Eqe,"A",{href:!0});var dxt=s(vJ);OMr=r(dxt,"TFConvNextForImageClassification"),dxt.forEach(t),VMr=r(Eqe," (ConvNeXT model)"),Eqe.forEach(t),XMr=i($a),X8=n($a,"LI",{});var Cqe=s(X8);mTe=n(Cqe,"STRONG",{});var cxt=s(mTe);zMr=r(cxt,"data2vec-vision"),cxt.forEach(t),WMr=r(Cqe," \u2014 "),FJ=n(Cqe,"A",{href:!0});var fxt=s(FJ);QMr=r(fxt,"TFData2VecVisionForImageClassification"),fxt.forEach(t),HMr=r(Cqe," (Data2VecVision model)"),Cqe.forEach(t),UMr=i($a),Js=n($a,"LI",{});var uS=s(Js);gTe=n(uS,"STRONG",{});var mxt=s(gTe);JMr=r(mxt,"deit"),mxt.forEach(t),YMr=r(uS," \u2014 "),TJ=n(uS,"A",{href:!0});var gxt=s(TJ);KMr=r(gxt,"TFDeiTForImageClassification"),gxt.forEach(t),ZMr=r(uS," or "),MJ=n(uS,"A",{href:!0});var hxt=s(MJ);e4r=r(hxt,"TFDeiTForImageClassificationWithTeacher"),hxt.forEach(t),o4r=r(uS," (DeiT model)"),uS.forEach(t),r4r=i($a),z8=n($a,"LI",{});var wqe=s(z8);hTe=n(wqe,"STRONG",{});var pxt=s(hTe);t4r=r(pxt,"regnet"),pxt.forEach(t),a4r=r(wqe," \u2014 "),EJ=n(wqe,"A",{href:!0});var _xt=s(EJ);n4r=r(_xt,"TFRegNetForImageClassification"),_xt.forEach(t),s4r=r(wqe," (RegNet model)"),wqe.forEach(t),l4r=i($a),W8=n($a,"LI",{});var Aqe=s(W8);pTe=n(Aqe,"STRONG",{});var uxt=s(pTe);i4r=r(uxt,"swin"),uxt.forEach(t),d4r=r(Aqe," \u2014 "),CJ=n(Aqe,"A",{href:!0});var bxt=s(CJ);c4r=r(bxt,"TFSwinForImageClassification"),bxt.forEach(t),f4r=r(Aqe," (Swin Transformer model)"),Aqe.forEach(t),m4r=i($a),Q8=n($a,"LI",{});var Lqe=s(Q8);_Te=n(Lqe,"STRONG",{});var vxt=s(_Te);g4r=r(vxt,"vit"),vxt.forEach(t),h4r=r(Lqe," \u2014 "),wJ=n(Lqe,"A",{href:!0});var Fxt=s(wJ);p4r=r(Fxt,"TFViTForImageClassification"),Fxt.forEach(t),_4r=r(Lqe," (ViT model)"),Lqe.forEach(t),$a.forEach(t),u4r=i(Pl),T(H8.$$.fragment,Pl),Pl.forEach(t),Rl.forEach(t),oXe=i(f),_c=n(f,"H2",{class:!0});var dWe=s(_c);U8=n(dWe,"A",{id:!0,class:!0,href:!0});var Txt=s(U8);uTe=n(Txt,"SPAN",{});var Mxt=s(uTe);T(H9.$$.fragment,Mxt),Mxt.forEach(t),Txt.forEach(t),b4r=i(dWe),bTe=n(dWe,"SPAN",{});var Ext=s(bTe);v4r=r(Ext,"TFAutoModelForMaskedLM"),Ext.forEach(t),dWe.forEach(t),rXe=i(f),nr=n(f,"DIV",{class:!0});var Bl=s(nr);T(U9.$$.fragment,Bl),F4r=i(Bl),uc=n(Bl,"P",{});var ete=s(uc);T4r=r(ete,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),AJ=n(ete,"A",{href:!0});var Cxt=s(AJ);M4r=r(Cxt,"from_pretrained()"),Cxt.forEach(t),E4r=r(ete," class method or the "),LJ=n(ete,"A",{href:!0});var wxt=s(LJ);C4r=r(wxt,"from_config()"),wxt.forEach(t),w4r=r(ete,` class
method.`),ete.forEach(t),A4r=i(Bl),J9=n(Bl,"P",{});var cWe=s(J9);L4r=r(cWe,"This class cannot be instantiated directly using "),vTe=n(cWe,"CODE",{});var Axt=s(vTe);y4r=r(Axt,"__init__()"),Axt.forEach(t),x4r=r(cWe," (throws an error)."),cWe.forEach(t),$4r=i(Bl),Bt=n(Bl,"DIV",{class:!0});var Hw=s(Bt);T(Y9.$$.fragment,Hw),k4r=i(Hw),FTe=n(Hw,"P",{});var Lxt=s(FTe);S4r=r(Lxt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Lxt.forEach(t),R4r=i(Hw),bc=n(Hw,"P",{});var ote=s(bc);P4r=r(ote,`Note:
Loading a model from its configuration file does `),TTe=n(ote,"STRONG",{});var yxt=s(TTe);B4r=r(yxt,"not"),yxt.forEach(t),I4r=r(ote,` load the model weights. It only affects the
model\u2019s configuration. Use `),yJ=n(ote,"A",{href:!0});var xxt=s(yJ);N4r=r(xxt,"from_pretrained()"),xxt.forEach(t),q4r=r(ote," to load the model weights."),ote.forEach(t),j4r=i(Hw),T(J8.$$.fragment,Hw),Hw.forEach(t),D4r=i(Bl),Rr=n(Bl,"DIV",{class:!0});var Il=s(Rr);T(K9.$$.fragment,Il),G4r=i(Il),MTe=n(Il,"P",{});var $xt=s(MTe);O4r=r($xt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),$xt.forEach(t),V4r=i(Il),fn=n(Il,"P",{});var Uw=s(fn);X4r=r(Uw,"The model class to instantiate is selected based on the "),ETe=n(Uw,"CODE",{});var kxt=s(ETe);z4r=r(kxt,"model_type"),kxt.forEach(t),W4r=r(Uw,` property of the config object (either
passed as an argument or loaded from `),CTe=n(Uw,"CODE",{});var Sxt=s(CTe);Q4r=r(Sxt,"pretrained_model_name_or_path"),Sxt.forEach(t),H4r=r(Uw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wTe=n(Uw,"CODE",{});var Rxt=s(wTe);U4r=r(Rxt,"pretrained_model_name_or_path"),Rxt.forEach(t),J4r=r(Uw,":"),Uw.forEach(t),Y4r=i(Il),ie=n(Il,"UL",{});var fe=s(ie);Y8=n(fe,"LI",{});var yqe=s(Y8);ATe=n(yqe,"STRONG",{});var Pxt=s(ATe);K4r=r(Pxt,"albert"),Pxt.forEach(t),Z4r=r(yqe," \u2014 "),xJ=n(yqe,"A",{href:!0});var Bxt=s(xJ);eEr=r(Bxt,"TFAlbertForMaskedLM"),Bxt.forEach(t),oEr=r(yqe," (ALBERT model)"),yqe.forEach(t),rEr=i(fe),K8=n(fe,"LI",{});var xqe=s(K8);LTe=n(xqe,"STRONG",{});var Ixt=s(LTe);tEr=r(Ixt,"bert"),Ixt.forEach(t),aEr=r(xqe," \u2014 "),$J=n(xqe,"A",{href:!0});var Nxt=s($J);nEr=r(Nxt,"TFBertForMaskedLM"),Nxt.forEach(t),sEr=r(xqe," (BERT model)"),xqe.forEach(t),lEr=i(fe),Z8=n(fe,"LI",{});var $qe=s(Z8);yTe=n($qe,"STRONG",{});var qxt=s(yTe);iEr=r(qxt,"camembert"),qxt.forEach(t),dEr=r($qe," \u2014 "),kJ=n($qe,"A",{href:!0});var jxt=s(kJ);cEr=r(jxt,"TFCamembertForMaskedLM"),jxt.forEach(t),fEr=r($qe," (CamemBERT model)"),$qe.forEach(t),mEr=i(fe),eM=n(fe,"LI",{});var kqe=s(eM);xTe=n(kqe,"STRONG",{});var Dxt=s(xTe);gEr=r(Dxt,"convbert"),Dxt.forEach(t),hEr=r(kqe," \u2014 "),SJ=n(kqe,"A",{href:!0});var Gxt=s(SJ);pEr=r(Gxt,"TFConvBertForMaskedLM"),Gxt.forEach(t),_Er=r(kqe," (ConvBERT model)"),kqe.forEach(t),uEr=i(fe),oM=n(fe,"LI",{});var Sqe=s(oM);$Te=n(Sqe,"STRONG",{});var Oxt=s($Te);bEr=r(Oxt,"deberta"),Oxt.forEach(t),vEr=r(Sqe," \u2014 "),RJ=n(Sqe,"A",{href:!0});var Vxt=s(RJ);FEr=r(Vxt,"TFDebertaForMaskedLM"),Vxt.forEach(t),TEr=r(Sqe," (DeBERTa model)"),Sqe.forEach(t),MEr=i(fe),rM=n(fe,"LI",{});var Rqe=s(rM);kTe=n(Rqe,"STRONG",{});var Xxt=s(kTe);EEr=r(Xxt,"deberta-v2"),Xxt.forEach(t),CEr=r(Rqe," \u2014 "),PJ=n(Rqe,"A",{href:!0});var zxt=s(PJ);wEr=r(zxt,"TFDebertaV2ForMaskedLM"),zxt.forEach(t),AEr=r(Rqe," (DeBERTa-v2 model)"),Rqe.forEach(t),LEr=i(fe),tM=n(fe,"LI",{});var Pqe=s(tM);STe=n(Pqe,"STRONG",{});var Wxt=s(STe);yEr=r(Wxt,"distilbert"),Wxt.forEach(t),xEr=r(Pqe," \u2014 "),BJ=n(Pqe,"A",{href:!0});var Qxt=s(BJ);$Er=r(Qxt,"TFDistilBertForMaskedLM"),Qxt.forEach(t),kEr=r(Pqe," (DistilBERT model)"),Pqe.forEach(t),SEr=i(fe),aM=n(fe,"LI",{});var Bqe=s(aM);RTe=n(Bqe,"STRONG",{});var Hxt=s(RTe);REr=r(Hxt,"electra"),Hxt.forEach(t),PEr=r(Bqe," \u2014 "),IJ=n(Bqe,"A",{href:!0});var Uxt=s(IJ);BEr=r(Uxt,"TFElectraForMaskedLM"),Uxt.forEach(t),IEr=r(Bqe," (ELECTRA model)"),Bqe.forEach(t),NEr=i(fe),nM=n(fe,"LI",{});var Iqe=s(nM);PTe=n(Iqe,"STRONG",{});var Jxt=s(PTe);qEr=r(Jxt,"flaubert"),Jxt.forEach(t),jEr=r(Iqe," \u2014 "),NJ=n(Iqe,"A",{href:!0});var Yxt=s(NJ);DEr=r(Yxt,"TFFlaubertWithLMHeadModel"),Yxt.forEach(t),GEr=r(Iqe," (FlauBERT model)"),Iqe.forEach(t),OEr=i(fe),sM=n(fe,"LI",{});var Nqe=s(sM);BTe=n(Nqe,"STRONG",{});var Kxt=s(BTe);VEr=r(Kxt,"funnel"),Kxt.forEach(t),XEr=r(Nqe," \u2014 "),qJ=n(Nqe,"A",{href:!0});var Zxt=s(qJ);zEr=r(Zxt,"TFFunnelForMaskedLM"),Zxt.forEach(t),WEr=r(Nqe," (Funnel Transformer model)"),Nqe.forEach(t),QEr=i(fe),lM=n(fe,"LI",{});var qqe=s(lM);ITe=n(qqe,"STRONG",{});var e$t=s(ITe);HEr=r(e$t,"layoutlm"),e$t.forEach(t),UEr=r(qqe," \u2014 "),jJ=n(qqe,"A",{href:!0});var o$t=s(jJ);JEr=r(o$t,"TFLayoutLMForMaskedLM"),o$t.forEach(t),YEr=r(qqe," (LayoutLM model)"),qqe.forEach(t),KEr=i(fe),iM=n(fe,"LI",{});var jqe=s(iM);NTe=n(jqe,"STRONG",{});var r$t=s(NTe);ZEr=r(r$t,"longformer"),r$t.forEach(t),eCr=r(jqe," \u2014 "),DJ=n(jqe,"A",{href:!0});var t$t=s(DJ);oCr=r(t$t,"TFLongformerForMaskedLM"),t$t.forEach(t),rCr=r(jqe," (Longformer model)"),jqe.forEach(t),tCr=i(fe),dM=n(fe,"LI",{});var Dqe=s(dM);qTe=n(Dqe,"STRONG",{});var a$t=s(qTe);aCr=r(a$t,"mobilebert"),a$t.forEach(t),nCr=r(Dqe," \u2014 "),GJ=n(Dqe,"A",{href:!0});var n$t=s(GJ);sCr=r(n$t,"TFMobileBertForMaskedLM"),n$t.forEach(t),lCr=r(Dqe," (MobileBERT model)"),Dqe.forEach(t),iCr=i(fe),cM=n(fe,"LI",{});var Gqe=s(cM);jTe=n(Gqe,"STRONG",{});var s$t=s(jTe);dCr=r(s$t,"mpnet"),s$t.forEach(t),cCr=r(Gqe," \u2014 "),OJ=n(Gqe,"A",{href:!0});var l$t=s(OJ);fCr=r(l$t,"TFMPNetForMaskedLM"),l$t.forEach(t),mCr=r(Gqe," (MPNet model)"),Gqe.forEach(t),gCr=i(fe),fM=n(fe,"LI",{});var Oqe=s(fM);DTe=n(Oqe,"STRONG",{});var i$t=s(DTe);hCr=r(i$t,"rembert"),i$t.forEach(t),pCr=r(Oqe," \u2014 "),VJ=n(Oqe,"A",{href:!0});var d$t=s(VJ);_Cr=r(d$t,"TFRemBertForMaskedLM"),d$t.forEach(t),uCr=r(Oqe," (RemBERT model)"),Oqe.forEach(t),bCr=i(fe),mM=n(fe,"LI",{});var Vqe=s(mM);GTe=n(Vqe,"STRONG",{});var c$t=s(GTe);vCr=r(c$t,"roberta"),c$t.forEach(t),FCr=r(Vqe," \u2014 "),XJ=n(Vqe,"A",{href:!0});var f$t=s(XJ);TCr=r(f$t,"TFRobertaForMaskedLM"),f$t.forEach(t),MCr=r(Vqe," (RoBERTa model)"),Vqe.forEach(t),ECr=i(fe),gM=n(fe,"LI",{});var Xqe=s(gM);OTe=n(Xqe,"STRONG",{});var m$t=s(OTe);CCr=r(m$t,"roformer"),m$t.forEach(t),wCr=r(Xqe," \u2014 "),zJ=n(Xqe,"A",{href:!0});var g$t=s(zJ);ACr=r(g$t,"TFRoFormerForMaskedLM"),g$t.forEach(t),LCr=r(Xqe," (RoFormer model)"),Xqe.forEach(t),yCr=i(fe),hM=n(fe,"LI",{});var zqe=s(hM);VTe=n(zqe,"STRONG",{});var h$t=s(VTe);xCr=r(h$t,"tapas"),h$t.forEach(t),$Cr=r(zqe," \u2014 "),WJ=n(zqe,"A",{href:!0});var p$t=s(WJ);kCr=r(p$t,"TFTapasForMaskedLM"),p$t.forEach(t),SCr=r(zqe," (TAPAS model)"),zqe.forEach(t),RCr=i(fe),pM=n(fe,"LI",{});var Wqe=s(pM);XTe=n(Wqe,"STRONG",{});var _$t=s(XTe);PCr=r(_$t,"xlm"),_$t.forEach(t),BCr=r(Wqe," \u2014 "),QJ=n(Wqe,"A",{href:!0});var u$t=s(QJ);ICr=r(u$t,"TFXLMWithLMHeadModel"),u$t.forEach(t),NCr=r(Wqe," (XLM model)"),Wqe.forEach(t),qCr=i(fe),_M=n(fe,"LI",{});var Qqe=s(_M);zTe=n(Qqe,"STRONG",{});var b$t=s(zTe);jCr=r(b$t,"xlm-roberta"),b$t.forEach(t),DCr=r(Qqe," \u2014 "),HJ=n(Qqe,"A",{href:!0});var v$t=s(HJ);GCr=r(v$t,"TFXLMRobertaForMaskedLM"),v$t.forEach(t),OCr=r(Qqe," (XLM-RoBERTa model)"),Qqe.forEach(t),fe.forEach(t),VCr=i(Il),T(uM.$$.fragment,Il),Il.forEach(t),Bl.forEach(t),tXe=i(f),vc=n(f,"H2",{class:!0});var fWe=s(vc);bM=n(fWe,"A",{id:!0,class:!0,href:!0});var F$t=s(bM);WTe=n(F$t,"SPAN",{});var T$t=s(WTe);T(Z9.$$.fragment,T$t),T$t.forEach(t),F$t.forEach(t),XCr=i(fWe),QTe=n(fWe,"SPAN",{});var M$t=s(QTe);zCr=r(M$t,"TFAutoModelForSeq2SeqLM"),M$t.forEach(t),fWe.forEach(t),aXe=i(f),sr=n(f,"DIV",{class:!0});var Nl=s(sr);T(ex.$$.fragment,Nl),WCr=i(Nl),Fc=n(Nl,"P",{});var rte=s(Fc);QCr=r(rte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),UJ=n(rte,"A",{href:!0});var E$t=s(UJ);HCr=r(E$t,"from_pretrained()"),E$t.forEach(t),UCr=r(rte," class method or the "),JJ=n(rte,"A",{href:!0});var C$t=s(JJ);JCr=r(C$t,"from_config()"),C$t.forEach(t),YCr=r(rte,` class
method.`),rte.forEach(t),KCr=i(Nl),ox=n(Nl,"P",{});var mWe=s(ox);ZCr=r(mWe,"This class cannot be instantiated directly using "),HTe=n(mWe,"CODE",{});var w$t=s(HTe);e3r=r(w$t,"__init__()"),w$t.forEach(t),o3r=r(mWe," (throws an error)."),mWe.forEach(t),r3r=i(Nl),It=n(Nl,"DIV",{class:!0});var Jw=s(It);T(rx.$$.fragment,Jw),t3r=i(Jw),UTe=n(Jw,"P",{});var A$t=s(UTe);a3r=r(A$t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),A$t.forEach(t),n3r=i(Jw),Tc=n(Jw,"P",{});var tte=s(Tc);s3r=r(tte,`Note:
Loading a model from its configuration file does `),JTe=n(tte,"STRONG",{});var L$t=s(JTe);l3r=r(L$t,"not"),L$t.forEach(t),i3r=r(tte,` load the model weights. It only affects the
model\u2019s configuration. Use `),YJ=n(tte,"A",{href:!0});var y$t=s(YJ);d3r=r(y$t,"from_pretrained()"),y$t.forEach(t),c3r=r(tte," to load the model weights."),tte.forEach(t),f3r=i(Jw),T(vM.$$.fragment,Jw),Jw.forEach(t),m3r=i(Nl),Pr=n(Nl,"DIV",{class:!0});var ql=s(Pr);T(tx.$$.fragment,ql),g3r=i(ql),YTe=n(ql,"P",{});var x$t=s(YTe);h3r=r(x$t,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),x$t.forEach(t),p3r=i(ql),mn=n(ql,"P",{});var Yw=s(mn);_3r=r(Yw,"The model class to instantiate is selected based on the "),KTe=n(Yw,"CODE",{});var $$t=s(KTe);u3r=r($$t,"model_type"),$$t.forEach(t),b3r=r(Yw,` property of the config object (either
passed as an argument or loaded from `),ZTe=n(Yw,"CODE",{});var k$t=s(ZTe);v3r=r(k$t,"pretrained_model_name_or_path"),k$t.forEach(t),F3r=r(Yw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e7e=n(Yw,"CODE",{});var S$t=s(e7e);T3r=r(S$t,"pretrained_model_name_or_path"),S$t.forEach(t),M3r=r(Yw,":"),Yw.forEach(t),E3r=i(ql),ye=n(ql,"UL",{});var Ie=s(ye);FM=n(Ie,"LI",{});var Hqe=s(FM);o7e=n(Hqe,"STRONG",{});var R$t=s(o7e);C3r=r(R$t,"bart"),R$t.forEach(t),w3r=r(Hqe," \u2014 "),KJ=n(Hqe,"A",{href:!0});var P$t=s(KJ);A3r=r(P$t,"TFBartForConditionalGeneration"),P$t.forEach(t),L3r=r(Hqe," (BART model)"),Hqe.forEach(t),y3r=i(Ie),TM=n(Ie,"LI",{});var Uqe=s(TM);r7e=n(Uqe,"STRONG",{});var B$t=s(r7e);x3r=r(B$t,"blenderbot"),B$t.forEach(t),$3r=r(Uqe," \u2014 "),ZJ=n(Uqe,"A",{href:!0});var I$t=s(ZJ);k3r=r(I$t,"TFBlenderbotForConditionalGeneration"),I$t.forEach(t),S3r=r(Uqe," (Blenderbot model)"),Uqe.forEach(t),R3r=i(Ie),MM=n(Ie,"LI",{});var Jqe=s(MM);t7e=n(Jqe,"STRONG",{});var N$t=s(t7e);P3r=r(N$t,"blenderbot-small"),N$t.forEach(t),B3r=r(Jqe," \u2014 "),eY=n(Jqe,"A",{href:!0});var q$t=s(eY);I3r=r(q$t,"TFBlenderbotSmallForConditionalGeneration"),q$t.forEach(t),N3r=r(Jqe," (BlenderbotSmall model)"),Jqe.forEach(t),q3r=i(Ie),EM=n(Ie,"LI",{});var Yqe=s(EM);a7e=n(Yqe,"STRONG",{});var j$t=s(a7e);j3r=r(j$t,"encoder-decoder"),j$t.forEach(t),D3r=r(Yqe," \u2014 "),oY=n(Yqe,"A",{href:!0});var D$t=s(oY);G3r=r(D$t,"TFEncoderDecoderModel"),D$t.forEach(t),O3r=r(Yqe," (Encoder decoder model)"),Yqe.forEach(t),V3r=i(Ie),CM=n(Ie,"LI",{});var Kqe=s(CM);n7e=n(Kqe,"STRONG",{});var G$t=s(n7e);X3r=r(G$t,"led"),G$t.forEach(t),z3r=r(Kqe," \u2014 "),rY=n(Kqe,"A",{href:!0});var O$t=s(rY);W3r=r(O$t,"TFLEDForConditionalGeneration"),O$t.forEach(t),Q3r=r(Kqe," (LED model)"),Kqe.forEach(t),H3r=i(Ie),wM=n(Ie,"LI",{});var Zqe=s(wM);s7e=n(Zqe,"STRONG",{});var V$t=s(s7e);U3r=r(V$t,"marian"),V$t.forEach(t),J3r=r(Zqe," \u2014 "),tY=n(Zqe,"A",{href:!0});var X$t=s(tY);Y3r=r(X$t,"TFMarianMTModel"),X$t.forEach(t),K3r=r(Zqe," (Marian model)"),Zqe.forEach(t),Z3r=i(Ie),AM=n(Ie,"LI",{});var eje=s(AM);l7e=n(eje,"STRONG",{});var z$t=s(l7e);e5r=r(z$t,"mbart"),z$t.forEach(t),o5r=r(eje," \u2014 "),aY=n(eje,"A",{href:!0});var W$t=s(aY);r5r=r(W$t,"TFMBartForConditionalGeneration"),W$t.forEach(t),t5r=r(eje," (mBART model)"),eje.forEach(t),a5r=i(Ie),LM=n(Ie,"LI",{});var oje=s(LM);i7e=n(oje,"STRONG",{});var Q$t=s(i7e);n5r=r(Q$t,"mt5"),Q$t.forEach(t),s5r=r(oje," \u2014 "),nY=n(oje,"A",{href:!0});var H$t=s(nY);l5r=r(H$t,"TFMT5ForConditionalGeneration"),H$t.forEach(t),i5r=r(oje," (MT5 model)"),oje.forEach(t),d5r=i(Ie),yM=n(Ie,"LI",{});var rje=s(yM);d7e=n(rje,"STRONG",{});var U$t=s(d7e);c5r=r(U$t,"pegasus"),U$t.forEach(t),f5r=r(rje," \u2014 "),sY=n(rje,"A",{href:!0});var J$t=s(sY);m5r=r(J$t,"TFPegasusForConditionalGeneration"),J$t.forEach(t),g5r=r(rje," (Pegasus model)"),rje.forEach(t),h5r=i(Ie),xM=n(Ie,"LI",{});var tje=s(xM);c7e=n(tje,"STRONG",{});var Y$t=s(c7e);p5r=r(Y$t,"t5"),Y$t.forEach(t),_5r=r(tje," \u2014 "),lY=n(tje,"A",{href:!0});var K$t=s(lY);u5r=r(K$t,"TFT5ForConditionalGeneration"),K$t.forEach(t),b5r=r(tje," (T5 model)"),tje.forEach(t),Ie.forEach(t),v5r=i(ql),T($M.$$.fragment,ql),ql.forEach(t),Nl.forEach(t),nXe=i(f),Mc=n(f,"H2",{class:!0});var gWe=s(Mc);kM=n(gWe,"A",{id:!0,class:!0,href:!0});var Z$t=s(kM);f7e=n(Z$t,"SPAN",{});var ekt=s(f7e);T(ax.$$.fragment,ekt),ekt.forEach(t),Z$t.forEach(t),F5r=i(gWe),m7e=n(gWe,"SPAN",{});var okt=s(m7e);T5r=r(okt,"TFAutoModelForSequenceClassification"),okt.forEach(t),gWe.forEach(t),sXe=i(f),lr=n(f,"DIV",{class:!0});var jl=s(lr);T(nx.$$.fragment,jl),M5r=i(jl),Ec=n(jl,"P",{});var ate=s(Ec);E5r=r(ate,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),iY=n(ate,"A",{href:!0});var rkt=s(iY);C5r=r(rkt,"from_pretrained()"),rkt.forEach(t),w5r=r(ate," class method or the "),dY=n(ate,"A",{href:!0});var tkt=s(dY);A5r=r(tkt,"from_config()"),tkt.forEach(t),L5r=r(ate,` class
method.`),ate.forEach(t),y5r=i(jl),sx=n(jl,"P",{});var hWe=s(sx);x5r=r(hWe,"This class cannot be instantiated directly using "),g7e=n(hWe,"CODE",{});var akt=s(g7e);$5r=r(akt,"__init__()"),akt.forEach(t),k5r=r(hWe," (throws an error)."),hWe.forEach(t),S5r=i(jl),Nt=n(jl,"DIV",{class:!0});var Kw=s(Nt);T(lx.$$.fragment,Kw),R5r=i(Kw),h7e=n(Kw,"P",{});var nkt=s(h7e);P5r=r(nkt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),nkt.forEach(t),B5r=i(Kw),Cc=n(Kw,"P",{});var nte=s(Cc);I5r=r(nte,`Note:
Loading a model from its configuration file does `),p7e=n(nte,"STRONG",{});var skt=s(p7e);N5r=r(skt,"not"),skt.forEach(t),q5r=r(nte,` load the model weights. It only affects the
model\u2019s configuration. Use `),cY=n(nte,"A",{href:!0});var lkt=s(cY);j5r=r(lkt,"from_pretrained()"),lkt.forEach(t),D5r=r(nte," to load the model weights."),nte.forEach(t),G5r=i(Kw),T(SM.$$.fragment,Kw),Kw.forEach(t),O5r=i(jl),Br=n(jl,"DIV",{class:!0});var Dl=s(Br);T(ix.$$.fragment,Dl),V5r=i(Dl),_7e=n(Dl,"P",{});var ikt=s(_7e);X5r=r(ikt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),ikt.forEach(t),z5r=i(Dl),gn=n(Dl,"P",{});var Zw=s(gn);W5r=r(Zw,"The model class to instantiate is selected based on the "),u7e=n(Zw,"CODE",{});var dkt=s(u7e);Q5r=r(dkt,"model_type"),dkt.forEach(t),H5r=r(Zw,` property of the config object (either
passed as an argument or loaded from `),b7e=n(Zw,"CODE",{});var ckt=s(b7e);U5r=r(ckt,"pretrained_model_name_or_path"),ckt.forEach(t),J5r=r(Zw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v7e=n(Zw,"CODE",{});var fkt=s(v7e);Y5r=r(fkt,"pretrained_model_name_or_path"),fkt.forEach(t),K5r=r(Zw,":"),Zw.forEach(t),Z5r=i(Dl),te=n(Dl,"UL",{});var ne=s(te);RM=n(ne,"LI",{});var aje=s(RM);F7e=n(aje,"STRONG",{});var mkt=s(F7e);ewr=r(mkt,"albert"),mkt.forEach(t),owr=r(aje," \u2014 "),fY=n(aje,"A",{href:!0});var gkt=s(fY);rwr=r(gkt,"TFAlbertForSequenceClassification"),gkt.forEach(t),twr=r(aje," (ALBERT model)"),aje.forEach(t),awr=i(ne),PM=n(ne,"LI",{});var nje=s(PM);T7e=n(nje,"STRONG",{});var hkt=s(T7e);nwr=r(hkt,"bert"),hkt.forEach(t),swr=r(nje," \u2014 "),mY=n(nje,"A",{href:!0});var pkt=s(mY);lwr=r(pkt,"TFBertForSequenceClassification"),pkt.forEach(t),iwr=r(nje," (BERT model)"),nje.forEach(t),dwr=i(ne),BM=n(ne,"LI",{});var sje=s(BM);M7e=n(sje,"STRONG",{});var _kt=s(M7e);cwr=r(_kt,"camembert"),_kt.forEach(t),fwr=r(sje," \u2014 "),gY=n(sje,"A",{href:!0});var ukt=s(gY);mwr=r(ukt,"TFCamembertForSequenceClassification"),ukt.forEach(t),gwr=r(sje," (CamemBERT model)"),sje.forEach(t),hwr=i(ne),IM=n(ne,"LI",{});var lje=s(IM);E7e=n(lje,"STRONG",{});var bkt=s(E7e);pwr=r(bkt,"convbert"),bkt.forEach(t),_wr=r(lje," \u2014 "),hY=n(lje,"A",{href:!0});var vkt=s(hY);uwr=r(vkt,"TFConvBertForSequenceClassification"),vkt.forEach(t),bwr=r(lje," (ConvBERT model)"),lje.forEach(t),vwr=i(ne),NM=n(ne,"LI",{});var ije=s(NM);C7e=n(ije,"STRONG",{});var Fkt=s(C7e);Fwr=r(Fkt,"ctrl"),Fkt.forEach(t),Twr=r(ije," \u2014 "),pY=n(ije,"A",{href:!0});var Tkt=s(pY);Mwr=r(Tkt,"TFCTRLForSequenceClassification"),Tkt.forEach(t),Ewr=r(ije," (CTRL model)"),ije.forEach(t),Cwr=i(ne),qM=n(ne,"LI",{});var dje=s(qM);w7e=n(dje,"STRONG",{});var Mkt=s(w7e);wwr=r(Mkt,"deberta"),Mkt.forEach(t),Awr=r(dje," \u2014 "),_Y=n(dje,"A",{href:!0});var Ekt=s(_Y);Lwr=r(Ekt,"TFDebertaForSequenceClassification"),Ekt.forEach(t),ywr=r(dje," (DeBERTa model)"),dje.forEach(t),xwr=i(ne),jM=n(ne,"LI",{});var cje=s(jM);A7e=n(cje,"STRONG",{});var Ckt=s(A7e);$wr=r(Ckt,"deberta-v2"),Ckt.forEach(t),kwr=r(cje," \u2014 "),uY=n(cje,"A",{href:!0});var wkt=s(uY);Swr=r(wkt,"TFDebertaV2ForSequenceClassification"),wkt.forEach(t),Rwr=r(cje," (DeBERTa-v2 model)"),cje.forEach(t),Pwr=i(ne),DM=n(ne,"LI",{});var fje=s(DM);L7e=n(fje,"STRONG",{});var Akt=s(L7e);Bwr=r(Akt,"distilbert"),Akt.forEach(t),Iwr=r(fje," \u2014 "),bY=n(fje,"A",{href:!0});var Lkt=s(bY);Nwr=r(Lkt,"TFDistilBertForSequenceClassification"),Lkt.forEach(t),qwr=r(fje," (DistilBERT model)"),fje.forEach(t),jwr=i(ne),GM=n(ne,"LI",{});var mje=s(GM);y7e=n(mje,"STRONG",{});var ykt=s(y7e);Dwr=r(ykt,"electra"),ykt.forEach(t),Gwr=r(mje," \u2014 "),vY=n(mje,"A",{href:!0});var xkt=s(vY);Owr=r(xkt,"TFElectraForSequenceClassification"),xkt.forEach(t),Vwr=r(mje," (ELECTRA model)"),mje.forEach(t),Xwr=i(ne),OM=n(ne,"LI",{});var gje=s(OM);x7e=n(gje,"STRONG",{});var $kt=s(x7e);zwr=r($kt,"flaubert"),$kt.forEach(t),Wwr=r(gje," \u2014 "),FY=n(gje,"A",{href:!0});var kkt=s(FY);Qwr=r(kkt,"TFFlaubertForSequenceClassification"),kkt.forEach(t),Hwr=r(gje," (FlauBERT model)"),gje.forEach(t),Uwr=i(ne),VM=n(ne,"LI",{});var hje=s(VM);$7e=n(hje,"STRONG",{});var Skt=s($7e);Jwr=r(Skt,"funnel"),Skt.forEach(t),Ywr=r(hje," \u2014 "),TY=n(hje,"A",{href:!0});var Rkt=s(TY);Kwr=r(Rkt,"TFFunnelForSequenceClassification"),Rkt.forEach(t),Zwr=r(hje," (Funnel Transformer model)"),hje.forEach(t),eAr=i(ne),XM=n(ne,"LI",{});var pje=s(XM);k7e=n(pje,"STRONG",{});var Pkt=s(k7e);oAr=r(Pkt,"gpt2"),Pkt.forEach(t),rAr=r(pje," \u2014 "),MY=n(pje,"A",{href:!0});var Bkt=s(MY);tAr=r(Bkt,"TFGPT2ForSequenceClassification"),Bkt.forEach(t),aAr=r(pje," (OpenAI GPT-2 model)"),pje.forEach(t),nAr=i(ne),zM=n(ne,"LI",{});var _je=s(zM);S7e=n(_je,"STRONG",{});var Ikt=s(S7e);sAr=r(Ikt,"gptj"),Ikt.forEach(t),lAr=r(_je," \u2014 "),EY=n(_je,"A",{href:!0});var Nkt=s(EY);iAr=r(Nkt,"TFGPTJForSequenceClassification"),Nkt.forEach(t),dAr=r(_je," (GPT-J model)"),_je.forEach(t),cAr=i(ne),WM=n(ne,"LI",{});var uje=s(WM);R7e=n(uje,"STRONG",{});var qkt=s(R7e);fAr=r(qkt,"layoutlm"),qkt.forEach(t),mAr=r(uje," \u2014 "),CY=n(uje,"A",{href:!0});var jkt=s(CY);gAr=r(jkt,"TFLayoutLMForSequenceClassification"),jkt.forEach(t),hAr=r(uje," (LayoutLM model)"),uje.forEach(t),pAr=i(ne),QM=n(ne,"LI",{});var bje=s(QM);P7e=n(bje,"STRONG",{});var Dkt=s(P7e);_Ar=r(Dkt,"longformer"),Dkt.forEach(t),uAr=r(bje," \u2014 "),wY=n(bje,"A",{href:!0});var Gkt=s(wY);bAr=r(Gkt,"TFLongformerForSequenceClassification"),Gkt.forEach(t),vAr=r(bje," (Longformer model)"),bje.forEach(t),FAr=i(ne),HM=n(ne,"LI",{});var vje=s(HM);B7e=n(vje,"STRONG",{});var Okt=s(B7e);TAr=r(Okt,"mobilebert"),Okt.forEach(t),MAr=r(vje," \u2014 "),AY=n(vje,"A",{href:!0});var Vkt=s(AY);EAr=r(Vkt,"TFMobileBertForSequenceClassification"),Vkt.forEach(t),CAr=r(vje," (MobileBERT model)"),vje.forEach(t),wAr=i(ne),UM=n(ne,"LI",{});var Fje=s(UM);I7e=n(Fje,"STRONG",{});var Xkt=s(I7e);AAr=r(Xkt,"mpnet"),Xkt.forEach(t),LAr=r(Fje," \u2014 "),LY=n(Fje,"A",{href:!0});var zkt=s(LY);yAr=r(zkt,"TFMPNetForSequenceClassification"),zkt.forEach(t),xAr=r(Fje," (MPNet model)"),Fje.forEach(t),$Ar=i(ne),JM=n(ne,"LI",{});var Tje=s(JM);N7e=n(Tje,"STRONG",{});var Wkt=s(N7e);kAr=r(Wkt,"openai-gpt"),Wkt.forEach(t),SAr=r(Tje," \u2014 "),yY=n(Tje,"A",{href:!0});var Qkt=s(yY);RAr=r(Qkt,"TFOpenAIGPTForSequenceClassification"),Qkt.forEach(t),PAr=r(Tje," (OpenAI GPT model)"),Tje.forEach(t),BAr=i(ne),YM=n(ne,"LI",{});var Mje=s(YM);q7e=n(Mje,"STRONG",{});var Hkt=s(q7e);IAr=r(Hkt,"rembert"),Hkt.forEach(t),NAr=r(Mje," \u2014 "),xY=n(Mje,"A",{href:!0});var Ukt=s(xY);qAr=r(Ukt,"TFRemBertForSequenceClassification"),Ukt.forEach(t),jAr=r(Mje," (RemBERT model)"),Mje.forEach(t),DAr=i(ne),KM=n(ne,"LI",{});var Eje=s(KM);j7e=n(Eje,"STRONG",{});var Jkt=s(j7e);GAr=r(Jkt,"roberta"),Jkt.forEach(t),OAr=r(Eje," \u2014 "),$Y=n(Eje,"A",{href:!0});var Ykt=s($Y);VAr=r(Ykt,"TFRobertaForSequenceClassification"),Ykt.forEach(t),XAr=r(Eje," (RoBERTa model)"),Eje.forEach(t),zAr=i(ne),ZM=n(ne,"LI",{});var Cje=s(ZM);D7e=n(Cje,"STRONG",{});var Kkt=s(D7e);WAr=r(Kkt,"roformer"),Kkt.forEach(t),QAr=r(Cje," \u2014 "),kY=n(Cje,"A",{href:!0});var Zkt=s(kY);HAr=r(Zkt,"TFRoFormerForSequenceClassification"),Zkt.forEach(t),UAr=r(Cje," (RoFormer model)"),Cje.forEach(t),JAr=i(ne),e4=n(ne,"LI",{});var wje=s(e4);G7e=n(wje,"STRONG",{});var eSt=s(G7e);YAr=r(eSt,"tapas"),eSt.forEach(t),KAr=r(wje," \u2014 "),SY=n(wje,"A",{href:!0});var oSt=s(SY);ZAr=r(oSt,"TFTapasForSequenceClassification"),oSt.forEach(t),eLr=r(wje," (TAPAS model)"),wje.forEach(t),oLr=i(ne),o4=n(ne,"LI",{});var Aje=s(o4);O7e=n(Aje,"STRONG",{});var rSt=s(O7e);rLr=r(rSt,"transfo-xl"),rSt.forEach(t),tLr=r(Aje," \u2014 "),RY=n(Aje,"A",{href:!0});var tSt=s(RY);aLr=r(tSt,"TFTransfoXLForSequenceClassification"),tSt.forEach(t),nLr=r(Aje," (Transformer-XL model)"),Aje.forEach(t),sLr=i(ne),r4=n(ne,"LI",{});var Lje=s(r4);V7e=n(Lje,"STRONG",{});var aSt=s(V7e);lLr=r(aSt,"xlm"),aSt.forEach(t),iLr=r(Lje," \u2014 "),PY=n(Lje,"A",{href:!0});var nSt=s(PY);dLr=r(nSt,"TFXLMForSequenceClassification"),nSt.forEach(t),cLr=r(Lje," (XLM model)"),Lje.forEach(t),fLr=i(ne),t4=n(ne,"LI",{});var yje=s(t4);X7e=n(yje,"STRONG",{});var sSt=s(X7e);mLr=r(sSt,"xlm-roberta"),sSt.forEach(t),gLr=r(yje," \u2014 "),BY=n(yje,"A",{href:!0});var lSt=s(BY);hLr=r(lSt,"TFXLMRobertaForSequenceClassification"),lSt.forEach(t),pLr=r(yje," (XLM-RoBERTa model)"),yje.forEach(t),_Lr=i(ne),a4=n(ne,"LI",{});var xje=s(a4);z7e=n(xje,"STRONG",{});var iSt=s(z7e);uLr=r(iSt,"xlnet"),iSt.forEach(t),bLr=r(xje," \u2014 "),IY=n(xje,"A",{href:!0});var dSt=s(IY);vLr=r(dSt,"TFXLNetForSequenceClassification"),dSt.forEach(t),FLr=r(xje," (XLNet model)"),xje.forEach(t),ne.forEach(t),TLr=i(Dl),T(n4.$$.fragment,Dl),Dl.forEach(t),jl.forEach(t),lXe=i(f),wc=n(f,"H2",{class:!0});var pWe=s(wc);s4=n(pWe,"A",{id:!0,class:!0,href:!0});var cSt=s(s4);W7e=n(cSt,"SPAN",{});var fSt=s(W7e);T(dx.$$.fragment,fSt),fSt.forEach(t),cSt.forEach(t),MLr=i(pWe),Q7e=n(pWe,"SPAN",{});var mSt=s(Q7e);ELr=r(mSt,"TFAutoModelForMultipleChoice"),mSt.forEach(t),pWe.forEach(t),iXe=i(f),ir=n(f,"DIV",{class:!0});var Gl=s(ir);T(cx.$$.fragment,Gl),CLr=i(Gl),Ac=n(Gl,"P",{});var ste=s(Ac);wLr=r(ste,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),NY=n(ste,"A",{href:!0});var gSt=s(NY);ALr=r(gSt,"from_pretrained()"),gSt.forEach(t),LLr=r(ste," class method or the "),qY=n(ste,"A",{href:!0});var hSt=s(qY);yLr=r(hSt,"from_config()"),hSt.forEach(t),xLr=r(ste,` class
method.`),ste.forEach(t),$Lr=i(Gl),fx=n(Gl,"P",{});var _We=s(fx);kLr=r(_We,"This class cannot be instantiated directly using "),H7e=n(_We,"CODE",{});var pSt=s(H7e);SLr=r(pSt,"__init__()"),pSt.forEach(t),RLr=r(_We," (throws an error)."),_We.forEach(t),PLr=i(Gl),qt=n(Gl,"DIV",{class:!0});var eA=s(qt);T(mx.$$.fragment,eA),BLr=i(eA),U7e=n(eA,"P",{});var _St=s(U7e);ILr=r(_St,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),_St.forEach(t),NLr=i(eA),Lc=n(eA,"P",{});var lte=s(Lc);qLr=r(lte,`Note:
Loading a model from its configuration file does `),J7e=n(lte,"STRONG",{});var uSt=s(J7e);jLr=r(uSt,"not"),uSt.forEach(t),DLr=r(lte,` load the model weights. It only affects the
model\u2019s configuration. Use `),jY=n(lte,"A",{href:!0});var bSt=s(jY);GLr=r(bSt,"from_pretrained()"),bSt.forEach(t),OLr=r(lte," to load the model weights."),lte.forEach(t),VLr=i(eA),T(l4.$$.fragment,eA),eA.forEach(t),XLr=i(Gl),Ir=n(Gl,"DIV",{class:!0});var Ol=s(Ir);T(gx.$$.fragment,Ol),zLr=i(Ol),Y7e=n(Ol,"P",{});var vSt=s(Y7e);WLr=r(vSt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),vSt.forEach(t),QLr=i(Ol),hn=n(Ol,"P",{});var oA=s(hn);HLr=r(oA,"The model class to instantiate is selected based on the "),K7e=n(oA,"CODE",{});var FSt=s(K7e);ULr=r(FSt,"model_type"),FSt.forEach(t),JLr=r(oA,` property of the config object (either
passed as an argument or loaded from `),Z7e=n(oA,"CODE",{});var TSt=s(Z7e);YLr=r(TSt,"pretrained_model_name_or_path"),TSt.forEach(t),KLr=r(oA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e8e=n(oA,"CODE",{});var MSt=s(e8e);ZLr=r(MSt,"pretrained_model_name_or_path"),MSt.forEach(t),eyr=r(oA,":"),oA.forEach(t),oyr=i(Ol),_e=n(Ol,"UL",{});var ve=s(_e);i4=n(ve,"LI",{});var $je=s(i4);o8e=n($je,"STRONG",{});var ESt=s(o8e);ryr=r(ESt,"albert"),ESt.forEach(t),tyr=r($je," \u2014 "),DY=n($je,"A",{href:!0});var CSt=s(DY);ayr=r(CSt,"TFAlbertForMultipleChoice"),CSt.forEach(t),nyr=r($je," (ALBERT model)"),$je.forEach(t),syr=i(ve),d4=n(ve,"LI",{});var kje=s(d4);r8e=n(kje,"STRONG",{});var wSt=s(r8e);lyr=r(wSt,"bert"),wSt.forEach(t),iyr=r(kje," \u2014 "),GY=n(kje,"A",{href:!0});var ASt=s(GY);dyr=r(ASt,"TFBertForMultipleChoice"),ASt.forEach(t),cyr=r(kje," (BERT model)"),kje.forEach(t),fyr=i(ve),c4=n(ve,"LI",{});var Sje=s(c4);t8e=n(Sje,"STRONG",{});var LSt=s(t8e);myr=r(LSt,"camembert"),LSt.forEach(t),gyr=r(Sje," \u2014 "),OY=n(Sje,"A",{href:!0});var ySt=s(OY);hyr=r(ySt,"TFCamembertForMultipleChoice"),ySt.forEach(t),pyr=r(Sje," (CamemBERT model)"),Sje.forEach(t),_yr=i(ve),f4=n(ve,"LI",{});var Rje=s(f4);a8e=n(Rje,"STRONG",{});var xSt=s(a8e);uyr=r(xSt,"convbert"),xSt.forEach(t),byr=r(Rje," \u2014 "),VY=n(Rje,"A",{href:!0});var $St=s(VY);vyr=r($St,"TFConvBertForMultipleChoice"),$St.forEach(t),Fyr=r(Rje," (ConvBERT model)"),Rje.forEach(t),Tyr=i(ve),m4=n(ve,"LI",{});var Pje=s(m4);n8e=n(Pje,"STRONG",{});var kSt=s(n8e);Myr=r(kSt,"distilbert"),kSt.forEach(t),Eyr=r(Pje," \u2014 "),XY=n(Pje,"A",{href:!0});var SSt=s(XY);Cyr=r(SSt,"TFDistilBertForMultipleChoice"),SSt.forEach(t),wyr=r(Pje," (DistilBERT model)"),Pje.forEach(t),Ayr=i(ve),g4=n(ve,"LI",{});var Bje=s(g4);s8e=n(Bje,"STRONG",{});var RSt=s(s8e);Lyr=r(RSt,"electra"),RSt.forEach(t),yyr=r(Bje," \u2014 "),zY=n(Bje,"A",{href:!0});var PSt=s(zY);xyr=r(PSt,"TFElectraForMultipleChoice"),PSt.forEach(t),$yr=r(Bje," (ELECTRA model)"),Bje.forEach(t),kyr=i(ve),h4=n(ve,"LI",{});var Ije=s(h4);l8e=n(Ije,"STRONG",{});var BSt=s(l8e);Syr=r(BSt,"flaubert"),BSt.forEach(t),Ryr=r(Ije," \u2014 "),WY=n(Ije,"A",{href:!0});var ISt=s(WY);Pyr=r(ISt,"TFFlaubertForMultipleChoice"),ISt.forEach(t),Byr=r(Ije," (FlauBERT model)"),Ije.forEach(t),Iyr=i(ve),p4=n(ve,"LI",{});var Nje=s(p4);i8e=n(Nje,"STRONG",{});var NSt=s(i8e);Nyr=r(NSt,"funnel"),NSt.forEach(t),qyr=r(Nje," \u2014 "),QY=n(Nje,"A",{href:!0});var qSt=s(QY);jyr=r(qSt,"TFFunnelForMultipleChoice"),qSt.forEach(t),Dyr=r(Nje," (Funnel Transformer model)"),Nje.forEach(t),Gyr=i(ve),_4=n(ve,"LI",{});var qje=s(_4);d8e=n(qje,"STRONG",{});var jSt=s(d8e);Oyr=r(jSt,"longformer"),jSt.forEach(t),Vyr=r(qje," \u2014 "),HY=n(qje,"A",{href:!0});var DSt=s(HY);Xyr=r(DSt,"TFLongformerForMultipleChoice"),DSt.forEach(t),zyr=r(qje," (Longformer model)"),qje.forEach(t),Wyr=i(ve),u4=n(ve,"LI",{});var jje=s(u4);c8e=n(jje,"STRONG",{});var GSt=s(c8e);Qyr=r(GSt,"mobilebert"),GSt.forEach(t),Hyr=r(jje," \u2014 "),UY=n(jje,"A",{href:!0});var OSt=s(UY);Uyr=r(OSt,"TFMobileBertForMultipleChoice"),OSt.forEach(t),Jyr=r(jje," (MobileBERT model)"),jje.forEach(t),Yyr=i(ve),b4=n(ve,"LI",{});var Dje=s(b4);f8e=n(Dje,"STRONG",{});var VSt=s(f8e);Kyr=r(VSt,"mpnet"),VSt.forEach(t),Zyr=r(Dje," \u2014 "),JY=n(Dje,"A",{href:!0});var XSt=s(JY);e9r=r(XSt,"TFMPNetForMultipleChoice"),XSt.forEach(t),o9r=r(Dje," (MPNet model)"),Dje.forEach(t),r9r=i(ve),v4=n(ve,"LI",{});var Gje=s(v4);m8e=n(Gje,"STRONG",{});var zSt=s(m8e);t9r=r(zSt,"rembert"),zSt.forEach(t),a9r=r(Gje," \u2014 "),YY=n(Gje,"A",{href:!0});var WSt=s(YY);n9r=r(WSt,"TFRemBertForMultipleChoice"),WSt.forEach(t),s9r=r(Gje," (RemBERT model)"),Gje.forEach(t),l9r=i(ve),F4=n(ve,"LI",{});var Oje=s(F4);g8e=n(Oje,"STRONG",{});var QSt=s(g8e);i9r=r(QSt,"roberta"),QSt.forEach(t),d9r=r(Oje," \u2014 "),KY=n(Oje,"A",{href:!0});var HSt=s(KY);c9r=r(HSt,"TFRobertaForMultipleChoice"),HSt.forEach(t),f9r=r(Oje," (RoBERTa model)"),Oje.forEach(t),m9r=i(ve),T4=n(ve,"LI",{});var Vje=s(T4);h8e=n(Vje,"STRONG",{});var USt=s(h8e);g9r=r(USt,"roformer"),USt.forEach(t),h9r=r(Vje," \u2014 "),ZY=n(Vje,"A",{href:!0});var JSt=s(ZY);p9r=r(JSt,"TFRoFormerForMultipleChoice"),JSt.forEach(t),_9r=r(Vje," (RoFormer model)"),Vje.forEach(t),u9r=i(ve),M4=n(ve,"LI",{});var Xje=s(M4);p8e=n(Xje,"STRONG",{});var YSt=s(p8e);b9r=r(YSt,"xlm"),YSt.forEach(t),v9r=r(Xje," \u2014 "),eK=n(Xje,"A",{href:!0});var KSt=s(eK);F9r=r(KSt,"TFXLMForMultipleChoice"),KSt.forEach(t),T9r=r(Xje," (XLM model)"),Xje.forEach(t),M9r=i(ve),E4=n(ve,"LI",{});var zje=s(E4);_8e=n(zje,"STRONG",{});var ZSt=s(_8e);E9r=r(ZSt,"xlm-roberta"),ZSt.forEach(t),C9r=r(zje," \u2014 "),oK=n(zje,"A",{href:!0});var eRt=s(oK);w9r=r(eRt,"TFXLMRobertaForMultipleChoice"),eRt.forEach(t),A9r=r(zje," (XLM-RoBERTa model)"),zje.forEach(t),L9r=i(ve),C4=n(ve,"LI",{});var Wje=s(C4);u8e=n(Wje,"STRONG",{});var oRt=s(u8e);y9r=r(oRt,"xlnet"),oRt.forEach(t),x9r=r(Wje," \u2014 "),rK=n(Wje,"A",{href:!0});var rRt=s(rK);$9r=r(rRt,"TFXLNetForMultipleChoice"),rRt.forEach(t),k9r=r(Wje," (XLNet model)"),Wje.forEach(t),ve.forEach(t),S9r=i(Ol),T(w4.$$.fragment,Ol),Ol.forEach(t),Gl.forEach(t),dXe=i(f),yc=n(f,"H2",{class:!0});var uWe=s(yc);A4=n(uWe,"A",{id:!0,class:!0,href:!0});var tRt=s(A4);b8e=n(tRt,"SPAN",{});var aRt=s(b8e);T(hx.$$.fragment,aRt),aRt.forEach(t),tRt.forEach(t),R9r=i(uWe),v8e=n(uWe,"SPAN",{});var nRt=s(v8e);P9r=r(nRt,"TFAutoModelForNextSentencePrediction"),nRt.forEach(t),uWe.forEach(t),cXe=i(f),dr=n(f,"DIV",{class:!0});var Vl=s(dr);T(px.$$.fragment,Vl),B9r=i(Vl),xc=n(Vl,"P",{});var ite=s(xc);I9r=r(ite,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),tK=n(ite,"A",{href:!0});var sRt=s(tK);N9r=r(sRt,"from_pretrained()"),sRt.forEach(t),q9r=r(ite," class method or the "),aK=n(ite,"A",{href:!0});var lRt=s(aK);j9r=r(lRt,"from_config()"),lRt.forEach(t),D9r=r(ite,` class
method.`),ite.forEach(t),G9r=i(Vl),_x=n(Vl,"P",{});var bWe=s(_x);O9r=r(bWe,"This class cannot be instantiated directly using "),F8e=n(bWe,"CODE",{});var iRt=s(F8e);V9r=r(iRt,"__init__()"),iRt.forEach(t),X9r=r(bWe," (throws an error)."),bWe.forEach(t),z9r=i(Vl),jt=n(Vl,"DIV",{class:!0});var rA=s(jt);T(ux.$$.fragment,rA),W9r=i(rA),T8e=n(rA,"P",{});var dRt=s(T8e);Q9r=r(dRt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),dRt.forEach(t),H9r=i(rA),$c=n(rA,"P",{});var dte=s($c);U9r=r(dte,`Note:
Loading a model from its configuration file does `),M8e=n(dte,"STRONG",{});var cRt=s(M8e);J9r=r(cRt,"not"),cRt.forEach(t),Y9r=r(dte,` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=n(dte,"A",{href:!0});var fRt=s(nK);K9r=r(fRt,"from_pretrained()"),fRt.forEach(t),Z9r=r(dte," to load the model weights."),dte.forEach(t),exr=i(rA),T(L4.$$.fragment,rA),rA.forEach(t),oxr=i(Vl),Nr=n(Vl,"DIV",{class:!0});var Xl=s(Nr);T(bx.$$.fragment,Xl),rxr=i(Xl),E8e=n(Xl,"P",{});var mRt=s(E8e);txr=r(mRt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),mRt.forEach(t),axr=i(Xl),pn=n(Xl,"P",{});var tA=s(pn);nxr=r(tA,"The model class to instantiate is selected based on the "),C8e=n(tA,"CODE",{});var gRt=s(C8e);sxr=r(gRt,"model_type"),gRt.forEach(t),lxr=r(tA,` property of the config object (either
passed as an argument or loaded from `),w8e=n(tA,"CODE",{});var hRt=s(w8e);ixr=r(hRt,"pretrained_model_name_or_path"),hRt.forEach(t),dxr=r(tA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A8e=n(tA,"CODE",{});var pRt=s(A8e);cxr=r(pRt,"pretrained_model_name_or_path"),pRt.forEach(t),fxr=r(tA,":"),tA.forEach(t),mxr=i(Xl),vx=n(Xl,"UL",{});var vWe=s(vx);y4=n(vWe,"LI",{});var Qje=s(y4);L8e=n(Qje,"STRONG",{});var _Rt=s(L8e);gxr=r(_Rt,"bert"),_Rt.forEach(t),hxr=r(Qje," \u2014 "),sK=n(Qje,"A",{href:!0});var uRt=s(sK);pxr=r(uRt,"TFBertForNextSentencePrediction"),uRt.forEach(t),_xr=r(Qje," (BERT model)"),Qje.forEach(t),uxr=i(vWe),x4=n(vWe,"LI",{});var Hje=s(x4);y8e=n(Hje,"STRONG",{});var bRt=s(y8e);bxr=r(bRt,"mobilebert"),bRt.forEach(t),vxr=r(Hje," \u2014 "),lK=n(Hje,"A",{href:!0});var vRt=s(lK);Fxr=r(vRt,"TFMobileBertForNextSentencePrediction"),vRt.forEach(t),Txr=r(Hje," (MobileBERT model)"),Hje.forEach(t),vWe.forEach(t),Mxr=i(Xl),T($4.$$.fragment,Xl),Xl.forEach(t),Vl.forEach(t),fXe=i(f),kc=n(f,"H2",{class:!0});var FWe=s(kc);k4=n(FWe,"A",{id:!0,class:!0,href:!0});var FRt=s(k4);x8e=n(FRt,"SPAN",{});var TRt=s(x8e);T(Fx.$$.fragment,TRt),TRt.forEach(t),FRt.forEach(t),Exr=i(FWe),$8e=n(FWe,"SPAN",{});var MRt=s($8e);Cxr=r(MRt,"TFAutoModelForTableQuestionAnswering"),MRt.forEach(t),FWe.forEach(t),mXe=i(f),cr=n(f,"DIV",{class:!0});var zl=s(cr);T(Tx.$$.fragment,zl),wxr=i(zl),Sc=n(zl,"P",{});var cte=s(Sc);Axr=r(cte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),iK=n(cte,"A",{href:!0});var ERt=s(iK);Lxr=r(ERt,"from_pretrained()"),ERt.forEach(t),yxr=r(cte," class method or the "),dK=n(cte,"A",{href:!0});var CRt=s(dK);xxr=r(CRt,"from_config()"),CRt.forEach(t),$xr=r(cte,` class
method.`),cte.forEach(t),kxr=i(zl),Mx=n(zl,"P",{});var TWe=s(Mx);Sxr=r(TWe,"This class cannot be instantiated directly using "),k8e=n(TWe,"CODE",{});var wRt=s(k8e);Rxr=r(wRt,"__init__()"),wRt.forEach(t),Pxr=r(TWe," (throws an error)."),TWe.forEach(t),Bxr=i(zl),Dt=n(zl,"DIV",{class:!0});var aA=s(Dt);T(Ex.$$.fragment,aA),Ixr=i(aA),S8e=n(aA,"P",{});var ARt=s(S8e);Nxr=r(ARt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),ARt.forEach(t),qxr=i(aA),Rc=n(aA,"P",{});var fte=s(Rc);jxr=r(fte,`Note:
Loading a model from its configuration file does `),R8e=n(fte,"STRONG",{});var LRt=s(R8e);Dxr=r(LRt,"not"),LRt.forEach(t),Gxr=r(fte,` load the model weights. It only affects the
model\u2019s configuration. Use `),cK=n(fte,"A",{href:!0});var yRt=s(cK);Oxr=r(yRt,"from_pretrained()"),yRt.forEach(t),Vxr=r(fte," to load the model weights."),fte.forEach(t),Xxr=i(aA),T(S4.$$.fragment,aA),aA.forEach(t),zxr=i(zl),qr=n(zl,"DIV",{class:!0});var Wl=s(qr);T(Cx.$$.fragment,Wl),Wxr=i(Wl),P8e=n(Wl,"P",{});var xRt=s(P8e);Qxr=r(xRt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),xRt.forEach(t),Hxr=i(Wl),_n=n(Wl,"P",{});var nA=s(_n);Uxr=r(nA,"The model class to instantiate is selected based on the "),B8e=n(nA,"CODE",{});var $Rt=s(B8e);Jxr=r($Rt,"model_type"),$Rt.forEach(t),Yxr=r(nA,` property of the config object (either
passed as an argument or loaded from `),I8e=n(nA,"CODE",{});var kRt=s(I8e);Kxr=r(kRt,"pretrained_model_name_or_path"),kRt.forEach(t),Zxr=r(nA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N8e=n(nA,"CODE",{});var SRt=s(N8e);e$r=r(SRt,"pretrained_model_name_or_path"),SRt.forEach(t),o$r=r(nA,":"),nA.forEach(t),r$r=i(Wl),q8e=n(Wl,"UL",{});var RRt=s(q8e);R4=n(RRt,"LI",{});var Uje=s(R4);j8e=n(Uje,"STRONG",{});var PRt=s(j8e);t$r=r(PRt,"tapas"),PRt.forEach(t),a$r=r(Uje," \u2014 "),fK=n(Uje,"A",{href:!0});var BRt=s(fK);n$r=r(BRt,"TFTapasForQuestionAnswering"),BRt.forEach(t),s$r=r(Uje," (TAPAS model)"),Uje.forEach(t),RRt.forEach(t),l$r=i(Wl),T(P4.$$.fragment,Wl),Wl.forEach(t),zl.forEach(t),gXe=i(f),Pc=n(f,"H2",{class:!0});var MWe=s(Pc);B4=n(MWe,"A",{id:!0,class:!0,href:!0});var IRt=s(B4);D8e=n(IRt,"SPAN",{});var NRt=s(D8e);T(wx.$$.fragment,NRt),NRt.forEach(t),IRt.forEach(t),i$r=i(MWe),G8e=n(MWe,"SPAN",{});var qRt=s(G8e);d$r=r(qRt,"TFAutoModelForTokenClassification"),qRt.forEach(t),MWe.forEach(t),hXe=i(f),fr=n(f,"DIV",{class:!0});var Ql=s(fr);T(Ax.$$.fragment,Ql),c$r=i(Ql),Bc=n(Ql,"P",{});var mte=s(Bc);f$r=r(mte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),mK=n(mte,"A",{href:!0});var jRt=s(mK);m$r=r(jRt,"from_pretrained()"),jRt.forEach(t),g$r=r(mte," class method or the "),gK=n(mte,"A",{href:!0});var DRt=s(gK);h$r=r(DRt,"from_config()"),DRt.forEach(t),p$r=r(mte,` class
method.`),mte.forEach(t),_$r=i(Ql),Lx=n(Ql,"P",{});var EWe=s(Lx);u$r=r(EWe,"This class cannot be instantiated directly using "),O8e=n(EWe,"CODE",{});var GRt=s(O8e);b$r=r(GRt,"__init__()"),GRt.forEach(t),v$r=r(EWe," (throws an error)."),EWe.forEach(t),F$r=i(Ql),Gt=n(Ql,"DIV",{class:!0});var sA=s(Gt);T(yx.$$.fragment,sA),T$r=i(sA),V8e=n(sA,"P",{});var ORt=s(V8e);M$r=r(ORt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),ORt.forEach(t),E$r=i(sA),Ic=n(sA,"P",{});var gte=s(Ic);C$r=r(gte,`Note:
Loading a model from its configuration file does `),X8e=n(gte,"STRONG",{});var VRt=s(X8e);w$r=r(VRt,"not"),VRt.forEach(t),A$r=r(gte,` load the model weights. It only affects the
model\u2019s configuration. Use `),hK=n(gte,"A",{href:!0});var XRt=s(hK);L$r=r(XRt,"from_pretrained()"),XRt.forEach(t),y$r=r(gte," to load the model weights."),gte.forEach(t),x$r=i(sA),T(I4.$$.fragment,sA),sA.forEach(t),$$r=i(Ql),jr=n(Ql,"DIV",{class:!0});var Hl=s(jr);T(xx.$$.fragment,Hl),k$r=i(Hl),z8e=n(Hl,"P",{});var zRt=s(z8e);S$r=r(zRt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),zRt.forEach(t),R$r=i(Hl),un=n(Hl,"P",{});var lA=s(un);P$r=r(lA,"The model class to instantiate is selected based on the "),W8e=n(lA,"CODE",{});var WRt=s(W8e);B$r=r(WRt,"model_type"),WRt.forEach(t),I$r=r(lA,` property of the config object (either
passed as an argument or loaded from `),Q8e=n(lA,"CODE",{});var QRt=s(Q8e);N$r=r(QRt,"pretrained_model_name_or_path"),QRt.forEach(t),q$r=r(lA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H8e=n(lA,"CODE",{});var HRt=s(H8e);j$r=r(HRt,"pretrained_model_name_or_path"),HRt.forEach(t),D$r=r(lA,":"),lA.forEach(t),G$r=i(Hl),de=n(Hl,"UL",{});var me=s(de);N4=n(me,"LI",{});var Jje=s(N4);U8e=n(Jje,"STRONG",{});var URt=s(U8e);O$r=r(URt,"albert"),URt.forEach(t),V$r=r(Jje," \u2014 "),pK=n(Jje,"A",{href:!0});var JRt=s(pK);X$r=r(JRt,"TFAlbertForTokenClassification"),JRt.forEach(t),z$r=r(Jje," (ALBERT model)"),Jje.forEach(t),W$r=i(me),q4=n(me,"LI",{});var Yje=s(q4);J8e=n(Yje,"STRONG",{});var YRt=s(J8e);Q$r=r(YRt,"bert"),YRt.forEach(t),H$r=r(Yje," \u2014 "),_K=n(Yje,"A",{href:!0});var KRt=s(_K);U$r=r(KRt,"TFBertForTokenClassification"),KRt.forEach(t),J$r=r(Yje," (BERT model)"),Yje.forEach(t),Y$r=i(me),j4=n(me,"LI",{});var Kje=s(j4);Y8e=n(Kje,"STRONG",{});var ZRt=s(Y8e);K$r=r(ZRt,"camembert"),ZRt.forEach(t),Z$r=r(Kje," \u2014 "),uK=n(Kje,"A",{href:!0});var ePt=s(uK);ekr=r(ePt,"TFCamembertForTokenClassification"),ePt.forEach(t),okr=r(Kje," (CamemBERT model)"),Kje.forEach(t),rkr=i(me),D4=n(me,"LI",{});var Zje=s(D4);K8e=n(Zje,"STRONG",{});var oPt=s(K8e);tkr=r(oPt,"convbert"),oPt.forEach(t),akr=r(Zje," \u2014 "),bK=n(Zje,"A",{href:!0});var rPt=s(bK);nkr=r(rPt,"TFConvBertForTokenClassification"),rPt.forEach(t),skr=r(Zje," (ConvBERT model)"),Zje.forEach(t),lkr=i(me),G4=n(me,"LI",{});var eDe=s(G4);Z8e=n(eDe,"STRONG",{});var tPt=s(Z8e);ikr=r(tPt,"deberta"),tPt.forEach(t),dkr=r(eDe," \u2014 "),vK=n(eDe,"A",{href:!0});var aPt=s(vK);ckr=r(aPt,"TFDebertaForTokenClassification"),aPt.forEach(t),fkr=r(eDe," (DeBERTa model)"),eDe.forEach(t),mkr=i(me),O4=n(me,"LI",{});var oDe=s(O4);eMe=n(oDe,"STRONG",{});var nPt=s(eMe);gkr=r(nPt,"deberta-v2"),nPt.forEach(t),hkr=r(oDe," \u2014 "),FK=n(oDe,"A",{href:!0});var sPt=s(FK);pkr=r(sPt,"TFDebertaV2ForTokenClassification"),sPt.forEach(t),_kr=r(oDe," (DeBERTa-v2 model)"),oDe.forEach(t),ukr=i(me),V4=n(me,"LI",{});var rDe=s(V4);oMe=n(rDe,"STRONG",{});var lPt=s(oMe);bkr=r(lPt,"distilbert"),lPt.forEach(t),vkr=r(rDe," \u2014 "),TK=n(rDe,"A",{href:!0});var iPt=s(TK);Fkr=r(iPt,"TFDistilBertForTokenClassification"),iPt.forEach(t),Tkr=r(rDe," (DistilBERT model)"),rDe.forEach(t),Mkr=i(me),X4=n(me,"LI",{});var tDe=s(X4);rMe=n(tDe,"STRONG",{});var dPt=s(rMe);Ekr=r(dPt,"electra"),dPt.forEach(t),Ckr=r(tDe," \u2014 "),MK=n(tDe,"A",{href:!0});var cPt=s(MK);wkr=r(cPt,"TFElectraForTokenClassification"),cPt.forEach(t),Akr=r(tDe," (ELECTRA model)"),tDe.forEach(t),Lkr=i(me),z4=n(me,"LI",{});var aDe=s(z4);tMe=n(aDe,"STRONG",{});var fPt=s(tMe);ykr=r(fPt,"flaubert"),fPt.forEach(t),xkr=r(aDe," \u2014 "),EK=n(aDe,"A",{href:!0});var mPt=s(EK);$kr=r(mPt,"TFFlaubertForTokenClassification"),mPt.forEach(t),kkr=r(aDe," (FlauBERT model)"),aDe.forEach(t),Skr=i(me),W4=n(me,"LI",{});var nDe=s(W4);aMe=n(nDe,"STRONG",{});var gPt=s(aMe);Rkr=r(gPt,"funnel"),gPt.forEach(t),Pkr=r(nDe," \u2014 "),CK=n(nDe,"A",{href:!0});var hPt=s(CK);Bkr=r(hPt,"TFFunnelForTokenClassification"),hPt.forEach(t),Ikr=r(nDe," (Funnel Transformer model)"),nDe.forEach(t),Nkr=i(me),Q4=n(me,"LI",{});var sDe=s(Q4);nMe=n(sDe,"STRONG",{});var pPt=s(nMe);qkr=r(pPt,"layoutlm"),pPt.forEach(t),jkr=r(sDe," \u2014 "),wK=n(sDe,"A",{href:!0});var _Pt=s(wK);Dkr=r(_Pt,"TFLayoutLMForTokenClassification"),_Pt.forEach(t),Gkr=r(sDe," (LayoutLM model)"),sDe.forEach(t),Okr=i(me),H4=n(me,"LI",{});var lDe=s(H4);sMe=n(lDe,"STRONG",{});var uPt=s(sMe);Vkr=r(uPt,"longformer"),uPt.forEach(t),Xkr=r(lDe," \u2014 "),AK=n(lDe,"A",{href:!0});var bPt=s(AK);zkr=r(bPt,"TFLongformerForTokenClassification"),bPt.forEach(t),Wkr=r(lDe," (Longformer model)"),lDe.forEach(t),Qkr=i(me),U4=n(me,"LI",{});var iDe=s(U4);lMe=n(iDe,"STRONG",{});var vPt=s(lMe);Hkr=r(vPt,"mobilebert"),vPt.forEach(t),Ukr=r(iDe," \u2014 "),LK=n(iDe,"A",{href:!0});var FPt=s(LK);Jkr=r(FPt,"TFMobileBertForTokenClassification"),FPt.forEach(t),Ykr=r(iDe," (MobileBERT model)"),iDe.forEach(t),Kkr=i(me),J4=n(me,"LI",{});var dDe=s(J4);iMe=n(dDe,"STRONG",{});var TPt=s(iMe);Zkr=r(TPt,"mpnet"),TPt.forEach(t),eSr=r(dDe," \u2014 "),yK=n(dDe,"A",{href:!0});var MPt=s(yK);oSr=r(MPt,"TFMPNetForTokenClassification"),MPt.forEach(t),rSr=r(dDe," (MPNet model)"),dDe.forEach(t),tSr=i(me),Y4=n(me,"LI",{});var cDe=s(Y4);dMe=n(cDe,"STRONG",{});var EPt=s(dMe);aSr=r(EPt,"rembert"),EPt.forEach(t),nSr=r(cDe," \u2014 "),xK=n(cDe,"A",{href:!0});var CPt=s(xK);sSr=r(CPt,"TFRemBertForTokenClassification"),CPt.forEach(t),lSr=r(cDe," (RemBERT model)"),cDe.forEach(t),iSr=i(me),K4=n(me,"LI",{});var fDe=s(K4);cMe=n(fDe,"STRONG",{});var wPt=s(cMe);dSr=r(wPt,"roberta"),wPt.forEach(t),cSr=r(fDe," \u2014 "),$K=n(fDe,"A",{href:!0});var APt=s($K);fSr=r(APt,"TFRobertaForTokenClassification"),APt.forEach(t),mSr=r(fDe," (RoBERTa model)"),fDe.forEach(t),gSr=i(me),Z4=n(me,"LI",{});var mDe=s(Z4);fMe=n(mDe,"STRONG",{});var LPt=s(fMe);hSr=r(LPt,"roformer"),LPt.forEach(t),pSr=r(mDe," \u2014 "),kK=n(mDe,"A",{href:!0});var yPt=s(kK);_Sr=r(yPt,"TFRoFormerForTokenClassification"),yPt.forEach(t),uSr=r(mDe," (RoFormer model)"),mDe.forEach(t),bSr=i(me),eE=n(me,"LI",{});var gDe=s(eE);mMe=n(gDe,"STRONG",{});var xPt=s(mMe);vSr=r(xPt,"xlm"),xPt.forEach(t),FSr=r(gDe," \u2014 "),SK=n(gDe,"A",{href:!0});var $Pt=s(SK);TSr=r($Pt,"TFXLMForTokenClassification"),$Pt.forEach(t),MSr=r(gDe," (XLM model)"),gDe.forEach(t),ESr=i(me),oE=n(me,"LI",{});var hDe=s(oE);gMe=n(hDe,"STRONG",{});var kPt=s(gMe);CSr=r(kPt,"xlm-roberta"),kPt.forEach(t),wSr=r(hDe," \u2014 "),RK=n(hDe,"A",{href:!0});var SPt=s(RK);ASr=r(SPt,"TFXLMRobertaForTokenClassification"),SPt.forEach(t),LSr=r(hDe," (XLM-RoBERTa model)"),hDe.forEach(t),ySr=i(me),rE=n(me,"LI",{});var pDe=s(rE);hMe=n(pDe,"STRONG",{});var RPt=s(hMe);xSr=r(RPt,"xlnet"),RPt.forEach(t),$Sr=r(pDe," \u2014 "),PK=n(pDe,"A",{href:!0});var PPt=s(PK);kSr=r(PPt,"TFXLNetForTokenClassification"),PPt.forEach(t),SSr=r(pDe," (XLNet model)"),pDe.forEach(t),me.forEach(t),RSr=i(Hl),T(tE.$$.fragment,Hl),Hl.forEach(t),Ql.forEach(t),pXe=i(f),Nc=n(f,"H2",{class:!0});var CWe=s(Nc);aE=n(CWe,"A",{id:!0,class:!0,href:!0});var BPt=s(aE);pMe=n(BPt,"SPAN",{});var IPt=s(pMe);T($x.$$.fragment,IPt),IPt.forEach(t),BPt.forEach(t),PSr=i(CWe),_Me=n(CWe,"SPAN",{});var NPt=s(_Me);BSr=r(NPt,"TFAutoModelForQuestionAnswering"),NPt.forEach(t),CWe.forEach(t),_Xe=i(f),mr=n(f,"DIV",{class:!0});var Ul=s(mr);T(kx.$$.fragment,Ul),ISr=i(Ul),qc=n(Ul,"P",{});var hte=s(qc);NSr=r(hte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),BK=n(hte,"A",{href:!0});var qPt=s(BK);qSr=r(qPt,"from_pretrained()"),qPt.forEach(t),jSr=r(hte," class method or the "),IK=n(hte,"A",{href:!0});var jPt=s(IK);DSr=r(jPt,"from_config()"),jPt.forEach(t),GSr=r(hte,` class
method.`),hte.forEach(t),OSr=i(Ul),Sx=n(Ul,"P",{});var wWe=s(Sx);VSr=r(wWe,"This class cannot be instantiated directly using "),uMe=n(wWe,"CODE",{});var DPt=s(uMe);XSr=r(DPt,"__init__()"),DPt.forEach(t),zSr=r(wWe," (throws an error)."),wWe.forEach(t),WSr=i(Ul),Ot=n(Ul,"DIV",{class:!0});var iA=s(Ot);T(Rx.$$.fragment,iA),QSr=i(iA),bMe=n(iA,"P",{});var GPt=s(bMe);HSr=r(GPt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),GPt.forEach(t),USr=i(iA),jc=n(iA,"P",{});var pte=s(jc);JSr=r(pte,`Note:
Loading a model from its configuration file does `),vMe=n(pte,"STRONG",{});var OPt=s(vMe);YSr=r(OPt,"not"),OPt.forEach(t),KSr=r(pte,` load the model weights. It only affects the
model\u2019s configuration. Use `),NK=n(pte,"A",{href:!0});var VPt=s(NK);ZSr=r(VPt,"from_pretrained()"),VPt.forEach(t),eRr=r(pte," to load the model weights."),pte.forEach(t),oRr=i(iA),T(nE.$$.fragment,iA),iA.forEach(t),rRr=i(Ul),Dr=n(Ul,"DIV",{class:!0});var Jl=s(Dr);T(Px.$$.fragment,Jl),tRr=i(Jl),FMe=n(Jl,"P",{});var XPt=s(FMe);aRr=r(XPt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),XPt.forEach(t),nRr=i(Jl),bn=n(Jl,"P",{});var dA=s(bn);sRr=r(dA,"The model class to instantiate is selected based on the "),TMe=n(dA,"CODE",{});var zPt=s(TMe);lRr=r(zPt,"model_type"),zPt.forEach(t),iRr=r(dA,` property of the config object (either
passed as an argument or loaded from `),MMe=n(dA,"CODE",{});var WPt=s(MMe);dRr=r(WPt,"pretrained_model_name_or_path"),WPt.forEach(t),cRr=r(dA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EMe=n(dA,"CODE",{});var QPt=s(EMe);fRr=r(QPt,"pretrained_model_name_or_path"),QPt.forEach(t),mRr=r(dA,":"),dA.forEach(t),gRr=i(Jl),ce=n(Jl,"UL",{});var ge=s(ce);sE=n(ge,"LI",{});var _De=s(sE);CMe=n(_De,"STRONG",{});var HPt=s(CMe);hRr=r(HPt,"albert"),HPt.forEach(t),pRr=r(_De," \u2014 "),qK=n(_De,"A",{href:!0});var UPt=s(qK);_Rr=r(UPt,"TFAlbertForQuestionAnswering"),UPt.forEach(t),uRr=r(_De," (ALBERT model)"),_De.forEach(t),bRr=i(ge),lE=n(ge,"LI",{});var uDe=s(lE);wMe=n(uDe,"STRONG",{});var JPt=s(wMe);vRr=r(JPt,"bert"),JPt.forEach(t),FRr=r(uDe," \u2014 "),jK=n(uDe,"A",{href:!0});var YPt=s(jK);TRr=r(YPt,"TFBertForQuestionAnswering"),YPt.forEach(t),MRr=r(uDe," (BERT model)"),uDe.forEach(t),ERr=i(ge),iE=n(ge,"LI",{});var bDe=s(iE);AMe=n(bDe,"STRONG",{});var KPt=s(AMe);CRr=r(KPt,"camembert"),KPt.forEach(t),wRr=r(bDe," \u2014 "),DK=n(bDe,"A",{href:!0});var ZPt=s(DK);ARr=r(ZPt,"TFCamembertForQuestionAnswering"),ZPt.forEach(t),LRr=r(bDe," (CamemBERT model)"),bDe.forEach(t),yRr=i(ge),dE=n(ge,"LI",{});var vDe=s(dE);LMe=n(vDe,"STRONG",{});var eBt=s(LMe);xRr=r(eBt,"convbert"),eBt.forEach(t),$Rr=r(vDe," \u2014 "),GK=n(vDe,"A",{href:!0});var oBt=s(GK);kRr=r(oBt,"TFConvBertForQuestionAnswering"),oBt.forEach(t),SRr=r(vDe," (ConvBERT model)"),vDe.forEach(t),RRr=i(ge),cE=n(ge,"LI",{});var FDe=s(cE);yMe=n(FDe,"STRONG",{});var rBt=s(yMe);PRr=r(rBt,"deberta"),rBt.forEach(t),BRr=r(FDe," \u2014 "),OK=n(FDe,"A",{href:!0});var tBt=s(OK);IRr=r(tBt,"TFDebertaForQuestionAnswering"),tBt.forEach(t),NRr=r(FDe," (DeBERTa model)"),FDe.forEach(t),qRr=i(ge),fE=n(ge,"LI",{});var TDe=s(fE);xMe=n(TDe,"STRONG",{});var aBt=s(xMe);jRr=r(aBt,"deberta-v2"),aBt.forEach(t),DRr=r(TDe," \u2014 "),VK=n(TDe,"A",{href:!0});var nBt=s(VK);GRr=r(nBt,"TFDebertaV2ForQuestionAnswering"),nBt.forEach(t),ORr=r(TDe," (DeBERTa-v2 model)"),TDe.forEach(t),VRr=i(ge),mE=n(ge,"LI",{});var MDe=s(mE);$Me=n(MDe,"STRONG",{});var sBt=s($Me);XRr=r(sBt,"distilbert"),sBt.forEach(t),zRr=r(MDe," \u2014 "),XK=n(MDe,"A",{href:!0});var lBt=s(XK);WRr=r(lBt,"TFDistilBertForQuestionAnswering"),lBt.forEach(t),QRr=r(MDe," (DistilBERT model)"),MDe.forEach(t),HRr=i(ge),gE=n(ge,"LI",{});var EDe=s(gE);kMe=n(EDe,"STRONG",{});var iBt=s(kMe);URr=r(iBt,"electra"),iBt.forEach(t),JRr=r(EDe," \u2014 "),zK=n(EDe,"A",{href:!0});var dBt=s(zK);YRr=r(dBt,"TFElectraForQuestionAnswering"),dBt.forEach(t),KRr=r(EDe," (ELECTRA model)"),EDe.forEach(t),ZRr=i(ge),hE=n(ge,"LI",{});var CDe=s(hE);SMe=n(CDe,"STRONG",{});var cBt=s(SMe);ePr=r(cBt,"flaubert"),cBt.forEach(t),oPr=r(CDe," \u2014 "),WK=n(CDe,"A",{href:!0});var fBt=s(WK);rPr=r(fBt,"TFFlaubertForQuestionAnsweringSimple"),fBt.forEach(t),tPr=r(CDe," (FlauBERT model)"),CDe.forEach(t),aPr=i(ge),pE=n(ge,"LI",{});var wDe=s(pE);RMe=n(wDe,"STRONG",{});var mBt=s(RMe);nPr=r(mBt,"funnel"),mBt.forEach(t),sPr=r(wDe," \u2014 "),QK=n(wDe,"A",{href:!0});var gBt=s(QK);lPr=r(gBt,"TFFunnelForQuestionAnswering"),gBt.forEach(t),iPr=r(wDe," (Funnel Transformer model)"),wDe.forEach(t),dPr=i(ge),_E=n(ge,"LI",{});var ADe=s(_E);PMe=n(ADe,"STRONG",{});var hBt=s(PMe);cPr=r(hBt,"gptj"),hBt.forEach(t),fPr=r(ADe," \u2014 "),HK=n(ADe,"A",{href:!0});var pBt=s(HK);mPr=r(pBt,"TFGPTJForQuestionAnswering"),pBt.forEach(t),gPr=r(ADe," (GPT-J model)"),ADe.forEach(t),hPr=i(ge),uE=n(ge,"LI",{});var LDe=s(uE);BMe=n(LDe,"STRONG",{});var _Bt=s(BMe);pPr=r(_Bt,"longformer"),_Bt.forEach(t),_Pr=r(LDe," \u2014 "),UK=n(LDe,"A",{href:!0});var uBt=s(UK);uPr=r(uBt,"TFLongformerForQuestionAnswering"),uBt.forEach(t),bPr=r(LDe," (Longformer model)"),LDe.forEach(t),vPr=i(ge),bE=n(ge,"LI",{});var yDe=s(bE);IMe=n(yDe,"STRONG",{});var bBt=s(IMe);FPr=r(bBt,"mobilebert"),bBt.forEach(t),TPr=r(yDe," \u2014 "),JK=n(yDe,"A",{href:!0});var vBt=s(JK);MPr=r(vBt,"TFMobileBertForQuestionAnswering"),vBt.forEach(t),EPr=r(yDe," (MobileBERT model)"),yDe.forEach(t),CPr=i(ge),vE=n(ge,"LI",{});var xDe=s(vE);NMe=n(xDe,"STRONG",{});var FBt=s(NMe);wPr=r(FBt,"mpnet"),FBt.forEach(t),APr=r(xDe," \u2014 "),YK=n(xDe,"A",{href:!0});var TBt=s(YK);LPr=r(TBt,"TFMPNetForQuestionAnswering"),TBt.forEach(t),yPr=r(xDe," (MPNet model)"),xDe.forEach(t),xPr=i(ge),FE=n(ge,"LI",{});var $De=s(FE);qMe=n($De,"STRONG",{});var MBt=s(qMe);$Pr=r(MBt,"rembert"),MBt.forEach(t),kPr=r($De," \u2014 "),KK=n($De,"A",{href:!0});var EBt=s(KK);SPr=r(EBt,"TFRemBertForQuestionAnswering"),EBt.forEach(t),RPr=r($De," (RemBERT model)"),$De.forEach(t),PPr=i(ge),TE=n(ge,"LI",{});var kDe=s(TE);jMe=n(kDe,"STRONG",{});var CBt=s(jMe);BPr=r(CBt,"roberta"),CBt.forEach(t),IPr=r(kDe," \u2014 "),ZK=n(kDe,"A",{href:!0});var wBt=s(ZK);NPr=r(wBt,"TFRobertaForQuestionAnswering"),wBt.forEach(t),qPr=r(kDe," (RoBERTa model)"),kDe.forEach(t),jPr=i(ge),ME=n(ge,"LI",{});var SDe=s(ME);DMe=n(SDe,"STRONG",{});var ABt=s(DMe);DPr=r(ABt,"roformer"),ABt.forEach(t),GPr=r(SDe," \u2014 "),eZ=n(SDe,"A",{href:!0});var LBt=s(eZ);OPr=r(LBt,"TFRoFormerForQuestionAnswering"),LBt.forEach(t),VPr=r(SDe," (RoFormer model)"),SDe.forEach(t),XPr=i(ge),EE=n(ge,"LI",{});var RDe=s(EE);GMe=n(RDe,"STRONG",{});var yBt=s(GMe);zPr=r(yBt,"xlm"),yBt.forEach(t),WPr=r(RDe," \u2014 "),oZ=n(RDe,"A",{href:!0});var xBt=s(oZ);QPr=r(xBt,"TFXLMForQuestionAnsweringSimple"),xBt.forEach(t),HPr=r(RDe," (XLM model)"),RDe.forEach(t),UPr=i(ge),CE=n(ge,"LI",{});var PDe=s(CE);OMe=n(PDe,"STRONG",{});var $Bt=s(OMe);JPr=r($Bt,"xlm-roberta"),$Bt.forEach(t),YPr=r(PDe," \u2014 "),rZ=n(PDe,"A",{href:!0});var kBt=s(rZ);KPr=r(kBt,"TFXLMRobertaForQuestionAnswering"),kBt.forEach(t),ZPr=r(PDe," (XLM-RoBERTa model)"),PDe.forEach(t),eBr=i(ge),wE=n(ge,"LI",{});var BDe=s(wE);VMe=n(BDe,"STRONG",{});var SBt=s(VMe);oBr=r(SBt,"xlnet"),SBt.forEach(t),rBr=r(BDe," \u2014 "),tZ=n(BDe,"A",{href:!0});var RBt=s(tZ);tBr=r(RBt,"TFXLNetForQuestionAnsweringSimple"),RBt.forEach(t),aBr=r(BDe," (XLNet model)"),BDe.forEach(t),ge.forEach(t),nBr=i(Jl),T(AE.$$.fragment,Jl),Jl.forEach(t),Ul.forEach(t),uXe=i(f),Dc=n(f,"H2",{class:!0});var AWe=s(Dc);LE=n(AWe,"A",{id:!0,class:!0,href:!0});var PBt=s(LE);XMe=n(PBt,"SPAN",{});var BBt=s(XMe);T(Bx.$$.fragment,BBt),BBt.forEach(t),PBt.forEach(t),sBr=i(AWe),zMe=n(AWe,"SPAN",{});var IBt=s(zMe);lBr=r(IBt,"TFAutoModelForVision2Seq"),IBt.forEach(t),AWe.forEach(t),bXe=i(f),gr=n(f,"DIV",{class:!0});var Yl=s(gr);T(Ix.$$.fragment,Yl),iBr=i(Yl),Gc=n(Yl,"P",{});var _te=s(Gc);dBr=r(_te,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),aZ=n(_te,"A",{href:!0});var NBt=s(aZ);cBr=r(NBt,"from_pretrained()"),NBt.forEach(t),fBr=r(_te," class method or the "),nZ=n(_te,"A",{href:!0});var qBt=s(nZ);mBr=r(qBt,"from_config()"),qBt.forEach(t),gBr=r(_te,` class
method.`),_te.forEach(t),hBr=i(Yl),Nx=n(Yl,"P",{});var LWe=s(Nx);pBr=r(LWe,"This class cannot be instantiated directly using "),WMe=n(LWe,"CODE",{});var jBt=s(WMe);_Br=r(jBt,"__init__()"),jBt.forEach(t),uBr=r(LWe," (throws an error)."),LWe.forEach(t),bBr=i(Yl),Vt=n(Yl,"DIV",{class:!0});var cA=s(Vt);T(qx.$$.fragment,cA),vBr=i(cA),QMe=n(cA,"P",{});var DBt=s(QMe);FBr=r(DBt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),DBt.forEach(t),TBr=i(cA),Oc=n(cA,"P",{});var ute=s(Oc);MBr=r(ute,`Note:
Loading a model from its configuration file does `),HMe=n(ute,"STRONG",{});var GBt=s(HMe);EBr=r(GBt,"not"),GBt.forEach(t),CBr=r(ute,` load the model weights. It only affects the
model\u2019s configuration. Use `),sZ=n(ute,"A",{href:!0});var OBt=s(sZ);wBr=r(OBt,"from_pretrained()"),OBt.forEach(t),ABr=r(ute," to load the model weights."),ute.forEach(t),LBr=i(cA),T(yE.$$.fragment,cA),cA.forEach(t),yBr=i(Yl),Gr=n(Yl,"DIV",{class:!0});var Kl=s(Gr);T(jx.$$.fragment,Kl),xBr=i(Kl),UMe=n(Kl,"P",{});var VBt=s(UMe);$Br=r(VBt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),VBt.forEach(t),kBr=i(Kl),vn=n(Kl,"P",{});var fA=s(vn);SBr=r(fA,"The model class to instantiate is selected based on the "),JMe=n(fA,"CODE",{});var XBt=s(JMe);RBr=r(XBt,"model_type"),XBt.forEach(t),PBr=r(fA,` property of the config object (either
passed as an argument or loaded from `),YMe=n(fA,"CODE",{});var zBt=s(YMe);BBr=r(zBt,"pretrained_model_name_or_path"),zBt.forEach(t),IBr=r(fA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KMe=n(fA,"CODE",{});var WBt=s(KMe);NBr=r(WBt,"pretrained_model_name_or_path"),WBt.forEach(t),qBr=r(fA,":"),fA.forEach(t),jBr=i(Kl),ZMe=n(Kl,"UL",{});var QBt=s(ZMe);xE=n(QBt,"LI",{});var IDe=s(xE);e4e=n(IDe,"STRONG",{});var HBt=s(e4e);DBr=r(HBt,"vision-encoder-decoder"),HBt.forEach(t),GBr=r(IDe," \u2014 "),lZ=n(IDe,"A",{href:!0});var UBt=s(lZ);OBr=r(UBt,"TFVisionEncoderDecoderModel"),UBt.forEach(t),VBr=r(IDe," (Vision Encoder decoder model)"),IDe.forEach(t),QBt.forEach(t),XBr=i(Kl),T($E.$$.fragment,Kl),Kl.forEach(t),Yl.forEach(t),vXe=i(f),Vc=n(f,"H2",{class:!0});var yWe=s(Vc);kE=n(yWe,"A",{id:!0,class:!0,href:!0});var JBt=s(kE);o4e=n(JBt,"SPAN",{});var YBt=s(o4e);T(Dx.$$.fragment,YBt),YBt.forEach(t),JBt.forEach(t),zBr=i(yWe),r4e=n(yWe,"SPAN",{});var KBt=s(r4e);WBr=r(KBt,"TFAutoModelForSpeechSeq2Seq"),KBt.forEach(t),yWe.forEach(t),FXe=i(f),hr=n(f,"DIV",{class:!0});var Zl=s(hr);T(Gx.$$.fragment,Zl),QBr=i(Zl),Xc=n(Zl,"P",{});var bte=s(Xc);HBr=r(bte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),iZ=n(bte,"A",{href:!0});var ZBt=s(iZ);UBr=r(ZBt,"from_pretrained()"),ZBt.forEach(t),JBr=r(bte," class method or the "),dZ=n(bte,"A",{href:!0});var eIt=s(dZ);YBr=r(eIt,"from_config()"),eIt.forEach(t),KBr=r(bte,` class
method.`),bte.forEach(t),ZBr=i(Zl),Ox=n(Zl,"P",{});var xWe=s(Ox);eIr=r(xWe,"This class cannot be instantiated directly using "),t4e=n(xWe,"CODE",{});var oIt=s(t4e);oIr=r(oIt,"__init__()"),oIt.forEach(t),rIr=r(xWe," (throws an error)."),xWe.forEach(t),tIr=i(Zl),Xt=n(Zl,"DIV",{class:!0});var mA=s(Xt);T(Vx.$$.fragment,mA),aIr=i(mA),a4e=n(mA,"P",{});var rIt=s(a4e);nIr=r(rIt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),rIt.forEach(t),sIr=i(mA),zc=n(mA,"P",{});var vte=s(zc);lIr=r(vte,`Note:
Loading a model from its configuration file does `),n4e=n(vte,"STRONG",{});var tIt=s(n4e);iIr=r(tIt,"not"),tIt.forEach(t),dIr=r(vte,` load the model weights. It only affects the
model\u2019s configuration. Use `),cZ=n(vte,"A",{href:!0});var aIt=s(cZ);cIr=r(aIt,"from_pretrained()"),aIt.forEach(t),fIr=r(vte," to load the model weights."),vte.forEach(t),mIr=i(mA),T(SE.$$.fragment,mA),mA.forEach(t),gIr=i(Zl),Or=n(Zl,"DIV",{class:!0});var ei=s(Or);T(Xx.$$.fragment,ei),hIr=i(ei),s4e=n(ei,"P",{});var nIt=s(s4e);pIr=r(nIt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),nIt.forEach(t),_Ir=i(ei),Fn=n(ei,"P",{});var gA=s(Fn);uIr=r(gA,"The model class to instantiate is selected based on the "),l4e=n(gA,"CODE",{});var sIt=s(l4e);bIr=r(sIt,"model_type"),sIt.forEach(t),vIr=r(gA,` property of the config object (either
passed as an argument or loaded from `),i4e=n(gA,"CODE",{});var lIt=s(i4e);FIr=r(lIt,"pretrained_model_name_or_path"),lIt.forEach(t),TIr=r(gA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d4e=n(gA,"CODE",{});var iIt=s(d4e);MIr=r(iIt,"pretrained_model_name_or_path"),iIt.forEach(t),EIr=r(gA,":"),gA.forEach(t),CIr=i(ei),c4e=n(ei,"UL",{});var dIt=s(c4e);RE=n(dIt,"LI",{});var NDe=s(RE);f4e=n(NDe,"STRONG",{});var cIt=s(f4e);wIr=r(cIt,"speech_to_text"),cIt.forEach(t),AIr=r(NDe," \u2014 "),fZ=n(NDe,"A",{href:!0});var fIt=s(fZ);LIr=r(fIt,"TFSpeech2TextForConditionalGeneration"),fIt.forEach(t),yIr=r(NDe," (Speech2Text model)"),NDe.forEach(t),dIt.forEach(t),xIr=i(ei),T(PE.$$.fragment,ei),ei.forEach(t),Zl.forEach(t),TXe=i(f),Wc=n(f,"H2",{class:!0});var $We=s(Wc);BE=n($We,"A",{id:!0,class:!0,href:!0});var mIt=s(BE);m4e=n(mIt,"SPAN",{});var gIt=s(m4e);T(zx.$$.fragment,gIt),gIt.forEach(t),mIt.forEach(t),$Ir=i($We),g4e=n($We,"SPAN",{});var hIt=s(g4e);kIr=r(hIt,"FlaxAutoModel"),hIt.forEach(t),$We.forEach(t),MXe=i(f),pr=n(f,"DIV",{class:!0});var oi=s(pr);T(Wx.$$.fragment,oi),SIr=i(oi),Qc=n(oi,"P",{});var Fte=s(Qc);RIr=r(Fte,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),mZ=n(Fte,"A",{href:!0});var pIt=s(mZ);PIr=r(pIt,"from_pretrained()"),pIt.forEach(t),BIr=r(Fte," class method or the "),gZ=n(Fte,"A",{href:!0});var _It=s(gZ);IIr=r(_It,"from_config()"),_It.forEach(t),NIr=r(Fte,` class
method.`),Fte.forEach(t),qIr=i(oi),Qx=n(oi,"P",{});var kWe=s(Qx);jIr=r(kWe,"This class cannot be instantiated directly using "),h4e=n(kWe,"CODE",{});var uIt=s(h4e);DIr=r(uIt,"__init__()"),uIt.forEach(t),GIr=r(kWe," (throws an error)."),kWe.forEach(t),OIr=i(oi),zt=n(oi,"DIV",{class:!0});var hA=s(zt);T(Hx.$$.fragment,hA),VIr=i(hA),p4e=n(hA,"P",{});var bIt=s(p4e);XIr=r(bIt,"Instantiates one of the base model classes of the library from a configuration."),bIt.forEach(t),zIr=i(hA),Hc=n(hA,"P",{});var Tte=s(Hc);WIr=r(Tte,`Note:
Loading a model from its configuration file does `),_4e=n(Tte,"STRONG",{});var vIt=s(_4e);QIr=r(vIt,"not"),vIt.forEach(t),HIr=r(Tte,` load the model weights. It only affects the
model\u2019s configuration. Use `),hZ=n(Tte,"A",{href:!0});var FIt=s(hZ);UIr=r(FIt,"from_pretrained()"),FIt.forEach(t),JIr=r(Tte," to load the model weights."),Tte.forEach(t),YIr=i(hA),T(IE.$$.fragment,hA),hA.forEach(t),KIr=i(oi),Vr=n(oi,"DIV",{class:!0});var ri=s(Vr);T(Ux.$$.fragment,ri),ZIr=i(ri),u4e=n(ri,"P",{});var TIt=s(u4e);eNr=r(TIt,"Instantiate one of the base model classes of the library from a pretrained model."),TIt.forEach(t),oNr=i(ri),Tn=n(ri,"P",{});var pA=s(Tn);rNr=r(pA,"The model class to instantiate is selected based on the "),b4e=n(pA,"CODE",{});var MIt=s(b4e);tNr=r(MIt,"model_type"),MIt.forEach(t),aNr=r(pA,` property of the config object (either
passed as an argument or loaded from `),v4e=n(pA,"CODE",{});var EIt=s(v4e);nNr=r(EIt,"pretrained_model_name_or_path"),EIt.forEach(t),sNr=r(pA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F4e=n(pA,"CODE",{});var CIt=s(F4e);lNr=r(CIt,"pretrained_model_name_or_path"),CIt.forEach(t),iNr=r(pA,":"),pA.forEach(t),dNr=i(ri),oe=n(ri,"UL",{});var ae=s(oe);NE=n(ae,"LI",{});var qDe=s(NE);T4e=n(qDe,"STRONG",{});var wIt=s(T4e);cNr=r(wIt,"albert"),wIt.forEach(t),fNr=r(qDe," \u2014 "),pZ=n(qDe,"A",{href:!0});var AIt=s(pZ);mNr=r(AIt,"FlaxAlbertModel"),AIt.forEach(t),gNr=r(qDe," (ALBERT model)"),qDe.forEach(t),hNr=i(ae),qE=n(ae,"LI",{});var jDe=s(qE);M4e=n(jDe,"STRONG",{});var LIt=s(M4e);pNr=r(LIt,"bart"),LIt.forEach(t),_Nr=r(jDe," \u2014 "),_Z=n(jDe,"A",{href:!0});var yIt=s(_Z);uNr=r(yIt,"FlaxBartModel"),yIt.forEach(t),bNr=r(jDe," (BART model)"),jDe.forEach(t),vNr=i(ae),jE=n(ae,"LI",{});var DDe=s(jE);E4e=n(DDe,"STRONG",{});var xIt=s(E4e);FNr=r(xIt,"beit"),xIt.forEach(t),TNr=r(DDe," \u2014 "),uZ=n(DDe,"A",{href:!0});var $It=s(uZ);MNr=r($It,"FlaxBeitModel"),$It.forEach(t),ENr=r(DDe," (BEiT model)"),DDe.forEach(t),CNr=i(ae),DE=n(ae,"LI",{});var GDe=s(DE);C4e=n(GDe,"STRONG",{});var kIt=s(C4e);wNr=r(kIt,"bert"),kIt.forEach(t),ANr=r(GDe," \u2014 "),bZ=n(GDe,"A",{href:!0});var SIt=s(bZ);LNr=r(SIt,"FlaxBertModel"),SIt.forEach(t),yNr=r(GDe," (BERT model)"),GDe.forEach(t),xNr=i(ae),GE=n(ae,"LI",{});var ODe=s(GE);w4e=n(ODe,"STRONG",{});var RIt=s(w4e);$Nr=r(RIt,"big_bird"),RIt.forEach(t),kNr=r(ODe," \u2014 "),vZ=n(ODe,"A",{href:!0});var PIt=s(vZ);SNr=r(PIt,"FlaxBigBirdModel"),PIt.forEach(t),RNr=r(ODe," (BigBird model)"),ODe.forEach(t),PNr=i(ae),OE=n(ae,"LI",{});var VDe=s(OE);A4e=n(VDe,"STRONG",{});var BIt=s(A4e);BNr=r(BIt,"blenderbot"),BIt.forEach(t),INr=r(VDe," \u2014 "),FZ=n(VDe,"A",{href:!0});var IIt=s(FZ);NNr=r(IIt,"FlaxBlenderbotModel"),IIt.forEach(t),qNr=r(VDe," (Blenderbot model)"),VDe.forEach(t),jNr=i(ae),VE=n(ae,"LI",{});var XDe=s(VE);L4e=n(XDe,"STRONG",{});var NIt=s(L4e);DNr=r(NIt,"blenderbot-small"),NIt.forEach(t),GNr=r(XDe," \u2014 "),TZ=n(XDe,"A",{href:!0});var qIt=s(TZ);ONr=r(qIt,"FlaxBlenderbotSmallModel"),qIt.forEach(t),VNr=r(XDe," (BlenderbotSmall model)"),XDe.forEach(t),XNr=i(ae),XE=n(ae,"LI",{});var zDe=s(XE);y4e=n(zDe,"STRONG",{});var jIt=s(y4e);zNr=r(jIt,"clip"),jIt.forEach(t),WNr=r(zDe," \u2014 "),MZ=n(zDe,"A",{href:!0});var DIt=s(MZ);QNr=r(DIt,"FlaxCLIPModel"),DIt.forEach(t),HNr=r(zDe," (CLIP model)"),zDe.forEach(t),UNr=i(ae),zE=n(ae,"LI",{});var WDe=s(zE);x4e=n(WDe,"STRONG",{});var GIt=s(x4e);JNr=r(GIt,"distilbert"),GIt.forEach(t),YNr=r(WDe," \u2014 "),EZ=n(WDe,"A",{href:!0});var OIt=s(EZ);KNr=r(OIt,"FlaxDistilBertModel"),OIt.forEach(t),ZNr=r(WDe," (DistilBERT model)"),WDe.forEach(t),eqr=i(ae),WE=n(ae,"LI",{});var QDe=s(WE);$4e=n(QDe,"STRONG",{});var VIt=s($4e);oqr=r(VIt,"electra"),VIt.forEach(t),rqr=r(QDe," \u2014 "),CZ=n(QDe,"A",{href:!0});var XIt=s(CZ);tqr=r(XIt,"FlaxElectraModel"),XIt.forEach(t),aqr=r(QDe," (ELECTRA model)"),QDe.forEach(t),nqr=i(ae),QE=n(ae,"LI",{});var HDe=s(QE);k4e=n(HDe,"STRONG",{});var zIt=s(k4e);sqr=r(zIt,"gpt2"),zIt.forEach(t),lqr=r(HDe," \u2014 "),wZ=n(HDe,"A",{href:!0});var WIt=s(wZ);iqr=r(WIt,"FlaxGPT2Model"),WIt.forEach(t),dqr=r(HDe," (OpenAI GPT-2 model)"),HDe.forEach(t),cqr=i(ae),HE=n(ae,"LI",{});var UDe=s(HE);S4e=n(UDe,"STRONG",{});var QIt=s(S4e);fqr=r(QIt,"gpt_neo"),QIt.forEach(t),mqr=r(UDe," \u2014 "),AZ=n(UDe,"A",{href:!0});var HIt=s(AZ);gqr=r(HIt,"FlaxGPTNeoModel"),HIt.forEach(t),hqr=r(UDe," (GPT Neo model)"),UDe.forEach(t),pqr=i(ae),UE=n(ae,"LI",{});var JDe=s(UE);R4e=n(JDe,"STRONG",{});var UIt=s(R4e);_qr=r(UIt,"gptj"),UIt.forEach(t),uqr=r(JDe," \u2014 "),LZ=n(JDe,"A",{href:!0});var JIt=s(LZ);bqr=r(JIt,"FlaxGPTJModel"),JIt.forEach(t),vqr=r(JDe," (GPT-J model)"),JDe.forEach(t),Fqr=i(ae),JE=n(ae,"LI",{});var YDe=s(JE);P4e=n(YDe,"STRONG",{});var YIt=s(P4e);Tqr=r(YIt,"longt5"),YIt.forEach(t),Mqr=r(YDe," \u2014 "),yZ=n(YDe,"A",{href:!0});var KIt=s(yZ);Eqr=r(KIt,"FlaxLongT5Model"),KIt.forEach(t),Cqr=r(YDe," (LongT5 model)"),YDe.forEach(t),wqr=i(ae),YE=n(ae,"LI",{});var KDe=s(YE);B4e=n(KDe,"STRONG",{});var ZIt=s(B4e);Aqr=r(ZIt,"marian"),ZIt.forEach(t),Lqr=r(KDe," \u2014 "),xZ=n(KDe,"A",{href:!0});var eNt=s(xZ);yqr=r(eNt,"FlaxMarianModel"),eNt.forEach(t),xqr=r(KDe," (Marian model)"),KDe.forEach(t),$qr=i(ae),KE=n(ae,"LI",{});var ZDe=s(KE);I4e=n(ZDe,"STRONG",{});var oNt=s(I4e);kqr=r(oNt,"mbart"),oNt.forEach(t),Sqr=r(ZDe," \u2014 "),$Z=n(ZDe,"A",{href:!0});var rNt=s($Z);Rqr=r(rNt,"FlaxMBartModel"),rNt.forEach(t),Pqr=r(ZDe," (mBART model)"),ZDe.forEach(t),Bqr=i(ae),ZE=n(ae,"LI",{});var eGe=s(ZE);N4e=n(eGe,"STRONG",{});var tNt=s(N4e);Iqr=r(tNt,"mt5"),tNt.forEach(t),Nqr=r(eGe," \u2014 "),kZ=n(eGe,"A",{href:!0});var aNt=s(kZ);qqr=r(aNt,"FlaxMT5Model"),aNt.forEach(t),jqr=r(eGe," (MT5 model)"),eGe.forEach(t),Dqr=i(ae),eC=n(ae,"LI",{});var oGe=s(eC);q4e=n(oGe,"STRONG",{});var nNt=s(q4e);Gqr=r(nNt,"opt"),nNt.forEach(t),Oqr=r(oGe," \u2014 "),SZ=n(oGe,"A",{href:!0});var sNt=s(SZ);Vqr=r(sNt,"FlaxOPTModel"),sNt.forEach(t),Xqr=r(oGe," (OPT model)"),oGe.forEach(t),zqr=i(ae),oC=n(ae,"LI",{});var rGe=s(oC);j4e=n(rGe,"STRONG",{});var lNt=s(j4e);Wqr=r(lNt,"pegasus"),lNt.forEach(t),Qqr=r(rGe," \u2014 "),RZ=n(rGe,"A",{href:!0});var iNt=s(RZ);Hqr=r(iNt,"FlaxPegasusModel"),iNt.forEach(t),Uqr=r(rGe," (Pegasus model)"),rGe.forEach(t),Jqr=i(ae),rC=n(ae,"LI",{});var tGe=s(rC);D4e=n(tGe,"STRONG",{});var dNt=s(D4e);Yqr=r(dNt,"roberta"),dNt.forEach(t),Kqr=r(tGe," \u2014 "),PZ=n(tGe,"A",{href:!0});var cNt=s(PZ);Zqr=r(cNt,"FlaxRobertaModel"),cNt.forEach(t),ejr=r(tGe," (RoBERTa model)"),tGe.forEach(t),ojr=i(ae),tC=n(ae,"LI",{});var aGe=s(tC);G4e=n(aGe,"STRONG",{});var fNt=s(G4e);rjr=r(fNt,"roformer"),fNt.forEach(t),tjr=r(aGe," \u2014 "),BZ=n(aGe,"A",{href:!0});var mNt=s(BZ);ajr=r(mNt,"FlaxRoFormerModel"),mNt.forEach(t),njr=r(aGe," (RoFormer model)"),aGe.forEach(t),sjr=i(ae),aC=n(ae,"LI",{});var nGe=s(aC);O4e=n(nGe,"STRONG",{});var gNt=s(O4e);ljr=r(gNt,"t5"),gNt.forEach(t),ijr=r(nGe," \u2014 "),IZ=n(nGe,"A",{href:!0});var hNt=s(IZ);djr=r(hNt,"FlaxT5Model"),hNt.forEach(t),cjr=r(nGe," (T5 model)"),nGe.forEach(t),fjr=i(ae),nC=n(ae,"LI",{});var sGe=s(nC);V4e=n(sGe,"STRONG",{});var pNt=s(V4e);mjr=r(pNt,"vision-text-dual-encoder"),pNt.forEach(t),gjr=r(sGe," \u2014 "),NZ=n(sGe,"A",{href:!0});var _Nt=s(NZ);hjr=r(_Nt,"FlaxVisionTextDualEncoderModel"),_Nt.forEach(t),pjr=r(sGe," (VisionTextDualEncoder model)"),sGe.forEach(t),_jr=i(ae),sC=n(ae,"LI",{});var lGe=s(sC);X4e=n(lGe,"STRONG",{});var uNt=s(X4e);ujr=r(uNt,"vit"),uNt.forEach(t),bjr=r(lGe," \u2014 "),qZ=n(lGe,"A",{href:!0});var bNt=s(qZ);vjr=r(bNt,"FlaxViTModel"),bNt.forEach(t),Fjr=r(lGe," (ViT model)"),lGe.forEach(t),Tjr=i(ae),lC=n(ae,"LI",{});var iGe=s(lC);z4e=n(iGe,"STRONG",{});var vNt=s(z4e);Mjr=r(vNt,"wav2vec2"),vNt.forEach(t),Ejr=r(iGe," \u2014 "),jZ=n(iGe,"A",{href:!0});var FNt=s(jZ);Cjr=r(FNt,"FlaxWav2Vec2Model"),FNt.forEach(t),wjr=r(iGe," (Wav2Vec2 model)"),iGe.forEach(t),Ajr=i(ae),iC=n(ae,"LI",{});var dGe=s(iC);W4e=n(dGe,"STRONG",{});var TNt=s(W4e);Ljr=r(TNt,"xglm"),TNt.forEach(t),yjr=r(dGe," \u2014 "),DZ=n(dGe,"A",{href:!0});var MNt=s(DZ);xjr=r(MNt,"FlaxXGLMModel"),MNt.forEach(t),$jr=r(dGe," (XGLM model)"),dGe.forEach(t),kjr=i(ae),dC=n(ae,"LI",{});var cGe=s(dC);Q4e=n(cGe,"STRONG",{});var ENt=s(Q4e);Sjr=r(ENt,"xlm-roberta"),ENt.forEach(t),Rjr=r(cGe," \u2014 "),GZ=n(cGe,"A",{href:!0});var CNt=s(GZ);Pjr=r(CNt,"FlaxXLMRobertaModel"),CNt.forEach(t),Bjr=r(cGe," (XLM-RoBERTa model)"),cGe.forEach(t),ae.forEach(t),Ijr=i(ri),T(cC.$$.fragment,ri),ri.forEach(t),oi.forEach(t),EXe=i(f),Uc=n(f,"H2",{class:!0});var SWe=s(Uc);fC=n(SWe,"A",{id:!0,class:!0,href:!0});var wNt=s(fC);H4e=n(wNt,"SPAN",{});var ANt=s(H4e);T(Jx.$$.fragment,ANt),ANt.forEach(t),wNt.forEach(t),Njr=i(SWe),U4e=n(SWe,"SPAN",{});var LNt=s(U4e);qjr=r(LNt,"FlaxAutoModelForCausalLM"),LNt.forEach(t),SWe.forEach(t),CXe=i(f),_r=n(f,"DIV",{class:!0});var ti=s(_r);T(Yx.$$.fragment,ti),jjr=i(ti),Jc=n(ti,"P",{});var Mte=s(Jc);Djr=r(Mte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),OZ=n(Mte,"A",{href:!0});var yNt=s(OZ);Gjr=r(yNt,"from_pretrained()"),yNt.forEach(t),Ojr=r(Mte," class method or the "),VZ=n(Mte,"A",{href:!0});var xNt=s(VZ);Vjr=r(xNt,"from_config()"),xNt.forEach(t),Xjr=r(Mte,` class
method.`),Mte.forEach(t),zjr=i(ti),Kx=n(ti,"P",{});var RWe=s(Kx);Wjr=r(RWe,"This class cannot be instantiated directly using "),J4e=n(RWe,"CODE",{});var $Nt=s(J4e);Qjr=r($Nt,"__init__()"),$Nt.forEach(t),Hjr=r(RWe," (throws an error)."),RWe.forEach(t),Ujr=i(ti),Wt=n(ti,"DIV",{class:!0});var _A=s(Wt);T(Zx.$$.fragment,_A),Jjr=i(_A),Y4e=n(_A,"P",{});var kNt=s(Y4e);Yjr=r(kNt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),kNt.forEach(t),Kjr=i(_A),Yc=n(_A,"P",{});var Ete=s(Yc);Zjr=r(Ete,`Note:
Loading a model from its configuration file does `),K4e=n(Ete,"STRONG",{});var SNt=s(K4e);eDr=r(SNt,"not"),SNt.forEach(t),oDr=r(Ete,` load the model weights. It only affects the
model\u2019s configuration. Use `),XZ=n(Ete,"A",{href:!0});var RNt=s(XZ);rDr=r(RNt,"from_pretrained()"),RNt.forEach(t),tDr=r(Ete," to load the model weights."),Ete.forEach(t),aDr=i(_A),T(mC.$$.fragment,_A),_A.forEach(t),nDr=i(ti),Xr=n(ti,"DIV",{class:!0});var ai=s(Xr);T(e$.$$.fragment,ai),sDr=i(ai),Z4e=n(ai,"P",{});var PNt=s(Z4e);lDr=r(PNt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),PNt.forEach(t),iDr=i(ai),Mn=n(ai,"P",{});var uA=s(Mn);dDr=r(uA,"The model class to instantiate is selected based on the "),eEe=n(uA,"CODE",{});var BNt=s(eEe);cDr=r(BNt,"model_type"),BNt.forEach(t),fDr=r(uA,` property of the config object (either
passed as an argument or loaded from `),oEe=n(uA,"CODE",{});var INt=s(oEe);mDr=r(INt,"pretrained_model_name_or_path"),INt.forEach(t),gDr=r(uA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rEe=n(uA,"CODE",{});var NNt=s(rEe);hDr=r(NNt,"pretrained_model_name_or_path"),NNt.forEach(t),pDr=r(uA,":"),uA.forEach(t),_Dr=i(ai),xe=n(ai,"UL",{});var Ne=s(xe);gC=n(Ne,"LI",{});var fGe=s(gC);tEe=n(fGe,"STRONG",{});var qNt=s(tEe);uDr=r(qNt,"bart"),qNt.forEach(t),bDr=r(fGe," \u2014 "),zZ=n(fGe,"A",{href:!0});var jNt=s(zZ);vDr=r(jNt,"FlaxBartForCausalLM"),jNt.forEach(t),FDr=r(fGe," (BART model)"),fGe.forEach(t),TDr=i(Ne),hC=n(Ne,"LI",{});var mGe=s(hC);aEe=n(mGe,"STRONG",{});var DNt=s(aEe);MDr=r(DNt,"bert"),DNt.forEach(t),EDr=r(mGe," \u2014 "),WZ=n(mGe,"A",{href:!0});var GNt=s(WZ);CDr=r(GNt,"FlaxBertForCausalLM"),GNt.forEach(t),wDr=r(mGe," (BERT model)"),mGe.forEach(t),ADr=i(Ne),pC=n(Ne,"LI",{});var gGe=s(pC);nEe=n(gGe,"STRONG",{});var ONt=s(nEe);LDr=r(ONt,"big_bird"),ONt.forEach(t),yDr=r(gGe," \u2014 "),QZ=n(gGe,"A",{href:!0});var VNt=s(QZ);xDr=r(VNt,"FlaxBigBirdForCausalLM"),VNt.forEach(t),$Dr=r(gGe," (BigBird model)"),gGe.forEach(t),kDr=i(Ne),_C=n(Ne,"LI",{});var hGe=s(_C);sEe=n(hGe,"STRONG",{});var XNt=s(sEe);SDr=r(XNt,"electra"),XNt.forEach(t),RDr=r(hGe," \u2014 "),HZ=n(hGe,"A",{href:!0});var zNt=s(HZ);PDr=r(zNt,"FlaxElectraForCausalLM"),zNt.forEach(t),BDr=r(hGe," (ELECTRA model)"),hGe.forEach(t),IDr=i(Ne),uC=n(Ne,"LI",{});var pGe=s(uC);lEe=n(pGe,"STRONG",{});var WNt=s(lEe);NDr=r(WNt,"gpt2"),WNt.forEach(t),qDr=r(pGe," \u2014 "),UZ=n(pGe,"A",{href:!0});var QNt=s(UZ);jDr=r(QNt,"FlaxGPT2LMHeadModel"),QNt.forEach(t),DDr=r(pGe," (OpenAI GPT-2 model)"),pGe.forEach(t),GDr=i(Ne),bC=n(Ne,"LI",{});var _Ge=s(bC);iEe=n(_Ge,"STRONG",{});var HNt=s(iEe);ODr=r(HNt,"gpt_neo"),HNt.forEach(t),VDr=r(_Ge," \u2014 "),JZ=n(_Ge,"A",{href:!0});var UNt=s(JZ);XDr=r(UNt,"FlaxGPTNeoForCausalLM"),UNt.forEach(t),zDr=r(_Ge," (GPT Neo model)"),_Ge.forEach(t),WDr=i(Ne),vC=n(Ne,"LI",{});var uGe=s(vC);dEe=n(uGe,"STRONG",{});var JNt=s(dEe);QDr=r(JNt,"gptj"),JNt.forEach(t),HDr=r(uGe," \u2014 "),YZ=n(uGe,"A",{href:!0});var YNt=s(YZ);UDr=r(YNt,"FlaxGPTJForCausalLM"),YNt.forEach(t),JDr=r(uGe," (GPT-J model)"),uGe.forEach(t),YDr=i(Ne),FC=n(Ne,"LI",{});var bGe=s(FC);cEe=n(bGe,"STRONG",{});var KNt=s(cEe);KDr=r(KNt,"opt"),KNt.forEach(t),ZDr=r(bGe," \u2014 "),KZ=n(bGe,"A",{href:!0});var ZNt=s(KZ);eGr=r(ZNt,"FlaxOPTForCausalLM"),ZNt.forEach(t),oGr=r(bGe," (OPT model)"),bGe.forEach(t),rGr=i(Ne),TC=n(Ne,"LI",{});var vGe=s(TC);fEe=n(vGe,"STRONG",{});var eqt=s(fEe);tGr=r(eqt,"roberta"),eqt.forEach(t),aGr=r(vGe," \u2014 "),ZZ=n(vGe,"A",{href:!0});var oqt=s(ZZ);nGr=r(oqt,"FlaxRobertaForCausalLM"),oqt.forEach(t),sGr=r(vGe," (RoBERTa model)"),vGe.forEach(t),lGr=i(Ne),MC=n(Ne,"LI",{});var FGe=s(MC);mEe=n(FGe,"STRONG",{});var rqt=s(mEe);iGr=r(rqt,"xglm"),rqt.forEach(t),dGr=r(FGe," \u2014 "),eee=n(FGe,"A",{href:!0});var tqt=s(eee);cGr=r(tqt,"FlaxXGLMForCausalLM"),tqt.forEach(t),fGr=r(FGe," (XGLM model)"),FGe.forEach(t),Ne.forEach(t),mGr=i(ai),T(EC.$$.fragment,ai),ai.forEach(t),ti.forEach(t),wXe=i(f),Kc=n(f,"H2",{class:!0});var PWe=s(Kc);CC=n(PWe,"A",{id:!0,class:!0,href:!0});var aqt=s(CC);gEe=n(aqt,"SPAN",{});var nqt=s(gEe);T(o$.$$.fragment,nqt),nqt.forEach(t),aqt.forEach(t),gGr=i(PWe),hEe=n(PWe,"SPAN",{});var sqt=s(hEe);hGr=r(sqt,"FlaxAutoModelForPreTraining"),sqt.forEach(t),PWe.forEach(t),AXe=i(f),ur=n(f,"DIV",{class:!0});var ni=s(ur);T(r$.$$.fragment,ni),pGr=i(ni),Zc=n(ni,"P",{});var Cte=s(Zc);_Gr=r(Cte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),oee=n(Cte,"A",{href:!0});var lqt=s(oee);uGr=r(lqt,"from_pretrained()"),lqt.forEach(t),bGr=r(Cte," class method or the "),ree=n(Cte,"A",{href:!0});var iqt=s(ree);vGr=r(iqt,"from_config()"),iqt.forEach(t),FGr=r(Cte,` class
method.`),Cte.forEach(t),TGr=i(ni),t$=n(ni,"P",{});var BWe=s(t$);MGr=r(BWe,"This class cannot be instantiated directly using "),pEe=n(BWe,"CODE",{});var dqt=s(pEe);EGr=r(dqt,"__init__()"),dqt.forEach(t),CGr=r(BWe," (throws an error)."),BWe.forEach(t),wGr=i(ni),Qt=n(ni,"DIV",{class:!0});var bA=s(Qt);T(a$.$$.fragment,bA),AGr=i(bA),_Ee=n(bA,"P",{});var cqt=s(_Ee);LGr=r(cqt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),cqt.forEach(t),yGr=i(bA),ef=n(bA,"P",{});var wte=s(ef);xGr=r(wte,`Note:
Loading a model from its configuration file does `),uEe=n(wte,"STRONG",{});var fqt=s(uEe);$Gr=r(fqt,"not"),fqt.forEach(t),kGr=r(wte,` load the model weights. It only affects the
model\u2019s configuration. Use `),tee=n(wte,"A",{href:!0});var mqt=s(tee);SGr=r(mqt,"from_pretrained()"),mqt.forEach(t),RGr=r(wte," to load the model weights."),wte.forEach(t),PGr=i(bA),T(wC.$$.fragment,bA),bA.forEach(t),BGr=i(ni),zr=n(ni,"DIV",{class:!0});var si=s(zr);T(n$.$$.fragment,si),IGr=i(si),bEe=n(si,"P",{});var gqt=s(bEe);NGr=r(gqt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),gqt.forEach(t),qGr=i(si),En=n(si,"P",{});var vA=s(En);jGr=r(vA,"The model class to instantiate is selected based on the "),vEe=n(vA,"CODE",{});var hqt=s(vEe);DGr=r(hqt,"model_type"),hqt.forEach(t),GGr=r(vA,` property of the config object (either
passed as an argument or loaded from `),FEe=n(vA,"CODE",{});var pqt=s(FEe);OGr=r(pqt,"pretrained_model_name_or_path"),pqt.forEach(t),VGr=r(vA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TEe=n(vA,"CODE",{});var _qt=s(TEe);XGr=r(_qt,"pretrained_model_name_or_path"),_qt.forEach(t),zGr=r(vA,":"),vA.forEach(t),WGr=i(si),Ee=n(si,"UL",{});var we=s(Ee);AC=n(we,"LI",{});var TGe=s(AC);MEe=n(TGe,"STRONG",{});var uqt=s(MEe);QGr=r(uqt,"albert"),uqt.forEach(t),HGr=r(TGe," \u2014 "),aee=n(TGe,"A",{href:!0});var bqt=s(aee);UGr=r(bqt,"FlaxAlbertForPreTraining"),bqt.forEach(t),JGr=r(TGe," (ALBERT model)"),TGe.forEach(t),YGr=i(we),LC=n(we,"LI",{});var MGe=s(LC);EEe=n(MGe,"STRONG",{});var vqt=s(EEe);KGr=r(vqt,"bart"),vqt.forEach(t),ZGr=r(MGe," \u2014 "),nee=n(MGe,"A",{href:!0});var Fqt=s(nee);eOr=r(Fqt,"FlaxBartForConditionalGeneration"),Fqt.forEach(t),oOr=r(MGe," (BART model)"),MGe.forEach(t),rOr=i(we),yC=n(we,"LI",{});var EGe=s(yC);CEe=n(EGe,"STRONG",{});var Tqt=s(CEe);tOr=r(Tqt,"bert"),Tqt.forEach(t),aOr=r(EGe," \u2014 "),see=n(EGe,"A",{href:!0});var Mqt=s(see);nOr=r(Mqt,"FlaxBertForPreTraining"),Mqt.forEach(t),sOr=r(EGe," (BERT model)"),EGe.forEach(t),lOr=i(we),xC=n(we,"LI",{});var CGe=s(xC);wEe=n(CGe,"STRONG",{});var Eqt=s(wEe);iOr=r(Eqt,"big_bird"),Eqt.forEach(t),dOr=r(CGe," \u2014 "),lee=n(CGe,"A",{href:!0});var Cqt=s(lee);cOr=r(Cqt,"FlaxBigBirdForPreTraining"),Cqt.forEach(t),fOr=r(CGe," (BigBird model)"),CGe.forEach(t),mOr=i(we),$C=n(we,"LI",{});var wGe=s($C);AEe=n(wGe,"STRONG",{});var wqt=s(AEe);gOr=r(wqt,"electra"),wqt.forEach(t),hOr=r(wGe," \u2014 "),iee=n(wGe,"A",{href:!0});var Aqt=s(iee);pOr=r(Aqt,"FlaxElectraForPreTraining"),Aqt.forEach(t),_Or=r(wGe," (ELECTRA model)"),wGe.forEach(t),uOr=i(we),kC=n(we,"LI",{});var AGe=s(kC);LEe=n(AGe,"STRONG",{});var Lqt=s(LEe);bOr=r(Lqt,"longt5"),Lqt.forEach(t),vOr=r(AGe," \u2014 "),dee=n(AGe,"A",{href:!0});var yqt=s(dee);FOr=r(yqt,"FlaxLongT5ForConditionalGeneration"),yqt.forEach(t),TOr=r(AGe," (LongT5 model)"),AGe.forEach(t),MOr=i(we),SC=n(we,"LI",{});var LGe=s(SC);yEe=n(LGe,"STRONG",{});var xqt=s(yEe);EOr=r(xqt,"mbart"),xqt.forEach(t),COr=r(LGe," \u2014 "),cee=n(LGe,"A",{href:!0});var $qt=s(cee);wOr=r($qt,"FlaxMBartForConditionalGeneration"),$qt.forEach(t),AOr=r(LGe," (mBART model)"),LGe.forEach(t),LOr=i(we),RC=n(we,"LI",{});var yGe=s(RC);xEe=n(yGe,"STRONG",{});var kqt=s(xEe);yOr=r(kqt,"mt5"),kqt.forEach(t),xOr=r(yGe," \u2014 "),fee=n(yGe,"A",{href:!0});var Sqt=s(fee);$Or=r(Sqt,"FlaxMT5ForConditionalGeneration"),Sqt.forEach(t),kOr=r(yGe," (MT5 model)"),yGe.forEach(t),SOr=i(we),PC=n(we,"LI",{});var xGe=s(PC);$Ee=n(xGe,"STRONG",{});var Rqt=s($Ee);ROr=r(Rqt,"roberta"),Rqt.forEach(t),POr=r(xGe," \u2014 "),mee=n(xGe,"A",{href:!0});var Pqt=s(mee);BOr=r(Pqt,"FlaxRobertaForMaskedLM"),Pqt.forEach(t),IOr=r(xGe," (RoBERTa model)"),xGe.forEach(t),NOr=i(we),BC=n(we,"LI",{});var $Ge=s(BC);kEe=n($Ge,"STRONG",{});var Bqt=s(kEe);qOr=r(Bqt,"roformer"),Bqt.forEach(t),jOr=r($Ge," \u2014 "),gee=n($Ge,"A",{href:!0});var Iqt=s(gee);DOr=r(Iqt,"FlaxRoFormerForMaskedLM"),Iqt.forEach(t),GOr=r($Ge," (RoFormer model)"),$Ge.forEach(t),OOr=i(we),IC=n(we,"LI",{});var kGe=s(IC);SEe=n(kGe,"STRONG",{});var Nqt=s(SEe);VOr=r(Nqt,"t5"),Nqt.forEach(t),XOr=r(kGe," \u2014 "),hee=n(kGe,"A",{href:!0});var qqt=s(hee);zOr=r(qqt,"FlaxT5ForConditionalGeneration"),qqt.forEach(t),WOr=r(kGe," (T5 model)"),kGe.forEach(t),QOr=i(we),NC=n(we,"LI",{});var SGe=s(NC);REe=n(SGe,"STRONG",{});var jqt=s(REe);HOr=r(jqt,"wav2vec2"),jqt.forEach(t),UOr=r(SGe," \u2014 "),pee=n(SGe,"A",{href:!0});var Dqt=s(pee);JOr=r(Dqt,"FlaxWav2Vec2ForPreTraining"),Dqt.forEach(t),YOr=r(SGe," (Wav2Vec2 model)"),SGe.forEach(t),KOr=i(we),qC=n(we,"LI",{});var RGe=s(qC);PEe=n(RGe,"STRONG",{});var Gqt=s(PEe);ZOr=r(Gqt,"xlm-roberta"),Gqt.forEach(t),eVr=r(RGe," \u2014 "),_ee=n(RGe,"A",{href:!0});var Oqt=s(_ee);oVr=r(Oqt,"FlaxXLMRobertaForMaskedLM"),Oqt.forEach(t),rVr=r(RGe," (XLM-RoBERTa model)"),RGe.forEach(t),we.forEach(t),tVr=i(si),T(jC.$$.fragment,si),si.forEach(t),ni.forEach(t),LXe=i(f),of=n(f,"H2",{class:!0});var IWe=s(of);DC=n(IWe,"A",{id:!0,class:!0,href:!0});var Vqt=s(DC);BEe=n(Vqt,"SPAN",{});var Xqt=s(BEe);T(s$.$$.fragment,Xqt),Xqt.forEach(t),Vqt.forEach(t),aVr=i(IWe),IEe=n(IWe,"SPAN",{});var zqt=s(IEe);nVr=r(zqt,"FlaxAutoModelForMaskedLM"),zqt.forEach(t),IWe.forEach(t),yXe=i(f),br=n(f,"DIV",{class:!0});var li=s(br);T(l$.$$.fragment,li),sVr=i(li),rf=n(li,"P",{});var Ate=s(rf);lVr=r(Ate,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),uee=n(Ate,"A",{href:!0});var Wqt=s(uee);iVr=r(Wqt,"from_pretrained()"),Wqt.forEach(t),dVr=r(Ate," class method or the "),bee=n(Ate,"A",{href:!0});var Qqt=s(bee);cVr=r(Qqt,"from_config()"),Qqt.forEach(t),fVr=r(Ate,` class
method.`),Ate.forEach(t),mVr=i(li),i$=n(li,"P",{});var NWe=s(i$);gVr=r(NWe,"This class cannot be instantiated directly using "),NEe=n(NWe,"CODE",{});var Hqt=s(NEe);hVr=r(Hqt,"__init__()"),Hqt.forEach(t),pVr=r(NWe," (throws an error)."),NWe.forEach(t),_Vr=i(li),Ht=n(li,"DIV",{class:!0});var FA=s(Ht);T(d$.$$.fragment,FA),uVr=i(FA),qEe=n(FA,"P",{});var Uqt=s(qEe);bVr=r(Uqt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Uqt.forEach(t),vVr=i(FA),tf=n(FA,"P",{});var Lte=s(tf);FVr=r(Lte,`Note:
Loading a model from its configuration file does `),jEe=n(Lte,"STRONG",{});var Jqt=s(jEe);TVr=r(Jqt,"not"),Jqt.forEach(t),MVr=r(Lte,` load the model weights. It only affects the
model\u2019s configuration. Use `),vee=n(Lte,"A",{href:!0});var Yqt=s(vee);EVr=r(Yqt,"from_pretrained()"),Yqt.forEach(t),CVr=r(Lte," to load the model weights."),Lte.forEach(t),wVr=i(FA),T(GC.$$.fragment,FA),FA.forEach(t),AVr=i(li),Wr=n(li,"DIV",{class:!0});var ii=s(Wr);T(c$.$$.fragment,ii),LVr=i(ii),DEe=n(ii,"P",{});var Kqt=s(DEe);yVr=r(Kqt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Kqt.forEach(t),xVr=i(ii),Cn=n(ii,"P",{});var TA=s(Cn);$Vr=r(TA,"The model class to instantiate is selected based on the "),GEe=n(TA,"CODE",{});var Zqt=s(GEe);kVr=r(Zqt,"model_type"),Zqt.forEach(t),SVr=r(TA,` property of the config object (either
passed as an argument or loaded from `),OEe=n(TA,"CODE",{});var ejt=s(OEe);RVr=r(ejt,"pretrained_model_name_or_path"),ejt.forEach(t),PVr=r(TA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VEe=n(TA,"CODE",{});var ojt=s(VEe);BVr=r(ojt,"pretrained_model_name_or_path"),ojt.forEach(t),IVr=r(TA,":"),TA.forEach(t),NVr=i(ii),$e=n(ii,"UL",{});var qe=s($e);OC=n(qe,"LI",{});var PGe=s(OC);XEe=n(PGe,"STRONG",{});var rjt=s(XEe);qVr=r(rjt,"albert"),rjt.forEach(t),jVr=r(PGe," \u2014 "),Fee=n(PGe,"A",{href:!0});var tjt=s(Fee);DVr=r(tjt,"FlaxAlbertForMaskedLM"),tjt.forEach(t),GVr=r(PGe," (ALBERT model)"),PGe.forEach(t),OVr=i(qe),VC=n(qe,"LI",{});var BGe=s(VC);zEe=n(BGe,"STRONG",{});var ajt=s(zEe);VVr=r(ajt,"bart"),ajt.forEach(t),XVr=r(BGe," \u2014 "),Tee=n(BGe,"A",{href:!0});var njt=s(Tee);zVr=r(njt,"FlaxBartForConditionalGeneration"),njt.forEach(t),WVr=r(BGe," (BART model)"),BGe.forEach(t),QVr=i(qe),XC=n(qe,"LI",{});var IGe=s(XC);WEe=n(IGe,"STRONG",{});var sjt=s(WEe);HVr=r(sjt,"bert"),sjt.forEach(t),UVr=r(IGe," \u2014 "),Mee=n(IGe,"A",{href:!0});var ljt=s(Mee);JVr=r(ljt,"FlaxBertForMaskedLM"),ljt.forEach(t),YVr=r(IGe," (BERT model)"),IGe.forEach(t),KVr=i(qe),zC=n(qe,"LI",{});var NGe=s(zC);QEe=n(NGe,"STRONG",{});var ijt=s(QEe);ZVr=r(ijt,"big_bird"),ijt.forEach(t),eXr=r(NGe," \u2014 "),Eee=n(NGe,"A",{href:!0});var djt=s(Eee);oXr=r(djt,"FlaxBigBirdForMaskedLM"),djt.forEach(t),rXr=r(NGe," (BigBird model)"),NGe.forEach(t),tXr=i(qe),WC=n(qe,"LI",{});var qGe=s(WC);HEe=n(qGe,"STRONG",{});var cjt=s(HEe);aXr=r(cjt,"distilbert"),cjt.forEach(t),nXr=r(qGe," \u2014 "),Cee=n(qGe,"A",{href:!0});var fjt=s(Cee);sXr=r(fjt,"FlaxDistilBertForMaskedLM"),fjt.forEach(t),lXr=r(qGe," (DistilBERT model)"),qGe.forEach(t),iXr=i(qe),QC=n(qe,"LI",{});var jGe=s(QC);UEe=n(jGe,"STRONG",{});var mjt=s(UEe);dXr=r(mjt,"electra"),mjt.forEach(t),cXr=r(jGe," \u2014 "),wee=n(jGe,"A",{href:!0});var gjt=s(wee);fXr=r(gjt,"FlaxElectraForMaskedLM"),gjt.forEach(t),mXr=r(jGe," (ELECTRA model)"),jGe.forEach(t),gXr=i(qe),HC=n(qe,"LI",{});var DGe=s(HC);JEe=n(DGe,"STRONG",{});var hjt=s(JEe);hXr=r(hjt,"mbart"),hjt.forEach(t),pXr=r(DGe," \u2014 "),Aee=n(DGe,"A",{href:!0});var pjt=s(Aee);_Xr=r(pjt,"FlaxMBartForConditionalGeneration"),pjt.forEach(t),uXr=r(DGe," (mBART model)"),DGe.forEach(t),bXr=i(qe),UC=n(qe,"LI",{});var GGe=s(UC);YEe=n(GGe,"STRONG",{});var _jt=s(YEe);vXr=r(_jt,"roberta"),_jt.forEach(t),FXr=r(GGe," \u2014 "),Lee=n(GGe,"A",{href:!0});var ujt=s(Lee);TXr=r(ujt,"FlaxRobertaForMaskedLM"),ujt.forEach(t),MXr=r(GGe," (RoBERTa model)"),GGe.forEach(t),EXr=i(qe),JC=n(qe,"LI",{});var OGe=s(JC);KEe=n(OGe,"STRONG",{});var bjt=s(KEe);CXr=r(bjt,"roformer"),bjt.forEach(t),wXr=r(OGe," \u2014 "),yee=n(OGe,"A",{href:!0});var vjt=s(yee);AXr=r(vjt,"FlaxRoFormerForMaskedLM"),vjt.forEach(t),LXr=r(OGe," (RoFormer model)"),OGe.forEach(t),yXr=i(qe),YC=n(qe,"LI",{});var VGe=s(YC);ZEe=n(VGe,"STRONG",{});var Fjt=s(ZEe);xXr=r(Fjt,"xlm-roberta"),Fjt.forEach(t),$Xr=r(VGe," \u2014 "),xee=n(VGe,"A",{href:!0});var Tjt=s(xee);kXr=r(Tjt,"FlaxXLMRobertaForMaskedLM"),Tjt.forEach(t),SXr=r(VGe," (XLM-RoBERTa model)"),VGe.forEach(t),qe.forEach(t),RXr=i(ii),T(KC.$$.fragment,ii),ii.forEach(t),li.forEach(t),xXe=i(f),af=n(f,"H2",{class:!0});var qWe=s(af);ZC=n(qWe,"A",{id:!0,class:!0,href:!0});var Mjt=s(ZC);eCe=n(Mjt,"SPAN",{});var Ejt=s(eCe);T(f$.$$.fragment,Ejt),Ejt.forEach(t),Mjt.forEach(t),PXr=i(qWe),oCe=n(qWe,"SPAN",{});var Cjt=s(oCe);BXr=r(Cjt,"FlaxAutoModelForSeq2SeqLM"),Cjt.forEach(t),qWe.forEach(t),$Xe=i(f),vr=n(f,"DIV",{class:!0});var di=s(vr);T(m$.$$.fragment,di),IXr=i(di),nf=n(di,"P",{});var yte=s(nf);NXr=r(yte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),$ee=n(yte,"A",{href:!0});var wjt=s($ee);qXr=r(wjt,"from_pretrained()"),wjt.forEach(t),jXr=r(yte," class method or the "),kee=n(yte,"A",{href:!0});var Ajt=s(kee);DXr=r(Ajt,"from_config()"),Ajt.forEach(t),GXr=r(yte,` class
method.`),yte.forEach(t),OXr=i(di),g$=n(di,"P",{});var jWe=s(g$);VXr=r(jWe,"This class cannot be instantiated directly using "),rCe=n(jWe,"CODE",{});var Ljt=s(rCe);XXr=r(Ljt,"__init__()"),Ljt.forEach(t),zXr=r(jWe," (throws an error)."),jWe.forEach(t),WXr=i(di),Ut=n(di,"DIV",{class:!0});var MA=s(Ut);T(h$.$$.fragment,MA),QXr=i(MA),tCe=n(MA,"P",{});var yjt=s(tCe);HXr=r(yjt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),yjt.forEach(t),UXr=i(MA),sf=n(MA,"P",{});var xte=s(sf);JXr=r(xte,`Note:
Loading a model from its configuration file does `),aCe=n(xte,"STRONG",{});var xjt=s(aCe);YXr=r(xjt,"not"),xjt.forEach(t),KXr=r(xte,` load the model weights. It only affects the
model\u2019s configuration. Use `),See=n(xte,"A",{href:!0});var $jt=s(See);ZXr=r($jt,"from_pretrained()"),$jt.forEach(t),ezr=r(xte," to load the model weights."),xte.forEach(t),ozr=i(MA),T(e3.$$.fragment,MA),MA.forEach(t),rzr=i(di),Qr=n(di,"DIV",{class:!0});var ci=s(Qr);T(p$.$$.fragment,ci),tzr=i(ci),nCe=n(ci,"P",{});var kjt=s(nCe);azr=r(kjt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),kjt.forEach(t),nzr=i(ci),wn=n(ci,"P",{});var EA=s(wn);szr=r(EA,"The model class to instantiate is selected based on the "),sCe=n(EA,"CODE",{});var Sjt=s(sCe);lzr=r(Sjt,"model_type"),Sjt.forEach(t),izr=r(EA,` property of the config object (either
passed as an argument or loaded from `),lCe=n(EA,"CODE",{});var Rjt=s(lCe);dzr=r(Rjt,"pretrained_model_name_or_path"),Rjt.forEach(t),czr=r(EA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iCe=n(EA,"CODE",{});var Pjt=s(iCe);fzr=r(Pjt,"pretrained_model_name_or_path"),Pjt.forEach(t),mzr=r(EA,":"),EA.forEach(t),gzr=i(ci),ke=n(ci,"UL",{});var je=s(ke);o3=n(je,"LI",{});var XGe=s(o3);dCe=n(XGe,"STRONG",{});var Bjt=s(dCe);hzr=r(Bjt,"bart"),Bjt.forEach(t),pzr=r(XGe," \u2014 "),Ree=n(XGe,"A",{href:!0});var Ijt=s(Ree);_zr=r(Ijt,"FlaxBartForConditionalGeneration"),Ijt.forEach(t),uzr=r(XGe," (BART model)"),XGe.forEach(t),bzr=i(je),r3=n(je,"LI",{});var zGe=s(r3);cCe=n(zGe,"STRONG",{});var Njt=s(cCe);vzr=r(Njt,"blenderbot"),Njt.forEach(t),Fzr=r(zGe," \u2014 "),Pee=n(zGe,"A",{href:!0});var qjt=s(Pee);Tzr=r(qjt,"FlaxBlenderbotForConditionalGeneration"),qjt.forEach(t),Mzr=r(zGe," (Blenderbot model)"),zGe.forEach(t),Ezr=i(je),t3=n(je,"LI",{});var WGe=s(t3);fCe=n(WGe,"STRONG",{});var jjt=s(fCe);Czr=r(jjt,"blenderbot-small"),jjt.forEach(t),wzr=r(WGe," \u2014 "),Bee=n(WGe,"A",{href:!0});var Djt=s(Bee);Azr=r(Djt,"FlaxBlenderbotSmallForConditionalGeneration"),Djt.forEach(t),Lzr=r(WGe," (BlenderbotSmall model)"),WGe.forEach(t),yzr=i(je),a3=n(je,"LI",{});var QGe=s(a3);mCe=n(QGe,"STRONG",{});var Gjt=s(mCe);xzr=r(Gjt,"encoder-decoder"),Gjt.forEach(t),$zr=r(QGe," \u2014 "),Iee=n(QGe,"A",{href:!0});var Ojt=s(Iee);kzr=r(Ojt,"FlaxEncoderDecoderModel"),Ojt.forEach(t),Szr=r(QGe," (Encoder decoder model)"),QGe.forEach(t),Rzr=i(je),n3=n(je,"LI",{});var HGe=s(n3);gCe=n(HGe,"STRONG",{});var Vjt=s(gCe);Pzr=r(Vjt,"longt5"),Vjt.forEach(t),Bzr=r(HGe," \u2014 "),Nee=n(HGe,"A",{href:!0});var Xjt=s(Nee);Izr=r(Xjt,"FlaxLongT5ForConditionalGeneration"),Xjt.forEach(t),Nzr=r(HGe," (LongT5 model)"),HGe.forEach(t),qzr=i(je),s3=n(je,"LI",{});var UGe=s(s3);hCe=n(UGe,"STRONG",{});var zjt=s(hCe);jzr=r(zjt,"marian"),zjt.forEach(t),Dzr=r(UGe," \u2014 "),qee=n(UGe,"A",{href:!0});var Wjt=s(qee);Gzr=r(Wjt,"FlaxMarianMTModel"),Wjt.forEach(t),Ozr=r(UGe," (Marian model)"),UGe.forEach(t),Vzr=i(je),l3=n(je,"LI",{});var JGe=s(l3);pCe=n(JGe,"STRONG",{});var Qjt=s(pCe);Xzr=r(Qjt,"mbart"),Qjt.forEach(t),zzr=r(JGe," \u2014 "),jee=n(JGe,"A",{href:!0});var Hjt=s(jee);Wzr=r(Hjt,"FlaxMBartForConditionalGeneration"),Hjt.forEach(t),Qzr=r(JGe," (mBART model)"),JGe.forEach(t),Hzr=i(je),i3=n(je,"LI",{});var YGe=s(i3);_Ce=n(YGe,"STRONG",{});var Ujt=s(_Ce);Uzr=r(Ujt,"mt5"),Ujt.forEach(t),Jzr=r(YGe," \u2014 "),Dee=n(YGe,"A",{href:!0});var Jjt=s(Dee);Yzr=r(Jjt,"FlaxMT5ForConditionalGeneration"),Jjt.forEach(t),Kzr=r(YGe," (MT5 model)"),YGe.forEach(t),Zzr=i(je),d3=n(je,"LI",{});var KGe=s(d3);uCe=n(KGe,"STRONG",{});var Yjt=s(uCe);eWr=r(Yjt,"pegasus"),Yjt.forEach(t),oWr=r(KGe," \u2014 "),Gee=n(KGe,"A",{href:!0});var Kjt=s(Gee);rWr=r(Kjt,"FlaxPegasusForConditionalGeneration"),Kjt.forEach(t),tWr=r(KGe," (Pegasus model)"),KGe.forEach(t),aWr=i(je),c3=n(je,"LI",{});var ZGe=s(c3);bCe=n(ZGe,"STRONG",{});var Zjt=s(bCe);nWr=r(Zjt,"t5"),Zjt.forEach(t),sWr=r(ZGe," \u2014 "),Oee=n(ZGe,"A",{href:!0});var eDt=s(Oee);lWr=r(eDt,"FlaxT5ForConditionalGeneration"),eDt.forEach(t),iWr=r(ZGe," (T5 model)"),ZGe.forEach(t),je.forEach(t),dWr=i(ci),T(f3.$$.fragment,ci),ci.forEach(t),di.forEach(t),kXe=i(f),lf=n(f,"H2",{class:!0});var DWe=s(lf);m3=n(DWe,"A",{id:!0,class:!0,href:!0});var oDt=s(m3);vCe=n(oDt,"SPAN",{});var rDt=s(vCe);T(_$.$$.fragment,rDt),rDt.forEach(t),oDt.forEach(t),cWr=i(DWe),FCe=n(DWe,"SPAN",{});var tDt=s(FCe);fWr=r(tDt,"FlaxAutoModelForSequenceClassification"),tDt.forEach(t),DWe.forEach(t),SXe=i(f),Fr=n(f,"DIV",{class:!0});var fi=s(Fr);T(u$.$$.fragment,fi),mWr=i(fi),df=n(fi,"P",{});var $te=s(df);gWr=r($te,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Vee=n($te,"A",{href:!0});var aDt=s(Vee);hWr=r(aDt,"from_pretrained()"),aDt.forEach(t),pWr=r($te," class method or the "),Xee=n($te,"A",{href:!0});var nDt=s(Xee);_Wr=r(nDt,"from_config()"),nDt.forEach(t),uWr=r($te,` class
method.`),$te.forEach(t),bWr=i(fi),b$=n(fi,"P",{});var GWe=s(b$);vWr=r(GWe,"This class cannot be instantiated directly using "),TCe=n(GWe,"CODE",{});var sDt=s(TCe);FWr=r(sDt,"__init__()"),sDt.forEach(t),TWr=r(GWe," (throws an error)."),GWe.forEach(t),MWr=i(fi),Jt=n(fi,"DIV",{class:!0});var CA=s(Jt);T(v$.$$.fragment,CA),EWr=i(CA),MCe=n(CA,"P",{});var lDt=s(MCe);CWr=r(lDt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),lDt.forEach(t),wWr=i(CA),cf=n(CA,"P",{});var kte=s(cf);AWr=r(kte,`Note:
Loading a model from its configuration file does `),ECe=n(kte,"STRONG",{});var iDt=s(ECe);LWr=r(iDt,"not"),iDt.forEach(t),yWr=r(kte,` load the model weights. It only affects the
model\u2019s configuration. Use `),zee=n(kte,"A",{href:!0});var dDt=s(zee);xWr=r(dDt,"from_pretrained()"),dDt.forEach(t),$Wr=r(kte," to load the model weights."),kte.forEach(t),kWr=i(CA),T(g3.$$.fragment,CA),CA.forEach(t),SWr=i(fi),Hr=n(fi,"DIV",{class:!0});var mi=s(Hr);T(F$.$$.fragment,mi),RWr=i(mi),CCe=n(mi,"P",{});var cDt=s(CCe);PWr=r(cDt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),cDt.forEach(t),BWr=i(mi),An=n(mi,"P",{});var wA=s(An);IWr=r(wA,"The model class to instantiate is selected based on the "),wCe=n(wA,"CODE",{});var fDt=s(wCe);NWr=r(fDt,"model_type"),fDt.forEach(t),qWr=r(wA,` property of the config object (either
passed as an argument or loaded from `),ACe=n(wA,"CODE",{});var mDt=s(ACe);jWr=r(mDt,"pretrained_model_name_or_path"),mDt.forEach(t),DWr=r(wA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LCe=n(wA,"CODE",{});var gDt=s(LCe);GWr=r(gDt,"pretrained_model_name_or_path"),gDt.forEach(t),OWr=r(wA,":"),wA.forEach(t),VWr=i(mi),Se=n(mi,"UL",{});var De=s(Se);h3=n(De,"LI",{});var eOe=s(h3);yCe=n(eOe,"STRONG",{});var hDt=s(yCe);XWr=r(hDt,"albert"),hDt.forEach(t),zWr=r(eOe," \u2014 "),Wee=n(eOe,"A",{href:!0});var pDt=s(Wee);WWr=r(pDt,"FlaxAlbertForSequenceClassification"),pDt.forEach(t),QWr=r(eOe," (ALBERT model)"),eOe.forEach(t),HWr=i(De),p3=n(De,"LI",{});var oOe=s(p3);xCe=n(oOe,"STRONG",{});var _Dt=s(xCe);UWr=r(_Dt,"bart"),_Dt.forEach(t),JWr=r(oOe," \u2014 "),Qee=n(oOe,"A",{href:!0});var uDt=s(Qee);YWr=r(uDt,"FlaxBartForSequenceClassification"),uDt.forEach(t),KWr=r(oOe," (BART model)"),oOe.forEach(t),ZWr=i(De),_3=n(De,"LI",{});var rOe=s(_3);$Ce=n(rOe,"STRONG",{});var bDt=s($Ce);eQr=r(bDt,"bert"),bDt.forEach(t),oQr=r(rOe," \u2014 "),Hee=n(rOe,"A",{href:!0});var vDt=s(Hee);rQr=r(vDt,"FlaxBertForSequenceClassification"),vDt.forEach(t),tQr=r(rOe," (BERT model)"),rOe.forEach(t),aQr=i(De),u3=n(De,"LI",{});var tOe=s(u3);kCe=n(tOe,"STRONG",{});var FDt=s(kCe);nQr=r(FDt,"big_bird"),FDt.forEach(t),sQr=r(tOe," \u2014 "),Uee=n(tOe,"A",{href:!0});var TDt=s(Uee);lQr=r(TDt,"FlaxBigBirdForSequenceClassification"),TDt.forEach(t),iQr=r(tOe," (BigBird model)"),tOe.forEach(t),dQr=i(De),b3=n(De,"LI",{});var aOe=s(b3);SCe=n(aOe,"STRONG",{});var MDt=s(SCe);cQr=r(MDt,"distilbert"),MDt.forEach(t),fQr=r(aOe," \u2014 "),Jee=n(aOe,"A",{href:!0});var EDt=s(Jee);mQr=r(EDt,"FlaxDistilBertForSequenceClassification"),EDt.forEach(t),gQr=r(aOe," (DistilBERT model)"),aOe.forEach(t),hQr=i(De),v3=n(De,"LI",{});var nOe=s(v3);RCe=n(nOe,"STRONG",{});var CDt=s(RCe);pQr=r(CDt,"electra"),CDt.forEach(t),_Qr=r(nOe," \u2014 "),Yee=n(nOe,"A",{href:!0});var wDt=s(Yee);uQr=r(wDt,"FlaxElectraForSequenceClassification"),wDt.forEach(t),bQr=r(nOe," (ELECTRA model)"),nOe.forEach(t),vQr=i(De),F3=n(De,"LI",{});var sOe=s(F3);PCe=n(sOe,"STRONG",{});var ADt=s(PCe);FQr=r(ADt,"mbart"),ADt.forEach(t),TQr=r(sOe," \u2014 "),Kee=n(sOe,"A",{href:!0});var LDt=s(Kee);MQr=r(LDt,"FlaxMBartForSequenceClassification"),LDt.forEach(t),EQr=r(sOe," (mBART model)"),sOe.forEach(t),CQr=i(De),T3=n(De,"LI",{});var lOe=s(T3);BCe=n(lOe,"STRONG",{});var yDt=s(BCe);wQr=r(yDt,"roberta"),yDt.forEach(t),AQr=r(lOe," \u2014 "),Zee=n(lOe,"A",{href:!0});var xDt=s(Zee);LQr=r(xDt,"FlaxRobertaForSequenceClassification"),xDt.forEach(t),yQr=r(lOe," (RoBERTa model)"),lOe.forEach(t),xQr=i(De),M3=n(De,"LI",{});var iOe=s(M3);ICe=n(iOe,"STRONG",{});var $Dt=s(ICe);$Qr=r($Dt,"roformer"),$Dt.forEach(t),kQr=r(iOe," \u2014 "),eoe=n(iOe,"A",{href:!0});var kDt=s(eoe);SQr=r(kDt,"FlaxRoFormerForSequenceClassification"),kDt.forEach(t),RQr=r(iOe," (RoFormer model)"),iOe.forEach(t),PQr=i(De),E3=n(De,"LI",{});var dOe=s(E3);NCe=n(dOe,"STRONG",{});var SDt=s(NCe);BQr=r(SDt,"xlm-roberta"),SDt.forEach(t),IQr=r(dOe," \u2014 "),ooe=n(dOe,"A",{href:!0});var RDt=s(ooe);NQr=r(RDt,"FlaxXLMRobertaForSequenceClassification"),RDt.forEach(t),qQr=r(dOe," (XLM-RoBERTa model)"),dOe.forEach(t),De.forEach(t),jQr=i(mi),T(C3.$$.fragment,mi),mi.forEach(t),fi.forEach(t),RXe=i(f),ff=n(f,"H2",{class:!0});var OWe=s(ff);w3=n(OWe,"A",{id:!0,class:!0,href:!0});var PDt=s(w3);qCe=n(PDt,"SPAN",{});var BDt=s(qCe);T(T$.$$.fragment,BDt),BDt.forEach(t),PDt.forEach(t),DQr=i(OWe),jCe=n(OWe,"SPAN",{});var IDt=s(jCe);GQr=r(IDt,"FlaxAutoModelForQuestionAnswering"),IDt.forEach(t),OWe.forEach(t),PXe=i(f),Tr=n(f,"DIV",{class:!0});var gi=s(Tr);T(M$.$$.fragment,gi),OQr=i(gi),mf=n(gi,"P",{});var Ste=s(mf);VQr=r(Ste,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),roe=n(Ste,"A",{href:!0});var NDt=s(roe);XQr=r(NDt,"from_pretrained()"),NDt.forEach(t),zQr=r(Ste," class method or the "),toe=n(Ste,"A",{href:!0});var qDt=s(toe);WQr=r(qDt,"from_config()"),qDt.forEach(t),QQr=r(Ste,` class
method.`),Ste.forEach(t),HQr=i(gi),E$=n(gi,"P",{});var VWe=s(E$);UQr=r(VWe,"This class cannot be instantiated directly using "),DCe=n(VWe,"CODE",{});var jDt=s(DCe);JQr=r(jDt,"__init__()"),jDt.forEach(t),YQr=r(VWe," (throws an error)."),VWe.forEach(t),KQr=i(gi),Yt=n(gi,"DIV",{class:!0});var AA=s(Yt);T(C$.$$.fragment,AA),ZQr=i(AA),GCe=n(AA,"P",{});var DDt=s(GCe);eHr=r(DDt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),DDt.forEach(t),oHr=i(AA),gf=n(AA,"P",{});var Rte=s(gf);rHr=r(Rte,`Note:
Loading a model from its configuration file does `),OCe=n(Rte,"STRONG",{});var GDt=s(OCe);tHr=r(GDt,"not"),GDt.forEach(t),aHr=r(Rte,` load the model weights. It only affects the
model\u2019s configuration. Use `),aoe=n(Rte,"A",{href:!0});var ODt=s(aoe);nHr=r(ODt,"from_pretrained()"),ODt.forEach(t),sHr=r(Rte," to load the model weights."),Rte.forEach(t),lHr=i(AA),T(A3.$$.fragment,AA),AA.forEach(t),iHr=i(gi),Ur=n(gi,"DIV",{class:!0});var hi=s(Ur);T(w$.$$.fragment,hi),dHr=i(hi),VCe=n(hi,"P",{});var VDt=s(VCe);cHr=r(VDt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),VDt.forEach(t),fHr=i(hi),Ln=n(hi,"P",{});var LA=s(Ln);mHr=r(LA,"The model class to instantiate is selected based on the "),XCe=n(LA,"CODE",{});var XDt=s(XCe);gHr=r(XDt,"model_type"),XDt.forEach(t),hHr=r(LA,` property of the config object (either
passed as an argument or loaded from `),zCe=n(LA,"CODE",{});var zDt=s(zCe);pHr=r(zDt,"pretrained_model_name_or_path"),zDt.forEach(t),_Hr=r(LA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WCe=n(LA,"CODE",{});var WDt=s(WCe);uHr=r(WDt,"pretrained_model_name_or_path"),WDt.forEach(t),bHr=r(LA,":"),LA.forEach(t),vHr=i(hi),Re=n(hi,"UL",{});var Ge=s(Re);L3=n(Ge,"LI",{});var cOe=s(L3);QCe=n(cOe,"STRONG",{});var QDt=s(QCe);FHr=r(QDt,"albert"),QDt.forEach(t),THr=r(cOe," \u2014 "),noe=n(cOe,"A",{href:!0});var HDt=s(noe);MHr=r(HDt,"FlaxAlbertForQuestionAnswering"),HDt.forEach(t),EHr=r(cOe," (ALBERT model)"),cOe.forEach(t),CHr=i(Ge),y3=n(Ge,"LI",{});var fOe=s(y3);HCe=n(fOe,"STRONG",{});var UDt=s(HCe);wHr=r(UDt,"bart"),UDt.forEach(t),AHr=r(fOe," \u2014 "),soe=n(fOe,"A",{href:!0});var JDt=s(soe);LHr=r(JDt,"FlaxBartForQuestionAnswering"),JDt.forEach(t),yHr=r(fOe," (BART model)"),fOe.forEach(t),xHr=i(Ge),x3=n(Ge,"LI",{});var mOe=s(x3);UCe=n(mOe,"STRONG",{});var YDt=s(UCe);$Hr=r(YDt,"bert"),YDt.forEach(t),kHr=r(mOe," \u2014 "),loe=n(mOe,"A",{href:!0});var KDt=s(loe);SHr=r(KDt,"FlaxBertForQuestionAnswering"),KDt.forEach(t),RHr=r(mOe," (BERT model)"),mOe.forEach(t),PHr=i(Ge),$3=n(Ge,"LI",{});var gOe=s($3);JCe=n(gOe,"STRONG",{});var ZDt=s(JCe);BHr=r(ZDt,"big_bird"),ZDt.forEach(t),IHr=r(gOe," \u2014 "),ioe=n(gOe,"A",{href:!0});var eGt=s(ioe);NHr=r(eGt,"FlaxBigBirdForQuestionAnswering"),eGt.forEach(t),qHr=r(gOe," (BigBird model)"),gOe.forEach(t),jHr=i(Ge),k3=n(Ge,"LI",{});var hOe=s(k3);YCe=n(hOe,"STRONG",{});var oGt=s(YCe);DHr=r(oGt,"distilbert"),oGt.forEach(t),GHr=r(hOe," \u2014 "),doe=n(hOe,"A",{href:!0});var rGt=s(doe);OHr=r(rGt,"FlaxDistilBertForQuestionAnswering"),rGt.forEach(t),VHr=r(hOe," (DistilBERT model)"),hOe.forEach(t),XHr=i(Ge),S3=n(Ge,"LI",{});var pOe=s(S3);KCe=n(pOe,"STRONG",{});var tGt=s(KCe);zHr=r(tGt,"electra"),tGt.forEach(t),WHr=r(pOe," \u2014 "),coe=n(pOe,"A",{href:!0});var aGt=s(coe);QHr=r(aGt,"FlaxElectraForQuestionAnswering"),aGt.forEach(t),HHr=r(pOe," (ELECTRA model)"),pOe.forEach(t),UHr=i(Ge),R3=n(Ge,"LI",{});var _Oe=s(R3);ZCe=n(_Oe,"STRONG",{});var nGt=s(ZCe);JHr=r(nGt,"mbart"),nGt.forEach(t),YHr=r(_Oe," \u2014 "),foe=n(_Oe,"A",{href:!0});var sGt=s(foe);KHr=r(sGt,"FlaxMBartForQuestionAnswering"),sGt.forEach(t),ZHr=r(_Oe," (mBART model)"),_Oe.forEach(t),eUr=i(Ge),P3=n(Ge,"LI",{});var uOe=s(P3);e3e=n(uOe,"STRONG",{});var lGt=s(e3e);oUr=r(lGt,"roberta"),lGt.forEach(t),rUr=r(uOe," \u2014 "),moe=n(uOe,"A",{href:!0});var iGt=s(moe);tUr=r(iGt,"FlaxRobertaForQuestionAnswering"),iGt.forEach(t),aUr=r(uOe," (RoBERTa model)"),uOe.forEach(t),nUr=i(Ge),B3=n(Ge,"LI",{});var bOe=s(B3);o3e=n(bOe,"STRONG",{});var dGt=s(o3e);sUr=r(dGt,"roformer"),dGt.forEach(t),lUr=r(bOe," \u2014 "),goe=n(bOe,"A",{href:!0});var cGt=s(goe);iUr=r(cGt,"FlaxRoFormerForQuestionAnswering"),cGt.forEach(t),dUr=r(bOe," (RoFormer model)"),bOe.forEach(t),cUr=i(Ge),I3=n(Ge,"LI",{});var vOe=s(I3);r3e=n(vOe,"STRONG",{});var fGt=s(r3e);fUr=r(fGt,"xlm-roberta"),fGt.forEach(t),mUr=r(vOe," \u2014 "),hoe=n(vOe,"A",{href:!0});var mGt=s(hoe);gUr=r(mGt,"FlaxXLMRobertaForQuestionAnswering"),mGt.forEach(t),hUr=r(vOe," (XLM-RoBERTa model)"),vOe.forEach(t),Ge.forEach(t),pUr=i(hi),T(N3.$$.fragment,hi),hi.forEach(t),gi.forEach(t),BXe=i(f),hf=n(f,"H2",{class:!0});var XWe=s(hf);q3=n(XWe,"A",{id:!0,class:!0,href:!0});var gGt=s(q3);t3e=n(gGt,"SPAN",{});var hGt=s(t3e);T(A$.$$.fragment,hGt),hGt.forEach(t),gGt.forEach(t),_Ur=i(XWe),a3e=n(XWe,"SPAN",{});var pGt=s(a3e);uUr=r(pGt,"FlaxAutoModelForTokenClassification"),pGt.forEach(t),XWe.forEach(t),IXe=i(f),Mr=n(f,"DIV",{class:!0});var pi=s(Mr);T(L$.$$.fragment,pi),bUr=i(pi),pf=n(pi,"P",{});var Pte=s(pf);vUr=r(Pte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),poe=n(Pte,"A",{href:!0});var _Gt=s(poe);FUr=r(_Gt,"from_pretrained()"),_Gt.forEach(t),TUr=r(Pte," class method or the "),_oe=n(Pte,"A",{href:!0});var uGt=s(_oe);MUr=r(uGt,"from_config()"),uGt.forEach(t),EUr=r(Pte,` class
method.`),Pte.forEach(t),CUr=i(pi),y$=n(pi,"P",{});var zWe=s(y$);wUr=r(zWe,"This class cannot be instantiated directly using "),n3e=n(zWe,"CODE",{});var bGt=s(n3e);AUr=r(bGt,"__init__()"),bGt.forEach(t),LUr=r(zWe," (throws an error)."),zWe.forEach(t),yUr=i(pi),Kt=n(pi,"DIV",{class:!0});var yA=s(Kt);T(x$.$$.fragment,yA),xUr=i(yA),s3e=n(yA,"P",{});var vGt=s(s3e);$Ur=r(vGt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),vGt.forEach(t),kUr=i(yA),_f=n(yA,"P",{});var Bte=s(_f);SUr=r(Bte,`Note:
Loading a model from its configuration file does `),l3e=n(Bte,"STRONG",{});var FGt=s(l3e);RUr=r(FGt,"not"),FGt.forEach(t),PUr=r(Bte,` load the model weights. It only affects the
model\u2019s configuration. Use `),uoe=n(Bte,"A",{href:!0});var TGt=s(uoe);BUr=r(TGt,"from_pretrained()"),TGt.forEach(t),IUr=r(Bte," to load the model weights."),Bte.forEach(t),NUr=i(yA),T(j3.$$.fragment,yA),yA.forEach(t),qUr=i(pi),Jr=n(pi,"DIV",{class:!0});var _i=s(Jr);T($$.$$.fragment,_i),jUr=i(_i),i3e=n(_i,"P",{});var MGt=s(i3e);DUr=r(MGt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),MGt.forEach(t),GUr=i(_i),yn=n(_i,"P",{});var xA=s(yn);OUr=r(xA,"The model class to instantiate is selected based on the "),d3e=n(xA,"CODE",{});var EGt=s(d3e);VUr=r(EGt,"model_type"),EGt.forEach(t),XUr=r(xA,` property of the config object (either
passed as an argument or loaded from `),c3e=n(xA,"CODE",{});var CGt=s(c3e);zUr=r(CGt,"pretrained_model_name_or_path"),CGt.forEach(t),WUr=r(xA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f3e=n(xA,"CODE",{});var wGt=s(f3e);QUr=r(wGt,"pretrained_model_name_or_path"),wGt.forEach(t),HUr=r(xA,":"),xA.forEach(t),UUr=i(_i),Ve=n(_i,"UL",{});var To=s(Ve);D3=n(To,"LI",{});var FOe=s(D3);m3e=n(FOe,"STRONG",{});var AGt=s(m3e);JUr=r(AGt,"albert"),AGt.forEach(t),YUr=r(FOe," \u2014 "),boe=n(FOe,"A",{href:!0});var LGt=s(boe);KUr=r(LGt,"FlaxAlbertForTokenClassification"),LGt.forEach(t),ZUr=r(FOe," (ALBERT model)"),FOe.forEach(t),eJr=i(To),G3=n(To,"LI",{});var TOe=s(G3);g3e=n(TOe,"STRONG",{});var yGt=s(g3e);oJr=r(yGt,"bert"),yGt.forEach(t),rJr=r(TOe," \u2014 "),voe=n(TOe,"A",{href:!0});var xGt=s(voe);tJr=r(xGt,"FlaxBertForTokenClassification"),xGt.forEach(t),aJr=r(TOe," (BERT model)"),TOe.forEach(t),nJr=i(To),O3=n(To,"LI",{});var MOe=s(O3);h3e=n(MOe,"STRONG",{});var $Gt=s(h3e);sJr=r($Gt,"big_bird"),$Gt.forEach(t),lJr=r(MOe," \u2014 "),Foe=n(MOe,"A",{href:!0});var kGt=s(Foe);iJr=r(kGt,"FlaxBigBirdForTokenClassification"),kGt.forEach(t),dJr=r(MOe," (BigBird model)"),MOe.forEach(t),cJr=i(To),V3=n(To,"LI",{});var EOe=s(V3);p3e=n(EOe,"STRONG",{});var SGt=s(p3e);fJr=r(SGt,"distilbert"),SGt.forEach(t),mJr=r(EOe," \u2014 "),Toe=n(EOe,"A",{href:!0});var RGt=s(Toe);gJr=r(RGt,"FlaxDistilBertForTokenClassification"),RGt.forEach(t),hJr=r(EOe," (DistilBERT model)"),EOe.forEach(t),pJr=i(To),X3=n(To,"LI",{});var COe=s(X3);_3e=n(COe,"STRONG",{});var PGt=s(_3e);_Jr=r(PGt,"electra"),PGt.forEach(t),uJr=r(COe," \u2014 "),Moe=n(COe,"A",{href:!0});var BGt=s(Moe);bJr=r(BGt,"FlaxElectraForTokenClassification"),BGt.forEach(t),vJr=r(COe," (ELECTRA model)"),COe.forEach(t),FJr=i(To),z3=n(To,"LI",{});var wOe=s(z3);u3e=n(wOe,"STRONG",{});var IGt=s(u3e);TJr=r(IGt,"roberta"),IGt.forEach(t),MJr=r(wOe," \u2014 "),Eoe=n(wOe,"A",{href:!0});var NGt=s(Eoe);EJr=r(NGt,"FlaxRobertaForTokenClassification"),NGt.forEach(t),CJr=r(wOe," (RoBERTa model)"),wOe.forEach(t),wJr=i(To),W3=n(To,"LI",{});var AOe=s(W3);b3e=n(AOe,"STRONG",{});var qGt=s(b3e);AJr=r(qGt,"roformer"),qGt.forEach(t),LJr=r(AOe," \u2014 "),Coe=n(AOe,"A",{href:!0});var jGt=s(Coe);yJr=r(jGt,"FlaxRoFormerForTokenClassification"),jGt.forEach(t),xJr=r(AOe," (RoFormer model)"),AOe.forEach(t),$Jr=i(To),Q3=n(To,"LI",{});var LOe=s(Q3);v3e=n(LOe,"STRONG",{});var DGt=s(v3e);kJr=r(DGt,"xlm-roberta"),DGt.forEach(t),SJr=r(LOe," \u2014 "),woe=n(LOe,"A",{href:!0});var GGt=s(woe);RJr=r(GGt,"FlaxXLMRobertaForTokenClassification"),GGt.forEach(t),PJr=r(LOe," (XLM-RoBERTa model)"),LOe.forEach(t),To.forEach(t),BJr=i(_i),T(H3.$$.fragment,_i),_i.forEach(t),pi.forEach(t),NXe=i(f),uf=n(f,"H2",{class:!0});var WWe=s(uf);U3=n(WWe,"A",{id:!0,class:!0,href:!0});var OGt=s(U3);F3e=n(OGt,"SPAN",{});var VGt=s(F3e);T(k$.$$.fragment,VGt),VGt.forEach(t),OGt.forEach(t),IJr=i(WWe),T3e=n(WWe,"SPAN",{});var XGt=s(T3e);NJr=r(XGt,"FlaxAutoModelForMultipleChoice"),XGt.forEach(t),WWe.forEach(t),qXe=i(f),Er=n(f,"DIV",{class:!0});var ui=s(Er);T(S$.$$.fragment,ui),qJr=i(ui),bf=n(ui,"P",{});var Ite=s(bf);jJr=r(Ite,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Aoe=n(Ite,"A",{href:!0});var zGt=s(Aoe);DJr=r(zGt,"from_pretrained()"),zGt.forEach(t),GJr=r(Ite," class method or the "),Loe=n(Ite,"A",{href:!0});var WGt=s(Loe);OJr=r(WGt,"from_config()"),WGt.forEach(t),VJr=r(Ite,` class
method.`),Ite.forEach(t),XJr=i(ui),R$=n(ui,"P",{});var QWe=s(R$);zJr=r(QWe,"This class cannot be instantiated directly using "),M3e=n(QWe,"CODE",{});var QGt=s(M3e);WJr=r(QGt,"__init__()"),QGt.forEach(t),QJr=r(QWe," (throws an error)."),QWe.forEach(t),HJr=i(ui),Zt=n(ui,"DIV",{class:!0});var $A=s(Zt);T(P$.$$.fragment,$A),UJr=i($A),E3e=n($A,"P",{});var HGt=s(E3e);JJr=r(HGt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),HGt.forEach(t),YJr=i($A),vf=n($A,"P",{});var Nte=s(vf);KJr=r(Nte,`Note:
Loading a model from its configuration file does `),C3e=n(Nte,"STRONG",{});var UGt=s(C3e);ZJr=r(UGt,"not"),UGt.forEach(t),eYr=r(Nte,` load the model weights. It only affects the
model\u2019s configuration. Use `),yoe=n(Nte,"A",{href:!0});var JGt=s(yoe);oYr=r(JGt,"from_pretrained()"),JGt.forEach(t),rYr=r(Nte," to load the model weights."),Nte.forEach(t),tYr=i($A),T(J3.$$.fragment,$A),$A.forEach(t),aYr=i(ui),Yr=n(ui,"DIV",{class:!0});var bi=s(Yr);T(B$.$$.fragment,bi),nYr=i(bi),w3e=n(bi,"P",{});var YGt=s(w3e);sYr=r(YGt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),YGt.forEach(t),lYr=i(bi),xn=n(bi,"P",{});var kA=s(xn);iYr=r(kA,"The model class to instantiate is selected based on the "),A3e=n(kA,"CODE",{});var KGt=s(A3e);dYr=r(KGt,"model_type"),KGt.forEach(t),cYr=r(kA,` property of the config object (either
passed as an argument or loaded from `),L3e=n(kA,"CODE",{});var ZGt=s(L3e);fYr=r(ZGt,"pretrained_model_name_or_path"),ZGt.forEach(t),mYr=r(kA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y3e=n(kA,"CODE",{});var eOt=s(y3e);gYr=r(eOt,"pretrained_model_name_or_path"),eOt.forEach(t),hYr=r(kA,":"),kA.forEach(t),pYr=i(bi),Xe=n(bi,"UL",{});var Mo=s(Xe);Y3=n(Mo,"LI",{});var yOe=s(Y3);x3e=n(yOe,"STRONG",{});var oOt=s(x3e);_Yr=r(oOt,"albert"),oOt.forEach(t),uYr=r(yOe," \u2014 "),xoe=n(yOe,"A",{href:!0});var rOt=s(xoe);bYr=r(rOt,"FlaxAlbertForMultipleChoice"),rOt.forEach(t),vYr=r(yOe," (ALBERT model)"),yOe.forEach(t),FYr=i(Mo),K3=n(Mo,"LI",{});var xOe=s(K3);$3e=n(xOe,"STRONG",{});var tOt=s($3e);TYr=r(tOt,"bert"),tOt.forEach(t),MYr=r(xOe," \u2014 "),$oe=n(xOe,"A",{href:!0});var aOt=s($oe);EYr=r(aOt,"FlaxBertForMultipleChoice"),aOt.forEach(t),CYr=r(xOe," (BERT model)"),xOe.forEach(t),wYr=i(Mo),Z3=n(Mo,"LI",{});var $Oe=s(Z3);k3e=n($Oe,"STRONG",{});var nOt=s(k3e);AYr=r(nOt,"big_bird"),nOt.forEach(t),LYr=r($Oe," \u2014 "),koe=n($Oe,"A",{href:!0});var sOt=s(koe);yYr=r(sOt,"FlaxBigBirdForMultipleChoice"),sOt.forEach(t),xYr=r($Oe," (BigBird model)"),$Oe.forEach(t),$Yr=i(Mo),e5=n(Mo,"LI",{});var kOe=s(e5);S3e=n(kOe,"STRONG",{});var lOt=s(S3e);kYr=r(lOt,"distilbert"),lOt.forEach(t),SYr=r(kOe," \u2014 "),Soe=n(kOe,"A",{href:!0});var iOt=s(Soe);RYr=r(iOt,"FlaxDistilBertForMultipleChoice"),iOt.forEach(t),PYr=r(kOe," (DistilBERT model)"),kOe.forEach(t),BYr=i(Mo),o5=n(Mo,"LI",{});var SOe=s(o5);R3e=n(SOe,"STRONG",{});var dOt=s(R3e);IYr=r(dOt,"electra"),dOt.forEach(t),NYr=r(SOe," \u2014 "),Roe=n(SOe,"A",{href:!0});var cOt=s(Roe);qYr=r(cOt,"FlaxElectraForMultipleChoice"),cOt.forEach(t),jYr=r(SOe," (ELECTRA model)"),SOe.forEach(t),DYr=i(Mo),r5=n(Mo,"LI",{});var ROe=s(r5);P3e=n(ROe,"STRONG",{});var fOt=s(P3e);GYr=r(fOt,"roberta"),fOt.forEach(t),OYr=r(ROe," \u2014 "),Poe=n(ROe,"A",{href:!0});var mOt=s(Poe);VYr=r(mOt,"FlaxRobertaForMultipleChoice"),mOt.forEach(t),XYr=r(ROe," (RoBERTa model)"),ROe.forEach(t),zYr=i(Mo),t5=n(Mo,"LI",{});var POe=s(t5);B3e=n(POe,"STRONG",{});var gOt=s(B3e);WYr=r(gOt,"roformer"),gOt.forEach(t),QYr=r(POe," \u2014 "),Boe=n(POe,"A",{href:!0});var hOt=s(Boe);HYr=r(hOt,"FlaxRoFormerForMultipleChoice"),hOt.forEach(t),UYr=r(POe," (RoFormer model)"),POe.forEach(t),JYr=i(Mo),a5=n(Mo,"LI",{});var BOe=s(a5);I3e=n(BOe,"STRONG",{});var pOt=s(I3e);YYr=r(pOt,"xlm-roberta"),pOt.forEach(t),KYr=r(BOe," \u2014 "),Ioe=n(BOe,"A",{href:!0});var _Ot=s(Ioe);ZYr=r(_Ot,"FlaxXLMRobertaForMultipleChoice"),_Ot.forEach(t),eKr=r(BOe," (XLM-RoBERTa model)"),BOe.forEach(t),Mo.forEach(t),oKr=i(bi),T(n5.$$.fragment,bi),bi.forEach(t),ui.forEach(t),jXe=i(f),Ff=n(f,"H2",{class:!0});var HWe=s(Ff);s5=n(HWe,"A",{id:!0,class:!0,href:!0});var uOt=s(s5);N3e=n(uOt,"SPAN",{});var bOt=s(N3e);T(I$.$$.fragment,bOt),bOt.forEach(t),uOt.forEach(t),rKr=i(HWe),q3e=n(HWe,"SPAN",{});var vOt=s(q3e);tKr=r(vOt,"FlaxAutoModelForNextSentencePrediction"),vOt.forEach(t),HWe.forEach(t),DXe=i(f),Cr=n(f,"DIV",{class:!0});var vi=s(Cr);T(N$.$$.fragment,vi),aKr=i(vi),Tf=n(vi,"P",{});var qte=s(Tf);nKr=r(qte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Noe=n(qte,"A",{href:!0});var FOt=s(Noe);sKr=r(FOt,"from_pretrained()"),FOt.forEach(t),lKr=r(qte," class method or the "),qoe=n(qte,"A",{href:!0});var TOt=s(qoe);iKr=r(TOt,"from_config()"),TOt.forEach(t),dKr=r(qte,` class
method.`),qte.forEach(t),cKr=i(vi),q$=n(vi,"P",{});var UWe=s(q$);fKr=r(UWe,"This class cannot be instantiated directly using "),j3e=n(UWe,"CODE",{});var MOt=s(j3e);mKr=r(MOt,"__init__()"),MOt.forEach(t),gKr=r(UWe," (throws an error)."),UWe.forEach(t),hKr=i(vi),ea=n(vi,"DIV",{class:!0});var SA=s(ea);T(j$.$$.fragment,SA),pKr=i(SA),D3e=n(SA,"P",{});var EOt=s(D3e);_Kr=r(EOt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),EOt.forEach(t),uKr=i(SA),Mf=n(SA,"P",{});var jte=s(Mf);bKr=r(jte,`Note:
Loading a model from its configuration file does `),G3e=n(jte,"STRONG",{});var COt=s(G3e);vKr=r(COt,"not"),COt.forEach(t),FKr=r(jte,` load the model weights. It only affects the
model\u2019s configuration. Use `),joe=n(jte,"A",{href:!0});var wOt=s(joe);TKr=r(wOt,"from_pretrained()"),wOt.forEach(t),MKr=r(jte," to load the model weights."),jte.forEach(t),EKr=i(SA),T(l5.$$.fragment,SA),SA.forEach(t),CKr=i(vi),Kr=n(vi,"DIV",{class:!0});var Fi=s(Kr);T(D$.$$.fragment,Fi),wKr=i(Fi),O3e=n(Fi,"P",{});var AOt=s(O3e);AKr=r(AOt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),AOt.forEach(t),LKr=i(Fi),$n=n(Fi,"P",{});var RA=s($n);yKr=r(RA,"The model class to instantiate is selected based on the "),V3e=n(RA,"CODE",{});var LOt=s(V3e);xKr=r(LOt,"model_type"),LOt.forEach(t),$Kr=r(RA,` property of the config object (either
passed as an argument or loaded from `),X3e=n(RA,"CODE",{});var yOt=s(X3e);kKr=r(yOt,"pretrained_model_name_or_path"),yOt.forEach(t),SKr=r(RA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z3e=n(RA,"CODE",{});var xOt=s(z3e);RKr=r(xOt,"pretrained_model_name_or_path"),xOt.forEach(t),PKr=r(RA,":"),RA.forEach(t),BKr=i(Fi),W3e=n(Fi,"UL",{});var $Ot=s(W3e);i5=n($Ot,"LI",{});var IOe=s(i5);Q3e=n(IOe,"STRONG",{});var kOt=s(Q3e);IKr=r(kOt,"bert"),kOt.forEach(t),NKr=r(IOe," \u2014 "),Doe=n(IOe,"A",{href:!0});var SOt=s(Doe);qKr=r(SOt,"FlaxBertForNextSentencePrediction"),SOt.forEach(t),jKr=r(IOe," (BERT model)"),IOe.forEach(t),$Ot.forEach(t),DKr=i(Fi),T(d5.$$.fragment,Fi),Fi.forEach(t),vi.forEach(t),GXe=i(f),Ef=n(f,"H2",{class:!0});var JWe=s(Ef);c5=n(JWe,"A",{id:!0,class:!0,href:!0});var ROt=s(c5);H3e=n(ROt,"SPAN",{});var POt=s(H3e);T(G$.$$.fragment,POt),POt.forEach(t),ROt.forEach(t),GKr=i(JWe),U3e=n(JWe,"SPAN",{});var BOt=s(U3e);OKr=r(BOt,"FlaxAutoModelForImageClassification"),BOt.forEach(t),JWe.forEach(t),OXe=i(f),wr=n(f,"DIV",{class:!0});var Ti=s(wr);T(O$.$$.fragment,Ti),VKr=i(Ti),Cf=n(Ti,"P",{});var Dte=s(Cf);XKr=r(Dte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Goe=n(Dte,"A",{href:!0});var IOt=s(Goe);zKr=r(IOt,"from_pretrained()"),IOt.forEach(t),WKr=r(Dte," class method or the "),Ooe=n(Dte,"A",{href:!0});var NOt=s(Ooe);QKr=r(NOt,"from_config()"),NOt.forEach(t),HKr=r(Dte,` class
method.`),Dte.forEach(t),UKr=i(Ti),V$=n(Ti,"P",{});var YWe=s(V$);JKr=r(YWe,"This class cannot be instantiated directly using "),J3e=n(YWe,"CODE",{});var qOt=s(J3e);YKr=r(qOt,"__init__()"),qOt.forEach(t),KKr=r(YWe," (throws an error)."),YWe.forEach(t),ZKr=i(Ti),oa=n(Ti,"DIV",{class:!0});var PA=s(oa);T(X$.$$.fragment,PA),eZr=i(PA),Y3e=n(PA,"P",{});var jOt=s(Y3e);oZr=r(jOt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),jOt.forEach(t),rZr=i(PA),wf=n(PA,"P",{});var Gte=s(wf);tZr=r(Gte,`Note:
Loading a model from its configuration file does `),K3e=n(Gte,"STRONG",{});var DOt=s(K3e);aZr=r(DOt,"not"),DOt.forEach(t),nZr=r(Gte,` load the model weights. It only affects the
model\u2019s configuration. Use `),Voe=n(Gte,"A",{href:!0});var GOt=s(Voe);sZr=r(GOt,"from_pretrained()"),GOt.forEach(t),lZr=r(Gte," to load the model weights."),Gte.forEach(t),iZr=i(PA),T(f5.$$.fragment,PA),PA.forEach(t),dZr=i(Ti),Zr=n(Ti,"DIV",{class:!0});var Mi=s(Zr);T(z$.$$.fragment,Mi),cZr=i(Mi),Z3e=n(Mi,"P",{});var OOt=s(Z3e);fZr=r(OOt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),OOt.forEach(t),mZr=i(Mi),kn=n(Mi,"P",{});var BA=s(kn);gZr=r(BA,"The model class to instantiate is selected based on the "),e5e=n(BA,"CODE",{});var VOt=s(e5e);hZr=r(VOt,"model_type"),VOt.forEach(t),pZr=r(BA,` property of the config object (either
passed as an argument or loaded from `),o5e=n(BA,"CODE",{});var XOt=s(o5e);_Zr=r(XOt,"pretrained_model_name_or_path"),XOt.forEach(t),uZr=r(BA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r5e=n(BA,"CODE",{});var zOt=s(r5e);bZr=r(zOt,"pretrained_model_name_or_path"),zOt.forEach(t),vZr=r(BA,":"),BA.forEach(t),FZr=i(Mi),W$=n(Mi,"UL",{});var KWe=s(W$);m5=n(KWe,"LI",{});var NOe=s(m5);t5e=n(NOe,"STRONG",{});var WOt=s(t5e);TZr=r(WOt,"beit"),WOt.forEach(t),MZr=r(NOe," \u2014 "),Xoe=n(NOe,"A",{href:!0});var QOt=s(Xoe);EZr=r(QOt,"FlaxBeitForImageClassification"),QOt.forEach(t),CZr=r(NOe," (BEiT model)"),NOe.forEach(t),wZr=i(KWe),g5=n(KWe,"LI",{});var qOe=s(g5);a5e=n(qOe,"STRONG",{});var HOt=s(a5e);AZr=r(HOt,"vit"),HOt.forEach(t),LZr=r(qOe," \u2014 "),zoe=n(qOe,"A",{href:!0});var UOt=s(zoe);yZr=r(UOt,"FlaxViTForImageClassification"),UOt.forEach(t),xZr=r(qOe," (ViT model)"),qOe.forEach(t),KWe.forEach(t),$Zr=i(Mi),T(h5.$$.fragment,Mi),Mi.forEach(t),Ti.forEach(t),VXe=i(f),Af=n(f,"H2",{class:!0});var ZWe=s(Af);p5=n(ZWe,"A",{id:!0,class:!0,href:!0});var JOt=s(p5);n5e=n(JOt,"SPAN",{});var YOt=s(n5e);T(Q$.$$.fragment,YOt),YOt.forEach(t),JOt.forEach(t),kZr=i(ZWe),s5e=n(ZWe,"SPAN",{});var KOt=s(s5e);SZr=r(KOt,"FlaxAutoModelForVision2Seq"),KOt.forEach(t),ZWe.forEach(t),XXe=i(f),Ar=n(f,"DIV",{class:!0});var Ei=s(Ar);T(H$.$$.fragment,Ei),RZr=i(Ei),Lf=n(Ei,"P",{});var Ote=s(Lf);PZr=r(Ote,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Woe=n(Ote,"A",{href:!0});var ZOt=s(Woe);BZr=r(ZOt,"from_pretrained()"),ZOt.forEach(t),IZr=r(Ote," class method or the "),Qoe=n(Ote,"A",{href:!0});var eVt=s(Qoe);NZr=r(eVt,"from_config()"),eVt.forEach(t),qZr=r(Ote,` class
method.`),Ote.forEach(t),jZr=i(Ei),U$=n(Ei,"P",{});var eQe=s(U$);DZr=r(eQe,"This class cannot be instantiated directly using "),l5e=n(eQe,"CODE",{});var oVt=s(l5e);GZr=r(oVt,"__init__()"),oVt.forEach(t),OZr=r(eQe," (throws an error)."),eQe.forEach(t),VZr=i(Ei),ra=n(Ei,"DIV",{class:!0});var IA=s(ra);T(J$.$$.fragment,IA),XZr=i(IA),i5e=n(IA,"P",{});var rVt=s(i5e);zZr=r(rVt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),rVt.forEach(t),WZr=i(IA),yf=n(IA,"P",{});var Vte=s(yf);QZr=r(Vte,`Note:
Loading a model from its configuration file does `),d5e=n(Vte,"STRONG",{});var tVt=s(d5e);HZr=r(tVt,"not"),tVt.forEach(t),UZr=r(Vte,` load the model weights. It only affects the
model\u2019s configuration. Use `),Hoe=n(Vte,"A",{href:!0});var aVt=s(Hoe);JZr=r(aVt,"from_pretrained()"),aVt.forEach(t),YZr=r(Vte," to load the model weights."),Vte.forEach(t),KZr=i(IA),T(_5.$$.fragment,IA),IA.forEach(t),ZZr=i(Ei),et=n(Ei,"DIV",{class:!0});var Ci=s(et);T(Y$.$$.fragment,Ci),eet=i(Ci),c5e=n(Ci,"P",{});var nVt=s(c5e);oet=r(nVt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),nVt.forEach(t),ret=i(Ci),Sn=n(Ci,"P",{});var NA=s(Sn);tet=r(NA,"The model class to instantiate is selected based on the "),f5e=n(NA,"CODE",{});var sVt=s(f5e);aet=r(sVt,"model_type"),sVt.forEach(t),net=r(NA,` property of the config object (either
passed as an argument or loaded from `),m5e=n(NA,"CODE",{});var lVt=s(m5e);set=r(lVt,"pretrained_model_name_or_path"),lVt.forEach(t),iet=r(NA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g5e=n(NA,"CODE",{});var iVt=s(g5e);det=r(iVt,"pretrained_model_name_or_path"),iVt.forEach(t),cet=r(NA,":"),NA.forEach(t),fet=i(Ci),h5e=n(Ci,"UL",{});var dVt=s(h5e);u5=n(dVt,"LI",{});var jOe=s(u5);p5e=n(jOe,"STRONG",{});var cVt=s(p5e);met=r(cVt,"vision-encoder-decoder"),cVt.forEach(t),get=r(jOe," \u2014 "),Uoe=n(jOe,"A",{href:!0});var fVt=s(Uoe);het=r(fVt,"FlaxVisionEncoderDecoderModel"),fVt.forEach(t),pet=r(jOe," (Vision Encoder decoder model)"),jOe.forEach(t),dVt.forEach(t),_et=i(Ci),T(b5.$$.fragment,Ci),Ci.forEach(t),Ei.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(uzt)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(Pn,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.AutoConfig"),c(In,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.AutoModel"),c(Nn,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.AutoTokenizer"),c(ki,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertModel"),c(If,"id","extending-the-auto-classes"),c(If,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(If,"href","#extending-the-auto-classes"),c(Si,"class","relative group"),c(qf,"id","transformers.AutoConfig"),c(qf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qf,"href","#transformers.AutoConfig"),c(Ri,"class","relative group"),c(CS,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(wS,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertConfig"),c(AS,"href","/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartConfig"),c(LS,"href","/docs/transformers/pr_17806/en/model_doc/beit#transformers.BeitConfig"),c(yS,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertConfig"),c(xS,"href","/docs/transformers/pr_17806/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c($S,"href","/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdConfig"),c(kS,"href","/docs/transformers/pr_17806/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(SS,"href","/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(RS,"href","/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(PS,"href","/docs/transformers/pr_17806/en/model_doc/bloom#transformers.BloomConfig"),c(BS,"href","/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertConfig"),c(IS,"href","/docs/transformers/pr_17806/en/model_doc/canine#transformers.CanineConfig"),c(NS,"href","/docs/transformers/pr_17806/en/model_doc/clip#transformers.CLIPConfig"),c(qS,"href","/docs/transformers/pr_17806/en/model_doc/codegen#transformers.CodeGenConfig"),c(jS,"href","/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertConfig"),c(DS,"href","/docs/transformers/pr_17806/en/model_doc/convnext#transformers.ConvNextConfig"),c(GS,"href","/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.CTRLConfig"),c(OS,"href","/docs/transformers/pr_17806/en/model_doc/cvt#transformers.CvtConfig"),c(VS,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(XS,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(zS,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(WS,"href","/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaConfig"),c(QS,"href","/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(HS,"href","/docs/transformers/pr_17806/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(US,"href","/docs/transformers/pr_17806/en/model_doc/deit#transformers.DeiTConfig"),c(JS,"href","/docs/transformers/pr_17806/en/model_doc/detr#transformers.DetrConfig"),c(YS,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertConfig"),c(KS,"href","/docs/transformers/pr_17806/en/model_doc/dpr#transformers.DPRConfig"),c(ZS,"href","/docs/transformers/pr_17806/en/model_doc/dpt#transformers.DPTConfig"),c(eR,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraConfig"),c(oR,"href","/docs/transformers/pr_17806/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(rR,"href","/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertConfig"),c(tR,"href","/docs/transformers/pr_17806/en/model_doc/flava#transformers.FlavaConfig"),c(aR,"href","/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetConfig"),c(nR,"href","/docs/transformers/pr_17806/en/model_doc/fsmt#transformers.FSMTConfig"),c(sR,"href","/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelConfig"),c(lR,"href","/docs/transformers/pr_17806/en/model_doc/glpn#transformers.GLPNConfig"),c(iR,"href","/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2Config"),c(dR,"href","/docs/transformers/pr_17806/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(cR,"href","/docs/transformers/pr_17806/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(fR,"href","/docs/transformers/pr_17806/en/model_doc/gptj#transformers.GPTJConfig"),c(mR,"href","/docs/transformers/pr_17806/en/model_doc/groupvit#transformers.GroupViTConfig"),c(gR,"href","/docs/transformers/pr_17806/en/model_doc/hubert#transformers.HubertConfig"),c(hR,"href","/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertConfig"),c(pR,"href","/docs/transformers/pr_17806/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(_R,"href","/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(uR,"href","/docs/transformers/pr_17806/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(bR,"href","/docs/transformers/pr_17806/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(vR,"href","/docs/transformers/pr_17806/en/model_doc/led#transformers.LEDConfig"),c(FR,"href","/docs/transformers/pr_17806/en/model_doc/levit#transformers.LevitConfig"),c(TR,"href","/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerConfig"),c(MR,"href","/docs/transformers/pr_17806/en/model_doc/longt5#transformers.LongT5Config"),c(ER,"href","/docs/transformers/pr_17806/en/model_doc/luke#transformers.LukeConfig"),c(CR,"href","/docs/transformers/pr_17806/en/model_doc/lxmert#transformers.LxmertConfig"),c(wR,"href","/docs/transformers/pr_17806/en/model_doc/m2m_100#transformers.M2M100Config"),c(AR,"href","/docs/transformers/pr_17806/en/model_doc/marian#transformers.MarianConfig"),c(LR,"href","/docs/transformers/pr_17806/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(yR,"href","/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartConfig"),c(xR,"href","/docs/transformers/pr_17806/en/model_doc/mctct#transformers.MCTCTConfig"),c($R,"href","/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(kR,"href","/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(SR,"href","/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetConfig"),c(RR,"href","/docs/transformers/pr_17806/en/model_doc/mt5#transformers.MT5Config"),c(PR,"href","/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaConfig"),c(BR,"href","/docs/transformers/pr_17806/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(IR,"href","/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(NR,"href","/docs/transformers/pr_17806/en/model_doc/opt#transformers.OPTConfig"),c(qR,"href","/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.PegasusConfig"),c(jR,"href","/docs/transformers/pr_17806/en/model_doc/perceiver#transformers.PerceiverConfig"),c(DR,"href","/docs/transformers/pr_17806/en/model_doc/plbart#transformers.PLBartConfig"),c(GR,"href","/docs/transformers/pr_17806/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(OR,"href","/docs/transformers/pr_17806/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(VR,"href","/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(XR,"href","/docs/transformers/pr_17806/en/model_doc/rag#transformers.RagConfig"),c(zR,"href","/docs/transformers/pr_17806/en/model_doc/realm#transformers.RealmConfig"),c(WR,"href","/docs/transformers/pr_17806/en/model_doc/reformer#transformers.ReformerConfig"),c(QR,"href","/docs/transformers/pr_17806/en/model_doc/regnet#transformers.RegNetConfig"),c(HR,"href","/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertConfig"),c(UR,"href","/docs/transformers/pr_17806/en/model_doc/resnet#transformers.ResNetConfig"),c(JR,"href","/docs/transformers/pr_17806/en/model_doc/retribert#transformers.RetriBertConfig"),c(YR,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaConfig"),c(KR,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerConfig"),c(ZR,"href","/docs/transformers/pr_17806/en/model_doc/segformer#transformers.SegformerConfig"),c(eP,"href","/docs/transformers/pr_17806/en/model_doc/sew#transformers.SEWConfig"),c(oP,"href","/docs/transformers/pr_17806/en/model_doc/sew-d#transformers.SEWDConfig"),c(rP,"href","/docs/transformers/pr_17806/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(tP,"href","/docs/transformers/pr_17806/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(aP,"href","/docs/transformers/pr_17806/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(nP,"href","/docs/transformers/pr_17806/en/model_doc/splinter#transformers.SplinterConfig"),c(sP,"href","/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(lP,"href","/docs/transformers/pr_17806/en/model_doc/swin#transformers.SwinConfig"),c(iP,"href","/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5Config"),c(dP,"href","/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasConfig"),c(cP,"href","/docs/transformers/pr_17806/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(fP,"href","/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(mP,"href","/docs/transformers/pr_17806/en/model_doc/trocr#transformers.TrOCRConfig"),c(gP,"href","/docs/transformers/pr_17806/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(hP,"href","/docs/transformers/pr_17806/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(pP,"href","/docs/transformers/pr_17806/en/model_doc/van#transformers.VanConfig"),c(_P,"href","/docs/transformers/pr_17806/en/model_doc/vilt#transformers.ViltConfig"),c(uP,"href","/docs/transformers/pr_17806/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(bP,"href","/docs/transformers/pr_17806/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(vP,"href","/docs/transformers/pr_17806/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(FP,"href","/docs/transformers/pr_17806/en/model_doc/vit#transformers.ViTConfig"),c(TP,"href","/docs/transformers/pr_17806/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(MP,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(EP,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(CP,"href","/docs/transformers/pr_17806/en/model_doc/wavlm#transformers.WavLMConfig"),c(wP,"href","/docs/transformers/pr_17806/en/model_doc/xglm#transformers.XGLMConfig"),c(AP,"href","/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMConfig"),c(LP,"href","/docs/transformers/pr_17806/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(yP,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(xP,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c($P,"href","/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetConfig"),c(kP,"href","/docs/transformers/pr_17806/en/model_doc/yolos#transformers.YolosConfig"),c(SP,"href","/docs/transformers/pr_17806/en/model_doc/yoso#transformers.YosoConfig"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Hg,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ug,"id","transformers.AutoTokenizer"),c(Ug,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ug,"href","#transformers.AutoTokenizer"),c(Bi,"class","relative group"),c(RP,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(PP,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertTokenizer"),c(BP,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(IP,"href","/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartTokenizer"),c(NP,"href","/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartTokenizerFast"),c(qP,"href","/docs/transformers/pr_17806/en/model_doc/barthez#transformers.BarthezTokenizer"),c(jP,"href","/docs/transformers/pr_17806/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(DP,"href","/docs/transformers/pr_17806/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(GP,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertTokenizer"),c(OP,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertTokenizerFast"),c(VP,"href","/docs/transformers/pr_17806/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(XP,"href","/docs/transformers/pr_17806/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(zP,"href","/docs/transformers/pr_17806/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(WP,"href","/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(QP,"href","/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(HP,"href","/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(UP,"href","/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(JP,"href","/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(YP,"href","/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(KP,"href","/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(ZP,"href","/docs/transformers/pr_17806/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(eB,"href","/docs/transformers/pr_17806/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(oB,"href","/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertTokenizer"),c(rB,"href","/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(tB,"href","/docs/transformers/pr_17806/en/model_doc/canine#transformers.CanineTokenizer"),c(aB,"href","/docs/transformers/pr_17806/en/model_doc/clip#transformers.CLIPTokenizer"),c(nB,"href","/docs/transformers/pr_17806/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(sB,"href","/docs/transformers/pr_17806/en/model_doc/codegen#transformers.CodeGenTokenizer"),c(lB,"href","/docs/transformers/pr_17806/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),c(iB,"href","/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(dB,"href","/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(cB,"href","/docs/transformers/pr_17806/en/model_doc/cpm#transformers.CpmTokenizer"),c(fB,"href","/docs/transformers/pr_17806/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(mB,"href","/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(gB,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaTokenizer"),c(hB,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(pB,"href","/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaTokenizer"),c(_B,"href","/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(uB,"href","/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(bB,"href","/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(vB,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(FB,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(TB,"href","/docs/transformers/pr_17806/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(MB,"href","/docs/transformers/pr_17806/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(EB,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraTokenizer"),c(CB,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(wB,"href","/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(AB,"href","/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetTokenizer"),c(LB,"href","/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(yB,"href","/docs/transformers/pr_17806/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(xB,"href","/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelTokenizer"),c($B,"href","/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(kB,"href","/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(SB,"href","/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(RB,"href","/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(PB,"href","/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(BB,"href","/docs/transformers/pr_17806/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(IB,"href","/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(NB,"href","/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(qB,"href","/docs/transformers/pr_17806/en/model_doc/clip#transformers.CLIPTokenizer"),c(jB,"href","/docs/transformers/pr_17806/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(DB,"href","/docs/transformers/pr_17806/en/model_doc/herbert#transformers.HerbertTokenizer"),c(GB,"href","/docs/transformers/pr_17806/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(OB,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(VB,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaTokenizer"),c(XB,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(zB,"href","/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(WB,"href","/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(QB,"href","/docs/transformers/pr_17806/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(HB,"href","/docs/transformers/pr_17806/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(UB,"href","/docs/transformers/pr_17806/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(JB,"href","/docs/transformers/pr_17806/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(YB,"href","/docs/transformers/pr_17806/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(KB,"href","/docs/transformers/pr_17806/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(ZB,"href","/docs/transformers/pr_17806/en/model_doc/led#transformers.LEDTokenizer"),c(eI,"href","/docs/transformers/pr_17806/en/model_doc/led#transformers.LEDTokenizerFast"),c(oI,"href","/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerTokenizer"),c(rI,"href","/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(tI,"href","/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5Tokenizer"),c(aI,"href","/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5TokenizerFast"),c(nI,"href","/docs/transformers/pr_17806/en/model_doc/luke#transformers.LukeTokenizer"),c(sI,"href","/docs/transformers/pr_17806/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(lI,"href","/docs/transformers/pr_17806/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(iI,"href","/docs/transformers/pr_17806/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(dI,"href","/docs/transformers/pr_17806/en/model_doc/marian#transformers.MarianTokenizer"),c(cI,"href","/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartTokenizer"),c(fI,"href","/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(mI,"href","/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(gI,"href","/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(hI,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertTokenizer"),c(pI,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertTokenizerFast"),c(_I,"href","/docs/transformers/pr_17806/en/model_doc/mluke#transformers.MLukeTokenizer"),c(uI,"href","/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(bI,"href","/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(vI,"href","/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(FI,"href","/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(TI,"href","/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5Tokenizer"),c(MI,"href","/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5TokenizerFast"),c(EI,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertTokenizer"),c(CI,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertTokenizerFast"),c(wI,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertTokenizer"),c(AI,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(LI,"href","/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(yI,"href","/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(xI,"href","/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c($I,"href","/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(kI,"href","/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(SI,"href","/docs/transformers/pr_17806/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(RI,"href","/docs/transformers/pr_17806/en/model_doc/phobert#transformers.PhobertTokenizer"),c(PI,"href","/docs/transformers/pr_17806/en/model_doc/plbart#transformers.PLBartTokenizer"),c(BI,"href","/docs/transformers/pr_17806/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(II,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertTokenizer"),c(NI,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertTokenizerFast"),c(qI,"href","/docs/transformers/pr_17806/en/model_doc/rag#transformers.RagTokenizer"),c(jI,"href","/docs/transformers/pr_17806/en/model_doc/realm#transformers.RealmTokenizer"),c(DI,"href","/docs/transformers/pr_17806/en/model_doc/realm#transformers.RealmTokenizerFast"),c(GI,"href","/docs/transformers/pr_17806/en/model_doc/reformer#transformers.ReformerTokenizer"),c(OI,"href","/docs/transformers/pr_17806/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(VI,"href","/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertTokenizer"),c(XI,"href","/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(zI,"href","/docs/transformers/pr_17806/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(WI,"href","/docs/transformers/pr_17806/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(QI,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaTokenizer"),c(HI,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(UI,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(JI,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(YI,"href","/docs/transformers/pr_17806/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(KI,"href","/docs/transformers/pr_17806/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(ZI,"href","/docs/transformers/pr_17806/en/model_doc/splinter#transformers.SplinterTokenizer"),c(eN,"href","/docs/transformers/pr_17806/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(oN,"href","/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(rN,"href","/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(tN,"href","/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5Tokenizer"),c(aN,"href","/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5TokenizerFast"),c(nN,"href","/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasTokenizer"),c(sN,"href","/docs/transformers/pr_17806/en/model_doc/tapex#transformers.TapexTokenizer"),c(lN,"href","/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(iN,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertTokenizer"),c(dN,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertTokenizerFast"),c(cN,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertTokenizer"),c(fN,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertTokenizerFast"),c(mN,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(gN,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(hN,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(pN,"href","/docs/transformers/pr_17806/en/model_doc/xglm#transformers.XGLMTokenizer"),c(_N,"href","/docs/transformers/pr_17806/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(uN,"href","/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMTokenizer"),c(bN,"href","/docs/transformers/pr_17806/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(vN,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(FN,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(TN,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaTokenizer"),c(MN,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(EN,"href","/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(CN,"href","/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(wN,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertTokenizer"),c(AN,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($h,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kh,"id","transformers.AutoFeatureExtractor"),c(kh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kh,"href","#transformers.AutoFeatureExtractor"),c(Ii,"class","relative group"),c(LN,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(yN,"href","/docs/transformers/pr_17806/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(xN,"href","/docs/transformers/pr_17806/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c($N,"href","/docs/transformers/pr_17806/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(kN,"href","/docs/transformers/pr_17806/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(SN,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(RN,"href","/docs/transformers/pr_17806/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(PN,"href","/docs/transformers/pr_17806/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(BN,"href","/docs/transformers/pr_17806/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(IN,"href","/docs/transformers/pr_17806/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(NN,"href","/docs/transformers/pr_17806/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(qN,"href","/docs/transformers/pr_17806/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(jN,"href","/docs/transformers/pr_17806/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(DN,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(GN,"href","/docs/transformers/pr_17806/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(ON,"href","/docs/transformers/pr_17806/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(VN,"href","/docs/transformers/pr_17806/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(XN,"href","/docs/transformers/pr_17806/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(zN,"href","/docs/transformers/pr_17806/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(WN,"href","/docs/transformers/pr_17806/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(QN,"href","/docs/transformers/pr_17806/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(HN,"href","/docs/transformers/pr_17806/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(UN,"href","/docs/transformers/pr_17806/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(JN,"href","/docs/transformers/pr_17806/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(YN,"href","/docs/transformers/pr_17806/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(KN,"href","/docs/transformers/pr_17806/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(ZN,"href","/docs/transformers/pr_17806/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(eq,"href","/docs/transformers/pr_17806/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(oq,"href","/docs/transformers/pr_17806/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(rq,"href","/docs/transformers/pr_17806/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(tq,"href","/docs/transformers/pr_17806/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(aq,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(nq,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(sq,"href","/docs/transformers/pr_17806/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hp,"id","transformers.AutoProcessor"),c(hp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hp,"href","#transformers.AutoProcessor"),c(Ni,"class","relative group"),c(lq,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(iq,"href","/docs/transformers/pr_17806/en/model_doc/clip#transformers.CLIPProcessor"),c(dq,"href","/docs/transformers/pr_17806/en/model_doc/clip#transformers.CLIPProcessor"),c(cq,"href","/docs/transformers/pr_17806/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(fq,"href","/docs/transformers/pr_17806/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(mq,"href","/docs/transformers/pr_17806/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(gq,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(hq,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(pq,"href","/docs/transformers/pr_17806/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(_q,"href","/docs/transformers/pr_17806/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(uq,"href","/docs/transformers/pr_17806/en/model_doc/trocr#transformers.TrOCRProcessor"),c(bq,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(vq,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Fq,"href","/docs/transformers/pr_17806/en/model_doc/vilt#transformers.ViltProcessor"),c(Tq,"href","/docs/transformers/pr_17806/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(Mq,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Eq,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Cq,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ip,"id","transformers.AutoModel"),c(Ip,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ip,"href","#transformers.AutoModel"),c(ji,"class","relative group"),c(wq,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Aq,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Lq,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yq,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertModel"),c(xq,"href","/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartModel"),c($q,"href","/docs/transformers/pr_17806/en/model_doc/beit#transformers.BeitModel"),c(kq,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertModel"),c(Sq,"href","/docs/transformers/pr_17806/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(Rq,"href","/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdModel"),c(Pq,"href","/docs/transformers/pr_17806/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(Bq,"href","/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(Iq,"href","/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(Nq,"href","/docs/transformers/pr_17806/en/model_doc/bloom#transformers.BloomModel"),c(qq,"href","/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertModel"),c(jq,"href","/docs/transformers/pr_17806/en/model_doc/canine#transformers.CanineModel"),c(Dq,"href","/docs/transformers/pr_17806/en/model_doc/clip#transformers.CLIPModel"),c(Gq,"href","/docs/transformers/pr_17806/en/model_doc/codegen#transformers.CodeGenModel"),c(Oq,"href","/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertModel"),c(Vq,"href","/docs/transformers/pr_17806/en/model_doc/convnext#transformers.ConvNextModel"),c(Xq,"href","/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.CTRLModel"),c(zq,"href","/docs/transformers/pr_17806/en/model_doc/cvt#transformers.CvtModel"),c(Wq,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(Qq,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(Hq,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(Uq,"href","/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaModel"),c(Jq,"href","/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(Yq,"href","/docs/transformers/pr_17806/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(Kq,"href","/docs/transformers/pr_17806/en/model_doc/deit#transformers.DeiTModel"),c(Zq,"href","/docs/transformers/pr_17806/en/model_doc/detr#transformers.DetrModel"),c(ej,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertModel"),c(oj,"href","/docs/transformers/pr_17806/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(rj,"href","/docs/transformers/pr_17806/en/model_doc/dpt#transformers.DPTModel"),c(tj,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraModel"),c(aj,"href","/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertModel"),c(nj,"href","/docs/transformers/pr_17806/en/model_doc/flava#transformers.FlavaModel"),c(sj,"href","/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetModel"),c(lj,"href","/docs/transformers/pr_17806/en/model_doc/fsmt#transformers.FSMTModel"),c(ij,"href","/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelModel"),c(dj,"href","/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelBaseModel"),c(cj,"href","/docs/transformers/pr_17806/en/model_doc/glpn#transformers.GLPNModel"),c(fj,"href","/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2Model"),c(mj,"href","/docs/transformers/pr_17806/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(gj,"href","/docs/transformers/pr_17806/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(hj,"href","/docs/transformers/pr_17806/en/model_doc/gptj#transformers.GPTJModel"),c(pj,"href","/docs/transformers/pr_17806/en/model_doc/groupvit#transformers.GroupViTModel"),c(_j,"href","/docs/transformers/pr_17806/en/model_doc/hubert#transformers.HubertModel"),c(uj,"href","/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertModel"),c(bj,"href","/docs/transformers/pr_17806/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(vj,"href","/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(Fj,"href","/docs/transformers/pr_17806/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(Tj,"href","/docs/transformers/pr_17806/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(Mj,"href","/docs/transformers/pr_17806/en/model_doc/led#transformers.LEDModel"),c(Ej,"href","/docs/transformers/pr_17806/en/model_doc/levit#transformers.LevitModel"),c(Cj,"href","/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerModel"),c(wj,"href","/docs/transformers/pr_17806/en/model_doc/longt5#transformers.LongT5Model"),c(Aj,"href","/docs/transformers/pr_17806/en/model_doc/luke#transformers.LukeModel"),c(Lj,"href","/docs/transformers/pr_17806/en/model_doc/lxmert#transformers.LxmertModel"),c(yj,"href","/docs/transformers/pr_17806/en/model_doc/m2m_100#transformers.M2M100Model"),c(xj,"href","/docs/transformers/pr_17806/en/model_doc/marian#transformers.MarianModel"),c($j,"href","/docs/transformers/pr_17806/en/model_doc/maskformer#transformers.MaskFormerModel"),c(kj,"href","/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartModel"),c(Sj,"href","/docs/transformers/pr_17806/en/model_doc/mctct#transformers.MCTCTModel"),c(Rj,"href","/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(Pj,"href","/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertModel"),c(Bj,"href","/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetModel"),c(Ij,"href","/docs/transformers/pr_17806/en/model_doc/mt5#transformers.MT5Model"),c(Nj,"href","/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaModel"),c(qj,"href","/docs/transformers/pr_17806/en/model_doc/nystromformer#transformers.NystromformerModel"),c(jj,"href","/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(Dj,"href","/docs/transformers/pr_17806/en/model_doc/opt#transformers.OPTModel"),c(Gj,"href","/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.PegasusModel"),c(Oj,"href","/docs/transformers/pr_17806/en/model_doc/perceiver#transformers.PerceiverModel"),c(Vj,"href","/docs/transformers/pr_17806/en/model_doc/plbart#transformers.PLBartModel"),c(Xj,"href","/docs/transformers/pr_17806/en/model_doc/poolformer#transformers.PoolFormerModel"),c(zj,"href","/docs/transformers/pr_17806/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(Wj,"href","/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertModel"),c(Qj,"href","/docs/transformers/pr_17806/en/model_doc/reformer#transformers.ReformerModel"),c(Hj,"href","/docs/transformers/pr_17806/en/model_doc/regnet#transformers.RegNetModel"),c(Uj,"href","/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertModel"),c(Jj,"href","/docs/transformers/pr_17806/en/model_doc/resnet#transformers.ResNetModel"),c(Yj,"href","/docs/transformers/pr_17806/en/model_doc/retribert#transformers.RetriBertModel"),c(Kj,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaModel"),c(Zj,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerModel"),c(eD,"href","/docs/transformers/pr_17806/en/model_doc/segformer#transformers.SegformerModel"),c(oD,"href","/docs/transformers/pr_17806/en/model_doc/sew#transformers.SEWModel"),c(rD,"href","/docs/transformers/pr_17806/en/model_doc/sew-d#transformers.SEWDModel"),c(tD,"href","/docs/transformers/pr_17806/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(aD,"href","/docs/transformers/pr_17806/en/model_doc/splinter#transformers.SplinterModel"),c(nD,"href","/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(sD,"href","/docs/transformers/pr_17806/en/model_doc/swin#transformers.SwinModel"),c(lD,"href","/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5Model"),c(iD,"href","/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasModel"),c(dD,"href","/docs/transformers/pr_17806/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(cD,"href","/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(fD,"href","/docs/transformers/pr_17806/en/model_doc/unispeech#transformers.UniSpeechModel"),c(mD,"href","/docs/transformers/pr_17806/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(gD,"href","/docs/transformers/pr_17806/en/model_doc/van#transformers.VanModel"),c(hD,"href","/docs/transformers/pr_17806/en/model_doc/vilt#transformers.ViltModel"),c(pD,"href","/docs/transformers/pr_17806/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(_D,"href","/docs/transformers/pr_17806/en/model_doc/visual_bert#transformers.VisualBertModel"),c(uD,"href","/docs/transformers/pr_17806/en/model_doc/vit#transformers.ViTModel"),c(bD,"href","/docs/transformers/pr_17806/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(vD,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(FD,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(TD,"href","/docs/transformers/pr_17806/en/model_doc/wavlm#transformers.WavLMModel"),c(MD,"href","/docs/transformers/pr_17806/en/model_doc/xglm#transformers.XGLMModel"),c(ED,"href","/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMModel"),c(CD,"href","/docs/transformers/pr_17806/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(wD,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(AD,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(LD,"href","/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetModel"),c(yD,"href","/docs/transformers/pr_17806/en/model_doc/yolos#transformers.YolosModel"),c(xD,"href","/docs/transformers/pr_17806/en/model_doc/yoso#transformers.YosoModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Du,"id","transformers.AutoModelForPreTraining"),c(Du,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Du,"href","#transformers.AutoModelForPreTraining"),c(Oi,"class","relative group"),c($D,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kD,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SD,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RD,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertForPreTraining"),c(PD,"href","/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(BD,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertForPreTraining"),c(ID,"href","/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(ND,"href","/docs/transformers/pr_17806/en/model_doc/bloom#transformers.BloomForCausalLM"),c(qD,"href","/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(jD,"href","/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(DD,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(GD,"href","/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(OD,"href","/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(VD,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(XD,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraForPreTraining"),c(zD,"href","/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(WD,"href","/docs/transformers/pr_17806/en/model_doc/flava#transformers.FlavaForPreTraining"),c(QD,"href","/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetForPreTraining"),c(HD,"href","/docs/transformers/pr_17806/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(UD,"href","/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(JD,"href","/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(YD,"href","/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(KD,"href","/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(ZD,"href","/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(eG,"href","/docs/transformers/pr_17806/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(oG,"href","/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(rG,"href","/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(tG,"href","/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(aG,"href","/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(nG,"href","/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(sG,"href","/docs/transformers/pr_17806/en/model_doc/retribert#transformers.RetriBertModel"),c(lG,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(iG,"href","/docs/transformers/pr_17806/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(dG,"href","/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(cG,"href","/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(fG,"href","/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(mG,"href","/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(gG,"href","/docs/transformers/pr_17806/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(hG,"href","/docs/transformers/pr_17806/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(pG,"href","/docs/transformers/pr_17806/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(_G,"href","/docs/transformers/pr_17806/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(uG,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(bG,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(vG,"href","/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(FG,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(TG,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(MG,"href","/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(P1,"id","transformers.AutoModelForCausalLM"),c(P1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(P1,"href","#transformers.AutoModelForCausalLM"),c(zi,"class","relative group"),c(EG,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CG,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wG,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AG,"href","/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartForCausalLM"),c(LG,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertLMHeadModel"),c(yG,"href","/docs/transformers/pr_17806/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(xG,"href","/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c($G,"href","/docs/transformers/pr_17806/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(kG,"href","/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(SG,"href","/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(RG,"href","/docs/transformers/pr_17806/en/model_doc/bloom#transformers.BloomForCausalLM"),c(PG,"href","/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(BG,"href","/docs/transformers/pr_17806/en/model_doc/codegen#transformers.CodeGenForCausalLM"),c(IG,"href","/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(NG,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(qG,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraForCausalLM"),c(jG,"href","/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(DG,"href","/docs/transformers/pr_17806/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(GG,"href","/docs/transformers/pr_17806/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(OG,"href","/docs/transformers/pr_17806/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(VG,"href","/docs/transformers/pr_17806/en/model_doc/marian#transformers.MarianForCausalLM"),c(XG,"href","/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartForCausalLM"),c(zG,"href","/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(WG,"href","/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(QG,"href","/docs/transformers/pr_17806/en/model_doc/opt#transformers.OPTForCausalLM"),c(HG,"href","/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(UG,"href","/docs/transformers/pr_17806/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(JG,"href","/docs/transformers/pr_17806/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(YG,"href","/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(KG,"href","/docs/transformers/pr_17806/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(ZG,"href","/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(eO,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(oO,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(rO,"href","/docs/transformers/pr_17806/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(tO,"href","/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(aO,"href","/docs/transformers/pr_17806/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(nO,"href","/docs/transformers/pr_17806/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(sO,"href","/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(lO,"href","/docs/transformers/pr_17806/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(iO,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(dO,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(cO,"href","/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(E2,"id","transformers.AutoModelForMaskedLM"),c(E2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(E2,"href","#transformers.AutoModelForMaskedLM"),c(Hi,"class","relative group"),c(fO,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mO,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gO,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hO,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(pO,"href","/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(_O,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertForMaskedLM"),c(uO,"href","/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(bO,"href","/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(vO,"href","/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(FO,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(TO,"href","/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(MO,"href","/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(EO,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(CO,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(wO,"href","/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(AO,"href","/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(LO,"href","/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(yO,"href","/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(xO,"href","/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c($O,"href","/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(kO,"href","/docs/transformers/pr_17806/en/model_doc/luke#transformers.LukeForMaskedLM"),c(SO,"href","/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(RO,"href","/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(PO,"href","/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(BO,"href","/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(IO,"href","/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(NO,"href","/docs/transformers/pr_17806/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(qO,"href","/docs/transformers/pr_17806/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(jO,"href","/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(DO,"href","/docs/transformers/pr_17806/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(GO,"href","/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(OO,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(VO,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(XO,"href","/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(zO,"href","/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(WO,"href","/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(QO,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(HO,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(UO,"href","/docs/transformers/pr_17806/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cb,"id","transformers.AutoModelForSeq2SeqLM"),c(cb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cb,"href","#transformers.AutoModelForSeq2SeqLM"),c(Yi,"class","relative group"),c(JO,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(YO,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(KO,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZO,"href","/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(eV,"href","/docs/transformers/pr_17806/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(oV,"href","/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(rV,"href","/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(tV,"href","/docs/transformers/pr_17806/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(aV,"href","/docs/transformers/pr_17806/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(nV,"href","/docs/transformers/pr_17806/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(sV,"href","/docs/transformers/pr_17806/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(lV,"href","/docs/transformers/pr_17806/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(iV,"href","/docs/transformers/pr_17806/en/model_doc/marian#transformers.MarianMTModel"),c(dV,"href","/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(cV,"href","/docs/transformers/pr_17806/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(fV,"href","/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(mV,"href","/docs/transformers/pr_17806/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(gV,"href","/docs/transformers/pr_17806/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(hV,"href","/docs/transformers/pr_17806/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(pV,"href","/docs/transformers/pr_17806/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kb,"id","transformers.AutoModelForSequenceClassification"),c(kb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kb,"href","#transformers.AutoModelForSequenceClassification"),c(ed,"class","relative group"),c(_V,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uV,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bV,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vV,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(FV,"href","/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartForSequenceClassification"),c(TV,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertForSequenceClassification"),c(MV,"href","/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(EV,"href","/docs/transformers/pr_17806/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(CV,"href","/docs/transformers/pr_17806/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(wV,"href","/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(AV,"href","/docs/transformers/pr_17806/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(LV,"href","/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(yV,"href","/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(xV,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c($V,"href","/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(kV,"href","/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(SV,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(RV,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(PV,"href","/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(BV,"href","/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(IV,"href","/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(NV,"href","/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(qV,"href","/docs/transformers/pr_17806/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(jV,"href","/docs/transformers/pr_17806/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(DV,"href","/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(GV,"href","/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(OV,"href","/docs/transformers/pr_17806/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(VV,"href","/docs/transformers/pr_17806/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(XV,"href","/docs/transformers/pr_17806/en/model_doc/led#transformers.LEDForSequenceClassification"),c(zV,"href","/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(WV,"href","/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(QV,"href","/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(HV,"href","/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(UV,"href","/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(JV,"href","/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(YV,"href","/docs/transformers/pr_17806/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(KV,"href","/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(ZV,"href","/docs/transformers/pr_17806/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(eX,"href","/docs/transformers/pr_17806/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(oX,"href","/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(rX,"href","/docs/transformers/pr_17806/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(tX,"href","/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(aX,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(nX,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(sX,"href","/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(lX,"href","/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(iX,"href","/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(dX,"href","/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(cX,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(fX,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(mX,"href","/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(gX,"href","/docs/transformers/pr_17806/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($v,"id","transformers.AutoModelForMultipleChoice"),c($v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($v,"href","#transformers.AutoModelForMultipleChoice"),c(td,"class","relative group"),c(hX,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pX,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_X,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uX,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(bX,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertForMultipleChoice"),c(vX,"href","/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(FX,"href","/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(TX,"href","/docs/transformers/pr_17806/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(MX,"href","/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(EX,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(CX,"href","/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(wX,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(AX,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(LX,"href","/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(yX,"href","/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(xX,"href","/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c($X,"href","/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(kX,"href","/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(SX,"href","/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(RX,"href","/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(PX,"href","/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(BX,"href","/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c(IX,"href","/docs/transformers/pr_17806/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(NX,"href","/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(qX,"href","/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(jX,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(DX,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(GX,"href","/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(OX,"href","/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(VX,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(XX,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(zX,"href","/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(WX,"href","/docs/transformers/pr_17806/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(c0,"id","transformers.AutoModelForNextSentencePrediction"),c(c0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(c0,"href","#transformers.AutoModelForNextSentencePrediction"),c(sd,"class","relative group"),c(QX,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(HX,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(UX,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JX,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(YX,"href","/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(KX,"href","/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(ZX,"href","/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(ez,"href","/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(oz,"href","/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(F0,"id","transformers.AutoModelForTokenClassification"),c(F0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(F0,"href","#transformers.AutoModelForTokenClassification"),c(dd,"class","relative group"),c(rz,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tz,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(az,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nz,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(sz,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertForTokenClassification"),c(lz,"href","/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(iz,"href","/docs/transformers/pr_17806/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(dz,"href","/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(cz,"href","/docs/transformers/pr_17806/en/model_doc/canine#transformers.CanineForTokenClassification"),c(fz,"href","/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(mz,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(gz,"href","/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(hz,"href","/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(pz,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(_z,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(uz,"href","/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(bz,"href","/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(vz,"href","/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(Fz,"href","/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(Tz,"href","/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(Mz,"href","/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(Ez,"href","/docs/transformers/pr_17806/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(Cz,"href","/docs/transformers/pr_17806/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(wz,"href","/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(Az,"href","/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(Lz,"href","/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(yz,"href","/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(xz,"href","/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c($z,"href","/docs/transformers/pr_17806/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(kz,"href","/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(Sz,"href","/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(Rz,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(Pz,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(Bz,"href","/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(Iz,"href","/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(Nz,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(qz,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(jz,"href","/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(Dz,"href","/docs/transformers/pr_17806/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sF,"id","transformers.AutoModelForQuestionAnswering"),c(sF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sF,"href","#transformers.AutoModelForQuestionAnswering"),c(md,"class","relative group"),c(Gz,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Oz,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Vz,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xz,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(zz,"href","/docs/transformers/pr_17806/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(Wz,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(Qz,"href","/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(Hz,"href","/docs/transformers/pr_17806/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(Uz,"href","/docs/transformers/pr_17806/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(Jz,"href","/docs/transformers/pr_17806/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(Yz,"href","/docs/transformers/pr_17806/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(Kz,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(Zz,"href","/docs/transformers/pr_17806/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(eW,"href","/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(oW,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(rW,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(tW,"href","/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(aW,"href","/docs/transformers/pr_17806/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(nW,"href","/docs/transformers/pr_17806/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(sW,"href","/docs/transformers/pr_17806/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(lW,"href","/docs/transformers/pr_17806/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(iW,"href","/docs/transformers/pr_17806/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(dW,"href","/docs/transformers/pr_17806/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(cW,"href","/docs/transformers/pr_17806/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(fW,"href","/docs/transformers/pr_17806/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(mW,"href","/docs/transformers/pr_17806/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(gW,"href","/docs/transformers/pr_17806/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(hW,"href","/docs/transformers/pr_17806/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(pW,"href","/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(_W,"href","/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(uW,"href","/docs/transformers/pr_17806/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(bW,"href","/docs/transformers/pr_17806/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(vW,"href","/docs/transformers/pr_17806/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(FW,"href","/docs/transformers/pr_17806/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(TW,"href","/docs/transformers/pr_17806/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(MW,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(EW,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(CW,"href","/docs/transformers/pr_17806/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(wW,"href","/docs/transformers/pr_17806/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(AW,"href","/docs/transformers/pr_17806/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(LW,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(yW,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(xW,"href","/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c($W,"href","/docs/transformers/pr_17806/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YF,"id","transformers.AutoModelForTableQuestionAnswering"),c(YF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(YF,"href","#transformers.AutoModelForTableQuestionAnswering"),c(pd,"class","relative group"),c(kW,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(SW,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(RW,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PW,"href","/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(r6,"id","transformers.AutoModelForImageClassification"),c(r6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(r6,"href","#transformers.AutoModelForImageClassification"),c(bd,"class","relative group"),c(BW,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(IW,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(NW,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qW,"href","/docs/transformers/pr_17806/en/model_doc/beit#transformers.BeitForImageClassification"),c(jW,"href","/docs/transformers/pr_17806/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(DW,"href","/docs/transformers/pr_17806/en/model_doc/cvt#transformers.CvtForImageClassification"),c(GW,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(OW,"href","/docs/transformers/pr_17806/en/model_doc/deit#transformers.DeiTForImageClassification"),c(VW,"href","/docs/transformers/pr_17806/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(XW,"href","/docs/transformers/pr_17806/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(zW,"href","/docs/transformers/pr_17806/en/model_doc/levit#transformers.LevitForImageClassification"),c(WW,"href","/docs/transformers/pr_17806/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(QW,"href","/docs/transformers/pr_17806/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(HW,"href","/docs/transformers/pr_17806/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(UW,"href","/docs/transformers/pr_17806/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(JW,"href","/docs/transformers/pr_17806/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(YW,"href","/docs/transformers/pr_17806/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(KW,"href","/docs/transformers/pr_17806/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(ZW,"href","/docs/transformers/pr_17806/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(eQ,"href","/docs/transformers/pr_17806/en/model_doc/swin#transformers.SwinForImageClassification"),c(oQ,"href","/docs/transformers/pr_17806/en/model_doc/van#transformers.VanForImageClassification"),c(rQ,"href","/docs/transformers/pr_17806/en/model_doc/vit#transformers.ViTForImageClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(b6,"id","transformers.AutoModelForVision2Seq"),c(b6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(b6,"href","#transformers.AutoModelForVision2Seq"),c(Td,"class","relative group"),c(tQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sQ,"href","/docs/transformers/pr_17806/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(E6,"id","transformers.AutoModelForVisualQuestionAnswering"),c(E6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(E6,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(Cd,"class","relative group"),c(lQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cQ,"href","/docs/transformers/pr_17806/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(y6,"id","transformers.AutoModelForAudioClassification"),c(y6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(y6,"href","#transformers.AutoModelForAudioClassification"),c(Ld,"class","relative group"),c(fQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hQ,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(pQ,"href","/docs/transformers/pr_17806/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(_Q,"href","/docs/transformers/pr_17806/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(uQ,"href","/docs/transformers/pr_17806/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(bQ,"href","/docs/transformers/pr_17806/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(vQ,"href","/docs/transformers/pr_17806/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(FQ,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(TQ,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(MQ,"href","/docs/transformers/pr_17806/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(G6,"id","transformers.AutoModelForAudioFrameClassification"),c(G6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(G6,"href","#transformers.AutoModelForAudioFrameClassification"),c($d,"class","relative group"),c(EQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AQ,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(LQ,"href","/docs/transformers/pr_17806/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(yQ,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(xQ,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c($Q,"href","/docs/transformers/pr_17806/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(J6,"id","transformers.AutoModelForCTC"),c(J6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(J6,"href","#transformers.AutoModelForCTC"),c(Rd,"class","relative group"),c(kQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(SQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(RQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PQ,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(BQ,"href","/docs/transformers/pr_17806/en/model_doc/hubert#transformers.HubertForCTC"),c(IQ,"href","/docs/transformers/pr_17806/en/model_doc/mctct#transformers.MCTCTForCTC"),c(NQ,"href","/docs/transformers/pr_17806/en/model_doc/sew#transformers.SEWForCTC"),c(qQ,"href","/docs/transformers/pr_17806/en/model_doc/sew-d#transformers.SEWDForCTC"),c(jQ,"href","/docs/transformers/pr_17806/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(DQ,"href","/docs/transformers/pr_17806/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(GQ,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(OQ,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(VQ,"href","/docs/transformers/pr_17806/en/model_doc/wavlm#transformers.WavLMForCTC"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cT,"id","transformers.AutoModelForSpeechSeq2Seq"),c(cT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cT,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Id,"class","relative group"),c(XQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QQ,"href","/docs/transformers/pr_17806/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(HQ,"href","/docs/transformers/pr_17806/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_T,"id","transformers.AutoModelForAudioXVector"),c(_T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_T,"href","#transformers.AutoModelForAudioXVector"),c(jd,"class","relative group"),c(UQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YQ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KQ,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(ZQ,"href","/docs/transformers/pr_17806/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(eH,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(oH,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(rH,"href","/docs/transformers/pr_17806/en/model_doc/wavlm#transformers.WavLMForXVector"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wT,"id","transformers.AutoModelForMaskedImageModeling"),c(wT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(wT,"href","#transformers.AutoModelForMaskedImageModeling"),c(Od,"class","relative group"),c(tH,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aH,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nH,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sH,"href","/docs/transformers/pr_17806/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(lH,"href","/docs/transformers/pr_17806/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(iH,"href","/docs/transformers/pr_17806/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ST,"id","transformers.AutoModelForObjectDetection"),c(ST,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ST,"href","#transformers.AutoModelForObjectDetection"),c(Wd,"class","relative group"),c(dH,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(cH,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(fH,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mH,"href","/docs/transformers/pr_17806/en/model_doc/detr#transformers.DetrForObjectDetection"),c(gH,"href","/docs/transformers/pr_17806/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qT,"id","transformers.AutoModelForImageSegmentation"),c(qT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qT,"href","#transformers.AutoModelForImageSegmentation"),c(Ud,"class","relative group"),c(hH,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pH,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_H,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uH,"href","/docs/transformers/pr_17806/en/model_doc/detr#transformers.DetrForSegmentation"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VT,"id","transformers.AutoModelForSemanticSegmentation"),c(VT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(VT,"href","#transformers.AutoModelForSemanticSegmentation"),c(Kd,"class","relative group"),c(bH,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vH,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(FH,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TH,"href","/docs/transformers/pr_17806/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(MH,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(EH,"href","/docs/transformers/pr_17806/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(CH,"href","/docs/transformers/pr_17806/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YT,"id","transformers.AutoModelForInstanceSegmentation"),c(YT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(YT,"href","#transformers.AutoModelForInstanceSegmentation"),c(oc,"class","relative group"),c(wH,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AH,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LH,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yH,"href","/docs/transformers/pr_17806/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(r7,"id","transformers.TFAutoModel"),c(r7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(r7,"href","#transformers.TFAutoModel"),c(ac,"class","relative group"),c(xH,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($H,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kH,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SH,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.TFAlbertModel"),c(RH,"href","/docs/transformers/pr_17806/en/model_doc/bart#transformers.TFBartModel"),c(PH,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.TFBertModel"),c(BH,"href","/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(IH,"href","/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(NH,"href","/docs/transformers/pr_17806/en/model_doc/camembert#transformers.TFCamembertModel"),c(qH,"href","/docs/transformers/pr_17806/en/model_doc/clip#transformers.TFCLIPModel"),c(jH,"href","/docs/transformers/pr_17806/en/model_doc/convbert#transformers.TFConvBertModel"),c(DH,"href","/docs/transformers/pr_17806/en/model_doc/convnext#transformers.TFConvNextModel"),c(GH,"href","/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.TFCTRLModel"),c(OH,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(VH,"href","/docs/transformers/pr_17806/en/model_doc/deberta#transformers.TFDebertaModel"),c(XH,"href","/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(zH,"href","/docs/transformers/pr_17806/en/model_doc/deit#transformers.TFDeiTModel"),c(WH,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(QH,"href","/docs/transformers/pr_17806/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(HH,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.TFElectraModel"),c(UH,"href","/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(JH,"href","/docs/transformers/pr_17806/en/model_doc/funnel#transformers.TFFunnelModel"),c(YH,"href","/docs/transformers/pr_17806/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(KH,"href","/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.TFGPT2Model"),c(ZH,"href","/docs/transformers/pr_17806/en/model_doc/gptj#transformers.TFGPTJModel"),c(eU,"href","/docs/transformers/pr_17806/en/model_doc/hubert#transformers.TFHubertModel"),c(oU,"href","/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(rU,"href","/docs/transformers/pr_17806/en/model_doc/led#transformers.TFLEDModel"),c(tU,"href","/docs/transformers/pr_17806/en/model_doc/longformer#transformers.TFLongformerModel"),c(aU,"href","/docs/transformers/pr_17806/en/model_doc/lxmert#transformers.TFLxmertModel"),c(nU,"href","/docs/transformers/pr_17806/en/model_doc/marian#transformers.TFMarianModel"),c(sU,"href","/docs/transformers/pr_17806/en/model_doc/mbart#transformers.TFMBartModel"),c(lU,"href","/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(iU,"href","/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.TFMPNetModel"),c(dU,"href","/docs/transformers/pr_17806/en/model_doc/mt5#transformers.TFMT5Model"),c(cU,"href","/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(fU,"href","/docs/transformers/pr_17806/en/model_doc/opt#transformers.TFOPTModel"),c(mU,"href","/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.TFPegasusModel"),c(gU,"href","/docs/transformers/pr_17806/en/model_doc/regnet#transformers.TFRegNetModel"),c(hU,"href","/docs/transformers/pr_17806/en/model_doc/rembert#transformers.TFRemBertModel"),c(pU,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.TFRobertaModel"),c(_U,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.TFRoFormerModel"),c(uU,"href","/docs/transformers/pr_17806/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(bU,"href","/docs/transformers/pr_17806/en/model_doc/swin#transformers.TFSwinModel"),c(vU,"href","/docs/transformers/pr_17806/en/model_doc/t5#transformers.TFT5Model"),c(FU,"href","/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TFTapasModel"),c(TU,"href","/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(MU,"href","/docs/transformers/pr_17806/en/model_doc/vit#transformers.TFViTModel"),c(EU,"href","/docs/transformers/pr_17806/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(CU,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(wU,"href","/docs/transformers/pr_17806/en/model_doc/xlm#transformers.TFXLMModel"),c(AU,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(LU,"href","/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.TFXLNetModel"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z7,"id","transformers.TFAutoModelForPreTraining"),c(Z7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z7,"href","#transformers.TFAutoModelForPreTraining"),c(lc,"class","relative group"),c(yU,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xU,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($U,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kU,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(SU,"href","/docs/transformers/pr_17806/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(RU,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.TFBertForPreTraining"),c(PU,"href","/docs/transformers/pr_17806/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(BU,"href","/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(IU,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(NU,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(qU,"href","/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(jU,"href","/docs/transformers/pr_17806/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(DU,"href","/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(GU,"href","/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(OU,"href","/docs/transformers/pr_17806/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(VU,"href","/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(XU,"href","/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(zU,"href","/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(WU,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(QU,"href","/docs/transformers/pr_17806/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(HU,"href","/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(UU,"href","/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(JU,"href","/docs/transformers/pr_17806/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(YU,"href","/docs/transformers/pr_17806/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(KU,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(ZU,"href","/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(w8,"id","transformers.TFAutoModelForCausalLM"),c(w8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w8,"href","#transformers.TFAutoModelForCausalLM"),c(cc,"class","relative group"),c(eJ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oJ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rJ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tJ,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(aJ,"href","/docs/transformers/pr_17806/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(nJ,"href","/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(sJ,"href","/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(lJ,"href","/docs/transformers/pr_17806/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(iJ,"href","/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(dJ,"href","/docs/transformers/pr_17806/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(cJ,"href","/docs/transformers/pr_17806/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(fJ,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(mJ,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(gJ,"href","/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(hJ,"href","/docs/transformers/pr_17806/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(pJ,"href","/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(G8,"id","transformers.TFAutoModelForImageClassification"),c(G8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(G8,"href","#transformers.TFAutoModelForImageClassification"),c(gc,"class","relative group"),c(_J,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uJ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bJ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vJ,"href","/docs/transformers/pr_17806/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(FJ,"href","/docs/transformers/pr_17806/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(TJ,"href","/docs/transformers/pr_17806/en/model_doc/deit#transformers.TFDeiTForImageClassification"),c(MJ,"href","/docs/transformers/pr_17806/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),c(EJ,"href","/docs/transformers/pr_17806/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),c(CJ,"href","/docs/transformers/pr_17806/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(wJ,"href","/docs/transformers/pr_17806/en/model_doc/vit#transformers.TFViTForImageClassification"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(U8,"id","transformers.TFAutoModelForMaskedLM"),c(U8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(U8,"href","#transformers.TFAutoModelForMaskedLM"),c(_c,"class","relative group"),c(AJ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LJ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yJ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xJ,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c($J,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(kJ,"href","/docs/transformers/pr_17806/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(SJ,"href","/docs/transformers/pr_17806/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(RJ,"href","/docs/transformers/pr_17806/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(PJ,"href","/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(BJ,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(IJ,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(NJ,"href","/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(qJ,"href","/docs/transformers/pr_17806/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(jJ,"href","/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(DJ,"href","/docs/transformers/pr_17806/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(GJ,"href","/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(OJ,"href","/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(VJ,"href","/docs/transformers/pr_17806/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(XJ,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(zJ,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(WJ,"href","/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(QJ,"href","/docs/transformers/pr_17806/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(HJ,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bM,"id","transformers.TFAutoModelForSeq2SeqLM"),c(bM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bM,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(vc,"class","relative group"),c(UJ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JJ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YJ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KJ,"href","/docs/transformers/pr_17806/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(ZJ,"href","/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(eY,"href","/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(oY,"href","/docs/transformers/pr_17806/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(rY,"href","/docs/transformers/pr_17806/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(tY,"href","/docs/transformers/pr_17806/en/model_doc/marian#transformers.TFMarianMTModel"),c(aY,"href","/docs/transformers/pr_17806/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(nY,"href","/docs/transformers/pr_17806/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(sY,"href","/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(lY,"href","/docs/transformers/pr_17806/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kM,"id","transformers.TFAutoModelForSequenceClassification"),c(kM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kM,"href","#transformers.TFAutoModelForSequenceClassification"),c(Mc,"class","relative group"),c(iY,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dY,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cY,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fY,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(mY,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(gY,"href","/docs/transformers/pr_17806/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(hY,"href","/docs/transformers/pr_17806/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(pY,"href","/docs/transformers/pr_17806/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(_Y,"href","/docs/transformers/pr_17806/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(uY,"href","/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(bY,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(vY,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(FY,"href","/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(TY,"href","/docs/transformers/pr_17806/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(MY,"href","/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(EY,"href","/docs/transformers/pr_17806/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(CY,"href","/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(wY,"href","/docs/transformers/pr_17806/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(AY,"href","/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(LY,"href","/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(yY,"href","/docs/transformers/pr_17806/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(xY,"href","/docs/transformers/pr_17806/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c($Y,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(kY,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(SY,"href","/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(RY,"href","/docs/transformers/pr_17806/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(PY,"href","/docs/transformers/pr_17806/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(BY,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(IY,"href","/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(s4,"id","transformers.TFAutoModelForMultipleChoice"),c(s4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(s4,"href","#transformers.TFAutoModelForMultipleChoice"),c(wc,"class","relative group"),c(NY,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qY,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jY,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DY,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(GY,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(OY,"href","/docs/transformers/pr_17806/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(VY,"href","/docs/transformers/pr_17806/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(XY,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(zY,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(WY,"href","/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(QY,"href","/docs/transformers/pr_17806/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(HY,"href","/docs/transformers/pr_17806/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(UY,"href","/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(JY,"href","/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(YY,"href","/docs/transformers/pr_17806/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(KY,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(ZY,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(eK,"href","/docs/transformers/pr_17806/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(oK,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(rK,"href","/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(A4,"id","transformers.TFAutoModelForNextSentencePrediction"),c(A4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(A4,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(yc,"class","relative group"),c(tK,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aK,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nK,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sK,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(lK,"href","/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(k4,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(k4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(k4,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(kc,"class","relative group"),c(iK,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dK,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cK,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fK,"href","/docs/transformers/pr_17806/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(B4,"id","transformers.TFAutoModelForTokenClassification"),c(B4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(B4,"href","#transformers.TFAutoModelForTokenClassification"),c(Pc,"class","relative group"),c(mK,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gK,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hK,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pK,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(_K,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(uK,"href","/docs/transformers/pr_17806/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(bK,"href","/docs/transformers/pr_17806/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(vK,"href","/docs/transformers/pr_17806/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(FK,"href","/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(TK,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(MK,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(EK,"href","/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(CK,"href","/docs/transformers/pr_17806/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(wK,"href","/docs/transformers/pr_17806/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(AK,"href","/docs/transformers/pr_17806/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(LK,"href","/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(yK,"href","/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(xK,"href","/docs/transformers/pr_17806/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c($K,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(kK,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(SK,"href","/docs/transformers/pr_17806/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(RK,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(PK,"href","/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aE,"id","transformers.TFAutoModelForQuestionAnswering"),c(aE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aE,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Nc,"class","relative group"),c(BK,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(IK,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(NK,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qK,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(jK,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(DK,"href","/docs/transformers/pr_17806/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(GK,"href","/docs/transformers/pr_17806/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(OK,"href","/docs/transformers/pr_17806/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(VK,"href","/docs/transformers/pr_17806/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(XK,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(zK,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(WK,"href","/docs/transformers/pr_17806/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(QK,"href","/docs/transformers/pr_17806/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(HK,"href","/docs/transformers/pr_17806/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(UK,"href","/docs/transformers/pr_17806/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(JK,"href","/docs/transformers/pr_17806/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(YK,"href","/docs/transformers/pr_17806/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(KK,"href","/docs/transformers/pr_17806/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(ZK,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(eZ,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(oZ,"href","/docs/transformers/pr_17806/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(rZ,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(tZ,"href","/docs/transformers/pr_17806/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(LE,"id","transformers.TFAutoModelForVision2Seq"),c(LE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(LE,"href","#transformers.TFAutoModelForVision2Seq"),c(Dc,"class","relative group"),c(aZ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nZ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sZ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lZ,"href","/docs/transformers/pr_17806/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kE,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(kE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kE,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(Vc,"class","relative group"),c(iZ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dZ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cZ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fZ,"href","/docs/transformers/pr_17806/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BE,"id","transformers.FlaxAutoModel"),c(BE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(BE,"href","#transformers.FlaxAutoModel"),c(Wc,"class","relative group"),c(mZ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gZ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hZ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pZ,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.FlaxAlbertModel"),c(_Z,"href","/docs/transformers/pr_17806/en/model_doc/bart#transformers.FlaxBartModel"),c(uZ,"href","/docs/transformers/pr_17806/en/model_doc/beit#transformers.FlaxBeitModel"),c(bZ,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.FlaxBertModel"),c(vZ,"href","/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(FZ,"href","/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(TZ,"href","/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(MZ,"href","/docs/transformers/pr_17806/en/model_doc/clip#transformers.FlaxCLIPModel"),c(EZ,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(CZ,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.FlaxElectraModel"),c(wZ,"href","/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(AZ,"href","/docs/transformers/pr_17806/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(LZ,"href","/docs/transformers/pr_17806/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(yZ,"href","/docs/transformers/pr_17806/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(xZ,"href","/docs/transformers/pr_17806/en/model_doc/marian#transformers.FlaxMarianModel"),c($Z,"href","/docs/transformers/pr_17806/en/model_doc/mbart#transformers.FlaxMBartModel"),c(kZ,"href","/docs/transformers/pr_17806/en/model_doc/mt5#transformers.FlaxMT5Model"),c(SZ,"href","/docs/transformers/pr_17806/en/model_doc/opt#transformers.FlaxOPTModel"),c(RZ,"href","/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(PZ,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(BZ,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(IZ,"href","/docs/transformers/pr_17806/en/model_doc/t5#transformers.FlaxT5Model"),c(NZ,"href","/docs/transformers/pr_17806/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(qZ,"href","/docs/transformers/pr_17806/en/model_doc/vit#transformers.FlaxViTModel"),c(jZ,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(DZ,"href","/docs/transformers/pr_17806/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(GZ,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fC,"id","transformers.FlaxAutoModelForCausalLM"),c(fC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fC,"href","#transformers.FlaxAutoModelForCausalLM"),c(Uc,"class","relative group"),c(OZ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VZ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XZ,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zZ,"href","/docs/transformers/pr_17806/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(WZ,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(QZ,"href","/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(HZ,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(UZ,"href","/docs/transformers/pr_17806/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(JZ,"href","/docs/transformers/pr_17806/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(YZ,"href","/docs/transformers/pr_17806/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(KZ,"href","/docs/transformers/pr_17806/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(ZZ,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(eee,"href","/docs/transformers/pr_17806/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CC,"id","transformers.FlaxAutoModelForPreTraining"),c(CC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(CC,"href","#transformers.FlaxAutoModelForPreTraining"),c(Kc,"class","relative group"),c(oee,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ree,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tee,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aee,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(nee,"href","/docs/transformers/pr_17806/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(see,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(lee,"href","/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(iee,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(dee,"href","/docs/transformers/pr_17806/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(cee,"href","/docs/transformers/pr_17806/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(fee,"href","/docs/transformers/pr_17806/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(mee,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(gee,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(hee,"href","/docs/transformers/pr_17806/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(pee,"href","/docs/transformers/pr_17806/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(_ee,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DC,"id","transformers.FlaxAutoModelForMaskedLM"),c(DC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DC,"href","#transformers.FlaxAutoModelForMaskedLM"),c(of,"class","relative group"),c(uee,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bee,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vee,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fee,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(Tee,"href","/docs/transformers/pr_17806/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(Mee,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(Eee,"href","/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(Cee,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(wee,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(Aee,"href","/docs/transformers/pr_17806/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Lee,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(yee,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(xee,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZC,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(ZC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ZC,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(af,"class","relative group"),c($ee,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kee,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(See,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ree,"href","/docs/transformers/pr_17806/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(Pee,"href","/docs/transformers/pr_17806/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(Bee,"href","/docs/transformers/pr_17806/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(Iee,"href","/docs/transformers/pr_17806/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(Nee,"href","/docs/transformers/pr_17806/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(qee,"href","/docs/transformers/pr_17806/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(jee,"href","/docs/transformers/pr_17806/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Dee,"href","/docs/transformers/pr_17806/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(Gee,"href","/docs/transformers/pr_17806/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(Oee,"href","/docs/transformers/pr_17806/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m3,"id","transformers.FlaxAutoModelForSequenceClassification"),c(m3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m3,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(lf,"class","relative group"),c(Vee,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xee,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zee,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wee,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(Qee,"href","/docs/transformers/pr_17806/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(Hee,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(Uee,"href","/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(Jee,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(Yee,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(Kee,"href","/docs/transformers/pr_17806/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(Zee,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(eoe,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(ooe,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(w3,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(w3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w3,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(ff,"class","relative group"),c(roe,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(toe,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aoe,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(noe,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(soe,"href","/docs/transformers/pr_17806/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(loe,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(ioe,"href","/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(doe,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(coe,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(foe,"href","/docs/transformers/pr_17806/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(moe,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(goe,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(hoe,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(q3,"id","transformers.FlaxAutoModelForTokenClassification"),c(q3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(q3,"href","#transformers.FlaxAutoModelForTokenClassification"),c(hf,"class","relative group"),c(poe,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_oe,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(uoe,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(boe,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(voe,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(Foe,"href","/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(Toe,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(Moe,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(Eoe,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(Coe,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(woe,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(U3,"id","transformers.FlaxAutoModelForMultipleChoice"),c(U3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(U3,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(uf,"class","relative group"),c(Aoe,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Loe,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yoe,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xoe,"href","/docs/transformers/pr_17806/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c($oe,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(koe,"href","/docs/transformers/pr_17806/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(Soe,"href","/docs/transformers/pr_17806/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(Roe,"href","/docs/transformers/pr_17806/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(Poe,"href","/docs/transformers/pr_17806/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(Boe,"href","/docs/transformers/pr_17806/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(Ioe,"href","/docs/transformers/pr_17806/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(s5,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(s5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(s5,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(Ff,"class","relative group"),c(Noe,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qoe,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(joe,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Doe,"href","/docs/transformers/pr_17806/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(c5,"id","transformers.FlaxAutoModelForImageClassification"),c(c5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(c5,"href","#transformers.FlaxAutoModelForImageClassification"),c(Ef,"class","relative group"),c(Goe,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ooe,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Voe,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xoe,"href","/docs/transformers/pr_17806/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(zoe,"href","/docs/transformers/pr_17806/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(p5,"id","transformers.FlaxAutoModelForVision2Seq"),c(p5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(p5,"href","#transformers.FlaxAutoModelForVision2Seq"),c(Af,"class","relative group"),c(Woe,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qoe,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Hoe,"href","/docs/transformers/pr_17806/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uoe,"href","/docs/transformers/pr_17806/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,u){e(document.head,g),b(f,v,u),b(f,p,u),e(p,m),e(m,_),M(d,_,null),e(p,h),e(p,Eo),e(Eo,wi),b(f,Sf,u),b(f,nt,u),e(nt,Ai),e(nt,Li),e(Li,qA),e(nt,Rf),b(f,Oe,u),b(f,We,u),e(We,yi),e(We,Pn),e(Pn,jA),e(We,Bn),e(We,In),e(In,DA),e(We,xi),e(We,Nn),e(Nn,GA),e(We,$i),b(f,Pf,u),M(ka,f,u),b(f,Qe,u),b(f,Ae,u),e(Ae,bS),e(Ae,ki),e(ki,vS),e(Ae,FS),b(f,Co,u),b(f,Sa,u),e(Sa,TS),e(Sa,Bf),e(Bf,MS),e(Sa,oQe),b(f,DOe,u),b(f,Si,u),e(Si,If),e(If,Xte),M(OA,Xte,null),e(Si,rQe),e(Si,zte),e(zte,tQe),b(f,GOe,u),b(f,qn,u),e(qn,aQe),e(qn,Wte),e(Wte,nQe),e(qn,sQe),e(qn,Qte),e(Qte,lQe),e(qn,iQe),b(f,OOe,u),M(VA,f,u),b(f,VOe,u),b(f,ES,u),e(ES,dQe),b(f,XOe,u),M(Nf,f,u),b(f,zOe,u),b(f,Ri,u),e(Ri,qf),e(qf,Hte),M(XA,Hte,null),e(Ri,cQe),e(Ri,Ute),e(Ute,fQe),b(f,WOe,u),b(f,wo,u),M(zA,wo,null),e(wo,mQe),e(wo,WA),e(WA,gQe),e(WA,CS),e(CS,hQe),e(WA,pQe),e(wo,_Qe),e(wo,QA),e(QA,uQe),e(QA,Jte),e(Jte,bQe),e(QA,vQe),e(wo,FQe),e(wo,Lr),M(HA,Lr,null),e(Lr,TQe),e(Lr,Yte),e(Yte,MQe),e(Lr,EQe),e(Lr,Pi),e(Pi,CQe),e(Pi,Kte),e(Kte,wQe),e(Pi,AQe),e(Pi,Zte),e(Zte,LQe),e(Pi,yQe),e(Lr,xQe),e(Lr,A),e(A,jf),e(jf,eae),e(eae,$Qe),e(jf,kQe),e(jf,wS),e(wS,SQe),e(jf,RQe),e(A,PQe),e(A,Df),e(Df,oae),e(oae,BQe),e(Df,IQe),e(Df,AS),e(AS,NQe),e(Df,qQe),e(A,jQe),e(A,Gf),e(Gf,rae),e(rae,DQe),e(Gf,GQe),e(Gf,LS),e(LS,OQe),e(Gf,VQe),e(A,XQe),e(A,Of),e(Of,tae),e(tae,zQe),e(Of,WQe),e(Of,yS),e(yS,QQe),e(Of,HQe),e(A,UQe),e(A,Vf),e(Vf,aae),e(aae,JQe),e(Vf,YQe),e(Vf,xS),e(xS,KQe),e(Vf,ZQe),e(A,eHe),e(A,Xf),e(Xf,nae),e(nae,oHe),e(Xf,rHe),e(Xf,$S),e($S,tHe),e(Xf,aHe),e(A,nHe),e(A,zf),e(zf,sae),e(sae,sHe),e(zf,lHe),e(zf,kS),e(kS,iHe),e(zf,dHe),e(A,cHe),e(A,Wf),e(Wf,lae),e(lae,fHe),e(Wf,mHe),e(Wf,SS),e(SS,gHe),e(Wf,hHe),e(A,pHe),e(A,Qf),e(Qf,iae),e(iae,_He),e(Qf,uHe),e(Qf,RS),e(RS,bHe),e(Qf,vHe),e(A,FHe),e(A,Hf),e(Hf,dae),e(dae,THe),e(Hf,MHe),e(Hf,PS),e(PS,EHe),e(Hf,CHe),e(A,wHe),e(A,Uf),e(Uf,cae),e(cae,AHe),e(Uf,LHe),e(Uf,BS),e(BS,yHe),e(Uf,xHe),e(A,$He),e(A,Jf),e(Jf,fae),e(fae,kHe),e(Jf,SHe),e(Jf,IS),e(IS,RHe),e(Jf,PHe),e(A,BHe),e(A,Yf),e(Yf,mae),e(mae,IHe),e(Yf,NHe),e(Yf,NS),e(NS,qHe),e(Yf,jHe),e(A,DHe),e(A,Kf),e(Kf,gae),e(gae,GHe),e(Kf,OHe),e(Kf,qS),e(qS,VHe),e(Kf,XHe),e(A,zHe),e(A,Zf),e(Zf,hae),e(hae,WHe),e(Zf,QHe),e(Zf,jS),e(jS,HHe),e(Zf,UHe),e(A,JHe),e(A,em),e(em,pae),e(pae,YHe),e(em,KHe),e(em,DS),e(DS,ZHe),e(em,eUe),e(A,oUe),e(A,om),e(om,_ae),e(_ae,rUe),e(om,tUe),e(om,GS),e(GS,aUe),e(om,nUe),e(A,sUe),e(A,rm),e(rm,uae),e(uae,lUe),e(rm,iUe),e(rm,OS),e(OS,dUe),e(rm,cUe),e(A,fUe),e(A,tm),e(tm,bae),e(bae,mUe),e(tm,gUe),e(tm,VS),e(VS,hUe),e(tm,pUe),e(A,_Ue),e(A,am),e(am,vae),e(vae,uUe),e(am,bUe),e(am,XS),e(XS,vUe),e(am,FUe),e(A,TUe),e(A,nm),e(nm,Fae),e(Fae,MUe),e(nm,EUe),e(nm,zS),e(zS,CUe),e(nm,wUe),e(A,AUe),e(A,sm),e(sm,Tae),e(Tae,LUe),e(sm,yUe),e(sm,WS),e(WS,xUe),e(sm,$Ue),e(A,kUe),e(A,lm),e(lm,Mae),e(Mae,SUe),e(lm,RUe),e(lm,QS),e(QS,PUe),e(lm,BUe),e(A,IUe),e(A,im),e(im,Eae),e(Eae,NUe),e(im,qUe),e(im,HS),e(HS,jUe),e(im,DUe),e(A,GUe),e(A,dm),e(dm,Cae),e(Cae,OUe),e(dm,VUe),e(dm,US),e(US,XUe),e(dm,zUe),e(A,WUe),e(A,cm),e(cm,wae),e(wae,QUe),e(cm,HUe),e(cm,JS),e(JS,UUe),e(cm,JUe),e(A,YUe),e(A,fm),e(fm,Aae),e(Aae,KUe),e(fm,ZUe),e(fm,YS),e(YS,eJe),e(fm,oJe),e(A,rJe),e(A,mm),e(mm,Lae),e(Lae,tJe),e(mm,aJe),e(mm,KS),e(KS,nJe),e(mm,sJe),e(A,lJe),e(A,gm),e(gm,yae),e(yae,iJe),e(gm,dJe),e(gm,ZS),e(ZS,cJe),e(gm,fJe),e(A,mJe),e(A,hm),e(hm,xae),e(xae,gJe),e(hm,hJe),e(hm,eR),e(eR,pJe),e(hm,_Je),e(A,uJe),e(A,pm),e(pm,$ae),e($ae,bJe),e(pm,vJe),e(pm,oR),e(oR,FJe),e(pm,TJe),e(A,MJe),e(A,_m),e(_m,kae),e(kae,EJe),e(_m,CJe),e(_m,rR),e(rR,wJe),e(_m,AJe),e(A,LJe),e(A,um),e(um,Sae),e(Sae,yJe),e(um,xJe),e(um,tR),e(tR,$Je),e(um,kJe),e(A,SJe),e(A,bm),e(bm,Rae),e(Rae,RJe),e(bm,PJe),e(bm,aR),e(aR,BJe),e(bm,IJe),e(A,NJe),e(A,vm),e(vm,Pae),e(Pae,qJe),e(vm,jJe),e(vm,nR),e(nR,DJe),e(vm,GJe),e(A,OJe),e(A,Fm),e(Fm,Bae),e(Bae,VJe),e(Fm,XJe),e(Fm,sR),e(sR,zJe),e(Fm,WJe),e(A,QJe),e(A,Tm),e(Tm,Iae),e(Iae,HJe),e(Tm,UJe),e(Tm,lR),e(lR,JJe),e(Tm,YJe),e(A,KJe),e(A,Mm),e(Mm,Nae),e(Nae,ZJe),e(Mm,eYe),e(Mm,iR),e(iR,oYe),e(Mm,rYe),e(A,tYe),e(A,Em),e(Em,qae),e(qae,aYe),e(Em,nYe),e(Em,dR),e(dR,sYe),e(Em,lYe),e(A,iYe),e(A,Cm),e(Cm,jae),e(jae,dYe),e(Cm,cYe),e(Cm,cR),e(cR,fYe),e(Cm,mYe),e(A,gYe),e(A,wm),e(wm,Dae),e(Dae,hYe),e(wm,pYe),e(wm,fR),e(fR,_Ye),e(wm,uYe),e(A,bYe),e(A,Am),e(Am,Gae),e(Gae,vYe),e(Am,FYe),e(Am,mR),e(mR,TYe),e(Am,MYe),e(A,EYe),e(A,Lm),e(Lm,Oae),e(Oae,CYe),e(Lm,wYe),e(Lm,gR),e(gR,AYe),e(Lm,LYe),e(A,yYe),e(A,ym),e(ym,Vae),e(Vae,xYe),e(ym,$Ye),e(ym,hR),e(hR,kYe),e(ym,SYe),e(A,RYe),e(A,xm),e(xm,Xae),e(Xae,PYe),e(xm,BYe),e(xm,pR),e(pR,IYe),e(xm,NYe),e(A,qYe),e(A,$m),e($m,zae),e(zae,jYe),e($m,DYe),e($m,_R),e(_R,GYe),e($m,OYe),e(A,VYe),e(A,km),e(km,Wae),e(Wae,XYe),e(km,zYe),e(km,uR),e(uR,WYe),e(km,QYe),e(A,HYe),e(A,Sm),e(Sm,Qae),e(Qae,UYe),e(Sm,JYe),e(Sm,bR),e(bR,YYe),e(Sm,KYe),e(A,ZYe),e(A,Rm),e(Rm,Hae),e(Hae,eKe),e(Rm,oKe),e(Rm,vR),e(vR,rKe),e(Rm,tKe),e(A,aKe),e(A,Pm),e(Pm,Uae),e(Uae,nKe),e(Pm,sKe),e(Pm,FR),e(FR,lKe),e(Pm,iKe),e(A,dKe),e(A,Bm),e(Bm,Jae),e(Jae,cKe),e(Bm,fKe),e(Bm,TR),e(TR,mKe),e(Bm,gKe),e(A,hKe),e(A,Im),e(Im,Yae),e(Yae,pKe),e(Im,_Ke),e(Im,MR),e(MR,uKe),e(Im,bKe),e(A,vKe),e(A,Nm),e(Nm,Kae),e(Kae,FKe),e(Nm,TKe),e(Nm,ER),e(ER,MKe),e(Nm,EKe),e(A,CKe),e(A,qm),e(qm,Zae),e(Zae,wKe),e(qm,AKe),e(qm,CR),e(CR,LKe),e(qm,yKe),e(A,xKe),e(A,jm),e(jm,ene),e(ene,$Ke),e(jm,kKe),e(jm,wR),e(wR,SKe),e(jm,RKe),e(A,PKe),e(A,Dm),e(Dm,one),e(one,BKe),e(Dm,IKe),e(Dm,AR),e(AR,NKe),e(Dm,qKe),e(A,jKe),e(A,Gm),e(Gm,rne),e(rne,DKe),e(Gm,GKe),e(Gm,LR),e(LR,OKe),e(Gm,VKe),e(A,XKe),e(A,Om),e(Om,tne),e(tne,zKe),e(Om,WKe),e(Om,yR),e(yR,QKe),e(Om,HKe),e(A,UKe),e(A,Vm),e(Vm,ane),e(ane,JKe),e(Vm,YKe),e(Vm,xR),e(xR,KKe),e(Vm,ZKe),e(A,eZe),e(A,Xm),e(Xm,nne),e(nne,oZe),e(Xm,rZe),e(Xm,$R),e($R,tZe),e(Xm,aZe),e(A,nZe),e(A,zm),e(zm,sne),e(sne,sZe),e(zm,lZe),e(zm,kR),e(kR,iZe),e(zm,dZe),e(A,cZe),e(A,Wm),e(Wm,lne),e(lne,fZe),e(Wm,mZe),e(Wm,SR),e(SR,gZe),e(Wm,hZe),e(A,pZe),e(A,Qm),e(Qm,ine),e(ine,_Ze),e(Qm,uZe),e(Qm,RR),e(RR,bZe),e(Qm,vZe),e(A,FZe),e(A,Hm),e(Hm,dne),e(dne,TZe),e(Hm,MZe),e(Hm,PR),e(PR,EZe),e(Hm,CZe),e(A,wZe),e(A,Um),e(Um,cne),e(cne,AZe),e(Um,LZe),e(Um,BR),e(BR,yZe),e(Um,xZe),e(A,$Ze),e(A,Jm),e(Jm,fne),e(fne,kZe),e(Jm,SZe),e(Jm,IR),e(IR,RZe),e(Jm,PZe),e(A,BZe),e(A,Ym),e(Ym,mne),e(mne,IZe),e(Ym,NZe),e(Ym,NR),e(NR,qZe),e(Ym,jZe),e(A,DZe),e(A,Km),e(Km,gne),e(gne,GZe),e(Km,OZe),e(Km,qR),e(qR,VZe),e(Km,XZe),e(A,zZe),e(A,Zm),e(Zm,hne),e(hne,WZe),e(Zm,QZe),e(Zm,jR),e(jR,HZe),e(Zm,UZe),e(A,JZe),e(A,eg),e(eg,pne),e(pne,YZe),e(eg,KZe),e(eg,DR),e(DR,ZZe),e(eg,eeo),e(A,oeo),e(A,og),e(og,_ne),e(_ne,reo),e(og,teo),e(og,GR),e(GR,aeo),e(og,neo),e(A,seo),e(A,rg),e(rg,une),e(une,leo),e(rg,ieo),e(rg,OR),e(OR,deo),e(rg,ceo),e(A,feo),e(A,tg),e(tg,bne),e(bne,meo),e(tg,geo),e(tg,VR),e(VR,heo),e(tg,peo),e(A,_eo),e(A,ag),e(ag,vne),e(vne,ueo),e(ag,beo),e(ag,XR),e(XR,veo),e(ag,Feo),e(A,Teo),e(A,ng),e(ng,Fne),e(Fne,Meo),e(ng,Eeo),e(ng,zR),e(zR,Ceo),e(ng,weo),e(A,Aeo),e(A,sg),e(sg,Tne),e(Tne,Leo),e(sg,yeo),e(sg,WR),e(WR,xeo),e(sg,$eo),e(A,keo),e(A,lg),e(lg,Mne),e(Mne,Seo),e(lg,Reo),e(lg,QR),e(QR,Peo),e(lg,Beo),e(A,Ieo),e(A,ig),e(ig,Ene),e(Ene,Neo),e(ig,qeo),e(ig,HR),e(HR,jeo),e(ig,Deo),e(A,Geo),e(A,dg),e(dg,Cne),e(Cne,Oeo),e(dg,Veo),e(dg,UR),e(UR,Xeo),e(dg,zeo),e(A,Weo),e(A,cg),e(cg,wne),e(wne,Qeo),e(cg,Heo),e(cg,JR),e(JR,Ueo),e(cg,Jeo),e(A,Yeo),e(A,fg),e(fg,Ane),e(Ane,Keo),e(fg,Zeo),e(fg,YR),e(YR,eoo),e(fg,ooo),e(A,roo),e(A,mg),e(mg,Lne),e(Lne,too),e(mg,aoo),e(mg,KR),e(KR,noo),e(mg,soo),e(A,loo),e(A,gg),e(gg,yne),e(yne,ioo),e(gg,doo),e(gg,ZR),e(ZR,coo),e(gg,foo),e(A,moo),e(A,hg),e(hg,xne),e(xne,goo),e(hg,hoo),e(hg,eP),e(eP,poo),e(hg,_oo),e(A,uoo),e(A,pg),e(pg,$ne),e($ne,boo),e(pg,voo),e(pg,oP),e(oP,Foo),e(pg,Too),e(A,Moo),e(A,_g),e(_g,kne),e(kne,Eoo),e(_g,Coo),e(_g,rP),e(rP,woo),e(_g,Aoo),e(A,Loo),e(A,ug),e(ug,Sne),e(Sne,yoo),e(ug,xoo),e(ug,tP),e(tP,$oo),e(ug,koo),e(A,Soo),e(A,bg),e(bg,Rne),e(Rne,Roo),e(bg,Poo),e(bg,aP),e(aP,Boo),e(bg,Ioo),e(A,Noo),e(A,vg),e(vg,Pne),e(Pne,qoo),e(vg,joo),e(vg,nP),e(nP,Doo),e(vg,Goo),e(A,Ooo),e(A,Fg),e(Fg,Bne),e(Bne,Voo),e(Fg,Xoo),e(Fg,sP),e(sP,zoo),e(Fg,Woo),e(A,Qoo),e(A,Tg),e(Tg,Ine),e(Ine,Hoo),e(Tg,Uoo),e(Tg,lP),e(lP,Joo),e(Tg,Yoo),e(A,Koo),e(A,Mg),e(Mg,Nne),e(Nne,Zoo),e(Mg,ero),e(Mg,iP),e(iP,oro),e(Mg,rro),e(A,tro),e(A,Eg),e(Eg,qne),e(qne,aro),e(Eg,nro),e(Eg,dP),e(dP,sro),e(Eg,lro),e(A,iro),e(A,Cg),e(Cg,jne),e(jne,dro),e(Cg,cro),e(Cg,cP),e(cP,fro),e(Cg,mro),e(A,gro),e(A,wg),e(wg,Dne),e(Dne,hro),e(wg,pro),e(wg,fP),e(fP,_ro),e(wg,uro),e(A,bro),e(A,Ag),e(Ag,Gne),e(Gne,vro),e(Ag,Fro),e(Ag,mP),e(mP,Tro),e(Ag,Mro),e(A,Ero),e(A,Lg),e(Lg,One),e(One,Cro),e(Lg,wro),e(Lg,gP),e(gP,Aro),e(Lg,Lro),e(A,yro),e(A,yg),e(yg,Vne),e(Vne,xro),e(yg,$ro),e(yg,hP),e(hP,kro),e(yg,Sro),e(A,Rro),e(A,xg),e(xg,Xne),e(Xne,Pro),e(xg,Bro),e(xg,pP),e(pP,Iro),e(xg,Nro),e(A,qro),e(A,$g),e($g,zne),e(zne,jro),e($g,Dro),e($g,_P),e(_P,Gro),e($g,Oro),e(A,Vro),e(A,kg),e(kg,Wne),e(Wne,Xro),e(kg,zro),e(kg,uP),e(uP,Wro),e(kg,Qro),e(A,Hro),e(A,Sg),e(Sg,Qne),e(Qne,Uro),e(Sg,Jro),e(Sg,bP),e(bP,Yro),e(Sg,Kro),e(A,Zro),e(A,Rg),e(Rg,Hne),e(Hne,eto),e(Rg,oto),e(Rg,vP),e(vP,rto),e(Rg,tto),e(A,ato),e(A,Pg),e(Pg,Une),e(Une,nto),e(Pg,sto),e(Pg,FP),e(FP,lto),e(Pg,ito),e(A,dto),e(A,Bg),e(Bg,Jne),e(Jne,cto),e(Bg,fto),e(Bg,TP),e(TP,mto),e(Bg,gto),e(A,hto),e(A,Ig),e(Ig,Yne),e(Yne,pto),e(Ig,_to),e(Ig,MP),e(MP,uto),e(Ig,bto),e(A,vto),e(A,Ng),e(Ng,Kne),e(Kne,Fto),e(Ng,Tto),e(Ng,EP),e(EP,Mto),e(Ng,Eto),e(A,Cto),e(A,qg),e(qg,Zne),e(Zne,wto),e(qg,Ato),e(qg,CP),e(CP,Lto),e(qg,yto),e(A,xto),e(A,jg),e(jg,ese),e(ese,$to),e(jg,kto),e(jg,wP),e(wP,Sto),e(jg,Rto),e(A,Pto),e(A,Dg),e(Dg,ose),e(ose,Bto),e(Dg,Ito),e(Dg,AP),e(AP,Nto),e(Dg,qto),e(A,jto),e(A,Gg),e(Gg,rse),e(rse,Dto),e(Gg,Gto),e(Gg,LP),e(LP,Oto),e(Gg,Vto),e(A,Xto),e(A,Og),e(Og,tse),e(tse,zto),e(Og,Wto),e(Og,yP),e(yP,Qto),e(Og,Hto),e(A,Uto),e(A,Vg),e(Vg,ase),e(ase,Jto),e(Vg,Yto),e(Vg,xP),e(xP,Kto),e(Vg,Zto),e(A,eao),e(A,Xg),e(Xg,nse),e(nse,oao),e(Xg,rao),e(Xg,$P),e($P,tao),e(Xg,aao),e(A,nao),e(A,zg),e(zg,sse),e(sse,sao),e(zg,lao),e(zg,kP),e(kP,iao),e(zg,dao),e(A,cao),e(A,Wg),e(Wg,lse),e(lse,fao),e(Wg,mao),e(Wg,SP),e(SP,gao),e(Wg,hao),e(Lr,pao),M(Qg,Lr,null),e(wo,_ao),e(wo,Hg),M(UA,Hg,null),e(Hg,uao),e(Hg,ise),e(ise,bao),b(f,QOe,u),b(f,Bi,u),e(Bi,Ug),e(Ug,dse),M(JA,dse,null),e(Bi,vao),e(Bi,cse),e(cse,Fao),b(f,HOe,u),b(f,Ao,u),M(YA,Ao,null),e(Ao,Tao),e(Ao,KA),e(KA,Mao),e(KA,RP),e(RP,Eao),e(KA,Cao),e(Ao,wao),e(Ao,ZA),e(ZA,Aao),e(ZA,fse),e(fse,Lao),e(ZA,yao),e(Ao,xao),e(Ao,yr),M(eL,yr,null),e(yr,$ao),e(yr,mse),e(mse,kao),e(yr,Sao),e(yr,Ra),e(Ra,Rao),e(Ra,gse),e(gse,Pao),e(Ra,Bao),e(Ra,hse),e(hse,Iao),e(Ra,Nao),e(Ra,pse),e(pse,qao),e(Ra,jao),e(yr,Dao),e(yr,k),e(k,jn),e(jn,_se),e(_se,Gao),e(jn,Oao),e(jn,PP),e(PP,Vao),e(jn,Xao),e(jn,BP),e(BP,zao),e(jn,Wao),e(k,Qao),e(k,Dn),e(Dn,use),e(use,Hao),e(Dn,Uao),e(Dn,IP),e(IP,Jao),e(Dn,Yao),e(Dn,NP),e(NP,Kao),e(Dn,Zao),e(k,eno),e(k,Gn),e(Gn,bse),e(bse,ono),e(Gn,rno),e(Gn,qP),e(qP,tno),e(Gn,ano),e(Gn,jP),e(jP,nno),e(Gn,sno),e(k,lno),e(k,Jg),e(Jg,vse),e(vse,ino),e(Jg,dno),e(Jg,DP),e(DP,cno),e(Jg,fno),e(k,mno),e(k,On),e(On,Fse),e(Fse,gno),e(On,hno),e(On,GP),e(GP,pno),e(On,_no),e(On,OP),e(OP,uno),e(On,bno),e(k,vno),e(k,Yg),e(Yg,Tse),e(Tse,Fno),e(Yg,Tno),e(Yg,VP),e(VP,Mno),e(Yg,Eno),e(k,Cno),e(k,Kg),e(Kg,Mse),e(Mse,wno),e(Kg,Ano),e(Kg,XP),e(XP,Lno),e(Kg,yno),e(k,xno),e(k,Zg),e(Zg,Ese),e(Ese,$no),e(Zg,kno),e(Zg,zP),e(zP,Sno),e(Zg,Rno),e(k,Pno),e(k,Vn),e(Vn,Cse),e(Cse,Bno),e(Vn,Ino),e(Vn,WP),e(WP,Nno),e(Vn,qno),e(Vn,QP),e(QP,jno),e(Vn,Dno),e(k,Gno),e(k,Xn),e(Xn,wse),e(wse,Ono),e(Xn,Vno),e(Xn,HP),e(HP,Xno),e(Xn,zno),e(Xn,UP),e(UP,Wno),e(Xn,Qno),e(k,Hno),e(k,zn),e(zn,Ase),e(Ase,Uno),e(zn,Jno),e(zn,JP),e(JP,Yno),e(zn,Kno),e(zn,YP),e(YP,Zno),e(zn,eso),e(k,oso),e(k,eh),e(eh,Lse),e(Lse,rso),e(eh,tso),e(eh,KP),e(KP,aso),e(eh,nso),e(k,sso),e(k,oh),e(oh,yse),e(yse,lso),e(oh,iso),e(oh,ZP),e(ZP,dso),e(oh,cso),e(k,fso),e(k,rh),e(rh,xse),e(xse,mso),e(rh,gso),e(rh,eB),e(eB,hso),e(rh,pso),e(k,_so),e(k,Wn),e(Wn,$se),e($se,uso),e(Wn,bso),e(Wn,oB),e(oB,vso),e(Wn,Fso),e(Wn,rB),e(rB,Tso),e(Wn,Mso),e(k,Eso),e(k,th),e(th,kse),e(kse,Cso),e(th,wso),e(th,tB),e(tB,Aso),e(th,Lso),e(k,yso),e(k,Qn),e(Qn,Sse),e(Sse,xso),e(Qn,$so),e(Qn,aB),e(aB,kso),e(Qn,Sso),e(Qn,nB),e(nB,Rso),e(Qn,Pso),e(k,Bso),e(k,Hn),e(Hn,Rse),e(Rse,Iso),e(Hn,Nso),e(Hn,sB),e(sB,qso),e(Hn,jso),e(Hn,lB),e(lB,Dso),e(Hn,Gso),e(k,Oso),e(k,Un),e(Un,Pse),e(Pse,Vso),e(Un,Xso),e(Un,iB),e(iB,zso),e(Un,Wso),e(Un,dB),e(dB,Qso),e(Un,Hso),e(k,Uso),e(k,Jn),e(Jn,Bse),e(Bse,Jso),e(Jn,Yso),e(Jn,cB),e(cB,Kso),e(Jn,Zso),e(Jn,fB),e(fB,elo),e(Jn,olo),e(k,rlo),e(k,ah),e(ah,Ise),e(Ise,tlo),e(ah,alo),e(ah,mB),e(mB,nlo),e(ah,slo),e(k,llo),e(k,Yn),e(Yn,Nse),e(Nse,ilo),e(Yn,dlo),e(Yn,gB),e(gB,clo),e(Yn,flo),e(Yn,hB),e(hB,mlo),e(Yn,glo),e(k,hlo),e(k,Kn),e(Kn,qse),e(qse,plo),e(Kn,_lo),e(Kn,pB),e(pB,ulo),e(Kn,blo),e(Kn,_B),e(_B,vlo),e(Kn,Flo),e(k,Tlo),e(k,Zn),e(Zn,jse),e(jse,Mlo),e(Zn,Elo),e(Zn,uB),e(uB,Clo),e(Zn,wlo),e(Zn,bB),e(bB,Alo),e(Zn,Llo),e(k,ylo),e(k,es),e(es,Dse),e(Dse,xlo),e(es,$lo),e(es,vB),e(vB,klo),e(es,Slo),e(es,FB),e(FB,Rlo),e(es,Plo),e(k,Blo),e(k,os),e(os,Gse),e(Gse,Ilo),e(os,Nlo),e(os,TB),e(TB,qlo),e(os,jlo),e(os,MB),e(MB,Dlo),e(os,Glo),e(k,Olo),e(k,rs),e(rs,Ose),e(Ose,Vlo),e(rs,Xlo),e(rs,EB),e(EB,zlo),e(rs,Wlo),e(rs,CB),e(CB,Qlo),e(rs,Hlo),e(k,Ulo),e(k,nh),e(nh,Vse),e(Vse,Jlo),e(nh,Ylo),e(nh,wB),e(wB,Klo),e(nh,Zlo),e(k,eio),e(k,ts),e(ts,Xse),e(Xse,oio),e(ts,rio),e(ts,AB),e(AB,tio),e(ts,aio),e(ts,LB),e(LB,nio),e(ts,sio),e(k,lio),e(k,sh),e(sh,zse),e(zse,iio),e(sh,dio),e(sh,yB),e(yB,cio),e(sh,fio),e(k,mio),e(k,as),e(as,Wse),e(Wse,gio),e(as,hio),e(as,xB),e(xB,pio),e(as,_io),e(as,$B),e($B,uio),e(as,bio),e(k,vio),e(k,ns),e(ns,Qse),e(Qse,Fio),e(ns,Tio),e(ns,kB),e(kB,Mio),e(ns,Eio),e(ns,SB),e(SB,Cio),e(ns,wio),e(k,Aio),e(k,ss),e(ss,Hse),e(Hse,Lio),e(ss,yio),e(ss,RB),e(RB,xio),e(ss,$io),e(ss,PB),e(PB,kio),e(ss,Sio),e(k,Rio),e(k,lh),e(lh,Use),e(Use,Pio),e(lh,Bio),e(lh,BB),e(BB,Iio),e(lh,Nio),e(k,qio),e(k,ls),e(ls,Jse),e(Jse,jio),e(ls,Dio),e(ls,IB),e(IB,Gio),e(ls,Oio),e(ls,NB),e(NB,Vio),e(ls,Xio),e(k,zio),e(k,is),e(is,Yse),e(Yse,Wio),e(is,Qio),e(is,qB),e(qB,Hio),e(is,Uio),e(is,jB),e(jB,Jio),e(is,Yio),e(k,Kio),e(k,ds),e(ds,Kse),e(Kse,Zio),e(ds,edo),e(ds,DB),e(DB,odo),e(ds,rdo),e(ds,GB),e(GB,tdo),e(ds,ado),e(k,ndo),e(k,ih),e(ih,Zse),e(Zse,sdo),e(ih,ldo),e(ih,OB),e(OB,ido),e(ih,ddo),e(k,cdo),e(k,cs),e(cs,ele),e(ele,fdo),e(cs,mdo),e(cs,VB),e(VB,gdo),e(cs,hdo),e(cs,XB),e(XB,pdo),e(cs,_do),e(k,udo),e(k,fs),e(fs,ole),e(ole,bdo),e(fs,vdo),e(fs,zB),e(zB,Fdo),e(fs,Tdo),e(fs,WB),e(WB,Mdo),e(fs,Edo),e(k,Cdo),e(k,ms),e(ms,rle),e(rle,wdo),e(ms,Ado),e(ms,QB),e(QB,Ldo),e(ms,ydo),e(ms,HB),e(HB,xdo),e(ms,$do),e(k,kdo),e(k,gs),e(gs,tle),e(tle,Sdo),e(gs,Rdo),e(gs,UB),e(UB,Pdo),e(gs,Bdo),e(gs,JB),e(JB,Ido),e(gs,Ndo),e(k,qdo),e(k,hs),e(hs,ale),e(ale,jdo),e(hs,Ddo),e(hs,YB),e(YB,Gdo),e(hs,Odo),e(hs,KB),e(KB,Vdo),e(hs,Xdo),e(k,zdo),e(k,ps),e(ps,nle),e(nle,Wdo),e(ps,Qdo),e(ps,ZB),e(ZB,Hdo),e(ps,Udo),e(ps,eI),e(eI,Jdo),e(ps,Ydo),e(k,Kdo),e(k,_s),e(_s,sle),e(sle,Zdo),e(_s,eco),e(_s,oI),e(oI,oco),e(_s,rco),e(_s,rI),e(rI,tco),e(_s,aco),e(k,nco),e(k,us),e(us,lle),e(lle,sco),e(us,lco),e(us,tI),e(tI,ico),e(us,dco),e(us,aI),e(aI,cco),e(us,fco),e(k,mco),e(k,dh),e(dh,ile),e(ile,gco),e(dh,hco),e(dh,nI),e(nI,pco),e(dh,_co),e(k,uco),e(k,bs),e(bs,dle),e(dle,bco),e(bs,vco),e(bs,sI),e(sI,Fco),e(bs,Tco),e(bs,lI),e(lI,Mco),e(bs,Eco),e(k,Cco),e(k,ch),e(ch,cle),e(cle,wco),e(ch,Aco),e(ch,iI),e(iI,Lco),e(ch,yco),e(k,xco),e(k,fh),e(fh,fle),e(fle,$co),e(fh,kco),e(fh,dI),e(dI,Sco),e(fh,Rco),e(k,Pco),e(k,vs),e(vs,mle),e(mle,Bco),e(vs,Ico),e(vs,cI),e(cI,Nco),e(vs,qco),e(vs,fI),e(fI,jco),e(vs,Dco),e(k,Gco),e(k,Fs),e(Fs,gle),e(gle,Oco),e(Fs,Vco),e(Fs,mI),e(mI,Xco),e(Fs,zco),e(Fs,gI),e(gI,Wco),e(Fs,Qco),e(k,Hco),e(k,Ts),e(Ts,hle),e(hle,Uco),e(Ts,Jco),e(Ts,hI),e(hI,Yco),e(Ts,Kco),e(Ts,pI),e(pI,Zco),e(Ts,efo),e(k,ofo),e(k,mh),e(mh,ple),e(ple,rfo),e(mh,tfo),e(mh,_I),e(_I,afo),e(mh,nfo),e(k,sfo),e(k,Ms),e(Ms,_le),e(_le,lfo),e(Ms,ifo),e(Ms,uI),e(uI,dfo),e(Ms,cfo),e(Ms,bI),e(bI,ffo),e(Ms,mfo),e(k,gfo),e(k,Es),e(Es,ule),e(ule,hfo),e(Es,pfo),e(Es,vI),e(vI,_fo),e(Es,ufo),e(Es,FI),e(FI,bfo),e(Es,vfo),e(k,Ffo),e(k,Cs),e(Cs,ble),e(ble,Tfo),e(Cs,Mfo),e(Cs,TI),e(TI,Efo),e(Cs,Cfo),e(Cs,MI),e(MI,wfo),e(Cs,Afo),e(k,Lfo),e(k,ws),e(ws,vle),e(vle,yfo),e(ws,xfo),e(ws,EI),e(EI,$fo),e(ws,kfo),e(ws,CI),e(CI,Sfo),e(ws,Rfo),e(k,Pfo),e(k,As),e(As,Fle),e(Fle,Bfo),e(As,Ifo),e(As,wI),e(wI,Nfo),e(As,qfo),e(As,AI),e(AI,jfo),e(As,Dfo),e(k,Gfo),e(k,Ls),e(Ls,Tle),e(Tle,Ofo),e(Ls,Vfo),e(Ls,LI),e(LI,Xfo),e(Ls,zfo),e(Ls,yI),e(yI,Wfo),e(Ls,Qfo),e(k,Hfo),e(k,gh),e(gh,Mle),e(Mle,Ufo),e(gh,Jfo),e(gh,xI),e(xI,Yfo),e(gh,Kfo),e(k,Zfo),e(k,ys),e(ys,Ele),e(Ele,emo),e(ys,omo),e(ys,$I),e($I,rmo),e(ys,tmo),e(ys,kI),e(kI,amo),e(ys,nmo),e(k,smo),e(k,hh),e(hh,Cle),e(Cle,lmo),e(hh,imo),e(hh,SI),e(SI,dmo),e(hh,cmo),e(k,fmo),e(k,ph),e(ph,wle),e(wle,mmo),e(ph,gmo),e(ph,RI),e(RI,hmo),e(ph,pmo),e(k,_mo),e(k,_h),e(_h,Ale),e(Ale,umo),e(_h,bmo),e(_h,PI),e(PI,vmo),e(_h,Fmo),e(k,Tmo),e(k,uh),e(uh,Lle),e(Lle,Mmo),e(uh,Emo),e(uh,BI),e(BI,Cmo),e(uh,wmo),e(k,Amo),e(k,xs),e(xs,yle),e(yle,Lmo),e(xs,ymo),e(xs,II),e(II,xmo),e(xs,$mo),e(xs,NI),e(NI,kmo),e(xs,Smo),e(k,Rmo),e(k,bh),e(bh,xle),e(xle,Pmo),e(bh,Bmo),e(bh,qI),e(qI,Imo),e(bh,Nmo),e(k,qmo),e(k,$s),e($s,$le),e($le,jmo),e($s,Dmo),e($s,jI),e(jI,Gmo),e($s,Omo),e($s,DI),e(DI,Vmo),e($s,Xmo),e(k,zmo),e(k,ks),e(ks,kle),e(kle,Wmo),e(ks,Qmo),e(ks,GI),e(GI,Hmo),e(ks,Umo),e(ks,OI),e(OI,Jmo),e(ks,Ymo),e(k,Kmo),e(k,Ss),e(Ss,Sle),e(Sle,Zmo),e(Ss,ego),e(Ss,VI),e(VI,ogo),e(Ss,rgo),e(Ss,XI),e(XI,tgo),e(Ss,ago),e(k,ngo),e(k,Rs),e(Rs,Rle),e(Rle,sgo),e(Rs,lgo),e(Rs,zI),e(zI,igo),e(Rs,dgo),e(Rs,WI),e(WI,cgo),e(Rs,fgo),e(k,mgo),e(k,Ps),e(Ps,Ple),e(Ple,ggo),e(Ps,hgo),e(Ps,QI),e(QI,pgo),e(Ps,_go),e(Ps,HI),e(HI,ugo),e(Ps,bgo),e(k,vgo),e(k,Bs),e(Bs,Ble),e(Ble,Fgo),e(Bs,Tgo),e(Bs,UI),e(UI,Mgo),e(Bs,Ego),e(Bs,JI),e(JI,Cgo),e(Bs,wgo),e(k,Ago),e(k,vh),e(vh,Ile),e(Ile,Lgo),e(vh,ygo),e(vh,YI),e(YI,xgo),e(vh,$go),e(k,kgo),e(k,Fh),e(Fh,Nle),e(Nle,Sgo),e(Fh,Rgo),e(Fh,KI),e(KI,Pgo),e(Fh,Bgo),e(k,Igo),e(k,Is),e(Is,qle),e(qle,Ngo),e(Is,qgo),e(Is,ZI),e(ZI,jgo),e(Is,Dgo),e(Is,eN),e(eN,Ggo),e(Is,Ogo),e(k,Vgo),e(k,Ns),e(Ns,jle),e(jle,Xgo),e(Ns,zgo),e(Ns,oN),e(oN,Wgo),e(Ns,Qgo),e(Ns,rN),e(rN,Hgo),e(Ns,Ugo),e(k,Jgo),e(k,qs),e(qs,Dle),e(Dle,Ygo),e(qs,Kgo),e(qs,tN),e(tN,Zgo),e(qs,eho),e(qs,aN),e(aN,oho),e(qs,rho),e(k,tho),e(k,Th),e(Th,Gle),e(Gle,aho),e(Th,nho),e(Th,nN),e(nN,sho),e(Th,lho),e(k,iho),e(k,Mh),e(Mh,Ole),e(Ole,dho),e(Mh,cho),e(Mh,sN),e(sN,fho),e(Mh,mho),e(k,gho),e(k,Eh),e(Eh,Vle),e(Vle,hho),e(Eh,pho),e(Eh,lN),e(lN,_ho),e(Eh,uho),e(k,bho),e(k,js),e(js,Xle),e(Xle,vho),e(js,Fho),e(js,iN),e(iN,Tho),e(js,Mho),e(js,dN),e(dN,Eho),e(js,Cho),e(k,who),e(k,Ds),e(Ds,zle),e(zle,Aho),e(Ds,Lho),e(Ds,cN),e(cN,yho),e(Ds,xho),e(Ds,fN),e(fN,$ho),e(Ds,kho),e(k,Sho),e(k,Ch),e(Ch,Wle),e(Wle,Rho),e(Ch,Pho),e(Ch,mN),e(mN,Bho),e(Ch,Iho),e(k,Nho),e(k,wh),e(wh,Qle),e(Qle,qho),e(wh,jho),e(wh,gN),e(gN,Dho),e(wh,Gho),e(k,Oho),e(k,Ah),e(Ah,Hle),e(Hle,Vho),e(Ah,Xho),e(Ah,hN),e(hN,zho),e(Ah,Who),e(k,Qho),e(k,Gs),e(Gs,Ule),e(Ule,Hho),e(Gs,Uho),e(Gs,pN),e(pN,Jho),e(Gs,Yho),e(Gs,_N),e(_N,Kho),e(Gs,Zho),e(k,epo),e(k,Lh),e(Lh,Jle),e(Jle,opo),e(Lh,rpo),e(Lh,uN),e(uN,tpo),e(Lh,apo),e(k,npo),e(k,yh),e(yh,Yle),e(Yle,spo),e(yh,lpo),e(yh,bN),e(bN,ipo),e(yh,dpo),e(k,cpo),e(k,Os),e(Os,Kle),e(Kle,fpo),e(Os,mpo),e(Os,vN),e(vN,gpo),e(Os,hpo),e(Os,FN),e(FN,ppo),e(Os,_po),e(k,upo),e(k,Vs),e(Vs,Zle),e(Zle,bpo),e(Vs,vpo),e(Vs,TN),e(TN,Fpo),e(Vs,Tpo),e(Vs,MN),e(MN,Mpo),e(Vs,Epo),e(k,Cpo),e(k,Xs),e(Xs,eie),e(eie,wpo),e(Xs,Apo),e(Xs,EN),e(EN,Lpo),e(Xs,ypo),e(Xs,CN),e(CN,xpo),e(Xs,$po),e(k,kpo),e(k,zs),e(zs,oie),e(oie,Spo),e(zs,Rpo),e(zs,wN),e(wN,Ppo),e(zs,Bpo),e(zs,AN),e(AN,Ipo),e(zs,Npo),e(yr,qpo),M(xh,yr,null),e(Ao,jpo),e(Ao,$h),M(oL,$h,null),e($h,Dpo),e($h,rie),e(rie,Gpo),b(f,UOe,u),b(f,Ii,u),e(Ii,kh),e(kh,tie),M(rL,tie,null),e(Ii,Opo),e(Ii,aie),e(aie,Vpo),b(f,JOe,u),b(f,Lo,u),M(tL,Lo,null),e(Lo,Xpo),e(Lo,aL),e(aL,zpo),e(aL,LN),e(LN,Wpo),e(aL,Qpo),e(Lo,Hpo),e(Lo,nL),e(nL,Upo),e(nL,nie),e(nie,Jpo),e(nL,Ypo),e(Lo,Kpo),e(Lo,He),M(sL,He,null),e(He,Zpo),e(He,sie),e(sie,e_o),e(He,o_o),e(He,Pa),e(Pa,r_o),e(Pa,lie),e(lie,t_o),e(Pa,a_o),e(Pa,iie),e(iie,n_o),e(Pa,s_o),e(Pa,die),e(die,l_o),e(Pa,i_o),e(He,d_o),e(He,Y),e(Y,Sh),e(Sh,cie),e(cie,c_o),e(Sh,f_o),e(Sh,yN),e(yN,m_o),e(Sh,g_o),e(Y,h_o),e(Y,Rh),e(Rh,fie),e(fie,p_o),e(Rh,__o),e(Rh,xN),e(xN,u_o),e(Rh,b_o),e(Y,v_o),e(Y,Ph),e(Ph,mie),e(mie,F_o),e(Ph,T_o),e(Ph,$N),e($N,M_o),e(Ph,E_o),e(Y,C_o),e(Y,Bh),e(Bh,gie),e(gie,w_o),e(Bh,A_o),e(Bh,kN),e(kN,L_o),e(Bh,y_o),e(Y,x_o),e(Y,Ih),e(Ih,hie),e(hie,$_o),e(Ih,k_o),e(Ih,SN),e(SN,S_o),e(Ih,R_o),e(Y,P_o),e(Y,Nh),e(Nh,pie),e(pie,B_o),e(Nh,I_o),e(Nh,RN),e(RN,N_o),e(Nh,q_o),e(Y,j_o),e(Y,qh),e(qh,_ie),e(_ie,D_o),e(qh,G_o),e(qh,PN),e(PN,O_o),e(qh,V_o),e(Y,X_o),e(Y,jh),e(jh,uie),e(uie,z_o),e(jh,W_o),e(jh,BN),e(BN,Q_o),e(jh,H_o),e(Y,U_o),e(Y,Dh),e(Dh,bie),e(bie,J_o),e(Dh,Y_o),e(Dh,IN),e(IN,K_o),e(Dh,Z_o),e(Y,euo),e(Y,Gh),e(Gh,vie),e(vie,ouo),e(Gh,ruo),e(Gh,NN),e(NN,tuo),e(Gh,auo),e(Y,nuo),e(Y,Oh),e(Oh,Fie),e(Fie,suo),e(Oh,luo),e(Oh,qN),e(qN,iuo),e(Oh,duo),e(Y,cuo),e(Y,Vh),e(Vh,Tie),e(Tie,fuo),e(Vh,muo),e(Vh,jN),e(jN,guo),e(Vh,huo),e(Y,puo),e(Y,Xh),e(Xh,Mie),e(Mie,_uo),e(Xh,uuo),e(Xh,DN),e(DN,buo),e(Xh,vuo),e(Y,Fuo),e(Y,zh),e(zh,Eie),e(Eie,Tuo),e(zh,Muo),e(zh,GN),e(GN,Euo),e(zh,Cuo),e(Y,wuo),e(Y,Wh),e(Wh,Cie),e(Cie,Auo),e(Wh,Luo),e(Wh,ON),e(ON,yuo),e(Wh,xuo),e(Y,$uo),e(Y,Qh),e(Qh,wie),e(wie,kuo),e(Qh,Suo),e(Qh,VN),e(VN,Ruo),e(Qh,Puo),e(Y,Buo),e(Y,Hh),e(Hh,Aie),e(Aie,Iuo),e(Hh,Nuo),e(Hh,XN),e(XN,quo),e(Hh,juo),e(Y,Duo),e(Y,Uh),e(Uh,Lie),e(Lie,Guo),e(Uh,Ouo),e(Uh,zN),e(zN,Vuo),e(Uh,Xuo),e(Y,zuo),e(Y,Jh),e(Jh,yie),e(yie,Wuo),e(Jh,Quo),e(Jh,WN),e(WN,Huo),e(Jh,Uuo),e(Y,Juo),e(Y,Yh),e(Yh,xie),e(xie,Yuo),e(Yh,Kuo),e(Yh,QN),e(QN,Zuo),e(Yh,e1o),e(Y,o1o),e(Y,Kh),e(Kh,$ie),e($ie,r1o),e(Kh,t1o),e(Kh,HN),e(HN,a1o),e(Kh,n1o),e(Y,s1o),e(Y,Zh),e(Zh,kie),e(kie,l1o),e(Zh,i1o),e(Zh,UN),e(UN,d1o),e(Zh,c1o),e(Y,f1o),e(Y,ep),e(ep,Sie),e(Sie,m1o),e(ep,g1o),e(ep,JN),e(JN,h1o),e(ep,p1o),e(Y,_1o),e(Y,op),e(op,Rie),e(Rie,u1o),e(op,b1o),e(op,YN),e(YN,v1o),e(op,F1o),e(Y,T1o),e(Y,rp),e(rp,Pie),e(Pie,M1o),e(rp,E1o),e(rp,KN),e(KN,C1o),e(rp,w1o),e(Y,A1o),e(Y,tp),e(tp,Bie),e(Bie,L1o),e(tp,y1o),e(tp,ZN),e(ZN,x1o),e(tp,$1o),e(Y,k1o),e(Y,ap),e(ap,Iie),e(Iie,S1o),e(ap,R1o),e(ap,eq),e(eq,P1o),e(ap,B1o),e(Y,I1o),e(Y,np),e(np,Nie),e(Nie,N1o),e(np,q1o),e(np,oq),e(oq,j1o),e(np,D1o),e(Y,G1o),e(Y,sp),e(sp,qie),e(qie,O1o),e(sp,V1o),e(sp,rq),e(rq,X1o),e(sp,z1o),e(Y,W1o),e(Y,lp),e(lp,jie),e(jie,Q1o),e(lp,H1o),e(lp,tq),e(tq,U1o),e(lp,J1o),e(Y,Y1o),e(Y,ip),e(ip,Die),e(Die,K1o),e(ip,Z1o),e(ip,aq),e(aq,e2o),e(ip,o2o),e(Y,r2o),e(Y,dp),e(dp,Gie),e(Gie,t2o),e(dp,a2o),e(dp,nq),e(nq,n2o),e(dp,s2o),e(Y,l2o),e(Y,cp),e(cp,Oie),e(Oie,i2o),e(cp,d2o),e(cp,sq),e(sq,c2o),e(cp,f2o),e(He,m2o),M(fp,He,null),e(He,g2o),M(mp,He,null),e(Lo,h2o),e(Lo,gp),M(lL,gp,null),e(gp,p2o),e(gp,Vie),e(Vie,_2o),b(f,YOe,u),b(f,Ni,u),e(Ni,hp),e(hp,Xie),M(iL,Xie,null),e(Ni,u2o),e(Ni,zie),e(zie,b2o),b(f,KOe,u),b(f,yo,u),M(dL,yo,null),e(yo,v2o),e(yo,cL),e(cL,F2o),e(cL,lq),e(lq,T2o),e(cL,M2o),e(yo,E2o),e(yo,fL),e(fL,C2o),e(fL,Wie),e(Wie,w2o),e(fL,A2o),e(yo,L2o),e(yo,Ue),M(mL,Ue,null),e(Ue,y2o),e(Ue,Qie),e(Qie,x2o),e(Ue,$2o),e(Ue,qi),e(qi,k2o),e(qi,Hie),e(Hie,S2o),e(qi,R2o),e(qi,Uie),e(Uie,P2o),e(qi,B2o),e(Ue,I2o),e(Ue,he),e(he,pp),e(pp,Jie),e(Jie,N2o),e(pp,q2o),e(pp,iq),e(iq,j2o),e(pp,D2o),e(he,G2o),e(he,_p),e(_p,Yie),e(Yie,O2o),e(_p,V2o),e(_p,Kie),e(Kie,X2o),e(_p,z2o),e(he,W2o),e(he,up),e(up,Zie),e(Zie,Q2o),e(up,H2o),e(up,dq),e(dq,U2o),e(up,J2o),e(he,Y2o),e(he,bp),e(bp,ede),e(ede,K2o),e(bp,Z2o),e(bp,cq),e(cq,ebo),e(bp,obo),e(he,rbo),e(he,vp),e(vp,ode),e(ode,tbo),e(vp,abo),e(vp,fq),e(fq,nbo),e(vp,sbo),e(he,lbo),e(he,Fp),e(Fp,rde),e(rde,ibo),e(Fp,dbo),e(Fp,mq),e(mq,cbo),e(Fp,fbo),e(he,mbo),e(he,Tp),e(Tp,tde),e(tde,gbo),e(Tp,hbo),e(Tp,gq),e(gq,pbo),e(Tp,_bo),e(he,ubo),e(he,Mp),e(Mp,ade),e(ade,bbo),e(Mp,vbo),e(Mp,hq),e(hq,Fbo),e(Mp,Tbo),e(he,Mbo),e(he,Ep),e(Ep,nde),e(nde,Ebo),e(Ep,Cbo),e(Ep,pq),e(pq,wbo),e(Ep,Abo),e(he,Lbo),e(he,Cp),e(Cp,sde),e(sde,ybo),e(Cp,xbo),e(Cp,_q),e(_q,$bo),e(Cp,kbo),e(he,Sbo),e(he,wp),e(wp,lde),e(lde,Rbo),e(wp,Pbo),e(wp,uq),e(uq,Bbo),e(wp,Ibo),e(he,Nbo),e(he,Ap),e(Ap,ide),e(ide,qbo),e(Ap,jbo),e(Ap,bq),e(bq,Dbo),e(Ap,Gbo),e(he,Obo),e(he,Lp),e(Lp,dde),e(dde,Vbo),e(Lp,Xbo),e(Lp,vq),e(vq,zbo),e(Lp,Wbo),e(he,Qbo),e(he,yp),e(yp,cde),e(cde,Hbo),e(yp,Ubo),e(yp,Fq),e(Fq,Jbo),e(yp,Ybo),e(he,Kbo),e(he,xp),e(xp,fde),e(fde,Zbo),e(xp,evo),e(xp,Tq),e(Tq,ovo),e(xp,rvo),e(he,tvo),e(he,$p),e($p,mde),e(mde,avo),e($p,nvo),e($p,Mq),e(Mq,svo),e($p,lvo),e(he,ivo),e(he,kp),e(kp,gde),e(gde,dvo),e(kp,cvo),e(kp,Eq),e(Eq,fvo),e(kp,mvo),e(he,gvo),e(he,Sp),e(Sp,hde),e(hde,hvo),e(Sp,pvo),e(Sp,Cq),e(Cq,_vo),e(Sp,uvo),e(Ue,bvo),M(Rp,Ue,null),e(Ue,vvo),M(Pp,Ue,null),e(yo,Fvo),e(yo,Bp),M(gL,Bp,null),e(Bp,Tvo),e(Bp,pde),e(pde,Mvo),b(f,ZOe,u),b(f,ji,u),e(ji,Ip),e(Ip,_de),M(hL,_de,null),e(ji,Evo),e(ji,ude),e(ude,Cvo),b(f,eVe,u),b(f,xo,u),M(pL,xo,null),e(xo,wvo),e(xo,Di),e(Di,Avo),e(Di,wq),e(wq,Lvo),e(Di,yvo),e(Di,Aq),e(Aq,xvo),e(Di,$vo),e(xo,kvo),e(xo,_L),e(_L,Svo),e(_L,bde),e(bde,Rvo),e(_L,Pvo),e(xo,Bvo),e(xo,st),M(uL,st,null),e(st,Ivo),e(st,vde),e(vde,Nvo),e(st,qvo),e(st,Gi),e(Gi,jvo),e(Gi,Fde),e(Fde,Dvo),e(Gi,Gvo),e(Gi,Lq),e(Lq,Ovo),e(Gi,Vvo),e(st,Xvo),M(Np,st,null),e(xo,zvo),e(xo,Je),M(bL,Je,null),e(Je,Wvo),e(Je,Tde),e(Tde,Qvo),e(Je,Hvo),e(Je,Ba),e(Ba,Uvo),e(Ba,Mde),e(Mde,Jvo),e(Ba,Yvo),e(Ba,Ede),e(Ede,Kvo),e(Ba,Zvo),e(Ba,Cde),e(Cde,e0o),e(Ba,o0o),e(Je,r0o),e(Je,y),e(y,qp),e(qp,wde),e(wde,t0o),e(qp,a0o),e(qp,yq),e(yq,n0o),e(qp,s0o),e(y,l0o),e(y,jp),e(jp,Ade),e(Ade,i0o),e(jp,d0o),e(jp,xq),e(xq,c0o),e(jp,f0o),e(y,m0o),e(y,Dp),e(Dp,Lde),e(Lde,g0o),e(Dp,h0o),e(Dp,$q),e($q,p0o),e(Dp,_0o),e(y,u0o),e(y,Gp),e(Gp,yde),e(yde,b0o),e(Gp,v0o),e(Gp,kq),e(kq,F0o),e(Gp,T0o),e(y,M0o),e(y,Op),e(Op,xde),e(xde,E0o),e(Op,C0o),e(Op,Sq),e(Sq,w0o),e(Op,A0o),e(y,L0o),e(y,Vp),e(Vp,$de),e($de,y0o),e(Vp,x0o),e(Vp,Rq),e(Rq,$0o),e(Vp,k0o),e(y,S0o),e(y,Xp),e(Xp,kde),e(kde,R0o),e(Xp,P0o),e(Xp,Pq),e(Pq,B0o),e(Xp,I0o),e(y,N0o),e(y,zp),e(zp,Sde),e(Sde,q0o),e(zp,j0o),e(zp,Bq),e(Bq,D0o),e(zp,G0o),e(y,O0o),e(y,Wp),e(Wp,Rde),e(Rde,V0o),e(Wp,X0o),e(Wp,Iq),e(Iq,z0o),e(Wp,W0o),e(y,Q0o),e(y,Qp),e(Qp,Pde),e(Pde,H0o),e(Qp,U0o),e(Qp,Nq),e(Nq,J0o),e(Qp,Y0o),e(y,K0o),e(y,Hp),e(Hp,Bde),e(Bde,Z0o),e(Hp,eFo),e(Hp,qq),e(qq,oFo),e(Hp,rFo),e(y,tFo),e(y,Up),e(Up,Ide),e(Ide,aFo),e(Up,nFo),e(Up,jq),e(jq,sFo),e(Up,lFo),e(y,iFo),e(y,Jp),e(Jp,Nde),e(Nde,dFo),e(Jp,cFo),e(Jp,Dq),e(Dq,fFo),e(Jp,mFo),e(y,gFo),e(y,Yp),e(Yp,qde),e(qde,hFo),e(Yp,pFo),e(Yp,Gq),e(Gq,_Fo),e(Yp,uFo),e(y,bFo),e(y,Kp),e(Kp,jde),e(jde,vFo),e(Kp,FFo),e(Kp,Oq),e(Oq,TFo),e(Kp,MFo),e(y,EFo),e(y,Zp),e(Zp,Dde),e(Dde,CFo),e(Zp,wFo),e(Zp,Vq),e(Vq,AFo),e(Zp,LFo),e(y,yFo),e(y,e_),e(e_,Gde),e(Gde,xFo),e(e_,$Fo),e(e_,Xq),e(Xq,kFo),e(e_,SFo),e(y,RFo),e(y,o_),e(o_,Ode),e(Ode,PFo),e(o_,BFo),e(o_,zq),e(zq,IFo),e(o_,NFo),e(y,qFo),e(y,r_),e(r_,Vde),e(Vde,jFo),e(r_,DFo),e(r_,Wq),e(Wq,GFo),e(r_,OFo),e(y,VFo),e(y,t_),e(t_,Xde),e(Xde,XFo),e(t_,zFo),e(t_,Qq),e(Qq,WFo),e(t_,QFo),e(y,HFo),e(y,a_),e(a_,zde),e(zde,UFo),e(a_,JFo),e(a_,Hq),e(Hq,YFo),e(a_,KFo),e(y,ZFo),e(y,n_),e(n_,Wde),e(Wde,e6o),e(n_,o6o),e(n_,Uq),e(Uq,r6o),e(n_,t6o),e(y,a6o),e(y,s_),e(s_,Qde),e(Qde,n6o),e(s_,s6o),e(s_,Jq),e(Jq,l6o),e(s_,i6o),e(y,d6o),e(y,l_),e(l_,Hde),e(Hde,c6o),e(l_,f6o),e(l_,Yq),e(Yq,m6o),e(l_,g6o),e(y,h6o),e(y,i_),e(i_,Ude),e(Ude,p6o),e(i_,_6o),e(i_,Kq),e(Kq,u6o),e(i_,b6o),e(y,v6o),e(y,d_),e(d_,Jde),e(Jde,F6o),e(d_,T6o),e(d_,Zq),e(Zq,M6o),e(d_,E6o),e(y,C6o),e(y,c_),e(c_,Yde),e(Yde,w6o),e(c_,A6o),e(c_,ej),e(ej,L6o),e(c_,y6o),e(y,x6o),e(y,f_),e(f_,Kde),e(Kde,$6o),e(f_,k6o),e(f_,oj),e(oj,S6o),e(f_,R6o),e(y,P6o),e(y,m_),e(m_,Zde),e(Zde,B6o),e(m_,I6o),e(m_,rj),e(rj,N6o),e(m_,q6o),e(y,j6o),e(y,g_),e(g_,ece),e(ece,D6o),e(g_,G6o),e(g_,tj),e(tj,O6o),e(g_,V6o),e(y,X6o),e(y,h_),e(h_,oce),e(oce,z6o),e(h_,W6o),e(h_,aj),e(aj,Q6o),e(h_,H6o),e(y,U6o),e(y,p_),e(p_,rce),e(rce,J6o),e(p_,Y6o),e(p_,nj),e(nj,K6o),e(p_,Z6o),e(y,eTo),e(y,__),e(__,tce),e(tce,oTo),e(__,rTo),e(__,sj),e(sj,tTo),e(__,aTo),e(y,nTo),e(y,u_),e(u_,ace),e(ace,sTo),e(u_,lTo),e(u_,lj),e(lj,iTo),e(u_,dTo),e(y,cTo),e(y,Ws),e(Ws,nce),e(nce,fTo),e(Ws,mTo),e(Ws,ij),e(ij,gTo),e(Ws,hTo),e(Ws,dj),e(dj,pTo),e(Ws,_To),e(y,uTo),e(y,b_),e(b_,sce),e(sce,bTo),e(b_,vTo),e(b_,cj),e(cj,FTo),e(b_,TTo),e(y,MTo),e(y,v_),e(v_,lce),e(lce,ETo),e(v_,CTo),e(v_,fj),e(fj,wTo),e(v_,ATo),e(y,LTo),e(y,F_),e(F_,ice),e(ice,yTo),e(F_,xTo),e(F_,mj),e(mj,$To),e(F_,kTo),e(y,STo),e(y,T_),e(T_,dce),e(dce,RTo),e(T_,PTo),e(T_,gj),e(gj,BTo),e(T_,ITo),e(y,NTo),e(y,M_),e(M_,cce),e(cce,qTo),e(M_,jTo),e(M_,hj),e(hj,DTo),e(M_,GTo),e(y,OTo),e(y,E_),e(E_,fce),e(fce,VTo),e(E_,XTo),e(E_,pj),e(pj,zTo),e(E_,WTo),e(y,QTo),e(y,C_),e(C_,mce),e(mce,HTo),e(C_,UTo),e(C_,_j),e(_j,JTo),e(C_,YTo),e(y,KTo),e(y,w_),e(w_,gce),e(gce,ZTo),e(w_,e7o),e(w_,uj),e(uj,o7o),e(w_,r7o),e(y,t7o),e(y,A_),e(A_,hce),e(hce,a7o),e(A_,n7o),e(A_,bj),e(bj,s7o),e(A_,l7o),e(y,i7o),e(y,L_),e(L_,pce),e(pce,d7o),e(L_,c7o),e(L_,vj),e(vj,f7o),e(L_,m7o),e(y,g7o),e(y,y_),e(y_,_ce),e(_ce,h7o),e(y_,p7o),e(y_,Fj),e(Fj,_7o),e(y_,u7o),e(y,b7o),e(y,x_),e(x_,uce),e(uce,v7o),e(x_,F7o),e(x_,Tj),e(Tj,T7o),e(x_,M7o),e(y,E7o),e(y,$_),e($_,bce),e(bce,C7o),e($_,w7o),e($_,Mj),e(Mj,A7o),e($_,L7o),e(y,y7o),e(y,k_),e(k_,vce),e(vce,x7o),e(k_,$7o),e(k_,Ej),e(Ej,k7o),e(k_,S7o),e(y,R7o),e(y,S_),e(S_,Fce),e(Fce,P7o),e(S_,B7o),e(S_,Cj),e(Cj,I7o),e(S_,N7o),e(y,q7o),e(y,R_),e(R_,Tce),e(Tce,j7o),e(R_,D7o),e(R_,wj),e(wj,G7o),e(R_,O7o),e(y,V7o),e(y,P_),e(P_,Mce),e(Mce,X7o),e(P_,z7o),e(P_,Aj),e(Aj,W7o),e(P_,Q7o),e(y,H7o),e(y,B_),e(B_,Ece),e(Ece,U7o),e(B_,J7o),e(B_,Lj),e(Lj,Y7o),e(B_,K7o),e(y,Z7o),e(y,I_),e(I_,Cce),e(Cce,e8o),e(I_,o8o),e(I_,yj),e(yj,r8o),e(I_,t8o),e(y,a8o),e(y,N_),e(N_,wce),e(wce,n8o),e(N_,s8o),e(N_,xj),e(xj,l8o),e(N_,i8o),e(y,d8o),e(y,q_),e(q_,Ace),e(Ace,c8o),e(q_,f8o),e(q_,$j),e($j,m8o),e(q_,g8o),e(y,h8o),e(y,j_),e(j_,Lce),e(Lce,p8o),e(j_,_8o),e(j_,kj),e(kj,u8o),e(j_,b8o),e(y,v8o),e(y,D_),e(D_,yce),e(yce,F8o),e(D_,T8o),e(D_,Sj),e(Sj,M8o),e(D_,E8o),e(y,C8o),e(y,G_),e(G_,xce),e(xce,w8o),e(G_,A8o),e(G_,Rj),e(Rj,L8o),e(G_,y8o),e(y,x8o),e(y,O_),e(O_,$ce),e($ce,$8o),e(O_,k8o),e(O_,Pj),e(Pj,S8o),e(O_,R8o),e(y,P8o),e(y,V_),e(V_,kce),e(kce,B8o),e(V_,I8o),e(V_,Bj),e(Bj,N8o),e(V_,q8o),e(y,j8o),e(y,X_),e(X_,Sce),e(Sce,D8o),e(X_,G8o),e(X_,Ij),e(Ij,O8o),e(X_,V8o),e(y,X8o),e(y,z_),e(z_,Rce),e(Rce,z8o),e(z_,W8o),e(z_,Nj),e(Nj,Q8o),e(z_,H8o),e(y,U8o),e(y,W_),e(W_,Pce),e(Pce,J8o),e(W_,Y8o),e(W_,qj),e(qj,K8o),e(W_,Z8o),e(y,eMo),e(y,Q_),e(Q_,Bce),e(Bce,oMo),e(Q_,rMo),e(Q_,jj),e(jj,tMo),e(Q_,aMo),e(y,nMo),e(y,H_),e(H_,Ice),e(Ice,sMo),e(H_,lMo),e(H_,Dj),e(Dj,iMo),e(H_,dMo),e(y,cMo),e(y,U_),e(U_,Nce),e(Nce,fMo),e(U_,mMo),e(U_,Gj),e(Gj,gMo),e(U_,hMo),e(y,pMo),e(y,J_),e(J_,qce),e(qce,_Mo),e(J_,uMo),e(J_,Oj),e(Oj,bMo),e(J_,vMo),e(y,FMo),e(y,Y_),e(Y_,jce),e(jce,TMo),e(Y_,MMo),e(Y_,Vj),e(Vj,EMo),e(Y_,CMo),e(y,wMo),e(y,K_),e(K_,Dce),e(Dce,AMo),e(K_,LMo),e(K_,Xj),e(Xj,yMo),e(K_,xMo),e(y,$Mo),e(y,Z_),e(Z_,Gce),e(Gce,kMo),e(Z_,SMo),e(Z_,zj),e(zj,RMo),e(Z_,PMo),e(y,BMo),e(y,eu),e(eu,Oce),e(Oce,IMo),e(eu,NMo),e(eu,Wj),e(Wj,qMo),e(eu,jMo),e(y,DMo),e(y,ou),e(ou,Vce),e(Vce,GMo),e(ou,OMo),e(ou,Qj),e(Qj,VMo),e(ou,XMo),e(y,zMo),e(y,ru),e(ru,Xce),e(Xce,WMo),e(ru,QMo),e(ru,Hj),e(Hj,HMo),e(ru,UMo),e(y,JMo),e(y,tu),e(tu,zce),e(zce,YMo),e(tu,KMo),e(tu,Uj),e(Uj,ZMo),e(tu,e4o),e(y,o4o),e(y,au),e(au,Wce),e(Wce,r4o),e(au,t4o),e(au,Jj),e(Jj,a4o),e(au,n4o),e(y,s4o),e(y,nu),e(nu,Qce),e(Qce,l4o),e(nu,i4o),e(nu,Yj),e(Yj,d4o),e(nu,c4o),e(y,f4o),e(y,su),e(su,Hce),e(Hce,m4o),e(su,g4o),e(su,Kj),e(Kj,h4o),e(su,p4o),e(y,_4o),e(y,lu),e(lu,Uce),e(Uce,u4o),e(lu,b4o),e(lu,Zj),e(Zj,v4o),e(lu,F4o),e(y,T4o),e(y,iu),e(iu,Jce),e(Jce,M4o),e(iu,E4o),e(iu,eD),e(eD,C4o),e(iu,w4o),e(y,A4o),e(y,du),e(du,Yce),e(Yce,L4o),e(du,y4o),e(du,oD),e(oD,x4o),e(du,$4o),e(y,k4o),e(y,cu),e(cu,Kce),e(Kce,S4o),e(cu,R4o),e(cu,rD),e(rD,P4o),e(cu,B4o),e(y,I4o),e(y,fu),e(fu,Zce),e(Zce,N4o),e(fu,q4o),e(fu,tD),e(tD,j4o),e(fu,D4o),e(y,G4o),e(y,mu),e(mu,efe),e(efe,O4o),e(mu,V4o),e(mu,aD),e(aD,X4o),e(mu,z4o),e(y,W4o),e(y,gu),e(gu,ofe),e(ofe,Q4o),e(gu,H4o),e(gu,nD),e(nD,U4o),e(gu,J4o),e(y,Y4o),e(y,hu),e(hu,rfe),e(rfe,K4o),e(hu,Z4o),e(hu,sD),e(sD,eEo),e(hu,oEo),e(y,rEo),e(y,pu),e(pu,tfe),e(tfe,tEo),e(pu,aEo),e(pu,lD),e(lD,nEo),e(pu,sEo),e(y,lEo),e(y,_u),e(_u,afe),e(afe,iEo),e(_u,dEo),e(_u,iD),e(iD,cEo),e(_u,fEo),e(y,mEo),e(y,uu),e(uu,nfe),e(nfe,gEo),e(uu,hEo),e(uu,dD),e(dD,pEo),e(uu,_Eo),e(y,uEo),e(y,bu),e(bu,sfe),e(sfe,bEo),e(bu,vEo),e(bu,cD),e(cD,FEo),e(bu,TEo),e(y,MEo),e(y,vu),e(vu,lfe),e(lfe,EEo),e(vu,CEo),e(vu,fD),e(fD,wEo),e(vu,AEo),e(y,LEo),e(y,Fu),e(Fu,ife),e(ife,yEo),e(Fu,xEo),e(Fu,mD),e(mD,$Eo),e(Fu,kEo),e(y,SEo),e(y,Tu),e(Tu,dfe),e(dfe,REo),e(Tu,PEo),e(Tu,gD),e(gD,BEo),e(Tu,IEo),e(y,NEo),e(y,Mu),e(Mu,cfe),e(cfe,qEo),e(Mu,jEo),e(Mu,hD),e(hD,DEo),e(Mu,GEo),e(y,OEo),e(y,Eu),e(Eu,ffe),e(ffe,VEo),e(Eu,XEo),e(Eu,pD),e(pD,zEo),e(Eu,WEo),e(y,QEo),e(y,Cu),e(Cu,mfe),e(mfe,HEo),e(Cu,UEo),e(Cu,_D),e(_D,JEo),e(Cu,YEo),e(y,KEo),e(y,wu),e(wu,gfe),e(gfe,ZEo),e(wu,eCo),e(wu,uD),e(uD,oCo),e(wu,rCo),e(y,tCo),e(y,Au),e(Au,hfe),e(hfe,aCo),e(Au,nCo),e(Au,bD),e(bD,sCo),e(Au,lCo),e(y,iCo),e(y,Lu),e(Lu,pfe),e(pfe,dCo),e(Lu,cCo),e(Lu,vD),e(vD,fCo),e(Lu,mCo),e(y,gCo),e(y,yu),e(yu,_fe),e(_fe,hCo),e(yu,pCo),e(yu,FD),e(FD,_Co),e(yu,uCo),e(y,bCo),e(y,xu),e(xu,ufe),e(ufe,vCo),e(xu,FCo),e(xu,TD),e(TD,TCo),e(xu,MCo),e(y,ECo),e(y,$u),e($u,bfe),e(bfe,CCo),e($u,wCo),e($u,MD),e(MD,ACo),e($u,LCo),e(y,yCo),e(y,ku),e(ku,vfe),e(vfe,xCo),e(ku,$Co),e(ku,ED),e(ED,kCo),e(ku,SCo),e(y,RCo),e(y,Su),e(Su,Ffe),e(Ffe,PCo),e(Su,BCo),e(Su,CD),e(CD,ICo),e(Su,NCo),e(y,qCo),e(y,Ru),e(Ru,Tfe),e(Tfe,jCo),e(Ru,DCo),e(Ru,wD),e(wD,GCo),e(Ru,OCo),e(y,VCo),e(y,Pu),e(Pu,Mfe),e(Mfe,XCo),e(Pu,zCo),e(Pu,AD),e(AD,WCo),e(Pu,QCo),e(y,HCo),e(y,Bu),e(Bu,Efe),e(Efe,UCo),e(Bu,JCo),e(Bu,LD),e(LD,YCo),e(Bu,KCo),e(y,ZCo),e(y,Iu),e(Iu,Cfe),e(Cfe,e3o),e(Iu,o3o),e(Iu,yD),e(yD,r3o),e(Iu,t3o),e(y,a3o),e(y,Nu),e(Nu,wfe),e(wfe,n3o),e(Nu,s3o),e(Nu,xD),e(xD,l3o),e(Nu,i3o),e(Je,d3o),e(Je,qu),e(qu,c3o),e(qu,Afe),e(Afe,f3o),e(qu,m3o),e(qu,Lfe),e(Lfe,g3o),e(Je,h3o),M(ju,Je,null),b(f,oVe,u),b(f,Oi,u),e(Oi,Du),e(Du,yfe),M(vL,yfe,null),e(Oi,p3o),e(Oi,xfe),e(xfe,_3o),b(f,rVe,u),b(f,$o,u),M(FL,$o,null),e($o,u3o),e($o,Vi),e(Vi,b3o),e(Vi,$D),e($D,v3o),e(Vi,F3o),e(Vi,kD),e(kD,T3o),e(Vi,M3o),e($o,E3o),e($o,TL),e(TL,C3o),e(TL,$fe),e($fe,w3o),e(TL,A3o),e($o,L3o),e($o,lt),M(ML,lt,null),e(lt,y3o),e(lt,kfe),e(kfe,x3o),e(lt,$3o),e(lt,Xi),e(Xi,k3o),e(Xi,Sfe),e(Sfe,S3o),e(Xi,R3o),e(Xi,SD),e(SD,P3o),e(Xi,B3o),e(lt,I3o),M(Gu,lt,null),e($o,N3o),e($o,Ye),M(EL,Ye,null),e(Ye,q3o),e(Ye,Rfe),e(Rfe,j3o),e(Ye,D3o),e(Ye,Ia),e(Ia,G3o),e(Ia,Pfe),e(Pfe,O3o),e(Ia,V3o),e(Ia,Bfe),e(Bfe,X3o),e(Ia,z3o),e(Ia,Ife),e(Ife,W3o),e(Ia,Q3o),e(Ye,H3o),e(Ye,G),e(G,Ou),e(Ou,Nfe),e(Nfe,U3o),e(Ou,J3o),e(Ou,RD),e(RD,Y3o),e(Ou,K3o),e(G,Z3o),e(G,Vu),e(Vu,qfe),e(qfe,e5o),e(Vu,o5o),e(Vu,PD),e(PD,r5o),e(Vu,t5o),e(G,a5o),e(G,Xu),e(Xu,jfe),e(jfe,n5o),e(Xu,s5o),e(Xu,BD),e(BD,l5o),e(Xu,i5o),e(G,d5o),e(G,zu),e(zu,Dfe),e(Dfe,c5o),e(zu,f5o),e(zu,ID),e(ID,m5o),e(zu,g5o),e(G,h5o),e(G,Wu),e(Wu,Gfe),e(Gfe,p5o),e(Wu,_5o),e(Wu,ND),e(ND,u5o),e(Wu,b5o),e(G,v5o),e(G,Qu),e(Qu,Ofe),e(Ofe,F5o),e(Qu,T5o),e(Qu,qD),e(qD,M5o),e(Qu,E5o),e(G,C5o),e(G,Hu),e(Hu,Vfe),e(Vfe,w5o),e(Hu,A5o),e(Hu,jD),e(jD,L5o),e(Hu,y5o),e(G,x5o),e(G,Uu),e(Uu,Xfe),e(Xfe,$5o),e(Uu,k5o),e(Uu,DD),e(DD,S5o),e(Uu,R5o),e(G,P5o),e(G,Ju),e(Ju,zfe),e(zfe,B5o),e(Ju,I5o),e(Ju,GD),e(GD,N5o),e(Ju,q5o),e(G,j5o),e(G,Yu),e(Yu,Wfe),e(Wfe,D5o),e(Yu,G5o),e(Yu,OD),e(OD,O5o),e(Yu,V5o),e(G,X5o),e(G,Ku),e(Ku,Qfe),e(Qfe,z5o),e(Ku,W5o),e(Ku,VD),e(VD,Q5o),e(Ku,H5o),e(G,U5o),e(G,Zu),e(Zu,Hfe),e(Hfe,J5o),e(Zu,Y5o),e(Zu,XD),e(XD,K5o),e(Zu,Z5o),e(G,ewo),e(G,e1),e(e1,Ufe),e(Ufe,owo),e(e1,rwo),e(e1,zD),e(zD,two),e(e1,awo),e(G,nwo),e(G,o1),e(o1,Jfe),e(Jfe,swo),e(o1,lwo),e(o1,WD),e(WD,iwo),e(o1,dwo),e(G,cwo),e(G,r1),e(r1,Yfe),e(Yfe,fwo),e(r1,mwo),e(r1,QD),e(QD,gwo),e(r1,hwo),e(G,pwo),e(G,t1),e(t1,Kfe),e(Kfe,_wo),e(t1,uwo),e(t1,HD),e(HD,bwo),e(t1,vwo),e(G,Fwo),e(G,a1),e(a1,Zfe),e(Zfe,Two),e(a1,Mwo),e(a1,UD),e(UD,Ewo),e(a1,Cwo),e(G,wwo),e(G,n1),e(n1,eme),e(eme,Awo),e(n1,Lwo),e(n1,JD),e(JD,ywo),e(n1,xwo),e(G,$wo),e(G,s1),e(s1,ome),e(ome,kwo),e(s1,Swo),e(s1,YD),e(YD,Rwo),e(s1,Pwo),e(G,Bwo),e(G,l1),e(l1,rme),e(rme,Iwo),e(l1,Nwo),e(l1,KD),e(KD,qwo),e(l1,jwo),e(G,Dwo),e(G,i1),e(i1,tme),e(tme,Gwo),e(i1,Owo),e(i1,ZD),e(ZD,Vwo),e(i1,Xwo),e(G,zwo),e(G,d1),e(d1,ame),e(ame,Wwo),e(d1,Qwo),e(d1,eG),e(eG,Hwo),e(d1,Uwo),e(G,Jwo),e(G,c1),e(c1,nme),e(nme,Ywo),e(c1,Kwo),e(c1,oG),e(oG,Zwo),e(c1,eAo),e(G,oAo),e(G,f1),e(f1,sme),e(sme,rAo),e(f1,tAo),e(f1,rG),e(rG,aAo),e(f1,nAo),e(G,sAo),e(G,m1),e(m1,lme),e(lme,lAo),e(m1,iAo),e(m1,tG),e(tG,dAo),e(m1,cAo),e(G,fAo),e(G,g1),e(g1,ime),e(ime,mAo),e(g1,gAo),e(g1,aG),e(aG,hAo),e(g1,pAo),e(G,_Ao),e(G,h1),e(h1,dme),e(dme,uAo),e(h1,bAo),e(h1,nG),e(nG,vAo),e(h1,FAo),e(G,TAo),e(G,p1),e(p1,cme),e(cme,MAo),e(p1,EAo),e(p1,sG),e(sG,CAo),e(p1,wAo),e(G,AAo),e(G,_1),e(_1,fme),e(fme,LAo),e(_1,yAo),e(_1,lG),e(lG,xAo),e(_1,$Ao),e(G,kAo),e(G,u1),e(u1,mme),e(mme,SAo),e(u1,RAo),e(u1,iG),e(iG,PAo),e(u1,BAo),e(G,IAo),e(G,b1),e(b1,gme),e(gme,NAo),e(b1,qAo),e(b1,dG),e(dG,jAo),e(b1,DAo),e(G,GAo),e(G,v1),e(v1,hme),e(hme,OAo),e(v1,VAo),e(v1,cG),e(cG,XAo),e(v1,zAo),e(G,WAo),e(G,F1),e(F1,pme),e(pme,QAo),e(F1,HAo),e(F1,fG),e(fG,UAo),e(F1,JAo),e(G,YAo),e(G,T1),e(T1,_me),e(_me,KAo),e(T1,ZAo),e(T1,mG),e(mG,eLo),e(T1,oLo),e(G,rLo),e(G,M1),e(M1,ume),e(ume,tLo),e(M1,aLo),e(M1,gG),e(gG,nLo),e(M1,sLo),e(G,lLo),e(G,E1),e(E1,bme),e(bme,iLo),e(E1,dLo),e(E1,hG),e(hG,cLo),e(E1,fLo),e(G,mLo),e(G,C1),e(C1,vme),e(vme,gLo),e(C1,hLo),e(C1,pG),e(pG,pLo),e(C1,_Lo),e(G,uLo),e(G,w1),e(w1,Fme),e(Fme,bLo),e(w1,vLo),e(w1,_G),e(_G,FLo),e(w1,TLo),e(G,MLo),e(G,A1),e(A1,Tme),e(Tme,ELo),e(A1,CLo),e(A1,uG),e(uG,wLo),e(A1,ALo),e(G,LLo),e(G,L1),e(L1,Mme),e(Mme,yLo),e(L1,xLo),e(L1,bG),e(bG,$Lo),e(L1,kLo),e(G,SLo),e(G,y1),e(y1,Eme),e(Eme,RLo),e(y1,PLo),e(y1,vG),e(vG,BLo),e(y1,ILo),e(G,NLo),e(G,x1),e(x1,Cme),e(Cme,qLo),e(x1,jLo),e(x1,FG),e(FG,DLo),e(x1,GLo),e(G,OLo),e(G,$1),e($1,wme),e(wme,VLo),e($1,XLo),e($1,TG),e(TG,zLo),e($1,WLo),e(G,QLo),e(G,k1),e(k1,Ame),e(Ame,HLo),e(k1,ULo),e(k1,MG),e(MG,JLo),e(k1,YLo),e(Ye,KLo),e(Ye,S1),e(S1,ZLo),e(S1,Lme),e(Lme,eyo),e(S1,oyo),e(S1,yme),e(yme,ryo),e(Ye,tyo),M(R1,Ye,null),b(f,tVe,u),b(f,zi,u),e(zi,P1),e(P1,xme),M(CL,xme,null),e(zi,ayo),e(zi,$me),e($me,nyo),b(f,aVe,u),b(f,ko,u),M(wL,ko,null),e(ko,syo),e(ko,Wi),e(Wi,lyo),e(Wi,EG),e(EG,iyo),e(Wi,dyo),e(Wi,CG),e(CG,cyo),e(Wi,fyo),e(ko,myo),e(ko,AL),e(AL,gyo),e(AL,kme),e(kme,hyo),e(AL,pyo),e(ko,_yo),e(ko,it),M(LL,it,null),e(it,uyo),e(it,Sme),e(Sme,byo),e(it,vyo),e(it,Qi),e(Qi,Fyo),e(Qi,Rme),e(Rme,Tyo),e(Qi,Myo),e(Qi,wG),e(wG,Eyo),e(Qi,Cyo),e(it,wyo),M(B1,it,null),e(ko,Ayo),e(ko,Ke),M(yL,Ke,null),e(Ke,Lyo),e(Ke,Pme),e(Pme,yyo),e(Ke,xyo),e(Ke,Na),e(Na,$yo),e(Na,Bme),e(Bme,kyo),e(Na,Syo),e(Na,Ime),e(Ime,Ryo),e(Na,Pyo),e(Na,Nme),e(Nme,Byo),e(Na,Iyo),e(Ke,Nyo),e(Ke,z),e(z,I1),e(I1,qme),e(qme,qyo),e(I1,jyo),e(I1,AG),e(AG,Dyo),e(I1,Gyo),e(z,Oyo),e(z,N1),e(N1,jme),e(jme,Vyo),e(N1,Xyo),e(N1,LG),e(LG,zyo),e(N1,Wyo),e(z,Qyo),e(z,q1),e(q1,Dme),e(Dme,Hyo),e(q1,Uyo),e(q1,yG),e(yG,Jyo),e(q1,Yyo),e(z,Kyo),e(z,j1),e(j1,Gme),e(Gme,Zyo),e(j1,e9o),e(j1,xG),e(xG,o9o),e(j1,r9o),e(z,t9o),e(z,D1),e(D1,Ome),e(Ome,a9o),e(D1,n9o),e(D1,$G),e($G,s9o),e(D1,l9o),e(z,i9o),e(z,G1),e(G1,Vme),e(Vme,d9o),e(G1,c9o),e(G1,kG),e(kG,f9o),e(G1,m9o),e(z,g9o),e(z,O1),e(O1,Xme),e(Xme,h9o),e(O1,p9o),e(O1,SG),e(SG,_9o),e(O1,u9o),e(z,b9o),e(z,V1),e(V1,zme),e(zme,v9o),e(V1,F9o),e(V1,RG),e(RG,T9o),e(V1,M9o),e(z,E9o),e(z,X1),e(X1,Wme),e(Wme,C9o),e(X1,w9o),e(X1,PG),e(PG,A9o),e(X1,L9o),e(z,y9o),e(z,z1),e(z1,Qme),e(Qme,x9o),e(z1,$9o),e(z1,BG),e(BG,k9o),e(z1,S9o),e(z,R9o),e(z,W1),e(W1,Hme),e(Hme,P9o),e(W1,B9o),e(W1,IG),e(IG,I9o),e(W1,N9o),e(z,q9o),e(z,Q1),e(Q1,Ume),e(Ume,j9o),e(Q1,D9o),e(Q1,NG),e(NG,G9o),e(Q1,O9o),e(z,V9o),e(z,H1),e(H1,Jme),e(Jme,X9o),e(H1,z9o),e(H1,qG),e(qG,W9o),e(H1,Q9o),e(z,H9o),e(z,U1),e(U1,Yme),e(Yme,U9o),e(U1,J9o),e(U1,jG),e(jG,Y9o),e(U1,K9o),e(z,Z9o),e(z,J1),e(J1,Kme),e(Kme,exo),e(J1,oxo),e(J1,DG),e(DG,rxo),e(J1,txo),e(z,axo),e(z,Y1),e(Y1,Zme),e(Zme,nxo),e(Y1,sxo),e(Y1,GG),e(GG,lxo),e(Y1,ixo),e(z,dxo),e(z,K1),e(K1,ege),e(ege,cxo),e(K1,fxo),e(K1,OG),e(OG,mxo),e(K1,gxo),e(z,hxo),e(z,Z1),e(Z1,oge),e(oge,pxo),e(Z1,_xo),e(Z1,VG),e(VG,uxo),e(Z1,bxo),e(z,vxo),e(z,e2),e(e2,rge),e(rge,Fxo),e(e2,Txo),e(e2,XG),e(XG,Mxo),e(e2,Exo),e(z,Cxo),e(z,o2),e(o2,tge),e(tge,wxo),e(o2,Axo),e(o2,zG),e(zG,Lxo),e(o2,yxo),e(z,xxo),e(z,r2),e(r2,age),e(age,$xo),e(r2,kxo),e(r2,WG),e(WG,Sxo),e(r2,Rxo),e(z,Pxo),e(z,t2),e(t2,nge),e(nge,Bxo),e(t2,Ixo),e(t2,QG),e(QG,Nxo),e(t2,qxo),e(z,jxo),e(z,a2),e(a2,sge),e(sge,Dxo),e(a2,Gxo),e(a2,HG),e(HG,Oxo),e(a2,Vxo),e(z,Xxo),e(z,n2),e(n2,lge),e(lge,zxo),e(n2,Wxo),e(n2,UG),e(UG,Qxo),e(n2,Hxo),e(z,Uxo),e(z,s2),e(s2,ige),e(ige,Jxo),e(s2,Yxo),e(s2,JG),e(JG,Kxo),e(s2,Zxo),e(z,e$o),e(z,l2),e(l2,dge),e(dge,o$o),e(l2,r$o),e(l2,YG),e(YG,t$o),e(l2,a$o),e(z,n$o),e(z,i2),e(i2,cge),e(cge,s$o),e(i2,l$o),e(i2,KG),e(KG,i$o),e(i2,d$o),e(z,c$o),e(z,d2),e(d2,fge),e(fge,f$o),e(d2,m$o),e(d2,ZG),e(ZG,g$o),e(d2,h$o),e(z,p$o),e(z,c2),e(c2,mge),e(mge,_$o),e(c2,u$o),e(c2,eO),e(eO,b$o),e(c2,v$o),e(z,F$o),e(z,f2),e(f2,gge),e(gge,T$o),e(f2,M$o),e(f2,oO),e(oO,E$o),e(f2,C$o),e(z,w$o),e(z,m2),e(m2,hge),e(hge,A$o),e(m2,L$o),e(m2,rO),e(rO,y$o),e(m2,x$o),e(z,$$o),e(z,g2),e(g2,pge),e(pge,k$o),e(g2,S$o),e(g2,tO),e(tO,R$o),e(g2,P$o),e(z,B$o),e(z,h2),e(h2,_ge),e(_ge,I$o),e(h2,N$o),e(h2,aO),e(aO,q$o),e(h2,j$o),e(z,D$o),e(z,p2),e(p2,uge),e(uge,G$o),e(p2,O$o),e(p2,nO),e(nO,V$o),e(p2,X$o),e(z,z$o),e(z,_2),e(_2,bge),e(bge,W$o),e(_2,Q$o),e(_2,sO),e(sO,H$o),e(_2,U$o),e(z,J$o),e(z,u2),e(u2,vge),e(vge,Y$o),e(u2,K$o),e(u2,lO),e(lO,Z$o),e(u2,eko),e(z,oko),e(z,b2),e(b2,Fge),e(Fge,rko),e(b2,tko),e(b2,iO),e(iO,ako),e(b2,nko),e(z,sko),e(z,v2),e(v2,Tge),e(Tge,lko),e(v2,iko),e(v2,dO),e(dO,dko),e(v2,cko),e(z,fko),e(z,F2),e(F2,Mge),e(Mge,mko),e(F2,gko),e(F2,cO),e(cO,hko),e(F2,pko),e(Ke,_ko),e(Ke,T2),e(T2,uko),e(T2,Ege),e(Ege,bko),e(T2,vko),e(T2,Cge),e(Cge,Fko),e(Ke,Tko),M(M2,Ke,null),b(f,nVe,u),b(f,Hi,u),e(Hi,E2),e(E2,wge),M(xL,wge,null),e(Hi,Mko),e(Hi,Age),e(Age,Eko),b(f,sVe,u),b(f,So,u),M($L,So,null),e(So,Cko),e(So,Ui),e(Ui,wko),e(Ui,fO),e(fO,Ako),e(Ui,Lko),e(Ui,mO),e(mO,yko),e(Ui,xko),e(So,$ko),e(So,kL),e(kL,kko),e(kL,Lge),e(Lge,Sko),e(kL,Rko),e(So,Pko),e(So,dt),M(SL,dt,null),e(dt,Bko),e(dt,yge),e(yge,Iko),e(dt,Nko),e(dt,Ji),e(Ji,qko),e(Ji,xge),e(xge,jko),e(Ji,Dko),e(Ji,gO),e(gO,Gko),e(Ji,Oko),e(dt,Vko),M(C2,dt,null),e(So,Xko),e(So,Ze),M(RL,Ze,null),e(Ze,zko),e(Ze,$ge),e($ge,Wko),e(Ze,Qko),e(Ze,qa),e(qa,Hko),e(qa,kge),e(kge,Uko),e(qa,Jko),e(qa,Sge),e(Sge,Yko),e(qa,Kko),e(qa,Rge),e(Rge,Zko),e(qa,eSo),e(Ze,oSo),e(Ze,Q),e(Q,w2),e(w2,Pge),e(Pge,rSo),e(w2,tSo),e(w2,hO),e(hO,aSo),e(w2,nSo),e(Q,sSo),e(Q,A2),e(A2,Bge),e(Bge,lSo),e(A2,iSo),e(A2,pO),e(pO,dSo),e(A2,cSo),e(Q,fSo),e(Q,L2),e(L2,Ige),e(Ige,mSo),e(L2,gSo),e(L2,_O),e(_O,hSo),e(L2,pSo),e(Q,_So),e(Q,y2),e(y2,Nge),e(Nge,uSo),e(y2,bSo),e(y2,uO),e(uO,vSo),e(y2,FSo),e(Q,TSo),e(Q,x2),e(x2,qge),e(qge,MSo),e(x2,ESo),e(x2,bO),e(bO,CSo),e(x2,wSo),e(Q,ASo),e(Q,$2),e($2,jge),e(jge,LSo),e($2,ySo),e($2,vO),e(vO,xSo),e($2,$So),e(Q,kSo),e(Q,k2),e(k2,Dge),e(Dge,SSo),e(k2,RSo),e(k2,FO),e(FO,PSo),e(k2,BSo),e(Q,ISo),e(Q,S2),e(S2,Gge),e(Gge,NSo),e(S2,qSo),e(S2,TO),e(TO,jSo),e(S2,DSo),e(Q,GSo),e(Q,R2),e(R2,Oge),e(Oge,OSo),e(R2,VSo),e(R2,MO),e(MO,XSo),e(R2,zSo),e(Q,WSo),e(Q,P2),e(P2,Vge),e(Vge,QSo),e(P2,HSo),e(P2,EO),e(EO,USo),e(P2,JSo),e(Q,YSo),e(Q,B2),e(B2,Xge),e(Xge,KSo),e(B2,ZSo),e(B2,CO),e(CO,eRo),e(B2,oRo),e(Q,rRo),e(Q,I2),e(I2,zge),e(zge,tRo),e(I2,aRo),e(I2,wO),e(wO,nRo),e(I2,sRo),e(Q,lRo),e(Q,N2),e(N2,Wge),e(Wge,iRo),e(N2,dRo),e(N2,AO),e(AO,cRo),e(N2,fRo),e(Q,mRo),e(Q,q2),e(q2,Qge),e(Qge,gRo),e(q2,hRo),e(q2,LO),e(LO,pRo),e(q2,_Ro),e(Q,uRo),e(Q,j2),e(j2,Hge),e(Hge,bRo),e(j2,vRo),e(j2,yO),e(yO,FRo),e(j2,TRo),e(Q,MRo),e(Q,D2),e(D2,Uge),e(Uge,ERo),e(D2,CRo),e(D2,xO),e(xO,wRo),e(D2,ARo),e(Q,LRo),e(Q,G2),e(G2,Jge),e(Jge,yRo),e(G2,xRo),e(G2,$O),e($O,$Ro),e(G2,kRo),e(Q,SRo),e(Q,O2),e(O2,Yge),e(Yge,RRo),e(O2,PRo),e(O2,kO),e(kO,BRo),e(O2,IRo),e(Q,NRo),e(Q,V2),e(V2,Kge),e(Kge,qRo),e(V2,jRo),e(V2,SO),e(SO,DRo),e(V2,GRo),e(Q,ORo),e(Q,X2),e(X2,Zge),e(Zge,VRo),e(X2,XRo),e(X2,RO),e(RO,zRo),e(X2,WRo),e(Q,QRo),e(Q,z2),e(z2,ehe),e(ehe,HRo),e(z2,URo),e(z2,PO),e(PO,JRo),e(z2,YRo),e(Q,KRo),e(Q,W2),e(W2,ohe),e(ohe,ZRo),e(W2,ePo),e(W2,BO),e(BO,oPo),e(W2,rPo),e(Q,tPo),e(Q,Q2),e(Q2,rhe),e(rhe,aPo),e(Q2,nPo),e(Q2,IO),e(IO,sPo),e(Q2,lPo),e(Q,iPo),e(Q,H2),e(H2,the),e(the,dPo),e(H2,cPo),e(H2,NO),e(NO,fPo),e(H2,mPo),e(Q,gPo),e(Q,U2),e(U2,ahe),e(ahe,hPo),e(U2,pPo),e(U2,qO),e(qO,_Po),e(U2,uPo),e(Q,bPo),e(Q,J2),e(J2,nhe),e(nhe,vPo),e(J2,FPo),e(J2,jO),e(jO,TPo),e(J2,MPo),e(Q,EPo),e(Q,Y2),e(Y2,she),e(she,CPo),e(Y2,wPo),e(Y2,DO),e(DO,APo),e(Y2,LPo),e(Q,yPo),e(Q,K2),e(K2,lhe),e(lhe,xPo),e(K2,$Po),e(K2,GO),e(GO,kPo),e(K2,SPo),e(Q,RPo),e(Q,Z2),e(Z2,ihe),e(ihe,PPo),e(Z2,BPo),e(Z2,OO),e(OO,IPo),e(Z2,NPo),e(Q,qPo),e(Q,eb),e(eb,dhe),e(dhe,jPo),e(eb,DPo),e(eb,VO),e(VO,GPo),e(eb,OPo),e(Q,VPo),e(Q,ob),e(ob,che),e(che,XPo),e(ob,zPo),e(ob,XO),e(XO,WPo),e(ob,QPo),e(Q,HPo),e(Q,rb),e(rb,fhe),e(fhe,UPo),e(rb,JPo),e(rb,zO),e(zO,YPo),e(rb,KPo),e(Q,ZPo),e(Q,tb),e(tb,mhe),e(mhe,eBo),e(tb,oBo),e(tb,ghe),e(ghe,rBo),e(tb,tBo),e(Q,aBo),e(Q,ab),e(ab,hhe),e(hhe,nBo),e(ab,sBo),e(ab,WO),e(WO,lBo),e(ab,iBo),e(Q,dBo),e(Q,nb),e(nb,phe),e(phe,cBo),e(nb,fBo),e(nb,QO),e(QO,mBo),e(nb,gBo),e(Q,hBo),e(Q,sb),e(sb,_he),e(_he,pBo),e(sb,_Bo),e(sb,HO),e(HO,uBo),e(sb,bBo),e(Q,vBo),e(Q,lb),e(lb,uhe),e(uhe,FBo),e(lb,TBo),e(lb,UO),e(UO,MBo),e(lb,EBo),e(Ze,CBo),e(Ze,ib),e(ib,wBo),e(ib,bhe),e(bhe,ABo),e(ib,LBo),e(ib,vhe),e(vhe,yBo),e(Ze,xBo),M(db,Ze,null),b(f,lVe,u),b(f,Yi,u),e(Yi,cb),e(cb,Fhe),M(PL,Fhe,null),e(Yi,$Bo),e(Yi,The),e(The,kBo),b(f,iVe,u),b(f,Ro,u),M(BL,Ro,null),e(Ro,SBo),e(Ro,Ki),e(Ki,RBo),e(Ki,JO),e(JO,PBo),e(Ki,BBo),e(Ki,YO),e(YO,IBo),e(Ki,NBo),e(Ro,qBo),e(Ro,IL),e(IL,jBo),e(IL,Mhe),e(Mhe,DBo),e(IL,GBo),e(Ro,OBo),e(Ro,ct),M(NL,ct,null),e(ct,VBo),e(ct,Ehe),e(Ehe,XBo),e(ct,zBo),e(ct,Zi),e(Zi,WBo),e(Zi,Che),e(Che,QBo),e(Zi,HBo),e(Zi,KO),e(KO,UBo),e(Zi,JBo),e(ct,YBo),M(fb,ct,null),e(Ro,KBo),e(Ro,eo),M(qL,eo,null),e(eo,ZBo),e(eo,whe),e(whe,eIo),e(eo,oIo),e(eo,ja),e(ja,rIo),e(ja,Ahe),e(Ahe,tIo),e(ja,aIo),e(ja,Lhe),e(Lhe,nIo),e(ja,sIo),e(ja,yhe),e(yhe,lIo),e(ja,iIo),e(eo,dIo),e(eo,pe),e(pe,mb),e(mb,xhe),e(xhe,cIo),e(mb,fIo),e(mb,ZO),e(ZO,mIo),e(mb,gIo),e(pe,hIo),e(pe,gb),e(gb,$he),e($he,pIo),e(gb,_Io),e(gb,eV),e(eV,uIo),e(gb,bIo),e(pe,vIo),e(pe,hb),e(hb,khe),e(khe,FIo),e(hb,TIo),e(hb,oV),e(oV,MIo),e(hb,EIo),e(pe,CIo),e(pe,pb),e(pb,She),e(She,wIo),e(pb,AIo),e(pb,rV),e(rV,LIo),e(pb,yIo),e(pe,xIo),e(pe,_b),e(_b,Rhe),e(Rhe,$Io),e(_b,kIo),e(_b,tV),e(tV,SIo),e(_b,RIo),e(pe,PIo),e(pe,ub),e(ub,Phe),e(Phe,BIo),e(ub,IIo),e(ub,aV),e(aV,NIo),e(ub,qIo),e(pe,jIo),e(pe,bb),e(bb,Bhe),e(Bhe,DIo),e(bb,GIo),e(bb,nV),e(nV,OIo),e(bb,VIo),e(pe,XIo),e(pe,vb),e(vb,Ihe),e(Ihe,zIo),e(vb,WIo),e(vb,sV),e(sV,QIo),e(vb,HIo),e(pe,UIo),e(pe,Fb),e(Fb,Nhe),e(Nhe,JIo),e(Fb,YIo),e(Fb,lV),e(lV,KIo),e(Fb,ZIo),e(pe,eNo),e(pe,Tb),e(Tb,qhe),e(qhe,oNo),e(Tb,rNo),e(Tb,iV),e(iV,tNo),e(Tb,aNo),e(pe,nNo),e(pe,Mb),e(Mb,jhe),e(jhe,sNo),e(Mb,lNo),e(Mb,dV),e(dV,iNo),e(Mb,dNo),e(pe,cNo),e(pe,Eb),e(Eb,Dhe),e(Dhe,fNo),e(Eb,mNo),e(Eb,cV),e(cV,gNo),e(Eb,hNo),e(pe,pNo),e(pe,Cb),e(Cb,Ghe),e(Ghe,_No),e(Cb,uNo),e(Cb,fV),e(fV,bNo),e(Cb,vNo),e(pe,FNo),e(pe,wb),e(wb,Ohe),e(Ohe,TNo),e(wb,MNo),e(wb,mV),e(mV,ENo),e(wb,CNo),e(pe,wNo),e(pe,Ab),e(Ab,Vhe),e(Vhe,ANo),e(Ab,LNo),e(Ab,gV),e(gV,yNo),e(Ab,xNo),e(pe,$No),e(pe,Lb),e(Lb,Xhe),e(Xhe,kNo),e(Lb,SNo),e(Lb,hV),e(hV,RNo),e(Lb,PNo),e(pe,BNo),e(pe,yb),e(yb,zhe),e(zhe,INo),e(yb,NNo),e(yb,pV),e(pV,qNo),e(yb,jNo),e(eo,DNo),e(eo,xb),e(xb,GNo),e(xb,Whe),e(Whe,ONo),e(xb,VNo),e(xb,Qhe),e(Qhe,XNo),e(eo,zNo),M($b,eo,null),b(f,dVe,u),b(f,ed,u),e(ed,kb),e(kb,Hhe),M(jL,Hhe,null),e(ed,WNo),e(ed,Uhe),e(Uhe,QNo),b(f,cVe,u),b(f,Po,u),M(DL,Po,null),e(Po,HNo),e(Po,od),e(od,UNo),e(od,_V),e(_V,JNo),e(od,YNo),e(od,uV),e(uV,KNo),e(od,ZNo),e(Po,eqo),e(Po,GL),e(GL,oqo),e(GL,Jhe),e(Jhe,rqo),e(GL,tqo),e(Po,aqo),e(Po,ft),M(OL,ft,null),e(ft,nqo),e(ft,Yhe),e(Yhe,sqo),e(ft,lqo),e(ft,rd),e(rd,iqo),e(rd,Khe),e(Khe,dqo),e(rd,cqo),e(rd,bV),e(bV,fqo),e(rd,mqo),e(ft,gqo),M(Sb,ft,null),e(Po,hqo),e(Po,oo),M(VL,oo,null),e(oo,pqo),e(oo,Zhe),e(Zhe,_qo),e(oo,uqo),e(oo,Da),e(Da,bqo),e(Da,epe),e(epe,vqo),e(Da,Fqo),e(Da,ope),e(ope,Tqo),e(Da,Mqo),e(Da,rpe),e(rpe,Eqo),e(Da,Cqo),e(oo,wqo),e(oo,N),e(N,Rb),e(Rb,tpe),e(tpe,Aqo),e(Rb,Lqo),e(Rb,vV),e(vV,yqo),e(Rb,xqo),e(N,$qo),e(N,Pb),e(Pb,ape),e(ape,kqo),e(Pb,Sqo),e(Pb,FV),e(FV,Rqo),e(Pb,Pqo),e(N,Bqo),e(N,Bb),e(Bb,npe),e(npe,Iqo),e(Bb,Nqo),e(Bb,TV),e(TV,qqo),e(Bb,jqo),e(N,Dqo),e(N,Ib),e(Ib,spe),e(spe,Gqo),e(Ib,Oqo),e(Ib,MV),e(MV,Vqo),e(Ib,Xqo),e(N,zqo),e(N,Nb),e(Nb,lpe),e(lpe,Wqo),e(Nb,Qqo),e(Nb,EV),e(EV,Hqo),e(Nb,Uqo),e(N,Jqo),e(N,qb),e(qb,ipe),e(ipe,Yqo),e(qb,Kqo),e(qb,CV),e(CV,Zqo),e(qb,ejo),e(N,ojo),e(N,jb),e(jb,dpe),e(dpe,rjo),e(jb,tjo),e(jb,wV),e(wV,ajo),e(jb,njo),e(N,sjo),e(N,Db),e(Db,cpe),e(cpe,ljo),e(Db,ijo),e(Db,AV),e(AV,djo),e(Db,cjo),e(N,fjo),e(N,Gb),e(Gb,fpe),e(fpe,mjo),e(Gb,gjo),e(Gb,LV),e(LV,hjo),e(Gb,pjo),e(N,_jo),e(N,Ob),e(Ob,mpe),e(mpe,ujo),e(Ob,bjo),e(Ob,yV),e(yV,vjo),e(Ob,Fjo),e(N,Tjo),e(N,Vb),e(Vb,gpe),e(gpe,Mjo),e(Vb,Ejo),e(Vb,xV),e(xV,Cjo),e(Vb,wjo),e(N,Ajo),e(N,Xb),e(Xb,hpe),e(hpe,Ljo),e(Xb,yjo),e(Xb,$V),e($V,xjo),e(Xb,$jo),e(N,kjo),e(N,zb),e(zb,ppe),e(ppe,Sjo),e(zb,Rjo),e(zb,kV),e(kV,Pjo),e(zb,Bjo),e(N,Ijo),e(N,Wb),e(Wb,_pe),e(_pe,Njo),e(Wb,qjo),e(Wb,SV),e(SV,jjo),e(Wb,Djo),e(N,Gjo),e(N,Qb),e(Qb,upe),e(upe,Ojo),e(Qb,Vjo),e(Qb,RV),e(RV,Xjo),e(Qb,zjo),e(N,Wjo),e(N,Hb),e(Hb,bpe),e(bpe,Qjo),e(Hb,Hjo),e(Hb,PV),e(PV,Ujo),e(Hb,Jjo),e(N,Yjo),e(N,Ub),e(Ub,vpe),e(vpe,Kjo),e(Ub,Zjo),e(Ub,BV),e(BV,eDo),e(Ub,oDo),e(N,rDo),e(N,Jb),e(Jb,Fpe),e(Fpe,tDo),e(Jb,aDo),e(Jb,IV),e(IV,nDo),e(Jb,sDo),e(N,lDo),e(N,Yb),e(Yb,Tpe),e(Tpe,iDo),e(Yb,dDo),e(Yb,NV),e(NV,cDo),e(Yb,fDo),e(N,mDo),e(N,Kb),e(Kb,Mpe),e(Mpe,gDo),e(Kb,hDo),e(Kb,qV),e(qV,pDo),e(Kb,_Do),e(N,uDo),e(N,Zb),e(Zb,Epe),e(Epe,bDo),e(Zb,vDo),e(Zb,jV),e(jV,FDo),e(Zb,TDo),e(N,MDo),e(N,ev),e(ev,Cpe),e(Cpe,EDo),e(ev,CDo),e(ev,DV),e(DV,wDo),e(ev,ADo),e(N,LDo),e(N,ov),e(ov,wpe),e(wpe,yDo),e(ov,xDo),e(ov,GV),e(GV,$Do),e(ov,kDo),e(N,SDo),e(N,rv),e(rv,Ape),e(Ape,RDo),e(rv,PDo),e(rv,OV),e(OV,BDo),e(rv,IDo),e(N,NDo),e(N,tv),e(tv,Lpe),e(Lpe,qDo),e(tv,jDo),e(tv,VV),e(VV,DDo),e(tv,GDo),e(N,ODo),e(N,av),e(av,ype),e(ype,VDo),e(av,XDo),e(av,XV),e(XV,zDo),e(av,WDo),e(N,QDo),e(N,nv),e(nv,xpe),e(xpe,HDo),e(nv,UDo),e(nv,zV),e(zV,JDo),e(nv,YDo),e(N,KDo),e(N,sv),e(sv,$pe),e($pe,ZDo),e(sv,eGo),e(sv,WV),e(WV,oGo),e(sv,rGo),e(N,tGo),e(N,lv),e(lv,kpe),e(kpe,aGo),e(lv,nGo),e(lv,QV),e(QV,sGo),e(lv,lGo),e(N,iGo),e(N,iv),e(iv,Spe),e(Spe,dGo),e(iv,cGo),e(iv,HV),e(HV,fGo),e(iv,mGo),e(N,gGo),e(N,dv),e(dv,Rpe),e(Rpe,hGo),e(dv,pGo),e(dv,UV),e(UV,_Go),e(dv,uGo),e(N,bGo),e(N,cv),e(cv,Ppe),e(Ppe,vGo),e(cv,FGo),e(cv,JV),e(JV,TGo),e(cv,MGo),e(N,EGo),e(N,fv),e(fv,Bpe),e(Bpe,CGo),e(fv,wGo),e(fv,YV),e(YV,AGo),e(fv,LGo),e(N,yGo),e(N,mv),e(mv,Ipe),e(Ipe,xGo),e(mv,$Go),e(mv,KV),e(KV,kGo),e(mv,SGo),e(N,RGo),e(N,gv),e(gv,Npe),e(Npe,PGo),e(gv,BGo),e(gv,ZV),e(ZV,IGo),e(gv,NGo),e(N,qGo),e(N,hv),e(hv,qpe),e(qpe,jGo),e(hv,DGo),e(hv,eX),e(eX,GGo),e(hv,OGo),e(N,VGo),e(N,pv),e(pv,jpe),e(jpe,XGo),e(pv,zGo),e(pv,oX),e(oX,WGo),e(pv,QGo),e(N,HGo),e(N,_v),e(_v,Dpe),e(Dpe,UGo),e(_v,JGo),e(_v,rX),e(rX,YGo),e(_v,KGo),e(N,ZGo),e(N,uv),e(uv,Gpe),e(Gpe,eOo),e(uv,oOo),e(uv,tX),e(tX,rOo),e(uv,tOo),e(N,aOo),e(N,bv),e(bv,Ope),e(Ope,nOo),e(bv,sOo),e(bv,aX),e(aX,lOo),e(bv,iOo),e(N,dOo),e(N,vv),e(vv,Vpe),e(Vpe,cOo),e(vv,fOo),e(vv,nX),e(nX,mOo),e(vv,gOo),e(N,hOo),e(N,Fv),e(Fv,Xpe),e(Xpe,pOo),e(Fv,_Oo),e(Fv,sX),e(sX,uOo),e(Fv,bOo),e(N,vOo),e(N,Tv),e(Tv,zpe),e(zpe,FOo),e(Tv,TOo),e(Tv,lX),e(lX,MOo),e(Tv,EOo),e(N,COo),e(N,Mv),e(Mv,Wpe),e(Wpe,wOo),e(Mv,AOo),e(Mv,iX),e(iX,LOo),e(Mv,yOo),e(N,xOo),e(N,Ev),e(Ev,Qpe),e(Qpe,$Oo),e(Ev,kOo),e(Ev,dX),e(dX,SOo),e(Ev,ROo),e(N,POo),e(N,Cv),e(Cv,Hpe),e(Hpe,BOo),e(Cv,IOo),e(Cv,cX),e(cX,NOo),e(Cv,qOo),e(N,jOo),e(N,wv),e(wv,Upe),e(Upe,DOo),e(wv,GOo),e(wv,fX),e(fX,OOo),e(wv,VOo),e(N,XOo),e(N,Av),e(Av,Jpe),e(Jpe,zOo),e(Av,WOo),e(Av,mX),e(mX,QOo),e(Av,HOo),e(N,UOo),e(N,Lv),e(Lv,Ype),e(Ype,JOo),e(Lv,YOo),e(Lv,gX),e(gX,KOo),e(Lv,ZOo),e(oo,eVo),e(oo,yv),e(yv,oVo),e(yv,Kpe),e(Kpe,rVo),e(yv,tVo),e(yv,Zpe),e(Zpe,aVo),e(oo,nVo),M(xv,oo,null),b(f,fVe,u),b(f,td,u),e(td,$v),e($v,e_e),M(XL,e_e,null),e(td,sVo),e(td,o_e),e(o_e,lVo),b(f,mVe,u),b(f,Bo,u),M(zL,Bo,null),e(Bo,iVo),e(Bo,ad),e(ad,dVo),e(ad,hX),e(hX,cVo),e(ad,fVo),e(ad,pX),e(pX,mVo),e(ad,gVo),e(Bo,hVo),e(Bo,WL),e(WL,pVo),e(WL,r_e),e(r_e,_Vo),e(WL,uVo),e(Bo,bVo),e(Bo,mt),M(QL,mt,null),e(mt,vVo),e(mt,t_e),e(t_e,FVo),e(mt,TVo),e(mt,nd),e(nd,MVo),e(nd,a_e),e(a_e,EVo),e(nd,CVo),e(nd,_X),e(_X,wVo),e(nd,AVo),e(mt,LVo),M(kv,mt,null),e(Bo,yVo),e(Bo,ro),M(HL,ro,null),e(ro,xVo),e(ro,n_e),e(n_e,$Vo),e(ro,kVo),e(ro,Ga),e(Ga,SVo),e(Ga,s_e),e(s_e,RVo),e(Ga,PVo),e(Ga,l_e),e(l_e,BVo),e(Ga,IVo),e(Ga,i_e),e(i_e,NVo),e(Ga,qVo),e(ro,jVo),e(ro,Z),e(Z,Sv),e(Sv,d_e),e(d_e,DVo),e(Sv,GVo),e(Sv,uX),e(uX,OVo),e(Sv,VVo),e(Z,XVo),e(Z,Rv),e(Rv,c_e),e(c_e,zVo),e(Rv,WVo),e(Rv,bX),e(bX,QVo),e(Rv,HVo),e(Z,UVo),e(Z,Pv),e(Pv,f_e),e(f_e,JVo),e(Pv,YVo),e(Pv,vX),e(vX,KVo),e(Pv,ZVo),e(Z,eXo),e(Z,Bv),e(Bv,m_e),e(m_e,oXo),e(Bv,rXo),e(Bv,FX),e(FX,tXo),e(Bv,aXo),e(Z,nXo),e(Z,Iv),e(Iv,g_e),e(g_e,sXo),e(Iv,lXo),e(Iv,TX),e(TX,iXo),e(Iv,dXo),e(Z,cXo),e(Z,Nv),e(Nv,h_e),e(h_e,fXo),e(Nv,mXo),e(Nv,MX),e(MX,gXo),e(Nv,hXo),e(Z,pXo),e(Z,qv),e(qv,p_e),e(p_e,_Xo),e(qv,uXo),e(qv,EX),e(EX,bXo),e(qv,vXo),e(Z,FXo),e(Z,jv),e(jv,__e),e(__e,TXo),e(jv,MXo),e(jv,CX),e(CX,EXo),e(jv,CXo),e(Z,wXo),e(Z,Dv),e(Dv,u_e),e(u_e,AXo),e(Dv,LXo),e(Dv,wX),e(wX,yXo),e(Dv,xXo),e(Z,$Xo),e(Z,Gv),e(Gv,b_e),e(b_e,kXo),e(Gv,SXo),e(Gv,AX),e(AX,RXo),e(Gv,PXo),e(Z,BXo),e(Z,Ov),e(Ov,v_e),e(v_e,IXo),e(Ov,NXo),e(Ov,LX),e(LX,qXo),e(Ov,jXo),e(Z,DXo),e(Z,Vv),e(Vv,F_e),e(F_e,GXo),e(Vv,OXo),e(Vv,yX),e(yX,VXo),e(Vv,XXo),e(Z,zXo),e(Z,Xv),e(Xv,T_e),e(T_e,WXo),e(Xv,QXo),e(Xv,xX),e(xX,HXo),e(Xv,UXo),e(Z,JXo),e(Z,zv),e(zv,M_e),e(M_e,YXo),e(zv,KXo),e(zv,$X),e($X,ZXo),e(zv,ezo),e(Z,ozo),e(Z,Wv),e(Wv,E_e),e(E_e,rzo),e(Wv,tzo),e(Wv,kX),e(kX,azo),e(Wv,nzo),e(Z,szo),e(Z,Qv),e(Qv,C_e),e(C_e,lzo),e(Qv,izo),e(Qv,SX),e(SX,dzo),e(Qv,czo),e(Z,fzo),e(Z,Hv),e(Hv,w_e),e(w_e,mzo),e(Hv,gzo),e(Hv,RX),e(RX,hzo),e(Hv,pzo),e(Z,_zo),e(Z,Uv),e(Uv,A_e),e(A_e,uzo),e(Uv,bzo),e(Uv,PX),e(PX,vzo),e(Uv,Fzo),e(Z,Tzo),e(Z,Jv),e(Jv,L_e),e(L_e,Mzo),e(Jv,Ezo),e(Jv,BX),e(BX,Czo),e(Jv,wzo),e(Z,Azo),e(Z,Yv),e(Yv,y_e),e(y_e,Lzo),e(Yv,yzo),e(Yv,IX),e(IX,xzo),e(Yv,$zo),e(Z,kzo),e(Z,Kv),e(Kv,x_e),e(x_e,Szo),e(Kv,Rzo),e(Kv,NX),e(NX,Pzo),e(Kv,Bzo),e(Z,Izo),e(Z,Zv),e(Zv,$_e),e($_e,Nzo),e(Zv,qzo),e(Zv,qX),e(qX,jzo),e(Zv,Dzo),e(Z,Gzo),e(Z,e0),e(e0,k_e),e(k_e,Ozo),e(e0,Vzo),e(e0,jX),e(jX,Xzo),e(e0,zzo),e(Z,Wzo),e(Z,o0),e(o0,S_e),e(S_e,Qzo),e(o0,Hzo),e(o0,DX),e(DX,Uzo),e(o0,Jzo),e(Z,Yzo),e(Z,r0),e(r0,R_e),e(R_e,Kzo),e(r0,Zzo),e(r0,GX),e(GX,eWo),e(r0,oWo),e(Z,rWo),e(Z,t0),e(t0,P_e),e(P_e,tWo),e(t0,aWo),e(t0,OX),e(OX,nWo),e(t0,sWo),e(Z,lWo),e(Z,a0),e(a0,B_e),e(B_e,iWo),e(a0,dWo),e(a0,VX),e(VX,cWo),e(a0,fWo),e(Z,mWo),e(Z,n0),e(n0,I_e),e(I_e,gWo),e(n0,hWo),e(n0,XX),e(XX,pWo),e(n0,_Wo),e(Z,uWo),e(Z,s0),e(s0,N_e),e(N_e,bWo),e(s0,vWo),e(s0,zX),e(zX,FWo),e(s0,TWo),e(Z,MWo),e(Z,l0),e(l0,q_e),e(q_e,EWo),e(l0,CWo),e(l0,WX),e(WX,wWo),e(l0,AWo),e(ro,LWo),e(ro,i0),e(i0,yWo),e(i0,j_e),e(j_e,xWo),e(i0,$Wo),e(i0,D_e),e(D_e,kWo),e(ro,SWo),M(d0,ro,null),b(f,gVe,u),b(f,sd,u),e(sd,c0),e(c0,G_e),M(UL,G_e,null),e(sd,RWo),e(sd,O_e),e(O_e,PWo),b(f,hVe,u),b(f,Io,u),M(JL,Io,null),e(Io,BWo),e(Io,ld),e(ld,IWo),e(ld,QX),e(QX,NWo),e(ld,qWo),e(ld,HX),e(HX,jWo),e(ld,DWo),e(Io,GWo),e(Io,YL),e(YL,OWo),e(YL,V_e),e(V_e,VWo),e(YL,XWo),e(Io,zWo),e(Io,gt),M(KL,gt,null),e(gt,WWo),e(gt,X_e),e(X_e,QWo),e(gt,HWo),e(gt,id),e(id,UWo),e(id,z_e),e(z_e,JWo),e(id,YWo),e(id,UX),e(UX,KWo),e(id,ZWo),e(gt,eQo),M(f0,gt,null),e(Io,oQo),e(Io,to),M(ZL,to,null),e(to,rQo),e(to,W_e),e(W_e,tQo),e(to,aQo),e(to,Oa),e(Oa,nQo),e(Oa,Q_e),e(Q_e,sQo),e(Oa,lQo),e(Oa,H_e),e(H_e,iQo),e(Oa,dQo),e(Oa,U_e),e(U_e,cQo),e(Oa,fQo),e(to,mQo),e(to,No),e(No,m0),e(m0,J_e),e(J_e,gQo),e(m0,hQo),e(m0,JX),e(JX,pQo),e(m0,_Qo),e(No,uQo),e(No,g0),e(g0,Y_e),e(Y_e,bQo),e(g0,vQo),e(g0,YX),e(YX,FQo),e(g0,TQo),e(No,MQo),e(No,h0),e(h0,K_e),e(K_e,EQo),e(h0,CQo),e(h0,KX),e(KX,wQo),e(h0,AQo),e(No,LQo),e(No,p0),e(p0,Z_e),e(Z_e,yQo),e(p0,xQo),e(p0,ZX),e(ZX,$Qo),e(p0,kQo),e(No,SQo),e(No,_0),e(_0,eue),e(eue,RQo),e(_0,PQo),e(_0,ez),e(ez,BQo),e(_0,IQo),e(No,NQo),e(No,u0),e(u0,oue),e(oue,qQo),e(u0,jQo),e(u0,oz),e(oz,DQo),e(u0,GQo),e(to,OQo),e(to,b0),e(b0,VQo),e(b0,rue),e(rue,XQo),e(b0,zQo),e(b0,tue),e(tue,WQo),e(to,QQo),M(v0,to,null),b(f,pVe,u),b(f,dd,u),e(dd,F0),e(F0,aue),M(ey,aue,null),e(dd,HQo),e(dd,nue),e(nue,UQo),b(f,_Ve,u),b(f,qo,u),M(oy,qo,null),e(qo,JQo),e(qo,cd),e(cd,YQo),e(cd,rz),e(rz,KQo),e(cd,ZQo),e(cd,tz),e(tz,eHo),e(cd,oHo),e(qo,rHo),e(qo,ry),e(ry,tHo),e(ry,sue),e(sue,aHo),e(ry,nHo),e(qo,sHo),e(qo,ht),M(ty,ht,null),e(ht,lHo),e(ht,lue),e(lue,iHo),e(ht,dHo),e(ht,fd),e(fd,cHo),e(fd,iue),e(iue,fHo),e(fd,mHo),e(fd,az),e(az,gHo),e(fd,hHo),e(ht,pHo),M(T0,ht,null),e(qo,_Ho),e(qo,ao),M(ay,ao,null),e(ao,uHo),e(ao,due),e(due,bHo),e(ao,vHo),e(ao,Va),e(Va,FHo),e(Va,cue),e(cue,THo),e(Va,MHo),e(Va,fue),e(fue,EHo),e(Va,CHo),e(Va,mue),e(mue,wHo),e(Va,AHo),e(ao,LHo),e(ao,H),e(H,M0),e(M0,gue),e(gue,yHo),e(M0,xHo),e(M0,nz),e(nz,$Ho),e(M0,kHo),e(H,SHo),e(H,E0),e(E0,hue),e(hue,RHo),e(E0,PHo),e(E0,sz),e(sz,BHo),e(E0,IHo),e(H,NHo),e(H,C0),e(C0,pue),e(pue,qHo),e(C0,jHo),e(C0,lz),e(lz,DHo),e(C0,GHo),e(H,OHo),e(H,w0),e(w0,_ue),e(_ue,VHo),e(w0,XHo),e(w0,iz),e(iz,zHo),e(w0,WHo),e(H,QHo),e(H,A0),e(A0,uue),e(uue,HHo),e(A0,UHo),e(A0,dz),e(dz,JHo),e(A0,YHo),e(H,KHo),e(H,L0),e(L0,bue),e(bue,ZHo),e(L0,eUo),e(L0,cz),e(cz,oUo),e(L0,rUo),e(H,tUo),e(H,y0),e(y0,vue),e(vue,aUo),e(y0,nUo),e(y0,fz),e(fz,sUo),e(y0,lUo),e(H,iUo),e(H,x0),e(x0,Fue),e(Fue,dUo),e(x0,cUo),e(x0,mz),e(mz,fUo),e(x0,mUo),e(H,gUo),e(H,$0),e($0,Tue),e(Tue,hUo),e($0,pUo),e($0,gz),e(gz,_Uo),e($0,uUo),e(H,bUo),e(H,k0),e(k0,Mue),e(Mue,vUo),e(k0,FUo),e(k0,hz),e(hz,TUo),e(k0,MUo),e(H,EUo),e(H,S0),e(S0,Eue),e(Eue,CUo),e(S0,wUo),e(S0,pz),e(pz,AUo),e(S0,LUo),e(H,yUo),e(H,R0),e(R0,Cue),e(Cue,xUo),e(R0,$Uo),e(R0,_z),e(_z,kUo),e(R0,SUo),e(H,RUo),e(H,P0),e(P0,wue),e(wue,PUo),e(P0,BUo),e(P0,uz),e(uz,IUo),e(P0,NUo),e(H,qUo),e(H,B0),e(B0,Aue),e(Aue,jUo),e(B0,DUo),e(B0,bz),e(bz,GUo),e(B0,OUo),e(H,VUo),e(H,I0),e(I0,Lue),e(Lue,XUo),e(I0,zUo),e(I0,vz),e(vz,WUo),e(I0,QUo),e(H,HUo),e(H,N0),e(N0,yue),e(yue,UUo),e(N0,JUo),e(N0,Fz),e(Fz,YUo),e(N0,KUo),e(H,ZUo),e(H,q0),e(q0,xue),e(xue,eJo),e(q0,oJo),e(q0,Tz),e(Tz,rJo),e(q0,tJo),e(H,aJo),e(H,j0),e(j0,$ue),e($ue,nJo),e(j0,sJo),e(j0,Mz),e(Mz,lJo),e(j0,iJo),e(H,dJo),e(H,D0),e(D0,kue),e(kue,cJo),e(D0,fJo),e(D0,Ez),e(Ez,mJo),e(D0,gJo),e(H,hJo),e(H,G0),e(G0,Sue),e(Sue,pJo),e(G0,_Jo),e(G0,Cz),e(Cz,uJo),e(G0,bJo),e(H,vJo),e(H,O0),e(O0,Rue),e(Rue,FJo),e(O0,TJo),e(O0,wz),e(wz,MJo),e(O0,EJo),e(H,CJo),e(H,V0),e(V0,Pue),e(Pue,wJo),e(V0,AJo),e(V0,Az),e(Az,LJo),e(V0,yJo),e(H,xJo),e(H,X0),e(X0,Bue),e(Bue,$Jo),e(X0,kJo),e(X0,Lz),e(Lz,SJo),e(X0,RJo),e(H,PJo),e(H,z0),e(z0,Iue),e(Iue,BJo),e(z0,IJo),e(z0,yz),e(yz,NJo),e(z0,qJo),e(H,jJo),e(H,W0),e(W0,Nue),e(Nue,DJo),e(W0,GJo),e(W0,xz),e(xz,OJo),e(W0,VJo),e(H,XJo),e(H,Q0),e(Q0,que),e(que,zJo),e(Q0,WJo),e(Q0,$z),e($z,QJo),e(Q0,HJo),e(H,UJo),e(H,H0),e(H0,jue),e(jue,JJo),e(H0,YJo),e(H0,kz),e(kz,KJo),e(H0,ZJo),e(H,eYo),e(H,U0),e(U0,Due),e(Due,oYo),e(U0,rYo),e(U0,Sz),e(Sz,tYo),e(U0,aYo),e(H,nYo),e(H,J0),e(J0,Gue),e(Gue,sYo),e(J0,lYo),e(J0,Rz),e(Rz,iYo),e(J0,dYo),e(H,cYo),e(H,Y0),e(Y0,Oue),e(Oue,fYo),e(Y0,mYo),e(Y0,Pz),e(Pz,gYo),e(Y0,hYo),e(H,pYo),e(H,K0),e(K0,Vue),e(Vue,_Yo),e(K0,uYo),e(K0,Bz),e(Bz,bYo),e(K0,vYo),e(H,FYo),e(H,Z0),e(Z0,Xue),e(Xue,TYo),e(Z0,MYo),e(Z0,Iz),e(Iz,EYo),e(Z0,CYo),e(H,wYo),e(H,eF),e(eF,zue),e(zue,AYo),e(eF,LYo),e(eF,Nz),e(Nz,yYo),e(eF,xYo),e(H,$Yo),e(H,oF),e(oF,Wue),e(Wue,kYo),e(oF,SYo),e(oF,qz),e(qz,RYo),e(oF,PYo),e(H,BYo),e(H,rF),e(rF,Que),e(Que,IYo),e(rF,NYo),e(rF,jz),e(jz,qYo),e(rF,jYo),e(H,DYo),e(H,tF),e(tF,Hue),e(Hue,GYo),e(tF,OYo),e(tF,Dz),e(Dz,VYo),e(tF,XYo),e(ao,zYo),e(ao,aF),e(aF,WYo),e(aF,Uue),e(Uue,QYo),e(aF,HYo),e(aF,Jue),e(Jue,UYo),e(ao,JYo),M(nF,ao,null),b(f,uVe,u),b(f,md,u),e(md,sF),e(sF,Yue),M(ny,Yue,null),e(md,YYo),e(md,Kue),e(Kue,KYo),b(f,bVe,u),b(f,jo,u),M(sy,jo,null),e(jo,ZYo),e(jo,gd),e(gd,eKo),e(gd,Gz),e(Gz,oKo),e(gd,rKo),e(gd,Oz),e(Oz,tKo),e(gd,aKo),e(jo,nKo),e(jo,ly),e(ly,sKo),e(ly,Zue),e(Zue,lKo),e(ly,iKo),e(jo,dKo),e(jo,pt),M(iy,pt,null),e(pt,cKo),e(pt,e1e),e(e1e,fKo),e(pt,mKo),e(pt,hd),e(hd,gKo),e(hd,o1e),e(o1e,hKo),e(hd,pKo),e(hd,Vz),e(Vz,_Ko),e(hd,uKo),e(pt,bKo),M(lF,pt,null),e(jo,vKo),e(jo,no),M(dy,no,null),e(no,FKo),e(no,r1e),e(r1e,TKo),e(no,MKo),e(no,Xa),e(Xa,EKo),e(Xa,t1e),e(t1e,CKo),e(Xa,wKo),e(Xa,a1e),e(a1e,AKo),e(Xa,LKo),e(Xa,n1e),e(n1e,yKo),e(Xa,xKo),e(no,$Ko),e(no,V),e(V,iF),e(iF,s1e),e(s1e,kKo),e(iF,SKo),e(iF,Xz),e(Xz,RKo),e(iF,PKo),e(V,BKo),e(V,dF),e(dF,l1e),e(l1e,IKo),e(dF,NKo),e(dF,zz),e(zz,qKo),e(dF,jKo),e(V,DKo),e(V,cF),e(cF,i1e),e(i1e,GKo),e(cF,OKo),e(cF,Wz),e(Wz,VKo),e(cF,XKo),e(V,zKo),e(V,fF),e(fF,d1e),e(d1e,WKo),e(fF,QKo),e(fF,Qz),e(Qz,HKo),e(fF,UKo),e(V,JKo),e(V,mF),e(mF,c1e),e(c1e,YKo),e(mF,KKo),e(mF,Hz),e(Hz,ZKo),e(mF,eZo),e(V,oZo),e(V,gF),e(gF,f1e),e(f1e,rZo),e(gF,tZo),e(gF,Uz),e(Uz,aZo),e(gF,nZo),e(V,sZo),e(V,hF),e(hF,m1e),e(m1e,lZo),e(hF,iZo),e(hF,Jz),e(Jz,dZo),e(hF,cZo),e(V,fZo),e(V,pF),e(pF,g1e),e(g1e,mZo),e(pF,gZo),e(pF,Yz),e(Yz,hZo),e(pF,pZo),e(V,_Zo),e(V,_F),e(_F,h1e),e(h1e,uZo),e(_F,bZo),e(_F,Kz),e(Kz,vZo),e(_F,FZo),e(V,TZo),e(V,uF),e(uF,p1e),e(p1e,MZo),e(uF,EZo),e(uF,Zz),e(Zz,CZo),e(uF,wZo),e(V,AZo),e(V,bF),e(bF,_1e),e(_1e,LZo),e(bF,yZo),e(bF,eW),e(eW,xZo),e(bF,$Zo),e(V,kZo),e(V,vF),e(vF,u1e),e(u1e,SZo),e(vF,RZo),e(vF,oW),e(oW,PZo),e(vF,BZo),e(V,IZo),e(V,FF),e(FF,b1e),e(b1e,NZo),e(FF,qZo),e(FF,rW),e(rW,jZo),e(FF,DZo),e(V,GZo),e(V,TF),e(TF,v1e),e(v1e,OZo),e(TF,VZo),e(TF,tW),e(tW,XZo),e(TF,zZo),e(V,WZo),e(V,MF),e(MF,F1e),e(F1e,QZo),e(MF,HZo),e(MF,aW),e(aW,UZo),e(MF,JZo),e(V,YZo),e(V,EF),e(EF,T1e),e(T1e,KZo),e(EF,ZZo),e(EF,nW),e(nW,eer),e(EF,oer),e(V,rer),e(V,CF),e(CF,M1e),e(M1e,ter),e(CF,aer),e(CF,sW),e(sW,ner),e(CF,ser),e(V,ler),e(V,wF),e(wF,E1e),e(E1e,ier),e(wF,der),e(wF,lW),e(lW,cer),e(wF,fer),e(V,mer),e(V,AF),e(AF,C1e),e(C1e,ger),e(AF,her),e(AF,iW),e(iW,per),e(AF,_er),e(V,uer),e(V,LF),e(LF,w1e),e(w1e,ber),e(LF,ver),e(LF,dW),e(dW,Fer),e(LF,Ter),e(V,Mer),e(V,yF),e(yF,A1e),e(A1e,Eer),e(yF,Cer),e(yF,cW),e(cW,wer),e(yF,Aer),e(V,Ler),e(V,xF),e(xF,L1e),e(L1e,yer),e(xF,xer),e(xF,fW),e(fW,$er),e(xF,ker),e(V,Ser),e(V,$F),e($F,y1e),e(y1e,Rer),e($F,Per),e($F,mW),e(mW,Ber),e($F,Ier),e(V,Ner),e(V,kF),e(kF,x1e),e(x1e,qer),e(kF,jer),e(kF,gW),e(gW,Der),e(kF,Ger),e(V,Oer),e(V,SF),e(SF,$1e),e($1e,Ver),e(SF,Xer),e(SF,hW),e(hW,zer),e(SF,Wer),e(V,Qer),e(V,RF),e(RF,k1e),e(k1e,Her),e(RF,Uer),e(RF,pW),e(pW,Jer),e(RF,Yer),e(V,Ker),e(V,PF),e(PF,S1e),e(S1e,Zer),e(PF,eor),e(PF,_W),e(_W,oor),e(PF,ror),e(V,tor),e(V,BF),e(BF,R1e),e(R1e,aor),e(BF,nor),e(BF,uW),e(uW,sor),e(BF,lor),e(V,ior),e(V,IF),e(IF,P1e),e(P1e,dor),e(IF,cor),e(IF,bW),e(bW,mor),e(IF,gor),e(V,hor),e(V,NF),e(NF,B1e),e(B1e,por),e(NF,_or),e(NF,vW),e(vW,uor),e(NF,bor),e(V,vor),e(V,qF),e(qF,I1e),e(I1e,For),e(qF,Tor),e(qF,FW),e(FW,Mor),e(qF,Eor),e(V,Cor),e(V,jF),e(jF,N1e),e(N1e,wor),e(jF,Aor),e(jF,TW),e(TW,Lor),e(jF,yor),e(V,xor),e(V,DF),e(DF,q1e),e(q1e,$or),e(DF,kor),e(DF,MW),e(MW,Sor),e(DF,Ror),e(V,Por),e(V,GF),e(GF,j1e),e(j1e,Bor),e(GF,Ior),e(GF,EW),e(EW,Nor),e(GF,qor),e(V,jor),e(V,OF),e(OF,D1e),e(D1e,Dor),e(OF,Gor),e(OF,CW),e(CW,Oor),e(OF,Vor),e(V,Xor),e(V,VF),e(VF,G1e),e(G1e,zor),e(VF,Wor),e(VF,wW),e(wW,Qor),e(VF,Hor),e(V,Uor),e(V,XF),e(XF,O1e),e(O1e,Jor),e(XF,Yor),e(XF,AW),e(AW,Kor),e(XF,Zor),e(V,err),e(V,zF),e(zF,V1e),e(V1e,orr),e(zF,rrr),e(zF,LW),e(LW,trr),e(zF,arr),e(V,nrr),e(V,WF),e(WF,X1e),e(X1e,srr),e(WF,lrr),e(WF,yW),e(yW,irr),e(WF,drr),e(V,crr),e(V,QF),e(QF,z1e),e(z1e,frr),e(QF,mrr),e(QF,xW),e(xW,grr),e(QF,hrr),e(V,prr),e(V,HF),e(HF,W1e),e(W1e,_rr),e(HF,urr),e(HF,$W),e($W,brr),e(HF,vrr),e(no,Frr),e(no,UF),e(UF,Trr),e(UF,Q1e),e(Q1e,Mrr),e(UF,Err),e(UF,H1e),e(H1e,Crr),e(no,wrr),M(JF,no,null),b(f,vVe,u),b(f,pd,u),e(pd,YF),e(YF,U1e),M(cy,U1e,null),e(pd,Arr),e(pd,J1e),e(J1e,Lrr),b(f,FVe,u),b(f,Do,u),M(fy,Do,null),e(Do,yrr),e(Do,_d),e(_d,xrr),e(_d,kW),e(kW,$rr),e(_d,krr),e(_d,SW),e(SW,Srr),e(_d,Rrr),e(Do,Prr),e(Do,my),e(my,Brr),e(my,Y1e),e(Y1e,Irr),e(my,Nrr),e(Do,qrr),e(Do,_t),M(gy,_t,null),e(_t,jrr),e(_t,K1e),e(K1e,Drr),e(_t,Grr),e(_t,ud),e(ud,Orr),e(ud,Z1e),e(Z1e,Vrr),e(ud,Xrr),e(ud,RW),e(RW,zrr),e(ud,Wrr),e(_t,Qrr),M(KF,_t,null),e(Do,Hrr),e(Do,so),M(hy,so,null),e(so,Urr),e(so,e2e),e(e2e,Jrr),e(so,Yrr),e(so,za),e(za,Krr),e(za,o2e),e(o2e,Zrr),e(za,etr),e(za,r2e),e(r2e,otr),e(za,rtr),e(za,t2e),e(t2e,ttr),e(za,atr),e(so,ntr),e(so,a2e),e(a2e,ZF),e(ZF,n2e),e(n2e,str),e(ZF,ltr),e(ZF,PW),e(PW,itr),e(ZF,dtr),e(so,ctr),e(so,e6),e(e6,ftr),e(e6,s2e),e(s2e,mtr),e(e6,gtr),e(e6,l2e),e(l2e,htr),e(so,ptr),M(o6,so,null),b(f,TVe,u),b(f,bd,u),e(bd,r6),e(r6,i2e),M(py,i2e,null),e(bd,_tr),e(bd,d2e),e(d2e,utr),b(f,MVe,u),b(f,Go,u),M(_y,Go,null),e(Go,btr),e(Go,vd),e(vd,vtr),e(vd,BW),e(BW,Ftr),e(vd,Ttr),e(vd,IW),e(IW,Mtr),e(vd,Etr),e(Go,Ctr),e(Go,uy),e(uy,wtr),e(uy,c2e),e(c2e,Atr),e(uy,Ltr),e(Go,ytr),e(Go,ut),M(by,ut,null),e(ut,xtr),e(ut,f2e),e(f2e,$tr),e(ut,ktr),e(ut,Fd),e(Fd,Str),e(Fd,m2e),e(m2e,Rtr),e(Fd,Ptr),e(Fd,NW),e(NW,Btr),e(Fd,Itr),e(ut,Ntr),M(t6,ut,null),e(Go,qtr),e(Go,lo),M(vy,lo,null),e(lo,jtr),e(lo,g2e),e(g2e,Dtr),e(lo,Gtr),e(lo,Wa),e(Wa,Otr),e(Wa,h2e),e(h2e,Vtr),e(Wa,Xtr),e(Wa,p2e),e(p2e,ztr),e(Wa,Wtr),e(Wa,_2e),e(_2e,Qtr),e(Wa,Htr),e(lo,Utr),e(lo,Fe),e(Fe,a6),e(a6,u2e),e(u2e,Jtr),e(a6,Ytr),e(a6,qW),e(qW,Ktr),e(a6,Ztr),e(Fe,ear),e(Fe,n6),e(n6,b2e),e(b2e,oar),e(n6,rar),e(n6,jW),e(jW,tar),e(n6,aar),e(Fe,nar),e(Fe,s6),e(s6,v2e),e(v2e,sar),e(s6,lar),e(s6,DW),e(DW,iar),e(s6,dar),e(Fe,car),e(Fe,l6),e(l6,F2e),e(F2e,far),e(l6,mar),e(l6,GW),e(GW,gar),e(l6,har),e(Fe,par),e(Fe,Qs),e(Qs,T2e),e(T2e,_ar),e(Qs,uar),e(Qs,OW),e(OW,bar),e(Qs,Far),e(Qs,VW),e(VW,Tar),e(Qs,Mar),e(Fe,Ear),e(Fe,i6),e(i6,M2e),e(M2e,Car),e(i6,war),e(i6,XW),e(XW,Aar),e(i6,Lar),e(Fe,yar),e(Fe,Hs),e(Hs,E2e),e(E2e,xar),e(Hs,$ar),e(Hs,zW),e(zW,kar),e(Hs,Sar),e(Hs,WW),e(WW,Rar),e(Hs,Par),e(Fe,Bar),e(Fe,bt),e(bt,C2e),e(C2e,Iar),e(bt,Nar),e(bt,QW),e(QW,qar),e(bt,jar),e(bt,HW),e(HW,Dar),e(bt,Gar),e(bt,UW),e(UW,Oar),e(bt,Var),e(Fe,Xar),e(Fe,d6),e(d6,w2e),e(w2e,zar),e(d6,War),e(d6,JW),e(JW,Qar),e(d6,Har),e(Fe,Uar),e(Fe,c6),e(c6,A2e),e(A2e,Jar),e(c6,Yar),e(c6,YW),e(YW,Kar),e(c6,Zar),e(Fe,enr),e(Fe,f6),e(f6,L2e),e(L2e,onr),e(f6,rnr),e(f6,KW),e(KW,tnr),e(f6,anr),e(Fe,nnr),e(Fe,m6),e(m6,y2e),e(y2e,snr),e(m6,lnr),e(m6,ZW),e(ZW,inr),e(m6,dnr),e(Fe,cnr),e(Fe,g6),e(g6,x2e),e(x2e,fnr),e(g6,mnr),e(g6,eQ),e(eQ,gnr),e(g6,hnr),e(Fe,pnr),e(Fe,h6),e(h6,$2e),e($2e,_nr),e(h6,unr),e(h6,oQ),e(oQ,bnr),e(h6,vnr),e(Fe,Fnr),e(Fe,p6),e(p6,k2e),e(k2e,Tnr),e(p6,Mnr),e(p6,rQ),e(rQ,Enr),e(p6,Cnr),e(lo,wnr),e(lo,_6),e(_6,Anr),e(_6,S2e),e(S2e,Lnr),e(_6,ynr),e(_6,R2e),e(R2e,xnr),e(lo,$nr),M(u6,lo,null),b(f,EVe,u),b(f,Td,u),e(Td,b6),e(b6,P2e),M(Fy,P2e,null),e(Td,knr),e(Td,B2e),e(B2e,Snr),b(f,CVe,u),b(f,Oo,u),M(Ty,Oo,null),e(Oo,Rnr),e(Oo,Md),e(Md,Pnr),e(Md,tQ),e(tQ,Bnr),e(Md,Inr),e(Md,aQ),e(aQ,Nnr),e(Md,qnr),e(Oo,jnr),e(Oo,My),e(My,Dnr),e(My,I2e),e(I2e,Gnr),e(My,Onr),e(Oo,Vnr),e(Oo,vt),M(Ey,vt,null),e(vt,Xnr),e(vt,N2e),e(N2e,znr),e(vt,Wnr),e(vt,Ed),e(Ed,Qnr),e(Ed,q2e),e(q2e,Hnr),e(Ed,Unr),e(Ed,nQ),e(nQ,Jnr),e(Ed,Ynr),e(vt,Knr),M(v6,vt,null),e(Oo,Znr),e(Oo,io),M(Cy,io,null),e(io,esr),e(io,j2e),e(j2e,osr),e(io,rsr),e(io,Qa),e(Qa,tsr),e(Qa,D2e),e(D2e,asr),e(Qa,nsr),e(Qa,G2e),e(G2e,ssr),e(Qa,lsr),e(Qa,O2e),e(O2e,isr),e(Qa,dsr),e(io,csr),e(io,V2e),e(V2e,F6),e(F6,X2e),e(X2e,fsr),e(F6,msr),e(F6,sQ),e(sQ,gsr),e(F6,hsr),e(io,psr),e(io,T6),e(T6,_sr),e(T6,z2e),e(z2e,usr),e(T6,bsr),e(T6,W2e),e(W2e,vsr),e(io,Fsr),M(M6,io,null),b(f,wVe,u),b(f,Cd,u),e(Cd,E6),e(E6,Q2e),M(wy,Q2e,null),e(Cd,Tsr),e(Cd,H2e),e(H2e,Msr),b(f,AVe,u),b(f,Vo,u),M(Ay,Vo,null),e(Vo,Esr),e(Vo,wd),e(wd,Csr),e(wd,lQ),e(lQ,wsr),e(wd,Asr),e(wd,iQ),e(iQ,Lsr),e(wd,ysr),e(Vo,xsr),e(Vo,Ly),e(Ly,$sr),e(Ly,U2e),e(U2e,ksr),e(Ly,Ssr),e(Vo,Rsr),e(Vo,Ft),M(yy,Ft,null),e(Ft,Psr),e(Ft,J2e),e(J2e,Bsr),e(Ft,Isr),e(Ft,Ad),e(Ad,Nsr),e(Ad,Y2e),e(Y2e,qsr),e(Ad,jsr),e(Ad,dQ),e(dQ,Dsr),e(Ad,Gsr),e(Ft,Osr),M(C6,Ft,null),e(Vo,Vsr),e(Vo,co),M(xy,co,null),e(co,Xsr),e(co,K2e),e(K2e,zsr),e(co,Wsr),e(co,Ha),e(Ha,Qsr),e(Ha,Z2e),e(Z2e,Hsr),e(Ha,Usr),e(Ha,ebe),e(ebe,Jsr),e(Ha,Ysr),e(Ha,obe),e(obe,Ksr),e(Ha,Zsr),e(co,elr),e(co,rbe),e(rbe,w6),e(w6,tbe),e(tbe,olr),e(w6,rlr),e(w6,cQ),e(cQ,tlr),e(w6,alr),e(co,nlr),e(co,A6),e(A6,slr),e(A6,abe),e(abe,llr),e(A6,ilr),e(A6,nbe),e(nbe,dlr),e(co,clr),M(L6,co,null),b(f,LVe,u),b(f,Ld,u),e(Ld,y6),e(y6,sbe),M($y,sbe,null),e(Ld,flr),e(Ld,lbe),e(lbe,mlr),b(f,yVe,u),b(f,Xo,u),M(ky,Xo,null),e(Xo,glr),e(Xo,yd),e(yd,hlr),e(yd,fQ),e(fQ,plr),e(yd,_lr),e(yd,mQ),e(mQ,ulr),e(yd,blr),e(Xo,vlr),e(Xo,Sy),e(Sy,Flr),e(Sy,ibe),e(ibe,Tlr),e(Sy,Mlr),e(Xo,Elr),e(Xo,Tt),M(Ry,Tt,null),e(Tt,Clr),e(Tt,dbe),e(dbe,wlr),e(Tt,Alr),e(Tt,xd),e(xd,Llr),e(xd,cbe),e(cbe,ylr),e(xd,xlr),e(xd,gQ),e(gQ,$lr),e(xd,klr),e(Tt,Slr),M(x6,Tt,null),e(Xo,Rlr),e(Xo,fo),M(Py,fo,null),e(fo,Plr),e(fo,fbe),e(fbe,Blr),e(fo,Ilr),e(fo,Ua),e(Ua,Nlr),e(Ua,mbe),e(mbe,qlr),e(Ua,jlr),e(Ua,gbe),e(gbe,Dlr),e(Ua,Glr),e(Ua,hbe),e(hbe,Olr),e(Ua,Vlr),e(fo,Xlr),e(fo,Pe),e(Pe,$6),e($6,pbe),e(pbe,zlr),e($6,Wlr),e($6,hQ),e(hQ,Qlr),e($6,Hlr),e(Pe,Ulr),e(Pe,k6),e(k6,_be),e(_be,Jlr),e(k6,Ylr),e(k6,pQ),e(pQ,Klr),e(k6,Zlr),e(Pe,eir),e(Pe,S6),e(S6,ube),e(ube,oir),e(S6,rir),e(S6,_Q),e(_Q,tir),e(S6,air),e(Pe,nir),e(Pe,R6),e(R6,bbe),e(bbe,sir),e(R6,lir),e(R6,uQ),e(uQ,iir),e(R6,dir),e(Pe,cir),e(Pe,P6),e(P6,vbe),e(vbe,fir),e(P6,mir),e(P6,bQ),e(bQ,gir),e(P6,hir),e(Pe,pir),e(Pe,B6),e(B6,Fbe),e(Fbe,_ir),e(B6,uir),e(B6,vQ),e(vQ,bir),e(B6,vir),e(Pe,Fir),e(Pe,I6),e(I6,Tbe),e(Tbe,Tir),e(I6,Mir),e(I6,FQ),e(FQ,Eir),e(I6,Cir),e(Pe,wir),e(Pe,N6),e(N6,Mbe),e(Mbe,Air),e(N6,Lir),e(N6,TQ),e(TQ,yir),e(N6,xir),e(Pe,$ir),e(Pe,q6),e(q6,Ebe),e(Ebe,kir),e(q6,Sir),e(q6,MQ),e(MQ,Rir),e(q6,Pir),e(fo,Bir),e(fo,j6),e(j6,Iir),e(j6,Cbe),e(Cbe,Nir),e(j6,qir),e(j6,wbe),e(wbe,jir),e(fo,Dir),M(D6,fo,null),b(f,xVe,u),b(f,$d,u),e($d,G6),e(G6,Abe),M(By,Abe,null),e($d,Gir),e($d,Lbe),e(Lbe,Oir),b(f,$Ve,u),b(f,zo,u),M(Iy,zo,null),e(zo,Vir),e(zo,kd),e(kd,Xir),e(kd,EQ),e(EQ,zir),e(kd,Wir),e(kd,CQ),e(CQ,Qir),e(kd,Hir),e(zo,Uir),e(zo,Ny),e(Ny,Jir),e(Ny,ybe),e(ybe,Yir),e(Ny,Kir),e(zo,Zir),e(zo,Mt),M(qy,Mt,null),e(Mt,edr),e(Mt,xbe),e(xbe,odr),e(Mt,rdr),e(Mt,Sd),e(Sd,tdr),e(Sd,$be),e($be,adr),e(Sd,ndr),e(Sd,wQ),e(wQ,sdr),e(Sd,ldr),e(Mt,idr),M(O6,Mt,null),e(zo,ddr),e(zo,mo),M(jy,mo,null),e(mo,cdr),e(mo,kbe),e(kbe,fdr),e(mo,mdr),e(mo,Ja),e(Ja,gdr),e(Ja,Sbe),e(Sbe,hdr),e(Ja,pdr),e(Ja,Rbe),e(Rbe,_dr),e(Ja,udr),e(Ja,Pbe),e(Pbe,bdr),e(Ja,vdr),e(mo,Fdr),e(mo,ot),e(ot,V6),e(V6,Bbe),e(Bbe,Tdr),e(V6,Mdr),e(V6,AQ),e(AQ,Edr),e(V6,Cdr),e(ot,wdr),e(ot,X6),e(X6,Ibe),e(Ibe,Adr),e(X6,Ldr),e(X6,LQ),e(LQ,ydr),e(X6,xdr),e(ot,$dr),e(ot,z6),e(z6,Nbe),e(Nbe,kdr),e(z6,Sdr),e(z6,yQ),e(yQ,Rdr),e(z6,Pdr),e(ot,Bdr),e(ot,W6),e(W6,qbe),e(qbe,Idr),e(W6,Ndr),e(W6,xQ),e(xQ,qdr),e(W6,jdr),e(ot,Ddr),e(ot,Q6),e(Q6,jbe),e(jbe,Gdr),e(Q6,Odr),e(Q6,$Q),e($Q,Vdr),e(Q6,Xdr),e(mo,zdr),e(mo,H6),e(H6,Wdr),e(H6,Dbe),e(Dbe,Qdr),e(H6,Hdr),e(H6,Gbe),e(Gbe,Udr),e(mo,Jdr),M(U6,mo,null),b(f,kVe,u),b(f,Rd,u),e(Rd,J6),e(J6,Obe),M(Dy,Obe,null),e(Rd,Ydr),e(Rd,Vbe),e(Vbe,Kdr),b(f,SVe,u),b(f,Wo,u),M(Gy,Wo,null),e(Wo,Zdr),e(Wo,Pd),e(Pd,ecr),e(Pd,kQ),e(kQ,ocr),e(Pd,rcr),e(Pd,SQ),e(SQ,tcr),e(Pd,acr),e(Wo,ncr),e(Wo,Oy),e(Oy,scr),e(Oy,Xbe),e(Xbe,lcr),e(Oy,icr),e(Wo,dcr),e(Wo,Et),M(Vy,Et,null),e(Et,ccr),e(Et,zbe),e(zbe,fcr),e(Et,mcr),e(Et,Bd),e(Bd,gcr),e(Bd,Wbe),e(Wbe,hcr),e(Bd,pcr),e(Bd,RQ),e(RQ,_cr),e(Bd,ucr),e(Et,bcr),M(Y6,Et,null),e(Wo,vcr),e(Wo,go),M(Xy,go,null),e(go,Fcr),e(go,Qbe),e(Qbe,Tcr),e(go,Mcr),e(go,Ya),e(Ya,Ecr),e(Ya,Hbe),e(Hbe,Ccr),e(Ya,wcr),e(Ya,Ube),e(Ube,Acr),e(Ya,Lcr),e(Ya,Jbe),e(Jbe,ycr),e(Ya,xcr),e(go,$cr),e(go,Le),e(Le,K6),e(K6,Ybe),e(Ybe,kcr),e(K6,Scr),e(K6,PQ),e(PQ,Rcr),e(K6,Pcr),e(Le,Bcr),e(Le,Z6),e(Z6,Kbe),e(Kbe,Icr),e(Z6,Ncr),e(Z6,BQ),e(BQ,qcr),e(Z6,jcr),e(Le,Dcr),e(Le,eT),e(eT,Zbe),e(Zbe,Gcr),e(eT,Ocr),e(eT,IQ),e(IQ,Vcr),e(eT,Xcr),e(Le,zcr),e(Le,oT),e(oT,eve),e(eve,Wcr),e(oT,Qcr),e(oT,NQ),e(NQ,Hcr),e(oT,Ucr),e(Le,Jcr),e(Le,rT),e(rT,ove),e(ove,Ycr),e(rT,Kcr),e(rT,qQ),e(qQ,Zcr),e(rT,efr),e(Le,ofr),e(Le,tT),e(tT,rve),e(rve,rfr),e(tT,tfr),e(tT,jQ),e(jQ,afr),e(tT,nfr),e(Le,sfr),e(Le,aT),e(aT,tve),e(tve,lfr),e(aT,ifr),e(aT,DQ),e(DQ,dfr),e(aT,cfr),e(Le,ffr),e(Le,nT),e(nT,ave),e(ave,mfr),e(nT,gfr),e(nT,GQ),e(GQ,hfr),e(nT,pfr),e(Le,_fr),e(Le,sT),e(sT,nve),e(nve,ufr),e(sT,bfr),e(sT,OQ),e(OQ,vfr),e(sT,Ffr),e(Le,Tfr),e(Le,lT),e(lT,sve),e(sve,Mfr),e(lT,Efr),e(lT,VQ),e(VQ,Cfr),e(lT,wfr),e(go,Afr),e(go,iT),e(iT,Lfr),e(iT,lve),e(lve,yfr),e(iT,xfr),e(iT,ive),e(ive,$fr),e(go,kfr),M(dT,go,null),b(f,RVe,u),b(f,Id,u),e(Id,cT),e(cT,dve),M(zy,dve,null),e(Id,Sfr),e(Id,cve),e(cve,Rfr),b(f,PVe,u),b(f,Qo,u),M(Wy,Qo,null),e(Qo,Pfr),e(Qo,Nd),e(Nd,Bfr),e(Nd,XQ),e(XQ,Ifr),e(Nd,Nfr),e(Nd,zQ),e(zQ,qfr),e(Nd,jfr),e(Qo,Dfr),e(Qo,Qy),e(Qy,Gfr),e(Qy,fve),e(fve,Ofr),e(Qy,Vfr),e(Qo,Xfr),e(Qo,Ct),M(Hy,Ct,null),e(Ct,zfr),e(Ct,mve),e(mve,Wfr),e(Ct,Qfr),e(Ct,qd),e(qd,Hfr),e(qd,gve),e(gve,Ufr),e(qd,Jfr),e(qd,WQ),e(WQ,Yfr),e(qd,Kfr),e(Ct,Zfr),M(fT,Ct,null),e(Qo,emr),e(Qo,ho),M(Uy,ho,null),e(ho,omr),e(ho,hve),e(hve,rmr),e(ho,tmr),e(ho,Ka),e(Ka,amr),e(Ka,pve),e(pve,nmr),e(Ka,smr),e(Ka,_ve),e(_ve,lmr),e(Ka,imr),e(Ka,uve),e(uve,dmr),e(Ka,cmr),e(ho,fmr),e(ho,Jy),e(Jy,mT),e(mT,bve),e(bve,mmr),e(mT,gmr),e(mT,QQ),e(QQ,hmr),e(mT,pmr),e(Jy,_mr),e(Jy,gT),e(gT,vve),e(vve,umr),e(gT,bmr),e(gT,HQ),e(HQ,vmr),e(gT,Fmr),e(ho,Tmr),e(ho,hT),e(hT,Mmr),e(hT,Fve),e(Fve,Emr),e(hT,Cmr),e(hT,Tve),e(Tve,wmr),e(ho,Amr),M(pT,ho,null),b(f,BVe,u),b(f,jd,u),e(jd,_T),e(_T,Mve),M(Yy,Mve,null),e(jd,Lmr),e(jd,Eve),e(Eve,ymr),b(f,IVe,u),b(f,Ho,u),M(Ky,Ho,null),e(Ho,xmr),e(Ho,Dd),e(Dd,$mr),e(Dd,UQ),e(UQ,kmr),e(Dd,Smr),e(Dd,JQ),e(JQ,Rmr),e(Dd,Pmr),e(Ho,Bmr),e(Ho,Zy),e(Zy,Imr),e(Zy,Cve),e(Cve,Nmr),e(Zy,qmr),e(Ho,jmr),e(Ho,wt),M(e9,wt,null),e(wt,Dmr),e(wt,wve),e(wve,Gmr),e(wt,Omr),e(wt,Gd),e(Gd,Vmr),e(Gd,Ave),e(Ave,Xmr),e(Gd,zmr),e(Gd,YQ),e(YQ,Wmr),e(Gd,Qmr),e(wt,Hmr),M(uT,wt,null),e(Ho,Umr),e(Ho,po),M(o9,po,null),e(po,Jmr),e(po,Lve),e(Lve,Ymr),e(po,Kmr),e(po,Za),e(Za,Zmr),e(Za,yve),e(yve,egr),e(Za,ogr),e(Za,xve),e(xve,rgr),e(Za,tgr),e(Za,$ve),e($ve,agr),e(Za,ngr),e(po,sgr),e(po,rt),e(rt,bT),e(bT,kve),e(kve,lgr),e(bT,igr),e(bT,KQ),e(KQ,dgr),e(bT,cgr),e(rt,fgr),e(rt,vT),e(vT,Sve),e(Sve,mgr),e(vT,ggr),e(vT,ZQ),e(ZQ,hgr),e(vT,pgr),e(rt,_gr),e(rt,FT),e(FT,Rve),e(Rve,ugr),e(FT,bgr),e(FT,eH),e(eH,vgr),e(FT,Fgr),e(rt,Tgr),e(rt,TT),e(TT,Pve),e(Pve,Mgr),e(TT,Egr),e(TT,oH),e(oH,Cgr),e(TT,wgr),e(rt,Agr),e(rt,MT),e(MT,Bve),e(Bve,Lgr),e(MT,ygr),e(MT,rH),e(rH,xgr),e(MT,$gr),e(po,kgr),e(po,ET),e(ET,Sgr),e(ET,Ive),e(Ive,Rgr),e(ET,Pgr),e(ET,Nve),e(Nve,Bgr),e(po,Igr),M(CT,po,null),b(f,NVe,u),b(f,Od,u),e(Od,wT),e(wT,qve),M(r9,qve,null),e(Od,Ngr),e(Od,jve),e(jve,qgr),b(f,qVe,u),b(f,Uo,u),M(t9,Uo,null),e(Uo,jgr),e(Uo,Vd),e(Vd,Dgr),e(Vd,tH),e(tH,Ggr),e(Vd,Ogr),e(Vd,aH),e(aH,Vgr),e(Vd,Xgr),e(Uo,zgr),e(Uo,a9),e(a9,Wgr),e(a9,Dve),e(Dve,Qgr),e(a9,Hgr),e(Uo,Ugr),e(Uo,At),M(n9,At,null),e(At,Jgr),e(At,Gve),e(Gve,Ygr),e(At,Kgr),e(At,Xd),e(Xd,Zgr),e(Xd,Ove),e(Ove,ehr),e(Xd,ohr),e(Xd,nH),e(nH,rhr),e(Xd,thr),e(At,ahr),M(AT,At,null),e(Uo,nhr),e(Uo,_o),M(s9,_o,null),e(_o,shr),e(_o,Vve),e(Vve,lhr),e(_o,ihr),e(_o,en),e(en,dhr),e(en,Xve),e(Xve,chr),e(en,fhr),e(en,zve),e(zve,mhr),e(en,ghr),e(en,Wve),e(Wve,hhr),e(en,phr),e(_o,_hr),e(_o,zd),e(zd,LT),e(LT,Qve),e(Qve,uhr),e(LT,bhr),e(LT,sH),e(sH,vhr),e(LT,Fhr),e(zd,Thr),e(zd,yT),e(yT,Hve),e(Hve,Mhr),e(yT,Ehr),e(yT,lH),e(lH,Chr),e(yT,whr),e(zd,Ahr),e(zd,xT),e(xT,Uve),e(Uve,Lhr),e(xT,yhr),e(xT,iH),e(iH,xhr),e(xT,$hr),e(_o,khr),e(_o,$T),e($T,Shr),e($T,Jve),e(Jve,Rhr),e($T,Phr),e($T,Yve),e(Yve,Bhr),e(_o,Ihr),M(kT,_o,null),b(f,jVe,u),b(f,Wd,u),e(Wd,ST),e(ST,Kve),M(l9,Kve,null),e(Wd,Nhr),e(Wd,Zve),e(Zve,qhr),b(f,DVe,u),b(f,Jo,u),M(i9,Jo,null),e(Jo,jhr),e(Jo,Qd),e(Qd,Dhr),e(Qd,dH),e(dH,Ghr),e(Qd,Ohr),e(Qd,cH),e(cH,Vhr),e(Qd,Xhr),e(Jo,zhr),e(Jo,d9),e(d9,Whr),e(d9,e0e),e(e0e,Qhr),e(d9,Hhr),e(Jo,Uhr),e(Jo,Lt),M(c9,Lt,null),e(Lt,Jhr),e(Lt,o0e),e(o0e,Yhr),e(Lt,Khr),e(Lt,Hd),e(Hd,Zhr),e(Hd,r0e),e(r0e,epr),e(Hd,opr),e(Hd,fH),e(fH,rpr),e(Hd,tpr),e(Lt,apr),M(RT,Lt,null),e(Jo,npr),e(Jo,uo),M(f9,uo,null),e(uo,spr),e(uo,t0e),e(t0e,lpr),e(uo,ipr),e(uo,on),e(on,dpr),e(on,a0e),e(a0e,cpr),e(on,fpr),e(on,n0e),e(n0e,mpr),e(on,gpr),e(on,s0e),e(s0e,hpr),e(on,ppr),e(uo,_pr),e(uo,m9),e(m9,PT),e(PT,l0e),e(l0e,upr),e(PT,bpr),e(PT,mH),e(mH,vpr),e(PT,Fpr),e(m9,Tpr),e(m9,BT),e(BT,i0e),e(i0e,Mpr),e(BT,Epr),e(BT,gH),e(gH,Cpr),e(BT,wpr),e(uo,Apr),e(uo,IT),e(IT,Lpr),e(IT,d0e),e(d0e,ypr),e(IT,xpr),e(IT,c0e),e(c0e,$pr),e(uo,kpr),M(NT,uo,null),b(f,GVe,u),b(f,Ud,u),e(Ud,qT),e(qT,f0e),M(g9,f0e,null),e(Ud,Spr),e(Ud,m0e),e(m0e,Rpr),b(f,OVe,u),b(f,Yo,u),M(h9,Yo,null),e(Yo,Ppr),e(Yo,Jd),e(Jd,Bpr),e(Jd,hH),e(hH,Ipr),e(Jd,Npr),e(Jd,pH),e(pH,qpr),e(Jd,jpr),e(Yo,Dpr),e(Yo,p9),e(p9,Gpr),e(p9,g0e),e(g0e,Opr),e(p9,Vpr),e(Yo,Xpr),e(Yo,yt),M(_9,yt,null),e(yt,zpr),e(yt,h0e),e(h0e,Wpr),e(yt,Qpr),e(yt,Yd),e(Yd,Hpr),e(Yd,p0e),e(p0e,Upr),e(Yd,Jpr),e(Yd,_H),e(_H,Ypr),e(Yd,Kpr),e(yt,Zpr),M(jT,yt,null),e(Yo,e_r),e(Yo,bo),M(u9,bo,null),e(bo,o_r),e(bo,_0e),e(_0e,r_r),e(bo,t_r),e(bo,rn),e(rn,a_r),e(rn,u0e),e(u0e,n_r),e(rn,s_r),e(rn,b0e),e(b0e,l_r),e(rn,i_r),e(rn,v0e),e(v0e,d_r),e(rn,c_r),e(bo,f_r),e(bo,F0e),e(F0e,DT),e(DT,T0e),e(T0e,m_r),e(DT,g_r),e(DT,uH),e(uH,h_r),e(DT,p_r),e(bo,__r),e(bo,GT),e(GT,u_r),e(GT,M0e),e(M0e,b_r),e(GT,v_r),e(GT,E0e),e(E0e,F_r),e(bo,T_r),M(OT,bo,null),b(f,VVe,u),b(f,Kd,u),e(Kd,VT),e(VT,C0e),M(b9,C0e,null),e(Kd,M_r),e(Kd,w0e),e(w0e,E_r),b(f,XVe,u),b(f,Ko,u),M(v9,Ko,null),e(Ko,C_r),e(Ko,Zd),e(Zd,w_r),e(Zd,bH),e(bH,A_r),e(Zd,L_r),e(Zd,vH),e(vH,y_r),e(Zd,x_r),e(Ko,$_r),e(Ko,F9),e(F9,k_r),e(F9,A0e),e(A0e,S_r),e(F9,R_r),e(Ko,P_r),e(Ko,xt),M(T9,xt,null),e(xt,B_r),e(xt,L0e),e(L0e,I_r),e(xt,N_r),e(xt,ec),e(ec,q_r),e(ec,y0e),e(y0e,j_r),e(ec,D_r),e(ec,FH),e(FH,G_r),e(ec,O_r),e(xt,V_r),M(XT,xt,null),e(Ko,X_r),e(Ko,vo),M(M9,vo,null),e(vo,z_r),e(vo,x0e),e(x0e,W_r),e(vo,Q_r),e(vo,tn),e(tn,H_r),e(tn,$0e),e($0e,U_r),e(tn,J_r),e(tn,k0e),e(k0e,Y_r),e(tn,K_r),e(tn,S0e),e(S0e,Z_r),e(tn,eur),e(vo,our),e(vo,an),e(an,zT),e(zT,R0e),e(R0e,rur),e(zT,tur),e(zT,TH),e(TH,aur),e(zT,nur),e(an,sur),e(an,WT),e(WT,P0e),e(P0e,lur),e(WT,iur),e(WT,MH),e(MH,dur),e(WT,cur),e(an,fur),e(an,QT),e(QT,B0e),e(B0e,mur),e(QT,gur),e(QT,EH),e(EH,hur),e(QT,pur),e(an,_ur),e(an,HT),e(HT,I0e),e(I0e,uur),e(HT,bur),e(HT,CH),e(CH,vur),e(HT,Fur),e(vo,Tur),e(vo,UT),e(UT,Mur),e(UT,N0e),e(N0e,Eur),e(UT,Cur),e(UT,q0e),e(q0e,wur),e(vo,Aur),M(JT,vo,null),b(f,zVe,u),b(f,oc,u),e(oc,YT),e(YT,j0e),M(E9,j0e,null),e(oc,Lur),e(oc,D0e),e(D0e,yur),b(f,WVe,u),b(f,Zo,u),M(C9,Zo,null),e(Zo,xur),e(Zo,rc),e(rc,$ur),e(rc,wH),e(wH,kur),e(rc,Sur),e(rc,AH),e(AH,Rur),e(rc,Pur),e(Zo,Bur),e(Zo,w9),e(w9,Iur),e(w9,G0e),e(G0e,Nur),e(w9,qur),e(Zo,jur),e(Zo,$t),M(A9,$t,null),e($t,Dur),e($t,O0e),e(O0e,Gur),e($t,Our),e($t,tc),e(tc,Vur),e(tc,V0e),e(V0e,Xur),e(tc,zur),e(tc,LH),e(LH,Wur),e(tc,Qur),e($t,Hur),M(KT,$t,null),e(Zo,Uur),e(Zo,Fo),M(L9,Fo,null),e(Fo,Jur),e(Fo,X0e),e(X0e,Yur),e(Fo,Kur),e(Fo,nn),e(nn,Zur),e(nn,z0e),e(z0e,e1r),e(nn,o1r),e(nn,W0e),e(W0e,r1r),e(nn,t1r),e(nn,Q0e),e(Q0e,a1r),e(nn,n1r),e(Fo,s1r),e(Fo,H0e),e(H0e,ZT),e(ZT,U0e),e(U0e,l1r),e(ZT,i1r),e(ZT,yH),e(yH,d1r),e(ZT,c1r),e(Fo,f1r),e(Fo,e7),e(e7,m1r),e(e7,J0e),e(J0e,g1r),e(e7,h1r),e(e7,Y0e),e(Y0e,p1r),e(Fo,_1r),M(o7,Fo,null),b(f,QVe,u),b(f,ac,u),e(ac,r7),e(r7,K0e),M(y9,K0e,null),e(ac,u1r),e(ac,Z0e),e(Z0e,b1r),b(f,HVe,u),b(f,er,u),M(x9,er,null),e(er,v1r),e(er,nc),e(nc,F1r),e(nc,xH),e(xH,T1r),e(nc,M1r),e(nc,$H),e($H,E1r),e(nc,C1r),e(er,w1r),e(er,$9),e($9,A1r),e($9,eFe),e(eFe,L1r),e($9,y1r),e(er,x1r),e(er,kt),M(k9,kt,null),e(kt,$1r),e(kt,oFe),e(oFe,k1r),e(kt,S1r),e(kt,sc),e(sc,R1r),e(sc,rFe),e(rFe,P1r),e(sc,B1r),e(sc,kH),e(kH,I1r),e(sc,N1r),e(kt,q1r),M(t7,kt,null),e(er,j1r),e(er,xr),M(S9,xr,null),e(xr,D1r),e(xr,tFe),e(tFe,G1r),e(xr,O1r),e(xr,sn),e(sn,V1r),e(sn,aFe),e(aFe,X1r),e(sn,z1r),e(sn,nFe),e(nFe,W1r),e(sn,Q1r),e(sn,sFe),e(sFe,H1r),e(sn,U1r),e(xr,J1r),e(xr,q),e(q,a7),e(a7,lFe),e(lFe,Y1r),e(a7,K1r),e(a7,SH),e(SH,Z1r),e(a7,e2r),e(q,o2r),e(q,n7),e(n7,iFe),e(iFe,r2r),e(n7,t2r),e(n7,RH),e(RH,a2r),e(n7,n2r),e(q,s2r),e(q,s7),e(s7,dFe),e(dFe,l2r),e(s7,i2r),e(s7,PH),e(PH,d2r),e(s7,c2r),e(q,f2r),e(q,l7),e(l7,cFe),e(cFe,m2r),e(l7,g2r),e(l7,BH),e(BH,h2r),e(l7,p2r),e(q,_2r),e(q,i7),e(i7,fFe),e(fFe,u2r),e(i7,b2r),e(i7,IH),e(IH,v2r),e(i7,F2r),e(q,T2r),e(q,d7),e(d7,mFe),e(mFe,M2r),e(d7,E2r),e(d7,NH),e(NH,C2r),e(d7,w2r),e(q,A2r),e(q,c7),e(c7,gFe),e(gFe,L2r),e(c7,y2r),e(c7,qH),e(qH,x2r),e(c7,$2r),e(q,k2r),e(q,f7),e(f7,hFe),e(hFe,S2r),e(f7,R2r),e(f7,jH),e(jH,P2r),e(f7,B2r),e(q,I2r),e(q,m7),e(m7,pFe),e(pFe,N2r),e(m7,q2r),e(m7,DH),e(DH,j2r),e(m7,D2r),e(q,G2r),e(q,g7),e(g7,_Fe),e(_Fe,O2r),e(g7,V2r),e(g7,GH),e(GH,X2r),e(g7,z2r),e(q,W2r),e(q,h7),e(h7,uFe),e(uFe,Q2r),e(h7,H2r),e(h7,OH),e(OH,U2r),e(h7,J2r),e(q,Y2r),e(q,p7),e(p7,bFe),e(bFe,K2r),e(p7,Z2r),e(p7,VH),e(VH,ebr),e(p7,obr),e(q,rbr),e(q,_7),e(_7,vFe),e(vFe,tbr),e(_7,abr),e(_7,XH),e(XH,nbr),e(_7,sbr),e(q,lbr),e(q,u7),e(u7,FFe),e(FFe,ibr),e(u7,dbr),e(u7,zH),e(zH,cbr),e(u7,fbr),e(q,mbr),e(q,b7),e(b7,TFe),e(TFe,gbr),e(b7,hbr),e(b7,WH),e(WH,pbr),e(b7,_br),e(q,ubr),e(q,v7),e(v7,MFe),e(MFe,bbr),e(v7,vbr),e(v7,QH),e(QH,Fbr),e(v7,Tbr),e(q,Mbr),e(q,F7),e(F7,EFe),e(EFe,Ebr),e(F7,Cbr),e(F7,HH),e(HH,wbr),e(F7,Abr),e(q,Lbr),e(q,T7),e(T7,CFe),e(CFe,ybr),e(T7,xbr),e(T7,UH),e(UH,$br),e(T7,kbr),e(q,Sbr),e(q,Us),e(Us,wFe),e(wFe,Rbr),e(Us,Pbr),e(Us,JH),e(JH,Bbr),e(Us,Ibr),e(Us,YH),e(YH,Nbr),e(Us,qbr),e(q,jbr),e(q,M7),e(M7,AFe),e(AFe,Dbr),e(M7,Gbr),e(M7,KH),e(KH,Obr),e(M7,Vbr),e(q,Xbr),e(q,E7),e(E7,LFe),e(LFe,zbr),e(E7,Wbr),e(E7,ZH),e(ZH,Qbr),e(E7,Hbr),e(q,Ubr),e(q,C7),e(C7,yFe),e(yFe,Jbr),e(C7,Ybr),e(C7,eU),e(eU,Kbr),e(C7,Zbr),e(q,evr),e(q,w7),e(w7,xFe),e(xFe,ovr),e(w7,rvr),e(w7,oU),e(oU,tvr),e(w7,avr),e(q,nvr),e(q,A7),e(A7,$Fe),e($Fe,svr),e(A7,lvr),e(A7,rU),e(rU,ivr),e(A7,dvr),e(q,cvr),e(q,L7),e(L7,kFe),e(kFe,fvr),e(L7,mvr),e(L7,tU),e(tU,gvr),e(L7,hvr),e(q,pvr),e(q,y7),e(y7,SFe),e(SFe,_vr),e(y7,uvr),e(y7,aU),e(aU,bvr),e(y7,vvr),e(q,Fvr),e(q,x7),e(x7,RFe),e(RFe,Tvr),e(x7,Mvr),e(x7,nU),e(nU,Evr),e(x7,Cvr),e(q,wvr),e(q,$7),e($7,PFe),e(PFe,Avr),e($7,Lvr),e($7,sU),e(sU,yvr),e($7,xvr),e(q,$vr),e(q,k7),e(k7,BFe),e(BFe,kvr),e(k7,Svr),e(k7,lU),e(lU,Rvr),e(k7,Pvr),e(q,Bvr),e(q,S7),e(S7,IFe),e(IFe,Ivr),e(S7,Nvr),e(S7,iU),e(iU,qvr),e(S7,jvr),e(q,Dvr),e(q,R7),e(R7,NFe),e(NFe,Gvr),e(R7,Ovr),e(R7,dU),e(dU,Vvr),e(R7,Xvr),e(q,zvr),e(q,P7),e(P7,qFe),e(qFe,Wvr),e(P7,Qvr),e(P7,cU),e(cU,Hvr),e(P7,Uvr),e(q,Jvr),e(q,B7),e(B7,jFe),e(jFe,Yvr),e(B7,Kvr),e(B7,fU),e(fU,Zvr),e(B7,e0r),e(q,o0r),e(q,I7),e(I7,DFe),e(DFe,r0r),e(I7,t0r),e(I7,mU),e(mU,a0r),e(I7,n0r),e(q,s0r),e(q,N7),e(N7,GFe),e(GFe,l0r),e(N7,i0r),e(N7,gU),e(gU,d0r),e(N7,c0r),e(q,f0r),e(q,q7),e(q7,OFe),e(OFe,m0r),e(q7,g0r),e(q7,hU),e(hU,h0r),e(q7,p0r),e(q,_0r),e(q,j7),e(j7,VFe),e(VFe,u0r),e(j7,b0r),e(j7,pU),e(pU,v0r),e(j7,F0r),e(q,T0r),e(q,D7),e(D7,XFe),e(XFe,M0r),e(D7,E0r),e(D7,_U),e(_U,C0r),e(D7,w0r),e(q,A0r),e(q,G7),e(G7,zFe),e(zFe,L0r),e(G7,y0r),e(G7,uU),e(uU,x0r),e(G7,$0r),e(q,k0r),e(q,O7),e(O7,WFe),e(WFe,S0r),e(O7,R0r),e(O7,bU),e(bU,P0r),e(O7,B0r),e(q,I0r),e(q,V7),e(V7,QFe),e(QFe,N0r),e(V7,q0r),e(V7,vU),e(vU,j0r),e(V7,D0r),e(q,G0r),e(q,X7),e(X7,HFe),e(HFe,O0r),e(X7,V0r),e(X7,FU),e(FU,X0r),e(X7,z0r),e(q,W0r),e(q,z7),e(z7,UFe),e(UFe,Q0r),e(z7,H0r),e(z7,TU),e(TU,U0r),e(z7,J0r),e(q,Y0r),e(q,W7),e(W7,JFe),e(JFe,K0r),e(W7,Z0r),e(W7,MU),e(MU,eFr),e(W7,oFr),e(q,rFr),e(q,Q7),e(Q7,YFe),e(YFe,tFr),e(Q7,aFr),e(Q7,EU),e(EU,nFr),e(Q7,sFr),e(q,lFr),e(q,H7),e(H7,KFe),e(KFe,iFr),e(H7,dFr),e(H7,CU),e(CU,cFr),e(H7,fFr),e(q,mFr),e(q,U7),e(U7,ZFe),e(ZFe,gFr),e(U7,hFr),e(U7,wU),e(wU,pFr),e(U7,_Fr),e(q,uFr),e(q,J7),e(J7,e6e),e(e6e,bFr),e(J7,vFr),e(J7,AU),e(AU,FFr),e(J7,TFr),e(q,MFr),e(q,Y7),e(Y7,o6e),e(o6e,EFr),e(Y7,CFr),e(Y7,LU),e(LU,wFr),e(Y7,AFr),e(xr,LFr),M(K7,xr,null),b(f,UVe,u),b(f,lc,u),e(lc,Z7),e(Z7,r6e),M(R9,r6e,null),e(lc,yFr),e(lc,t6e),e(t6e,xFr),b(f,JVe,u),b(f,or,u),M(P9,or,null),e(or,$Fr),e(or,ic),e(ic,kFr),e(ic,yU),e(yU,SFr),e(ic,RFr),e(ic,xU),e(xU,PFr),e(ic,BFr),e(or,IFr),e(or,B9),e(B9,NFr),e(B9,a6e),e(a6e,qFr),e(B9,jFr),e(or,DFr),e(or,St),M(I9,St,null),e(St,GFr),e(St,n6e),e(n6e,OFr),e(St,VFr),e(St,dc),e(dc,XFr),e(dc,s6e),e(s6e,zFr),e(dc,WFr),e(dc,$U),e($U,QFr),e(dc,HFr),e(St,UFr),M(e8,St,null),e(or,JFr),e(or,$r),M(N9,$r,null),e($r,YFr),e($r,l6e),e(l6e,KFr),e($r,ZFr),e($r,ln),e(ln,e6r),e(ln,i6e),e(i6e,o6r),e(ln,r6r),e(ln,d6e),e(d6e,t6r),e(ln,a6r),e(ln,c6e),e(c6e,n6r),e(ln,s6r),e($r,l6r),e($r,se),e(se,o8),e(o8,f6e),e(f6e,i6r),e(o8,d6r),e(o8,kU),e(kU,c6r),e(o8,f6r),e(se,m6r),e(se,r8),e(r8,m6e),e(m6e,g6r),e(r8,h6r),e(r8,SU),e(SU,p6r),e(r8,_6r),e(se,u6r),e(se,t8),e(t8,g6e),e(g6e,b6r),e(t8,v6r),e(t8,RU),e(RU,F6r),e(t8,T6r),e(se,M6r),e(se,a8),e(a8,h6e),e(h6e,E6r),e(a8,C6r),e(a8,PU),e(PU,w6r),e(a8,A6r),e(se,L6r),e(se,n8),e(n8,p6e),e(p6e,y6r),e(n8,x6r),e(n8,BU),e(BU,$6r),e(n8,k6r),e(se,S6r),e(se,s8),e(s8,_6e),e(_6e,R6r),e(s8,P6r),e(s8,IU),e(IU,B6r),e(s8,I6r),e(se,N6r),e(se,l8),e(l8,u6e),e(u6e,q6r),e(l8,j6r),e(l8,NU),e(NU,D6r),e(l8,G6r),e(se,O6r),e(se,i8),e(i8,b6e),e(b6e,V6r),e(i8,X6r),e(i8,qU),e(qU,z6r),e(i8,W6r),e(se,Q6r),e(se,d8),e(d8,v6e),e(v6e,H6r),e(d8,U6r),e(d8,jU),e(jU,J6r),e(d8,Y6r),e(se,K6r),e(se,c8),e(c8,F6e),e(F6e,Z6r),e(c8,eTr),e(c8,DU),e(DU,oTr),e(c8,rTr),e(se,tTr),e(se,f8),e(f8,T6e),e(T6e,aTr),e(f8,nTr),e(f8,GU),e(GU,sTr),e(f8,lTr),e(se,iTr),e(se,m8),e(m8,M6e),e(M6e,dTr),e(m8,cTr),e(m8,OU),e(OU,fTr),e(m8,mTr),e(se,gTr),e(se,g8),e(g8,E6e),e(E6e,hTr),e(g8,pTr),e(g8,VU),e(VU,_Tr),e(g8,uTr),e(se,bTr),e(se,h8),e(h8,C6e),e(C6e,vTr),e(h8,FTr),e(h8,XU),e(XU,TTr),e(h8,MTr),e(se,ETr),e(se,p8),e(p8,w6e),e(w6e,CTr),e(p8,wTr),e(p8,zU),e(zU,ATr),e(p8,LTr),e(se,yTr),e(se,_8),e(_8,A6e),e(A6e,xTr),e(_8,$Tr),e(_8,WU),e(WU,kTr),e(_8,STr),e(se,RTr),e(se,u8),e(u8,L6e),e(L6e,PTr),e(u8,BTr),e(u8,QU),e(QU,ITr),e(u8,NTr),e(se,qTr),e(se,b8),e(b8,y6e),e(y6e,jTr),e(b8,DTr),e(b8,HU),e(HU,GTr),e(b8,OTr),e(se,VTr),e(se,v8),e(v8,x6e),e(x6e,XTr),e(v8,zTr),e(v8,UU),e(UU,WTr),e(v8,QTr),e(se,HTr),e(se,F8),e(F8,$6e),e($6e,UTr),e(F8,JTr),e(F8,JU),e(JU,YTr),e(F8,KTr),e(se,ZTr),e(se,T8),e(T8,k6e),e(k6e,e7r),e(T8,o7r),e(T8,YU),e(YU,r7r),e(T8,t7r),e(se,a7r),e(se,M8),e(M8,S6e),e(S6e,n7r),e(M8,s7r),e(M8,KU),e(KU,l7r),e(M8,i7r),e(se,d7r),e(se,E8),e(E8,R6e),e(R6e,c7r),e(E8,f7r),e(E8,ZU),e(ZU,m7r),e(E8,g7r),e($r,h7r),M(C8,$r,null),b(f,YVe,u),b(f,cc,u),e(cc,w8),e(w8,P6e),M(q9,P6e,null),e(cc,p7r),e(cc,B6e),e(B6e,_7r),b(f,KVe,u),b(f,rr,u),M(j9,rr,null),e(rr,u7r),e(rr,fc),e(fc,b7r),e(fc,eJ),e(eJ,v7r),e(fc,F7r),e(fc,oJ),e(oJ,T7r),e(fc,M7r),e(rr,E7r),e(rr,D9),e(D9,C7r),e(D9,I6e),e(I6e,w7r),e(D9,A7r),e(rr,L7r),e(rr,Rt),M(G9,Rt,null),e(Rt,y7r),e(Rt,N6e),e(N6e,x7r),e(Rt,$7r),e(Rt,mc),e(mc,k7r),e(mc,q6e),e(q6e,S7r),e(mc,R7r),e(mc,rJ),e(rJ,P7r),e(mc,B7r),e(Rt,I7r),M(A8,Rt,null),e(rr,N7r),e(rr,kr),M(O9,kr,null),e(kr,q7r),e(kr,j6e),e(j6e,j7r),e(kr,D7r),e(kr,dn),e(dn,G7r),e(dn,D6e),e(D6e,O7r),e(dn,V7r),e(dn,G6e),e(G6e,X7r),e(dn,z7r),e(dn,O6e),e(O6e,W7r),e(dn,Q7r),e(kr,H7r),e(kr,Me),e(Me,L8),e(L8,V6e),e(V6e,U7r),e(L8,J7r),e(L8,tJ),e(tJ,Y7r),e(L8,K7r),e(Me,Z7r),e(Me,y8),e(y8,X6e),e(X6e,e8r),e(y8,o8r),e(y8,aJ),e(aJ,r8r),e(y8,t8r),e(Me,a8r),e(Me,x8),e(x8,z6e),e(z6e,n8r),e(x8,s8r),e(x8,nJ),e(nJ,l8r),e(x8,i8r),e(Me,d8r),e(Me,$8),e($8,W6e),e(W6e,c8r),e($8,f8r),e($8,sJ),e(sJ,m8r),e($8,g8r),e(Me,h8r),e(Me,k8),e(k8,Q6e),e(Q6e,p8r),e(k8,_8r),e(k8,lJ),e(lJ,u8r),e(k8,b8r),e(Me,v8r),e(Me,S8),e(S8,H6e),e(H6e,F8r),e(S8,T8r),e(S8,iJ),e(iJ,M8r),e(S8,E8r),e(Me,C8r),e(Me,R8),e(R8,U6e),e(U6e,w8r),e(R8,A8r),e(R8,dJ),e(dJ,L8r),e(R8,y8r),e(Me,x8r),e(Me,P8),e(P8,J6e),e(J6e,$8r),e(P8,k8r),e(P8,cJ),e(cJ,S8r),e(P8,R8r),e(Me,P8r),e(Me,B8),e(B8,Y6e),e(Y6e,B8r),e(B8,I8r),e(B8,fJ),e(fJ,N8r),e(B8,q8r),e(Me,j8r),e(Me,I8),e(I8,K6e),e(K6e,D8r),e(I8,G8r),e(I8,mJ),e(mJ,O8r),e(I8,V8r),e(Me,X8r),e(Me,N8),e(N8,Z6e),e(Z6e,z8r),e(N8,W8r),e(N8,gJ),e(gJ,Q8r),e(N8,H8r),e(Me,U8r),e(Me,q8),e(q8,eTe),e(eTe,J8r),e(q8,Y8r),e(q8,hJ),e(hJ,K8r),e(q8,Z8r),e(Me,eMr),e(Me,j8),e(j8,oTe),e(oTe,oMr),e(j8,rMr),e(j8,pJ),e(pJ,tMr),e(j8,aMr),e(kr,nMr),M(D8,kr,null),b(f,ZVe,u),b(f,gc,u),e(gc,G8),e(G8,rTe),M(V9,rTe,null),e(gc,sMr),e(gc,tTe),e(tTe,lMr),b(f,eXe,u),b(f,tr,u),M(X9,tr,null),e(tr,iMr),e(tr,hc),e(hc,dMr),e(hc,_J),e(_J,cMr),e(hc,fMr),e(hc,uJ),e(uJ,mMr),e(hc,gMr),e(tr,hMr),e(tr,z9),e(z9,pMr),e(z9,aTe),e(aTe,_Mr),e(z9,uMr),e(tr,bMr),e(tr,Pt),M(W9,Pt,null),e(Pt,vMr),e(Pt,nTe),e(nTe,FMr),e(Pt,TMr),e(Pt,pc),e(pc,MMr),e(pc,sTe),e(sTe,EMr),e(pc,CMr),e(pc,bJ),e(bJ,wMr),e(pc,AMr),e(Pt,LMr),M(O8,Pt,null),e(tr,yMr),e(tr,Sr),M(Q9,Sr,null),e(Sr,xMr),e(Sr,lTe),e(lTe,$Mr),e(Sr,kMr),e(Sr,cn),e(cn,SMr),e(cn,iTe),e(iTe,RMr),e(cn,PMr),e(cn,dTe),e(dTe,BMr),e(cn,IMr),e(cn,cTe),e(cTe,NMr),e(cn,qMr),e(Sr,jMr),e(Sr,ar),e(ar,V8),e(V8,fTe),e(fTe,DMr),e(V8,GMr),e(V8,vJ),e(vJ,OMr),e(V8,VMr),e(ar,XMr),e(ar,X8),e(X8,mTe),e(mTe,zMr),e(X8,WMr),e(X8,FJ),e(FJ,QMr),e(X8,HMr),e(ar,UMr),e(ar,Js),e(Js,gTe),e(gTe,JMr),e(Js,YMr),e(Js,TJ),e(TJ,KMr),e(Js,ZMr),e(Js,MJ),e(MJ,e4r),e(Js,o4r),e(ar,r4r),e(ar,z8),e(z8,hTe),e(hTe,t4r),e(z8,a4r),e(z8,EJ),e(EJ,n4r),e(z8,s4r),e(ar,l4r),e(ar,W8),e(W8,pTe),e(pTe,i4r),e(W8,d4r),e(W8,CJ),e(CJ,c4r),e(W8,f4r),e(ar,m4r),e(ar,Q8),e(Q8,_Te),e(_Te,g4r),e(Q8,h4r),e(Q8,wJ),e(wJ,p4r),e(Q8,_4r),e(Sr,u4r),M(H8,Sr,null),b(f,oXe,u),b(f,_c,u),e(_c,U8),e(U8,uTe),M(H9,uTe,null),e(_c,b4r),e(_c,bTe),e(bTe,v4r),b(f,rXe,u),b(f,nr,u),M(U9,nr,null),e(nr,F4r),e(nr,uc),e(uc,T4r),e(uc,AJ),e(AJ,M4r),e(uc,E4r),e(uc,LJ),e(LJ,C4r),e(uc,w4r),e(nr,A4r),e(nr,J9),e(J9,L4r),e(J9,vTe),e(vTe,y4r),e(J9,x4r),e(nr,$4r),e(nr,Bt),M(Y9,Bt,null),e(Bt,k4r),e(Bt,FTe),e(FTe,S4r),e(Bt,R4r),e(Bt,bc),e(bc,P4r),e(bc,TTe),e(TTe,B4r),e(bc,I4r),e(bc,yJ),e(yJ,N4r),e(bc,q4r),e(Bt,j4r),M(J8,Bt,null),e(nr,D4r),e(nr,Rr),M(K9,Rr,null),e(Rr,G4r),e(Rr,MTe),e(MTe,O4r),e(Rr,V4r),e(Rr,fn),e(fn,X4r),e(fn,ETe),e(ETe,z4r),e(fn,W4r),e(fn,CTe),e(CTe,Q4r),e(fn,H4r),e(fn,wTe),e(wTe,U4r),e(fn,J4r),e(Rr,Y4r),e(Rr,ie),e(ie,Y8),e(Y8,ATe),e(ATe,K4r),e(Y8,Z4r),e(Y8,xJ),e(xJ,eEr),e(Y8,oEr),e(ie,rEr),e(ie,K8),e(K8,LTe),e(LTe,tEr),e(K8,aEr),e(K8,$J),e($J,nEr),e(K8,sEr),e(ie,lEr),e(ie,Z8),e(Z8,yTe),e(yTe,iEr),e(Z8,dEr),e(Z8,kJ),e(kJ,cEr),e(Z8,fEr),e(ie,mEr),e(ie,eM),e(eM,xTe),e(xTe,gEr),e(eM,hEr),e(eM,SJ),e(SJ,pEr),e(eM,_Er),e(ie,uEr),e(ie,oM),e(oM,$Te),e($Te,bEr),e(oM,vEr),e(oM,RJ),e(RJ,FEr),e(oM,TEr),e(ie,MEr),e(ie,rM),e(rM,kTe),e(kTe,EEr),e(rM,CEr),e(rM,PJ),e(PJ,wEr),e(rM,AEr),e(ie,LEr),e(ie,tM),e(tM,STe),e(STe,yEr),e(tM,xEr),e(tM,BJ),e(BJ,$Er),e(tM,kEr),e(ie,SEr),e(ie,aM),e(aM,RTe),e(RTe,REr),e(aM,PEr),e(aM,IJ),e(IJ,BEr),e(aM,IEr),e(ie,NEr),e(ie,nM),e(nM,PTe),e(PTe,qEr),e(nM,jEr),e(nM,NJ),e(NJ,DEr),e(nM,GEr),e(ie,OEr),e(ie,sM),e(sM,BTe),e(BTe,VEr),e(sM,XEr),e(sM,qJ),e(qJ,zEr),e(sM,WEr),e(ie,QEr),e(ie,lM),e(lM,ITe),e(ITe,HEr),e(lM,UEr),e(lM,jJ),e(jJ,JEr),e(lM,YEr),e(ie,KEr),e(ie,iM),e(iM,NTe),e(NTe,ZEr),e(iM,eCr),e(iM,DJ),e(DJ,oCr),e(iM,rCr),e(ie,tCr),e(ie,dM),e(dM,qTe),e(qTe,aCr),e(dM,nCr),e(dM,GJ),e(GJ,sCr),e(dM,lCr),e(ie,iCr),e(ie,cM),e(cM,jTe),e(jTe,dCr),e(cM,cCr),e(cM,OJ),e(OJ,fCr),e(cM,mCr),e(ie,gCr),e(ie,fM),e(fM,DTe),e(DTe,hCr),e(fM,pCr),e(fM,VJ),e(VJ,_Cr),e(fM,uCr),e(ie,bCr),e(ie,mM),e(mM,GTe),e(GTe,vCr),e(mM,FCr),e(mM,XJ),e(XJ,TCr),e(mM,MCr),e(ie,ECr),e(ie,gM),e(gM,OTe),e(OTe,CCr),e(gM,wCr),e(gM,zJ),e(zJ,ACr),e(gM,LCr),e(ie,yCr),e(ie,hM),e(hM,VTe),e(VTe,xCr),e(hM,$Cr),e(hM,WJ),e(WJ,kCr),e(hM,SCr),e(ie,RCr),e(ie,pM),e(pM,XTe),e(XTe,PCr),e(pM,BCr),e(pM,QJ),e(QJ,ICr),e(pM,NCr),e(ie,qCr),e(ie,_M),e(_M,zTe),e(zTe,jCr),e(_M,DCr),e(_M,HJ),e(HJ,GCr),e(_M,OCr),e(Rr,VCr),M(uM,Rr,null),b(f,tXe,u),b(f,vc,u),e(vc,bM),e(bM,WTe),M(Z9,WTe,null),e(vc,XCr),e(vc,QTe),e(QTe,zCr),b(f,aXe,u),b(f,sr,u),M(ex,sr,null),e(sr,WCr),e(sr,Fc),e(Fc,QCr),e(Fc,UJ),e(UJ,HCr),e(Fc,UCr),e(Fc,JJ),e(JJ,JCr),e(Fc,YCr),e(sr,KCr),e(sr,ox),e(ox,ZCr),e(ox,HTe),e(HTe,e3r),e(ox,o3r),e(sr,r3r),e(sr,It),M(rx,It,null),e(It,t3r),e(It,UTe),e(UTe,a3r),e(It,n3r),e(It,Tc),e(Tc,s3r),e(Tc,JTe),e(JTe,l3r),e(Tc,i3r),e(Tc,YJ),e(YJ,d3r),e(Tc,c3r),e(It,f3r),M(vM,It,null),e(sr,m3r),e(sr,Pr),M(tx,Pr,null),e(Pr,g3r),e(Pr,YTe),e(YTe,h3r),e(Pr,p3r),e(Pr,mn),e(mn,_3r),e(mn,KTe),e(KTe,u3r),e(mn,b3r),e(mn,ZTe),e(ZTe,v3r),e(mn,F3r),e(mn,e7e),e(e7e,T3r),e(mn,M3r),e(Pr,E3r),e(Pr,ye),e(ye,FM),e(FM,o7e),e(o7e,C3r),e(FM,w3r),e(FM,KJ),e(KJ,A3r),e(FM,L3r),e(ye,y3r),e(ye,TM),e(TM,r7e),e(r7e,x3r),e(TM,$3r),e(TM,ZJ),e(ZJ,k3r),e(TM,S3r),e(ye,R3r),e(ye,MM),e(MM,t7e),e(t7e,P3r),e(MM,B3r),e(MM,eY),e(eY,I3r),e(MM,N3r),e(ye,q3r),e(ye,EM),e(EM,a7e),e(a7e,j3r),e(EM,D3r),e(EM,oY),e(oY,G3r),e(EM,O3r),e(ye,V3r),e(ye,CM),e(CM,n7e),e(n7e,X3r),e(CM,z3r),e(CM,rY),e(rY,W3r),e(CM,Q3r),e(ye,H3r),e(ye,wM),e(wM,s7e),e(s7e,U3r),e(wM,J3r),e(wM,tY),e(tY,Y3r),e(wM,K3r),e(ye,Z3r),e(ye,AM),e(AM,l7e),e(l7e,e5r),e(AM,o5r),e(AM,aY),e(aY,r5r),e(AM,t5r),e(ye,a5r),e(ye,LM),e(LM,i7e),e(i7e,n5r),e(LM,s5r),e(LM,nY),e(nY,l5r),e(LM,i5r),e(ye,d5r),e(ye,yM),e(yM,d7e),e(d7e,c5r),e(yM,f5r),e(yM,sY),e(sY,m5r),e(yM,g5r),e(ye,h5r),e(ye,xM),e(xM,c7e),e(c7e,p5r),e(xM,_5r),e(xM,lY),e(lY,u5r),e(xM,b5r),e(Pr,v5r),M($M,Pr,null),b(f,nXe,u),b(f,Mc,u),e(Mc,kM),e(kM,f7e),M(ax,f7e,null),e(Mc,F5r),e(Mc,m7e),e(m7e,T5r),b(f,sXe,u),b(f,lr,u),M(nx,lr,null),e(lr,M5r),e(lr,Ec),e(Ec,E5r),e(Ec,iY),e(iY,C5r),e(Ec,w5r),e(Ec,dY),e(dY,A5r),e(Ec,L5r),e(lr,y5r),e(lr,sx),e(sx,x5r),e(sx,g7e),e(g7e,$5r),e(sx,k5r),e(lr,S5r),e(lr,Nt),M(lx,Nt,null),e(Nt,R5r),e(Nt,h7e),e(h7e,P5r),e(Nt,B5r),e(Nt,Cc),e(Cc,I5r),e(Cc,p7e),e(p7e,N5r),e(Cc,q5r),e(Cc,cY),e(cY,j5r),e(Cc,D5r),e(Nt,G5r),M(SM,Nt,null),e(lr,O5r),e(lr,Br),M(ix,Br,null),e(Br,V5r),e(Br,_7e),e(_7e,X5r),e(Br,z5r),e(Br,gn),e(gn,W5r),e(gn,u7e),e(u7e,Q5r),e(gn,H5r),e(gn,b7e),e(b7e,U5r),e(gn,J5r),e(gn,v7e),e(v7e,Y5r),e(gn,K5r),e(Br,Z5r),e(Br,te),e(te,RM),e(RM,F7e),e(F7e,ewr),e(RM,owr),e(RM,fY),e(fY,rwr),e(RM,twr),e(te,awr),e(te,PM),e(PM,T7e),e(T7e,nwr),e(PM,swr),e(PM,mY),e(mY,lwr),e(PM,iwr),e(te,dwr),e(te,BM),e(BM,M7e),e(M7e,cwr),e(BM,fwr),e(BM,gY),e(gY,mwr),e(BM,gwr),e(te,hwr),e(te,IM),e(IM,E7e),e(E7e,pwr),e(IM,_wr),e(IM,hY),e(hY,uwr),e(IM,bwr),e(te,vwr),e(te,NM),e(NM,C7e),e(C7e,Fwr),e(NM,Twr),e(NM,pY),e(pY,Mwr),e(NM,Ewr),e(te,Cwr),e(te,qM),e(qM,w7e),e(w7e,wwr),e(qM,Awr),e(qM,_Y),e(_Y,Lwr),e(qM,ywr),e(te,xwr),e(te,jM),e(jM,A7e),e(A7e,$wr),e(jM,kwr),e(jM,uY),e(uY,Swr),e(jM,Rwr),e(te,Pwr),e(te,DM),e(DM,L7e),e(L7e,Bwr),e(DM,Iwr),e(DM,bY),e(bY,Nwr),e(DM,qwr),e(te,jwr),e(te,GM),e(GM,y7e),e(y7e,Dwr),e(GM,Gwr),e(GM,vY),e(vY,Owr),e(GM,Vwr),e(te,Xwr),e(te,OM),e(OM,x7e),e(x7e,zwr),e(OM,Wwr),e(OM,FY),e(FY,Qwr),e(OM,Hwr),e(te,Uwr),e(te,VM),e(VM,$7e),e($7e,Jwr),e(VM,Ywr),e(VM,TY),e(TY,Kwr),e(VM,Zwr),e(te,eAr),e(te,XM),e(XM,k7e),e(k7e,oAr),e(XM,rAr),e(XM,MY),e(MY,tAr),e(XM,aAr),e(te,nAr),e(te,zM),e(zM,S7e),e(S7e,sAr),e(zM,lAr),e(zM,EY),e(EY,iAr),e(zM,dAr),e(te,cAr),e(te,WM),e(WM,R7e),e(R7e,fAr),e(WM,mAr),e(WM,CY),e(CY,gAr),e(WM,hAr),e(te,pAr),e(te,QM),e(QM,P7e),e(P7e,_Ar),e(QM,uAr),e(QM,wY),e(wY,bAr),e(QM,vAr),e(te,FAr),e(te,HM),e(HM,B7e),e(B7e,TAr),e(HM,MAr),e(HM,AY),e(AY,EAr),e(HM,CAr),e(te,wAr),e(te,UM),e(UM,I7e),e(I7e,AAr),e(UM,LAr),e(UM,LY),e(LY,yAr),e(UM,xAr),e(te,$Ar),e(te,JM),e(JM,N7e),e(N7e,kAr),e(JM,SAr),e(JM,yY),e(yY,RAr),e(JM,PAr),e(te,BAr),e(te,YM),e(YM,q7e),e(q7e,IAr),e(YM,NAr),e(YM,xY),e(xY,qAr),e(YM,jAr),e(te,DAr),e(te,KM),e(KM,j7e),e(j7e,GAr),e(KM,OAr),e(KM,$Y),e($Y,VAr),e(KM,XAr),e(te,zAr),e(te,ZM),e(ZM,D7e),e(D7e,WAr),e(ZM,QAr),e(ZM,kY),e(kY,HAr),e(ZM,UAr),e(te,JAr),e(te,e4),e(e4,G7e),e(G7e,YAr),e(e4,KAr),e(e4,SY),e(SY,ZAr),e(e4,eLr),e(te,oLr),e(te,o4),e(o4,O7e),e(O7e,rLr),e(o4,tLr),e(o4,RY),e(RY,aLr),e(o4,nLr),e(te,sLr),e(te,r4),e(r4,V7e),e(V7e,lLr),e(r4,iLr),e(r4,PY),e(PY,dLr),e(r4,cLr),e(te,fLr),e(te,t4),e(t4,X7e),e(X7e,mLr),e(t4,gLr),e(t4,BY),e(BY,hLr),e(t4,pLr),e(te,_Lr),e(te,a4),e(a4,z7e),e(z7e,uLr),e(a4,bLr),e(a4,IY),e(IY,vLr),e(a4,FLr),e(Br,TLr),M(n4,Br,null),b(f,lXe,u),b(f,wc,u),e(wc,s4),e(s4,W7e),M(dx,W7e,null),e(wc,MLr),e(wc,Q7e),e(Q7e,ELr),b(f,iXe,u),b(f,ir,u),M(cx,ir,null),e(ir,CLr),e(ir,Ac),e(Ac,wLr),e(Ac,NY),e(NY,ALr),e(Ac,LLr),e(Ac,qY),e(qY,yLr),e(Ac,xLr),e(ir,$Lr),e(ir,fx),e(fx,kLr),e(fx,H7e),e(H7e,SLr),e(fx,RLr),e(ir,PLr),e(ir,qt),M(mx,qt,null),e(qt,BLr),e(qt,U7e),e(U7e,ILr),e(qt,NLr),e(qt,Lc),e(Lc,qLr),e(Lc,J7e),e(J7e,jLr),e(Lc,DLr),e(Lc,jY),e(jY,GLr),e(Lc,OLr),e(qt,VLr),M(l4,qt,null),e(ir,XLr),e(ir,Ir),M(gx,Ir,null),e(Ir,zLr),e(Ir,Y7e),e(Y7e,WLr),e(Ir,QLr),e(Ir,hn),e(hn,HLr),e(hn,K7e),e(K7e,ULr),e(hn,JLr),e(hn,Z7e),e(Z7e,YLr),e(hn,KLr),e(hn,e8e),e(e8e,ZLr),e(hn,eyr),e(Ir,oyr),e(Ir,_e),e(_e,i4),e(i4,o8e),e(o8e,ryr),e(i4,tyr),e(i4,DY),e(DY,ayr),e(i4,nyr),e(_e,syr),e(_e,d4),e(d4,r8e),e(r8e,lyr),e(d4,iyr),e(d4,GY),e(GY,dyr),e(d4,cyr),e(_e,fyr),e(_e,c4),e(c4,t8e),e(t8e,myr),e(c4,gyr),e(c4,OY),e(OY,hyr),e(c4,pyr),e(_e,_yr),e(_e,f4),e(f4,a8e),e(a8e,uyr),e(f4,byr),e(f4,VY),e(VY,vyr),e(f4,Fyr),e(_e,Tyr),e(_e,m4),e(m4,n8e),e(n8e,Myr),e(m4,Eyr),e(m4,XY),e(XY,Cyr),e(m4,wyr),e(_e,Ayr),e(_e,g4),e(g4,s8e),e(s8e,Lyr),e(g4,yyr),e(g4,zY),e(zY,xyr),e(g4,$yr),e(_e,kyr),e(_e,h4),e(h4,l8e),e(l8e,Syr),e(h4,Ryr),e(h4,WY),e(WY,Pyr),e(h4,Byr),e(_e,Iyr),e(_e,p4),e(p4,i8e),e(i8e,Nyr),e(p4,qyr),e(p4,QY),e(QY,jyr),e(p4,Dyr),e(_e,Gyr),e(_e,_4),e(_4,d8e),e(d8e,Oyr),e(_4,Vyr),e(_4,HY),e(HY,Xyr),e(_4,zyr),e(_e,Wyr),e(_e,u4),e(u4,c8e),e(c8e,Qyr),e(u4,Hyr),e(u4,UY),e(UY,Uyr),e(u4,Jyr),e(_e,Yyr),e(_e,b4),e(b4,f8e),e(f8e,Kyr),e(b4,Zyr),e(b4,JY),e(JY,e9r),e(b4,o9r),e(_e,r9r),e(_e,v4),e(v4,m8e),e(m8e,t9r),e(v4,a9r),e(v4,YY),e(YY,n9r),e(v4,s9r),e(_e,l9r),e(_e,F4),e(F4,g8e),e(g8e,i9r),e(F4,d9r),e(F4,KY),e(KY,c9r),e(F4,f9r),e(_e,m9r),e(_e,T4),e(T4,h8e),e(h8e,g9r),e(T4,h9r),e(T4,ZY),e(ZY,p9r),e(T4,_9r),e(_e,u9r),e(_e,M4),e(M4,p8e),e(p8e,b9r),e(M4,v9r),e(M4,eK),e(eK,F9r),e(M4,T9r),e(_e,M9r),e(_e,E4),e(E4,_8e),e(_8e,E9r),e(E4,C9r),e(E4,oK),e(oK,w9r),e(E4,A9r),e(_e,L9r),e(_e,C4),e(C4,u8e),e(u8e,y9r),e(C4,x9r),e(C4,rK),e(rK,$9r),e(C4,k9r),e(Ir,S9r),M(w4,Ir,null),b(f,dXe,u),b(f,yc,u),e(yc,A4),e(A4,b8e),M(hx,b8e,null),e(yc,R9r),e(yc,v8e),e(v8e,P9r),b(f,cXe,u),b(f,dr,u),M(px,dr,null),e(dr,B9r),e(dr,xc),e(xc,I9r),e(xc,tK),e(tK,N9r),e(xc,q9r),e(xc,aK),e(aK,j9r),e(xc,D9r),e(dr,G9r),e(dr,_x),e(_x,O9r),e(_x,F8e),e(F8e,V9r),e(_x,X9r),e(dr,z9r),e(dr,jt),M(ux,jt,null),e(jt,W9r),e(jt,T8e),e(T8e,Q9r),e(jt,H9r),e(jt,$c),e($c,U9r),e($c,M8e),e(M8e,J9r),e($c,Y9r),e($c,nK),e(nK,K9r),e($c,Z9r),e(jt,exr),M(L4,jt,null),e(dr,oxr),e(dr,Nr),M(bx,Nr,null),e(Nr,rxr),e(Nr,E8e),e(E8e,txr),e(Nr,axr),e(Nr,pn),e(pn,nxr),e(pn,C8e),e(C8e,sxr),e(pn,lxr),e(pn,w8e),e(w8e,ixr),e(pn,dxr),e(pn,A8e),e(A8e,cxr),e(pn,fxr),e(Nr,mxr),e(Nr,vx),e(vx,y4),e(y4,L8e),e(L8e,gxr),e(y4,hxr),e(y4,sK),e(sK,pxr),e(y4,_xr),e(vx,uxr),e(vx,x4),e(x4,y8e),e(y8e,bxr),e(x4,vxr),e(x4,lK),e(lK,Fxr),e(x4,Txr),e(Nr,Mxr),M($4,Nr,null),b(f,fXe,u),b(f,kc,u),e(kc,k4),e(k4,x8e),M(Fx,x8e,null),e(kc,Exr),e(kc,$8e),e($8e,Cxr),b(f,mXe,u),b(f,cr,u),M(Tx,cr,null),e(cr,wxr),e(cr,Sc),e(Sc,Axr),e(Sc,iK),e(iK,Lxr),e(Sc,yxr),e(Sc,dK),e(dK,xxr),e(Sc,$xr),e(cr,kxr),e(cr,Mx),e(Mx,Sxr),e(Mx,k8e),e(k8e,Rxr),e(Mx,Pxr),e(cr,Bxr),e(cr,Dt),M(Ex,Dt,null),e(Dt,Ixr),e(Dt,S8e),e(S8e,Nxr),e(Dt,qxr),e(Dt,Rc),e(Rc,jxr),e(Rc,R8e),e(R8e,Dxr),e(Rc,Gxr),e(Rc,cK),e(cK,Oxr),e(Rc,Vxr),e(Dt,Xxr),M(S4,Dt,null),e(cr,zxr),e(cr,qr),M(Cx,qr,null),e(qr,Wxr),e(qr,P8e),e(P8e,Qxr),e(qr,Hxr),e(qr,_n),e(_n,Uxr),e(_n,B8e),e(B8e,Jxr),e(_n,Yxr),e(_n,I8e),e(I8e,Kxr),e(_n,Zxr),e(_n,N8e),e(N8e,e$r),e(_n,o$r),e(qr,r$r),e(qr,q8e),e(q8e,R4),e(R4,j8e),e(j8e,t$r),e(R4,a$r),e(R4,fK),e(fK,n$r),e(R4,s$r),e(qr,l$r),M(P4,qr,null),b(f,gXe,u),b(f,Pc,u),e(Pc,B4),e(B4,D8e),M(wx,D8e,null),e(Pc,i$r),e(Pc,G8e),e(G8e,d$r),b(f,hXe,u),b(f,fr,u),M(Ax,fr,null),e(fr,c$r),e(fr,Bc),e(Bc,f$r),e(Bc,mK),e(mK,m$r),e(Bc,g$r),e(Bc,gK),e(gK,h$r),e(Bc,p$r),e(fr,_$r),e(fr,Lx),e(Lx,u$r),e(Lx,O8e),e(O8e,b$r),e(Lx,v$r),e(fr,F$r),e(fr,Gt),M(yx,Gt,null),e(Gt,T$r),e(Gt,V8e),e(V8e,M$r),e(Gt,E$r),e(Gt,Ic),e(Ic,C$r),e(Ic,X8e),e(X8e,w$r),e(Ic,A$r),e(Ic,hK),e(hK,L$r),e(Ic,y$r),e(Gt,x$r),M(I4,Gt,null),e(fr,$$r),e(fr,jr),M(xx,jr,null),e(jr,k$r),e(jr,z8e),e(z8e,S$r),e(jr,R$r),e(jr,un),e(un,P$r),e(un,W8e),e(W8e,B$r),e(un,I$r),e(un,Q8e),e(Q8e,N$r),e(un,q$r),e(un,H8e),e(H8e,j$r),e(un,D$r),e(jr,G$r),e(jr,de),e(de,N4),e(N4,U8e),e(U8e,O$r),e(N4,V$r),e(N4,pK),e(pK,X$r),e(N4,z$r),e(de,W$r),e(de,q4),e(q4,J8e),e(J8e,Q$r),e(q4,H$r),e(q4,_K),e(_K,U$r),e(q4,J$r),e(de,Y$r),e(de,j4),e(j4,Y8e),e(Y8e,K$r),e(j4,Z$r),e(j4,uK),e(uK,ekr),e(j4,okr),e(de,rkr),e(de,D4),e(D4,K8e),e(K8e,tkr),e(D4,akr),e(D4,bK),e(bK,nkr),e(D4,skr),e(de,lkr),e(de,G4),e(G4,Z8e),e(Z8e,ikr),e(G4,dkr),e(G4,vK),e(vK,ckr),e(G4,fkr),e(de,mkr),e(de,O4),e(O4,eMe),e(eMe,gkr),e(O4,hkr),e(O4,FK),e(FK,pkr),e(O4,_kr),e(de,ukr),e(de,V4),e(V4,oMe),e(oMe,bkr),e(V4,vkr),e(V4,TK),e(TK,Fkr),e(V4,Tkr),e(de,Mkr),e(de,X4),e(X4,rMe),e(rMe,Ekr),e(X4,Ckr),e(X4,MK),e(MK,wkr),e(X4,Akr),e(de,Lkr),e(de,z4),e(z4,tMe),e(tMe,ykr),e(z4,xkr),e(z4,EK),e(EK,$kr),e(z4,kkr),e(de,Skr),e(de,W4),e(W4,aMe),e(aMe,Rkr),e(W4,Pkr),e(W4,CK),e(CK,Bkr),e(W4,Ikr),e(de,Nkr),e(de,Q4),e(Q4,nMe),e(nMe,qkr),e(Q4,jkr),e(Q4,wK),e(wK,Dkr),e(Q4,Gkr),e(de,Okr),e(de,H4),e(H4,sMe),e(sMe,Vkr),e(H4,Xkr),e(H4,AK),e(AK,zkr),e(H4,Wkr),e(de,Qkr),e(de,U4),e(U4,lMe),e(lMe,Hkr),e(U4,Ukr),e(U4,LK),e(LK,Jkr),e(U4,Ykr),e(de,Kkr),e(de,J4),e(J4,iMe),e(iMe,Zkr),e(J4,eSr),e(J4,yK),e(yK,oSr),e(J4,rSr),e(de,tSr),e(de,Y4),e(Y4,dMe),e(dMe,aSr),e(Y4,nSr),e(Y4,xK),e(xK,sSr),e(Y4,lSr),e(de,iSr),e(de,K4),e(K4,cMe),e(cMe,dSr),e(K4,cSr),e(K4,$K),e($K,fSr),e(K4,mSr),e(de,gSr),e(de,Z4),e(Z4,fMe),e(fMe,hSr),e(Z4,pSr),e(Z4,kK),e(kK,_Sr),e(Z4,uSr),e(de,bSr),e(de,eE),e(eE,mMe),e(mMe,vSr),e(eE,FSr),e(eE,SK),e(SK,TSr),e(eE,MSr),e(de,ESr),e(de,oE),e(oE,gMe),e(gMe,CSr),e(oE,wSr),e(oE,RK),e(RK,ASr),e(oE,LSr),e(de,ySr),e(de,rE),e(rE,hMe),e(hMe,xSr),e(rE,$Sr),e(rE,PK),e(PK,kSr),e(rE,SSr),e(jr,RSr),M(tE,jr,null),b(f,pXe,u),b(f,Nc,u),e(Nc,aE),e(aE,pMe),M($x,pMe,null),e(Nc,PSr),e(Nc,_Me),e(_Me,BSr),b(f,_Xe,u),b(f,mr,u),M(kx,mr,null),e(mr,ISr),e(mr,qc),e(qc,NSr),e(qc,BK),e(BK,qSr),e(qc,jSr),e(qc,IK),e(IK,DSr),e(qc,GSr),e(mr,OSr),e(mr,Sx),e(Sx,VSr),e(Sx,uMe),e(uMe,XSr),e(Sx,zSr),e(mr,WSr),e(mr,Ot),M(Rx,Ot,null),e(Ot,QSr),e(Ot,bMe),e(bMe,HSr),e(Ot,USr),e(Ot,jc),e(jc,JSr),e(jc,vMe),e(vMe,YSr),e(jc,KSr),e(jc,NK),e(NK,ZSr),e(jc,eRr),e(Ot,oRr),M(nE,Ot,null),e(mr,rRr),e(mr,Dr),M(Px,Dr,null),e(Dr,tRr),e(Dr,FMe),e(FMe,aRr),e(Dr,nRr),e(Dr,bn),e(bn,sRr),e(bn,TMe),e(TMe,lRr),e(bn,iRr),e(bn,MMe),e(MMe,dRr),e(bn,cRr),e(bn,EMe),e(EMe,fRr),e(bn,mRr),e(Dr,gRr),e(Dr,ce),e(ce,sE),e(sE,CMe),e(CMe,hRr),e(sE,pRr),e(sE,qK),e(qK,_Rr),e(sE,uRr),e(ce,bRr),e(ce,lE),e(lE,wMe),e(wMe,vRr),e(lE,FRr),e(lE,jK),e(jK,TRr),e(lE,MRr),e(ce,ERr),e(ce,iE),e(iE,AMe),e(AMe,CRr),e(iE,wRr),e(iE,DK),e(DK,ARr),e(iE,LRr),e(ce,yRr),e(ce,dE),e(dE,LMe),e(LMe,xRr),e(dE,$Rr),e(dE,GK),e(GK,kRr),e(dE,SRr),e(ce,RRr),e(ce,cE),e(cE,yMe),e(yMe,PRr),e(cE,BRr),e(cE,OK),e(OK,IRr),e(cE,NRr),e(ce,qRr),e(ce,fE),e(fE,xMe),e(xMe,jRr),e(fE,DRr),e(fE,VK),e(VK,GRr),e(fE,ORr),e(ce,VRr),e(ce,mE),e(mE,$Me),e($Me,XRr),e(mE,zRr),e(mE,XK),e(XK,WRr),e(mE,QRr),e(ce,HRr),e(ce,gE),e(gE,kMe),e(kMe,URr),e(gE,JRr),e(gE,zK),e(zK,YRr),e(gE,KRr),e(ce,ZRr),e(ce,hE),e(hE,SMe),e(SMe,ePr),e(hE,oPr),e(hE,WK),e(WK,rPr),e(hE,tPr),e(ce,aPr),e(ce,pE),e(pE,RMe),e(RMe,nPr),e(pE,sPr),e(pE,QK),e(QK,lPr),e(pE,iPr),e(ce,dPr),e(ce,_E),e(_E,PMe),e(PMe,cPr),e(_E,fPr),e(_E,HK),e(HK,mPr),e(_E,gPr),e(ce,hPr),e(ce,uE),e(uE,BMe),e(BMe,pPr),e(uE,_Pr),e(uE,UK),e(UK,uPr),e(uE,bPr),e(ce,vPr),e(ce,bE),e(bE,IMe),e(IMe,FPr),e(bE,TPr),e(bE,JK),e(JK,MPr),e(bE,EPr),e(ce,CPr),e(ce,vE),e(vE,NMe),e(NMe,wPr),e(vE,APr),e(vE,YK),e(YK,LPr),e(vE,yPr),e(ce,xPr),e(ce,FE),e(FE,qMe),e(qMe,$Pr),e(FE,kPr),e(FE,KK),e(KK,SPr),e(FE,RPr),e(ce,PPr),e(ce,TE),e(TE,jMe),e(jMe,BPr),e(TE,IPr),e(TE,ZK),e(ZK,NPr),e(TE,qPr),e(ce,jPr),e(ce,ME),e(ME,DMe),e(DMe,DPr),e(ME,GPr),e(ME,eZ),e(eZ,OPr),e(ME,VPr),e(ce,XPr),e(ce,EE),e(EE,GMe),e(GMe,zPr),e(EE,WPr),e(EE,oZ),e(oZ,QPr),e(EE,HPr),e(ce,UPr),e(ce,CE),e(CE,OMe),e(OMe,JPr),e(CE,YPr),e(CE,rZ),e(rZ,KPr),e(CE,ZPr),e(ce,eBr),e(ce,wE),e(wE,VMe),e(VMe,oBr),e(wE,rBr),e(wE,tZ),e(tZ,tBr),e(wE,aBr),e(Dr,nBr),M(AE,Dr,null),b(f,uXe,u),b(f,Dc,u),e(Dc,LE),e(LE,XMe),M(Bx,XMe,null),e(Dc,sBr),e(Dc,zMe),e(zMe,lBr),b(f,bXe,u),b(f,gr,u),M(Ix,gr,null),e(gr,iBr),e(gr,Gc),e(Gc,dBr),e(Gc,aZ),e(aZ,cBr),e(Gc,fBr),e(Gc,nZ),e(nZ,mBr),e(Gc,gBr),e(gr,hBr),e(gr,Nx),e(Nx,pBr),e(Nx,WMe),e(WMe,_Br),e(Nx,uBr),e(gr,bBr),e(gr,Vt),M(qx,Vt,null),e(Vt,vBr),e(Vt,QMe),e(QMe,FBr),e(Vt,TBr),e(Vt,Oc),e(Oc,MBr),e(Oc,HMe),e(HMe,EBr),e(Oc,CBr),e(Oc,sZ),e(sZ,wBr),e(Oc,ABr),e(Vt,LBr),M(yE,Vt,null),e(gr,yBr),e(gr,Gr),M(jx,Gr,null),e(Gr,xBr),e(Gr,UMe),e(UMe,$Br),e(Gr,kBr),e(Gr,vn),e(vn,SBr),e(vn,JMe),e(JMe,RBr),e(vn,PBr),e(vn,YMe),e(YMe,BBr),e(vn,IBr),e(vn,KMe),e(KMe,NBr),e(vn,qBr),e(Gr,jBr),e(Gr,ZMe),e(ZMe,xE),e(xE,e4e),e(e4e,DBr),e(xE,GBr),e(xE,lZ),e(lZ,OBr),e(xE,VBr),e(Gr,XBr),M($E,Gr,null),b(f,vXe,u),b(f,Vc,u),e(Vc,kE),e(kE,o4e),M(Dx,o4e,null),e(Vc,zBr),e(Vc,r4e),e(r4e,WBr),b(f,FXe,u),b(f,hr,u),M(Gx,hr,null),e(hr,QBr),e(hr,Xc),e(Xc,HBr),e(Xc,iZ),e(iZ,UBr),e(Xc,JBr),e(Xc,dZ),e(dZ,YBr),e(Xc,KBr),e(hr,ZBr),e(hr,Ox),e(Ox,eIr),e(Ox,t4e),e(t4e,oIr),e(Ox,rIr),e(hr,tIr),e(hr,Xt),M(Vx,Xt,null),e(Xt,aIr),e(Xt,a4e),e(a4e,nIr),e(Xt,sIr),e(Xt,zc),e(zc,lIr),e(zc,n4e),e(n4e,iIr),e(zc,dIr),e(zc,cZ),e(cZ,cIr),e(zc,fIr),e(Xt,mIr),M(SE,Xt,null),e(hr,gIr),e(hr,Or),M(Xx,Or,null),e(Or,hIr),e(Or,s4e),e(s4e,pIr),e(Or,_Ir),e(Or,Fn),e(Fn,uIr),e(Fn,l4e),e(l4e,bIr),e(Fn,vIr),e(Fn,i4e),e(i4e,FIr),e(Fn,TIr),e(Fn,d4e),e(d4e,MIr),e(Fn,EIr),e(Or,CIr),e(Or,c4e),e(c4e,RE),e(RE,f4e),e(f4e,wIr),e(RE,AIr),e(RE,fZ),e(fZ,LIr),e(RE,yIr),e(Or,xIr),M(PE,Or,null),b(f,TXe,u),b(f,Wc,u),e(Wc,BE),e(BE,m4e),M(zx,m4e,null),e(Wc,$Ir),e(Wc,g4e),e(g4e,kIr),b(f,MXe,u),b(f,pr,u),M(Wx,pr,null),e(pr,SIr),e(pr,Qc),e(Qc,RIr),e(Qc,mZ),e(mZ,PIr),e(Qc,BIr),e(Qc,gZ),e(gZ,IIr),e(Qc,NIr),e(pr,qIr),e(pr,Qx),e(Qx,jIr),e(Qx,h4e),e(h4e,DIr),e(Qx,GIr),e(pr,OIr),e(pr,zt),M(Hx,zt,null),e(zt,VIr),e(zt,p4e),e(p4e,XIr),e(zt,zIr),e(zt,Hc),e(Hc,WIr),e(Hc,_4e),e(_4e,QIr),e(Hc,HIr),e(Hc,hZ),e(hZ,UIr),e(Hc,JIr),e(zt,YIr),M(IE,zt,null),e(pr,KIr),e(pr,Vr),M(Ux,Vr,null),e(Vr,ZIr),e(Vr,u4e),e(u4e,eNr),e(Vr,oNr),e(Vr,Tn),e(Tn,rNr),e(Tn,b4e),e(b4e,tNr),e(Tn,aNr),e(Tn,v4e),e(v4e,nNr),e(Tn,sNr),e(Tn,F4e),e(F4e,lNr),e(Tn,iNr),e(Vr,dNr),e(Vr,oe),e(oe,NE),e(NE,T4e),e(T4e,cNr),e(NE,fNr),e(NE,pZ),e(pZ,mNr),e(NE,gNr),e(oe,hNr),e(oe,qE),e(qE,M4e),e(M4e,pNr),e(qE,_Nr),e(qE,_Z),e(_Z,uNr),e(qE,bNr),e(oe,vNr),e(oe,jE),e(jE,E4e),e(E4e,FNr),e(jE,TNr),e(jE,uZ),e(uZ,MNr),e(jE,ENr),e(oe,CNr),e(oe,DE),e(DE,C4e),e(C4e,wNr),e(DE,ANr),e(DE,bZ),e(bZ,LNr),e(DE,yNr),e(oe,xNr),e(oe,GE),e(GE,w4e),e(w4e,$Nr),e(GE,kNr),e(GE,vZ),e(vZ,SNr),e(GE,RNr),e(oe,PNr),e(oe,OE),e(OE,A4e),e(A4e,BNr),e(OE,INr),e(OE,FZ),e(FZ,NNr),e(OE,qNr),e(oe,jNr),e(oe,VE),e(VE,L4e),e(L4e,DNr),e(VE,GNr),e(VE,TZ),e(TZ,ONr),e(VE,VNr),e(oe,XNr),e(oe,XE),e(XE,y4e),e(y4e,zNr),e(XE,WNr),e(XE,MZ),e(MZ,QNr),e(XE,HNr),e(oe,UNr),e(oe,zE),e(zE,x4e),e(x4e,JNr),e(zE,YNr),e(zE,EZ),e(EZ,KNr),e(zE,ZNr),e(oe,eqr),e(oe,WE),e(WE,$4e),e($4e,oqr),e(WE,rqr),e(WE,CZ),e(CZ,tqr),e(WE,aqr),e(oe,nqr),e(oe,QE),e(QE,k4e),e(k4e,sqr),e(QE,lqr),e(QE,wZ),e(wZ,iqr),e(QE,dqr),e(oe,cqr),e(oe,HE),e(HE,S4e),e(S4e,fqr),e(HE,mqr),e(HE,AZ),e(AZ,gqr),e(HE,hqr),e(oe,pqr),e(oe,UE),e(UE,R4e),e(R4e,_qr),e(UE,uqr),e(UE,LZ),e(LZ,bqr),e(UE,vqr),e(oe,Fqr),e(oe,JE),e(JE,P4e),e(P4e,Tqr),e(JE,Mqr),e(JE,yZ),e(yZ,Eqr),e(JE,Cqr),e(oe,wqr),e(oe,YE),e(YE,B4e),e(B4e,Aqr),e(YE,Lqr),e(YE,xZ),e(xZ,yqr),e(YE,xqr),e(oe,$qr),e(oe,KE),e(KE,I4e),e(I4e,kqr),e(KE,Sqr),e(KE,$Z),e($Z,Rqr),e(KE,Pqr),e(oe,Bqr),e(oe,ZE),e(ZE,N4e),e(N4e,Iqr),e(ZE,Nqr),e(ZE,kZ),e(kZ,qqr),e(ZE,jqr),e(oe,Dqr),e(oe,eC),e(eC,q4e),e(q4e,Gqr),e(eC,Oqr),e(eC,SZ),e(SZ,Vqr),e(eC,Xqr),e(oe,zqr),e(oe,oC),e(oC,j4e),e(j4e,Wqr),e(oC,Qqr),e(oC,RZ),e(RZ,Hqr),e(oC,Uqr),e(oe,Jqr),e(oe,rC),e(rC,D4e),e(D4e,Yqr),e(rC,Kqr),e(rC,PZ),e(PZ,Zqr),e(rC,ejr),e(oe,ojr),e(oe,tC),e(tC,G4e),e(G4e,rjr),e(tC,tjr),e(tC,BZ),e(BZ,ajr),e(tC,njr),e(oe,sjr),e(oe,aC),e(aC,O4e),e(O4e,ljr),e(aC,ijr),e(aC,IZ),e(IZ,djr),e(aC,cjr),e(oe,fjr),e(oe,nC),e(nC,V4e),e(V4e,mjr),e(nC,gjr),e(nC,NZ),e(NZ,hjr),e(nC,pjr),e(oe,_jr),e(oe,sC),e(sC,X4e),e(X4e,ujr),e(sC,bjr),e(sC,qZ),e(qZ,vjr),e(sC,Fjr),e(oe,Tjr),e(oe,lC),e(lC,z4e),e(z4e,Mjr),e(lC,Ejr),e(lC,jZ),e(jZ,Cjr),e(lC,wjr),e(oe,Ajr),e(oe,iC),e(iC,W4e),e(W4e,Ljr),e(iC,yjr),e(iC,DZ),e(DZ,xjr),e(iC,$jr),e(oe,kjr),e(oe,dC),e(dC,Q4e),e(Q4e,Sjr),e(dC,Rjr),e(dC,GZ),e(GZ,Pjr),e(dC,Bjr),e(Vr,Ijr),M(cC,Vr,null),b(f,EXe,u),b(f,Uc,u),e(Uc,fC),e(fC,H4e),M(Jx,H4e,null),e(Uc,Njr),e(Uc,U4e),e(U4e,qjr),b(f,CXe,u),b(f,_r,u),M(Yx,_r,null),e(_r,jjr),e(_r,Jc),e(Jc,Djr),e(Jc,OZ),e(OZ,Gjr),e(Jc,Ojr),e(Jc,VZ),e(VZ,Vjr),e(Jc,Xjr),e(_r,zjr),e(_r,Kx),e(Kx,Wjr),e(Kx,J4e),e(J4e,Qjr),e(Kx,Hjr),e(_r,Ujr),e(_r,Wt),M(Zx,Wt,null),e(Wt,Jjr),e(Wt,Y4e),e(Y4e,Yjr),e(Wt,Kjr),e(Wt,Yc),e(Yc,Zjr),e(Yc,K4e),e(K4e,eDr),e(Yc,oDr),e(Yc,XZ),e(XZ,rDr),e(Yc,tDr),e(Wt,aDr),M(mC,Wt,null),e(_r,nDr),e(_r,Xr),M(e$,Xr,null),e(Xr,sDr),e(Xr,Z4e),e(Z4e,lDr),e(Xr,iDr),e(Xr,Mn),e(Mn,dDr),e(Mn,eEe),e(eEe,cDr),e(Mn,fDr),e(Mn,oEe),e(oEe,mDr),e(Mn,gDr),e(Mn,rEe),e(rEe,hDr),e(Mn,pDr),e(Xr,_Dr),e(Xr,xe),e(xe,gC),e(gC,tEe),e(tEe,uDr),e(gC,bDr),e(gC,zZ),e(zZ,vDr),e(gC,FDr),e(xe,TDr),e(xe,hC),e(hC,aEe),e(aEe,MDr),e(hC,EDr),e(hC,WZ),e(WZ,CDr),e(hC,wDr),e(xe,ADr),e(xe,pC),e(pC,nEe),e(nEe,LDr),e(pC,yDr),e(pC,QZ),e(QZ,xDr),e(pC,$Dr),e(xe,kDr),e(xe,_C),e(_C,sEe),e(sEe,SDr),e(_C,RDr),e(_C,HZ),e(HZ,PDr),e(_C,BDr),e(xe,IDr),e(xe,uC),e(uC,lEe),e(lEe,NDr),e(uC,qDr),e(uC,UZ),e(UZ,jDr),e(uC,DDr),e(xe,GDr),e(xe,bC),e(bC,iEe),e(iEe,ODr),e(bC,VDr),e(bC,JZ),e(JZ,XDr),e(bC,zDr),e(xe,WDr),e(xe,vC),e(vC,dEe),e(dEe,QDr),e(vC,HDr),e(vC,YZ),e(YZ,UDr),e(vC,JDr),e(xe,YDr),e(xe,FC),e(FC,cEe),e(cEe,KDr),e(FC,ZDr),e(FC,KZ),e(KZ,eGr),e(FC,oGr),e(xe,rGr),e(xe,TC),e(TC,fEe),e(fEe,tGr),e(TC,aGr),e(TC,ZZ),e(ZZ,nGr),e(TC,sGr),e(xe,lGr),e(xe,MC),e(MC,mEe),e(mEe,iGr),e(MC,dGr),e(MC,eee),e(eee,cGr),e(MC,fGr),e(Xr,mGr),M(EC,Xr,null),b(f,wXe,u),b(f,Kc,u),e(Kc,CC),e(CC,gEe),M(o$,gEe,null),e(Kc,gGr),e(Kc,hEe),e(hEe,hGr),b(f,AXe,u),b(f,ur,u),M(r$,ur,null),e(ur,pGr),e(ur,Zc),e(Zc,_Gr),e(Zc,oee),e(oee,uGr),e(Zc,bGr),e(Zc,ree),e(ree,vGr),e(Zc,FGr),e(ur,TGr),e(ur,t$),e(t$,MGr),e(t$,pEe),e(pEe,EGr),e(t$,CGr),e(ur,wGr),e(ur,Qt),M(a$,Qt,null),e(Qt,AGr),e(Qt,_Ee),e(_Ee,LGr),e(Qt,yGr),e(Qt,ef),e(ef,xGr),e(ef,uEe),e(uEe,$Gr),e(ef,kGr),e(ef,tee),e(tee,SGr),e(ef,RGr),e(Qt,PGr),M(wC,Qt,null),e(ur,BGr),e(ur,zr),M(n$,zr,null),e(zr,IGr),e(zr,bEe),e(bEe,NGr),e(zr,qGr),e(zr,En),e(En,jGr),e(En,vEe),e(vEe,DGr),e(En,GGr),e(En,FEe),e(FEe,OGr),e(En,VGr),e(En,TEe),e(TEe,XGr),e(En,zGr),e(zr,WGr),e(zr,Ee),e(Ee,AC),e(AC,MEe),e(MEe,QGr),e(AC,HGr),e(AC,aee),e(aee,UGr),e(AC,JGr),e(Ee,YGr),e(Ee,LC),e(LC,EEe),e(EEe,KGr),e(LC,ZGr),e(LC,nee),e(nee,eOr),e(LC,oOr),e(Ee,rOr),e(Ee,yC),e(yC,CEe),e(CEe,tOr),e(yC,aOr),e(yC,see),e(see,nOr),e(yC,sOr),e(Ee,lOr),e(Ee,xC),e(xC,wEe),e(wEe,iOr),e(xC,dOr),e(xC,lee),e(lee,cOr),e(xC,fOr),e(Ee,mOr),e(Ee,$C),e($C,AEe),e(AEe,gOr),e($C,hOr),e($C,iee),e(iee,pOr),e($C,_Or),e(Ee,uOr),e(Ee,kC),e(kC,LEe),e(LEe,bOr),e(kC,vOr),e(kC,dee),e(dee,FOr),e(kC,TOr),e(Ee,MOr),e(Ee,SC),e(SC,yEe),e(yEe,EOr),e(SC,COr),e(SC,cee),e(cee,wOr),e(SC,AOr),e(Ee,LOr),e(Ee,RC),e(RC,xEe),e(xEe,yOr),e(RC,xOr),e(RC,fee),e(fee,$Or),e(RC,kOr),e(Ee,SOr),e(Ee,PC),e(PC,$Ee),e($Ee,ROr),e(PC,POr),e(PC,mee),e(mee,BOr),e(PC,IOr),e(Ee,NOr),e(Ee,BC),e(BC,kEe),e(kEe,qOr),e(BC,jOr),e(BC,gee),e(gee,DOr),e(BC,GOr),e(Ee,OOr),e(Ee,IC),e(IC,SEe),e(SEe,VOr),e(IC,XOr),e(IC,hee),e(hee,zOr),e(IC,WOr),e(Ee,QOr),e(Ee,NC),e(NC,REe),e(REe,HOr),e(NC,UOr),e(NC,pee),e(pee,JOr),e(NC,YOr),e(Ee,KOr),e(Ee,qC),e(qC,PEe),e(PEe,ZOr),e(qC,eVr),e(qC,_ee),e(_ee,oVr),e(qC,rVr),e(zr,tVr),M(jC,zr,null),b(f,LXe,u),b(f,of,u),e(of,DC),e(DC,BEe),M(s$,BEe,null),e(of,aVr),e(of,IEe),e(IEe,nVr),b(f,yXe,u),b(f,br,u),M(l$,br,null),e(br,sVr),e(br,rf),e(rf,lVr),e(rf,uee),e(uee,iVr),e(rf,dVr),e(rf,bee),e(bee,cVr),e(rf,fVr),e(br,mVr),e(br,i$),e(i$,gVr),e(i$,NEe),e(NEe,hVr),e(i$,pVr),e(br,_Vr),e(br,Ht),M(d$,Ht,null),e(Ht,uVr),e(Ht,qEe),e(qEe,bVr),e(Ht,vVr),e(Ht,tf),e(tf,FVr),e(tf,jEe),e(jEe,TVr),e(tf,MVr),e(tf,vee),e(vee,EVr),e(tf,CVr),e(Ht,wVr),M(GC,Ht,null),e(br,AVr),e(br,Wr),M(c$,Wr,null),e(Wr,LVr),e(Wr,DEe),e(DEe,yVr),e(Wr,xVr),e(Wr,Cn),e(Cn,$Vr),e(Cn,GEe),e(GEe,kVr),e(Cn,SVr),e(Cn,OEe),e(OEe,RVr),e(Cn,PVr),e(Cn,VEe),e(VEe,BVr),e(Cn,IVr),e(Wr,NVr),e(Wr,$e),e($e,OC),e(OC,XEe),e(XEe,qVr),e(OC,jVr),e(OC,Fee),e(Fee,DVr),e(OC,GVr),e($e,OVr),e($e,VC),e(VC,zEe),e(zEe,VVr),e(VC,XVr),e(VC,Tee),e(Tee,zVr),e(VC,WVr),e($e,QVr),e($e,XC),e(XC,WEe),e(WEe,HVr),e(XC,UVr),e(XC,Mee),e(Mee,JVr),e(XC,YVr),e($e,KVr),e($e,zC),e(zC,QEe),e(QEe,ZVr),e(zC,eXr),e(zC,Eee),e(Eee,oXr),e(zC,rXr),e($e,tXr),e($e,WC),e(WC,HEe),e(HEe,aXr),e(WC,nXr),e(WC,Cee),e(Cee,sXr),e(WC,lXr),e($e,iXr),e($e,QC),e(QC,UEe),e(UEe,dXr),e(QC,cXr),e(QC,wee),e(wee,fXr),e(QC,mXr),e($e,gXr),e($e,HC),e(HC,JEe),e(JEe,hXr),e(HC,pXr),e(HC,Aee),e(Aee,_Xr),e(HC,uXr),e($e,bXr),e($e,UC),e(UC,YEe),e(YEe,vXr),e(UC,FXr),e(UC,Lee),e(Lee,TXr),e(UC,MXr),e($e,EXr),e($e,JC),e(JC,KEe),e(KEe,CXr),e(JC,wXr),e(JC,yee),e(yee,AXr),e(JC,LXr),e($e,yXr),e($e,YC),e(YC,ZEe),e(ZEe,xXr),e(YC,$Xr),e(YC,xee),e(xee,kXr),e(YC,SXr),e(Wr,RXr),M(KC,Wr,null),b(f,xXe,u),b(f,af,u),e(af,ZC),e(ZC,eCe),M(f$,eCe,null),e(af,PXr),e(af,oCe),e(oCe,BXr),b(f,$Xe,u),b(f,vr,u),M(m$,vr,null),e(vr,IXr),e(vr,nf),e(nf,NXr),e(nf,$ee),e($ee,qXr),e(nf,jXr),e(nf,kee),e(kee,DXr),e(nf,GXr),e(vr,OXr),e(vr,g$),e(g$,VXr),e(g$,rCe),e(rCe,XXr),e(g$,zXr),e(vr,WXr),e(vr,Ut),M(h$,Ut,null),e(Ut,QXr),e(Ut,tCe),e(tCe,HXr),e(Ut,UXr),e(Ut,sf),e(sf,JXr),e(sf,aCe),e(aCe,YXr),e(sf,KXr),e(sf,See),e(See,ZXr),e(sf,ezr),e(Ut,ozr),M(e3,Ut,null),e(vr,rzr),e(vr,Qr),M(p$,Qr,null),e(Qr,tzr),e(Qr,nCe),e(nCe,azr),e(Qr,nzr),e(Qr,wn),e(wn,szr),e(wn,sCe),e(sCe,lzr),e(wn,izr),e(wn,lCe),e(lCe,dzr),e(wn,czr),e(wn,iCe),e(iCe,fzr),e(wn,mzr),e(Qr,gzr),e(Qr,ke),e(ke,o3),e(o3,dCe),e(dCe,hzr),e(o3,pzr),e(o3,Ree),e(Ree,_zr),e(o3,uzr),e(ke,bzr),e(ke,r3),e(r3,cCe),e(cCe,vzr),e(r3,Fzr),e(r3,Pee),e(Pee,Tzr),e(r3,Mzr),e(ke,Ezr),e(ke,t3),e(t3,fCe),e(fCe,Czr),e(t3,wzr),e(t3,Bee),e(Bee,Azr),e(t3,Lzr),e(ke,yzr),e(ke,a3),e(a3,mCe),e(mCe,xzr),e(a3,$zr),e(a3,Iee),e(Iee,kzr),e(a3,Szr),e(ke,Rzr),e(ke,n3),e(n3,gCe),e(gCe,Pzr),e(n3,Bzr),e(n3,Nee),e(Nee,Izr),e(n3,Nzr),e(ke,qzr),e(ke,s3),e(s3,hCe),e(hCe,jzr),e(s3,Dzr),e(s3,qee),e(qee,Gzr),e(s3,Ozr),e(ke,Vzr),e(ke,l3),e(l3,pCe),e(pCe,Xzr),e(l3,zzr),e(l3,jee),e(jee,Wzr),e(l3,Qzr),e(ke,Hzr),e(ke,i3),e(i3,_Ce),e(_Ce,Uzr),e(i3,Jzr),e(i3,Dee),e(Dee,Yzr),e(i3,Kzr),e(ke,Zzr),e(ke,d3),e(d3,uCe),e(uCe,eWr),e(d3,oWr),e(d3,Gee),e(Gee,rWr),e(d3,tWr),e(ke,aWr),e(ke,c3),e(c3,bCe),e(bCe,nWr),e(c3,sWr),e(c3,Oee),e(Oee,lWr),e(c3,iWr),e(Qr,dWr),M(f3,Qr,null),b(f,kXe,u),b(f,lf,u),e(lf,m3),e(m3,vCe),M(_$,vCe,null),e(lf,cWr),e(lf,FCe),e(FCe,fWr),b(f,SXe,u),b(f,Fr,u),M(u$,Fr,null),e(Fr,mWr),e(Fr,df),e(df,gWr),e(df,Vee),e(Vee,hWr),e(df,pWr),e(df,Xee),e(Xee,_Wr),e(df,uWr),e(Fr,bWr),e(Fr,b$),e(b$,vWr),e(b$,TCe),e(TCe,FWr),e(b$,TWr),e(Fr,MWr),e(Fr,Jt),M(v$,Jt,null),e(Jt,EWr),e(Jt,MCe),e(MCe,CWr),e(Jt,wWr),e(Jt,cf),e(cf,AWr),e(cf,ECe),e(ECe,LWr),e(cf,yWr),e(cf,zee),e(zee,xWr),e(cf,$Wr),e(Jt,kWr),M(g3,Jt,null),e(Fr,SWr),e(Fr,Hr),M(F$,Hr,null),e(Hr,RWr),e(Hr,CCe),e(CCe,PWr),e(Hr,BWr),e(Hr,An),e(An,IWr),e(An,wCe),e(wCe,NWr),e(An,qWr),e(An,ACe),e(ACe,jWr),e(An,DWr),e(An,LCe),e(LCe,GWr),e(An,OWr),e(Hr,VWr),e(Hr,Se),e(Se,h3),e(h3,yCe),e(yCe,XWr),e(h3,zWr),e(h3,Wee),e(Wee,WWr),e(h3,QWr),e(Se,HWr),e(Se,p3),e(p3,xCe),e(xCe,UWr),e(p3,JWr),e(p3,Qee),e(Qee,YWr),e(p3,KWr),e(Se,ZWr),e(Se,_3),e(_3,$Ce),e($Ce,eQr),e(_3,oQr),e(_3,Hee),e(Hee,rQr),e(_3,tQr),e(Se,aQr),e(Se,u3),e(u3,kCe),e(kCe,nQr),e(u3,sQr),e(u3,Uee),e(Uee,lQr),e(u3,iQr),e(Se,dQr),e(Se,b3),e(b3,SCe),e(SCe,cQr),e(b3,fQr),e(b3,Jee),e(Jee,mQr),e(b3,gQr),e(Se,hQr),e(Se,v3),e(v3,RCe),e(RCe,pQr),e(v3,_Qr),e(v3,Yee),e(Yee,uQr),e(v3,bQr),e(Se,vQr),e(Se,F3),e(F3,PCe),e(PCe,FQr),e(F3,TQr),e(F3,Kee),e(Kee,MQr),e(F3,EQr),e(Se,CQr),e(Se,T3),e(T3,BCe),e(BCe,wQr),e(T3,AQr),e(T3,Zee),e(Zee,LQr),e(T3,yQr),e(Se,xQr),e(Se,M3),e(M3,ICe),e(ICe,$Qr),e(M3,kQr),e(M3,eoe),e(eoe,SQr),e(M3,RQr),e(Se,PQr),e(Se,E3),e(E3,NCe),e(NCe,BQr),e(E3,IQr),e(E3,ooe),e(ooe,NQr),e(E3,qQr),e(Hr,jQr),M(C3,Hr,null),b(f,RXe,u),b(f,ff,u),e(ff,w3),e(w3,qCe),M(T$,qCe,null),e(ff,DQr),e(ff,jCe),e(jCe,GQr),b(f,PXe,u),b(f,Tr,u),M(M$,Tr,null),e(Tr,OQr),e(Tr,mf),e(mf,VQr),e(mf,roe),e(roe,XQr),e(mf,zQr),e(mf,toe),e(toe,WQr),e(mf,QQr),e(Tr,HQr),e(Tr,E$),e(E$,UQr),e(E$,DCe),e(DCe,JQr),e(E$,YQr),e(Tr,KQr),e(Tr,Yt),M(C$,Yt,null),e(Yt,ZQr),e(Yt,GCe),e(GCe,eHr),e(Yt,oHr),e(Yt,gf),e(gf,rHr),e(gf,OCe),e(OCe,tHr),e(gf,aHr),e(gf,aoe),e(aoe,nHr),e(gf,sHr),e(Yt,lHr),M(A3,Yt,null),e(Tr,iHr),e(Tr,Ur),M(w$,Ur,null),e(Ur,dHr),e(Ur,VCe),e(VCe,cHr),e(Ur,fHr),e(Ur,Ln),e(Ln,mHr),e(Ln,XCe),e(XCe,gHr),e(Ln,hHr),e(Ln,zCe),e(zCe,pHr),e(Ln,_Hr),e(Ln,WCe),e(WCe,uHr),e(Ln,bHr),e(Ur,vHr),e(Ur,Re),e(Re,L3),e(L3,QCe),e(QCe,FHr),e(L3,THr),e(L3,noe),e(noe,MHr),e(L3,EHr),e(Re,CHr),e(Re,y3),e(y3,HCe),e(HCe,wHr),e(y3,AHr),e(y3,soe),e(soe,LHr),e(y3,yHr),e(Re,xHr),e(Re,x3),e(x3,UCe),e(UCe,$Hr),e(x3,kHr),e(x3,loe),e(loe,SHr),e(x3,RHr),e(Re,PHr),e(Re,$3),e($3,JCe),e(JCe,BHr),e($3,IHr),e($3,ioe),e(ioe,NHr),e($3,qHr),e(Re,jHr),e(Re,k3),e(k3,YCe),e(YCe,DHr),e(k3,GHr),e(k3,doe),e(doe,OHr),e(k3,VHr),e(Re,XHr),e(Re,S3),e(S3,KCe),e(KCe,zHr),e(S3,WHr),e(S3,coe),e(coe,QHr),e(S3,HHr),e(Re,UHr),e(Re,R3),e(R3,ZCe),e(ZCe,JHr),e(R3,YHr),e(R3,foe),e(foe,KHr),e(R3,ZHr),e(Re,eUr),e(Re,P3),e(P3,e3e),e(e3e,oUr),e(P3,rUr),e(P3,moe),e(moe,tUr),e(P3,aUr),e(Re,nUr),e(Re,B3),e(B3,o3e),e(o3e,sUr),e(B3,lUr),e(B3,goe),e(goe,iUr),e(B3,dUr),e(Re,cUr),e(Re,I3),e(I3,r3e),e(r3e,fUr),e(I3,mUr),e(I3,hoe),e(hoe,gUr),e(I3,hUr),e(Ur,pUr),M(N3,Ur,null),b(f,BXe,u),b(f,hf,u),e(hf,q3),e(q3,t3e),M(A$,t3e,null),e(hf,_Ur),e(hf,a3e),e(a3e,uUr),b(f,IXe,u),b(f,Mr,u),M(L$,Mr,null),e(Mr,bUr),e(Mr,pf),e(pf,vUr),e(pf,poe),e(poe,FUr),e(pf,TUr),e(pf,_oe),e(_oe,MUr),e(pf,EUr),e(Mr,CUr),e(Mr,y$),e(y$,wUr),e(y$,n3e),e(n3e,AUr),e(y$,LUr),e(Mr,yUr),e(Mr,Kt),M(x$,Kt,null),e(Kt,xUr),e(Kt,s3e),e(s3e,$Ur),e(Kt,kUr),e(Kt,_f),e(_f,SUr),e(_f,l3e),e(l3e,RUr),e(_f,PUr),e(_f,uoe),e(uoe,BUr),e(_f,IUr),e(Kt,NUr),M(j3,Kt,null),e(Mr,qUr),e(Mr,Jr),M($$,Jr,null),e(Jr,jUr),e(Jr,i3e),e(i3e,DUr),e(Jr,GUr),e(Jr,yn),e(yn,OUr),e(yn,d3e),e(d3e,VUr),e(yn,XUr),e(yn,c3e),e(c3e,zUr),e(yn,WUr),e(yn,f3e),e(f3e,QUr),e(yn,HUr),e(Jr,UUr),e(Jr,Ve),e(Ve,D3),e(D3,m3e),e(m3e,JUr),e(D3,YUr),e(D3,boe),e(boe,KUr),e(D3,ZUr),e(Ve,eJr),e(Ve,G3),e(G3,g3e),e(g3e,oJr),e(G3,rJr),e(G3,voe),e(voe,tJr),e(G3,aJr),e(Ve,nJr),e(Ve,O3),e(O3,h3e),e(h3e,sJr),e(O3,lJr),e(O3,Foe),e(Foe,iJr),e(O3,dJr),e(Ve,cJr),e(Ve,V3),e(V3,p3e),e(p3e,fJr),e(V3,mJr),e(V3,Toe),e(Toe,gJr),e(V3,hJr),e(Ve,pJr),e(Ve,X3),e(X3,_3e),e(_3e,_Jr),e(X3,uJr),e(X3,Moe),e(Moe,bJr),e(X3,vJr),e(Ve,FJr),e(Ve,z3),e(z3,u3e),e(u3e,TJr),e(z3,MJr),e(z3,Eoe),e(Eoe,EJr),e(z3,CJr),e(Ve,wJr),e(Ve,W3),e(W3,b3e),e(b3e,AJr),e(W3,LJr),e(W3,Coe),e(Coe,yJr),e(W3,xJr),e(Ve,$Jr),e(Ve,Q3),e(Q3,v3e),e(v3e,kJr),e(Q3,SJr),e(Q3,woe),e(woe,RJr),e(Q3,PJr),e(Jr,BJr),M(H3,Jr,null),b(f,NXe,u),b(f,uf,u),e(uf,U3),e(U3,F3e),M(k$,F3e,null),e(uf,IJr),e(uf,T3e),e(T3e,NJr),b(f,qXe,u),b(f,Er,u),M(S$,Er,null),e(Er,qJr),e(Er,bf),e(bf,jJr),e(bf,Aoe),e(Aoe,DJr),e(bf,GJr),e(bf,Loe),e(Loe,OJr),e(bf,VJr),e(Er,XJr),e(Er,R$),e(R$,zJr),e(R$,M3e),e(M3e,WJr),e(R$,QJr),e(Er,HJr),e(Er,Zt),M(P$,Zt,null),e(Zt,UJr),e(Zt,E3e),e(E3e,JJr),e(Zt,YJr),e(Zt,vf),e(vf,KJr),e(vf,C3e),e(C3e,ZJr),e(vf,eYr),e(vf,yoe),e(yoe,oYr),e(vf,rYr),e(Zt,tYr),M(J3,Zt,null),e(Er,aYr),e(Er,Yr),M(B$,Yr,null),e(Yr,nYr),e(Yr,w3e),e(w3e,sYr),e(Yr,lYr),e(Yr,xn),e(xn,iYr),e(xn,A3e),e(A3e,dYr),e(xn,cYr),e(xn,L3e),e(L3e,fYr),e(xn,mYr),e(xn,y3e),e(y3e,gYr),e(xn,hYr),e(Yr,pYr),e(Yr,Xe),e(Xe,Y3),e(Y3,x3e),e(x3e,_Yr),e(Y3,uYr),e(Y3,xoe),e(xoe,bYr),e(Y3,vYr),e(Xe,FYr),e(Xe,K3),e(K3,$3e),e($3e,TYr),e(K3,MYr),e(K3,$oe),e($oe,EYr),e(K3,CYr),e(Xe,wYr),e(Xe,Z3),e(Z3,k3e),e(k3e,AYr),e(Z3,LYr),e(Z3,koe),e(koe,yYr),e(Z3,xYr),e(Xe,$Yr),e(Xe,e5),e(e5,S3e),e(S3e,kYr),e(e5,SYr),e(e5,Soe),e(Soe,RYr),e(e5,PYr),e(Xe,BYr),e(Xe,o5),e(o5,R3e),e(R3e,IYr),e(o5,NYr),e(o5,Roe),e(Roe,qYr),e(o5,jYr),e(Xe,DYr),e(Xe,r5),e(r5,P3e),e(P3e,GYr),e(r5,OYr),e(r5,Poe),e(Poe,VYr),e(r5,XYr),e(Xe,zYr),e(Xe,t5),e(t5,B3e),e(B3e,WYr),e(t5,QYr),e(t5,Boe),e(Boe,HYr),e(t5,UYr),e(Xe,JYr),e(Xe,a5),e(a5,I3e),e(I3e,YYr),e(a5,KYr),e(a5,Ioe),e(Ioe,ZYr),e(a5,eKr),e(Yr,oKr),M(n5,Yr,null),b(f,jXe,u),b(f,Ff,u),e(Ff,s5),e(s5,N3e),M(I$,N3e,null),e(Ff,rKr),e(Ff,q3e),e(q3e,tKr),b(f,DXe,u),b(f,Cr,u),M(N$,Cr,null),e(Cr,aKr),e(Cr,Tf),e(Tf,nKr),e(Tf,Noe),e(Noe,sKr),e(Tf,lKr),e(Tf,qoe),e(qoe,iKr),e(Tf,dKr),e(Cr,cKr),e(Cr,q$),e(q$,fKr),e(q$,j3e),e(j3e,mKr),e(q$,gKr),e(Cr,hKr),e(Cr,ea),M(j$,ea,null),e(ea,pKr),e(ea,D3e),e(D3e,_Kr),e(ea,uKr),e(ea,Mf),e(Mf,bKr),e(Mf,G3e),e(G3e,vKr),e(Mf,FKr),e(Mf,joe),e(joe,TKr),e(Mf,MKr),e(ea,EKr),M(l5,ea,null),e(Cr,CKr),e(Cr,Kr),M(D$,Kr,null),e(Kr,wKr),e(Kr,O3e),e(O3e,AKr),e(Kr,LKr),e(Kr,$n),e($n,yKr),e($n,V3e),e(V3e,xKr),e($n,$Kr),e($n,X3e),e(X3e,kKr),e($n,SKr),e($n,z3e),e(z3e,RKr),e($n,PKr),e(Kr,BKr),e(Kr,W3e),e(W3e,i5),e(i5,Q3e),e(Q3e,IKr),e(i5,NKr),e(i5,Doe),e(Doe,qKr),e(i5,jKr),e(Kr,DKr),M(d5,Kr,null),b(f,GXe,u),b(f,Ef,u),e(Ef,c5),e(c5,H3e),M(G$,H3e,null),e(Ef,GKr),e(Ef,U3e),e(U3e,OKr),b(f,OXe,u),b(f,wr,u),M(O$,wr,null),e(wr,VKr),e(wr,Cf),e(Cf,XKr),e(Cf,Goe),e(Goe,zKr),e(Cf,WKr),e(Cf,Ooe),e(Ooe,QKr),e(Cf,HKr),e(wr,UKr),e(wr,V$),e(V$,JKr),e(V$,J3e),e(J3e,YKr),e(V$,KKr),e(wr,ZKr),e(wr,oa),M(X$,oa,null),e(oa,eZr),e(oa,Y3e),e(Y3e,oZr),e(oa,rZr),e(oa,wf),e(wf,tZr),e(wf,K3e),e(K3e,aZr),e(wf,nZr),e(wf,Voe),e(Voe,sZr),e(wf,lZr),e(oa,iZr),M(f5,oa,null),e(wr,dZr),e(wr,Zr),M(z$,Zr,null),e(Zr,cZr),e(Zr,Z3e),e(Z3e,fZr),e(Zr,mZr),e(Zr,kn),e(kn,gZr),e(kn,e5e),e(e5e,hZr),e(kn,pZr),e(kn,o5e),e(o5e,_Zr),e(kn,uZr),e(kn,r5e),e(r5e,bZr),e(kn,vZr),e(Zr,FZr),e(Zr,W$),e(W$,m5),e(m5,t5e),e(t5e,TZr),e(m5,MZr),e(m5,Xoe),e(Xoe,EZr),e(m5,CZr),e(W$,wZr),e(W$,g5),e(g5,a5e),e(a5e,AZr),e(g5,LZr),e(g5,zoe),e(zoe,yZr),e(g5,xZr),e(Zr,$Zr),M(h5,Zr,null),b(f,VXe,u),b(f,Af,u),e(Af,p5),e(p5,n5e),M(Q$,n5e,null),e(Af,kZr),e(Af,s5e),e(s5e,SZr),b(f,XXe,u),b(f,Ar,u),M(H$,Ar,null),e(Ar,RZr),e(Ar,Lf),e(Lf,PZr),e(Lf,Woe),e(Woe,BZr),e(Lf,IZr),e(Lf,Qoe),e(Qoe,NZr),e(Lf,qZr),e(Ar,jZr),e(Ar,U$),e(U$,DZr),e(U$,l5e),e(l5e,GZr),e(U$,OZr),e(Ar,VZr),e(Ar,ra),M(J$,ra,null),e(ra,XZr),e(ra,i5e),e(i5e,zZr),e(ra,WZr),e(ra,yf),e(yf,QZr),e(yf,d5e),e(d5e,HZr),e(yf,UZr),e(yf,Hoe),e(Hoe,JZr),e(yf,YZr),e(ra,KZr),M(_5,ra,null),e(Ar,ZZr),e(Ar,et),M(Y$,et,null),e(et,eet),e(et,c5e),e(c5e,oet),e(et,ret),e(et,Sn),e(Sn,tet),e(Sn,f5e),e(f5e,aet),e(Sn,net),e(Sn,m5e),e(m5e,set),e(Sn,iet),e(Sn,g5e),e(g5e,det),e(Sn,cet),e(et,fet),e(et,h5e),e(h5e,u5),e(u5,p5e),e(p5e,met),e(u5,get),e(u5,Uoe),e(Uoe,het),e(u5,pet),e(et,_et),M(b5,et,null),zXe=!0},p(f,[u]){const K$={};u&2&&(K$.$$scope={dirty:u,ctx:f}),Nf.$set(K$);const _5e={};u&2&&(_5e.$$scope={dirty:u,ctx:f}),Qg.$set(_5e);const u5e={};u&2&&(u5e.$$scope={dirty:u,ctx:f}),xh.$set(u5e);const b5e={};u&2&&(b5e.$$scope={dirty:u,ctx:f}),fp.$set(b5e);const Z$={};u&2&&(Z$.$$scope={dirty:u,ctx:f}),mp.$set(Z$);const v5e={};u&2&&(v5e.$$scope={dirty:u,ctx:f}),Rp.$set(v5e);const Rn={};u&2&&(Rn.$$scope={dirty:u,ctx:f}),Pp.$set(Rn);const F5e={};u&2&&(F5e.$$scope={dirty:u,ctx:f}),Np.$set(F5e);const T5e={};u&2&&(T5e.$$scope={dirty:u,ctx:f}),ju.$set(T5e);const M5e={};u&2&&(M5e.$$scope={dirty:u,ctx:f}),Gu.$set(M5e);const ek={};u&2&&(ek.$$scope={dirty:u,ctx:f}),R1.$set(ek);const E5e={};u&2&&(E5e.$$scope={dirty:u,ctx:f}),B1.$set(E5e);const ok={};u&2&&(ok.$$scope={dirty:u,ctx:f}),M2.$set(ok);const C5e={};u&2&&(C5e.$$scope={dirty:u,ctx:f}),C2.$set(C5e);const rk={};u&2&&(rk.$$scope={dirty:u,ctx:f}),db.$set(rk);const w5e={};u&2&&(w5e.$$scope={dirty:u,ctx:f}),fb.$set(w5e);const A5e={};u&2&&(A5e.$$scope={dirty:u,ctx:f}),$b.$set(A5e);const L5e={};u&2&&(L5e.$$scope={dirty:u,ctx:f}),Sb.$set(L5e);const xf={};u&2&&(xf.$$scope={dirty:u,ctx:f}),xv.$set(xf);const y5e={};u&2&&(y5e.$$scope={dirty:u,ctx:f}),kv.$set(y5e);const x5e={};u&2&&(x5e.$$scope={dirty:u,ctx:f}),d0.$set(x5e);const $5e={};u&2&&($5e.$$scope={dirty:u,ctx:f}),f0.$set($5e);const tk={};u&2&&(tk.$$scope={dirty:u,ctx:f}),v0.$set(tk);const k5e={};u&2&&(k5e.$$scope={dirty:u,ctx:f}),T0.$set(k5e);const S5e={};u&2&&(S5e.$$scope={dirty:u,ctx:f}),nF.$set(S5e);const R5e={};u&2&&(R5e.$$scope={dirty:u,ctx:f}),lF.$set(R5e);const tt={};u&2&&(tt.$$scope={dirty:u,ctx:f}),JF.$set(tt);const ak={};u&2&&(ak.$$scope={dirty:u,ctx:f}),KF.$set(ak);const P5e={};u&2&&(P5e.$$scope={dirty:u,ctx:f}),o6.$set(P5e);const nk={};u&2&&(nk.$$scope={dirty:u,ctx:f}),t6.$set(nk);const B5e={};u&2&&(B5e.$$scope={dirty:u,ctx:f}),u6.$set(B5e);const at={};u&2&&(at.$$scope={dirty:u,ctx:f}),v6.$set(at);const I5e={};u&2&&(I5e.$$scope={dirty:u,ctx:f}),M6.$set(I5e);const $f={};u&2&&($f.$$scope={dirty:u,ctx:f}),C6.$set($f);const N5e={};u&2&&(N5e.$$scope={dirty:u,ctx:f}),L6.$set(N5e);const q5e={};u&2&&(q5e.$$scope={dirty:u,ctx:f}),x6.$set(q5e);const L={};u&2&&(L.$$scope={dirty:u,ctx:f}),D6.$set(L);const v5={};u&2&&(v5.$$scope={dirty:u,ctx:f}),O6.$set(v5);const j5e={};u&2&&(j5e.$$scope={dirty:u,ctx:f}),U6.$set(j5e);const D5e={};u&2&&(D5e.$$scope={dirty:u,ctx:f}),Y6.$set(D5e);const F5={};u&2&&(F5.$$scope={dirty:u,ctx:f}),dT.$set(F5);const G5e={};u&2&&(G5e.$$scope={dirty:u,ctx:f}),fT.$set(G5e);const O5e={};u&2&&(O5e.$$scope={dirty:u,ctx:f}),pT.$set(O5e);const T5={};u&2&&(T5.$$scope={dirty:u,ctx:f}),uT.$set(T5);const V5e={};u&2&&(V5e.$$scope={dirty:u,ctx:f}),CT.$set(V5e);const X5e={};u&2&&(X5e.$$scope={dirty:u,ctx:f}),AT.$set(X5e);const M5={};u&2&&(M5.$$scope={dirty:u,ctx:f}),kT.$set(M5);const z5e={};u&2&&(z5e.$$scope={dirty:u,ctx:f}),RT.$set(z5e);const W5e={};u&2&&(W5e.$$scope={dirty:u,ctx:f}),NT.$set(W5e);const E5={};u&2&&(E5.$$scope={dirty:u,ctx:f}),jT.$set(E5);const Q5e={};u&2&&(Q5e.$$scope={dirty:u,ctx:f}),OT.$set(Q5e);const H5e={};u&2&&(H5e.$$scope={dirty:u,ctx:f}),XT.$set(H5e);const C5={};u&2&&(C5.$$scope={dirty:u,ctx:f}),JT.$set(C5);const U5e={};u&2&&(U5e.$$scope={dirty:u,ctx:f}),KT.$set(U5e);const J5e={};u&2&&(J5e.$$scope={dirty:u,ctx:f}),o7.$set(J5e);const w5={};u&2&&(w5.$$scope={dirty:u,ctx:f}),t7.$set(w5);const Y5e={};u&2&&(Y5e.$$scope={dirty:u,ctx:f}),K7.$set(Y5e);const K5e={};u&2&&(K5e.$$scope={dirty:u,ctx:f}),e8.$set(K5e);const A5={};u&2&&(A5.$$scope={dirty:u,ctx:f}),C8.$set(A5);const Z5e={};u&2&&(Z5e.$$scope={dirty:u,ctx:f}),A8.$set(Z5e);const ewe={};u&2&&(ewe.$$scope={dirty:u,ctx:f}),D8.$set(ewe);const L5={};u&2&&(L5.$$scope={dirty:u,ctx:f}),O8.$set(L5);const owe={};u&2&&(owe.$$scope={dirty:u,ctx:f}),H8.$set(owe);const rwe={};u&2&&(rwe.$$scope={dirty:u,ctx:f}),J8.$set(rwe);const y5={};u&2&&(y5.$$scope={dirty:u,ctx:f}),uM.$set(y5);const twe={};u&2&&(twe.$$scope={dirty:u,ctx:f}),vM.$set(twe);const awe={};u&2&&(awe.$$scope={dirty:u,ctx:f}),$M.$set(awe);const x5={};u&2&&(x5.$$scope={dirty:u,ctx:f}),SM.$set(x5);const nwe={};u&2&&(nwe.$$scope={dirty:u,ctx:f}),n4.$set(nwe);const swe={};u&2&&(swe.$$scope={dirty:u,ctx:f}),l4.$set(swe);const $5={};u&2&&($5.$$scope={dirty:u,ctx:f}),w4.$set($5);const lwe={};u&2&&(lwe.$$scope={dirty:u,ctx:f}),L4.$set(lwe);const iwe={};u&2&&(iwe.$$scope={dirty:u,ctx:f}),$4.$set(iwe);const k5={};u&2&&(k5.$$scope={dirty:u,ctx:f}),S4.$set(k5);const dwe={};u&2&&(dwe.$$scope={dirty:u,ctx:f}),P4.$set(dwe);const cwe={};u&2&&(cwe.$$scope={dirty:u,ctx:f}),I4.$set(cwe);const S5={};u&2&&(S5.$$scope={dirty:u,ctx:f}),tE.$set(S5);const fwe={};u&2&&(fwe.$$scope={dirty:u,ctx:f}),nE.$set(fwe);const mwe={};u&2&&(mwe.$$scope={dirty:u,ctx:f}),AE.$set(mwe);const R5={};u&2&&(R5.$$scope={dirty:u,ctx:f}),yE.$set(R5);const gwe={};u&2&&(gwe.$$scope={dirty:u,ctx:f}),$E.$set(gwe);const hwe={};u&2&&(hwe.$$scope={dirty:u,ctx:f}),SE.$set(hwe);const P5={};u&2&&(P5.$$scope={dirty:u,ctx:f}),PE.$set(P5);const pwe={};u&2&&(pwe.$$scope={dirty:u,ctx:f}),IE.$set(pwe);const _we={};u&2&&(_we.$$scope={dirty:u,ctx:f}),cC.$set(_we);const B5={};u&2&&(B5.$$scope={dirty:u,ctx:f}),mC.$set(B5);const uwe={};u&2&&(uwe.$$scope={dirty:u,ctx:f}),EC.$set(uwe);const bwe={};u&2&&(bwe.$$scope={dirty:u,ctx:f}),wC.$set(bwe);const I5={};u&2&&(I5.$$scope={dirty:u,ctx:f}),jC.$set(I5);const vwe={};u&2&&(vwe.$$scope={dirty:u,ctx:f}),GC.$set(vwe);const Fwe={};u&2&&(Fwe.$$scope={dirty:u,ctx:f}),KC.$set(Fwe);const N5={};u&2&&(N5.$$scope={dirty:u,ctx:f}),e3.$set(N5);const Twe={};u&2&&(Twe.$$scope={dirty:u,ctx:f}),f3.$set(Twe);const Mwe={};u&2&&(Mwe.$$scope={dirty:u,ctx:f}),g3.$set(Mwe);const q5={};u&2&&(q5.$$scope={dirty:u,ctx:f}),C3.$set(q5);const Ewe={};u&2&&(Ewe.$$scope={dirty:u,ctx:f}),A3.$set(Ewe);const Cwe={};u&2&&(Cwe.$$scope={dirty:u,ctx:f}),N3.$set(Cwe);const j5={};u&2&&(j5.$$scope={dirty:u,ctx:f}),j3.$set(j5);const wwe={};u&2&&(wwe.$$scope={dirty:u,ctx:f}),H3.$set(wwe);const Awe={};u&2&&(Awe.$$scope={dirty:u,ctx:f}),J3.$set(Awe);const D5={};u&2&&(D5.$$scope={dirty:u,ctx:f}),n5.$set(D5);const Lwe={};u&2&&(Lwe.$$scope={dirty:u,ctx:f}),l5.$set(Lwe);const ywe={};u&2&&(ywe.$$scope={dirty:u,ctx:f}),d5.$set(ywe);const G5={};u&2&&(G5.$$scope={dirty:u,ctx:f}),f5.$set(G5);const xwe={};u&2&&(xwe.$$scope={dirty:u,ctx:f}),h5.$set(xwe);const $we={};u&2&&($we.$$scope={dirty:u,ctx:f}),_5.$set($we);const O5={};u&2&&(O5.$$scope={dirty:u,ctx:f}),b5.$set(O5)},i(f){zXe||(E(d.$$.fragment,f),E(ka.$$.fragment,f),E(OA.$$.fragment,f),E(VA.$$.fragment,f),E(Nf.$$.fragment,f),E(XA.$$.fragment,f),E(zA.$$.fragment,f),E(HA.$$.fragment,f),E(Qg.$$.fragment,f),E(UA.$$.fragment,f),E(JA.$$.fragment,f),E(YA.$$.fragment,f),E(eL.$$.fragment,f),E(xh.$$.fragment,f),E(oL.$$.fragment,f),E(rL.$$.fragment,f),E(tL.$$.fragment,f),E(sL.$$.fragment,f),E(fp.$$.fragment,f),E(mp.$$.fragment,f),E(lL.$$.fragment,f),E(iL.$$.fragment,f),E(dL.$$.fragment,f),E(mL.$$.fragment,f),E(Rp.$$.fragment,f),E(Pp.$$.fragment,f),E(gL.$$.fragment,f),E(hL.$$.fragment,f),E(pL.$$.fragment,f),E(uL.$$.fragment,f),E(Np.$$.fragment,f),E(bL.$$.fragment,f),E(ju.$$.fragment,f),E(vL.$$.fragment,f),E(FL.$$.fragment,f),E(ML.$$.fragment,f),E(Gu.$$.fragment,f),E(EL.$$.fragment,f),E(R1.$$.fragment,f),E(CL.$$.fragment,f),E(wL.$$.fragment,f),E(LL.$$.fragment,f),E(B1.$$.fragment,f),E(yL.$$.fragment,f),E(M2.$$.fragment,f),E(xL.$$.fragment,f),E($L.$$.fragment,f),E(SL.$$.fragment,f),E(C2.$$.fragment,f),E(RL.$$.fragment,f),E(db.$$.fragment,f),E(PL.$$.fragment,f),E(BL.$$.fragment,f),E(NL.$$.fragment,f),E(fb.$$.fragment,f),E(qL.$$.fragment,f),E($b.$$.fragment,f),E(jL.$$.fragment,f),E(DL.$$.fragment,f),E(OL.$$.fragment,f),E(Sb.$$.fragment,f),E(VL.$$.fragment,f),E(xv.$$.fragment,f),E(XL.$$.fragment,f),E(zL.$$.fragment,f),E(QL.$$.fragment,f),E(kv.$$.fragment,f),E(HL.$$.fragment,f),E(d0.$$.fragment,f),E(UL.$$.fragment,f),E(JL.$$.fragment,f),E(KL.$$.fragment,f),E(f0.$$.fragment,f),E(ZL.$$.fragment,f),E(v0.$$.fragment,f),E(ey.$$.fragment,f),E(oy.$$.fragment,f),E(ty.$$.fragment,f),E(T0.$$.fragment,f),E(ay.$$.fragment,f),E(nF.$$.fragment,f),E(ny.$$.fragment,f),E(sy.$$.fragment,f),E(iy.$$.fragment,f),E(lF.$$.fragment,f),E(dy.$$.fragment,f),E(JF.$$.fragment,f),E(cy.$$.fragment,f),E(fy.$$.fragment,f),E(gy.$$.fragment,f),E(KF.$$.fragment,f),E(hy.$$.fragment,f),E(o6.$$.fragment,f),E(py.$$.fragment,f),E(_y.$$.fragment,f),E(by.$$.fragment,f),E(t6.$$.fragment,f),E(vy.$$.fragment,f),E(u6.$$.fragment,f),E(Fy.$$.fragment,f),E(Ty.$$.fragment,f),E(Ey.$$.fragment,f),E(v6.$$.fragment,f),E(Cy.$$.fragment,f),E(M6.$$.fragment,f),E(wy.$$.fragment,f),E(Ay.$$.fragment,f),E(yy.$$.fragment,f),E(C6.$$.fragment,f),E(xy.$$.fragment,f),E(L6.$$.fragment,f),E($y.$$.fragment,f),E(ky.$$.fragment,f),E(Ry.$$.fragment,f),E(x6.$$.fragment,f),E(Py.$$.fragment,f),E(D6.$$.fragment,f),E(By.$$.fragment,f),E(Iy.$$.fragment,f),E(qy.$$.fragment,f),E(O6.$$.fragment,f),E(jy.$$.fragment,f),E(U6.$$.fragment,f),E(Dy.$$.fragment,f),E(Gy.$$.fragment,f),E(Vy.$$.fragment,f),E(Y6.$$.fragment,f),E(Xy.$$.fragment,f),E(dT.$$.fragment,f),E(zy.$$.fragment,f),E(Wy.$$.fragment,f),E(Hy.$$.fragment,f),E(fT.$$.fragment,f),E(Uy.$$.fragment,f),E(pT.$$.fragment,f),E(Yy.$$.fragment,f),E(Ky.$$.fragment,f),E(e9.$$.fragment,f),E(uT.$$.fragment,f),E(o9.$$.fragment,f),E(CT.$$.fragment,f),E(r9.$$.fragment,f),E(t9.$$.fragment,f),E(n9.$$.fragment,f),E(AT.$$.fragment,f),E(s9.$$.fragment,f),E(kT.$$.fragment,f),E(l9.$$.fragment,f),E(i9.$$.fragment,f),E(c9.$$.fragment,f),E(RT.$$.fragment,f),E(f9.$$.fragment,f),E(NT.$$.fragment,f),E(g9.$$.fragment,f),E(h9.$$.fragment,f),E(_9.$$.fragment,f),E(jT.$$.fragment,f),E(u9.$$.fragment,f),E(OT.$$.fragment,f),E(b9.$$.fragment,f),E(v9.$$.fragment,f),E(T9.$$.fragment,f),E(XT.$$.fragment,f),E(M9.$$.fragment,f),E(JT.$$.fragment,f),E(E9.$$.fragment,f),E(C9.$$.fragment,f),E(A9.$$.fragment,f),E(KT.$$.fragment,f),E(L9.$$.fragment,f),E(o7.$$.fragment,f),E(y9.$$.fragment,f),E(x9.$$.fragment,f),E(k9.$$.fragment,f),E(t7.$$.fragment,f),E(S9.$$.fragment,f),E(K7.$$.fragment,f),E(R9.$$.fragment,f),E(P9.$$.fragment,f),E(I9.$$.fragment,f),E(e8.$$.fragment,f),E(N9.$$.fragment,f),E(C8.$$.fragment,f),E(q9.$$.fragment,f),E(j9.$$.fragment,f),E(G9.$$.fragment,f),E(A8.$$.fragment,f),E(O9.$$.fragment,f),E(D8.$$.fragment,f),E(V9.$$.fragment,f),E(X9.$$.fragment,f),E(W9.$$.fragment,f),E(O8.$$.fragment,f),E(Q9.$$.fragment,f),E(H8.$$.fragment,f),E(H9.$$.fragment,f),E(U9.$$.fragment,f),E(Y9.$$.fragment,f),E(J8.$$.fragment,f),E(K9.$$.fragment,f),E(uM.$$.fragment,f),E(Z9.$$.fragment,f),E(ex.$$.fragment,f),E(rx.$$.fragment,f),E(vM.$$.fragment,f),E(tx.$$.fragment,f),E($M.$$.fragment,f),E(ax.$$.fragment,f),E(nx.$$.fragment,f),E(lx.$$.fragment,f),E(SM.$$.fragment,f),E(ix.$$.fragment,f),E(n4.$$.fragment,f),E(dx.$$.fragment,f),E(cx.$$.fragment,f),E(mx.$$.fragment,f),E(l4.$$.fragment,f),E(gx.$$.fragment,f),E(w4.$$.fragment,f),E(hx.$$.fragment,f),E(px.$$.fragment,f),E(ux.$$.fragment,f),E(L4.$$.fragment,f),E(bx.$$.fragment,f),E($4.$$.fragment,f),E(Fx.$$.fragment,f),E(Tx.$$.fragment,f),E(Ex.$$.fragment,f),E(S4.$$.fragment,f),E(Cx.$$.fragment,f),E(P4.$$.fragment,f),E(wx.$$.fragment,f),E(Ax.$$.fragment,f),E(yx.$$.fragment,f),E(I4.$$.fragment,f),E(xx.$$.fragment,f),E(tE.$$.fragment,f),E($x.$$.fragment,f),E(kx.$$.fragment,f),E(Rx.$$.fragment,f),E(nE.$$.fragment,f),E(Px.$$.fragment,f),E(AE.$$.fragment,f),E(Bx.$$.fragment,f),E(Ix.$$.fragment,f),E(qx.$$.fragment,f),E(yE.$$.fragment,f),E(jx.$$.fragment,f),E($E.$$.fragment,f),E(Dx.$$.fragment,f),E(Gx.$$.fragment,f),E(Vx.$$.fragment,f),E(SE.$$.fragment,f),E(Xx.$$.fragment,f),E(PE.$$.fragment,f),E(zx.$$.fragment,f),E(Wx.$$.fragment,f),E(Hx.$$.fragment,f),E(IE.$$.fragment,f),E(Ux.$$.fragment,f),E(cC.$$.fragment,f),E(Jx.$$.fragment,f),E(Yx.$$.fragment,f),E(Zx.$$.fragment,f),E(mC.$$.fragment,f),E(e$.$$.fragment,f),E(EC.$$.fragment,f),E(o$.$$.fragment,f),E(r$.$$.fragment,f),E(a$.$$.fragment,f),E(wC.$$.fragment,f),E(n$.$$.fragment,f),E(jC.$$.fragment,f),E(s$.$$.fragment,f),E(l$.$$.fragment,f),E(d$.$$.fragment,f),E(GC.$$.fragment,f),E(c$.$$.fragment,f),E(KC.$$.fragment,f),E(f$.$$.fragment,f),E(m$.$$.fragment,f),E(h$.$$.fragment,f),E(e3.$$.fragment,f),E(p$.$$.fragment,f),E(f3.$$.fragment,f),E(_$.$$.fragment,f),E(u$.$$.fragment,f),E(v$.$$.fragment,f),E(g3.$$.fragment,f),E(F$.$$.fragment,f),E(C3.$$.fragment,f),E(T$.$$.fragment,f),E(M$.$$.fragment,f),E(C$.$$.fragment,f),E(A3.$$.fragment,f),E(w$.$$.fragment,f),E(N3.$$.fragment,f),E(A$.$$.fragment,f),E(L$.$$.fragment,f),E(x$.$$.fragment,f),E(j3.$$.fragment,f),E($$.$$.fragment,f),E(H3.$$.fragment,f),E(k$.$$.fragment,f),E(S$.$$.fragment,f),E(P$.$$.fragment,f),E(J3.$$.fragment,f),E(B$.$$.fragment,f),E(n5.$$.fragment,f),E(I$.$$.fragment,f),E(N$.$$.fragment,f),E(j$.$$.fragment,f),E(l5.$$.fragment,f),E(D$.$$.fragment,f),E(d5.$$.fragment,f),E(G$.$$.fragment,f),E(O$.$$.fragment,f),E(X$.$$.fragment,f),E(f5.$$.fragment,f),E(z$.$$.fragment,f),E(h5.$$.fragment,f),E(Q$.$$.fragment,f),E(H$.$$.fragment,f),E(J$.$$.fragment,f),E(_5.$$.fragment,f),E(Y$.$$.fragment,f),E(b5.$$.fragment,f),zXe=!0)},o(f){C(d.$$.fragment,f),C(ka.$$.fragment,f),C(OA.$$.fragment,f),C(VA.$$.fragment,f),C(Nf.$$.fragment,f),C(XA.$$.fragment,f),C(zA.$$.fragment,f),C(HA.$$.fragment,f),C(Qg.$$.fragment,f),C(UA.$$.fragment,f),C(JA.$$.fragment,f),C(YA.$$.fragment,f),C(eL.$$.fragment,f),C(xh.$$.fragment,f),C(oL.$$.fragment,f),C(rL.$$.fragment,f),C(tL.$$.fragment,f),C(sL.$$.fragment,f),C(fp.$$.fragment,f),C(mp.$$.fragment,f),C(lL.$$.fragment,f),C(iL.$$.fragment,f),C(dL.$$.fragment,f),C(mL.$$.fragment,f),C(Rp.$$.fragment,f),C(Pp.$$.fragment,f),C(gL.$$.fragment,f),C(hL.$$.fragment,f),C(pL.$$.fragment,f),C(uL.$$.fragment,f),C(Np.$$.fragment,f),C(bL.$$.fragment,f),C(ju.$$.fragment,f),C(vL.$$.fragment,f),C(FL.$$.fragment,f),C(ML.$$.fragment,f),C(Gu.$$.fragment,f),C(EL.$$.fragment,f),C(R1.$$.fragment,f),C(CL.$$.fragment,f),C(wL.$$.fragment,f),C(LL.$$.fragment,f),C(B1.$$.fragment,f),C(yL.$$.fragment,f),C(M2.$$.fragment,f),C(xL.$$.fragment,f),C($L.$$.fragment,f),C(SL.$$.fragment,f),C(C2.$$.fragment,f),C(RL.$$.fragment,f),C(db.$$.fragment,f),C(PL.$$.fragment,f),C(BL.$$.fragment,f),C(NL.$$.fragment,f),C(fb.$$.fragment,f),C(qL.$$.fragment,f),C($b.$$.fragment,f),C(jL.$$.fragment,f),C(DL.$$.fragment,f),C(OL.$$.fragment,f),C(Sb.$$.fragment,f),C(VL.$$.fragment,f),C(xv.$$.fragment,f),C(XL.$$.fragment,f),C(zL.$$.fragment,f),C(QL.$$.fragment,f),C(kv.$$.fragment,f),C(HL.$$.fragment,f),C(d0.$$.fragment,f),C(UL.$$.fragment,f),C(JL.$$.fragment,f),C(KL.$$.fragment,f),C(f0.$$.fragment,f),C(ZL.$$.fragment,f),C(v0.$$.fragment,f),C(ey.$$.fragment,f),C(oy.$$.fragment,f),C(ty.$$.fragment,f),C(T0.$$.fragment,f),C(ay.$$.fragment,f),C(nF.$$.fragment,f),C(ny.$$.fragment,f),C(sy.$$.fragment,f),C(iy.$$.fragment,f),C(lF.$$.fragment,f),C(dy.$$.fragment,f),C(JF.$$.fragment,f),C(cy.$$.fragment,f),C(fy.$$.fragment,f),C(gy.$$.fragment,f),C(KF.$$.fragment,f),C(hy.$$.fragment,f),C(o6.$$.fragment,f),C(py.$$.fragment,f),C(_y.$$.fragment,f),C(by.$$.fragment,f),C(t6.$$.fragment,f),C(vy.$$.fragment,f),C(u6.$$.fragment,f),C(Fy.$$.fragment,f),C(Ty.$$.fragment,f),C(Ey.$$.fragment,f),C(v6.$$.fragment,f),C(Cy.$$.fragment,f),C(M6.$$.fragment,f),C(wy.$$.fragment,f),C(Ay.$$.fragment,f),C(yy.$$.fragment,f),C(C6.$$.fragment,f),C(xy.$$.fragment,f),C(L6.$$.fragment,f),C($y.$$.fragment,f),C(ky.$$.fragment,f),C(Ry.$$.fragment,f),C(x6.$$.fragment,f),C(Py.$$.fragment,f),C(D6.$$.fragment,f),C(By.$$.fragment,f),C(Iy.$$.fragment,f),C(qy.$$.fragment,f),C(O6.$$.fragment,f),C(jy.$$.fragment,f),C(U6.$$.fragment,f),C(Dy.$$.fragment,f),C(Gy.$$.fragment,f),C(Vy.$$.fragment,f),C(Y6.$$.fragment,f),C(Xy.$$.fragment,f),C(dT.$$.fragment,f),C(zy.$$.fragment,f),C(Wy.$$.fragment,f),C(Hy.$$.fragment,f),C(fT.$$.fragment,f),C(Uy.$$.fragment,f),C(pT.$$.fragment,f),C(Yy.$$.fragment,f),C(Ky.$$.fragment,f),C(e9.$$.fragment,f),C(uT.$$.fragment,f),C(o9.$$.fragment,f),C(CT.$$.fragment,f),C(r9.$$.fragment,f),C(t9.$$.fragment,f),C(n9.$$.fragment,f),C(AT.$$.fragment,f),C(s9.$$.fragment,f),C(kT.$$.fragment,f),C(l9.$$.fragment,f),C(i9.$$.fragment,f),C(c9.$$.fragment,f),C(RT.$$.fragment,f),C(f9.$$.fragment,f),C(NT.$$.fragment,f),C(g9.$$.fragment,f),C(h9.$$.fragment,f),C(_9.$$.fragment,f),C(jT.$$.fragment,f),C(u9.$$.fragment,f),C(OT.$$.fragment,f),C(b9.$$.fragment,f),C(v9.$$.fragment,f),C(T9.$$.fragment,f),C(XT.$$.fragment,f),C(M9.$$.fragment,f),C(JT.$$.fragment,f),C(E9.$$.fragment,f),C(C9.$$.fragment,f),C(A9.$$.fragment,f),C(KT.$$.fragment,f),C(L9.$$.fragment,f),C(o7.$$.fragment,f),C(y9.$$.fragment,f),C(x9.$$.fragment,f),C(k9.$$.fragment,f),C(t7.$$.fragment,f),C(S9.$$.fragment,f),C(K7.$$.fragment,f),C(R9.$$.fragment,f),C(P9.$$.fragment,f),C(I9.$$.fragment,f),C(e8.$$.fragment,f),C(N9.$$.fragment,f),C(C8.$$.fragment,f),C(q9.$$.fragment,f),C(j9.$$.fragment,f),C(G9.$$.fragment,f),C(A8.$$.fragment,f),C(O9.$$.fragment,f),C(D8.$$.fragment,f),C(V9.$$.fragment,f),C(X9.$$.fragment,f),C(W9.$$.fragment,f),C(O8.$$.fragment,f),C(Q9.$$.fragment,f),C(H8.$$.fragment,f),C(H9.$$.fragment,f),C(U9.$$.fragment,f),C(Y9.$$.fragment,f),C(J8.$$.fragment,f),C(K9.$$.fragment,f),C(uM.$$.fragment,f),C(Z9.$$.fragment,f),C(ex.$$.fragment,f),C(rx.$$.fragment,f),C(vM.$$.fragment,f),C(tx.$$.fragment,f),C($M.$$.fragment,f),C(ax.$$.fragment,f),C(nx.$$.fragment,f),C(lx.$$.fragment,f),C(SM.$$.fragment,f),C(ix.$$.fragment,f),C(n4.$$.fragment,f),C(dx.$$.fragment,f),C(cx.$$.fragment,f),C(mx.$$.fragment,f),C(l4.$$.fragment,f),C(gx.$$.fragment,f),C(w4.$$.fragment,f),C(hx.$$.fragment,f),C(px.$$.fragment,f),C(ux.$$.fragment,f),C(L4.$$.fragment,f),C(bx.$$.fragment,f),C($4.$$.fragment,f),C(Fx.$$.fragment,f),C(Tx.$$.fragment,f),C(Ex.$$.fragment,f),C(S4.$$.fragment,f),C(Cx.$$.fragment,f),C(P4.$$.fragment,f),C(wx.$$.fragment,f),C(Ax.$$.fragment,f),C(yx.$$.fragment,f),C(I4.$$.fragment,f),C(xx.$$.fragment,f),C(tE.$$.fragment,f),C($x.$$.fragment,f),C(kx.$$.fragment,f),C(Rx.$$.fragment,f),C(nE.$$.fragment,f),C(Px.$$.fragment,f),C(AE.$$.fragment,f),C(Bx.$$.fragment,f),C(Ix.$$.fragment,f),C(qx.$$.fragment,f),C(yE.$$.fragment,f),C(jx.$$.fragment,f),C($E.$$.fragment,f),C(Dx.$$.fragment,f),C(Gx.$$.fragment,f),C(Vx.$$.fragment,f),C(SE.$$.fragment,f),C(Xx.$$.fragment,f),C(PE.$$.fragment,f),C(zx.$$.fragment,f),C(Wx.$$.fragment,f),C(Hx.$$.fragment,f),C(IE.$$.fragment,f),C(Ux.$$.fragment,f),C(cC.$$.fragment,f),C(Jx.$$.fragment,f),C(Yx.$$.fragment,f),C(Zx.$$.fragment,f),C(mC.$$.fragment,f),C(e$.$$.fragment,f),C(EC.$$.fragment,f),C(o$.$$.fragment,f),C(r$.$$.fragment,f),C(a$.$$.fragment,f),C(wC.$$.fragment,f),C(n$.$$.fragment,f),C(jC.$$.fragment,f),C(s$.$$.fragment,f),C(l$.$$.fragment,f),C(d$.$$.fragment,f),C(GC.$$.fragment,f),C(c$.$$.fragment,f),C(KC.$$.fragment,f),C(f$.$$.fragment,f),C(m$.$$.fragment,f),C(h$.$$.fragment,f),C(e3.$$.fragment,f),C(p$.$$.fragment,f),C(f3.$$.fragment,f),C(_$.$$.fragment,f),C(u$.$$.fragment,f),C(v$.$$.fragment,f),C(g3.$$.fragment,f),C(F$.$$.fragment,f),C(C3.$$.fragment,f),C(T$.$$.fragment,f),C(M$.$$.fragment,f),C(C$.$$.fragment,f),C(A3.$$.fragment,f),C(w$.$$.fragment,f),C(N3.$$.fragment,f),C(A$.$$.fragment,f),C(L$.$$.fragment,f),C(x$.$$.fragment,f),C(j3.$$.fragment,f),C($$.$$.fragment,f),C(H3.$$.fragment,f),C(k$.$$.fragment,f),C(S$.$$.fragment,f),C(P$.$$.fragment,f),C(J3.$$.fragment,f),C(B$.$$.fragment,f),C(n5.$$.fragment,f),C(I$.$$.fragment,f),C(N$.$$.fragment,f),C(j$.$$.fragment,f),C(l5.$$.fragment,f),C(D$.$$.fragment,f),C(d5.$$.fragment,f),C(G$.$$.fragment,f),C(O$.$$.fragment,f),C(X$.$$.fragment,f),C(f5.$$.fragment,f),C(z$.$$.fragment,f),C(h5.$$.fragment,f),C(Q$.$$.fragment,f),C(H$.$$.fragment,f),C(J$.$$.fragment,f),C(_5.$$.fragment,f),C(Y$.$$.fragment,f),C(b5.$$.fragment,f),zXe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(Sf),f&&t(nt),f&&t(Oe),f&&t(We),f&&t(Pf),w(ka,f),f&&t(Qe),f&&t(Ae),f&&t(Co),f&&t(Sa),f&&t(DOe),f&&t(Si),w(OA),f&&t(GOe),f&&t(qn),f&&t(OOe),w(VA,f),f&&t(VOe),f&&t(ES),f&&t(XOe),w(Nf,f),f&&t(zOe),f&&t(Ri),w(XA),f&&t(WOe),f&&t(wo),w(zA),w(HA),w(Qg),w(UA),f&&t(QOe),f&&t(Bi),w(JA),f&&t(HOe),f&&t(Ao),w(YA),w(eL),w(xh),w(oL),f&&t(UOe),f&&t(Ii),w(rL),f&&t(JOe),f&&t(Lo),w(tL),w(sL),w(fp),w(mp),w(lL),f&&t(YOe),f&&t(Ni),w(iL),f&&t(KOe),f&&t(yo),w(dL),w(mL),w(Rp),w(Pp),w(gL),f&&t(ZOe),f&&t(ji),w(hL),f&&t(eVe),f&&t(xo),w(pL),w(uL),w(Np),w(bL),w(ju),f&&t(oVe),f&&t(Oi),w(vL),f&&t(rVe),f&&t($o),w(FL),w(ML),w(Gu),w(EL),w(R1),f&&t(tVe),f&&t(zi),w(CL),f&&t(aVe),f&&t(ko),w(wL),w(LL),w(B1),w(yL),w(M2),f&&t(nVe),f&&t(Hi),w(xL),f&&t(sVe),f&&t(So),w($L),w(SL),w(C2),w(RL),w(db),f&&t(lVe),f&&t(Yi),w(PL),f&&t(iVe),f&&t(Ro),w(BL),w(NL),w(fb),w(qL),w($b),f&&t(dVe),f&&t(ed),w(jL),f&&t(cVe),f&&t(Po),w(DL),w(OL),w(Sb),w(VL),w(xv),f&&t(fVe),f&&t(td),w(XL),f&&t(mVe),f&&t(Bo),w(zL),w(QL),w(kv),w(HL),w(d0),f&&t(gVe),f&&t(sd),w(UL),f&&t(hVe),f&&t(Io),w(JL),w(KL),w(f0),w(ZL),w(v0),f&&t(pVe),f&&t(dd),w(ey),f&&t(_Ve),f&&t(qo),w(oy),w(ty),w(T0),w(ay),w(nF),f&&t(uVe),f&&t(md),w(ny),f&&t(bVe),f&&t(jo),w(sy),w(iy),w(lF),w(dy),w(JF),f&&t(vVe),f&&t(pd),w(cy),f&&t(FVe),f&&t(Do),w(fy),w(gy),w(KF),w(hy),w(o6),f&&t(TVe),f&&t(bd),w(py),f&&t(MVe),f&&t(Go),w(_y),w(by),w(t6),w(vy),w(u6),f&&t(EVe),f&&t(Td),w(Fy),f&&t(CVe),f&&t(Oo),w(Ty),w(Ey),w(v6),w(Cy),w(M6),f&&t(wVe),f&&t(Cd),w(wy),f&&t(AVe),f&&t(Vo),w(Ay),w(yy),w(C6),w(xy),w(L6),f&&t(LVe),f&&t(Ld),w($y),f&&t(yVe),f&&t(Xo),w(ky),w(Ry),w(x6),w(Py),w(D6),f&&t(xVe),f&&t($d),w(By),f&&t($Ve),f&&t(zo),w(Iy),w(qy),w(O6),w(jy),w(U6),f&&t(kVe),f&&t(Rd),w(Dy),f&&t(SVe),f&&t(Wo),w(Gy),w(Vy),w(Y6),w(Xy),w(dT),f&&t(RVe),f&&t(Id),w(zy),f&&t(PVe),f&&t(Qo),w(Wy),w(Hy),w(fT),w(Uy),w(pT),f&&t(BVe),f&&t(jd),w(Yy),f&&t(IVe),f&&t(Ho),w(Ky),w(e9),w(uT),w(o9),w(CT),f&&t(NVe),f&&t(Od),w(r9),f&&t(qVe),f&&t(Uo),w(t9),w(n9),w(AT),w(s9),w(kT),f&&t(jVe),f&&t(Wd),w(l9),f&&t(DVe),f&&t(Jo),w(i9),w(c9),w(RT),w(f9),w(NT),f&&t(GVe),f&&t(Ud),w(g9),f&&t(OVe),f&&t(Yo),w(h9),w(_9),w(jT),w(u9),w(OT),f&&t(VVe),f&&t(Kd),w(b9),f&&t(XVe),f&&t(Ko),w(v9),w(T9),w(XT),w(M9),w(JT),f&&t(zVe),f&&t(oc),w(E9),f&&t(WVe),f&&t(Zo),w(C9),w(A9),w(KT),w(L9),w(o7),f&&t(QVe),f&&t(ac),w(y9),f&&t(HVe),f&&t(er),w(x9),w(k9),w(t7),w(S9),w(K7),f&&t(UVe),f&&t(lc),w(R9),f&&t(JVe),f&&t(or),w(P9),w(I9),w(e8),w(N9),w(C8),f&&t(YVe),f&&t(cc),w(q9),f&&t(KVe),f&&t(rr),w(j9),w(G9),w(A8),w(O9),w(D8),f&&t(ZVe),f&&t(gc),w(V9),f&&t(eXe),f&&t(tr),w(X9),w(W9),w(O8),w(Q9),w(H8),f&&t(oXe),f&&t(_c),w(H9),f&&t(rXe),f&&t(nr),w(U9),w(Y9),w(J8),w(K9),w(uM),f&&t(tXe),f&&t(vc),w(Z9),f&&t(aXe),f&&t(sr),w(ex),w(rx),w(vM),w(tx),w($M),f&&t(nXe),f&&t(Mc),w(ax),f&&t(sXe),f&&t(lr),w(nx),w(lx),w(SM),w(ix),w(n4),f&&t(lXe),f&&t(wc),w(dx),f&&t(iXe),f&&t(ir),w(cx),w(mx),w(l4),w(gx),w(w4),f&&t(dXe),f&&t(yc),w(hx),f&&t(cXe),f&&t(dr),w(px),w(ux),w(L4),w(bx),w($4),f&&t(fXe),f&&t(kc),w(Fx),f&&t(mXe),f&&t(cr),w(Tx),w(Ex),w(S4),w(Cx),w(P4),f&&t(gXe),f&&t(Pc),w(wx),f&&t(hXe),f&&t(fr),w(Ax),w(yx),w(I4),w(xx),w(tE),f&&t(pXe),f&&t(Nc),w($x),f&&t(_Xe),f&&t(mr),w(kx),w(Rx),w(nE),w(Px),w(AE),f&&t(uXe),f&&t(Dc),w(Bx),f&&t(bXe),f&&t(gr),w(Ix),w(qx),w(yE),w(jx),w($E),f&&t(vXe),f&&t(Vc),w(Dx),f&&t(FXe),f&&t(hr),w(Gx),w(Vx),w(SE),w(Xx),w(PE),f&&t(TXe),f&&t(Wc),w(zx),f&&t(MXe),f&&t(pr),w(Wx),w(Hx),w(IE),w(Ux),w(cC),f&&t(EXe),f&&t(Uc),w(Jx),f&&t(CXe),f&&t(_r),w(Yx),w(Zx),w(mC),w(e$),w(EC),f&&t(wXe),f&&t(Kc),w(o$),f&&t(AXe),f&&t(ur),w(r$),w(a$),w(wC),w(n$),w(jC),f&&t(LXe),f&&t(of),w(s$),f&&t(yXe),f&&t(br),w(l$),w(d$),w(GC),w(c$),w(KC),f&&t(xXe),f&&t(af),w(f$),f&&t($Xe),f&&t(vr),w(m$),w(h$),w(e3),w(p$),w(f3),f&&t(kXe),f&&t(lf),w(_$),f&&t(SXe),f&&t(Fr),w(u$),w(v$),w(g3),w(F$),w(C3),f&&t(RXe),f&&t(ff),w(T$),f&&t(PXe),f&&t(Tr),w(M$),w(C$),w(A3),w(w$),w(N3),f&&t(BXe),f&&t(hf),w(A$),f&&t(IXe),f&&t(Mr),w(L$),w(x$),w(j3),w($$),w(H3),f&&t(NXe),f&&t(uf),w(k$),f&&t(qXe),f&&t(Er),w(S$),w(P$),w(J3),w(B$),w(n5),f&&t(jXe),f&&t(Ff),w(I$),f&&t(DXe),f&&t(Cr),w(N$),w(j$),w(l5),w(D$),w(d5),f&&t(GXe),f&&t(Ef),w(G$),f&&t(OXe),f&&t(wr),w(O$),w(X$),w(f5),w(z$),w(h5),f&&t(VXe),f&&t(Af),w(Q$),f&&t(XXe),f&&t(Ar),w(H$),w(J$),w(_5),w(Y$),w(b5)}}}const uzt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function bzt($){return _Vt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class wzt extends mVt{constructor(g){super();gVt(this,g,bzt,_zt,hVt,{})}}export{wzt as default,uzt as metadata};
