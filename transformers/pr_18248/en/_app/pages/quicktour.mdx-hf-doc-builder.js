import{S as Of,i as Df,s as Hf,e as l,k as h,w as b,t as o,M as Lf,c as i,d as s,m as d,a as p,x as A,h as n,b as $,G as t,g as u,y as E,q as T,o as j,B as x,v as Wf,L as ge}from"../chunks/vendor-hf-doc-builder.js";import{T as Ks}from"../chunks/Tip-hf-doc-builder.js";import{Y as Nf}from"../chunks/Youtube-hf-doc-builder.js";import{I as Me}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as L}from"../chunks/CodeBlock-hf-doc-builder.js";import{D as Uf}from"../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as rs,M as ce}from"../chunks/Markdown-hf-doc-builder.js";function Rf(P){let a,m;return{c(){a=l("p"),m=o(`All code examples presented in the documentation have a toggle on the top left for PyTorch and TensorFlow. If
not, the code is expected to work for both backends without any change.`)},l(r){a=i(r,"P",{});var c=p(a);m=n(c,`All code examples presented in the documentation have a toggle on the top left for PyTorch and TensorFlow. If
not, the code is expected to work for both backends without any change.`),c.forEach(s)},m(r,c){u(r,a,c),t(a,m)},d(r){r&&s(a)}}}function Gf(P){let a,m,r,c,_,w,k,F;return{c(){a=l("p"),m=o("For more details about the "),r=l("a"),c=o("pipeline()"),_=o(" and associated tasks, refer to the documentation "),w=l("a"),k=o("here"),F=o("."),this.h()},l(g){a=i(g,"P",{});var y=p(a);m=n(y,"For more details about the "),r=i(y,"A",{href:!0});var I=p(r);c=n(I,"pipeline()"),I.forEach(s),_=n(y," and associated tasks, refer to the documentation "),w=i(y,"A",{href:!0});var N=p(w);k=n(N,"here"),N.forEach(s),F=n(y,"."),y.forEach(s),this.h()},h(){$(r,"href","/docs/transformers/pr_18248/en/main_classes/pipelines#transformers.pipeline"),$(w,"href","./main_classes/pipelines")},m(g,y){u(g,a,y),t(a,m),t(a,r),t(r,c),t(a,_),t(a,w),t(w,k),t(a,F)},d(g){g&&s(a)}}}function Yf(P){let a,m;return a=new L({props:{code:"pip install torch",highlighted:"pip install torch"}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p:ge,i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function Jf(P){let a,m;return a=new ce({props:{$$slots:{default:[Yf]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function Qf(P){let a,m;return a=new L({props:{code:"pip install tensorflow",highlighted:"pip install tensorflow"}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p:ge,i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function Vf(P){let a,m;return a=new ce({props:{$$slots:{default:[Qf]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function Bf(P){let a,m,r,c,_,w,k,F,g,y,I,N,D,W;return D=new L({props:{code:`from transformers import AutoTokenizer, AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),{c(){a=l("p"),m=o("Use the "),r=l("a"),c=o("AutoModelForSequenceClassification"),_=o(" and "),w=l("a"),k=o("AutoTokenizer"),F=o(" to load the pretrained model and it\u2019s associated tokenizer (more on an "),g=l("code"),y=o("AutoClass"),I=o(" below):"),N=h(),b(D.$$.fragment),this.h()},l(z){a=i(z,"P",{});var C=p(a);m=n(C,"Use the "),r=i(C,"A",{href:!0});var v=p(r);c=n(v,"AutoModelForSequenceClassification"),v.forEach(s),_=n(C," and "),w=i(C,"A",{href:!0});var S=p(w);k=n(S,"AutoTokenizer"),S.forEach(s),F=n(C," to load the pretrained model and it\u2019s associated tokenizer (more on an "),g=i(C,"CODE",{});var R=p(g);y=n(R,"AutoClass"),R.forEach(s),I=n(C," below):"),C.forEach(s),N=d(z),A(D.$$.fragment,z),this.h()},h(){$(r,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.AutoModelForSequenceClassification"),$(w,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.AutoTokenizer")},m(z,C){u(z,a,C),t(a,m),t(a,r),t(r,c),t(a,_),t(a,w),t(w,k),t(a,F),t(a,g),t(g,y),t(a,I),u(z,N,C),E(D,z,C),W=!0},p:ge,i(z){W||(T(D.$$.fragment,z),W=!0)},o(z){j(D.$$.fragment,z),W=!1},d(z){z&&s(a),z&&s(N),x(D,z)}}}function Kf(P){let a,m;return a=new ce({props:{$$slots:{default:[Bf]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function Zf(P){let a,m,r,c,_,w,k,F,g,y,I,N,D,W;return D=new L({props:{code:`from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),{c(){a=l("p"),m=o("Use the "),r=l("a"),c=o("TFAutoModelForSequenceClassification"),_=o(" and "),w=l("a"),k=o("AutoTokenizer"),F=o(" to load the pretrained model and it\u2019s associated tokenizer (more on an "),g=l("code"),y=o("TFAutoClass"),I=o(" below):"),N=h(),b(D.$$.fragment),this.h()},l(z){a=i(z,"P",{});var C=p(a);m=n(C,"Use the "),r=i(C,"A",{href:!0});var v=p(r);c=n(v,"TFAutoModelForSequenceClassification"),v.forEach(s),_=n(C," and "),w=i(C,"A",{href:!0});var S=p(w);k=n(S,"AutoTokenizer"),S.forEach(s),F=n(C," to load the pretrained model and it\u2019s associated tokenizer (more on an "),g=i(C,"CODE",{});var R=p(g);y=n(R,"TFAutoClass"),R.forEach(s),I=n(C," below):"),C.forEach(s),N=d(z),A(D.$$.fragment,z),this.h()},h(){$(r,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.TFAutoModelForSequenceClassification"),$(w,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.AutoTokenizer")},m(z,C){u(z,a,C),t(a,m),t(a,r),t(r,c),t(a,_),t(a,w),t(w,k),t(a,F),t(a,g),t(g,y),t(a,I),u(z,N,C),E(D,z,C),W=!0},p:ge,i(z){W||(T(D.$$.fragment,z),W=!0)},o(z){j(D.$$.fragment,z),W=!1},d(z){z&&s(a),z&&s(N),x(D,z)}}}function Xf(P){let a,m;return a=new ce({props:{$$slots:{default:[Zf]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function eu(P){let a,m;return a=new L({props:{code:`pt_batch = tokenizer(
    ["We are very happy to show you the \u{1F917} Transformers library.", "We hope you don't hate it."],
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="pt",
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;pt&quot;</span>,
<span class="hljs-meta">... </span>)`}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p:ge,i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function tu(P){let a,m;return a=new ce({props:{$$slots:{default:[eu]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function su(P){let a,m;return a=new L({props:{code:`tf_batch = tokenizer(
    ["We are very happy to show you the \u{1F917} Transformers library.", "We hope you don't hate it."],
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="tf",
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;tf&quot;</span>,
<span class="hljs-meta">... </span>)`}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p:ge,i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function au(P){let a,m;return a=new ce({props:{$$slots:{default:[su]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function ru(P){let a,m,r,c,_,w,k,F;return{c(){a=l("p"),m=o("See the "),r=l("a"),c=o("task summary"),_=o(" for which "),w=l("a"),k=o("AutoModel"),F=o(" class to use for which task."),this.h()},l(g){a=i(g,"P",{});var y=p(a);m=n(y,"See the "),r=i(y,"A",{href:!0});var I=p(r);c=n(I,"task summary"),I.forEach(s),_=n(y," for which "),w=i(y,"A",{href:!0});var N=p(w);k=n(N,"AutoModel"),N.forEach(s),F=n(y," class to use for which task."),y.forEach(s),this.h()},h(){$(r,"href","./task_summary"),$(w,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.AutoModel")},m(g,y){u(g,a,y),t(a,m),t(a,r),t(r,c),t(a,_),t(a,w),t(w,k),t(a,F)},d(g){g&&s(a)}}}function ou(P){let a,m,r,c,_,w,k,F,g,y,I,N,D,W,z,C,v,S,R,U,Q,J,se,V,G,ee,B,K,he,re,$e,oe,te,ne,_e,M,O,le;return C=new L({props:{code:`from transformers import AutoModelForSequenceClassification

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`}}),S=new Ks({props:{$$slots:{default:[ru]},$$scope:{ctx:P}}}),ee=new L({props:{code:"pt_outputs = pt_model(**pt_batch)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_outputs = pt_model(**pt_batch)'}}),O=new L({props:{code:`from torch import nn

pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)
print(pt_predictions)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn

<span class="hljs-meta">&gt;&gt;&gt; </span>pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(pt_predictions)
tensor([[<span class="hljs-number">0.0021</span>, <span class="hljs-number">0.0018</span>, <span class="hljs-number">0.0115</span>, <span class="hljs-number">0.2121</span>, <span class="hljs-number">0.7725</span>],
        [<span class="hljs-number">0.2084</span>, <span class="hljs-number">0.1826</span>, <span class="hljs-number">0.1969</span>, <span class="hljs-number">0.1755</span>, <span class="hljs-number">0.2365</span>]], grad_fn=&lt;SoftmaxBackward0&gt;)`}}),{c(){a=l("p"),m=o("\u{1F917} Transformers provides a simple and unified way to load pretrained instances. This means you can load an "),r=l("a"),c=o("AutoModel"),_=o(" like you would load an "),w=l("a"),k=o("AutoTokenizer"),F=o(". The only difference is selecting the correct "),g=l("a"),y=o("AutoModel"),I=o(" for the task. Since you are doing text - or sequence - classification, load "),N=l("a"),D=o("AutoModelForSequenceClassification"),W=o(":"),z=h(),b(C.$$.fragment),v=h(),b(S.$$.fragment),R=h(),U=l("p"),Q=o("Now you can pass your preprocessed batch of inputs directly to the model. You just have to unpack the dictionary by adding "),J=l("code"),se=o("**"),V=o(":"),G=h(),b(ee.$$.fragment),B=h(),K=l("p"),he=o("The model outputs the final activations in the "),re=l("code"),$e=o("logits"),oe=o(" attribute. Apply the softmax function to the "),te=l("code"),ne=o("logits"),_e=o(" to retrieve the probabilities:"),M=h(),b(O.$$.fragment),this.h()},l(q){a=i(q,"P",{});var H=p(a);m=n(H,"\u{1F917} Transformers provides a simple and unified way to load pretrained instances. This means you can load an "),r=i(H,"A",{href:!0});var ie=p(r);c=n(ie,"AutoModel"),ie.forEach(s),_=n(H," like you would load an "),w=i(H,"A",{href:!0});var Fe=p(w);k=n(Fe,"AutoTokenizer"),Fe.forEach(s),F=n(H,". The only difference is selecting the correct "),g=i(H,"A",{href:!0});var de=p(g);y=n(de,"AutoModel"),de.forEach(s),I=n(H," for the task. Since you are doing text - or sequence - classification, load "),N=i(H,"A",{href:!0});var we=p(N);D=n(we,"AutoModelForSequenceClassification"),we.forEach(s),W=n(H,":"),H.forEach(s),z=d(q),A(C.$$.fragment,q),v=d(q),A(S.$$.fragment,q),R=d(q),U=i(q,"P",{});var pe=p(U);Q=n(pe,"Now you can pass your preprocessed batch of inputs directly to the model. You just have to unpack the dictionary by adding "),J=i(pe,"CODE",{});var Ue=p(J);se=n(Ue,"**"),Ue.forEach(s),V=n(pe,":"),pe.forEach(s),G=d(q),A(ee.$$.fragment,q),B=d(q),K=i(q,"P",{});var ve=p(K);he=n(ve,"The model outputs the final activations in the "),re=i(ve,"CODE",{});var os=p(re);$e=n(os,"logits"),os.forEach(s),oe=n(ve," attribute. Apply the softmax function to the "),te=i(ve,"CODE",{});var yt=p(te);ne=n(yt,"logits"),yt.forEach(s),_e=n(ve," to retrieve the probabilities:"),ve.forEach(s),M=d(q),A(O.$$.fragment,q),this.h()},h(){$(r,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.AutoModel"),$(w,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.AutoTokenizer"),$(g,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.AutoModel"),$(N,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.AutoModelForSequenceClassification")},m(q,H){u(q,a,H),t(a,m),t(a,r),t(r,c),t(a,_),t(a,w),t(w,k),t(a,F),t(a,g),t(g,y),t(a,I),t(a,N),t(N,D),t(a,W),u(q,z,H),E(C,q,H),u(q,v,H),E(S,q,H),u(q,R,H),u(q,U,H),t(U,Q),t(U,J),t(J,se),t(U,V),u(q,G,H),E(ee,q,H),u(q,B,H),u(q,K,H),t(K,he),t(K,re),t(re,$e),t(K,oe),t(K,te),t(te,ne),t(K,_e),u(q,M,H),E(O,q,H),le=!0},p(q,H){const ie={};H&2&&(ie.$$scope={dirty:H,ctx:q}),S.$set(ie)},i(q){le||(T(C.$$.fragment,q),T(S.$$.fragment,q),T(ee.$$.fragment,q),T(O.$$.fragment,q),le=!0)},o(q){j(C.$$.fragment,q),j(S.$$.fragment,q),j(ee.$$.fragment,q),j(O.$$.fragment,q),le=!1},d(q){q&&s(a),q&&s(z),x(C,q),q&&s(v),x(S,q),q&&s(R),q&&s(U),q&&s(G),x(ee,q),q&&s(B),q&&s(K),q&&s(M),x(O,q)}}}function nu(P){let a,m;return a=new ce({props:{$$slots:{default:[ou]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function lu(P){let a,m,r,c,_,w,k,F;return{c(){a=l("p"),m=o("See the "),r=l("a"),c=o("task summary"),_=o(" for which "),w=l("a"),k=o("AutoModel"),F=o(" class to use for which task."),this.h()},l(g){a=i(g,"P",{});var y=p(a);m=n(y,"See the "),r=i(y,"A",{href:!0});var I=p(r);c=n(I,"task summary"),I.forEach(s),_=n(y," for which "),w=i(y,"A",{href:!0});var N=p(w);k=n(N,"AutoModel"),N.forEach(s),F=n(y," class to use for which task."),y.forEach(s),this.h()},h(){$(r,"href","./task_summary"),$(w,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.AutoModel")},m(g,y){u(g,a,y),t(a,m),t(a,r),t(r,c),t(a,_),t(a,w),t(w,k),t(a,F)},d(g){g&&s(a)}}}function iu(P){let a,m,r,c,_,w,k,F,g,y,I,N,D,W,z,C,v,S,R,U,Q,J,se,V,G,ee,B,K,he,re,$e,oe,te,ne,_e;return C=new L({props:{code:`from transformers import TFAutoModelForSequenceClassification

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)`}}),S=new Ks({props:{$$slots:{default:[lu]},$$scope:{ctx:P}}}),se=new L({props:{code:"tf_outputs = tf_model(tf_batch)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_outputs = tf_model(tf_batch)'}}),ne=new L({props:{code:`import tensorflow as tf

tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-1)
tf_predictions`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions`}}),{c(){a=l("p"),m=o("\u{1F917} Transformers provides a simple and unified way to load pretrained instances. This means you can load an "),r=l("a"),c=o("TFAutoModel"),_=o(" like you would load an "),w=l("a"),k=o("AutoTokenizer"),F=o(". The only difference is selecting the correct "),g=l("a"),y=o("TFAutoModel"),I=o(" for the task. Since you are doing text - or sequence - classification, load "),N=l("a"),D=o("TFAutoModelForSequenceClassification"),W=o(":"),z=h(),b(C.$$.fragment),v=h(),b(S.$$.fragment),R=h(),U=l("p"),Q=o("Now you can pass your preprocessed batch of inputs directly to the model by passing the dictionary keys directly to the tensors:"),J=h(),b(se.$$.fragment),V=h(),G=l("p"),ee=o("The model outputs the final activations in the "),B=l("code"),K=o("logits"),he=o(" attribute. Apply the softmax function to the "),re=l("code"),$e=o("logits"),oe=o(" to retrieve the probabilities:"),te=h(),b(ne.$$.fragment),this.h()},l(M){a=i(M,"P",{});var O=p(a);m=n(O,"\u{1F917} Transformers provides a simple and unified way to load pretrained instances. This means you can load an "),r=i(O,"A",{href:!0});var le=p(r);c=n(le,"TFAutoModel"),le.forEach(s),_=n(O," like you would load an "),w=i(O,"A",{href:!0});var q=p(w);k=n(q,"AutoTokenizer"),q.forEach(s),F=n(O,". The only difference is selecting the correct "),g=i(O,"A",{href:!0});var H=p(g);y=n(H,"TFAutoModel"),H.forEach(s),I=n(O," for the task. Since you are doing text - or sequence - classification, load "),N=i(O,"A",{href:!0});var ie=p(N);D=n(ie,"TFAutoModelForSequenceClassification"),ie.forEach(s),W=n(O,":"),O.forEach(s),z=d(M),A(C.$$.fragment,M),v=d(M),A(S.$$.fragment,M),R=d(M),U=i(M,"P",{});var Fe=p(U);Q=n(Fe,"Now you can pass your preprocessed batch of inputs directly to the model by passing the dictionary keys directly to the tensors:"),Fe.forEach(s),J=d(M),A(se.$$.fragment,M),V=d(M),G=i(M,"P",{});var de=p(G);ee=n(de,"The model outputs the final activations in the "),B=i(de,"CODE",{});var we=p(B);K=n(we,"logits"),we.forEach(s),he=n(de," attribute. Apply the softmax function to the "),re=i(de,"CODE",{});var pe=p(re);$e=n(pe,"logits"),pe.forEach(s),oe=n(de," to retrieve the probabilities:"),de.forEach(s),te=d(M),A(ne.$$.fragment,M),this.h()},h(){$(r,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.TFAutoModel"),$(w,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.AutoTokenizer"),$(g,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.TFAutoModel"),$(N,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.TFAutoModelForSequenceClassification")},m(M,O){u(M,a,O),t(a,m),t(a,r),t(r,c),t(a,_),t(a,w),t(w,k),t(a,F),t(a,g),t(g,y),t(a,I),t(a,N),t(N,D),t(a,W),u(M,z,O),E(C,M,O),u(M,v,O),E(S,M,O),u(M,R,O),u(M,U,O),t(U,Q),u(M,J,O),E(se,M,O),u(M,V,O),u(M,G,O),t(G,ee),t(G,B),t(B,K),t(G,he),t(G,re),t(re,$e),t(G,oe),u(M,te,O),E(ne,M,O),_e=!0},p(M,O){const le={};O&2&&(le.$$scope={dirty:O,ctx:M}),S.$set(le)},i(M){_e||(T(C.$$.fragment,M),T(S.$$.fragment,M),T(se.$$.fragment,M),T(ne.$$.fragment,M),_e=!0)},o(M){j(C.$$.fragment,M),j(S.$$.fragment,M),j(se.$$.fragment,M),j(ne.$$.fragment,M),_e=!1},d(M){M&&s(a),M&&s(z),x(C,M),M&&s(v),x(S,M),M&&s(R),M&&s(U),M&&s(J),x(se,M),M&&s(V),M&&s(G),M&&s(te),x(ne,M)}}}function pu(P){let a,m;return a=new ce({props:{$$slots:{default:[iu]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function fu(P){let a,m,r,c,_;return{c(){a=l("p"),m=o("All \u{1F917} Transformers models (PyTorch or TensorFlow) outputs the tensors "),r=l("em"),c=o("before"),_=o(` the final activation
function (like softmax) because the final activation function is often fused with the loss.`)},l(w){a=i(w,"P",{});var k=p(a);m=n(k,"All \u{1F917} Transformers models (PyTorch or TensorFlow) outputs the tensors "),r=i(k,"EM",{});var F=p(r);c=n(F,"before"),F.forEach(s),_=n(k,` the final activation
function (like softmax) because the final activation function is often fused with the loss.`),k.forEach(s)},m(w,k){u(w,a,k),t(a,m),t(a,r),t(r,c),t(a,_)},d(w){w&&s(a)}}}function uu(P){let a,m,r,c,_;return{c(){a=l("p"),m=o(`\u{1F917} Transformers model outputs are special dataclasses so their attributes are autocompleted in an IDE.
The model outputs also behave like a tuple or a dictionary (e.g., you can index with an integer, a slice or a string) in which case the attributes that are `),r=l("code"),c=o("None"),_=o(" are ignored.")},l(w){a=i(w,"P",{});var k=p(a);m=n(k,`\u{1F917} Transformers model outputs are special dataclasses so their attributes are autocompleted in an IDE.
The model outputs also behave like a tuple or a dictionary (e.g., you can index with an integer, a slice or a string) in which case the attributes that are `),r=i(k,"CODE",{});var F=p(r);c=n(F,"None"),F.forEach(s),_=n(k," are ignored."),k.forEach(s)},m(w,k){u(w,a,k),t(a,m),t(a,r),t(r,c),t(a,_)},d(w){w&&s(a)}}}function mu(P){let a,m,r,c,_,w,k,F,g,y,I,N,D,W,z,C;return k=new L({props:{code:`pt_save_directory = "./pt_save_pretrained"
tokenizer.save_pretrained(pt_save_directory)
pt_model.save_pretrained(pt_save_directory)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_save_directory = <span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.save_pretrained(pt_save_directory)`}}),z=new L({props:{code:'pt_model = AutoModelForSequenceClassification.from_pretrained("./pt_save_pretrained")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>)'}}),{c(){a=l("p"),m=o("Once your model is fine-tuned, you can save it with its tokenizer using "),r=l("a"),c=o("PreTrainedModel.save_pretrained()"),_=o(":"),w=h(),b(k.$$.fragment),F=h(),g=l("p"),y=o("When you are ready to use the model again, reload it with "),I=l("a"),N=o("PreTrainedModel.from_pretrained()"),D=o(":"),W=h(),b(z.$$.fragment),this.h()},l(v){a=i(v,"P",{});var S=p(a);m=n(S,"Once your model is fine-tuned, you can save it with its tokenizer using "),r=i(S,"A",{href:!0});var R=p(r);c=n(R,"PreTrainedModel.save_pretrained()"),R.forEach(s),_=n(S,":"),S.forEach(s),w=d(v),A(k.$$.fragment,v),F=d(v),g=i(v,"P",{});var U=p(g);y=n(U,"When you are ready to use the model again, reload it with "),I=i(U,"A",{href:!0});var Q=p(I);N=n(Q,"PreTrainedModel.from_pretrained()"),Q.forEach(s),D=n(U,":"),U.forEach(s),W=d(v),A(z.$$.fragment,v),this.h()},h(){$(r,"href","/docs/transformers/pr_18248/en/main_classes/model#transformers.PreTrainedModel.save_pretrained"),$(I,"href","/docs/transformers/pr_18248/en/main_classes/model#transformers.PreTrainedModel.from_pretrained")},m(v,S){u(v,a,S),t(a,m),t(a,r),t(r,c),t(a,_),u(v,w,S),E(k,v,S),u(v,F,S),u(v,g,S),t(g,y),t(g,I),t(I,N),t(g,D),u(v,W,S),E(z,v,S),C=!0},p:ge,i(v){C||(T(k.$$.fragment,v),T(z.$$.fragment,v),C=!0)},o(v){j(k.$$.fragment,v),j(z.$$.fragment,v),C=!1},d(v){v&&s(a),v&&s(w),x(k,v),v&&s(F),v&&s(g),v&&s(W),x(z,v)}}}function cu(P){let a,m;return a=new ce({props:{$$slots:{default:[mu]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function hu(P){let a,m,r,c,_,w,k,F,g,y,I,N,D,W,z,C;return k=new L({props:{code:`tf_save_directory = "./tf_save_pretrained"
tokenizer.save_pretrained(tf_save_directory)
tf_model.save_pretrained(tf_save_directory)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_save_directory = <span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.save_pretrained(tf_save_directory)`}}),z=new L({props:{code:'tf_model = TFAutoModelForSequenceClassification.from_pretrained("./tf_save_pretrained")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>)'}}),{c(){a=l("p"),m=o("Once your model is fine-tuned, you can save it with its tokenizer using "),r=l("a"),c=o("TFPreTrainedModel.save_pretrained()"),_=o(":"),w=h(),b(k.$$.fragment),F=h(),g=l("p"),y=o("When you are ready to use the model again, reload it with "),I=l("a"),N=o("TFPreTrainedModel.from_pretrained()"),D=o(":"),W=h(),b(z.$$.fragment),this.h()},l(v){a=i(v,"P",{});var S=p(a);m=n(S,"Once your model is fine-tuned, you can save it with its tokenizer using "),r=i(S,"A",{href:!0});var R=p(r);c=n(R,"TFPreTrainedModel.save_pretrained()"),R.forEach(s),_=n(S,":"),S.forEach(s),w=d(v),A(k.$$.fragment,v),F=d(v),g=i(v,"P",{});var U=p(g);y=n(U,"When you are ready to use the model again, reload it with "),I=i(U,"A",{href:!0});var Q=p(I);N=n(Q,"TFPreTrainedModel.from_pretrained()"),Q.forEach(s),D=n(U,":"),U.forEach(s),W=d(v),A(z.$$.fragment,v),this.h()},h(){$(r,"href","/docs/transformers/pr_18248/en/main_classes/model#transformers.TFPreTrainedModel.save_pretrained"),$(I,"href","/docs/transformers/pr_18248/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained")},m(v,S){u(v,a,S),t(a,m),t(a,r),t(r,c),t(a,_),u(v,w,S),E(k,v,S),u(v,F,S),u(v,g,S),t(g,y),t(g,I),t(I,N),t(g,D),u(v,W,S),E(z,v,S),C=!0},p:ge,i(v){C||(T(k.$$.fragment,v),T(z.$$.fragment,v),C=!0)},o(v){j(k.$$.fragment,v),j(z.$$.fragment,v),C=!1},d(v){v&&s(a),v&&s(w),x(k,v),v&&s(F),v&&s(g),v&&s(W),x(z,v)}}}function du(P){let a,m;return a=new ce({props:{$$slots:{default:[hu]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function $u(P){let a,m;return a=new L({props:{code:`from transformers import AutoModel

tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=<span class="hljs-literal">True</span>)`}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p:ge,i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function _u(P){let a,m;return a=new ce({props:{$$slots:{default:[$u]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function gu(P){let a,m;return a=new L({props:{code:`from transformers import TFAutoModel

tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=<span class="hljs-literal">True</span>)`}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p:ge,i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function wu(P){let a,m;return a=new ce({props:{$$slots:{default:[gu]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function vu(P){let a,m,r,c,_,w,k,F;return k=new L({props:{code:`from transformers import AutoModel

my_model = AutoModel.from_config(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_model = AutoModel.from_config(my_config)`}}),{c(){a=l("p"),m=o("Create a model from your custom configuration with "),r=l("a"),c=o("AutoModel.from_config()"),_=o(":"),w=h(),b(k.$$.fragment),this.h()},l(g){a=i(g,"P",{});var y=p(a);m=n(y,"Create a model from your custom configuration with "),r=i(y,"A",{href:!0});var I=p(r);c=n(I,"AutoModel.from_config()"),I.forEach(s),_=n(y,":"),y.forEach(s),w=d(g),A(k.$$.fragment,g),this.h()},h(){$(r,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config")},m(g,y){u(g,a,y),t(a,m),t(a,r),t(r,c),t(a,_),u(g,w,y),E(k,g,y),F=!0},p:ge,i(g){F||(T(k.$$.fragment,g),F=!0)},o(g){j(k.$$.fragment,g),F=!1},d(g){g&&s(a),g&&s(w),x(k,g)}}}function ku(P){let a,m;return a=new ce({props:{$$slots:{default:[vu]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function yu(P){let a,m,r,c,_,w,k,F;return k=new L({props:{code:`from transformers import TFAutoModel

my_model = TFAutoModel.from_config(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_model = TFAutoModel.from_config(my_config)`}}),{c(){a=l("p"),m=o("Create a model from your custom configuration with "),r=l("a"),c=o("TFAutoModel.from_config()"),_=o(":"),w=h(),b(k.$$.fragment),this.h()},l(g){a=i(g,"P",{});var y=p(a);m=n(y,"Create a model from your custom configuration with "),r=i(y,"A",{href:!0});var I=p(r);c=n(I,"TFAutoModel.from_config()"),I.forEach(s),_=n(y,":"),y.forEach(s),w=d(g),A(k.$$.fragment,g),this.h()},h(){$(r,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config")},m(g,y){u(g,a,y),t(a,m),t(a,r),t(r,c),t(a,_),u(g,w,y),E(k,g,y),F=!0},p:ge,i(g){F||(T(k.$$.fragment,g),F=!0)},o(g){j(k.$$.fragment,g),F=!1},d(g){g&&s(a),g&&s(w),x(k,g)}}}function bu(P){let a,m;return a=new ce({props:{$$slots:{default:[yu]},$$scope:{ctx:P}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){E(a,r,c),m=!0},p(r,c){const _={};c&2&&(_.$$scope={dirty:c,ctx:r}),a.$set(_)},i(r){m||(T(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){x(a,r)}}}function Au(P){let a,m,r,c,_,w,k,F,g,y,I,N,D,W,z,C,v,S,R,U,Q,J,se,V,G,ee,B,K,he,re,$e,oe,te,ne,_e,M,O,le,q,H,ie,Fe,de,we,pe,Ue,ve,os,yt,Y,Zs,Fo,So,Xs,Co,Io,ea,No,Oo,ta,Do,Ho,sa,Lo,Wo,aa,Uo,Ro,ra,Go,Yo,oa,Jo,Ba,bt,na,Qo,Vo,Ka,ke,la,Bo,Ko,ia,Zo,Xo,pa,en,Za,At,fa,tn,sn,Xa,Re,ua,an,rn,ma,on,er,Ge,tr,Se,Ye,ca,Et,nn,ha,ln,sr,Je,pn,ns,fn,un,ar,ls,mn,rr,Qe,or,Ve,cn,is,hn,dn,nr,Tt,lr,ye,$n,jt,_n,gn,da,wn,vn,ir,xt,pr,Be,kn,ps,yn,bn,fr,qt,ur,be,An,fs,En,Tn,zt,jn,xn,mr,Pt,cr,Ke,qn,us,zn,Pn,hr,Mt,dr,Ae,Mn,Ft,Fn,Sn,St,Cn,In,$r,Ct,_r,Ze,Nn,$a,On,Dn,gr,It,wr,Xe,Hn,_a,Ln,Wn,vr,Nt,kr,et,Un,ms,Rn,Gn,yr,Ce,tt,ga,Ot,Yn,wa,Jn,br,fe,Qn,cs,Vn,Bn,Dt,Kn,Zn,hs,Xn,el,Ht,tl,sl,Ar,Lt,Er,st,Tr,Ee,al,ds,rl,ol,va,nl,ll,jr,Wt,xr,Te,il,$s,pl,fl,_s,ul,ml,qr,Ie,at,ka,Ut,cl,ya,hl,zr,Rt,Pr,Z,dl,gs,$l,_l,ws,gl,wl,vs,vl,kl,ks,yl,bl,ba,Al,El,ys,Tl,jl,Mr,je,xl,Aa,ql,zl,bs,Pl,Ml,Fr,Ne,rt,Ea,Gt,Fl,Ta,Sl,Sr,xe,Cl,ja,Il,Nl,As,Ol,Dl,Cr,ot,Hl,Es,Ll,Wl,Ir,Yt,Nr,nt,Ul,xa,Rl,Gl,Or,Ts,Yl,Dr,Jt,Hr,js,Jl,Lr,lt,xs,qs,Ql,Vl,Bl,zs,Ps,Kl,Zl,Wr,it,Xl,Ms,ei,ti,Ur,pt,Rr,ft,si,Fs,ai,ri,Gr,Oe,ut,qa,Qt,oi,za,ni,Yr,mt,Jr,ct,Qr,X,li,Vt,Pa,ii,pi,Bt,Ma,fi,ui,Ss,mi,ci,Fa,hi,di,Kt,$i,_i,Cs,gi,wi,Vr,ht,Br,De,dt,Sa,Zt,vi,Ca,ki,Kr,$t,Zr,qe,yi,Ia,bi,Ai,Na,Ei,Ti,Xr,_t,eo,He,gt,Oa,Xt,ji,Da,xi,to,Is,qi,so,ze,zi,Ns,Pi,Mi,Os,Fi,Si,ao,es,ro,wt,oo,vt,Ci,Ds,Ii,Ni,no,Le,kt,Ha,ts,Oi,La,Di,lo,Hs,Hi,io;return w=new Me({}),I=new Uf({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/tensorflow/quicktour.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/tensorflow/quicktour.ipynb"}]}}),J=new Ks({props:{$$slots:{default:[Rf]},$$scope:{ctx:P}}}),B=new Me({}),O=new Nf({props:{id:"tiZFewofSLM"}}),Ge=new Ks({props:{$$slots:{default:[Gf]},$$scope:{ctx:P}}}),Et=new Me({}),Qe=new rs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Vf],pytorch:[Jf]},$$scope:{ctx:P}}}),Tt=new L({props:{code:`from transformers import pipeline

classifier = pipeline("sentiment-analysis")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>)`}}),xt=new L({props:{code:'classifier("We are very happy to show you the \u{1F917} Transformers library.")',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;POSITIVE&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9998</span>}]`}}),qt=new L({props:{code:`results = classifier(["We are very happy to show you the \u{1F917} Transformers library.", "We hope you don't hate it."])
for result in results:
    print(f"label: {result['label']}, with score: {round(result['score'], 4)}")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>results = classifier([<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> result <span class="hljs-keyword">in</span> results:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;label: <span class="hljs-subst">{result[<span class="hljs-string">&#x27;label&#x27;</span>]}</span>, with score: <span class="hljs-subst">{<span class="hljs-built_in">round</span>(result[<span class="hljs-string">&#x27;score&#x27;</span>], <span class="hljs-number">4</span>)}</span>&quot;</span>)
label: POSITIVE, <span class="hljs-keyword">with</span> score: <span class="hljs-number">0.9998</span>
label: NEGATIVE, <span class="hljs-keyword">with</span> score: <span class="hljs-number">0.5309</span>`}}),Pt=new L({props:{code:"pip install datasets ",highlighted:"pip install datasets "}}),Mt=new L({props:{code:`import torch
from transformers import pipeline

speech_recognizer = pipeline("automatic-speech-recognition", model="facebook/wav2vec2-base-960h")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>speech_recognizer = pipeline(<span class="hljs-string">&quot;automatic-speech-recognition&quot;</span>, model=<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)`}}),Ct=new L({props:{code:`from datasets import load_dataset, Audio

dataset = load_dataset("PolyAI/minds14", name="en-US", split="train")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, name=<span class="hljs-string">&quot;en-US&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`}}),It=new L({props:{code:'dataset = dataset.cast_column("audio", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))'}}),Nt=new L({props:{code:`result = speech_recognizer(dataset[:4]["audio"])
print([d["text"] for d in result])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>result = speech_recognizer(dataset[:<span class="hljs-number">4</span>][<span class="hljs-string">&quot;audio&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>([d[<span class="hljs-string">&quot;text&quot;</span>] <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> result])
[<span class="hljs-string">&#x27;I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT&#x27;</span>, <span class="hljs-string">&quot;FONDERING HOW I&#x27;D SET UP A JOIN TO HET WITH MY WIFE AND WHERE THE AP MIGHT BE&quot;</span>, <span class="hljs-string">&quot;I I&#x27;D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I&#x27;M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AND I&#x27;M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS&quot;</span>, <span class="hljs-string">&#x27;HOW DO I TURN A JOIN A COUNT&#x27;</span>]`}}),Ot=new Me({}),Lt=new L({props:{code:'model_name = "nlptown/bert-base-multilingual-uncased-sentiment"',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>'}}),st=new rs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Xf],pytorch:[Kf]},$$scope:{ctx:P}}}),Wt=new L({props:{code:`classifier = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
classifier("Nous sommes tr\xE8s heureux de vous pr\xE9senter la biblioth\xE8que \u{1F917} Transformers.")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>, model=model, tokenizer=tokenizer)
<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;Nous sommes tr\xE8s heureux de vous pr\xE9senter la biblioth\xE8que \u{1F917} Transformers.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;5 stars&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.7273</span>}]`}}),Ut=new Me({}),Rt=new Nf({props:{id:"AhChOFRegn4"}}),Gt=new Me({}),Yt=new L({props:{code:`from transformers import AutoTokenizer

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),Jt=new L({props:{code:`encoding = tokenizer("We are very happy to show you the \u{1F917} Transformers library.")
print(encoding)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>encoding = tokenizer(<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoding)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">11312</span>, <span class="hljs-number">10320</span>, <span class="hljs-number">12495</span>, <span class="hljs-number">19308</span>, <span class="hljs-number">10114</span>, <span class="hljs-number">11391</span>, <span class="hljs-number">10855</span>, <span class="hljs-number">10103</span>, <span class="hljs-number">100</span>, <span class="hljs-number">58263</span>, <span class="hljs-number">13299</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>],
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),pt=new rs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[au],pytorch:[tu]},$$scope:{ctx:P}}}),Qt=new Me({}),mt=new rs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[pu],pytorch:[nu]},$$scope:{ctx:P}}}),ct=new Ks({props:{$$slots:{default:[fu]},$$scope:{ctx:P}}}),ht=new Ks({props:{$$slots:{default:[uu]},$$scope:{ctx:P}}}),Zt=new Me({}),$t=new rs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[du],pytorch:[cu]},$$scope:{ctx:P}}}),_t=new rs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[wu],pytorch:[_u]},$$scope:{ctx:P}}}),Xt=new Me({}),es=new L({props:{code:`from transformers import AutoConfig

my_config = AutoConfig.from_pretrained("distilbert-base-uncased", n_heads=12)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, n_heads=<span class="hljs-number">12</span>)`}}),wt=new rs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[bu],pytorch:[ku]},$$scope:{ctx:P}}}),ts=new Me({}),{c(){a=l("meta"),m=h(),r=l("h1"),c=l("a"),_=l("span"),b(w.$$.fragment),k=h(),F=l("span"),g=o("Quick tour"),y=h(),b(I.$$.fragment),N=h(),D=l("p"),W=o("Get up and running with \u{1F917} Transformers! Start using the "),z=l("a"),C=o("pipeline()"),v=o(" for rapid inference, and quickly load a pretrained model and tokenizer with an "),S=l("a"),R=o("AutoClass"),U=o(" to solve your text, vision or audio task."),Q=h(),b(J.$$.fragment),se=h(),V=l("h2"),G=l("a"),ee=l("span"),b(B.$$.fragment),K=h(),he=l("span"),re=o("Pipeline"),$e=h(),oe=l("p"),te=l("a"),ne=o("pipeline()"),_e=o(" is the easiest way to use a pretrained model for a given task."),M=h(),b(O.$$.fragment),le=h(),q=l("p"),H=o("The "),ie=l("a"),Fe=o("pipeline()"),de=o(" supports many common tasks out-of-the-box:"),we=h(),pe=l("p"),Ue=l("strong"),ve=o("Text"),os=o(":"),yt=h(),Y=l("ul"),Zs=l("li"),Fo=o("Sentiment analysis: classify the polarity of a given text."),So=h(),Xs=l("li"),Co=o("Text generation (in English): generate text from a given input."),Io=h(),ea=l("li"),No=o("Name entity recognition (NER): label each word with the entity it represents (person, date, location, etc.)."),Oo=h(),ta=l("li"),Do=o("Question answering: extract the answer from the context, given some context and a question."),Ho=h(),sa=l("li"),Lo=o("Fill-mask: fill in the blank given a text with masked words."),Wo=h(),aa=l("li"),Uo=o("Summarization: generate a summary of a long sequence of text or document."),Ro=h(),ra=l("li"),Go=o("Translation: translate text into another language."),Yo=h(),oa=l("li"),Jo=o("Feature extraction: create a tensor representation of the text."),Ba=h(),bt=l("p"),na=l("strong"),Qo=o("Image"),Vo=o(":"),Ka=h(),ke=l("ul"),la=l("li"),Bo=o("Image classification: classify an image."),Ko=h(),ia=l("li"),Zo=o("Image segmentation: classify every pixel in an image."),Xo=h(),pa=l("li"),en=o("Object detection: detect objects within an image."),Za=h(),At=l("p"),fa=l("strong"),tn=o("Audio"),sn=o(":"),Xa=h(),Re=l("ul"),ua=l("li"),an=o("Audio classification: assign a label to a given segment of audio."),rn=h(),ma=l("li"),on=o("Automatic speech recognition (ASR): transcribe audio data into text."),er=h(),b(Ge.$$.fragment),tr=h(),Se=l("h3"),Ye=l("a"),ca=l("span"),b(Et.$$.fragment),nn=h(),ha=l("span"),ln=o("Pipeline usage"),sr=h(),Je=l("p"),pn=o("In the following example, you will use the "),ns=l("a"),fn=o("pipeline()"),un=o(" for sentiment analysis."),ar=h(),ls=l("p"),mn=o("Install the following dependencies if you haven\u2019t already:"),rr=h(),b(Qe.$$.fragment),or=h(),Ve=l("p"),cn=o("Import "),is=l("a"),hn=o("pipeline()"),dn=o(" and specify the task you want to complete:"),nr=h(),b(Tt.$$.fragment),lr=h(),ye=l("p"),$n=o("The pipeline downloads and caches a default "),jt=l("a"),_n=o("pretrained model"),gn=o(" and tokenizer for sentiment analysis. Now you can use the "),da=l("code"),wn=o("classifier"),vn=o(" on your target text:"),ir=h(),b(xt.$$.fragment),pr=h(),Be=l("p"),kn=o("For more than one sentence, pass a list of sentences to the "),ps=l("a"),yn=o("pipeline()"),bn=o(" which returns a list of dictionaries:"),fr=h(),b(qt.$$.fragment),ur=h(),be=l("p"),An=o("The "),fs=l("a"),En=o("pipeline()"),Tn=o(" can also iterate over an entire dataset. Start by installing the "),zt=l("a"),jn=o("\u{1F917} Datasets"),xn=o(" library:"),mr=h(),b(Pt.$$.fragment),cr=h(),Ke=l("p"),qn=o("Create a "),us=l("a"),zn=o("pipeline()"),Pn=o(" with the task you want to solve for and the model you want to use."),hr=h(),b(Mt.$$.fragment),dr=h(),Ae=l("p"),Mn=o("Next, load a dataset (see the \u{1F917} Datasets "),Ft=l("a"),Fn=o("Quick Start"),Sn=o(" for more details) you\u2019d like to iterate over. For example, let\u2019s load the "),St=l("a"),Cn=o("MInDS-14"),In=o(" dataset:"),$r=h(),b(Ct.$$.fragment),_r=h(),Ze=l("p"),Nn=o(`We need to make sure that the sampling rate of the dataset matches the sampling
rate `),$a=l("code"),On=o("facebook/wav2vec2-base-960h"),Dn=o(" was trained on."),gr=h(),b(It.$$.fragment),wr=h(),Xe=l("p"),Hn=o("Audio files are automatically loaded and resampled when calling the "),_a=l("code"),Ln=o('"audio"'),Wn=o(` column.
Let\u2019s extract the raw waveform arrays of the first 4 samples and pass it as a list to the pipeline:`),vr=h(),b(Nt.$$.fragment),kr=h(),et=l("p"),Un=o("For a larger dataset where the inputs are big (like in speech or vision), you will want to pass along a generator instead of a list that loads all the inputs in memory. See the "),ms=l("a"),Rn=o("pipeline documentation"),Gn=o(" for more information."),yr=h(),Ce=l("h3"),tt=l("a"),ga=l("span"),b(Ot.$$.fragment),Yn=h(),wa=l("span"),Jn=o("Use another model and tokenizer in the pipeline"),br=h(),fe=l("p"),Qn=o("The "),cs=l("a"),Vn=o("pipeline()"),Bn=o(" can accommodate any model from the "),Dt=l("a"),Kn=o("Model Hub"),Zn=o(", making it easy to adapt the "),hs=l("a"),Xn=o("pipeline()"),el=o(" for other use-cases. For example, if you\u2019d like a model capable of handling French text, use the tags on the Model Hub to filter for an appropriate model. The top filtered result returns a multilingual "),Ht=l("a"),tl=o("BERT model"),sl=o(" fine-tuned for sentiment analysis. Great, let\u2019s use this model!"),Ar=h(),b(Lt.$$.fragment),Er=h(),b(st.$$.fragment),Tr=h(),Ee=l("p"),al=o("Then you can specify the model and tokenizer in the "),ds=l("a"),rl=o("pipeline()"),ol=o(", and apply the "),va=l("code"),nl=o("classifier"),ll=o(" on your target text:"),jr=h(),b(Wt.$$.fragment),xr=h(),Te=l("p"),il=o("If you can\u2019t find a model for your use-case, you will need to fine-tune a pretrained model on your data. Take a look at our "),$s=l("a"),pl=o("fine-tuning tutorial"),fl=o(" to learn how. Finally, after you\u2019ve fine-tuned your pretrained model, please consider sharing it (see tutorial "),_s=l("a"),ul=o("here"),ml=o(") with the community on the Model Hub to democratize NLP for everyone! \u{1F917}"),qr=h(),Ie=l("h2"),at=l("a"),ka=l("span"),b(Ut.$$.fragment),cl=h(),ya=l("span"),hl=o("AutoClass"),zr=h(),b(Rt.$$.fragment),Pr=h(),Z=l("p"),dl=o("Under the hood, the "),gs=l("a"),$l=o("AutoModelForSequenceClassification"),_l=o(" and "),ws=l("a"),gl=o("AutoTokenizer"),wl=o(" classes work together to power the "),vs=l("a"),vl=o("pipeline()"),kl=o(". An "),ks=l("a"),yl=o("AutoClass"),bl=o(" is a shortcut that automatically retrieves the architecture of a pretrained model from it\u2019s name or path. You only need to select the appropriate "),ba=l("code"),Al=o("AutoClass"),El=o(" for your task and it\u2019s associated tokenizer with "),ys=l("a"),Tl=o("AutoTokenizer"),jl=o("."),Mr=h(),je=l("p"),xl=o("Let\u2019s return to our example and see how you can use the "),Aa=l("code"),ql=o("AutoClass"),zl=o(" to replicate the results of the "),bs=l("a"),Pl=o("pipeline()"),Ml=o("."),Fr=h(),Ne=l("h3"),rt=l("a"),Ea=l("span"),b(Gt.$$.fragment),Fl=h(),Ta=l("span"),Sl=o("AutoTokenizer"),Sr=h(),xe=l("p"),Cl=o("A tokenizer is responsible for preprocessing text into a format that is understandable to the model. First, the tokenizer will split the text into words called "),ja=l("em"),Il=o("tokens"),Nl=o(". There are multiple rules that govern the tokenization process, including how to split a word and at what level (learn more about tokenization "),As=l("a"),Ol=o("here"),Dl=o("). The most important thing to remember though is you need to instantiate the tokenizer with the same model name to ensure you\u2019re using the same tokenization rules a model was pretrained with."),Cr=h(),ot=l("p"),Hl=o("Load a tokenizer with "),Es=l("a"),Ll=o("AutoTokenizer"),Wl=o(":"),Ir=h(),b(Yt.$$.fragment),Nr=h(),nt=l("p"),Ul=o("Next, the tokenizer converts the tokens into numbers in order to construct a tensor as input to the model. This is known as the model\u2019s "),xa=l("em"),Rl=o("vocabulary"),Gl=o("."),Or=h(),Ts=l("p"),Yl=o("Pass your text to the tokenizer:"),Dr=h(),b(Jt.$$.fragment),Hr=h(),js=l("p"),Jl=o("The tokenizer will return a dictionary containing:"),Lr=h(),lt=l("ul"),xs=l("li"),qs=l("a"),Ql=o("input_ids"),Vl=o(": numerical representions of your tokens."),Bl=h(),zs=l("li"),Ps=l("a"),Kl=o("atttention_mask"),Zl=o(": indicates which tokens should be attended to."),Wr=h(),it=l("p"),Xl=o("Just like the "),Ms=l("a"),ei=o("pipeline()"),ti=o(", the tokenizer will accept a list of inputs. In addition, the tokenizer can also pad and truncate the text to return a batch with uniform length:"),Ur=h(),b(pt.$$.fragment),Rr=h(),ft=l("p"),si=o("Read the "),Fs=l("a"),ai=o("preprocessing"),ri=o(" tutorial for more details about tokenization."),Gr=h(),Oe=l("h3"),ut=l("a"),qa=l("span"),b(Qt.$$.fragment),oi=h(),za=l("span"),ni=o("AutoModel"),Yr=h(),b(mt.$$.fragment),Jr=h(),b(ct.$$.fragment),Qr=h(),X=l("p"),li=o("Models are a standard "),Vt=l("a"),Pa=l("code"),ii=o("torch.nn.Module"),pi=o(" or a "),Bt=l("a"),Ma=l("code"),fi=o("tf.keras.Model"),ui=o(" so you can use them in your usual training loop. However, to make things easier, \u{1F917} Transformers provides a "),Ss=l("a"),mi=o("Trainer"),ci=o(" class for PyTorch that adds functionality for distributed training, mixed precision, and more. For TensorFlow, you can use the "),Fa=l("code"),hi=o("fit"),di=o(" method from "),Kt=l("a"),$i=o("Keras"),_i=o(". Refer to the "),Cs=l("a"),gi=o("training tutorial"),wi=o(" for more details."),Vr=h(),b(ht.$$.fragment),Br=h(),De=l("h3"),dt=l("a"),Sa=l("span"),b(Zt.$$.fragment),vi=h(),Ca=l("span"),ki=o("Save a model"),Kr=h(),b($t.$$.fragment),Zr=h(),qe=l("p"),yi=o("One particularly cool \u{1F917} Transformers feature is the ability to save a model and reload it as either a PyTorch or TensorFlow model. The "),Ia=l("code"),bi=o("from_pt"),Ai=o(" or "),Na=l("code"),Ei=o("from_tf"),Ti=o(" parameter can convert the model from one framework to the other:"),Xr=h(),b(_t.$$.fragment),eo=h(),He=l("h2"),gt=l("a"),Oa=l("span"),b(Xt.$$.fragment),ji=h(),Da=l("span"),xi=o("Custom model builds"),to=h(),Is=l("p"),qi=o("You can modify the model\u2019s configuration class to change how a model is built. The configuration specifies a model\u2019s attributes, such as the number of hidden layers or attention heads. You start from scratch when you initialize a model from a custom configuration class. The model attributes are randomly initialized, and you\u2019ll need to train the model before you can use it to get meaningful results."),so=h(),ze=l("p"),zi=o("Start by importing "),Ns=l("a"),Pi=o("AutoConfig"),Mi=o(", and then load the pretrained model you want to modify. Within "),Os=l("a"),Fi=o("AutoConfig.from_pretrained()"),Si=o(", you can specify the attribute you want to change, such as the number of attention heads:"),ao=h(),b(es.$$.fragment),ro=h(),b(wt.$$.fragment),oo=h(),vt=l("p"),Ci=o("Take a look at the "),Ds=l("a"),Ii=o("Create a custom architecture"),Ni=o(" guide for more information about building custom configurations."),no=h(),Le=l("h2"),kt=l("a"),Ha=l("span"),b(ts.$$.fragment),Oi=h(),La=l("span"),Di=o("What's next?"),lo=h(),Hs=l("p"),Hi=o("Now that you\u2019ve completed the \u{1F917} Transformers quick tour, check out our guides and learn how to do more specific things like writing a custom model, fine-tuning a model for a task, and how to train a model with a script. If you\u2019re interested in learning more about \u{1F917} Transformers core concepts, grab a cup of coffee and take a look at our Conceptual Guides!"),this.h()},l(e){const f=Lf('[data-svelte="svelte-1phssyn"]',document.head);a=i(f,"META",{name:!0,content:!0}),f.forEach(s),m=d(e),r=i(e,"H1",{class:!0});var ss=p(r);c=i(ss,"A",{id:!0,class:!0,href:!0});var Wa=p(c);_=i(Wa,"SPAN",{});var Ua=p(_);A(w.$$.fragment,Ua),Ua.forEach(s),Wa.forEach(s),k=d(ss),F=i(ss,"SPAN",{});var Ra=p(F);g=n(Ra,"Quick tour"),Ra.forEach(s),ss.forEach(s),y=d(e),A(I.$$.fragment,e),N=d(e),D=i(e,"P",{});var We=p(D);W=n(We,"Get up and running with \u{1F917} Transformers! Start using the "),z=i(We,"A",{href:!0});var Ga=p(z);C=n(Ga,"pipeline()"),Ga.forEach(s),v=n(We," for rapid inference, and quickly load a pretrained model and tokenizer with an "),S=i(We,"A",{href:!0});var Ya=p(S);R=n(Ya,"AutoClass"),Ya.forEach(s),U=n(We," to solve your text, vision or audio task."),We.forEach(s),Q=d(e),A(J.$$.fragment,e),se=d(e),V=i(e,"H2",{class:!0});var as=p(V);G=i(as,"A",{id:!0,class:!0,href:!0});var Ja=p(G);ee=i(Ja,"SPAN",{});var Qa=p(ee);A(B.$$.fragment,Qa),Qa.forEach(s),Ja.forEach(s),K=d(as),he=i(as,"SPAN",{});var Va=p(he);re=n(Va,"Pipeline"),Va.forEach(s),as.forEach(s),$e=d(e),oe=i(e,"P",{});var Li=p(oe);te=i(Li,"A",{href:!0});var Ji=p(te);ne=n(Ji,"pipeline()"),Ji.forEach(s),_e=n(Li," is the easiest way to use a pretrained model for a given task."),Li.forEach(s),M=d(e),A(O.$$.fragment,e),le=d(e),q=i(e,"P",{});var po=p(q);H=n(po,"The "),ie=i(po,"A",{href:!0});var Qi=p(ie);Fe=n(Qi,"pipeline()"),Qi.forEach(s),de=n(po," supports many common tasks out-of-the-box:"),po.forEach(s),we=d(e),pe=i(e,"P",{});var Wi=p(pe);Ue=i(Wi,"STRONG",{});var Vi=p(Ue);ve=n(Vi,"Text"),Vi.forEach(s),os=n(Wi,":"),Wi.forEach(s),yt=d(e),Y=i(e,"UL",{});var ae=p(Y);Zs=i(ae,"LI",{});var Bi=p(Zs);Fo=n(Bi,"Sentiment analysis: classify the polarity of a given text."),Bi.forEach(s),So=d(ae),Xs=i(ae,"LI",{});var Ki=p(Xs);Co=n(Ki,"Text generation (in English): generate text from a given input."),Ki.forEach(s),Io=d(ae),ea=i(ae,"LI",{});var Zi=p(ea);No=n(Zi,"Name entity recognition (NER): label each word with the entity it represents (person, date, location, etc.)."),Zi.forEach(s),Oo=d(ae),ta=i(ae,"LI",{});var Xi=p(ta);Do=n(Xi,"Question answering: extract the answer from the context, given some context and a question."),Xi.forEach(s),Ho=d(ae),sa=i(ae,"LI",{});var ep=p(sa);Lo=n(ep,"Fill-mask: fill in the blank given a text with masked words."),ep.forEach(s),Wo=d(ae),aa=i(ae,"LI",{});var tp=p(aa);Uo=n(tp,"Summarization: generate a summary of a long sequence of text or document."),tp.forEach(s),Ro=d(ae),ra=i(ae,"LI",{});var sp=p(ra);Go=n(sp,"Translation: translate text into another language."),sp.forEach(s),Yo=d(ae),oa=i(ae,"LI",{});var ap=p(oa);Jo=n(ap,"Feature extraction: create a tensor representation of the text."),ap.forEach(s),ae.forEach(s),Ba=d(e),bt=i(e,"P",{});var Ui=p(bt);na=i(Ui,"STRONG",{});var rp=p(na);Qo=n(rp,"Image"),rp.forEach(s),Vo=n(Ui,":"),Ui.forEach(s),Ka=d(e),ke=i(e,"UL",{});var Ls=p(ke);la=i(Ls,"LI",{});var op=p(la);Bo=n(op,"Image classification: classify an image."),op.forEach(s),Ko=d(Ls),ia=i(Ls,"LI",{});var np=p(ia);Zo=n(np,"Image segmentation: classify every pixel in an image."),np.forEach(s),Xo=d(Ls),pa=i(Ls,"LI",{});var lp=p(pa);en=n(lp,"Object detection: detect objects within an image."),lp.forEach(s),Ls.forEach(s),Za=d(e),At=i(e,"P",{});var Ri=p(At);fa=i(Ri,"STRONG",{});var ip=p(fa);tn=n(ip,"Audio"),ip.forEach(s),sn=n(Ri,":"),Ri.forEach(s),Xa=d(e),Re=i(e,"UL",{});var fo=p(Re);ua=i(fo,"LI",{});var pp=p(ua);an=n(pp,"Audio classification: assign a label to a given segment of audio."),pp.forEach(s),rn=d(fo),ma=i(fo,"LI",{});var fp=p(ma);on=n(fp,"Automatic speech recognition (ASR): transcribe audio data into text."),fp.forEach(s),fo.forEach(s),er=d(e),A(Ge.$$.fragment,e),tr=d(e),Se=i(e,"H3",{class:!0});var uo=p(Se);Ye=i(uo,"A",{id:!0,class:!0,href:!0});var up=p(Ye);ca=i(up,"SPAN",{});var mp=p(ca);A(Et.$$.fragment,mp),mp.forEach(s),up.forEach(s),nn=d(uo),ha=i(uo,"SPAN",{});var cp=p(ha);ln=n(cp,"Pipeline usage"),cp.forEach(s),uo.forEach(s),sr=d(e),Je=i(e,"P",{});var mo=p(Je);pn=n(mo,"In the following example, you will use the "),ns=i(mo,"A",{href:!0});var hp=p(ns);fn=n(hp,"pipeline()"),hp.forEach(s),un=n(mo," for sentiment analysis."),mo.forEach(s),ar=d(e),ls=i(e,"P",{});var dp=p(ls);mn=n(dp,"Install the following dependencies if you haven\u2019t already:"),dp.forEach(s),rr=d(e),A(Qe.$$.fragment,e),or=d(e),Ve=i(e,"P",{});var co=p(Ve);cn=n(co,"Import "),is=i(co,"A",{href:!0});var $p=p(is);hn=n($p,"pipeline()"),$p.forEach(s),dn=n(co," and specify the task you want to complete:"),co.forEach(s),nr=d(e),A(Tt.$$.fragment,e),lr=d(e),ye=i(e,"P",{});var Ws=p(ye);$n=n(Ws,"The pipeline downloads and caches a default "),jt=i(Ws,"A",{href:!0,rel:!0});var _p=p(jt);_n=n(_p,"pretrained model"),_p.forEach(s),gn=n(Ws," and tokenizer for sentiment analysis. Now you can use the "),da=i(Ws,"CODE",{});var gp=p(da);wn=n(gp,"classifier"),gp.forEach(s),vn=n(Ws," on your target text:"),Ws.forEach(s),ir=d(e),A(xt.$$.fragment,e),pr=d(e),Be=i(e,"P",{});var ho=p(Be);kn=n(ho,"For more than one sentence, pass a list of sentences to the "),ps=i(ho,"A",{href:!0});var wp=p(ps);yn=n(wp,"pipeline()"),wp.forEach(s),bn=n(ho," which returns a list of dictionaries:"),ho.forEach(s),fr=d(e),A(qt.$$.fragment,e),ur=d(e),be=i(e,"P",{});var Us=p(be);An=n(Us,"The "),fs=i(Us,"A",{href:!0});var vp=p(fs);En=n(vp,"pipeline()"),vp.forEach(s),Tn=n(Us," can also iterate over an entire dataset. Start by installing the "),zt=i(Us,"A",{href:!0,rel:!0});var kp=p(zt);jn=n(kp,"\u{1F917} Datasets"),kp.forEach(s),xn=n(Us," library:"),Us.forEach(s),mr=d(e),A(Pt.$$.fragment,e),cr=d(e),Ke=i(e,"P",{});var $o=p(Ke);qn=n($o,"Create a "),us=i($o,"A",{href:!0});var yp=p(us);zn=n(yp,"pipeline()"),yp.forEach(s),Pn=n($o," with the task you want to solve for and the model you want to use."),$o.forEach(s),hr=d(e),A(Mt.$$.fragment,e),dr=d(e),Ae=i(e,"P",{});var Rs=p(Ae);Mn=n(Rs,"Next, load a dataset (see the \u{1F917} Datasets "),Ft=i(Rs,"A",{href:!0,rel:!0});var bp=p(Ft);Fn=n(bp,"Quick Start"),bp.forEach(s),Sn=n(Rs," for more details) you\u2019d like to iterate over. For example, let\u2019s load the "),St=i(Rs,"A",{href:!0,rel:!0});var Ap=p(St);Cn=n(Ap,"MInDS-14"),Ap.forEach(s),In=n(Rs," dataset:"),Rs.forEach(s),$r=d(e),A(Ct.$$.fragment,e),_r=d(e),Ze=i(e,"P",{});var _o=p(Ze);Nn=n(_o,`We need to make sure that the sampling rate of the dataset matches the sampling
rate `),$a=i(_o,"CODE",{});var Ep=p($a);On=n(Ep,"facebook/wav2vec2-base-960h"),Ep.forEach(s),Dn=n(_o," was trained on."),_o.forEach(s),gr=d(e),A(It.$$.fragment,e),wr=d(e),Xe=i(e,"P",{});var go=p(Xe);Hn=n(go,"Audio files are automatically loaded and resampled when calling the "),_a=i(go,"CODE",{});var Tp=p(_a);Ln=n(Tp,'"audio"'),Tp.forEach(s),Wn=n(go,` column.
Let\u2019s extract the raw waveform arrays of the first 4 samples and pass it as a list to the pipeline:`),go.forEach(s),vr=d(e),A(Nt.$$.fragment,e),kr=d(e),et=i(e,"P",{});var wo=p(et);Un=n(wo,"For a larger dataset where the inputs are big (like in speech or vision), you will want to pass along a generator instead of a list that loads all the inputs in memory. See the "),ms=i(wo,"A",{href:!0});var jp=p(ms);Rn=n(jp,"pipeline documentation"),jp.forEach(s),Gn=n(wo," for more information."),wo.forEach(s),yr=d(e),Ce=i(e,"H3",{class:!0});var vo=p(Ce);tt=i(vo,"A",{id:!0,class:!0,href:!0});var xp=p(tt);ga=i(xp,"SPAN",{});var qp=p(ga);A(Ot.$$.fragment,qp),qp.forEach(s),xp.forEach(s),Yn=d(vo),wa=i(vo,"SPAN",{});var zp=p(wa);Jn=n(zp,"Use another model and tokenizer in the pipeline"),zp.forEach(s),vo.forEach(s),br=d(e),fe=i(e,"P",{});var Pe=p(fe);Qn=n(Pe,"The "),cs=i(Pe,"A",{href:!0});var Pp=p(cs);Vn=n(Pp,"pipeline()"),Pp.forEach(s),Bn=n(Pe," can accommodate any model from the "),Dt=i(Pe,"A",{href:!0,rel:!0});var Mp=p(Dt);Kn=n(Mp,"Model Hub"),Mp.forEach(s),Zn=n(Pe,", making it easy to adapt the "),hs=i(Pe,"A",{href:!0});var Fp=p(hs);Xn=n(Fp,"pipeline()"),Fp.forEach(s),el=n(Pe," for other use-cases. For example, if you\u2019d like a model capable of handling French text, use the tags on the Model Hub to filter for an appropriate model. The top filtered result returns a multilingual "),Ht=i(Pe,"A",{href:!0,rel:!0});var Sp=p(Ht);tl=n(Sp,"BERT model"),Sp.forEach(s),sl=n(Pe," fine-tuned for sentiment analysis. Great, let\u2019s use this model!"),Pe.forEach(s),Ar=d(e),A(Lt.$$.fragment,e),Er=d(e),A(st.$$.fragment,e),Tr=d(e),Ee=i(e,"P",{});var Gs=p(Ee);al=n(Gs,"Then you can specify the model and tokenizer in the "),ds=i(Gs,"A",{href:!0});var Cp=p(ds);rl=n(Cp,"pipeline()"),Cp.forEach(s),ol=n(Gs,", and apply the "),va=i(Gs,"CODE",{});var Ip=p(va);nl=n(Ip,"classifier"),Ip.forEach(s),ll=n(Gs," on your target text:"),Gs.forEach(s),jr=d(e),A(Wt.$$.fragment,e),xr=d(e),Te=i(e,"P",{});var Ys=p(Te);il=n(Ys,"If you can\u2019t find a model for your use-case, you will need to fine-tune a pretrained model on your data. Take a look at our "),$s=i(Ys,"A",{href:!0});var Np=p($s);pl=n(Np,"fine-tuning tutorial"),Np.forEach(s),fl=n(Ys," to learn how. Finally, after you\u2019ve fine-tuned your pretrained model, please consider sharing it (see tutorial "),_s=i(Ys,"A",{href:!0});var Op=p(_s);ul=n(Op,"here"),Op.forEach(s),ml=n(Ys,") with the community on the Model Hub to democratize NLP for everyone! \u{1F917}"),Ys.forEach(s),qr=d(e),Ie=i(e,"H2",{class:!0});var ko=p(Ie);at=i(ko,"A",{id:!0,class:!0,href:!0});var Dp=p(at);ka=i(Dp,"SPAN",{});var Hp=p(ka);A(Ut.$$.fragment,Hp),Hp.forEach(s),Dp.forEach(s),cl=d(ko),ya=i(ko,"SPAN",{});var Lp=p(ya);hl=n(Lp,"AutoClass"),Lp.forEach(s),ko.forEach(s),zr=d(e),A(Rt.$$.fragment,e),Pr=d(e),Z=i(e,"P",{});var ue=p(Z);dl=n(ue,"Under the hood, the "),gs=i(ue,"A",{href:!0});var Wp=p(gs);$l=n(Wp,"AutoModelForSequenceClassification"),Wp.forEach(s),_l=n(ue," and "),ws=i(ue,"A",{href:!0});var Up=p(ws);gl=n(Up,"AutoTokenizer"),Up.forEach(s),wl=n(ue," classes work together to power the "),vs=i(ue,"A",{href:!0});var Rp=p(vs);vl=n(Rp,"pipeline()"),Rp.forEach(s),kl=n(ue,". An "),ks=i(ue,"A",{href:!0});var Gp=p(ks);yl=n(Gp,"AutoClass"),Gp.forEach(s),bl=n(ue," is a shortcut that automatically retrieves the architecture of a pretrained model from it\u2019s name or path. You only need to select the appropriate "),ba=i(ue,"CODE",{});var Yp=p(ba);Al=n(Yp,"AutoClass"),Yp.forEach(s),El=n(ue," for your task and it\u2019s associated tokenizer with "),ys=i(ue,"A",{href:!0});var Jp=p(ys);Tl=n(Jp,"AutoTokenizer"),Jp.forEach(s),jl=n(ue,"."),ue.forEach(s),Mr=d(e),je=i(e,"P",{});var Js=p(je);xl=n(Js,"Let\u2019s return to our example and see how you can use the "),Aa=i(Js,"CODE",{});var Qp=p(Aa);ql=n(Qp,"AutoClass"),Qp.forEach(s),zl=n(Js," to replicate the results of the "),bs=i(Js,"A",{href:!0});var Vp=p(bs);Pl=n(Vp,"pipeline()"),Vp.forEach(s),Ml=n(Js,"."),Js.forEach(s),Fr=d(e),Ne=i(e,"H3",{class:!0});var yo=p(Ne);rt=i(yo,"A",{id:!0,class:!0,href:!0});var Bp=p(rt);Ea=i(Bp,"SPAN",{});var Kp=p(Ea);A(Gt.$$.fragment,Kp),Kp.forEach(s),Bp.forEach(s),Fl=d(yo),Ta=i(yo,"SPAN",{});var Zp=p(Ta);Sl=n(Zp,"AutoTokenizer"),Zp.forEach(s),yo.forEach(s),Sr=d(e),xe=i(e,"P",{});var Qs=p(xe);Cl=n(Qs,"A tokenizer is responsible for preprocessing text into a format that is understandable to the model. First, the tokenizer will split the text into words called "),ja=i(Qs,"EM",{});var Xp=p(ja);Il=n(Xp,"tokens"),Xp.forEach(s),Nl=n(Qs,". There are multiple rules that govern the tokenization process, including how to split a word and at what level (learn more about tokenization "),As=i(Qs,"A",{href:!0});var ef=p(As);Ol=n(ef,"here"),ef.forEach(s),Dl=n(Qs,"). The most important thing to remember though is you need to instantiate the tokenizer with the same model name to ensure you\u2019re using the same tokenization rules a model was pretrained with."),Qs.forEach(s),Cr=d(e),ot=i(e,"P",{});var bo=p(ot);Hl=n(bo,"Load a tokenizer with "),Es=i(bo,"A",{href:!0});var tf=p(Es);Ll=n(tf,"AutoTokenizer"),tf.forEach(s),Wl=n(bo,":"),bo.forEach(s),Ir=d(e),A(Yt.$$.fragment,e),Nr=d(e),nt=i(e,"P",{});var Ao=p(nt);Ul=n(Ao,"Next, the tokenizer converts the tokens into numbers in order to construct a tensor as input to the model. This is known as the model\u2019s "),xa=i(Ao,"EM",{});var sf=p(xa);Rl=n(sf,"vocabulary"),sf.forEach(s),Gl=n(Ao,"."),Ao.forEach(s),Or=d(e),Ts=i(e,"P",{});var af=p(Ts);Yl=n(af,"Pass your text to the tokenizer:"),af.forEach(s),Dr=d(e),A(Jt.$$.fragment,e),Hr=d(e),js=i(e,"P",{});var rf=p(js);Jl=n(rf,"The tokenizer will return a dictionary containing:"),rf.forEach(s),Lr=d(e),lt=i(e,"UL",{});var Eo=p(lt);xs=i(Eo,"LI",{});var Gi=p(xs);qs=i(Gi,"A",{href:!0});var of=p(qs);Ql=n(of,"input_ids"),of.forEach(s),Vl=n(Gi,": numerical representions of your tokens."),Gi.forEach(s),Bl=d(Eo),zs=i(Eo,"LI",{});var Yi=p(zs);Ps=i(Yi,"A",{href:!0});var nf=p(Ps);Kl=n(nf,"atttention_mask"),nf.forEach(s),Zl=n(Yi,": indicates which tokens should be attended to."),Yi.forEach(s),Eo.forEach(s),Wr=d(e),it=i(e,"P",{});var To=p(it);Xl=n(To,"Just like the "),Ms=i(To,"A",{href:!0});var lf=p(Ms);ei=n(lf,"pipeline()"),lf.forEach(s),ti=n(To,", the tokenizer will accept a list of inputs. In addition, the tokenizer can also pad and truncate the text to return a batch with uniform length:"),To.forEach(s),Ur=d(e),A(pt.$$.fragment,e),Rr=d(e),ft=i(e,"P",{});var jo=p(ft);si=n(jo,"Read the "),Fs=i(jo,"A",{href:!0});var pf=p(Fs);ai=n(pf,"preprocessing"),pf.forEach(s),ri=n(jo," tutorial for more details about tokenization."),jo.forEach(s),Gr=d(e),Oe=i(e,"H3",{class:!0});var xo=p(Oe);ut=i(xo,"A",{id:!0,class:!0,href:!0});var ff=p(ut);qa=i(ff,"SPAN",{});var uf=p(qa);A(Qt.$$.fragment,uf),uf.forEach(s),ff.forEach(s),oi=d(xo),za=i(xo,"SPAN",{});var mf=p(za);ni=n(mf,"AutoModel"),mf.forEach(s),xo.forEach(s),Yr=d(e),A(mt.$$.fragment,e),Jr=d(e),A(ct.$$.fragment,e),Qr=d(e),X=i(e,"P",{});var me=p(X);li=n(me,"Models are a standard "),Vt=i(me,"A",{href:!0,rel:!0});var cf=p(Vt);Pa=i(cf,"CODE",{});var hf=p(Pa);ii=n(hf,"torch.nn.Module"),hf.forEach(s),cf.forEach(s),pi=n(me," or a "),Bt=i(me,"A",{href:!0,rel:!0});var df=p(Bt);Ma=i(df,"CODE",{});var $f=p(Ma);fi=n($f,"tf.keras.Model"),$f.forEach(s),df.forEach(s),ui=n(me," so you can use them in your usual training loop. However, to make things easier, \u{1F917} Transformers provides a "),Ss=i(me,"A",{href:!0});var _f=p(Ss);mi=n(_f,"Trainer"),_f.forEach(s),ci=n(me," class for PyTorch that adds functionality for distributed training, mixed precision, and more. For TensorFlow, you can use the "),Fa=i(me,"CODE",{});var gf=p(Fa);hi=n(gf,"fit"),gf.forEach(s),di=n(me," method from "),Kt=i(me,"A",{href:!0,rel:!0});var wf=p(Kt);$i=n(wf,"Keras"),wf.forEach(s),_i=n(me,". Refer to the "),Cs=i(me,"A",{href:!0});var vf=p(Cs);gi=n(vf,"training tutorial"),vf.forEach(s),wi=n(me," for more details."),me.forEach(s),Vr=d(e),A(ht.$$.fragment,e),Br=d(e),De=i(e,"H3",{class:!0});var qo=p(De);dt=i(qo,"A",{id:!0,class:!0,href:!0});var kf=p(dt);Sa=i(kf,"SPAN",{});var yf=p(Sa);A(Zt.$$.fragment,yf),yf.forEach(s),kf.forEach(s),vi=d(qo),Ca=i(qo,"SPAN",{});var bf=p(Ca);ki=n(bf,"Save a model"),bf.forEach(s),qo.forEach(s),Kr=d(e),A($t.$$.fragment,e),Zr=d(e),qe=i(e,"P",{});var Vs=p(qe);yi=n(Vs,"One particularly cool \u{1F917} Transformers feature is the ability to save a model and reload it as either a PyTorch or TensorFlow model. The "),Ia=i(Vs,"CODE",{});var Af=p(Ia);bi=n(Af,"from_pt"),Af.forEach(s),Ai=n(Vs," or "),Na=i(Vs,"CODE",{});var Ef=p(Na);Ei=n(Ef,"from_tf"),Ef.forEach(s),Ti=n(Vs," parameter can convert the model from one framework to the other:"),Vs.forEach(s),Xr=d(e),A(_t.$$.fragment,e),eo=d(e),He=i(e,"H2",{class:!0});var zo=p(He);gt=i(zo,"A",{id:!0,class:!0,href:!0});var Tf=p(gt);Oa=i(Tf,"SPAN",{});var jf=p(Oa);A(Xt.$$.fragment,jf),jf.forEach(s),Tf.forEach(s),ji=d(zo),Da=i(zo,"SPAN",{});var xf=p(Da);xi=n(xf,"Custom model builds"),xf.forEach(s),zo.forEach(s),to=d(e),Is=i(e,"P",{});var qf=p(Is);qi=n(qf,"You can modify the model\u2019s configuration class to change how a model is built. The configuration specifies a model\u2019s attributes, such as the number of hidden layers or attention heads. You start from scratch when you initialize a model from a custom configuration class. The model attributes are randomly initialized, and you\u2019ll need to train the model before you can use it to get meaningful results."),qf.forEach(s),so=d(e),ze=i(e,"P",{});var Bs=p(ze);zi=n(Bs,"Start by importing "),Ns=i(Bs,"A",{href:!0});var zf=p(Ns);Pi=n(zf,"AutoConfig"),zf.forEach(s),Mi=n(Bs,", and then load the pretrained model you want to modify. Within "),Os=i(Bs,"A",{href:!0});var Pf=p(Os);Fi=n(Pf,"AutoConfig.from_pretrained()"),Pf.forEach(s),Si=n(Bs,", you can specify the attribute you want to change, such as the number of attention heads:"),Bs.forEach(s),ao=d(e),A(es.$$.fragment,e),ro=d(e),A(wt.$$.fragment,e),oo=d(e),vt=i(e,"P",{});var Po=p(vt);Ci=n(Po,"Take a look at the "),Ds=i(Po,"A",{href:!0});var Mf=p(Ds);Ii=n(Mf,"Create a custom architecture"),Mf.forEach(s),Ni=n(Po," guide for more information about building custom configurations."),Po.forEach(s),no=d(e),Le=i(e,"H2",{class:!0});var Mo=p(Le);kt=i(Mo,"A",{id:!0,class:!0,href:!0});var Ff=p(kt);Ha=i(Ff,"SPAN",{});var Sf=p(Ha);A(ts.$$.fragment,Sf),Sf.forEach(s),Ff.forEach(s),Oi=d(Mo),La=i(Mo,"SPAN",{});var Cf=p(La);Di=n(Cf,"What's next?"),Cf.forEach(s),Mo.forEach(s),lo=d(e),Hs=i(e,"P",{});var If=p(Hs);Hi=n(If,"Now that you\u2019ve completed the \u{1F917} Transformers quick tour, check out our guides and learn how to do more specific things like writing a custom model, fine-tuning a model for a task, and how to train a model with a script. If you\u2019re interested in learning more about \u{1F917} Transformers core concepts, grab a cup of coffee and take a look at our Conceptual Guides!"),If.forEach(s),this.h()},h(){$(a,"name","hf:doc:metadata"),$(a,"content",JSON.stringify(Eu)),$(c,"id","quick-tour"),$(c,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(c,"href","#quick-tour"),$(r,"class","relative group"),$(z,"href","/docs/transformers/pr_18248/en/main_classes/pipelines#transformers.pipeline"),$(S,"href","./model_doc/auto"),$(G,"id","pipeline"),$(G,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(G,"href","#pipeline"),$(V,"class","relative group"),$(te,"href","/docs/transformers/pr_18248/en/main_classes/pipelines#transformers.pipeline"),$(ie,"href","/docs/transformers/pr_18248/en/main_classes/pipelines#transformers.pipeline"),$(Ye,"id","pipeline-usage"),$(Ye,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(Ye,"href","#pipeline-usage"),$(Se,"class","relative group"),$(ns,"href","/docs/transformers/pr_18248/en/main_classes/pipelines#transformers.pipeline"),$(is,"href","/docs/transformers/pr_18248/en/main_classes/pipelines#transformers.pipeline"),$(jt,"href","https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english"),$(jt,"rel","nofollow"),$(ps,"href","/docs/transformers/pr_18248/en/main_classes/pipelines#transformers.pipeline"),$(fs,"href","/docs/transformers/pr_18248/en/main_classes/pipelines#transformers.pipeline"),$(zt,"href","https://huggingface.co/docs/datasets/"),$(zt,"rel","nofollow"),$(us,"href","/docs/transformers/pr_18248/en/main_classes/pipelines#transformers.pipeline"),$(Ft,"href","https://huggingface.co/docs/datasets/quickstart.html"),$(Ft,"rel","nofollow"),$(St,"href","https://huggingface.co/datasets/PolyAI/minds14"),$(St,"rel","nofollow"),$(ms,"href","./main_classes/pipelines"),$(tt,"id","use-another-model-and-tokenizer-in-the-pipeline"),$(tt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(tt,"href","#use-another-model-and-tokenizer-in-the-pipeline"),$(Ce,"class","relative group"),$(cs,"href","/docs/transformers/pr_18248/en/main_classes/pipelines#transformers.pipeline"),$(Dt,"href","https://huggingface.co/models"),$(Dt,"rel","nofollow"),$(hs,"href","/docs/transformers/pr_18248/en/main_classes/pipelines#transformers.pipeline"),$(Ht,"href","https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment"),$(Ht,"rel","nofollow"),$(ds,"href","/docs/transformers/pr_18248/en/main_classes/pipelines#transformers.pipeline"),$($s,"href","./training"),$(_s,"href","./model_sharing"),$(at,"id","autoclass"),$(at,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(at,"href","#autoclass"),$(Ie,"class","relative group"),$(gs,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.AutoModelForSequenceClassification"),$(ws,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.AutoTokenizer"),$(vs,"href","/docs/transformers/pr_18248/en/main_classes/pipelines#transformers.pipeline"),$(ks,"href","./model_doc/auto"),$(ys,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.AutoTokenizer"),$(bs,"href","/docs/transformers/pr_18248/en/main_classes/pipelines#transformers.pipeline"),$(rt,"id","autotokenizer"),$(rt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(rt,"href","#autotokenizer"),$(Ne,"class","relative group"),$(As,"href","./tokenizer_summary"),$(Es,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.AutoTokenizer"),$(qs,"href","./glossary#input-ids"),$(Ps,"href",".glossary#attention-mask"),$(Ms,"href","/docs/transformers/pr_18248/en/main_classes/pipelines#transformers.pipeline"),$(Fs,"href","./preprocessing"),$(ut,"id","automodel"),$(ut,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(ut,"href","#automodel"),$(Oe,"class","relative group"),$(Vt,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),$(Vt,"rel","nofollow"),$(Bt,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),$(Bt,"rel","nofollow"),$(Ss,"href","/docs/transformers/pr_18248/en/main_classes/trainer#transformers.Trainer"),$(Kt,"href","https://keras.io/"),$(Kt,"rel","nofollow"),$(Cs,"href","./training"),$(dt,"id","save-a-model"),$(dt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(dt,"href","#save-a-model"),$(De,"class","relative group"),$(gt,"id","custom-model-builds"),$(gt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(gt,"href","#custom-model-builds"),$(He,"class","relative group"),$(Ns,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.AutoConfig"),$(Os,"href","/docs/transformers/pr_18248/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),$(Ds,"href","./create_a_model"),$(kt,"id","whats-next"),$(kt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),$(kt,"href","#whats-next"),$(Le,"class","relative group")},m(e,f){t(document.head,a),u(e,m,f),u(e,r,f),t(r,c),t(c,_),E(w,_,null),t(r,k),t(r,F),t(F,g),u(e,y,f),E(I,e,f),u(e,N,f),u(e,D,f),t(D,W),t(D,z),t(z,C),t(D,v),t(D,S),t(S,R),t(D,U),u(e,Q,f),E(J,e,f),u(e,se,f),u(e,V,f),t(V,G),t(G,ee),E(B,ee,null),t(V,K),t(V,he),t(he,re),u(e,$e,f),u(e,oe,f),t(oe,te),t(te,ne),t(oe,_e),u(e,M,f),E(O,e,f),u(e,le,f),u(e,q,f),t(q,H),t(q,ie),t(ie,Fe),t(q,de),u(e,we,f),u(e,pe,f),t(pe,Ue),t(Ue,ve),t(pe,os),u(e,yt,f),u(e,Y,f),t(Y,Zs),t(Zs,Fo),t(Y,So),t(Y,Xs),t(Xs,Co),t(Y,Io),t(Y,ea),t(ea,No),t(Y,Oo),t(Y,ta),t(ta,Do),t(Y,Ho),t(Y,sa),t(sa,Lo),t(Y,Wo),t(Y,aa),t(aa,Uo),t(Y,Ro),t(Y,ra),t(ra,Go),t(Y,Yo),t(Y,oa),t(oa,Jo),u(e,Ba,f),u(e,bt,f),t(bt,na),t(na,Qo),t(bt,Vo),u(e,Ka,f),u(e,ke,f),t(ke,la),t(la,Bo),t(ke,Ko),t(ke,ia),t(ia,Zo),t(ke,Xo),t(ke,pa),t(pa,en),u(e,Za,f),u(e,At,f),t(At,fa),t(fa,tn),t(At,sn),u(e,Xa,f),u(e,Re,f),t(Re,ua),t(ua,an),t(Re,rn),t(Re,ma),t(ma,on),u(e,er,f),E(Ge,e,f),u(e,tr,f),u(e,Se,f),t(Se,Ye),t(Ye,ca),E(Et,ca,null),t(Se,nn),t(Se,ha),t(ha,ln),u(e,sr,f),u(e,Je,f),t(Je,pn),t(Je,ns),t(ns,fn),t(Je,un),u(e,ar,f),u(e,ls,f),t(ls,mn),u(e,rr,f),E(Qe,e,f),u(e,or,f),u(e,Ve,f),t(Ve,cn),t(Ve,is),t(is,hn),t(Ve,dn),u(e,nr,f),E(Tt,e,f),u(e,lr,f),u(e,ye,f),t(ye,$n),t(ye,jt),t(jt,_n),t(ye,gn),t(ye,da),t(da,wn),t(ye,vn),u(e,ir,f),E(xt,e,f),u(e,pr,f),u(e,Be,f),t(Be,kn),t(Be,ps),t(ps,yn),t(Be,bn),u(e,fr,f),E(qt,e,f),u(e,ur,f),u(e,be,f),t(be,An),t(be,fs),t(fs,En),t(be,Tn),t(be,zt),t(zt,jn),t(be,xn),u(e,mr,f),E(Pt,e,f),u(e,cr,f),u(e,Ke,f),t(Ke,qn),t(Ke,us),t(us,zn),t(Ke,Pn),u(e,hr,f),E(Mt,e,f),u(e,dr,f),u(e,Ae,f),t(Ae,Mn),t(Ae,Ft),t(Ft,Fn),t(Ae,Sn),t(Ae,St),t(St,Cn),t(Ae,In),u(e,$r,f),E(Ct,e,f),u(e,_r,f),u(e,Ze,f),t(Ze,Nn),t(Ze,$a),t($a,On),t(Ze,Dn),u(e,gr,f),E(It,e,f),u(e,wr,f),u(e,Xe,f),t(Xe,Hn),t(Xe,_a),t(_a,Ln),t(Xe,Wn),u(e,vr,f),E(Nt,e,f),u(e,kr,f),u(e,et,f),t(et,Un),t(et,ms),t(ms,Rn),t(et,Gn),u(e,yr,f),u(e,Ce,f),t(Ce,tt),t(tt,ga),E(Ot,ga,null),t(Ce,Yn),t(Ce,wa),t(wa,Jn),u(e,br,f),u(e,fe,f),t(fe,Qn),t(fe,cs),t(cs,Vn),t(fe,Bn),t(fe,Dt),t(Dt,Kn),t(fe,Zn),t(fe,hs),t(hs,Xn),t(fe,el),t(fe,Ht),t(Ht,tl),t(fe,sl),u(e,Ar,f),E(Lt,e,f),u(e,Er,f),E(st,e,f),u(e,Tr,f),u(e,Ee,f),t(Ee,al),t(Ee,ds),t(ds,rl),t(Ee,ol),t(Ee,va),t(va,nl),t(Ee,ll),u(e,jr,f),E(Wt,e,f),u(e,xr,f),u(e,Te,f),t(Te,il),t(Te,$s),t($s,pl),t(Te,fl),t(Te,_s),t(_s,ul),t(Te,ml),u(e,qr,f),u(e,Ie,f),t(Ie,at),t(at,ka),E(Ut,ka,null),t(Ie,cl),t(Ie,ya),t(ya,hl),u(e,zr,f),E(Rt,e,f),u(e,Pr,f),u(e,Z,f),t(Z,dl),t(Z,gs),t(gs,$l),t(Z,_l),t(Z,ws),t(ws,gl),t(Z,wl),t(Z,vs),t(vs,vl),t(Z,kl),t(Z,ks),t(ks,yl),t(Z,bl),t(Z,ba),t(ba,Al),t(Z,El),t(Z,ys),t(ys,Tl),t(Z,jl),u(e,Mr,f),u(e,je,f),t(je,xl),t(je,Aa),t(Aa,ql),t(je,zl),t(je,bs),t(bs,Pl),t(je,Ml),u(e,Fr,f),u(e,Ne,f),t(Ne,rt),t(rt,Ea),E(Gt,Ea,null),t(Ne,Fl),t(Ne,Ta),t(Ta,Sl),u(e,Sr,f),u(e,xe,f),t(xe,Cl),t(xe,ja),t(ja,Il),t(xe,Nl),t(xe,As),t(As,Ol),t(xe,Dl),u(e,Cr,f),u(e,ot,f),t(ot,Hl),t(ot,Es),t(Es,Ll),t(ot,Wl),u(e,Ir,f),E(Yt,e,f),u(e,Nr,f),u(e,nt,f),t(nt,Ul),t(nt,xa),t(xa,Rl),t(nt,Gl),u(e,Or,f),u(e,Ts,f),t(Ts,Yl),u(e,Dr,f),E(Jt,e,f),u(e,Hr,f),u(e,js,f),t(js,Jl),u(e,Lr,f),u(e,lt,f),t(lt,xs),t(xs,qs),t(qs,Ql),t(xs,Vl),t(lt,Bl),t(lt,zs),t(zs,Ps),t(Ps,Kl),t(zs,Zl),u(e,Wr,f),u(e,it,f),t(it,Xl),t(it,Ms),t(Ms,ei),t(it,ti),u(e,Ur,f),E(pt,e,f),u(e,Rr,f),u(e,ft,f),t(ft,si),t(ft,Fs),t(Fs,ai),t(ft,ri),u(e,Gr,f),u(e,Oe,f),t(Oe,ut),t(ut,qa),E(Qt,qa,null),t(Oe,oi),t(Oe,za),t(za,ni),u(e,Yr,f),E(mt,e,f),u(e,Jr,f),E(ct,e,f),u(e,Qr,f),u(e,X,f),t(X,li),t(X,Vt),t(Vt,Pa),t(Pa,ii),t(X,pi),t(X,Bt),t(Bt,Ma),t(Ma,fi),t(X,ui),t(X,Ss),t(Ss,mi),t(X,ci),t(X,Fa),t(Fa,hi),t(X,di),t(X,Kt),t(Kt,$i),t(X,_i),t(X,Cs),t(Cs,gi),t(X,wi),u(e,Vr,f),E(ht,e,f),u(e,Br,f),u(e,De,f),t(De,dt),t(dt,Sa),E(Zt,Sa,null),t(De,vi),t(De,Ca),t(Ca,ki),u(e,Kr,f),E($t,e,f),u(e,Zr,f),u(e,qe,f),t(qe,yi),t(qe,Ia),t(Ia,bi),t(qe,Ai),t(qe,Na),t(Na,Ei),t(qe,Ti),u(e,Xr,f),E(_t,e,f),u(e,eo,f),u(e,He,f),t(He,gt),t(gt,Oa),E(Xt,Oa,null),t(He,ji),t(He,Da),t(Da,xi),u(e,to,f),u(e,Is,f),t(Is,qi),u(e,so,f),u(e,ze,f),t(ze,zi),t(ze,Ns),t(Ns,Pi),t(ze,Mi),t(ze,Os),t(Os,Fi),t(ze,Si),u(e,ao,f),E(es,e,f),u(e,ro,f),E(wt,e,f),u(e,oo,f),u(e,vt,f),t(vt,Ci),t(vt,Ds),t(Ds,Ii),t(vt,Ni),u(e,no,f),u(e,Le,f),t(Le,kt),t(kt,Ha),E(ts,Ha,null),t(Le,Oi),t(Le,La),t(La,Di),u(e,lo,f),u(e,Hs,f),t(Hs,Hi),io=!0},p(e,[f]){const ss={};f&2&&(ss.$$scope={dirty:f,ctx:e}),J.$set(ss);const Wa={};f&2&&(Wa.$$scope={dirty:f,ctx:e}),Ge.$set(Wa);const Ua={};f&2&&(Ua.$$scope={dirty:f,ctx:e}),Qe.$set(Ua);const Ra={};f&2&&(Ra.$$scope={dirty:f,ctx:e}),st.$set(Ra);const We={};f&2&&(We.$$scope={dirty:f,ctx:e}),pt.$set(We);const Ga={};f&2&&(Ga.$$scope={dirty:f,ctx:e}),mt.$set(Ga);const Ya={};f&2&&(Ya.$$scope={dirty:f,ctx:e}),ct.$set(Ya);const as={};f&2&&(as.$$scope={dirty:f,ctx:e}),ht.$set(as);const Ja={};f&2&&(Ja.$$scope={dirty:f,ctx:e}),$t.$set(Ja);const Qa={};f&2&&(Qa.$$scope={dirty:f,ctx:e}),_t.$set(Qa);const Va={};f&2&&(Va.$$scope={dirty:f,ctx:e}),wt.$set(Va)},i(e){io||(T(w.$$.fragment,e),T(I.$$.fragment,e),T(J.$$.fragment,e),T(B.$$.fragment,e),T(O.$$.fragment,e),T(Ge.$$.fragment,e),T(Et.$$.fragment,e),T(Qe.$$.fragment,e),T(Tt.$$.fragment,e),T(xt.$$.fragment,e),T(qt.$$.fragment,e),T(Pt.$$.fragment,e),T(Mt.$$.fragment,e),T(Ct.$$.fragment,e),T(It.$$.fragment,e),T(Nt.$$.fragment,e),T(Ot.$$.fragment,e),T(Lt.$$.fragment,e),T(st.$$.fragment,e),T(Wt.$$.fragment,e),T(Ut.$$.fragment,e),T(Rt.$$.fragment,e),T(Gt.$$.fragment,e),T(Yt.$$.fragment,e),T(Jt.$$.fragment,e),T(pt.$$.fragment,e),T(Qt.$$.fragment,e),T(mt.$$.fragment,e),T(ct.$$.fragment,e),T(ht.$$.fragment,e),T(Zt.$$.fragment,e),T($t.$$.fragment,e),T(_t.$$.fragment,e),T(Xt.$$.fragment,e),T(es.$$.fragment,e),T(wt.$$.fragment,e),T(ts.$$.fragment,e),io=!0)},o(e){j(w.$$.fragment,e),j(I.$$.fragment,e),j(J.$$.fragment,e),j(B.$$.fragment,e),j(O.$$.fragment,e),j(Ge.$$.fragment,e),j(Et.$$.fragment,e),j(Qe.$$.fragment,e),j(Tt.$$.fragment,e),j(xt.$$.fragment,e),j(qt.$$.fragment,e),j(Pt.$$.fragment,e),j(Mt.$$.fragment,e),j(Ct.$$.fragment,e),j(It.$$.fragment,e),j(Nt.$$.fragment,e),j(Ot.$$.fragment,e),j(Lt.$$.fragment,e),j(st.$$.fragment,e),j(Wt.$$.fragment,e),j(Ut.$$.fragment,e),j(Rt.$$.fragment,e),j(Gt.$$.fragment,e),j(Yt.$$.fragment,e),j(Jt.$$.fragment,e),j(pt.$$.fragment,e),j(Qt.$$.fragment,e),j(mt.$$.fragment,e),j(ct.$$.fragment,e),j(ht.$$.fragment,e),j(Zt.$$.fragment,e),j($t.$$.fragment,e),j(_t.$$.fragment,e),j(Xt.$$.fragment,e),j(es.$$.fragment,e),j(wt.$$.fragment,e),j(ts.$$.fragment,e),io=!1},d(e){s(a),e&&s(m),e&&s(r),x(w),e&&s(y),x(I,e),e&&s(N),e&&s(D),e&&s(Q),x(J,e),e&&s(se),e&&s(V),x(B),e&&s($e),e&&s(oe),e&&s(M),x(O,e),e&&s(le),e&&s(q),e&&s(we),e&&s(pe),e&&s(yt),e&&s(Y),e&&s(Ba),e&&s(bt),e&&s(Ka),e&&s(ke),e&&s(Za),e&&s(At),e&&s(Xa),e&&s(Re),e&&s(er),x(Ge,e),e&&s(tr),e&&s(Se),x(Et),e&&s(sr),e&&s(Je),e&&s(ar),e&&s(ls),e&&s(rr),x(Qe,e),e&&s(or),e&&s(Ve),e&&s(nr),x(Tt,e),e&&s(lr),e&&s(ye),e&&s(ir),x(xt,e),e&&s(pr),e&&s(Be),e&&s(fr),x(qt,e),e&&s(ur),e&&s(be),e&&s(mr),x(Pt,e),e&&s(cr),e&&s(Ke),e&&s(hr),x(Mt,e),e&&s(dr),e&&s(Ae),e&&s($r),x(Ct,e),e&&s(_r),e&&s(Ze),e&&s(gr),x(It,e),e&&s(wr),e&&s(Xe),e&&s(vr),x(Nt,e),e&&s(kr),e&&s(et),e&&s(yr),e&&s(Ce),x(Ot),e&&s(br),e&&s(fe),e&&s(Ar),x(Lt,e),e&&s(Er),x(st,e),e&&s(Tr),e&&s(Ee),e&&s(jr),x(Wt,e),e&&s(xr),e&&s(Te),e&&s(qr),e&&s(Ie),x(Ut),e&&s(zr),x(Rt,e),e&&s(Pr),e&&s(Z),e&&s(Mr),e&&s(je),e&&s(Fr),e&&s(Ne),x(Gt),e&&s(Sr),e&&s(xe),e&&s(Cr),e&&s(ot),e&&s(Ir),x(Yt,e),e&&s(Nr),e&&s(nt),e&&s(Or),e&&s(Ts),e&&s(Dr),x(Jt,e),e&&s(Hr),e&&s(js),e&&s(Lr),e&&s(lt),e&&s(Wr),e&&s(it),e&&s(Ur),x(pt,e),e&&s(Rr),e&&s(ft),e&&s(Gr),e&&s(Oe),x(Qt),e&&s(Yr),x(mt,e),e&&s(Jr),x(ct,e),e&&s(Qr),e&&s(X),e&&s(Vr),x(ht,e),e&&s(Br),e&&s(De),x(Zt),e&&s(Kr),x($t,e),e&&s(Zr),e&&s(qe),e&&s(Xr),x(_t,e),e&&s(eo),e&&s(He),x(Xt),e&&s(to),e&&s(Is),e&&s(so),e&&s(ze),e&&s(ao),x(es,e),e&&s(ro),x(wt,e),e&&s(oo),e&&s(vt),e&&s(no),e&&s(Le),x(ts),e&&s(lo),e&&s(Hs)}}}const Eu={local:"quick-tour",sections:[{local:"pipeline",sections:[{local:"pipeline-usage",title:"Pipeline usage"},{local:"use-another-model-and-tokenizer-in-the-pipeline",title:"Use another model and tokenizer in the pipeline"}],title:"Pipeline"},{local:"autoclass",sections:[{local:"autotokenizer",title:"AutoTokenizer"},{local:"automodel",title:"AutoModel"},{local:"save-a-model",title:"Save a model"}],title:"AutoClass"},{local:"custom-model-builds",title:"Custom model builds"},{local:"whats-next",title:"What's next?"}],title:"Quick tour"};function Tu(P){return Wf(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Su extends Of{constructor(a){super();Df(this,a,Tu,Au,Hf,{})}}export{Su as default,Eu as metadata};
