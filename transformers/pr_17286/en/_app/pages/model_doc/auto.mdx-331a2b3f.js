import{S as Ryt,i as Pyt,s as Byt,e as a,k as l,w as F,t as o,M as Iyt,c as n,d as t,m as i,a as s,x as T,h as r,b as c,F as e,g as b,y as M,q as E,o as C,B as w,v as qyt,L as I}from"../../chunks/vendor-6b77c823.js";import{T as DDr}from"../../chunks/Tip-39098574.js";import{D as R}from"../../chunks/Docstring-1088f2fb.js";import{C as P}from"../../chunks/CodeBlock-3a8b25a8.js";import{I as Z}from"../../chunks/IconCopyLink-7a11ce68.js";import{E as B}from"../../chunks/ExampleCodeBlock-5212b321.js";function Nyt(A){let g,v,p,m,u,d,h,Eo,hi,Mf,rt,pi,ui,mA,Ef,qe,Xe,_i,kn,gA,Sn,Rn,hA,bi,Pn,pA,vi,Cf,Aa;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),u=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Eo=o(`, make sure its
`),hi=a("code"),Mf=o("model_type"),rt=o(" attribute is set to the same key you use when registering the config (here "),pi=a("code"),ui=o('"new-model"'),mA=o(")."),Ef=l(),qe=a("p"),Xe=o("Likewise, if your "),_i=a("code"),kn=o("NewModel"),gA=o(" is a subclass of "),Sn=a("a"),Rn=o("PreTrainedModel"),hA=o(`, make sure its
`),bi=a("code"),Pn=o("config_class"),pA=o(` attribute is set to the same class you use when registering the model (here
`),vi=a("code"),Cf=o("NewModelConfig"),Aa=o(")."),this.h()},l(ze){g=n(ze,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var j$=s(p);m=r(j$,"NewModelConfig"),j$.forEach(t),u=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var Fi=s(d);h=r(Fi,"PretrainedConfig"),Fi.forEach(t),Eo=r(Ae,`, make sure its
`),hi=n(Ae,"CODE",{});var D$=s(hi);Mf=r(D$,"model_type"),D$.forEach(t),rt=r(Ae," attribute is set to the same key you use when registering the config (here "),pi=n(Ae,"CODE",{});var G$=s(pi);ui=r(G$,'"new-model"'),G$.forEach(t),mA=r(Ae,")."),Ae.forEach(t),Ef=i(ze),qe=n(ze,"P",{});var Co=s(qe);Xe=r(Co,"Likewise, if your "),_i=n(Co,"CODE",{});var ya=s(_i);kn=r(ya,"NewModel"),ya.forEach(t),gA=r(Co," is a subclass of "),Sn=n(Co,"A",{href:!0});var O$=s(Sn);Rn=r(O$,"PreTrainedModel"),O$.forEach(t),hA=r(Co,`, make sure its
`),bi=n(Co,"CODE",{});var wf=s(bi);Pn=r(wf,"config_class"),wf.forEach(t),pA=r(Co,` attribute is set to the same class you use when registering the model (here
`),vi=n(Co,"CODE",{});var V$=s(vi);Cf=r(V$,"NewModelConfig"),V$.forEach(t),Aa=r(Co,")."),Co.forEach(t),this.h()},h(){c(Sn,"href","/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel")},m(ze,Ae){b(ze,g,Ae),e(g,v),e(g,p),e(p,m),e(g,u),e(g,d),e(d,h),e(g,Eo),e(g,hi),e(hi,Mf),e(g,rt),e(g,pi),e(pi,ui),e(g,mA),b(ze,Ef,Ae),b(ze,qe,Ae),e(qe,Xe),e(qe,_i),e(_i,kn),e(qe,gA),e(qe,Sn),e(Sn,Rn),e(qe,hA),e(qe,bi),e(bi,Pn),e(qe,pA),e(qe,vi),e(vi,Cf),e(qe,Aa)},d(ze){ze&&t(g),ze&&t(Ef),ze&&t(qe)}}}function jyt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

config.unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config.unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Dyt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Gyt(A){let g,v,p,m,u;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),u=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),u=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,u)},d(d){d&&t(g)}}}function Oyt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Vyt(A){let g,v,p,m,u;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),u=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),u=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,u)},d(d){d&&t(g)}}}function Xyt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zyt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Qyt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Wyt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Hyt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Uyt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Jyt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Yyt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Kyt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Zyt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Lt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ELt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ALt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $Lt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ILt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function OLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ULt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZLt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ext(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function txt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function axt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ixt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _xt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Fxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Txt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Mxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ext(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Cxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Axt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Lxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $xt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Sxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Rxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Pxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Bxt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ixt(A){let g,v,p,m,u;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),u=!0},p:I,i(d){u||(E(m.$$.fragment,d),u=!0)},o(d){C(m.$$.fragment,d),u=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qxt(A){let g,v,p,m,u,d,h,Eo,hi,Mf,rt,pi,ui,mA,Ef,qe,Xe,_i,kn,gA,Sn,Rn,hA,bi,Pn,pA,vi,Cf,Aa,ze,Ae,j$,Fi,D$,G$,Co,ya,O$,wf,V$,rGe,GIe,Ti,Af,Pee,uA,tGe,Bee,aGe,OIe,Bn,nGe,Iee,sGe,lGe,qee,iGe,dGe,VIe,_A,XIe,X$,cGe,zIe,yf,QIe,Mi,Lf,Nee,bA,fGe,jee,mGe,WIe,wo,vA,gGe,FA,hGe,z$,pGe,uGe,_Ge,TA,bGe,Dee,vGe,FGe,TGe,wr,MA,MGe,Gee,EGe,CGe,Ei,wGe,Oee,AGe,yGe,Vee,LGe,xGe,$Ge,y,xf,Xee,kGe,SGe,Q$,RGe,PGe,BGe,$f,zee,IGe,qGe,W$,NGe,jGe,DGe,kf,Qee,GGe,OGe,H$,VGe,XGe,zGe,Sf,Wee,QGe,WGe,U$,HGe,UGe,JGe,Rf,Hee,YGe,KGe,J$,ZGe,eOe,oOe,Pf,Uee,rOe,tOe,Y$,aOe,nOe,sOe,Bf,Jee,lOe,iOe,K$,dOe,cOe,fOe,If,Yee,mOe,gOe,Z$,hOe,pOe,uOe,qf,Kee,_Oe,bOe,ek,vOe,FOe,TOe,Nf,Zee,MOe,EOe,ok,COe,wOe,AOe,jf,eoe,yOe,LOe,rk,xOe,$Oe,kOe,Df,ooe,SOe,ROe,tk,POe,BOe,IOe,Gf,roe,qOe,NOe,ak,jOe,DOe,GOe,Of,toe,OOe,VOe,nk,XOe,zOe,QOe,Vf,aoe,WOe,HOe,sk,UOe,JOe,YOe,Xf,noe,KOe,ZOe,lk,eVe,oVe,rVe,zf,soe,tVe,aVe,ik,nVe,sVe,lVe,Qf,loe,iVe,dVe,dk,cVe,fVe,mVe,Wf,ioe,gVe,hVe,ck,pVe,uVe,_Ve,Hf,doe,bVe,vVe,fk,FVe,TVe,MVe,Uf,coe,EVe,CVe,mk,wVe,AVe,yVe,Jf,foe,LVe,xVe,gk,$Ve,kVe,SVe,Yf,moe,RVe,PVe,hk,BVe,IVe,qVe,Kf,goe,NVe,jVe,pk,DVe,GVe,OVe,Zf,hoe,VVe,XVe,uk,zVe,QVe,WVe,em,poe,HVe,UVe,_k,JVe,YVe,KVe,om,uoe,ZVe,eXe,bk,oXe,rXe,tXe,rm,_oe,aXe,nXe,vk,sXe,lXe,iXe,tm,boe,dXe,cXe,Fk,fXe,mXe,gXe,am,voe,hXe,pXe,Tk,uXe,_Xe,bXe,nm,Foe,vXe,FXe,Mk,TXe,MXe,EXe,sm,Toe,CXe,wXe,Ek,AXe,yXe,LXe,lm,Moe,xXe,$Xe,Ck,kXe,SXe,RXe,im,Eoe,PXe,BXe,wk,IXe,qXe,NXe,dm,Coe,jXe,DXe,Ak,GXe,OXe,VXe,cm,woe,XXe,zXe,yk,QXe,WXe,HXe,fm,Aoe,UXe,JXe,Lk,YXe,KXe,ZXe,mm,yoe,eze,oze,xk,rze,tze,aze,gm,Loe,nze,sze,$k,lze,ize,dze,hm,xoe,cze,fze,kk,mze,gze,hze,pm,$oe,pze,uze,Sk,_ze,bze,vze,um,koe,Fze,Tze,Rk,Mze,Eze,Cze,_m,Soe,wze,Aze,Pk,yze,Lze,xze,bm,Roe,$ze,kze,Bk,Sze,Rze,Pze,vm,Poe,Bze,Ize,Ik,qze,Nze,jze,Fm,Boe,Dze,Gze,qk,Oze,Vze,Xze,Tm,Ioe,zze,Qze,Nk,Wze,Hze,Uze,Mm,qoe,Jze,Yze,jk,Kze,Zze,eQe,Em,Noe,oQe,rQe,Dk,tQe,aQe,nQe,Cm,joe,sQe,lQe,Gk,iQe,dQe,cQe,wm,Doe,fQe,mQe,Ok,gQe,hQe,pQe,Am,Goe,uQe,_Qe,Vk,bQe,vQe,FQe,ym,Ooe,TQe,MQe,Xk,EQe,CQe,wQe,Lm,Voe,AQe,yQe,zk,LQe,xQe,$Qe,xm,Xoe,kQe,SQe,Qk,RQe,PQe,BQe,$m,zoe,IQe,qQe,Wk,NQe,jQe,DQe,km,Qoe,GQe,OQe,Hk,VQe,XQe,zQe,Sm,Woe,QQe,WQe,Uk,HQe,UQe,JQe,Rm,Hoe,YQe,KQe,Jk,ZQe,eWe,oWe,Pm,Uoe,rWe,tWe,Yk,aWe,nWe,sWe,Bm,Joe,lWe,iWe,Kk,dWe,cWe,fWe,Im,Yoe,mWe,gWe,Zk,hWe,pWe,uWe,qm,Koe,_We,bWe,eS,vWe,FWe,TWe,Nm,Zoe,MWe,EWe,oS,CWe,wWe,AWe,jm,ere,yWe,LWe,rS,xWe,$We,kWe,Dm,ore,SWe,RWe,tS,PWe,BWe,IWe,Gm,rre,qWe,NWe,aS,jWe,DWe,GWe,Om,tre,OWe,VWe,nS,XWe,zWe,QWe,Vm,are,WWe,HWe,sS,UWe,JWe,YWe,Xm,nre,KWe,ZWe,lS,eHe,oHe,rHe,zm,sre,tHe,aHe,iS,nHe,sHe,lHe,Qm,lre,iHe,dHe,dS,cHe,fHe,mHe,Wm,ire,gHe,hHe,cS,pHe,uHe,_He,Hm,dre,bHe,vHe,fS,FHe,THe,MHe,Um,cre,EHe,CHe,mS,wHe,AHe,yHe,Jm,fre,LHe,xHe,gS,$He,kHe,SHe,Ym,mre,RHe,PHe,hS,BHe,IHe,qHe,Km,gre,NHe,jHe,pS,DHe,GHe,OHe,Zm,hre,VHe,XHe,uS,zHe,QHe,WHe,eg,pre,HHe,UHe,_S,JHe,YHe,KHe,og,ure,ZHe,eUe,bS,oUe,rUe,tUe,rg,_re,aUe,nUe,vS,sUe,lUe,iUe,tg,bre,dUe,cUe,FS,fUe,mUe,gUe,ag,vre,hUe,pUe,TS,uUe,_Ue,bUe,ng,Fre,vUe,FUe,MS,TUe,MUe,EUe,sg,Tre,CUe,wUe,ES,AUe,yUe,LUe,lg,Mre,xUe,$Ue,CS,kUe,SUe,RUe,ig,Ere,PUe,BUe,wS,IUe,qUe,NUe,dg,Cre,jUe,DUe,AS,GUe,OUe,VUe,cg,wre,XUe,zUe,yS,QUe,WUe,HUe,fg,Are,UUe,JUe,LS,YUe,KUe,ZUe,mg,yre,eJe,oJe,xS,rJe,tJe,aJe,gg,Lre,nJe,sJe,$S,lJe,iJe,dJe,hg,xre,cJe,fJe,kS,mJe,gJe,hJe,pg,$re,pJe,uJe,SS,_Je,bJe,vJe,ug,kre,FJe,TJe,RS,MJe,EJe,CJe,_g,Sre,wJe,AJe,PS,yJe,LJe,xJe,bg,Rre,$Je,kJe,BS,SJe,RJe,PJe,vg,Pre,BJe,IJe,IS,qJe,NJe,jJe,Fg,Bre,DJe,GJe,qS,OJe,VJe,XJe,Tg,Ire,zJe,QJe,NS,WJe,HJe,UJe,Mg,qre,JJe,YJe,jS,KJe,ZJe,eYe,Eg,Nre,oYe,rYe,DS,tYe,aYe,nYe,Cg,jre,sYe,lYe,GS,iYe,dYe,cYe,wg,Dre,fYe,mYe,OS,gYe,hYe,pYe,Ag,uYe,yg,EA,_Ye,Gre,bYe,HIe,Ci,Lg,Ore,CA,vYe,Vre,FYe,UIe,Ao,wA,TYe,AA,MYe,VS,EYe,CYe,wYe,yA,AYe,Xre,yYe,LYe,xYe,Ar,LA,$Ye,zre,kYe,SYe,La,RYe,Qre,PYe,BYe,Wre,IYe,qYe,Hre,NYe,jYe,DYe,k,In,Ure,GYe,OYe,XS,VYe,XYe,zS,zYe,QYe,WYe,qn,Jre,HYe,UYe,QS,JYe,YYe,WS,KYe,ZYe,eKe,Nn,Yre,oKe,rKe,HS,tKe,aKe,US,nKe,sKe,lKe,xg,Kre,iKe,dKe,JS,cKe,fKe,mKe,jn,Zre,gKe,hKe,YS,pKe,uKe,KS,_Ke,bKe,vKe,$g,ete,FKe,TKe,ZS,MKe,EKe,CKe,kg,ote,wKe,AKe,eR,yKe,LKe,xKe,Sg,rte,$Ke,kKe,oR,SKe,RKe,PKe,Dn,tte,BKe,IKe,rR,qKe,NKe,tR,jKe,DKe,GKe,Gn,ate,OKe,VKe,aR,XKe,zKe,nR,QKe,WKe,HKe,On,nte,UKe,JKe,sR,YKe,KKe,lR,ZKe,eZe,oZe,Rg,ste,rZe,tZe,iR,aZe,nZe,sZe,Pg,lte,lZe,iZe,dR,dZe,cZe,fZe,Vn,ite,mZe,gZe,cR,hZe,pZe,fR,uZe,_Ze,bZe,Bg,dte,vZe,FZe,mR,TZe,MZe,EZe,Xn,cte,CZe,wZe,gR,AZe,yZe,hR,LZe,xZe,$Ze,zn,fte,kZe,SZe,pR,RZe,PZe,uR,BZe,IZe,qZe,Qn,mte,NZe,jZe,_R,DZe,GZe,bR,OZe,VZe,XZe,Ig,gte,zZe,QZe,vR,WZe,HZe,UZe,Wn,hte,JZe,YZe,FR,KZe,ZZe,TR,eeo,oeo,reo,Hn,pte,teo,aeo,MR,neo,seo,ER,leo,ieo,deo,Un,ute,ceo,feo,CR,meo,geo,wR,heo,peo,ueo,Jn,_te,_eo,beo,AR,veo,Feo,yR,Teo,Meo,Eeo,Yn,bte,Ceo,weo,LR,Aeo,yeo,xR,Leo,xeo,$eo,Kn,vte,keo,Seo,$R,Reo,Peo,kR,Beo,Ieo,qeo,qg,Fte,Neo,jeo,SR,Deo,Geo,Oeo,Zn,Tte,Veo,Xeo,RR,zeo,Qeo,PR,Weo,Heo,Ueo,Ng,Mte,Jeo,Yeo,BR,Keo,Zeo,eoo,es,Ete,ooo,roo,IR,too,aoo,qR,noo,soo,loo,os,Cte,ioo,doo,NR,coo,foo,jR,moo,goo,hoo,rs,wte,poo,uoo,DR,_oo,boo,GR,voo,Foo,Too,ts,Ate,Moo,Eoo,OR,Coo,woo,VR,Aoo,yoo,Loo,as,yte,xoo,$oo,XR,koo,Soo,zR,Roo,Poo,Boo,jg,Lte,Ioo,qoo,QR,Noo,joo,Doo,ns,xte,Goo,Ooo,WR,Voo,Xoo,HR,zoo,Qoo,Woo,ss,$te,Hoo,Uoo,UR,Joo,Yoo,JR,Koo,Zoo,ero,ls,kte,oro,rro,YR,tro,aro,KR,nro,sro,lro,is,Ste,iro,dro,ZR,cro,fro,eP,mro,gro,hro,ds,Rte,pro,uro,oP,_ro,bro,rP,vro,Fro,Tro,cs,Pte,Mro,Ero,tP,Cro,wro,aP,Aro,yro,Lro,Dg,Bte,xro,$ro,nP,kro,Sro,Rro,fs,Ite,Pro,Bro,sP,Iro,qro,lP,Nro,jro,Dro,Gg,qte,Gro,Oro,iP,Vro,Xro,zro,Og,Nte,Qro,Wro,dP,Hro,Uro,Jro,ms,jte,Yro,Kro,cP,Zro,eto,fP,oto,rto,tto,gs,Dte,ato,nto,mP,sto,lto,gP,ito,dto,cto,hs,Gte,fto,mto,hP,gto,hto,pP,pto,uto,_to,Vg,Ote,bto,vto,uP,Fto,Tto,Mto,ps,Vte,Eto,Cto,_P,wto,Ato,bP,yto,Lto,xto,us,Xte,$to,kto,vP,Sto,Rto,FP,Pto,Bto,Ito,_s,zte,qto,Nto,TP,jto,Dto,MP,Gto,Oto,Vto,bs,Qte,Xto,zto,EP,Qto,Wto,CP,Hto,Uto,Jto,vs,Wte,Yto,Kto,wP,Zto,eao,AP,oao,rao,tao,Xg,Hte,aao,nao,yP,sao,lao,iao,Fs,Ute,dao,cao,LP,fao,mao,xP,gao,hao,pao,zg,Jte,uao,_ao,$P,bao,vao,Fao,Qg,Yte,Tao,Mao,kP,Eao,Cao,wao,Wg,Kte,Aao,yao,SP,Lao,xao,$ao,Hg,Zte,kao,Sao,RP,Rao,Pao,Bao,Ts,eae,Iao,qao,PP,Nao,jao,BP,Dao,Gao,Oao,Ug,oae,Vao,Xao,IP,zao,Qao,Wao,Ms,rae,Hao,Uao,qP,Jao,Yao,NP,Kao,Zao,eno,Es,tae,ono,rno,jP,tno,ano,DP,nno,sno,lno,Cs,aae,ino,dno,GP,cno,fno,OP,mno,gno,hno,ws,nae,pno,uno,VP,_no,bno,XP,vno,Fno,Tno,As,sae,Mno,Eno,zP,Cno,wno,QP,Ano,yno,Lno,ys,lae,xno,$no,WP,kno,Sno,HP,Rno,Pno,Bno,Jg,iae,Ino,qno,UP,Nno,jno,Dno,Yg,dae,Gno,Ono,JP,Vno,Xno,zno,Ls,cae,Qno,Wno,YP,Hno,Uno,KP,Jno,Yno,Kno,xs,fae,Zno,eso,ZP,oso,rso,eB,tso,aso,nso,$s,mae,sso,lso,oB,iso,dso,rB,cso,fso,mso,Kg,gae,gso,hso,tB,pso,uso,_so,Zg,hae,bso,vso,aB,Fso,Tso,Mso,eh,pae,Eso,Cso,nB,wso,Aso,yso,ks,uae,Lso,xso,sB,$so,kso,lB,Sso,Rso,Pso,Ss,_ae,Bso,Iso,iB,qso,Nso,dB,jso,Dso,Gso,oh,bae,Oso,Vso,cB,Xso,zso,Qso,rh,vae,Wso,Hso,fB,Uso,Jso,Yso,Rs,Fae,Kso,Zso,mB,elo,olo,gB,rlo,tlo,alo,th,Tae,nlo,slo,hB,llo,ilo,dlo,ah,Mae,clo,flo,pB,mlo,glo,hlo,Ps,Eae,plo,ulo,uB,_lo,blo,_B,vlo,Flo,Tlo,Bs,Cae,Mlo,Elo,bB,Clo,wlo,vB,Alo,ylo,Llo,Is,wae,xlo,$lo,FB,klo,Slo,TB,Rlo,Plo,Blo,qs,Aae,Ilo,qlo,MB,Nlo,jlo,EB,Dlo,Glo,Olo,nh,Vlo,sh,xA,Xlo,yae,zlo,JIe,wi,lh,Lae,$A,Qlo,xae,Wlo,YIe,yo,kA,Hlo,SA,Ulo,CB,Jlo,Ylo,Klo,RA,Zlo,$ae,eio,oio,rio,Qe,PA,tio,kae,aio,nio,xa,sio,Sae,lio,iio,Rae,dio,cio,Pae,fio,mio,gio,ee,ih,Bae,hio,pio,wB,uio,_io,bio,dh,Iae,vio,Fio,AB,Tio,Mio,Eio,ch,qae,Cio,wio,yB,Aio,yio,Lio,fh,Nae,xio,$io,LB,kio,Sio,Rio,mh,jae,Pio,Bio,xB,Iio,qio,Nio,gh,Dae,jio,Dio,$B,Gio,Oio,Vio,hh,Gae,Xio,zio,kB,Qio,Wio,Hio,ph,Oae,Uio,Jio,SB,Yio,Kio,Zio,uh,Vae,edo,odo,RB,rdo,tdo,ado,_h,Xae,ndo,sdo,PB,ldo,ido,ddo,bh,zae,cdo,fdo,BB,mdo,gdo,hdo,vh,Qae,pdo,udo,IB,_do,bdo,vdo,Fh,Wae,Fdo,Tdo,qB,Mdo,Edo,Cdo,Th,Hae,wdo,Ado,NB,ydo,Ldo,xdo,Mh,Uae,$do,kdo,jB,Sdo,Rdo,Pdo,Eh,Jae,Bdo,Ido,DB,qdo,Ndo,jdo,Ch,Yae,Ddo,Gdo,GB,Odo,Vdo,Xdo,wh,Kae,zdo,Qdo,OB,Wdo,Hdo,Udo,Ah,Zae,Jdo,Ydo,VB,Kdo,Zdo,eco,yh,ene,oco,rco,XB,tco,aco,nco,Lh,one,sco,lco,zB,ico,dco,cco,xh,rne,fco,mco,QB,gco,hco,pco,$h,tne,uco,_co,WB,bco,vco,Fco,kh,ane,Tco,Mco,HB,Eco,Cco,wco,Sh,nne,Aco,yco,UB,Lco,xco,$co,Rh,sne,kco,Sco,JB,Rco,Pco,Bco,Ph,Ico,Bh,qco,Ih,BA,Nco,lne,jco,KIe,Ai,qh,ine,IA,Dco,dne,Gco,ZIe,Lo,qA,Oco,NA,Vco,YB,Xco,zco,Qco,jA,Wco,cne,Hco,Uco,Jco,We,DA,Yco,fne,Kco,Zco,yi,efo,mne,ofo,rfo,gne,tfo,afo,nfo,be,Nh,hne,sfo,lfo,KB,ifo,dfo,cfo,jh,pne,ffo,mfo,une,gfo,hfo,pfo,Dh,_ne,ufo,_fo,ZB,bfo,vfo,Ffo,Gh,bne,Tfo,Mfo,eI,Efo,Cfo,wfo,Oh,vne,Afo,yfo,oI,Lfo,xfo,$fo,Vh,Fne,kfo,Sfo,rI,Rfo,Pfo,Bfo,Xh,Tne,Ifo,qfo,tI,Nfo,jfo,Dfo,zh,Mne,Gfo,Ofo,aI,Vfo,Xfo,zfo,Qh,Ene,Qfo,Wfo,nI,Hfo,Ufo,Jfo,Wh,Cne,Yfo,Kfo,sI,Zfo,emo,omo,Hh,wne,rmo,tmo,lI,amo,nmo,smo,Uh,Ane,lmo,imo,iI,dmo,cmo,fmo,Jh,yne,mmo,gmo,dI,hmo,pmo,umo,Yh,Lne,_mo,bmo,cI,vmo,Fmo,Tmo,Kh,xne,Mmo,Emo,fI,Cmo,wmo,Amo,Zh,ymo,ep,Lmo,op,GA,xmo,$ne,$mo,eqe,Li,rp,kne,OA,kmo,Sne,Smo,oqe,xo,VA,Rmo,xi,Pmo,mI,Bmo,Imo,gI,qmo,Nmo,jmo,XA,Dmo,Rne,Gmo,Omo,Vmo,tt,zA,Xmo,Pne,zmo,Qmo,$i,Wmo,Bne,Hmo,Umo,hI,Jmo,Ymo,Kmo,tp,Zmo,He,QA,ego,Ine,ogo,rgo,$a,tgo,qne,ago,ngo,Nne,sgo,lgo,jne,igo,dgo,cgo,x,ap,Dne,fgo,mgo,pI,ggo,hgo,pgo,np,Gne,ugo,_go,uI,bgo,vgo,Fgo,sp,One,Tgo,Mgo,_I,Ego,Cgo,wgo,lp,Vne,Ago,ygo,bI,Lgo,xgo,$go,ip,Xne,kgo,Sgo,vI,Rgo,Pgo,Bgo,dp,zne,Igo,qgo,FI,Ngo,jgo,Dgo,cp,Qne,Ggo,Ogo,TI,Vgo,Xgo,zgo,fp,Wne,Qgo,Wgo,MI,Hgo,Ugo,Jgo,mp,Hne,Ygo,Kgo,EI,Zgo,eho,oho,gp,Une,rho,tho,CI,aho,nho,sho,hp,Jne,lho,iho,wI,dho,cho,fho,pp,Yne,mho,gho,AI,hho,pho,uho,up,Kne,_ho,bho,yI,vho,Fho,Tho,_p,Zne,Mho,Eho,LI,Cho,who,Aho,bp,ese,yho,Lho,xI,xho,$ho,kho,vp,ose,Sho,Rho,$I,Pho,Bho,Iho,Fp,rse,qho,Nho,kI,jho,Dho,Gho,Tp,tse,Oho,Vho,SI,Xho,zho,Qho,Mp,ase,Who,Hho,RI,Uho,Jho,Yho,Ep,nse,Kho,Zho,PI,epo,opo,rpo,Cp,sse,tpo,apo,BI,npo,spo,lpo,wp,lse,ipo,dpo,II,cpo,fpo,mpo,Ap,ise,gpo,hpo,qI,ppo,upo,_po,yp,dse,bpo,vpo,NI,Fpo,Tpo,Mpo,Lp,cse,Epo,Cpo,jI,wpo,Apo,ypo,xp,fse,Lpo,xpo,DI,$po,kpo,Spo,$p,mse,Rpo,Ppo,GI,Bpo,Ipo,qpo,kp,gse,Npo,jpo,OI,Dpo,Gpo,Opo,Sp,hse,Vpo,Xpo,VI,zpo,Qpo,Wpo,Rp,pse,Hpo,Upo,XI,Jpo,Ypo,Kpo,Pp,use,Zpo,euo,zI,ouo,ruo,tuo,Ns,_se,auo,nuo,QI,suo,luo,WI,iuo,duo,cuo,Bp,bse,fuo,muo,HI,guo,huo,puo,Ip,vse,uuo,_uo,UI,buo,vuo,Fuo,qp,Fse,Tuo,Muo,JI,Euo,Cuo,wuo,Np,Tse,Auo,yuo,YI,Luo,xuo,$uo,jp,Mse,kuo,Suo,KI,Ruo,Puo,Buo,Dp,Ese,Iuo,quo,ZI,Nuo,juo,Duo,Gp,Cse,Guo,Ouo,eq,Vuo,Xuo,zuo,Op,wse,Quo,Wuo,oq,Huo,Uuo,Juo,Vp,Ase,Yuo,Kuo,rq,Zuo,e_o,o_o,Xp,yse,r_o,t_o,tq,a_o,n_o,s_o,zp,Lse,l_o,i_o,aq,d_o,c_o,f_o,Qp,xse,m_o,g_o,nq,h_o,p_o,u_o,Wp,$se,__o,b_o,sq,v_o,F_o,T_o,Hp,kse,M_o,E_o,lq,C_o,w_o,A_o,Up,Sse,y_o,L_o,iq,x_o,$_o,k_o,Jp,Rse,S_o,R_o,dq,P_o,B_o,I_o,Yp,Pse,q_o,N_o,cq,j_o,D_o,G_o,Kp,Bse,O_o,V_o,fq,X_o,z_o,Q_o,Zp,Ise,W_o,H_o,mq,U_o,J_o,Y_o,eu,qse,K_o,Z_o,gq,e2o,o2o,r2o,ou,Nse,t2o,a2o,hq,n2o,s2o,l2o,ru,jse,i2o,d2o,pq,c2o,f2o,m2o,tu,Dse,g2o,h2o,uq,p2o,u2o,_2o,au,Gse,b2o,v2o,_q,F2o,T2o,M2o,nu,Ose,E2o,C2o,bq,w2o,A2o,y2o,su,Vse,L2o,x2o,vq,$2o,k2o,S2o,lu,Xse,R2o,P2o,Fq,B2o,I2o,q2o,iu,zse,N2o,j2o,Tq,D2o,G2o,O2o,du,Qse,V2o,X2o,Mq,z2o,Q2o,W2o,cu,Wse,H2o,U2o,Eq,J2o,Y2o,K2o,fu,Hse,Z2o,e1o,Cq,o1o,r1o,t1o,mu,Use,a1o,n1o,wq,s1o,l1o,i1o,gu,Jse,d1o,c1o,Aq,f1o,m1o,g1o,hu,Yse,h1o,p1o,yq,u1o,_1o,b1o,pu,Kse,v1o,F1o,Lq,T1o,M1o,E1o,uu,Zse,C1o,w1o,xq,A1o,y1o,L1o,_u,ele,x1o,$1o,$q,k1o,S1o,R1o,bu,ole,P1o,B1o,kq,I1o,q1o,N1o,vu,rle,j1o,D1o,Sq,G1o,O1o,V1o,Fu,tle,X1o,z1o,Rq,Q1o,W1o,H1o,Tu,ale,U1o,J1o,Pq,Y1o,K1o,Z1o,Mu,nle,ebo,obo,Bq,rbo,tbo,abo,Eu,sle,nbo,sbo,Iq,lbo,ibo,dbo,Cu,lle,cbo,fbo,qq,mbo,gbo,hbo,wu,ile,pbo,ubo,Nq,_bo,bbo,vbo,Au,dle,Fbo,Tbo,jq,Mbo,Ebo,Cbo,yu,cle,wbo,Abo,Dq,ybo,Lbo,xbo,Lu,fle,$bo,kbo,Gq,Sbo,Rbo,Pbo,xu,mle,Bbo,Ibo,Oq,qbo,Nbo,jbo,$u,gle,Dbo,Gbo,Vq,Obo,Vbo,Xbo,ku,hle,zbo,Qbo,Xq,Wbo,Hbo,Ubo,Su,ple,Jbo,Ybo,zq,Kbo,Zbo,evo,Ru,ule,ovo,rvo,Qq,tvo,avo,nvo,Pu,_le,svo,lvo,Wq,ivo,dvo,cvo,Bu,ble,fvo,mvo,Hq,gvo,hvo,pvo,Iu,vle,uvo,_vo,Uq,bvo,vvo,Fvo,qu,Fle,Tvo,Mvo,Jq,Evo,Cvo,wvo,Nu,Tle,Avo,yvo,Yq,Lvo,xvo,$vo,ju,Mle,kvo,Svo,Kq,Rvo,Pvo,Bvo,Du,Ele,Ivo,qvo,Zq,Nvo,jvo,Dvo,Gu,Cle,Gvo,Ovo,eN,Vvo,Xvo,zvo,Ou,wle,Qvo,Wvo,oN,Hvo,Uvo,Jvo,Vu,Ale,Yvo,Kvo,rN,Zvo,eFo,oFo,Xu,yle,rFo,tFo,tN,aFo,nFo,sFo,zu,Lle,lFo,iFo,aN,dFo,cFo,fFo,Qu,mFo,xle,gFo,hFo,$le,pFo,uFo,Wu,rqe,ki,Hu,kle,WA,_Fo,Sle,bFo,tqe,$o,HA,vFo,Si,FFo,nN,TFo,MFo,sN,EFo,CFo,wFo,UA,AFo,Rle,yFo,LFo,xFo,at,JA,$Fo,Ple,kFo,SFo,Ri,RFo,Ble,PFo,BFo,lN,IFo,qFo,NFo,Uu,jFo,Ue,YA,DFo,Ile,GFo,OFo,ka,VFo,qle,XFo,zFo,Nle,QFo,WFo,jle,HFo,UFo,JFo,G,Ju,Dle,YFo,KFo,iN,ZFo,e6o,o6o,Yu,Gle,r6o,t6o,dN,a6o,n6o,s6o,Ku,Ole,l6o,i6o,cN,d6o,c6o,f6o,Zu,Vle,m6o,g6o,fN,h6o,p6o,u6o,e_,Xle,_6o,b6o,mN,v6o,F6o,T6o,o_,zle,M6o,E6o,gN,C6o,w6o,A6o,r_,Qle,y6o,L6o,hN,x6o,$6o,k6o,t_,Wle,S6o,R6o,pN,P6o,B6o,I6o,a_,Hle,q6o,N6o,uN,j6o,D6o,G6o,n_,Ule,O6o,V6o,_N,X6o,z6o,Q6o,s_,Jle,W6o,H6o,bN,U6o,J6o,Y6o,l_,Yle,K6o,Z6o,vN,eTo,oTo,rTo,i_,Kle,tTo,aTo,FN,nTo,sTo,lTo,d_,Zle,iTo,dTo,TN,cTo,fTo,mTo,c_,eie,gTo,hTo,MN,pTo,uTo,_To,f_,oie,bTo,vTo,EN,FTo,TTo,MTo,m_,rie,ETo,CTo,CN,wTo,ATo,yTo,g_,tie,LTo,xTo,wN,$To,kTo,STo,h_,aie,RTo,PTo,AN,BTo,ITo,qTo,p_,nie,NTo,jTo,yN,DTo,GTo,OTo,u_,sie,VTo,XTo,LN,zTo,QTo,WTo,__,lie,HTo,UTo,xN,JTo,YTo,KTo,b_,iie,ZTo,e8o,$N,o8o,r8o,t8o,v_,die,a8o,n8o,kN,s8o,l8o,i8o,F_,cie,d8o,c8o,SN,f8o,m8o,g8o,T_,fie,h8o,p8o,RN,u8o,_8o,b8o,M_,mie,v8o,F8o,PN,T8o,M8o,E8o,E_,gie,C8o,w8o,BN,A8o,y8o,L8o,C_,hie,x8o,$8o,IN,k8o,S8o,R8o,w_,pie,P8o,B8o,qN,I8o,q8o,N8o,A_,uie,j8o,D8o,NN,G8o,O8o,V8o,y_,_ie,X8o,z8o,jN,Q8o,W8o,H8o,L_,bie,U8o,J8o,DN,Y8o,K8o,Z8o,x_,vie,e7o,o7o,GN,r7o,t7o,a7o,$_,Fie,n7o,s7o,ON,l7o,i7o,d7o,k_,Tie,c7o,f7o,VN,m7o,g7o,h7o,S_,Mie,p7o,u7o,XN,_7o,b7o,v7o,R_,Eie,F7o,T7o,zN,M7o,E7o,C7o,P_,Cie,w7o,A7o,QN,y7o,L7o,x7o,B_,wie,$7o,k7o,WN,S7o,R7o,P7o,I_,B7o,Aie,I7o,q7o,yie,N7o,j7o,q_,aqe,Pi,N_,Lie,KA,D7o,xie,G7o,nqe,ko,ZA,O7o,Bi,V7o,HN,X7o,z7o,UN,Q7o,W7o,H7o,e0,U7o,$ie,J7o,Y7o,K7o,nt,o0,Z7o,kie,eMo,oMo,Ii,rMo,Sie,tMo,aMo,JN,nMo,sMo,lMo,j_,iMo,Je,r0,dMo,Rie,cMo,fMo,Sa,mMo,Pie,gMo,hMo,Bie,pMo,uMo,Iie,_Mo,bMo,vMo,z,D_,qie,FMo,TMo,YN,MMo,EMo,CMo,G_,Nie,wMo,AMo,KN,yMo,LMo,xMo,O_,jie,$Mo,kMo,ZN,SMo,RMo,PMo,V_,Die,BMo,IMo,ej,qMo,NMo,jMo,X_,Gie,DMo,GMo,oj,OMo,VMo,XMo,z_,Oie,zMo,QMo,rj,WMo,HMo,UMo,Q_,Vie,JMo,YMo,tj,KMo,ZMo,e4o,W_,Xie,o4o,r4o,aj,t4o,a4o,n4o,H_,zie,s4o,l4o,nj,i4o,d4o,c4o,U_,Qie,f4o,m4o,sj,g4o,h4o,p4o,J_,Wie,u4o,_4o,lj,b4o,v4o,F4o,Y_,Hie,T4o,M4o,ij,E4o,C4o,w4o,K_,Uie,A4o,y4o,dj,L4o,x4o,$4o,Z_,Jie,k4o,S4o,cj,R4o,P4o,B4o,e2,Yie,I4o,q4o,fj,N4o,j4o,D4o,o2,Kie,G4o,O4o,mj,V4o,X4o,z4o,r2,Zie,Q4o,W4o,gj,H4o,U4o,J4o,t2,ede,Y4o,K4o,hj,Z4o,eEo,oEo,a2,ode,rEo,tEo,pj,aEo,nEo,sEo,n2,rde,lEo,iEo,uj,dEo,cEo,fEo,s2,tde,mEo,gEo,_j,hEo,pEo,uEo,l2,ade,_Eo,bEo,bj,vEo,FEo,TEo,i2,nde,MEo,EEo,vj,CEo,wEo,AEo,d2,sde,yEo,LEo,Fj,xEo,$Eo,kEo,c2,lde,SEo,REo,Tj,PEo,BEo,IEo,f2,ide,qEo,NEo,Mj,jEo,DEo,GEo,m2,dde,OEo,VEo,Ej,XEo,zEo,QEo,g2,cde,WEo,HEo,Cj,UEo,JEo,YEo,h2,fde,KEo,ZEo,wj,e5o,o5o,r5o,p2,mde,t5o,a5o,Aj,n5o,s5o,l5o,u2,gde,i5o,d5o,yj,c5o,f5o,m5o,_2,hde,g5o,h5o,Lj,p5o,u5o,_5o,b2,pde,b5o,v5o,xj,F5o,T5o,M5o,v2,ude,E5o,C5o,$j,w5o,A5o,y5o,F2,_de,L5o,x5o,kj,$5o,k5o,S5o,T2,bde,R5o,P5o,Sj,B5o,I5o,q5o,M2,N5o,vde,j5o,D5o,Fde,G5o,O5o,E2,sqe,qi,C2,Tde,t0,V5o,Mde,X5o,lqe,So,a0,z5o,Ni,Q5o,Rj,W5o,H5o,Pj,U5o,J5o,Y5o,n0,K5o,Ede,Z5o,eCo,oCo,st,s0,rCo,Cde,tCo,aCo,ji,nCo,wde,sCo,lCo,Bj,iCo,dCo,cCo,w2,fCo,Ye,l0,mCo,Ade,gCo,hCo,Ra,pCo,yde,uCo,_Co,Lde,bCo,vCo,xde,FCo,TCo,MCo,Q,A2,$de,ECo,CCo,Ij,wCo,ACo,yCo,y2,kde,LCo,xCo,qj,$Co,kCo,SCo,L2,Sde,RCo,PCo,Nj,BCo,ICo,qCo,x2,Rde,NCo,jCo,jj,DCo,GCo,OCo,$2,Pde,VCo,XCo,Dj,zCo,QCo,WCo,k2,Bde,HCo,UCo,Gj,JCo,YCo,KCo,S2,Ide,ZCo,e3o,Oj,o3o,r3o,t3o,R2,qde,a3o,n3o,Vj,s3o,l3o,i3o,P2,Nde,d3o,c3o,Xj,f3o,m3o,g3o,B2,jde,h3o,p3o,zj,u3o,_3o,b3o,I2,Dde,v3o,F3o,Qj,T3o,M3o,E3o,q2,Gde,C3o,w3o,Wj,A3o,y3o,L3o,N2,Ode,x3o,$3o,Hj,k3o,S3o,R3o,j2,Vde,P3o,B3o,Uj,I3o,q3o,N3o,D2,Xde,j3o,D3o,Jj,G3o,O3o,V3o,G2,zde,X3o,z3o,Yj,Q3o,W3o,H3o,O2,Qde,U3o,J3o,Kj,Y3o,K3o,Z3o,V2,Wde,ewo,owo,Zj,rwo,two,awo,X2,Hde,nwo,swo,eD,lwo,iwo,dwo,z2,Ude,cwo,fwo,oD,mwo,gwo,hwo,Q2,Jde,pwo,uwo,rD,_wo,bwo,vwo,W2,Yde,Fwo,Two,tD,Mwo,Ewo,Cwo,H2,Kde,wwo,Awo,aD,ywo,Lwo,xwo,U2,Zde,$wo,kwo,nD,Swo,Rwo,Pwo,J2,ece,Bwo,Iwo,sD,qwo,Nwo,jwo,Y2,oce,Dwo,Gwo,lD,Owo,Vwo,Xwo,K2,rce,zwo,Qwo,iD,Wwo,Hwo,Uwo,Z2,tce,Jwo,Ywo,dD,Kwo,Zwo,eAo,e1,ace,oAo,rAo,cD,tAo,aAo,nAo,o1,nce,sAo,lAo,fD,iAo,dAo,cAo,r1,sce,fAo,mAo,lce,gAo,hAo,pAo,t1,ice,uAo,_Ao,mD,bAo,vAo,FAo,a1,dce,TAo,MAo,gD,EAo,CAo,wAo,n1,cce,AAo,yAo,hD,LAo,xAo,$Ao,s1,fce,kAo,SAo,pD,RAo,PAo,BAo,l1,IAo,mce,qAo,NAo,gce,jAo,DAo,i1,iqe,Di,d1,hce,i0,GAo,pce,OAo,dqe,Ro,d0,VAo,Gi,XAo,uD,zAo,QAo,_D,WAo,HAo,UAo,c0,JAo,uce,YAo,KAo,ZAo,lt,f0,e0o,_ce,o0o,r0o,Oi,t0o,bce,a0o,n0o,bD,s0o,l0o,i0o,c1,d0o,Ke,m0,c0o,vce,f0o,m0o,Pa,g0o,Fce,h0o,p0o,Tce,u0o,_0o,Mce,b0o,v0o,F0o,he,f1,Ece,T0o,M0o,vD,E0o,C0o,w0o,m1,Cce,A0o,y0o,FD,L0o,x0o,$0o,g1,wce,k0o,S0o,TD,R0o,P0o,B0o,h1,Ace,I0o,q0o,MD,N0o,j0o,D0o,p1,yce,G0o,O0o,ED,V0o,X0o,z0o,u1,Lce,Q0o,W0o,CD,H0o,U0o,J0o,_1,xce,Y0o,K0o,wD,Z0o,eyo,oyo,b1,$ce,ryo,tyo,AD,ayo,nyo,syo,v1,kce,lyo,iyo,yD,dyo,cyo,fyo,F1,Sce,myo,gyo,LD,hyo,pyo,uyo,T1,Rce,_yo,byo,xD,vyo,Fyo,Tyo,M1,Pce,Myo,Eyo,$D,Cyo,wyo,Ayo,E1,Bce,yyo,Lyo,kD,xyo,$yo,kyo,C1,Ice,Syo,Ryo,SD,Pyo,Byo,Iyo,w1,qce,qyo,Nyo,RD,jyo,Dyo,Gyo,A1,Nce,Oyo,Vyo,PD,Xyo,zyo,Qyo,y1,jce,Wyo,Hyo,BD,Uyo,Jyo,Yyo,L1,Kyo,Dce,Zyo,eLo,Gce,oLo,rLo,x1,cqe,Vi,$1,Oce,g0,tLo,Vce,aLo,fqe,Po,h0,nLo,Xi,sLo,ID,lLo,iLo,qD,dLo,cLo,fLo,p0,mLo,Xce,gLo,hLo,pLo,it,u0,uLo,zce,_Lo,bLo,zi,vLo,Qce,FLo,TLo,ND,MLo,ELo,CLo,k1,wLo,Ze,_0,ALo,Wce,yLo,LLo,Ba,xLo,Hce,$Lo,kLo,Uce,SLo,RLo,Jce,PLo,BLo,ILo,q,S1,Yce,qLo,NLo,jD,jLo,DLo,GLo,R1,Kce,OLo,VLo,DD,XLo,zLo,QLo,P1,Zce,WLo,HLo,GD,ULo,JLo,YLo,B1,efe,KLo,ZLo,OD,exo,oxo,rxo,I1,ofe,txo,axo,VD,nxo,sxo,lxo,q1,rfe,ixo,dxo,XD,cxo,fxo,mxo,N1,tfe,gxo,hxo,zD,pxo,uxo,_xo,j1,afe,bxo,vxo,QD,Fxo,Txo,Mxo,D1,nfe,Exo,Cxo,WD,wxo,Axo,yxo,G1,sfe,Lxo,xxo,HD,$xo,kxo,Sxo,O1,lfe,Rxo,Pxo,UD,Bxo,Ixo,qxo,V1,ife,Nxo,jxo,JD,Dxo,Gxo,Oxo,X1,dfe,Vxo,Xxo,YD,zxo,Qxo,Wxo,z1,cfe,Hxo,Uxo,KD,Jxo,Yxo,Kxo,Q1,ffe,Zxo,e9o,ZD,o9o,r9o,t9o,W1,mfe,a9o,n9o,eG,s9o,l9o,i9o,H1,gfe,d9o,c9o,oG,f9o,m9o,g9o,U1,hfe,h9o,p9o,rG,u9o,_9o,b9o,J1,pfe,v9o,F9o,tG,T9o,M9o,E9o,Y1,ufe,C9o,w9o,aG,A9o,y9o,L9o,K1,_fe,x9o,$9o,nG,k9o,S9o,R9o,Z1,bfe,P9o,B9o,sG,I9o,q9o,N9o,eb,vfe,j9o,D9o,lG,G9o,O9o,V9o,ob,Ffe,X9o,z9o,iG,Q9o,W9o,H9o,rb,Tfe,U9o,J9o,dG,Y9o,K9o,Z9o,tb,Mfe,e$o,o$o,cG,r$o,t$o,a$o,ab,Efe,n$o,s$o,fG,l$o,i$o,d$o,nb,Cfe,c$o,f$o,mG,m$o,g$o,h$o,sb,wfe,p$o,u$o,gG,_$o,b$o,v$o,lb,Afe,F$o,T$o,hG,M$o,E$o,C$o,ib,yfe,w$o,A$o,pG,y$o,L$o,x$o,db,Lfe,$$o,k$o,uG,S$o,R$o,P$o,cb,xfe,B$o,I$o,_G,q$o,N$o,j$o,fb,$fe,D$o,G$o,bG,O$o,V$o,X$o,mb,kfe,z$o,Q$o,vG,W$o,H$o,U$o,gb,Sfe,J$o,Y$o,FG,K$o,Z$o,eko,hb,Rfe,oko,rko,TG,tko,ako,nko,pb,Pfe,sko,lko,MG,iko,dko,cko,ub,Bfe,fko,mko,EG,gko,hko,pko,_b,Ife,uko,_ko,CG,bko,vko,Fko,bb,qfe,Tko,Mko,wG,Eko,Cko,wko,vb,Nfe,Ako,yko,AG,Lko,xko,$ko,Fb,jfe,kko,Sko,yG,Rko,Pko,Bko,Tb,Dfe,Iko,qko,LG,Nko,jko,Dko,Mb,Gfe,Gko,Oko,xG,Vko,Xko,zko,Eb,Ofe,Qko,Wko,$G,Hko,Uko,Jko,Cb,Vfe,Yko,Kko,kG,Zko,eSo,oSo,wb,rSo,Xfe,tSo,aSo,zfe,nSo,sSo,Ab,mqe,Qi,yb,Qfe,b0,lSo,Wfe,iSo,gqe,Bo,v0,dSo,Wi,cSo,SG,fSo,mSo,RG,gSo,hSo,pSo,F0,uSo,Hfe,_So,bSo,vSo,dt,T0,FSo,Ufe,TSo,MSo,Hi,ESo,Jfe,CSo,wSo,PG,ASo,ySo,LSo,Lb,xSo,eo,M0,$So,Yfe,kSo,SSo,Ia,RSo,Kfe,PSo,BSo,Zfe,ISo,qSo,eme,NSo,jSo,DSo,Y,xb,ome,GSo,OSo,BG,VSo,XSo,zSo,$b,rme,QSo,WSo,IG,HSo,USo,JSo,kb,tme,YSo,KSo,qG,ZSo,eRo,oRo,Sb,ame,rRo,tRo,NG,aRo,nRo,sRo,Rb,nme,lRo,iRo,jG,dRo,cRo,fRo,Pb,sme,mRo,gRo,DG,hRo,pRo,uRo,Bb,lme,_Ro,bRo,GG,vRo,FRo,TRo,Ib,ime,MRo,ERo,OG,CRo,wRo,ARo,qb,dme,yRo,LRo,VG,xRo,$Ro,kRo,Nb,cme,SRo,RRo,XG,PRo,BRo,IRo,jb,fme,qRo,NRo,zG,jRo,DRo,GRo,Db,mme,ORo,VRo,QG,XRo,zRo,QRo,Gb,gme,WRo,HRo,WG,URo,JRo,YRo,Ob,hme,KRo,ZRo,HG,ePo,oPo,rPo,Vb,pme,tPo,aPo,UG,nPo,sPo,lPo,Xb,ume,iPo,dPo,JG,cPo,fPo,mPo,zb,_me,gPo,hPo,YG,pPo,uPo,_Po,Qb,bme,bPo,vPo,KG,FPo,TPo,MPo,Wb,vme,EPo,CPo,ZG,wPo,APo,yPo,Hb,Fme,LPo,xPo,eO,$Po,kPo,SPo,Ub,Tme,RPo,PPo,oO,BPo,IPo,qPo,Jb,Mme,NPo,jPo,rO,DPo,GPo,OPo,Yb,Eme,VPo,XPo,tO,zPo,QPo,WPo,Kb,Cme,HPo,UPo,aO,JPo,YPo,KPo,Zb,wme,ZPo,eBo,nO,oBo,rBo,tBo,ev,Ame,aBo,nBo,sO,sBo,lBo,iBo,ov,yme,dBo,cBo,lO,fBo,mBo,gBo,rv,Lme,hBo,pBo,iO,uBo,_Bo,bBo,tv,xme,vBo,FBo,dO,TBo,MBo,EBo,av,CBo,$me,wBo,ABo,kme,yBo,LBo,nv,hqe,Ui,sv,Sme,E0,xBo,Rme,$Bo,pqe,Io,C0,kBo,Ji,SBo,cO,RBo,PBo,fO,BBo,IBo,qBo,w0,NBo,Pme,jBo,DBo,GBo,ct,A0,OBo,Bme,VBo,XBo,Yi,zBo,Ime,QBo,WBo,mO,HBo,UBo,JBo,lv,YBo,oo,y0,KBo,qme,ZBo,eIo,qa,oIo,Nme,rIo,tIo,jme,aIo,nIo,Dme,sIo,lIo,iIo,Zr,iv,Gme,dIo,cIo,gO,fIo,mIo,gIo,dv,Ome,hIo,pIo,hO,uIo,_Io,bIo,cv,Vme,vIo,FIo,pO,TIo,MIo,EIo,fv,Xme,CIo,wIo,uO,AIo,yIo,LIo,mv,zme,xIo,$Io,_O,kIo,SIo,RIo,gv,PIo,Qme,BIo,IIo,Wme,qIo,NIo,hv,uqe,Ki,pv,Hme,L0,jIo,Ume,DIo,_qe,qo,x0,GIo,Zi,OIo,bO,VIo,XIo,vO,zIo,QIo,WIo,$0,HIo,Jme,UIo,JIo,YIo,ft,k0,KIo,Yme,ZIo,eqo,ed,oqo,Kme,rqo,tqo,FO,aqo,nqo,sqo,uv,lqo,ro,S0,iqo,Zme,dqo,cqo,Na,fqo,ege,mqo,gqo,oge,hqo,pqo,rge,uqo,_qo,bqo,U,_v,tge,vqo,Fqo,TO,Tqo,Mqo,Eqo,bv,age,Cqo,wqo,MO,Aqo,yqo,Lqo,vv,nge,xqo,$qo,EO,kqo,Sqo,Rqo,Fv,sge,Pqo,Bqo,CO,Iqo,qqo,Nqo,Tv,lge,jqo,Dqo,wO,Gqo,Oqo,Vqo,Mv,ige,Xqo,zqo,AO,Qqo,Wqo,Hqo,Ev,dge,Uqo,Jqo,yO,Yqo,Kqo,Zqo,Cv,cge,eNo,oNo,LO,rNo,tNo,aNo,wv,fge,nNo,sNo,xO,lNo,iNo,dNo,Av,mge,cNo,fNo,$O,mNo,gNo,hNo,yv,gge,pNo,uNo,kO,_No,bNo,vNo,Lv,hge,FNo,TNo,SO,MNo,ENo,CNo,xv,pge,wNo,ANo,RO,yNo,LNo,xNo,$v,uge,$No,kNo,PO,SNo,RNo,PNo,kv,_ge,BNo,INo,BO,qNo,NNo,jNo,Sv,bge,DNo,GNo,IO,ONo,VNo,XNo,Rv,vge,zNo,QNo,qO,WNo,HNo,UNo,Pv,Fge,JNo,YNo,NO,KNo,ZNo,ejo,Bv,Tge,ojo,rjo,jO,tjo,ajo,njo,Iv,Mge,sjo,ljo,DO,ijo,djo,cjo,qv,Ege,fjo,mjo,GO,gjo,hjo,pjo,Nv,Cge,ujo,_jo,OO,bjo,vjo,Fjo,jv,wge,Tjo,Mjo,VO,Ejo,Cjo,wjo,Dv,Age,Ajo,yjo,XO,Ljo,xjo,$jo,Gv,yge,kjo,Sjo,zO,Rjo,Pjo,Bjo,Ov,Lge,Ijo,qjo,QO,Njo,jjo,Djo,Vv,xge,Gjo,Ojo,WO,Vjo,Xjo,zjo,Xv,$ge,Qjo,Wjo,HO,Hjo,Ujo,Jjo,zv,kge,Yjo,Kjo,UO,Zjo,eDo,oDo,Qv,Sge,rDo,tDo,JO,aDo,nDo,sDo,Wv,Rge,lDo,iDo,YO,dDo,cDo,fDo,Hv,Pge,mDo,gDo,KO,hDo,pDo,uDo,Uv,Bge,_Do,bDo,ZO,vDo,FDo,TDo,Jv,MDo,Ige,EDo,CDo,qge,wDo,ADo,Yv,bqe,od,Kv,Nge,R0,yDo,jge,LDo,vqe,No,P0,xDo,rd,$Do,eV,kDo,SDo,oV,RDo,PDo,BDo,B0,IDo,Dge,qDo,NDo,jDo,mt,I0,DDo,Gge,GDo,ODo,td,VDo,Oge,XDo,zDo,rV,QDo,WDo,HDo,Zv,UDo,to,q0,JDo,Vge,YDo,KDo,ja,ZDo,Xge,eGo,oGo,zge,rGo,tGo,Qge,aGo,nGo,sGo,O,eF,Wge,lGo,iGo,tV,dGo,cGo,fGo,oF,Hge,mGo,gGo,aV,hGo,pGo,uGo,rF,Uge,_Go,bGo,nV,vGo,FGo,TGo,tF,Jge,MGo,EGo,sV,CGo,wGo,AGo,aF,Yge,yGo,LGo,lV,xGo,$Go,kGo,nF,Kge,SGo,RGo,iV,PGo,BGo,IGo,sF,Zge,qGo,NGo,dV,jGo,DGo,GGo,lF,ehe,OGo,VGo,cV,XGo,zGo,QGo,iF,ohe,WGo,HGo,fV,UGo,JGo,YGo,dF,rhe,KGo,ZGo,mV,eOo,oOo,rOo,cF,the,tOo,aOo,gV,nOo,sOo,lOo,fF,ahe,iOo,dOo,hV,cOo,fOo,mOo,mF,nhe,gOo,hOo,pV,pOo,uOo,_Oo,gF,she,bOo,vOo,uV,FOo,TOo,MOo,hF,lhe,EOo,COo,_V,wOo,AOo,yOo,pF,ihe,LOo,xOo,bV,$Oo,kOo,SOo,uF,dhe,ROo,POo,vV,BOo,IOo,qOo,_F,che,NOo,jOo,FV,DOo,GOo,OOo,bF,fhe,VOo,XOo,TV,zOo,QOo,WOo,vF,mhe,HOo,UOo,MV,JOo,YOo,KOo,FF,ghe,ZOo,eVo,EV,oVo,rVo,tVo,TF,hhe,aVo,nVo,CV,sVo,lVo,iVo,MF,phe,dVo,cVo,wV,fVo,mVo,gVo,EF,uhe,hVo,pVo,AV,uVo,_Vo,bVo,CF,_he,vVo,FVo,yV,TVo,MVo,EVo,wF,bhe,CVo,wVo,LV,AVo,yVo,LVo,AF,vhe,xVo,$Vo,xV,kVo,SVo,RVo,yF,Fhe,PVo,BVo,$V,IVo,qVo,NVo,LF,The,jVo,DVo,kV,GVo,OVo,VVo,xF,Mhe,XVo,zVo,SV,QVo,WVo,HVo,$F,Ehe,UVo,JVo,RV,YVo,KVo,ZVo,kF,Che,eXo,oXo,PV,rXo,tXo,aXo,SF,whe,nXo,sXo,BV,lXo,iXo,dXo,RF,Ahe,cXo,fXo,IV,mXo,gXo,hXo,PF,yhe,pXo,uXo,qV,_Xo,bXo,vXo,BF,Lhe,FXo,TXo,NV,MXo,EXo,CXo,IF,xhe,wXo,AXo,jV,yXo,LXo,xXo,qF,$he,$Xo,kXo,DV,SXo,RXo,PXo,NF,khe,BXo,IXo,GV,qXo,NXo,jXo,jF,DXo,She,GXo,OXo,Rhe,VXo,XXo,DF,Fqe,ad,GF,Phe,N0,zXo,Bhe,QXo,Tqe,jo,j0,WXo,nd,HXo,OV,UXo,JXo,VV,YXo,KXo,ZXo,D0,ezo,Ihe,ozo,rzo,tzo,gt,G0,azo,qhe,nzo,szo,sd,lzo,Nhe,izo,dzo,XV,czo,fzo,mzo,OF,gzo,ao,O0,hzo,jhe,pzo,uzo,Da,_zo,Dhe,bzo,vzo,Ghe,Fzo,Tzo,Ohe,Mzo,Ezo,Czo,Vhe,VF,Xhe,wzo,Azo,zV,yzo,Lzo,xzo,XF,$zo,zhe,kzo,Szo,Qhe,Rzo,Pzo,zF,Mqe,ld,QF,Whe,V0,Bzo,Hhe,Izo,Eqe,Do,X0,qzo,id,Nzo,QV,jzo,Dzo,WV,Gzo,Ozo,Vzo,z0,Xzo,Uhe,zzo,Qzo,Wzo,ht,Q0,Hzo,Jhe,Uzo,Jzo,dd,Yzo,Yhe,Kzo,Zzo,HV,eQo,oQo,rQo,WF,tQo,no,W0,aQo,Khe,nQo,sQo,Ga,lQo,Zhe,iQo,dQo,epe,cQo,fQo,ope,mQo,gQo,hQo,Fe,HF,rpe,pQo,uQo,UV,_Qo,bQo,vQo,UF,tpe,FQo,TQo,JV,MQo,EQo,CQo,JF,ape,wQo,AQo,YV,yQo,LQo,xQo,js,npe,$Qo,kQo,KV,SQo,RQo,ZV,PQo,BQo,IQo,YF,spe,qQo,NQo,eX,jQo,DQo,GQo,pt,lpe,OQo,VQo,oX,XQo,zQo,rX,QQo,WQo,tX,HQo,UQo,JQo,KF,ipe,YQo,KQo,aX,ZQo,eWo,oWo,ZF,dpe,rWo,tWo,nX,aWo,nWo,sWo,e6,cpe,lWo,iWo,sX,dWo,cWo,fWo,o6,fpe,mWo,gWo,lX,hWo,pWo,uWo,r6,mpe,_Wo,bWo,iX,vWo,FWo,TWo,t6,gpe,MWo,EWo,dX,CWo,wWo,AWo,a6,hpe,yWo,LWo,cX,xWo,$Wo,kWo,n6,SWo,ppe,RWo,PWo,upe,BWo,IWo,s6,Cqe,cd,l6,_pe,H0,qWo,bpe,NWo,wqe,Go,U0,jWo,fd,DWo,fX,GWo,OWo,mX,VWo,XWo,zWo,J0,QWo,vpe,WWo,HWo,UWo,ut,Y0,JWo,Fpe,YWo,KWo,md,ZWo,Tpe,eHo,oHo,gX,rHo,tHo,aHo,i6,nHo,so,K0,sHo,Mpe,lHo,iHo,Oa,dHo,Epe,cHo,fHo,Cpe,mHo,gHo,wpe,hHo,pHo,uHo,Ape,d6,ype,_Ho,bHo,hX,vHo,FHo,THo,c6,MHo,Lpe,EHo,CHo,xpe,wHo,AHo,f6,Aqe,gd,m6,$pe,Z0,yHo,kpe,LHo,yqe,Oo,ey,xHo,hd,$Ho,pX,kHo,SHo,uX,RHo,PHo,BHo,oy,IHo,Spe,qHo,NHo,jHo,_t,ry,DHo,Rpe,GHo,OHo,pd,VHo,Ppe,XHo,zHo,_X,QHo,WHo,HHo,g6,UHo,lo,ty,JHo,Bpe,YHo,KHo,Va,ZHo,Ipe,eUo,oUo,qpe,rUo,tUo,Npe,aUo,nUo,sUo,jpe,h6,Dpe,lUo,iUo,bX,dUo,cUo,fUo,p6,mUo,Gpe,gUo,hUo,Ope,pUo,uUo,u6,Lqe,ud,_6,Vpe,ay,_Uo,Xpe,bUo,xqe,Vo,ny,vUo,_d,FUo,vX,TUo,MUo,FX,EUo,CUo,wUo,sy,AUo,zpe,yUo,LUo,xUo,bt,ly,$Uo,Qpe,kUo,SUo,bd,RUo,Wpe,PUo,BUo,TX,IUo,qUo,NUo,b6,jUo,io,iy,DUo,Hpe,GUo,OUo,Xa,VUo,Upe,XUo,zUo,Jpe,QUo,WUo,Ype,HUo,UUo,JUo,Ne,v6,Kpe,YUo,KUo,MX,ZUo,eJo,oJo,F6,Zpe,rJo,tJo,EX,aJo,nJo,sJo,T6,eue,lJo,iJo,CX,dJo,cJo,fJo,M6,oue,mJo,gJo,wX,hJo,pJo,uJo,E6,rue,_Jo,bJo,AX,vJo,FJo,TJo,C6,tue,MJo,EJo,yX,CJo,wJo,AJo,w6,aue,yJo,LJo,LX,xJo,$Jo,kJo,A6,nue,SJo,RJo,xX,PJo,BJo,IJo,y6,qJo,sue,NJo,jJo,lue,DJo,GJo,L6,$qe,vd,x6,iue,dy,OJo,due,VJo,kqe,Xo,cy,XJo,Fd,zJo,$X,QJo,WJo,kX,HJo,UJo,JJo,fy,YJo,cue,KJo,ZJo,eYo,vt,my,oYo,fue,rYo,tYo,Td,aYo,mue,nYo,sYo,SX,lYo,iYo,dYo,$6,cYo,co,gy,fYo,gue,mYo,gYo,za,hYo,hue,pYo,uYo,pue,_Yo,bYo,uue,vYo,FYo,TYo,Qa,k6,_ue,MYo,EYo,RX,CYo,wYo,AYo,S6,bue,yYo,LYo,PX,xYo,$Yo,kYo,R6,vue,SYo,RYo,BX,PYo,BYo,IYo,P6,Fue,qYo,NYo,IX,jYo,DYo,GYo,B6,OYo,Tue,VYo,XYo,Mue,zYo,QYo,I6,Sqe,Md,q6,Eue,hy,WYo,Cue,HYo,Rqe,zo,py,UYo,Ed,JYo,qX,YYo,KYo,NX,ZYo,eKo,oKo,uy,rKo,wue,tKo,aKo,nKo,Ft,_y,sKo,Aue,lKo,iKo,Cd,dKo,yue,cKo,fKo,jX,mKo,gKo,hKo,N6,pKo,fo,by,uKo,Lue,_Ko,bKo,Wa,vKo,xue,FKo,TKo,$ue,MKo,EKo,kue,CKo,wKo,AKo,je,j6,Sue,yKo,LKo,DX,xKo,$Ko,kKo,D6,Rue,SKo,RKo,GX,PKo,BKo,IKo,G6,Pue,qKo,NKo,OX,jKo,DKo,GKo,O6,Bue,OKo,VKo,VX,XKo,zKo,QKo,V6,Iue,WKo,HKo,XX,UKo,JKo,YKo,X6,que,KKo,ZKo,zX,eZo,oZo,rZo,z6,Nue,tZo,aZo,QX,nZo,sZo,lZo,Q6,jue,iZo,dZo,WX,cZo,fZo,mZo,W6,gZo,Due,hZo,pZo,Gue,uZo,_Zo,H6,Pqe,wd,U6,Oue,vy,bZo,Vue,vZo,Bqe,Qo,Fy,FZo,Ad,TZo,HX,MZo,EZo,UX,CZo,wZo,AZo,Ty,yZo,Xue,LZo,xZo,$Zo,Tt,My,kZo,zue,SZo,RZo,yd,PZo,Que,BZo,IZo,JX,qZo,NZo,jZo,J6,DZo,mo,Ey,GZo,Wue,OZo,VZo,Ha,XZo,Hue,zZo,QZo,Uue,WZo,HZo,Jue,UZo,JZo,YZo,Cy,Y6,Yue,KZo,ZZo,YX,eer,oer,rer,K6,Kue,ter,aer,KX,ner,ser,ler,Z6,ier,Zue,der,cer,e_e,fer,mer,eT,Iqe,Ld,oT,o_e,wy,ger,r_e,her,qqe,Wo,Ay,per,xd,uer,ZX,_er,ber,ez,ver,Fer,Ter,yy,Mer,t_e,Eer,Cer,wer,Mt,Ly,Aer,a_e,yer,Ler,$d,xer,n_e,$er,ker,oz,Ser,Rer,Per,rT,Ber,go,xy,Ier,s_e,qer,Ner,Ua,jer,l_e,Der,Ger,i_e,Oer,Ver,d_e,Xer,zer,Qer,Ja,tT,c_e,Wer,Her,rz,Uer,Jer,Yer,aT,f_e,Ker,Zer,tz,eor,oor,ror,nT,m_e,tor,aor,az,nor,sor,lor,sT,g_e,ior,dor,nz,cor,mor,gor,lT,hor,h_e,por,uor,p_e,_or,bor,iT,Nqe,kd,dT,u_e,$y,vor,__e,For,jqe,Ho,ky,Tor,Sd,Mor,sz,Eor,Cor,lz,wor,Aor,yor,Sy,Lor,b_e,xor,$or,kor,Et,Ry,Sor,v_e,Ror,Por,Rd,Bor,F_e,Ior,qor,iz,Nor,jor,Dor,cT,Gor,ho,Py,Oor,T_e,Vor,Xor,Ya,zor,M_e,Qor,Wor,E_e,Hor,Uor,C_e,Jor,Yor,Kor,Pd,fT,w_e,Zor,err,dz,orr,rrr,trr,mT,A_e,arr,nrr,cz,srr,lrr,irr,gT,y_e,drr,crr,fz,frr,mrr,grr,hT,hrr,L_e,prr,urr,x_e,_rr,brr,pT,Dqe,Bd,uT,$_e,By,vrr,k_e,Frr,Gqe,Uo,Iy,Trr,Id,Mrr,mz,Err,Crr,gz,wrr,Arr,yrr,qy,Lrr,S_e,xrr,$rr,krr,Ct,Ny,Srr,R_e,Rrr,Prr,qd,Brr,P_e,Irr,qrr,hz,Nrr,jrr,Drr,_T,Grr,po,jy,Orr,B_e,Vrr,Xrr,Ka,zrr,I_e,Qrr,Wrr,q_e,Hrr,Urr,N_e,Jrr,Yrr,Krr,Dy,bT,j_e,Zrr,etr,pz,otr,rtr,ttr,vT,D_e,atr,ntr,uz,str,ltr,itr,FT,dtr,G_e,ctr,ftr,O_e,mtr,gtr,TT,Oqe,Nd,MT,V_e,Gy,htr,X_e,ptr,Vqe,Jo,Oy,utr,jd,_tr,_z,btr,vtr,bz,Ftr,Ttr,Mtr,Vy,Etr,z_e,Ctr,wtr,Atr,wt,Xy,ytr,Q_e,Ltr,xtr,Dd,$tr,W_e,ktr,Str,vz,Rtr,Ptr,Btr,ET,Itr,uo,zy,qtr,H_e,Ntr,jtr,Za,Dtr,U_e,Gtr,Otr,J_e,Vtr,Xtr,Y_e,ztr,Qtr,Wtr,K_e,CT,Z_e,Htr,Utr,Fz,Jtr,Ytr,Ktr,wT,Ztr,e2e,ear,oar,o2e,rar,tar,AT,Xqe,Gd,yT,r2e,Qy,aar,t2e,nar,zqe,Yo,Wy,sar,Od,lar,Tz,iar,dar,Mz,car,far,mar,Hy,gar,a2e,har,par,uar,At,Uy,_ar,n2e,bar,Far,Vd,Tar,s2e,Mar,Ear,Ez,Car,war,Aar,LT,yar,_o,Jy,Lar,l2e,xar,$ar,en,kar,i2e,Sar,Rar,d2e,Par,Bar,c2e,Iar,qar,Nar,on,xT,f2e,jar,Dar,Cz,Gar,Oar,Var,$T,m2e,Xar,zar,wz,Qar,War,Har,kT,g2e,Uar,Jar,Az,Yar,Kar,Zar,ST,h2e,enr,onr,yz,rnr,tnr,anr,RT,nnr,p2e,snr,lnr,u2e,inr,dnr,PT,Qqe,Xd,BT,_2e,Yy,cnr,b2e,fnr,Wqe,Ko,Ky,mnr,zd,gnr,Lz,hnr,pnr,xz,unr,_nr,bnr,Zy,vnr,v2e,Fnr,Tnr,Mnr,yt,eL,Enr,F2e,Cnr,wnr,Qd,Anr,T2e,ynr,Lnr,$z,xnr,$nr,knr,IT,Snr,bo,oL,Rnr,M2e,Pnr,Bnr,rn,Inr,E2e,qnr,Nnr,C2e,jnr,Dnr,w2e,Gnr,Onr,Vnr,A2e,qT,y2e,Xnr,znr,kz,Qnr,Wnr,Hnr,NT,Unr,L2e,Jnr,Ynr,x2e,Knr,Znr,jT,Hqe,Wd,DT,$2e,rL,esr,k2e,osr,Uqe,Zo,tL,rsr,Hd,tsr,Sz,asr,nsr,Rz,ssr,lsr,isr,aL,dsr,S2e,csr,fsr,msr,Lt,nL,gsr,R2e,hsr,psr,Ud,usr,P2e,_sr,bsr,Pz,vsr,Fsr,Tsr,GT,Msr,yr,sL,Esr,B2e,Csr,wsr,tn,Asr,I2e,ysr,Lsr,q2e,xsr,$sr,N2e,ksr,Ssr,Rsr,j,OT,j2e,Psr,Bsr,Bz,Isr,qsr,Nsr,VT,D2e,jsr,Dsr,Iz,Gsr,Osr,Vsr,XT,G2e,Xsr,zsr,qz,Qsr,Wsr,Hsr,zT,O2e,Usr,Jsr,Nz,Ysr,Ksr,Zsr,QT,V2e,elr,olr,jz,rlr,tlr,alr,WT,X2e,nlr,slr,Dz,llr,ilr,dlr,HT,z2e,clr,flr,Gz,mlr,glr,hlr,UT,Q2e,plr,ulr,Oz,_lr,blr,vlr,JT,W2e,Flr,Tlr,Vz,Mlr,Elr,Clr,YT,H2e,wlr,Alr,Xz,ylr,Llr,xlr,KT,U2e,$lr,klr,zz,Slr,Rlr,Plr,ZT,J2e,Blr,Ilr,Qz,qlr,Nlr,jlr,e8,Y2e,Dlr,Glr,Wz,Olr,Vlr,Xlr,o8,K2e,zlr,Qlr,Hz,Wlr,Hlr,Ulr,r8,Z2e,Jlr,Ylr,Uz,Klr,Zlr,eir,t8,e1e,oir,rir,Jz,tir,air,nir,a8,o1e,sir,lir,Yz,iir,dir,cir,Ds,r1e,fir,mir,Kz,gir,hir,Zz,pir,uir,_ir,n8,t1e,bir,vir,eQ,Fir,Tir,Mir,s8,a1e,Eir,Cir,oQ,wir,Air,yir,l8,n1e,Lir,xir,rQ,$ir,kir,Sir,i8,s1e,Rir,Pir,tQ,Bir,Iir,qir,d8,l1e,Nir,jir,aQ,Dir,Gir,Oir,c8,i1e,Vir,Xir,nQ,zir,Qir,Wir,f8,d1e,Hir,Uir,sQ,Jir,Yir,Kir,m8,c1e,Zir,edr,lQ,odr,rdr,tdr,g8,f1e,adr,ndr,iQ,sdr,ldr,idr,h8,m1e,ddr,cdr,dQ,fdr,mdr,gdr,p8,g1e,hdr,pdr,cQ,udr,_dr,bdr,u8,h1e,vdr,Fdr,fQ,Tdr,Mdr,Edr,_8,p1e,Cdr,wdr,mQ,Adr,ydr,Ldr,b8,u1e,xdr,$dr,gQ,kdr,Sdr,Rdr,v8,_1e,Pdr,Bdr,hQ,Idr,qdr,Ndr,F8,b1e,jdr,Ddr,pQ,Gdr,Odr,Vdr,T8,v1e,Xdr,zdr,uQ,Qdr,Wdr,Hdr,M8,F1e,Udr,Jdr,_Q,Ydr,Kdr,Zdr,E8,T1e,ecr,ocr,bQ,rcr,tcr,acr,C8,M1e,ncr,scr,vQ,lcr,icr,dcr,w8,E1e,ccr,fcr,FQ,mcr,gcr,hcr,A8,C1e,pcr,ucr,TQ,_cr,bcr,vcr,y8,w1e,Fcr,Tcr,MQ,Mcr,Ecr,Ccr,L8,A1e,wcr,Acr,EQ,ycr,Lcr,xcr,x8,y1e,$cr,kcr,CQ,Scr,Rcr,Pcr,$8,L1e,Bcr,Icr,wQ,qcr,Ncr,jcr,k8,x1e,Dcr,Gcr,AQ,Ocr,Vcr,Xcr,S8,Jqe,Jd,R8,$1e,lL,zcr,k1e,Qcr,Yqe,er,iL,Wcr,Yd,Hcr,yQ,Ucr,Jcr,LQ,Ycr,Kcr,Zcr,dL,efr,S1e,ofr,rfr,tfr,xt,cL,afr,R1e,nfr,sfr,Kd,lfr,P1e,ifr,dfr,xQ,cfr,ffr,mfr,P8,gfr,Lr,fL,hfr,B1e,pfr,ufr,an,_fr,I1e,bfr,vfr,q1e,Ffr,Tfr,N1e,Mfr,Efr,Cfr,se,B8,j1e,wfr,Afr,$Q,yfr,Lfr,xfr,I8,D1e,$fr,kfr,kQ,Sfr,Rfr,Pfr,q8,G1e,Bfr,Ifr,SQ,qfr,Nfr,jfr,N8,O1e,Dfr,Gfr,RQ,Ofr,Vfr,Xfr,j8,V1e,zfr,Qfr,PQ,Wfr,Hfr,Ufr,D8,X1e,Jfr,Yfr,BQ,Kfr,Zfr,emr,G8,z1e,omr,rmr,IQ,tmr,amr,nmr,O8,Q1e,smr,lmr,qQ,imr,dmr,cmr,V8,W1e,fmr,mmr,NQ,gmr,hmr,pmr,X8,H1e,umr,_mr,jQ,bmr,vmr,Fmr,z8,U1e,Tmr,Mmr,DQ,Emr,Cmr,wmr,Q8,J1e,Amr,ymr,GQ,Lmr,xmr,$mr,W8,Y1e,kmr,Smr,OQ,Rmr,Pmr,Bmr,H8,K1e,Imr,qmr,VQ,Nmr,jmr,Dmr,U8,Z1e,Gmr,Omr,XQ,Vmr,Xmr,zmr,J8,ebe,Qmr,Wmr,zQ,Hmr,Umr,Jmr,Y8,obe,Ymr,Kmr,QQ,Zmr,egr,ogr,K8,rbe,rgr,tgr,WQ,agr,ngr,sgr,Z8,tbe,lgr,igr,HQ,dgr,cgr,fgr,e7,abe,mgr,ggr,UQ,hgr,pgr,ugr,o7,nbe,_gr,bgr,JQ,vgr,Fgr,Tgr,r7,sbe,Mgr,Egr,YQ,Cgr,wgr,Agr,t7,lbe,ygr,Lgr,KQ,xgr,$gr,kgr,a7,Kqe,Zd,n7,ibe,mL,Sgr,dbe,Rgr,Zqe,or,gL,Pgr,ec,Bgr,ZQ,Igr,qgr,eW,Ngr,jgr,Dgr,hL,Ggr,cbe,Ogr,Vgr,Xgr,$t,pL,zgr,fbe,Qgr,Wgr,oc,Hgr,mbe,Ugr,Jgr,oW,Ygr,Kgr,Zgr,s7,ehr,xr,uL,ohr,gbe,rhr,thr,nn,ahr,hbe,nhr,shr,pbe,lhr,ihr,ube,dhr,chr,fhr,Te,l7,_be,mhr,ghr,rW,hhr,phr,uhr,i7,bbe,_hr,bhr,tW,vhr,Fhr,Thr,d7,vbe,Mhr,Ehr,aW,Chr,whr,Ahr,c7,Fbe,yhr,Lhr,nW,xhr,$hr,khr,f7,Tbe,Shr,Rhr,sW,Phr,Bhr,Ihr,m7,Mbe,qhr,Nhr,lW,jhr,Dhr,Ghr,g7,Ebe,Ohr,Vhr,iW,Xhr,zhr,Qhr,h7,Cbe,Whr,Hhr,dW,Uhr,Jhr,Yhr,p7,wbe,Khr,Zhr,cW,epr,opr,rpr,u7,Abe,tpr,apr,fW,npr,spr,lpr,_7,ybe,ipr,dpr,mW,cpr,fpr,mpr,b7,Lbe,gpr,hpr,gW,ppr,upr,_pr,v7,eNe,rc,F7,xbe,_L,bpr,$be,vpr,oNe,rr,bL,Fpr,tc,Tpr,hW,Mpr,Epr,pW,Cpr,wpr,Apr,vL,ypr,kbe,Lpr,xpr,$pr,kt,FL,kpr,Sbe,Spr,Rpr,ac,Ppr,Rbe,Bpr,Ipr,uW,qpr,Npr,jpr,T7,Dpr,$r,TL,Gpr,Pbe,Opr,Vpr,sn,Xpr,Bbe,zpr,Qpr,Ibe,Wpr,Hpr,qbe,Upr,Jpr,Ypr,nc,M7,Nbe,Kpr,Zpr,_W,eur,our,rur,E7,jbe,tur,aur,bW,nur,sur,lur,C7,Dbe,iur,dur,vW,cur,fur,mur,w7,rNe,sc,A7,Gbe,ML,gur,Obe,hur,tNe,tr,EL,pur,lc,uur,FW,_ur,bur,TW,vur,Fur,Tur,CL,Mur,Vbe,Eur,Cur,wur,St,wL,Aur,Xbe,yur,Lur,ic,xur,zbe,$ur,kur,MW,Sur,Rur,Pur,y7,Bur,kr,AL,Iur,Qbe,qur,Nur,ln,jur,Wbe,Dur,Gur,Hbe,Our,Vur,Ube,Xur,zur,Qur,ie,L7,Jbe,Wur,Hur,EW,Uur,Jur,Yur,x7,Ybe,Kur,Zur,CW,e_r,o_r,r_r,$7,Kbe,t_r,a_r,wW,n_r,s_r,l_r,k7,Zbe,i_r,d_r,AW,c_r,f_r,m_r,S7,eve,g_r,h_r,yW,p_r,u_r,__r,R7,ove,b_r,v_r,LW,F_r,T_r,M_r,P7,rve,E_r,C_r,xW,w_r,A_r,y_r,B7,tve,L_r,x_r,$W,$_r,k_r,S_r,I7,ave,R_r,P_r,kW,B_r,I_r,q_r,q7,nve,N_r,j_r,SW,D_r,G_r,O_r,N7,sve,V_r,X_r,RW,z_r,Q_r,W_r,j7,lve,H_r,U_r,PW,J_r,Y_r,K_r,D7,ive,Z_r,e2r,BW,o2r,r2r,t2r,G7,dve,a2r,n2r,IW,s2r,l2r,i2r,O7,cve,d2r,c2r,qW,f2r,m2r,g2r,V7,fve,h2r,p2r,NW,u2r,_2r,b2r,X7,mve,v2r,F2r,jW,T2r,M2r,E2r,z7,gve,C2r,w2r,DW,A2r,y2r,L2r,Q7,hve,x2r,$2r,GW,k2r,S2r,R2r,W7,pve,P2r,B2r,OW,I2r,q2r,N2r,H7,aNe,dc,U7,uve,yL,j2r,_ve,D2r,nNe,ar,LL,G2r,cc,O2r,VW,V2r,X2r,XW,z2r,Q2r,W2r,xL,H2r,bve,U2r,J2r,Y2r,Rt,$L,K2r,vve,Z2r,e1r,fc,o1r,Fve,r1r,t1r,zW,a1r,n1r,s1r,J7,l1r,Sr,kL,i1r,Tve,d1r,c1r,dn,f1r,Mve,m1r,g1r,Eve,h1r,p1r,Cve,u1r,_1r,b1r,ye,Y7,wve,v1r,F1r,QW,T1r,M1r,E1r,K7,Ave,C1r,w1r,WW,A1r,y1r,L1r,Z7,yve,x1r,$1r,HW,k1r,S1r,R1r,eM,Lve,P1r,B1r,UW,I1r,q1r,N1r,oM,xve,j1r,D1r,JW,G1r,O1r,V1r,rM,$ve,X1r,z1r,YW,Q1r,W1r,H1r,tM,kve,U1r,J1r,KW,Y1r,K1r,Z1r,aM,Sve,ebr,obr,ZW,rbr,tbr,abr,nM,Rve,nbr,sbr,eH,lbr,ibr,dbr,sM,Pve,cbr,fbr,oH,mbr,gbr,hbr,lM,sNe,mc,iM,Bve,SL,pbr,Ive,ubr,lNe,nr,RL,_br,gc,bbr,rH,vbr,Fbr,tH,Tbr,Mbr,Ebr,PL,Cbr,qve,wbr,Abr,ybr,Pt,BL,Lbr,Nve,xbr,$br,hc,kbr,jve,Sbr,Rbr,aH,Pbr,Bbr,Ibr,dM,qbr,Rr,IL,Nbr,Dve,jbr,Dbr,cn,Gbr,Gve,Obr,Vbr,Ove,Xbr,zbr,Vve,Qbr,Wbr,Hbr,oe,cM,Xve,Ubr,Jbr,nH,Ybr,Kbr,Zbr,fM,zve,evr,ovr,sH,rvr,tvr,avr,mM,Qve,nvr,svr,lH,lvr,ivr,dvr,gM,Wve,cvr,fvr,iH,mvr,gvr,hvr,hM,Hve,pvr,uvr,dH,_vr,bvr,vvr,pM,Uve,Fvr,Tvr,cH,Mvr,Evr,Cvr,uM,Jve,wvr,Avr,fH,yvr,Lvr,xvr,_M,Yve,$vr,kvr,mH,Svr,Rvr,Pvr,bM,Kve,Bvr,Ivr,gH,qvr,Nvr,jvr,vM,Zve,Dvr,Gvr,hH,Ovr,Vvr,Xvr,FM,eFe,zvr,Qvr,pH,Wvr,Hvr,Uvr,TM,oFe,Jvr,Yvr,uH,Kvr,Zvr,eFr,MM,rFe,oFr,rFr,_H,tFr,aFr,nFr,EM,tFe,sFr,lFr,bH,iFr,dFr,cFr,CM,aFe,fFr,mFr,vH,gFr,hFr,pFr,wM,nFe,uFr,_Fr,FH,bFr,vFr,FFr,AM,sFe,TFr,MFr,TH,EFr,CFr,wFr,yM,lFe,AFr,yFr,MH,LFr,xFr,$Fr,LM,iFe,kFr,SFr,EH,RFr,PFr,BFr,xM,dFe,IFr,qFr,CH,NFr,jFr,DFr,$M,cFe,GFr,OFr,wH,VFr,XFr,zFr,kM,fFe,QFr,WFr,AH,HFr,UFr,JFr,SM,mFe,YFr,KFr,yH,ZFr,e6r,o6r,RM,gFe,r6r,t6r,LH,a6r,n6r,s6r,PM,hFe,l6r,i6r,xH,d6r,c6r,f6r,BM,pFe,m6r,g6r,$H,h6r,p6r,u6r,IM,iNe,pc,qM,uFe,qL,_6r,_Fe,b6r,dNe,sr,NL,v6r,uc,F6r,kH,T6r,M6r,SH,E6r,C6r,w6r,jL,A6r,bFe,y6r,L6r,x6r,Bt,DL,$6r,vFe,k6r,S6r,_c,R6r,FFe,P6r,B6r,RH,I6r,q6r,N6r,NM,j6r,Pr,GL,D6r,TFe,G6r,O6r,fn,V6r,MFe,X6r,z6r,EFe,Q6r,W6r,CFe,H6r,U6r,J6r,pe,jM,wFe,Y6r,K6r,PH,Z6r,eTr,oTr,DM,AFe,rTr,tTr,BH,aTr,nTr,sTr,GM,yFe,lTr,iTr,IH,dTr,cTr,fTr,OM,LFe,mTr,gTr,qH,hTr,pTr,uTr,VM,xFe,_Tr,bTr,NH,vTr,FTr,TTr,XM,$Fe,MTr,ETr,jH,CTr,wTr,ATr,zM,kFe,yTr,LTr,DH,xTr,$Tr,kTr,QM,SFe,STr,RTr,GH,PTr,BTr,ITr,WM,RFe,qTr,NTr,OH,jTr,DTr,GTr,HM,PFe,OTr,VTr,VH,XTr,zTr,QTr,UM,BFe,WTr,HTr,XH,UTr,JTr,YTr,JM,IFe,KTr,ZTr,zH,e8r,o8r,r8r,YM,qFe,t8r,a8r,QH,n8r,s8r,l8r,KM,NFe,i8r,d8r,WH,c8r,f8r,m8r,ZM,jFe,g8r,h8r,HH,p8r,u8r,_8r,e4,DFe,b8r,v8r,UH,F8r,T8r,M8r,o4,GFe,E8r,C8r,JH,w8r,A8r,y8r,r4,cNe,bc,t4,OFe,OL,L8r,VFe,x8r,fNe,lr,VL,$8r,vc,k8r,YH,S8r,R8r,KH,P8r,B8r,I8r,XL,q8r,XFe,N8r,j8r,D8r,It,zL,G8r,zFe,O8r,V8r,Fc,X8r,QFe,z8r,Q8r,ZH,W8r,H8r,U8r,a4,J8r,Br,QL,Y8r,WFe,K8r,Z8r,mn,e7r,HFe,o7r,r7r,UFe,t7r,a7r,JFe,n7r,s7r,l7r,WL,n4,YFe,i7r,d7r,eU,c7r,f7r,m7r,s4,KFe,g7r,h7r,oU,p7r,u7r,_7r,l4,mNe,Tc,i4,ZFe,HL,b7r,e6e,v7r,gNe,ir,UL,F7r,Mc,T7r,rU,M7r,E7r,tU,C7r,w7r,A7r,JL,y7r,o6e,L7r,x7r,$7r,qt,YL,k7r,r6e,S7r,R7r,Ec,P7r,t6e,B7r,I7r,aU,q7r,N7r,j7r,d4,D7r,Ir,KL,G7r,a6e,O7r,V7r,gn,X7r,n6e,z7r,Q7r,s6e,W7r,H7r,l6e,U7r,J7r,Y7r,i6e,c4,d6e,K7r,Z7r,nU,eMr,oMr,rMr,f4,hNe,Cc,m4,c6e,ZL,tMr,f6e,aMr,pNe,dr,ex,nMr,wc,sMr,sU,lMr,iMr,lU,dMr,cMr,fMr,ox,mMr,m6e,gMr,hMr,pMr,Nt,rx,uMr,g6e,_Mr,bMr,Ac,vMr,h6e,FMr,TMr,iU,MMr,EMr,CMr,g4,wMr,qr,tx,AMr,p6e,yMr,LMr,hn,xMr,u6e,$Mr,kMr,_6e,SMr,RMr,b6e,PMr,BMr,IMr,de,h4,v6e,qMr,NMr,dU,jMr,DMr,GMr,p4,F6e,OMr,VMr,cU,XMr,zMr,QMr,u4,T6e,WMr,HMr,fU,UMr,JMr,YMr,_4,M6e,KMr,ZMr,mU,e4r,o4r,r4r,b4,E6e,t4r,a4r,gU,n4r,s4r,l4r,v4,C6e,i4r,d4r,hU,c4r,f4r,m4r,F4,w6e,g4r,h4r,pU,p4r,u4r,_4r,T4,A6e,b4r,v4r,uU,F4r,T4r,M4r,M4,y6e,E4r,C4r,_U,w4r,A4r,y4r,E4,L6e,L4r,x4r,bU,$4r,k4r,S4r,C4,x6e,R4r,P4r,vU,B4r,I4r,q4r,w4,$6e,N4r,j4r,FU,D4r,G4r,O4r,A4,k6e,V4r,X4r,TU,z4r,Q4r,W4r,y4,S6e,H4r,U4r,MU,J4r,Y4r,K4r,L4,R6e,Z4r,eEr,EU,oEr,rEr,tEr,x4,P6e,aEr,nEr,CU,sEr,lEr,iEr,$4,B6e,dEr,cEr,wU,fEr,mEr,gEr,k4,I6e,hEr,pEr,AU,uEr,_Er,bEr,S4,q6e,vEr,FEr,yU,TEr,MEr,EEr,R4,N6e,CEr,wEr,LU,AEr,yEr,LEr,P4,uNe,yc,B4,j6e,ax,xEr,D6e,$Er,_Ne,cr,nx,kEr,Lc,SEr,xU,REr,PEr,$U,BEr,IEr,qEr,sx,NEr,G6e,jEr,DEr,GEr,jt,lx,OEr,O6e,VEr,XEr,xc,zEr,V6e,QEr,WEr,kU,HEr,UEr,JEr,I4,YEr,Nr,ix,KEr,X6e,ZEr,e5r,pn,o5r,z6e,r5r,t5r,Q6e,a5r,n5r,W6e,s5r,l5r,i5r,ce,q4,H6e,d5r,c5r,SU,f5r,m5r,g5r,N4,U6e,h5r,p5r,RU,u5r,_5r,b5r,j4,J6e,v5r,F5r,PU,T5r,M5r,E5r,D4,Y6e,C5r,w5r,BU,A5r,y5r,L5r,G4,K6e,x5r,$5r,IU,k5r,S5r,R5r,O4,Z6e,P5r,B5r,qU,I5r,q5r,N5r,V4,eTe,j5r,D5r,NU,G5r,O5r,V5r,X4,oTe,X5r,z5r,jU,Q5r,W5r,H5r,z4,rTe,U5r,J5r,DU,Y5r,K5r,Z5r,Q4,tTe,eCr,oCr,GU,rCr,tCr,aCr,W4,aTe,nCr,sCr,OU,lCr,iCr,dCr,H4,nTe,cCr,fCr,VU,mCr,gCr,hCr,U4,sTe,pCr,uCr,XU,_Cr,bCr,vCr,J4,lTe,FCr,TCr,zU,MCr,ECr,CCr,Y4,iTe,wCr,ACr,QU,yCr,LCr,xCr,K4,dTe,$Cr,kCr,WU,SCr,RCr,PCr,Z4,cTe,BCr,ICr,HU,qCr,NCr,jCr,eE,fTe,DCr,GCr,UU,OCr,VCr,XCr,oE,mTe,zCr,QCr,JU,WCr,HCr,UCr,rE,gTe,JCr,YCr,YU,KCr,ZCr,e3r,tE,bNe,$c,aE,hTe,dx,o3r,pTe,r3r,vNe,fr,cx,t3r,kc,a3r,KU,n3r,s3r,ZU,l3r,i3r,d3r,fx,c3r,uTe,f3r,m3r,g3r,Dt,mx,h3r,_Te,p3r,u3r,Sc,_3r,bTe,b3r,v3r,eJ,F3r,T3r,M3r,nE,E3r,jr,gx,C3r,vTe,w3r,A3r,un,y3r,FTe,L3r,x3r,TTe,$3r,k3r,MTe,S3r,R3r,P3r,ETe,sE,CTe,B3r,I3r,oJ,q3r,N3r,j3r,lE,FNe,Rc,iE,wTe,hx,D3r,ATe,G3r,TNe,mr,px,O3r,Pc,V3r,rJ,X3r,z3r,tJ,Q3r,W3r,H3r,ux,U3r,yTe,J3r,Y3r,K3r,Gt,_x,Z3r,LTe,ewr,owr,Bc,rwr,xTe,twr,awr,aJ,nwr,swr,lwr,dE,iwr,Dr,bx,dwr,$Te,cwr,fwr,_n,mwr,kTe,gwr,hwr,STe,pwr,uwr,RTe,_wr,bwr,vwr,PTe,cE,BTe,Fwr,Twr,nJ,Mwr,Ewr,Cwr,fE,MNe,Ic,mE,ITe,vx,wwr,qTe,Awr,ENe,gr,Fx,ywr,qc,Lwr,sJ,xwr,$wr,lJ,kwr,Swr,Rwr,Tx,Pwr,NTe,Bwr,Iwr,qwr,Ot,Mx,Nwr,jTe,jwr,Dwr,Nc,Gwr,DTe,Owr,Vwr,iJ,Xwr,zwr,Qwr,gE,Wwr,Gr,Ex,Hwr,GTe,Uwr,Jwr,bn,Ywr,OTe,Kwr,Zwr,VTe,eAr,oAr,XTe,rAr,tAr,aAr,re,hE,zTe,nAr,sAr,dJ,lAr,iAr,dAr,pE,QTe,cAr,fAr,cJ,mAr,gAr,hAr,uE,WTe,pAr,uAr,fJ,_Ar,bAr,vAr,_E,HTe,FAr,TAr,mJ,MAr,EAr,CAr,bE,UTe,wAr,AAr,gJ,yAr,LAr,xAr,vE,JTe,$Ar,kAr,hJ,SAr,RAr,PAr,FE,YTe,BAr,IAr,pJ,qAr,NAr,jAr,TE,KTe,DAr,GAr,uJ,OAr,VAr,XAr,ME,ZTe,zAr,QAr,_J,WAr,HAr,UAr,EE,e8e,JAr,YAr,bJ,KAr,ZAr,e0r,CE,o8e,o0r,r0r,vJ,t0r,a0r,n0r,wE,r8e,s0r,l0r,FJ,i0r,d0r,c0r,AE,t8e,f0r,m0r,TJ,g0r,h0r,p0r,yE,a8e,u0r,_0r,MJ,b0r,v0r,F0r,LE,n8e,T0r,M0r,EJ,E0r,C0r,w0r,xE,s8e,A0r,y0r,CJ,L0r,x0r,$0r,$E,l8e,k0r,S0r,wJ,R0r,P0r,B0r,kE,i8e,I0r,q0r,AJ,N0r,j0r,D0r,SE,d8e,G0r,O0r,yJ,V0r,X0r,z0r,RE,c8e,Q0r,W0r,LJ,H0r,U0r,J0r,PE,f8e,Y0r,K0r,xJ,Z0r,eyr,oyr,BE,m8e,ryr,tyr,$J,ayr,nyr,syr,IE,g8e,lyr,iyr,kJ,dyr,cyr,fyr,qE,h8e,myr,gyr,SJ,hyr,pyr,uyr,NE,p8e,_yr,byr,RJ,vyr,Fyr,Tyr,jE,CNe,jc,DE,u8e,Cx,Myr,_8e,Eyr,wNe,hr,wx,Cyr,Dc,wyr,PJ,Ayr,yyr,BJ,Lyr,xyr,$yr,Ax,kyr,b8e,Syr,Ryr,Pyr,Vt,yx,Byr,v8e,Iyr,qyr,Gc,Nyr,F8e,jyr,Dyr,IJ,Gyr,Oyr,Vyr,GE,Xyr,Or,Lx,zyr,T8e,Qyr,Wyr,vn,Hyr,M8e,Uyr,Jyr,E8e,Yyr,Kyr,C8e,Zyr,eLr,oLr,ke,OE,w8e,rLr,tLr,qJ,aLr,nLr,sLr,VE,A8e,lLr,iLr,NJ,dLr,cLr,fLr,XE,y8e,mLr,gLr,jJ,hLr,pLr,uLr,zE,L8e,_Lr,bLr,DJ,vLr,FLr,TLr,QE,x8e,MLr,ELr,GJ,CLr,wLr,ALr,WE,$8e,yLr,LLr,OJ,xLr,$Lr,kLr,HE,k8e,SLr,RLr,VJ,PLr,BLr,ILr,UE,S8e,qLr,NLr,XJ,jLr,DLr,GLr,JE,R8e,OLr,VLr,zJ,XLr,zLr,QLr,YE,ANe,Oc,KE,P8e,xx,WLr,B8e,HLr,yNe,pr,$x,ULr,Vc,JLr,QJ,YLr,KLr,WJ,ZLr,exr,oxr,kx,rxr,I8e,txr,axr,nxr,Xt,Sx,sxr,q8e,lxr,ixr,Xc,dxr,N8e,cxr,fxr,HJ,mxr,gxr,hxr,ZE,pxr,Vr,Rx,uxr,j8e,_xr,bxr,Fn,vxr,D8e,Fxr,Txr,G8e,Mxr,Exr,O8e,Cxr,wxr,Axr,Me,e5,V8e,yxr,Lxr,UJ,xxr,$xr,kxr,o5,X8e,Sxr,Rxr,JJ,Pxr,Bxr,Ixr,r5,z8e,qxr,Nxr,YJ,jxr,Dxr,Gxr,t5,Q8e,Oxr,Vxr,KJ,Xxr,zxr,Qxr,a5,W8e,Wxr,Hxr,ZJ,Uxr,Jxr,Yxr,n5,H8e,Kxr,Zxr,eY,e9r,o9r,r9r,s5,U8e,t9r,a9r,oY,n9r,s9r,l9r,l5,J8e,i9r,d9r,rY,c9r,f9r,m9r,i5,Y8e,g9r,h9r,tY,p9r,u9r,_9r,d5,K8e,b9r,v9r,aY,F9r,T9r,M9r,c5,Z8e,E9r,C9r,nY,w9r,A9r,y9r,f5,e7e,L9r,x9r,sY,$9r,k9r,S9r,m5,LNe,zc,g5,o7e,Px,R9r,r7e,P9r,xNe,ur,Bx,B9r,Qc,I9r,lY,q9r,N9r,iY,j9r,D9r,G9r,Ix,O9r,t7e,V9r,X9r,z9r,zt,qx,Q9r,a7e,W9r,H9r,Wc,U9r,n7e,J9r,Y9r,dY,K9r,Z9r,e$r,h5,o$r,Xr,Nx,r$r,s7e,t$r,a$r,Tn,n$r,l7e,s$r,l$r,i7e,i$r,d$r,d7e,c$r,f$r,m$r,Le,p5,c7e,g$r,h$r,cY,p$r,u$r,_$r,u5,f7e,b$r,v$r,fY,F$r,T$r,M$r,_5,m7e,E$r,C$r,mY,w$r,A$r,y$r,b5,g7e,L$r,x$r,gY,$$r,k$r,S$r,v5,h7e,R$r,P$r,hY,B$r,I$r,q$r,F5,p7e,N$r,j$r,pY,D$r,G$r,O$r,T5,u7e,V$r,X$r,uY,z$r,Q$r,W$r,M5,_7e,H$r,U$r,_Y,J$r,Y$r,K$r,E5,b7e,Z$r,ekr,bY,okr,rkr,tkr,C5,v7e,akr,nkr,vY,skr,lkr,ikr,w5,$Ne,Hc,A5,F7e,jx,dkr,T7e,ckr,kNe,_r,Dx,fkr,Uc,mkr,FY,gkr,hkr,TY,pkr,ukr,_kr,Gx,bkr,M7e,vkr,Fkr,Tkr,Qt,Ox,Mkr,E7e,Ekr,Ckr,Jc,wkr,C7e,Akr,ykr,MY,Lkr,xkr,$kr,y5,kkr,zr,Vx,Skr,w7e,Rkr,Pkr,Mn,Bkr,A7e,Ikr,qkr,y7e,Nkr,jkr,L7e,Dkr,Gkr,Okr,Se,L5,x7e,Vkr,Xkr,EY,zkr,Qkr,Wkr,x5,$7e,Hkr,Ukr,CY,Jkr,Ykr,Kkr,$5,k7e,Zkr,eSr,wY,oSr,rSr,tSr,k5,S7e,aSr,nSr,AY,sSr,lSr,iSr,S5,R7e,dSr,cSr,yY,fSr,mSr,gSr,R5,P7e,hSr,pSr,LY,uSr,_Sr,bSr,P5,B7e,vSr,FSr,xY,TSr,MSr,ESr,B5,I7e,CSr,wSr,$Y,ASr,ySr,LSr,I5,q7e,xSr,$Sr,kY,kSr,SSr,RSr,q5,SNe,Yc,N5,N7e,Xx,PSr,j7e,BSr,RNe,br,zx,ISr,Kc,qSr,SY,NSr,jSr,RY,DSr,GSr,OSr,Qx,VSr,D7e,XSr,zSr,QSr,Wt,Wx,WSr,G7e,HSr,USr,Zc,JSr,O7e,YSr,KSr,PY,ZSr,eRr,oRr,j5,rRr,Qr,Hx,tRr,V7e,aRr,nRr,En,sRr,X7e,lRr,iRr,z7e,dRr,cRr,Q7e,fRr,mRr,gRr,xe,D5,W7e,hRr,pRr,BY,uRr,_Rr,bRr,G5,H7e,vRr,FRr,IY,TRr,MRr,ERr,O5,U7e,CRr,wRr,qY,ARr,yRr,LRr,V5,J7e,xRr,$Rr,NY,kRr,SRr,RRr,X5,Y7e,PRr,BRr,jY,IRr,qRr,NRr,z5,K7e,jRr,DRr,DY,GRr,ORr,VRr,Q5,Z7e,XRr,zRr,GY,QRr,WRr,HRr,W5,eMe,URr,JRr,OY,YRr,KRr,ZRr,H5,oMe,ePr,oPr,VY,rPr,tPr,aPr,U5,rMe,nPr,sPr,XY,lPr,iPr,dPr,J5,PNe,ef,Y5,tMe,Ux,cPr,aMe,fPr,BNe,vr,Jx,mPr,of,gPr,zY,hPr,pPr,QY,uPr,_Pr,bPr,Yx,vPr,nMe,FPr,TPr,MPr,Ht,Kx,EPr,sMe,CPr,wPr,rf,APr,lMe,yPr,LPr,WY,xPr,$Pr,kPr,K5,SPr,Wr,Zx,RPr,iMe,PPr,BPr,Cn,IPr,dMe,qPr,NPr,cMe,jPr,DPr,fMe,GPr,OPr,VPr,$e,Z5,mMe,XPr,zPr,HY,QPr,WPr,HPr,eC,gMe,UPr,JPr,UY,YPr,KPr,ZPr,oC,hMe,eBr,oBr,JY,rBr,tBr,aBr,rC,pMe,nBr,sBr,YY,lBr,iBr,dBr,tC,uMe,cBr,fBr,KY,mBr,gBr,hBr,aC,_Me,pBr,uBr,ZY,_Br,bBr,vBr,nC,bMe,FBr,TBr,eK,MBr,EBr,CBr,sC,vMe,wBr,ABr,oK,yBr,LBr,xBr,lC,FMe,$Br,kBr,rK,SBr,RBr,PBr,iC,TMe,BBr,IBr,tK,qBr,NBr,jBr,dC,INe,tf,cC,MMe,e9,DBr,EMe,GBr,qNe,Fr,o9,OBr,af,VBr,aK,XBr,zBr,nK,QBr,WBr,HBr,r9,UBr,CMe,JBr,YBr,KBr,Ut,t9,ZBr,wMe,eIr,oIr,nf,rIr,AMe,tIr,aIr,sK,nIr,sIr,lIr,fC,iIr,Hr,a9,dIr,yMe,cIr,fIr,wn,mIr,LMe,gIr,hIr,xMe,pIr,uIr,$Me,_Ir,bIr,vIr,De,mC,kMe,FIr,TIr,lK,MIr,EIr,CIr,gC,SMe,wIr,AIr,iK,yIr,LIr,xIr,hC,RMe,$Ir,kIr,dK,SIr,RIr,PIr,pC,PMe,BIr,IIr,cK,qIr,NIr,jIr,uC,BMe,DIr,GIr,fK,OIr,VIr,XIr,_C,IMe,zIr,QIr,mK,WIr,HIr,UIr,bC,qMe,JIr,YIr,gK,KIr,ZIr,eqr,vC,NMe,oqr,rqr,hK,tqr,aqr,nqr,FC,NNe,sf,TC,jMe,n9,sqr,DMe,lqr,jNe,Tr,s9,iqr,lf,dqr,pK,cqr,fqr,uK,mqr,gqr,hqr,l9,pqr,GMe,uqr,_qr,bqr,Jt,i9,vqr,OMe,Fqr,Tqr,df,Mqr,VMe,Eqr,Cqr,_K,wqr,Aqr,yqr,MC,Lqr,Ur,d9,xqr,XMe,$qr,kqr,An,Sqr,zMe,Rqr,Pqr,QMe,Bqr,Iqr,WMe,qqr,Nqr,jqr,Ge,EC,HMe,Dqr,Gqr,bK,Oqr,Vqr,Xqr,CC,UMe,zqr,Qqr,vK,Wqr,Hqr,Uqr,wC,JMe,Jqr,Yqr,FK,Kqr,Zqr,eNr,AC,YMe,oNr,rNr,TK,tNr,aNr,nNr,yC,KMe,sNr,lNr,MK,iNr,dNr,cNr,LC,ZMe,fNr,mNr,EK,gNr,hNr,pNr,xC,e4e,uNr,_Nr,CK,bNr,vNr,FNr,$C,o4e,TNr,MNr,wK,ENr,CNr,wNr,kC,DNe,cf,SC,r4e,c9,ANr,t4e,yNr,GNe,Mr,f9,LNr,ff,xNr,AK,$Nr,kNr,yK,SNr,RNr,PNr,m9,BNr,a4e,INr,qNr,NNr,Yt,g9,jNr,n4e,DNr,GNr,mf,ONr,s4e,VNr,XNr,LK,zNr,QNr,WNr,RC,HNr,Jr,h9,UNr,l4e,JNr,YNr,yn,KNr,i4e,ZNr,ejr,d4e,ojr,rjr,c4e,tjr,ajr,njr,f4e,PC,m4e,sjr,ljr,xK,ijr,djr,cjr,BC,ONe,gf,IC,g4e,p9,fjr,h4e,mjr,VNe,Er,u9,gjr,hf,hjr,$K,pjr,ujr,kK,_jr,bjr,vjr,_9,Fjr,p4e,Tjr,Mjr,Ejr,Kt,b9,Cjr,u4e,wjr,Ajr,pf,yjr,_4e,Ljr,xjr,SK,$jr,kjr,Sjr,qC,Rjr,Yr,v9,Pjr,b4e,Bjr,Ijr,Ln,qjr,v4e,Njr,jjr,F4e,Djr,Gjr,T4e,Ojr,Vjr,Xjr,F9,NC,M4e,zjr,Qjr,RK,Wjr,Hjr,Ujr,jC,E4e,Jjr,Yjr,PK,Kjr,Zjr,eDr,DC,XNe,uf,GC,C4e,T9,oDr,w4e,rDr,zNe,Cr,M9,tDr,_f,aDr,BK,nDr,sDr,IK,lDr,iDr,dDr,E9,cDr,A4e,fDr,mDr,gDr,Zt,C9,hDr,y4e,pDr,uDr,bf,_Dr,L4e,bDr,vDr,qK,FDr,TDr,MDr,OC,EDr,Kr,w9,CDr,x4e,wDr,ADr,xn,yDr,$4e,LDr,xDr,k4e,$Dr,kDr,S4e,SDr,RDr,PDr,R4e,VC,P4e,BDr,IDr,NK,qDr,NDr,jDr,XC,QNe;return d=new Z({}),Aa=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),uA=new Z({}),_A=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),yf=new DDr({props:{warning:!0,$$slots:{default:[Nyt]},$$scope:{ctx:A}}}),bA=new Z({}),vA=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/configuration_auto.py#L574"}}),MA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/configuration_auto.py#L597"}}),Ag=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[jyt]},$$scope:{ctx:A}}}),EA=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/configuration_auto.py#L719"}}),CA=new Z({}),wA=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/tokenization_auto.py#L379"}}),LA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17286/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/tokenization_auto.py#L393"}}),nh=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[Dyt]},$$scope:{ctx:A}}}),xA=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/tokenization_auto.py#L589"}}),$A=new Z({}),kA=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/feature_extraction_auto.py#L179"}}),PA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17286/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/feature_extraction_auto.py#L193"}}),Ph=new DDr({props:{$$slots:{default:[Gyt]},$$scope:{ctx:A}}}),Bh=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[Oyt]},$$scope:{ctx:A}}}),BA=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/feature_extraction_auto.py#L320"}}),IA=new Z({}),qA=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/processing_auto.py#L77"}}),DA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/processing_auto.py#L91"}}),Zh=new DDr({props:{$$slots:{default:[Vyt]},$$scope:{ctx:A}}}),ep=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[Xyt]},$$scope:{ctx:A}}}),GA=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/processing_auto.py#L244"}}),OA=new Z({}),VA=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L731"}}),zA=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (Flava model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),tp=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[zyt]},$$scope:{ctx:A}}}),QA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),Wu=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[Qyt]},$$scope:{ctx:A}}}),WA=new Z({}),HA=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L738"}}),JA=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (Flava model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),Uu=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[Wyt]},$$scope:{ctx:A}}}),YA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),q_=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Hyt]},$$scope:{ctx:A}}}),KA=new Z({}),ZA=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L753"}}),o0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),j_=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[Uyt]},$$scope:{ctx:A}}}),r0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),E2=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Jyt]},$$scope:{ctx:A}}}),t0=new Z({}),a0=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L760"}}),s0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),w2=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[Yyt]},$$scope:{ctx:A}}}),l0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),i1=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[Kyt]},$$scope:{ctx:A}}}),i0=new Z({}),d0=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L767"}}),f0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLMProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),c1=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Zyt]},$$scope:{ctx:A}}}),m0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),x1=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[eLt]},$$scope:{ctx:A}}}),g0=new Z({}),h0=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L776"}}),u0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),k1=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[oLt]},$$scope:{ctx:A}}}),_0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),Ab=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[rLt]},$$scope:{ctx:A}}}),b0=new Z({}),v0=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L821"}}),T0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),Lb=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[tLt]},$$scope:{ctx:A}}}),M0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),nv=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[aLt]},$$scope:{ctx:A}}}),E0=new Z({}),C0=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L828"}}),A0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),lv=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[nLt]},$$scope:{ctx:A}}}),y0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),hv=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[sLt]},$$scope:{ctx:A}}}),L0=new Z({}),x0=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L814"}}),k0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),uv=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[lLt]},$$scope:{ctx:A}}}),S0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),Yv=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[iLt]},$$scope:{ctx:A}}}),R0=new Z({}),P0=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L785"}}),I0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),Zv=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[dLt]},$$scope:{ctx:A}}}),q0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),DF=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[cLt]},$$scope:{ctx:A}}}),N0=new Z({}),j0=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L792"}}),G0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),OF=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[fLt]},$$scope:{ctx:A}}}),O0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),zF=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[mLt]},$$scope:{ctx:A}}}),V0=new Z({}),X0=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L837"}}),Q0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17286/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17286/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17286/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),WF=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[gLt]},$$scope:{ctx:A}}}),W0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),s6=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[hLt]},$$scope:{ctx:A}}}),H0=new Z({}),U0=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L876"}}),Y0=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),i6=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[pLt]},$$scope:{ctx:A}}}),K0=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),f6=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[uLt]},$$scope:{ctx:A}}}),Z0=new Z({}),ey=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L803"}}),ry=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),g6=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[_Lt]},$$scope:{ctx:A}}}),ty=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),u6=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[bLt]},$$scope:{ctx:A}}}),ay=new Z({}),ny=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L883"}}),ly=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),b6=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[vLt]},$$scope:{ctx:A}}}),iy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),L6=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[FLt]},$$scope:{ctx:A}}}),dy=new Z({}),cy=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L906"}}),my=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),$6=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[TLt]},$$scope:{ctx:A}}}),gy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),I6=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[MLt]},$$scope:{ctx:A}}}),hy=new Z({}),py=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L890"}}),_y=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),N6=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[ELt]},$$scope:{ctx:A}}}),by=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),H6=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[CLt]},$$scope:{ctx:A}}}),vy=new Z({}),Fy=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L897"}}),My=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),J6=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[wLt]},$$scope:{ctx:A}}}),Ey=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),eT=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[ALt]},$$scope:{ctx:A}}}),wy=new Z({}),Ay=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L915"}}),Ly=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),rT=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[yLt]},$$scope:{ctx:A}}}),xy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),iT=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[LLt]},$$scope:{ctx:A}}}),$y=new Z({}),ky=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L922"}}),Ry=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),cT=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[xLt]},$$scope:{ctx:A}}}),Py=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),pT=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[$Lt]},$$scope:{ctx:A}}}),By=new Z({}),Iy=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L869"}}),Ny=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),_T=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[kLt]},$$scope:{ctx:A}}}),jy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),TT=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[SLt]},$$scope:{ctx:A}}}),Gy=new Z({}),Oy=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L844"}}),Xy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),ET=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[RLt]},$$scope:{ctx:A}}}),zy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),AT=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[PLt]},$$scope:{ctx:A}}}),Qy=new Z({}),Wy=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L851"}}),Uy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),LT=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[BLt]},$$scope:{ctx:A}}}),Jy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),PT=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[ILt]},$$scope:{ctx:A}}}),Yy=new Z({}),Ky=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_auto.py#L860"}}),eL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),IT=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[qLt]},$$scope:{ctx:A}}}),oL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),jT=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[NLt]},$$scope:{ctx:A}}}),rL=new Z({}),tL=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_tf_auto.py#L383"}}),nL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),GT=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[jLt]},$$scope:{ctx:A}}}),sL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),S8=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[DLt]},$$scope:{ctx:A}}}),lL=new Z({}),iL=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_tf_auto.py#L390"}}),cL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),P8=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[GLt]},$$scope:{ctx:A}}}),fL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),a7=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[OLt]},$$scope:{ctx:A}}}),mL=new Z({}),gL=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_tf_auto.py#L405"}}),pL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),s7=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[VLt]},$$scope:{ctx:A}}}),uL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),v7=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[XLt]},$$scope:{ctx:A}}}),_L=new Z({}),bL=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_tf_auto.py#L412"}}),FL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),T7=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[zLt]},$$scope:{ctx:A}}}),TL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),w7=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[QLt]},$$scope:{ctx:A}}}),ML=new Z({}),EL=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_tf_auto.py#L428"}}),wL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),y7=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[WLt]},$$scope:{ctx:A}}}),AL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),H7=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[HLt]},$$scope:{ctx:A}}}),yL=new Z({}),LL=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_tf_auto.py#L435"}}),$L=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),J7=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[ULt]},$$scope:{ctx:A}}}),kL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),lM=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[JLt]},$$scope:{ctx:A}}}),SL=new Z({}),RL=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),BL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),dM=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[YLt]},$$scope:{ctx:A}}}),IL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),IM=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[KLt]},$$scope:{ctx:A}}}),qL=new Z({}),NL=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_tf_auto.py#L480"}}),DL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),NM=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[ZLt]},$$scope:{ctx:A}}}),GL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),r4=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[ext]},$$scope:{ctx:A}}}),OL=new Z({}),VL=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_tf_auto.py#L487"}}),zL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),a4=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[oxt]},$$scope:{ctx:A}}}),QL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),l4=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[rxt]},$$scope:{ctx:A}}}),HL=new Z({}),UL=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_tf_auto.py#L460"}}),YL=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),d4=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[txt]},$$scope:{ctx:A}}}),KL=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),f4=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[axt]},$$scope:{ctx:A}}}),ZL=new Z({}),ex=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_tf_auto.py#L471"}}),rx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),g4=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[nxt]},$$scope:{ctx:A}}}),tx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),P4=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[sxt]},$$scope:{ctx:A}}}),ax=new Z({}),nx=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_tf_auto.py#L453"}}),lx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),I4=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[lxt]},$$scope:{ctx:A}}}),ix=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),tE=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[ixt]},$$scope:{ctx:A}}}),dx=new Z({}),cx=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_tf_auto.py#L421"}}),mx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),nE=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[dxt]},$$scope:{ctx:A}}}),gx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),lE=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[cxt]},$$scope:{ctx:A}}}),hx=new Z({}),px=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_tf_auto.py#L496"}}),_x=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),dE=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[fxt]},$$scope:{ctx:A}}}),bx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),fE=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[mxt]},$$scope:{ctx:A}}}),vx=new Z({}),Fx=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_flax_auto.py#L241"}}),Mx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),gE=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[gxt]},$$scope:{ctx:A}}}),Ex=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),jE=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[hxt]},$$scope:{ctx:A}}}),Cx=new Z({}),wx=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_flax_auto.py#L255"}}),yx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),GE=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[pxt]},$$scope:{ctx:A}}}),Lx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),YE=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[uxt]},$$scope:{ctx:A}}}),xx=new Z({}),$x=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_flax_auto.py#L248"}}),Sx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),ZE=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[_xt]},$$scope:{ctx:A}}}),Rx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),m5=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[bxt]},$$scope:{ctx:A}}}),Px=new Z({}),Bx=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_flax_auto.py#L262"}}),qx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),h5=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[vxt]},$$scope:{ctx:A}}}),Nx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),w5=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[Fxt]},$$scope:{ctx:A}}}),jx=new Z({}),Dx=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_flax_auto.py#L269"}}),Ox=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),y5=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Txt]},$$scope:{ctx:A}}}),Vx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),q5=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Mxt]},$$scope:{ctx:A}}}),Xx=new Z({}),zx=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_flax_auto.py#L278"}}),Wx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),j5=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[Ext]},$$scope:{ctx:A}}}),Hx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),J5=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Cxt]},$$scope:{ctx:A}}}),Ux=new Z({}),Jx=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_flax_auto.py#L287"}}),Kx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),K5=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[wxt]},$$scope:{ctx:A}}}),Zx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),dC=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Axt]},$$scope:{ctx:A}}}),e9=new Z({}),o9=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_flax_auto.py#L294"}}),t9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),fC=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[yxt]},$$scope:{ctx:A}}}),a9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),FC=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[Lxt]},$$scope:{ctx:A}}}),n9=new Z({}),s9=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_flax_auto.py#L303"}}),i9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),MC=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[xxt]},$$scope:{ctx:A}}}),d9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),kC=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[$xt]},$$scope:{ctx:A}}}),c9=new Z({}),f9=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_flax_auto.py#L310"}}),g9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),RC=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[kxt]},$$scope:{ctx:A}}}),h9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),BC=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[Sxt]},$$scope:{ctx:A}}}),p9=new Z({}),u9=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_flax_auto.py#L319"}}),b9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17286/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),qC=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[Rxt]},$$scope:{ctx:A}}}),v9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),DC=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Pxt]},$$scope:{ctx:A}}}),T9=new Z({}),M9=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/modeling_flax_auto.py#L328"}}),C9=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17286/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17286/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L389"}}),OC=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[Bxt]},$$scope:{ctx:A}}}),w9=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17286/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17286/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17286/src/transformers/models/auto/auto_factory.py#L417"}}),XC=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Ixt]},$$scope:{ctx:A}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),u=a("span"),F(d.$$.fragment),h=l(),Eo=a("span"),hi=o("Auto Classes"),Mf=l(),rt=a("p"),pi=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),ui=a("code"),mA=o("from_pretrained()"),Ef=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),qe=l(),Xe=a("p"),_i=o("Instantiating one of "),kn=a("a"),gA=o("AutoConfig"),Sn=o(", "),Rn=a("a"),hA=o("AutoModel"),bi=o(`, and
`),Pn=a("a"),pA=o("AutoTokenizer"),vi=o(" will directly create a class of the relevant architecture. For instance"),Cf=l(),F(Aa.$$.fragment),ze=l(),Ae=a("p"),j$=o("will create a model that is an instance of "),Fi=a("a"),D$=o("BertModel"),G$=o("."),Co=l(),ya=a("p"),O$=o("There is one class of "),wf=a("code"),V$=o("AutoModel"),rGe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),GIe=l(),Ti=a("h2"),Af=a("a"),Pee=a("span"),F(uA.$$.fragment),tGe=l(),Bee=a("span"),aGe=o("Extending the Auto Classes"),OIe=l(),Bn=a("p"),nGe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Iee=a("code"),sGe=o("NewModel"),lGe=o(", make sure you have a "),qee=a("code"),iGe=o("NewModelConfig"),dGe=o(` then you can add those to the auto
classes like this:`),VIe=l(),F(_A.$$.fragment),XIe=l(),X$=a("p"),cGe=o("You will then be able to use the auto classes like you would usually do!"),zIe=l(),F(yf.$$.fragment),QIe=l(),Mi=a("h2"),Lf=a("a"),Nee=a("span"),F(bA.$$.fragment),fGe=l(),jee=a("span"),mGe=o("AutoConfig"),WIe=l(),wo=a("div"),F(vA.$$.fragment),gGe=l(),FA=a("p"),hGe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),z$=a("a"),pGe=o("from_pretrained()"),uGe=o(" class method."),_Ge=l(),TA=a("p"),bGe=o("This class cannot be instantiated directly using "),Dee=a("code"),vGe=o("__init__()"),FGe=o(" (throws an error)."),TGe=l(),wr=a("div"),F(MA.$$.fragment),MGe=l(),Gee=a("p"),EGe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),CGe=l(),Ei=a("p"),wGe=o("The configuration class to instantiate is selected based on the "),Oee=a("code"),AGe=o("model_type"),yGe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Vee=a("code"),LGe=o("pretrained_model_name_or_path"),xGe=o(":"),$Ge=l(),y=a("ul"),xf=a("li"),Xee=a("strong"),kGe=o("albert"),SGe=o(" \u2014 "),Q$=a("a"),RGe=o("AlbertConfig"),PGe=o(" (ALBERT model)"),BGe=l(),$f=a("li"),zee=a("strong"),IGe=o("bart"),qGe=o(" \u2014 "),W$=a("a"),NGe=o("BartConfig"),jGe=o(" (BART model)"),DGe=l(),kf=a("li"),Qee=a("strong"),GGe=o("beit"),OGe=o(" \u2014 "),H$=a("a"),VGe=o("BeitConfig"),XGe=o(" (BEiT model)"),zGe=l(),Sf=a("li"),Wee=a("strong"),QGe=o("bert"),WGe=o(" \u2014 "),U$=a("a"),HGe=o("BertConfig"),UGe=o(" (BERT model)"),JGe=l(),Rf=a("li"),Hee=a("strong"),YGe=o("bert-generation"),KGe=o(" \u2014 "),J$=a("a"),ZGe=o("BertGenerationConfig"),eOe=o(" (Bert Generation model)"),oOe=l(),Pf=a("li"),Uee=a("strong"),rOe=o("big_bird"),tOe=o(" \u2014 "),Y$=a("a"),aOe=o("BigBirdConfig"),nOe=o(" (BigBird model)"),sOe=l(),Bf=a("li"),Jee=a("strong"),lOe=o("bigbird_pegasus"),iOe=o(" \u2014 "),K$=a("a"),dOe=o("BigBirdPegasusConfig"),cOe=o(" (BigBirdPegasus model)"),fOe=l(),If=a("li"),Yee=a("strong"),mOe=o("blenderbot"),gOe=o(" \u2014 "),Z$=a("a"),hOe=o("BlenderbotConfig"),pOe=o(" (Blenderbot model)"),uOe=l(),qf=a("li"),Kee=a("strong"),_Oe=o("blenderbot-small"),bOe=o(" \u2014 "),ek=a("a"),vOe=o("BlenderbotSmallConfig"),FOe=o(" (BlenderbotSmall model)"),TOe=l(),Nf=a("li"),Zee=a("strong"),MOe=o("camembert"),EOe=o(" \u2014 "),ok=a("a"),COe=o("CamembertConfig"),wOe=o(" (CamemBERT model)"),AOe=l(),jf=a("li"),eoe=a("strong"),yOe=o("canine"),LOe=o(" \u2014 "),rk=a("a"),xOe=o("CanineConfig"),$Oe=o(" (Canine model)"),kOe=l(),Df=a("li"),ooe=a("strong"),SOe=o("clip"),ROe=o(" \u2014 "),tk=a("a"),POe=o("CLIPConfig"),BOe=o(" (CLIP model)"),IOe=l(),Gf=a("li"),roe=a("strong"),qOe=o("convbert"),NOe=o(" \u2014 "),ak=a("a"),jOe=o("ConvBertConfig"),DOe=o(" (ConvBERT model)"),GOe=l(),Of=a("li"),toe=a("strong"),OOe=o("convnext"),VOe=o(" \u2014 "),nk=a("a"),XOe=o("ConvNextConfig"),zOe=o(" (ConvNext model)"),QOe=l(),Vf=a("li"),aoe=a("strong"),WOe=o("ctrl"),HOe=o(" \u2014 "),sk=a("a"),UOe=o("CTRLConfig"),JOe=o(" (CTRL model)"),YOe=l(),Xf=a("li"),noe=a("strong"),KOe=o("data2vec-audio"),ZOe=o(" \u2014 "),lk=a("a"),eVe=o("Data2VecAudioConfig"),oVe=o(" (Data2VecAudio model)"),rVe=l(),zf=a("li"),soe=a("strong"),tVe=o("data2vec-text"),aVe=o(" \u2014 "),ik=a("a"),nVe=o("Data2VecTextConfig"),sVe=o(" (Data2VecText model)"),lVe=l(),Qf=a("li"),loe=a("strong"),iVe=o("data2vec-vision"),dVe=o(" \u2014 "),dk=a("a"),cVe=o("Data2VecVisionConfig"),fVe=o(" (Data2VecVision model)"),mVe=l(),Wf=a("li"),ioe=a("strong"),gVe=o("deberta"),hVe=o(" \u2014 "),ck=a("a"),pVe=o("DebertaConfig"),uVe=o(" (DeBERTa model)"),_Ve=l(),Hf=a("li"),doe=a("strong"),bVe=o("deberta-v2"),vVe=o(" \u2014 "),fk=a("a"),FVe=o("DebertaV2Config"),TVe=o(" (DeBERTa-v2 model)"),MVe=l(),Uf=a("li"),coe=a("strong"),EVe=o("decision_transformer"),CVe=o(" \u2014 "),mk=a("a"),wVe=o("DecisionTransformerConfig"),AVe=o(" (Decision Transformer model)"),yVe=l(),Jf=a("li"),foe=a("strong"),LVe=o("deit"),xVe=o(" \u2014 "),gk=a("a"),$Ve=o("DeiTConfig"),kVe=o(" (DeiT model)"),SVe=l(),Yf=a("li"),moe=a("strong"),RVe=o("detr"),PVe=o(" \u2014 "),hk=a("a"),BVe=o("DetrConfig"),IVe=o(" (DETR model)"),qVe=l(),Kf=a("li"),goe=a("strong"),NVe=o("distilbert"),jVe=o(" \u2014 "),pk=a("a"),DVe=o("DistilBertConfig"),GVe=o(" (DistilBERT model)"),OVe=l(),Zf=a("li"),hoe=a("strong"),VVe=o("dpr"),XVe=o(" \u2014 "),uk=a("a"),zVe=o("DPRConfig"),QVe=o(" (DPR model)"),WVe=l(),em=a("li"),poe=a("strong"),HVe=o("dpt"),UVe=o(" \u2014 "),_k=a("a"),JVe=o("DPTConfig"),YVe=o(" (DPT model)"),KVe=l(),om=a("li"),uoe=a("strong"),ZVe=o("electra"),eXe=o(" \u2014 "),bk=a("a"),oXe=o("ElectraConfig"),rXe=o(" (ELECTRA model)"),tXe=l(),rm=a("li"),_oe=a("strong"),aXe=o("encoder-decoder"),nXe=o(" \u2014 "),vk=a("a"),sXe=o("EncoderDecoderConfig"),lXe=o(" (Encoder decoder model)"),iXe=l(),tm=a("li"),boe=a("strong"),dXe=o("flaubert"),cXe=o(" \u2014 "),Fk=a("a"),fXe=o("FlaubertConfig"),mXe=o(" (FlauBERT model)"),gXe=l(),am=a("li"),voe=a("strong"),hXe=o("flava"),pXe=o(" \u2014 "),Tk=a("a"),uXe=o("FlavaConfig"),_Xe=o(" (Flava model)"),bXe=l(),nm=a("li"),Foe=a("strong"),vXe=o("fnet"),FXe=o(" \u2014 "),Mk=a("a"),TXe=o("FNetConfig"),MXe=o(" (FNet model)"),EXe=l(),sm=a("li"),Toe=a("strong"),CXe=o("fsmt"),wXe=o(" \u2014 "),Ek=a("a"),AXe=o("FSMTConfig"),yXe=o(" (FairSeq Machine-Translation model)"),LXe=l(),lm=a("li"),Moe=a("strong"),xXe=o("funnel"),$Xe=o(" \u2014 "),Ck=a("a"),kXe=o("FunnelConfig"),SXe=o(" (Funnel Transformer model)"),RXe=l(),im=a("li"),Eoe=a("strong"),PXe=o("glpn"),BXe=o(" \u2014 "),wk=a("a"),IXe=o("GLPNConfig"),qXe=o(" (GLPN model)"),NXe=l(),dm=a("li"),Coe=a("strong"),jXe=o("gpt2"),DXe=o(" \u2014 "),Ak=a("a"),GXe=o("GPT2Config"),OXe=o(" (OpenAI GPT-2 model)"),VXe=l(),cm=a("li"),woe=a("strong"),XXe=o("gpt_neo"),zXe=o(" \u2014 "),yk=a("a"),QXe=o("GPTNeoConfig"),WXe=o(" (GPT Neo model)"),HXe=l(),fm=a("li"),Aoe=a("strong"),UXe=o("gptj"),JXe=o(" \u2014 "),Lk=a("a"),YXe=o("GPTJConfig"),KXe=o(" (GPT-J model)"),ZXe=l(),mm=a("li"),yoe=a("strong"),eze=o("hubert"),oze=o(" \u2014 "),xk=a("a"),rze=o("HubertConfig"),tze=o(" (Hubert model)"),aze=l(),gm=a("li"),Loe=a("strong"),nze=o("ibert"),sze=o(" \u2014 "),$k=a("a"),lze=o("IBertConfig"),ize=o(" (I-BERT model)"),dze=l(),hm=a("li"),xoe=a("strong"),cze=o("imagegpt"),fze=o(" \u2014 "),kk=a("a"),mze=o("ImageGPTConfig"),gze=o(" (ImageGPT model)"),hze=l(),pm=a("li"),$oe=a("strong"),pze=o("layoutlm"),uze=o(" \u2014 "),Sk=a("a"),_ze=o("LayoutLMConfig"),bze=o(" (LayoutLM model)"),vze=l(),um=a("li"),koe=a("strong"),Fze=o("layoutlmv2"),Tze=o(" \u2014 "),Rk=a("a"),Mze=o("LayoutLMv2Config"),Eze=o(" (LayoutLMv2 model)"),Cze=l(),_m=a("li"),Soe=a("strong"),wze=o("led"),Aze=o(" \u2014 "),Pk=a("a"),yze=o("LEDConfig"),Lze=o(" (LED model)"),xze=l(),bm=a("li"),Roe=a("strong"),$ze=o("longformer"),kze=o(" \u2014 "),Bk=a("a"),Sze=o("LongformerConfig"),Rze=o(" (Longformer model)"),Pze=l(),vm=a("li"),Poe=a("strong"),Bze=o("luke"),Ize=o(" \u2014 "),Ik=a("a"),qze=o("LukeConfig"),Nze=o(" (LUKE model)"),jze=l(),Fm=a("li"),Boe=a("strong"),Dze=o("lxmert"),Gze=o(" \u2014 "),qk=a("a"),Oze=o("LxmertConfig"),Vze=o(" (LXMERT model)"),Xze=l(),Tm=a("li"),Ioe=a("strong"),zze=o("m2m_100"),Qze=o(" \u2014 "),Nk=a("a"),Wze=o("M2M100Config"),Hze=o(" (M2M100 model)"),Uze=l(),Mm=a("li"),qoe=a("strong"),Jze=o("marian"),Yze=o(" \u2014 "),jk=a("a"),Kze=o("MarianConfig"),Zze=o(" (Marian model)"),eQe=l(),Em=a("li"),Noe=a("strong"),oQe=o("maskformer"),rQe=o(" \u2014 "),Dk=a("a"),tQe=o("MaskFormerConfig"),aQe=o(" (MaskFormer model)"),nQe=l(),Cm=a("li"),joe=a("strong"),sQe=o("mbart"),lQe=o(" \u2014 "),Gk=a("a"),iQe=o("MBartConfig"),dQe=o(" (mBART model)"),cQe=l(),wm=a("li"),Doe=a("strong"),fQe=o("megatron-bert"),mQe=o(" \u2014 "),Ok=a("a"),gQe=o("MegatronBertConfig"),hQe=o(" (MegatronBert model)"),pQe=l(),Am=a("li"),Goe=a("strong"),uQe=o("mobilebert"),_Qe=o(" \u2014 "),Vk=a("a"),bQe=o("MobileBertConfig"),vQe=o(" (MobileBERT model)"),FQe=l(),ym=a("li"),Ooe=a("strong"),TQe=o("mpnet"),MQe=o(" \u2014 "),Xk=a("a"),EQe=o("MPNetConfig"),CQe=o(" (MPNet model)"),wQe=l(),Lm=a("li"),Voe=a("strong"),AQe=o("mt5"),yQe=o(" \u2014 "),zk=a("a"),LQe=o("MT5Config"),xQe=o(" (mT5 model)"),$Qe=l(),xm=a("li"),Xoe=a("strong"),kQe=o("nystromformer"),SQe=o(" \u2014 "),Qk=a("a"),RQe=o("NystromformerConfig"),PQe=o(" (Nystromformer model)"),BQe=l(),$m=a("li"),zoe=a("strong"),IQe=o("openai-gpt"),qQe=o(" \u2014 "),Wk=a("a"),NQe=o("OpenAIGPTConfig"),jQe=o(" (OpenAI GPT model)"),DQe=l(),km=a("li"),Qoe=a("strong"),GQe=o("opt"),OQe=o(" \u2014 "),Hk=a("a"),VQe=o("OPTConfig"),XQe=o(" (OPT model)"),zQe=l(),Sm=a("li"),Woe=a("strong"),QQe=o("pegasus"),WQe=o(" \u2014 "),Uk=a("a"),HQe=o("PegasusConfig"),UQe=o(" (Pegasus model)"),JQe=l(),Rm=a("li"),Hoe=a("strong"),YQe=o("perceiver"),KQe=o(" \u2014 "),Jk=a("a"),ZQe=o("PerceiverConfig"),eWe=o(" (Perceiver model)"),oWe=l(),Pm=a("li"),Uoe=a("strong"),rWe=o("plbart"),tWe=o(" \u2014 "),Yk=a("a"),aWe=o("PLBartConfig"),nWe=o(" (PLBart model)"),sWe=l(),Bm=a("li"),Joe=a("strong"),lWe=o("poolformer"),iWe=o(" \u2014 "),Kk=a("a"),dWe=o("PoolFormerConfig"),cWe=o(" (PoolFormer model)"),fWe=l(),Im=a("li"),Yoe=a("strong"),mWe=o("prophetnet"),gWe=o(" \u2014 "),Zk=a("a"),hWe=o("ProphetNetConfig"),pWe=o(" (ProphetNet model)"),uWe=l(),qm=a("li"),Koe=a("strong"),_We=o("qdqbert"),bWe=o(" \u2014 "),eS=a("a"),vWe=o("QDQBertConfig"),FWe=o(" (QDQBert model)"),TWe=l(),Nm=a("li"),Zoe=a("strong"),MWe=o("rag"),EWe=o(" \u2014 "),oS=a("a"),CWe=o("RagConfig"),wWe=o(" (RAG model)"),AWe=l(),jm=a("li"),ere=a("strong"),yWe=o("realm"),LWe=o(" \u2014 "),rS=a("a"),xWe=o("RealmConfig"),$We=o(" (Realm model)"),kWe=l(),Dm=a("li"),ore=a("strong"),SWe=o("reformer"),RWe=o(" \u2014 "),tS=a("a"),PWe=o("ReformerConfig"),BWe=o(" (Reformer model)"),IWe=l(),Gm=a("li"),rre=a("strong"),qWe=o("regnet"),NWe=o(" \u2014 "),aS=a("a"),jWe=o("RegNetConfig"),DWe=o(" (RegNet model)"),GWe=l(),Om=a("li"),tre=a("strong"),OWe=o("rembert"),VWe=o(" \u2014 "),nS=a("a"),XWe=o("RemBertConfig"),zWe=o(" (RemBERT model)"),QWe=l(),Vm=a("li"),are=a("strong"),WWe=o("resnet"),HWe=o(" \u2014 "),sS=a("a"),UWe=o("ResNetConfig"),JWe=o(" (ResNet model)"),YWe=l(),Xm=a("li"),nre=a("strong"),KWe=o("retribert"),ZWe=o(" \u2014 "),lS=a("a"),eHe=o("RetriBertConfig"),oHe=o(" (RetriBERT model)"),rHe=l(),zm=a("li"),sre=a("strong"),tHe=o("roberta"),aHe=o(" \u2014 "),iS=a("a"),nHe=o("RobertaConfig"),sHe=o(" (RoBERTa model)"),lHe=l(),Qm=a("li"),lre=a("strong"),iHe=o("roformer"),dHe=o(" \u2014 "),dS=a("a"),cHe=o("RoFormerConfig"),fHe=o(" (RoFormer model)"),mHe=l(),Wm=a("li"),ire=a("strong"),gHe=o("segformer"),hHe=o(" \u2014 "),cS=a("a"),pHe=o("SegformerConfig"),uHe=o(" (SegFormer model)"),_He=l(),Hm=a("li"),dre=a("strong"),bHe=o("sew"),vHe=o(" \u2014 "),fS=a("a"),FHe=o("SEWConfig"),THe=o(" (SEW model)"),MHe=l(),Um=a("li"),cre=a("strong"),EHe=o("sew-d"),CHe=o(" \u2014 "),mS=a("a"),wHe=o("SEWDConfig"),AHe=o(" (SEW-D model)"),yHe=l(),Jm=a("li"),fre=a("strong"),LHe=o("speech-encoder-decoder"),xHe=o(" \u2014 "),gS=a("a"),$He=o("SpeechEncoderDecoderConfig"),kHe=o(" (Speech Encoder decoder model)"),SHe=l(),Ym=a("li"),mre=a("strong"),RHe=o("speech_to_text"),PHe=o(" \u2014 "),hS=a("a"),BHe=o("Speech2TextConfig"),IHe=o(" (Speech2Text model)"),qHe=l(),Km=a("li"),gre=a("strong"),NHe=o("speech_to_text_2"),jHe=o(" \u2014 "),pS=a("a"),DHe=o("Speech2Text2Config"),GHe=o(" (Speech2Text2 model)"),OHe=l(),Zm=a("li"),hre=a("strong"),VHe=o("splinter"),XHe=o(" \u2014 "),uS=a("a"),zHe=o("SplinterConfig"),QHe=o(" (Splinter model)"),WHe=l(),eg=a("li"),pre=a("strong"),HHe=o("squeezebert"),UHe=o(" \u2014 "),_S=a("a"),JHe=o("SqueezeBertConfig"),YHe=o(" (SqueezeBERT model)"),KHe=l(),og=a("li"),ure=a("strong"),ZHe=o("swin"),eUe=o(" \u2014 "),bS=a("a"),oUe=o("SwinConfig"),rUe=o(" (Swin model)"),tUe=l(),rg=a("li"),_re=a("strong"),aUe=o("t5"),nUe=o(" \u2014 "),vS=a("a"),sUe=o("T5Config"),lUe=o(" (T5 model)"),iUe=l(),tg=a("li"),bre=a("strong"),dUe=o("tapas"),cUe=o(" \u2014 "),FS=a("a"),fUe=o("TapasConfig"),mUe=o(" (TAPAS model)"),gUe=l(),ag=a("li"),vre=a("strong"),hUe=o("tapex"),pUe=o(" \u2014 "),TS=a("a"),uUe=o("BartConfig"),_Ue=o(" (TAPEX model)"),bUe=l(),ng=a("li"),Fre=a("strong"),vUe=o("transfo-xl"),FUe=o(" \u2014 "),MS=a("a"),TUe=o("TransfoXLConfig"),MUe=o(" (Transformer-XL model)"),EUe=l(),sg=a("li"),Tre=a("strong"),CUe=o("trocr"),wUe=o(" \u2014 "),ES=a("a"),AUe=o("TrOCRConfig"),yUe=o(" (TrOCR model)"),LUe=l(),lg=a("li"),Mre=a("strong"),xUe=o("unispeech"),$Ue=o(" \u2014 "),CS=a("a"),kUe=o("UniSpeechConfig"),SUe=o(" (UniSpeech model)"),RUe=l(),ig=a("li"),Ere=a("strong"),PUe=o("unispeech-sat"),BUe=o(" \u2014 "),wS=a("a"),IUe=o("UniSpeechSatConfig"),qUe=o(" (UniSpeechSat model)"),NUe=l(),dg=a("li"),Cre=a("strong"),jUe=o("van"),DUe=o(" \u2014 "),AS=a("a"),GUe=o("VanConfig"),OUe=o(" (VAN model)"),VUe=l(),cg=a("li"),wre=a("strong"),XUe=o("vilt"),zUe=o(" \u2014 "),yS=a("a"),QUe=o("ViltConfig"),WUe=o(" (ViLT model)"),HUe=l(),fg=a("li"),Are=a("strong"),UUe=o("vision-encoder-decoder"),JUe=o(" \u2014 "),LS=a("a"),YUe=o("VisionEncoderDecoderConfig"),KUe=o(" (Vision Encoder decoder model)"),ZUe=l(),mg=a("li"),yre=a("strong"),eJe=o("vision-text-dual-encoder"),oJe=o(" \u2014 "),xS=a("a"),rJe=o("VisionTextDualEncoderConfig"),tJe=o(" (VisionTextDualEncoder model)"),aJe=l(),gg=a("li"),Lre=a("strong"),nJe=o("visual_bert"),sJe=o(" \u2014 "),$S=a("a"),lJe=o("VisualBertConfig"),iJe=o(" (VisualBert model)"),dJe=l(),hg=a("li"),xre=a("strong"),cJe=o("vit"),fJe=o(" \u2014 "),kS=a("a"),mJe=o("ViTConfig"),gJe=o(" (ViT model)"),hJe=l(),pg=a("li"),$re=a("strong"),pJe=o("vit_mae"),uJe=o(" \u2014 "),SS=a("a"),_Je=o("ViTMAEConfig"),bJe=o(" (ViTMAE model)"),vJe=l(),ug=a("li"),kre=a("strong"),FJe=o("wav2vec2"),TJe=o(" \u2014 "),RS=a("a"),MJe=o("Wav2Vec2Config"),EJe=o(" (Wav2Vec2 model)"),CJe=l(),_g=a("li"),Sre=a("strong"),wJe=o("wavlm"),AJe=o(" \u2014 "),PS=a("a"),yJe=o("WavLMConfig"),LJe=o(" (WavLM model)"),xJe=l(),bg=a("li"),Rre=a("strong"),$Je=o("xglm"),kJe=o(" \u2014 "),BS=a("a"),SJe=o("XGLMConfig"),RJe=o(" (XGLM model)"),PJe=l(),vg=a("li"),Pre=a("strong"),BJe=o("xlm"),IJe=o(" \u2014 "),IS=a("a"),qJe=o("XLMConfig"),NJe=o(" (XLM model)"),jJe=l(),Fg=a("li"),Bre=a("strong"),DJe=o("xlm-prophetnet"),GJe=o(" \u2014 "),qS=a("a"),OJe=o("XLMProphetNetConfig"),VJe=o(" (XLMProphetNet model)"),XJe=l(),Tg=a("li"),Ire=a("strong"),zJe=o("xlm-roberta"),QJe=o(" \u2014 "),NS=a("a"),WJe=o("XLMRobertaConfig"),HJe=o(" (XLM-RoBERTa model)"),UJe=l(),Mg=a("li"),qre=a("strong"),JJe=o("xlm-roberta-xl"),YJe=o(" \u2014 "),jS=a("a"),KJe=o("XLMRobertaXLConfig"),ZJe=o(" (XLM-RoBERTa-XL model)"),eYe=l(),Eg=a("li"),Nre=a("strong"),oYe=o("xlnet"),rYe=o(" \u2014 "),DS=a("a"),tYe=o("XLNetConfig"),aYe=o(" (XLNet model)"),nYe=l(),Cg=a("li"),jre=a("strong"),sYe=o("yolos"),lYe=o(" \u2014 "),GS=a("a"),iYe=o("YolosConfig"),dYe=o(" (YOLOS model)"),cYe=l(),wg=a("li"),Dre=a("strong"),fYe=o("yoso"),mYe=o(" \u2014 "),OS=a("a"),gYe=o("YosoConfig"),hYe=o(" (YOSO model)"),pYe=l(),F(Ag.$$.fragment),uYe=l(),yg=a("div"),F(EA.$$.fragment),_Ye=l(),Gre=a("p"),bYe=o("Register a new configuration for this class."),HIe=l(),Ci=a("h2"),Lg=a("a"),Ore=a("span"),F(CA.$$.fragment),vYe=l(),Vre=a("span"),FYe=o("AutoTokenizer"),UIe=l(),Ao=a("div"),F(wA.$$.fragment),TYe=l(),AA=a("p"),MYe=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),VS=a("a"),EYe=o("AutoTokenizer.from_pretrained()"),CYe=o(" class method."),wYe=l(),yA=a("p"),AYe=o("This class cannot be instantiated directly using "),Xre=a("code"),yYe=o("__init__()"),LYe=o(" (throws an error)."),xYe=l(),Ar=a("div"),F(LA.$$.fragment),$Ye=l(),zre=a("p"),kYe=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),SYe=l(),La=a("p"),RYe=o("The tokenizer class to instantiate is selected based on the "),Qre=a("code"),PYe=o("model_type"),BYe=o(` property of the config object (either
passed as an argument or loaded from `),Wre=a("code"),IYe=o("pretrained_model_name_or_path"),qYe=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hre=a("code"),NYe=o("pretrained_model_name_or_path"),jYe=o(":"),DYe=l(),k=a("ul"),In=a("li"),Ure=a("strong"),GYe=o("albert"),OYe=o(" \u2014 "),XS=a("a"),VYe=o("AlbertTokenizer"),XYe=o(" or "),zS=a("a"),zYe=o("AlbertTokenizerFast"),QYe=o(" (ALBERT model)"),WYe=l(),qn=a("li"),Jre=a("strong"),HYe=o("bart"),UYe=o(" \u2014 "),QS=a("a"),JYe=o("BartTokenizer"),YYe=o(" or "),WS=a("a"),KYe=o("BartTokenizerFast"),ZYe=o(" (BART model)"),eKe=l(),Nn=a("li"),Yre=a("strong"),oKe=o("barthez"),rKe=o(" \u2014 "),HS=a("a"),tKe=o("BarthezTokenizer"),aKe=o(" or "),US=a("a"),nKe=o("BarthezTokenizerFast"),sKe=o(" (BARThez model)"),lKe=l(),xg=a("li"),Kre=a("strong"),iKe=o("bartpho"),dKe=o(" \u2014 "),JS=a("a"),cKe=o("BartphoTokenizer"),fKe=o(" (BARTpho model)"),mKe=l(),jn=a("li"),Zre=a("strong"),gKe=o("bert"),hKe=o(" \u2014 "),YS=a("a"),pKe=o("BertTokenizer"),uKe=o(" or "),KS=a("a"),_Ke=o("BertTokenizerFast"),bKe=o(" (BERT model)"),vKe=l(),$g=a("li"),ete=a("strong"),FKe=o("bert-generation"),TKe=o(" \u2014 "),ZS=a("a"),MKe=o("BertGenerationTokenizer"),EKe=o(" (Bert Generation model)"),CKe=l(),kg=a("li"),ote=a("strong"),wKe=o("bert-japanese"),AKe=o(" \u2014 "),eR=a("a"),yKe=o("BertJapaneseTokenizer"),LKe=o(" (BertJapanese model)"),xKe=l(),Sg=a("li"),rte=a("strong"),$Ke=o("bertweet"),kKe=o(" \u2014 "),oR=a("a"),SKe=o("BertweetTokenizer"),RKe=o(" (Bertweet model)"),PKe=l(),Dn=a("li"),tte=a("strong"),BKe=o("big_bird"),IKe=o(" \u2014 "),rR=a("a"),qKe=o("BigBirdTokenizer"),NKe=o(" or "),tR=a("a"),jKe=o("BigBirdTokenizerFast"),DKe=o(" (BigBird model)"),GKe=l(),Gn=a("li"),ate=a("strong"),OKe=o("bigbird_pegasus"),VKe=o(" \u2014 "),aR=a("a"),XKe=o("PegasusTokenizer"),zKe=o(" or "),nR=a("a"),QKe=o("PegasusTokenizerFast"),WKe=o(" (BigBirdPegasus model)"),HKe=l(),On=a("li"),nte=a("strong"),UKe=o("blenderbot"),JKe=o(" \u2014 "),sR=a("a"),YKe=o("BlenderbotTokenizer"),KKe=o(" or "),lR=a("a"),ZKe=o("BlenderbotTokenizerFast"),eZe=o(" (Blenderbot model)"),oZe=l(),Rg=a("li"),ste=a("strong"),rZe=o("blenderbot-small"),tZe=o(" \u2014 "),iR=a("a"),aZe=o("BlenderbotSmallTokenizer"),nZe=o(" (BlenderbotSmall model)"),sZe=l(),Pg=a("li"),lte=a("strong"),lZe=o("byt5"),iZe=o(" \u2014 "),dR=a("a"),dZe=o("ByT5Tokenizer"),cZe=o(" (ByT5 model)"),fZe=l(),Vn=a("li"),ite=a("strong"),mZe=o("camembert"),gZe=o(" \u2014 "),cR=a("a"),hZe=o("CamembertTokenizer"),pZe=o(" or "),fR=a("a"),uZe=o("CamembertTokenizerFast"),_Ze=o(" (CamemBERT model)"),bZe=l(),Bg=a("li"),dte=a("strong"),vZe=o("canine"),FZe=o(" \u2014 "),mR=a("a"),TZe=o("CanineTokenizer"),MZe=o(" (Canine model)"),EZe=l(),Xn=a("li"),cte=a("strong"),CZe=o("clip"),wZe=o(" \u2014 "),gR=a("a"),AZe=o("CLIPTokenizer"),yZe=o(" or "),hR=a("a"),LZe=o("CLIPTokenizerFast"),xZe=o(" (CLIP model)"),$Ze=l(),zn=a("li"),fte=a("strong"),kZe=o("convbert"),SZe=o(" \u2014 "),pR=a("a"),RZe=o("ConvBertTokenizer"),PZe=o(" or "),uR=a("a"),BZe=o("ConvBertTokenizerFast"),IZe=o(" (ConvBERT model)"),qZe=l(),Qn=a("li"),mte=a("strong"),NZe=o("cpm"),jZe=o(" \u2014 "),_R=a("a"),DZe=o("CpmTokenizer"),GZe=o(" or "),bR=a("a"),OZe=o("CpmTokenizerFast"),VZe=o(" (CPM model)"),XZe=l(),Ig=a("li"),gte=a("strong"),zZe=o("ctrl"),QZe=o(" \u2014 "),vR=a("a"),WZe=o("CTRLTokenizer"),HZe=o(" (CTRL model)"),UZe=l(),Wn=a("li"),hte=a("strong"),JZe=o("data2vec-text"),YZe=o(" \u2014 "),FR=a("a"),KZe=o("RobertaTokenizer"),ZZe=o(" or "),TR=a("a"),eeo=o("RobertaTokenizerFast"),oeo=o(" (Data2VecText model)"),reo=l(),Hn=a("li"),pte=a("strong"),teo=o("deberta"),aeo=o(" \u2014 "),MR=a("a"),neo=o("DebertaTokenizer"),seo=o(" or "),ER=a("a"),leo=o("DebertaTokenizerFast"),ieo=o(" (DeBERTa model)"),deo=l(),Un=a("li"),ute=a("strong"),ceo=o("deberta-v2"),feo=o(" \u2014 "),CR=a("a"),meo=o("DebertaV2Tokenizer"),geo=o(" or "),wR=a("a"),heo=o("DebertaV2TokenizerFast"),peo=o(" (DeBERTa-v2 model)"),ueo=l(),Jn=a("li"),_te=a("strong"),_eo=o("distilbert"),beo=o(" \u2014 "),AR=a("a"),veo=o("DistilBertTokenizer"),Feo=o(" or "),yR=a("a"),Teo=o("DistilBertTokenizerFast"),Meo=o(" (DistilBERT model)"),Eeo=l(),Yn=a("li"),bte=a("strong"),Ceo=o("dpr"),weo=o(" \u2014 "),LR=a("a"),Aeo=o("DPRQuestionEncoderTokenizer"),yeo=o(" or "),xR=a("a"),Leo=o("DPRQuestionEncoderTokenizerFast"),xeo=o(" (DPR model)"),$eo=l(),Kn=a("li"),vte=a("strong"),keo=o("electra"),Seo=o(" \u2014 "),$R=a("a"),Reo=o("ElectraTokenizer"),Peo=o(" or "),kR=a("a"),Beo=o("ElectraTokenizerFast"),Ieo=o(" (ELECTRA model)"),qeo=l(),qg=a("li"),Fte=a("strong"),Neo=o("flaubert"),jeo=o(" \u2014 "),SR=a("a"),Deo=o("FlaubertTokenizer"),Geo=o(" (FlauBERT model)"),Oeo=l(),Zn=a("li"),Tte=a("strong"),Veo=o("fnet"),Xeo=o(" \u2014 "),RR=a("a"),zeo=o("FNetTokenizer"),Qeo=o(" or "),PR=a("a"),Weo=o("FNetTokenizerFast"),Heo=o(" (FNet model)"),Ueo=l(),Ng=a("li"),Mte=a("strong"),Jeo=o("fsmt"),Yeo=o(" \u2014 "),BR=a("a"),Keo=o("FSMTTokenizer"),Zeo=o(" (FairSeq Machine-Translation model)"),eoo=l(),es=a("li"),Ete=a("strong"),ooo=o("funnel"),roo=o(" \u2014 "),IR=a("a"),too=o("FunnelTokenizer"),aoo=o(" or "),qR=a("a"),noo=o("FunnelTokenizerFast"),soo=o(" (Funnel Transformer model)"),loo=l(),os=a("li"),Cte=a("strong"),ioo=o("gpt2"),doo=o(" \u2014 "),NR=a("a"),coo=o("GPT2Tokenizer"),foo=o(" or "),jR=a("a"),moo=o("GPT2TokenizerFast"),goo=o(" (OpenAI GPT-2 model)"),hoo=l(),rs=a("li"),wte=a("strong"),poo=o("gpt_neo"),uoo=o(" \u2014 "),DR=a("a"),_oo=o("GPT2Tokenizer"),boo=o(" or "),GR=a("a"),voo=o("GPT2TokenizerFast"),Foo=o(" (GPT Neo model)"),Too=l(),ts=a("li"),Ate=a("strong"),Moo=o("gptj"),Eoo=o(" \u2014 "),OR=a("a"),Coo=o("GPT2Tokenizer"),woo=o(" or "),VR=a("a"),Aoo=o("GPT2TokenizerFast"),yoo=o(" (GPT-J model)"),Loo=l(),as=a("li"),yte=a("strong"),xoo=o("herbert"),$oo=o(" \u2014 "),XR=a("a"),koo=o("HerbertTokenizer"),Soo=o(" or "),zR=a("a"),Roo=o("HerbertTokenizerFast"),Poo=o(" (HerBERT model)"),Boo=l(),jg=a("li"),Lte=a("strong"),Ioo=o("hubert"),qoo=o(" \u2014 "),QR=a("a"),Noo=o("Wav2Vec2CTCTokenizer"),joo=o(" (Hubert model)"),Doo=l(),ns=a("li"),xte=a("strong"),Goo=o("ibert"),Ooo=o(" \u2014 "),WR=a("a"),Voo=o("RobertaTokenizer"),Xoo=o(" or "),HR=a("a"),zoo=o("RobertaTokenizerFast"),Qoo=o(" (I-BERT model)"),Woo=l(),ss=a("li"),$te=a("strong"),Hoo=o("layoutlm"),Uoo=o(" \u2014 "),UR=a("a"),Joo=o("LayoutLMTokenizer"),Yoo=o(" or "),JR=a("a"),Koo=o("LayoutLMTokenizerFast"),Zoo=o(" (LayoutLM model)"),ero=l(),ls=a("li"),kte=a("strong"),oro=o("layoutlmv2"),rro=o(" \u2014 "),YR=a("a"),tro=o("LayoutLMv2Tokenizer"),aro=o(" or "),KR=a("a"),nro=o("LayoutLMv2TokenizerFast"),sro=o(" (LayoutLMv2 model)"),lro=l(),is=a("li"),Ste=a("strong"),iro=o("layoutxlm"),dro=o(" \u2014 "),ZR=a("a"),cro=o("LayoutXLMTokenizer"),fro=o(" or "),eP=a("a"),mro=o("LayoutXLMTokenizerFast"),gro=o(" (LayoutXLM model)"),hro=l(),ds=a("li"),Rte=a("strong"),pro=o("led"),uro=o(" \u2014 "),oP=a("a"),_ro=o("LEDTokenizer"),bro=o(" or "),rP=a("a"),vro=o("LEDTokenizerFast"),Fro=o(" (LED model)"),Tro=l(),cs=a("li"),Pte=a("strong"),Mro=o("longformer"),Ero=o(" \u2014 "),tP=a("a"),Cro=o("LongformerTokenizer"),wro=o(" or "),aP=a("a"),Aro=o("LongformerTokenizerFast"),yro=o(" (Longformer model)"),Lro=l(),Dg=a("li"),Bte=a("strong"),xro=o("luke"),$ro=o(" \u2014 "),nP=a("a"),kro=o("LukeTokenizer"),Sro=o(" (LUKE model)"),Rro=l(),fs=a("li"),Ite=a("strong"),Pro=o("lxmert"),Bro=o(" \u2014 "),sP=a("a"),Iro=o("LxmertTokenizer"),qro=o(" or "),lP=a("a"),Nro=o("LxmertTokenizerFast"),jro=o(" (LXMERT model)"),Dro=l(),Gg=a("li"),qte=a("strong"),Gro=o("m2m_100"),Oro=o(" \u2014 "),iP=a("a"),Vro=o("M2M100Tokenizer"),Xro=o(" (M2M100 model)"),zro=l(),Og=a("li"),Nte=a("strong"),Qro=o("marian"),Wro=o(" \u2014 "),dP=a("a"),Hro=o("MarianTokenizer"),Uro=o(" (Marian model)"),Jro=l(),ms=a("li"),jte=a("strong"),Yro=o("mbart"),Kro=o(" \u2014 "),cP=a("a"),Zro=o("MBartTokenizer"),eto=o(" or "),fP=a("a"),oto=o("MBartTokenizerFast"),rto=o(" (mBART model)"),tto=l(),gs=a("li"),Dte=a("strong"),ato=o("mbart50"),nto=o(" \u2014 "),mP=a("a"),sto=o("MBart50Tokenizer"),lto=o(" or "),gP=a("a"),ito=o("MBart50TokenizerFast"),dto=o(" (mBART-50 model)"),cto=l(),hs=a("li"),Gte=a("strong"),fto=o("megatron-bert"),mto=o(" \u2014 "),hP=a("a"),gto=o("BertTokenizer"),hto=o(" or "),pP=a("a"),pto=o("BertTokenizerFast"),uto=o(" (MegatronBert model)"),_to=l(),Vg=a("li"),Ote=a("strong"),bto=o("mluke"),vto=o(" \u2014 "),uP=a("a"),Fto=o("MLukeTokenizer"),Tto=o(" (mLUKE model)"),Mto=l(),ps=a("li"),Vte=a("strong"),Eto=o("mobilebert"),Cto=o(" \u2014 "),_P=a("a"),wto=o("MobileBertTokenizer"),Ato=o(" or "),bP=a("a"),yto=o("MobileBertTokenizerFast"),Lto=o(" (MobileBERT model)"),xto=l(),us=a("li"),Xte=a("strong"),$to=o("mpnet"),kto=o(" \u2014 "),vP=a("a"),Sto=o("MPNetTokenizer"),Rto=o(" or "),FP=a("a"),Pto=o("MPNetTokenizerFast"),Bto=o(" (MPNet model)"),Ito=l(),_s=a("li"),zte=a("strong"),qto=o("mt5"),Nto=o(" \u2014 "),TP=a("a"),jto=o("MT5Tokenizer"),Dto=o(" or "),MP=a("a"),Gto=o("MT5TokenizerFast"),Oto=o(" (mT5 model)"),Vto=l(),bs=a("li"),Qte=a("strong"),Xto=o("nystromformer"),zto=o(" \u2014 "),EP=a("a"),Qto=o("AlbertTokenizer"),Wto=o(" or "),CP=a("a"),Hto=o("AlbertTokenizerFast"),Uto=o(" (Nystromformer model)"),Jto=l(),vs=a("li"),Wte=a("strong"),Yto=o("openai-gpt"),Kto=o(" \u2014 "),wP=a("a"),Zto=o("OpenAIGPTTokenizer"),eao=o(" or "),AP=a("a"),oao=o("OpenAIGPTTokenizerFast"),rao=o(" (OpenAI GPT model)"),tao=l(),Xg=a("li"),Hte=a("strong"),aao=o("opt"),nao=o(" \u2014 "),yP=a("a"),sao=o("GPT2Tokenizer"),lao=o(" (OPT model)"),iao=l(),Fs=a("li"),Ute=a("strong"),dao=o("pegasus"),cao=o(" \u2014 "),LP=a("a"),fao=o("PegasusTokenizer"),mao=o(" or "),xP=a("a"),gao=o("PegasusTokenizerFast"),hao=o(" (Pegasus model)"),pao=l(),zg=a("li"),Jte=a("strong"),uao=o("perceiver"),_ao=o(" \u2014 "),$P=a("a"),bao=o("PerceiverTokenizer"),vao=o(" (Perceiver model)"),Fao=l(),Qg=a("li"),Yte=a("strong"),Tao=o("phobert"),Mao=o(" \u2014 "),kP=a("a"),Eao=o("PhobertTokenizer"),Cao=o(" (PhoBERT model)"),wao=l(),Wg=a("li"),Kte=a("strong"),Aao=o("plbart"),yao=o(" \u2014 "),SP=a("a"),Lao=o("PLBartTokenizer"),xao=o(" (PLBart model)"),$ao=l(),Hg=a("li"),Zte=a("strong"),kao=o("prophetnet"),Sao=o(" \u2014 "),RP=a("a"),Rao=o("ProphetNetTokenizer"),Pao=o(" (ProphetNet model)"),Bao=l(),Ts=a("li"),eae=a("strong"),Iao=o("qdqbert"),qao=o(" \u2014 "),PP=a("a"),Nao=o("BertTokenizer"),jao=o(" or "),BP=a("a"),Dao=o("BertTokenizerFast"),Gao=o(" (QDQBert model)"),Oao=l(),Ug=a("li"),oae=a("strong"),Vao=o("rag"),Xao=o(" \u2014 "),IP=a("a"),zao=o("RagTokenizer"),Qao=o(" (RAG model)"),Wao=l(),Ms=a("li"),rae=a("strong"),Hao=o("realm"),Uao=o(" \u2014 "),qP=a("a"),Jao=o("RealmTokenizer"),Yao=o(" or "),NP=a("a"),Kao=o("RealmTokenizerFast"),Zao=o(" (Realm model)"),eno=l(),Es=a("li"),tae=a("strong"),ono=o("reformer"),rno=o(" \u2014 "),jP=a("a"),tno=o("ReformerTokenizer"),ano=o(" or "),DP=a("a"),nno=o("ReformerTokenizerFast"),sno=o(" (Reformer model)"),lno=l(),Cs=a("li"),aae=a("strong"),ino=o("rembert"),dno=o(" \u2014 "),GP=a("a"),cno=o("RemBertTokenizer"),fno=o(" or "),OP=a("a"),mno=o("RemBertTokenizerFast"),gno=o(" (RemBERT model)"),hno=l(),ws=a("li"),nae=a("strong"),pno=o("retribert"),uno=o(" \u2014 "),VP=a("a"),_no=o("RetriBertTokenizer"),bno=o(" or "),XP=a("a"),vno=o("RetriBertTokenizerFast"),Fno=o(" (RetriBERT model)"),Tno=l(),As=a("li"),sae=a("strong"),Mno=o("roberta"),Eno=o(" \u2014 "),zP=a("a"),Cno=o("RobertaTokenizer"),wno=o(" or "),QP=a("a"),Ano=o("RobertaTokenizerFast"),yno=o(" (RoBERTa model)"),Lno=l(),ys=a("li"),lae=a("strong"),xno=o("roformer"),$no=o(" \u2014 "),WP=a("a"),kno=o("RoFormerTokenizer"),Sno=o(" or "),HP=a("a"),Rno=o("RoFormerTokenizerFast"),Pno=o(" (RoFormer model)"),Bno=l(),Jg=a("li"),iae=a("strong"),Ino=o("speech_to_text"),qno=o(" \u2014 "),UP=a("a"),Nno=o("Speech2TextTokenizer"),jno=o(" (Speech2Text model)"),Dno=l(),Yg=a("li"),dae=a("strong"),Gno=o("speech_to_text_2"),Ono=o(" \u2014 "),JP=a("a"),Vno=o("Speech2Text2Tokenizer"),Xno=o(" (Speech2Text2 model)"),zno=l(),Ls=a("li"),cae=a("strong"),Qno=o("splinter"),Wno=o(" \u2014 "),YP=a("a"),Hno=o("SplinterTokenizer"),Uno=o(" or "),KP=a("a"),Jno=o("SplinterTokenizerFast"),Yno=o(" (Splinter model)"),Kno=l(),xs=a("li"),fae=a("strong"),Zno=o("squeezebert"),eso=o(" \u2014 "),ZP=a("a"),oso=o("SqueezeBertTokenizer"),rso=o(" or "),eB=a("a"),tso=o("SqueezeBertTokenizerFast"),aso=o(" (SqueezeBERT model)"),nso=l(),$s=a("li"),mae=a("strong"),sso=o("t5"),lso=o(" \u2014 "),oB=a("a"),iso=o("T5Tokenizer"),dso=o(" or "),rB=a("a"),cso=o("T5TokenizerFast"),fso=o(" (T5 model)"),mso=l(),Kg=a("li"),gae=a("strong"),gso=o("tapas"),hso=o(" \u2014 "),tB=a("a"),pso=o("TapasTokenizer"),uso=o(" (TAPAS model)"),_so=l(),Zg=a("li"),hae=a("strong"),bso=o("tapex"),vso=o(" \u2014 "),aB=a("a"),Fso=o("TapexTokenizer"),Tso=o(" (TAPEX model)"),Mso=l(),eh=a("li"),pae=a("strong"),Eso=o("transfo-xl"),Cso=o(" \u2014 "),nB=a("a"),wso=o("TransfoXLTokenizer"),Aso=o(" (Transformer-XL model)"),yso=l(),ks=a("li"),uae=a("strong"),Lso=o("vilt"),xso=o(" \u2014 "),sB=a("a"),$so=o("BertTokenizer"),kso=o(" or "),lB=a("a"),Sso=o("BertTokenizerFast"),Rso=o(" (ViLT model)"),Pso=l(),Ss=a("li"),_ae=a("strong"),Bso=o("visual_bert"),Iso=o(" \u2014 "),iB=a("a"),qso=o("BertTokenizer"),Nso=o(" or "),dB=a("a"),jso=o("BertTokenizerFast"),Dso=o(" (VisualBert model)"),Gso=l(),oh=a("li"),bae=a("strong"),Oso=o("wav2vec2"),Vso=o(" \u2014 "),cB=a("a"),Xso=o("Wav2Vec2CTCTokenizer"),zso=o(" (Wav2Vec2 model)"),Qso=l(),rh=a("li"),vae=a("strong"),Wso=o("wav2vec2_phoneme"),Hso=o(" \u2014 "),fB=a("a"),Uso=o("Wav2Vec2PhonemeCTCTokenizer"),Jso=o(" (Wav2Vec2Phoneme model)"),Yso=l(),Rs=a("li"),Fae=a("strong"),Kso=o("xglm"),Zso=o(" \u2014 "),mB=a("a"),elo=o("XGLMTokenizer"),olo=o(" or "),gB=a("a"),rlo=o("XGLMTokenizerFast"),tlo=o(" (XGLM model)"),alo=l(),th=a("li"),Tae=a("strong"),nlo=o("xlm"),slo=o(" \u2014 "),hB=a("a"),llo=o("XLMTokenizer"),ilo=o(" (XLM model)"),dlo=l(),ah=a("li"),Mae=a("strong"),clo=o("xlm-prophetnet"),flo=o(" \u2014 "),pB=a("a"),mlo=o("XLMProphetNetTokenizer"),glo=o(" (XLMProphetNet model)"),hlo=l(),Ps=a("li"),Eae=a("strong"),plo=o("xlm-roberta"),ulo=o(" \u2014 "),uB=a("a"),_lo=o("XLMRobertaTokenizer"),blo=o(" or "),_B=a("a"),vlo=o("XLMRobertaTokenizerFast"),Flo=o(" (XLM-RoBERTa model)"),Tlo=l(),Bs=a("li"),Cae=a("strong"),Mlo=o("xlm-roberta-xl"),Elo=o(" \u2014 "),bB=a("a"),Clo=o("RobertaTokenizer"),wlo=o(" or "),vB=a("a"),Alo=o("RobertaTokenizerFast"),ylo=o(" (XLM-RoBERTa-XL model)"),Llo=l(),Is=a("li"),wae=a("strong"),xlo=o("xlnet"),$lo=o(" \u2014 "),FB=a("a"),klo=o("XLNetTokenizer"),Slo=o(" or "),TB=a("a"),Rlo=o("XLNetTokenizerFast"),Plo=o(" (XLNet model)"),Blo=l(),qs=a("li"),Aae=a("strong"),Ilo=o("yoso"),qlo=o(" \u2014 "),MB=a("a"),Nlo=o("AlbertTokenizer"),jlo=o(" or "),EB=a("a"),Dlo=o("AlbertTokenizerFast"),Glo=o(" (YOSO model)"),Olo=l(),F(nh.$$.fragment),Vlo=l(),sh=a("div"),F(xA.$$.fragment),Xlo=l(),yae=a("p"),zlo=o("Register a new tokenizer in this mapping."),JIe=l(),wi=a("h2"),lh=a("a"),Lae=a("span"),F($A.$$.fragment),Qlo=l(),xae=a("span"),Wlo=o("AutoFeatureExtractor"),YIe=l(),yo=a("div"),F(kA.$$.fragment),Hlo=l(),SA=a("p"),Ulo=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),CB=a("a"),Jlo=o("AutoFeatureExtractor.from_pretrained()"),Ylo=o(" class method."),Klo=l(),RA=a("p"),Zlo=o("This class cannot be instantiated directly using "),$ae=a("code"),eio=o("__init__()"),oio=o(" (throws an error)."),rio=l(),Qe=a("div"),F(PA.$$.fragment),tio=l(),kae=a("p"),aio=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),nio=l(),xa=a("p"),sio=o("The feature extractor class to instantiate is selected based on the "),Sae=a("code"),lio=o("model_type"),iio=o(` property of the config object
(either passed as an argument or loaded from `),Rae=a("code"),dio=o("pretrained_model_name_or_path"),cio=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Pae=a("code"),fio=o("pretrained_model_name_or_path"),mio=o(":"),gio=l(),ee=a("ul"),ih=a("li"),Bae=a("strong"),hio=o("beit"),pio=o(" \u2014 "),wB=a("a"),uio=o("BeitFeatureExtractor"),_io=o(" (BEiT model)"),bio=l(),dh=a("li"),Iae=a("strong"),vio=o("clip"),Fio=o(" \u2014 "),AB=a("a"),Tio=o("CLIPFeatureExtractor"),Mio=o(" (CLIP model)"),Eio=l(),ch=a("li"),qae=a("strong"),Cio=o("convnext"),wio=o(" \u2014 "),yB=a("a"),Aio=o("ConvNextFeatureExtractor"),yio=o(" (ConvNext model)"),Lio=l(),fh=a("li"),Nae=a("strong"),xio=o("data2vec-audio"),$io=o(" \u2014 "),LB=a("a"),kio=o("Wav2Vec2FeatureExtractor"),Sio=o(" (Data2VecAudio model)"),Rio=l(),mh=a("li"),jae=a("strong"),Pio=o("data2vec-vision"),Bio=o(" \u2014 "),xB=a("a"),Iio=o("BeitFeatureExtractor"),qio=o(" (Data2VecVision model)"),Nio=l(),gh=a("li"),Dae=a("strong"),jio=o("deit"),Dio=o(" \u2014 "),$B=a("a"),Gio=o("DeiTFeatureExtractor"),Oio=o(" (DeiT model)"),Vio=l(),hh=a("li"),Gae=a("strong"),Xio=o("detr"),zio=o(" \u2014 "),kB=a("a"),Qio=o("DetrFeatureExtractor"),Wio=o(" (DETR model)"),Hio=l(),ph=a("li"),Oae=a("strong"),Uio=o("dpt"),Jio=o(" \u2014 "),SB=a("a"),Yio=o("DPTFeatureExtractor"),Kio=o(" (DPT model)"),Zio=l(),uh=a("li"),Vae=a("strong"),edo=o("flava"),odo=o(" \u2014 "),RB=a("a"),rdo=o("FlavaFeatureExtractor"),tdo=o(" (Flava model)"),ado=l(),_h=a("li"),Xae=a("strong"),ndo=o("glpn"),sdo=o(" \u2014 "),PB=a("a"),ldo=o("GLPNFeatureExtractor"),ido=o(" (GLPN model)"),ddo=l(),bh=a("li"),zae=a("strong"),cdo=o("hubert"),fdo=o(" \u2014 "),BB=a("a"),mdo=o("Wav2Vec2FeatureExtractor"),gdo=o(" (Hubert model)"),hdo=l(),vh=a("li"),Qae=a("strong"),pdo=o("layoutlmv2"),udo=o(" \u2014 "),IB=a("a"),_do=o("LayoutLMv2FeatureExtractor"),bdo=o(" (LayoutLMv2 model)"),vdo=l(),Fh=a("li"),Wae=a("strong"),Fdo=o("maskformer"),Tdo=o(" \u2014 "),qB=a("a"),Mdo=o("MaskFormerFeatureExtractor"),Edo=o(" (MaskFormer model)"),Cdo=l(),Th=a("li"),Hae=a("strong"),wdo=o("perceiver"),Ado=o(" \u2014 "),NB=a("a"),ydo=o("PerceiverFeatureExtractor"),Ldo=o(" (Perceiver model)"),xdo=l(),Mh=a("li"),Uae=a("strong"),$do=o("poolformer"),kdo=o(" \u2014 "),jB=a("a"),Sdo=o("PoolFormerFeatureExtractor"),Rdo=o(" (PoolFormer model)"),Pdo=l(),Eh=a("li"),Jae=a("strong"),Bdo=o("regnet"),Ido=o(" \u2014 "),DB=a("a"),qdo=o("ConvNextFeatureExtractor"),Ndo=o(" (RegNet model)"),jdo=l(),Ch=a("li"),Yae=a("strong"),Ddo=o("resnet"),Gdo=o(" \u2014 "),GB=a("a"),Odo=o("ConvNextFeatureExtractor"),Vdo=o(" (ResNet model)"),Xdo=l(),wh=a("li"),Kae=a("strong"),zdo=o("segformer"),Qdo=o(" \u2014 "),OB=a("a"),Wdo=o("SegformerFeatureExtractor"),Hdo=o(" (SegFormer model)"),Udo=l(),Ah=a("li"),Zae=a("strong"),Jdo=o("speech_to_text"),Ydo=o(" \u2014 "),VB=a("a"),Kdo=o("Speech2TextFeatureExtractor"),Zdo=o(" (Speech2Text model)"),eco=l(),yh=a("li"),ene=a("strong"),oco=o("swin"),rco=o(" \u2014 "),XB=a("a"),tco=o("ViTFeatureExtractor"),aco=o(" (Swin model)"),nco=l(),Lh=a("li"),one=a("strong"),sco=o("van"),lco=o(" \u2014 "),zB=a("a"),ico=o("ConvNextFeatureExtractor"),dco=o(" (VAN model)"),cco=l(),xh=a("li"),rne=a("strong"),fco=o("vilt"),mco=o(" \u2014 "),QB=a("a"),gco=o("ViltFeatureExtractor"),hco=o(" (ViLT model)"),pco=l(),$h=a("li"),tne=a("strong"),uco=o("vit"),_co=o(" \u2014 "),WB=a("a"),bco=o("ViTFeatureExtractor"),vco=o(" (ViT model)"),Fco=l(),kh=a("li"),ane=a("strong"),Tco=o("vit_mae"),Mco=o(" \u2014 "),HB=a("a"),Eco=o("ViTFeatureExtractor"),Cco=o(" (ViTMAE model)"),wco=l(),Sh=a("li"),nne=a("strong"),Aco=o("wav2vec2"),yco=o(" \u2014 "),UB=a("a"),Lco=o("Wav2Vec2FeatureExtractor"),xco=o(" (Wav2Vec2 model)"),$co=l(),Rh=a("li"),sne=a("strong"),kco=o("yolos"),Sco=o(" \u2014 "),JB=a("a"),Rco=o("YolosFeatureExtractor"),Pco=o(" (YOLOS model)"),Bco=l(),F(Ph.$$.fragment),Ico=l(),F(Bh.$$.fragment),qco=l(),Ih=a("div"),F(BA.$$.fragment),Nco=l(),lne=a("p"),jco=o("Register a new feature extractor for this class."),KIe=l(),Ai=a("h2"),qh=a("a"),ine=a("span"),F(IA.$$.fragment),Dco=l(),dne=a("span"),Gco=o("AutoProcessor"),ZIe=l(),Lo=a("div"),F(qA.$$.fragment),Oco=l(),NA=a("p"),Vco=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),YB=a("a"),Xco=o("AutoProcessor.from_pretrained()"),zco=o(" class method."),Qco=l(),jA=a("p"),Wco=o("This class cannot be instantiated directly using "),cne=a("code"),Hco=o("__init__()"),Uco=o(" (throws an error)."),Jco=l(),We=a("div"),F(DA.$$.fragment),Yco=l(),fne=a("p"),Kco=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),Zco=l(),yi=a("p"),efo=o("The processor class to instantiate is selected based on the "),mne=a("code"),ofo=o("model_type"),rfo=o(` property of the config object (either
passed as an argument or loaded from `),gne=a("code"),tfo=o("pretrained_model_name_or_path"),afo=o(" if possible):"),nfo=l(),be=a("ul"),Nh=a("li"),hne=a("strong"),sfo=o("clip"),lfo=o(" \u2014 "),KB=a("a"),ifo=o("CLIPProcessor"),dfo=o(" (CLIP model)"),cfo=l(),jh=a("li"),pne=a("strong"),ffo=o("flava"),mfo=o(" \u2014 "),une=a("code"),gfo=o("FLAVAProcessor"),hfo=o(" (Flava model)"),pfo=l(),Dh=a("li"),_ne=a("strong"),ufo=o("layoutlmv2"),_fo=o(" \u2014 "),ZB=a("a"),bfo=o("LayoutLMv2Processor"),vfo=o(" (LayoutLMv2 model)"),Ffo=l(),Gh=a("li"),bne=a("strong"),Tfo=o("layoutxlm"),Mfo=o(" \u2014 "),eI=a("a"),Efo=o("LayoutXLMProcessor"),Cfo=o(" (LayoutXLM model)"),wfo=l(),Oh=a("li"),vne=a("strong"),Afo=o("sew"),yfo=o(" \u2014 "),oI=a("a"),Lfo=o("Wav2Vec2Processor"),xfo=o(" (SEW model)"),$fo=l(),Vh=a("li"),Fne=a("strong"),kfo=o("sew-d"),Sfo=o(" \u2014 "),rI=a("a"),Rfo=o("Wav2Vec2Processor"),Pfo=o(" (SEW-D model)"),Bfo=l(),Xh=a("li"),Tne=a("strong"),Ifo=o("speech_to_text"),qfo=o(" \u2014 "),tI=a("a"),Nfo=o("Speech2TextProcessor"),jfo=o(" (Speech2Text model)"),Dfo=l(),zh=a("li"),Mne=a("strong"),Gfo=o("speech_to_text_2"),Ofo=o(" \u2014 "),aI=a("a"),Vfo=o("Speech2Text2Processor"),Xfo=o(" (Speech2Text2 model)"),zfo=l(),Qh=a("li"),Ene=a("strong"),Qfo=o("trocr"),Wfo=o(" \u2014 "),nI=a("a"),Hfo=o("TrOCRProcessor"),Ufo=o(" (TrOCR model)"),Jfo=l(),Wh=a("li"),Cne=a("strong"),Yfo=o("unispeech"),Kfo=o(" \u2014 "),sI=a("a"),Zfo=o("Wav2Vec2Processor"),emo=o(" (UniSpeech model)"),omo=l(),Hh=a("li"),wne=a("strong"),rmo=o("unispeech-sat"),tmo=o(" \u2014 "),lI=a("a"),amo=o("Wav2Vec2Processor"),nmo=o(" (UniSpeechSat model)"),smo=l(),Uh=a("li"),Ane=a("strong"),lmo=o("vilt"),imo=o(" \u2014 "),iI=a("a"),dmo=o("ViltProcessor"),cmo=o(" (ViLT model)"),fmo=l(),Jh=a("li"),yne=a("strong"),mmo=o("vision-text-dual-encoder"),gmo=o(" \u2014 "),dI=a("a"),hmo=o("VisionTextDualEncoderProcessor"),pmo=o(" (VisionTextDualEncoder model)"),umo=l(),Yh=a("li"),Lne=a("strong"),_mo=o("wav2vec2"),bmo=o(" \u2014 "),cI=a("a"),vmo=o("Wav2Vec2Processor"),Fmo=o(" (Wav2Vec2 model)"),Tmo=l(),Kh=a("li"),xne=a("strong"),Mmo=o("wavlm"),Emo=o(" \u2014 "),fI=a("a"),Cmo=o("Wav2Vec2Processor"),wmo=o(" (WavLM model)"),Amo=l(),F(Zh.$$.fragment),ymo=l(),F(ep.$$.fragment),Lmo=l(),op=a("div"),F(GA.$$.fragment),xmo=l(),$ne=a("p"),$mo=o("Register a new processor for this class."),eqe=l(),Li=a("h2"),rp=a("a"),kne=a("span"),F(OA.$$.fragment),kmo=l(),Sne=a("span"),Smo=o("AutoModel"),oqe=l(),xo=a("div"),F(VA.$$.fragment),Rmo=l(),xi=a("p"),Pmo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),mI=a("a"),Bmo=o("from_pretrained()"),Imo=o(" class method or the "),gI=a("a"),qmo=o("from_config()"),Nmo=o(` class
method.`),jmo=l(),XA=a("p"),Dmo=o("This class cannot be instantiated directly using "),Rne=a("code"),Gmo=o("__init__()"),Omo=o(" (throws an error)."),Vmo=l(),tt=a("div"),F(zA.$$.fragment),Xmo=l(),Pne=a("p"),zmo=o("Instantiates one of the base model classes of the library from a configuration."),Qmo=l(),$i=a("p"),Wmo=o(`Note:
Loading a model from its configuration file does `),Bne=a("strong"),Hmo=o("not"),Umo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hI=a("a"),Jmo=o("from_pretrained()"),Ymo=o(" to load the model weights."),Kmo=l(),F(tp.$$.fragment),Zmo=l(),He=a("div"),F(QA.$$.fragment),ego=l(),Ine=a("p"),ogo=o("Instantiate one of the base model classes of the library from a pretrained model."),rgo=l(),$a=a("p"),tgo=o("The model class to instantiate is selected based on the "),qne=a("code"),ago=o("model_type"),ngo=o(` property of the config object (either
passed as an argument or loaded from `),Nne=a("code"),sgo=o("pretrained_model_name_or_path"),lgo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jne=a("code"),igo=o("pretrained_model_name_or_path"),dgo=o(":"),cgo=l(),x=a("ul"),ap=a("li"),Dne=a("strong"),fgo=o("albert"),mgo=o(" \u2014 "),pI=a("a"),ggo=o("AlbertModel"),hgo=o(" (ALBERT model)"),pgo=l(),np=a("li"),Gne=a("strong"),ugo=o("bart"),_go=o(" \u2014 "),uI=a("a"),bgo=o("BartModel"),vgo=o(" (BART model)"),Fgo=l(),sp=a("li"),One=a("strong"),Tgo=o("beit"),Mgo=o(" \u2014 "),_I=a("a"),Ego=o("BeitModel"),Cgo=o(" (BEiT model)"),wgo=l(),lp=a("li"),Vne=a("strong"),Ago=o("bert"),ygo=o(" \u2014 "),bI=a("a"),Lgo=o("BertModel"),xgo=o(" (BERT model)"),$go=l(),ip=a("li"),Xne=a("strong"),kgo=o("bert-generation"),Sgo=o(" \u2014 "),vI=a("a"),Rgo=o("BertGenerationEncoder"),Pgo=o(" (Bert Generation model)"),Bgo=l(),dp=a("li"),zne=a("strong"),Igo=o("big_bird"),qgo=o(" \u2014 "),FI=a("a"),Ngo=o("BigBirdModel"),jgo=o(" (BigBird model)"),Dgo=l(),cp=a("li"),Qne=a("strong"),Ggo=o("bigbird_pegasus"),Ogo=o(" \u2014 "),TI=a("a"),Vgo=o("BigBirdPegasusModel"),Xgo=o(" (BigBirdPegasus model)"),zgo=l(),fp=a("li"),Wne=a("strong"),Qgo=o("blenderbot"),Wgo=o(" \u2014 "),MI=a("a"),Hgo=o("BlenderbotModel"),Ugo=o(" (Blenderbot model)"),Jgo=l(),mp=a("li"),Hne=a("strong"),Ygo=o("blenderbot-small"),Kgo=o(" \u2014 "),EI=a("a"),Zgo=o("BlenderbotSmallModel"),eho=o(" (BlenderbotSmall model)"),oho=l(),gp=a("li"),Une=a("strong"),rho=o("camembert"),tho=o(" \u2014 "),CI=a("a"),aho=o("CamembertModel"),nho=o(" (CamemBERT model)"),sho=l(),hp=a("li"),Jne=a("strong"),lho=o("canine"),iho=o(" \u2014 "),wI=a("a"),dho=o("CanineModel"),cho=o(" (Canine model)"),fho=l(),pp=a("li"),Yne=a("strong"),mho=o("clip"),gho=o(" \u2014 "),AI=a("a"),hho=o("CLIPModel"),pho=o(" (CLIP model)"),uho=l(),up=a("li"),Kne=a("strong"),_ho=o("convbert"),bho=o(" \u2014 "),yI=a("a"),vho=o("ConvBertModel"),Fho=o(" (ConvBERT model)"),Tho=l(),_p=a("li"),Zne=a("strong"),Mho=o("convnext"),Eho=o(" \u2014 "),LI=a("a"),Cho=o("ConvNextModel"),who=o(" (ConvNext model)"),Aho=l(),bp=a("li"),ese=a("strong"),yho=o("ctrl"),Lho=o(" \u2014 "),xI=a("a"),xho=o("CTRLModel"),$ho=o(" (CTRL model)"),kho=l(),vp=a("li"),ose=a("strong"),Sho=o("data2vec-audio"),Rho=o(" \u2014 "),$I=a("a"),Pho=o("Data2VecAudioModel"),Bho=o(" (Data2VecAudio model)"),Iho=l(),Fp=a("li"),rse=a("strong"),qho=o("data2vec-text"),Nho=o(" \u2014 "),kI=a("a"),jho=o("Data2VecTextModel"),Dho=o(" (Data2VecText model)"),Gho=l(),Tp=a("li"),tse=a("strong"),Oho=o("data2vec-vision"),Vho=o(" \u2014 "),SI=a("a"),Xho=o("Data2VecVisionModel"),zho=o(" (Data2VecVision model)"),Qho=l(),Mp=a("li"),ase=a("strong"),Who=o("deberta"),Hho=o(" \u2014 "),RI=a("a"),Uho=o("DebertaModel"),Jho=o(" (DeBERTa model)"),Yho=l(),Ep=a("li"),nse=a("strong"),Kho=o("deberta-v2"),Zho=o(" \u2014 "),PI=a("a"),epo=o("DebertaV2Model"),opo=o(" (DeBERTa-v2 model)"),rpo=l(),Cp=a("li"),sse=a("strong"),tpo=o("decision_transformer"),apo=o(" \u2014 "),BI=a("a"),npo=o("DecisionTransformerModel"),spo=o(" (Decision Transformer model)"),lpo=l(),wp=a("li"),lse=a("strong"),ipo=o("deit"),dpo=o(" \u2014 "),II=a("a"),cpo=o("DeiTModel"),fpo=o(" (DeiT model)"),mpo=l(),Ap=a("li"),ise=a("strong"),gpo=o("detr"),hpo=o(" \u2014 "),qI=a("a"),ppo=o("DetrModel"),upo=o(" (DETR model)"),_po=l(),yp=a("li"),dse=a("strong"),bpo=o("distilbert"),vpo=o(" \u2014 "),NI=a("a"),Fpo=o("DistilBertModel"),Tpo=o(" (DistilBERT model)"),Mpo=l(),Lp=a("li"),cse=a("strong"),Epo=o("dpr"),Cpo=o(" \u2014 "),jI=a("a"),wpo=o("DPRQuestionEncoder"),Apo=o(" (DPR model)"),ypo=l(),xp=a("li"),fse=a("strong"),Lpo=o("dpt"),xpo=o(" \u2014 "),DI=a("a"),$po=o("DPTModel"),kpo=o(" (DPT model)"),Spo=l(),$p=a("li"),mse=a("strong"),Rpo=o("electra"),Ppo=o(" \u2014 "),GI=a("a"),Bpo=o("ElectraModel"),Ipo=o(" (ELECTRA model)"),qpo=l(),kp=a("li"),gse=a("strong"),Npo=o("flaubert"),jpo=o(" \u2014 "),OI=a("a"),Dpo=o("FlaubertModel"),Gpo=o(" (FlauBERT model)"),Opo=l(),Sp=a("li"),hse=a("strong"),Vpo=o("flava"),Xpo=o(" \u2014 "),VI=a("a"),zpo=o("FlavaModel"),Qpo=o(" (Flava model)"),Wpo=l(),Rp=a("li"),pse=a("strong"),Hpo=o("fnet"),Upo=o(" \u2014 "),XI=a("a"),Jpo=o("FNetModel"),Ypo=o(" (FNet model)"),Kpo=l(),Pp=a("li"),use=a("strong"),Zpo=o("fsmt"),euo=o(" \u2014 "),zI=a("a"),ouo=o("FSMTModel"),ruo=o(" (FairSeq Machine-Translation model)"),tuo=l(),Ns=a("li"),_se=a("strong"),auo=o("funnel"),nuo=o(" \u2014 "),QI=a("a"),suo=o("FunnelModel"),luo=o(" or "),WI=a("a"),iuo=o("FunnelBaseModel"),duo=o(" (Funnel Transformer model)"),cuo=l(),Bp=a("li"),bse=a("strong"),fuo=o("glpn"),muo=o(" \u2014 "),HI=a("a"),guo=o("GLPNModel"),huo=o(" (GLPN model)"),puo=l(),Ip=a("li"),vse=a("strong"),uuo=o("gpt2"),_uo=o(" \u2014 "),UI=a("a"),buo=o("GPT2Model"),vuo=o(" (OpenAI GPT-2 model)"),Fuo=l(),qp=a("li"),Fse=a("strong"),Tuo=o("gpt_neo"),Muo=o(" \u2014 "),JI=a("a"),Euo=o("GPTNeoModel"),Cuo=o(" (GPT Neo model)"),wuo=l(),Np=a("li"),Tse=a("strong"),Auo=o("gptj"),yuo=o(" \u2014 "),YI=a("a"),Luo=o("GPTJModel"),xuo=o(" (GPT-J model)"),$uo=l(),jp=a("li"),Mse=a("strong"),kuo=o("hubert"),Suo=o(" \u2014 "),KI=a("a"),Ruo=o("HubertModel"),Puo=o(" (Hubert model)"),Buo=l(),Dp=a("li"),Ese=a("strong"),Iuo=o("ibert"),quo=o(" \u2014 "),ZI=a("a"),Nuo=o("IBertModel"),juo=o(" (I-BERT model)"),Duo=l(),Gp=a("li"),Cse=a("strong"),Guo=o("imagegpt"),Ouo=o(" \u2014 "),eq=a("a"),Vuo=o("ImageGPTModel"),Xuo=o(" (ImageGPT model)"),zuo=l(),Op=a("li"),wse=a("strong"),Quo=o("layoutlm"),Wuo=o(" \u2014 "),oq=a("a"),Huo=o("LayoutLMModel"),Uuo=o(" (LayoutLM model)"),Juo=l(),Vp=a("li"),Ase=a("strong"),Yuo=o("layoutlmv2"),Kuo=o(" \u2014 "),rq=a("a"),Zuo=o("LayoutLMv2Model"),e_o=o(" (LayoutLMv2 model)"),o_o=l(),Xp=a("li"),yse=a("strong"),r_o=o("led"),t_o=o(" \u2014 "),tq=a("a"),a_o=o("LEDModel"),n_o=o(" (LED model)"),s_o=l(),zp=a("li"),Lse=a("strong"),l_o=o("longformer"),i_o=o(" \u2014 "),aq=a("a"),d_o=o("LongformerModel"),c_o=o(" (Longformer model)"),f_o=l(),Qp=a("li"),xse=a("strong"),m_o=o("luke"),g_o=o(" \u2014 "),nq=a("a"),h_o=o("LukeModel"),p_o=o(" (LUKE model)"),u_o=l(),Wp=a("li"),$se=a("strong"),__o=o("lxmert"),b_o=o(" \u2014 "),sq=a("a"),v_o=o("LxmertModel"),F_o=o(" (LXMERT model)"),T_o=l(),Hp=a("li"),kse=a("strong"),M_o=o("m2m_100"),E_o=o(" \u2014 "),lq=a("a"),C_o=o("M2M100Model"),w_o=o(" (M2M100 model)"),A_o=l(),Up=a("li"),Sse=a("strong"),y_o=o("marian"),L_o=o(" \u2014 "),iq=a("a"),x_o=o("MarianModel"),$_o=o(" (Marian model)"),k_o=l(),Jp=a("li"),Rse=a("strong"),S_o=o("maskformer"),R_o=o(" \u2014 "),dq=a("a"),P_o=o("MaskFormerModel"),B_o=o(" (MaskFormer model)"),I_o=l(),Yp=a("li"),Pse=a("strong"),q_o=o("mbart"),N_o=o(" \u2014 "),cq=a("a"),j_o=o("MBartModel"),D_o=o(" (mBART model)"),G_o=l(),Kp=a("li"),Bse=a("strong"),O_o=o("megatron-bert"),V_o=o(" \u2014 "),fq=a("a"),X_o=o("MegatronBertModel"),z_o=o(" (MegatronBert model)"),Q_o=l(),Zp=a("li"),Ise=a("strong"),W_o=o("mobilebert"),H_o=o(" \u2014 "),mq=a("a"),U_o=o("MobileBertModel"),J_o=o(" (MobileBERT model)"),Y_o=l(),eu=a("li"),qse=a("strong"),K_o=o("mpnet"),Z_o=o(" \u2014 "),gq=a("a"),e2o=o("MPNetModel"),o2o=o(" (MPNet model)"),r2o=l(),ou=a("li"),Nse=a("strong"),t2o=o("mt5"),a2o=o(" \u2014 "),hq=a("a"),n2o=o("MT5Model"),s2o=o(" (mT5 model)"),l2o=l(),ru=a("li"),jse=a("strong"),i2o=o("nystromformer"),d2o=o(" \u2014 "),pq=a("a"),c2o=o("NystromformerModel"),f2o=o(" (Nystromformer model)"),m2o=l(),tu=a("li"),Dse=a("strong"),g2o=o("openai-gpt"),h2o=o(" \u2014 "),uq=a("a"),p2o=o("OpenAIGPTModel"),u2o=o(" (OpenAI GPT model)"),_2o=l(),au=a("li"),Gse=a("strong"),b2o=o("opt"),v2o=o(" \u2014 "),_q=a("a"),F2o=o("OPTModel"),T2o=o(" (OPT model)"),M2o=l(),nu=a("li"),Ose=a("strong"),E2o=o("pegasus"),C2o=o(" \u2014 "),bq=a("a"),w2o=o("PegasusModel"),A2o=o(" (Pegasus model)"),y2o=l(),su=a("li"),Vse=a("strong"),L2o=o("perceiver"),x2o=o(" \u2014 "),vq=a("a"),$2o=o("PerceiverModel"),k2o=o(" (Perceiver model)"),S2o=l(),lu=a("li"),Xse=a("strong"),R2o=o("plbart"),P2o=o(" \u2014 "),Fq=a("a"),B2o=o("PLBartModel"),I2o=o(" (PLBart model)"),q2o=l(),iu=a("li"),zse=a("strong"),N2o=o("poolformer"),j2o=o(" \u2014 "),Tq=a("a"),D2o=o("PoolFormerModel"),G2o=o(" (PoolFormer model)"),O2o=l(),du=a("li"),Qse=a("strong"),V2o=o("prophetnet"),X2o=o(" \u2014 "),Mq=a("a"),z2o=o("ProphetNetModel"),Q2o=o(" (ProphetNet model)"),W2o=l(),cu=a("li"),Wse=a("strong"),H2o=o("qdqbert"),U2o=o(" \u2014 "),Eq=a("a"),J2o=o("QDQBertModel"),Y2o=o(" (QDQBert model)"),K2o=l(),fu=a("li"),Hse=a("strong"),Z2o=o("reformer"),e1o=o(" \u2014 "),Cq=a("a"),o1o=o("ReformerModel"),r1o=o(" (Reformer model)"),t1o=l(),mu=a("li"),Use=a("strong"),a1o=o("regnet"),n1o=o(" \u2014 "),wq=a("a"),s1o=o("RegNetModel"),l1o=o(" (RegNet model)"),i1o=l(),gu=a("li"),Jse=a("strong"),d1o=o("rembert"),c1o=o(" \u2014 "),Aq=a("a"),f1o=o("RemBertModel"),m1o=o(" (RemBERT model)"),g1o=l(),hu=a("li"),Yse=a("strong"),h1o=o("resnet"),p1o=o(" \u2014 "),yq=a("a"),u1o=o("ResNetModel"),_1o=o(" (ResNet model)"),b1o=l(),pu=a("li"),Kse=a("strong"),v1o=o("retribert"),F1o=o(" \u2014 "),Lq=a("a"),T1o=o("RetriBertModel"),M1o=o(" (RetriBERT model)"),E1o=l(),uu=a("li"),Zse=a("strong"),C1o=o("roberta"),w1o=o(" \u2014 "),xq=a("a"),A1o=o("RobertaModel"),y1o=o(" (RoBERTa model)"),L1o=l(),_u=a("li"),ele=a("strong"),x1o=o("roformer"),$1o=o(" \u2014 "),$q=a("a"),k1o=o("RoFormerModel"),S1o=o(" (RoFormer model)"),R1o=l(),bu=a("li"),ole=a("strong"),P1o=o("segformer"),B1o=o(" \u2014 "),kq=a("a"),I1o=o("SegformerModel"),q1o=o(" (SegFormer model)"),N1o=l(),vu=a("li"),rle=a("strong"),j1o=o("sew"),D1o=o(" \u2014 "),Sq=a("a"),G1o=o("SEWModel"),O1o=o(" (SEW model)"),V1o=l(),Fu=a("li"),tle=a("strong"),X1o=o("sew-d"),z1o=o(" \u2014 "),Rq=a("a"),Q1o=o("SEWDModel"),W1o=o(" (SEW-D model)"),H1o=l(),Tu=a("li"),ale=a("strong"),U1o=o("speech_to_text"),J1o=o(" \u2014 "),Pq=a("a"),Y1o=o("Speech2TextModel"),K1o=o(" (Speech2Text model)"),Z1o=l(),Mu=a("li"),nle=a("strong"),ebo=o("splinter"),obo=o(" \u2014 "),Bq=a("a"),rbo=o("SplinterModel"),tbo=o(" (Splinter model)"),abo=l(),Eu=a("li"),sle=a("strong"),nbo=o("squeezebert"),sbo=o(" \u2014 "),Iq=a("a"),lbo=o("SqueezeBertModel"),ibo=o(" (SqueezeBERT model)"),dbo=l(),Cu=a("li"),lle=a("strong"),cbo=o("swin"),fbo=o(" \u2014 "),qq=a("a"),mbo=o("SwinModel"),gbo=o(" (Swin model)"),hbo=l(),wu=a("li"),ile=a("strong"),pbo=o("t5"),ubo=o(" \u2014 "),Nq=a("a"),_bo=o("T5Model"),bbo=o(" (T5 model)"),vbo=l(),Au=a("li"),dle=a("strong"),Fbo=o("tapas"),Tbo=o(" \u2014 "),jq=a("a"),Mbo=o("TapasModel"),Ebo=o(" (TAPAS model)"),Cbo=l(),yu=a("li"),cle=a("strong"),wbo=o("transfo-xl"),Abo=o(" \u2014 "),Dq=a("a"),ybo=o("TransfoXLModel"),Lbo=o(" (Transformer-XL model)"),xbo=l(),Lu=a("li"),fle=a("strong"),$bo=o("unispeech"),kbo=o(" \u2014 "),Gq=a("a"),Sbo=o("UniSpeechModel"),Rbo=o(" (UniSpeech model)"),Pbo=l(),xu=a("li"),mle=a("strong"),Bbo=o("unispeech-sat"),Ibo=o(" \u2014 "),Oq=a("a"),qbo=o("UniSpeechSatModel"),Nbo=o(" (UniSpeechSat model)"),jbo=l(),$u=a("li"),gle=a("strong"),Dbo=o("van"),Gbo=o(" \u2014 "),Vq=a("a"),Obo=o("VanModel"),Vbo=o(" (VAN model)"),Xbo=l(),ku=a("li"),hle=a("strong"),zbo=o("vilt"),Qbo=o(" \u2014 "),Xq=a("a"),Wbo=o("ViltModel"),Hbo=o(" (ViLT model)"),Ubo=l(),Su=a("li"),ple=a("strong"),Jbo=o("vision-text-dual-encoder"),Ybo=o(" \u2014 "),zq=a("a"),Kbo=o("VisionTextDualEncoderModel"),Zbo=o(" (VisionTextDualEncoder model)"),evo=l(),Ru=a("li"),ule=a("strong"),ovo=o("visual_bert"),rvo=o(" \u2014 "),Qq=a("a"),tvo=o("VisualBertModel"),avo=o(" (VisualBert model)"),nvo=l(),Pu=a("li"),_le=a("strong"),svo=o("vit"),lvo=o(" \u2014 "),Wq=a("a"),ivo=o("ViTModel"),dvo=o(" (ViT model)"),cvo=l(),Bu=a("li"),ble=a("strong"),fvo=o("vit_mae"),mvo=o(" \u2014 "),Hq=a("a"),gvo=o("ViTMAEModel"),hvo=o(" (ViTMAE model)"),pvo=l(),Iu=a("li"),vle=a("strong"),uvo=o("wav2vec2"),_vo=o(" \u2014 "),Uq=a("a"),bvo=o("Wav2Vec2Model"),vvo=o(" (Wav2Vec2 model)"),Fvo=l(),qu=a("li"),Fle=a("strong"),Tvo=o("wavlm"),Mvo=o(" \u2014 "),Jq=a("a"),Evo=o("WavLMModel"),Cvo=o(" (WavLM model)"),wvo=l(),Nu=a("li"),Tle=a("strong"),Avo=o("xglm"),yvo=o(" \u2014 "),Yq=a("a"),Lvo=o("XGLMModel"),xvo=o(" (XGLM model)"),$vo=l(),ju=a("li"),Mle=a("strong"),kvo=o("xlm"),Svo=o(" \u2014 "),Kq=a("a"),Rvo=o("XLMModel"),Pvo=o(" (XLM model)"),Bvo=l(),Du=a("li"),Ele=a("strong"),Ivo=o("xlm-prophetnet"),qvo=o(" \u2014 "),Zq=a("a"),Nvo=o("XLMProphetNetModel"),jvo=o(" (XLMProphetNet model)"),Dvo=l(),Gu=a("li"),Cle=a("strong"),Gvo=o("xlm-roberta"),Ovo=o(" \u2014 "),eN=a("a"),Vvo=o("XLMRobertaModel"),Xvo=o(" (XLM-RoBERTa model)"),zvo=l(),Ou=a("li"),wle=a("strong"),Qvo=o("xlm-roberta-xl"),Wvo=o(" \u2014 "),oN=a("a"),Hvo=o("XLMRobertaXLModel"),Uvo=o(" (XLM-RoBERTa-XL model)"),Jvo=l(),Vu=a("li"),Ale=a("strong"),Yvo=o("xlnet"),Kvo=o(" \u2014 "),rN=a("a"),Zvo=o("XLNetModel"),eFo=o(" (XLNet model)"),oFo=l(),Xu=a("li"),yle=a("strong"),rFo=o("yolos"),tFo=o(" \u2014 "),tN=a("a"),aFo=o("YolosModel"),nFo=o(" (YOLOS model)"),sFo=l(),zu=a("li"),Lle=a("strong"),lFo=o("yoso"),iFo=o(" \u2014 "),aN=a("a"),dFo=o("YosoModel"),cFo=o(" (YOSO model)"),fFo=l(),Qu=a("p"),mFo=o("The model is set in evaluation mode by default using "),xle=a("code"),gFo=o("model.eval()"),hFo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$le=a("code"),pFo=o("model.train()"),uFo=l(),F(Wu.$$.fragment),rqe=l(),ki=a("h2"),Hu=a("a"),kle=a("span"),F(WA.$$.fragment),_Fo=l(),Sle=a("span"),bFo=o("AutoModelForPreTraining"),tqe=l(),$o=a("div"),F(HA.$$.fragment),vFo=l(),Si=a("p"),FFo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),nN=a("a"),TFo=o("from_pretrained()"),MFo=o(" class method or the "),sN=a("a"),EFo=o("from_config()"),CFo=o(` class
method.`),wFo=l(),UA=a("p"),AFo=o("This class cannot be instantiated directly using "),Rle=a("code"),yFo=o("__init__()"),LFo=o(" (throws an error)."),xFo=l(),at=a("div"),F(JA.$$.fragment),$Fo=l(),Ple=a("p"),kFo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),SFo=l(),Ri=a("p"),RFo=o(`Note:
Loading a model from its configuration file does `),Ble=a("strong"),PFo=o("not"),BFo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lN=a("a"),IFo=o("from_pretrained()"),qFo=o(" to load the model weights."),NFo=l(),F(Uu.$$.fragment),jFo=l(),Ue=a("div"),F(YA.$$.fragment),DFo=l(),Ile=a("p"),GFo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),OFo=l(),ka=a("p"),VFo=o("The model class to instantiate is selected based on the "),qle=a("code"),XFo=o("model_type"),zFo=o(` property of the config object (either
passed as an argument or loaded from `),Nle=a("code"),QFo=o("pretrained_model_name_or_path"),WFo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jle=a("code"),HFo=o("pretrained_model_name_or_path"),UFo=o(":"),JFo=l(),G=a("ul"),Ju=a("li"),Dle=a("strong"),YFo=o("albert"),KFo=o(" \u2014 "),iN=a("a"),ZFo=o("AlbertForPreTraining"),e6o=o(" (ALBERT model)"),o6o=l(),Yu=a("li"),Gle=a("strong"),r6o=o("bart"),t6o=o(" \u2014 "),dN=a("a"),a6o=o("BartForConditionalGeneration"),n6o=o(" (BART model)"),s6o=l(),Ku=a("li"),Ole=a("strong"),l6o=o("bert"),i6o=o(" \u2014 "),cN=a("a"),d6o=o("BertForPreTraining"),c6o=o(" (BERT model)"),f6o=l(),Zu=a("li"),Vle=a("strong"),m6o=o("big_bird"),g6o=o(" \u2014 "),fN=a("a"),h6o=o("BigBirdForPreTraining"),p6o=o(" (BigBird model)"),u6o=l(),e_=a("li"),Xle=a("strong"),_6o=o("camembert"),b6o=o(" \u2014 "),mN=a("a"),v6o=o("CamembertForMaskedLM"),F6o=o(" (CamemBERT model)"),T6o=l(),o_=a("li"),zle=a("strong"),M6o=o("ctrl"),E6o=o(" \u2014 "),gN=a("a"),C6o=o("CTRLLMHeadModel"),w6o=o(" (CTRL model)"),A6o=l(),r_=a("li"),Qle=a("strong"),y6o=o("data2vec-text"),L6o=o(" \u2014 "),hN=a("a"),x6o=o("Data2VecTextForMaskedLM"),$6o=o(" (Data2VecText model)"),k6o=l(),t_=a("li"),Wle=a("strong"),S6o=o("deberta"),R6o=o(" \u2014 "),pN=a("a"),P6o=o("DebertaForMaskedLM"),B6o=o(" (DeBERTa model)"),I6o=l(),a_=a("li"),Hle=a("strong"),q6o=o("deberta-v2"),N6o=o(" \u2014 "),uN=a("a"),j6o=o("DebertaV2ForMaskedLM"),D6o=o(" (DeBERTa-v2 model)"),G6o=l(),n_=a("li"),Ule=a("strong"),O6o=o("distilbert"),V6o=o(" \u2014 "),_N=a("a"),X6o=o("DistilBertForMaskedLM"),z6o=o(" (DistilBERT model)"),Q6o=l(),s_=a("li"),Jle=a("strong"),W6o=o("electra"),H6o=o(" \u2014 "),bN=a("a"),U6o=o("ElectraForPreTraining"),J6o=o(" (ELECTRA model)"),Y6o=l(),l_=a("li"),Yle=a("strong"),K6o=o("flaubert"),Z6o=o(" \u2014 "),vN=a("a"),eTo=o("FlaubertWithLMHeadModel"),oTo=o(" (FlauBERT model)"),rTo=l(),i_=a("li"),Kle=a("strong"),tTo=o("flava"),aTo=o(" \u2014 "),FN=a("a"),nTo=o("FlavaForPreTraining"),sTo=o(" (Flava model)"),lTo=l(),d_=a("li"),Zle=a("strong"),iTo=o("fnet"),dTo=o(" \u2014 "),TN=a("a"),cTo=o("FNetForPreTraining"),fTo=o(" (FNet model)"),mTo=l(),c_=a("li"),eie=a("strong"),gTo=o("fsmt"),hTo=o(" \u2014 "),MN=a("a"),pTo=o("FSMTForConditionalGeneration"),uTo=o(" (FairSeq Machine-Translation model)"),_To=l(),f_=a("li"),oie=a("strong"),bTo=o("funnel"),vTo=o(" \u2014 "),EN=a("a"),FTo=o("FunnelForPreTraining"),TTo=o(" (Funnel Transformer model)"),MTo=l(),m_=a("li"),rie=a("strong"),ETo=o("gpt2"),CTo=o(" \u2014 "),CN=a("a"),wTo=o("GPT2LMHeadModel"),ATo=o(" (OpenAI GPT-2 model)"),yTo=l(),g_=a("li"),tie=a("strong"),LTo=o("ibert"),xTo=o(" \u2014 "),wN=a("a"),$To=o("IBertForMaskedLM"),kTo=o(" (I-BERT model)"),STo=l(),h_=a("li"),aie=a("strong"),RTo=o("layoutlm"),PTo=o(" \u2014 "),AN=a("a"),BTo=o("LayoutLMForMaskedLM"),ITo=o(" (LayoutLM model)"),qTo=l(),p_=a("li"),nie=a("strong"),NTo=o("longformer"),jTo=o(" \u2014 "),yN=a("a"),DTo=o("LongformerForMaskedLM"),GTo=o(" (Longformer model)"),OTo=l(),u_=a("li"),sie=a("strong"),VTo=o("lxmert"),XTo=o(" \u2014 "),LN=a("a"),zTo=o("LxmertForPreTraining"),QTo=o(" (LXMERT model)"),WTo=l(),__=a("li"),lie=a("strong"),HTo=o("megatron-bert"),UTo=o(" \u2014 "),xN=a("a"),JTo=o("MegatronBertForPreTraining"),YTo=o(" (MegatronBert model)"),KTo=l(),b_=a("li"),iie=a("strong"),ZTo=o("mobilebert"),e8o=o(" \u2014 "),$N=a("a"),o8o=o("MobileBertForPreTraining"),r8o=o(" (MobileBERT model)"),t8o=l(),v_=a("li"),die=a("strong"),a8o=o("mpnet"),n8o=o(" \u2014 "),kN=a("a"),s8o=o("MPNetForMaskedLM"),l8o=o(" (MPNet model)"),i8o=l(),F_=a("li"),cie=a("strong"),d8o=o("openai-gpt"),c8o=o(" \u2014 "),SN=a("a"),f8o=o("OpenAIGPTLMHeadModel"),m8o=o(" (OpenAI GPT model)"),g8o=l(),T_=a("li"),fie=a("strong"),h8o=o("retribert"),p8o=o(" \u2014 "),RN=a("a"),u8o=o("RetriBertModel"),_8o=o(" (RetriBERT model)"),b8o=l(),M_=a("li"),mie=a("strong"),v8o=o("roberta"),F8o=o(" \u2014 "),PN=a("a"),T8o=o("RobertaForMaskedLM"),M8o=o(" (RoBERTa model)"),E8o=l(),E_=a("li"),gie=a("strong"),C8o=o("squeezebert"),w8o=o(" \u2014 "),BN=a("a"),A8o=o("SqueezeBertForMaskedLM"),y8o=o(" (SqueezeBERT model)"),L8o=l(),C_=a("li"),hie=a("strong"),x8o=o("t5"),$8o=o(" \u2014 "),IN=a("a"),k8o=o("T5ForConditionalGeneration"),S8o=o(" (T5 model)"),R8o=l(),w_=a("li"),pie=a("strong"),P8o=o("tapas"),B8o=o(" \u2014 "),qN=a("a"),I8o=o("TapasForMaskedLM"),q8o=o(" (TAPAS model)"),N8o=l(),A_=a("li"),uie=a("strong"),j8o=o("transfo-xl"),D8o=o(" \u2014 "),NN=a("a"),G8o=o("TransfoXLLMHeadModel"),O8o=o(" (Transformer-XL model)"),V8o=l(),y_=a("li"),_ie=a("strong"),X8o=o("unispeech"),z8o=o(" \u2014 "),jN=a("a"),Q8o=o("UniSpeechForPreTraining"),W8o=o(" (UniSpeech model)"),H8o=l(),L_=a("li"),bie=a("strong"),U8o=o("unispeech-sat"),J8o=o(" \u2014 "),DN=a("a"),Y8o=o("UniSpeechSatForPreTraining"),K8o=o(" (UniSpeechSat model)"),Z8o=l(),x_=a("li"),vie=a("strong"),e7o=o("visual_bert"),o7o=o(" \u2014 "),GN=a("a"),r7o=o("VisualBertForPreTraining"),t7o=o(" (VisualBert model)"),a7o=l(),$_=a("li"),Fie=a("strong"),n7o=o("vit_mae"),s7o=o(" \u2014 "),ON=a("a"),l7o=o("ViTMAEForPreTraining"),i7o=o(" (ViTMAE model)"),d7o=l(),k_=a("li"),Tie=a("strong"),c7o=o("wav2vec2"),f7o=o(" \u2014 "),VN=a("a"),m7o=o("Wav2Vec2ForPreTraining"),g7o=o(" (Wav2Vec2 model)"),h7o=l(),S_=a("li"),Mie=a("strong"),p7o=o("xlm"),u7o=o(" \u2014 "),XN=a("a"),_7o=o("XLMWithLMHeadModel"),b7o=o(" (XLM model)"),v7o=l(),R_=a("li"),Eie=a("strong"),F7o=o("xlm-roberta"),T7o=o(" \u2014 "),zN=a("a"),M7o=o("XLMRobertaForMaskedLM"),E7o=o(" (XLM-RoBERTa model)"),C7o=l(),P_=a("li"),Cie=a("strong"),w7o=o("xlm-roberta-xl"),A7o=o(" \u2014 "),QN=a("a"),y7o=o("XLMRobertaXLForMaskedLM"),L7o=o(" (XLM-RoBERTa-XL model)"),x7o=l(),B_=a("li"),wie=a("strong"),$7o=o("xlnet"),k7o=o(" \u2014 "),WN=a("a"),S7o=o("XLNetLMHeadModel"),R7o=o(" (XLNet model)"),P7o=l(),I_=a("p"),B7o=o("The model is set in evaluation mode by default using "),Aie=a("code"),I7o=o("model.eval()"),q7o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yie=a("code"),N7o=o("model.train()"),j7o=l(),F(q_.$$.fragment),aqe=l(),Pi=a("h2"),N_=a("a"),Lie=a("span"),F(KA.$$.fragment),D7o=l(),xie=a("span"),G7o=o("AutoModelForCausalLM"),nqe=l(),ko=a("div"),F(ZA.$$.fragment),O7o=l(),Bi=a("p"),V7o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),HN=a("a"),X7o=o("from_pretrained()"),z7o=o(" class method or the "),UN=a("a"),Q7o=o("from_config()"),W7o=o(` class
method.`),H7o=l(),e0=a("p"),U7o=o("This class cannot be instantiated directly using "),$ie=a("code"),J7o=o("__init__()"),Y7o=o(" (throws an error)."),K7o=l(),nt=a("div"),F(o0.$$.fragment),Z7o=l(),kie=a("p"),eMo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),oMo=l(),Ii=a("p"),rMo=o(`Note:
Loading a model from its configuration file does `),Sie=a("strong"),tMo=o("not"),aMo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JN=a("a"),nMo=o("from_pretrained()"),sMo=o(" to load the model weights."),lMo=l(),F(j_.$$.fragment),iMo=l(),Je=a("div"),F(r0.$$.fragment),dMo=l(),Rie=a("p"),cMo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),fMo=l(),Sa=a("p"),mMo=o("The model class to instantiate is selected based on the "),Pie=a("code"),gMo=o("model_type"),hMo=o(` property of the config object (either
passed as an argument or loaded from `),Bie=a("code"),pMo=o("pretrained_model_name_or_path"),uMo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Iie=a("code"),_Mo=o("pretrained_model_name_or_path"),bMo=o(":"),vMo=l(),z=a("ul"),D_=a("li"),qie=a("strong"),FMo=o("bart"),TMo=o(" \u2014 "),YN=a("a"),MMo=o("BartForCausalLM"),EMo=o(" (BART model)"),CMo=l(),G_=a("li"),Nie=a("strong"),wMo=o("bert"),AMo=o(" \u2014 "),KN=a("a"),yMo=o("BertLMHeadModel"),LMo=o(" (BERT model)"),xMo=l(),O_=a("li"),jie=a("strong"),$Mo=o("bert-generation"),kMo=o(" \u2014 "),ZN=a("a"),SMo=o("BertGenerationDecoder"),RMo=o(" (Bert Generation model)"),PMo=l(),V_=a("li"),Die=a("strong"),BMo=o("big_bird"),IMo=o(" \u2014 "),ej=a("a"),qMo=o("BigBirdForCausalLM"),NMo=o(" (BigBird model)"),jMo=l(),X_=a("li"),Gie=a("strong"),DMo=o("bigbird_pegasus"),GMo=o(" \u2014 "),oj=a("a"),OMo=o("BigBirdPegasusForCausalLM"),VMo=o(" (BigBirdPegasus model)"),XMo=l(),z_=a("li"),Oie=a("strong"),zMo=o("blenderbot"),QMo=o(" \u2014 "),rj=a("a"),WMo=o("BlenderbotForCausalLM"),HMo=o(" (Blenderbot model)"),UMo=l(),Q_=a("li"),Vie=a("strong"),JMo=o("blenderbot-small"),YMo=o(" \u2014 "),tj=a("a"),KMo=o("BlenderbotSmallForCausalLM"),ZMo=o(" (BlenderbotSmall model)"),e4o=l(),W_=a("li"),Xie=a("strong"),o4o=o("camembert"),r4o=o(" \u2014 "),aj=a("a"),t4o=o("CamembertForCausalLM"),a4o=o(" (CamemBERT model)"),n4o=l(),H_=a("li"),zie=a("strong"),s4o=o("ctrl"),l4o=o(" \u2014 "),nj=a("a"),i4o=o("CTRLLMHeadModel"),d4o=o(" (CTRL model)"),c4o=l(),U_=a("li"),Qie=a("strong"),f4o=o("data2vec-text"),m4o=o(" \u2014 "),sj=a("a"),g4o=o("Data2VecTextForCausalLM"),h4o=o(" (Data2VecText model)"),p4o=l(),J_=a("li"),Wie=a("strong"),u4o=o("electra"),_4o=o(" \u2014 "),lj=a("a"),b4o=o("ElectraForCausalLM"),v4o=o(" (ELECTRA model)"),F4o=l(),Y_=a("li"),Hie=a("strong"),T4o=o("gpt2"),M4o=o(" \u2014 "),ij=a("a"),E4o=o("GPT2LMHeadModel"),C4o=o(" (OpenAI GPT-2 model)"),w4o=l(),K_=a("li"),Uie=a("strong"),A4o=o("gpt_neo"),y4o=o(" \u2014 "),dj=a("a"),L4o=o("GPTNeoForCausalLM"),x4o=o(" (GPT Neo model)"),$4o=l(),Z_=a("li"),Jie=a("strong"),k4o=o("gptj"),S4o=o(" \u2014 "),cj=a("a"),R4o=o("GPTJForCausalLM"),P4o=o(" (GPT-J model)"),B4o=l(),e2=a("li"),Yie=a("strong"),I4o=o("marian"),q4o=o(" \u2014 "),fj=a("a"),N4o=o("MarianForCausalLM"),j4o=o(" (Marian model)"),D4o=l(),o2=a("li"),Kie=a("strong"),G4o=o("mbart"),O4o=o(" \u2014 "),mj=a("a"),V4o=o("MBartForCausalLM"),X4o=o(" (mBART model)"),z4o=l(),r2=a("li"),Zie=a("strong"),Q4o=o("megatron-bert"),W4o=o(" \u2014 "),gj=a("a"),H4o=o("MegatronBertForCausalLM"),U4o=o(" (MegatronBert model)"),J4o=l(),t2=a("li"),ede=a("strong"),Y4o=o("openai-gpt"),K4o=o(" \u2014 "),hj=a("a"),Z4o=o("OpenAIGPTLMHeadModel"),eEo=o(" (OpenAI GPT model)"),oEo=l(),a2=a("li"),ode=a("strong"),rEo=o("opt"),tEo=o(" \u2014 "),pj=a("a"),aEo=o("OPTForCausalLM"),nEo=o(" (OPT model)"),sEo=l(),n2=a("li"),rde=a("strong"),lEo=o("pegasus"),iEo=o(" \u2014 "),uj=a("a"),dEo=o("PegasusForCausalLM"),cEo=o(" (Pegasus model)"),fEo=l(),s2=a("li"),tde=a("strong"),mEo=o("plbart"),gEo=o(" \u2014 "),_j=a("a"),hEo=o("PLBartForCausalLM"),pEo=o(" (PLBart model)"),uEo=l(),l2=a("li"),ade=a("strong"),_Eo=o("prophetnet"),bEo=o(" \u2014 "),bj=a("a"),vEo=o("ProphetNetForCausalLM"),FEo=o(" (ProphetNet model)"),TEo=l(),i2=a("li"),nde=a("strong"),MEo=o("qdqbert"),EEo=o(" \u2014 "),vj=a("a"),CEo=o("QDQBertLMHeadModel"),wEo=o(" (QDQBert model)"),AEo=l(),d2=a("li"),sde=a("strong"),yEo=o("reformer"),LEo=o(" \u2014 "),Fj=a("a"),xEo=o("ReformerModelWithLMHead"),$Eo=o(" (Reformer model)"),kEo=l(),c2=a("li"),lde=a("strong"),SEo=o("rembert"),REo=o(" \u2014 "),Tj=a("a"),PEo=o("RemBertForCausalLM"),BEo=o(" (RemBERT model)"),IEo=l(),f2=a("li"),ide=a("strong"),qEo=o("roberta"),NEo=o(" \u2014 "),Mj=a("a"),jEo=o("RobertaForCausalLM"),DEo=o(" (RoBERTa model)"),GEo=l(),m2=a("li"),dde=a("strong"),OEo=o("roformer"),VEo=o(" \u2014 "),Ej=a("a"),XEo=o("RoFormerForCausalLM"),zEo=o(" (RoFormer model)"),QEo=l(),g2=a("li"),cde=a("strong"),WEo=o("speech_to_text_2"),HEo=o(" \u2014 "),Cj=a("a"),UEo=o("Speech2Text2ForCausalLM"),JEo=o(" (Speech2Text2 model)"),YEo=l(),h2=a("li"),fde=a("strong"),KEo=o("transfo-xl"),ZEo=o(" \u2014 "),wj=a("a"),e5o=o("TransfoXLLMHeadModel"),o5o=o(" (Transformer-XL model)"),r5o=l(),p2=a("li"),mde=a("strong"),t5o=o("trocr"),a5o=o(" \u2014 "),Aj=a("a"),n5o=o("TrOCRForCausalLM"),s5o=o(" (TrOCR model)"),l5o=l(),u2=a("li"),gde=a("strong"),i5o=o("xglm"),d5o=o(" \u2014 "),yj=a("a"),c5o=o("XGLMForCausalLM"),f5o=o(" (XGLM model)"),m5o=l(),_2=a("li"),hde=a("strong"),g5o=o("xlm"),h5o=o(" \u2014 "),Lj=a("a"),p5o=o("XLMWithLMHeadModel"),u5o=o(" (XLM model)"),_5o=l(),b2=a("li"),pde=a("strong"),b5o=o("xlm-prophetnet"),v5o=o(" \u2014 "),xj=a("a"),F5o=o("XLMProphetNetForCausalLM"),T5o=o(" (XLMProphetNet model)"),M5o=l(),v2=a("li"),ude=a("strong"),E5o=o("xlm-roberta"),C5o=o(" \u2014 "),$j=a("a"),w5o=o("XLMRobertaForCausalLM"),A5o=o(" (XLM-RoBERTa model)"),y5o=l(),F2=a("li"),_de=a("strong"),L5o=o("xlm-roberta-xl"),x5o=o(" \u2014 "),kj=a("a"),$5o=o("XLMRobertaXLForCausalLM"),k5o=o(" (XLM-RoBERTa-XL model)"),S5o=l(),T2=a("li"),bde=a("strong"),R5o=o("xlnet"),P5o=o(" \u2014 "),Sj=a("a"),B5o=o("XLNetLMHeadModel"),I5o=o(" (XLNet model)"),q5o=l(),M2=a("p"),N5o=o("The model is set in evaluation mode by default using "),vde=a("code"),j5o=o("model.eval()"),D5o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fde=a("code"),G5o=o("model.train()"),O5o=l(),F(E2.$$.fragment),sqe=l(),qi=a("h2"),C2=a("a"),Tde=a("span"),F(t0.$$.fragment),V5o=l(),Mde=a("span"),X5o=o("AutoModelForMaskedLM"),lqe=l(),So=a("div"),F(a0.$$.fragment),z5o=l(),Ni=a("p"),Q5o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Rj=a("a"),W5o=o("from_pretrained()"),H5o=o(" class method or the "),Pj=a("a"),U5o=o("from_config()"),J5o=o(` class
method.`),Y5o=l(),n0=a("p"),K5o=o("This class cannot be instantiated directly using "),Ede=a("code"),Z5o=o("__init__()"),eCo=o(" (throws an error)."),oCo=l(),st=a("div"),F(s0.$$.fragment),rCo=l(),Cde=a("p"),tCo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),aCo=l(),ji=a("p"),nCo=o(`Note:
Loading a model from its configuration file does `),wde=a("strong"),sCo=o("not"),lCo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Bj=a("a"),iCo=o("from_pretrained()"),dCo=o(" to load the model weights."),cCo=l(),F(w2.$$.fragment),fCo=l(),Ye=a("div"),F(l0.$$.fragment),mCo=l(),Ade=a("p"),gCo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),hCo=l(),Ra=a("p"),pCo=o("The model class to instantiate is selected based on the "),yde=a("code"),uCo=o("model_type"),_Co=o(` property of the config object (either
passed as an argument or loaded from `),Lde=a("code"),bCo=o("pretrained_model_name_or_path"),vCo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xde=a("code"),FCo=o("pretrained_model_name_or_path"),TCo=o(":"),MCo=l(),Q=a("ul"),A2=a("li"),$de=a("strong"),ECo=o("albert"),CCo=o(" \u2014 "),Ij=a("a"),wCo=o("AlbertForMaskedLM"),ACo=o(" (ALBERT model)"),yCo=l(),y2=a("li"),kde=a("strong"),LCo=o("bart"),xCo=o(" \u2014 "),qj=a("a"),$Co=o("BartForConditionalGeneration"),kCo=o(" (BART model)"),SCo=l(),L2=a("li"),Sde=a("strong"),RCo=o("bert"),PCo=o(" \u2014 "),Nj=a("a"),BCo=o("BertForMaskedLM"),ICo=o(" (BERT model)"),qCo=l(),x2=a("li"),Rde=a("strong"),NCo=o("big_bird"),jCo=o(" \u2014 "),jj=a("a"),DCo=o("BigBirdForMaskedLM"),GCo=o(" (BigBird model)"),OCo=l(),$2=a("li"),Pde=a("strong"),VCo=o("camembert"),XCo=o(" \u2014 "),Dj=a("a"),zCo=o("CamembertForMaskedLM"),QCo=o(" (CamemBERT model)"),WCo=l(),k2=a("li"),Bde=a("strong"),HCo=o("convbert"),UCo=o(" \u2014 "),Gj=a("a"),JCo=o("ConvBertForMaskedLM"),YCo=o(" (ConvBERT model)"),KCo=l(),S2=a("li"),Ide=a("strong"),ZCo=o("data2vec-text"),e3o=o(" \u2014 "),Oj=a("a"),o3o=o("Data2VecTextForMaskedLM"),r3o=o(" (Data2VecText model)"),t3o=l(),R2=a("li"),qde=a("strong"),a3o=o("deberta"),n3o=o(" \u2014 "),Vj=a("a"),s3o=o("DebertaForMaskedLM"),l3o=o(" (DeBERTa model)"),i3o=l(),P2=a("li"),Nde=a("strong"),d3o=o("deberta-v2"),c3o=o(" \u2014 "),Xj=a("a"),f3o=o("DebertaV2ForMaskedLM"),m3o=o(" (DeBERTa-v2 model)"),g3o=l(),B2=a("li"),jde=a("strong"),h3o=o("distilbert"),p3o=o(" \u2014 "),zj=a("a"),u3o=o("DistilBertForMaskedLM"),_3o=o(" (DistilBERT model)"),b3o=l(),I2=a("li"),Dde=a("strong"),v3o=o("electra"),F3o=o(" \u2014 "),Qj=a("a"),T3o=o("ElectraForMaskedLM"),M3o=o(" (ELECTRA model)"),E3o=l(),q2=a("li"),Gde=a("strong"),C3o=o("flaubert"),w3o=o(" \u2014 "),Wj=a("a"),A3o=o("FlaubertWithLMHeadModel"),y3o=o(" (FlauBERT model)"),L3o=l(),N2=a("li"),Ode=a("strong"),x3o=o("fnet"),$3o=o(" \u2014 "),Hj=a("a"),k3o=o("FNetForMaskedLM"),S3o=o(" (FNet model)"),R3o=l(),j2=a("li"),Vde=a("strong"),P3o=o("funnel"),B3o=o(" \u2014 "),Uj=a("a"),I3o=o("FunnelForMaskedLM"),q3o=o(" (Funnel Transformer model)"),N3o=l(),D2=a("li"),Xde=a("strong"),j3o=o("ibert"),D3o=o(" \u2014 "),Jj=a("a"),G3o=o("IBertForMaskedLM"),O3o=o(" (I-BERT model)"),V3o=l(),G2=a("li"),zde=a("strong"),X3o=o("layoutlm"),z3o=o(" \u2014 "),Yj=a("a"),Q3o=o("LayoutLMForMaskedLM"),W3o=o(" (LayoutLM model)"),H3o=l(),O2=a("li"),Qde=a("strong"),U3o=o("longformer"),J3o=o(" \u2014 "),Kj=a("a"),Y3o=o("LongformerForMaskedLM"),K3o=o(" (Longformer model)"),Z3o=l(),V2=a("li"),Wde=a("strong"),ewo=o("mbart"),owo=o(" \u2014 "),Zj=a("a"),rwo=o("MBartForConditionalGeneration"),two=o(" (mBART model)"),awo=l(),X2=a("li"),Hde=a("strong"),nwo=o("megatron-bert"),swo=o(" \u2014 "),eD=a("a"),lwo=o("MegatronBertForMaskedLM"),iwo=o(" (MegatronBert model)"),dwo=l(),z2=a("li"),Ude=a("strong"),cwo=o("mobilebert"),fwo=o(" \u2014 "),oD=a("a"),mwo=o("MobileBertForMaskedLM"),gwo=o(" (MobileBERT model)"),hwo=l(),Q2=a("li"),Jde=a("strong"),pwo=o("mpnet"),uwo=o(" \u2014 "),rD=a("a"),_wo=o("MPNetForMaskedLM"),bwo=o(" (MPNet model)"),vwo=l(),W2=a("li"),Yde=a("strong"),Fwo=o("nystromformer"),Two=o(" \u2014 "),tD=a("a"),Mwo=o("NystromformerForMaskedLM"),Ewo=o(" (Nystromformer model)"),Cwo=l(),H2=a("li"),Kde=a("strong"),wwo=o("perceiver"),Awo=o(" \u2014 "),aD=a("a"),ywo=o("PerceiverForMaskedLM"),Lwo=o(" (Perceiver model)"),xwo=l(),U2=a("li"),Zde=a("strong"),$wo=o("qdqbert"),kwo=o(" \u2014 "),nD=a("a"),Swo=o("QDQBertForMaskedLM"),Rwo=o(" (QDQBert model)"),Pwo=l(),J2=a("li"),ece=a("strong"),Bwo=o("reformer"),Iwo=o(" \u2014 "),sD=a("a"),qwo=o("ReformerForMaskedLM"),Nwo=o(" (Reformer model)"),jwo=l(),Y2=a("li"),oce=a("strong"),Dwo=o("rembert"),Gwo=o(" \u2014 "),lD=a("a"),Owo=o("RemBertForMaskedLM"),Vwo=o(" (RemBERT model)"),Xwo=l(),K2=a("li"),rce=a("strong"),zwo=o("roberta"),Qwo=o(" \u2014 "),iD=a("a"),Wwo=o("RobertaForMaskedLM"),Hwo=o(" (RoBERTa model)"),Uwo=l(),Z2=a("li"),tce=a("strong"),Jwo=o("roformer"),Ywo=o(" \u2014 "),dD=a("a"),Kwo=o("RoFormerForMaskedLM"),Zwo=o(" (RoFormer model)"),eAo=l(),e1=a("li"),ace=a("strong"),oAo=o("squeezebert"),rAo=o(" \u2014 "),cD=a("a"),tAo=o("SqueezeBertForMaskedLM"),aAo=o(" (SqueezeBERT model)"),nAo=l(),o1=a("li"),nce=a("strong"),sAo=o("tapas"),lAo=o(" \u2014 "),fD=a("a"),iAo=o("TapasForMaskedLM"),dAo=o(" (TAPAS model)"),cAo=l(),r1=a("li"),sce=a("strong"),fAo=o("wav2vec2"),mAo=o(" \u2014 "),lce=a("code"),gAo=o("Wav2Vec2ForMaskedLM"),hAo=o(" (Wav2Vec2 model)"),pAo=l(),t1=a("li"),ice=a("strong"),uAo=o("xlm"),_Ao=o(" \u2014 "),mD=a("a"),bAo=o("XLMWithLMHeadModel"),vAo=o(" (XLM model)"),FAo=l(),a1=a("li"),dce=a("strong"),TAo=o("xlm-roberta"),MAo=o(" \u2014 "),gD=a("a"),EAo=o("XLMRobertaForMaskedLM"),CAo=o(" (XLM-RoBERTa model)"),wAo=l(),n1=a("li"),cce=a("strong"),AAo=o("xlm-roberta-xl"),yAo=o(" \u2014 "),hD=a("a"),LAo=o("XLMRobertaXLForMaskedLM"),xAo=o(" (XLM-RoBERTa-XL model)"),$Ao=l(),s1=a("li"),fce=a("strong"),kAo=o("yoso"),SAo=o(" \u2014 "),pD=a("a"),RAo=o("YosoForMaskedLM"),PAo=o(" (YOSO model)"),BAo=l(),l1=a("p"),IAo=o("The model is set in evaluation mode by default using "),mce=a("code"),qAo=o("model.eval()"),NAo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gce=a("code"),jAo=o("model.train()"),DAo=l(),F(i1.$$.fragment),iqe=l(),Di=a("h2"),d1=a("a"),hce=a("span"),F(i0.$$.fragment),GAo=l(),pce=a("span"),OAo=o("AutoModelForSeq2SeqLM"),dqe=l(),Ro=a("div"),F(d0.$$.fragment),VAo=l(),Gi=a("p"),XAo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),uD=a("a"),zAo=o("from_pretrained()"),QAo=o(" class method or the "),_D=a("a"),WAo=o("from_config()"),HAo=o(` class
method.`),UAo=l(),c0=a("p"),JAo=o("This class cannot be instantiated directly using "),uce=a("code"),YAo=o("__init__()"),KAo=o(" (throws an error)."),ZAo=l(),lt=a("div"),F(f0.$$.fragment),e0o=l(),_ce=a("p"),o0o=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),r0o=l(),Oi=a("p"),t0o=o(`Note:
Loading a model from its configuration file does `),bce=a("strong"),a0o=o("not"),n0o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bD=a("a"),s0o=o("from_pretrained()"),l0o=o(" to load the model weights."),i0o=l(),F(c1.$$.fragment),d0o=l(),Ke=a("div"),F(m0.$$.fragment),c0o=l(),vce=a("p"),f0o=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),m0o=l(),Pa=a("p"),g0o=o("The model class to instantiate is selected based on the "),Fce=a("code"),h0o=o("model_type"),p0o=o(` property of the config object (either
passed as an argument or loaded from `),Tce=a("code"),u0o=o("pretrained_model_name_or_path"),_0o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mce=a("code"),b0o=o("pretrained_model_name_or_path"),v0o=o(":"),F0o=l(),he=a("ul"),f1=a("li"),Ece=a("strong"),T0o=o("bart"),M0o=o(" \u2014 "),vD=a("a"),E0o=o("BartForConditionalGeneration"),C0o=o(" (BART model)"),w0o=l(),m1=a("li"),Cce=a("strong"),A0o=o("bigbird_pegasus"),y0o=o(" \u2014 "),FD=a("a"),L0o=o("BigBirdPegasusForConditionalGeneration"),x0o=o(" (BigBirdPegasus model)"),$0o=l(),g1=a("li"),wce=a("strong"),k0o=o("blenderbot"),S0o=o(" \u2014 "),TD=a("a"),R0o=o("BlenderbotForConditionalGeneration"),P0o=o(" (Blenderbot model)"),B0o=l(),h1=a("li"),Ace=a("strong"),I0o=o("blenderbot-small"),q0o=o(" \u2014 "),MD=a("a"),N0o=o("BlenderbotSmallForConditionalGeneration"),j0o=o(" (BlenderbotSmall model)"),D0o=l(),p1=a("li"),yce=a("strong"),G0o=o("encoder-decoder"),O0o=o(" \u2014 "),ED=a("a"),V0o=o("EncoderDecoderModel"),X0o=o(" (Encoder decoder model)"),z0o=l(),u1=a("li"),Lce=a("strong"),Q0o=o("fsmt"),W0o=o(" \u2014 "),CD=a("a"),H0o=o("FSMTForConditionalGeneration"),U0o=o(" (FairSeq Machine-Translation model)"),J0o=l(),_1=a("li"),xce=a("strong"),Y0o=o("led"),K0o=o(" \u2014 "),wD=a("a"),Z0o=o("LEDForConditionalGeneration"),eyo=o(" (LED model)"),oyo=l(),b1=a("li"),$ce=a("strong"),ryo=o("m2m_100"),tyo=o(" \u2014 "),AD=a("a"),ayo=o("M2M100ForConditionalGeneration"),nyo=o(" (M2M100 model)"),syo=l(),v1=a("li"),kce=a("strong"),lyo=o("marian"),iyo=o(" \u2014 "),yD=a("a"),dyo=o("MarianMTModel"),cyo=o(" (Marian model)"),fyo=l(),F1=a("li"),Sce=a("strong"),myo=o("mbart"),gyo=o(" \u2014 "),LD=a("a"),hyo=o("MBartForConditionalGeneration"),pyo=o(" (mBART model)"),uyo=l(),T1=a("li"),Rce=a("strong"),_yo=o("mt5"),byo=o(" \u2014 "),xD=a("a"),vyo=o("MT5ForConditionalGeneration"),Fyo=o(" (mT5 model)"),Tyo=l(),M1=a("li"),Pce=a("strong"),Myo=o("pegasus"),Eyo=o(" \u2014 "),$D=a("a"),Cyo=o("PegasusForConditionalGeneration"),wyo=o(" (Pegasus model)"),Ayo=l(),E1=a("li"),Bce=a("strong"),yyo=o("plbart"),Lyo=o(" \u2014 "),kD=a("a"),xyo=o("PLBartForConditionalGeneration"),$yo=o(" (PLBart model)"),kyo=l(),C1=a("li"),Ice=a("strong"),Syo=o("prophetnet"),Ryo=o(" \u2014 "),SD=a("a"),Pyo=o("ProphetNetForConditionalGeneration"),Byo=o(" (ProphetNet model)"),Iyo=l(),w1=a("li"),qce=a("strong"),qyo=o("t5"),Nyo=o(" \u2014 "),RD=a("a"),jyo=o("T5ForConditionalGeneration"),Dyo=o(" (T5 model)"),Gyo=l(),A1=a("li"),Nce=a("strong"),Oyo=o("tapex"),Vyo=o(" \u2014 "),PD=a("a"),Xyo=o("BartForConditionalGeneration"),zyo=o(" (TAPEX model)"),Qyo=l(),y1=a("li"),jce=a("strong"),Wyo=o("xlm-prophetnet"),Hyo=o(" \u2014 "),BD=a("a"),Uyo=o("XLMProphetNetForConditionalGeneration"),Jyo=o(" (XLMProphetNet model)"),Yyo=l(),L1=a("p"),Kyo=o("The model is set in evaluation mode by default using "),Dce=a("code"),Zyo=o("model.eval()"),eLo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gce=a("code"),oLo=o("model.train()"),rLo=l(),F(x1.$$.fragment),cqe=l(),Vi=a("h2"),$1=a("a"),Oce=a("span"),F(g0.$$.fragment),tLo=l(),Vce=a("span"),aLo=o("AutoModelForSequenceClassification"),fqe=l(),Po=a("div"),F(h0.$$.fragment),nLo=l(),Xi=a("p"),sLo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),ID=a("a"),lLo=o("from_pretrained()"),iLo=o(" class method or the "),qD=a("a"),dLo=o("from_config()"),cLo=o(` class
method.`),fLo=l(),p0=a("p"),mLo=o("This class cannot be instantiated directly using "),Xce=a("code"),gLo=o("__init__()"),hLo=o(" (throws an error)."),pLo=l(),it=a("div"),F(u0.$$.fragment),uLo=l(),zce=a("p"),_Lo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),bLo=l(),zi=a("p"),vLo=o(`Note:
Loading a model from its configuration file does `),Qce=a("strong"),FLo=o("not"),TLo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ND=a("a"),MLo=o("from_pretrained()"),ELo=o(" to load the model weights."),CLo=l(),F(k1.$$.fragment),wLo=l(),Ze=a("div"),F(_0.$$.fragment),ALo=l(),Wce=a("p"),yLo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),LLo=l(),Ba=a("p"),xLo=o("The model class to instantiate is selected based on the "),Hce=a("code"),$Lo=o("model_type"),kLo=o(` property of the config object (either
passed as an argument or loaded from `),Uce=a("code"),SLo=o("pretrained_model_name_or_path"),RLo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jce=a("code"),PLo=o("pretrained_model_name_or_path"),BLo=o(":"),ILo=l(),q=a("ul"),S1=a("li"),Yce=a("strong"),qLo=o("albert"),NLo=o(" \u2014 "),jD=a("a"),jLo=o("AlbertForSequenceClassification"),DLo=o(" (ALBERT model)"),GLo=l(),R1=a("li"),Kce=a("strong"),OLo=o("bart"),VLo=o(" \u2014 "),DD=a("a"),XLo=o("BartForSequenceClassification"),zLo=o(" (BART model)"),QLo=l(),P1=a("li"),Zce=a("strong"),WLo=o("bert"),HLo=o(" \u2014 "),GD=a("a"),ULo=o("BertForSequenceClassification"),JLo=o(" (BERT model)"),YLo=l(),B1=a("li"),efe=a("strong"),KLo=o("big_bird"),ZLo=o(" \u2014 "),OD=a("a"),exo=o("BigBirdForSequenceClassification"),oxo=o(" (BigBird model)"),rxo=l(),I1=a("li"),ofe=a("strong"),txo=o("bigbird_pegasus"),axo=o(" \u2014 "),VD=a("a"),nxo=o("BigBirdPegasusForSequenceClassification"),sxo=o(" (BigBirdPegasus model)"),lxo=l(),q1=a("li"),rfe=a("strong"),ixo=o("camembert"),dxo=o(" \u2014 "),XD=a("a"),cxo=o("CamembertForSequenceClassification"),fxo=o(" (CamemBERT model)"),mxo=l(),N1=a("li"),tfe=a("strong"),gxo=o("canine"),hxo=o(" \u2014 "),zD=a("a"),pxo=o("CanineForSequenceClassification"),uxo=o(" (Canine model)"),_xo=l(),j1=a("li"),afe=a("strong"),bxo=o("convbert"),vxo=o(" \u2014 "),QD=a("a"),Fxo=o("ConvBertForSequenceClassification"),Txo=o(" (ConvBERT model)"),Mxo=l(),D1=a("li"),nfe=a("strong"),Exo=o("ctrl"),Cxo=o(" \u2014 "),WD=a("a"),wxo=o("CTRLForSequenceClassification"),Axo=o(" (CTRL model)"),yxo=l(),G1=a("li"),sfe=a("strong"),Lxo=o("data2vec-text"),xxo=o(" \u2014 "),HD=a("a"),$xo=o("Data2VecTextForSequenceClassification"),kxo=o(" (Data2VecText model)"),Sxo=l(),O1=a("li"),lfe=a("strong"),Rxo=o("deberta"),Pxo=o(" \u2014 "),UD=a("a"),Bxo=o("DebertaForSequenceClassification"),Ixo=o(" (DeBERTa model)"),qxo=l(),V1=a("li"),ife=a("strong"),Nxo=o("deberta-v2"),jxo=o(" \u2014 "),JD=a("a"),Dxo=o("DebertaV2ForSequenceClassification"),Gxo=o(" (DeBERTa-v2 model)"),Oxo=l(),X1=a("li"),dfe=a("strong"),Vxo=o("distilbert"),Xxo=o(" \u2014 "),YD=a("a"),zxo=o("DistilBertForSequenceClassification"),Qxo=o(" (DistilBERT model)"),Wxo=l(),z1=a("li"),cfe=a("strong"),Hxo=o("electra"),Uxo=o(" \u2014 "),KD=a("a"),Jxo=o("ElectraForSequenceClassification"),Yxo=o(" (ELECTRA model)"),Kxo=l(),Q1=a("li"),ffe=a("strong"),Zxo=o("flaubert"),e9o=o(" \u2014 "),ZD=a("a"),o9o=o("FlaubertForSequenceClassification"),r9o=o(" (FlauBERT model)"),t9o=l(),W1=a("li"),mfe=a("strong"),a9o=o("fnet"),n9o=o(" \u2014 "),eG=a("a"),s9o=o("FNetForSequenceClassification"),l9o=o(" (FNet model)"),i9o=l(),H1=a("li"),gfe=a("strong"),d9o=o("funnel"),c9o=o(" \u2014 "),oG=a("a"),f9o=o("FunnelForSequenceClassification"),m9o=o(" (Funnel Transformer model)"),g9o=l(),U1=a("li"),hfe=a("strong"),h9o=o("gpt2"),p9o=o(" \u2014 "),rG=a("a"),u9o=o("GPT2ForSequenceClassification"),_9o=o(" (OpenAI GPT-2 model)"),b9o=l(),J1=a("li"),pfe=a("strong"),v9o=o("gpt_neo"),F9o=o(" \u2014 "),tG=a("a"),T9o=o("GPTNeoForSequenceClassification"),M9o=o(" (GPT Neo model)"),E9o=l(),Y1=a("li"),ufe=a("strong"),C9o=o("gptj"),w9o=o(" \u2014 "),aG=a("a"),A9o=o("GPTJForSequenceClassification"),y9o=o(" (GPT-J model)"),L9o=l(),K1=a("li"),_fe=a("strong"),x9o=o("ibert"),$9o=o(" \u2014 "),nG=a("a"),k9o=o("IBertForSequenceClassification"),S9o=o(" (I-BERT model)"),R9o=l(),Z1=a("li"),bfe=a("strong"),P9o=o("layoutlm"),B9o=o(" \u2014 "),sG=a("a"),I9o=o("LayoutLMForSequenceClassification"),q9o=o(" (LayoutLM model)"),N9o=l(),eb=a("li"),vfe=a("strong"),j9o=o("layoutlmv2"),D9o=o(" \u2014 "),lG=a("a"),G9o=o("LayoutLMv2ForSequenceClassification"),O9o=o(" (LayoutLMv2 model)"),V9o=l(),ob=a("li"),Ffe=a("strong"),X9o=o("led"),z9o=o(" \u2014 "),iG=a("a"),Q9o=o("LEDForSequenceClassification"),W9o=o(" (LED model)"),H9o=l(),rb=a("li"),Tfe=a("strong"),U9o=o("longformer"),J9o=o(" \u2014 "),dG=a("a"),Y9o=o("LongformerForSequenceClassification"),K9o=o(" (Longformer model)"),Z9o=l(),tb=a("li"),Mfe=a("strong"),e$o=o("mbart"),o$o=o(" \u2014 "),cG=a("a"),r$o=o("MBartForSequenceClassification"),t$o=o(" (mBART model)"),a$o=l(),ab=a("li"),Efe=a("strong"),n$o=o("megatron-bert"),s$o=o(" \u2014 "),fG=a("a"),l$o=o("MegatronBertForSequenceClassification"),i$o=o(" (MegatronBert model)"),d$o=l(),nb=a("li"),Cfe=a("strong"),c$o=o("mobilebert"),f$o=o(" \u2014 "),mG=a("a"),m$o=o("MobileBertForSequenceClassification"),g$o=o(" (MobileBERT model)"),h$o=l(),sb=a("li"),wfe=a("strong"),p$o=o("mpnet"),u$o=o(" \u2014 "),gG=a("a"),_$o=o("MPNetForSequenceClassification"),b$o=o(" (MPNet model)"),v$o=l(),lb=a("li"),Afe=a("strong"),F$o=o("nystromformer"),T$o=o(" \u2014 "),hG=a("a"),M$o=o("NystromformerForSequenceClassification"),E$o=o(" (Nystromformer model)"),C$o=l(),ib=a("li"),yfe=a("strong"),w$o=o("openai-gpt"),A$o=o(" \u2014 "),pG=a("a"),y$o=o("OpenAIGPTForSequenceClassification"),L$o=o(" (OpenAI GPT model)"),x$o=l(),db=a("li"),Lfe=a("strong"),$$o=o("perceiver"),k$o=o(" \u2014 "),uG=a("a"),S$o=o("PerceiverForSequenceClassification"),R$o=o(" (Perceiver model)"),P$o=l(),cb=a("li"),xfe=a("strong"),B$o=o("plbart"),I$o=o(" \u2014 "),_G=a("a"),q$o=o("PLBartForSequenceClassification"),N$o=o(" (PLBart model)"),j$o=l(),fb=a("li"),$fe=a("strong"),D$o=o("qdqbert"),G$o=o(" \u2014 "),bG=a("a"),O$o=o("QDQBertForSequenceClassification"),V$o=o(" (QDQBert model)"),X$o=l(),mb=a("li"),kfe=a("strong"),z$o=o("reformer"),Q$o=o(" \u2014 "),vG=a("a"),W$o=o("ReformerForSequenceClassification"),H$o=o(" (Reformer model)"),U$o=l(),gb=a("li"),Sfe=a("strong"),J$o=o("rembert"),Y$o=o(" \u2014 "),FG=a("a"),K$o=o("RemBertForSequenceClassification"),Z$o=o(" (RemBERT model)"),eko=l(),hb=a("li"),Rfe=a("strong"),oko=o("roberta"),rko=o(" \u2014 "),TG=a("a"),tko=o("RobertaForSequenceClassification"),ako=o(" (RoBERTa model)"),nko=l(),pb=a("li"),Pfe=a("strong"),sko=o("roformer"),lko=o(" \u2014 "),MG=a("a"),iko=o("RoFormerForSequenceClassification"),dko=o(" (RoFormer model)"),cko=l(),ub=a("li"),Bfe=a("strong"),fko=o("squeezebert"),mko=o(" \u2014 "),EG=a("a"),gko=o("SqueezeBertForSequenceClassification"),hko=o(" (SqueezeBERT model)"),pko=l(),_b=a("li"),Ife=a("strong"),uko=o("tapas"),_ko=o(" \u2014 "),CG=a("a"),bko=o("TapasForSequenceClassification"),vko=o(" (TAPAS model)"),Fko=l(),bb=a("li"),qfe=a("strong"),Tko=o("tapex"),Mko=o(" \u2014 "),wG=a("a"),Eko=o("BartForSequenceClassification"),Cko=o(" (TAPEX model)"),wko=l(),vb=a("li"),Nfe=a("strong"),Ako=o("transfo-xl"),yko=o(" \u2014 "),AG=a("a"),Lko=o("TransfoXLForSequenceClassification"),xko=o(" (Transformer-XL model)"),$ko=l(),Fb=a("li"),jfe=a("strong"),kko=o("xlm"),Sko=o(" \u2014 "),yG=a("a"),Rko=o("XLMForSequenceClassification"),Pko=o(" (XLM model)"),Bko=l(),Tb=a("li"),Dfe=a("strong"),Iko=o("xlm-roberta"),qko=o(" \u2014 "),LG=a("a"),Nko=o("XLMRobertaForSequenceClassification"),jko=o(" (XLM-RoBERTa model)"),Dko=l(),Mb=a("li"),Gfe=a("strong"),Gko=o("xlm-roberta-xl"),Oko=o(" \u2014 "),xG=a("a"),Vko=o("XLMRobertaXLForSequenceClassification"),Xko=o(" (XLM-RoBERTa-XL model)"),zko=l(),Eb=a("li"),Ofe=a("strong"),Qko=o("xlnet"),Wko=o(" \u2014 "),$G=a("a"),Hko=o("XLNetForSequenceClassification"),Uko=o(" (XLNet model)"),Jko=l(),Cb=a("li"),Vfe=a("strong"),Yko=o("yoso"),Kko=o(" \u2014 "),kG=a("a"),Zko=o("YosoForSequenceClassification"),eSo=o(" (YOSO model)"),oSo=l(),wb=a("p"),rSo=o("The model is set in evaluation mode by default using "),Xfe=a("code"),tSo=o("model.eval()"),aSo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zfe=a("code"),nSo=o("model.train()"),sSo=l(),F(Ab.$$.fragment),mqe=l(),Qi=a("h2"),yb=a("a"),Qfe=a("span"),F(b0.$$.fragment),lSo=l(),Wfe=a("span"),iSo=o("AutoModelForMultipleChoice"),gqe=l(),Bo=a("div"),F(v0.$$.fragment),dSo=l(),Wi=a("p"),cSo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),SG=a("a"),fSo=o("from_pretrained()"),mSo=o(" class method or the "),RG=a("a"),gSo=o("from_config()"),hSo=o(` class
method.`),pSo=l(),F0=a("p"),uSo=o("This class cannot be instantiated directly using "),Hfe=a("code"),_So=o("__init__()"),bSo=o(" (throws an error)."),vSo=l(),dt=a("div"),F(T0.$$.fragment),FSo=l(),Ufe=a("p"),TSo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),MSo=l(),Hi=a("p"),ESo=o(`Note:
Loading a model from its configuration file does `),Jfe=a("strong"),CSo=o("not"),wSo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),PG=a("a"),ASo=o("from_pretrained()"),ySo=o(" to load the model weights."),LSo=l(),F(Lb.$$.fragment),xSo=l(),eo=a("div"),F(M0.$$.fragment),$So=l(),Yfe=a("p"),kSo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),SSo=l(),Ia=a("p"),RSo=o("The model class to instantiate is selected based on the "),Kfe=a("code"),PSo=o("model_type"),BSo=o(` property of the config object (either
passed as an argument or loaded from `),Zfe=a("code"),ISo=o("pretrained_model_name_or_path"),qSo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eme=a("code"),NSo=o("pretrained_model_name_or_path"),jSo=o(":"),DSo=l(),Y=a("ul"),xb=a("li"),ome=a("strong"),GSo=o("albert"),OSo=o(" \u2014 "),BG=a("a"),VSo=o("AlbertForMultipleChoice"),XSo=o(" (ALBERT model)"),zSo=l(),$b=a("li"),rme=a("strong"),QSo=o("bert"),WSo=o(" \u2014 "),IG=a("a"),HSo=o("BertForMultipleChoice"),USo=o(" (BERT model)"),JSo=l(),kb=a("li"),tme=a("strong"),YSo=o("big_bird"),KSo=o(" \u2014 "),qG=a("a"),ZSo=o("BigBirdForMultipleChoice"),eRo=o(" (BigBird model)"),oRo=l(),Sb=a("li"),ame=a("strong"),rRo=o("camembert"),tRo=o(" \u2014 "),NG=a("a"),aRo=o("CamembertForMultipleChoice"),nRo=o(" (CamemBERT model)"),sRo=l(),Rb=a("li"),nme=a("strong"),lRo=o("canine"),iRo=o(" \u2014 "),jG=a("a"),dRo=o("CanineForMultipleChoice"),cRo=o(" (Canine model)"),fRo=l(),Pb=a("li"),sme=a("strong"),mRo=o("convbert"),gRo=o(" \u2014 "),DG=a("a"),hRo=o("ConvBertForMultipleChoice"),pRo=o(" (ConvBERT model)"),uRo=l(),Bb=a("li"),lme=a("strong"),_Ro=o("data2vec-text"),bRo=o(" \u2014 "),GG=a("a"),vRo=o("Data2VecTextForMultipleChoice"),FRo=o(" (Data2VecText model)"),TRo=l(),Ib=a("li"),ime=a("strong"),MRo=o("deberta-v2"),ERo=o(" \u2014 "),OG=a("a"),CRo=o("DebertaV2ForMultipleChoice"),wRo=o(" (DeBERTa-v2 model)"),ARo=l(),qb=a("li"),dme=a("strong"),yRo=o("distilbert"),LRo=o(" \u2014 "),VG=a("a"),xRo=o("DistilBertForMultipleChoice"),$Ro=o(" (DistilBERT model)"),kRo=l(),Nb=a("li"),cme=a("strong"),SRo=o("electra"),RRo=o(" \u2014 "),XG=a("a"),PRo=o("ElectraForMultipleChoice"),BRo=o(" (ELECTRA model)"),IRo=l(),jb=a("li"),fme=a("strong"),qRo=o("flaubert"),NRo=o(" \u2014 "),zG=a("a"),jRo=o("FlaubertForMultipleChoice"),DRo=o(" (FlauBERT model)"),GRo=l(),Db=a("li"),mme=a("strong"),ORo=o("fnet"),VRo=o(" \u2014 "),QG=a("a"),XRo=o("FNetForMultipleChoice"),zRo=o(" (FNet model)"),QRo=l(),Gb=a("li"),gme=a("strong"),WRo=o("funnel"),HRo=o(" \u2014 "),WG=a("a"),URo=o("FunnelForMultipleChoice"),JRo=o(" (Funnel Transformer model)"),YRo=l(),Ob=a("li"),hme=a("strong"),KRo=o("ibert"),ZRo=o(" \u2014 "),HG=a("a"),ePo=o("IBertForMultipleChoice"),oPo=o(" (I-BERT model)"),rPo=l(),Vb=a("li"),pme=a("strong"),tPo=o("longformer"),aPo=o(" \u2014 "),UG=a("a"),nPo=o("LongformerForMultipleChoice"),sPo=o(" (Longformer model)"),lPo=l(),Xb=a("li"),ume=a("strong"),iPo=o("megatron-bert"),dPo=o(" \u2014 "),JG=a("a"),cPo=o("MegatronBertForMultipleChoice"),fPo=o(" (MegatronBert model)"),mPo=l(),zb=a("li"),_me=a("strong"),gPo=o("mobilebert"),hPo=o(" \u2014 "),YG=a("a"),pPo=o("MobileBertForMultipleChoice"),uPo=o(" (MobileBERT model)"),_Po=l(),Qb=a("li"),bme=a("strong"),bPo=o("mpnet"),vPo=o(" \u2014 "),KG=a("a"),FPo=o("MPNetForMultipleChoice"),TPo=o(" (MPNet model)"),MPo=l(),Wb=a("li"),vme=a("strong"),EPo=o("nystromformer"),CPo=o(" \u2014 "),ZG=a("a"),wPo=o("NystromformerForMultipleChoice"),APo=o(" (Nystromformer model)"),yPo=l(),Hb=a("li"),Fme=a("strong"),LPo=o("qdqbert"),xPo=o(" \u2014 "),eO=a("a"),$Po=o("QDQBertForMultipleChoice"),kPo=o(" (QDQBert model)"),SPo=l(),Ub=a("li"),Tme=a("strong"),RPo=o("rembert"),PPo=o(" \u2014 "),oO=a("a"),BPo=o("RemBertForMultipleChoice"),IPo=o(" (RemBERT model)"),qPo=l(),Jb=a("li"),Mme=a("strong"),NPo=o("roberta"),jPo=o(" \u2014 "),rO=a("a"),DPo=o("RobertaForMultipleChoice"),GPo=o(" (RoBERTa model)"),OPo=l(),Yb=a("li"),Eme=a("strong"),VPo=o("roformer"),XPo=o(" \u2014 "),tO=a("a"),zPo=o("RoFormerForMultipleChoice"),QPo=o(" (RoFormer model)"),WPo=l(),Kb=a("li"),Cme=a("strong"),HPo=o("squeezebert"),UPo=o(" \u2014 "),aO=a("a"),JPo=o("SqueezeBertForMultipleChoice"),YPo=o(" (SqueezeBERT model)"),KPo=l(),Zb=a("li"),wme=a("strong"),ZPo=o("xlm"),eBo=o(" \u2014 "),nO=a("a"),oBo=o("XLMForMultipleChoice"),rBo=o(" (XLM model)"),tBo=l(),ev=a("li"),Ame=a("strong"),aBo=o("xlm-roberta"),nBo=o(" \u2014 "),sO=a("a"),sBo=o("XLMRobertaForMultipleChoice"),lBo=o(" (XLM-RoBERTa model)"),iBo=l(),ov=a("li"),yme=a("strong"),dBo=o("xlm-roberta-xl"),cBo=o(" \u2014 "),lO=a("a"),fBo=o("XLMRobertaXLForMultipleChoice"),mBo=o(" (XLM-RoBERTa-XL model)"),gBo=l(),rv=a("li"),Lme=a("strong"),hBo=o("xlnet"),pBo=o(" \u2014 "),iO=a("a"),uBo=o("XLNetForMultipleChoice"),_Bo=o(" (XLNet model)"),bBo=l(),tv=a("li"),xme=a("strong"),vBo=o("yoso"),FBo=o(" \u2014 "),dO=a("a"),TBo=o("YosoForMultipleChoice"),MBo=o(" (YOSO model)"),EBo=l(),av=a("p"),CBo=o("The model is set in evaluation mode by default using "),$me=a("code"),wBo=o("model.eval()"),ABo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kme=a("code"),yBo=o("model.train()"),LBo=l(),F(nv.$$.fragment),hqe=l(),Ui=a("h2"),sv=a("a"),Sme=a("span"),F(E0.$$.fragment),xBo=l(),Rme=a("span"),$Bo=o("AutoModelForNextSentencePrediction"),pqe=l(),Io=a("div"),F(C0.$$.fragment),kBo=l(),Ji=a("p"),SBo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),cO=a("a"),RBo=o("from_pretrained()"),PBo=o(" class method or the "),fO=a("a"),BBo=o("from_config()"),IBo=o(` class
method.`),qBo=l(),w0=a("p"),NBo=o("This class cannot be instantiated directly using "),Pme=a("code"),jBo=o("__init__()"),DBo=o(" (throws an error)."),GBo=l(),ct=a("div"),F(A0.$$.fragment),OBo=l(),Bme=a("p"),VBo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),XBo=l(),Yi=a("p"),zBo=o(`Note:
Loading a model from its configuration file does `),Ime=a("strong"),QBo=o("not"),WBo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mO=a("a"),HBo=o("from_pretrained()"),UBo=o(" to load the model weights."),JBo=l(),F(lv.$$.fragment),YBo=l(),oo=a("div"),F(y0.$$.fragment),KBo=l(),qme=a("p"),ZBo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),eIo=l(),qa=a("p"),oIo=o("The model class to instantiate is selected based on the "),Nme=a("code"),rIo=o("model_type"),tIo=o(` property of the config object (either
passed as an argument or loaded from `),jme=a("code"),aIo=o("pretrained_model_name_or_path"),nIo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Dme=a("code"),sIo=o("pretrained_model_name_or_path"),lIo=o(":"),iIo=l(),Zr=a("ul"),iv=a("li"),Gme=a("strong"),dIo=o("bert"),cIo=o(" \u2014 "),gO=a("a"),fIo=o("BertForNextSentencePrediction"),mIo=o(" (BERT model)"),gIo=l(),dv=a("li"),Ome=a("strong"),hIo=o("fnet"),pIo=o(" \u2014 "),hO=a("a"),uIo=o("FNetForNextSentencePrediction"),_Io=o(" (FNet model)"),bIo=l(),cv=a("li"),Vme=a("strong"),vIo=o("megatron-bert"),FIo=o(" \u2014 "),pO=a("a"),TIo=o("MegatronBertForNextSentencePrediction"),MIo=o(" (MegatronBert model)"),EIo=l(),fv=a("li"),Xme=a("strong"),CIo=o("mobilebert"),wIo=o(" \u2014 "),uO=a("a"),AIo=o("MobileBertForNextSentencePrediction"),yIo=o(" (MobileBERT model)"),LIo=l(),mv=a("li"),zme=a("strong"),xIo=o("qdqbert"),$Io=o(" \u2014 "),_O=a("a"),kIo=o("QDQBertForNextSentencePrediction"),SIo=o(" (QDQBert model)"),RIo=l(),gv=a("p"),PIo=o("The model is set in evaluation mode by default using "),Qme=a("code"),BIo=o("model.eval()"),IIo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Wme=a("code"),qIo=o("model.train()"),NIo=l(),F(hv.$$.fragment),uqe=l(),Ki=a("h2"),pv=a("a"),Hme=a("span"),F(L0.$$.fragment),jIo=l(),Ume=a("span"),DIo=o("AutoModelForTokenClassification"),_qe=l(),qo=a("div"),F(x0.$$.fragment),GIo=l(),Zi=a("p"),OIo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),bO=a("a"),VIo=o("from_pretrained()"),XIo=o(" class method or the "),vO=a("a"),zIo=o("from_config()"),QIo=o(` class
method.`),WIo=l(),$0=a("p"),HIo=o("This class cannot be instantiated directly using "),Jme=a("code"),UIo=o("__init__()"),JIo=o(" (throws an error)."),YIo=l(),ft=a("div"),F(k0.$$.fragment),KIo=l(),Yme=a("p"),ZIo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),eqo=l(),ed=a("p"),oqo=o(`Note:
Loading a model from its configuration file does `),Kme=a("strong"),rqo=o("not"),tqo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),FO=a("a"),aqo=o("from_pretrained()"),nqo=o(" to load the model weights."),sqo=l(),F(uv.$$.fragment),lqo=l(),ro=a("div"),F(S0.$$.fragment),iqo=l(),Zme=a("p"),dqo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),cqo=l(),Na=a("p"),fqo=o("The model class to instantiate is selected based on the "),ege=a("code"),mqo=o("model_type"),gqo=o(` property of the config object (either
passed as an argument or loaded from `),oge=a("code"),hqo=o("pretrained_model_name_or_path"),pqo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rge=a("code"),uqo=o("pretrained_model_name_or_path"),_qo=o(":"),bqo=l(),U=a("ul"),_v=a("li"),tge=a("strong"),vqo=o("albert"),Fqo=o(" \u2014 "),TO=a("a"),Tqo=o("AlbertForTokenClassification"),Mqo=o(" (ALBERT model)"),Eqo=l(),bv=a("li"),age=a("strong"),Cqo=o("bert"),wqo=o(" \u2014 "),MO=a("a"),Aqo=o("BertForTokenClassification"),yqo=o(" (BERT model)"),Lqo=l(),vv=a("li"),nge=a("strong"),xqo=o("big_bird"),$qo=o(" \u2014 "),EO=a("a"),kqo=o("BigBirdForTokenClassification"),Sqo=o(" (BigBird model)"),Rqo=l(),Fv=a("li"),sge=a("strong"),Pqo=o("camembert"),Bqo=o(" \u2014 "),CO=a("a"),Iqo=o("CamembertForTokenClassification"),qqo=o(" (CamemBERT model)"),Nqo=l(),Tv=a("li"),lge=a("strong"),jqo=o("canine"),Dqo=o(" \u2014 "),wO=a("a"),Gqo=o("CanineForTokenClassification"),Oqo=o(" (Canine model)"),Vqo=l(),Mv=a("li"),ige=a("strong"),Xqo=o("convbert"),zqo=o(" \u2014 "),AO=a("a"),Qqo=o("ConvBertForTokenClassification"),Wqo=o(" (ConvBERT model)"),Hqo=l(),Ev=a("li"),dge=a("strong"),Uqo=o("data2vec-text"),Jqo=o(" \u2014 "),yO=a("a"),Yqo=o("Data2VecTextForTokenClassification"),Kqo=o(" (Data2VecText model)"),Zqo=l(),Cv=a("li"),cge=a("strong"),eNo=o("deberta"),oNo=o(" \u2014 "),LO=a("a"),rNo=o("DebertaForTokenClassification"),tNo=o(" (DeBERTa model)"),aNo=l(),wv=a("li"),fge=a("strong"),nNo=o("deberta-v2"),sNo=o(" \u2014 "),xO=a("a"),lNo=o("DebertaV2ForTokenClassification"),iNo=o(" (DeBERTa-v2 model)"),dNo=l(),Av=a("li"),mge=a("strong"),cNo=o("distilbert"),fNo=o(" \u2014 "),$O=a("a"),mNo=o("DistilBertForTokenClassification"),gNo=o(" (DistilBERT model)"),hNo=l(),yv=a("li"),gge=a("strong"),pNo=o("electra"),uNo=o(" \u2014 "),kO=a("a"),_No=o("ElectraForTokenClassification"),bNo=o(" (ELECTRA model)"),vNo=l(),Lv=a("li"),hge=a("strong"),FNo=o("flaubert"),TNo=o(" \u2014 "),SO=a("a"),MNo=o("FlaubertForTokenClassification"),ENo=o(" (FlauBERT model)"),CNo=l(),xv=a("li"),pge=a("strong"),wNo=o("fnet"),ANo=o(" \u2014 "),RO=a("a"),yNo=o("FNetForTokenClassification"),LNo=o(" (FNet model)"),xNo=l(),$v=a("li"),uge=a("strong"),$No=o("funnel"),kNo=o(" \u2014 "),PO=a("a"),SNo=o("FunnelForTokenClassification"),RNo=o(" (Funnel Transformer model)"),PNo=l(),kv=a("li"),_ge=a("strong"),BNo=o("gpt2"),INo=o(" \u2014 "),BO=a("a"),qNo=o("GPT2ForTokenClassification"),NNo=o(" (OpenAI GPT-2 model)"),jNo=l(),Sv=a("li"),bge=a("strong"),DNo=o("ibert"),GNo=o(" \u2014 "),IO=a("a"),ONo=o("IBertForTokenClassification"),VNo=o(" (I-BERT model)"),XNo=l(),Rv=a("li"),vge=a("strong"),zNo=o("layoutlm"),QNo=o(" \u2014 "),qO=a("a"),WNo=o("LayoutLMForTokenClassification"),HNo=o(" (LayoutLM model)"),UNo=l(),Pv=a("li"),Fge=a("strong"),JNo=o("layoutlmv2"),YNo=o(" \u2014 "),NO=a("a"),KNo=o("LayoutLMv2ForTokenClassification"),ZNo=o(" (LayoutLMv2 model)"),ejo=l(),Bv=a("li"),Tge=a("strong"),ojo=o("longformer"),rjo=o(" \u2014 "),jO=a("a"),tjo=o("LongformerForTokenClassification"),ajo=o(" (Longformer model)"),njo=l(),Iv=a("li"),Mge=a("strong"),sjo=o("megatron-bert"),ljo=o(" \u2014 "),DO=a("a"),ijo=o("MegatronBertForTokenClassification"),djo=o(" (MegatronBert model)"),cjo=l(),qv=a("li"),Ege=a("strong"),fjo=o("mobilebert"),mjo=o(" \u2014 "),GO=a("a"),gjo=o("MobileBertForTokenClassification"),hjo=o(" (MobileBERT model)"),pjo=l(),Nv=a("li"),Cge=a("strong"),ujo=o("mpnet"),_jo=o(" \u2014 "),OO=a("a"),bjo=o("MPNetForTokenClassification"),vjo=o(" (MPNet model)"),Fjo=l(),jv=a("li"),wge=a("strong"),Tjo=o("nystromformer"),Mjo=o(" \u2014 "),VO=a("a"),Ejo=o("NystromformerForTokenClassification"),Cjo=o(" (Nystromformer model)"),wjo=l(),Dv=a("li"),Age=a("strong"),Ajo=o("qdqbert"),yjo=o(" \u2014 "),XO=a("a"),Ljo=o("QDQBertForTokenClassification"),xjo=o(" (QDQBert model)"),$jo=l(),Gv=a("li"),yge=a("strong"),kjo=o("rembert"),Sjo=o(" \u2014 "),zO=a("a"),Rjo=o("RemBertForTokenClassification"),Pjo=o(" (RemBERT model)"),Bjo=l(),Ov=a("li"),Lge=a("strong"),Ijo=o("roberta"),qjo=o(" \u2014 "),QO=a("a"),Njo=o("RobertaForTokenClassification"),jjo=o(" (RoBERTa model)"),Djo=l(),Vv=a("li"),xge=a("strong"),Gjo=o("roformer"),Ojo=o(" \u2014 "),WO=a("a"),Vjo=o("RoFormerForTokenClassification"),Xjo=o(" (RoFormer model)"),zjo=l(),Xv=a("li"),$ge=a("strong"),Qjo=o("squeezebert"),Wjo=o(" \u2014 "),HO=a("a"),Hjo=o("SqueezeBertForTokenClassification"),Ujo=o(" (SqueezeBERT model)"),Jjo=l(),zv=a("li"),kge=a("strong"),Yjo=o("xlm"),Kjo=o(" \u2014 "),UO=a("a"),Zjo=o("XLMForTokenClassification"),eDo=o(" (XLM model)"),oDo=l(),Qv=a("li"),Sge=a("strong"),rDo=o("xlm-roberta"),tDo=o(" \u2014 "),JO=a("a"),aDo=o("XLMRobertaForTokenClassification"),nDo=o(" (XLM-RoBERTa model)"),sDo=l(),Wv=a("li"),Rge=a("strong"),lDo=o("xlm-roberta-xl"),iDo=o(" \u2014 "),YO=a("a"),dDo=o("XLMRobertaXLForTokenClassification"),cDo=o(" (XLM-RoBERTa-XL model)"),fDo=l(),Hv=a("li"),Pge=a("strong"),mDo=o("xlnet"),gDo=o(" \u2014 "),KO=a("a"),hDo=o("XLNetForTokenClassification"),pDo=o(" (XLNet model)"),uDo=l(),Uv=a("li"),Bge=a("strong"),_Do=o("yoso"),bDo=o(" \u2014 "),ZO=a("a"),vDo=o("YosoForTokenClassification"),FDo=o(" (YOSO model)"),TDo=l(),Jv=a("p"),MDo=o("The model is set in evaluation mode by default using "),Ige=a("code"),EDo=o("model.eval()"),CDo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qge=a("code"),wDo=o("model.train()"),ADo=l(),F(Yv.$$.fragment),bqe=l(),od=a("h2"),Kv=a("a"),Nge=a("span"),F(R0.$$.fragment),yDo=l(),jge=a("span"),LDo=o("AutoModelForQuestionAnswering"),vqe=l(),No=a("div"),F(P0.$$.fragment),xDo=l(),rd=a("p"),$Do=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),eV=a("a"),kDo=o("from_pretrained()"),SDo=o(" class method or the "),oV=a("a"),RDo=o("from_config()"),PDo=o(` class
method.`),BDo=l(),B0=a("p"),IDo=o("This class cannot be instantiated directly using "),Dge=a("code"),qDo=o("__init__()"),NDo=o(" (throws an error)."),jDo=l(),mt=a("div"),F(I0.$$.fragment),DDo=l(),Gge=a("p"),GDo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),ODo=l(),td=a("p"),VDo=o(`Note:
Loading a model from its configuration file does `),Oge=a("strong"),XDo=o("not"),zDo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rV=a("a"),QDo=o("from_pretrained()"),WDo=o(" to load the model weights."),HDo=l(),F(Zv.$$.fragment),UDo=l(),to=a("div"),F(q0.$$.fragment),JDo=l(),Vge=a("p"),YDo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),KDo=l(),ja=a("p"),ZDo=o("The model class to instantiate is selected based on the "),Xge=a("code"),eGo=o("model_type"),oGo=o(` property of the config object (either
passed as an argument or loaded from `),zge=a("code"),rGo=o("pretrained_model_name_or_path"),tGo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qge=a("code"),aGo=o("pretrained_model_name_or_path"),nGo=o(":"),sGo=l(),O=a("ul"),eF=a("li"),Wge=a("strong"),lGo=o("albert"),iGo=o(" \u2014 "),tV=a("a"),dGo=o("AlbertForQuestionAnswering"),cGo=o(" (ALBERT model)"),fGo=l(),oF=a("li"),Hge=a("strong"),mGo=o("bart"),gGo=o(" \u2014 "),aV=a("a"),hGo=o("BartForQuestionAnswering"),pGo=o(" (BART model)"),uGo=l(),rF=a("li"),Uge=a("strong"),_Go=o("bert"),bGo=o(" \u2014 "),nV=a("a"),vGo=o("BertForQuestionAnswering"),FGo=o(" (BERT model)"),TGo=l(),tF=a("li"),Jge=a("strong"),MGo=o("big_bird"),EGo=o(" \u2014 "),sV=a("a"),CGo=o("BigBirdForQuestionAnswering"),wGo=o(" (BigBird model)"),AGo=l(),aF=a("li"),Yge=a("strong"),yGo=o("bigbird_pegasus"),LGo=o(" \u2014 "),lV=a("a"),xGo=o("BigBirdPegasusForQuestionAnswering"),$Go=o(" (BigBirdPegasus model)"),kGo=l(),nF=a("li"),Kge=a("strong"),SGo=o("camembert"),RGo=o(" \u2014 "),iV=a("a"),PGo=o("CamembertForQuestionAnswering"),BGo=o(" (CamemBERT model)"),IGo=l(),sF=a("li"),Zge=a("strong"),qGo=o("canine"),NGo=o(" \u2014 "),dV=a("a"),jGo=o("CanineForQuestionAnswering"),DGo=o(" (Canine model)"),GGo=l(),lF=a("li"),ehe=a("strong"),OGo=o("convbert"),VGo=o(" \u2014 "),cV=a("a"),XGo=o("ConvBertForQuestionAnswering"),zGo=o(" (ConvBERT model)"),QGo=l(),iF=a("li"),ohe=a("strong"),WGo=o("data2vec-text"),HGo=o(" \u2014 "),fV=a("a"),UGo=o("Data2VecTextForQuestionAnswering"),JGo=o(" (Data2VecText model)"),YGo=l(),dF=a("li"),rhe=a("strong"),KGo=o("deberta"),ZGo=o(" \u2014 "),mV=a("a"),eOo=o("DebertaForQuestionAnswering"),oOo=o(" (DeBERTa model)"),rOo=l(),cF=a("li"),the=a("strong"),tOo=o("deberta-v2"),aOo=o(" \u2014 "),gV=a("a"),nOo=o("DebertaV2ForQuestionAnswering"),sOo=o(" (DeBERTa-v2 model)"),lOo=l(),fF=a("li"),ahe=a("strong"),iOo=o("distilbert"),dOo=o(" \u2014 "),hV=a("a"),cOo=o("DistilBertForQuestionAnswering"),fOo=o(" (DistilBERT model)"),mOo=l(),mF=a("li"),nhe=a("strong"),gOo=o("electra"),hOo=o(" \u2014 "),pV=a("a"),pOo=o("ElectraForQuestionAnswering"),uOo=o(" (ELECTRA model)"),_Oo=l(),gF=a("li"),she=a("strong"),bOo=o("flaubert"),vOo=o(" \u2014 "),uV=a("a"),FOo=o("FlaubertForQuestionAnsweringSimple"),TOo=o(" (FlauBERT model)"),MOo=l(),hF=a("li"),lhe=a("strong"),EOo=o("fnet"),COo=o(" \u2014 "),_V=a("a"),wOo=o("FNetForQuestionAnswering"),AOo=o(" (FNet model)"),yOo=l(),pF=a("li"),ihe=a("strong"),LOo=o("funnel"),xOo=o(" \u2014 "),bV=a("a"),$Oo=o("FunnelForQuestionAnswering"),kOo=o(" (Funnel Transformer model)"),SOo=l(),uF=a("li"),dhe=a("strong"),ROo=o("gptj"),POo=o(" \u2014 "),vV=a("a"),BOo=o("GPTJForQuestionAnswering"),IOo=o(" (GPT-J model)"),qOo=l(),_F=a("li"),che=a("strong"),NOo=o("ibert"),jOo=o(" \u2014 "),FV=a("a"),DOo=o("IBertForQuestionAnswering"),GOo=o(" (I-BERT model)"),OOo=l(),bF=a("li"),fhe=a("strong"),VOo=o("layoutlmv2"),XOo=o(" \u2014 "),TV=a("a"),zOo=o("LayoutLMv2ForQuestionAnswering"),QOo=o(" (LayoutLMv2 model)"),WOo=l(),vF=a("li"),mhe=a("strong"),HOo=o("led"),UOo=o(" \u2014 "),MV=a("a"),JOo=o("LEDForQuestionAnswering"),YOo=o(" (LED model)"),KOo=l(),FF=a("li"),ghe=a("strong"),ZOo=o("longformer"),eVo=o(" \u2014 "),EV=a("a"),oVo=o("LongformerForQuestionAnswering"),rVo=o(" (Longformer model)"),tVo=l(),TF=a("li"),hhe=a("strong"),aVo=o("lxmert"),nVo=o(" \u2014 "),CV=a("a"),sVo=o("LxmertForQuestionAnswering"),lVo=o(" (LXMERT model)"),iVo=l(),MF=a("li"),phe=a("strong"),dVo=o("mbart"),cVo=o(" \u2014 "),wV=a("a"),fVo=o("MBartForQuestionAnswering"),mVo=o(" (mBART model)"),gVo=l(),EF=a("li"),uhe=a("strong"),hVo=o("megatron-bert"),pVo=o(" \u2014 "),AV=a("a"),uVo=o("MegatronBertForQuestionAnswering"),_Vo=o(" (MegatronBert model)"),bVo=l(),CF=a("li"),_he=a("strong"),vVo=o("mobilebert"),FVo=o(" \u2014 "),yV=a("a"),TVo=o("MobileBertForQuestionAnswering"),MVo=o(" (MobileBERT model)"),EVo=l(),wF=a("li"),bhe=a("strong"),CVo=o("mpnet"),wVo=o(" \u2014 "),LV=a("a"),AVo=o("MPNetForQuestionAnswering"),yVo=o(" (MPNet model)"),LVo=l(),AF=a("li"),vhe=a("strong"),xVo=o("nystromformer"),$Vo=o(" \u2014 "),xV=a("a"),kVo=o("NystromformerForQuestionAnswering"),SVo=o(" (Nystromformer model)"),RVo=l(),yF=a("li"),Fhe=a("strong"),PVo=o("qdqbert"),BVo=o(" \u2014 "),$V=a("a"),IVo=o("QDQBertForQuestionAnswering"),qVo=o(" (QDQBert model)"),NVo=l(),LF=a("li"),The=a("strong"),jVo=o("reformer"),DVo=o(" \u2014 "),kV=a("a"),GVo=o("ReformerForQuestionAnswering"),OVo=o(" (Reformer model)"),VVo=l(),xF=a("li"),Mhe=a("strong"),XVo=o("rembert"),zVo=o(" \u2014 "),SV=a("a"),QVo=o("RemBertForQuestionAnswering"),WVo=o(" (RemBERT model)"),HVo=l(),$F=a("li"),Ehe=a("strong"),UVo=o("roberta"),JVo=o(" \u2014 "),RV=a("a"),YVo=o("RobertaForQuestionAnswering"),KVo=o(" (RoBERTa model)"),ZVo=l(),kF=a("li"),Che=a("strong"),eXo=o("roformer"),oXo=o(" \u2014 "),PV=a("a"),rXo=o("RoFormerForQuestionAnswering"),tXo=o(" (RoFormer model)"),aXo=l(),SF=a("li"),whe=a("strong"),nXo=o("splinter"),sXo=o(" \u2014 "),BV=a("a"),lXo=o("SplinterForQuestionAnswering"),iXo=o(" (Splinter model)"),dXo=l(),RF=a("li"),Ahe=a("strong"),cXo=o("squeezebert"),fXo=o(" \u2014 "),IV=a("a"),mXo=o("SqueezeBertForQuestionAnswering"),gXo=o(" (SqueezeBERT model)"),hXo=l(),PF=a("li"),yhe=a("strong"),pXo=o("xlm"),uXo=o(" \u2014 "),qV=a("a"),_Xo=o("XLMForQuestionAnsweringSimple"),bXo=o(" (XLM model)"),vXo=l(),BF=a("li"),Lhe=a("strong"),FXo=o("xlm-roberta"),TXo=o(" \u2014 "),NV=a("a"),MXo=o("XLMRobertaForQuestionAnswering"),EXo=o(" (XLM-RoBERTa model)"),CXo=l(),IF=a("li"),xhe=a("strong"),wXo=o("xlm-roberta-xl"),AXo=o(" \u2014 "),jV=a("a"),yXo=o("XLMRobertaXLForQuestionAnswering"),LXo=o(" (XLM-RoBERTa-XL model)"),xXo=l(),qF=a("li"),$he=a("strong"),$Xo=o("xlnet"),kXo=o(" \u2014 "),DV=a("a"),SXo=o("XLNetForQuestionAnsweringSimple"),RXo=o(" (XLNet model)"),PXo=l(),NF=a("li"),khe=a("strong"),BXo=o("yoso"),IXo=o(" \u2014 "),GV=a("a"),qXo=o("YosoForQuestionAnswering"),NXo=o(" (YOSO model)"),jXo=l(),jF=a("p"),DXo=o("The model is set in evaluation mode by default using "),She=a("code"),GXo=o("model.eval()"),OXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Rhe=a("code"),VXo=o("model.train()"),XXo=l(),F(DF.$$.fragment),Fqe=l(),ad=a("h2"),GF=a("a"),Phe=a("span"),F(N0.$$.fragment),zXo=l(),Bhe=a("span"),QXo=o("AutoModelForTableQuestionAnswering"),Tqe=l(),jo=a("div"),F(j0.$$.fragment),WXo=l(),nd=a("p"),HXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),OV=a("a"),UXo=o("from_pretrained()"),JXo=o(" class method or the "),VV=a("a"),YXo=o("from_config()"),KXo=o(` class
method.`),ZXo=l(),D0=a("p"),ezo=o("This class cannot be instantiated directly using "),Ihe=a("code"),ozo=o("__init__()"),rzo=o(" (throws an error)."),tzo=l(),gt=a("div"),F(G0.$$.fragment),azo=l(),qhe=a("p"),nzo=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),szo=l(),sd=a("p"),lzo=o(`Note:
Loading a model from its configuration file does `),Nhe=a("strong"),izo=o("not"),dzo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XV=a("a"),czo=o("from_pretrained()"),fzo=o(" to load the model weights."),mzo=l(),F(OF.$$.fragment),gzo=l(),ao=a("div"),F(O0.$$.fragment),hzo=l(),jhe=a("p"),pzo=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),uzo=l(),Da=a("p"),_zo=o("The model class to instantiate is selected based on the "),Dhe=a("code"),bzo=o("model_type"),vzo=o(` property of the config object (either
passed as an argument or loaded from `),Ghe=a("code"),Fzo=o("pretrained_model_name_or_path"),Tzo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ohe=a("code"),Mzo=o("pretrained_model_name_or_path"),Ezo=o(":"),Czo=l(),Vhe=a("ul"),VF=a("li"),Xhe=a("strong"),wzo=o("tapas"),Azo=o(" \u2014 "),zV=a("a"),yzo=o("TapasForQuestionAnswering"),Lzo=o(" (TAPAS model)"),xzo=l(),XF=a("p"),$zo=o("The model is set in evaluation mode by default using "),zhe=a("code"),kzo=o("model.eval()"),Szo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Qhe=a("code"),Rzo=o("model.train()"),Pzo=l(),F(zF.$$.fragment),Mqe=l(),ld=a("h2"),QF=a("a"),Whe=a("span"),F(V0.$$.fragment),Bzo=l(),Hhe=a("span"),Izo=o("AutoModelForImageClassification"),Eqe=l(),Do=a("div"),F(X0.$$.fragment),qzo=l(),id=a("p"),Nzo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),QV=a("a"),jzo=o("from_pretrained()"),Dzo=o(" class method or the "),WV=a("a"),Gzo=o("from_config()"),Ozo=o(` class
method.`),Vzo=l(),z0=a("p"),Xzo=o("This class cannot be instantiated directly using "),Uhe=a("code"),zzo=o("__init__()"),Qzo=o(" (throws an error)."),Wzo=l(),ht=a("div"),F(Q0.$$.fragment),Hzo=l(),Jhe=a("p"),Uzo=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Jzo=l(),dd=a("p"),Yzo=o(`Note:
Loading a model from its configuration file does `),Yhe=a("strong"),Kzo=o("not"),Zzo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HV=a("a"),eQo=o("from_pretrained()"),oQo=o(" to load the model weights."),rQo=l(),F(WF.$$.fragment),tQo=l(),no=a("div"),F(W0.$$.fragment),aQo=l(),Khe=a("p"),nQo=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),sQo=l(),Ga=a("p"),lQo=o("The model class to instantiate is selected based on the "),Zhe=a("code"),iQo=o("model_type"),dQo=o(` property of the config object (either
passed as an argument or loaded from `),epe=a("code"),cQo=o("pretrained_model_name_or_path"),fQo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ope=a("code"),mQo=o("pretrained_model_name_or_path"),gQo=o(":"),hQo=l(),Fe=a("ul"),HF=a("li"),rpe=a("strong"),pQo=o("beit"),uQo=o(" \u2014 "),UV=a("a"),_Qo=o("BeitForImageClassification"),bQo=o(" (BEiT model)"),vQo=l(),UF=a("li"),tpe=a("strong"),FQo=o("convnext"),TQo=o(" \u2014 "),JV=a("a"),MQo=o("ConvNextForImageClassification"),EQo=o(" (ConvNext model)"),CQo=l(),JF=a("li"),ape=a("strong"),wQo=o("data2vec-vision"),AQo=o(" \u2014 "),YV=a("a"),yQo=o("Data2VecVisionForImageClassification"),LQo=o(" (Data2VecVision model)"),xQo=l(),js=a("li"),npe=a("strong"),$Qo=o("deit"),kQo=o(" \u2014 "),KV=a("a"),SQo=o("DeiTForImageClassification"),RQo=o(" or "),ZV=a("a"),PQo=o("DeiTForImageClassificationWithTeacher"),BQo=o(" (DeiT model)"),IQo=l(),YF=a("li"),spe=a("strong"),qQo=o("imagegpt"),NQo=o(" \u2014 "),eX=a("a"),jQo=o("ImageGPTForImageClassification"),DQo=o(" (ImageGPT model)"),GQo=l(),pt=a("li"),lpe=a("strong"),OQo=o("perceiver"),VQo=o(" \u2014 "),oX=a("a"),XQo=o("PerceiverForImageClassificationLearned"),zQo=o(" or "),rX=a("a"),QQo=o("PerceiverForImageClassificationFourier"),WQo=o(" or "),tX=a("a"),HQo=o("PerceiverForImageClassificationConvProcessing"),UQo=o(" (Perceiver model)"),JQo=l(),KF=a("li"),ipe=a("strong"),YQo=o("poolformer"),KQo=o(" \u2014 "),aX=a("a"),ZQo=o("PoolFormerForImageClassification"),eWo=o(" (PoolFormer model)"),oWo=l(),ZF=a("li"),dpe=a("strong"),rWo=o("regnet"),tWo=o(" \u2014 "),nX=a("a"),aWo=o("RegNetForImageClassification"),nWo=o(" (RegNet model)"),sWo=l(),e6=a("li"),cpe=a("strong"),lWo=o("resnet"),iWo=o(" \u2014 "),sX=a("a"),dWo=o("ResNetForImageClassification"),cWo=o(" (ResNet model)"),fWo=l(),o6=a("li"),fpe=a("strong"),mWo=o("segformer"),gWo=o(" \u2014 "),lX=a("a"),hWo=o("SegformerForImageClassification"),pWo=o(" (SegFormer model)"),uWo=l(),r6=a("li"),mpe=a("strong"),_Wo=o("swin"),bWo=o(" \u2014 "),iX=a("a"),vWo=o("SwinForImageClassification"),FWo=o(" (Swin model)"),TWo=l(),t6=a("li"),gpe=a("strong"),MWo=o("van"),EWo=o(" \u2014 "),dX=a("a"),CWo=o("VanForImageClassification"),wWo=o(" (VAN model)"),AWo=l(),a6=a("li"),hpe=a("strong"),yWo=o("vit"),LWo=o(" \u2014 "),cX=a("a"),xWo=o("ViTForImageClassification"),$Wo=o(" (ViT model)"),kWo=l(),n6=a("p"),SWo=o("The model is set in evaluation mode by default using "),ppe=a("code"),RWo=o("model.eval()"),PWo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),upe=a("code"),BWo=o("model.train()"),IWo=l(),F(s6.$$.fragment),Cqe=l(),cd=a("h2"),l6=a("a"),_pe=a("span"),F(H0.$$.fragment),qWo=l(),bpe=a("span"),NWo=o("AutoModelForVision2Seq"),wqe=l(),Go=a("div"),F(U0.$$.fragment),jWo=l(),fd=a("p"),DWo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),fX=a("a"),GWo=o("from_pretrained()"),OWo=o(" class method or the "),mX=a("a"),VWo=o("from_config()"),XWo=o(` class
method.`),zWo=l(),J0=a("p"),QWo=o("This class cannot be instantiated directly using "),vpe=a("code"),WWo=o("__init__()"),HWo=o(" (throws an error)."),UWo=l(),ut=a("div"),F(Y0.$$.fragment),JWo=l(),Fpe=a("p"),YWo=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),KWo=l(),md=a("p"),ZWo=o(`Note:
Loading a model from its configuration file does `),Tpe=a("strong"),eHo=o("not"),oHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gX=a("a"),rHo=o("from_pretrained()"),tHo=o(" to load the model weights."),aHo=l(),F(i6.$$.fragment),nHo=l(),so=a("div"),F(K0.$$.fragment),sHo=l(),Mpe=a("p"),lHo=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),iHo=l(),Oa=a("p"),dHo=o("The model class to instantiate is selected based on the "),Epe=a("code"),cHo=o("model_type"),fHo=o(` property of the config object (either
passed as an argument or loaded from `),Cpe=a("code"),mHo=o("pretrained_model_name_or_path"),gHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wpe=a("code"),hHo=o("pretrained_model_name_or_path"),pHo=o(":"),uHo=l(),Ape=a("ul"),d6=a("li"),ype=a("strong"),_Ho=o("vision-encoder-decoder"),bHo=o(" \u2014 "),hX=a("a"),vHo=o("VisionEncoderDecoderModel"),FHo=o(" (Vision Encoder decoder model)"),THo=l(),c6=a("p"),MHo=o("The model is set in evaluation mode by default using "),Lpe=a("code"),EHo=o("model.eval()"),CHo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),xpe=a("code"),wHo=o("model.train()"),AHo=l(),F(f6.$$.fragment),Aqe=l(),gd=a("h2"),m6=a("a"),$pe=a("span"),F(Z0.$$.fragment),yHo=l(),kpe=a("span"),LHo=o("AutoModelForVisualQuestionAnswering"),yqe=l(),Oo=a("div"),F(ey.$$.fragment),xHo=l(),hd=a("p"),$Ho=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),pX=a("a"),kHo=o("from_pretrained()"),SHo=o(" class method or the "),uX=a("a"),RHo=o("from_config()"),PHo=o(` class
method.`),BHo=l(),oy=a("p"),IHo=o("This class cannot be instantiated directly using "),Spe=a("code"),qHo=o("__init__()"),NHo=o(" (throws an error)."),jHo=l(),_t=a("div"),F(ry.$$.fragment),DHo=l(),Rpe=a("p"),GHo=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),OHo=l(),pd=a("p"),VHo=o(`Note:
Loading a model from its configuration file does `),Ppe=a("strong"),XHo=o("not"),zHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_X=a("a"),QHo=o("from_pretrained()"),WHo=o(" to load the model weights."),HHo=l(),F(g6.$$.fragment),UHo=l(),lo=a("div"),F(ty.$$.fragment),JHo=l(),Bpe=a("p"),YHo=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),KHo=l(),Va=a("p"),ZHo=o("The model class to instantiate is selected based on the "),Ipe=a("code"),eUo=o("model_type"),oUo=o(` property of the config object (either
passed as an argument or loaded from `),qpe=a("code"),rUo=o("pretrained_model_name_or_path"),tUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Npe=a("code"),aUo=o("pretrained_model_name_or_path"),nUo=o(":"),sUo=l(),jpe=a("ul"),h6=a("li"),Dpe=a("strong"),lUo=o("vilt"),iUo=o(" \u2014 "),bX=a("a"),dUo=o("ViltForQuestionAnswering"),cUo=o(" (ViLT model)"),fUo=l(),p6=a("p"),mUo=o("The model is set in evaluation mode by default using "),Gpe=a("code"),gUo=o("model.eval()"),hUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ope=a("code"),pUo=o("model.train()"),uUo=l(),F(u6.$$.fragment),Lqe=l(),ud=a("h2"),_6=a("a"),Vpe=a("span"),F(ay.$$.fragment),_Uo=l(),Xpe=a("span"),bUo=o("AutoModelForAudioClassification"),xqe=l(),Vo=a("div"),F(ny.$$.fragment),vUo=l(),_d=a("p"),FUo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),vX=a("a"),TUo=o("from_pretrained()"),MUo=o(" class method or the "),FX=a("a"),EUo=o("from_config()"),CUo=o(` class
method.`),wUo=l(),sy=a("p"),AUo=o("This class cannot be instantiated directly using "),zpe=a("code"),yUo=o("__init__()"),LUo=o(" (throws an error)."),xUo=l(),bt=a("div"),F(ly.$$.fragment),$Uo=l(),Qpe=a("p"),kUo=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),SUo=l(),bd=a("p"),RUo=o(`Note:
Loading a model from its configuration file does `),Wpe=a("strong"),PUo=o("not"),BUo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),TX=a("a"),IUo=o("from_pretrained()"),qUo=o(" to load the model weights."),NUo=l(),F(b6.$$.fragment),jUo=l(),io=a("div"),F(iy.$$.fragment),DUo=l(),Hpe=a("p"),GUo=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),OUo=l(),Xa=a("p"),VUo=o("The model class to instantiate is selected based on the "),Upe=a("code"),XUo=o("model_type"),zUo=o(` property of the config object (either
passed as an argument or loaded from `),Jpe=a("code"),QUo=o("pretrained_model_name_or_path"),WUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ype=a("code"),HUo=o("pretrained_model_name_or_path"),UUo=o(":"),JUo=l(),Ne=a("ul"),v6=a("li"),Kpe=a("strong"),YUo=o("data2vec-audio"),KUo=o(" \u2014 "),MX=a("a"),ZUo=o("Data2VecAudioForSequenceClassification"),eJo=o(" (Data2VecAudio model)"),oJo=l(),F6=a("li"),Zpe=a("strong"),rJo=o("hubert"),tJo=o(" \u2014 "),EX=a("a"),aJo=o("HubertForSequenceClassification"),nJo=o(" (Hubert model)"),sJo=l(),T6=a("li"),eue=a("strong"),lJo=o("sew"),iJo=o(" \u2014 "),CX=a("a"),dJo=o("SEWForSequenceClassification"),cJo=o(" (SEW model)"),fJo=l(),M6=a("li"),oue=a("strong"),mJo=o("sew-d"),gJo=o(" \u2014 "),wX=a("a"),hJo=o("SEWDForSequenceClassification"),pJo=o(" (SEW-D model)"),uJo=l(),E6=a("li"),rue=a("strong"),_Jo=o("unispeech"),bJo=o(" \u2014 "),AX=a("a"),vJo=o("UniSpeechForSequenceClassification"),FJo=o(" (UniSpeech model)"),TJo=l(),C6=a("li"),tue=a("strong"),MJo=o("unispeech-sat"),EJo=o(" \u2014 "),yX=a("a"),CJo=o("UniSpeechSatForSequenceClassification"),wJo=o(" (UniSpeechSat model)"),AJo=l(),w6=a("li"),aue=a("strong"),yJo=o("wav2vec2"),LJo=o(" \u2014 "),LX=a("a"),xJo=o("Wav2Vec2ForSequenceClassification"),$Jo=o(" (Wav2Vec2 model)"),kJo=l(),A6=a("li"),nue=a("strong"),SJo=o("wavlm"),RJo=o(" \u2014 "),xX=a("a"),PJo=o("WavLMForSequenceClassification"),BJo=o(" (WavLM model)"),IJo=l(),y6=a("p"),qJo=o("The model is set in evaluation mode by default using "),sue=a("code"),NJo=o("model.eval()"),jJo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lue=a("code"),DJo=o("model.train()"),GJo=l(),F(L6.$$.fragment),$qe=l(),vd=a("h2"),x6=a("a"),iue=a("span"),F(dy.$$.fragment),OJo=l(),due=a("span"),VJo=o("AutoModelForAudioFrameClassification"),kqe=l(),Xo=a("div"),F(cy.$$.fragment),XJo=l(),Fd=a("p"),zJo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),$X=a("a"),QJo=o("from_pretrained()"),WJo=o(" class method or the "),kX=a("a"),HJo=o("from_config()"),UJo=o(` class
method.`),JJo=l(),fy=a("p"),YJo=o("This class cannot be instantiated directly using "),cue=a("code"),KJo=o("__init__()"),ZJo=o(" (throws an error)."),eYo=l(),vt=a("div"),F(my.$$.fragment),oYo=l(),fue=a("p"),rYo=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),tYo=l(),Td=a("p"),aYo=o(`Note:
Loading a model from its configuration file does `),mue=a("strong"),nYo=o("not"),sYo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SX=a("a"),lYo=o("from_pretrained()"),iYo=o(" to load the model weights."),dYo=l(),F($6.$$.fragment),cYo=l(),co=a("div"),F(gy.$$.fragment),fYo=l(),gue=a("p"),mYo=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),gYo=l(),za=a("p"),hYo=o("The model class to instantiate is selected based on the "),hue=a("code"),pYo=o("model_type"),uYo=o(` property of the config object (either
passed as an argument or loaded from `),pue=a("code"),_Yo=o("pretrained_model_name_or_path"),bYo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uue=a("code"),vYo=o("pretrained_model_name_or_path"),FYo=o(":"),TYo=l(),Qa=a("ul"),k6=a("li"),_ue=a("strong"),MYo=o("data2vec-audio"),EYo=o(" \u2014 "),RX=a("a"),CYo=o("Data2VecAudioForAudioFrameClassification"),wYo=o(" (Data2VecAudio model)"),AYo=l(),S6=a("li"),bue=a("strong"),yYo=o("unispeech-sat"),LYo=o(" \u2014 "),PX=a("a"),xYo=o("UniSpeechSatForAudioFrameClassification"),$Yo=o(" (UniSpeechSat model)"),kYo=l(),R6=a("li"),vue=a("strong"),SYo=o("wav2vec2"),RYo=o(" \u2014 "),BX=a("a"),PYo=o("Wav2Vec2ForAudioFrameClassification"),BYo=o(" (Wav2Vec2 model)"),IYo=l(),P6=a("li"),Fue=a("strong"),qYo=o("wavlm"),NYo=o(" \u2014 "),IX=a("a"),jYo=o("WavLMForAudioFrameClassification"),DYo=o(" (WavLM model)"),GYo=l(),B6=a("p"),OYo=o("The model is set in evaluation mode by default using "),Tue=a("code"),VYo=o("model.eval()"),XYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mue=a("code"),zYo=o("model.train()"),QYo=l(),F(I6.$$.fragment),Sqe=l(),Md=a("h2"),q6=a("a"),Eue=a("span"),F(hy.$$.fragment),WYo=l(),Cue=a("span"),HYo=o("AutoModelForCTC"),Rqe=l(),zo=a("div"),F(py.$$.fragment),UYo=l(),Ed=a("p"),JYo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),qX=a("a"),YYo=o("from_pretrained()"),KYo=o(" class method or the "),NX=a("a"),ZYo=o("from_config()"),eKo=o(` class
method.`),oKo=l(),uy=a("p"),rKo=o("This class cannot be instantiated directly using "),wue=a("code"),tKo=o("__init__()"),aKo=o(" (throws an error)."),nKo=l(),Ft=a("div"),F(_y.$$.fragment),sKo=l(),Aue=a("p"),lKo=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),iKo=l(),Cd=a("p"),dKo=o(`Note:
Loading a model from its configuration file does `),yue=a("strong"),cKo=o("not"),fKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jX=a("a"),mKo=o("from_pretrained()"),gKo=o(" to load the model weights."),hKo=l(),F(N6.$$.fragment),pKo=l(),fo=a("div"),F(by.$$.fragment),uKo=l(),Lue=a("p"),_Ko=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),bKo=l(),Wa=a("p"),vKo=o("The model class to instantiate is selected based on the "),xue=a("code"),FKo=o("model_type"),TKo=o(` property of the config object (either
passed as an argument or loaded from `),$ue=a("code"),MKo=o("pretrained_model_name_or_path"),EKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kue=a("code"),CKo=o("pretrained_model_name_or_path"),wKo=o(":"),AKo=l(),je=a("ul"),j6=a("li"),Sue=a("strong"),yKo=o("data2vec-audio"),LKo=o(" \u2014 "),DX=a("a"),xKo=o("Data2VecAudioForCTC"),$Ko=o(" (Data2VecAudio model)"),kKo=l(),D6=a("li"),Rue=a("strong"),SKo=o("hubert"),RKo=o(" \u2014 "),GX=a("a"),PKo=o("HubertForCTC"),BKo=o(" (Hubert model)"),IKo=l(),G6=a("li"),Pue=a("strong"),qKo=o("sew"),NKo=o(" \u2014 "),OX=a("a"),jKo=o("SEWForCTC"),DKo=o(" (SEW model)"),GKo=l(),O6=a("li"),Bue=a("strong"),OKo=o("sew-d"),VKo=o(" \u2014 "),VX=a("a"),XKo=o("SEWDForCTC"),zKo=o(" (SEW-D model)"),QKo=l(),V6=a("li"),Iue=a("strong"),WKo=o("unispeech"),HKo=o(" \u2014 "),XX=a("a"),UKo=o("UniSpeechForCTC"),JKo=o(" (UniSpeech model)"),YKo=l(),X6=a("li"),que=a("strong"),KKo=o("unispeech-sat"),ZKo=o(" \u2014 "),zX=a("a"),eZo=o("UniSpeechSatForCTC"),oZo=o(" (UniSpeechSat model)"),rZo=l(),z6=a("li"),Nue=a("strong"),tZo=o("wav2vec2"),aZo=o(" \u2014 "),QX=a("a"),nZo=o("Wav2Vec2ForCTC"),sZo=o(" (Wav2Vec2 model)"),lZo=l(),Q6=a("li"),jue=a("strong"),iZo=o("wavlm"),dZo=o(" \u2014 "),WX=a("a"),cZo=o("WavLMForCTC"),fZo=o(" (WavLM model)"),mZo=l(),W6=a("p"),gZo=o("The model is set in evaluation mode by default using "),Due=a("code"),hZo=o("model.eval()"),pZo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gue=a("code"),uZo=o("model.train()"),_Zo=l(),F(H6.$$.fragment),Pqe=l(),wd=a("h2"),U6=a("a"),Oue=a("span"),F(vy.$$.fragment),bZo=l(),Vue=a("span"),vZo=o("AutoModelForSpeechSeq2Seq"),Bqe=l(),Qo=a("div"),F(Fy.$$.fragment),FZo=l(),Ad=a("p"),TZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),HX=a("a"),MZo=o("from_pretrained()"),EZo=o(" class method or the "),UX=a("a"),CZo=o("from_config()"),wZo=o(` class
method.`),AZo=l(),Ty=a("p"),yZo=o("This class cannot be instantiated directly using "),Xue=a("code"),LZo=o("__init__()"),xZo=o(" (throws an error)."),$Zo=l(),Tt=a("div"),F(My.$$.fragment),kZo=l(),zue=a("p"),SZo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),RZo=l(),yd=a("p"),PZo=o(`Note:
Loading a model from its configuration file does `),Que=a("strong"),BZo=o("not"),IZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JX=a("a"),qZo=o("from_pretrained()"),NZo=o(" to load the model weights."),jZo=l(),F(J6.$$.fragment),DZo=l(),mo=a("div"),F(Ey.$$.fragment),GZo=l(),Wue=a("p"),OZo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),VZo=l(),Ha=a("p"),XZo=o("The model class to instantiate is selected based on the "),Hue=a("code"),zZo=o("model_type"),QZo=o(` property of the config object (either
passed as an argument or loaded from `),Uue=a("code"),WZo=o("pretrained_model_name_or_path"),HZo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jue=a("code"),UZo=o("pretrained_model_name_or_path"),JZo=o(":"),YZo=l(),Cy=a("ul"),Y6=a("li"),Yue=a("strong"),KZo=o("speech-encoder-decoder"),ZZo=o(" \u2014 "),YX=a("a"),eer=o("SpeechEncoderDecoderModel"),oer=o(" (Speech Encoder decoder model)"),rer=l(),K6=a("li"),Kue=a("strong"),ter=o("speech_to_text"),aer=o(" \u2014 "),KX=a("a"),ner=o("Speech2TextForConditionalGeneration"),ser=o(" (Speech2Text model)"),ler=l(),Z6=a("p"),ier=o("The model is set in evaluation mode by default using "),Zue=a("code"),der=o("model.eval()"),cer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),e_e=a("code"),fer=o("model.train()"),mer=l(),F(eT.$$.fragment),Iqe=l(),Ld=a("h2"),oT=a("a"),o_e=a("span"),F(wy.$$.fragment),ger=l(),r_e=a("span"),her=o("AutoModelForAudioXVector"),qqe=l(),Wo=a("div"),F(Ay.$$.fragment),per=l(),xd=a("p"),uer=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),ZX=a("a"),_er=o("from_pretrained()"),ber=o(" class method or the "),ez=a("a"),ver=o("from_config()"),Fer=o(` class
method.`),Ter=l(),yy=a("p"),Mer=o("This class cannot be instantiated directly using "),t_e=a("code"),Eer=o("__init__()"),Cer=o(" (throws an error)."),wer=l(),Mt=a("div"),F(Ly.$$.fragment),Aer=l(),a_e=a("p"),yer=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Ler=l(),$d=a("p"),xer=o(`Note:
Loading a model from its configuration file does `),n_e=a("strong"),$er=o("not"),ker=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oz=a("a"),Ser=o("from_pretrained()"),Rer=o(" to load the model weights."),Per=l(),F(rT.$$.fragment),Ber=l(),go=a("div"),F(xy.$$.fragment),Ier=l(),s_e=a("p"),qer=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Ner=l(),Ua=a("p"),jer=o("The model class to instantiate is selected based on the "),l_e=a("code"),Der=o("model_type"),Ger=o(` property of the config object (either
passed as an argument or loaded from `),i_e=a("code"),Oer=o("pretrained_model_name_or_path"),Ver=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d_e=a("code"),Xer=o("pretrained_model_name_or_path"),zer=o(":"),Qer=l(),Ja=a("ul"),tT=a("li"),c_e=a("strong"),Wer=o("data2vec-audio"),Her=o(" \u2014 "),rz=a("a"),Uer=o("Data2VecAudioForXVector"),Jer=o(" (Data2VecAudio model)"),Yer=l(),aT=a("li"),f_e=a("strong"),Ker=o("unispeech-sat"),Zer=o(" \u2014 "),tz=a("a"),eor=o("UniSpeechSatForXVector"),oor=o(" (UniSpeechSat model)"),ror=l(),nT=a("li"),m_e=a("strong"),tor=o("wav2vec2"),aor=o(" \u2014 "),az=a("a"),nor=o("Wav2Vec2ForXVector"),sor=o(" (Wav2Vec2 model)"),lor=l(),sT=a("li"),g_e=a("strong"),ior=o("wavlm"),dor=o(" \u2014 "),nz=a("a"),cor=o("WavLMForXVector"),mor=o(" (WavLM model)"),gor=l(),lT=a("p"),hor=o("The model is set in evaluation mode by default using "),h_e=a("code"),por=o("model.eval()"),uor=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),p_e=a("code"),_or=o("model.train()"),bor=l(),F(iT.$$.fragment),Nqe=l(),kd=a("h2"),dT=a("a"),u_e=a("span"),F($y.$$.fragment),vor=l(),__e=a("span"),For=o("AutoModelForMaskedImageModeling"),jqe=l(),Ho=a("div"),F(ky.$$.fragment),Tor=l(),Sd=a("p"),Mor=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),sz=a("a"),Eor=o("from_pretrained()"),Cor=o(" class method or the "),lz=a("a"),wor=o("from_config()"),Aor=o(` class
method.`),yor=l(),Sy=a("p"),Lor=o("This class cannot be instantiated directly using "),b_e=a("code"),xor=o("__init__()"),$or=o(" (throws an error)."),kor=l(),Et=a("div"),F(Ry.$$.fragment),Sor=l(),v_e=a("p"),Ror=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Por=l(),Rd=a("p"),Bor=o(`Note:
Loading a model from its configuration file does `),F_e=a("strong"),Ior=o("not"),qor=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iz=a("a"),Nor=o("from_pretrained()"),jor=o(" to load the model weights."),Dor=l(),F(cT.$$.fragment),Gor=l(),ho=a("div"),F(Py.$$.fragment),Oor=l(),T_e=a("p"),Vor=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Xor=l(),Ya=a("p"),zor=o("The model class to instantiate is selected based on the "),M_e=a("code"),Qor=o("model_type"),Wor=o(` property of the config object (either
passed as an argument or loaded from `),E_e=a("code"),Hor=o("pretrained_model_name_or_path"),Uor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C_e=a("code"),Jor=o("pretrained_model_name_or_path"),Yor=o(":"),Kor=l(),Pd=a("ul"),fT=a("li"),w_e=a("strong"),Zor=o("deit"),err=o(" \u2014 "),dz=a("a"),orr=o("DeiTForMaskedImageModeling"),rrr=o(" (DeiT model)"),trr=l(),mT=a("li"),A_e=a("strong"),arr=o("swin"),nrr=o(" \u2014 "),cz=a("a"),srr=o("SwinForMaskedImageModeling"),lrr=o(" (Swin model)"),irr=l(),gT=a("li"),y_e=a("strong"),drr=o("vit"),crr=o(" \u2014 "),fz=a("a"),frr=o("ViTForMaskedImageModeling"),mrr=o(" (ViT model)"),grr=l(),hT=a("p"),hrr=o("The model is set in evaluation mode by default using "),L_e=a("code"),prr=o("model.eval()"),urr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),x_e=a("code"),_rr=o("model.train()"),brr=l(),F(pT.$$.fragment),Dqe=l(),Bd=a("h2"),uT=a("a"),$_e=a("span"),F(By.$$.fragment),vrr=l(),k_e=a("span"),Frr=o("AutoModelForObjectDetection"),Gqe=l(),Uo=a("div"),F(Iy.$$.fragment),Trr=l(),Id=a("p"),Mrr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),mz=a("a"),Err=o("from_pretrained()"),Crr=o(" class method or the "),gz=a("a"),wrr=o("from_config()"),Arr=o(` class
method.`),yrr=l(),qy=a("p"),Lrr=o("This class cannot be instantiated directly using "),S_e=a("code"),xrr=o("__init__()"),$rr=o(" (throws an error)."),krr=l(),Ct=a("div"),F(Ny.$$.fragment),Srr=l(),R_e=a("p"),Rrr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Prr=l(),qd=a("p"),Brr=o(`Note:
Loading a model from its configuration file does `),P_e=a("strong"),Irr=o("not"),qrr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hz=a("a"),Nrr=o("from_pretrained()"),jrr=o(" to load the model weights."),Drr=l(),F(_T.$$.fragment),Grr=l(),po=a("div"),F(jy.$$.fragment),Orr=l(),B_e=a("p"),Vrr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),Xrr=l(),Ka=a("p"),zrr=o("The model class to instantiate is selected based on the "),I_e=a("code"),Qrr=o("model_type"),Wrr=o(` property of the config object (either
passed as an argument or loaded from `),q_e=a("code"),Hrr=o("pretrained_model_name_or_path"),Urr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N_e=a("code"),Jrr=o("pretrained_model_name_or_path"),Yrr=o(":"),Krr=l(),Dy=a("ul"),bT=a("li"),j_e=a("strong"),Zrr=o("detr"),etr=o(" \u2014 "),pz=a("a"),otr=o("DetrForObjectDetection"),rtr=o(" (DETR model)"),ttr=l(),vT=a("li"),D_e=a("strong"),atr=o("yolos"),ntr=o(" \u2014 "),uz=a("a"),str=o("YolosForObjectDetection"),ltr=o(" (YOLOS model)"),itr=l(),FT=a("p"),dtr=o("The model is set in evaluation mode by default using "),G_e=a("code"),ctr=o("model.eval()"),ftr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),O_e=a("code"),mtr=o("model.train()"),gtr=l(),F(TT.$$.fragment),Oqe=l(),Nd=a("h2"),MT=a("a"),V_e=a("span"),F(Gy.$$.fragment),htr=l(),X_e=a("span"),ptr=o("AutoModelForImageSegmentation"),Vqe=l(),Jo=a("div"),F(Oy.$$.fragment),utr=l(),jd=a("p"),_tr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),_z=a("a"),btr=o("from_pretrained()"),vtr=o(" class method or the "),bz=a("a"),Ftr=o("from_config()"),Ttr=o(` class
method.`),Mtr=l(),Vy=a("p"),Etr=o("This class cannot be instantiated directly using "),z_e=a("code"),Ctr=o("__init__()"),wtr=o(" (throws an error)."),Atr=l(),wt=a("div"),F(Xy.$$.fragment),ytr=l(),Q_e=a("p"),Ltr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),xtr=l(),Dd=a("p"),$tr=o(`Note:
Loading a model from its configuration file does `),W_e=a("strong"),ktr=o("not"),Str=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vz=a("a"),Rtr=o("from_pretrained()"),Ptr=o(" to load the model weights."),Btr=l(),F(ET.$$.fragment),Itr=l(),uo=a("div"),F(zy.$$.fragment),qtr=l(),H_e=a("p"),Ntr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),jtr=l(),Za=a("p"),Dtr=o("The model class to instantiate is selected based on the "),U_e=a("code"),Gtr=o("model_type"),Otr=o(` property of the config object (either
passed as an argument or loaded from `),J_e=a("code"),Vtr=o("pretrained_model_name_or_path"),Xtr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Y_e=a("code"),ztr=o("pretrained_model_name_or_path"),Qtr=o(":"),Wtr=l(),K_e=a("ul"),CT=a("li"),Z_e=a("strong"),Htr=o("detr"),Utr=o(" \u2014 "),Fz=a("a"),Jtr=o("DetrForSegmentation"),Ytr=o(" (DETR model)"),Ktr=l(),wT=a("p"),Ztr=o("The model is set in evaluation mode by default using "),e2e=a("code"),ear=o("model.eval()"),oar=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o2e=a("code"),rar=o("model.train()"),tar=l(),F(AT.$$.fragment),Xqe=l(),Gd=a("h2"),yT=a("a"),r2e=a("span"),F(Qy.$$.fragment),aar=l(),t2e=a("span"),nar=o("AutoModelForSemanticSegmentation"),zqe=l(),Yo=a("div"),F(Wy.$$.fragment),sar=l(),Od=a("p"),lar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Tz=a("a"),iar=o("from_pretrained()"),dar=o(" class method or the "),Mz=a("a"),car=o("from_config()"),far=o(` class
method.`),mar=l(),Hy=a("p"),gar=o("This class cannot be instantiated directly using "),a2e=a("code"),har=o("__init__()"),par=o(" (throws an error)."),uar=l(),At=a("div"),F(Uy.$$.fragment),_ar=l(),n2e=a("p"),bar=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Far=l(),Vd=a("p"),Tar=o(`Note:
Loading a model from its configuration file does `),s2e=a("strong"),Mar=o("not"),Ear=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ez=a("a"),Car=o("from_pretrained()"),war=o(" to load the model weights."),Aar=l(),F(LT.$$.fragment),yar=l(),_o=a("div"),F(Jy.$$.fragment),Lar=l(),l2e=a("p"),xar=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),$ar=l(),en=a("p"),kar=o("The model class to instantiate is selected based on the "),i2e=a("code"),Sar=o("model_type"),Rar=o(` property of the config object (either
passed as an argument or loaded from `),d2e=a("code"),Par=o("pretrained_model_name_or_path"),Bar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c2e=a("code"),Iar=o("pretrained_model_name_or_path"),qar=o(":"),Nar=l(),on=a("ul"),xT=a("li"),f2e=a("strong"),jar=o("beit"),Dar=o(" \u2014 "),Cz=a("a"),Gar=o("BeitForSemanticSegmentation"),Oar=o(" (BEiT model)"),Var=l(),$T=a("li"),m2e=a("strong"),Xar=o("data2vec-vision"),zar=o(" \u2014 "),wz=a("a"),Qar=o("Data2VecVisionForSemanticSegmentation"),War=o(" (Data2VecVision model)"),Har=l(),kT=a("li"),g2e=a("strong"),Uar=o("dpt"),Jar=o(" \u2014 "),Az=a("a"),Yar=o("DPTForSemanticSegmentation"),Kar=o(" (DPT model)"),Zar=l(),ST=a("li"),h2e=a("strong"),enr=o("segformer"),onr=o(" \u2014 "),yz=a("a"),rnr=o("SegformerForSemanticSegmentation"),tnr=o(" (SegFormer model)"),anr=l(),RT=a("p"),nnr=o("The model is set in evaluation mode by default using "),p2e=a("code"),snr=o("model.eval()"),lnr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u2e=a("code"),inr=o("model.train()"),dnr=l(),F(PT.$$.fragment),Qqe=l(),Xd=a("h2"),BT=a("a"),_2e=a("span"),F(Yy.$$.fragment),cnr=l(),b2e=a("span"),fnr=o("AutoModelForInstanceSegmentation"),Wqe=l(),Ko=a("div"),F(Ky.$$.fragment),mnr=l(),zd=a("p"),gnr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Lz=a("a"),hnr=o("from_pretrained()"),pnr=o(" class method or the "),xz=a("a"),unr=o("from_config()"),_nr=o(` class
method.`),bnr=l(),Zy=a("p"),vnr=o("This class cannot be instantiated directly using "),v2e=a("code"),Fnr=o("__init__()"),Tnr=o(" (throws an error)."),Mnr=l(),yt=a("div"),F(eL.$$.fragment),Enr=l(),F2e=a("p"),Cnr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),wnr=l(),Qd=a("p"),Anr=o(`Note:
Loading a model from its configuration file does `),T2e=a("strong"),ynr=o("not"),Lnr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$z=a("a"),xnr=o("from_pretrained()"),$nr=o(" to load the model weights."),knr=l(),F(IT.$$.fragment),Snr=l(),bo=a("div"),F(oL.$$.fragment),Rnr=l(),M2e=a("p"),Pnr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Bnr=l(),rn=a("p"),Inr=o("The model class to instantiate is selected based on the "),E2e=a("code"),qnr=o("model_type"),Nnr=o(` property of the config object (either
passed as an argument or loaded from `),C2e=a("code"),jnr=o("pretrained_model_name_or_path"),Dnr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w2e=a("code"),Gnr=o("pretrained_model_name_or_path"),Onr=o(":"),Vnr=l(),A2e=a("ul"),qT=a("li"),y2e=a("strong"),Xnr=o("maskformer"),znr=o(" \u2014 "),kz=a("a"),Qnr=o("MaskFormerForInstanceSegmentation"),Wnr=o(" (MaskFormer model)"),Hnr=l(),NT=a("p"),Unr=o("The model is set in evaluation mode by default using "),L2e=a("code"),Jnr=o("model.eval()"),Ynr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),x2e=a("code"),Knr=o("model.train()"),Znr=l(),F(jT.$$.fragment),Hqe=l(),Wd=a("h2"),DT=a("a"),$2e=a("span"),F(rL.$$.fragment),esr=l(),k2e=a("span"),osr=o("TFAutoModel"),Uqe=l(),Zo=a("div"),F(tL.$$.fragment),rsr=l(),Hd=a("p"),tsr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Sz=a("a"),asr=o("from_pretrained()"),nsr=o(" class method or the "),Rz=a("a"),ssr=o("from_config()"),lsr=o(` class
method.`),isr=l(),aL=a("p"),dsr=o("This class cannot be instantiated directly using "),S2e=a("code"),csr=o("__init__()"),fsr=o(" (throws an error)."),msr=l(),Lt=a("div"),F(nL.$$.fragment),gsr=l(),R2e=a("p"),hsr=o("Instantiates one of the base model classes of the library from a configuration."),psr=l(),Ud=a("p"),usr=o(`Note:
Loading a model from its configuration file does `),P2e=a("strong"),_sr=o("not"),bsr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Pz=a("a"),vsr=o("from_pretrained()"),Fsr=o(" to load the model weights."),Tsr=l(),F(GT.$$.fragment),Msr=l(),yr=a("div"),F(sL.$$.fragment),Esr=l(),B2e=a("p"),Csr=o("Instantiate one of the base model classes of the library from a pretrained model."),wsr=l(),tn=a("p"),Asr=o("The model class to instantiate is selected based on the "),I2e=a("code"),ysr=o("model_type"),Lsr=o(` property of the config object (either
passed as an argument or loaded from `),q2e=a("code"),xsr=o("pretrained_model_name_or_path"),$sr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N2e=a("code"),ksr=o("pretrained_model_name_or_path"),Ssr=o(":"),Rsr=l(),j=a("ul"),OT=a("li"),j2e=a("strong"),Psr=o("albert"),Bsr=o(" \u2014 "),Bz=a("a"),Isr=o("TFAlbertModel"),qsr=o(" (ALBERT model)"),Nsr=l(),VT=a("li"),D2e=a("strong"),jsr=o("bart"),Dsr=o(" \u2014 "),Iz=a("a"),Gsr=o("TFBartModel"),Osr=o(" (BART model)"),Vsr=l(),XT=a("li"),G2e=a("strong"),Xsr=o("bert"),zsr=o(" \u2014 "),qz=a("a"),Qsr=o("TFBertModel"),Wsr=o(" (BERT model)"),Hsr=l(),zT=a("li"),O2e=a("strong"),Usr=o("blenderbot"),Jsr=o(" \u2014 "),Nz=a("a"),Ysr=o("TFBlenderbotModel"),Ksr=o(" (Blenderbot model)"),Zsr=l(),QT=a("li"),V2e=a("strong"),elr=o("blenderbot-small"),olr=o(" \u2014 "),jz=a("a"),rlr=o("TFBlenderbotSmallModel"),tlr=o(" (BlenderbotSmall model)"),alr=l(),WT=a("li"),X2e=a("strong"),nlr=o("camembert"),slr=o(" \u2014 "),Dz=a("a"),llr=o("TFCamembertModel"),ilr=o(" (CamemBERT model)"),dlr=l(),HT=a("li"),z2e=a("strong"),clr=o("clip"),flr=o(" \u2014 "),Gz=a("a"),mlr=o("TFCLIPModel"),glr=o(" (CLIP model)"),hlr=l(),UT=a("li"),Q2e=a("strong"),plr=o("convbert"),ulr=o(" \u2014 "),Oz=a("a"),_lr=o("TFConvBertModel"),blr=o(" (ConvBERT model)"),vlr=l(),JT=a("li"),W2e=a("strong"),Flr=o("convnext"),Tlr=o(" \u2014 "),Vz=a("a"),Mlr=o("TFConvNextModel"),Elr=o(" (ConvNext model)"),Clr=l(),YT=a("li"),H2e=a("strong"),wlr=o("ctrl"),Alr=o(" \u2014 "),Xz=a("a"),ylr=o("TFCTRLModel"),Llr=o(" (CTRL model)"),xlr=l(),KT=a("li"),U2e=a("strong"),$lr=o("data2vec-vision"),klr=o(" \u2014 "),zz=a("a"),Slr=o("TFData2VecVisionModel"),Rlr=o(" (Data2VecVision model)"),Plr=l(),ZT=a("li"),J2e=a("strong"),Blr=o("deberta"),Ilr=o(" \u2014 "),Qz=a("a"),qlr=o("TFDebertaModel"),Nlr=o(" (DeBERTa model)"),jlr=l(),e8=a("li"),Y2e=a("strong"),Dlr=o("deberta-v2"),Glr=o(" \u2014 "),Wz=a("a"),Olr=o("TFDebertaV2Model"),Vlr=o(" (DeBERTa-v2 model)"),Xlr=l(),o8=a("li"),K2e=a("strong"),zlr=o("distilbert"),Qlr=o(" \u2014 "),Hz=a("a"),Wlr=o("TFDistilBertModel"),Hlr=o(" (DistilBERT model)"),Ulr=l(),r8=a("li"),Z2e=a("strong"),Jlr=o("dpr"),Ylr=o(" \u2014 "),Uz=a("a"),Klr=o("TFDPRQuestionEncoder"),Zlr=o(" (DPR model)"),eir=l(),t8=a("li"),e1e=a("strong"),oir=o("electra"),rir=o(" \u2014 "),Jz=a("a"),tir=o("TFElectraModel"),air=o(" (ELECTRA model)"),nir=l(),a8=a("li"),o1e=a("strong"),sir=o("flaubert"),lir=o(" \u2014 "),Yz=a("a"),iir=o("TFFlaubertModel"),dir=o(" (FlauBERT model)"),cir=l(),Ds=a("li"),r1e=a("strong"),fir=o("funnel"),mir=o(" \u2014 "),Kz=a("a"),gir=o("TFFunnelModel"),hir=o(" or "),Zz=a("a"),pir=o("TFFunnelBaseModel"),uir=o(" (Funnel Transformer model)"),_ir=l(),n8=a("li"),t1e=a("strong"),bir=o("gpt2"),vir=o(" \u2014 "),eQ=a("a"),Fir=o("TFGPT2Model"),Tir=o(" (OpenAI GPT-2 model)"),Mir=l(),s8=a("li"),a1e=a("strong"),Eir=o("gptj"),Cir=o(" \u2014 "),oQ=a("a"),wir=o("TFGPTJModel"),Air=o(" (GPT-J model)"),yir=l(),l8=a("li"),n1e=a("strong"),Lir=o("hubert"),xir=o(" \u2014 "),rQ=a("a"),$ir=o("TFHubertModel"),kir=o(" (Hubert model)"),Sir=l(),i8=a("li"),s1e=a("strong"),Rir=o("layoutlm"),Pir=o(" \u2014 "),tQ=a("a"),Bir=o("TFLayoutLMModel"),Iir=o(" (LayoutLM model)"),qir=l(),d8=a("li"),l1e=a("strong"),Nir=o("led"),jir=o(" \u2014 "),aQ=a("a"),Dir=o("TFLEDModel"),Gir=o(" (LED model)"),Oir=l(),c8=a("li"),i1e=a("strong"),Vir=o("longformer"),Xir=o(" \u2014 "),nQ=a("a"),zir=o("TFLongformerModel"),Qir=o(" (Longformer model)"),Wir=l(),f8=a("li"),d1e=a("strong"),Hir=o("lxmert"),Uir=o(" \u2014 "),sQ=a("a"),Jir=o("TFLxmertModel"),Yir=o(" (LXMERT model)"),Kir=l(),m8=a("li"),c1e=a("strong"),Zir=o("marian"),edr=o(" \u2014 "),lQ=a("a"),odr=o("TFMarianModel"),rdr=o(" (Marian model)"),tdr=l(),g8=a("li"),f1e=a("strong"),adr=o("mbart"),ndr=o(" \u2014 "),iQ=a("a"),sdr=o("TFMBartModel"),ldr=o(" (mBART model)"),idr=l(),h8=a("li"),m1e=a("strong"),ddr=o("mobilebert"),cdr=o(" \u2014 "),dQ=a("a"),fdr=o("TFMobileBertModel"),mdr=o(" (MobileBERT model)"),gdr=l(),p8=a("li"),g1e=a("strong"),hdr=o("mpnet"),pdr=o(" \u2014 "),cQ=a("a"),udr=o("TFMPNetModel"),_dr=o(" (MPNet model)"),bdr=l(),u8=a("li"),h1e=a("strong"),vdr=o("mt5"),Fdr=o(" \u2014 "),fQ=a("a"),Tdr=o("TFMT5Model"),Mdr=o(" (mT5 model)"),Edr=l(),_8=a("li"),p1e=a("strong"),Cdr=o("openai-gpt"),wdr=o(" \u2014 "),mQ=a("a"),Adr=o("TFOpenAIGPTModel"),ydr=o(" (OpenAI GPT model)"),Ldr=l(),b8=a("li"),u1e=a("strong"),xdr=o("pegasus"),$dr=o(" \u2014 "),gQ=a("a"),kdr=o("TFPegasusModel"),Sdr=o(" (Pegasus model)"),Rdr=l(),v8=a("li"),_1e=a("strong"),Pdr=o("rembert"),Bdr=o(" \u2014 "),hQ=a("a"),Idr=o("TFRemBertModel"),qdr=o(" (RemBERT model)"),Ndr=l(),F8=a("li"),b1e=a("strong"),jdr=o("roberta"),Ddr=o(" \u2014 "),pQ=a("a"),Gdr=o("TFRobertaModel"),Odr=o(" (RoBERTa model)"),Vdr=l(),T8=a("li"),v1e=a("strong"),Xdr=o("roformer"),zdr=o(" \u2014 "),uQ=a("a"),Qdr=o("TFRoFormerModel"),Wdr=o(" (RoFormer model)"),Hdr=l(),M8=a("li"),F1e=a("strong"),Udr=o("speech_to_text"),Jdr=o(" \u2014 "),_Q=a("a"),Ydr=o("TFSpeech2TextModel"),Kdr=o(" (Speech2Text model)"),Zdr=l(),E8=a("li"),T1e=a("strong"),ecr=o("t5"),ocr=o(" \u2014 "),bQ=a("a"),rcr=o("TFT5Model"),tcr=o(" (T5 model)"),acr=l(),C8=a("li"),M1e=a("strong"),ncr=o("tapas"),scr=o(" \u2014 "),vQ=a("a"),lcr=o("TFTapasModel"),icr=o(" (TAPAS model)"),dcr=l(),w8=a("li"),E1e=a("strong"),ccr=o("transfo-xl"),fcr=o(" \u2014 "),FQ=a("a"),mcr=o("TFTransfoXLModel"),gcr=o(" (Transformer-XL model)"),hcr=l(),A8=a("li"),C1e=a("strong"),pcr=o("vit"),ucr=o(" \u2014 "),TQ=a("a"),_cr=o("TFViTModel"),bcr=o(" (ViT model)"),vcr=l(),y8=a("li"),w1e=a("strong"),Fcr=o("vit_mae"),Tcr=o(" \u2014 "),MQ=a("a"),Mcr=o("TFViTMAEModel"),Ecr=o(" (ViTMAE model)"),Ccr=l(),L8=a("li"),A1e=a("strong"),wcr=o("wav2vec2"),Acr=o(" \u2014 "),EQ=a("a"),ycr=o("TFWav2Vec2Model"),Lcr=o(" (Wav2Vec2 model)"),xcr=l(),x8=a("li"),y1e=a("strong"),$cr=o("xlm"),kcr=o(" \u2014 "),CQ=a("a"),Scr=o("TFXLMModel"),Rcr=o(" (XLM model)"),Pcr=l(),$8=a("li"),L1e=a("strong"),Bcr=o("xlm-roberta"),Icr=o(" \u2014 "),wQ=a("a"),qcr=o("TFXLMRobertaModel"),Ncr=o(" (XLM-RoBERTa model)"),jcr=l(),k8=a("li"),x1e=a("strong"),Dcr=o("xlnet"),Gcr=o(" \u2014 "),AQ=a("a"),Ocr=o("TFXLNetModel"),Vcr=o(" (XLNet model)"),Xcr=l(),F(S8.$$.fragment),Jqe=l(),Jd=a("h2"),R8=a("a"),$1e=a("span"),F(lL.$$.fragment),zcr=l(),k1e=a("span"),Qcr=o("TFAutoModelForPreTraining"),Yqe=l(),er=a("div"),F(iL.$$.fragment),Wcr=l(),Yd=a("p"),Hcr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),yQ=a("a"),Ucr=o("from_pretrained()"),Jcr=o(" class method or the "),LQ=a("a"),Ycr=o("from_config()"),Kcr=o(` class
method.`),Zcr=l(),dL=a("p"),efr=o("This class cannot be instantiated directly using "),S1e=a("code"),ofr=o("__init__()"),rfr=o(" (throws an error)."),tfr=l(),xt=a("div"),F(cL.$$.fragment),afr=l(),R1e=a("p"),nfr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),sfr=l(),Kd=a("p"),lfr=o(`Note:
Loading a model from its configuration file does `),P1e=a("strong"),ifr=o("not"),dfr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xQ=a("a"),cfr=o("from_pretrained()"),ffr=o(" to load the model weights."),mfr=l(),F(P8.$$.fragment),gfr=l(),Lr=a("div"),F(fL.$$.fragment),hfr=l(),B1e=a("p"),pfr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),ufr=l(),an=a("p"),_fr=o("The model class to instantiate is selected based on the "),I1e=a("code"),bfr=o("model_type"),vfr=o(` property of the config object (either
passed as an argument or loaded from `),q1e=a("code"),Ffr=o("pretrained_model_name_or_path"),Tfr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N1e=a("code"),Mfr=o("pretrained_model_name_or_path"),Efr=o(":"),Cfr=l(),se=a("ul"),B8=a("li"),j1e=a("strong"),wfr=o("albert"),Afr=o(" \u2014 "),$Q=a("a"),yfr=o("TFAlbertForPreTraining"),Lfr=o(" (ALBERT model)"),xfr=l(),I8=a("li"),D1e=a("strong"),$fr=o("bart"),kfr=o(" \u2014 "),kQ=a("a"),Sfr=o("TFBartForConditionalGeneration"),Rfr=o(" (BART model)"),Pfr=l(),q8=a("li"),G1e=a("strong"),Bfr=o("bert"),Ifr=o(" \u2014 "),SQ=a("a"),qfr=o("TFBertForPreTraining"),Nfr=o(" (BERT model)"),jfr=l(),N8=a("li"),O1e=a("strong"),Dfr=o("camembert"),Gfr=o(" \u2014 "),RQ=a("a"),Ofr=o("TFCamembertForMaskedLM"),Vfr=o(" (CamemBERT model)"),Xfr=l(),j8=a("li"),V1e=a("strong"),zfr=o("ctrl"),Qfr=o(" \u2014 "),PQ=a("a"),Wfr=o("TFCTRLLMHeadModel"),Hfr=o(" (CTRL model)"),Ufr=l(),D8=a("li"),X1e=a("strong"),Jfr=o("distilbert"),Yfr=o(" \u2014 "),BQ=a("a"),Kfr=o("TFDistilBertForMaskedLM"),Zfr=o(" (DistilBERT model)"),emr=l(),G8=a("li"),z1e=a("strong"),omr=o("electra"),rmr=o(" \u2014 "),IQ=a("a"),tmr=o("TFElectraForPreTraining"),amr=o(" (ELECTRA model)"),nmr=l(),O8=a("li"),Q1e=a("strong"),smr=o("flaubert"),lmr=o(" \u2014 "),qQ=a("a"),imr=o("TFFlaubertWithLMHeadModel"),dmr=o(" (FlauBERT model)"),cmr=l(),V8=a("li"),W1e=a("strong"),fmr=o("funnel"),mmr=o(" \u2014 "),NQ=a("a"),gmr=o("TFFunnelForPreTraining"),hmr=o(" (Funnel Transformer model)"),pmr=l(),X8=a("li"),H1e=a("strong"),umr=o("gpt2"),_mr=o(" \u2014 "),jQ=a("a"),bmr=o("TFGPT2LMHeadModel"),vmr=o(" (OpenAI GPT-2 model)"),Fmr=l(),z8=a("li"),U1e=a("strong"),Tmr=o("layoutlm"),Mmr=o(" \u2014 "),DQ=a("a"),Emr=o("TFLayoutLMForMaskedLM"),Cmr=o(" (LayoutLM model)"),wmr=l(),Q8=a("li"),J1e=a("strong"),Amr=o("lxmert"),ymr=o(" \u2014 "),GQ=a("a"),Lmr=o("TFLxmertForPreTraining"),xmr=o(" (LXMERT model)"),$mr=l(),W8=a("li"),Y1e=a("strong"),kmr=o("mobilebert"),Smr=o(" \u2014 "),OQ=a("a"),Rmr=o("TFMobileBertForPreTraining"),Pmr=o(" (MobileBERT model)"),Bmr=l(),H8=a("li"),K1e=a("strong"),Imr=o("mpnet"),qmr=o(" \u2014 "),VQ=a("a"),Nmr=o("TFMPNetForMaskedLM"),jmr=o(" (MPNet model)"),Dmr=l(),U8=a("li"),Z1e=a("strong"),Gmr=o("openai-gpt"),Omr=o(" \u2014 "),XQ=a("a"),Vmr=o("TFOpenAIGPTLMHeadModel"),Xmr=o(" (OpenAI GPT model)"),zmr=l(),J8=a("li"),ebe=a("strong"),Qmr=o("roberta"),Wmr=o(" \u2014 "),zQ=a("a"),Hmr=o("TFRobertaForMaskedLM"),Umr=o(" (RoBERTa model)"),Jmr=l(),Y8=a("li"),obe=a("strong"),Ymr=o("t5"),Kmr=o(" \u2014 "),QQ=a("a"),Zmr=o("TFT5ForConditionalGeneration"),egr=o(" (T5 model)"),ogr=l(),K8=a("li"),rbe=a("strong"),rgr=o("tapas"),tgr=o(" \u2014 "),WQ=a("a"),agr=o("TFTapasForMaskedLM"),ngr=o(" (TAPAS model)"),sgr=l(),Z8=a("li"),tbe=a("strong"),lgr=o("transfo-xl"),igr=o(" \u2014 "),HQ=a("a"),dgr=o("TFTransfoXLLMHeadModel"),cgr=o(" (Transformer-XL model)"),fgr=l(),e7=a("li"),abe=a("strong"),mgr=o("vit_mae"),ggr=o(" \u2014 "),UQ=a("a"),hgr=o("TFViTMAEForPreTraining"),pgr=o(" (ViTMAE model)"),ugr=l(),o7=a("li"),nbe=a("strong"),_gr=o("xlm"),bgr=o(" \u2014 "),JQ=a("a"),vgr=o("TFXLMWithLMHeadModel"),Fgr=o(" (XLM model)"),Tgr=l(),r7=a("li"),sbe=a("strong"),Mgr=o("xlm-roberta"),Egr=o(" \u2014 "),YQ=a("a"),Cgr=o("TFXLMRobertaForMaskedLM"),wgr=o(" (XLM-RoBERTa model)"),Agr=l(),t7=a("li"),lbe=a("strong"),ygr=o("xlnet"),Lgr=o(" \u2014 "),KQ=a("a"),xgr=o("TFXLNetLMHeadModel"),$gr=o(" (XLNet model)"),kgr=l(),F(a7.$$.fragment),Kqe=l(),Zd=a("h2"),n7=a("a"),ibe=a("span"),F(mL.$$.fragment),Sgr=l(),dbe=a("span"),Rgr=o("TFAutoModelForCausalLM"),Zqe=l(),or=a("div"),F(gL.$$.fragment),Pgr=l(),ec=a("p"),Bgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),ZQ=a("a"),Igr=o("from_pretrained()"),qgr=o(" class method or the "),eW=a("a"),Ngr=o("from_config()"),jgr=o(` class
method.`),Dgr=l(),hL=a("p"),Ggr=o("This class cannot be instantiated directly using "),cbe=a("code"),Ogr=o("__init__()"),Vgr=o(" (throws an error)."),Xgr=l(),$t=a("div"),F(pL.$$.fragment),zgr=l(),fbe=a("p"),Qgr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Wgr=l(),oc=a("p"),Hgr=o(`Note:
Loading a model from its configuration file does `),mbe=a("strong"),Ugr=o("not"),Jgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oW=a("a"),Ygr=o("from_pretrained()"),Kgr=o(" to load the model weights."),Zgr=l(),F(s7.$$.fragment),ehr=l(),xr=a("div"),F(uL.$$.fragment),ohr=l(),gbe=a("p"),rhr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),thr=l(),nn=a("p"),ahr=o("The model class to instantiate is selected based on the "),hbe=a("code"),nhr=o("model_type"),shr=o(` property of the config object (either
passed as an argument or loaded from `),pbe=a("code"),lhr=o("pretrained_model_name_or_path"),ihr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ube=a("code"),dhr=o("pretrained_model_name_or_path"),chr=o(":"),fhr=l(),Te=a("ul"),l7=a("li"),_be=a("strong"),mhr=o("bert"),ghr=o(" \u2014 "),rW=a("a"),hhr=o("TFBertLMHeadModel"),phr=o(" (BERT model)"),uhr=l(),i7=a("li"),bbe=a("strong"),_hr=o("camembert"),bhr=o(" \u2014 "),tW=a("a"),vhr=o("TFCamembertForCausalLM"),Fhr=o(" (CamemBERT model)"),Thr=l(),d7=a("li"),vbe=a("strong"),Mhr=o("ctrl"),Ehr=o(" \u2014 "),aW=a("a"),Chr=o("TFCTRLLMHeadModel"),whr=o(" (CTRL model)"),Ahr=l(),c7=a("li"),Fbe=a("strong"),yhr=o("gpt2"),Lhr=o(" \u2014 "),nW=a("a"),xhr=o("TFGPT2LMHeadModel"),$hr=o(" (OpenAI GPT-2 model)"),khr=l(),f7=a("li"),Tbe=a("strong"),Shr=o("gptj"),Rhr=o(" \u2014 "),sW=a("a"),Phr=o("TFGPTJForCausalLM"),Bhr=o(" (GPT-J model)"),Ihr=l(),m7=a("li"),Mbe=a("strong"),qhr=o("openai-gpt"),Nhr=o(" \u2014 "),lW=a("a"),jhr=o("TFOpenAIGPTLMHeadModel"),Dhr=o(" (OpenAI GPT model)"),Ghr=l(),g7=a("li"),Ebe=a("strong"),Ohr=o("rembert"),Vhr=o(" \u2014 "),iW=a("a"),Xhr=o("TFRemBertForCausalLM"),zhr=o(" (RemBERT model)"),Qhr=l(),h7=a("li"),Cbe=a("strong"),Whr=o("roberta"),Hhr=o(" \u2014 "),dW=a("a"),Uhr=o("TFRobertaForCausalLM"),Jhr=o(" (RoBERTa model)"),Yhr=l(),p7=a("li"),wbe=a("strong"),Khr=o("roformer"),Zhr=o(" \u2014 "),cW=a("a"),epr=o("TFRoFormerForCausalLM"),opr=o(" (RoFormer model)"),rpr=l(),u7=a("li"),Abe=a("strong"),tpr=o("transfo-xl"),apr=o(" \u2014 "),fW=a("a"),npr=o("TFTransfoXLLMHeadModel"),spr=o(" (Transformer-XL model)"),lpr=l(),_7=a("li"),ybe=a("strong"),ipr=o("xlm"),dpr=o(" \u2014 "),mW=a("a"),cpr=o("TFXLMWithLMHeadModel"),fpr=o(" (XLM model)"),mpr=l(),b7=a("li"),Lbe=a("strong"),gpr=o("xlnet"),hpr=o(" \u2014 "),gW=a("a"),ppr=o("TFXLNetLMHeadModel"),upr=o(" (XLNet model)"),_pr=l(),F(v7.$$.fragment),eNe=l(),rc=a("h2"),F7=a("a"),xbe=a("span"),F(_L.$$.fragment),bpr=l(),$be=a("span"),vpr=o("TFAutoModelForImageClassification"),oNe=l(),rr=a("div"),F(bL.$$.fragment),Fpr=l(),tc=a("p"),Tpr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),hW=a("a"),Mpr=o("from_pretrained()"),Epr=o(" class method or the "),pW=a("a"),Cpr=o("from_config()"),wpr=o(` class
method.`),Apr=l(),vL=a("p"),ypr=o("This class cannot be instantiated directly using "),kbe=a("code"),Lpr=o("__init__()"),xpr=o(" (throws an error)."),$pr=l(),kt=a("div"),F(FL.$$.fragment),kpr=l(),Sbe=a("p"),Spr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Rpr=l(),ac=a("p"),Ppr=o(`Note:
Loading a model from its configuration file does `),Rbe=a("strong"),Bpr=o("not"),Ipr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uW=a("a"),qpr=o("from_pretrained()"),Npr=o(" to load the model weights."),jpr=l(),F(T7.$$.fragment),Dpr=l(),$r=a("div"),F(TL.$$.fragment),Gpr=l(),Pbe=a("p"),Opr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Vpr=l(),sn=a("p"),Xpr=o("The model class to instantiate is selected based on the "),Bbe=a("code"),zpr=o("model_type"),Qpr=o(` property of the config object (either
passed as an argument or loaded from `),Ibe=a("code"),Wpr=o("pretrained_model_name_or_path"),Hpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qbe=a("code"),Upr=o("pretrained_model_name_or_path"),Jpr=o(":"),Ypr=l(),nc=a("ul"),M7=a("li"),Nbe=a("strong"),Kpr=o("convnext"),Zpr=o(" \u2014 "),_W=a("a"),eur=o("TFConvNextForImageClassification"),our=o(" (ConvNext model)"),rur=l(),E7=a("li"),jbe=a("strong"),tur=o("data2vec-vision"),aur=o(" \u2014 "),bW=a("a"),nur=o("TFData2VecVisionForImageClassification"),sur=o(" (Data2VecVision model)"),lur=l(),C7=a("li"),Dbe=a("strong"),iur=o("vit"),dur=o(" \u2014 "),vW=a("a"),cur=o("TFViTForImageClassification"),fur=o(" (ViT model)"),mur=l(),F(w7.$$.fragment),rNe=l(),sc=a("h2"),A7=a("a"),Gbe=a("span"),F(ML.$$.fragment),gur=l(),Obe=a("span"),hur=o("TFAutoModelForMaskedLM"),tNe=l(),tr=a("div"),F(EL.$$.fragment),pur=l(),lc=a("p"),uur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),FW=a("a"),_ur=o("from_pretrained()"),bur=o(" class method or the "),TW=a("a"),vur=o("from_config()"),Fur=o(` class
method.`),Tur=l(),CL=a("p"),Mur=o("This class cannot be instantiated directly using "),Vbe=a("code"),Eur=o("__init__()"),Cur=o(" (throws an error)."),wur=l(),St=a("div"),F(wL.$$.fragment),Aur=l(),Xbe=a("p"),yur=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Lur=l(),ic=a("p"),xur=o(`Note:
Loading a model from its configuration file does `),zbe=a("strong"),$ur=o("not"),kur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MW=a("a"),Sur=o("from_pretrained()"),Rur=o(" to load the model weights."),Pur=l(),F(y7.$$.fragment),Bur=l(),kr=a("div"),F(AL.$$.fragment),Iur=l(),Qbe=a("p"),qur=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Nur=l(),ln=a("p"),jur=o("The model class to instantiate is selected based on the "),Wbe=a("code"),Dur=o("model_type"),Gur=o(` property of the config object (either
passed as an argument or loaded from `),Hbe=a("code"),Our=o("pretrained_model_name_or_path"),Vur=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ube=a("code"),Xur=o("pretrained_model_name_or_path"),zur=o(":"),Qur=l(),ie=a("ul"),L7=a("li"),Jbe=a("strong"),Wur=o("albert"),Hur=o(" \u2014 "),EW=a("a"),Uur=o("TFAlbertForMaskedLM"),Jur=o(" (ALBERT model)"),Yur=l(),x7=a("li"),Ybe=a("strong"),Kur=o("bert"),Zur=o(" \u2014 "),CW=a("a"),e_r=o("TFBertForMaskedLM"),o_r=o(" (BERT model)"),r_r=l(),$7=a("li"),Kbe=a("strong"),t_r=o("camembert"),a_r=o(" \u2014 "),wW=a("a"),n_r=o("TFCamembertForMaskedLM"),s_r=o(" (CamemBERT model)"),l_r=l(),k7=a("li"),Zbe=a("strong"),i_r=o("convbert"),d_r=o(" \u2014 "),AW=a("a"),c_r=o("TFConvBertForMaskedLM"),f_r=o(" (ConvBERT model)"),m_r=l(),S7=a("li"),eve=a("strong"),g_r=o("deberta"),h_r=o(" \u2014 "),yW=a("a"),p_r=o("TFDebertaForMaskedLM"),u_r=o(" (DeBERTa model)"),__r=l(),R7=a("li"),ove=a("strong"),b_r=o("deberta-v2"),v_r=o(" \u2014 "),LW=a("a"),F_r=o("TFDebertaV2ForMaskedLM"),T_r=o(" (DeBERTa-v2 model)"),M_r=l(),P7=a("li"),rve=a("strong"),E_r=o("distilbert"),C_r=o(" \u2014 "),xW=a("a"),w_r=o("TFDistilBertForMaskedLM"),A_r=o(" (DistilBERT model)"),y_r=l(),B7=a("li"),tve=a("strong"),L_r=o("electra"),x_r=o(" \u2014 "),$W=a("a"),$_r=o("TFElectraForMaskedLM"),k_r=o(" (ELECTRA model)"),S_r=l(),I7=a("li"),ave=a("strong"),R_r=o("flaubert"),P_r=o(" \u2014 "),kW=a("a"),B_r=o("TFFlaubertWithLMHeadModel"),I_r=o(" (FlauBERT model)"),q_r=l(),q7=a("li"),nve=a("strong"),N_r=o("funnel"),j_r=o(" \u2014 "),SW=a("a"),D_r=o("TFFunnelForMaskedLM"),G_r=o(" (Funnel Transformer model)"),O_r=l(),N7=a("li"),sve=a("strong"),V_r=o("layoutlm"),X_r=o(" \u2014 "),RW=a("a"),z_r=o("TFLayoutLMForMaskedLM"),Q_r=o(" (LayoutLM model)"),W_r=l(),j7=a("li"),lve=a("strong"),H_r=o("longformer"),U_r=o(" \u2014 "),PW=a("a"),J_r=o("TFLongformerForMaskedLM"),Y_r=o(" (Longformer model)"),K_r=l(),D7=a("li"),ive=a("strong"),Z_r=o("mobilebert"),e2r=o(" \u2014 "),BW=a("a"),o2r=o("TFMobileBertForMaskedLM"),r2r=o(" (MobileBERT model)"),t2r=l(),G7=a("li"),dve=a("strong"),a2r=o("mpnet"),n2r=o(" \u2014 "),IW=a("a"),s2r=o("TFMPNetForMaskedLM"),l2r=o(" (MPNet model)"),i2r=l(),O7=a("li"),cve=a("strong"),d2r=o("rembert"),c2r=o(" \u2014 "),qW=a("a"),f2r=o("TFRemBertForMaskedLM"),m2r=o(" (RemBERT model)"),g2r=l(),V7=a("li"),fve=a("strong"),h2r=o("roberta"),p2r=o(" \u2014 "),NW=a("a"),u2r=o("TFRobertaForMaskedLM"),_2r=o(" (RoBERTa model)"),b2r=l(),X7=a("li"),mve=a("strong"),v2r=o("roformer"),F2r=o(" \u2014 "),jW=a("a"),T2r=o("TFRoFormerForMaskedLM"),M2r=o(" (RoFormer model)"),E2r=l(),z7=a("li"),gve=a("strong"),C2r=o("tapas"),w2r=o(" \u2014 "),DW=a("a"),A2r=o("TFTapasForMaskedLM"),y2r=o(" (TAPAS model)"),L2r=l(),Q7=a("li"),hve=a("strong"),x2r=o("xlm"),$2r=o(" \u2014 "),GW=a("a"),k2r=o("TFXLMWithLMHeadModel"),S2r=o(" (XLM model)"),R2r=l(),W7=a("li"),pve=a("strong"),P2r=o("xlm-roberta"),B2r=o(" \u2014 "),OW=a("a"),I2r=o("TFXLMRobertaForMaskedLM"),q2r=o(" (XLM-RoBERTa model)"),N2r=l(),F(H7.$$.fragment),aNe=l(),dc=a("h2"),U7=a("a"),uve=a("span"),F(yL.$$.fragment),j2r=l(),_ve=a("span"),D2r=o("TFAutoModelForSeq2SeqLM"),nNe=l(),ar=a("div"),F(LL.$$.fragment),G2r=l(),cc=a("p"),O2r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),VW=a("a"),V2r=o("from_pretrained()"),X2r=o(" class method or the "),XW=a("a"),z2r=o("from_config()"),Q2r=o(` class
method.`),W2r=l(),xL=a("p"),H2r=o("This class cannot be instantiated directly using "),bve=a("code"),U2r=o("__init__()"),J2r=o(" (throws an error)."),Y2r=l(),Rt=a("div"),F($L.$$.fragment),K2r=l(),vve=a("p"),Z2r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),e1r=l(),fc=a("p"),o1r=o(`Note:
Loading a model from its configuration file does `),Fve=a("strong"),r1r=o("not"),t1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zW=a("a"),a1r=o("from_pretrained()"),n1r=o(" to load the model weights."),s1r=l(),F(J7.$$.fragment),l1r=l(),Sr=a("div"),F(kL.$$.fragment),i1r=l(),Tve=a("p"),d1r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),c1r=l(),dn=a("p"),f1r=o("The model class to instantiate is selected based on the "),Mve=a("code"),m1r=o("model_type"),g1r=o(` property of the config object (either
passed as an argument or loaded from `),Eve=a("code"),h1r=o("pretrained_model_name_or_path"),p1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cve=a("code"),u1r=o("pretrained_model_name_or_path"),_1r=o(":"),b1r=l(),ye=a("ul"),Y7=a("li"),wve=a("strong"),v1r=o("bart"),F1r=o(" \u2014 "),QW=a("a"),T1r=o("TFBartForConditionalGeneration"),M1r=o(" (BART model)"),E1r=l(),K7=a("li"),Ave=a("strong"),C1r=o("blenderbot"),w1r=o(" \u2014 "),WW=a("a"),A1r=o("TFBlenderbotForConditionalGeneration"),y1r=o(" (Blenderbot model)"),L1r=l(),Z7=a("li"),yve=a("strong"),x1r=o("blenderbot-small"),$1r=o(" \u2014 "),HW=a("a"),k1r=o("TFBlenderbotSmallForConditionalGeneration"),S1r=o(" (BlenderbotSmall model)"),R1r=l(),eM=a("li"),Lve=a("strong"),P1r=o("encoder-decoder"),B1r=o(" \u2014 "),UW=a("a"),I1r=o("TFEncoderDecoderModel"),q1r=o(" (Encoder decoder model)"),N1r=l(),oM=a("li"),xve=a("strong"),j1r=o("led"),D1r=o(" \u2014 "),JW=a("a"),G1r=o("TFLEDForConditionalGeneration"),O1r=o(" (LED model)"),V1r=l(),rM=a("li"),$ve=a("strong"),X1r=o("marian"),z1r=o(" \u2014 "),YW=a("a"),Q1r=o("TFMarianMTModel"),W1r=o(" (Marian model)"),H1r=l(),tM=a("li"),kve=a("strong"),U1r=o("mbart"),J1r=o(" \u2014 "),KW=a("a"),Y1r=o("TFMBartForConditionalGeneration"),K1r=o(" (mBART model)"),Z1r=l(),aM=a("li"),Sve=a("strong"),ebr=o("mt5"),obr=o(" \u2014 "),ZW=a("a"),rbr=o("TFMT5ForConditionalGeneration"),tbr=o(" (mT5 model)"),abr=l(),nM=a("li"),Rve=a("strong"),nbr=o("pegasus"),sbr=o(" \u2014 "),eH=a("a"),lbr=o("TFPegasusForConditionalGeneration"),ibr=o(" (Pegasus model)"),dbr=l(),sM=a("li"),Pve=a("strong"),cbr=o("t5"),fbr=o(" \u2014 "),oH=a("a"),mbr=o("TFT5ForConditionalGeneration"),gbr=o(" (T5 model)"),hbr=l(),F(lM.$$.fragment),sNe=l(),mc=a("h2"),iM=a("a"),Bve=a("span"),F(SL.$$.fragment),pbr=l(),Ive=a("span"),ubr=o("TFAutoModelForSequenceClassification"),lNe=l(),nr=a("div"),F(RL.$$.fragment),_br=l(),gc=a("p"),bbr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),rH=a("a"),vbr=o("from_pretrained()"),Fbr=o(" class method or the "),tH=a("a"),Tbr=o("from_config()"),Mbr=o(` class
method.`),Ebr=l(),PL=a("p"),Cbr=o("This class cannot be instantiated directly using "),qve=a("code"),wbr=o("__init__()"),Abr=o(" (throws an error)."),ybr=l(),Pt=a("div"),F(BL.$$.fragment),Lbr=l(),Nve=a("p"),xbr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),$br=l(),hc=a("p"),kbr=o(`Note:
Loading a model from its configuration file does `),jve=a("strong"),Sbr=o("not"),Rbr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aH=a("a"),Pbr=o("from_pretrained()"),Bbr=o(" to load the model weights."),Ibr=l(),F(dM.$$.fragment),qbr=l(),Rr=a("div"),F(IL.$$.fragment),Nbr=l(),Dve=a("p"),jbr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Dbr=l(),cn=a("p"),Gbr=o("The model class to instantiate is selected based on the "),Gve=a("code"),Obr=o("model_type"),Vbr=o(` property of the config object (either
passed as an argument or loaded from `),Ove=a("code"),Xbr=o("pretrained_model_name_or_path"),zbr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vve=a("code"),Qbr=o("pretrained_model_name_or_path"),Wbr=o(":"),Hbr=l(),oe=a("ul"),cM=a("li"),Xve=a("strong"),Ubr=o("albert"),Jbr=o(" \u2014 "),nH=a("a"),Ybr=o("TFAlbertForSequenceClassification"),Kbr=o(" (ALBERT model)"),Zbr=l(),fM=a("li"),zve=a("strong"),evr=o("bert"),ovr=o(" \u2014 "),sH=a("a"),rvr=o("TFBertForSequenceClassification"),tvr=o(" (BERT model)"),avr=l(),mM=a("li"),Qve=a("strong"),nvr=o("camembert"),svr=o(" \u2014 "),lH=a("a"),lvr=o("TFCamembertForSequenceClassification"),ivr=o(" (CamemBERT model)"),dvr=l(),gM=a("li"),Wve=a("strong"),cvr=o("convbert"),fvr=o(" \u2014 "),iH=a("a"),mvr=o("TFConvBertForSequenceClassification"),gvr=o(" (ConvBERT model)"),hvr=l(),hM=a("li"),Hve=a("strong"),pvr=o("ctrl"),uvr=o(" \u2014 "),dH=a("a"),_vr=o("TFCTRLForSequenceClassification"),bvr=o(" (CTRL model)"),vvr=l(),pM=a("li"),Uve=a("strong"),Fvr=o("deberta"),Tvr=o(" \u2014 "),cH=a("a"),Mvr=o("TFDebertaForSequenceClassification"),Evr=o(" (DeBERTa model)"),Cvr=l(),uM=a("li"),Jve=a("strong"),wvr=o("deberta-v2"),Avr=o(" \u2014 "),fH=a("a"),yvr=o("TFDebertaV2ForSequenceClassification"),Lvr=o(" (DeBERTa-v2 model)"),xvr=l(),_M=a("li"),Yve=a("strong"),$vr=o("distilbert"),kvr=o(" \u2014 "),mH=a("a"),Svr=o("TFDistilBertForSequenceClassification"),Rvr=o(" (DistilBERT model)"),Pvr=l(),bM=a("li"),Kve=a("strong"),Bvr=o("electra"),Ivr=o(" \u2014 "),gH=a("a"),qvr=o("TFElectraForSequenceClassification"),Nvr=o(" (ELECTRA model)"),jvr=l(),vM=a("li"),Zve=a("strong"),Dvr=o("flaubert"),Gvr=o(" \u2014 "),hH=a("a"),Ovr=o("TFFlaubertForSequenceClassification"),Vvr=o(" (FlauBERT model)"),Xvr=l(),FM=a("li"),eFe=a("strong"),zvr=o("funnel"),Qvr=o(" \u2014 "),pH=a("a"),Wvr=o("TFFunnelForSequenceClassification"),Hvr=o(" (Funnel Transformer model)"),Uvr=l(),TM=a("li"),oFe=a("strong"),Jvr=o("gpt2"),Yvr=o(" \u2014 "),uH=a("a"),Kvr=o("TFGPT2ForSequenceClassification"),Zvr=o(" (OpenAI GPT-2 model)"),eFr=l(),MM=a("li"),rFe=a("strong"),oFr=o("gptj"),rFr=o(" \u2014 "),_H=a("a"),tFr=o("TFGPTJForSequenceClassification"),aFr=o(" (GPT-J model)"),nFr=l(),EM=a("li"),tFe=a("strong"),sFr=o("layoutlm"),lFr=o(" \u2014 "),bH=a("a"),iFr=o("TFLayoutLMForSequenceClassification"),dFr=o(" (LayoutLM model)"),cFr=l(),CM=a("li"),aFe=a("strong"),fFr=o("longformer"),mFr=o(" \u2014 "),vH=a("a"),gFr=o("TFLongformerForSequenceClassification"),hFr=o(" (Longformer model)"),pFr=l(),wM=a("li"),nFe=a("strong"),uFr=o("mobilebert"),_Fr=o(" \u2014 "),FH=a("a"),bFr=o("TFMobileBertForSequenceClassification"),vFr=o(" (MobileBERT model)"),FFr=l(),AM=a("li"),sFe=a("strong"),TFr=o("mpnet"),MFr=o(" \u2014 "),TH=a("a"),EFr=o("TFMPNetForSequenceClassification"),CFr=o(" (MPNet model)"),wFr=l(),yM=a("li"),lFe=a("strong"),AFr=o("openai-gpt"),yFr=o(" \u2014 "),MH=a("a"),LFr=o("TFOpenAIGPTForSequenceClassification"),xFr=o(" (OpenAI GPT model)"),$Fr=l(),LM=a("li"),iFe=a("strong"),kFr=o("rembert"),SFr=o(" \u2014 "),EH=a("a"),RFr=o("TFRemBertForSequenceClassification"),PFr=o(" (RemBERT model)"),BFr=l(),xM=a("li"),dFe=a("strong"),IFr=o("roberta"),qFr=o(" \u2014 "),CH=a("a"),NFr=o("TFRobertaForSequenceClassification"),jFr=o(" (RoBERTa model)"),DFr=l(),$M=a("li"),cFe=a("strong"),GFr=o("roformer"),OFr=o(" \u2014 "),wH=a("a"),VFr=o("TFRoFormerForSequenceClassification"),XFr=o(" (RoFormer model)"),zFr=l(),kM=a("li"),fFe=a("strong"),QFr=o("tapas"),WFr=o(" \u2014 "),AH=a("a"),HFr=o("TFTapasForSequenceClassification"),UFr=o(" (TAPAS model)"),JFr=l(),SM=a("li"),mFe=a("strong"),YFr=o("transfo-xl"),KFr=o(" \u2014 "),yH=a("a"),ZFr=o("TFTransfoXLForSequenceClassification"),e6r=o(" (Transformer-XL model)"),o6r=l(),RM=a("li"),gFe=a("strong"),r6r=o("xlm"),t6r=o(" \u2014 "),LH=a("a"),a6r=o("TFXLMForSequenceClassification"),n6r=o(" (XLM model)"),s6r=l(),PM=a("li"),hFe=a("strong"),l6r=o("xlm-roberta"),i6r=o(" \u2014 "),xH=a("a"),d6r=o("TFXLMRobertaForSequenceClassification"),c6r=o(" (XLM-RoBERTa model)"),f6r=l(),BM=a("li"),pFe=a("strong"),m6r=o("xlnet"),g6r=o(" \u2014 "),$H=a("a"),h6r=o("TFXLNetForSequenceClassification"),p6r=o(" (XLNet model)"),u6r=l(),F(IM.$$.fragment),iNe=l(),pc=a("h2"),qM=a("a"),uFe=a("span"),F(qL.$$.fragment),_6r=l(),_Fe=a("span"),b6r=o("TFAutoModelForMultipleChoice"),dNe=l(),sr=a("div"),F(NL.$$.fragment),v6r=l(),uc=a("p"),F6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),kH=a("a"),T6r=o("from_pretrained()"),M6r=o(" class method or the "),SH=a("a"),E6r=o("from_config()"),C6r=o(` class
method.`),w6r=l(),jL=a("p"),A6r=o("This class cannot be instantiated directly using "),bFe=a("code"),y6r=o("__init__()"),L6r=o(" (throws an error)."),x6r=l(),Bt=a("div"),F(DL.$$.fragment),$6r=l(),vFe=a("p"),k6r=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),S6r=l(),_c=a("p"),R6r=o(`Note:
Loading a model from its configuration file does `),FFe=a("strong"),P6r=o("not"),B6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RH=a("a"),I6r=o("from_pretrained()"),q6r=o(" to load the model weights."),N6r=l(),F(NM.$$.fragment),j6r=l(),Pr=a("div"),F(GL.$$.fragment),D6r=l(),TFe=a("p"),G6r=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),O6r=l(),fn=a("p"),V6r=o("The model class to instantiate is selected based on the "),MFe=a("code"),X6r=o("model_type"),z6r=o(` property of the config object (either
passed as an argument or loaded from `),EFe=a("code"),Q6r=o("pretrained_model_name_or_path"),W6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CFe=a("code"),H6r=o("pretrained_model_name_or_path"),U6r=o(":"),J6r=l(),pe=a("ul"),jM=a("li"),wFe=a("strong"),Y6r=o("albert"),K6r=o(" \u2014 "),PH=a("a"),Z6r=o("TFAlbertForMultipleChoice"),eTr=o(" (ALBERT model)"),oTr=l(),DM=a("li"),AFe=a("strong"),rTr=o("bert"),tTr=o(" \u2014 "),BH=a("a"),aTr=o("TFBertForMultipleChoice"),nTr=o(" (BERT model)"),sTr=l(),GM=a("li"),yFe=a("strong"),lTr=o("camembert"),iTr=o(" \u2014 "),IH=a("a"),dTr=o("TFCamembertForMultipleChoice"),cTr=o(" (CamemBERT model)"),fTr=l(),OM=a("li"),LFe=a("strong"),mTr=o("convbert"),gTr=o(" \u2014 "),qH=a("a"),hTr=o("TFConvBertForMultipleChoice"),pTr=o(" (ConvBERT model)"),uTr=l(),VM=a("li"),xFe=a("strong"),_Tr=o("distilbert"),bTr=o(" \u2014 "),NH=a("a"),vTr=o("TFDistilBertForMultipleChoice"),FTr=o(" (DistilBERT model)"),TTr=l(),XM=a("li"),$Fe=a("strong"),MTr=o("electra"),ETr=o(" \u2014 "),jH=a("a"),CTr=o("TFElectraForMultipleChoice"),wTr=o(" (ELECTRA model)"),ATr=l(),zM=a("li"),kFe=a("strong"),yTr=o("flaubert"),LTr=o(" \u2014 "),DH=a("a"),xTr=o("TFFlaubertForMultipleChoice"),$Tr=o(" (FlauBERT model)"),kTr=l(),QM=a("li"),SFe=a("strong"),STr=o("funnel"),RTr=o(" \u2014 "),GH=a("a"),PTr=o("TFFunnelForMultipleChoice"),BTr=o(" (Funnel Transformer model)"),ITr=l(),WM=a("li"),RFe=a("strong"),qTr=o("longformer"),NTr=o(" \u2014 "),OH=a("a"),jTr=o("TFLongformerForMultipleChoice"),DTr=o(" (Longformer model)"),GTr=l(),HM=a("li"),PFe=a("strong"),OTr=o("mobilebert"),VTr=o(" \u2014 "),VH=a("a"),XTr=o("TFMobileBertForMultipleChoice"),zTr=o(" (MobileBERT model)"),QTr=l(),UM=a("li"),BFe=a("strong"),WTr=o("mpnet"),HTr=o(" \u2014 "),XH=a("a"),UTr=o("TFMPNetForMultipleChoice"),JTr=o(" (MPNet model)"),YTr=l(),JM=a("li"),IFe=a("strong"),KTr=o("rembert"),ZTr=o(" \u2014 "),zH=a("a"),e8r=o("TFRemBertForMultipleChoice"),o8r=o(" (RemBERT model)"),r8r=l(),YM=a("li"),qFe=a("strong"),t8r=o("roberta"),a8r=o(" \u2014 "),QH=a("a"),n8r=o("TFRobertaForMultipleChoice"),s8r=o(" (RoBERTa model)"),l8r=l(),KM=a("li"),NFe=a("strong"),i8r=o("roformer"),d8r=o(" \u2014 "),WH=a("a"),c8r=o("TFRoFormerForMultipleChoice"),f8r=o(" (RoFormer model)"),m8r=l(),ZM=a("li"),jFe=a("strong"),g8r=o("xlm"),h8r=o(" \u2014 "),HH=a("a"),p8r=o("TFXLMForMultipleChoice"),u8r=o(" (XLM model)"),_8r=l(),e4=a("li"),DFe=a("strong"),b8r=o("xlm-roberta"),v8r=o(" \u2014 "),UH=a("a"),F8r=o("TFXLMRobertaForMultipleChoice"),T8r=o(" (XLM-RoBERTa model)"),M8r=l(),o4=a("li"),GFe=a("strong"),E8r=o("xlnet"),C8r=o(" \u2014 "),JH=a("a"),w8r=o("TFXLNetForMultipleChoice"),A8r=o(" (XLNet model)"),y8r=l(),F(r4.$$.fragment),cNe=l(),bc=a("h2"),t4=a("a"),OFe=a("span"),F(OL.$$.fragment),L8r=l(),VFe=a("span"),x8r=o("TFAutoModelForNextSentencePrediction"),fNe=l(),lr=a("div"),F(VL.$$.fragment),$8r=l(),vc=a("p"),k8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),YH=a("a"),S8r=o("from_pretrained()"),R8r=o(" class method or the "),KH=a("a"),P8r=o("from_config()"),B8r=o(` class
method.`),I8r=l(),XL=a("p"),q8r=o("This class cannot be instantiated directly using "),XFe=a("code"),N8r=o("__init__()"),j8r=o(" (throws an error)."),D8r=l(),It=a("div"),F(zL.$$.fragment),G8r=l(),zFe=a("p"),O8r=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),V8r=l(),Fc=a("p"),X8r=o(`Note:
Loading a model from its configuration file does `),QFe=a("strong"),z8r=o("not"),Q8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZH=a("a"),W8r=o("from_pretrained()"),H8r=o(" to load the model weights."),U8r=l(),F(a4.$$.fragment),J8r=l(),Br=a("div"),F(QL.$$.fragment),Y8r=l(),WFe=a("p"),K8r=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Z8r=l(),mn=a("p"),e7r=o("The model class to instantiate is selected based on the "),HFe=a("code"),o7r=o("model_type"),r7r=o(` property of the config object (either
passed as an argument or loaded from `),UFe=a("code"),t7r=o("pretrained_model_name_or_path"),a7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JFe=a("code"),n7r=o("pretrained_model_name_or_path"),s7r=o(":"),l7r=l(),WL=a("ul"),n4=a("li"),YFe=a("strong"),i7r=o("bert"),d7r=o(" \u2014 "),eU=a("a"),c7r=o("TFBertForNextSentencePrediction"),f7r=o(" (BERT model)"),m7r=l(),s4=a("li"),KFe=a("strong"),g7r=o("mobilebert"),h7r=o(" \u2014 "),oU=a("a"),p7r=o("TFMobileBertForNextSentencePrediction"),u7r=o(" (MobileBERT model)"),_7r=l(),F(l4.$$.fragment),mNe=l(),Tc=a("h2"),i4=a("a"),ZFe=a("span"),F(HL.$$.fragment),b7r=l(),e6e=a("span"),v7r=o("TFAutoModelForTableQuestionAnswering"),gNe=l(),ir=a("div"),F(UL.$$.fragment),F7r=l(),Mc=a("p"),T7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),rU=a("a"),M7r=o("from_pretrained()"),E7r=o(" class method or the "),tU=a("a"),C7r=o("from_config()"),w7r=o(` class
method.`),A7r=l(),JL=a("p"),y7r=o("This class cannot be instantiated directly using "),o6e=a("code"),L7r=o("__init__()"),x7r=o(" (throws an error)."),$7r=l(),qt=a("div"),F(YL.$$.fragment),k7r=l(),r6e=a("p"),S7r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),R7r=l(),Ec=a("p"),P7r=o(`Note:
Loading a model from its configuration file does `),t6e=a("strong"),B7r=o("not"),I7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aU=a("a"),q7r=o("from_pretrained()"),N7r=o(" to load the model weights."),j7r=l(),F(d4.$$.fragment),D7r=l(),Ir=a("div"),F(KL.$$.fragment),G7r=l(),a6e=a("p"),O7r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),V7r=l(),gn=a("p"),X7r=o("The model class to instantiate is selected based on the "),n6e=a("code"),z7r=o("model_type"),Q7r=o(` property of the config object (either
passed as an argument or loaded from `),s6e=a("code"),W7r=o("pretrained_model_name_or_path"),H7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l6e=a("code"),U7r=o("pretrained_model_name_or_path"),J7r=o(":"),Y7r=l(),i6e=a("ul"),c4=a("li"),d6e=a("strong"),K7r=o("tapas"),Z7r=o(" \u2014 "),nU=a("a"),eMr=o("TFTapasForQuestionAnswering"),oMr=o(" (TAPAS model)"),rMr=l(),F(f4.$$.fragment),hNe=l(),Cc=a("h2"),m4=a("a"),c6e=a("span"),F(ZL.$$.fragment),tMr=l(),f6e=a("span"),aMr=o("TFAutoModelForTokenClassification"),pNe=l(),dr=a("div"),F(ex.$$.fragment),nMr=l(),wc=a("p"),sMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),sU=a("a"),lMr=o("from_pretrained()"),iMr=o(" class method or the "),lU=a("a"),dMr=o("from_config()"),cMr=o(` class
method.`),fMr=l(),ox=a("p"),mMr=o("This class cannot be instantiated directly using "),m6e=a("code"),gMr=o("__init__()"),hMr=o(" (throws an error)."),pMr=l(),Nt=a("div"),F(rx.$$.fragment),uMr=l(),g6e=a("p"),_Mr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),bMr=l(),Ac=a("p"),vMr=o(`Note:
Loading a model from its configuration file does `),h6e=a("strong"),FMr=o("not"),TMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iU=a("a"),MMr=o("from_pretrained()"),EMr=o(" to load the model weights."),CMr=l(),F(g4.$$.fragment),wMr=l(),qr=a("div"),F(tx.$$.fragment),AMr=l(),p6e=a("p"),yMr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),LMr=l(),hn=a("p"),xMr=o("The model class to instantiate is selected based on the "),u6e=a("code"),$Mr=o("model_type"),kMr=o(` property of the config object (either
passed as an argument or loaded from `),_6e=a("code"),SMr=o("pretrained_model_name_or_path"),RMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b6e=a("code"),PMr=o("pretrained_model_name_or_path"),BMr=o(":"),IMr=l(),de=a("ul"),h4=a("li"),v6e=a("strong"),qMr=o("albert"),NMr=o(" \u2014 "),dU=a("a"),jMr=o("TFAlbertForTokenClassification"),DMr=o(" (ALBERT model)"),GMr=l(),p4=a("li"),F6e=a("strong"),OMr=o("bert"),VMr=o(" \u2014 "),cU=a("a"),XMr=o("TFBertForTokenClassification"),zMr=o(" (BERT model)"),QMr=l(),u4=a("li"),T6e=a("strong"),WMr=o("camembert"),HMr=o(" \u2014 "),fU=a("a"),UMr=o("TFCamembertForTokenClassification"),JMr=o(" (CamemBERT model)"),YMr=l(),_4=a("li"),M6e=a("strong"),KMr=o("convbert"),ZMr=o(" \u2014 "),mU=a("a"),e4r=o("TFConvBertForTokenClassification"),o4r=o(" (ConvBERT model)"),r4r=l(),b4=a("li"),E6e=a("strong"),t4r=o("deberta"),a4r=o(" \u2014 "),gU=a("a"),n4r=o("TFDebertaForTokenClassification"),s4r=o(" (DeBERTa model)"),l4r=l(),v4=a("li"),C6e=a("strong"),i4r=o("deberta-v2"),d4r=o(" \u2014 "),hU=a("a"),c4r=o("TFDebertaV2ForTokenClassification"),f4r=o(" (DeBERTa-v2 model)"),m4r=l(),F4=a("li"),w6e=a("strong"),g4r=o("distilbert"),h4r=o(" \u2014 "),pU=a("a"),p4r=o("TFDistilBertForTokenClassification"),u4r=o(" (DistilBERT model)"),_4r=l(),T4=a("li"),A6e=a("strong"),b4r=o("electra"),v4r=o(" \u2014 "),uU=a("a"),F4r=o("TFElectraForTokenClassification"),T4r=o(" (ELECTRA model)"),M4r=l(),M4=a("li"),y6e=a("strong"),E4r=o("flaubert"),C4r=o(" \u2014 "),_U=a("a"),w4r=o("TFFlaubertForTokenClassification"),A4r=o(" (FlauBERT model)"),y4r=l(),E4=a("li"),L6e=a("strong"),L4r=o("funnel"),x4r=o(" \u2014 "),bU=a("a"),$4r=o("TFFunnelForTokenClassification"),k4r=o(" (Funnel Transformer model)"),S4r=l(),C4=a("li"),x6e=a("strong"),R4r=o("layoutlm"),P4r=o(" \u2014 "),vU=a("a"),B4r=o("TFLayoutLMForTokenClassification"),I4r=o(" (LayoutLM model)"),q4r=l(),w4=a("li"),$6e=a("strong"),N4r=o("longformer"),j4r=o(" \u2014 "),FU=a("a"),D4r=o("TFLongformerForTokenClassification"),G4r=o(" (Longformer model)"),O4r=l(),A4=a("li"),k6e=a("strong"),V4r=o("mobilebert"),X4r=o(" \u2014 "),TU=a("a"),z4r=o("TFMobileBertForTokenClassification"),Q4r=o(" (MobileBERT model)"),W4r=l(),y4=a("li"),S6e=a("strong"),H4r=o("mpnet"),U4r=o(" \u2014 "),MU=a("a"),J4r=o("TFMPNetForTokenClassification"),Y4r=o(" (MPNet model)"),K4r=l(),L4=a("li"),R6e=a("strong"),Z4r=o("rembert"),eEr=o(" \u2014 "),EU=a("a"),oEr=o("TFRemBertForTokenClassification"),rEr=o(" (RemBERT model)"),tEr=l(),x4=a("li"),P6e=a("strong"),aEr=o("roberta"),nEr=o(" \u2014 "),CU=a("a"),sEr=o("TFRobertaForTokenClassification"),lEr=o(" (RoBERTa model)"),iEr=l(),$4=a("li"),B6e=a("strong"),dEr=o("roformer"),cEr=o(" \u2014 "),wU=a("a"),fEr=o("TFRoFormerForTokenClassification"),mEr=o(" (RoFormer model)"),gEr=l(),k4=a("li"),I6e=a("strong"),hEr=o("xlm"),pEr=o(" \u2014 "),AU=a("a"),uEr=o("TFXLMForTokenClassification"),_Er=o(" (XLM model)"),bEr=l(),S4=a("li"),q6e=a("strong"),vEr=o("xlm-roberta"),FEr=o(" \u2014 "),yU=a("a"),TEr=o("TFXLMRobertaForTokenClassification"),MEr=o(" (XLM-RoBERTa model)"),EEr=l(),R4=a("li"),N6e=a("strong"),CEr=o("xlnet"),wEr=o(" \u2014 "),LU=a("a"),AEr=o("TFXLNetForTokenClassification"),yEr=o(" (XLNet model)"),LEr=l(),F(P4.$$.fragment),uNe=l(),yc=a("h2"),B4=a("a"),j6e=a("span"),F(ax.$$.fragment),xEr=l(),D6e=a("span"),$Er=o("TFAutoModelForQuestionAnswering"),_Ne=l(),cr=a("div"),F(nx.$$.fragment),kEr=l(),Lc=a("p"),SEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),xU=a("a"),REr=o("from_pretrained()"),PEr=o(" class method or the "),$U=a("a"),BEr=o("from_config()"),IEr=o(` class
method.`),qEr=l(),sx=a("p"),NEr=o("This class cannot be instantiated directly using "),G6e=a("code"),jEr=o("__init__()"),DEr=o(" (throws an error)."),GEr=l(),jt=a("div"),F(lx.$$.fragment),OEr=l(),O6e=a("p"),VEr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),XEr=l(),xc=a("p"),zEr=o(`Note:
Loading a model from its configuration file does `),V6e=a("strong"),QEr=o("not"),WEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kU=a("a"),HEr=o("from_pretrained()"),UEr=o(" to load the model weights."),JEr=l(),F(I4.$$.fragment),YEr=l(),Nr=a("div"),F(ix.$$.fragment),KEr=l(),X6e=a("p"),ZEr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),e5r=l(),pn=a("p"),o5r=o("The model class to instantiate is selected based on the "),z6e=a("code"),r5r=o("model_type"),t5r=o(` property of the config object (either
passed as an argument or loaded from `),Q6e=a("code"),a5r=o("pretrained_model_name_or_path"),n5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W6e=a("code"),s5r=o("pretrained_model_name_or_path"),l5r=o(":"),i5r=l(),ce=a("ul"),q4=a("li"),H6e=a("strong"),d5r=o("albert"),c5r=o(" \u2014 "),SU=a("a"),f5r=o("TFAlbertForQuestionAnswering"),m5r=o(" (ALBERT model)"),g5r=l(),N4=a("li"),U6e=a("strong"),h5r=o("bert"),p5r=o(" \u2014 "),RU=a("a"),u5r=o("TFBertForQuestionAnswering"),_5r=o(" (BERT model)"),b5r=l(),j4=a("li"),J6e=a("strong"),v5r=o("camembert"),F5r=o(" \u2014 "),PU=a("a"),T5r=o("TFCamembertForQuestionAnswering"),M5r=o(" (CamemBERT model)"),E5r=l(),D4=a("li"),Y6e=a("strong"),C5r=o("convbert"),w5r=o(" \u2014 "),BU=a("a"),A5r=o("TFConvBertForQuestionAnswering"),y5r=o(" (ConvBERT model)"),L5r=l(),G4=a("li"),K6e=a("strong"),x5r=o("deberta"),$5r=o(" \u2014 "),IU=a("a"),k5r=o("TFDebertaForQuestionAnswering"),S5r=o(" (DeBERTa model)"),R5r=l(),O4=a("li"),Z6e=a("strong"),P5r=o("deberta-v2"),B5r=o(" \u2014 "),qU=a("a"),I5r=o("TFDebertaV2ForQuestionAnswering"),q5r=o(" (DeBERTa-v2 model)"),N5r=l(),V4=a("li"),eTe=a("strong"),j5r=o("distilbert"),D5r=o(" \u2014 "),NU=a("a"),G5r=o("TFDistilBertForQuestionAnswering"),O5r=o(" (DistilBERT model)"),V5r=l(),X4=a("li"),oTe=a("strong"),X5r=o("electra"),z5r=o(" \u2014 "),jU=a("a"),Q5r=o("TFElectraForQuestionAnswering"),W5r=o(" (ELECTRA model)"),H5r=l(),z4=a("li"),rTe=a("strong"),U5r=o("flaubert"),J5r=o(" \u2014 "),DU=a("a"),Y5r=o("TFFlaubertForQuestionAnsweringSimple"),K5r=o(" (FlauBERT model)"),Z5r=l(),Q4=a("li"),tTe=a("strong"),eCr=o("funnel"),oCr=o(" \u2014 "),GU=a("a"),rCr=o("TFFunnelForQuestionAnswering"),tCr=o(" (Funnel Transformer model)"),aCr=l(),W4=a("li"),aTe=a("strong"),nCr=o("gptj"),sCr=o(" \u2014 "),OU=a("a"),lCr=o("TFGPTJForQuestionAnswering"),iCr=o(" (GPT-J model)"),dCr=l(),H4=a("li"),nTe=a("strong"),cCr=o("longformer"),fCr=o(" \u2014 "),VU=a("a"),mCr=o("TFLongformerForQuestionAnswering"),gCr=o(" (Longformer model)"),hCr=l(),U4=a("li"),sTe=a("strong"),pCr=o("mobilebert"),uCr=o(" \u2014 "),XU=a("a"),_Cr=o("TFMobileBertForQuestionAnswering"),bCr=o(" (MobileBERT model)"),vCr=l(),J4=a("li"),lTe=a("strong"),FCr=o("mpnet"),TCr=o(" \u2014 "),zU=a("a"),MCr=o("TFMPNetForQuestionAnswering"),ECr=o(" (MPNet model)"),CCr=l(),Y4=a("li"),iTe=a("strong"),wCr=o("rembert"),ACr=o(" \u2014 "),QU=a("a"),yCr=o("TFRemBertForQuestionAnswering"),LCr=o(" (RemBERT model)"),xCr=l(),K4=a("li"),dTe=a("strong"),$Cr=o("roberta"),kCr=o(" \u2014 "),WU=a("a"),SCr=o("TFRobertaForQuestionAnswering"),RCr=o(" (RoBERTa model)"),PCr=l(),Z4=a("li"),cTe=a("strong"),BCr=o("roformer"),ICr=o(" \u2014 "),HU=a("a"),qCr=o("TFRoFormerForQuestionAnswering"),NCr=o(" (RoFormer model)"),jCr=l(),eE=a("li"),fTe=a("strong"),DCr=o("xlm"),GCr=o(" \u2014 "),UU=a("a"),OCr=o("TFXLMForQuestionAnsweringSimple"),VCr=o(" (XLM model)"),XCr=l(),oE=a("li"),mTe=a("strong"),zCr=o("xlm-roberta"),QCr=o(" \u2014 "),JU=a("a"),WCr=o("TFXLMRobertaForQuestionAnswering"),HCr=o(" (XLM-RoBERTa model)"),UCr=l(),rE=a("li"),gTe=a("strong"),JCr=o("xlnet"),YCr=o(" \u2014 "),YU=a("a"),KCr=o("TFXLNetForQuestionAnsweringSimple"),ZCr=o(" (XLNet model)"),e3r=l(),F(tE.$$.fragment),bNe=l(),$c=a("h2"),aE=a("a"),hTe=a("span"),F(dx.$$.fragment),o3r=l(),pTe=a("span"),r3r=o("TFAutoModelForVision2Seq"),vNe=l(),fr=a("div"),F(cx.$$.fragment),t3r=l(),kc=a("p"),a3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),KU=a("a"),n3r=o("from_pretrained()"),s3r=o(" class method or the "),ZU=a("a"),l3r=o("from_config()"),i3r=o(` class
method.`),d3r=l(),fx=a("p"),c3r=o("This class cannot be instantiated directly using "),uTe=a("code"),f3r=o("__init__()"),m3r=o(" (throws an error)."),g3r=l(),Dt=a("div"),F(mx.$$.fragment),h3r=l(),_Te=a("p"),p3r=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),u3r=l(),Sc=a("p"),_3r=o(`Note:
Loading a model from its configuration file does `),bTe=a("strong"),b3r=o("not"),v3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eJ=a("a"),F3r=o("from_pretrained()"),T3r=o(" to load the model weights."),M3r=l(),F(nE.$$.fragment),E3r=l(),jr=a("div"),F(gx.$$.fragment),C3r=l(),vTe=a("p"),w3r=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),A3r=l(),un=a("p"),y3r=o("The model class to instantiate is selected based on the "),FTe=a("code"),L3r=o("model_type"),x3r=o(` property of the config object (either
passed as an argument or loaded from `),TTe=a("code"),$3r=o("pretrained_model_name_or_path"),k3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MTe=a("code"),S3r=o("pretrained_model_name_or_path"),R3r=o(":"),P3r=l(),ETe=a("ul"),sE=a("li"),CTe=a("strong"),B3r=o("vision-encoder-decoder"),I3r=o(" \u2014 "),oJ=a("a"),q3r=o("TFVisionEncoderDecoderModel"),N3r=o(" (Vision Encoder decoder model)"),j3r=l(),F(lE.$$.fragment),FNe=l(),Rc=a("h2"),iE=a("a"),wTe=a("span"),F(hx.$$.fragment),D3r=l(),ATe=a("span"),G3r=o("TFAutoModelForSpeechSeq2Seq"),TNe=l(),mr=a("div"),F(px.$$.fragment),O3r=l(),Pc=a("p"),V3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),rJ=a("a"),X3r=o("from_pretrained()"),z3r=o(" class method or the "),tJ=a("a"),Q3r=o("from_config()"),W3r=o(` class
method.`),H3r=l(),ux=a("p"),U3r=o("This class cannot be instantiated directly using "),yTe=a("code"),J3r=o("__init__()"),Y3r=o(" (throws an error)."),K3r=l(),Gt=a("div"),F(_x.$$.fragment),Z3r=l(),LTe=a("p"),ewr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),owr=l(),Bc=a("p"),rwr=o(`Note:
Loading a model from its configuration file does `),xTe=a("strong"),twr=o("not"),awr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aJ=a("a"),nwr=o("from_pretrained()"),swr=o(" to load the model weights."),lwr=l(),F(dE.$$.fragment),iwr=l(),Dr=a("div"),F(bx.$$.fragment),dwr=l(),$Te=a("p"),cwr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),fwr=l(),_n=a("p"),mwr=o("The model class to instantiate is selected based on the "),kTe=a("code"),gwr=o("model_type"),hwr=o(` property of the config object (either
passed as an argument or loaded from `),STe=a("code"),pwr=o("pretrained_model_name_or_path"),uwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RTe=a("code"),_wr=o("pretrained_model_name_or_path"),bwr=o(":"),vwr=l(),PTe=a("ul"),cE=a("li"),BTe=a("strong"),Fwr=o("speech_to_text"),Twr=o(" \u2014 "),nJ=a("a"),Mwr=o("TFSpeech2TextForConditionalGeneration"),Ewr=o(" (Speech2Text model)"),Cwr=l(),F(fE.$$.fragment),MNe=l(),Ic=a("h2"),mE=a("a"),ITe=a("span"),F(vx.$$.fragment),wwr=l(),qTe=a("span"),Awr=o("FlaxAutoModel"),ENe=l(),gr=a("div"),F(Fx.$$.fragment),ywr=l(),qc=a("p"),Lwr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),sJ=a("a"),xwr=o("from_pretrained()"),$wr=o(" class method or the "),lJ=a("a"),kwr=o("from_config()"),Swr=o(` class
method.`),Rwr=l(),Tx=a("p"),Pwr=o("This class cannot be instantiated directly using "),NTe=a("code"),Bwr=o("__init__()"),Iwr=o(" (throws an error)."),qwr=l(),Ot=a("div"),F(Mx.$$.fragment),Nwr=l(),jTe=a("p"),jwr=o("Instantiates one of the base model classes of the library from a configuration."),Dwr=l(),Nc=a("p"),Gwr=o(`Note:
Loading a model from its configuration file does `),DTe=a("strong"),Owr=o("not"),Vwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iJ=a("a"),Xwr=o("from_pretrained()"),zwr=o(" to load the model weights."),Qwr=l(),F(gE.$$.fragment),Wwr=l(),Gr=a("div"),F(Ex.$$.fragment),Hwr=l(),GTe=a("p"),Uwr=o("Instantiate one of the base model classes of the library from a pretrained model."),Jwr=l(),bn=a("p"),Ywr=o("The model class to instantiate is selected based on the "),OTe=a("code"),Kwr=o("model_type"),Zwr=o(` property of the config object (either
passed as an argument or loaded from `),VTe=a("code"),eAr=o("pretrained_model_name_or_path"),oAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),XTe=a("code"),rAr=o("pretrained_model_name_or_path"),tAr=o(":"),aAr=l(),re=a("ul"),hE=a("li"),zTe=a("strong"),nAr=o("albert"),sAr=o(" \u2014 "),dJ=a("a"),lAr=o("FlaxAlbertModel"),iAr=o(" (ALBERT model)"),dAr=l(),pE=a("li"),QTe=a("strong"),cAr=o("bart"),fAr=o(" \u2014 "),cJ=a("a"),mAr=o("FlaxBartModel"),gAr=o(" (BART model)"),hAr=l(),uE=a("li"),WTe=a("strong"),pAr=o("beit"),uAr=o(" \u2014 "),fJ=a("a"),_Ar=o("FlaxBeitModel"),bAr=o(" (BEiT model)"),vAr=l(),_E=a("li"),HTe=a("strong"),FAr=o("bert"),TAr=o(" \u2014 "),mJ=a("a"),MAr=o("FlaxBertModel"),EAr=o(" (BERT model)"),CAr=l(),bE=a("li"),UTe=a("strong"),wAr=o("big_bird"),AAr=o(" \u2014 "),gJ=a("a"),yAr=o("FlaxBigBirdModel"),LAr=o(" (BigBird model)"),xAr=l(),vE=a("li"),JTe=a("strong"),$Ar=o("blenderbot"),kAr=o(" \u2014 "),hJ=a("a"),SAr=o("FlaxBlenderbotModel"),RAr=o(" (Blenderbot model)"),PAr=l(),FE=a("li"),YTe=a("strong"),BAr=o("blenderbot-small"),IAr=o(" \u2014 "),pJ=a("a"),qAr=o("FlaxBlenderbotSmallModel"),NAr=o(" (BlenderbotSmall model)"),jAr=l(),TE=a("li"),KTe=a("strong"),DAr=o("clip"),GAr=o(" \u2014 "),uJ=a("a"),OAr=o("FlaxCLIPModel"),VAr=o(" (CLIP model)"),XAr=l(),ME=a("li"),ZTe=a("strong"),zAr=o("distilbert"),QAr=o(" \u2014 "),_J=a("a"),WAr=o("FlaxDistilBertModel"),HAr=o(" (DistilBERT model)"),UAr=l(),EE=a("li"),e8e=a("strong"),JAr=o("electra"),YAr=o(" \u2014 "),bJ=a("a"),KAr=o("FlaxElectraModel"),ZAr=o(" (ELECTRA model)"),e0r=l(),CE=a("li"),o8e=a("strong"),o0r=o("gpt2"),r0r=o(" \u2014 "),vJ=a("a"),t0r=o("FlaxGPT2Model"),a0r=o(" (OpenAI GPT-2 model)"),n0r=l(),wE=a("li"),r8e=a("strong"),s0r=o("gpt_neo"),l0r=o(" \u2014 "),FJ=a("a"),i0r=o("FlaxGPTNeoModel"),d0r=o(" (GPT Neo model)"),c0r=l(),AE=a("li"),t8e=a("strong"),f0r=o("gptj"),m0r=o(" \u2014 "),TJ=a("a"),g0r=o("FlaxGPTJModel"),h0r=o(" (GPT-J model)"),p0r=l(),yE=a("li"),a8e=a("strong"),u0r=o("marian"),_0r=o(" \u2014 "),MJ=a("a"),b0r=o("FlaxMarianModel"),v0r=o(" (Marian model)"),F0r=l(),LE=a("li"),n8e=a("strong"),T0r=o("mbart"),M0r=o(" \u2014 "),EJ=a("a"),E0r=o("FlaxMBartModel"),C0r=o(" (mBART model)"),w0r=l(),xE=a("li"),s8e=a("strong"),A0r=o("mt5"),y0r=o(" \u2014 "),CJ=a("a"),L0r=o("FlaxMT5Model"),x0r=o(" (mT5 model)"),$0r=l(),$E=a("li"),l8e=a("strong"),k0r=o("pegasus"),S0r=o(" \u2014 "),wJ=a("a"),R0r=o("FlaxPegasusModel"),P0r=o(" (Pegasus model)"),B0r=l(),kE=a("li"),i8e=a("strong"),I0r=o("roberta"),q0r=o(" \u2014 "),AJ=a("a"),N0r=o("FlaxRobertaModel"),j0r=o(" (RoBERTa model)"),D0r=l(),SE=a("li"),d8e=a("strong"),G0r=o("roformer"),O0r=o(" \u2014 "),yJ=a("a"),V0r=o("FlaxRoFormerModel"),X0r=o(" (RoFormer model)"),z0r=l(),RE=a("li"),c8e=a("strong"),Q0r=o("t5"),W0r=o(" \u2014 "),LJ=a("a"),H0r=o("FlaxT5Model"),U0r=o(" (T5 model)"),J0r=l(),PE=a("li"),f8e=a("strong"),Y0r=o("vision-text-dual-encoder"),K0r=o(" \u2014 "),xJ=a("a"),Z0r=o("FlaxVisionTextDualEncoderModel"),eyr=o(" (VisionTextDualEncoder model)"),oyr=l(),BE=a("li"),m8e=a("strong"),ryr=o("vit"),tyr=o(" \u2014 "),$J=a("a"),ayr=o("FlaxViTModel"),nyr=o(" (ViT model)"),syr=l(),IE=a("li"),g8e=a("strong"),lyr=o("wav2vec2"),iyr=o(" \u2014 "),kJ=a("a"),dyr=o("FlaxWav2Vec2Model"),cyr=o(" (Wav2Vec2 model)"),fyr=l(),qE=a("li"),h8e=a("strong"),myr=o("xglm"),gyr=o(" \u2014 "),SJ=a("a"),hyr=o("FlaxXGLMModel"),pyr=o(" (XGLM model)"),uyr=l(),NE=a("li"),p8e=a("strong"),_yr=o("xlm-roberta"),byr=o(" \u2014 "),RJ=a("a"),vyr=o("FlaxXLMRobertaModel"),Fyr=o(" (XLM-RoBERTa model)"),Tyr=l(),F(jE.$$.fragment),CNe=l(),jc=a("h2"),DE=a("a"),u8e=a("span"),F(Cx.$$.fragment),Myr=l(),_8e=a("span"),Eyr=o("FlaxAutoModelForCausalLM"),wNe=l(),hr=a("div"),F(wx.$$.fragment),Cyr=l(),Dc=a("p"),wyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),PJ=a("a"),Ayr=o("from_pretrained()"),yyr=o(" class method or the "),BJ=a("a"),Lyr=o("from_config()"),xyr=o(` class
method.`),$yr=l(),Ax=a("p"),kyr=o("This class cannot be instantiated directly using "),b8e=a("code"),Syr=o("__init__()"),Ryr=o(" (throws an error)."),Pyr=l(),Vt=a("div"),F(yx.$$.fragment),Byr=l(),v8e=a("p"),Iyr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),qyr=l(),Gc=a("p"),Nyr=o(`Note:
Loading a model from its configuration file does `),F8e=a("strong"),jyr=o("not"),Dyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IJ=a("a"),Gyr=o("from_pretrained()"),Oyr=o(" to load the model weights."),Vyr=l(),F(GE.$$.fragment),Xyr=l(),Or=a("div"),F(Lx.$$.fragment),zyr=l(),T8e=a("p"),Qyr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Wyr=l(),vn=a("p"),Hyr=o("The model class to instantiate is selected based on the "),M8e=a("code"),Uyr=o("model_type"),Jyr=o(` property of the config object (either
passed as an argument or loaded from `),E8e=a("code"),Yyr=o("pretrained_model_name_or_path"),Kyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C8e=a("code"),Zyr=o("pretrained_model_name_or_path"),eLr=o(":"),oLr=l(),ke=a("ul"),OE=a("li"),w8e=a("strong"),rLr=o("bart"),tLr=o(" \u2014 "),qJ=a("a"),aLr=o("FlaxBartForCausalLM"),nLr=o(" (BART model)"),sLr=l(),VE=a("li"),A8e=a("strong"),lLr=o("bert"),iLr=o(" \u2014 "),NJ=a("a"),dLr=o("FlaxBertForCausalLM"),cLr=o(" (BERT model)"),fLr=l(),XE=a("li"),y8e=a("strong"),mLr=o("big_bird"),gLr=o(" \u2014 "),jJ=a("a"),hLr=o("FlaxBigBirdForCausalLM"),pLr=o(" (BigBird model)"),uLr=l(),zE=a("li"),L8e=a("strong"),_Lr=o("electra"),bLr=o(" \u2014 "),DJ=a("a"),vLr=o("FlaxElectraForCausalLM"),FLr=o(" (ELECTRA model)"),TLr=l(),QE=a("li"),x8e=a("strong"),MLr=o("gpt2"),ELr=o(" \u2014 "),GJ=a("a"),CLr=o("FlaxGPT2LMHeadModel"),wLr=o(" (OpenAI GPT-2 model)"),ALr=l(),WE=a("li"),$8e=a("strong"),yLr=o("gpt_neo"),LLr=o(" \u2014 "),OJ=a("a"),xLr=o("FlaxGPTNeoForCausalLM"),$Lr=o(" (GPT Neo model)"),kLr=l(),HE=a("li"),k8e=a("strong"),SLr=o("gptj"),RLr=o(" \u2014 "),VJ=a("a"),PLr=o("FlaxGPTJForCausalLM"),BLr=o(" (GPT-J model)"),ILr=l(),UE=a("li"),S8e=a("strong"),qLr=o("roberta"),NLr=o(" \u2014 "),XJ=a("a"),jLr=o("FlaxRobertaForCausalLM"),DLr=o(" (RoBERTa model)"),GLr=l(),JE=a("li"),R8e=a("strong"),OLr=o("xglm"),VLr=o(" \u2014 "),zJ=a("a"),XLr=o("FlaxXGLMForCausalLM"),zLr=o(" (XGLM model)"),QLr=l(),F(YE.$$.fragment),ANe=l(),Oc=a("h2"),KE=a("a"),P8e=a("span"),F(xx.$$.fragment),WLr=l(),B8e=a("span"),HLr=o("FlaxAutoModelForPreTraining"),yNe=l(),pr=a("div"),F($x.$$.fragment),ULr=l(),Vc=a("p"),JLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),QJ=a("a"),YLr=o("from_pretrained()"),KLr=o(" class method or the "),WJ=a("a"),ZLr=o("from_config()"),exr=o(` class
method.`),oxr=l(),kx=a("p"),rxr=o("This class cannot be instantiated directly using "),I8e=a("code"),txr=o("__init__()"),axr=o(" (throws an error)."),nxr=l(),Xt=a("div"),F(Sx.$$.fragment),sxr=l(),q8e=a("p"),lxr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),ixr=l(),Xc=a("p"),dxr=o(`Note:
Loading a model from its configuration file does `),N8e=a("strong"),cxr=o("not"),fxr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HJ=a("a"),mxr=o("from_pretrained()"),gxr=o(" to load the model weights."),hxr=l(),F(ZE.$$.fragment),pxr=l(),Vr=a("div"),F(Rx.$$.fragment),uxr=l(),j8e=a("p"),_xr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),bxr=l(),Fn=a("p"),vxr=o("The model class to instantiate is selected based on the "),D8e=a("code"),Fxr=o("model_type"),Txr=o(` property of the config object (either
passed as an argument or loaded from `),G8e=a("code"),Mxr=o("pretrained_model_name_or_path"),Exr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O8e=a("code"),Cxr=o("pretrained_model_name_or_path"),wxr=o(":"),Axr=l(),Me=a("ul"),e5=a("li"),V8e=a("strong"),yxr=o("albert"),Lxr=o(" \u2014 "),UJ=a("a"),xxr=o("FlaxAlbertForPreTraining"),$xr=o(" (ALBERT model)"),kxr=l(),o5=a("li"),X8e=a("strong"),Sxr=o("bart"),Rxr=o(" \u2014 "),JJ=a("a"),Pxr=o("FlaxBartForConditionalGeneration"),Bxr=o(" (BART model)"),Ixr=l(),r5=a("li"),z8e=a("strong"),qxr=o("bert"),Nxr=o(" \u2014 "),YJ=a("a"),jxr=o("FlaxBertForPreTraining"),Dxr=o(" (BERT model)"),Gxr=l(),t5=a("li"),Q8e=a("strong"),Oxr=o("big_bird"),Vxr=o(" \u2014 "),KJ=a("a"),Xxr=o("FlaxBigBirdForPreTraining"),zxr=o(" (BigBird model)"),Qxr=l(),a5=a("li"),W8e=a("strong"),Wxr=o("electra"),Hxr=o(" \u2014 "),ZJ=a("a"),Uxr=o("FlaxElectraForPreTraining"),Jxr=o(" (ELECTRA model)"),Yxr=l(),n5=a("li"),H8e=a("strong"),Kxr=o("mbart"),Zxr=o(" \u2014 "),eY=a("a"),e9r=o("FlaxMBartForConditionalGeneration"),o9r=o(" (mBART model)"),r9r=l(),s5=a("li"),U8e=a("strong"),t9r=o("mt5"),a9r=o(" \u2014 "),oY=a("a"),n9r=o("FlaxMT5ForConditionalGeneration"),s9r=o(" (mT5 model)"),l9r=l(),l5=a("li"),J8e=a("strong"),i9r=o("roberta"),d9r=o(" \u2014 "),rY=a("a"),c9r=o("FlaxRobertaForMaskedLM"),f9r=o(" (RoBERTa model)"),m9r=l(),i5=a("li"),Y8e=a("strong"),g9r=o("roformer"),h9r=o(" \u2014 "),tY=a("a"),p9r=o("FlaxRoFormerForMaskedLM"),u9r=o(" (RoFormer model)"),_9r=l(),d5=a("li"),K8e=a("strong"),b9r=o("t5"),v9r=o(" \u2014 "),aY=a("a"),F9r=o("FlaxT5ForConditionalGeneration"),T9r=o(" (T5 model)"),M9r=l(),c5=a("li"),Z8e=a("strong"),E9r=o("wav2vec2"),C9r=o(" \u2014 "),nY=a("a"),w9r=o("FlaxWav2Vec2ForPreTraining"),A9r=o(" (Wav2Vec2 model)"),y9r=l(),f5=a("li"),e7e=a("strong"),L9r=o("xlm-roberta"),x9r=o(" \u2014 "),sY=a("a"),$9r=o("FlaxXLMRobertaForMaskedLM"),k9r=o(" (XLM-RoBERTa model)"),S9r=l(),F(m5.$$.fragment),LNe=l(),zc=a("h2"),g5=a("a"),o7e=a("span"),F(Px.$$.fragment),R9r=l(),r7e=a("span"),P9r=o("FlaxAutoModelForMaskedLM"),xNe=l(),ur=a("div"),F(Bx.$$.fragment),B9r=l(),Qc=a("p"),I9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),lY=a("a"),q9r=o("from_pretrained()"),N9r=o(" class method or the "),iY=a("a"),j9r=o("from_config()"),D9r=o(` class
method.`),G9r=l(),Ix=a("p"),O9r=o("This class cannot be instantiated directly using "),t7e=a("code"),V9r=o("__init__()"),X9r=o(" (throws an error)."),z9r=l(),zt=a("div"),F(qx.$$.fragment),Q9r=l(),a7e=a("p"),W9r=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),H9r=l(),Wc=a("p"),U9r=o(`Note:
Loading a model from its configuration file does `),n7e=a("strong"),J9r=o("not"),Y9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dY=a("a"),K9r=o("from_pretrained()"),Z9r=o(" to load the model weights."),e$r=l(),F(h5.$$.fragment),o$r=l(),Xr=a("div"),F(Nx.$$.fragment),r$r=l(),s7e=a("p"),t$r=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),a$r=l(),Tn=a("p"),n$r=o("The model class to instantiate is selected based on the "),l7e=a("code"),s$r=o("model_type"),l$r=o(` property of the config object (either
passed as an argument or loaded from `),i7e=a("code"),i$r=o("pretrained_model_name_or_path"),d$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d7e=a("code"),c$r=o("pretrained_model_name_or_path"),f$r=o(":"),m$r=l(),Le=a("ul"),p5=a("li"),c7e=a("strong"),g$r=o("albert"),h$r=o(" \u2014 "),cY=a("a"),p$r=o("FlaxAlbertForMaskedLM"),u$r=o(" (ALBERT model)"),_$r=l(),u5=a("li"),f7e=a("strong"),b$r=o("bart"),v$r=o(" \u2014 "),fY=a("a"),F$r=o("FlaxBartForConditionalGeneration"),T$r=o(" (BART model)"),M$r=l(),_5=a("li"),m7e=a("strong"),E$r=o("bert"),C$r=o(" \u2014 "),mY=a("a"),w$r=o("FlaxBertForMaskedLM"),A$r=o(" (BERT model)"),y$r=l(),b5=a("li"),g7e=a("strong"),L$r=o("big_bird"),x$r=o(" \u2014 "),gY=a("a"),$$r=o("FlaxBigBirdForMaskedLM"),k$r=o(" (BigBird model)"),S$r=l(),v5=a("li"),h7e=a("strong"),R$r=o("distilbert"),P$r=o(" \u2014 "),hY=a("a"),B$r=o("FlaxDistilBertForMaskedLM"),I$r=o(" (DistilBERT model)"),q$r=l(),F5=a("li"),p7e=a("strong"),N$r=o("electra"),j$r=o(" \u2014 "),pY=a("a"),D$r=o("FlaxElectraForMaskedLM"),G$r=o(" (ELECTRA model)"),O$r=l(),T5=a("li"),u7e=a("strong"),V$r=o("mbart"),X$r=o(" \u2014 "),uY=a("a"),z$r=o("FlaxMBartForConditionalGeneration"),Q$r=o(" (mBART model)"),W$r=l(),M5=a("li"),_7e=a("strong"),H$r=o("roberta"),U$r=o(" \u2014 "),_Y=a("a"),J$r=o("FlaxRobertaForMaskedLM"),Y$r=o(" (RoBERTa model)"),K$r=l(),E5=a("li"),b7e=a("strong"),Z$r=o("roformer"),ekr=o(" \u2014 "),bY=a("a"),okr=o("FlaxRoFormerForMaskedLM"),rkr=o(" (RoFormer model)"),tkr=l(),C5=a("li"),v7e=a("strong"),akr=o("xlm-roberta"),nkr=o(" \u2014 "),vY=a("a"),skr=o("FlaxXLMRobertaForMaskedLM"),lkr=o(" (XLM-RoBERTa model)"),ikr=l(),F(w5.$$.fragment),$Ne=l(),Hc=a("h2"),A5=a("a"),F7e=a("span"),F(jx.$$.fragment),dkr=l(),T7e=a("span"),ckr=o("FlaxAutoModelForSeq2SeqLM"),kNe=l(),_r=a("div"),F(Dx.$$.fragment),fkr=l(),Uc=a("p"),mkr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),FY=a("a"),gkr=o("from_pretrained()"),hkr=o(" class method or the "),TY=a("a"),pkr=o("from_config()"),ukr=o(` class
method.`),_kr=l(),Gx=a("p"),bkr=o("This class cannot be instantiated directly using "),M7e=a("code"),vkr=o("__init__()"),Fkr=o(" (throws an error)."),Tkr=l(),Qt=a("div"),F(Ox.$$.fragment),Mkr=l(),E7e=a("p"),Ekr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Ckr=l(),Jc=a("p"),wkr=o(`Note:
Loading a model from its configuration file does `),C7e=a("strong"),Akr=o("not"),ykr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MY=a("a"),Lkr=o("from_pretrained()"),xkr=o(" to load the model weights."),$kr=l(),F(y5.$$.fragment),kkr=l(),zr=a("div"),F(Vx.$$.fragment),Skr=l(),w7e=a("p"),Rkr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Pkr=l(),Mn=a("p"),Bkr=o("The model class to instantiate is selected based on the "),A7e=a("code"),Ikr=o("model_type"),qkr=o(` property of the config object (either
passed as an argument or loaded from `),y7e=a("code"),Nkr=o("pretrained_model_name_or_path"),jkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L7e=a("code"),Dkr=o("pretrained_model_name_or_path"),Gkr=o(":"),Okr=l(),Se=a("ul"),L5=a("li"),x7e=a("strong"),Vkr=o("bart"),Xkr=o(" \u2014 "),EY=a("a"),zkr=o("FlaxBartForConditionalGeneration"),Qkr=o(" (BART model)"),Wkr=l(),x5=a("li"),$7e=a("strong"),Hkr=o("blenderbot"),Ukr=o(" \u2014 "),CY=a("a"),Jkr=o("FlaxBlenderbotForConditionalGeneration"),Ykr=o(" (Blenderbot model)"),Kkr=l(),$5=a("li"),k7e=a("strong"),Zkr=o("blenderbot-small"),eSr=o(" \u2014 "),wY=a("a"),oSr=o("FlaxBlenderbotSmallForConditionalGeneration"),rSr=o(" (BlenderbotSmall model)"),tSr=l(),k5=a("li"),S7e=a("strong"),aSr=o("encoder-decoder"),nSr=o(" \u2014 "),AY=a("a"),sSr=o("FlaxEncoderDecoderModel"),lSr=o(" (Encoder decoder model)"),iSr=l(),S5=a("li"),R7e=a("strong"),dSr=o("marian"),cSr=o(" \u2014 "),yY=a("a"),fSr=o("FlaxMarianMTModel"),mSr=o(" (Marian model)"),gSr=l(),R5=a("li"),P7e=a("strong"),hSr=o("mbart"),pSr=o(" \u2014 "),LY=a("a"),uSr=o("FlaxMBartForConditionalGeneration"),_Sr=o(" (mBART model)"),bSr=l(),P5=a("li"),B7e=a("strong"),vSr=o("mt5"),FSr=o(" \u2014 "),xY=a("a"),TSr=o("FlaxMT5ForConditionalGeneration"),MSr=o(" (mT5 model)"),ESr=l(),B5=a("li"),I7e=a("strong"),CSr=o("pegasus"),wSr=o(" \u2014 "),$Y=a("a"),ASr=o("FlaxPegasusForConditionalGeneration"),ySr=o(" (Pegasus model)"),LSr=l(),I5=a("li"),q7e=a("strong"),xSr=o("t5"),$Sr=o(" \u2014 "),kY=a("a"),kSr=o("FlaxT5ForConditionalGeneration"),SSr=o(" (T5 model)"),RSr=l(),F(q5.$$.fragment),SNe=l(),Yc=a("h2"),N5=a("a"),N7e=a("span"),F(Xx.$$.fragment),PSr=l(),j7e=a("span"),BSr=o("FlaxAutoModelForSequenceClassification"),RNe=l(),br=a("div"),F(zx.$$.fragment),ISr=l(),Kc=a("p"),qSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),SY=a("a"),NSr=o("from_pretrained()"),jSr=o(" class method or the "),RY=a("a"),DSr=o("from_config()"),GSr=o(` class
method.`),OSr=l(),Qx=a("p"),VSr=o("This class cannot be instantiated directly using "),D7e=a("code"),XSr=o("__init__()"),zSr=o(" (throws an error)."),QSr=l(),Wt=a("div"),F(Wx.$$.fragment),WSr=l(),G7e=a("p"),HSr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),USr=l(),Zc=a("p"),JSr=o(`Note:
Loading a model from its configuration file does `),O7e=a("strong"),YSr=o("not"),KSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),PY=a("a"),ZSr=o("from_pretrained()"),eRr=o(" to load the model weights."),oRr=l(),F(j5.$$.fragment),rRr=l(),Qr=a("div"),F(Hx.$$.fragment),tRr=l(),V7e=a("p"),aRr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),nRr=l(),En=a("p"),sRr=o("The model class to instantiate is selected based on the "),X7e=a("code"),lRr=o("model_type"),iRr=o(` property of the config object (either
passed as an argument or loaded from `),z7e=a("code"),dRr=o("pretrained_model_name_or_path"),cRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q7e=a("code"),fRr=o("pretrained_model_name_or_path"),mRr=o(":"),gRr=l(),xe=a("ul"),D5=a("li"),W7e=a("strong"),hRr=o("albert"),pRr=o(" \u2014 "),BY=a("a"),uRr=o("FlaxAlbertForSequenceClassification"),_Rr=o(" (ALBERT model)"),bRr=l(),G5=a("li"),H7e=a("strong"),vRr=o("bart"),FRr=o(" \u2014 "),IY=a("a"),TRr=o("FlaxBartForSequenceClassification"),MRr=o(" (BART model)"),ERr=l(),O5=a("li"),U7e=a("strong"),CRr=o("bert"),wRr=o(" \u2014 "),qY=a("a"),ARr=o("FlaxBertForSequenceClassification"),yRr=o(" (BERT model)"),LRr=l(),V5=a("li"),J7e=a("strong"),xRr=o("big_bird"),$Rr=o(" \u2014 "),NY=a("a"),kRr=o("FlaxBigBirdForSequenceClassification"),SRr=o(" (BigBird model)"),RRr=l(),X5=a("li"),Y7e=a("strong"),PRr=o("distilbert"),BRr=o(" \u2014 "),jY=a("a"),IRr=o("FlaxDistilBertForSequenceClassification"),qRr=o(" (DistilBERT model)"),NRr=l(),z5=a("li"),K7e=a("strong"),jRr=o("electra"),DRr=o(" \u2014 "),DY=a("a"),GRr=o("FlaxElectraForSequenceClassification"),ORr=o(" (ELECTRA model)"),VRr=l(),Q5=a("li"),Z7e=a("strong"),XRr=o("mbart"),zRr=o(" \u2014 "),GY=a("a"),QRr=o("FlaxMBartForSequenceClassification"),WRr=o(" (mBART model)"),HRr=l(),W5=a("li"),eMe=a("strong"),URr=o("roberta"),JRr=o(" \u2014 "),OY=a("a"),YRr=o("FlaxRobertaForSequenceClassification"),KRr=o(" (RoBERTa model)"),ZRr=l(),H5=a("li"),oMe=a("strong"),ePr=o("roformer"),oPr=o(" \u2014 "),VY=a("a"),rPr=o("FlaxRoFormerForSequenceClassification"),tPr=o(" (RoFormer model)"),aPr=l(),U5=a("li"),rMe=a("strong"),nPr=o("xlm-roberta"),sPr=o(" \u2014 "),XY=a("a"),lPr=o("FlaxXLMRobertaForSequenceClassification"),iPr=o(" (XLM-RoBERTa model)"),dPr=l(),F(J5.$$.fragment),PNe=l(),ef=a("h2"),Y5=a("a"),tMe=a("span"),F(Ux.$$.fragment),cPr=l(),aMe=a("span"),fPr=o("FlaxAutoModelForQuestionAnswering"),BNe=l(),vr=a("div"),F(Jx.$$.fragment),mPr=l(),of=a("p"),gPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),zY=a("a"),hPr=o("from_pretrained()"),pPr=o(" class method or the "),QY=a("a"),uPr=o("from_config()"),_Pr=o(` class
method.`),bPr=l(),Yx=a("p"),vPr=o("This class cannot be instantiated directly using "),nMe=a("code"),FPr=o("__init__()"),TPr=o(" (throws an error)."),MPr=l(),Ht=a("div"),F(Kx.$$.fragment),EPr=l(),sMe=a("p"),CPr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),wPr=l(),rf=a("p"),APr=o(`Note:
Loading a model from its configuration file does `),lMe=a("strong"),yPr=o("not"),LPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WY=a("a"),xPr=o("from_pretrained()"),$Pr=o(" to load the model weights."),kPr=l(),F(K5.$$.fragment),SPr=l(),Wr=a("div"),F(Zx.$$.fragment),RPr=l(),iMe=a("p"),PPr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),BPr=l(),Cn=a("p"),IPr=o("The model class to instantiate is selected based on the "),dMe=a("code"),qPr=o("model_type"),NPr=o(` property of the config object (either
passed as an argument or loaded from `),cMe=a("code"),jPr=o("pretrained_model_name_or_path"),DPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fMe=a("code"),GPr=o("pretrained_model_name_or_path"),OPr=o(":"),VPr=l(),$e=a("ul"),Z5=a("li"),mMe=a("strong"),XPr=o("albert"),zPr=o(" \u2014 "),HY=a("a"),QPr=o("FlaxAlbertForQuestionAnswering"),WPr=o(" (ALBERT model)"),HPr=l(),eC=a("li"),gMe=a("strong"),UPr=o("bart"),JPr=o(" \u2014 "),UY=a("a"),YPr=o("FlaxBartForQuestionAnswering"),KPr=o(" (BART model)"),ZPr=l(),oC=a("li"),hMe=a("strong"),eBr=o("bert"),oBr=o(" \u2014 "),JY=a("a"),rBr=o("FlaxBertForQuestionAnswering"),tBr=o(" (BERT model)"),aBr=l(),rC=a("li"),pMe=a("strong"),nBr=o("big_bird"),sBr=o(" \u2014 "),YY=a("a"),lBr=o("FlaxBigBirdForQuestionAnswering"),iBr=o(" (BigBird model)"),dBr=l(),tC=a("li"),uMe=a("strong"),cBr=o("distilbert"),fBr=o(" \u2014 "),KY=a("a"),mBr=o("FlaxDistilBertForQuestionAnswering"),gBr=o(" (DistilBERT model)"),hBr=l(),aC=a("li"),_Me=a("strong"),pBr=o("electra"),uBr=o(" \u2014 "),ZY=a("a"),_Br=o("FlaxElectraForQuestionAnswering"),bBr=o(" (ELECTRA model)"),vBr=l(),nC=a("li"),bMe=a("strong"),FBr=o("mbart"),TBr=o(" \u2014 "),eK=a("a"),MBr=o("FlaxMBartForQuestionAnswering"),EBr=o(" (mBART model)"),CBr=l(),sC=a("li"),vMe=a("strong"),wBr=o("roberta"),ABr=o(" \u2014 "),oK=a("a"),yBr=o("FlaxRobertaForQuestionAnswering"),LBr=o(" (RoBERTa model)"),xBr=l(),lC=a("li"),FMe=a("strong"),$Br=o("roformer"),kBr=o(" \u2014 "),rK=a("a"),SBr=o("FlaxRoFormerForQuestionAnswering"),RBr=o(" (RoFormer model)"),PBr=l(),iC=a("li"),TMe=a("strong"),BBr=o("xlm-roberta"),IBr=o(" \u2014 "),tK=a("a"),qBr=o("FlaxXLMRobertaForQuestionAnswering"),NBr=o(" (XLM-RoBERTa model)"),jBr=l(),F(dC.$$.fragment),INe=l(),tf=a("h2"),cC=a("a"),MMe=a("span"),F(e9.$$.fragment),DBr=l(),EMe=a("span"),GBr=o("FlaxAutoModelForTokenClassification"),qNe=l(),Fr=a("div"),F(o9.$$.fragment),OBr=l(),af=a("p"),VBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),aK=a("a"),XBr=o("from_pretrained()"),zBr=o(" class method or the "),nK=a("a"),QBr=o("from_config()"),WBr=o(` class
method.`),HBr=l(),r9=a("p"),UBr=o("This class cannot be instantiated directly using "),CMe=a("code"),JBr=o("__init__()"),YBr=o(" (throws an error)."),KBr=l(),Ut=a("div"),F(t9.$$.fragment),ZBr=l(),wMe=a("p"),eIr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),oIr=l(),nf=a("p"),rIr=o(`Note:
Loading a model from its configuration file does `),AMe=a("strong"),tIr=o("not"),aIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sK=a("a"),nIr=o("from_pretrained()"),sIr=o(" to load the model weights."),lIr=l(),F(fC.$$.fragment),iIr=l(),Hr=a("div"),F(a9.$$.fragment),dIr=l(),yMe=a("p"),cIr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),fIr=l(),wn=a("p"),mIr=o("The model class to instantiate is selected based on the "),LMe=a("code"),gIr=o("model_type"),hIr=o(` property of the config object (either
passed as an argument or loaded from `),xMe=a("code"),pIr=o("pretrained_model_name_or_path"),uIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Me=a("code"),_Ir=o("pretrained_model_name_or_path"),bIr=o(":"),vIr=l(),De=a("ul"),mC=a("li"),kMe=a("strong"),FIr=o("albert"),TIr=o(" \u2014 "),lK=a("a"),MIr=o("FlaxAlbertForTokenClassification"),EIr=o(" (ALBERT model)"),CIr=l(),gC=a("li"),SMe=a("strong"),wIr=o("bert"),AIr=o(" \u2014 "),iK=a("a"),yIr=o("FlaxBertForTokenClassification"),LIr=o(" (BERT model)"),xIr=l(),hC=a("li"),RMe=a("strong"),$Ir=o("big_bird"),kIr=o(" \u2014 "),dK=a("a"),SIr=o("FlaxBigBirdForTokenClassification"),RIr=o(" (BigBird model)"),PIr=l(),pC=a("li"),PMe=a("strong"),BIr=o("distilbert"),IIr=o(" \u2014 "),cK=a("a"),qIr=o("FlaxDistilBertForTokenClassification"),NIr=o(" (DistilBERT model)"),jIr=l(),uC=a("li"),BMe=a("strong"),DIr=o("electra"),GIr=o(" \u2014 "),fK=a("a"),OIr=o("FlaxElectraForTokenClassification"),VIr=o(" (ELECTRA model)"),XIr=l(),_C=a("li"),IMe=a("strong"),zIr=o("roberta"),QIr=o(" \u2014 "),mK=a("a"),WIr=o("FlaxRobertaForTokenClassification"),HIr=o(" (RoBERTa model)"),UIr=l(),bC=a("li"),qMe=a("strong"),JIr=o("roformer"),YIr=o(" \u2014 "),gK=a("a"),KIr=o("FlaxRoFormerForTokenClassification"),ZIr=o(" (RoFormer model)"),eqr=l(),vC=a("li"),NMe=a("strong"),oqr=o("xlm-roberta"),rqr=o(" \u2014 "),hK=a("a"),tqr=o("FlaxXLMRobertaForTokenClassification"),aqr=o(" (XLM-RoBERTa model)"),nqr=l(),F(FC.$$.fragment),NNe=l(),sf=a("h2"),TC=a("a"),jMe=a("span"),F(n9.$$.fragment),sqr=l(),DMe=a("span"),lqr=o("FlaxAutoModelForMultipleChoice"),jNe=l(),Tr=a("div"),F(s9.$$.fragment),iqr=l(),lf=a("p"),dqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),pK=a("a"),cqr=o("from_pretrained()"),fqr=o(" class method or the "),uK=a("a"),mqr=o("from_config()"),gqr=o(` class
method.`),hqr=l(),l9=a("p"),pqr=o("This class cannot be instantiated directly using "),GMe=a("code"),uqr=o("__init__()"),_qr=o(" (throws an error)."),bqr=l(),Jt=a("div"),F(i9.$$.fragment),vqr=l(),OMe=a("p"),Fqr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Tqr=l(),df=a("p"),Mqr=o(`Note:
Loading a model from its configuration file does `),VMe=a("strong"),Eqr=o("not"),Cqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_K=a("a"),wqr=o("from_pretrained()"),Aqr=o(" to load the model weights."),yqr=l(),F(MC.$$.fragment),Lqr=l(),Ur=a("div"),F(d9.$$.fragment),xqr=l(),XMe=a("p"),$qr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),kqr=l(),An=a("p"),Sqr=o("The model class to instantiate is selected based on the "),zMe=a("code"),Rqr=o("model_type"),Pqr=o(` property of the config object (either
passed as an argument or loaded from `),QMe=a("code"),Bqr=o("pretrained_model_name_or_path"),Iqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WMe=a("code"),qqr=o("pretrained_model_name_or_path"),Nqr=o(":"),jqr=l(),Ge=a("ul"),EC=a("li"),HMe=a("strong"),Dqr=o("albert"),Gqr=o(" \u2014 "),bK=a("a"),Oqr=o("FlaxAlbertForMultipleChoice"),Vqr=o(" (ALBERT model)"),Xqr=l(),CC=a("li"),UMe=a("strong"),zqr=o("bert"),Qqr=o(" \u2014 "),vK=a("a"),Wqr=o("FlaxBertForMultipleChoice"),Hqr=o(" (BERT model)"),Uqr=l(),wC=a("li"),JMe=a("strong"),Jqr=o("big_bird"),Yqr=o(" \u2014 "),FK=a("a"),Kqr=o("FlaxBigBirdForMultipleChoice"),Zqr=o(" (BigBird model)"),eNr=l(),AC=a("li"),YMe=a("strong"),oNr=o("distilbert"),rNr=o(" \u2014 "),TK=a("a"),tNr=o("FlaxDistilBertForMultipleChoice"),aNr=o(" (DistilBERT model)"),nNr=l(),yC=a("li"),KMe=a("strong"),sNr=o("electra"),lNr=o(" \u2014 "),MK=a("a"),iNr=o("FlaxElectraForMultipleChoice"),dNr=o(" (ELECTRA model)"),cNr=l(),LC=a("li"),ZMe=a("strong"),fNr=o("roberta"),mNr=o(" \u2014 "),EK=a("a"),gNr=o("FlaxRobertaForMultipleChoice"),hNr=o(" (RoBERTa model)"),pNr=l(),xC=a("li"),e4e=a("strong"),uNr=o("roformer"),_Nr=o(" \u2014 "),CK=a("a"),bNr=o("FlaxRoFormerForMultipleChoice"),vNr=o(" (RoFormer model)"),FNr=l(),$C=a("li"),o4e=a("strong"),TNr=o("xlm-roberta"),MNr=o(" \u2014 "),wK=a("a"),ENr=o("FlaxXLMRobertaForMultipleChoice"),CNr=o(" (XLM-RoBERTa model)"),wNr=l(),F(kC.$$.fragment),DNe=l(),cf=a("h2"),SC=a("a"),r4e=a("span"),F(c9.$$.fragment),ANr=l(),t4e=a("span"),yNr=o("FlaxAutoModelForNextSentencePrediction"),GNe=l(),Mr=a("div"),F(f9.$$.fragment),LNr=l(),ff=a("p"),xNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),AK=a("a"),$Nr=o("from_pretrained()"),kNr=o(" class method or the "),yK=a("a"),SNr=o("from_config()"),RNr=o(` class
method.`),PNr=l(),m9=a("p"),BNr=o("This class cannot be instantiated directly using "),a4e=a("code"),INr=o("__init__()"),qNr=o(" (throws an error)."),NNr=l(),Yt=a("div"),F(g9.$$.fragment),jNr=l(),n4e=a("p"),DNr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),GNr=l(),mf=a("p"),ONr=o(`Note:
Loading a model from its configuration file does `),s4e=a("strong"),VNr=o("not"),XNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LK=a("a"),zNr=o("from_pretrained()"),QNr=o(" to load the model weights."),WNr=l(),F(RC.$$.fragment),HNr=l(),Jr=a("div"),F(h9.$$.fragment),UNr=l(),l4e=a("p"),JNr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),YNr=l(),yn=a("p"),KNr=o("The model class to instantiate is selected based on the "),i4e=a("code"),ZNr=o("model_type"),ejr=o(` property of the config object (either
passed as an argument or loaded from `),d4e=a("code"),ojr=o("pretrained_model_name_or_path"),rjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c4e=a("code"),tjr=o("pretrained_model_name_or_path"),ajr=o(":"),njr=l(),f4e=a("ul"),PC=a("li"),m4e=a("strong"),sjr=o("bert"),ljr=o(" \u2014 "),xK=a("a"),ijr=o("FlaxBertForNextSentencePrediction"),djr=o(" (BERT model)"),cjr=l(),F(BC.$$.fragment),ONe=l(),gf=a("h2"),IC=a("a"),g4e=a("span"),F(p9.$$.fragment),fjr=l(),h4e=a("span"),mjr=o("FlaxAutoModelForImageClassification"),VNe=l(),Er=a("div"),F(u9.$$.fragment),gjr=l(),hf=a("p"),hjr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),$K=a("a"),pjr=o("from_pretrained()"),ujr=o(" class method or the "),kK=a("a"),_jr=o("from_config()"),bjr=o(` class
method.`),vjr=l(),_9=a("p"),Fjr=o("This class cannot be instantiated directly using "),p4e=a("code"),Tjr=o("__init__()"),Mjr=o(" (throws an error)."),Ejr=l(),Kt=a("div"),F(b9.$$.fragment),Cjr=l(),u4e=a("p"),wjr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Ajr=l(),pf=a("p"),yjr=o(`Note:
Loading a model from its configuration file does `),_4e=a("strong"),Ljr=o("not"),xjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SK=a("a"),$jr=o("from_pretrained()"),kjr=o(" to load the model weights."),Sjr=l(),F(qC.$$.fragment),Rjr=l(),Yr=a("div"),F(v9.$$.fragment),Pjr=l(),b4e=a("p"),Bjr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Ijr=l(),Ln=a("p"),qjr=o("The model class to instantiate is selected based on the "),v4e=a("code"),Njr=o("model_type"),jjr=o(` property of the config object (either
passed as an argument or loaded from `),F4e=a("code"),Djr=o("pretrained_model_name_or_path"),Gjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T4e=a("code"),Ojr=o("pretrained_model_name_or_path"),Vjr=o(":"),Xjr=l(),F9=a("ul"),NC=a("li"),M4e=a("strong"),zjr=o("beit"),Qjr=o(" \u2014 "),RK=a("a"),Wjr=o("FlaxBeitForImageClassification"),Hjr=o(" (BEiT model)"),Ujr=l(),jC=a("li"),E4e=a("strong"),Jjr=o("vit"),Yjr=o(" \u2014 "),PK=a("a"),Kjr=o("FlaxViTForImageClassification"),Zjr=o(" (ViT model)"),eDr=l(),F(DC.$$.fragment),XNe=l(),uf=a("h2"),GC=a("a"),C4e=a("span"),F(T9.$$.fragment),oDr=l(),w4e=a("span"),rDr=o("FlaxAutoModelForVision2Seq"),zNe=l(),Cr=a("div"),F(M9.$$.fragment),tDr=l(),_f=a("p"),aDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),BK=a("a"),nDr=o("from_pretrained()"),sDr=o(" class method or the "),IK=a("a"),lDr=o("from_config()"),iDr=o(` class
method.`),dDr=l(),E9=a("p"),cDr=o("This class cannot be instantiated directly using "),A4e=a("code"),fDr=o("__init__()"),mDr=o(" (throws an error)."),gDr=l(),Zt=a("div"),F(C9.$$.fragment),hDr=l(),y4e=a("p"),pDr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),uDr=l(),bf=a("p"),_Dr=o(`Note:
Loading a model from its configuration file does `),L4e=a("strong"),bDr=o("not"),vDr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qK=a("a"),FDr=o("from_pretrained()"),TDr=o(" to load the model weights."),MDr=l(),F(OC.$$.fragment),EDr=l(),Kr=a("div"),F(w9.$$.fragment),CDr=l(),x4e=a("p"),wDr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),ADr=l(),xn=a("p"),yDr=o("The model class to instantiate is selected based on the "),$4e=a("code"),LDr=o("model_type"),xDr=o(` property of the config object (either
passed as an argument or loaded from `),k4e=a("code"),$Dr=o("pretrained_model_name_or_path"),kDr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S4e=a("code"),SDr=o("pretrained_model_name_or_path"),RDr=o(":"),PDr=l(),R4e=a("ul"),VC=a("li"),P4e=a("strong"),BDr=o("vision-encoder-decoder"),IDr=o(" \u2014 "),NK=a("a"),qDr=o("FlaxVisionEncoderDecoderModel"),NDr=o(" (Vision Encoder decoder model)"),jDr=l(),F(XC.$$.fragment),this.h()},l(f){const _=Iyt('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var A9=s(p);m=n(A9,"A",{id:!0,class:!0,href:!0});var B4e=s(m);u=n(B4e,"SPAN",{});var I4e=s(u);T(d.$$.fragment,I4e),I4e.forEach(t),B4e.forEach(t),h=i(A9),Eo=n(A9,"SPAN",{});var q4e=s(Eo);hi=r(q4e,"Auto Classes"),q4e.forEach(t),A9.forEach(t),Mf=i(f),rt=n(f,"P",{});var y9=s(rt);pi=r(y9,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),ui=n(y9,"CODE",{});var N4e=s(ui);mA=r(N4e,"from_pretrained()"),N4e.forEach(t),Ef=r(y9,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),y9.forEach(t),qe=i(f),Xe=n(f,"P",{});var $n=s(Xe);_i=r($n,"Instantiating one of "),kn=n($n,"A",{href:!0});var j4e=s(kn);gA=r(j4e,"AutoConfig"),j4e.forEach(t),Sn=r($n,", "),Rn=n($n,"A",{href:!0});var D4e=s(Rn);hA=r(D4e,"AutoModel"),D4e.forEach(t),bi=r($n,`, and
`),Pn=n($n,"A",{href:!0});var G4e=s(Pn);pA=r(G4e,"AutoTokenizer"),G4e.forEach(t),vi=r($n," will directly create a class of the relevant architecture. For instance"),$n.forEach(t),Cf=i(f),T(Aa.$$.fragment,f),ze=i(f),Ae=n(f,"P",{});var L9=s(Ae);j$=r(L9,"will create a model that is an instance of "),Fi=n(L9,"A",{href:!0});var O4e=s(Fi);D$=r(O4e,"BertModel"),O4e.forEach(t),G$=r(L9,"."),L9.forEach(t),Co=i(f),ya=n(f,"P",{});var x9=s(ya);O$=r(x9,"There is one class of "),wf=n(x9,"CODE",{});var V4e=s(wf);V$=r(V4e,"AutoModel"),V4e.forEach(t),rGe=r(x9," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),x9.forEach(t),GIe=i(f),Ti=n(f,"H2",{class:!0});var $9=s(Ti);Af=n($9,"A",{id:!0,class:!0,href:!0});var X4e=s(Af);Pee=n(X4e,"SPAN",{});var z4e=s(Pee);T(uA.$$.fragment,z4e),z4e.forEach(t),X4e.forEach(t),tGe=i($9),Bee=n($9,"SPAN",{});var Q4e=s(Bee);aGe=r(Q4e,"Extending the Auto Classes"),Q4e.forEach(t),$9.forEach(t),OIe=i(f),Bn=n(f,"P",{});var vf=s(Bn);nGe=r(vf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Iee=n(vf,"CODE",{});var W4e=s(Iee);sGe=r(W4e,"NewModel"),W4e.forEach(t),lGe=r(vf,", make sure you have a "),qee=n(vf,"CODE",{});var H4e=s(qee);iGe=r(H4e,"NewModelConfig"),H4e.forEach(t),dGe=r(vf,` then you can add those to the auto
classes like this:`),vf.forEach(t),VIe=i(f),T(_A.$$.fragment,f),XIe=i(f),X$=n(f,"P",{});var U4e=s(X$);cGe=r(U4e,"You will then be able to use the auto classes like you would usually do!"),U4e.forEach(t),zIe=i(f),T(yf.$$.fragment,f),QIe=i(f),Mi=n(f,"H2",{class:!0});var k9=s(Mi);Lf=n(k9,"A",{id:!0,class:!0,href:!0});var J4e=s(Lf);Nee=n(J4e,"SPAN",{});var Y4e=s(Nee);T(bA.$$.fragment,Y4e),Y4e.forEach(t),J4e.forEach(t),fGe=i(k9),jee=n(k9,"SPAN",{});var K4e=s(jee);mGe=r(K4e,"AutoConfig"),K4e.forEach(t),k9.forEach(t),WIe=i(f),wo=n(f,"DIV",{class:!0});var et=s(wo);T(vA.$$.fragment,et),gGe=i(et),FA=n(et,"P",{});var S9=s(FA);hGe=r(S9,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),z$=n(S9,"A",{href:!0});var Z4e=s(z$);pGe=r(Z4e,"from_pretrained()"),Z4e.forEach(t),uGe=r(S9," class method."),S9.forEach(t),_Ge=i(et),TA=n(et,"P",{});var R9=s(TA);bGe=r(R9,"This class cannot be instantiated directly using "),Dee=n(R9,"CODE",{});var eEe=s(Dee);vGe=r(eEe,"__init__()"),eEe.forEach(t),FGe=r(R9," (throws an error)."),R9.forEach(t),TGe=i(et),wr=n(et,"DIV",{class:!0});var ot=s(wr);T(MA.$$.fragment,ot),MGe=i(ot),Gee=n(ot,"P",{});var oEe=s(Gee);EGe=r(oEe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),oEe.forEach(t),CGe=i(ot),Ei=n(ot,"P",{});var Ff=s(Ei);wGe=r(Ff,"The configuration class to instantiate is selected based on the "),Oee=n(Ff,"CODE",{});var rEe=s(Oee);AGe=r(rEe,"model_type"),rEe.forEach(t),yGe=r(Ff,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Vee=n(Ff,"CODE",{});var tEe=s(Vee);LGe=r(tEe,"pretrained_model_name_or_path"),tEe.forEach(t),xGe=r(Ff,":"),Ff.forEach(t),$Ge=i(ot),y=n(ot,"UL",{});var L=s(y);xf=n(L,"LI",{});var zC=s(xf);Xee=n(zC,"STRONG",{});var aEe=s(Xee);kGe=r(aEe,"albert"),aEe.forEach(t),SGe=r(zC," \u2014 "),Q$=n(zC,"A",{href:!0});var nEe=s(Q$);RGe=r(nEe,"AlbertConfig"),nEe.forEach(t),PGe=r(zC," (ALBERT model)"),zC.forEach(t),BGe=i(L),$f=n(L,"LI",{});var QC=s($f);zee=n(QC,"STRONG",{});var sEe=s(zee);IGe=r(sEe,"bart"),sEe.forEach(t),qGe=r(QC," \u2014 "),W$=n(QC,"A",{href:!0});var lEe=s(W$);NGe=r(lEe,"BartConfig"),lEe.forEach(t),jGe=r(QC," (BART model)"),QC.forEach(t),DGe=i(L),kf=n(L,"LI",{});var WC=s(kf);Qee=n(WC,"STRONG",{});var iEe=s(Qee);GGe=r(iEe,"beit"),iEe.forEach(t),OGe=r(WC," \u2014 "),H$=n(WC,"A",{href:!0});var dEe=s(H$);VGe=r(dEe,"BeitConfig"),dEe.forEach(t),XGe=r(WC," (BEiT model)"),WC.forEach(t),zGe=i(L),Sf=n(L,"LI",{});var HC=s(Sf);Wee=n(HC,"STRONG",{});var cEe=s(Wee);QGe=r(cEe,"bert"),cEe.forEach(t),WGe=r(HC," \u2014 "),U$=n(HC,"A",{href:!0});var fEe=s(U$);HGe=r(fEe,"BertConfig"),fEe.forEach(t),UGe=r(HC," (BERT model)"),HC.forEach(t),JGe=i(L),Rf=n(L,"LI",{});var UC=s(Rf);Hee=n(UC,"STRONG",{});var mEe=s(Hee);YGe=r(mEe,"bert-generation"),mEe.forEach(t),KGe=r(UC," \u2014 "),J$=n(UC,"A",{href:!0});var gEe=s(J$);ZGe=r(gEe,"BertGenerationConfig"),gEe.forEach(t),eOe=r(UC," (Bert Generation model)"),UC.forEach(t),oOe=i(L),Pf=n(L,"LI",{});var JC=s(Pf);Uee=n(JC,"STRONG",{});var hEe=s(Uee);rOe=r(hEe,"big_bird"),hEe.forEach(t),tOe=r(JC," \u2014 "),Y$=n(JC,"A",{href:!0});var pEe=s(Y$);aOe=r(pEe,"BigBirdConfig"),pEe.forEach(t),nOe=r(JC," (BigBird model)"),JC.forEach(t),sOe=i(L),Bf=n(L,"LI",{});var YC=s(Bf);Jee=n(YC,"STRONG",{});var uEe=s(Jee);lOe=r(uEe,"bigbird_pegasus"),uEe.forEach(t),iOe=r(YC," \u2014 "),K$=n(YC,"A",{href:!0});var _Ee=s(K$);dOe=r(_Ee,"BigBirdPegasusConfig"),_Ee.forEach(t),cOe=r(YC," (BigBirdPegasus model)"),YC.forEach(t),fOe=i(L),If=n(L,"LI",{});var KC=s(If);Yee=n(KC,"STRONG",{});var bEe=s(Yee);mOe=r(bEe,"blenderbot"),bEe.forEach(t),gOe=r(KC," \u2014 "),Z$=n(KC,"A",{href:!0});var vEe=s(Z$);hOe=r(vEe,"BlenderbotConfig"),vEe.forEach(t),pOe=r(KC," (Blenderbot model)"),KC.forEach(t),uOe=i(L),qf=n(L,"LI",{});var ZC=s(qf);Kee=n(ZC,"STRONG",{});var FEe=s(Kee);_Oe=r(FEe,"blenderbot-small"),FEe.forEach(t),bOe=r(ZC," \u2014 "),ek=n(ZC,"A",{href:!0});var TEe=s(ek);vOe=r(TEe,"BlenderbotSmallConfig"),TEe.forEach(t),FOe=r(ZC," (BlenderbotSmall model)"),ZC.forEach(t),TOe=i(L),Nf=n(L,"LI",{});var e3=s(Nf);Zee=n(e3,"STRONG",{});var MEe=s(Zee);MOe=r(MEe,"camembert"),MEe.forEach(t),EOe=r(e3," \u2014 "),ok=n(e3,"A",{href:!0});var EEe=s(ok);COe=r(EEe,"CamembertConfig"),EEe.forEach(t),wOe=r(e3," (CamemBERT model)"),e3.forEach(t),AOe=i(L),jf=n(L,"LI",{});var o3=s(jf);eoe=n(o3,"STRONG",{});var CEe=s(eoe);yOe=r(CEe,"canine"),CEe.forEach(t),LOe=r(o3," \u2014 "),rk=n(o3,"A",{href:!0});var wEe=s(rk);xOe=r(wEe,"CanineConfig"),wEe.forEach(t),$Oe=r(o3," (Canine model)"),o3.forEach(t),kOe=i(L),Df=n(L,"LI",{});var r3=s(Df);ooe=n(r3,"STRONG",{});var AEe=s(ooe);SOe=r(AEe,"clip"),AEe.forEach(t),ROe=r(r3," \u2014 "),tk=n(r3,"A",{href:!0});var yEe=s(tk);POe=r(yEe,"CLIPConfig"),yEe.forEach(t),BOe=r(r3," (CLIP model)"),r3.forEach(t),IOe=i(L),Gf=n(L,"LI",{});var t3=s(Gf);roe=n(t3,"STRONG",{});var LEe=s(roe);qOe=r(LEe,"convbert"),LEe.forEach(t),NOe=r(t3," \u2014 "),ak=n(t3,"A",{href:!0});var xEe=s(ak);jOe=r(xEe,"ConvBertConfig"),xEe.forEach(t),DOe=r(t3," (ConvBERT model)"),t3.forEach(t),GOe=i(L),Of=n(L,"LI",{});var a3=s(Of);toe=n(a3,"STRONG",{});var $Ee=s(toe);OOe=r($Ee,"convnext"),$Ee.forEach(t),VOe=r(a3," \u2014 "),nk=n(a3,"A",{href:!0});var kEe=s(nk);XOe=r(kEe,"ConvNextConfig"),kEe.forEach(t),zOe=r(a3," (ConvNext model)"),a3.forEach(t),QOe=i(L),Vf=n(L,"LI",{});var n3=s(Vf);aoe=n(n3,"STRONG",{});var SEe=s(aoe);WOe=r(SEe,"ctrl"),SEe.forEach(t),HOe=r(n3," \u2014 "),sk=n(n3,"A",{href:!0});var REe=s(sk);UOe=r(REe,"CTRLConfig"),REe.forEach(t),JOe=r(n3," (CTRL model)"),n3.forEach(t),YOe=i(L),Xf=n(L,"LI",{});var s3=s(Xf);noe=n(s3,"STRONG",{});var PEe=s(noe);KOe=r(PEe,"data2vec-audio"),PEe.forEach(t),ZOe=r(s3," \u2014 "),lk=n(s3,"A",{href:!0});var BEe=s(lk);eVe=r(BEe,"Data2VecAudioConfig"),BEe.forEach(t),oVe=r(s3," (Data2VecAudio model)"),s3.forEach(t),rVe=i(L),zf=n(L,"LI",{});var l3=s(zf);soe=n(l3,"STRONG",{});var IEe=s(soe);tVe=r(IEe,"data2vec-text"),IEe.forEach(t),aVe=r(l3," \u2014 "),ik=n(l3,"A",{href:!0});var qEe=s(ik);nVe=r(qEe,"Data2VecTextConfig"),qEe.forEach(t),sVe=r(l3," (Data2VecText model)"),l3.forEach(t),lVe=i(L),Qf=n(L,"LI",{});var i3=s(Qf);loe=n(i3,"STRONG",{});var NEe=s(loe);iVe=r(NEe,"data2vec-vision"),NEe.forEach(t),dVe=r(i3," \u2014 "),dk=n(i3,"A",{href:!0});var jEe=s(dk);cVe=r(jEe,"Data2VecVisionConfig"),jEe.forEach(t),fVe=r(i3," (Data2VecVision model)"),i3.forEach(t),mVe=i(L),Wf=n(L,"LI",{});var d3=s(Wf);ioe=n(d3,"STRONG",{});var DEe=s(ioe);gVe=r(DEe,"deberta"),DEe.forEach(t),hVe=r(d3," \u2014 "),ck=n(d3,"A",{href:!0});var GEe=s(ck);pVe=r(GEe,"DebertaConfig"),GEe.forEach(t),uVe=r(d3," (DeBERTa model)"),d3.forEach(t),_Ve=i(L),Hf=n(L,"LI",{});var c3=s(Hf);doe=n(c3,"STRONG",{});var OEe=s(doe);bVe=r(OEe,"deberta-v2"),OEe.forEach(t),vVe=r(c3," \u2014 "),fk=n(c3,"A",{href:!0});var VEe=s(fk);FVe=r(VEe,"DebertaV2Config"),VEe.forEach(t),TVe=r(c3," (DeBERTa-v2 model)"),c3.forEach(t),MVe=i(L),Uf=n(L,"LI",{});var f3=s(Uf);coe=n(f3,"STRONG",{});var XEe=s(coe);EVe=r(XEe,"decision_transformer"),XEe.forEach(t),CVe=r(f3," \u2014 "),mk=n(f3,"A",{href:!0});var zEe=s(mk);wVe=r(zEe,"DecisionTransformerConfig"),zEe.forEach(t),AVe=r(f3," (Decision Transformer model)"),f3.forEach(t),yVe=i(L),Jf=n(L,"LI",{});var m3=s(Jf);foe=n(m3,"STRONG",{});var QEe=s(foe);LVe=r(QEe,"deit"),QEe.forEach(t),xVe=r(m3," \u2014 "),gk=n(m3,"A",{href:!0});var WEe=s(gk);$Ve=r(WEe,"DeiTConfig"),WEe.forEach(t),kVe=r(m3," (DeiT model)"),m3.forEach(t),SVe=i(L),Yf=n(L,"LI",{});var g3=s(Yf);moe=n(g3,"STRONG",{});var HEe=s(moe);RVe=r(HEe,"detr"),HEe.forEach(t),PVe=r(g3," \u2014 "),hk=n(g3,"A",{href:!0});var UEe=s(hk);BVe=r(UEe,"DetrConfig"),UEe.forEach(t),IVe=r(g3," (DETR model)"),g3.forEach(t),qVe=i(L),Kf=n(L,"LI",{});var h3=s(Kf);goe=n(h3,"STRONG",{});var GDr=s(goe);NVe=r(GDr,"distilbert"),GDr.forEach(t),jVe=r(h3," \u2014 "),pk=n(h3,"A",{href:!0});var ODr=s(pk);DVe=r(ODr,"DistilBertConfig"),ODr.forEach(t),GVe=r(h3," (DistilBERT model)"),h3.forEach(t),OVe=i(L),Zf=n(L,"LI",{});var JEe=s(Zf);hoe=n(JEe,"STRONG",{});var VDr=s(hoe);VVe=r(VDr,"dpr"),VDr.forEach(t),XVe=r(JEe," \u2014 "),uk=n(JEe,"A",{href:!0});var XDr=s(uk);zVe=r(XDr,"DPRConfig"),XDr.forEach(t),QVe=r(JEe," (DPR model)"),JEe.forEach(t),WVe=i(L),em=n(L,"LI",{});var YEe=s(em);poe=n(YEe,"STRONG",{});var zDr=s(poe);HVe=r(zDr,"dpt"),zDr.forEach(t),UVe=r(YEe," \u2014 "),_k=n(YEe,"A",{href:!0});var QDr=s(_k);JVe=r(QDr,"DPTConfig"),QDr.forEach(t),YVe=r(YEe," (DPT model)"),YEe.forEach(t),KVe=i(L),om=n(L,"LI",{});var KEe=s(om);uoe=n(KEe,"STRONG",{});var WDr=s(uoe);ZVe=r(WDr,"electra"),WDr.forEach(t),eXe=r(KEe," \u2014 "),bk=n(KEe,"A",{href:!0});var HDr=s(bk);oXe=r(HDr,"ElectraConfig"),HDr.forEach(t),rXe=r(KEe," (ELECTRA model)"),KEe.forEach(t),tXe=i(L),rm=n(L,"LI",{});var ZEe=s(rm);_oe=n(ZEe,"STRONG",{});var UDr=s(_oe);aXe=r(UDr,"encoder-decoder"),UDr.forEach(t),nXe=r(ZEe," \u2014 "),vk=n(ZEe,"A",{href:!0});var JDr=s(vk);sXe=r(JDr,"EncoderDecoderConfig"),JDr.forEach(t),lXe=r(ZEe," (Encoder decoder model)"),ZEe.forEach(t),iXe=i(L),tm=n(L,"LI",{});var e5e=s(tm);boe=n(e5e,"STRONG",{});var YDr=s(boe);dXe=r(YDr,"flaubert"),YDr.forEach(t),cXe=r(e5e," \u2014 "),Fk=n(e5e,"A",{href:!0});var KDr=s(Fk);fXe=r(KDr,"FlaubertConfig"),KDr.forEach(t),mXe=r(e5e," (FlauBERT model)"),e5e.forEach(t),gXe=i(L),am=n(L,"LI",{});var o5e=s(am);voe=n(o5e,"STRONG",{});var ZDr=s(voe);hXe=r(ZDr,"flava"),ZDr.forEach(t),pXe=r(o5e," \u2014 "),Tk=n(o5e,"A",{href:!0});var eGr=s(Tk);uXe=r(eGr,"FlavaConfig"),eGr.forEach(t),_Xe=r(o5e," (Flava model)"),o5e.forEach(t),bXe=i(L),nm=n(L,"LI",{});var r5e=s(nm);Foe=n(r5e,"STRONG",{});var oGr=s(Foe);vXe=r(oGr,"fnet"),oGr.forEach(t),FXe=r(r5e," \u2014 "),Mk=n(r5e,"A",{href:!0});var rGr=s(Mk);TXe=r(rGr,"FNetConfig"),rGr.forEach(t),MXe=r(r5e," (FNet model)"),r5e.forEach(t),EXe=i(L),sm=n(L,"LI",{});var t5e=s(sm);Toe=n(t5e,"STRONG",{});var tGr=s(Toe);CXe=r(tGr,"fsmt"),tGr.forEach(t),wXe=r(t5e," \u2014 "),Ek=n(t5e,"A",{href:!0});var aGr=s(Ek);AXe=r(aGr,"FSMTConfig"),aGr.forEach(t),yXe=r(t5e," (FairSeq Machine-Translation model)"),t5e.forEach(t),LXe=i(L),lm=n(L,"LI",{});var a5e=s(lm);Moe=n(a5e,"STRONG",{});var nGr=s(Moe);xXe=r(nGr,"funnel"),nGr.forEach(t),$Xe=r(a5e," \u2014 "),Ck=n(a5e,"A",{href:!0});var sGr=s(Ck);kXe=r(sGr,"FunnelConfig"),sGr.forEach(t),SXe=r(a5e," (Funnel Transformer model)"),a5e.forEach(t),RXe=i(L),im=n(L,"LI",{});var n5e=s(im);Eoe=n(n5e,"STRONG",{});var lGr=s(Eoe);PXe=r(lGr,"glpn"),lGr.forEach(t),BXe=r(n5e," \u2014 "),wk=n(n5e,"A",{href:!0});var iGr=s(wk);IXe=r(iGr,"GLPNConfig"),iGr.forEach(t),qXe=r(n5e," (GLPN model)"),n5e.forEach(t),NXe=i(L),dm=n(L,"LI",{});var s5e=s(dm);Coe=n(s5e,"STRONG",{});var dGr=s(Coe);jXe=r(dGr,"gpt2"),dGr.forEach(t),DXe=r(s5e," \u2014 "),Ak=n(s5e,"A",{href:!0});var cGr=s(Ak);GXe=r(cGr,"GPT2Config"),cGr.forEach(t),OXe=r(s5e," (OpenAI GPT-2 model)"),s5e.forEach(t),VXe=i(L),cm=n(L,"LI",{});var l5e=s(cm);woe=n(l5e,"STRONG",{});var fGr=s(woe);XXe=r(fGr,"gpt_neo"),fGr.forEach(t),zXe=r(l5e," \u2014 "),yk=n(l5e,"A",{href:!0});var mGr=s(yk);QXe=r(mGr,"GPTNeoConfig"),mGr.forEach(t),WXe=r(l5e," (GPT Neo model)"),l5e.forEach(t),HXe=i(L),fm=n(L,"LI",{});var i5e=s(fm);Aoe=n(i5e,"STRONG",{});var gGr=s(Aoe);UXe=r(gGr,"gptj"),gGr.forEach(t),JXe=r(i5e," \u2014 "),Lk=n(i5e,"A",{href:!0});var hGr=s(Lk);YXe=r(hGr,"GPTJConfig"),hGr.forEach(t),KXe=r(i5e," (GPT-J model)"),i5e.forEach(t),ZXe=i(L),mm=n(L,"LI",{});var d5e=s(mm);yoe=n(d5e,"STRONG",{});var pGr=s(yoe);eze=r(pGr,"hubert"),pGr.forEach(t),oze=r(d5e," \u2014 "),xk=n(d5e,"A",{href:!0});var uGr=s(xk);rze=r(uGr,"HubertConfig"),uGr.forEach(t),tze=r(d5e," (Hubert model)"),d5e.forEach(t),aze=i(L),gm=n(L,"LI",{});var c5e=s(gm);Loe=n(c5e,"STRONG",{});var _Gr=s(Loe);nze=r(_Gr,"ibert"),_Gr.forEach(t),sze=r(c5e," \u2014 "),$k=n(c5e,"A",{href:!0});var bGr=s($k);lze=r(bGr,"IBertConfig"),bGr.forEach(t),ize=r(c5e," (I-BERT model)"),c5e.forEach(t),dze=i(L),hm=n(L,"LI",{});var f5e=s(hm);xoe=n(f5e,"STRONG",{});var vGr=s(xoe);cze=r(vGr,"imagegpt"),vGr.forEach(t),fze=r(f5e," \u2014 "),kk=n(f5e,"A",{href:!0});var FGr=s(kk);mze=r(FGr,"ImageGPTConfig"),FGr.forEach(t),gze=r(f5e," (ImageGPT model)"),f5e.forEach(t),hze=i(L),pm=n(L,"LI",{});var m5e=s(pm);$oe=n(m5e,"STRONG",{});var TGr=s($oe);pze=r(TGr,"layoutlm"),TGr.forEach(t),uze=r(m5e," \u2014 "),Sk=n(m5e,"A",{href:!0});var MGr=s(Sk);_ze=r(MGr,"LayoutLMConfig"),MGr.forEach(t),bze=r(m5e," (LayoutLM model)"),m5e.forEach(t),vze=i(L),um=n(L,"LI",{});var g5e=s(um);koe=n(g5e,"STRONG",{});var EGr=s(koe);Fze=r(EGr,"layoutlmv2"),EGr.forEach(t),Tze=r(g5e," \u2014 "),Rk=n(g5e,"A",{href:!0});var CGr=s(Rk);Mze=r(CGr,"LayoutLMv2Config"),CGr.forEach(t),Eze=r(g5e," (LayoutLMv2 model)"),g5e.forEach(t),Cze=i(L),_m=n(L,"LI",{});var h5e=s(_m);Soe=n(h5e,"STRONG",{});var wGr=s(Soe);wze=r(wGr,"led"),wGr.forEach(t),Aze=r(h5e," \u2014 "),Pk=n(h5e,"A",{href:!0});var AGr=s(Pk);yze=r(AGr,"LEDConfig"),AGr.forEach(t),Lze=r(h5e," (LED model)"),h5e.forEach(t),xze=i(L),bm=n(L,"LI",{});var p5e=s(bm);Roe=n(p5e,"STRONG",{});var yGr=s(Roe);$ze=r(yGr,"longformer"),yGr.forEach(t),kze=r(p5e," \u2014 "),Bk=n(p5e,"A",{href:!0});var LGr=s(Bk);Sze=r(LGr,"LongformerConfig"),LGr.forEach(t),Rze=r(p5e," (Longformer model)"),p5e.forEach(t),Pze=i(L),vm=n(L,"LI",{});var u5e=s(vm);Poe=n(u5e,"STRONG",{});var xGr=s(Poe);Bze=r(xGr,"luke"),xGr.forEach(t),Ize=r(u5e," \u2014 "),Ik=n(u5e,"A",{href:!0});var $Gr=s(Ik);qze=r($Gr,"LukeConfig"),$Gr.forEach(t),Nze=r(u5e," (LUKE model)"),u5e.forEach(t),jze=i(L),Fm=n(L,"LI",{});var _5e=s(Fm);Boe=n(_5e,"STRONG",{});var kGr=s(Boe);Dze=r(kGr,"lxmert"),kGr.forEach(t),Gze=r(_5e," \u2014 "),qk=n(_5e,"A",{href:!0});var SGr=s(qk);Oze=r(SGr,"LxmertConfig"),SGr.forEach(t),Vze=r(_5e," (LXMERT model)"),_5e.forEach(t),Xze=i(L),Tm=n(L,"LI",{});var b5e=s(Tm);Ioe=n(b5e,"STRONG",{});var RGr=s(Ioe);zze=r(RGr,"m2m_100"),RGr.forEach(t),Qze=r(b5e," \u2014 "),Nk=n(b5e,"A",{href:!0});var PGr=s(Nk);Wze=r(PGr,"M2M100Config"),PGr.forEach(t),Hze=r(b5e," (M2M100 model)"),b5e.forEach(t),Uze=i(L),Mm=n(L,"LI",{});var v5e=s(Mm);qoe=n(v5e,"STRONG",{});var BGr=s(qoe);Jze=r(BGr,"marian"),BGr.forEach(t),Yze=r(v5e," \u2014 "),jk=n(v5e,"A",{href:!0});var IGr=s(jk);Kze=r(IGr,"MarianConfig"),IGr.forEach(t),Zze=r(v5e," (Marian model)"),v5e.forEach(t),eQe=i(L),Em=n(L,"LI",{});var F5e=s(Em);Noe=n(F5e,"STRONG",{});var qGr=s(Noe);oQe=r(qGr,"maskformer"),qGr.forEach(t),rQe=r(F5e," \u2014 "),Dk=n(F5e,"A",{href:!0});var NGr=s(Dk);tQe=r(NGr,"MaskFormerConfig"),NGr.forEach(t),aQe=r(F5e," (MaskFormer model)"),F5e.forEach(t),nQe=i(L),Cm=n(L,"LI",{});var T5e=s(Cm);joe=n(T5e,"STRONG",{});var jGr=s(joe);sQe=r(jGr,"mbart"),jGr.forEach(t),lQe=r(T5e," \u2014 "),Gk=n(T5e,"A",{href:!0});var DGr=s(Gk);iQe=r(DGr,"MBartConfig"),DGr.forEach(t),dQe=r(T5e," (mBART model)"),T5e.forEach(t),cQe=i(L),wm=n(L,"LI",{});var M5e=s(wm);Doe=n(M5e,"STRONG",{});var GGr=s(Doe);fQe=r(GGr,"megatron-bert"),GGr.forEach(t),mQe=r(M5e," \u2014 "),Ok=n(M5e,"A",{href:!0});var OGr=s(Ok);gQe=r(OGr,"MegatronBertConfig"),OGr.forEach(t),hQe=r(M5e," (MegatronBert model)"),M5e.forEach(t),pQe=i(L),Am=n(L,"LI",{});var E5e=s(Am);Goe=n(E5e,"STRONG",{});var VGr=s(Goe);uQe=r(VGr,"mobilebert"),VGr.forEach(t),_Qe=r(E5e," \u2014 "),Vk=n(E5e,"A",{href:!0});var XGr=s(Vk);bQe=r(XGr,"MobileBertConfig"),XGr.forEach(t),vQe=r(E5e," (MobileBERT model)"),E5e.forEach(t),FQe=i(L),ym=n(L,"LI",{});var C5e=s(ym);Ooe=n(C5e,"STRONG",{});var zGr=s(Ooe);TQe=r(zGr,"mpnet"),zGr.forEach(t),MQe=r(C5e," \u2014 "),Xk=n(C5e,"A",{href:!0});var QGr=s(Xk);EQe=r(QGr,"MPNetConfig"),QGr.forEach(t),CQe=r(C5e," (MPNet model)"),C5e.forEach(t),wQe=i(L),Lm=n(L,"LI",{});var w5e=s(Lm);Voe=n(w5e,"STRONG",{});var WGr=s(Voe);AQe=r(WGr,"mt5"),WGr.forEach(t),yQe=r(w5e," \u2014 "),zk=n(w5e,"A",{href:!0});var HGr=s(zk);LQe=r(HGr,"MT5Config"),HGr.forEach(t),xQe=r(w5e," (mT5 model)"),w5e.forEach(t),$Qe=i(L),xm=n(L,"LI",{});var A5e=s(xm);Xoe=n(A5e,"STRONG",{});var UGr=s(Xoe);kQe=r(UGr,"nystromformer"),UGr.forEach(t),SQe=r(A5e," \u2014 "),Qk=n(A5e,"A",{href:!0});var JGr=s(Qk);RQe=r(JGr,"NystromformerConfig"),JGr.forEach(t),PQe=r(A5e," (Nystromformer model)"),A5e.forEach(t),BQe=i(L),$m=n(L,"LI",{});var y5e=s($m);zoe=n(y5e,"STRONG",{});var YGr=s(zoe);IQe=r(YGr,"openai-gpt"),YGr.forEach(t),qQe=r(y5e," \u2014 "),Wk=n(y5e,"A",{href:!0});var KGr=s(Wk);NQe=r(KGr,"OpenAIGPTConfig"),KGr.forEach(t),jQe=r(y5e," (OpenAI GPT model)"),y5e.forEach(t),DQe=i(L),km=n(L,"LI",{});var L5e=s(km);Qoe=n(L5e,"STRONG",{});var ZGr=s(Qoe);GQe=r(ZGr,"opt"),ZGr.forEach(t),OQe=r(L5e," \u2014 "),Hk=n(L5e,"A",{href:!0});var eOr=s(Hk);VQe=r(eOr,"OPTConfig"),eOr.forEach(t),XQe=r(L5e," (OPT model)"),L5e.forEach(t),zQe=i(L),Sm=n(L,"LI",{});var x5e=s(Sm);Woe=n(x5e,"STRONG",{});var oOr=s(Woe);QQe=r(oOr,"pegasus"),oOr.forEach(t),WQe=r(x5e," \u2014 "),Uk=n(x5e,"A",{href:!0});var rOr=s(Uk);HQe=r(rOr,"PegasusConfig"),rOr.forEach(t),UQe=r(x5e," (Pegasus model)"),x5e.forEach(t),JQe=i(L),Rm=n(L,"LI",{});var $5e=s(Rm);Hoe=n($5e,"STRONG",{});var tOr=s(Hoe);YQe=r(tOr,"perceiver"),tOr.forEach(t),KQe=r($5e," \u2014 "),Jk=n($5e,"A",{href:!0});var aOr=s(Jk);ZQe=r(aOr,"PerceiverConfig"),aOr.forEach(t),eWe=r($5e," (Perceiver model)"),$5e.forEach(t),oWe=i(L),Pm=n(L,"LI",{});var k5e=s(Pm);Uoe=n(k5e,"STRONG",{});var nOr=s(Uoe);rWe=r(nOr,"plbart"),nOr.forEach(t),tWe=r(k5e," \u2014 "),Yk=n(k5e,"A",{href:!0});var sOr=s(Yk);aWe=r(sOr,"PLBartConfig"),sOr.forEach(t),nWe=r(k5e," (PLBart model)"),k5e.forEach(t),sWe=i(L),Bm=n(L,"LI",{});var S5e=s(Bm);Joe=n(S5e,"STRONG",{});var lOr=s(Joe);lWe=r(lOr,"poolformer"),lOr.forEach(t),iWe=r(S5e," \u2014 "),Kk=n(S5e,"A",{href:!0});var iOr=s(Kk);dWe=r(iOr,"PoolFormerConfig"),iOr.forEach(t),cWe=r(S5e," (PoolFormer model)"),S5e.forEach(t),fWe=i(L),Im=n(L,"LI",{});var R5e=s(Im);Yoe=n(R5e,"STRONG",{});var dOr=s(Yoe);mWe=r(dOr,"prophetnet"),dOr.forEach(t),gWe=r(R5e," \u2014 "),Zk=n(R5e,"A",{href:!0});var cOr=s(Zk);hWe=r(cOr,"ProphetNetConfig"),cOr.forEach(t),pWe=r(R5e," (ProphetNet model)"),R5e.forEach(t),uWe=i(L),qm=n(L,"LI",{});var P5e=s(qm);Koe=n(P5e,"STRONG",{});var fOr=s(Koe);_We=r(fOr,"qdqbert"),fOr.forEach(t),bWe=r(P5e," \u2014 "),eS=n(P5e,"A",{href:!0});var mOr=s(eS);vWe=r(mOr,"QDQBertConfig"),mOr.forEach(t),FWe=r(P5e," (QDQBert model)"),P5e.forEach(t),TWe=i(L),Nm=n(L,"LI",{});var B5e=s(Nm);Zoe=n(B5e,"STRONG",{});var gOr=s(Zoe);MWe=r(gOr,"rag"),gOr.forEach(t),EWe=r(B5e," \u2014 "),oS=n(B5e,"A",{href:!0});var hOr=s(oS);CWe=r(hOr,"RagConfig"),hOr.forEach(t),wWe=r(B5e," (RAG model)"),B5e.forEach(t),AWe=i(L),jm=n(L,"LI",{});var I5e=s(jm);ere=n(I5e,"STRONG",{});var pOr=s(ere);yWe=r(pOr,"realm"),pOr.forEach(t),LWe=r(I5e," \u2014 "),rS=n(I5e,"A",{href:!0});var uOr=s(rS);xWe=r(uOr,"RealmConfig"),uOr.forEach(t),$We=r(I5e," (Realm model)"),I5e.forEach(t),kWe=i(L),Dm=n(L,"LI",{});var q5e=s(Dm);ore=n(q5e,"STRONG",{});var _Or=s(ore);SWe=r(_Or,"reformer"),_Or.forEach(t),RWe=r(q5e," \u2014 "),tS=n(q5e,"A",{href:!0});var bOr=s(tS);PWe=r(bOr,"ReformerConfig"),bOr.forEach(t),BWe=r(q5e," (Reformer model)"),q5e.forEach(t),IWe=i(L),Gm=n(L,"LI",{});var N5e=s(Gm);rre=n(N5e,"STRONG",{});var vOr=s(rre);qWe=r(vOr,"regnet"),vOr.forEach(t),NWe=r(N5e," \u2014 "),aS=n(N5e,"A",{href:!0});var FOr=s(aS);jWe=r(FOr,"RegNetConfig"),FOr.forEach(t),DWe=r(N5e," (RegNet model)"),N5e.forEach(t),GWe=i(L),Om=n(L,"LI",{});var j5e=s(Om);tre=n(j5e,"STRONG",{});var TOr=s(tre);OWe=r(TOr,"rembert"),TOr.forEach(t),VWe=r(j5e," \u2014 "),nS=n(j5e,"A",{href:!0});var MOr=s(nS);XWe=r(MOr,"RemBertConfig"),MOr.forEach(t),zWe=r(j5e," (RemBERT model)"),j5e.forEach(t),QWe=i(L),Vm=n(L,"LI",{});var D5e=s(Vm);are=n(D5e,"STRONG",{});var EOr=s(are);WWe=r(EOr,"resnet"),EOr.forEach(t),HWe=r(D5e," \u2014 "),sS=n(D5e,"A",{href:!0});var COr=s(sS);UWe=r(COr,"ResNetConfig"),COr.forEach(t),JWe=r(D5e," (ResNet model)"),D5e.forEach(t),YWe=i(L),Xm=n(L,"LI",{});var G5e=s(Xm);nre=n(G5e,"STRONG",{});var wOr=s(nre);KWe=r(wOr,"retribert"),wOr.forEach(t),ZWe=r(G5e," \u2014 "),lS=n(G5e,"A",{href:!0});var AOr=s(lS);eHe=r(AOr,"RetriBertConfig"),AOr.forEach(t),oHe=r(G5e," (RetriBERT model)"),G5e.forEach(t),rHe=i(L),zm=n(L,"LI",{});var O5e=s(zm);sre=n(O5e,"STRONG",{});var yOr=s(sre);tHe=r(yOr,"roberta"),yOr.forEach(t),aHe=r(O5e," \u2014 "),iS=n(O5e,"A",{href:!0});var LOr=s(iS);nHe=r(LOr,"RobertaConfig"),LOr.forEach(t),sHe=r(O5e," (RoBERTa model)"),O5e.forEach(t),lHe=i(L),Qm=n(L,"LI",{});var V5e=s(Qm);lre=n(V5e,"STRONG",{});var xOr=s(lre);iHe=r(xOr,"roformer"),xOr.forEach(t),dHe=r(V5e," \u2014 "),dS=n(V5e,"A",{href:!0});var $Or=s(dS);cHe=r($Or,"RoFormerConfig"),$Or.forEach(t),fHe=r(V5e," (RoFormer model)"),V5e.forEach(t),mHe=i(L),Wm=n(L,"LI",{});var X5e=s(Wm);ire=n(X5e,"STRONG",{});var kOr=s(ire);gHe=r(kOr,"segformer"),kOr.forEach(t),hHe=r(X5e," \u2014 "),cS=n(X5e,"A",{href:!0});var SOr=s(cS);pHe=r(SOr,"SegformerConfig"),SOr.forEach(t),uHe=r(X5e," (SegFormer model)"),X5e.forEach(t),_He=i(L),Hm=n(L,"LI",{});var z5e=s(Hm);dre=n(z5e,"STRONG",{});var ROr=s(dre);bHe=r(ROr,"sew"),ROr.forEach(t),vHe=r(z5e," \u2014 "),fS=n(z5e,"A",{href:!0});var POr=s(fS);FHe=r(POr,"SEWConfig"),POr.forEach(t),THe=r(z5e," (SEW model)"),z5e.forEach(t),MHe=i(L),Um=n(L,"LI",{});var Q5e=s(Um);cre=n(Q5e,"STRONG",{});var BOr=s(cre);EHe=r(BOr,"sew-d"),BOr.forEach(t),CHe=r(Q5e," \u2014 "),mS=n(Q5e,"A",{href:!0});var IOr=s(mS);wHe=r(IOr,"SEWDConfig"),IOr.forEach(t),AHe=r(Q5e," (SEW-D model)"),Q5e.forEach(t),yHe=i(L),Jm=n(L,"LI",{});var W5e=s(Jm);fre=n(W5e,"STRONG",{});var qOr=s(fre);LHe=r(qOr,"speech-encoder-decoder"),qOr.forEach(t),xHe=r(W5e," \u2014 "),gS=n(W5e,"A",{href:!0});var NOr=s(gS);$He=r(NOr,"SpeechEncoderDecoderConfig"),NOr.forEach(t),kHe=r(W5e," (Speech Encoder decoder model)"),W5e.forEach(t),SHe=i(L),Ym=n(L,"LI",{});var H5e=s(Ym);mre=n(H5e,"STRONG",{});var jOr=s(mre);RHe=r(jOr,"speech_to_text"),jOr.forEach(t),PHe=r(H5e," \u2014 "),hS=n(H5e,"A",{href:!0});var DOr=s(hS);BHe=r(DOr,"Speech2TextConfig"),DOr.forEach(t),IHe=r(H5e," (Speech2Text model)"),H5e.forEach(t),qHe=i(L),Km=n(L,"LI",{});var U5e=s(Km);gre=n(U5e,"STRONG",{});var GOr=s(gre);NHe=r(GOr,"speech_to_text_2"),GOr.forEach(t),jHe=r(U5e," \u2014 "),pS=n(U5e,"A",{href:!0});var OOr=s(pS);DHe=r(OOr,"Speech2Text2Config"),OOr.forEach(t),GHe=r(U5e," (Speech2Text2 model)"),U5e.forEach(t),OHe=i(L),Zm=n(L,"LI",{});var J5e=s(Zm);hre=n(J5e,"STRONG",{});var VOr=s(hre);VHe=r(VOr,"splinter"),VOr.forEach(t),XHe=r(J5e," \u2014 "),uS=n(J5e,"A",{href:!0});var XOr=s(uS);zHe=r(XOr,"SplinterConfig"),XOr.forEach(t),QHe=r(J5e," (Splinter model)"),J5e.forEach(t),WHe=i(L),eg=n(L,"LI",{});var Y5e=s(eg);pre=n(Y5e,"STRONG",{});var zOr=s(pre);HHe=r(zOr,"squeezebert"),zOr.forEach(t),UHe=r(Y5e," \u2014 "),_S=n(Y5e,"A",{href:!0});var QOr=s(_S);JHe=r(QOr,"SqueezeBertConfig"),QOr.forEach(t),YHe=r(Y5e," (SqueezeBERT model)"),Y5e.forEach(t),KHe=i(L),og=n(L,"LI",{});var K5e=s(og);ure=n(K5e,"STRONG",{});var WOr=s(ure);ZHe=r(WOr,"swin"),WOr.forEach(t),eUe=r(K5e," \u2014 "),bS=n(K5e,"A",{href:!0});var HOr=s(bS);oUe=r(HOr,"SwinConfig"),HOr.forEach(t),rUe=r(K5e," (Swin model)"),K5e.forEach(t),tUe=i(L),rg=n(L,"LI",{});var Z5e=s(rg);_re=n(Z5e,"STRONG",{});var UOr=s(_re);aUe=r(UOr,"t5"),UOr.forEach(t),nUe=r(Z5e," \u2014 "),vS=n(Z5e,"A",{href:!0});var JOr=s(vS);sUe=r(JOr,"T5Config"),JOr.forEach(t),lUe=r(Z5e," (T5 model)"),Z5e.forEach(t),iUe=i(L),tg=n(L,"LI",{});var eCe=s(tg);bre=n(eCe,"STRONG",{});var YOr=s(bre);dUe=r(YOr,"tapas"),YOr.forEach(t),cUe=r(eCe," \u2014 "),FS=n(eCe,"A",{href:!0});var KOr=s(FS);fUe=r(KOr,"TapasConfig"),KOr.forEach(t),mUe=r(eCe," (TAPAS model)"),eCe.forEach(t),gUe=i(L),ag=n(L,"LI",{});var oCe=s(ag);vre=n(oCe,"STRONG",{});var ZOr=s(vre);hUe=r(ZOr,"tapex"),ZOr.forEach(t),pUe=r(oCe," \u2014 "),TS=n(oCe,"A",{href:!0});var eVr=s(TS);uUe=r(eVr,"BartConfig"),eVr.forEach(t),_Ue=r(oCe," (TAPEX model)"),oCe.forEach(t),bUe=i(L),ng=n(L,"LI",{});var rCe=s(ng);Fre=n(rCe,"STRONG",{});var oVr=s(Fre);vUe=r(oVr,"transfo-xl"),oVr.forEach(t),FUe=r(rCe," \u2014 "),MS=n(rCe,"A",{href:!0});var rVr=s(MS);TUe=r(rVr,"TransfoXLConfig"),rVr.forEach(t),MUe=r(rCe," (Transformer-XL model)"),rCe.forEach(t),EUe=i(L),sg=n(L,"LI",{});var tCe=s(sg);Tre=n(tCe,"STRONG",{});var tVr=s(Tre);CUe=r(tVr,"trocr"),tVr.forEach(t),wUe=r(tCe," \u2014 "),ES=n(tCe,"A",{href:!0});var aVr=s(ES);AUe=r(aVr,"TrOCRConfig"),aVr.forEach(t),yUe=r(tCe," (TrOCR model)"),tCe.forEach(t),LUe=i(L),lg=n(L,"LI",{});var aCe=s(lg);Mre=n(aCe,"STRONG",{});var nVr=s(Mre);xUe=r(nVr,"unispeech"),nVr.forEach(t),$Ue=r(aCe," \u2014 "),CS=n(aCe,"A",{href:!0});var sVr=s(CS);kUe=r(sVr,"UniSpeechConfig"),sVr.forEach(t),SUe=r(aCe," (UniSpeech model)"),aCe.forEach(t),RUe=i(L),ig=n(L,"LI",{});var nCe=s(ig);Ere=n(nCe,"STRONG",{});var lVr=s(Ere);PUe=r(lVr,"unispeech-sat"),lVr.forEach(t),BUe=r(nCe," \u2014 "),wS=n(nCe,"A",{href:!0});var iVr=s(wS);IUe=r(iVr,"UniSpeechSatConfig"),iVr.forEach(t),qUe=r(nCe," (UniSpeechSat model)"),nCe.forEach(t),NUe=i(L),dg=n(L,"LI",{});var sCe=s(dg);Cre=n(sCe,"STRONG",{});var dVr=s(Cre);jUe=r(dVr,"van"),dVr.forEach(t),DUe=r(sCe," \u2014 "),AS=n(sCe,"A",{href:!0});var cVr=s(AS);GUe=r(cVr,"VanConfig"),cVr.forEach(t),OUe=r(sCe," (VAN model)"),sCe.forEach(t),VUe=i(L),cg=n(L,"LI",{});var lCe=s(cg);wre=n(lCe,"STRONG",{});var fVr=s(wre);XUe=r(fVr,"vilt"),fVr.forEach(t),zUe=r(lCe," \u2014 "),yS=n(lCe,"A",{href:!0});var mVr=s(yS);QUe=r(mVr,"ViltConfig"),mVr.forEach(t),WUe=r(lCe," (ViLT model)"),lCe.forEach(t),HUe=i(L),fg=n(L,"LI",{});var iCe=s(fg);Are=n(iCe,"STRONG",{});var gVr=s(Are);UUe=r(gVr,"vision-encoder-decoder"),gVr.forEach(t),JUe=r(iCe," \u2014 "),LS=n(iCe,"A",{href:!0});var hVr=s(LS);YUe=r(hVr,"VisionEncoderDecoderConfig"),hVr.forEach(t),KUe=r(iCe," (Vision Encoder decoder model)"),iCe.forEach(t),ZUe=i(L),mg=n(L,"LI",{});var dCe=s(mg);yre=n(dCe,"STRONG",{});var pVr=s(yre);eJe=r(pVr,"vision-text-dual-encoder"),pVr.forEach(t),oJe=r(dCe," \u2014 "),xS=n(dCe,"A",{href:!0});var uVr=s(xS);rJe=r(uVr,"VisionTextDualEncoderConfig"),uVr.forEach(t),tJe=r(dCe," (VisionTextDualEncoder model)"),dCe.forEach(t),aJe=i(L),gg=n(L,"LI",{});var cCe=s(gg);Lre=n(cCe,"STRONG",{});var _Vr=s(Lre);nJe=r(_Vr,"visual_bert"),_Vr.forEach(t),sJe=r(cCe," \u2014 "),$S=n(cCe,"A",{href:!0});var bVr=s($S);lJe=r(bVr,"VisualBertConfig"),bVr.forEach(t),iJe=r(cCe," (VisualBert model)"),cCe.forEach(t),dJe=i(L),hg=n(L,"LI",{});var fCe=s(hg);xre=n(fCe,"STRONG",{});var vVr=s(xre);cJe=r(vVr,"vit"),vVr.forEach(t),fJe=r(fCe," \u2014 "),kS=n(fCe,"A",{href:!0});var FVr=s(kS);mJe=r(FVr,"ViTConfig"),FVr.forEach(t),gJe=r(fCe," (ViT model)"),fCe.forEach(t),hJe=i(L),pg=n(L,"LI",{});var mCe=s(pg);$re=n(mCe,"STRONG",{});var TVr=s($re);pJe=r(TVr,"vit_mae"),TVr.forEach(t),uJe=r(mCe," \u2014 "),SS=n(mCe,"A",{href:!0});var MVr=s(SS);_Je=r(MVr,"ViTMAEConfig"),MVr.forEach(t),bJe=r(mCe," (ViTMAE model)"),mCe.forEach(t),vJe=i(L),ug=n(L,"LI",{});var gCe=s(ug);kre=n(gCe,"STRONG",{});var EVr=s(kre);FJe=r(EVr,"wav2vec2"),EVr.forEach(t),TJe=r(gCe," \u2014 "),RS=n(gCe,"A",{href:!0});var CVr=s(RS);MJe=r(CVr,"Wav2Vec2Config"),CVr.forEach(t),EJe=r(gCe," (Wav2Vec2 model)"),gCe.forEach(t),CJe=i(L),_g=n(L,"LI",{});var hCe=s(_g);Sre=n(hCe,"STRONG",{});var wVr=s(Sre);wJe=r(wVr,"wavlm"),wVr.forEach(t),AJe=r(hCe," \u2014 "),PS=n(hCe,"A",{href:!0});var AVr=s(PS);yJe=r(AVr,"WavLMConfig"),AVr.forEach(t),LJe=r(hCe," (WavLM model)"),hCe.forEach(t),xJe=i(L),bg=n(L,"LI",{});var pCe=s(bg);Rre=n(pCe,"STRONG",{});var yVr=s(Rre);$Je=r(yVr,"xglm"),yVr.forEach(t),kJe=r(pCe," \u2014 "),BS=n(pCe,"A",{href:!0});var LVr=s(BS);SJe=r(LVr,"XGLMConfig"),LVr.forEach(t),RJe=r(pCe," (XGLM model)"),pCe.forEach(t),PJe=i(L),vg=n(L,"LI",{});var uCe=s(vg);Pre=n(uCe,"STRONG",{});var xVr=s(Pre);BJe=r(xVr,"xlm"),xVr.forEach(t),IJe=r(uCe," \u2014 "),IS=n(uCe,"A",{href:!0});var $Vr=s(IS);qJe=r($Vr,"XLMConfig"),$Vr.forEach(t),NJe=r(uCe," (XLM model)"),uCe.forEach(t),jJe=i(L),Fg=n(L,"LI",{});var _Ce=s(Fg);Bre=n(_Ce,"STRONG",{});var kVr=s(Bre);DJe=r(kVr,"xlm-prophetnet"),kVr.forEach(t),GJe=r(_Ce," \u2014 "),qS=n(_Ce,"A",{href:!0});var SVr=s(qS);OJe=r(SVr,"XLMProphetNetConfig"),SVr.forEach(t),VJe=r(_Ce," (XLMProphetNet model)"),_Ce.forEach(t),XJe=i(L),Tg=n(L,"LI",{});var bCe=s(Tg);Ire=n(bCe,"STRONG",{});var RVr=s(Ire);zJe=r(RVr,"xlm-roberta"),RVr.forEach(t),QJe=r(bCe," \u2014 "),NS=n(bCe,"A",{href:!0});var PVr=s(NS);WJe=r(PVr,"XLMRobertaConfig"),PVr.forEach(t),HJe=r(bCe," (XLM-RoBERTa model)"),bCe.forEach(t),UJe=i(L),Mg=n(L,"LI",{});var vCe=s(Mg);qre=n(vCe,"STRONG",{});var BVr=s(qre);JJe=r(BVr,"xlm-roberta-xl"),BVr.forEach(t),YJe=r(vCe," \u2014 "),jS=n(vCe,"A",{href:!0});var IVr=s(jS);KJe=r(IVr,"XLMRobertaXLConfig"),IVr.forEach(t),ZJe=r(vCe," (XLM-RoBERTa-XL model)"),vCe.forEach(t),eYe=i(L),Eg=n(L,"LI",{});var FCe=s(Eg);Nre=n(FCe,"STRONG",{});var qVr=s(Nre);oYe=r(qVr,"xlnet"),qVr.forEach(t),rYe=r(FCe," \u2014 "),DS=n(FCe,"A",{href:!0});var NVr=s(DS);tYe=r(NVr,"XLNetConfig"),NVr.forEach(t),aYe=r(FCe," (XLNet model)"),FCe.forEach(t),nYe=i(L),Cg=n(L,"LI",{});var TCe=s(Cg);jre=n(TCe,"STRONG",{});var jVr=s(jre);sYe=r(jVr,"yolos"),jVr.forEach(t),lYe=r(TCe," \u2014 "),GS=n(TCe,"A",{href:!0});var DVr=s(GS);iYe=r(DVr,"YolosConfig"),DVr.forEach(t),dYe=r(TCe," (YOLOS model)"),TCe.forEach(t),cYe=i(L),wg=n(L,"LI",{});var MCe=s(wg);Dre=n(MCe,"STRONG",{});var GVr=s(Dre);fYe=r(GVr,"yoso"),GVr.forEach(t),mYe=r(MCe," \u2014 "),OS=n(MCe,"A",{href:!0});var OVr=s(OS);gYe=r(OVr,"YosoConfig"),OVr.forEach(t),hYe=r(MCe," (YOSO model)"),MCe.forEach(t),L.forEach(t),pYe=i(ot),T(Ag.$$.fragment,ot),ot.forEach(t),uYe=i(et),yg=n(et,"DIV",{class:!0});var WNe=s(yg);T(EA.$$.fragment,WNe),_Ye=i(WNe),Gre=n(WNe,"P",{});var VVr=s(Gre);bYe=r(VVr,"Register a new configuration for this class."),VVr.forEach(t),WNe.forEach(t),et.forEach(t),HIe=i(f),Ci=n(f,"H2",{class:!0});var HNe=s(Ci);Lg=n(HNe,"A",{id:!0,class:!0,href:!0});var XVr=s(Lg);Ore=n(XVr,"SPAN",{});var zVr=s(Ore);T(CA.$$.fragment,zVr),zVr.forEach(t),XVr.forEach(t),vYe=i(HNe),Vre=n(HNe,"SPAN",{});var QVr=s(Vre);FYe=r(QVr,"AutoTokenizer"),QVr.forEach(t),HNe.forEach(t),UIe=i(f),Ao=n(f,"DIV",{class:!0});var Gs=s(Ao);T(wA.$$.fragment,Gs),TYe=i(Gs),AA=n(Gs,"P",{});var UNe=s(AA);MYe=r(UNe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),VS=n(UNe,"A",{href:!0});var WVr=s(VS);EYe=r(WVr,"AutoTokenizer.from_pretrained()"),WVr.forEach(t),CYe=r(UNe," class method."),UNe.forEach(t),wYe=i(Gs),yA=n(Gs,"P",{});var JNe=s(yA);AYe=r(JNe,"This class cannot be instantiated directly using "),Xre=n(JNe,"CODE",{});var HVr=s(Xre);yYe=r(HVr,"__init__()"),HVr.forEach(t),LYe=r(JNe," (throws an error)."),JNe.forEach(t),xYe=i(Gs),Ar=n(Gs,"DIV",{class:!0});var Os=s(Ar);T(LA.$$.fragment,Os),$Ye=i(Os),zre=n(Os,"P",{});var UVr=s(zre);kYe=r(UVr,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),UVr.forEach(t),SYe=i(Os),La=n(Os,"P",{});var p3=s(La);RYe=r(p3,"The tokenizer class to instantiate is selected based on the "),Qre=n(p3,"CODE",{});var JVr=s(Qre);PYe=r(JVr,"model_type"),JVr.forEach(t),BYe=r(p3,` property of the config object (either
passed as an argument or loaded from `),Wre=n(p3,"CODE",{});var YVr=s(Wre);IYe=r(YVr,"pretrained_model_name_or_path"),YVr.forEach(t),qYe=r(p3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hre=n(p3,"CODE",{});var KVr=s(Hre);NYe=r(KVr,"pretrained_model_name_or_path"),KVr.forEach(t),jYe=r(p3,":"),p3.forEach(t),DYe=i(Os),k=n(Os,"UL",{});var S=s(k);In=n(S,"LI",{});var P9=s(In);Ure=n(P9,"STRONG",{});var ZVr=s(Ure);GYe=r(ZVr,"albert"),ZVr.forEach(t),OYe=r(P9," \u2014 "),XS=n(P9,"A",{href:!0});var eXr=s(XS);VYe=r(eXr,"AlbertTokenizer"),eXr.forEach(t),XYe=r(P9," or "),zS=n(P9,"A",{href:!0});var oXr=s(zS);zYe=r(oXr,"AlbertTokenizerFast"),oXr.forEach(t),QYe=r(P9," (ALBERT model)"),P9.forEach(t),WYe=i(S),qn=n(S,"LI",{});var B9=s(qn);Jre=n(B9,"STRONG",{});var rXr=s(Jre);HYe=r(rXr,"bart"),rXr.forEach(t),UYe=r(B9," \u2014 "),QS=n(B9,"A",{href:!0});var tXr=s(QS);JYe=r(tXr,"BartTokenizer"),tXr.forEach(t),YYe=r(B9," or "),WS=n(B9,"A",{href:!0});var aXr=s(WS);KYe=r(aXr,"BartTokenizerFast"),aXr.forEach(t),ZYe=r(B9," (BART model)"),B9.forEach(t),eKe=i(S),Nn=n(S,"LI",{});var I9=s(Nn);Yre=n(I9,"STRONG",{});var nXr=s(Yre);oKe=r(nXr,"barthez"),nXr.forEach(t),rKe=r(I9," \u2014 "),HS=n(I9,"A",{href:!0});var sXr=s(HS);tKe=r(sXr,"BarthezTokenizer"),sXr.forEach(t),aKe=r(I9," or "),US=n(I9,"A",{href:!0});var lXr=s(US);nKe=r(lXr,"BarthezTokenizerFast"),lXr.forEach(t),sKe=r(I9," (BARThez model)"),I9.forEach(t),lKe=i(S),xg=n(S,"LI",{});var ECe=s(xg);Kre=n(ECe,"STRONG",{});var iXr=s(Kre);iKe=r(iXr,"bartpho"),iXr.forEach(t),dKe=r(ECe," \u2014 "),JS=n(ECe,"A",{href:!0});var dXr=s(JS);cKe=r(dXr,"BartphoTokenizer"),dXr.forEach(t),fKe=r(ECe," (BARTpho model)"),ECe.forEach(t),mKe=i(S),jn=n(S,"LI",{});var q9=s(jn);Zre=n(q9,"STRONG",{});var cXr=s(Zre);gKe=r(cXr,"bert"),cXr.forEach(t),hKe=r(q9," \u2014 "),YS=n(q9,"A",{href:!0});var fXr=s(YS);pKe=r(fXr,"BertTokenizer"),fXr.forEach(t),uKe=r(q9," or "),KS=n(q9,"A",{href:!0});var mXr=s(KS);_Ke=r(mXr,"BertTokenizerFast"),mXr.forEach(t),bKe=r(q9," (BERT model)"),q9.forEach(t),vKe=i(S),$g=n(S,"LI",{});var CCe=s($g);ete=n(CCe,"STRONG",{});var gXr=s(ete);FKe=r(gXr,"bert-generation"),gXr.forEach(t),TKe=r(CCe," \u2014 "),ZS=n(CCe,"A",{href:!0});var hXr=s(ZS);MKe=r(hXr,"BertGenerationTokenizer"),hXr.forEach(t),EKe=r(CCe," (Bert Generation model)"),CCe.forEach(t),CKe=i(S),kg=n(S,"LI",{});var wCe=s(kg);ote=n(wCe,"STRONG",{});var pXr=s(ote);wKe=r(pXr,"bert-japanese"),pXr.forEach(t),AKe=r(wCe," \u2014 "),eR=n(wCe,"A",{href:!0});var uXr=s(eR);yKe=r(uXr,"BertJapaneseTokenizer"),uXr.forEach(t),LKe=r(wCe," (BertJapanese model)"),wCe.forEach(t),xKe=i(S),Sg=n(S,"LI",{});var ACe=s(Sg);rte=n(ACe,"STRONG",{});var _Xr=s(rte);$Ke=r(_Xr,"bertweet"),_Xr.forEach(t),kKe=r(ACe," \u2014 "),oR=n(ACe,"A",{href:!0});var bXr=s(oR);SKe=r(bXr,"BertweetTokenizer"),bXr.forEach(t),RKe=r(ACe," (Bertweet model)"),ACe.forEach(t),PKe=i(S),Dn=n(S,"LI",{});var N9=s(Dn);tte=n(N9,"STRONG",{});var vXr=s(tte);BKe=r(vXr,"big_bird"),vXr.forEach(t),IKe=r(N9," \u2014 "),rR=n(N9,"A",{href:!0});var FXr=s(rR);qKe=r(FXr,"BigBirdTokenizer"),FXr.forEach(t),NKe=r(N9," or "),tR=n(N9,"A",{href:!0});var TXr=s(tR);jKe=r(TXr,"BigBirdTokenizerFast"),TXr.forEach(t),DKe=r(N9," (BigBird model)"),N9.forEach(t),GKe=i(S),Gn=n(S,"LI",{});var j9=s(Gn);ate=n(j9,"STRONG",{});var MXr=s(ate);OKe=r(MXr,"bigbird_pegasus"),MXr.forEach(t),VKe=r(j9," \u2014 "),aR=n(j9,"A",{href:!0});var EXr=s(aR);XKe=r(EXr,"PegasusTokenizer"),EXr.forEach(t),zKe=r(j9," or "),nR=n(j9,"A",{href:!0});var CXr=s(nR);QKe=r(CXr,"PegasusTokenizerFast"),CXr.forEach(t),WKe=r(j9," (BigBirdPegasus model)"),j9.forEach(t),HKe=i(S),On=n(S,"LI",{});var D9=s(On);nte=n(D9,"STRONG",{});var wXr=s(nte);UKe=r(wXr,"blenderbot"),wXr.forEach(t),JKe=r(D9," \u2014 "),sR=n(D9,"A",{href:!0});var AXr=s(sR);YKe=r(AXr,"BlenderbotTokenizer"),AXr.forEach(t),KKe=r(D9," or "),lR=n(D9,"A",{href:!0});var yXr=s(lR);ZKe=r(yXr,"BlenderbotTokenizerFast"),yXr.forEach(t),eZe=r(D9," (Blenderbot model)"),D9.forEach(t),oZe=i(S),Rg=n(S,"LI",{});var yCe=s(Rg);ste=n(yCe,"STRONG",{});var LXr=s(ste);rZe=r(LXr,"blenderbot-small"),LXr.forEach(t),tZe=r(yCe," \u2014 "),iR=n(yCe,"A",{href:!0});var xXr=s(iR);aZe=r(xXr,"BlenderbotSmallTokenizer"),xXr.forEach(t),nZe=r(yCe," (BlenderbotSmall model)"),yCe.forEach(t),sZe=i(S),Pg=n(S,"LI",{});var LCe=s(Pg);lte=n(LCe,"STRONG",{});var $Xr=s(lte);lZe=r($Xr,"byt5"),$Xr.forEach(t),iZe=r(LCe," \u2014 "),dR=n(LCe,"A",{href:!0});var kXr=s(dR);dZe=r(kXr,"ByT5Tokenizer"),kXr.forEach(t),cZe=r(LCe," (ByT5 model)"),LCe.forEach(t),fZe=i(S),Vn=n(S,"LI",{});var G9=s(Vn);ite=n(G9,"STRONG",{});var SXr=s(ite);mZe=r(SXr,"camembert"),SXr.forEach(t),gZe=r(G9," \u2014 "),cR=n(G9,"A",{href:!0});var RXr=s(cR);hZe=r(RXr,"CamembertTokenizer"),RXr.forEach(t),pZe=r(G9," or "),fR=n(G9,"A",{href:!0});var PXr=s(fR);uZe=r(PXr,"CamembertTokenizerFast"),PXr.forEach(t),_Ze=r(G9," (CamemBERT model)"),G9.forEach(t),bZe=i(S),Bg=n(S,"LI",{});var xCe=s(Bg);dte=n(xCe,"STRONG",{});var BXr=s(dte);vZe=r(BXr,"canine"),BXr.forEach(t),FZe=r(xCe," \u2014 "),mR=n(xCe,"A",{href:!0});var IXr=s(mR);TZe=r(IXr,"CanineTokenizer"),IXr.forEach(t),MZe=r(xCe," (Canine model)"),xCe.forEach(t),EZe=i(S),Xn=n(S,"LI",{});var O9=s(Xn);cte=n(O9,"STRONG",{});var qXr=s(cte);CZe=r(qXr,"clip"),qXr.forEach(t),wZe=r(O9," \u2014 "),gR=n(O9,"A",{href:!0});var NXr=s(gR);AZe=r(NXr,"CLIPTokenizer"),NXr.forEach(t),yZe=r(O9," or "),hR=n(O9,"A",{href:!0});var jXr=s(hR);LZe=r(jXr,"CLIPTokenizerFast"),jXr.forEach(t),xZe=r(O9," (CLIP model)"),O9.forEach(t),$Ze=i(S),zn=n(S,"LI",{});var V9=s(zn);fte=n(V9,"STRONG",{});var DXr=s(fte);kZe=r(DXr,"convbert"),DXr.forEach(t),SZe=r(V9," \u2014 "),pR=n(V9,"A",{href:!0});var GXr=s(pR);RZe=r(GXr,"ConvBertTokenizer"),GXr.forEach(t),PZe=r(V9," or "),uR=n(V9,"A",{href:!0});var OXr=s(uR);BZe=r(OXr,"ConvBertTokenizerFast"),OXr.forEach(t),IZe=r(V9," (ConvBERT model)"),V9.forEach(t),qZe=i(S),Qn=n(S,"LI",{});var X9=s(Qn);mte=n(X9,"STRONG",{});var VXr=s(mte);NZe=r(VXr,"cpm"),VXr.forEach(t),jZe=r(X9," \u2014 "),_R=n(X9,"A",{href:!0});var XXr=s(_R);DZe=r(XXr,"CpmTokenizer"),XXr.forEach(t),GZe=r(X9," or "),bR=n(X9,"A",{href:!0});var zXr=s(bR);OZe=r(zXr,"CpmTokenizerFast"),zXr.forEach(t),VZe=r(X9," (CPM model)"),X9.forEach(t),XZe=i(S),Ig=n(S,"LI",{});var $Ce=s(Ig);gte=n($Ce,"STRONG",{});var QXr=s(gte);zZe=r(QXr,"ctrl"),QXr.forEach(t),QZe=r($Ce," \u2014 "),vR=n($Ce,"A",{href:!0});var WXr=s(vR);WZe=r(WXr,"CTRLTokenizer"),WXr.forEach(t),HZe=r($Ce," (CTRL model)"),$Ce.forEach(t),UZe=i(S),Wn=n(S,"LI",{});var z9=s(Wn);hte=n(z9,"STRONG",{});var HXr=s(hte);JZe=r(HXr,"data2vec-text"),HXr.forEach(t),YZe=r(z9," \u2014 "),FR=n(z9,"A",{href:!0});var UXr=s(FR);KZe=r(UXr,"RobertaTokenizer"),UXr.forEach(t),ZZe=r(z9," or "),TR=n(z9,"A",{href:!0});var JXr=s(TR);eeo=r(JXr,"RobertaTokenizerFast"),JXr.forEach(t),oeo=r(z9," (Data2VecText model)"),z9.forEach(t),reo=i(S),Hn=n(S,"LI",{});var Q9=s(Hn);pte=n(Q9,"STRONG",{});var YXr=s(pte);teo=r(YXr,"deberta"),YXr.forEach(t),aeo=r(Q9," \u2014 "),MR=n(Q9,"A",{href:!0});var KXr=s(MR);neo=r(KXr,"DebertaTokenizer"),KXr.forEach(t),seo=r(Q9," or "),ER=n(Q9,"A",{href:!0});var ZXr=s(ER);leo=r(ZXr,"DebertaTokenizerFast"),ZXr.forEach(t),ieo=r(Q9," (DeBERTa model)"),Q9.forEach(t),deo=i(S),Un=n(S,"LI",{});var W9=s(Un);ute=n(W9,"STRONG",{});var ezr=s(ute);ceo=r(ezr,"deberta-v2"),ezr.forEach(t),feo=r(W9," \u2014 "),CR=n(W9,"A",{href:!0});var ozr=s(CR);meo=r(ozr,"DebertaV2Tokenizer"),ozr.forEach(t),geo=r(W9," or "),wR=n(W9,"A",{href:!0});var rzr=s(wR);heo=r(rzr,"DebertaV2TokenizerFast"),rzr.forEach(t),peo=r(W9," (DeBERTa-v2 model)"),W9.forEach(t),ueo=i(S),Jn=n(S,"LI",{});var H9=s(Jn);_te=n(H9,"STRONG",{});var tzr=s(_te);_eo=r(tzr,"distilbert"),tzr.forEach(t),beo=r(H9," \u2014 "),AR=n(H9,"A",{href:!0});var azr=s(AR);veo=r(azr,"DistilBertTokenizer"),azr.forEach(t),Feo=r(H9," or "),yR=n(H9,"A",{href:!0});var nzr=s(yR);Teo=r(nzr,"DistilBertTokenizerFast"),nzr.forEach(t),Meo=r(H9," (DistilBERT model)"),H9.forEach(t),Eeo=i(S),Yn=n(S,"LI",{});var U9=s(Yn);bte=n(U9,"STRONG",{});var szr=s(bte);Ceo=r(szr,"dpr"),szr.forEach(t),weo=r(U9," \u2014 "),LR=n(U9,"A",{href:!0});var lzr=s(LR);Aeo=r(lzr,"DPRQuestionEncoderTokenizer"),lzr.forEach(t),yeo=r(U9," or "),xR=n(U9,"A",{href:!0});var izr=s(xR);Leo=r(izr,"DPRQuestionEncoderTokenizerFast"),izr.forEach(t),xeo=r(U9," (DPR model)"),U9.forEach(t),$eo=i(S),Kn=n(S,"LI",{});var J9=s(Kn);vte=n(J9,"STRONG",{});var dzr=s(vte);keo=r(dzr,"electra"),dzr.forEach(t),Seo=r(J9," \u2014 "),$R=n(J9,"A",{href:!0});var czr=s($R);Reo=r(czr,"ElectraTokenizer"),czr.forEach(t),Peo=r(J9," or "),kR=n(J9,"A",{href:!0});var fzr=s(kR);Beo=r(fzr,"ElectraTokenizerFast"),fzr.forEach(t),Ieo=r(J9," (ELECTRA model)"),J9.forEach(t),qeo=i(S),qg=n(S,"LI",{});var kCe=s(qg);Fte=n(kCe,"STRONG",{});var mzr=s(Fte);Neo=r(mzr,"flaubert"),mzr.forEach(t),jeo=r(kCe," \u2014 "),SR=n(kCe,"A",{href:!0});var gzr=s(SR);Deo=r(gzr,"FlaubertTokenizer"),gzr.forEach(t),Geo=r(kCe," (FlauBERT model)"),kCe.forEach(t),Oeo=i(S),Zn=n(S,"LI",{});var Y9=s(Zn);Tte=n(Y9,"STRONG",{});var hzr=s(Tte);Veo=r(hzr,"fnet"),hzr.forEach(t),Xeo=r(Y9," \u2014 "),RR=n(Y9,"A",{href:!0});var pzr=s(RR);zeo=r(pzr,"FNetTokenizer"),pzr.forEach(t),Qeo=r(Y9," or "),PR=n(Y9,"A",{href:!0});var uzr=s(PR);Weo=r(uzr,"FNetTokenizerFast"),uzr.forEach(t),Heo=r(Y9," (FNet model)"),Y9.forEach(t),Ueo=i(S),Ng=n(S,"LI",{});var SCe=s(Ng);Mte=n(SCe,"STRONG",{});var _zr=s(Mte);Jeo=r(_zr,"fsmt"),_zr.forEach(t),Yeo=r(SCe," \u2014 "),BR=n(SCe,"A",{href:!0});var bzr=s(BR);Keo=r(bzr,"FSMTTokenizer"),bzr.forEach(t),Zeo=r(SCe," (FairSeq Machine-Translation model)"),SCe.forEach(t),eoo=i(S),es=n(S,"LI",{});var K9=s(es);Ete=n(K9,"STRONG",{});var vzr=s(Ete);ooo=r(vzr,"funnel"),vzr.forEach(t),roo=r(K9," \u2014 "),IR=n(K9,"A",{href:!0});var Fzr=s(IR);too=r(Fzr,"FunnelTokenizer"),Fzr.forEach(t),aoo=r(K9," or "),qR=n(K9,"A",{href:!0});var Tzr=s(qR);noo=r(Tzr,"FunnelTokenizerFast"),Tzr.forEach(t),soo=r(K9," (Funnel Transformer model)"),K9.forEach(t),loo=i(S),os=n(S,"LI",{});var Z9=s(os);Cte=n(Z9,"STRONG",{});var Mzr=s(Cte);ioo=r(Mzr,"gpt2"),Mzr.forEach(t),doo=r(Z9," \u2014 "),NR=n(Z9,"A",{href:!0});var Ezr=s(NR);coo=r(Ezr,"GPT2Tokenizer"),Ezr.forEach(t),foo=r(Z9," or "),jR=n(Z9,"A",{href:!0});var Czr=s(jR);moo=r(Czr,"GPT2TokenizerFast"),Czr.forEach(t),goo=r(Z9," (OpenAI GPT-2 model)"),Z9.forEach(t),hoo=i(S),rs=n(S,"LI",{});var e$=s(rs);wte=n(e$,"STRONG",{});var wzr=s(wte);poo=r(wzr,"gpt_neo"),wzr.forEach(t),uoo=r(e$," \u2014 "),DR=n(e$,"A",{href:!0});var Azr=s(DR);_oo=r(Azr,"GPT2Tokenizer"),Azr.forEach(t),boo=r(e$," or "),GR=n(e$,"A",{href:!0});var yzr=s(GR);voo=r(yzr,"GPT2TokenizerFast"),yzr.forEach(t),Foo=r(e$," (GPT Neo model)"),e$.forEach(t),Too=i(S),ts=n(S,"LI",{});var o$=s(ts);Ate=n(o$,"STRONG",{});var Lzr=s(Ate);Moo=r(Lzr,"gptj"),Lzr.forEach(t),Eoo=r(o$," \u2014 "),OR=n(o$,"A",{href:!0});var xzr=s(OR);Coo=r(xzr,"GPT2Tokenizer"),xzr.forEach(t),woo=r(o$," or "),VR=n(o$,"A",{href:!0});var $zr=s(VR);Aoo=r($zr,"GPT2TokenizerFast"),$zr.forEach(t),yoo=r(o$," (GPT-J model)"),o$.forEach(t),Loo=i(S),as=n(S,"LI",{});var r$=s(as);yte=n(r$,"STRONG",{});var kzr=s(yte);xoo=r(kzr,"herbert"),kzr.forEach(t),$oo=r(r$," \u2014 "),XR=n(r$,"A",{href:!0});var Szr=s(XR);koo=r(Szr,"HerbertTokenizer"),Szr.forEach(t),Soo=r(r$," or "),zR=n(r$,"A",{href:!0});var Rzr=s(zR);Roo=r(Rzr,"HerbertTokenizerFast"),Rzr.forEach(t),Poo=r(r$," (HerBERT model)"),r$.forEach(t),Boo=i(S),jg=n(S,"LI",{});var RCe=s(jg);Lte=n(RCe,"STRONG",{});var Pzr=s(Lte);Ioo=r(Pzr,"hubert"),Pzr.forEach(t),qoo=r(RCe," \u2014 "),QR=n(RCe,"A",{href:!0});var Bzr=s(QR);Noo=r(Bzr,"Wav2Vec2CTCTokenizer"),Bzr.forEach(t),joo=r(RCe," (Hubert model)"),RCe.forEach(t),Doo=i(S),ns=n(S,"LI",{});var t$=s(ns);xte=n(t$,"STRONG",{});var Izr=s(xte);Goo=r(Izr,"ibert"),Izr.forEach(t),Ooo=r(t$," \u2014 "),WR=n(t$,"A",{href:!0});var qzr=s(WR);Voo=r(qzr,"RobertaTokenizer"),qzr.forEach(t),Xoo=r(t$," or "),HR=n(t$,"A",{href:!0});var Nzr=s(HR);zoo=r(Nzr,"RobertaTokenizerFast"),Nzr.forEach(t),Qoo=r(t$," (I-BERT model)"),t$.forEach(t),Woo=i(S),ss=n(S,"LI",{});var a$=s(ss);$te=n(a$,"STRONG",{});var jzr=s($te);Hoo=r(jzr,"layoutlm"),jzr.forEach(t),Uoo=r(a$," \u2014 "),UR=n(a$,"A",{href:!0});var Dzr=s(UR);Joo=r(Dzr,"LayoutLMTokenizer"),Dzr.forEach(t),Yoo=r(a$," or "),JR=n(a$,"A",{href:!0});var Gzr=s(JR);Koo=r(Gzr,"LayoutLMTokenizerFast"),Gzr.forEach(t),Zoo=r(a$," (LayoutLM model)"),a$.forEach(t),ero=i(S),ls=n(S,"LI",{});var n$=s(ls);kte=n(n$,"STRONG",{});var Ozr=s(kte);oro=r(Ozr,"layoutlmv2"),Ozr.forEach(t),rro=r(n$," \u2014 "),YR=n(n$,"A",{href:!0});var Vzr=s(YR);tro=r(Vzr,"LayoutLMv2Tokenizer"),Vzr.forEach(t),aro=r(n$," or "),KR=n(n$,"A",{href:!0});var Xzr=s(KR);nro=r(Xzr,"LayoutLMv2TokenizerFast"),Xzr.forEach(t),sro=r(n$," (LayoutLMv2 model)"),n$.forEach(t),lro=i(S),is=n(S,"LI",{});var s$=s(is);Ste=n(s$,"STRONG",{});var zzr=s(Ste);iro=r(zzr,"layoutxlm"),zzr.forEach(t),dro=r(s$," \u2014 "),ZR=n(s$,"A",{href:!0});var Qzr=s(ZR);cro=r(Qzr,"LayoutXLMTokenizer"),Qzr.forEach(t),fro=r(s$," or "),eP=n(s$,"A",{href:!0});var Wzr=s(eP);mro=r(Wzr,"LayoutXLMTokenizerFast"),Wzr.forEach(t),gro=r(s$," (LayoutXLM model)"),s$.forEach(t),hro=i(S),ds=n(S,"LI",{});var l$=s(ds);Rte=n(l$,"STRONG",{});var Hzr=s(Rte);pro=r(Hzr,"led"),Hzr.forEach(t),uro=r(l$," \u2014 "),oP=n(l$,"A",{href:!0});var Uzr=s(oP);_ro=r(Uzr,"LEDTokenizer"),Uzr.forEach(t),bro=r(l$," or "),rP=n(l$,"A",{href:!0});var Jzr=s(rP);vro=r(Jzr,"LEDTokenizerFast"),Jzr.forEach(t),Fro=r(l$," (LED model)"),l$.forEach(t),Tro=i(S),cs=n(S,"LI",{});var i$=s(cs);Pte=n(i$,"STRONG",{});var Yzr=s(Pte);Mro=r(Yzr,"longformer"),Yzr.forEach(t),Ero=r(i$," \u2014 "),tP=n(i$,"A",{href:!0});var Kzr=s(tP);Cro=r(Kzr,"LongformerTokenizer"),Kzr.forEach(t),wro=r(i$," or "),aP=n(i$,"A",{href:!0});var Zzr=s(aP);Aro=r(Zzr,"LongformerTokenizerFast"),Zzr.forEach(t),yro=r(i$," (Longformer model)"),i$.forEach(t),Lro=i(S),Dg=n(S,"LI",{});var PCe=s(Dg);Bte=n(PCe,"STRONG",{});var eQr=s(Bte);xro=r(eQr,"luke"),eQr.forEach(t),$ro=r(PCe," \u2014 "),nP=n(PCe,"A",{href:!0});var oQr=s(nP);kro=r(oQr,"LukeTokenizer"),oQr.forEach(t),Sro=r(PCe," (LUKE model)"),PCe.forEach(t),Rro=i(S),fs=n(S,"LI",{});var d$=s(fs);Ite=n(d$,"STRONG",{});var rQr=s(Ite);Pro=r(rQr,"lxmert"),rQr.forEach(t),Bro=r(d$," \u2014 "),sP=n(d$,"A",{href:!0});var tQr=s(sP);Iro=r(tQr,"LxmertTokenizer"),tQr.forEach(t),qro=r(d$," or "),lP=n(d$,"A",{href:!0});var aQr=s(lP);Nro=r(aQr,"LxmertTokenizerFast"),aQr.forEach(t),jro=r(d$," (LXMERT model)"),d$.forEach(t),Dro=i(S),Gg=n(S,"LI",{});var BCe=s(Gg);qte=n(BCe,"STRONG",{});var nQr=s(qte);Gro=r(nQr,"m2m_100"),nQr.forEach(t),Oro=r(BCe," \u2014 "),iP=n(BCe,"A",{href:!0});var sQr=s(iP);Vro=r(sQr,"M2M100Tokenizer"),sQr.forEach(t),Xro=r(BCe," (M2M100 model)"),BCe.forEach(t),zro=i(S),Og=n(S,"LI",{});var ICe=s(Og);Nte=n(ICe,"STRONG",{});var lQr=s(Nte);Qro=r(lQr,"marian"),lQr.forEach(t),Wro=r(ICe," \u2014 "),dP=n(ICe,"A",{href:!0});var iQr=s(dP);Hro=r(iQr,"MarianTokenizer"),iQr.forEach(t),Uro=r(ICe," (Marian model)"),ICe.forEach(t),Jro=i(S),ms=n(S,"LI",{});var c$=s(ms);jte=n(c$,"STRONG",{});var dQr=s(jte);Yro=r(dQr,"mbart"),dQr.forEach(t),Kro=r(c$," \u2014 "),cP=n(c$,"A",{href:!0});var cQr=s(cP);Zro=r(cQr,"MBartTokenizer"),cQr.forEach(t),eto=r(c$," or "),fP=n(c$,"A",{href:!0});var fQr=s(fP);oto=r(fQr,"MBartTokenizerFast"),fQr.forEach(t),rto=r(c$," (mBART model)"),c$.forEach(t),tto=i(S),gs=n(S,"LI",{});var f$=s(gs);Dte=n(f$,"STRONG",{});var mQr=s(Dte);ato=r(mQr,"mbart50"),mQr.forEach(t),nto=r(f$," \u2014 "),mP=n(f$,"A",{href:!0});var gQr=s(mP);sto=r(gQr,"MBart50Tokenizer"),gQr.forEach(t),lto=r(f$," or "),gP=n(f$,"A",{href:!0});var hQr=s(gP);ito=r(hQr,"MBart50TokenizerFast"),hQr.forEach(t),dto=r(f$," (mBART-50 model)"),f$.forEach(t),cto=i(S),hs=n(S,"LI",{});var m$=s(hs);Gte=n(m$,"STRONG",{});var pQr=s(Gte);fto=r(pQr,"megatron-bert"),pQr.forEach(t),mto=r(m$," \u2014 "),hP=n(m$,"A",{href:!0});var uQr=s(hP);gto=r(uQr,"BertTokenizer"),uQr.forEach(t),hto=r(m$," or "),pP=n(m$,"A",{href:!0});var _Qr=s(pP);pto=r(_Qr,"BertTokenizerFast"),_Qr.forEach(t),uto=r(m$," (MegatronBert model)"),m$.forEach(t),_to=i(S),Vg=n(S,"LI",{});var qCe=s(Vg);Ote=n(qCe,"STRONG",{});var bQr=s(Ote);bto=r(bQr,"mluke"),bQr.forEach(t),vto=r(qCe," \u2014 "),uP=n(qCe,"A",{href:!0});var vQr=s(uP);Fto=r(vQr,"MLukeTokenizer"),vQr.forEach(t),Tto=r(qCe," (mLUKE model)"),qCe.forEach(t),Mto=i(S),ps=n(S,"LI",{});var g$=s(ps);Vte=n(g$,"STRONG",{});var FQr=s(Vte);Eto=r(FQr,"mobilebert"),FQr.forEach(t),Cto=r(g$," \u2014 "),_P=n(g$,"A",{href:!0});var TQr=s(_P);wto=r(TQr,"MobileBertTokenizer"),TQr.forEach(t),Ato=r(g$," or "),bP=n(g$,"A",{href:!0});var MQr=s(bP);yto=r(MQr,"MobileBertTokenizerFast"),MQr.forEach(t),Lto=r(g$," (MobileBERT model)"),g$.forEach(t),xto=i(S),us=n(S,"LI",{});var h$=s(us);Xte=n(h$,"STRONG",{});var EQr=s(Xte);$to=r(EQr,"mpnet"),EQr.forEach(t),kto=r(h$," \u2014 "),vP=n(h$,"A",{href:!0});var CQr=s(vP);Sto=r(CQr,"MPNetTokenizer"),CQr.forEach(t),Rto=r(h$," or "),FP=n(h$,"A",{href:!0});var wQr=s(FP);Pto=r(wQr,"MPNetTokenizerFast"),wQr.forEach(t),Bto=r(h$," (MPNet model)"),h$.forEach(t),Ito=i(S),_s=n(S,"LI",{});var p$=s(_s);zte=n(p$,"STRONG",{});var AQr=s(zte);qto=r(AQr,"mt5"),AQr.forEach(t),Nto=r(p$," \u2014 "),TP=n(p$,"A",{href:!0});var yQr=s(TP);jto=r(yQr,"MT5Tokenizer"),yQr.forEach(t),Dto=r(p$," or "),MP=n(p$,"A",{href:!0});var LQr=s(MP);Gto=r(LQr,"MT5TokenizerFast"),LQr.forEach(t),Oto=r(p$," (mT5 model)"),p$.forEach(t),Vto=i(S),bs=n(S,"LI",{});var u$=s(bs);Qte=n(u$,"STRONG",{});var xQr=s(Qte);Xto=r(xQr,"nystromformer"),xQr.forEach(t),zto=r(u$," \u2014 "),EP=n(u$,"A",{href:!0});var $Qr=s(EP);Qto=r($Qr,"AlbertTokenizer"),$Qr.forEach(t),Wto=r(u$," or "),CP=n(u$,"A",{href:!0});var kQr=s(CP);Hto=r(kQr,"AlbertTokenizerFast"),kQr.forEach(t),Uto=r(u$," (Nystromformer model)"),u$.forEach(t),Jto=i(S),vs=n(S,"LI",{});var _$=s(vs);Wte=n(_$,"STRONG",{});var SQr=s(Wte);Yto=r(SQr,"openai-gpt"),SQr.forEach(t),Kto=r(_$," \u2014 "),wP=n(_$,"A",{href:!0});var RQr=s(wP);Zto=r(RQr,"OpenAIGPTTokenizer"),RQr.forEach(t),eao=r(_$," or "),AP=n(_$,"A",{href:!0});var PQr=s(AP);oao=r(PQr,"OpenAIGPTTokenizerFast"),PQr.forEach(t),rao=r(_$," (OpenAI GPT model)"),_$.forEach(t),tao=i(S),Xg=n(S,"LI",{});var NCe=s(Xg);Hte=n(NCe,"STRONG",{});var BQr=s(Hte);aao=r(BQr,"opt"),BQr.forEach(t),nao=r(NCe," \u2014 "),yP=n(NCe,"A",{href:!0});var IQr=s(yP);sao=r(IQr,"GPT2Tokenizer"),IQr.forEach(t),lao=r(NCe," (OPT model)"),NCe.forEach(t),iao=i(S),Fs=n(S,"LI",{});var b$=s(Fs);Ute=n(b$,"STRONG",{});var qQr=s(Ute);dao=r(qQr,"pegasus"),qQr.forEach(t),cao=r(b$," \u2014 "),LP=n(b$,"A",{href:!0});var NQr=s(LP);fao=r(NQr,"PegasusTokenizer"),NQr.forEach(t),mao=r(b$," or "),xP=n(b$,"A",{href:!0});var jQr=s(xP);gao=r(jQr,"PegasusTokenizerFast"),jQr.forEach(t),hao=r(b$," (Pegasus model)"),b$.forEach(t),pao=i(S),zg=n(S,"LI",{});var jCe=s(zg);Jte=n(jCe,"STRONG",{});var DQr=s(Jte);uao=r(DQr,"perceiver"),DQr.forEach(t),_ao=r(jCe," \u2014 "),$P=n(jCe,"A",{href:!0});var GQr=s($P);bao=r(GQr,"PerceiverTokenizer"),GQr.forEach(t),vao=r(jCe," (Perceiver model)"),jCe.forEach(t),Fao=i(S),Qg=n(S,"LI",{});var DCe=s(Qg);Yte=n(DCe,"STRONG",{});var OQr=s(Yte);Tao=r(OQr,"phobert"),OQr.forEach(t),Mao=r(DCe," \u2014 "),kP=n(DCe,"A",{href:!0});var VQr=s(kP);Eao=r(VQr,"PhobertTokenizer"),VQr.forEach(t),Cao=r(DCe," (PhoBERT model)"),DCe.forEach(t),wao=i(S),Wg=n(S,"LI",{});var GCe=s(Wg);Kte=n(GCe,"STRONG",{});var XQr=s(Kte);Aao=r(XQr,"plbart"),XQr.forEach(t),yao=r(GCe," \u2014 "),SP=n(GCe,"A",{href:!0});var zQr=s(SP);Lao=r(zQr,"PLBartTokenizer"),zQr.forEach(t),xao=r(GCe," (PLBart model)"),GCe.forEach(t),$ao=i(S),Hg=n(S,"LI",{});var OCe=s(Hg);Zte=n(OCe,"STRONG",{});var QQr=s(Zte);kao=r(QQr,"prophetnet"),QQr.forEach(t),Sao=r(OCe," \u2014 "),RP=n(OCe,"A",{href:!0});var WQr=s(RP);Rao=r(WQr,"ProphetNetTokenizer"),WQr.forEach(t),Pao=r(OCe," (ProphetNet model)"),OCe.forEach(t),Bao=i(S),Ts=n(S,"LI",{});var v$=s(Ts);eae=n(v$,"STRONG",{});var HQr=s(eae);Iao=r(HQr,"qdqbert"),HQr.forEach(t),qao=r(v$," \u2014 "),PP=n(v$,"A",{href:!0});var UQr=s(PP);Nao=r(UQr,"BertTokenizer"),UQr.forEach(t),jao=r(v$," or "),BP=n(v$,"A",{href:!0});var JQr=s(BP);Dao=r(JQr,"BertTokenizerFast"),JQr.forEach(t),Gao=r(v$," (QDQBert model)"),v$.forEach(t),Oao=i(S),Ug=n(S,"LI",{});var VCe=s(Ug);oae=n(VCe,"STRONG",{});var YQr=s(oae);Vao=r(YQr,"rag"),YQr.forEach(t),Xao=r(VCe," \u2014 "),IP=n(VCe,"A",{href:!0});var KQr=s(IP);zao=r(KQr,"RagTokenizer"),KQr.forEach(t),Qao=r(VCe," (RAG model)"),VCe.forEach(t),Wao=i(S),Ms=n(S,"LI",{});var F$=s(Ms);rae=n(F$,"STRONG",{});var ZQr=s(rae);Hao=r(ZQr,"realm"),ZQr.forEach(t),Uao=r(F$," \u2014 "),qP=n(F$,"A",{href:!0});var eWr=s(qP);Jao=r(eWr,"RealmTokenizer"),eWr.forEach(t),Yao=r(F$," or "),NP=n(F$,"A",{href:!0});var oWr=s(NP);Kao=r(oWr,"RealmTokenizerFast"),oWr.forEach(t),Zao=r(F$," (Realm model)"),F$.forEach(t),eno=i(S),Es=n(S,"LI",{});var T$=s(Es);tae=n(T$,"STRONG",{});var rWr=s(tae);ono=r(rWr,"reformer"),rWr.forEach(t),rno=r(T$," \u2014 "),jP=n(T$,"A",{href:!0});var tWr=s(jP);tno=r(tWr,"ReformerTokenizer"),tWr.forEach(t),ano=r(T$," or "),DP=n(T$,"A",{href:!0});var aWr=s(DP);nno=r(aWr,"ReformerTokenizerFast"),aWr.forEach(t),sno=r(T$," (Reformer model)"),T$.forEach(t),lno=i(S),Cs=n(S,"LI",{});var M$=s(Cs);aae=n(M$,"STRONG",{});var nWr=s(aae);ino=r(nWr,"rembert"),nWr.forEach(t),dno=r(M$," \u2014 "),GP=n(M$,"A",{href:!0});var sWr=s(GP);cno=r(sWr,"RemBertTokenizer"),sWr.forEach(t),fno=r(M$," or "),OP=n(M$,"A",{href:!0});var lWr=s(OP);mno=r(lWr,"RemBertTokenizerFast"),lWr.forEach(t),gno=r(M$," (RemBERT model)"),M$.forEach(t),hno=i(S),ws=n(S,"LI",{});var E$=s(ws);nae=n(E$,"STRONG",{});var iWr=s(nae);pno=r(iWr,"retribert"),iWr.forEach(t),uno=r(E$," \u2014 "),VP=n(E$,"A",{href:!0});var dWr=s(VP);_no=r(dWr,"RetriBertTokenizer"),dWr.forEach(t),bno=r(E$," or "),XP=n(E$,"A",{href:!0});var cWr=s(XP);vno=r(cWr,"RetriBertTokenizerFast"),cWr.forEach(t),Fno=r(E$," (RetriBERT model)"),E$.forEach(t),Tno=i(S),As=n(S,"LI",{});var C$=s(As);sae=n(C$,"STRONG",{});var fWr=s(sae);Mno=r(fWr,"roberta"),fWr.forEach(t),Eno=r(C$," \u2014 "),zP=n(C$,"A",{href:!0});var mWr=s(zP);Cno=r(mWr,"RobertaTokenizer"),mWr.forEach(t),wno=r(C$," or "),QP=n(C$,"A",{href:!0});var gWr=s(QP);Ano=r(gWr,"RobertaTokenizerFast"),gWr.forEach(t),yno=r(C$," (RoBERTa model)"),C$.forEach(t),Lno=i(S),ys=n(S,"LI",{});var w$=s(ys);lae=n(w$,"STRONG",{});var hWr=s(lae);xno=r(hWr,"roformer"),hWr.forEach(t),$no=r(w$," \u2014 "),WP=n(w$,"A",{href:!0});var pWr=s(WP);kno=r(pWr,"RoFormerTokenizer"),pWr.forEach(t),Sno=r(w$," or "),HP=n(w$,"A",{href:!0});var uWr=s(HP);Rno=r(uWr,"RoFormerTokenizerFast"),uWr.forEach(t),Pno=r(w$," (RoFormer model)"),w$.forEach(t),Bno=i(S),Jg=n(S,"LI",{});var XCe=s(Jg);iae=n(XCe,"STRONG",{});var _Wr=s(iae);Ino=r(_Wr,"speech_to_text"),_Wr.forEach(t),qno=r(XCe," \u2014 "),UP=n(XCe,"A",{href:!0});var bWr=s(UP);Nno=r(bWr,"Speech2TextTokenizer"),bWr.forEach(t),jno=r(XCe," (Speech2Text model)"),XCe.forEach(t),Dno=i(S),Yg=n(S,"LI",{});var zCe=s(Yg);dae=n(zCe,"STRONG",{});var vWr=s(dae);Gno=r(vWr,"speech_to_text_2"),vWr.forEach(t),Ono=r(zCe," \u2014 "),JP=n(zCe,"A",{href:!0});var FWr=s(JP);Vno=r(FWr,"Speech2Text2Tokenizer"),FWr.forEach(t),Xno=r(zCe," (Speech2Text2 model)"),zCe.forEach(t),zno=i(S),Ls=n(S,"LI",{});var A$=s(Ls);cae=n(A$,"STRONG",{});var TWr=s(cae);Qno=r(TWr,"splinter"),TWr.forEach(t),Wno=r(A$," \u2014 "),YP=n(A$,"A",{href:!0});var MWr=s(YP);Hno=r(MWr,"SplinterTokenizer"),MWr.forEach(t),Uno=r(A$," or "),KP=n(A$,"A",{href:!0});var EWr=s(KP);Jno=r(EWr,"SplinterTokenizerFast"),EWr.forEach(t),Yno=r(A$," (Splinter model)"),A$.forEach(t),Kno=i(S),xs=n(S,"LI",{});var y$=s(xs);fae=n(y$,"STRONG",{});var CWr=s(fae);Zno=r(CWr,"squeezebert"),CWr.forEach(t),eso=r(y$," \u2014 "),ZP=n(y$,"A",{href:!0});var wWr=s(ZP);oso=r(wWr,"SqueezeBertTokenizer"),wWr.forEach(t),rso=r(y$," or "),eB=n(y$,"A",{href:!0});var AWr=s(eB);tso=r(AWr,"SqueezeBertTokenizerFast"),AWr.forEach(t),aso=r(y$," (SqueezeBERT model)"),y$.forEach(t),nso=i(S),$s=n(S,"LI",{});var L$=s($s);mae=n(L$,"STRONG",{});var yWr=s(mae);sso=r(yWr,"t5"),yWr.forEach(t),lso=r(L$," \u2014 "),oB=n(L$,"A",{href:!0});var LWr=s(oB);iso=r(LWr,"T5Tokenizer"),LWr.forEach(t),dso=r(L$," or "),rB=n(L$,"A",{href:!0});var xWr=s(rB);cso=r(xWr,"T5TokenizerFast"),xWr.forEach(t),fso=r(L$," (T5 model)"),L$.forEach(t),mso=i(S),Kg=n(S,"LI",{});var QCe=s(Kg);gae=n(QCe,"STRONG",{});var $Wr=s(gae);gso=r($Wr,"tapas"),$Wr.forEach(t),hso=r(QCe," \u2014 "),tB=n(QCe,"A",{href:!0});var kWr=s(tB);pso=r(kWr,"TapasTokenizer"),kWr.forEach(t),uso=r(QCe," (TAPAS model)"),QCe.forEach(t),_so=i(S),Zg=n(S,"LI",{});var WCe=s(Zg);hae=n(WCe,"STRONG",{});var SWr=s(hae);bso=r(SWr,"tapex"),SWr.forEach(t),vso=r(WCe," \u2014 "),aB=n(WCe,"A",{href:!0});var RWr=s(aB);Fso=r(RWr,"TapexTokenizer"),RWr.forEach(t),Tso=r(WCe," (TAPEX model)"),WCe.forEach(t),Mso=i(S),eh=n(S,"LI",{});var HCe=s(eh);pae=n(HCe,"STRONG",{});var PWr=s(pae);Eso=r(PWr,"transfo-xl"),PWr.forEach(t),Cso=r(HCe," \u2014 "),nB=n(HCe,"A",{href:!0});var BWr=s(nB);wso=r(BWr,"TransfoXLTokenizer"),BWr.forEach(t),Aso=r(HCe," (Transformer-XL model)"),HCe.forEach(t),yso=i(S),ks=n(S,"LI",{});var x$=s(ks);uae=n(x$,"STRONG",{});var IWr=s(uae);Lso=r(IWr,"vilt"),IWr.forEach(t),xso=r(x$," \u2014 "),sB=n(x$,"A",{href:!0});var qWr=s(sB);$so=r(qWr,"BertTokenizer"),qWr.forEach(t),kso=r(x$," or "),lB=n(x$,"A",{href:!0});var NWr=s(lB);Sso=r(NWr,"BertTokenizerFast"),NWr.forEach(t),Rso=r(x$," (ViLT model)"),x$.forEach(t),Pso=i(S),Ss=n(S,"LI",{});var $$=s(Ss);_ae=n($$,"STRONG",{});var jWr=s(_ae);Bso=r(jWr,"visual_bert"),jWr.forEach(t),Iso=r($$," \u2014 "),iB=n($$,"A",{href:!0});var DWr=s(iB);qso=r(DWr,"BertTokenizer"),DWr.forEach(t),Nso=r($$," or "),dB=n($$,"A",{href:!0});var GWr=s(dB);jso=r(GWr,"BertTokenizerFast"),GWr.forEach(t),Dso=r($$," (VisualBert model)"),$$.forEach(t),Gso=i(S),oh=n(S,"LI",{});var UCe=s(oh);bae=n(UCe,"STRONG",{});var OWr=s(bae);Oso=r(OWr,"wav2vec2"),OWr.forEach(t),Vso=r(UCe," \u2014 "),cB=n(UCe,"A",{href:!0});var VWr=s(cB);Xso=r(VWr,"Wav2Vec2CTCTokenizer"),VWr.forEach(t),zso=r(UCe," (Wav2Vec2 model)"),UCe.forEach(t),Qso=i(S),rh=n(S,"LI",{});var JCe=s(rh);vae=n(JCe,"STRONG",{});var XWr=s(vae);Wso=r(XWr,"wav2vec2_phoneme"),XWr.forEach(t),Hso=r(JCe," \u2014 "),fB=n(JCe,"A",{href:!0});var zWr=s(fB);Uso=r(zWr,"Wav2Vec2PhonemeCTCTokenizer"),zWr.forEach(t),Jso=r(JCe," (Wav2Vec2Phoneme model)"),JCe.forEach(t),Yso=i(S),Rs=n(S,"LI",{});var k$=s(Rs);Fae=n(k$,"STRONG",{});var QWr=s(Fae);Kso=r(QWr,"xglm"),QWr.forEach(t),Zso=r(k$," \u2014 "),mB=n(k$,"A",{href:!0});var WWr=s(mB);elo=r(WWr,"XGLMTokenizer"),WWr.forEach(t),olo=r(k$," or "),gB=n(k$,"A",{href:!0});var HWr=s(gB);rlo=r(HWr,"XGLMTokenizerFast"),HWr.forEach(t),tlo=r(k$," (XGLM model)"),k$.forEach(t),alo=i(S),th=n(S,"LI",{});var YCe=s(th);Tae=n(YCe,"STRONG",{});var UWr=s(Tae);nlo=r(UWr,"xlm"),UWr.forEach(t),slo=r(YCe," \u2014 "),hB=n(YCe,"A",{href:!0});var JWr=s(hB);llo=r(JWr,"XLMTokenizer"),JWr.forEach(t),ilo=r(YCe," (XLM model)"),YCe.forEach(t),dlo=i(S),ah=n(S,"LI",{});var KCe=s(ah);Mae=n(KCe,"STRONG",{});var YWr=s(Mae);clo=r(YWr,"xlm-prophetnet"),YWr.forEach(t),flo=r(KCe," \u2014 "),pB=n(KCe,"A",{href:!0});var KWr=s(pB);mlo=r(KWr,"XLMProphetNetTokenizer"),KWr.forEach(t),glo=r(KCe," (XLMProphetNet model)"),KCe.forEach(t),hlo=i(S),Ps=n(S,"LI",{});var S$=s(Ps);Eae=n(S$,"STRONG",{});var ZWr=s(Eae);plo=r(ZWr,"xlm-roberta"),ZWr.forEach(t),ulo=r(S$," \u2014 "),uB=n(S$,"A",{href:!0});var eHr=s(uB);_lo=r(eHr,"XLMRobertaTokenizer"),eHr.forEach(t),blo=r(S$," or "),_B=n(S$,"A",{href:!0});var oHr=s(_B);vlo=r(oHr,"XLMRobertaTokenizerFast"),oHr.forEach(t),Flo=r(S$," (XLM-RoBERTa model)"),S$.forEach(t),Tlo=i(S),Bs=n(S,"LI",{});var R$=s(Bs);Cae=n(R$,"STRONG",{});var rHr=s(Cae);Mlo=r(rHr,"xlm-roberta-xl"),rHr.forEach(t),Elo=r(R$," \u2014 "),bB=n(R$,"A",{href:!0});var tHr=s(bB);Clo=r(tHr,"RobertaTokenizer"),tHr.forEach(t),wlo=r(R$," or "),vB=n(R$,"A",{href:!0});var aHr=s(vB);Alo=r(aHr,"RobertaTokenizerFast"),aHr.forEach(t),ylo=r(R$," (XLM-RoBERTa-XL model)"),R$.forEach(t),Llo=i(S),Is=n(S,"LI",{});var P$=s(Is);wae=n(P$,"STRONG",{});var nHr=s(wae);xlo=r(nHr,"xlnet"),nHr.forEach(t),$lo=r(P$," \u2014 "),FB=n(P$,"A",{href:!0});var sHr=s(FB);klo=r(sHr,"XLNetTokenizer"),sHr.forEach(t),Slo=r(P$," or "),TB=n(P$,"A",{href:!0});var lHr=s(TB);Rlo=r(lHr,"XLNetTokenizerFast"),lHr.forEach(t),Plo=r(P$," (XLNet model)"),P$.forEach(t),Blo=i(S),qs=n(S,"LI",{});var B$=s(qs);Aae=n(B$,"STRONG",{});var iHr=s(Aae);Ilo=r(iHr,"yoso"),iHr.forEach(t),qlo=r(B$," \u2014 "),MB=n(B$,"A",{href:!0});var dHr=s(MB);Nlo=r(dHr,"AlbertTokenizer"),dHr.forEach(t),jlo=r(B$," or "),EB=n(B$,"A",{href:!0});var cHr=s(EB);Dlo=r(cHr,"AlbertTokenizerFast"),cHr.forEach(t),Glo=r(B$," (YOSO model)"),B$.forEach(t),S.forEach(t),Olo=i(Os),T(nh.$$.fragment,Os),Os.forEach(t),Vlo=i(Gs),sh=n(Gs,"DIV",{class:!0});var YNe=s(sh);T(xA.$$.fragment,YNe),Xlo=i(YNe),yae=n(YNe,"P",{});var fHr=s(yae);zlo=r(fHr,"Register a new tokenizer in this mapping."),fHr.forEach(t),YNe.forEach(t),Gs.forEach(t),JIe=i(f),wi=n(f,"H2",{class:!0});var KNe=s(wi);lh=n(KNe,"A",{id:!0,class:!0,href:!0});var mHr=s(lh);Lae=n(mHr,"SPAN",{});var gHr=s(Lae);T($A.$$.fragment,gHr),gHr.forEach(t),mHr.forEach(t),Qlo=i(KNe),xae=n(KNe,"SPAN",{});var hHr=s(xae);Wlo=r(hHr,"AutoFeatureExtractor"),hHr.forEach(t),KNe.forEach(t),YIe=i(f),yo=n(f,"DIV",{class:!0});var Vs=s(yo);T(kA.$$.fragment,Vs),Hlo=i(Vs),SA=n(Vs,"P",{});var ZNe=s(SA);Ulo=r(ZNe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),CB=n(ZNe,"A",{href:!0});var pHr=s(CB);Jlo=r(pHr,"AutoFeatureExtractor.from_pretrained()"),pHr.forEach(t),Ylo=r(ZNe," class method."),ZNe.forEach(t),Klo=i(Vs),RA=n(Vs,"P",{});var eje=s(RA);Zlo=r(eje,"This class cannot be instantiated directly using "),$ae=n(eje,"CODE",{});var uHr=s($ae);eio=r(uHr,"__init__()"),uHr.forEach(t),oio=r(eje," (throws an error)."),eje.forEach(t),rio=i(Vs),Qe=n(Vs,"DIV",{class:!0});var ea=s(Qe);T(PA.$$.fragment,ea),tio=i(ea),kae=n(ea,"P",{});var _Hr=s(kae);aio=r(_Hr,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),_Hr.forEach(t),nio=i(ea),xa=n(ea,"P",{});var u3=s(xa);sio=r(u3,"The feature extractor class to instantiate is selected based on the "),Sae=n(u3,"CODE",{});var bHr=s(Sae);lio=r(bHr,"model_type"),bHr.forEach(t),iio=r(u3,` property of the config object
(either passed as an argument or loaded from `),Rae=n(u3,"CODE",{});var vHr=s(Rae);dio=r(vHr,"pretrained_model_name_or_path"),vHr.forEach(t),cio=r(u3,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Pae=n(u3,"CODE",{});var FHr=s(Pae);fio=r(FHr,"pretrained_model_name_or_path"),FHr.forEach(t),mio=r(u3,":"),u3.forEach(t),gio=i(ea),ee=n(ea,"UL",{});var te=s(ee);ih=n(te,"LI",{});var ZCe=s(ih);Bae=n(ZCe,"STRONG",{});var THr=s(Bae);hio=r(THr,"beit"),THr.forEach(t),pio=r(ZCe," \u2014 "),wB=n(ZCe,"A",{href:!0});var MHr=s(wB);uio=r(MHr,"BeitFeatureExtractor"),MHr.forEach(t),_io=r(ZCe," (BEiT model)"),ZCe.forEach(t),bio=i(te),dh=n(te,"LI",{});var e3e=s(dh);Iae=n(e3e,"STRONG",{});var EHr=s(Iae);vio=r(EHr,"clip"),EHr.forEach(t),Fio=r(e3e," \u2014 "),AB=n(e3e,"A",{href:!0});var CHr=s(AB);Tio=r(CHr,"CLIPFeatureExtractor"),CHr.forEach(t),Mio=r(e3e," (CLIP model)"),e3e.forEach(t),Eio=i(te),ch=n(te,"LI",{});var o3e=s(ch);qae=n(o3e,"STRONG",{});var wHr=s(qae);Cio=r(wHr,"convnext"),wHr.forEach(t),wio=r(o3e," \u2014 "),yB=n(o3e,"A",{href:!0});var AHr=s(yB);Aio=r(AHr,"ConvNextFeatureExtractor"),AHr.forEach(t),yio=r(o3e," (ConvNext model)"),o3e.forEach(t),Lio=i(te),fh=n(te,"LI",{});var r3e=s(fh);Nae=n(r3e,"STRONG",{});var yHr=s(Nae);xio=r(yHr,"data2vec-audio"),yHr.forEach(t),$io=r(r3e," \u2014 "),LB=n(r3e,"A",{href:!0});var LHr=s(LB);kio=r(LHr,"Wav2Vec2FeatureExtractor"),LHr.forEach(t),Sio=r(r3e," (Data2VecAudio model)"),r3e.forEach(t),Rio=i(te),mh=n(te,"LI",{});var t3e=s(mh);jae=n(t3e,"STRONG",{});var xHr=s(jae);Pio=r(xHr,"data2vec-vision"),xHr.forEach(t),Bio=r(t3e," \u2014 "),xB=n(t3e,"A",{href:!0});var $Hr=s(xB);Iio=r($Hr,"BeitFeatureExtractor"),$Hr.forEach(t),qio=r(t3e," (Data2VecVision model)"),t3e.forEach(t),Nio=i(te),gh=n(te,"LI",{});var a3e=s(gh);Dae=n(a3e,"STRONG",{});var kHr=s(Dae);jio=r(kHr,"deit"),kHr.forEach(t),Dio=r(a3e," \u2014 "),$B=n(a3e,"A",{href:!0});var SHr=s($B);Gio=r(SHr,"DeiTFeatureExtractor"),SHr.forEach(t),Oio=r(a3e," (DeiT model)"),a3e.forEach(t),Vio=i(te),hh=n(te,"LI",{});var n3e=s(hh);Gae=n(n3e,"STRONG",{});var RHr=s(Gae);Xio=r(RHr,"detr"),RHr.forEach(t),zio=r(n3e," \u2014 "),kB=n(n3e,"A",{href:!0});var PHr=s(kB);Qio=r(PHr,"DetrFeatureExtractor"),PHr.forEach(t),Wio=r(n3e," (DETR model)"),n3e.forEach(t),Hio=i(te),ph=n(te,"LI",{});var s3e=s(ph);Oae=n(s3e,"STRONG",{});var BHr=s(Oae);Uio=r(BHr,"dpt"),BHr.forEach(t),Jio=r(s3e," \u2014 "),SB=n(s3e,"A",{href:!0});var IHr=s(SB);Yio=r(IHr,"DPTFeatureExtractor"),IHr.forEach(t),Kio=r(s3e," (DPT model)"),s3e.forEach(t),Zio=i(te),uh=n(te,"LI",{});var l3e=s(uh);Vae=n(l3e,"STRONG",{});var qHr=s(Vae);edo=r(qHr,"flava"),qHr.forEach(t),odo=r(l3e," \u2014 "),RB=n(l3e,"A",{href:!0});var NHr=s(RB);rdo=r(NHr,"FlavaFeatureExtractor"),NHr.forEach(t),tdo=r(l3e," (Flava model)"),l3e.forEach(t),ado=i(te),_h=n(te,"LI",{});var i3e=s(_h);Xae=n(i3e,"STRONG",{});var jHr=s(Xae);ndo=r(jHr,"glpn"),jHr.forEach(t),sdo=r(i3e," \u2014 "),PB=n(i3e,"A",{href:!0});var DHr=s(PB);ldo=r(DHr,"GLPNFeatureExtractor"),DHr.forEach(t),ido=r(i3e," (GLPN model)"),i3e.forEach(t),ddo=i(te),bh=n(te,"LI",{});var d3e=s(bh);zae=n(d3e,"STRONG",{});var GHr=s(zae);cdo=r(GHr,"hubert"),GHr.forEach(t),fdo=r(d3e," \u2014 "),BB=n(d3e,"A",{href:!0});var OHr=s(BB);mdo=r(OHr,"Wav2Vec2FeatureExtractor"),OHr.forEach(t),gdo=r(d3e," (Hubert model)"),d3e.forEach(t),hdo=i(te),vh=n(te,"LI",{});var c3e=s(vh);Qae=n(c3e,"STRONG",{});var VHr=s(Qae);pdo=r(VHr,"layoutlmv2"),VHr.forEach(t),udo=r(c3e," \u2014 "),IB=n(c3e,"A",{href:!0});var XHr=s(IB);_do=r(XHr,"LayoutLMv2FeatureExtractor"),XHr.forEach(t),bdo=r(c3e," (LayoutLMv2 model)"),c3e.forEach(t),vdo=i(te),Fh=n(te,"LI",{});var f3e=s(Fh);Wae=n(f3e,"STRONG",{});var zHr=s(Wae);Fdo=r(zHr,"maskformer"),zHr.forEach(t),Tdo=r(f3e," \u2014 "),qB=n(f3e,"A",{href:!0});var QHr=s(qB);Mdo=r(QHr,"MaskFormerFeatureExtractor"),QHr.forEach(t),Edo=r(f3e," (MaskFormer model)"),f3e.forEach(t),Cdo=i(te),Th=n(te,"LI",{});var m3e=s(Th);Hae=n(m3e,"STRONG",{});var WHr=s(Hae);wdo=r(WHr,"perceiver"),WHr.forEach(t),Ado=r(m3e," \u2014 "),NB=n(m3e,"A",{href:!0});var HHr=s(NB);ydo=r(HHr,"PerceiverFeatureExtractor"),HHr.forEach(t),Ldo=r(m3e," (Perceiver model)"),m3e.forEach(t),xdo=i(te),Mh=n(te,"LI",{});var g3e=s(Mh);Uae=n(g3e,"STRONG",{});var UHr=s(Uae);$do=r(UHr,"poolformer"),UHr.forEach(t),kdo=r(g3e," \u2014 "),jB=n(g3e,"A",{href:!0});var JHr=s(jB);Sdo=r(JHr,"PoolFormerFeatureExtractor"),JHr.forEach(t),Rdo=r(g3e," (PoolFormer model)"),g3e.forEach(t),Pdo=i(te),Eh=n(te,"LI",{});var h3e=s(Eh);Jae=n(h3e,"STRONG",{});var YHr=s(Jae);Bdo=r(YHr,"regnet"),YHr.forEach(t),Ido=r(h3e," \u2014 "),DB=n(h3e,"A",{href:!0});var KHr=s(DB);qdo=r(KHr,"ConvNextFeatureExtractor"),KHr.forEach(t),Ndo=r(h3e," (RegNet model)"),h3e.forEach(t),jdo=i(te),Ch=n(te,"LI",{});var p3e=s(Ch);Yae=n(p3e,"STRONG",{});var ZHr=s(Yae);Ddo=r(ZHr,"resnet"),ZHr.forEach(t),Gdo=r(p3e," \u2014 "),GB=n(p3e,"A",{href:!0});var eUr=s(GB);Odo=r(eUr,"ConvNextFeatureExtractor"),eUr.forEach(t),Vdo=r(p3e," (ResNet model)"),p3e.forEach(t),Xdo=i(te),wh=n(te,"LI",{});var u3e=s(wh);Kae=n(u3e,"STRONG",{});var oUr=s(Kae);zdo=r(oUr,"segformer"),oUr.forEach(t),Qdo=r(u3e," \u2014 "),OB=n(u3e,"A",{href:!0});var rUr=s(OB);Wdo=r(rUr,"SegformerFeatureExtractor"),rUr.forEach(t),Hdo=r(u3e," (SegFormer model)"),u3e.forEach(t),Udo=i(te),Ah=n(te,"LI",{});var _3e=s(Ah);Zae=n(_3e,"STRONG",{});var tUr=s(Zae);Jdo=r(tUr,"speech_to_text"),tUr.forEach(t),Ydo=r(_3e," \u2014 "),VB=n(_3e,"A",{href:!0});var aUr=s(VB);Kdo=r(aUr,"Speech2TextFeatureExtractor"),aUr.forEach(t),Zdo=r(_3e," (Speech2Text model)"),_3e.forEach(t),eco=i(te),yh=n(te,"LI",{});var b3e=s(yh);ene=n(b3e,"STRONG",{});var nUr=s(ene);oco=r(nUr,"swin"),nUr.forEach(t),rco=r(b3e," \u2014 "),XB=n(b3e,"A",{href:!0});var sUr=s(XB);tco=r(sUr,"ViTFeatureExtractor"),sUr.forEach(t),aco=r(b3e," (Swin model)"),b3e.forEach(t),nco=i(te),Lh=n(te,"LI",{});var v3e=s(Lh);one=n(v3e,"STRONG",{});var lUr=s(one);sco=r(lUr,"van"),lUr.forEach(t),lco=r(v3e," \u2014 "),zB=n(v3e,"A",{href:!0});var iUr=s(zB);ico=r(iUr,"ConvNextFeatureExtractor"),iUr.forEach(t),dco=r(v3e," (VAN model)"),v3e.forEach(t),cco=i(te),xh=n(te,"LI",{});var F3e=s(xh);rne=n(F3e,"STRONG",{});var dUr=s(rne);fco=r(dUr,"vilt"),dUr.forEach(t),mco=r(F3e," \u2014 "),QB=n(F3e,"A",{href:!0});var cUr=s(QB);gco=r(cUr,"ViltFeatureExtractor"),cUr.forEach(t),hco=r(F3e," (ViLT model)"),F3e.forEach(t),pco=i(te),$h=n(te,"LI",{});var T3e=s($h);tne=n(T3e,"STRONG",{});var fUr=s(tne);uco=r(fUr,"vit"),fUr.forEach(t),_co=r(T3e," \u2014 "),WB=n(T3e,"A",{href:!0});var mUr=s(WB);bco=r(mUr,"ViTFeatureExtractor"),mUr.forEach(t),vco=r(T3e," (ViT model)"),T3e.forEach(t),Fco=i(te),kh=n(te,"LI",{});var M3e=s(kh);ane=n(M3e,"STRONG",{});var gUr=s(ane);Tco=r(gUr,"vit_mae"),gUr.forEach(t),Mco=r(M3e," \u2014 "),HB=n(M3e,"A",{href:!0});var hUr=s(HB);Eco=r(hUr,"ViTFeatureExtractor"),hUr.forEach(t),Cco=r(M3e," (ViTMAE model)"),M3e.forEach(t),wco=i(te),Sh=n(te,"LI",{});var E3e=s(Sh);nne=n(E3e,"STRONG",{});var pUr=s(nne);Aco=r(pUr,"wav2vec2"),pUr.forEach(t),yco=r(E3e," \u2014 "),UB=n(E3e,"A",{href:!0});var uUr=s(UB);Lco=r(uUr,"Wav2Vec2FeatureExtractor"),uUr.forEach(t),xco=r(E3e," (Wav2Vec2 model)"),E3e.forEach(t),$co=i(te),Rh=n(te,"LI",{});var C3e=s(Rh);sne=n(C3e,"STRONG",{});var _Ur=s(sne);kco=r(_Ur,"yolos"),_Ur.forEach(t),Sco=r(C3e," \u2014 "),JB=n(C3e,"A",{href:!0});var bUr=s(JB);Rco=r(bUr,"YolosFeatureExtractor"),bUr.forEach(t),Pco=r(C3e," (YOLOS model)"),C3e.forEach(t),te.forEach(t),Bco=i(ea),T(Ph.$$.fragment,ea),Ico=i(ea),T(Bh.$$.fragment,ea),ea.forEach(t),qco=i(Vs),Ih=n(Vs,"DIV",{class:!0});var oje=s(Ih);T(BA.$$.fragment,oje),Nco=i(oje),lne=n(oje,"P",{});var vUr=s(lne);jco=r(vUr,"Register a new feature extractor for this class."),vUr.forEach(t),oje.forEach(t),Vs.forEach(t),KIe=i(f),Ai=n(f,"H2",{class:!0});var rje=s(Ai);qh=n(rje,"A",{id:!0,class:!0,href:!0});var FUr=s(qh);ine=n(FUr,"SPAN",{});var TUr=s(ine);T(IA.$$.fragment,TUr),TUr.forEach(t),FUr.forEach(t),Dco=i(rje),dne=n(rje,"SPAN",{});var MUr=s(dne);Gco=r(MUr,"AutoProcessor"),MUr.forEach(t),rje.forEach(t),ZIe=i(f),Lo=n(f,"DIV",{class:!0});var Xs=s(Lo);T(qA.$$.fragment,Xs),Oco=i(Xs),NA=n(Xs,"P",{});var tje=s(NA);Vco=r(tje,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),YB=n(tje,"A",{href:!0});var EUr=s(YB);Xco=r(EUr,"AutoProcessor.from_pretrained()"),EUr.forEach(t),zco=r(tje," class method."),tje.forEach(t),Qco=i(Xs),jA=n(Xs,"P",{});var aje=s(jA);Wco=r(aje,"This class cannot be instantiated directly using "),cne=n(aje,"CODE",{});var CUr=s(cne);Hco=r(CUr,"__init__()"),CUr.forEach(t),Uco=r(aje," (throws an error)."),aje.forEach(t),Jco=i(Xs),We=n(Xs,"DIV",{class:!0});var oa=s(We);T(DA.$$.fragment,oa),Yco=i(oa),fne=n(oa,"P",{});var wUr=s(fne);Kco=r(wUr,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),wUr.forEach(t),Zco=i(oa),yi=n(oa,"P",{});var jK=s(yi);efo=r(jK,"The processor class to instantiate is selected based on the "),mne=n(jK,"CODE",{});var AUr=s(mne);ofo=r(AUr,"model_type"),AUr.forEach(t),rfo=r(jK,` property of the config object (either
passed as an argument or loaded from `),gne=n(jK,"CODE",{});var yUr=s(gne);tfo=r(yUr,"pretrained_model_name_or_path"),yUr.forEach(t),afo=r(jK," if possible):"),jK.forEach(t),nfo=i(oa),be=n(oa,"UL",{});var ve=s(be);Nh=n(ve,"LI",{});var w3e=s(Nh);hne=n(w3e,"STRONG",{});var LUr=s(hne);sfo=r(LUr,"clip"),LUr.forEach(t),lfo=r(w3e," \u2014 "),KB=n(w3e,"A",{href:!0});var xUr=s(KB);ifo=r(xUr,"CLIPProcessor"),xUr.forEach(t),dfo=r(w3e," (CLIP model)"),w3e.forEach(t),cfo=i(ve),jh=n(ve,"LI",{});var A3e=s(jh);pne=n(A3e,"STRONG",{});var $Ur=s(pne);ffo=r($Ur,"flava"),$Ur.forEach(t),mfo=r(A3e," \u2014 "),une=n(A3e,"CODE",{});var kUr=s(une);gfo=r(kUr,"FLAVAProcessor"),kUr.forEach(t),hfo=r(A3e," (Flava model)"),A3e.forEach(t),pfo=i(ve),Dh=n(ve,"LI",{});var y3e=s(Dh);_ne=n(y3e,"STRONG",{});var SUr=s(_ne);ufo=r(SUr,"layoutlmv2"),SUr.forEach(t),_fo=r(y3e," \u2014 "),ZB=n(y3e,"A",{href:!0});var RUr=s(ZB);bfo=r(RUr,"LayoutLMv2Processor"),RUr.forEach(t),vfo=r(y3e," (LayoutLMv2 model)"),y3e.forEach(t),Ffo=i(ve),Gh=n(ve,"LI",{});var L3e=s(Gh);bne=n(L3e,"STRONG",{});var PUr=s(bne);Tfo=r(PUr,"layoutxlm"),PUr.forEach(t),Mfo=r(L3e," \u2014 "),eI=n(L3e,"A",{href:!0});var BUr=s(eI);Efo=r(BUr,"LayoutXLMProcessor"),BUr.forEach(t),Cfo=r(L3e," (LayoutXLM model)"),L3e.forEach(t),wfo=i(ve),Oh=n(ve,"LI",{});var x3e=s(Oh);vne=n(x3e,"STRONG",{});var IUr=s(vne);Afo=r(IUr,"sew"),IUr.forEach(t),yfo=r(x3e," \u2014 "),oI=n(x3e,"A",{href:!0});var qUr=s(oI);Lfo=r(qUr,"Wav2Vec2Processor"),qUr.forEach(t),xfo=r(x3e," (SEW model)"),x3e.forEach(t),$fo=i(ve),Vh=n(ve,"LI",{});var $3e=s(Vh);Fne=n($3e,"STRONG",{});var NUr=s(Fne);kfo=r(NUr,"sew-d"),NUr.forEach(t),Sfo=r($3e," \u2014 "),rI=n($3e,"A",{href:!0});var jUr=s(rI);Rfo=r(jUr,"Wav2Vec2Processor"),jUr.forEach(t),Pfo=r($3e," (SEW-D model)"),$3e.forEach(t),Bfo=i(ve),Xh=n(ve,"LI",{});var k3e=s(Xh);Tne=n(k3e,"STRONG",{});var DUr=s(Tne);Ifo=r(DUr,"speech_to_text"),DUr.forEach(t),qfo=r(k3e," \u2014 "),tI=n(k3e,"A",{href:!0});var GUr=s(tI);Nfo=r(GUr,"Speech2TextProcessor"),GUr.forEach(t),jfo=r(k3e," (Speech2Text model)"),k3e.forEach(t),Dfo=i(ve),zh=n(ve,"LI",{});var S3e=s(zh);Mne=n(S3e,"STRONG",{});var OUr=s(Mne);Gfo=r(OUr,"speech_to_text_2"),OUr.forEach(t),Ofo=r(S3e," \u2014 "),aI=n(S3e,"A",{href:!0});var VUr=s(aI);Vfo=r(VUr,"Speech2Text2Processor"),VUr.forEach(t),Xfo=r(S3e," (Speech2Text2 model)"),S3e.forEach(t),zfo=i(ve),Qh=n(ve,"LI",{});var R3e=s(Qh);Ene=n(R3e,"STRONG",{});var XUr=s(Ene);Qfo=r(XUr,"trocr"),XUr.forEach(t),Wfo=r(R3e," \u2014 "),nI=n(R3e,"A",{href:!0});var zUr=s(nI);Hfo=r(zUr,"TrOCRProcessor"),zUr.forEach(t),Ufo=r(R3e," (TrOCR model)"),R3e.forEach(t),Jfo=i(ve),Wh=n(ve,"LI",{});var P3e=s(Wh);Cne=n(P3e,"STRONG",{});var QUr=s(Cne);Yfo=r(QUr,"unispeech"),QUr.forEach(t),Kfo=r(P3e," \u2014 "),sI=n(P3e,"A",{href:!0});var WUr=s(sI);Zfo=r(WUr,"Wav2Vec2Processor"),WUr.forEach(t),emo=r(P3e," (UniSpeech model)"),P3e.forEach(t),omo=i(ve),Hh=n(ve,"LI",{});var B3e=s(Hh);wne=n(B3e,"STRONG",{});var HUr=s(wne);rmo=r(HUr,"unispeech-sat"),HUr.forEach(t),tmo=r(B3e," \u2014 "),lI=n(B3e,"A",{href:!0});var UUr=s(lI);amo=r(UUr,"Wav2Vec2Processor"),UUr.forEach(t),nmo=r(B3e," (UniSpeechSat model)"),B3e.forEach(t),smo=i(ve),Uh=n(ve,"LI",{});var I3e=s(Uh);Ane=n(I3e,"STRONG",{});var JUr=s(Ane);lmo=r(JUr,"vilt"),JUr.forEach(t),imo=r(I3e," \u2014 "),iI=n(I3e,"A",{href:!0});var YUr=s(iI);dmo=r(YUr,"ViltProcessor"),YUr.forEach(t),cmo=r(I3e," (ViLT model)"),I3e.forEach(t),fmo=i(ve),Jh=n(ve,"LI",{});var q3e=s(Jh);yne=n(q3e,"STRONG",{});var KUr=s(yne);mmo=r(KUr,"vision-text-dual-encoder"),KUr.forEach(t),gmo=r(q3e," \u2014 "),dI=n(q3e,"A",{href:!0});var ZUr=s(dI);hmo=r(ZUr,"VisionTextDualEncoderProcessor"),ZUr.forEach(t),pmo=r(q3e," (VisionTextDualEncoder model)"),q3e.forEach(t),umo=i(ve),Yh=n(ve,"LI",{});var N3e=s(Yh);Lne=n(N3e,"STRONG",{});var eJr=s(Lne);_mo=r(eJr,"wav2vec2"),eJr.forEach(t),bmo=r(N3e," \u2014 "),cI=n(N3e,"A",{href:!0});var oJr=s(cI);vmo=r(oJr,"Wav2Vec2Processor"),oJr.forEach(t),Fmo=r(N3e," (Wav2Vec2 model)"),N3e.forEach(t),Tmo=i(ve),Kh=n(ve,"LI",{});var j3e=s(Kh);xne=n(j3e,"STRONG",{});var rJr=s(xne);Mmo=r(rJr,"wavlm"),rJr.forEach(t),Emo=r(j3e," \u2014 "),fI=n(j3e,"A",{href:!0});var tJr=s(fI);Cmo=r(tJr,"Wav2Vec2Processor"),tJr.forEach(t),wmo=r(j3e," (WavLM model)"),j3e.forEach(t),ve.forEach(t),Amo=i(oa),T(Zh.$$.fragment,oa),ymo=i(oa),T(ep.$$.fragment,oa),oa.forEach(t),Lmo=i(Xs),op=n(Xs,"DIV",{class:!0});var nje=s(op);T(GA.$$.fragment,nje),xmo=i(nje),$ne=n(nje,"P",{});var aJr=s($ne);$mo=r(aJr,"Register a new processor for this class."),aJr.forEach(t),nje.forEach(t),Xs.forEach(t),eqe=i(f),Li=n(f,"H2",{class:!0});var sje=s(Li);rp=n(sje,"A",{id:!0,class:!0,href:!0});var nJr=s(rp);kne=n(nJr,"SPAN",{});var sJr=s(kne);T(OA.$$.fragment,sJr),sJr.forEach(t),nJr.forEach(t),kmo=i(sje),Sne=n(sje,"SPAN",{});var lJr=s(Sne);Smo=r(lJr,"AutoModel"),lJr.forEach(t),sje.forEach(t),oqe=i(f),xo=n(f,"DIV",{class:!0});var zs=s(xo);T(VA.$$.fragment,zs),Rmo=i(zs),xi=n(zs,"P",{});var DK=s(xi);Pmo=r(DK,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),mI=n(DK,"A",{href:!0});var iJr=s(mI);Bmo=r(iJr,"from_pretrained()"),iJr.forEach(t),Imo=r(DK," class method or the "),gI=n(DK,"A",{href:!0});var dJr=s(gI);qmo=r(dJr,"from_config()"),dJr.forEach(t),Nmo=r(DK,` class
method.`),DK.forEach(t),jmo=i(zs),XA=n(zs,"P",{});var lje=s(XA);Dmo=r(lje,"This class cannot be instantiated directly using "),Rne=n(lje,"CODE",{});var cJr=s(Rne);Gmo=r(cJr,"__init__()"),cJr.forEach(t),Omo=r(lje," (throws an error)."),lje.forEach(t),Vmo=i(zs),tt=n(zs,"DIV",{class:!0});var _3=s(tt);T(zA.$$.fragment,_3),Xmo=i(_3),Pne=n(_3,"P",{});var fJr=s(Pne);zmo=r(fJr,"Instantiates one of the base model classes of the library from a configuration."),fJr.forEach(t),Qmo=i(_3),$i=n(_3,"P",{});var GK=s($i);Wmo=r(GK,`Note:
Loading a model from its configuration file does `),Bne=n(GK,"STRONG",{});var mJr=s(Bne);Hmo=r(mJr,"not"),mJr.forEach(t),Umo=r(GK,` load the model weights. It only affects the
model\u2019s configuration. Use `),hI=n(GK,"A",{href:!0});var gJr=s(hI);Jmo=r(gJr,"from_pretrained()"),gJr.forEach(t),Ymo=r(GK," to load the model weights."),GK.forEach(t),Kmo=i(_3),T(tp.$$.fragment,_3),_3.forEach(t),Zmo=i(zs),He=n(zs,"DIV",{class:!0});var ra=s(He);T(QA.$$.fragment,ra),ego=i(ra),Ine=n(ra,"P",{});var hJr=s(Ine);ogo=r(hJr,"Instantiate one of the base model classes of the library from a pretrained model."),hJr.forEach(t),rgo=i(ra),$a=n(ra,"P",{});var b3=s($a);tgo=r(b3,"The model class to instantiate is selected based on the "),qne=n(b3,"CODE",{});var pJr=s(qne);ago=r(pJr,"model_type"),pJr.forEach(t),ngo=r(b3,` property of the config object (either
passed as an argument or loaded from `),Nne=n(b3,"CODE",{});var uJr=s(Nne);sgo=r(uJr,"pretrained_model_name_or_path"),uJr.forEach(t),lgo=r(b3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jne=n(b3,"CODE",{});var _Jr=s(jne);igo=r(_Jr,"pretrained_model_name_or_path"),_Jr.forEach(t),dgo=r(b3,":"),b3.forEach(t),cgo=i(ra),x=n(ra,"UL",{});var $=s(x);ap=n($,"LI",{});var D3e=s(ap);Dne=n(D3e,"STRONG",{});var bJr=s(Dne);fgo=r(bJr,"albert"),bJr.forEach(t),mgo=r(D3e," \u2014 "),pI=n(D3e,"A",{href:!0});var vJr=s(pI);ggo=r(vJr,"AlbertModel"),vJr.forEach(t),hgo=r(D3e," (ALBERT model)"),D3e.forEach(t),pgo=i($),np=n($,"LI",{});var G3e=s(np);Gne=n(G3e,"STRONG",{});var FJr=s(Gne);ugo=r(FJr,"bart"),FJr.forEach(t),_go=r(G3e," \u2014 "),uI=n(G3e,"A",{href:!0});var TJr=s(uI);bgo=r(TJr,"BartModel"),TJr.forEach(t),vgo=r(G3e," (BART model)"),G3e.forEach(t),Fgo=i($),sp=n($,"LI",{});var O3e=s(sp);One=n(O3e,"STRONG",{});var MJr=s(One);Tgo=r(MJr,"beit"),MJr.forEach(t),Mgo=r(O3e," \u2014 "),_I=n(O3e,"A",{href:!0});var EJr=s(_I);Ego=r(EJr,"BeitModel"),EJr.forEach(t),Cgo=r(O3e," (BEiT model)"),O3e.forEach(t),wgo=i($),lp=n($,"LI",{});var V3e=s(lp);Vne=n(V3e,"STRONG",{});var CJr=s(Vne);Ago=r(CJr,"bert"),CJr.forEach(t),ygo=r(V3e," \u2014 "),bI=n(V3e,"A",{href:!0});var wJr=s(bI);Lgo=r(wJr,"BertModel"),wJr.forEach(t),xgo=r(V3e," (BERT model)"),V3e.forEach(t),$go=i($),ip=n($,"LI",{});var X3e=s(ip);Xne=n(X3e,"STRONG",{});var AJr=s(Xne);kgo=r(AJr,"bert-generation"),AJr.forEach(t),Sgo=r(X3e," \u2014 "),vI=n(X3e,"A",{href:!0});var yJr=s(vI);Rgo=r(yJr,"BertGenerationEncoder"),yJr.forEach(t),Pgo=r(X3e," (Bert Generation model)"),X3e.forEach(t),Bgo=i($),dp=n($,"LI",{});var z3e=s(dp);zne=n(z3e,"STRONG",{});var LJr=s(zne);Igo=r(LJr,"big_bird"),LJr.forEach(t),qgo=r(z3e," \u2014 "),FI=n(z3e,"A",{href:!0});var xJr=s(FI);Ngo=r(xJr,"BigBirdModel"),xJr.forEach(t),jgo=r(z3e," (BigBird model)"),z3e.forEach(t),Dgo=i($),cp=n($,"LI",{});var Q3e=s(cp);Qne=n(Q3e,"STRONG",{});var $Jr=s(Qne);Ggo=r($Jr,"bigbird_pegasus"),$Jr.forEach(t),Ogo=r(Q3e," \u2014 "),TI=n(Q3e,"A",{href:!0});var kJr=s(TI);Vgo=r(kJr,"BigBirdPegasusModel"),kJr.forEach(t),Xgo=r(Q3e," (BigBirdPegasus model)"),Q3e.forEach(t),zgo=i($),fp=n($,"LI",{});var W3e=s(fp);Wne=n(W3e,"STRONG",{});var SJr=s(Wne);Qgo=r(SJr,"blenderbot"),SJr.forEach(t),Wgo=r(W3e," \u2014 "),MI=n(W3e,"A",{href:!0});var RJr=s(MI);Hgo=r(RJr,"BlenderbotModel"),RJr.forEach(t),Ugo=r(W3e," (Blenderbot model)"),W3e.forEach(t),Jgo=i($),mp=n($,"LI",{});var H3e=s(mp);Hne=n(H3e,"STRONG",{});var PJr=s(Hne);Ygo=r(PJr,"blenderbot-small"),PJr.forEach(t),Kgo=r(H3e," \u2014 "),EI=n(H3e,"A",{href:!0});var BJr=s(EI);Zgo=r(BJr,"BlenderbotSmallModel"),BJr.forEach(t),eho=r(H3e," (BlenderbotSmall model)"),H3e.forEach(t),oho=i($),gp=n($,"LI",{});var U3e=s(gp);Une=n(U3e,"STRONG",{});var IJr=s(Une);rho=r(IJr,"camembert"),IJr.forEach(t),tho=r(U3e," \u2014 "),CI=n(U3e,"A",{href:!0});var qJr=s(CI);aho=r(qJr,"CamembertModel"),qJr.forEach(t),nho=r(U3e," (CamemBERT model)"),U3e.forEach(t),sho=i($),hp=n($,"LI",{});var J3e=s(hp);Jne=n(J3e,"STRONG",{});var NJr=s(Jne);lho=r(NJr,"canine"),NJr.forEach(t),iho=r(J3e," \u2014 "),wI=n(J3e,"A",{href:!0});var jJr=s(wI);dho=r(jJr,"CanineModel"),jJr.forEach(t),cho=r(J3e," (Canine model)"),J3e.forEach(t),fho=i($),pp=n($,"LI",{});var Y3e=s(pp);Yne=n(Y3e,"STRONG",{});var DJr=s(Yne);mho=r(DJr,"clip"),DJr.forEach(t),gho=r(Y3e," \u2014 "),AI=n(Y3e,"A",{href:!0});var GJr=s(AI);hho=r(GJr,"CLIPModel"),GJr.forEach(t),pho=r(Y3e," (CLIP model)"),Y3e.forEach(t),uho=i($),up=n($,"LI",{});var K3e=s(up);Kne=n(K3e,"STRONG",{});var OJr=s(Kne);_ho=r(OJr,"convbert"),OJr.forEach(t),bho=r(K3e," \u2014 "),yI=n(K3e,"A",{href:!0});var VJr=s(yI);vho=r(VJr,"ConvBertModel"),VJr.forEach(t),Fho=r(K3e," (ConvBERT model)"),K3e.forEach(t),Tho=i($),_p=n($,"LI",{});var Z3e=s(_p);Zne=n(Z3e,"STRONG",{});var XJr=s(Zne);Mho=r(XJr,"convnext"),XJr.forEach(t),Eho=r(Z3e," \u2014 "),LI=n(Z3e,"A",{href:!0});var zJr=s(LI);Cho=r(zJr,"ConvNextModel"),zJr.forEach(t),who=r(Z3e," (ConvNext model)"),Z3e.forEach(t),Aho=i($),bp=n($,"LI",{});var ewe=s(bp);ese=n(ewe,"STRONG",{});var QJr=s(ese);yho=r(QJr,"ctrl"),QJr.forEach(t),Lho=r(ewe," \u2014 "),xI=n(ewe,"A",{href:!0});var WJr=s(xI);xho=r(WJr,"CTRLModel"),WJr.forEach(t),$ho=r(ewe," (CTRL model)"),ewe.forEach(t),kho=i($),vp=n($,"LI",{});var owe=s(vp);ose=n(owe,"STRONG",{});var HJr=s(ose);Sho=r(HJr,"data2vec-audio"),HJr.forEach(t),Rho=r(owe," \u2014 "),$I=n(owe,"A",{href:!0});var UJr=s($I);Pho=r(UJr,"Data2VecAudioModel"),UJr.forEach(t),Bho=r(owe," (Data2VecAudio model)"),owe.forEach(t),Iho=i($),Fp=n($,"LI",{});var rwe=s(Fp);rse=n(rwe,"STRONG",{});var JJr=s(rse);qho=r(JJr,"data2vec-text"),JJr.forEach(t),Nho=r(rwe," \u2014 "),kI=n(rwe,"A",{href:!0});var YJr=s(kI);jho=r(YJr,"Data2VecTextModel"),YJr.forEach(t),Dho=r(rwe," (Data2VecText model)"),rwe.forEach(t),Gho=i($),Tp=n($,"LI",{});var twe=s(Tp);tse=n(twe,"STRONG",{});var KJr=s(tse);Oho=r(KJr,"data2vec-vision"),KJr.forEach(t),Vho=r(twe," \u2014 "),SI=n(twe,"A",{href:!0});var ZJr=s(SI);Xho=r(ZJr,"Data2VecVisionModel"),ZJr.forEach(t),zho=r(twe," (Data2VecVision model)"),twe.forEach(t),Qho=i($),Mp=n($,"LI",{});var awe=s(Mp);ase=n(awe,"STRONG",{});var eYr=s(ase);Who=r(eYr,"deberta"),eYr.forEach(t),Hho=r(awe," \u2014 "),RI=n(awe,"A",{href:!0});var oYr=s(RI);Uho=r(oYr,"DebertaModel"),oYr.forEach(t),Jho=r(awe," (DeBERTa model)"),awe.forEach(t),Yho=i($),Ep=n($,"LI",{});var nwe=s(Ep);nse=n(nwe,"STRONG",{});var rYr=s(nse);Kho=r(rYr,"deberta-v2"),rYr.forEach(t),Zho=r(nwe," \u2014 "),PI=n(nwe,"A",{href:!0});var tYr=s(PI);epo=r(tYr,"DebertaV2Model"),tYr.forEach(t),opo=r(nwe," (DeBERTa-v2 model)"),nwe.forEach(t),rpo=i($),Cp=n($,"LI",{});var swe=s(Cp);sse=n(swe,"STRONG",{});var aYr=s(sse);tpo=r(aYr,"decision_transformer"),aYr.forEach(t),apo=r(swe," \u2014 "),BI=n(swe,"A",{href:!0});var nYr=s(BI);npo=r(nYr,"DecisionTransformerModel"),nYr.forEach(t),spo=r(swe," (Decision Transformer model)"),swe.forEach(t),lpo=i($),wp=n($,"LI",{});var lwe=s(wp);lse=n(lwe,"STRONG",{});var sYr=s(lse);ipo=r(sYr,"deit"),sYr.forEach(t),dpo=r(lwe," \u2014 "),II=n(lwe,"A",{href:!0});var lYr=s(II);cpo=r(lYr,"DeiTModel"),lYr.forEach(t),fpo=r(lwe," (DeiT model)"),lwe.forEach(t),mpo=i($),Ap=n($,"LI",{});var iwe=s(Ap);ise=n(iwe,"STRONG",{});var iYr=s(ise);gpo=r(iYr,"detr"),iYr.forEach(t),hpo=r(iwe," \u2014 "),qI=n(iwe,"A",{href:!0});var dYr=s(qI);ppo=r(dYr,"DetrModel"),dYr.forEach(t),upo=r(iwe," (DETR model)"),iwe.forEach(t),_po=i($),yp=n($,"LI",{});var dwe=s(yp);dse=n(dwe,"STRONG",{});var cYr=s(dse);bpo=r(cYr,"distilbert"),cYr.forEach(t),vpo=r(dwe," \u2014 "),NI=n(dwe,"A",{href:!0});var fYr=s(NI);Fpo=r(fYr,"DistilBertModel"),fYr.forEach(t),Tpo=r(dwe," (DistilBERT model)"),dwe.forEach(t),Mpo=i($),Lp=n($,"LI",{});var cwe=s(Lp);cse=n(cwe,"STRONG",{});var mYr=s(cse);Epo=r(mYr,"dpr"),mYr.forEach(t),Cpo=r(cwe," \u2014 "),jI=n(cwe,"A",{href:!0});var gYr=s(jI);wpo=r(gYr,"DPRQuestionEncoder"),gYr.forEach(t),Apo=r(cwe," (DPR model)"),cwe.forEach(t),ypo=i($),xp=n($,"LI",{});var fwe=s(xp);fse=n(fwe,"STRONG",{});var hYr=s(fse);Lpo=r(hYr,"dpt"),hYr.forEach(t),xpo=r(fwe," \u2014 "),DI=n(fwe,"A",{href:!0});var pYr=s(DI);$po=r(pYr,"DPTModel"),pYr.forEach(t),kpo=r(fwe," (DPT model)"),fwe.forEach(t),Spo=i($),$p=n($,"LI",{});var mwe=s($p);mse=n(mwe,"STRONG",{});var uYr=s(mse);Rpo=r(uYr,"electra"),uYr.forEach(t),Ppo=r(mwe," \u2014 "),GI=n(mwe,"A",{href:!0});var _Yr=s(GI);Bpo=r(_Yr,"ElectraModel"),_Yr.forEach(t),Ipo=r(mwe," (ELECTRA model)"),mwe.forEach(t),qpo=i($),kp=n($,"LI",{});var gwe=s(kp);gse=n(gwe,"STRONG",{});var bYr=s(gse);Npo=r(bYr,"flaubert"),bYr.forEach(t),jpo=r(gwe," \u2014 "),OI=n(gwe,"A",{href:!0});var vYr=s(OI);Dpo=r(vYr,"FlaubertModel"),vYr.forEach(t),Gpo=r(gwe," (FlauBERT model)"),gwe.forEach(t),Opo=i($),Sp=n($,"LI",{});var hwe=s(Sp);hse=n(hwe,"STRONG",{});var FYr=s(hse);Vpo=r(FYr,"flava"),FYr.forEach(t),Xpo=r(hwe," \u2014 "),VI=n(hwe,"A",{href:!0});var TYr=s(VI);zpo=r(TYr,"FlavaModel"),TYr.forEach(t),Qpo=r(hwe," (Flava model)"),hwe.forEach(t),Wpo=i($),Rp=n($,"LI",{});var pwe=s(Rp);pse=n(pwe,"STRONG",{});var MYr=s(pse);Hpo=r(MYr,"fnet"),MYr.forEach(t),Upo=r(pwe," \u2014 "),XI=n(pwe,"A",{href:!0});var EYr=s(XI);Jpo=r(EYr,"FNetModel"),EYr.forEach(t),Ypo=r(pwe," (FNet model)"),pwe.forEach(t),Kpo=i($),Pp=n($,"LI",{});var uwe=s(Pp);use=n(uwe,"STRONG",{});var CYr=s(use);Zpo=r(CYr,"fsmt"),CYr.forEach(t),euo=r(uwe," \u2014 "),zI=n(uwe,"A",{href:!0});var wYr=s(zI);ouo=r(wYr,"FSMTModel"),wYr.forEach(t),ruo=r(uwe," (FairSeq Machine-Translation model)"),uwe.forEach(t),tuo=i($),Ns=n($,"LI",{});var I$=s(Ns);_se=n(I$,"STRONG",{});var AYr=s(_se);auo=r(AYr,"funnel"),AYr.forEach(t),nuo=r(I$," \u2014 "),QI=n(I$,"A",{href:!0});var yYr=s(QI);suo=r(yYr,"FunnelModel"),yYr.forEach(t),luo=r(I$," or "),WI=n(I$,"A",{href:!0});var LYr=s(WI);iuo=r(LYr,"FunnelBaseModel"),LYr.forEach(t),duo=r(I$," (Funnel Transformer model)"),I$.forEach(t),cuo=i($),Bp=n($,"LI",{});var _we=s(Bp);bse=n(_we,"STRONG",{});var xYr=s(bse);fuo=r(xYr,"glpn"),xYr.forEach(t),muo=r(_we," \u2014 "),HI=n(_we,"A",{href:!0});var $Yr=s(HI);guo=r($Yr,"GLPNModel"),$Yr.forEach(t),huo=r(_we," (GLPN model)"),_we.forEach(t),puo=i($),Ip=n($,"LI",{});var bwe=s(Ip);vse=n(bwe,"STRONG",{});var kYr=s(vse);uuo=r(kYr,"gpt2"),kYr.forEach(t),_uo=r(bwe," \u2014 "),UI=n(bwe,"A",{href:!0});var SYr=s(UI);buo=r(SYr,"GPT2Model"),SYr.forEach(t),vuo=r(bwe," (OpenAI GPT-2 model)"),bwe.forEach(t),Fuo=i($),qp=n($,"LI",{});var vwe=s(qp);Fse=n(vwe,"STRONG",{});var RYr=s(Fse);Tuo=r(RYr,"gpt_neo"),RYr.forEach(t),Muo=r(vwe," \u2014 "),JI=n(vwe,"A",{href:!0});var PYr=s(JI);Euo=r(PYr,"GPTNeoModel"),PYr.forEach(t),Cuo=r(vwe," (GPT Neo model)"),vwe.forEach(t),wuo=i($),Np=n($,"LI",{});var Fwe=s(Np);Tse=n(Fwe,"STRONG",{});var BYr=s(Tse);Auo=r(BYr,"gptj"),BYr.forEach(t),yuo=r(Fwe," \u2014 "),YI=n(Fwe,"A",{href:!0});var IYr=s(YI);Luo=r(IYr,"GPTJModel"),IYr.forEach(t),xuo=r(Fwe," (GPT-J model)"),Fwe.forEach(t),$uo=i($),jp=n($,"LI",{});var Twe=s(jp);Mse=n(Twe,"STRONG",{});var qYr=s(Mse);kuo=r(qYr,"hubert"),qYr.forEach(t),Suo=r(Twe," \u2014 "),KI=n(Twe,"A",{href:!0});var NYr=s(KI);Ruo=r(NYr,"HubertModel"),NYr.forEach(t),Puo=r(Twe," (Hubert model)"),Twe.forEach(t),Buo=i($),Dp=n($,"LI",{});var Mwe=s(Dp);Ese=n(Mwe,"STRONG",{});var jYr=s(Ese);Iuo=r(jYr,"ibert"),jYr.forEach(t),quo=r(Mwe," \u2014 "),ZI=n(Mwe,"A",{href:!0});var DYr=s(ZI);Nuo=r(DYr,"IBertModel"),DYr.forEach(t),juo=r(Mwe," (I-BERT model)"),Mwe.forEach(t),Duo=i($),Gp=n($,"LI",{});var Ewe=s(Gp);Cse=n(Ewe,"STRONG",{});var GYr=s(Cse);Guo=r(GYr,"imagegpt"),GYr.forEach(t),Ouo=r(Ewe," \u2014 "),eq=n(Ewe,"A",{href:!0});var OYr=s(eq);Vuo=r(OYr,"ImageGPTModel"),OYr.forEach(t),Xuo=r(Ewe," (ImageGPT model)"),Ewe.forEach(t),zuo=i($),Op=n($,"LI",{});var Cwe=s(Op);wse=n(Cwe,"STRONG",{});var VYr=s(wse);Quo=r(VYr,"layoutlm"),VYr.forEach(t),Wuo=r(Cwe," \u2014 "),oq=n(Cwe,"A",{href:!0});var XYr=s(oq);Huo=r(XYr,"LayoutLMModel"),XYr.forEach(t),Uuo=r(Cwe," (LayoutLM model)"),Cwe.forEach(t),Juo=i($),Vp=n($,"LI",{});var wwe=s(Vp);Ase=n(wwe,"STRONG",{});var zYr=s(Ase);Yuo=r(zYr,"layoutlmv2"),zYr.forEach(t),Kuo=r(wwe," \u2014 "),rq=n(wwe,"A",{href:!0});var QYr=s(rq);Zuo=r(QYr,"LayoutLMv2Model"),QYr.forEach(t),e_o=r(wwe," (LayoutLMv2 model)"),wwe.forEach(t),o_o=i($),Xp=n($,"LI",{});var Awe=s(Xp);yse=n(Awe,"STRONG",{});var WYr=s(yse);r_o=r(WYr,"led"),WYr.forEach(t),t_o=r(Awe," \u2014 "),tq=n(Awe,"A",{href:!0});var HYr=s(tq);a_o=r(HYr,"LEDModel"),HYr.forEach(t),n_o=r(Awe," (LED model)"),Awe.forEach(t),s_o=i($),zp=n($,"LI",{});var ywe=s(zp);Lse=n(ywe,"STRONG",{});var UYr=s(Lse);l_o=r(UYr,"longformer"),UYr.forEach(t),i_o=r(ywe," \u2014 "),aq=n(ywe,"A",{href:!0});var JYr=s(aq);d_o=r(JYr,"LongformerModel"),JYr.forEach(t),c_o=r(ywe," (Longformer model)"),ywe.forEach(t),f_o=i($),Qp=n($,"LI",{});var Lwe=s(Qp);xse=n(Lwe,"STRONG",{});var YYr=s(xse);m_o=r(YYr,"luke"),YYr.forEach(t),g_o=r(Lwe," \u2014 "),nq=n(Lwe,"A",{href:!0});var KYr=s(nq);h_o=r(KYr,"LukeModel"),KYr.forEach(t),p_o=r(Lwe," (LUKE model)"),Lwe.forEach(t),u_o=i($),Wp=n($,"LI",{});var xwe=s(Wp);$se=n(xwe,"STRONG",{});var ZYr=s($se);__o=r(ZYr,"lxmert"),ZYr.forEach(t),b_o=r(xwe," \u2014 "),sq=n(xwe,"A",{href:!0});var eKr=s(sq);v_o=r(eKr,"LxmertModel"),eKr.forEach(t),F_o=r(xwe," (LXMERT model)"),xwe.forEach(t),T_o=i($),Hp=n($,"LI",{});var $we=s(Hp);kse=n($we,"STRONG",{});var oKr=s(kse);M_o=r(oKr,"m2m_100"),oKr.forEach(t),E_o=r($we," \u2014 "),lq=n($we,"A",{href:!0});var rKr=s(lq);C_o=r(rKr,"M2M100Model"),rKr.forEach(t),w_o=r($we," (M2M100 model)"),$we.forEach(t),A_o=i($),Up=n($,"LI",{});var kwe=s(Up);Sse=n(kwe,"STRONG",{});var tKr=s(Sse);y_o=r(tKr,"marian"),tKr.forEach(t),L_o=r(kwe," \u2014 "),iq=n(kwe,"A",{href:!0});var aKr=s(iq);x_o=r(aKr,"MarianModel"),aKr.forEach(t),$_o=r(kwe," (Marian model)"),kwe.forEach(t),k_o=i($),Jp=n($,"LI",{});var Swe=s(Jp);Rse=n(Swe,"STRONG",{});var nKr=s(Rse);S_o=r(nKr,"maskformer"),nKr.forEach(t),R_o=r(Swe," \u2014 "),dq=n(Swe,"A",{href:!0});var sKr=s(dq);P_o=r(sKr,"MaskFormerModel"),sKr.forEach(t),B_o=r(Swe," (MaskFormer model)"),Swe.forEach(t),I_o=i($),Yp=n($,"LI",{});var Rwe=s(Yp);Pse=n(Rwe,"STRONG",{});var lKr=s(Pse);q_o=r(lKr,"mbart"),lKr.forEach(t),N_o=r(Rwe," \u2014 "),cq=n(Rwe,"A",{href:!0});var iKr=s(cq);j_o=r(iKr,"MBartModel"),iKr.forEach(t),D_o=r(Rwe," (mBART model)"),Rwe.forEach(t),G_o=i($),Kp=n($,"LI",{});var Pwe=s(Kp);Bse=n(Pwe,"STRONG",{});var dKr=s(Bse);O_o=r(dKr,"megatron-bert"),dKr.forEach(t),V_o=r(Pwe," \u2014 "),fq=n(Pwe,"A",{href:!0});var cKr=s(fq);X_o=r(cKr,"MegatronBertModel"),cKr.forEach(t),z_o=r(Pwe," (MegatronBert model)"),Pwe.forEach(t),Q_o=i($),Zp=n($,"LI",{});var Bwe=s(Zp);Ise=n(Bwe,"STRONG",{});var fKr=s(Ise);W_o=r(fKr,"mobilebert"),fKr.forEach(t),H_o=r(Bwe," \u2014 "),mq=n(Bwe,"A",{href:!0});var mKr=s(mq);U_o=r(mKr,"MobileBertModel"),mKr.forEach(t),J_o=r(Bwe," (MobileBERT model)"),Bwe.forEach(t),Y_o=i($),eu=n($,"LI",{});var Iwe=s(eu);qse=n(Iwe,"STRONG",{});var gKr=s(qse);K_o=r(gKr,"mpnet"),gKr.forEach(t),Z_o=r(Iwe," \u2014 "),gq=n(Iwe,"A",{href:!0});var hKr=s(gq);e2o=r(hKr,"MPNetModel"),hKr.forEach(t),o2o=r(Iwe," (MPNet model)"),Iwe.forEach(t),r2o=i($),ou=n($,"LI",{});var qwe=s(ou);Nse=n(qwe,"STRONG",{});var pKr=s(Nse);t2o=r(pKr,"mt5"),pKr.forEach(t),a2o=r(qwe," \u2014 "),hq=n(qwe,"A",{href:!0});var uKr=s(hq);n2o=r(uKr,"MT5Model"),uKr.forEach(t),s2o=r(qwe," (mT5 model)"),qwe.forEach(t),l2o=i($),ru=n($,"LI",{});var Nwe=s(ru);jse=n(Nwe,"STRONG",{});var _Kr=s(jse);i2o=r(_Kr,"nystromformer"),_Kr.forEach(t),d2o=r(Nwe," \u2014 "),pq=n(Nwe,"A",{href:!0});var bKr=s(pq);c2o=r(bKr,"NystromformerModel"),bKr.forEach(t),f2o=r(Nwe," (Nystromformer model)"),Nwe.forEach(t),m2o=i($),tu=n($,"LI",{});var jwe=s(tu);Dse=n(jwe,"STRONG",{});var vKr=s(Dse);g2o=r(vKr,"openai-gpt"),vKr.forEach(t),h2o=r(jwe," \u2014 "),uq=n(jwe,"A",{href:!0});var FKr=s(uq);p2o=r(FKr,"OpenAIGPTModel"),FKr.forEach(t),u2o=r(jwe," (OpenAI GPT model)"),jwe.forEach(t),_2o=i($),au=n($,"LI",{});var Dwe=s(au);Gse=n(Dwe,"STRONG",{});var TKr=s(Gse);b2o=r(TKr,"opt"),TKr.forEach(t),v2o=r(Dwe," \u2014 "),_q=n(Dwe,"A",{href:!0});var MKr=s(_q);F2o=r(MKr,"OPTModel"),MKr.forEach(t),T2o=r(Dwe," (OPT model)"),Dwe.forEach(t),M2o=i($),nu=n($,"LI",{});var Gwe=s(nu);Ose=n(Gwe,"STRONG",{});var EKr=s(Ose);E2o=r(EKr,"pegasus"),EKr.forEach(t),C2o=r(Gwe," \u2014 "),bq=n(Gwe,"A",{href:!0});var CKr=s(bq);w2o=r(CKr,"PegasusModel"),CKr.forEach(t),A2o=r(Gwe," (Pegasus model)"),Gwe.forEach(t),y2o=i($),su=n($,"LI",{});var Owe=s(su);Vse=n(Owe,"STRONG",{});var wKr=s(Vse);L2o=r(wKr,"perceiver"),wKr.forEach(t),x2o=r(Owe," \u2014 "),vq=n(Owe,"A",{href:!0});var AKr=s(vq);$2o=r(AKr,"PerceiverModel"),AKr.forEach(t),k2o=r(Owe," (Perceiver model)"),Owe.forEach(t),S2o=i($),lu=n($,"LI",{});var Vwe=s(lu);Xse=n(Vwe,"STRONG",{});var yKr=s(Xse);R2o=r(yKr,"plbart"),yKr.forEach(t),P2o=r(Vwe," \u2014 "),Fq=n(Vwe,"A",{href:!0});var LKr=s(Fq);B2o=r(LKr,"PLBartModel"),LKr.forEach(t),I2o=r(Vwe," (PLBart model)"),Vwe.forEach(t),q2o=i($),iu=n($,"LI",{});var Xwe=s(iu);zse=n(Xwe,"STRONG",{});var xKr=s(zse);N2o=r(xKr,"poolformer"),xKr.forEach(t),j2o=r(Xwe," \u2014 "),Tq=n(Xwe,"A",{href:!0});var $Kr=s(Tq);D2o=r($Kr,"PoolFormerModel"),$Kr.forEach(t),G2o=r(Xwe," (PoolFormer model)"),Xwe.forEach(t),O2o=i($),du=n($,"LI",{});var zwe=s(du);Qse=n(zwe,"STRONG",{});var kKr=s(Qse);V2o=r(kKr,"prophetnet"),kKr.forEach(t),X2o=r(zwe," \u2014 "),Mq=n(zwe,"A",{href:!0});var SKr=s(Mq);z2o=r(SKr,"ProphetNetModel"),SKr.forEach(t),Q2o=r(zwe," (ProphetNet model)"),zwe.forEach(t),W2o=i($),cu=n($,"LI",{});var Qwe=s(cu);Wse=n(Qwe,"STRONG",{});var RKr=s(Wse);H2o=r(RKr,"qdqbert"),RKr.forEach(t),U2o=r(Qwe," \u2014 "),Eq=n(Qwe,"A",{href:!0});var PKr=s(Eq);J2o=r(PKr,"QDQBertModel"),PKr.forEach(t),Y2o=r(Qwe," (QDQBert model)"),Qwe.forEach(t),K2o=i($),fu=n($,"LI",{});var Wwe=s(fu);Hse=n(Wwe,"STRONG",{});var BKr=s(Hse);Z2o=r(BKr,"reformer"),BKr.forEach(t),e1o=r(Wwe," \u2014 "),Cq=n(Wwe,"A",{href:!0});var IKr=s(Cq);o1o=r(IKr,"ReformerModel"),IKr.forEach(t),r1o=r(Wwe," (Reformer model)"),Wwe.forEach(t),t1o=i($),mu=n($,"LI",{});var Hwe=s(mu);Use=n(Hwe,"STRONG",{});var qKr=s(Use);a1o=r(qKr,"regnet"),qKr.forEach(t),n1o=r(Hwe," \u2014 "),wq=n(Hwe,"A",{href:!0});var NKr=s(wq);s1o=r(NKr,"RegNetModel"),NKr.forEach(t),l1o=r(Hwe," (RegNet model)"),Hwe.forEach(t),i1o=i($),gu=n($,"LI",{});var Uwe=s(gu);Jse=n(Uwe,"STRONG",{});var jKr=s(Jse);d1o=r(jKr,"rembert"),jKr.forEach(t),c1o=r(Uwe," \u2014 "),Aq=n(Uwe,"A",{href:!0});var DKr=s(Aq);f1o=r(DKr,"RemBertModel"),DKr.forEach(t),m1o=r(Uwe," (RemBERT model)"),Uwe.forEach(t),g1o=i($),hu=n($,"LI",{});var Jwe=s(hu);Yse=n(Jwe,"STRONG",{});var GKr=s(Yse);h1o=r(GKr,"resnet"),GKr.forEach(t),p1o=r(Jwe," \u2014 "),yq=n(Jwe,"A",{href:!0});var OKr=s(yq);u1o=r(OKr,"ResNetModel"),OKr.forEach(t),_1o=r(Jwe," (ResNet model)"),Jwe.forEach(t),b1o=i($),pu=n($,"LI",{});var Ywe=s(pu);Kse=n(Ywe,"STRONG",{});var VKr=s(Kse);v1o=r(VKr,"retribert"),VKr.forEach(t),F1o=r(Ywe," \u2014 "),Lq=n(Ywe,"A",{href:!0});var XKr=s(Lq);T1o=r(XKr,"RetriBertModel"),XKr.forEach(t),M1o=r(Ywe," (RetriBERT model)"),Ywe.forEach(t),E1o=i($),uu=n($,"LI",{});var Kwe=s(uu);Zse=n(Kwe,"STRONG",{});var zKr=s(Zse);C1o=r(zKr,"roberta"),zKr.forEach(t),w1o=r(Kwe," \u2014 "),xq=n(Kwe,"A",{href:!0});var QKr=s(xq);A1o=r(QKr,"RobertaModel"),QKr.forEach(t),y1o=r(Kwe," (RoBERTa model)"),Kwe.forEach(t),L1o=i($),_u=n($,"LI",{});var Zwe=s(_u);ele=n(Zwe,"STRONG",{});var WKr=s(ele);x1o=r(WKr,"roformer"),WKr.forEach(t),$1o=r(Zwe," \u2014 "),$q=n(Zwe,"A",{href:!0});var HKr=s($q);k1o=r(HKr,"RoFormerModel"),HKr.forEach(t),S1o=r(Zwe," (RoFormer model)"),Zwe.forEach(t),R1o=i($),bu=n($,"LI",{});var eAe=s(bu);ole=n(eAe,"STRONG",{});var UKr=s(ole);P1o=r(UKr,"segformer"),UKr.forEach(t),B1o=r(eAe," \u2014 "),kq=n(eAe,"A",{href:!0});var JKr=s(kq);I1o=r(JKr,"SegformerModel"),JKr.forEach(t),q1o=r(eAe," (SegFormer model)"),eAe.forEach(t),N1o=i($),vu=n($,"LI",{});var oAe=s(vu);rle=n(oAe,"STRONG",{});var YKr=s(rle);j1o=r(YKr,"sew"),YKr.forEach(t),D1o=r(oAe," \u2014 "),Sq=n(oAe,"A",{href:!0});var KKr=s(Sq);G1o=r(KKr,"SEWModel"),KKr.forEach(t),O1o=r(oAe," (SEW model)"),oAe.forEach(t),V1o=i($),Fu=n($,"LI",{});var rAe=s(Fu);tle=n(rAe,"STRONG",{});var ZKr=s(tle);X1o=r(ZKr,"sew-d"),ZKr.forEach(t),z1o=r(rAe," \u2014 "),Rq=n(rAe,"A",{href:!0});var eZr=s(Rq);Q1o=r(eZr,"SEWDModel"),eZr.forEach(t),W1o=r(rAe," (SEW-D model)"),rAe.forEach(t),H1o=i($),Tu=n($,"LI",{});var tAe=s(Tu);ale=n(tAe,"STRONG",{});var oZr=s(ale);U1o=r(oZr,"speech_to_text"),oZr.forEach(t),J1o=r(tAe," \u2014 "),Pq=n(tAe,"A",{href:!0});var rZr=s(Pq);Y1o=r(rZr,"Speech2TextModel"),rZr.forEach(t),K1o=r(tAe," (Speech2Text model)"),tAe.forEach(t),Z1o=i($),Mu=n($,"LI",{});var aAe=s(Mu);nle=n(aAe,"STRONG",{});var tZr=s(nle);ebo=r(tZr,"splinter"),tZr.forEach(t),obo=r(aAe," \u2014 "),Bq=n(aAe,"A",{href:!0});var aZr=s(Bq);rbo=r(aZr,"SplinterModel"),aZr.forEach(t),tbo=r(aAe," (Splinter model)"),aAe.forEach(t),abo=i($),Eu=n($,"LI",{});var nAe=s(Eu);sle=n(nAe,"STRONG",{});var nZr=s(sle);nbo=r(nZr,"squeezebert"),nZr.forEach(t),sbo=r(nAe," \u2014 "),Iq=n(nAe,"A",{href:!0});var sZr=s(Iq);lbo=r(sZr,"SqueezeBertModel"),sZr.forEach(t),ibo=r(nAe," (SqueezeBERT model)"),nAe.forEach(t),dbo=i($),Cu=n($,"LI",{});var sAe=s(Cu);lle=n(sAe,"STRONG",{});var lZr=s(lle);cbo=r(lZr,"swin"),lZr.forEach(t),fbo=r(sAe," \u2014 "),qq=n(sAe,"A",{href:!0});var iZr=s(qq);mbo=r(iZr,"SwinModel"),iZr.forEach(t),gbo=r(sAe," (Swin model)"),sAe.forEach(t),hbo=i($),wu=n($,"LI",{});var lAe=s(wu);ile=n(lAe,"STRONG",{});var dZr=s(ile);pbo=r(dZr,"t5"),dZr.forEach(t),ubo=r(lAe," \u2014 "),Nq=n(lAe,"A",{href:!0});var cZr=s(Nq);_bo=r(cZr,"T5Model"),cZr.forEach(t),bbo=r(lAe," (T5 model)"),lAe.forEach(t),vbo=i($),Au=n($,"LI",{});var iAe=s(Au);dle=n(iAe,"STRONG",{});var fZr=s(dle);Fbo=r(fZr,"tapas"),fZr.forEach(t),Tbo=r(iAe," \u2014 "),jq=n(iAe,"A",{href:!0});var mZr=s(jq);Mbo=r(mZr,"TapasModel"),mZr.forEach(t),Ebo=r(iAe," (TAPAS model)"),iAe.forEach(t),Cbo=i($),yu=n($,"LI",{});var dAe=s(yu);cle=n(dAe,"STRONG",{});var gZr=s(cle);wbo=r(gZr,"transfo-xl"),gZr.forEach(t),Abo=r(dAe," \u2014 "),Dq=n(dAe,"A",{href:!0});var hZr=s(Dq);ybo=r(hZr,"TransfoXLModel"),hZr.forEach(t),Lbo=r(dAe," (Transformer-XL model)"),dAe.forEach(t),xbo=i($),Lu=n($,"LI",{});var cAe=s(Lu);fle=n(cAe,"STRONG",{});var pZr=s(fle);$bo=r(pZr,"unispeech"),pZr.forEach(t),kbo=r(cAe," \u2014 "),Gq=n(cAe,"A",{href:!0});var uZr=s(Gq);Sbo=r(uZr,"UniSpeechModel"),uZr.forEach(t),Rbo=r(cAe," (UniSpeech model)"),cAe.forEach(t),Pbo=i($),xu=n($,"LI",{});var fAe=s(xu);mle=n(fAe,"STRONG",{});var _Zr=s(mle);Bbo=r(_Zr,"unispeech-sat"),_Zr.forEach(t),Ibo=r(fAe," \u2014 "),Oq=n(fAe,"A",{href:!0});var bZr=s(Oq);qbo=r(bZr,"UniSpeechSatModel"),bZr.forEach(t),Nbo=r(fAe," (UniSpeechSat model)"),fAe.forEach(t),jbo=i($),$u=n($,"LI",{});var mAe=s($u);gle=n(mAe,"STRONG",{});var vZr=s(gle);Dbo=r(vZr,"van"),vZr.forEach(t),Gbo=r(mAe," \u2014 "),Vq=n(mAe,"A",{href:!0});var FZr=s(Vq);Obo=r(FZr,"VanModel"),FZr.forEach(t),Vbo=r(mAe," (VAN model)"),mAe.forEach(t),Xbo=i($),ku=n($,"LI",{});var gAe=s(ku);hle=n(gAe,"STRONG",{});var TZr=s(hle);zbo=r(TZr,"vilt"),TZr.forEach(t),Qbo=r(gAe," \u2014 "),Xq=n(gAe,"A",{href:!0});var MZr=s(Xq);Wbo=r(MZr,"ViltModel"),MZr.forEach(t),Hbo=r(gAe," (ViLT model)"),gAe.forEach(t),Ubo=i($),Su=n($,"LI",{});var hAe=s(Su);ple=n(hAe,"STRONG",{});var EZr=s(ple);Jbo=r(EZr,"vision-text-dual-encoder"),EZr.forEach(t),Ybo=r(hAe," \u2014 "),zq=n(hAe,"A",{href:!0});var CZr=s(zq);Kbo=r(CZr,"VisionTextDualEncoderModel"),CZr.forEach(t),Zbo=r(hAe," (VisionTextDualEncoder model)"),hAe.forEach(t),evo=i($),Ru=n($,"LI",{});var pAe=s(Ru);ule=n(pAe,"STRONG",{});var wZr=s(ule);ovo=r(wZr,"visual_bert"),wZr.forEach(t),rvo=r(pAe," \u2014 "),Qq=n(pAe,"A",{href:!0});var AZr=s(Qq);tvo=r(AZr,"VisualBertModel"),AZr.forEach(t),avo=r(pAe," (VisualBert model)"),pAe.forEach(t),nvo=i($),Pu=n($,"LI",{});var uAe=s(Pu);_le=n(uAe,"STRONG",{});var yZr=s(_le);svo=r(yZr,"vit"),yZr.forEach(t),lvo=r(uAe," \u2014 "),Wq=n(uAe,"A",{href:!0});var LZr=s(Wq);ivo=r(LZr,"ViTModel"),LZr.forEach(t),dvo=r(uAe," (ViT model)"),uAe.forEach(t),cvo=i($),Bu=n($,"LI",{});var _Ae=s(Bu);ble=n(_Ae,"STRONG",{});var xZr=s(ble);fvo=r(xZr,"vit_mae"),xZr.forEach(t),mvo=r(_Ae," \u2014 "),Hq=n(_Ae,"A",{href:!0});var $Zr=s(Hq);gvo=r($Zr,"ViTMAEModel"),$Zr.forEach(t),hvo=r(_Ae," (ViTMAE model)"),_Ae.forEach(t),pvo=i($),Iu=n($,"LI",{});var bAe=s(Iu);vle=n(bAe,"STRONG",{});var kZr=s(vle);uvo=r(kZr,"wav2vec2"),kZr.forEach(t),_vo=r(bAe," \u2014 "),Uq=n(bAe,"A",{href:!0});var SZr=s(Uq);bvo=r(SZr,"Wav2Vec2Model"),SZr.forEach(t),vvo=r(bAe," (Wav2Vec2 model)"),bAe.forEach(t),Fvo=i($),qu=n($,"LI",{});var vAe=s(qu);Fle=n(vAe,"STRONG",{});var RZr=s(Fle);Tvo=r(RZr,"wavlm"),RZr.forEach(t),Mvo=r(vAe," \u2014 "),Jq=n(vAe,"A",{href:!0});var PZr=s(Jq);Evo=r(PZr,"WavLMModel"),PZr.forEach(t),Cvo=r(vAe," (WavLM model)"),vAe.forEach(t),wvo=i($),Nu=n($,"LI",{});var FAe=s(Nu);Tle=n(FAe,"STRONG",{});var BZr=s(Tle);Avo=r(BZr,"xglm"),BZr.forEach(t),yvo=r(FAe," \u2014 "),Yq=n(FAe,"A",{href:!0});var IZr=s(Yq);Lvo=r(IZr,"XGLMModel"),IZr.forEach(t),xvo=r(FAe," (XGLM model)"),FAe.forEach(t),$vo=i($),ju=n($,"LI",{});var TAe=s(ju);Mle=n(TAe,"STRONG",{});var qZr=s(Mle);kvo=r(qZr,"xlm"),qZr.forEach(t),Svo=r(TAe," \u2014 "),Kq=n(TAe,"A",{href:!0});var NZr=s(Kq);Rvo=r(NZr,"XLMModel"),NZr.forEach(t),Pvo=r(TAe," (XLM model)"),TAe.forEach(t),Bvo=i($),Du=n($,"LI",{});var MAe=s(Du);Ele=n(MAe,"STRONG",{});var jZr=s(Ele);Ivo=r(jZr,"xlm-prophetnet"),jZr.forEach(t),qvo=r(MAe," \u2014 "),Zq=n(MAe,"A",{href:!0});var DZr=s(Zq);Nvo=r(DZr,"XLMProphetNetModel"),DZr.forEach(t),jvo=r(MAe," (XLMProphetNet model)"),MAe.forEach(t),Dvo=i($),Gu=n($,"LI",{});var EAe=s(Gu);Cle=n(EAe,"STRONG",{});var GZr=s(Cle);Gvo=r(GZr,"xlm-roberta"),GZr.forEach(t),Ovo=r(EAe," \u2014 "),eN=n(EAe,"A",{href:!0});var OZr=s(eN);Vvo=r(OZr,"XLMRobertaModel"),OZr.forEach(t),Xvo=r(EAe," (XLM-RoBERTa model)"),EAe.forEach(t),zvo=i($),Ou=n($,"LI",{});var CAe=s(Ou);wle=n(CAe,"STRONG",{});var VZr=s(wle);Qvo=r(VZr,"xlm-roberta-xl"),VZr.forEach(t),Wvo=r(CAe," \u2014 "),oN=n(CAe,"A",{href:!0});var XZr=s(oN);Hvo=r(XZr,"XLMRobertaXLModel"),XZr.forEach(t),Uvo=r(CAe," (XLM-RoBERTa-XL model)"),CAe.forEach(t),Jvo=i($),Vu=n($,"LI",{});var wAe=s(Vu);Ale=n(wAe,"STRONG",{});var zZr=s(Ale);Yvo=r(zZr,"xlnet"),zZr.forEach(t),Kvo=r(wAe," \u2014 "),rN=n(wAe,"A",{href:!0});var QZr=s(rN);Zvo=r(QZr,"XLNetModel"),QZr.forEach(t),eFo=r(wAe," (XLNet model)"),wAe.forEach(t),oFo=i($),Xu=n($,"LI",{});var AAe=s(Xu);yle=n(AAe,"STRONG",{});var WZr=s(yle);rFo=r(WZr,"yolos"),WZr.forEach(t),tFo=r(AAe," \u2014 "),tN=n(AAe,"A",{href:!0});var HZr=s(tN);aFo=r(HZr,"YolosModel"),HZr.forEach(t),nFo=r(AAe," (YOLOS model)"),AAe.forEach(t),sFo=i($),zu=n($,"LI",{});var yAe=s(zu);Lle=n(yAe,"STRONG",{});var UZr=s(Lle);lFo=r(UZr,"yoso"),UZr.forEach(t),iFo=r(yAe," \u2014 "),aN=n(yAe,"A",{href:!0});var JZr=s(aN);dFo=r(JZr,"YosoModel"),JZr.forEach(t),cFo=r(yAe," (YOSO model)"),yAe.forEach(t),$.forEach(t),fFo=i(ra),Qu=n(ra,"P",{});var LAe=s(Qu);mFo=r(LAe,"The model is set in evaluation mode by default using "),xle=n(LAe,"CODE",{});var YZr=s(xle);gFo=r(YZr,"model.eval()"),YZr.forEach(t),hFo=r(LAe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$le=n(LAe,"CODE",{});var KZr=s($le);pFo=r(KZr,"model.train()"),KZr.forEach(t),LAe.forEach(t),uFo=i(ra),T(Wu.$$.fragment,ra),ra.forEach(t),zs.forEach(t),rqe=i(f),ki=n(f,"H2",{class:!0});var ije=s(ki);Hu=n(ije,"A",{id:!0,class:!0,href:!0});var ZZr=s(Hu);kle=n(ZZr,"SPAN",{});var eet=s(kle);T(WA.$$.fragment,eet),eet.forEach(t),ZZr.forEach(t),_Fo=i(ije),Sle=n(ije,"SPAN",{});var oet=s(Sle);bFo=r(oet,"AutoModelForPreTraining"),oet.forEach(t),ije.forEach(t),tqe=i(f),$o=n(f,"DIV",{class:!0});var Qs=s($o);T(HA.$$.fragment,Qs),vFo=i(Qs),Si=n(Qs,"P",{});var OK=s(Si);FFo=r(OK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),nN=n(OK,"A",{href:!0});var ret=s(nN);TFo=r(ret,"from_pretrained()"),ret.forEach(t),MFo=r(OK," class method or the "),sN=n(OK,"A",{href:!0});var tet=s(sN);EFo=r(tet,"from_config()"),tet.forEach(t),CFo=r(OK,` class
method.`),OK.forEach(t),wFo=i(Qs),UA=n(Qs,"P",{});var dje=s(UA);AFo=r(dje,"This class cannot be instantiated directly using "),Rle=n(dje,"CODE",{});var aet=s(Rle);yFo=r(aet,"__init__()"),aet.forEach(t),LFo=r(dje," (throws an error)."),dje.forEach(t),xFo=i(Qs),at=n(Qs,"DIV",{class:!0});var v3=s(at);T(JA.$$.fragment,v3),$Fo=i(v3),Ple=n(v3,"P",{});var net=s(Ple);kFo=r(net,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),net.forEach(t),SFo=i(v3),Ri=n(v3,"P",{});var VK=s(Ri);RFo=r(VK,`Note:
Loading a model from its configuration file does `),Ble=n(VK,"STRONG",{});var set=s(Ble);PFo=r(set,"not"),set.forEach(t),BFo=r(VK,` load the model weights. It only affects the
model\u2019s configuration. Use `),lN=n(VK,"A",{href:!0});var iet=s(lN);IFo=r(iet,"from_pretrained()"),iet.forEach(t),qFo=r(VK," to load the model weights."),VK.forEach(t),NFo=i(v3),T(Uu.$$.fragment,v3),v3.forEach(t),jFo=i(Qs),Ue=n(Qs,"DIV",{class:!0});var ta=s(Ue);T(YA.$$.fragment,ta),DFo=i(ta),Ile=n(ta,"P",{});var det=s(Ile);GFo=r(det,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),det.forEach(t),OFo=i(ta),ka=n(ta,"P",{});var F3=s(ka);VFo=r(F3,"The model class to instantiate is selected based on the "),qle=n(F3,"CODE",{});var cet=s(qle);XFo=r(cet,"model_type"),cet.forEach(t),zFo=r(F3,` property of the config object (either
passed as an argument or loaded from `),Nle=n(F3,"CODE",{});var fet=s(Nle);QFo=r(fet,"pretrained_model_name_or_path"),fet.forEach(t),WFo=r(F3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jle=n(F3,"CODE",{});var met=s(jle);HFo=r(met,"pretrained_model_name_or_path"),met.forEach(t),UFo=r(F3,":"),F3.forEach(t),JFo=i(ta),G=n(ta,"UL",{});var V=s(G);Ju=n(V,"LI",{});var xAe=s(Ju);Dle=n(xAe,"STRONG",{});var get=s(Dle);YFo=r(get,"albert"),get.forEach(t),KFo=r(xAe," \u2014 "),iN=n(xAe,"A",{href:!0});var het=s(iN);ZFo=r(het,"AlbertForPreTraining"),het.forEach(t),e6o=r(xAe," (ALBERT model)"),xAe.forEach(t),o6o=i(V),Yu=n(V,"LI",{});var $Ae=s(Yu);Gle=n($Ae,"STRONG",{});var pet=s(Gle);r6o=r(pet,"bart"),pet.forEach(t),t6o=r($Ae," \u2014 "),dN=n($Ae,"A",{href:!0});var uet=s(dN);a6o=r(uet,"BartForConditionalGeneration"),uet.forEach(t),n6o=r($Ae," (BART model)"),$Ae.forEach(t),s6o=i(V),Ku=n(V,"LI",{});var kAe=s(Ku);Ole=n(kAe,"STRONG",{});var _et=s(Ole);l6o=r(_et,"bert"),_et.forEach(t),i6o=r(kAe," \u2014 "),cN=n(kAe,"A",{href:!0});var bet=s(cN);d6o=r(bet,"BertForPreTraining"),bet.forEach(t),c6o=r(kAe," (BERT model)"),kAe.forEach(t),f6o=i(V),Zu=n(V,"LI",{});var SAe=s(Zu);Vle=n(SAe,"STRONG",{});var vet=s(Vle);m6o=r(vet,"big_bird"),vet.forEach(t),g6o=r(SAe," \u2014 "),fN=n(SAe,"A",{href:!0});var Fet=s(fN);h6o=r(Fet,"BigBirdForPreTraining"),Fet.forEach(t),p6o=r(SAe," (BigBird model)"),SAe.forEach(t),u6o=i(V),e_=n(V,"LI",{});var RAe=s(e_);Xle=n(RAe,"STRONG",{});var Tet=s(Xle);_6o=r(Tet,"camembert"),Tet.forEach(t),b6o=r(RAe," \u2014 "),mN=n(RAe,"A",{href:!0});var Met=s(mN);v6o=r(Met,"CamembertForMaskedLM"),Met.forEach(t),F6o=r(RAe," (CamemBERT model)"),RAe.forEach(t),T6o=i(V),o_=n(V,"LI",{});var PAe=s(o_);zle=n(PAe,"STRONG",{});var Eet=s(zle);M6o=r(Eet,"ctrl"),Eet.forEach(t),E6o=r(PAe," \u2014 "),gN=n(PAe,"A",{href:!0});var Cet=s(gN);C6o=r(Cet,"CTRLLMHeadModel"),Cet.forEach(t),w6o=r(PAe," (CTRL model)"),PAe.forEach(t),A6o=i(V),r_=n(V,"LI",{});var BAe=s(r_);Qle=n(BAe,"STRONG",{});var wet=s(Qle);y6o=r(wet,"data2vec-text"),wet.forEach(t),L6o=r(BAe," \u2014 "),hN=n(BAe,"A",{href:!0});var Aet=s(hN);x6o=r(Aet,"Data2VecTextForMaskedLM"),Aet.forEach(t),$6o=r(BAe," (Data2VecText model)"),BAe.forEach(t),k6o=i(V),t_=n(V,"LI",{});var IAe=s(t_);Wle=n(IAe,"STRONG",{});var yet=s(Wle);S6o=r(yet,"deberta"),yet.forEach(t),R6o=r(IAe," \u2014 "),pN=n(IAe,"A",{href:!0});var Let=s(pN);P6o=r(Let,"DebertaForMaskedLM"),Let.forEach(t),B6o=r(IAe," (DeBERTa model)"),IAe.forEach(t),I6o=i(V),a_=n(V,"LI",{});var qAe=s(a_);Hle=n(qAe,"STRONG",{});var xet=s(Hle);q6o=r(xet,"deberta-v2"),xet.forEach(t),N6o=r(qAe," \u2014 "),uN=n(qAe,"A",{href:!0});var $et=s(uN);j6o=r($et,"DebertaV2ForMaskedLM"),$et.forEach(t),D6o=r(qAe," (DeBERTa-v2 model)"),qAe.forEach(t),G6o=i(V),n_=n(V,"LI",{});var NAe=s(n_);Ule=n(NAe,"STRONG",{});var ket=s(Ule);O6o=r(ket,"distilbert"),ket.forEach(t),V6o=r(NAe," \u2014 "),_N=n(NAe,"A",{href:!0});var Set=s(_N);X6o=r(Set,"DistilBertForMaskedLM"),Set.forEach(t),z6o=r(NAe," (DistilBERT model)"),NAe.forEach(t),Q6o=i(V),s_=n(V,"LI",{});var jAe=s(s_);Jle=n(jAe,"STRONG",{});var Ret=s(Jle);W6o=r(Ret,"electra"),Ret.forEach(t),H6o=r(jAe," \u2014 "),bN=n(jAe,"A",{href:!0});var Pet=s(bN);U6o=r(Pet,"ElectraForPreTraining"),Pet.forEach(t),J6o=r(jAe," (ELECTRA model)"),jAe.forEach(t),Y6o=i(V),l_=n(V,"LI",{});var DAe=s(l_);Yle=n(DAe,"STRONG",{});var Bet=s(Yle);K6o=r(Bet,"flaubert"),Bet.forEach(t),Z6o=r(DAe," \u2014 "),vN=n(DAe,"A",{href:!0});var Iet=s(vN);eTo=r(Iet,"FlaubertWithLMHeadModel"),Iet.forEach(t),oTo=r(DAe," (FlauBERT model)"),DAe.forEach(t),rTo=i(V),i_=n(V,"LI",{});var GAe=s(i_);Kle=n(GAe,"STRONG",{});var qet=s(Kle);tTo=r(qet,"flava"),qet.forEach(t),aTo=r(GAe," \u2014 "),FN=n(GAe,"A",{href:!0});var Net=s(FN);nTo=r(Net,"FlavaForPreTraining"),Net.forEach(t),sTo=r(GAe," (Flava model)"),GAe.forEach(t),lTo=i(V),d_=n(V,"LI",{});var OAe=s(d_);Zle=n(OAe,"STRONG",{});var jet=s(Zle);iTo=r(jet,"fnet"),jet.forEach(t),dTo=r(OAe," \u2014 "),TN=n(OAe,"A",{href:!0});var Det=s(TN);cTo=r(Det,"FNetForPreTraining"),Det.forEach(t),fTo=r(OAe," (FNet model)"),OAe.forEach(t),mTo=i(V),c_=n(V,"LI",{});var VAe=s(c_);eie=n(VAe,"STRONG",{});var Get=s(eie);gTo=r(Get,"fsmt"),Get.forEach(t),hTo=r(VAe," \u2014 "),MN=n(VAe,"A",{href:!0});var Oet=s(MN);pTo=r(Oet,"FSMTForConditionalGeneration"),Oet.forEach(t),uTo=r(VAe," (FairSeq Machine-Translation model)"),VAe.forEach(t),_To=i(V),f_=n(V,"LI",{});var XAe=s(f_);oie=n(XAe,"STRONG",{});var Vet=s(oie);bTo=r(Vet,"funnel"),Vet.forEach(t),vTo=r(XAe," \u2014 "),EN=n(XAe,"A",{href:!0});var Xet=s(EN);FTo=r(Xet,"FunnelForPreTraining"),Xet.forEach(t),TTo=r(XAe," (Funnel Transformer model)"),XAe.forEach(t),MTo=i(V),m_=n(V,"LI",{});var zAe=s(m_);rie=n(zAe,"STRONG",{});var zet=s(rie);ETo=r(zet,"gpt2"),zet.forEach(t),CTo=r(zAe," \u2014 "),CN=n(zAe,"A",{href:!0});var Qet=s(CN);wTo=r(Qet,"GPT2LMHeadModel"),Qet.forEach(t),ATo=r(zAe," (OpenAI GPT-2 model)"),zAe.forEach(t),yTo=i(V),g_=n(V,"LI",{});var QAe=s(g_);tie=n(QAe,"STRONG",{});var Wet=s(tie);LTo=r(Wet,"ibert"),Wet.forEach(t),xTo=r(QAe," \u2014 "),wN=n(QAe,"A",{href:!0});var Het=s(wN);$To=r(Het,"IBertForMaskedLM"),Het.forEach(t),kTo=r(QAe," (I-BERT model)"),QAe.forEach(t),STo=i(V),h_=n(V,"LI",{});var WAe=s(h_);aie=n(WAe,"STRONG",{});var Uet=s(aie);RTo=r(Uet,"layoutlm"),Uet.forEach(t),PTo=r(WAe," \u2014 "),AN=n(WAe,"A",{href:!0});var Jet=s(AN);BTo=r(Jet,"LayoutLMForMaskedLM"),Jet.forEach(t),ITo=r(WAe," (LayoutLM model)"),WAe.forEach(t),qTo=i(V),p_=n(V,"LI",{});var HAe=s(p_);nie=n(HAe,"STRONG",{});var Yet=s(nie);NTo=r(Yet,"longformer"),Yet.forEach(t),jTo=r(HAe," \u2014 "),yN=n(HAe,"A",{href:!0});var Ket=s(yN);DTo=r(Ket,"LongformerForMaskedLM"),Ket.forEach(t),GTo=r(HAe," (Longformer model)"),HAe.forEach(t),OTo=i(V),u_=n(V,"LI",{});var UAe=s(u_);sie=n(UAe,"STRONG",{});var Zet=s(sie);VTo=r(Zet,"lxmert"),Zet.forEach(t),XTo=r(UAe," \u2014 "),LN=n(UAe,"A",{href:!0});var eot=s(LN);zTo=r(eot,"LxmertForPreTraining"),eot.forEach(t),QTo=r(UAe," (LXMERT model)"),UAe.forEach(t),WTo=i(V),__=n(V,"LI",{});var JAe=s(__);lie=n(JAe,"STRONG",{});var oot=s(lie);HTo=r(oot,"megatron-bert"),oot.forEach(t),UTo=r(JAe," \u2014 "),xN=n(JAe,"A",{href:!0});var rot=s(xN);JTo=r(rot,"MegatronBertForPreTraining"),rot.forEach(t),YTo=r(JAe," (MegatronBert model)"),JAe.forEach(t),KTo=i(V),b_=n(V,"LI",{});var YAe=s(b_);iie=n(YAe,"STRONG",{});var tot=s(iie);ZTo=r(tot,"mobilebert"),tot.forEach(t),e8o=r(YAe," \u2014 "),$N=n(YAe,"A",{href:!0});var aot=s($N);o8o=r(aot,"MobileBertForPreTraining"),aot.forEach(t),r8o=r(YAe," (MobileBERT model)"),YAe.forEach(t),t8o=i(V),v_=n(V,"LI",{});var KAe=s(v_);die=n(KAe,"STRONG",{});var not=s(die);a8o=r(not,"mpnet"),not.forEach(t),n8o=r(KAe," \u2014 "),kN=n(KAe,"A",{href:!0});var sot=s(kN);s8o=r(sot,"MPNetForMaskedLM"),sot.forEach(t),l8o=r(KAe," (MPNet model)"),KAe.forEach(t),i8o=i(V),F_=n(V,"LI",{});var ZAe=s(F_);cie=n(ZAe,"STRONG",{});var lot=s(cie);d8o=r(lot,"openai-gpt"),lot.forEach(t),c8o=r(ZAe," \u2014 "),SN=n(ZAe,"A",{href:!0});var iot=s(SN);f8o=r(iot,"OpenAIGPTLMHeadModel"),iot.forEach(t),m8o=r(ZAe," (OpenAI GPT model)"),ZAe.forEach(t),g8o=i(V),T_=n(V,"LI",{});var e0e=s(T_);fie=n(e0e,"STRONG",{});var dot=s(fie);h8o=r(dot,"retribert"),dot.forEach(t),p8o=r(e0e," \u2014 "),RN=n(e0e,"A",{href:!0});var cot=s(RN);u8o=r(cot,"RetriBertModel"),cot.forEach(t),_8o=r(e0e," (RetriBERT model)"),e0e.forEach(t),b8o=i(V),M_=n(V,"LI",{});var o0e=s(M_);mie=n(o0e,"STRONG",{});var fot=s(mie);v8o=r(fot,"roberta"),fot.forEach(t),F8o=r(o0e," \u2014 "),PN=n(o0e,"A",{href:!0});var mot=s(PN);T8o=r(mot,"RobertaForMaskedLM"),mot.forEach(t),M8o=r(o0e," (RoBERTa model)"),o0e.forEach(t),E8o=i(V),E_=n(V,"LI",{});var r0e=s(E_);gie=n(r0e,"STRONG",{});var got=s(gie);C8o=r(got,"squeezebert"),got.forEach(t),w8o=r(r0e," \u2014 "),BN=n(r0e,"A",{href:!0});var hot=s(BN);A8o=r(hot,"SqueezeBertForMaskedLM"),hot.forEach(t),y8o=r(r0e," (SqueezeBERT model)"),r0e.forEach(t),L8o=i(V),C_=n(V,"LI",{});var t0e=s(C_);hie=n(t0e,"STRONG",{});var pot=s(hie);x8o=r(pot,"t5"),pot.forEach(t),$8o=r(t0e," \u2014 "),IN=n(t0e,"A",{href:!0});var uot=s(IN);k8o=r(uot,"T5ForConditionalGeneration"),uot.forEach(t),S8o=r(t0e," (T5 model)"),t0e.forEach(t),R8o=i(V),w_=n(V,"LI",{});var a0e=s(w_);pie=n(a0e,"STRONG",{});var _ot=s(pie);P8o=r(_ot,"tapas"),_ot.forEach(t),B8o=r(a0e," \u2014 "),qN=n(a0e,"A",{href:!0});var bot=s(qN);I8o=r(bot,"TapasForMaskedLM"),bot.forEach(t),q8o=r(a0e," (TAPAS model)"),a0e.forEach(t),N8o=i(V),A_=n(V,"LI",{});var n0e=s(A_);uie=n(n0e,"STRONG",{});var vot=s(uie);j8o=r(vot,"transfo-xl"),vot.forEach(t),D8o=r(n0e," \u2014 "),NN=n(n0e,"A",{href:!0});var Fot=s(NN);G8o=r(Fot,"TransfoXLLMHeadModel"),Fot.forEach(t),O8o=r(n0e," (Transformer-XL model)"),n0e.forEach(t),V8o=i(V),y_=n(V,"LI",{});var s0e=s(y_);_ie=n(s0e,"STRONG",{});var Tot=s(_ie);X8o=r(Tot,"unispeech"),Tot.forEach(t),z8o=r(s0e," \u2014 "),jN=n(s0e,"A",{href:!0});var Mot=s(jN);Q8o=r(Mot,"UniSpeechForPreTraining"),Mot.forEach(t),W8o=r(s0e," (UniSpeech model)"),s0e.forEach(t),H8o=i(V),L_=n(V,"LI",{});var l0e=s(L_);bie=n(l0e,"STRONG",{});var Eot=s(bie);U8o=r(Eot,"unispeech-sat"),Eot.forEach(t),J8o=r(l0e," \u2014 "),DN=n(l0e,"A",{href:!0});var Cot=s(DN);Y8o=r(Cot,"UniSpeechSatForPreTraining"),Cot.forEach(t),K8o=r(l0e," (UniSpeechSat model)"),l0e.forEach(t),Z8o=i(V),x_=n(V,"LI",{});var i0e=s(x_);vie=n(i0e,"STRONG",{});var wot=s(vie);e7o=r(wot,"visual_bert"),wot.forEach(t),o7o=r(i0e," \u2014 "),GN=n(i0e,"A",{href:!0});var Aot=s(GN);r7o=r(Aot,"VisualBertForPreTraining"),Aot.forEach(t),t7o=r(i0e," (VisualBert model)"),i0e.forEach(t),a7o=i(V),$_=n(V,"LI",{});var d0e=s($_);Fie=n(d0e,"STRONG",{});var yot=s(Fie);n7o=r(yot,"vit_mae"),yot.forEach(t),s7o=r(d0e," \u2014 "),ON=n(d0e,"A",{href:!0});var Lot=s(ON);l7o=r(Lot,"ViTMAEForPreTraining"),Lot.forEach(t),i7o=r(d0e," (ViTMAE model)"),d0e.forEach(t),d7o=i(V),k_=n(V,"LI",{});var c0e=s(k_);Tie=n(c0e,"STRONG",{});var xot=s(Tie);c7o=r(xot,"wav2vec2"),xot.forEach(t),f7o=r(c0e," \u2014 "),VN=n(c0e,"A",{href:!0});var $ot=s(VN);m7o=r($ot,"Wav2Vec2ForPreTraining"),$ot.forEach(t),g7o=r(c0e," (Wav2Vec2 model)"),c0e.forEach(t),h7o=i(V),S_=n(V,"LI",{});var f0e=s(S_);Mie=n(f0e,"STRONG",{});var kot=s(Mie);p7o=r(kot,"xlm"),kot.forEach(t),u7o=r(f0e," \u2014 "),XN=n(f0e,"A",{href:!0});var Sot=s(XN);_7o=r(Sot,"XLMWithLMHeadModel"),Sot.forEach(t),b7o=r(f0e," (XLM model)"),f0e.forEach(t),v7o=i(V),R_=n(V,"LI",{});var m0e=s(R_);Eie=n(m0e,"STRONG",{});var Rot=s(Eie);F7o=r(Rot,"xlm-roberta"),Rot.forEach(t),T7o=r(m0e," \u2014 "),zN=n(m0e,"A",{href:!0});var Pot=s(zN);M7o=r(Pot,"XLMRobertaForMaskedLM"),Pot.forEach(t),E7o=r(m0e," (XLM-RoBERTa model)"),m0e.forEach(t),C7o=i(V),P_=n(V,"LI",{});var g0e=s(P_);Cie=n(g0e,"STRONG",{});var Bot=s(Cie);w7o=r(Bot,"xlm-roberta-xl"),Bot.forEach(t),A7o=r(g0e," \u2014 "),QN=n(g0e,"A",{href:!0});var Iot=s(QN);y7o=r(Iot,"XLMRobertaXLForMaskedLM"),Iot.forEach(t),L7o=r(g0e," (XLM-RoBERTa-XL model)"),g0e.forEach(t),x7o=i(V),B_=n(V,"LI",{});var h0e=s(B_);wie=n(h0e,"STRONG",{});var qot=s(wie);$7o=r(qot,"xlnet"),qot.forEach(t),k7o=r(h0e," \u2014 "),WN=n(h0e,"A",{href:!0});var Not=s(WN);S7o=r(Not,"XLNetLMHeadModel"),Not.forEach(t),R7o=r(h0e," (XLNet model)"),h0e.forEach(t),V.forEach(t),P7o=i(ta),I_=n(ta,"P",{});var p0e=s(I_);B7o=r(p0e,"The model is set in evaluation mode by default using "),Aie=n(p0e,"CODE",{});var jot=s(Aie);I7o=r(jot,"model.eval()"),jot.forEach(t),q7o=r(p0e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yie=n(p0e,"CODE",{});var Dot=s(yie);N7o=r(Dot,"model.train()"),Dot.forEach(t),p0e.forEach(t),j7o=i(ta),T(q_.$$.fragment,ta),ta.forEach(t),Qs.forEach(t),aqe=i(f),Pi=n(f,"H2",{class:!0});var cje=s(Pi);N_=n(cje,"A",{id:!0,class:!0,href:!0});var Got=s(N_);Lie=n(Got,"SPAN",{});var Oot=s(Lie);T(KA.$$.fragment,Oot),Oot.forEach(t),Got.forEach(t),D7o=i(cje),xie=n(cje,"SPAN",{});var Vot=s(xie);G7o=r(Vot,"AutoModelForCausalLM"),Vot.forEach(t),cje.forEach(t),nqe=i(f),ko=n(f,"DIV",{class:!0});var Ws=s(ko);T(ZA.$$.fragment,Ws),O7o=i(Ws),Bi=n(Ws,"P",{});var XK=s(Bi);V7o=r(XK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),HN=n(XK,"A",{href:!0});var Xot=s(HN);X7o=r(Xot,"from_pretrained()"),Xot.forEach(t),z7o=r(XK," class method or the "),UN=n(XK,"A",{href:!0});var zot=s(UN);Q7o=r(zot,"from_config()"),zot.forEach(t),W7o=r(XK,` class
method.`),XK.forEach(t),H7o=i(Ws),e0=n(Ws,"P",{});var fje=s(e0);U7o=r(fje,"This class cannot be instantiated directly using "),$ie=n(fje,"CODE",{});var Qot=s($ie);J7o=r(Qot,"__init__()"),Qot.forEach(t),Y7o=r(fje," (throws an error)."),fje.forEach(t),K7o=i(Ws),nt=n(Ws,"DIV",{class:!0});var T3=s(nt);T(o0.$$.fragment,T3),Z7o=i(T3),kie=n(T3,"P",{});var Wot=s(kie);eMo=r(Wot,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Wot.forEach(t),oMo=i(T3),Ii=n(T3,"P",{});var zK=s(Ii);rMo=r(zK,`Note:
Loading a model from its configuration file does `),Sie=n(zK,"STRONG",{});var Hot=s(Sie);tMo=r(Hot,"not"),Hot.forEach(t),aMo=r(zK,` load the model weights. It only affects the
model\u2019s configuration. Use `),JN=n(zK,"A",{href:!0});var Uot=s(JN);nMo=r(Uot,"from_pretrained()"),Uot.forEach(t),sMo=r(zK," to load the model weights."),zK.forEach(t),lMo=i(T3),T(j_.$$.fragment,T3),T3.forEach(t),iMo=i(Ws),Je=n(Ws,"DIV",{class:!0});var aa=s(Je);T(r0.$$.fragment,aa),dMo=i(aa),Rie=n(aa,"P",{});var Jot=s(Rie);cMo=r(Jot,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Jot.forEach(t),fMo=i(aa),Sa=n(aa,"P",{});var M3=s(Sa);mMo=r(M3,"The model class to instantiate is selected based on the "),Pie=n(M3,"CODE",{});var Yot=s(Pie);gMo=r(Yot,"model_type"),Yot.forEach(t),hMo=r(M3,` property of the config object (either
passed as an argument or loaded from `),Bie=n(M3,"CODE",{});var Kot=s(Bie);pMo=r(Kot,"pretrained_model_name_or_path"),Kot.forEach(t),uMo=r(M3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Iie=n(M3,"CODE",{});var Zot=s(Iie);_Mo=r(Zot,"pretrained_model_name_or_path"),Zot.forEach(t),bMo=r(M3,":"),M3.forEach(t),vMo=i(aa),z=n(aa,"UL",{});var W=s(z);D_=n(W,"LI",{});var u0e=s(D_);qie=n(u0e,"STRONG",{});var ert=s(qie);FMo=r(ert,"bart"),ert.forEach(t),TMo=r(u0e," \u2014 "),YN=n(u0e,"A",{href:!0});var ort=s(YN);MMo=r(ort,"BartForCausalLM"),ort.forEach(t),EMo=r(u0e," (BART model)"),u0e.forEach(t),CMo=i(W),G_=n(W,"LI",{});var _0e=s(G_);Nie=n(_0e,"STRONG",{});var rrt=s(Nie);wMo=r(rrt,"bert"),rrt.forEach(t),AMo=r(_0e," \u2014 "),KN=n(_0e,"A",{href:!0});var trt=s(KN);yMo=r(trt,"BertLMHeadModel"),trt.forEach(t),LMo=r(_0e," (BERT model)"),_0e.forEach(t),xMo=i(W),O_=n(W,"LI",{});var b0e=s(O_);jie=n(b0e,"STRONG",{});var art=s(jie);$Mo=r(art,"bert-generation"),art.forEach(t),kMo=r(b0e," \u2014 "),ZN=n(b0e,"A",{href:!0});var nrt=s(ZN);SMo=r(nrt,"BertGenerationDecoder"),nrt.forEach(t),RMo=r(b0e," (Bert Generation model)"),b0e.forEach(t),PMo=i(W),V_=n(W,"LI",{});var v0e=s(V_);Die=n(v0e,"STRONG",{});var srt=s(Die);BMo=r(srt,"big_bird"),srt.forEach(t),IMo=r(v0e," \u2014 "),ej=n(v0e,"A",{href:!0});var lrt=s(ej);qMo=r(lrt,"BigBirdForCausalLM"),lrt.forEach(t),NMo=r(v0e," (BigBird model)"),v0e.forEach(t),jMo=i(W),X_=n(W,"LI",{});var F0e=s(X_);Gie=n(F0e,"STRONG",{});var irt=s(Gie);DMo=r(irt,"bigbird_pegasus"),irt.forEach(t),GMo=r(F0e," \u2014 "),oj=n(F0e,"A",{href:!0});var drt=s(oj);OMo=r(drt,"BigBirdPegasusForCausalLM"),drt.forEach(t),VMo=r(F0e," (BigBirdPegasus model)"),F0e.forEach(t),XMo=i(W),z_=n(W,"LI",{});var T0e=s(z_);Oie=n(T0e,"STRONG",{});var crt=s(Oie);zMo=r(crt,"blenderbot"),crt.forEach(t),QMo=r(T0e," \u2014 "),rj=n(T0e,"A",{href:!0});var frt=s(rj);WMo=r(frt,"BlenderbotForCausalLM"),frt.forEach(t),HMo=r(T0e," (Blenderbot model)"),T0e.forEach(t),UMo=i(W),Q_=n(W,"LI",{});var M0e=s(Q_);Vie=n(M0e,"STRONG",{});var mrt=s(Vie);JMo=r(mrt,"blenderbot-small"),mrt.forEach(t),YMo=r(M0e," \u2014 "),tj=n(M0e,"A",{href:!0});var grt=s(tj);KMo=r(grt,"BlenderbotSmallForCausalLM"),grt.forEach(t),ZMo=r(M0e," (BlenderbotSmall model)"),M0e.forEach(t),e4o=i(W),W_=n(W,"LI",{});var E0e=s(W_);Xie=n(E0e,"STRONG",{});var hrt=s(Xie);o4o=r(hrt,"camembert"),hrt.forEach(t),r4o=r(E0e," \u2014 "),aj=n(E0e,"A",{href:!0});var prt=s(aj);t4o=r(prt,"CamembertForCausalLM"),prt.forEach(t),a4o=r(E0e," (CamemBERT model)"),E0e.forEach(t),n4o=i(W),H_=n(W,"LI",{});var C0e=s(H_);zie=n(C0e,"STRONG",{});var urt=s(zie);s4o=r(urt,"ctrl"),urt.forEach(t),l4o=r(C0e," \u2014 "),nj=n(C0e,"A",{href:!0});var _rt=s(nj);i4o=r(_rt,"CTRLLMHeadModel"),_rt.forEach(t),d4o=r(C0e," (CTRL model)"),C0e.forEach(t),c4o=i(W),U_=n(W,"LI",{});var w0e=s(U_);Qie=n(w0e,"STRONG",{});var brt=s(Qie);f4o=r(brt,"data2vec-text"),brt.forEach(t),m4o=r(w0e," \u2014 "),sj=n(w0e,"A",{href:!0});var vrt=s(sj);g4o=r(vrt,"Data2VecTextForCausalLM"),vrt.forEach(t),h4o=r(w0e," (Data2VecText model)"),w0e.forEach(t),p4o=i(W),J_=n(W,"LI",{});var A0e=s(J_);Wie=n(A0e,"STRONG",{});var Frt=s(Wie);u4o=r(Frt,"electra"),Frt.forEach(t),_4o=r(A0e," \u2014 "),lj=n(A0e,"A",{href:!0});var Trt=s(lj);b4o=r(Trt,"ElectraForCausalLM"),Trt.forEach(t),v4o=r(A0e," (ELECTRA model)"),A0e.forEach(t),F4o=i(W),Y_=n(W,"LI",{});var y0e=s(Y_);Hie=n(y0e,"STRONG",{});var Mrt=s(Hie);T4o=r(Mrt,"gpt2"),Mrt.forEach(t),M4o=r(y0e," \u2014 "),ij=n(y0e,"A",{href:!0});var Ert=s(ij);E4o=r(Ert,"GPT2LMHeadModel"),Ert.forEach(t),C4o=r(y0e," (OpenAI GPT-2 model)"),y0e.forEach(t),w4o=i(W),K_=n(W,"LI",{});var L0e=s(K_);Uie=n(L0e,"STRONG",{});var Crt=s(Uie);A4o=r(Crt,"gpt_neo"),Crt.forEach(t),y4o=r(L0e," \u2014 "),dj=n(L0e,"A",{href:!0});var wrt=s(dj);L4o=r(wrt,"GPTNeoForCausalLM"),wrt.forEach(t),x4o=r(L0e," (GPT Neo model)"),L0e.forEach(t),$4o=i(W),Z_=n(W,"LI",{});var x0e=s(Z_);Jie=n(x0e,"STRONG",{});var Art=s(Jie);k4o=r(Art,"gptj"),Art.forEach(t),S4o=r(x0e," \u2014 "),cj=n(x0e,"A",{href:!0});var yrt=s(cj);R4o=r(yrt,"GPTJForCausalLM"),yrt.forEach(t),P4o=r(x0e," (GPT-J model)"),x0e.forEach(t),B4o=i(W),e2=n(W,"LI",{});var $0e=s(e2);Yie=n($0e,"STRONG",{});var Lrt=s(Yie);I4o=r(Lrt,"marian"),Lrt.forEach(t),q4o=r($0e," \u2014 "),fj=n($0e,"A",{href:!0});var xrt=s(fj);N4o=r(xrt,"MarianForCausalLM"),xrt.forEach(t),j4o=r($0e," (Marian model)"),$0e.forEach(t),D4o=i(W),o2=n(W,"LI",{});var k0e=s(o2);Kie=n(k0e,"STRONG",{});var $rt=s(Kie);G4o=r($rt,"mbart"),$rt.forEach(t),O4o=r(k0e," \u2014 "),mj=n(k0e,"A",{href:!0});var krt=s(mj);V4o=r(krt,"MBartForCausalLM"),krt.forEach(t),X4o=r(k0e," (mBART model)"),k0e.forEach(t),z4o=i(W),r2=n(W,"LI",{});var S0e=s(r2);Zie=n(S0e,"STRONG",{});var Srt=s(Zie);Q4o=r(Srt,"megatron-bert"),Srt.forEach(t),W4o=r(S0e," \u2014 "),gj=n(S0e,"A",{href:!0});var Rrt=s(gj);H4o=r(Rrt,"MegatronBertForCausalLM"),Rrt.forEach(t),U4o=r(S0e," (MegatronBert model)"),S0e.forEach(t),J4o=i(W),t2=n(W,"LI",{});var R0e=s(t2);ede=n(R0e,"STRONG",{});var Prt=s(ede);Y4o=r(Prt,"openai-gpt"),Prt.forEach(t),K4o=r(R0e," \u2014 "),hj=n(R0e,"A",{href:!0});var Brt=s(hj);Z4o=r(Brt,"OpenAIGPTLMHeadModel"),Brt.forEach(t),eEo=r(R0e," (OpenAI GPT model)"),R0e.forEach(t),oEo=i(W),a2=n(W,"LI",{});var P0e=s(a2);ode=n(P0e,"STRONG",{});var Irt=s(ode);rEo=r(Irt,"opt"),Irt.forEach(t),tEo=r(P0e," \u2014 "),pj=n(P0e,"A",{href:!0});var qrt=s(pj);aEo=r(qrt,"OPTForCausalLM"),qrt.forEach(t),nEo=r(P0e," (OPT model)"),P0e.forEach(t),sEo=i(W),n2=n(W,"LI",{});var B0e=s(n2);rde=n(B0e,"STRONG",{});var Nrt=s(rde);lEo=r(Nrt,"pegasus"),Nrt.forEach(t),iEo=r(B0e," \u2014 "),uj=n(B0e,"A",{href:!0});var jrt=s(uj);dEo=r(jrt,"PegasusForCausalLM"),jrt.forEach(t),cEo=r(B0e," (Pegasus model)"),B0e.forEach(t),fEo=i(W),s2=n(W,"LI",{});var I0e=s(s2);tde=n(I0e,"STRONG",{});var Drt=s(tde);mEo=r(Drt,"plbart"),Drt.forEach(t),gEo=r(I0e," \u2014 "),_j=n(I0e,"A",{href:!0});var Grt=s(_j);hEo=r(Grt,"PLBartForCausalLM"),Grt.forEach(t),pEo=r(I0e," (PLBart model)"),I0e.forEach(t),uEo=i(W),l2=n(W,"LI",{});var q0e=s(l2);ade=n(q0e,"STRONG",{});var Ort=s(ade);_Eo=r(Ort,"prophetnet"),Ort.forEach(t),bEo=r(q0e," \u2014 "),bj=n(q0e,"A",{href:!0});var Vrt=s(bj);vEo=r(Vrt,"ProphetNetForCausalLM"),Vrt.forEach(t),FEo=r(q0e," (ProphetNet model)"),q0e.forEach(t),TEo=i(W),i2=n(W,"LI",{});var N0e=s(i2);nde=n(N0e,"STRONG",{});var Xrt=s(nde);MEo=r(Xrt,"qdqbert"),Xrt.forEach(t),EEo=r(N0e," \u2014 "),vj=n(N0e,"A",{href:!0});var zrt=s(vj);CEo=r(zrt,"QDQBertLMHeadModel"),zrt.forEach(t),wEo=r(N0e," (QDQBert model)"),N0e.forEach(t),AEo=i(W),d2=n(W,"LI",{});var j0e=s(d2);sde=n(j0e,"STRONG",{});var Qrt=s(sde);yEo=r(Qrt,"reformer"),Qrt.forEach(t),LEo=r(j0e," \u2014 "),Fj=n(j0e,"A",{href:!0});var Wrt=s(Fj);xEo=r(Wrt,"ReformerModelWithLMHead"),Wrt.forEach(t),$Eo=r(j0e," (Reformer model)"),j0e.forEach(t),kEo=i(W),c2=n(W,"LI",{});var D0e=s(c2);lde=n(D0e,"STRONG",{});var Hrt=s(lde);SEo=r(Hrt,"rembert"),Hrt.forEach(t),REo=r(D0e," \u2014 "),Tj=n(D0e,"A",{href:!0});var Urt=s(Tj);PEo=r(Urt,"RemBertForCausalLM"),Urt.forEach(t),BEo=r(D0e," (RemBERT model)"),D0e.forEach(t),IEo=i(W),f2=n(W,"LI",{});var G0e=s(f2);ide=n(G0e,"STRONG",{});var Jrt=s(ide);qEo=r(Jrt,"roberta"),Jrt.forEach(t),NEo=r(G0e," \u2014 "),Mj=n(G0e,"A",{href:!0});var Yrt=s(Mj);jEo=r(Yrt,"RobertaForCausalLM"),Yrt.forEach(t),DEo=r(G0e," (RoBERTa model)"),G0e.forEach(t),GEo=i(W),m2=n(W,"LI",{});var O0e=s(m2);dde=n(O0e,"STRONG",{});var Krt=s(dde);OEo=r(Krt,"roformer"),Krt.forEach(t),VEo=r(O0e," \u2014 "),Ej=n(O0e,"A",{href:!0});var Zrt=s(Ej);XEo=r(Zrt,"RoFormerForCausalLM"),Zrt.forEach(t),zEo=r(O0e," (RoFormer model)"),O0e.forEach(t),QEo=i(W),g2=n(W,"LI",{});var V0e=s(g2);cde=n(V0e,"STRONG",{});var ett=s(cde);WEo=r(ett,"speech_to_text_2"),ett.forEach(t),HEo=r(V0e," \u2014 "),Cj=n(V0e,"A",{href:!0});var ott=s(Cj);UEo=r(ott,"Speech2Text2ForCausalLM"),ott.forEach(t),JEo=r(V0e," (Speech2Text2 model)"),V0e.forEach(t),YEo=i(W),h2=n(W,"LI",{});var X0e=s(h2);fde=n(X0e,"STRONG",{});var rtt=s(fde);KEo=r(rtt,"transfo-xl"),rtt.forEach(t),ZEo=r(X0e," \u2014 "),wj=n(X0e,"A",{href:!0});var ttt=s(wj);e5o=r(ttt,"TransfoXLLMHeadModel"),ttt.forEach(t),o5o=r(X0e," (Transformer-XL model)"),X0e.forEach(t),r5o=i(W),p2=n(W,"LI",{});var z0e=s(p2);mde=n(z0e,"STRONG",{});var att=s(mde);t5o=r(att,"trocr"),att.forEach(t),a5o=r(z0e," \u2014 "),Aj=n(z0e,"A",{href:!0});var ntt=s(Aj);n5o=r(ntt,"TrOCRForCausalLM"),ntt.forEach(t),s5o=r(z0e," (TrOCR model)"),z0e.forEach(t),l5o=i(W),u2=n(W,"LI",{});var Q0e=s(u2);gde=n(Q0e,"STRONG",{});var stt=s(gde);i5o=r(stt,"xglm"),stt.forEach(t),d5o=r(Q0e," \u2014 "),yj=n(Q0e,"A",{href:!0});var ltt=s(yj);c5o=r(ltt,"XGLMForCausalLM"),ltt.forEach(t),f5o=r(Q0e," (XGLM model)"),Q0e.forEach(t),m5o=i(W),_2=n(W,"LI",{});var W0e=s(_2);hde=n(W0e,"STRONG",{});var itt=s(hde);g5o=r(itt,"xlm"),itt.forEach(t),h5o=r(W0e," \u2014 "),Lj=n(W0e,"A",{href:!0});var dtt=s(Lj);p5o=r(dtt,"XLMWithLMHeadModel"),dtt.forEach(t),u5o=r(W0e," (XLM model)"),W0e.forEach(t),_5o=i(W),b2=n(W,"LI",{});var H0e=s(b2);pde=n(H0e,"STRONG",{});var ctt=s(pde);b5o=r(ctt,"xlm-prophetnet"),ctt.forEach(t),v5o=r(H0e," \u2014 "),xj=n(H0e,"A",{href:!0});var ftt=s(xj);F5o=r(ftt,"XLMProphetNetForCausalLM"),ftt.forEach(t),T5o=r(H0e," (XLMProphetNet model)"),H0e.forEach(t),M5o=i(W),v2=n(W,"LI",{});var U0e=s(v2);ude=n(U0e,"STRONG",{});var mtt=s(ude);E5o=r(mtt,"xlm-roberta"),mtt.forEach(t),C5o=r(U0e," \u2014 "),$j=n(U0e,"A",{href:!0});var gtt=s($j);w5o=r(gtt,"XLMRobertaForCausalLM"),gtt.forEach(t),A5o=r(U0e," (XLM-RoBERTa model)"),U0e.forEach(t),y5o=i(W),F2=n(W,"LI",{});var J0e=s(F2);_de=n(J0e,"STRONG",{});var htt=s(_de);L5o=r(htt,"xlm-roberta-xl"),htt.forEach(t),x5o=r(J0e," \u2014 "),kj=n(J0e,"A",{href:!0});var ptt=s(kj);$5o=r(ptt,"XLMRobertaXLForCausalLM"),ptt.forEach(t),k5o=r(J0e," (XLM-RoBERTa-XL model)"),J0e.forEach(t),S5o=i(W),T2=n(W,"LI",{});var Y0e=s(T2);bde=n(Y0e,"STRONG",{});var utt=s(bde);R5o=r(utt,"xlnet"),utt.forEach(t),P5o=r(Y0e," \u2014 "),Sj=n(Y0e,"A",{href:!0});var _tt=s(Sj);B5o=r(_tt,"XLNetLMHeadModel"),_tt.forEach(t),I5o=r(Y0e," (XLNet model)"),Y0e.forEach(t),W.forEach(t),q5o=i(aa),M2=n(aa,"P",{});var K0e=s(M2);N5o=r(K0e,"The model is set in evaluation mode by default using "),vde=n(K0e,"CODE",{});var btt=s(vde);j5o=r(btt,"model.eval()"),btt.forEach(t),D5o=r(K0e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fde=n(K0e,"CODE",{});var vtt=s(Fde);G5o=r(vtt,"model.train()"),vtt.forEach(t),K0e.forEach(t),O5o=i(aa),T(E2.$$.fragment,aa),aa.forEach(t),Ws.forEach(t),sqe=i(f),qi=n(f,"H2",{class:!0});var mje=s(qi);C2=n(mje,"A",{id:!0,class:!0,href:!0});var Ftt=s(C2);Tde=n(Ftt,"SPAN",{});var Ttt=s(Tde);T(t0.$$.fragment,Ttt),Ttt.forEach(t),Ftt.forEach(t),V5o=i(mje),Mde=n(mje,"SPAN",{});var Mtt=s(Mde);X5o=r(Mtt,"AutoModelForMaskedLM"),Mtt.forEach(t),mje.forEach(t),lqe=i(f),So=n(f,"DIV",{class:!0});var Hs=s(So);T(a0.$$.fragment,Hs),z5o=i(Hs),Ni=n(Hs,"P",{});var QK=s(Ni);Q5o=r(QK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Rj=n(QK,"A",{href:!0});var Ett=s(Rj);W5o=r(Ett,"from_pretrained()"),Ett.forEach(t),H5o=r(QK," class method or the "),Pj=n(QK,"A",{href:!0});var Ctt=s(Pj);U5o=r(Ctt,"from_config()"),Ctt.forEach(t),J5o=r(QK,` class
method.`),QK.forEach(t),Y5o=i(Hs),n0=n(Hs,"P",{});var gje=s(n0);K5o=r(gje,"This class cannot be instantiated directly using "),Ede=n(gje,"CODE",{});var wtt=s(Ede);Z5o=r(wtt,"__init__()"),wtt.forEach(t),eCo=r(gje," (throws an error)."),gje.forEach(t),oCo=i(Hs),st=n(Hs,"DIV",{class:!0});var E3=s(st);T(s0.$$.fragment,E3),rCo=i(E3),Cde=n(E3,"P",{});var Att=s(Cde);tCo=r(Att,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Att.forEach(t),aCo=i(E3),ji=n(E3,"P",{});var WK=s(ji);nCo=r(WK,`Note:
Loading a model from its configuration file does `),wde=n(WK,"STRONG",{});var ytt=s(wde);sCo=r(ytt,"not"),ytt.forEach(t),lCo=r(WK,` load the model weights. It only affects the
model\u2019s configuration. Use `),Bj=n(WK,"A",{href:!0});var Ltt=s(Bj);iCo=r(Ltt,"from_pretrained()"),Ltt.forEach(t),dCo=r(WK," to load the model weights."),WK.forEach(t),cCo=i(E3),T(w2.$$.fragment,E3),E3.forEach(t),fCo=i(Hs),Ye=n(Hs,"DIV",{class:!0});var na=s(Ye);T(l0.$$.fragment,na),mCo=i(na),Ade=n(na,"P",{});var xtt=s(Ade);gCo=r(xtt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),xtt.forEach(t),hCo=i(na),Ra=n(na,"P",{});var C3=s(Ra);pCo=r(C3,"The model class to instantiate is selected based on the "),yde=n(C3,"CODE",{});var $tt=s(yde);uCo=r($tt,"model_type"),$tt.forEach(t),_Co=r(C3,` property of the config object (either
passed as an argument or loaded from `),Lde=n(C3,"CODE",{});var ktt=s(Lde);bCo=r(ktt,"pretrained_model_name_or_path"),ktt.forEach(t),vCo=r(C3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xde=n(C3,"CODE",{});var Stt=s(xde);FCo=r(Stt,"pretrained_model_name_or_path"),Stt.forEach(t),TCo=r(C3,":"),C3.forEach(t),MCo=i(na),Q=n(na,"UL",{});var H=s(Q);A2=n(H,"LI",{});var Z0e=s(A2);$de=n(Z0e,"STRONG",{});var Rtt=s($de);ECo=r(Rtt,"albert"),Rtt.forEach(t),CCo=r(Z0e," \u2014 "),Ij=n(Z0e,"A",{href:!0});var Ptt=s(Ij);wCo=r(Ptt,"AlbertForMaskedLM"),Ptt.forEach(t),ACo=r(Z0e," (ALBERT model)"),Z0e.forEach(t),yCo=i(H),y2=n(H,"LI",{});var eye=s(y2);kde=n(eye,"STRONG",{});var Btt=s(kde);LCo=r(Btt,"bart"),Btt.forEach(t),xCo=r(eye," \u2014 "),qj=n(eye,"A",{href:!0});var Itt=s(qj);$Co=r(Itt,"BartForConditionalGeneration"),Itt.forEach(t),kCo=r(eye," (BART model)"),eye.forEach(t),SCo=i(H),L2=n(H,"LI",{});var oye=s(L2);Sde=n(oye,"STRONG",{});var qtt=s(Sde);RCo=r(qtt,"bert"),qtt.forEach(t),PCo=r(oye," \u2014 "),Nj=n(oye,"A",{href:!0});var Ntt=s(Nj);BCo=r(Ntt,"BertForMaskedLM"),Ntt.forEach(t),ICo=r(oye," (BERT model)"),oye.forEach(t),qCo=i(H),x2=n(H,"LI",{});var rye=s(x2);Rde=n(rye,"STRONG",{});var jtt=s(Rde);NCo=r(jtt,"big_bird"),jtt.forEach(t),jCo=r(rye," \u2014 "),jj=n(rye,"A",{href:!0});var Dtt=s(jj);DCo=r(Dtt,"BigBirdForMaskedLM"),Dtt.forEach(t),GCo=r(rye," (BigBird model)"),rye.forEach(t),OCo=i(H),$2=n(H,"LI",{});var tye=s($2);Pde=n(tye,"STRONG",{});var Gtt=s(Pde);VCo=r(Gtt,"camembert"),Gtt.forEach(t),XCo=r(tye," \u2014 "),Dj=n(tye,"A",{href:!0});var Ott=s(Dj);zCo=r(Ott,"CamembertForMaskedLM"),Ott.forEach(t),QCo=r(tye," (CamemBERT model)"),tye.forEach(t),WCo=i(H),k2=n(H,"LI",{});var aye=s(k2);Bde=n(aye,"STRONG",{});var Vtt=s(Bde);HCo=r(Vtt,"convbert"),Vtt.forEach(t),UCo=r(aye," \u2014 "),Gj=n(aye,"A",{href:!0});var Xtt=s(Gj);JCo=r(Xtt,"ConvBertForMaskedLM"),Xtt.forEach(t),YCo=r(aye," (ConvBERT model)"),aye.forEach(t),KCo=i(H),S2=n(H,"LI",{});var nye=s(S2);Ide=n(nye,"STRONG",{});var ztt=s(Ide);ZCo=r(ztt,"data2vec-text"),ztt.forEach(t),e3o=r(nye," \u2014 "),Oj=n(nye,"A",{href:!0});var Qtt=s(Oj);o3o=r(Qtt,"Data2VecTextForMaskedLM"),Qtt.forEach(t),r3o=r(nye," (Data2VecText model)"),nye.forEach(t),t3o=i(H),R2=n(H,"LI",{});var sye=s(R2);qde=n(sye,"STRONG",{});var Wtt=s(qde);a3o=r(Wtt,"deberta"),Wtt.forEach(t),n3o=r(sye," \u2014 "),Vj=n(sye,"A",{href:!0});var Htt=s(Vj);s3o=r(Htt,"DebertaForMaskedLM"),Htt.forEach(t),l3o=r(sye," (DeBERTa model)"),sye.forEach(t),i3o=i(H),P2=n(H,"LI",{});var lye=s(P2);Nde=n(lye,"STRONG",{});var Utt=s(Nde);d3o=r(Utt,"deberta-v2"),Utt.forEach(t),c3o=r(lye," \u2014 "),Xj=n(lye,"A",{href:!0});var Jtt=s(Xj);f3o=r(Jtt,"DebertaV2ForMaskedLM"),Jtt.forEach(t),m3o=r(lye," (DeBERTa-v2 model)"),lye.forEach(t),g3o=i(H),B2=n(H,"LI",{});var iye=s(B2);jde=n(iye,"STRONG",{});var Ytt=s(jde);h3o=r(Ytt,"distilbert"),Ytt.forEach(t),p3o=r(iye," \u2014 "),zj=n(iye,"A",{href:!0});var Ktt=s(zj);u3o=r(Ktt,"DistilBertForMaskedLM"),Ktt.forEach(t),_3o=r(iye," (DistilBERT model)"),iye.forEach(t),b3o=i(H),I2=n(H,"LI",{});var dye=s(I2);Dde=n(dye,"STRONG",{});var Ztt=s(Dde);v3o=r(Ztt,"electra"),Ztt.forEach(t),F3o=r(dye," \u2014 "),Qj=n(dye,"A",{href:!0});var eat=s(Qj);T3o=r(eat,"ElectraForMaskedLM"),eat.forEach(t),M3o=r(dye," (ELECTRA model)"),dye.forEach(t),E3o=i(H),q2=n(H,"LI",{});var cye=s(q2);Gde=n(cye,"STRONG",{});var oat=s(Gde);C3o=r(oat,"flaubert"),oat.forEach(t),w3o=r(cye," \u2014 "),Wj=n(cye,"A",{href:!0});var rat=s(Wj);A3o=r(rat,"FlaubertWithLMHeadModel"),rat.forEach(t),y3o=r(cye," (FlauBERT model)"),cye.forEach(t),L3o=i(H),N2=n(H,"LI",{});var fye=s(N2);Ode=n(fye,"STRONG",{});var tat=s(Ode);x3o=r(tat,"fnet"),tat.forEach(t),$3o=r(fye," \u2014 "),Hj=n(fye,"A",{href:!0});var aat=s(Hj);k3o=r(aat,"FNetForMaskedLM"),aat.forEach(t),S3o=r(fye," (FNet model)"),fye.forEach(t),R3o=i(H),j2=n(H,"LI",{});var mye=s(j2);Vde=n(mye,"STRONG",{});var nat=s(Vde);P3o=r(nat,"funnel"),nat.forEach(t),B3o=r(mye," \u2014 "),Uj=n(mye,"A",{href:!0});var sat=s(Uj);I3o=r(sat,"FunnelForMaskedLM"),sat.forEach(t),q3o=r(mye," (Funnel Transformer model)"),mye.forEach(t),N3o=i(H),D2=n(H,"LI",{});var gye=s(D2);Xde=n(gye,"STRONG",{});var lat=s(Xde);j3o=r(lat,"ibert"),lat.forEach(t),D3o=r(gye," \u2014 "),Jj=n(gye,"A",{href:!0});var iat=s(Jj);G3o=r(iat,"IBertForMaskedLM"),iat.forEach(t),O3o=r(gye," (I-BERT model)"),gye.forEach(t),V3o=i(H),G2=n(H,"LI",{});var hye=s(G2);zde=n(hye,"STRONG",{});var dat=s(zde);X3o=r(dat,"layoutlm"),dat.forEach(t),z3o=r(hye," \u2014 "),Yj=n(hye,"A",{href:!0});var cat=s(Yj);Q3o=r(cat,"LayoutLMForMaskedLM"),cat.forEach(t),W3o=r(hye," (LayoutLM model)"),hye.forEach(t),H3o=i(H),O2=n(H,"LI",{});var pye=s(O2);Qde=n(pye,"STRONG",{});var fat=s(Qde);U3o=r(fat,"longformer"),fat.forEach(t),J3o=r(pye," \u2014 "),Kj=n(pye,"A",{href:!0});var mat=s(Kj);Y3o=r(mat,"LongformerForMaskedLM"),mat.forEach(t),K3o=r(pye," (Longformer model)"),pye.forEach(t),Z3o=i(H),V2=n(H,"LI",{});var uye=s(V2);Wde=n(uye,"STRONG",{});var gat=s(Wde);ewo=r(gat,"mbart"),gat.forEach(t),owo=r(uye," \u2014 "),Zj=n(uye,"A",{href:!0});var hat=s(Zj);rwo=r(hat,"MBartForConditionalGeneration"),hat.forEach(t),two=r(uye," (mBART model)"),uye.forEach(t),awo=i(H),X2=n(H,"LI",{});var _ye=s(X2);Hde=n(_ye,"STRONG",{});var pat=s(Hde);nwo=r(pat,"megatron-bert"),pat.forEach(t),swo=r(_ye," \u2014 "),eD=n(_ye,"A",{href:!0});var uat=s(eD);lwo=r(uat,"MegatronBertForMaskedLM"),uat.forEach(t),iwo=r(_ye," (MegatronBert model)"),_ye.forEach(t),dwo=i(H),z2=n(H,"LI",{});var bye=s(z2);Ude=n(bye,"STRONG",{});var _at=s(Ude);cwo=r(_at,"mobilebert"),_at.forEach(t),fwo=r(bye," \u2014 "),oD=n(bye,"A",{href:!0});var bat=s(oD);mwo=r(bat,"MobileBertForMaskedLM"),bat.forEach(t),gwo=r(bye," (MobileBERT model)"),bye.forEach(t),hwo=i(H),Q2=n(H,"LI",{});var vye=s(Q2);Jde=n(vye,"STRONG",{});var vat=s(Jde);pwo=r(vat,"mpnet"),vat.forEach(t),uwo=r(vye," \u2014 "),rD=n(vye,"A",{href:!0});var Fat=s(rD);_wo=r(Fat,"MPNetForMaskedLM"),Fat.forEach(t),bwo=r(vye," (MPNet model)"),vye.forEach(t),vwo=i(H),W2=n(H,"LI",{});var Fye=s(W2);Yde=n(Fye,"STRONG",{});var Tat=s(Yde);Fwo=r(Tat,"nystromformer"),Tat.forEach(t),Two=r(Fye," \u2014 "),tD=n(Fye,"A",{href:!0});var Mat=s(tD);Mwo=r(Mat,"NystromformerForMaskedLM"),Mat.forEach(t),Ewo=r(Fye," (Nystromformer model)"),Fye.forEach(t),Cwo=i(H),H2=n(H,"LI",{});var Tye=s(H2);Kde=n(Tye,"STRONG",{});var Eat=s(Kde);wwo=r(Eat,"perceiver"),Eat.forEach(t),Awo=r(Tye," \u2014 "),aD=n(Tye,"A",{href:!0});var Cat=s(aD);ywo=r(Cat,"PerceiverForMaskedLM"),Cat.forEach(t),Lwo=r(Tye," (Perceiver model)"),Tye.forEach(t),xwo=i(H),U2=n(H,"LI",{});var Mye=s(U2);Zde=n(Mye,"STRONG",{});var wat=s(Zde);$wo=r(wat,"qdqbert"),wat.forEach(t),kwo=r(Mye," \u2014 "),nD=n(Mye,"A",{href:!0});var Aat=s(nD);Swo=r(Aat,"QDQBertForMaskedLM"),Aat.forEach(t),Rwo=r(Mye," (QDQBert model)"),Mye.forEach(t),Pwo=i(H),J2=n(H,"LI",{});var Eye=s(J2);ece=n(Eye,"STRONG",{});var yat=s(ece);Bwo=r(yat,"reformer"),yat.forEach(t),Iwo=r(Eye," \u2014 "),sD=n(Eye,"A",{href:!0});var Lat=s(sD);qwo=r(Lat,"ReformerForMaskedLM"),Lat.forEach(t),Nwo=r(Eye," (Reformer model)"),Eye.forEach(t),jwo=i(H),Y2=n(H,"LI",{});var Cye=s(Y2);oce=n(Cye,"STRONG",{});var xat=s(oce);Dwo=r(xat,"rembert"),xat.forEach(t),Gwo=r(Cye," \u2014 "),lD=n(Cye,"A",{href:!0});var $at=s(lD);Owo=r($at,"RemBertForMaskedLM"),$at.forEach(t),Vwo=r(Cye," (RemBERT model)"),Cye.forEach(t),Xwo=i(H),K2=n(H,"LI",{});var wye=s(K2);rce=n(wye,"STRONG",{});var kat=s(rce);zwo=r(kat,"roberta"),kat.forEach(t),Qwo=r(wye," \u2014 "),iD=n(wye,"A",{href:!0});var Sat=s(iD);Wwo=r(Sat,"RobertaForMaskedLM"),Sat.forEach(t),Hwo=r(wye," (RoBERTa model)"),wye.forEach(t),Uwo=i(H),Z2=n(H,"LI",{});var Aye=s(Z2);tce=n(Aye,"STRONG",{});var Rat=s(tce);Jwo=r(Rat,"roformer"),Rat.forEach(t),Ywo=r(Aye," \u2014 "),dD=n(Aye,"A",{href:!0});var Pat=s(dD);Kwo=r(Pat,"RoFormerForMaskedLM"),Pat.forEach(t),Zwo=r(Aye," (RoFormer model)"),Aye.forEach(t),eAo=i(H),e1=n(H,"LI",{});var yye=s(e1);ace=n(yye,"STRONG",{});var Bat=s(ace);oAo=r(Bat,"squeezebert"),Bat.forEach(t),rAo=r(yye," \u2014 "),cD=n(yye,"A",{href:!0});var Iat=s(cD);tAo=r(Iat,"SqueezeBertForMaskedLM"),Iat.forEach(t),aAo=r(yye," (SqueezeBERT model)"),yye.forEach(t),nAo=i(H),o1=n(H,"LI",{});var Lye=s(o1);nce=n(Lye,"STRONG",{});var qat=s(nce);sAo=r(qat,"tapas"),qat.forEach(t),lAo=r(Lye," \u2014 "),fD=n(Lye,"A",{href:!0});var Nat=s(fD);iAo=r(Nat,"TapasForMaskedLM"),Nat.forEach(t),dAo=r(Lye," (TAPAS model)"),Lye.forEach(t),cAo=i(H),r1=n(H,"LI",{});var xye=s(r1);sce=n(xye,"STRONG",{});var jat=s(sce);fAo=r(jat,"wav2vec2"),jat.forEach(t),mAo=r(xye," \u2014 "),lce=n(xye,"CODE",{});var Dat=s(lce);gAo=r(Dat,"Wav2Vec2ForMaskedLM"),Dat.forEach(t),hAo=r(xye," (Wav2Vec2 model)"),xye.forEach(t),pAo=i(H),t1=n(H,"LI",{});var $ye=s(t1);ice=n($ye,"STRONG",{});var Gat=s(ice);uAo=r(Gat,"xlm"),Gat.forEach(t),_Ao=r($ye," \u2014 "),mD=n($ye,"A",{href:!0});var Oat=s(mD);bAo=r(Oat,"XLMWithLMHeadModel"),Oat.forEach(t),vAo=r($ye," (XLM model)"),$ye.forEach(t),FAo=i(H),a1=n(H,"LI",{});var kye=s(a1);dce=n(kye,"STRONG",{});var Vat=s(dce);TAo=r(Vat,"xlm-roberta"),Vat.forEach(t),MAo=r(kye," \u2014 "),gD=n(kye,"A",{href:!0});var Xat=s(gD);EAo=r(Xat,"XLMRobertaForMaskedLM"),Xat.forEach(t),CAo=r(kye," (XLM-RoBERTa model)"),kye.forEach(t),wAo=i(H),n1=n(H,"LI",{});var Sye=s(n1);cce=n(Sye,"STRONG",{});var zat=s(cce);AAo=r(zat,"xlm-roberta-xl"),zat.forEach(t),yAo=r(Sye," \u2014 "),hD=n(Sye,"A",{href:!0});var Qat=s(hD);LAo=r(Qat,"XLMRobertaXLForMaskedLM"),Qat.forEach(t),xAo=r(Sye," (XLM-RoBERTa-XL model)"),Sye.forEach(t),$Ao=i(H),s1=n(H,"LI",{});var Rye=s(s1);fce=n(Rye,"STRONG",{});var Wat=s(fce);kAo=r(Wat,"yoso"),Wat.forEach(t),SAo=r(Rye," \u2014 "),pD=n(Rye,"A",{href:!0});var Hat=s(pD);RAo=r(Hat,"YosoForMaskedLM"),Hat.forEach(t),PAo=r(Rye," (YOSO model)"),Rye.forEach(t),H.forEach(t),BAo=i(na),l1=n(na,"P",{});var Pye=s(l1);IAo=r(Pye,"The model is set in evaluation mode by default using "),mce=n(Pye,"CODE",{});var Uat=s(mce);qAo=r(Uat,"model.eval()"),Uat.forEach(t),NAo=r(Pye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gce=n(Pye,"CODE",{});var Jat=s(gce);jAo=r(Jat,"model.train()"),Jat.forEach(t),Pye.forEach(t),DAo=i(na),T(i1.$$.fragment,na),na.forEach(t),Hs.forEach(t),iqe=i(f),Di=n(f,"H2",{class:!0});var hje=s(Di);d1=n(hje,"A",{id:!0,class:!0,href:!0});var Yat=s(d1);hce=n(Yat,"SPAN",{});var Kat=s(hce);T(i0.$$.fragment,Kat),Kat.forEach(t),Yat.forEach(t),GAo=i(hje),pce=n(hje,"SPAN",{});var Zat=s(pce);OAo=r(Zat,"AutoModelForSeq2SeqLM"),Zat.forEach(t),hje.forEach(t),dqe=i(f),Ro=n(f,"DIV",{class:!0});var Us=s(Ro);T(d0.$$.fragment,Us),VAo=i(Us),Gi=n(Us,"P",{});var HK=s(Gi);XAo=r(HK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),uD=n(HK,"A",{href:!0});var ent=s(uD);zAo=r(ent,"from_pretrained()"),ent.forEach(t),QAo=r(HK," class method or the "),_D=n(HK,"A",{href:!0});var ont=s(_D);WAo=r(ont,"from_config()"),ont.forEach(t),HAo=r(HK,` class
method.`),HK.forEach(t),UAo=i(Us),c0=n(Us,"P",{});var pje=s(c0);JAo=r(pje,"This class cannot be instantiated directly using "),uce=n(pje,"CODE",{});var rnt=s(uce);YAo=r(rnt,"__init__()"),rnt.forEach(t),KAo=r(pje," (throws an error)."),pje.forEach(t),ZAo=i(Us),lt=n(Us,"DIV",{class:!0});var w3=s(lt);T(f0.$$.fragment,w3),e0o=i(w3),_ce=n(w3,"P",{});var tnt=s(_ce);o0o=r(tnt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),tnt.forEach(t),r0o=i(w3),Oi=n(w3,"P",{});var UK=s(Oi);t0o=r(UK,`Note:
Loading a model from its configuration file does `),bce=n(UK,"STRONG",{});var ant=s(bce);a0o=r(ant,"not"),ant.forEach(t),n0o=r(UK,` load the model weights. It only affects the
model\u2019s configuration. Use `),bD=n(UK,"A",{href:!0});var nnt=s(bD);s0o=r(nnt,"from_pretrained()"),nnt.forEach(t),l0o=r(UK," to load the model weights."),UK.forEach(t),i0o=i(w3),T(c1.$$.fragment,w3),w3.forEach(t),d0o=i(Us),Ke=n(Us,"DIV",{class:!0});var sa=s(Ke);T(m0.$$.fragment,sa),c0o=i(sa),vce=n(sa,"P",{});var snt=s(vce);f0o=r(snt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),snt.forEach(t),m0o=i(sa),Pa=n(sa,"P",{});var A3=s(Pa);g0o=r(A3,"The model class to instantiate is selected based on the "),Fce=n(A3,"CODE",{});var lnt=s(Fce);h0o=r(lnt,"model_type"),lnt.forEach(t),p0o=r(A3,` property of the config object (either
passed as an argument or loaded from `),Tce=n(A3,"CODE",{});var int=s(Tce);u0o=r(int,"pretrained_model_name_or_path"),int.forEach(t),_0o=r(A3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mce=n(A3,"CODE",{});var dnt=s(Mce);b0o=r(dnt,"pretrained_model_name_or_path"),dnt.forEach(t),v0o=r(A3,":"),A3.forEach(t),F0o=i(sa),he=n(sa,"UL",{});var ue=s(he);f1=n(ue,"LI",{});var Bye=s(f1);Ece=n(Bye,"STRONG",{});var cnt=s(Ece);T0o=r(cnt,"bart"),cnt.forEach(t),M0o=r(Bye," \u2014 "),vD=n(Bye,"A",{href:!0});var fnt=s(vD);E0o=r(fnt,"BartForConditionalGeneration"),fnt.forEach(t),C0o=r(Bye," (BART model)"),Bye.forEach(t),w0o=i(ue),m1=n(ue,"LI",{});var Iye=s(m1);Cce=n(Iye,"STRONG",{});var mnt=s(Cce);A0o=r(mnt,"bigbird_pegasus"),mnt.forEach(t),y0o=r(Iye," \u2014 "),FD=n(Iye,"A",{href:!0});var gnt=s(FD);L0o=r(gnt,"BigBirdPegasusForConditionalGeneration"),gnt.forEach(t),x0o=r(Iye," (BigBirdPegasus model)"),Iye.forEach(t),$0o=i(ue),g1=n(ue,"LI",{});var qye=s(g1);wce=n(qye,"STRONG",{});var hnt=s(wce);k0o=r(hnt,"blenderbot"),hnt.forEach(t),S0o=r(qye," \u2014 "),TD=n(qye,"A",{href:!0});var pnt=s(TD);R0o=r(pnt,"BlenderbotForConditionalGeneration"),pnt.forEach(t),P0o=r(qye," (Blenderbot model)"),qye.forEach(t),B0o=i(ue),h1=n(ue,"LI",{});var Nye=s(h1);Ace=n(Nye,"STRONG",{});var unt=s(Ace);I0o=r(unt,"blenderbot-small"),unt.forEach(t),q0o=r(Nye," \u2014 "),MD=n(Nye,"A",{href:!0});var _nt=s(MD);N0o=r(_nt,"BlenderbotSmallForConditionalGeneration"),_nt.forEach(t),j0o=r(Nye," (BlenderbotSmall model)"),Nye.forEach(t),D0o=i(ue),p1=n(ue,"LI",{});var jye=s(p1);yce=n(jye,"STRONG",{});var bnt=s(yce);G0o=r(bnt,"encoder-decoder"),bnt.forEach(t),O0o=r(jye," \u2014 "),ED=n(jye,"A",{href:!0});var vnt=s(ED);V0o=r(vnt,"EncoderDecoderModel"),vnt.forEach(t),X0o=r(jye," (Encoder decoder model)"),jye.forEach(t),z0o=i(ue),u1=n(ue,"LI",{});var Dye=s(u1);Lce=n(Dye,"STRONG",{});var Fnt=s(Lce);Q0o=r(Fnt,"fsmt"),Fnt.forEach(t),W0o=r(Dye," \u2014 "),CD=n(Dye,"A",{href:!0});var Tnt=s(CD);H0o=r(Tnt,"FSMTForConditionalGeneration"),Tnt.forEach(t),U0o=r(Dye," (FairSeq Machine-Translation model)"),Dye.forEach(t),J0o=i(ue),_1=n(ue,"LI",{});var Gye=s(_1);xce=n(Gye,"STRONG",{});var Mnt=s(xce);Y0o=r(Mnt,"led"),Mnt.forEach(t),K0o=r(Gye," \u2014 "),wD=n(Gye,"A",{href:!0});var Ent=s(wD);Z0o=r(Ent,"LEDForConditionalGeneration"),Ent.forEach(t),eyo=r(Gye," (LED model)"),Gye.forEach(t),oyo=i(ue),b1=n(ue,"LI",{});var Oye=s(b1);$ce=n(Oye,"STRONG",{});var Cnt=s($ce);ryo=r(Cnt,"m2m_100"),Cnt.forEach(t),tyo=r(Oye," \u2014 "),AD=n(Oye,"A",{href:!0});var wnt=s(AD);ayo=r(wnt,"M2M100ForConditionalGeneration"),wnt.forEach(t),nyo=r(Oye," (M2M100 model)"),Oye.forEach(t),syo=i(ue),v1=n(ue,"LI",{});var Vye=s(v1);kce=n(Vye,"STRONG",{});var Ant=s(kce);lyo=r(Ant,"marian"),Ant.forEach(t),iyo=r(Vye," \u2014 "),yD=n(Vye,"A",{href:!0});var ynt=s(yD);dyo=r(ynt,"MarianMTModel"),ynt.forEach(t),cyo=r(Vye," (Marian model)"),Vye.forEach(t),fyo=i(ue),F1=n(ue,"LI",{});var Xye=s(F1);Sce=n(Xye,"STRONG",{});var Lnt=s(Sce);myo=r(Lnt,"mbart"),Lnt.forEach(t),gyo=r(Xye," \u2014 "),LD=n(Xye,"A",{href:!0});var xnt=s(LD);hyo=r(xnt,"MBartForConditionalGeneration"),xnt.forEach(t),pyo=r(Xye," (mBART model)"),Xye.forEach(t),uyo=i(ue),T1=n(ue,"LI",{});var zye=s(T1);Rce=n(zye,"STRONG",{});var $nt=s(Rce);_yo=r($nt,"mt5"),$nt.forEach(t),byo=r(zye," \u2014 "),xD=n(zye,"A",{href:!0});var knt=s(xD);vyo=r(knt,"MT5ForConditionalGeneration"),knt.forEach(t),Fyo=r(zye," (mT5 model)"),zye.forEach(t),Tyo=i(ue),M1=n(ue,"LI",{});var Qye=s(M1);Pce=n(Qye,"STRONG",{});var Snt=s(Pce);Myo=r(Snt,"pegasus"),Snt.forEach(t),Eyo=r(Qye," \u2014 "),$D=n(Qye,"A",{href:!0});var Rnt=s($D);Cyo=r(Rnt,"PegasusForConditionalGeneration"),Rnt.forEach(t),wyo=r(Qye," (Pegasus model)"),Qye.forEach(t),Ayo=i(ue),E1=n(ue,"LI",{});var Wye=s(E1);Bce=n(Wye,"STRONG",{});var Pnt=s(Bce);yyo=r(Pnt,"plbart"),Pnt.forEach(t),Lyo=r(Wye," \u2014 "),kD=n(Wye,"A",{href:!0});var Bnt=s(kD);xyo=r(Bnt,"PLBartForConditionalGeneration"),Bnt.forEach(t),$yo=r(Wye," (PLBart model)"),Wye.forEach(t),kyo=i(ue),C1=n(ue,"LI",{});var Hye=s(C1);Ice=n(Hye,"STRONG",{});var Int=s(Ice);Syo=r(Int,"prophetnet"),Int.forEach(t),Ryo=r(Hye," \u2014 "),SD=n(Hye,"A",{href:!0});var qnt=s(SD);Pyo=r(qnt,"ProphetNetForConditionalGeneration"),qnt.forEach(t),Byo=r(Hye," (ProphetNet model)"),Hye.forEach(t),Iyo=i(ue),w1=n(ue,"LI",{});var Uye=s(w1);qce=n(Uye,"STRONG",{});var Nnt=s(qce);qyo=r(Nnt,"t5"),Nnt.forEach(t),Nyo=r(Uye," \u2014 "),RD=n(Uye,"A",{href:!0});var jnt=s(RD);jyo=r(jnt,"T5ForConditionalGeneration"),jnt.forEach(t),Dyo=r(Uye," (T5 model)"),Uye.forEach(t),Gyo=i(ue),A1=n(ue,"LI",{});var Jye=s(A1);Nce=n(Jye,"STRONG",{});var Dnt=s(Nce);Oyo=r(Dnt,"tapex"),Dnt.forEach(t),Vyo=r(Jye," \u2014 "),PD=n(Jye,"A",{href:!0});var Gnt=s(PD);Xyo=r(Gnt,"BartForConditionalGeneration"),Gnt.forEach(t),zyo=r(Jye," (TAPEX model)"),Jye.forEach(t),Qyo=i(ue),y1=n(ue,"LI",{});var Yye=s(y1);jce=n(Yye,"STRONG",{});var Ont=s(jce);Wyo=r(Ont,"xlm-prophetnet"),Ont.forEach(t),Hyo=r(Yye," \u2014 "),BD=n(Yye,"A",{href:!0});var Vnt=s(BD);Uyo=r(Vnt,"XLMProphetNetForConditionalGeneration"),Vnt.forEach(t),Jyo=r(Yye," (XLMProphetNet model)"),Yye.forEach(t),ue.forEach(t),Yyo=i(sa),L1=n(sa,"P",{});var Kye=s(L1);Kyo=r(Kye,"The model is set in evaluation mode by default using "),Dce=n(Kye,"CODE",{});var Xnt=s(Dce);Zyo=r(Xnt,"model.eval()"),Xnt.forEach(t),eLo=r(Kye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gce=n(Kye,"CODE",{});var znt=s(Gce);oLo=r(znt,"model.train()"),znt.forEach(t),Kye.forEach(t),rLo=i(sa),T(x1.$$.fragment,sa),sa.forEach(t),Us.forEach(t),cqe=i(f),Vi=n(f,"H2",{class:!0});var uje=s(Vi);$1=n(uje,"A",{id:!0,class:!0,href:!0});var Qnt=s($1);Oce=n(Qnt,"SPAN",{});var Wnt=s(Oce);T(g0.$$.fragment,Wnt),Wnt.forEach(t),Qnt.forEach(t),tLo=i(uje),Vce=n(uje,"SPAN",{});var Hnt=s(Vce);aLo=r(Hnt,"AutoModelForSequenceClassification"),Hnt.forEach(t),uje.forEach(t),fqe=i(f),Po=n(f,"DIV",{class:!0});var Js=s(Po);T(h0.$$.fragment,Js),nLo=i(Js),Xi=n(Js,"P",{});var JK=s(Xi);sLo=r(JK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),ID=n(JK,"A",{href:!0});var Unt=s(ID);lLo=r(Unt,"from_pretrained()"),Unt.forEach(t),iLo=r(JK," class method or the "),qD=n(JK,"A",{href:!0});var Jnt=s(qD);dLo=r(Jnt,"from_config()"),Jnt.forEach(t),cLo=r(JK,` class
method.`),JK.forEach(t),fLo=i(Js),p0=n(Js,"P",{});var _je=s(p0);mLo=r(_je,"This class cannot be instantiated directly using "),Xce=n(_je,"CODE",{});var Ynt=s(Xce);gLo=r(Ynt,"__init__()"),Ynt.forEach(t),hLo=r(_je," (throws an error)."),_je.forEach(t),pLo=i(Js),it=n(Js,"DIV",{class:!0});var y3=s(it);T(u0.$$.fragment,y3),uLo=i(y3),zce=n(y3,"P",{});var Knt=s(zce);_Lo=r(Knt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Knt.forEach(t),bLo=i(y3),zi=n(y3,"P",{});var YK=s(zi);vLo=r(YK,`Note:
Loading a model from its configuration file does `),Qce=n(YK,"STRONG",{});var Znt=s(Qce);FLo=r(Znt,"not"),Znt.forEach(t),TLo=r(YK,` load the model weights. It only affects the
model\u2019s configuration. Use `),ND=n(YK,"A",{href:!0});var est=s(ND);MLo=r(est,"from_pretrained()"),est.forEach(t),ELo=r(YK," to load the model weights."),YK.forEach(t),CLo=i(y3),T(k1.$$.fragment,y3),y3.forEach(t),wLo=i(Js),Ze=n(Js,"DIV",{class:!0});var la=s(Ze);T(_0.$$.fragment,la),ALo=i(la),Wce=n(la,"P",{});var ost=s(Wce);yLo=r(ost,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),ost.forEach(t),LLo=i(la),Ba=n(la,"P",{});var L3=s(Ba);xLo=r(L3,"The model class to instantiate is selected based on the "),Hce=n(L3,"CODE",{});var rst=s(Hce);$Lo=r(rst,"model_type"),rst.forEach(t),kLo=r(L3,` property of the config object (either
passed as an argument or loaded from `),Uce=n(L3,"CODE",{});var tst=s(Uce);SLo=r(tst,"pretrained_model_name_or_path"),tst.forEach(t),RLo=r(L3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jce=n(L3,"CODE",{});var ast=s(Jce);PLo=r(ast,"pretrained_model_name_or_path"),ast.forEach(t),BLo=r(L3,":"),L3.forEach(t),ILo=i(la),q=n(la,"UL",{});var N=s(q);S1=n(N,"LI",{});var Zye=s(S1);Yce=n(Zye,"STRONG",{});var nst=s(Yce);qLo=r(nst,"albert"),nst.forEach(t),NLo=r(Zye," \u2014 "),jD=n(Zye,"A",{href:!0});var sst=s(jD);jLo=r(sst,"AlbertForSequenceClassification"),sst.forEach(t),DLo=r(Zye," (ALBERT model)"),Zye.forEach(t),GLo=i(N),R1=n(N,"LI",{});var eLe=s(R1);Kce=n(eLe,"STRONG",{});var lst=s(Kce);OLo=r(lst,"bart"),lst.forEach(t),VLo=r(eLe," \u2014 "),DD=n(eLe,"A",{href:!0});var ist=s(DD);XLo=r(ist,"BartForSequenceClassification"),ist.forEach(t),zLo=r(eLe," (BART model)"),eLe.forEach(t),QLo=i(N),P1=n(N,"LI",{});var oLe=s(P1);Zce=n(oLe,"STRONG",{});var dst=s(Zce);WLo=r(dst,"bert"),dst.forEach(t),HLo=r(oLe," \u2014 "),GD=n(oLe,"A",{href:!0});var cst=s(GD);ULo=r(cst,"BertForSequenceClassification"),cst.forEach(t),JLo=r(oLe," (BERT model)"),oLe.forEach(t),YLo=i(N),B1=n(N,"LI",{});var rLe=s(B1);efe=n(rLe,"STRONG",{});var fst=s(efe);KLo=r(fst,"big_bird"),fst.forEach(t),ZLo=r(rLe," \u2014 "),OD=n(rLe,"A",{href:!0});var mst=s(OD);exo=r(mst,"BigBirdForSequenceClassification"),mst.forEach(t),oxo=r(rLe," (BigBird model)"),rLe.forEach(t),rxo=i(N),I1=n(N,"LI",{});var tLe=s(I1);ofe=n(tLe,"STRONG",{});var gst=s(ofe);txo=r(gst,"bigbird_pegasus"),gst.forEach(t),axo=r(tLe," \u2014 "),VD=n(tLe,"A",{href:!0});var hst=s(VD);nxo=r(hst,"BigBirdPegasusForSequenceClassification"),hst.forEach(t),sxo=r(tLe," (BigBirdPegasus model)"),tLe.forEach(t),lxo=i(N),q1=n(N,"LI",{});var aLe=s(q1);rfe=n(aLe,"STRONG",{});var pst=s(rfe);ixo=r(pst,"camembert"),pst.forEach(t),dxo=r(aLe," \u2014 "),XD=n(aLe,"A",{href:!0});var ust=s(XD);cxo=r(ust,"CamembertForSequenceClassification"),ust.forEach(t),fxo=r(aLe," (CamemBERT model)"),aLe.forEach(t),mxo=i(N),N1=n(N,"LI",{});var nLe=s(N1);tfe=n(nLe,"STRONG",{});var _st=s(tfe);gxo=r(_st,"canine"),_st.forEach(t),hxo=r(nLe," \u2014 "),zD=n(nLe,"A",{href:!0});var bst=s(zD);pxo=r(bst,"CanineForSequenceClassification"),bst.forEach(t),uxo=r(nLe," (Canine model)"),nLe.forEach(t),_xo=i(N),j1=n(N,"LI",{});var sLe=s(j1);afe=n(sLe,"STRONG",{});var vst=s(afe);bxo=r(vst,"convbert"),vst.forEach(t),vxo=r(sLe," \u2014 "),QD=n(sLe,"A",{href:!0});var Fst=s(QD);Fxo=r(Fst,"ConvBertForSequenceClassification"),Fst.forEach(t),Txo=r(sLe," (ConvBERT model)"),sLe.forEach(t),Mxo=i(N),D1=n(N,"LI",{});var lLe=s(D1);nfe=n(lLe,"STRONG",{});var Tst=s(nfe);Exo=r(Tst,"ctrl"),Tst.forEach(t),Cxo=r(lLe," \u2014 "),WD=n(lLe,"A",{href:!0});var Mst=s(WD);wxo=r(Mst,"CTRLForSequenceClassification"),Mst.forEach(t),Axo=r(lLe," (CTRL model)"),lLe.forEach(t),yxo=i(N),G1=n(N,"LI",{});var iLe=s(G1);sfe=n(iLe,"STRONG",{});var Est=s(sfe);Lxo=r(Est,"data2vec-text"),Est.forEach(t),xxo=r(iLe," \u2014 "),HD=n(iLe,"A",{href:!0});var Cst=s(HD);$xo=r(Cst,"Data2VecTextForSequenceClassification"),Cst.forEach(t),kxo=r(iLe," (Data2VecText model)"),iLe.forEach(t),Sxo=i(N),O1=n(N,"LI",{});var dLe=s(O1);lfe=n(dLe,"STRONG",{});var wst=s(lfe);Rxo=r(wst,"deberta"),wst.forEach(t),Pxo=r(dLe," \u2014 "),UD=n(dLe,"A",{href:!0});var Ast=s(UD);Bxo=r(Ast,"DebertaForSequenceClassification"),Ast.forEach(t),Ixo=r(dLe," (DeBERTa model)"),dLe.forEach(t),qxo=i(N),V1=n(N,"LI",{});var cLe=s(V1);ife=n(cLe,"STRONG",{});var yst=s(ife);Nxo=r(yst,"deberta-v2"),yst.forEach(t),jxo=r(cLe," \u2014 "),JD=n(cLe,"A",{href:!0});var Lst=s(JD);Dxo=r(Lst,"DebertaV2ForSequenceClassification"),Lst.forEach(t),Gxo=r(cLe," (DeBERTa-v2 model)"),cLe.forEach(t),Oxo=i(N),X1=n(N,"LI",{});var fLe=s(X1);dfe=n(fLe,"STRONG",{});var xst=s(dfe);Vxo=r(xst,"distilbert"),xst.forEach(t),Xxo=r(fLe," \u2014 "),YD=n(fLe,"A",{href:!0});var $st=s(YD);zxo=r($st,"DistilBertForSequenceClassification"),$st.forEach(t),Qxo=r(fLe," (DistilBERT model)"),fLe.forEach(t),Wxo=i(N),z1=n(N,"LI",{});var mLe=s(z1);cfe=n(mLe,"STRONG",{});var kst=s(cfe);Hxo=r(kst,"electra"),kst.forEach(t),Uxo=r(mLe," \u2014 "),KD=n(mLe,"A",{href:!0});var Sst=s(KD);Jxo=r(Sst,"ElectraForSequenceClassification"),Sst.forEach(t),Yxo=r(mLe," (ELECTRA model)"),mLe.forEach(t),Kxo=i(N),Q1=n(N,"LI",{});var gLe=s(Q1);ffe=n(gLe,"STRONG",{});var Rst=s(ffe);Zxo=r(Rst,"flaubert"),Rst.forEach(t),e9o=r(gLe," \u2014 "),ZD=n(gLe,"A",{href:!0});var Pst=s(ZD);o9o=r(Pst,"FlaubertForSequenceClassification"),Pst.forEach(t),r9o=r(gLe," (FlauBERT model)"),gLe.forEach(t),t9o=i(N),W1=n(N,"LI",{});var hLe=s(W1);mfe=n(hLe,"STRONG",{});var Bst=s(mfe);a9o=r(Bst,"fnet"),Bst.forEach(t),n9o=r(hLe," \u2014 "),eG=n(hLe,"A",{href:!0});var Ist=s(eG);s9o=r(Ist,"FNetForSequenceClassification"),Ist.forEach(t),l9o=r(hLe," (FNet model)"),hLe.forEach(t),i9o=i(N),H1=n(N,"LI",{});var pLe=s(H1);gfe=n(pLe,"STRONG",{});var qst=s(gfe);d9o=r(qst,"funnel"),qst.forEach(t),c9o=r(pLe," \u2014 "),oG=n(pLe,"A",{href:!0});var Nst=s(oG);f9o=r(Nst,"FunnelForSequenceClassification"),Nst.forEach(t),m9o=r(pLe," (Funnel Transformer model)"),pLe.forEach(t),g9o=i(N),U1=n(N,"LI",{});var uLe=s(U1);hfe=n(uLe,"STRONG",{});var jst=s(hfe);h9o=r(jst,"gpt2"),jst.forEach(t),p9o=r(uLe," \u2014 "),rG=n(uLe,"A",{href:!0});var Dst=s(rG);u9o=r(Dst,"GPT2ForSequenceClassification"),Dst.forEach(t),_9o=r(uLe," (OpenAI GPT-2 model)"),uLe.forEach(t),b9o=i(N),J1=n(N,"LI",{});var _Le=s(J1);pfe=n(_Le,"STRONG",{});var Gst=s(pfe);v9o=r(Gst,"gpt_neo"),Gst.forEach(t),F9o=r(_Le," \u2014 "),tG=n(_Le,"A",{href:!0});var Ost=s(tG);T9o=r(Ost,"GPTNeoForSequenceClassification"),Ost.forEach(t),M9o=r(_Le," (GPT Neo model)"),_Le.forEach(t),E9o=i(N),Y1=n(N,"LI",{});var bLe=s(Y1);ufe=n(bLe,"STRONG",{});var Vst=s(ufe);C9o=r(Vst,"gptj"),Vst.forEach(t),w9o=r(bLe," \u2014 "),aG=n(bLe,"A",{href:!0});var Xst=s(aG);A9o=r(Xst,"GPTJForSequenceClassification"),Xst.forEach(t),y9o=r(bLe," (GPT-J model)"),bLe.forEach(t),L9o=i(N),K1=n(N,"LI",{});var vLe=s(K1);_fe=n(vLe,"STRONG",{});var zst=s(_fe);x9o=r(zst,"ibert"),zst.forEach(t),$9o=r(vLe," \u2014 "),nG=n(vLe,"A",{href:!0});var Qst=s(nG);k9o=r(Qst,"IBertForSequenceClassification"),Qst.forEach(t),S9o=r(vLe," (I-BERT model)"),vLe.forEach(t),R9o=i(N),Z1=n(N,"LI",{});var FLe=s(Z1);bfe=n(FLe,"STRONG",{});var Wst=s(bfe);P9o=r(Wst,"layoutlm"),Wst.forEach(t),B9o=r(FLe," \u2014 "),sG=n(FLe,"A",{href:!0});var Hst=s(sG);I9o=r(Hst,"LayoutLMForSequenceClassification"),Hst.forEach(t),q9o=r(FLe," (LayoutLM model)"),FLe.forEach(t),N9o=i(N),eb=n(N,"LI",{});var TLe=s(eb);vfe=n(TLe,"STRONG",{});var Ust=s(vfe);j9o=r(Ust,"layoutlmv2"),Ust.forEach(t),D9o=r(TLe," \u2014 "),lG=n(TLe,"A",{href:!0});var Jst=s(lG);G9o=r(Jst,"LayoutLMv2ForSequenceClassification"),Jst.forEach(t),O9o=r(TLe," (LayoutLMv2 model)"),TLe.forEach(t),V9o=i(N),ob=n(N,"LI",{});var MLe=s(ob);Ffe=n(MLe,"STRONG",{});var Yst=s(Ffe);X9o=r(Yst,"led"),Yst.forEach(t),z9o=r(MLe," \u2014 "),iG=n(MLe,"A",{href:!0});var Kst=s(iG);Q9o=r(Kst,"LEDForSequenceClassification"),Kst.forEach(t),W9o=r(MLe," (LED model)"),MLe.forEach(t),H9o=i(N),rb=n(N,"LI",{});var ELe=s(rb);Tfe=n(ELe,"STRONG",{});var Zst=s(Tfe);U9o=r(Zst,"longformer"),Zst.forEach(t),J9o=r(ELe," \u2014 "),dG=n(ELe,"A",{href:!0});var elt=s(dG);Y9o=r(elt,"LongformerForSequenceClassification"),elt.forEach(t),K9o=r(ELe," (Longformer model)"),ELe.forEach(t),Z9o=i(N),tb=n(N,"LI",{});var CLe=s(tb);Mfe=n(CLe,"STRONG",{});var olt=s(Mfe);e$o=r(olt,"mbart"),olt.forEach(t),o$o=r(CLe," \u2014 "),cG=n(CLe,"A",{href:!0});var rlt=s(cG);r$o=r(rlt,"MBartForSequenceClassification"),rlt.forEach(t),t$o=r(CLe," (mBART model)"),CLe.forEach(t),a$o=i(N),ab=n(N,"LI",{});var wLe=s(ab);Efe=n(wLe,"STRONG",{});var tlt=s(Efe);n$o=r(tlt,"megatron-bert"),tlt.forEach(t),s$o=r(wLe," \u2014 "),fG=n(wLe,"A",{href:!0});var alt=s(fG);l$o=r(alt,"MegatronBertForSequenceClassification"),alt.forEach(t),i$o=r(wLe," (MegatronBert model)"),wLe.forEach(t),d$o=i(N),nb=n(N,"LI",{});var ALe=s(nb);Cfe=n(ALe,"STRONG",{});var nlt=s(Cfe);c$o=r(nlt,"mobilebert"),nlt.forEach(t),f$o=r(ALe," \u2014 "),mG=n(ALe,"A",{href:!0});var slt=s(mG);m$o=r(slt,"MobileBertForSequenceClassification"),slt.forEach(t),g$o=r(ALe," (MobileBERT model)"),ALe.forEach(t),h$o=i(N),sb=n(N,"LI",{});var yLe=s(sb);wfe=n(yLe,"STRONG",{});var llt=s(wfe);p$o=r(llt,"mpnet"),llt.forEach(t),u$o=r(yLe," \u2014 "),gG=n(yLe,"A",{href:!0});var ilt=s(gG);_$o=r(ilt,"MPNetForSequenceClassification"),ilt.forEach(t),b$o=r(yLe," (MPNet model)"),yLe.forEach(t),v$o=i(N),lb=n(N,"LI",{});var LLe=s(lb);Afe=n(LLe,"STRONG",{});var dlt=s(Afe);F$o=r(dlt,"nystromformer"),dlt.forEach(t),T$o=r(LLe," \u2014 "),hG=n(LLe,"A",{href:!0});var clt=s(hG);M$o=r(clt,"NystromformerForSequenceClassification"),clt.forEach(t),E$o=r(LLe," (Nystromformer model)"),LLe.forEach(t),C$o=i(N),ib=n(N,"LI",{});var xLe=s(ib);yfe=n(xLe,"STRONG",{});var flt=s(yfe);w$o=r(flt,"openai-gpt"),flt.forEach(t),A$o=r(xLe," \u2014 "),pG=n(xLe,"A",{href:!0});var mlt=s(pG);y$o=r(mlt,"OpenAIGPTForSequenceClassification"),mlt.forEach(t),L$o=r(xLe," (OpenAI GPT model)"),xLe.forEach(t),x$o=i(N),db=n(N,"LI",{});var $Le=s(db);Lfe=n($Le,"STRONG",{});var glt=s(Lfe);$$o=r(glt,"perceiver"),glt.forEach(t),k$o=r($Le," \u2014 "),uG=n($Le,"A",{href:!0});var hlt=s(uG);S$o=r(hlt,"PerceiverForSequenceClassification"),hlt.forEach(t),R$o=r($Le," (Perceiver model)"),$Le.forEach(t),P$o=i(N),cb=n(N,"LI",{});var kLe=s(cb);xfe=n(kLe,"STRONG",{});var plt=s(xfe);B$o=r(plt,"plbart"),plt.forEach(t),I$o=r(kLe," \u2014 "),_G=n(kLe,"A",{href:!0});var ult=s(_G);q$o=r(ult,"PLBartForSequenceClassification"),ult.forEach(t),N$o=r(kLe," (PLBart model)"),kLe.forEach(t),j$o=i(N),fb=n(N,"LI",{});var SLe=s(fb);$fe=n(SLe,"STRONG",{});var _lt=s($fe);D$o=r(_lt,"qdqbert"),_lt.forEach(t),G$o=r(SLe," \u2014 "),bG=n(SLe,"A",{href:!0});var blt=s(bG);O$o=r(blt,"QDQBertForSequenceClassification"),blt.forEach(t),V$o=r(SLe," (QDQBert model)"),SLe.forEach(t),X$o=i(N),mb=n(N,"LI",{});var RLe=s(mb);kfe=n(RLe,"STRONG",{});var vlt=s(kfe);z$o=r(vlt,"reformer"),vlt.forEach(t),Q$o=r(RLe," \u2014 "),vG=n(RLe,"A",{href:!0});var Flt=s(vG);W$o=r(Flt,"ReformerForSequenceClassification"),Flt.forEach(t),H$o=r(RLe," (Reformer model)"),RLe.forEach(t),U$o=i(N),gb=n(N,"LI",{});var PLe=s(gb);Sfe=n(PLe,"STRONG",{});var Tlt=s(Sfe);J$o=r(Tlt,"rembert"),Tlt.forEach(t),Y$o=r(PLe," \u2014 "),FG=n(PLe,"A",{href:!0});var Mlt=s(FG);K$o=r(Mlt,"RemBertForSequenceClassification"),Mlt.forEach(t),Z$o=r(PLe," (RemBERT model)"),PLe.forEach(t),eko=i(N),hb=n(N,"LI",{});var BLe=s(hb);Rfe=n(BLe,"STRONG",{});var Elt=s(Rfe);oko=r(Elt,"roberta"),Elt.forEach(t),rko=r(BLe," \u2014 "),TG=n(BLe,"A",{href:!0});var Clt=s(TG);tko=r(Clt,"RobertaForSequenceClassification"),Clt.forEach(t),ako=r(BLe," (RoBERTa model)"),BLe.forEach(t),nko=i(N),pb=n(N,"LI",{});var ILe=s(pb);Pfe=n(ILe,"STRONG",{});var wlt=s(Pfe);sko=r(wlt,"roformer"),wlt.forEach(t),lko=r(ILe," \u2014 "),MG=n(ILe,"A",{href:!0});var Alt=s(MG);iko=r(Alt,"RoFormerForSequenceClassification"),Alt.forEach(t),dko=r(ILe," (RoFormer model)"),ILe.forEach(t),cko=i(N),ub=n(N,"LI",{});var qLe=s(ub);Bfe=n(qLe,"STRONG",{});var ylt=s(Bfe);fko=r(ylt,"squeezebert"),ylt.forEach(t),mko=r(qLe," \u2014 "),EG=n(qLe,"A",{href:!0});var Llt=s(EG);gko=r(Llt,"SqueezeBertForSequenceClassification"),Llt.forEach(t),hko=r(qLe," (SqueezeBERT model)"),qLe.forEach(t),pko=i(N),_b=n(N,"LI",{});var NLe=s(_b);Ife=n(NLe,"STRONG",{});var xlt=s(Ife);uko=r(xlt,"tapas"),xlt.forEach(t),_ko=r(NLe," \u2014 "),CG=n(NLe,"A",{href:!0});var $lt=s(CG);bko=r($lt,"TapasForSequenceClassification"),$lt.forEach(t),vko=r(NLe," (TAPAS model)"),NLe.forEach(t),Fko=i(N),bb=n(N,"LI",{});var jLe=s(bb);qfe=n(jLe,"STRONG",{});var klt=s(qfe);Tko=r(klt,"tapex"),klt.forEach(t),Mko=r(jLe," \u2014 "),wG=n(jLe,"A",{href:!0});var Slt=s(wG);Eko=r(Slt,"BartForSequenceClassification"),Slt.forEach(t),Cko=r(jLe," (TAPEX model)"),jLe.forEach(t),wko=i(N),vb=n(N,"LI",{});var DLe=s(vb);Nfe=n(DLe,"STRONG",{});var Rlt=s(Nfe);Ako=r(Rlt,"transfo-xl"),Rlt.forEach(t),yko=r(DLe," \u2014 "),AG=n(DLe,"A",{href:!0});var Plt=s(AG);Lko=r(Plt,"TransfoXLForSequenceClassification"),Plt.forEach(t),xko=r(DLe," (Transformer-XL model)"),DLe.forEach(t),$ko=i(N),Fb=n(N,"LI",{});var GLe=s(Fb);jfe=n(GLe,"STRONG",{});var Blt=s(jfe);kko=r(Blt,"xlm"),Blt.forEach(t),Sko=r(GLe," \u2014 "),yG=n(GLe,"A",{href:!0});var Ilt=s(yG);Rko=r(Ilt,"XLMForSequenceClassification"),Ilt.forEach(t),Pko=r(GLe," (XLM model)"),GLe.forEach(t),Bko=i(N),Tb=n(N,"LI",{});var OLe=s(Tb);Dfe=n(OLe,"STRONG",{});var qlt=s(Dfe);Iko=r(qlt,"xlm-roberta"),qlt.forEach(t),qko=r(OLe," \u2014 "),LG=n(OLe,"A",{href:!0});var Nlt=s(LG);Nko=r(Nlt,"XLMRobertaForSequenceClassification"),Nlt.forEach(t),jko=r(OLe," (XLM-RoBERTa model)"),OLe.forEach(t),Dko=i(N),Mb=n(N,"LI",{});var VLe=s(Mb);Gfe=n(VLe,"STRONG",{});var jlt=s(Gfe);Gko=r(jlt,"xlm-roberta-xl"),jlt.forEach(t),Oko=r(VLe," \u2014 "),xG=n(VLe,"A",{href:!0});var Dlt=s(xG);Vko=r(Dlt,"XLMRobertaXLForSequenceClassification"),Dlt.forEach(t),Xko=r(VLe," (XLM-RoBERTa-XL model)"),VLe.forEach(t),zko=i(N),Eb=n(N,"LI",{});var XLe=s(Eb);Ofe=n(XLe,"STRONG",{});var Glt=s(Ofe);Qko=r(Glt,"xlnet"),Glt.forEach(t),Wko=r(XLe," \u2014 "),$G=n(XLe,"A",{href:!0});var Olt=s($G);Hko=r(Olt,"XLNetForSequenceClassification"),Olt.forEach(t),Uko=r(XLe," (XLNet model)"),XLe.forEach(t),Jko=i(N),Cb=n(N,"LI",{});var zLe=s(Cb);Vfe=n(zLe,"STRONG",{});var Vlt=s(Vfe);Yko=r(Vlt,"yoso"),Vlt.forEach(t),Kko=r(zLe," \u2014 "),kG=n(zLe,"A",{href:!0});var Xlt=s(kG);Zko=r(Xlt,"YosoForSequenceClassification"),Xlt.forEach(t),eSo=r(zLe," (YOSO model)"),zLe.forEach(t),N.forEach(t),oSo=i(la),wb=n(la,"P",{});var QLe=s(wb);rSo=r(QLe,"The model is set in evaluation mode by default using "),Xfe=n(QLe,"CODE",{});var zlt=s(Xfe);tSo=r(zlt,"model.eval()"),zlt.forEach(t),aSo=r(QLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zfe=n(QLe,"CODE",{});var Qlt=s(zfe);nSo=r(Qlt,"model.train()"),Qlt.forEach(t),QLe.forEach(t),sSo=i(la),T(Ab.$$.fragment,la),la.forEach(t),Js.forEach(t),mqe=i(f),Qi=n(f,"H2",{class:!0});var bje=s(Qi);yb=n(bje,"A",{id:!0,class:!0,href:!0});var Wlt=s(yb);Qfe=n(Wlt,"SPAN",{});var Hlt=s(Qfe);T(b0.$$.fragment,Hlt),Hlt.forEach(t),Wlt.forEach(t),lSo=i(bje),Wfe=n(bje,"SPAN",{});var Ult=s(Wfe);iSo=r(Ult,"AutoModelForMultipleChoice"),Ult.forEach(t),bje.forEach(t),gqe=i(f),Bo=n(f,"DIV",{class:!0});var Ys=s(Bo);T(v0.$$.fragment,Ys),dSo=i(Ys),Wi=n(Ys,"P",{});var KK=s(Wi);cSo=r(KK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),SG=n(KK,"A",{href:!0});var Jlt=s(SG);fSo=r(Jlt,"from_pretrained()"),Jlt.forEach(t),mSo=r(KK," class method or the "),RG=n(KK,"A",{href:!0});var Ylt=s(RG);gSo=r(Ylt,"from_config()"),Ylt.forEach(t),hSo=r(KK,` class
method.`),KK.forEach(t),pSo=i(Ys),F0=n(Ys,"P",{});var vje=s(F0);uSo=r(vje,"This class cannot be instantiated directly using "),Hfe=n(vje,"CODE",{});var Klt=s(Hfe);_So=r(Klt,"__init__()"),Klt.forEach(t),bSo=r(vje," (throws an error)."),vje.forEach(t),vSo=i(Ys),dt=n(Ys,"DIV",{class:!0});var x3=s(dt);T(T0.$$.fragment,x3),FSo=i(x3),Ufe=n(x3,"P",{});var Zlt=s(Ufe);TSo=r(Zlt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Zlt.forEach(t),MSo=i(x3),Hi=n(x3,"P",{});var ZK=s(Hi);ESo=r(ZK,`Note:
Loading a model from its configuration file does `),Jfe=n(ZK,"STRONG",{});var eit=s(Jfe);CSo=r(eit,"not"),eit.forEach(t),wSo=r(ZK,` load the model weights. It only affects the
model\u2019s configuration. Use `),PG=n(ZK,"A",{href:!0});var oit=s(PG);ASo=r(oit,"from_pretrained()"),oit.forEach(t),ySo=r(ZK," to load the model weights."),ZK.forEach(t),LSo=i(x3),T(Lb.$$.fragment,x3),x3.forEach(t),xSo=i(Ys),eo=n(Ys,"DIV",{class:!0});var ia=s(eo);T(M0.$$.fragment,ia),$So=i(ia),Yfe=n(ia,"P",{});var rit=s(Yfe);kSo=r(rit,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),rit.forEach(t),SSo=i(ia),Ia=n(ia,"P",{});var $3=s(Ia);RSo=r($3,"The model class to instantiate is selected based on the "),Kfe=n($3,"CODE",{});var tit=s(Kfe);PSo=r(tit,"model_type"),tit.forEach(t),BSo=r($3,` property of the config object (either
passed as an argument or loaded from `),Zfe=n($3,"CODE",{});var ait=s(Zfe);ISo=r(ait,"pretrained_model_name_or_path"),ait.forEach(t),qSo=r($3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eme=n($3,"CODE",{});var nit=s(eme);NSo=r(nit,"pretrained_model_name_or_path"),nit.forEach(t),jSo=r($3,":"),$3.forEach(t),DSo=i(ia),Y=n(ia,"UL",{});var K=s(Y);xb=n(K,"LI",{});var WLe=s(xb);ome=n(WLe,"STRONG",{});var sit=s(ome);GSo=r(sit,"albert"),sit.forEach(t),OSo=r(WLe," \u2014 "),BG=n(WLe,"A",{href:!0});var lit=s(BG);VSo=r(lit,"AlbertForMultipleChoice"),lit.forEach(t),XSo=r(WLe," (ALBERT model)"),WLe.forEach(t),zSo=i(K),$b=n(K,"LI",{});var HLe=s($b);rme=n(HLe,"STRONG",{});var iit=s(rme);QSo=r(iit,"bert"),iit.forEach(t),WSo=r(HLe," \u2014 "),IG=n(HLe,"A",{href:!0});var dit=s(IG);HSo=r(dit,"BertForMultipleChoice"),dit.forEach(t),USo=r(HLe," (BERT model)"),HLe.forEach(t),JSo=i(K),kb=n(K,"LI",{});var ULe=s(kb);tme=n(ULe,"STRONG",{});var cit=s(tme);YSo=r(cit,"big_bird"),cit.forEach(t),KSo=r(ULe," \u2014 "),qG=n(ULe,"A",{href:!0});var fit=s(qG);ZSo=r(fit,"BigBirdForMultipleChoice"),fit.forEach(t),eRo=r(ULe," (BigBird model)"),ULe.forEach(t),oRo=i(K),Sb=n(K,"LI",{});var JLe=s(Sb);ame=n(JLe,"STRONG",{});var mit=s(ame);rRo=r(mit,"camembert"),mit.forEach(t),tRo=r(JLe," \u2014 "),NG=n(JLe,"A",{href:!0});var git=s(NG);aRo=r(git,"CamembertForMultipleChoice"),git.forEach(t),nRo=r(JLe," (CamemBERT model)"),JLe.forEach(t),sRo=i(K),Rb=n(K,"LI",{});var YLe=s(Rb);nme=n(YLe,"STRONG",{});var hit=s(nme);lRo=r(hit,"canine"),hit.forEach(t),iRo=r(YLe," \u2014 "),jG=n(YLe,"A",{href:!0});var pit=s(jG);dRo=r(pit,"CanineForMultipleChoice"),pit.forEach(t),cRo=r(YLe," (Canine model)"),YLe.forEach(t),fRo=i(K),Pb=n(K,"LI",{});var KLe=s(Pb);sme=n(KLe,"STRONG",{});var uit=s(sme);mRo=r(uit,"convbert"),uit.forEach(t),gRo=r(KLe," \u2014 "),DG=n(KLe,"A",{href:!0});var _it=s(DG);hRo=r(_it,"ConvBertForMultipleChoice"),_it.forEach(t),pRo=r(KLe," (ConvBERT model)"),KLe.forEach(t),uRo=i(K),Bb=n(K,"LI",{});var ZLe=s(Bb);lme=n(ZLe,"STRONG",{});var bit=s(lme);_Ro=r(bit,"data2vec-text"),bit.forEach(t),bRo=r(ZLe," \u2014 "),GG=n(ZLe,"A",{href:!0});var vit=s(GG);vRo=r(vit,"Data2VecTextForMultipleChoice"),vit.forEach(t),FRo=r(ZLe," (Data2VecText model)"),ZLe.forEach(t),TRo=i(K),Ib=n(K,"LI",{});var exe=s(Ib);ime=n(exe,"STRONG",{});var Fit=s(ime);MRo=r(Fit,"deberta-v2"),Fit.forEach(t),ERo=r(exe," \u2014 "),OG=n(exe,"A",{href:!0});var Tit=s(OG);CRo=r(Tit,"DebertaV2ForMultipleChoice"),Tit.forEach(t),wRo=r(exe," (DeBERTa-v2 model)"),exe.forEach(t),ARo=i(K),qb=n(K,"LI",{});var oxe=s(qb);dme=n(oxe,"STRONG",{});var Mit=s(dme);yRo=r(Mit,"distilbert"),Mit.forEach(t),LRo=r(oxe," \u2014 "),VG=n(oxe,"A",{href:!0});var Eit=s(VG);xRo=r(Eit,"DistilBertForMultipleChoice"),Eit.forEach(t),$Ro=r(oxe," (DistilBERT model)"),oxe.forEach(t),kRo=i(K),Nb=n(K,"LI",{});var rxe=s(Nb);cme=n(rxe,"STRONG",{});var Cit=s(cme);SRo=r(Cit,"electra"),Cit.forEach(t),RRo=r(rxe," \u2014 "),XG=n(rxe,"A",{href:!0});var wit=s(XG);PRo=r(wit,"ElectraForMultipleChoice"),wit.forEach(t),BRo=r(rxe," (ELECTRA model)"),rxe.forEach(t),IRo=i(K),jb=n(K,"LI",{});var txe=s(jb);fme=n(txe,"STRONG",{});var Ait=s(fme);qRo=r(Ait,"flaubert"),Ait.forEach(t),NRo=r(txe," \u2014 "),zG=n(txe,"A",{href:!0});var yit=s(zG);jRo=r(yit,"FlaubertForMultipleChoice"),yit.forEach(t),DRo=r(txe," (FlauBERT model)"),txe.forEach(t),GRo=i(K),Db=n(K,"LI",{});var axe=s(Db);mme=n(axe,"STRONG",{});var Lit=s(mme);ORo=r(Lit,"fnet"),Lit.forEach(t),VRo=r(axe," \u2014 "),QG=n(axe,"A",{href:!0});var xit=s(QG);XRo=r(xit,"FNetForMultipleChoice"),xit.forEach(t),zRo=r(axe," (FNet model)"),axe.forEach(t),QRo=i(K),Gb=n(K,"LI",{});var nxe=s(Gb);gme=n(nxe,"STRONG",{});var $it=s(gme);WRo=r($it,"funnel"),$it.forEach(t),HRo=r(nxe," \u2014 "),WG=n(nxe,"A",{href:!0});var kit=s(WG);URo=r(kit,"FunnelForMultipleChoice"),kit.forEach(t),JRo=r(nxe," (Funnel Transformer model)"),nxe.forEach(t),YRo=i(K),Ob=n(K,"LI",{});var sxe=s(Ob);hme=n(sxe,"STRONG",{});var Sit=s(hme);KRo=r(Sit,"ibert"),Sit.forEach(t),ZRo=r(sxe," \u2014 "),HG=n(sxe,"A",{href:!0});var Rit=s(HG);ePo=r(Rit,"IBertForMultipleChoice"),Rit.forEach(t),oPo=r(sxe," (I-BERT model)"),sxe.forEach(t),rPo=i(K),Vb=n(K,"LI",{});var lxe=s(Vb);pme=n(lxe,"STRONG",{});var Pit=s(pme);tPo=r(Pit,"longformer"),Pit.forEach(t),aPo=r(lxe," \u2014 "),UG=n(lxe,"A",{href:!0});var Bit=s(UG);nPo=r(Bit,"LongformerForMultipleChoice"),Bit.forEach(t),sPo=r(lxe," (Longformer model)"),lxe.forEach(t),lPo=i(K),Xb=n(K,"LI",{});var ixe=s(Xb);ume=n(ixe,"STRONG",{});var Iit=s(ume);iPo=r(Iit,"megatron-bert"),Iit.forEach(t),dPo=r(ixe," \u2014 "),JG=n(ixe,"A",{href:!0});var qit=s(JG);cPo=r(qit,"MegatronBertForMultipleChoice"),qit.forEach(t),fPo=r(ixe," (MegatronBert model)"),ixe.forEach(t),mPo=i(K),zb=n(K,"LI",{});var dxe=s(zb);_me=n(dxe,"STRONG",{});var Nit=s(_me);gPo=r(Nit,"mobilebert"),Nit.forEach(t),hPo=r(dxe," \u2014 "),YG=n(dxe,"A",{href:!0});var jit=s(YG);pPo=r(jit,"MobileBertForMultipleChoice"),jit.forEach(t),uPo=r(dxe," (MobileBERT model)"),dxe.forEach(t),_Po=i(K),Qb=n(K,"LI",{});var cxe=s(Qb);bme=n(cxe,"STRONG",{});var Dit=s(bme);bPo=r(Dit,"mpnet"),Dit.forEach(t),vPo=r(cxe," \u2014 "),KG=n(cxe,"A",{href:!0});var Git=s(KG);FPo=r(Git,"MPNetForMultipleChoice"),Git.forEach(t),TPo=r(cxe," (MPNet model)"),cxe.forEach(t),MPo=i(K),Wb=n(K,"LI",{});var fxe=s(Wb);vme=n(fxe,"STRONG",{});var Oit=s(vme);EPo=r(Oit,"nystromformer"),Oit.forEach(t),CPo=r(fxe," \u2014 "),ZG=n(fxe,"A",{href:!0});var Vit=s(ZG);wPo=r(Vit,"NystromformerForMultipleChoice"),Vit.forEach(t),APo=r(fxe," (Nystromformer model)"),fxe.forEach(t),yPo=i(K),Hb=n(K,"LI",{});var mxe=s(Hb);Fme=n(mxe,"STRONG",{});var Xit=s(Fme);LPo=r(Xit,"qdqbert"),Xit.forEach(t),xPo=r(mxe," \u2014 "),eO=n(mxe,"A",{href:!0});var zit=s(eO);$Po=r(zit,"QDQBertForMultipleChoice"),zit.forEach(t),kPo=r(mxe," (QDQBert model)"),mxe.forEach(t),SPo=i(K),Ub=n(K,"LI",{});var gxe=s(Ub);Tme=n(gxe,"STRONG",{});var Qit=s(Tme);RPo=r(Qit,"rembert"),Qit.forEach(t),PPo=r(gxe," \u2014 "),oO=n(gxe,"A",{href:!0});var Wit=s(oO);BPo=r(Wit,"RemBertForMultipleChoice"),Wit.forEach(t),IPo=r(gxe," (RemBERT model)"),gxe.forEach(t),qPo=i(K),Jb=n(K,"LI",{});var hxe=s(Jb);Mme=n(hxe,"STRONG",{});var Hit=s(Mme);NPo=r(Hit,"roberta"),Hit.forEach(t),jPo=r(hxe," \u2014 "),rO=n(hxe,"A",{href:!0});var Uit=s(rO);DPo=r(Uit,"RobertaForMultipleChoice"),Uit.forEach(t),GPo=r(hxe," (RoBERTa model)"),hxe.forEach(t),OPo=i(K),Yb=n(K,"LI",{});var pxe=s(Yb);Eme=n(pxe,"STRONG",{});var Jit=s(Eme);VPo=r(Jit,"roformer"),Jit.forEach(t),XPo=r(pxe," \u2014 "),tO=n(pxe,"A",{href:!0});var Yit=s(tO);zPo=r(Yit,"RoFormerForMultipleChoice"),Yit.forEach(t),QPo=r(pxe," (RoFormer model)"),pxe.forEach(t),WPo=i(K),Kb=n(K,"LI",{});var uxe=s(Kb);Cme=n(uxe,"STRONG",{});var Kit=s(Cme);HPo=r(Kit,"squeezebert"),Kit.forEach(t),UPo=r(uxe," \u2014 "),aO=n(uxe,"A",{href:!0});var Zit=s(aO);JPo=r(Zit,"SqueezeBertForMultipleChoice"),Zit.forEach(t),YPo=r(uxe," (SqueezeBERT model)"),uxe.forEach(t),KPo=i(K),Zb=n(K,"LI",{});var _xe=s(Zb);wme=n(_xe,"STRONG",{});var edt=s(wme);ZPo=r(edt,"xlm"),edt.forEach(t),eBo=r(_xe," \u2014 "),nO=n(_xe,"A",{href:!0});var odt=s(nO);oBo=r(odt,"XLMForMultipleChoice"),odt.forEach(t),rBo=r(_xe," (XLM model)"),_xe.forEach(t),tBo=i(K),ev=n(K,"LI",{});var bxe=s(ev);Ame=n(bxe,"STRONG",{});var rdt=s(Ame);aBo=r(rdt,"xlm-roberta"),rdt.forEach(t),nBo=r(bxe," \u2014 "),sO=n(bxe,"A",{href:!0});var tdt=s(sO);sBo=r(tdt,"XLMRobertaForMultipleChoice"),tdt.forEach(t),lBo=r(bxe," (XLM-RoBERTa model)"),bxe.forEach(t),iBo=i(K),ov=n(K,"LI",{});var vxe=s(ov);yme=n(vxe,"STRONG",{});var adt=s(yme);dBo=r(adt,"xlm-roberta-xl"),adt.forEach(t),cBo=r(vxe," \u2014 "),lO=n(vxe,"A",{href:!0});var ndt=s(lO);fBo=r(ndt,"XLMRobertaXLForMultipleChoice"),ndt.forEach(t),mBo=r(vxe," (XLM-RoBERTa-XL model)"),vxe.forEach(t),gBo=i(K),rv=n(K,"LI",{});var Fxe=s(rv);Lme=n(Fxe,"STRONG",{});var sdt=s(Lme);hBo=r(sdt,"xlnet"),sdt.forEach(t),pBo=r(Fxe," \u2014 "),iO=n(Fxe,"A",{href:!0});var ldt=s(iO);uBo=r(ldt,"XLNetForMultipleChoice"),ldt.forEach(t),_Bo=r(Fxe," (XLNet model)"),Fxe.forEach(t),bBo=i(K),tv=n(K,"LI",{});var Txe=s(tv);xme=n(Txe,"STRONG",{});var idt=s(xme);vBo=r(idt,"yoso"),idt.forEach(t),FBo=r(Txe," \u2014 "),dO=n(Txe,"A",{href:!0});var ddt=s(dO);TBo=r(ddt,"YosoForMultipleChoice"),ddt.forEach(t),MBo=r(Txe," (YOSO model)"),Txe.forEach(t),K.forEach(t),EBo=i(ia),av=n(ia,"P",{});var Mxe=s(av);CBo=r(Mxe,"The model is set in evaluation mode by default using "),$me=n(Mxe,"CODE",{});var cdt=s($me);wBo=r(cdt,"model.eval()"),cdt.forEach(t),ABo=r(Mxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kme=n(Mxe,"CODE",{});var fdt=s(kme);yBo=r(fdt,"model.train()"),fdt.forEach(t),Mxe.forEach(t),LBo=i(ia),T(nv.$$.fragment,ia),ia.forEach(t),Ys.forEach(t),hqe=i(f),Ui=n(f,"H2",{class:!0});var Fje=s(Ui);sv=n(Fje,"A",{id:!0,class:!0,href:!0});var mdt=s(sv);Sme=n(mdt,"SPAN",{});var gdt=s(Sme);T(E0.$$.fragment,gdt),gdt.forEach(t),mdt.forEach(t),xBo=i(Fje),Rme=n(Fje,"SPAN",{});var hdt=s(Rme);$Bo=r(hdt,"AutoModelForNextSentencePrediction"),hdt.forEach(t),Fje.forEach(t),pqe=i(f),Io=n(f,"DIV",{class:!0});var Ks=s(Io);T(C0.$$.fragment,Ks),kBo=i(Ks),Ji=n(Ks,"P",{});var eZ=s(Ji);SBo=r(eZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),cO=n(eZ,"A",{href:!0});var pdt=s(cO);RBo=r(pdt,"from_pretrained()"),pdt.forEach(t),PBo=r(eZ," class method or the "),fO=n(eZ,"A",{href:!0});var udt=s(fO);BBo=r(udt,"from_config()"),udt.forEach(t),IBo=r(eZ,` class
method.`),eZ.forEach(t),qBo=i(Ks),w0=n(Ks,"P",{});var Tje=s(w0);NBo=r(Tje,"This class cannot be instantiated directly using "),Pme=n(Tje,"CODE",{});var _dt=s(Pme);jBo=r(_dt,"__init__()"),_dt.forEach(t),DBo=r(Tje," (throws an error)."),Tje.forEach(t),GBo=i(Ks),ct=n(Ks,"DIV",{class:!0});var k3=s(ct);T(A0.$$.fragment,k3),OBo=i(k3),Bme=n(k3,"P",{});var bdt=s(Bme);VBo=r(bdt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),bdt.forEach(t),XBo=i(k3),Yi=n(k3,"P",{});var oZ=s(Yi);zBo=r(oZ,`Note:
Loading a model from its configuration file does `),Ime=n(oZ,"STRONG",{});var vdt=s(Ime);QBo=r(vdt,"not"),vdt.forEach(t),WBo=r(oZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),mO=n(oZ,"A",{href:!0});var Fdt=s(mO);HBo=r(Fdt,"from_pretrained()"),Fdt.forEach(t),UBo=r(oZ," to load the model weights."),oZ.forEach(t),JBo=i(k3),T(lv.$$.fragment,k3),k3.forEach(t),YBo=i(Ks),oo=n(Ks,"DIV",{class:!0});var da=s(oo);T(y0.$$.fragment,da),KBo=i(da),qme=n(da,"P",{});var Tdt=s(qme);ZBo=r(Tdt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Tdt.forEach(t),eIo=i(da),qa=n(da,"P",{});var S3=s(qa);oIo=r(S3,"The model class to instantiate is selected based on the "),Nme=n(S3,"CODE",{});var Mdt=s(Nme);rIo=r(Mdt,"model_type"),Mdt.forEach(t),tIo=r(S3,` property of the config object (either
passed as an argument or loaded from `),jme=n(S3,"CODE",{});var Edt=s(jme);aIo=r(Edt,"pretrained_model_name_or_path"),Edt.forEach(t),nIo=r(S3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Dme=n(S3,"CODE",{});var Cdt=s(Dme);sIo=r(Cdt,"pretrained_model_name_or_path"),Cdt.forEach(t),lIo=r(S3,":"),S3.forEach(t),iIo=i(da),Zr=n(da,"UL",{});var Zs=s(Zr);iv=n(Zs,"LI",{});var Exe=s(iv);Gme=n(Exe,"STRONG",{});var wdt=s(Gme);dIo=r(wdt,"bert"),wdt.forEach(t),cIo=r(Exe," \u2014 "),gO=n(Exe,"A",{href:!0});var Adt=s(gO);fIo=r(Adt,"BertForNextSentencePrediction"),Adt.forEach(t),mIo=r(Exe," (BERT model)"),Exe.forEach(t),gIo=i(Zs),dv=n(Zs,"LI",{});var Cxe=s(dv);Ome=n(Cxe,"STRONG",{});var ydt=s(Ome);hIo=r(ydt,"fnet"),ydt.forEach(t),pIo=r(Cxe," \u2014 "),hO=n(Cxe,"A",{href:!0});var Ldt=s(hO);uIo=r(Ldt,"FNetForNextSentencePrediction"),Ldt.forEach(t),_Io=r(Cxe," (FNet model)"),Cxe.forEach(t),bIo=i(Zs),cv=n(Zs,"LI",{});var wxe=s(cv);Vme=n(wxe,"STRONG",{});var xdt=s(Vme);vIo=r(xdt,"megatron-bert"),xdt.forEach(t),FIo=r(wxe," \u2014 "),pO=n(wxe,"A",{href:!0});var $dt=s(pO);TIo=r($dt,"MegatronBertForNextSentencePrediction"),$dt.forEach(t),MIo=r(wxe," (MegatronBert model)"),wxe.forEach(t),EIo=i(Zs),fv=n(Zs,"LI",{});var Axe=s(fv);Xme=n(Axe,"STRONG",{});var kdt=s(Xme);CIo=r(kdt,"mobilebert"),kdt.forEach(t),wIo=r(Axe," \u2014 "),uO=n(Axe,"A",{href:!0});var Sdt=s(uO);AIo=r(Sdt,"MobileBertForNextSentencePrediction"),Sdt.forEach(t),yIo=r(Axe," (MobileBERT model)"),Axe.forEach(t),LIo=i(Zs),mv=n(Zs,"LI",{});var yxe=s(mv);zme=n(yxe,"STRONG",{});var Rdt=s(zme);xIo=r(Rdt,"qdqbert"),Rdt.forEach(t),$Io=r(yxe," \u2014 "),_O=n(yxe,"A",{href:!0});var Pdt=s(_O);kIo=r(Pdt,"QDQBertForNextSentencePrediction"),Pdt.forEach(t),SIo=r(yxe," (QDQBert model)"),yxe.forEach(t),Zs.forEach(t),RIo=i(da),gv=n(da,"P",{});var Lxe=s(gv);PIo=r(Lxe,"The model is set in evaluation mode by default using "),Qme=n(Lxe,"CODE",{});var Bdt=s(Qme);BIo=r(Bdt,"model.eval()"),Bdt.forEach(t),IIo=r(Lxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Wme=n(Lxe,"CODE",{});var Idt=s(Wme);qIo=r(Idt,"model.train()"),Idt.forEach(t),Lxe.forEach(t),NIo=i(da),T(hv.$$.fragment,da),da.forEach(t),Ks.forEach(t),uqe=i(f),Ki=n(f,"H2",{class:!0});var Mje=s(Ki);pv=n(Mje,"A",{id:!0,class:!0,href:!0});var qdt=s(pv);Hme=n(qdt,"SPAN",{});var Ndt=s(Hme);T(L0.$$.fragment,Ndt),Ndt.forEach(t),qdt.forEach(t),jIo=i(Mje),Ume=n(Mje,"SPAN",{});var jdt=s(Ume);DIo=r(jdt,"AutoModelForTokenClassification"),jdt.forEach(t),Mje.forEach(t),_qe=i(f),qo=n(f,"DIV",{class:!0});var el=s(qo);T(x0.$$.fragment,el),GIo=i(el),Zi=n(el,"P",{});var rZ=s(Zi);OIo=r(rZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),bO=n(rZ,"A",{href:!0});var Ddt=s(bO);VIo=r(Ddt,"from_pretrained()"),Ddt.forEach(t),XIo=r(rZ," class method or the "),vO=n(rZ,"A",{href:!0});var Gdt=s(vO);zIo=r(Gdt,"from_config()"),Gdt.forEach(t),QIo=r(rZ,` class
method.`),rZ.forEach(t),WIo=i(el),$0=n(el,"P",{});var Eje=s($0);HIo=r(Eje,"This class cannot be instantiated directly using "),Jme=n(Eje,"CODE",{});var Odt=s(Jme);UIo=r(Odt,"__init__()"),Odt.forEach(t),JIo=r(Eje," (throws an error)."),Eje.forEach(t),YIo=i(el),ft=n(el,"DIV",{class:!0});var R3=s(ft);T(k0.$$.fragment,R3),KIo=i(R3),Yme=n(R3,"P",{});var Vdt=s(Yme);ZIo=r(Vdt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Vdt.forEach(t),eqo=i(R3),ed=n(R3,"P",{});var tZ=s(ed);oqo=r(tZ,`Note:
Loading a model from its configuration file does `),Kme=n(tZ,"STRONG",{});var Xdt=s(Kme);rqo=r(Xdt,"not"),Xdt.forEach(t),tqo=r(tZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),FO=n(tZ,"A",{href:!0});var zdt=s(FO);aqo=r(zdt,"from_pretrained()"),zdt.forEach(t),nqo=r(tZ," to load the model weights."),tZ.forEach(t),sqo=i(R3),T(uv.$$.fragment,R3),R3.forEach(t),lqo=i(el),ro=n(el,"DIV",{class:!0});var ca=s(ro);T(S0.$$.fragment,ca),iqo=i(ca),Zme=n(ca,"P",{});var Qdt=s(Zme);dqo=r(Qdt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Qdt.forEach(t),cqo=i(ca),Na=n(ca,"P",{});var P3=s(Na);fqo=r(P3,"The model class to instantiate is selected based on the "),ege=n(P3,"CODE",{});var Wdt=s(ege);mqo=r(Wdt,"model_type"),Wdt.forEach(t),gqo=r(P3,` property of the config object (either
passed as an argument or loaded from `),oge=n(P3,"CODE",{});var Hdt=s(oge);hqo=r(Hdt,"pretrained_model_name_or_path"),Hdt.forEach(t),pqo=r(P3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rge=n(P3,"CODE",{});var Udt=s(rge);uqo=r(Udt,"pretrained_model_name_or_path"),Udt.forEach(t),_qo=r(P3,":"),P3.forEach(t),bqo=i(ca),U=n(ca,"UL",{});var J=s(U);_v=n(J,"LI",{});var xxe=s(_v);tge=n(xxe,"STRONG",{});var Jdt=s(tge);vqo=r(Jdt,"albert"),Jdt.forEach(t),Fqo=r(xxe," \u2014 "),TO=n(xxe,"A",{href:!0});var Ydt=s(TO);Tqo=r(Ydt,"AlbertForTokenClassification"),Ydt.forEach(t),Mqo=r(xxe," (ALBERT model)"),xxe.forEach(t),Eqo=i(J),bv=n(J,"LI",{});var $xe=s(bv);age=n($xe,"STRONG",{});var Kdt=s(age);Cqo=r(Kdt,"bert"),Kdt.forEach(t),wqo=r($xe," \u2014 "),MO=n($xe,"A",{href:!0});var Zdt=s(MO);Aqo=r(Zdt,"BertForTokenClassification"),Zdt.forEach(t),yqo=r($xe," (BERT model)"),$xe.forEach(t),Lqo=i(J),vv=n(J,"LI",{});var kxe=s(vv);nge=n(kxe,"STRONG",{});var ect=s(nge);xqo=r(ect,"big_bird"),ect.forEach(t),$qo=r(kxe," \u2014 "),EO=n(kxe,"A",{href:!0});var oct=s(EO);kqo=r(oct,"BigBirdForTokenClassification"),oct.forEach(t),Sqo=r(kxe," (BigBird model)"),kxe.forEach(t),Rqo=i(J),Fv=n(J,"LI",{});var Sxe=s(Fv);sge=n(Sxe,"STRONG",{});var rct=s(sge);Pqo=r(rct,"camembert"),rct.forEach(t),Bqo=r(Sxe," \u2014 "),CO=n(Sxe,"A",{href:!0});var tct=s(CO);Iqo=r(tct,"CamembertForTokenClassification"),tct.forEach(t),qqo=r(Sxe," (CamemBERT model)"),Sxe.forEach(t),Nqo=i(J),Tv=n(J,"LI",{});var Rxe=s(Tv);lge=n(Rxe,"STRONG",{});var act=s(lge);jqo=r(act,"canine"),act.forEach(t),Dqo=r(Rxe," \u2014 "),wO=n(Rxe,"A",{href:!0});var nct=s(wO);Gqo=r(nct,"CanineForTokenClassification"),nct.forEach(t),Oqo=r(Rxe," (Canine model)"),Rxe.forEach(t),Vqo=i(J),Mv=n(J,"LI",{});var Pxe=s(Mv);ige=n(Pxe,"STRONG",{});var sct=s(ige);Xqo=r(sct,"convbert"),sct.forEach(t),zqo=r(Pxe," \u2014 "),AO=n(Pxe,"A",{href:!0});var lct=s(AO);Qqo=r(lct,"ConvBertForTokenClassification"),lct.forEach(t),Wqo=r(Pxe," (ConvBERT model)"),Pxe.forEach(t),Hqo=i(J),Ev=n(J,"LI",{});var Bxe=s(Ev);dge=n(Bxe,"STRONG",{});var ict=s(dge);Uqo=r(ict,"data2vec-text"),ict.forEach(t),Jqo=r(Bxe," \u2014 "),yO=n(Bxe,"A",{href:!0});var dct=s(yO);Yqo=r(dct,"Data2VecTextForTokenClassification"),dct.forEach(t),Kqo=r(Bxe," (Data2VecText model)"),Bxe.forEach(t),Zqo=i(J),Cv=n(J,"LI",{});var Ixe=s(Cv);cge=n(Ixe,"STRONG",{});var cct=s(cge);eNo=r(cct,"deberta"),cct.forEach(t),oNo=r(Ixe," \u2014 "),LO=n(Ixe,"A",{href:!0});var fct=s(LO);rNo=r(fct,"DebertaForTokenClassification"),fct.forEach(t),tNo=r(Ixe," (DeBERTa model)"),Ixe.forEach(t),aNo=i(J),wv=n(J,"LI",{});var qxe=s(wv);fge=n(qxe,"STRONG",{});var mct=s(fge);nNo=r(mct,"deberta-v2"),mct.forEach(t),sNo=r(qxe," \u2014 "),xO=n(qxe,"A",{href:!0});var gct=s(xO);lNo=r(gct,"DebertaV2ForTokenClassification"),gct.forEach(t),iNo=r(qxe," (DeBERTa-v2 model)"),qxe.forEach(t),dNo=i(J),Av=n(J,"LI",{});var Nxe=s(Av);mge=n(Nxe,"STRONG",{});var hct=s(mge);cNo=r(hct,"distilbert"),hct.forEach(t),fNo=r(Nxe," \u2014 "),$O=n(Nxe,"A",{href:!0});var pct=s($O);mNo=r(pct,"DistilBertForTokenClassification"),pct.forEach(t),gNo=r(Nxe," (DistilBERT model)"),Nxe.forEach(t),hNo=i(J),yv=n(J,"LI",{});var jxe=s(yv);gge=n(jxe,"STRONG",{});var uct=s(gge);pNo=r(uct,"electra"),uct.forEach(t),uNo=r(jxe," \u2014 "),kO=n(jxe,"A",{href:!0});var _ct=s(kO);_No=r(_ct,"ElectraForTokenClassification"),_ct.forEach(t),bNo=r(jxe," (ELECTRA model)"),jxe.forEach(t),vNo=i(J),Lv=n(J,"LI",{});var Dxe=s(Lv);hge=n(Dxe,"STRONG",{});var bct=s(hge);FNo=r(bct,"flaubert"),bct.forEach(t),TNo=r(Dxe," \u2014 "),SO=n(Dxe,"A",{href:!0});var vct=s(SO);MNo=r(vct,"FlaubertForTokenClassification"),vct.forEach(t),ENo=r(Dxe," (FlauBERT model)"),Dxe.forEach(t),CNo=i(J),xv=n(J,"LI",{});var Gxe=s(xv);pge=n(Gxe,"STRONG",{});var Fct=s(pge);wNo=r(Fct,"fnet"),Fct.forEach(t),ANo=r(Gxe," \u2014 "),RO=n(Gxe,"A",{href:!0});var Tct=s(RO);yNo=r(Tct,"FNetForTokenClassification"),Tct.forEach(t),LNo=r(Gxe," (FNet model)"),Gxe.forEach(t),xNo=i(J),$v=n(J,"LI",{});var Oxe=s($v);uge=n(Oxe,"STRONG",{});var Mct=s(uge);$No=r(Mct,"funnel"),Mct.forEach(t),kNo=r(Oxe," \u2014 "),PO=n(Oxe,"A",{href:!0});var Ect=s(PO);SNo=r(Ect,"FunnelForTokenClassification"),Ect.forEach(t),RNo=r(Oxe," (Funnel Transformer model)"),Oxe.forEach(t),PNo=i(J),kv=n(J,"LI",{});var Vxe=s(kv);_ge=n(Vxe,"STRONG",{});var Cct=s(_ge);BNo=r(Cct,"gpt2"),Cct.forEach(t),INo=r(Vxe," \u2014 "),BO=n(Vxe,"A",{href:!0});var wct=s(BO);qNo=r(wct,"GPT2ForTokenClassification"),wct.forEach(t),NNo=r(Vxe," (OpenAI GPT-2 model)"),Vxe.forEach(t),jNo=i(J),Sv=n(J,"LI",{});var Xxe=s(Sv);bge=n(Xxe,"STRONG",{});var Act=s(bge);DNo=r(Act,"ibert"),Act.forEach(t),GNo=r(Xxe," \u2014 "),IO=n(Xxe,"A",{href:!0});var yct=s(IO);ONo=r(yct,"IBertForTokenClassification"),yct.forEach(t),VNo=r(Xxe," (I-BERT model)"),Xxe.forEach(t),XNo=i(J),Rv=n(J,"LI",{});var zxe=s(Rv);vge=n(zxe,"STRONG",{});var Lct=s(vge);zNo=r(Lct,"layoutlm"),Lct.forEach(t),QNo=r(zxe," \u2014 "),qO=n(zxe,"A",{href:!0});var xct=s(qO);WNo=r(xct,"LayoutLMForTokenClassification"),xct.forEach(t),HNo=r(zxe," (LayoutLM model)"),zxe.forEach(t),UNo=i(J),Pv=n(J,"LI",{});var Qxe=s(Pv);Fge=n(Qxe,"STRONG",{});var $ct=s(Fge);JNo=r($ct,"layoutlmv2"),$ct.forEach(t),YNo=r(Qxe," \u2014 "),NO=n(Qxe,"A",{href:!0});var kct=s(NO);KNo=r(kct,"LayoutLMv2ForTokenClassification"),kct.forEach(t),ZNo=r(Qxe," (LayoutLMv2 model)"),Qxe.forEach(t),ejo=i(J),Bv=n(J,"LI",{});var Wxe=s(Bv);Tge=n(Wxe,"STRONG",{});var Sct=s(Tge);ojo=r(Sct,"longformer"),Sct.forEach(t),rjo=r(Wxe," \u2014 "),jO=n(Wxe,"A",{href:!0});var Rct=s(jO);tjo=r(Rct,"LongformerForTokenClassification"),Rct.forEach(t),ajo=r(Wxe," (Longformer model)"),Wxe.forEach(t),njo=i(J),Iv=n(J,"LI",{});var Hxe=s(Iv);Mge=n(Hxe,"STRONG",{});var Pct=s(Mge);sjo=r(Pct,"megatron-bert"),Pct.forEach(t),ljo=r(Hxe," \u2014 "),DO=n(Hxe,"A",{href:!0});var Bct=s(DO);ijo=r(Bct,"MegatronBertForTokenClassification"),Bct.forEach(t),djo=r(Hxe," (MegatronBert model)"),Hxe.forEach(t),cjo=i(J),qv=n(J,"LI",{});var Uxe=s(qv);Ege=n(Uxe,"STRONG",{});var Ict=s(Ege);fjo=r(Ict,"mobilebert"),Ict.forEach(t),mjo=r(Uxe," \u2014 "),GO=n(Uxe,"A",{href:!0});var qct=s(GO);gjo=r(qct,"MobileBertForTokenClassification"),qct.forEach(t),hjo=r(Uxe," (MobileBERT model)"),Uxe.forEach(t),pjo=i(J),Nv=n(J,"LI",{});var Jxe=s(Nv);Cge=n(Jxe,"STRONG",{});var Nct=s(Cge);ujo=r(Nct,"mpnet"),Nct.forEach(t),_jo=r(Jxe," \u2014 "),OO=n(Jxe,"A",{href:!0});var jct=s(OO);bjo=r(jct,"MPNetForTokenClassification"),jct.forEach(t),vjo=r(Jxe," (MPNet model)"),Jxe.forEach(t),Fjo=i(J),jv=n(J,"LI",{});var Yxe=s(jv);wge=n(Yxe,"STRONG",{});var Dct=s(wge);Tjo=r(Dct,"nystromformer"),Dct.forEach(t),Mjo=r(Yxe," \u2014 "),VO=n(Yxe,"A",{href:!0});var Gct=s(VO);Ejo=r(Gct,"NystromformerForTokenClassification"),Gct.forEach(t),Cjo=r(Yxe," (Nystromformer model)"),Yxe.forEach(t),wjo=i(J),Dv=n(J,"LI",{});var Kxe=s(Dv);Age=n(Kxe,"STRONG",{});var Oct=s(Age);Ajo=r(Oct,"qdqbert"),Oct.forEach(t),yjo=r(Kxe," \u2014 "),XO=n(Kxe,"A",{href:!0});var Vct=s(XO);Ljo=r(Vct,"QDQBertForTokenClassification"),Vct.forEach(t),xjo=r(Kxe," (QDQBert model)"),Kxe.forEach(t),$jo=i(J),Gv=n(J,"LI",{});var Zxe=s(Gv);yge=n(Zxe,"STRONG",{});var Xct=s(yge);kjo=r(Xct,"rembert"),Xct.forEach(t),Sjo=r(Zxe," \u2014 "),zO=n(Zxe,"A",{href:!0});var zct=s(zO);Rjo=r(zct,"RemBertForTokenClassification"),zct.forEach(t),Pjo=r(Zxe," (RemBERT model)"),Zxe.forEach(t),Bjo=i(J),Ov=n(J,"LI",{});var e9e=s(Ov);Lge=n(e9e,"STRONG",{});var Qct=s(Lge);Ijo=r(Qct,"roberta"),Qct.forEach(t),qjo=r(e9e," \u2014 "),QO=n(e9e,"A",{href:!0});var Wct=s(QO);Njo=r(Wct,"RobertaForTokenClassification"),Wct.forEach(t),jjo=r(e9e," (RoBERTa model)"),e9e.forEach(t),Djo=i(J),Vv=n(J,"LI",{});var o9e=s(Vv);xge=n(o9e,"STRONG",{});var Hct=s(xge);Gjo=r(Hct,"roformer"),Hct.forEach(t),Ojo=r(o9e," \u2014 "),WO=n(o9e,"A",{href:!0});var Uct=s(WO);Vjo=r(Uct,"RoFormerForTokenClassification"),Uct.forEach(t),Xjo=r(o9e," (RoFormer model)"),o9e.forEach(t),zjo=i(J),Xv=n(J,"LI",{});var r9e=s(Xv);$ge=n(r9e,"STRONG",{});var Jct=s($ge);Qjo=r(Jct,"squeezebert"),Jct.forEach(t),Wjo=r(r9e," \u2014 "),HO=n(r9e,"A",{href:!0});var Yct=s(HO);Hjo=r(Yct,"SqueezeBertForTokenClassification"),Yct.forEach(t),Ujo=r(r9e," (SqueezeBERT model)"),r9e.forEach(t),Jjo=i(J),zv=n(J,"LI",{});var t9e=s(zv);kge=n(t9e,"STRONG",{});var Kct=s(kge);Yjo=r(Kct,"xlm"),Kct.forEach(t),Kjo=r(t9e," \u2014 "),UO=n(t9e,"A",{href:!0});var Zct=s(UO);Zjo=r(Zct,"XLMForTokenClassification"),Zct.forEach(t),eDo=r(t9e," (XLM model)"),t9e.forEach(t),oDo=i(J),Qv=n(J,"LI",{});var a9e=s(Qv);Sge=n(a9e,"STRONG",{});var eft=s(Sge);rDo=r(eft,"xlm-roberta"),eft.forEach(t),tDo=r(a9e," \u2014 "),JO=n(a9e,"A",{href:!0});var oft=s(JO);aDo=r(oft,"XLMRobertaForTokenClassification"),oft.forEach(t),nDo=r(a9e," (XLM-RoBERTa model)"),a9e.forEach(t),sDo=i(J),Wv=n(J,"LI",{});var n9e=s(Wv);Rge=n(n9e,"STRONG",{});var rft=s(Rge);lDo=r(rft,"xlm-roberta-xl"),rft.forEach(t),iDo=r(n9e," \u2014 "),YO=n(n9e,"A",{href:!0});var tft=s(YO);dDo=r(tft,"XLMRobertaXLForTokenClassification"),tft.forEach(t),cDo=r(n9e," (XLM-RoBERTa-XL model)"),n9e.forEach(t),fDo=i(J),Hv=n(J,"LI",{});var s9e=s(Hv);Pge=n(s9e,"STRONG",{});var aft=s(Pge);mDo=r(aft,"xlnet"),aft.forEach(t),gDo=r(s9e," \u2014 "),KO=n(s9e,"A",{href:!0});var nft=s(KO);hDo=r(nft,"XLNetForTokenClassification"),nft.forEach(t),pDo=r(s9e," (XLNet model)"),s9e.forEach(t),uDo=i(J),Uv=n(J,"LI",{});var l9e=s(Uv);Bge=n(l9e,"STRONG",{});var sft=s(Bge);_Do=r(sft,"yoso"),sft.forEach(t),bDo=r(l9e," \u2014 "),ZO=n(l9e,"A",{href:!0});var lft=s(ZO);vDo=r(lft,"YosoForTokenClassification"),lft.forEach(t),FDo=r(l9e," (YOSO model)"),l9e.forEach(t),J.forEach(t),TDo=i(ca),Jv=n(ca,"P",{});var i9e=s(Jv);MDo=r(i9e,"The model is set in evaluation mode by default using "),Ige=n(i9e,"CODE",{});var ift=s(Ige);EDo=r(ift,"model.eval()"),ift.forEach(t),CDo=r(i9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qge=n(i9e,"CODE",{});var dft=s(qge);wDo=r(dft,"model.train()"),dft.forEach(t),i9e.forEach(t),ADo=i(ca),T(Yv.$$.fragment,ca),ca.forEach(t),el.forEach(t),bqe=i(f),od=n(f,"H2",{class:!0});var Cje=s(od);Kv=n(Cje,"A",{id:!0,class:!0,href:!0});var cft=s(Kv);Nge=n(cft,"SPAN",{});var fft=s(Nge);T(R0.$$.fragment,fft),fft.forEach(t),cft.forEach(t),yDo=i(Cje),jge=n(Cje,"SPAN",{});var mft=s(jge);LDo=r(mft,"AutoModelForQuestionAnswering"),mft.forEach(t),Cje.forEach(t),vqe=i(f),No=n(f,"DIV",{class:!0});var ol=s(No);T(P0.$$.fragment,ol),xDo=i(ol),rd=n(ol,"P",{});var aZ=s(rd);$Do=r(aZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),eV=n(aZ,"A",{href:!0});var gft=s(eV);kDo=r(gft,"from_pretrained()"),gft.forEach(t),SDo=r(aZ," class method or the "),oV=n(aZ,"A",{href:!0});var hft=s(oV);RDo=r(hft,"from_config()"),hft.forEach(t),PDo=r(aZ,` class
method.`),aZ.forEach(t),BDo=i(ol),B0=n(ol,"P",{});var wje=s(B0);IDo=r(wje,"This class cannot be instantiated directly using "),Dge=n(wje,"CODE",{});var pft=s(Dge);qDo=r(pft,"__init__()"),pft.forEach(t),NDo=r(wje," (throws an error)."),wje.forEach(t),jDo=i(ol),mt=n(ol,"DIV",{class:!0});var B3=s(mt);T(I0.$$.fragment,B3),DDo=i(B3),Gge=n(B3,"P",{});var uft=s(Gge);GDo=r(uft,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),uft.forEach(t),ODo=i(B3),td=n(B3,"P",{});var nZ=s(td);VDo=r(nZ,`Note:
Loading a model from its configuration file does `),Oge=n(nZ,"STRONG",{});var _ft=s(Oge);XDo=r(_ft,"not"),_ft.forEach(t),zDo=r(nZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),rV=n(nZ,"A",{href:!0});var bft=s(rV);QDo=r(bft,"from_pretrained()"),bft.forEach(t),WDo=r(nZ," to load the model weights."),nZ.forEach(t),HDo=i(B3),T(Zv.$$.fragment,B3),B3.forEach(t),UDo=i(ol),to=n(ol,"DIV",{class:!0});var fa=s(to);T(q0.$$.fragment,fa),JDo=i(fa),Vge=n(fa,"P",{});var vft=s(Vge);YDo=r(vft,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),vft.forEach(t),KDo=i(fa),ja=n(fa,"P",{});var I3=s(ja);ZDo=r(I3,"The model class to instantiate is selected based on the "),Xge=n(I3,"CODE",{});var Fft=s(Xge);eGo=r(Fft,"model_type"),Fft.forEach(t),oGo=r(I3,` property of the config object (either
passed as an argument or loaded from `),zge=n(I3,"CODE",{});var Tft=s(zge);rGo=r(Tft,"pretrained_model_name_or_path"),Tft.forEach(t),tGo=r(I3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qge=n(I3,"CODE",{});var Mft=s(Qge);aGo=r(Mft,"pretrained_model_name_or_path"),Mft.forEach(t),nGo=r(I3,":"),I3.forEach(t),sGo=i(fa),O=n(fa,"UL",{});var X=s(O);eF=n(X,"LI",{});var d9e=s(eF);Wge=n(d9e,"STRONG",{});var Eft=s(Wge);lGo=r(Eft,"albert"),Eft.forEach(t),iGo=r(d9e," \u2014 "),tV=n(d9e,"A",{href:!0});var Cft=s(tV);dGo=r(Cft,"AlbertForQuestionAnswering"),Cft.forEach(t),cGo=r(d9e," (ALBERT model)"),d9e.forEach(t),fGo=i(X),oF=n(X,"LI",{});var c9e=s(oF);Hge=n(c9e,"STRONG",{});var wft=s(Hge);mGo=r(wft,"bart"),wft.forEach(t),gGo=r(c9e," \u2014 "),aV=n(c9e,"A",{href:!0});var Aft=s(aV);hGo=r(Aft,"BartForQuestionAnswering"),Aft.forEach(t),pGo=r(c9e," (BART model)"),c9e.forEach(t),uGo=i(X),rF=n(X,"LI",{});var f9e=s(rF);Uge=n(f9e,"STRONG",{});var yft=s(Uge);_Go=r(yft,"bert"),yft.forEach(t),bGo=r(f9e," \u2014 "),nV=n(f9e,"A",{href:!0});var Lft=s(nV);vGo=r(Lft,"BertForQuestionAnswering"),Lft.forEach(t),FGo=r(f9e," (BERT model)"),f9e.forEach(t),TGo=i(X),tF=n(X,"LI",{});var m9e=s(tF);Jge=n(m9e,"STRONG",{});var xft=s(Jge);MGo=r(xft,"big_bird"),xft.forEach(t),EGo=r(m9e," \u2014 "),sV=n(m9e,"A",{href:!0});var $ft=s(sV);CGo=r($ft,"BigBirdForQuestionAnswering"),$ft.forEach(t),wGo=r(m9e," (BigBird model)"),m9e.forEach(t),AGo=i(X),aF=n(X,"LI",{});var g9e=s(aF);Yge=n(g9e,"STRONG",{});var kft=s(Yge);yGo=r(kft,"bigbird_pegasus"),kft.forEach(t),LGo=r(g9e," \u2014 "),lV=n(g9e,"A",{href:!0});var Sft=s(lV);xGo=r(Sft,"BigBirdPegasusForQuestionAnswering"),Sft.forEach(t),$Go=r(g9e," (BigBirdPegasus model)"),g9e.forEach(t),kGo=i(X),nF=n(X,"LI",{});var h9e=s(nF);Kge=n(h9e,"STRONG",{});var Rft=s(Kge);SGo=r(Rft,"camembert"),Rft.forEach(t),RGo=r(h9e," \u2014 "),iV=n(h9e,"A",{href:!0});var Pft=s(iV);PGo=r(Pft,"CamembertForQuestionAnswering"),Pft.forEach(t),BGo=r(h9e," (CamemBERT model)"),h9e.forEach(t),IGo=i(X),sF=n(X,"LI",{});var p9e=s(sF);Zge=n(p9e,"STRONG",{});var Bft=s(Zge);qGo=r(Bft,"canine"),Bft.forEach(t),NGo=r(p9e," \u2014 "),dV=n(p9e,"A",{href:!0});var Ift=s(dV);jGo=r(Ift,"CanineForQuestionAnswering"),Ift.forEach(t),DGo=r(p9e," (Canine model)"),p9e.forEach(t),GGo=i(X),lF=n(X,"LI",{});var u9e=s(lF);ehe=n(u9e,"STRONG",{});var qft=s(ehe);OGo=r(qft,"convbert"),qft.forEach(t),VGo=r(u9e," \u2014 "),cV=n(u9e,"A",{href:!0});var Nft=s(cV);XGo=r(Nft,"ConvBertForQuestionAnswering"),Nft.forEach(t),zGo=r(u9e," (ConvBERT model)"),u9e.forEach(t),QGo=i(X),iF=n(X,"LI",{});var _9e=s(iF);ohe=n(_9e,"STRONG",{});var jft=s(ohe);WGo=r(jft,"data2vec-text"),jft.forEach(t),HGo=r(_9e," \u2014 "),fV=n(_9e,"A",{href:!0});var Dft=s(fV);UGo=r(Dft,"Data2VecTextForQuestionAnswering"),Dft.forEach(t),JGo=r(_9e," (Data2VecText model)"),_9e.forEach(t),YGo=i(X),dF=n(X,"LI",{});var b9e=s(dF);rhe=n(b9e,"STRONG",{});var Gft=s(rhe);KGo=r(Gft,"deberta"),Gft.forEach(t),ZGo=r(b9e," \u2014 "),mV=n(b9e,"A",{href:!0});var Oft=s(mV);eOo=r(Oft,"DebertaForQuestionAnswering"),Oft.forEach(t),oOo=r(b9e," (DeBERTa model)"),b9e.forEach(t),rOo=i(X),cF=n(X,"LI",{});var v9e=s(cF);the=n(v9e,"STRONG",{});var Vft=s(the);tOo=r(Vft,"deberta-v2"),Vft.forEach(t),aOo=r(v9e," \u2014 "),gV=n(v9e,"A",{href:!0});var Xft=s(gV);nOo=r(Xft,"DebertaV2ForQuestionAnswering"),Xft.forEach(t),sOo=r(v9e," (DeBERTa-v2 model)"),v9e.forEach(t),lOo=i(X),fF=n(X,"LI",{});var F9e=s(fF);ahe=n(F9e,"STRONG",{});var zft=s(ahe);iOo=r(zft,"distilbert"),zft.forEach(t),dOo=r(F9e," \u2014 "),hV=n(F9e,"A",{href:!0});var Qft=s(hV);cOo=r(Qft,"DistilBertForQuestionAnswering"),Qft.forEach(t),fOo=r(F9e," (DistilBERT model)"),F9e.forEach(t),mOo=i(X),mF=n(X,"LI",{});var T9e=s(mF);nhe=n(T9e,"STRONG",{});var Wft=s(nhe);gOo=r(Wft,"electra"),Wft.forEach(t),hOo=r(T9e," \u2014 "),pV=n(T9e,"A",{href:!0});var Hft=s(pV);pOo=r(Hft,"ElectraForQuestionAnswering"),Hft.forEach(t),uOo=r(T9e," (ELECTRA model)"),T9e.forEach(t),_Oo=i(X),gF=n(X,"LI",{});var M9e=s(gF);she=n(M9e,"STRONG",{});var Uft=s(she);bOo=r(Uft,"flaubert"),Uft.forEach(t),vOo=r(M9e," \u2014 "),uV=n(M9e,"A",{href:!0});var Jft=s(uV);FOo=r(Jft,"FlaubertForQuestionAnsweringSimple"),Jft.forEach(t),TOo=r(M9e," (FlauBERT model)"),M9e.forEach(t),MOo=i(X),hF=n(X,"LI",{});var E9e=s(hF);lhe=n(E9e,"STRONG",{});var Yft=s(lhe);EOo=r(Yft,"fnet"),Yft.forEach(t),COo=r(E9e," \u2014 "),_V=n(E9e,"A",{href:!0});var Kft=s(_V);wOo=r(Kft,"FNetForQuestionAnswering"),Kft.forEach(t),AOo=r(E9e," (FNet model)"),E9e.forEach(t),yOo=i(X),pF=n(X,"LI",{});var C9e=s(pF);ihe=n(C9e,"STRONG",{});var Zft=s(ihe);LOo=r(Zft,"funnel"),Zft.forEach(t),xOo=r(C9e," \u2014 "),bV=n(C9e,"A",{href:!0});var emt=s(bV);$Oo=r(emt,"FunnelForQuestionAnswering"),emt.forEach(t),kOo=r(C9e," (Funnel Transformer model)"),C9e.forEach(t),SOo=i(X),uF=n(X,"LI",{});var w9e=s(uF);dhe=n(w9e,"STRONG",{});var omt=s(dhe);ROo=r(omt,"gptj"),omt.forEach(t),POo=r(w9e," \u2014 "),vV=n(w9e,"A",{href:!0});var rmt=s(vV);BOo=r(rmt,"GPTJForQuestionAnswering"),rmt.forEach(t),IOo=r(w9e," (GPT-J model)"),w9e.forEach(t),qOo=i(X),_F=n(X,"LI",{});var A9e=s(_F);che=n(A9e,"STRONG",{});var tmt=s(che);NOo=r(tmt,"ibert"),tmt.forEach(t),jOo=r(A9e," \u2014 "),FV=n(A9e,"A",{href:!0});var amt=s(FV);DOo=r(amt,"IBertForQuestionAnswering"),amt.forEach(t),GOo=r(A9e," (I-BERT model)"),A9e.forEach(t),OOo=i(X),bF=n(X,"LI",{});var y9e=s(bF);fhe=n(y9e,"STRONG",{});var nmt=s(fhe);VOo=r(nmt,"layoutlmv2"),nmt.forEach(t),XOo=r(y9e," \u2014 "),TV=n(y9e,"A",{href:!0});var smt=s(TV);zOo=r(smt,"LayoutLMv2ForQuestionAnswering"),smt.forEach(t),QOo=r(y9e," (LayoutLMv2 model)"),y9e.forEach(t),WOo=i(X),vF=n(X,"LI",{});var L9e=s(vF);mhe=n(L9e,"STRONG",{});var lmt=s(mhe);HOo=r(lmt,"led"),lmt.forEach(t),UOo=r(L9e," \u2014 "),MV=n(L9e,"A",{href:!0});var imt=s(MV);JOo=r(imt,"LEDForQuestionAnswering"),imt.forEach(t),YOo=r(L9e," (LED model)"),L9e.forEach(t),KOo=i(X),FF=n(X,"LI",{});var x9e=s(FF);ghe=n(x9e,"STRONG",{});var dmt=s(ghe);ZOo=r(dmt,"longformer"),dmt.forEach(t),eVo=r(x9e," \u2014 "),EV=n(x9e,"A",{href:!0});var cmt=s(EV);oVo=r(cmt,"LongformerForQuestionAnswering"),cmt.forEach(t),rVo=r(x9e," (Longformer model)"),x9e.forEach(t),tVo=i(X),TF=n(X,"LI",{});var $9e=s(TF);hhe=n($9e,"STRONG",{});var fmt=s(hhe);aVo=r(fmt,"lxmert"),fmt.forEach(t),nVo=r($9e," \u2014 "),CV=n($9e,"A",{href:!0});var mmt=s(CV);sVo=r(mmt,"LxmertForQuestionAnswering"),mmt.forEach(t),lVo=r($9e," (LXMERT model)"),$9e.forEach(t),iVo=i(X),MF=n(X,"LI",{});var k9e=s(MF);phe=n(k9e,"STRONG",{});var gmt=s(phe);dVo=r(gmt,"mbart"),gmt.forEach(t),cVo=r(k9e," \u2014 "),wV=n(k9e,"A",{href:!0});var hmt=s(wV);fVo=r(hmt,"MBartForQuestionAnswering"),hmt.forEach(t),mVo=r(k9e," (mBART model)"),k9e.forEach(t),gVo=i(X),EF=n(X,"LI",{});var S9e=s(EF);uhe=n(S9e,"STRONG",{});var pmt=s(uhe);hVo=r(pmt,"megatron-bert"),pmt.forEach(t),pVo=r(S9e," \u2014 "),AV=n(S9e,"A",{href:!0});var umt=s(AV);uVo=r(umt,"MegatronBertForQuestionAnswering"),umt.forEach(t),_Vo=r(S9e," (MegatronBert model)"),S9e.forEach(t),bVo=i(X),CF=n(X,"LI",{});var R9e=s(CF);_he=n(R9e,"STRONG",{});var _mt=s(_he);vVo=r(_mt,"mobilebert"),_mt.forEach(t),FVo=r(R9e," \u2014 "),yV=n(R9e,"A",{href:!0});var bmt=s(yV);TVo=r(bmt,"MobileBertForQuestionAnswering"),bmt.forEach(t),MVo=r(R9e," (MobileBERT model)"),R9e.forEach(t),EVo=i(X),wF=n(X,"LI",{});var P9e=s(wF);bhe=n(P9e,"STRONG",{});var vmt=s(bhe);CVo=r(vmt,"mpnet"),vmt.forEach(t),wVo=r(P9e," \u2014 "),LV=n(P9e,"A",{href:!0});var Fmt=s(LV);AVo=r(Fmt,"MPNetForQuestionAnswering"),Fmt.forEach(t),yVo=r(P9e," (MPNet model)"),P9e.forEach(t),LVo=i(X),AF=n(X,"LI",{});var B9e=s(AF);vhe=n(B9e,"STRONG",{});var Tmt=s(vhe);xVo=r(Tmt,"nystromformer"),Tmt.forEach(t),$Vo=r(B9e," \u2014 "),xV=n(B9e,"A",{href:!0});var Mmt=s(xV);kVo=r(Mmt,"NystromformerForQuestionAnswering"),Mmt.forEach(t),SVo=r(B9e," (Nystromformer model)"),B9e.forEach(t),RVo=i(X),yF=n(X,"LI",{});var I9e=s(yF);Fhe=n(I9e,"STRONG",{});var Emt=s(Fhe);PVo=r(Emt,"qdqbert"),Emt.forEach(t),BVo=r(I9e," \u2014 "),$V=n(I9e,"A",{href:!0});var Cmt=s($V);IVo=r(Cmt,"QDQBertForQuestionAnswering"),Cmt.forEach(t),qVo=r(I9e," (QDQBert model)"),I9e.forEach(t),NVo=i(X),LF=n(X,"LI",{});var q9e=s(LF);The=n(q9e,"STRONG",{});var wmt=s(The);jVo=r(wmt,"reformer"),wmt.forEach(t),DVo=r(q9e," \u2014 "),kV=n(q9e,"A",{href:!0});var Amt=s(kV);GVo=r(Amt,"ReformerForQuestionAnswering"),Amt.forEach(t),OVo=r(q9e," (Reformer model)"),q9e.forEach(t),VVo=i(X),xF=n(X,"LI",{});var N9e=s(xF);Mhe=n(N9e,"STRONG",{});var ymt=s(Mhe);XVo=r(ymt,"rembert"),ymt.forEach(t),zVo=r(N9e," \u2014 "),SV=n(N9e,"A",{href:!0});var Lmt=s(SV);QVo=r(Lmt,"RemBertForQuestionAnswering"),Lmt.forEach(t),WVo=r(N9e," (RemBERT model)"),N9e.forEach(t),HVo=i(X),$F=n(X,"LI",{});var j9e=s($F);Ehe=n(j9e,"STRONG",{});var xmt=s(Ehe);UVo=r(xmt,"roberta"),xmt.forEach(t),JVo=r(j9e," \u2014 "),RV=n(j9e,"A",{href:!0});var $mt=s(RV);YVo=r($mt,"RobertaForQuestionAnswering"),$mt.forEach(t),KVo=r(j9e," (RoBERTa model)"),j9e.forEach(t),ZVo=i(X),kF=n(X,"LI",{});var D9e=s(kF);Che=n(D9e,"STRONG",{});var kmt=s(Che);eXo=r(kmt,"roformer"),kmt.forEach(t),oXo=r(D9e," \u2014 "),PV=n(D9e,"A",{href:!0});var Smt=s(PV);rXo=r(Smt,"RoFormerForQuestionAnswering"),Smt.forEach(t),tXo=r(D9e," (RoFormer model)"),D9e.forEach(t),aXo=i(X),SF=n(X,"LI",{});var G9e=s(SF);whe=n(G9e,"STRONG",{});var Rmt=s(whe);nXo=r(Rmt,"splinter"),Rmt.forEach(t),sXo=r(G9e," \u2014 "),BV=n(G9e,"A",{href:!0});var Pmt=s(BV);lXo=r(Pmt,"SplinterForQuestionAnswering"),Pmt.forEach(t),iXo=r(G9e," (Splinter model)"),G9e.forEach(t),dXo=i(X),RF=n(X,"LI",{});var O9e=s(RF);Ahe=n(O9e,"STRONG",{});var Bmt=s(Ahe);cXo=r(Bmt,"squeezebert"),Bmt.forEach(t),fXo=r(O9e," \u2014 "),IV=n(O9e,"A",{href:!0});var Imt=s(IV);mXo=r(Imt,"SqueezeBertForQuestionAnswering"),Imt.forEach(t),gXo=r(O9e," (SqueezeBERT model)"),O9e.forEach(t),hXo=i(X),PF=n(X,"LI",{});var V9e=s(PF);yhe=n(V9e,"STRONG",{});var qmt=s(yhe);pXo=r(qmt,"xlm"),qmt.forEach(t),uXo=r(V9e," \u2014 "),qV=n(V9e,"A",{href:!0});var Nmt=s(qV);_Xo=r(Nmt,"XLMForQuestionAnsweringSimple"),Nmt.forEach(t),bXo=r(V9e," (XLM model)"),V9e.forEach(t),vXo=i(X),BF=n(X,"LI",{});var X9e=s(BF);Lhe=n(X9e,"STRONG",{});var jmt=s(Lhe);FXo=r(jmt,"xlm-roberta"),jmt.forEach(t),TXo=r(X9e," \u2014 "),NV=n(X9e,"A",{href:!0});var Dmt=s(NV);MXo=r(Dmt,"XLMRobertaForQuestionAnswering"),Dmt.forEach(t),EXo=r(X9e," (XLM-RoBERTa model)"),X9e.forEach(t),CXo=i(X),IF=n(X,"LI",{});var z9e=s(IF);xhe=n(z9e,"STRONG",{});var Gmt=s(xhe);wXo=r(Gmt,"xlm-roberta-xl"),Gmt.forEach(t),AXo=r(z9e," \u2014 "),jV=n(z9e,"A",{href:!0});var Omt=s(jV);yXo=r(Omt,"XLMRobertaXLForQuestionAnswering"),Omt.forEach(t),LXo=r(z9e," (XLM-RoBERTa-XL model)"),z9e.forEach(t),xXo=i(X),qF=n(X,"LI",{});var Q9e=s(qF);$he=n(Q9e,"STRONG",{});var Vmt=s($he);$Xo=r(Vmt,"xlnet"),Vmt.forEach(t),kXo=r(Q9e," \u2014 "),DV=n(Q9e,"A",{href:!0});var Xmt=s(DV);SXo=r(Xmt,"XLNetForQuestionAnsweringSimple"),Xmt.forEach(t),RXo=r(Q9e," (XLNet model)"),Q9e.forEach(t),PXo=i(X),NF=n(X,"LI",{});var W9e=s(NF);khe=n(W9e,"STRONG",{});var zmt=s(khe);BXo=r(zmt,"yoso"),zmt.forEach(t),IXo=r(W9e," \u2014 "),GV=n(W9e,"A",{href:!0});var Qmt=s(GV);qXo=r(Qmt,"YosoForQuestionAnswering"),Qmt.forEach(t),NXo=r(W9e," (YOSO model)"),W9e.forEach(t),X.forEach(t),jXo=i(fa),jF=n(fa,"P",{});var H9e=s(jF);DXo=r(H9e,"The model is set in evaluation mode by default using "),She=n(H9e,"CODE",{});var Wmt=s(She);GXo=r(Wmt,"model.eval()"),Wmt.forEach(t),OXo=r(H9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Rhe=n(H9e,"CODE",{});var Hmt=s(Rhe);VXo=r(Hmt,"model.train()"),Hmt.forEach(t),H9e.forEach(t),XXo=i(fa),T(DF.$$.fragment,fa),fa.forEach(t),ol.forEach(t),Fqe=i(f),ad=n(f,"H2",{class:!0});var Aje=s(ad);GF=n(Aje,"A",{id:!0,class:!0,href:!0});var Umt=s(GF);Phe=n(Umt,"SPAN",{});var Jmt=s(Phe);T(N0.$$.fragment,Jmt),Jmt.forEach(t),Umt.forEach(t),zXo=i(Aje),Bhe=n(Aje,"SPAN",{});var Ymt=s(Bhe);QXo=r(Ymt,"AutoModelForTableQuestionAnswering"),Ymt.forEach(t),Aje.forEach(t),Tqe=i(f),jo=n(f,"DIV",{class:!0});var rl=s(jo);T(j0.$$.fragment,rl),WXo=i(rl),nd=n(rl,"P",{});var sZ=s(nd);HXo=r(sZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),OV=n(sZ,"A",{href:!0});var Kmt=s(OV);UXo=r(Kmt,"from_pretrained()"),Kmt.forEach(t),JXo=r(sZ," class method or the "),VV=n(sZ,"A",{href:!0});var Zmt=s(VV);YXo=r(Zmt,"from_config()"),Zmt.forEach(t),KXo=r(sZ,` class
method.`),sZ.forEach(t),ZXo=i(rl),D0=n(rl,"P",{});var yje=s(D0);ezo=r(yje,"This class cannot be instantiated directly using "),Ihe=n(yje,"CODE",{});var egt=s(Ihe);ozo=r(egt,"__init__()"),egt.forEach(t),rzo=r(yje," (throws an error)."),yje.forEach(t),tzo=i(rl),gt=n(rl,"DIV",{class:!0});var q3=s(gt);T(G0.$$.fragment,q3),azo=i(q3),qhe=n(q3,"P",{});var ogt=s(qhe);nzo=r(ogt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),ogt.forEach(t),szo=i(q3),sd=n(q3,"P",{});var lZ=s(sd);lzo=r(lZ,`Note:
Loading a model from its configuration file does `),Nhe=n(lZ,"STRONG",{});var rgt=s(Nhe);izo=r(rgt,"not"),rgt.forEach(t),dzo=r(lZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),XV=n(lZ,"A",{href:!0});var tgt=s(XV);czo=r(tgt,"from_pretrained()"),tgt.forEach(t),fzo=r(lZ," to load the model weights."),lZ.forEach(t),mzo=i(q3),T(OF.$$.fragment,q3),q3.forEach(t),gzo=i(rl),ao=n(rl,"DIV",{class:!0});var ma=s(ao);T(O0.$$.fragment,ma),hzo=i(ma),jhe=n(ma,"P",{});var agt=s(jhe);pzo=r(agt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),agt.forEach(t),uzo=i(ma),Da=n(ma,"P",{});var N3=s(Da);_zo=r(N3,"The model class to instantiate is selected based on the "),Dhe=n(N3,"CODE",{});var ngt=s(Dhe);bzo=r(ngt,"model_type"),ngt.forEach(t),vzo=r(N3,` property of the config object (either
passed as an argument or loaded from `),Ghe=n(N3,"CODE",{});var sgt=s(Ghe);Fzo=r(sgt,"pretrained_model_name_or_path"),sgt.forEach(t),Tzo=r(N3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ohe=n(N3,"CODE",{});var lgt=s(Ohe);Mzo=r(lgt,"pretrained_model_name_or_path"),lgt.forEach(t),Ezo=r(N3,":"),N3.forEach(t),Czo=i(ma),Vhe=n(ma,"UL",{});var igt=s(Vhe);VF=n(igt,"LI",{});var U9e=s(VF);Xhe=n(U9e,"STRONG",{});var dgt=s(Xhe);wzo=r(dgt,"tapas"),dgt.forEach(t),Azo=r(U9e," \u2014 "),zV=n(U9e,"A",{href:!0});var cgt=s(zV);yzo=r(cgt,"TapasForQuestionAnswering"),cgt.forEach(t),Lzo=r(U9e," (TAPAS model)"),U9e.forEach(t),igt.forEach(t),xzo=i(ma),XF=n(ma,"P",{});var J9e=s(XF);$zo=r(J9e,"The model is set in evaluation mode by default using "),zhe=n(J9e,"CODE",{});var fgt=s(zhe);kzo=r(fgt,"model.eval()"),fgt.forEach(t),Szo=r(J9e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Qhe=n(J9e,"CODE",{});var mgt=s(Qhe);Rzo=r(mgt,"model.train()"),mgt.forEach(t),J9e.forEach(t),Pzo=i(ma),T(zF.$$.fragment,ma),ma.forEach(t),rl.forEach(t),Mqe=i(f),ld=n(f,"H2",{class:!0});var Lje=s(ld);QF=n(Lje,"A",{id:!0,class:!0,href:!0});var ggt=s(QF);Whe=n(ggt,"SPAN",{});var hgt=s(Whe);T(V0.$$.fragment,hgt),hgt.forEach(t),ggt.forEach(t),Bzo=i(Lje),Hhe=n(Lje,"SPAN",{});var pgt=s(Hhe);Izo=r(pgt,"AutoModelForImageClassification"),pgt.forEach(t),Lje.forEach(t),Eqe=i(f),Do=n(f,"DIV",{class:!0});var tl=s(Do);T(X0.$$.fragment,tl),qzo=i(tl),id=n(tl,"P",{});var iZ=s(id);Nzo=r(iZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),QV=n(iZ,"A",{href:!0});var ugt=s(QV);jzo=r(ugt,"from_pretrained()"),ugt.forEach(t),Dzo=r(iZ," class method or the "),WV=n(iZ,"A",{href:!0});var _gt=s(WV);Gzo=r(_gt,"from_config()"),_gt.forEach(t),Ozo=r(iZ,` class
method.`),iZ.forEach(t),Vzo=i(tl),z0=n(tl,"P",{});var xje=s(z0);Xzo=r(xje,"This class cannot be instantiated directly using "),Uhe=n(xje,"CODE",{});var bgt=s(Uhe);zzo=r(bgt,"__init__()"),bgt.forEach(t),Qzo=r(xje," (throws an error)."),xje.forEach(t),Wzo=i(tl),ht=n(tl,"DIV",{class:!0});var j3=s(ht);T(Q0.$$.fragment,j3),Hzo=i(j3),Jhe=n(j3,"P",{});var vgt=s(Jhe);Uzo=r(vgt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),vgt.forEach(t),Jzo=i(j3),dd=n(j3,"P",{});var dZ=s(dd);Yzo=r(dZ,`Note:
Loading a model from its configuration file does `),Yhe=n(dZ,"STRONG",{});var Fgt=s(Yhe);Kzo=r(Fgt,"not"),Fgt.forEach(t),Zzo=r(dZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),HV=n(dZ,"A",{href:!0});var Tgt=s(HV);eQo=r(Tgt,"from_pretrained()"),Tgt.forEach(t),oQo=r(dZ," to load the model weights."),dZ.forEach(t),rQo=i(j3),T(WF.$$.fragment,j3),j3.forEach(t),tQo=i(tl),no=n(tl,"DIV",{class:!0});var ga=s(no);T(W0.$$.fragment,ga),aQo=i(ga),Khe=n(ga,"P",{});var Mgt=s(Khe);nQo=r(Mgt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Mgt.forEach(t),sQo=i(ga),Ga=n(ga,"P",{});var D3=s(Ga);lQo=r(D3,"The model class to instantiate is selected based on the "),Zhe=n(D3,"CODE",{});var Egt=s(Zhe);iQo=r(Egt,"model_type"),Egt.forEach(t),dQo=r(D3,` property of the config object (either
passed as an argument or loaded from `),epe=n(D3,"CODE",{});var Cgt=s(epe);cQo=r(Cgt,"pretrained_model_name_or_path"),Cgt.forEach(t),fQo=r(D3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ope=n(D3,"CODE",{});var wgt=s(ope);mQo=r(wgt,"pretrained_model_name_or_path"),wgt.forEach(t),gQo=r(D3,":"),D3.forEach(t),hQo=i(ga),Fe=n(ga,"UL",{});var Ee=s(Fe);HF=n(Ee,"LI",{});var Y9e=s(HF);rpe=n(Y9e,"STRONG",{});var Agt=s(rpe);pQo=r(Agt,"beit"),Agt.forEach(t),uQo=r(Y9e," \u2014 "),UV=n(Y9e,"A",{href:!0});var ygt=s(UV);_Qo=r(ygt,"BeitForImageClassification"),ygt.forEach(t),bQo=r(Y9e," (BEiT model)"),Y9e.forEach(t),vQo=i(Ee),UF=n(Ee,"LI",{});var K9e=s(UF);tpe=n(K9e,"STRONG",{});var Lgt=s(tpe);FQo=r(Lgt,"convnext"),Lgt.forEach(t),TQo=r(K9e," \u2014 "),JV=n(K9e,"A",{href:!0});var xgt=s(JV);MQo=r(xgt,"ConvNextForImageClassification"),xgt.forEach(t),EQo=r(K9e," (ConvNext model)"),K9e.forEach(t),CQo=i(Ee),JF=n(Ee,"LI",{});var Z9e=s(JF);ape=n(Z9e,"STRONG",{});var $gt=s(ape);wQo=r($gt,"data2vec-vision"),$gt.forEach(t),AQo=r(Z9e," \u2014 "),YV=n(Z9e,"A",{href:!0});var kgt=s(YV);yQo=r(kgt,"Data2VecVisionForImageClassification"),kgt.forEach(t),LQo=r(Z9e," (Data2VecVision model)"),Z9e.forEach(t),xQo=i(Ee),js=n(Ee,"LI",{});var q$=s(js);npe=n(q$,"STRONG",{});var Sgt=s(npe);$Qo=r(Sgt,"deit"),Sgt.forEach(t),kQo=r(q$," \u2014 "),KV=n(q$,"A",{href:!0});var Rgt=s(KV);SQo=r(Rgt,"DeiTForImageClassification"),Rgt.forEach(t),RQo=r(q$," or "),ZV=n(q$,"A",{href:!0});var Pgt=s(ZV);PQo=r(Pgt,"DeiTForImageClassificationWithTeacher"),Pgt.forEach(t),BQo=r(q$," (DeiT model)"),q$.forEach(t),IQo=i(Ee),YF=n(Ee,"LI",{});var e$e=s(YF);spe=n(e$e,"STRONG",{});var Bgt=s(spe);qQo=r(Bgt,"imagegpt"),Bgt.forEach(t),NQo=r(e$e," \u2014 "),eX=n(e$e,"A",{href:!0});var Igt=s(eX);jQo=r(Igt,"ImageGPTForImageClassification"),Igt.forEach(t),DQo=r(e$e," (ImageGPT model)"),e$e.forEach(t),GQo=i(Ee),pt=n(Ee,"LI",{});var Tf=s(pt);lpe=n(Tf,"STRONG",{});var qgt=s(lpe);OQo=r(qgt,"perceiver"),qgt.forEach(t),VQo=r(Tf," \u2014 "),oX=n(Tf,"A",{href:!0});var Ngt=s(oX);XQo=r(Ngt,"PerceiverForImageClassificationLearned"),Ngt.forEach(t),zQo=r(Tf," or "),rX=n(Tf,"A",{href:!0});var jgt=s(rX);QQo=r(jgt,"PerceiverForImageClassificationFourier"),jgt.forEach(t),WQo=r(Tf," or "),tX=n(Tf,"A",{href:!0});var Dgt=s(tX);HQo=r(Dgt,"PerceiverForImageClassificationConvProcessing"),Dgt.forEach(t),UQo=r(Tf," (Perceiver model)"),Tf.forEach(t),JQo=i(Ee),KF=n(Ee,"LI",{});var o$e=s(KF);ipe=n(o$e,"STRONG",{});var Ggt=s(ipe);YQo=r(Ggt,"poolformer"),Ggt.forEach(t),KQo=r(o$e," \u2014 "),aX=n(o$e,"A",{href:!0});var Ogt=s(aX);ZQo=r(Ogt,"PoolFormerForImageClassification"),Ogt.forEach(t),eWo=r(o$e," (PoolFormer model)"),o$e.forEach(t),oWo=i(Ee),ZF=n(Ee,"LI",{});var r$e=s(ZF);dpe=n(r$e,"STRONG",{});var Vgt=s(dpe);rWo=r(Vgt,"regnet"),Vgt.forEach(t),tWo=r(r$e," \u2014 "),nX=n(r$e,"A",{href:!0});var Xgt=s(nX);aWo=r(Xgt,"RegNetForImageClassification"),Xgt.forEach(t),nWo=r(r$e," (RegNet model)"),r$e.forEach(t),sWo=i(Ee),e6=n(Ee,"LI",{});var t$e=s(e6);cpe=n(t$e,"STRONG",{});var zgt=s(cpe);lWo=r(zgt,"resnet"),zgt.forEach(t),iWo=r(t$e," \u2014 "),sX=n(t$e,"A",{href:!0});var Qgt=s(sX);dWo=r(Qgt,"ResNetForImageClassification"),Qgt.forEach(t),cWo=r(t$e," (ResNet model)"),t$e.forEach(t),fWo=i(Ee),o6=n(Ee,"LI",{});var a$e=s(o6);fpe=n(a$e,"STRONG",{});var Wgt=s(fpe);mWo=r(Wgt,"segformer"),Wgt.forEach(t),gWo=r(a$e," \u2014 "),lX=n(a$e,"A",{href:!0});var Hgt=s(lX);hWo=r(Hgt,"SegformerForImageClassification"),Hgt.forEach(t),pWo=r(a$e," (SegFormer model)"),a$e.forEach(t),uWo=i(Ee),r6=n(Ee,"LI",{});var n$e=s(r6);mpe=n(n$e,"STRONG",{});var Ugt=s(mpe);_Wo=r(Ugt,"swin"),Ugt.forEach(t),bWo=r(n$e," \u2014 "),iX=n(n$e,"A",{href:!0});var Jgt=s(iX);vWo=r(Jgt,"SwinForImageClassification"),Jgt.forEach(t),FWo=r(n$e," (Swin model)"),n$e.forEach(t),TWo=i(Ee),t6=n(Ee,"LI",{});var s$e=s(t6);gpe=n(s$e,"STRONG",{});var Ygt=s(gpe);MWo=r(Ygt,"van"),Ygt.forEach(t),EWo=r(s$e," \u2014 "),dX=n(s$e,"A",{href:!0});var Kgt=s(dX);CWo=r(Kgt,"VanForImageClassification"),Kgt.forEach(t),wWo=r(s$e," (VAN model)"),s$e.forEach(t),AWo=i(Ee),a6=n(Ee,"LI",{});var l$e=s(a6);hpe=n(l$e,"STRONG",{});var Zgt=s(hpe);yWo=r(Zgt,"vit"),Zgt.forEach(t),LWo=r(l$e," \u2014 "),cX=n(l$e,"A",{href:!0});var eht=s(cX);xWo=r(eht,"ViTForImageClassification"),eht.forEach(t),$Wo=r(l$e," (ViT model)"),l$e.forEach(t),Ee.forEach(t),kWo=i(ga),n6=n(ga,"P",{});var i$e=s(n6);SWo=r(i$e,"The model is set in evaluation mode by default using "),ppe=n(i$e,"CODE",{});var oht=s(ppe);RWo=r(oht,"model.eval()"),oht.forEach(t),PWo=r(i$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),upe=n(i$e,"CODE",{});var rht=s(upe);BWo=r(rht,"model.train()"),rht.forEach(t),i$e.forEach(t),IWo=i(ga),T(s6.$$.fragment,ga),ga.forEach(t),tl.forEach(t),Cqe=i(f),cd=n(f,"H2",{class:!0});var $je=s(cd);l6=n($je,"A",{id:!0,class:!0,href:!0});var tht=s(l6);_pe=n(tht,"SPAN",{});var aht=s(_pe);T(H0.$$.fragment,aht),aht.forEach(t),tht.forEach(t),qWo=i($je),bpe=n($je,"SPAN",{});var nht=s(bpe);NWo=r(nht,"AutoModelForVision2Seq"),nht.forEach(t),$je.forEach(t),wqe=i(f),Go=n(f,"DIV",{class:!0});var al=s(Go);T(U0.$$.fragment,al),jWo=i(al),fd=n(al,"P",{});var cZ=s(fd);DWo=r(cZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),fX=n(cZ,"A",{href:!0});var sht=s(fX);GWo=r(sht,"from_pretrained()"),sht.forEach(t),OWo=r(cZ," class method or the "),mX=n(cZ,"A",{href:!0});var lht=s(mX);VWo=r(lht,"from_config()"),lht.forEach(t),XWo=r(cZ,` class
method.`),cZ.forEach(t),zWo=i(al),J0=n(al,"P",{});var kje=s(J0);QWo=r(kje,"This class cannot be instantiated directly using "),vpe=n(kje,"CODE",{});var iht=s(vpe);WWo=r(iht,"__init__()"),iht.forEach(t),HWo=r(kje," (throws an error)."),kje.forEach(t),UWo=i(al),ut=n(al,"DIV",{class:!0});var G3=s(ut);T(Y0.$$.fragment,G3),JWo=i(G3),Fpe=n(G3,"P",{});var dht=s(Fpe);YWo=r(dht,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),dht.forEach(t),KWo=i(G3),md=n(G3,"P",{});var fZ=s(md);ZWo=r(fZ,`Note:
Loading a model from its configuration file does `),Tpe=n(fZ,"STRONG",{});var cht=s(Tpe);eHo=r(cht,"not"),cht.forEach(t),oHo=r(fZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),gX=n(fZ,"A",{href:!0});var fht=s(gX);rHo=r(fht,"from_pretrained()"),fht.forEach(t),tHo=r(fZ," to load the model weights."),fZ.forEach(t),aHo=i(G3),T(i6.$$.fragment,G3),G3.forEach(t),nHo=i(al),so=n(al,"DIV",{class:!0});var ha=s(so);T(K0.$$.fragment,ha),sHo=i(ha),Mpe=n(ha,"P",{});var mht=s(Mpe);lHo=r(mht,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),mht.forEach(t),iHo=i(ha),Oa=n(ha,"P",{});var O3=s(Oa);dHo=r(O3,"The model class to instantiate is selected based on the "),Epe=n(O3,"CODE",{});var ght=s(Epe);cHo=r(ght,"model_type"),ght.forEach(t),fHo=r(O3,` property of the config object (either
passed as an argument or loaded from `),Cpe=n(O3,"CODE",{});var hht=s(Cpe);mHo=r(hht,"pretrained_model_name_or_path"),hht.forEach(t),gHo=r(O3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wpe=n(O3,"CODE",{});var pht=s(wpe);hHo=r(pht,"pretrained_model_name_or_path"),pht.forEach(t),pHo=r(O3,":"),O3.forEach(t),uHo=i(ha),Ape=n(ha,"UL",{});var uht=s(Ape);d6=n(uht,"LI",{});var d$e=s(d6);ype=n(d$e,"STRONG",{});var _ht=s(ype);_Ho=r(_ht,"vision-encoder-decoder"),_ht.forEach(t),bHo=r(d$e," \u2014 "),hX=n(d$e,"A",{href:!0});var bht=s(hX);vHo=r(bht,"VisionEncoderDecoderModel"),bht.forEach(t),FHo=r(d$e," (Vision Encoder decoder model)"),d$e.forEach(t),uht.forEach(t),THo=i(ha),c6=n(ha,"P",{});var c$e=s(c6);MHo=r(c$e,"The model is set in evaluation mode by default using "),Lpe=n(c$e,"CODE",{});var vht=s(Lpe);EHo=r(vht,"model.eval()"),vht.forEach(t),CHo=r(c$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),xpe=n(c$e,"CODE",{});var Fht=s(xpe);wHo=r(Fht,"model.train()"),Fht.forEach(t),c$e.forEach(t),AHo=i(ha),T(f6.$$.fragment,ha),ha.forEach(t),al.forEach(t),Aqe=i(f),gd=n(f,"H2",{class:!0});var Sje=s(gd);m6=n(Sje,"A",{id:!0,class:!0,href:!0});var Tht=s(m6);$pe=n(Tht,"SPAN",{});var Mht=s($pe);T(Z0.$$.fragment,Mht),Mht.forEach(t),Tht.forEach(t),yHo=i(Sje),kpe=n(Sje,"SPAN",{});var Eht=s(kpe);LHo=r(Eht,"AutoModelForVisualQuestionAnswering"),Eht.forEach(t),Sje.forEach(t),yqe=i(f),Oo=n(f,"DIV",{class:!0});var nl=s(Oo);T(ey.$$.fragment,nl),xHo=i(nl),hd=n(nl,"P",{});var mZ=s(hd);$Ho=r(mZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),pX=n(mZ,"A",{href:!0});var Cht=s(pX);kHo=r(Cht,"from_pretrained()"),Cht.forEach(t),SHo=r(mZ," class method or the "),uX=n(mZ,"A",{href:!0});var wht=s(uX);RHo=r(wht,"from_config()"),wht.forEach(t),PHo=r(mZ,` class
method.`),mZ.forEach(t),BHo=i(nl),oy=n(nl,"P",{});var Rje=s(oy);IHo=r(Rje,"This class cannot be instantiated directly using "),Spe=n(Rje,"CODE",{});var Aht=s(Spe);qHo=r(Aht,"__init__()"),Aht.forEach(t),NHo=r(Rje," (throws an error)."),Rje.forEach(t),jHo=i(nl),_t=n(nl,"DIV",{class:!0});var V3=s(_t);T(ry.$$.fragment,V3),DHo=i(V3),Rpe=n(V3,"P",{});var yht=s(Rpe);GHo=r(yht,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),yht.forEach(t),OHo=i(V3),pd=n(V3,"P",{});var gZ=s(pd);VHo=r(gZ,`Note:
Loading a model from its configuration file does `),Ppe=n(gZ,"STRONG",{});var Lht=s(Ppe);XHo=r(Lht,"not"),Lht.forEach(t),zHo=r(gZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),_X=n(gZ,"A",{href:!0});var xht=s(_X);QHo=r(xht,"from_pretrained()"),xht.forEach(t),WHo=r(gZ," to load the model weights."),gZ.forEach(t),HHo=i(V3),T(g6.$$.fragment,V3),V3.forEach(t),UHo=i(nl),lo=n(nl,"DIV",{class:!0});var pa=s(lo);T(ty.$$.fragment,pa),JHo=i(pa),Bpe=n(pa,"P",{});var $ht=s(Bpe);YHo=r($ht,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),$ht.forEach(t),KHo=i(pa),Va=n(pa,"P",{});var X3=s(Va);ZHo=r(X3,"The model class to instantiate is selected based on the "),Ipe=n(X3,"CODE",{});var kht=s(Ipe);eUo=r(kht,"model_type"),kht.forEach(t),oUo=r(X3,` property of the config object (either
passed as an argument or loaded from `),qpe=n(X3,"CODE",{});var Sht=s(qpe);rUo=r(Sht,"pretrained_model_name_or_path"),Sht.forEach(t),tUo=r(X3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Npe=n(X3,"CODE",{});var Rht=s(Npe);aUo=r(Rht,"pretrained_model_name_or_path"),Rht.forEach(t),nUo=r(X3,":"),X3.forEach(t),sUo=i(pa),jpe=n(pa,"UL",{});var Pht=s(jpe);h6=n(Pht,"LI",{});var f$e=s(h6);Dpe=n(f$e,"STRONG",{});var Bht=s(Dpe);lUo=r(Bht,"vilt"),Bht.forEach(t),iUo=r(f$e," \u2014 "),bX=n(f$e,"A",{href:!0});var Iht=s(bX);dUo=r(Iht,"ViltForQuestionAnswering"),Iht.forEach(t),cUo=r(f$e," (ViLT model)"),f$e.forEach(t),Pht.forEach(t),fUo=i(pa),p6=n(pa,"P",{});var m$e=s(p6);mUo=r(m$e,"The model is set in evaluation mode by default using "),Gpe=n(m$e,"CODE",{});var qht=s(Gpe);gUo=r(qht,"model.eval()"),qht.forEach(t),hUo=r(m$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ope=n(m$e,"CODE",{});var Nht=s(Ope);pUo=r(Nht,"model.train()"),Nht.forEach(t),m$e.forEach(t),uUo=i(pa),T(u6.$$.fragment,pa),pa.forEach(t),nl.forEach(t),Lqe=i(f),ud=n(f,"H2",{class:!0});var Pje=s(ud);_6=n(Pje,"A",{id:!0,class:!0,href:!0});var jht=s(_6);Vpe=n(jht,"SPAN",{});var Dht=s(Vpe);T(ay.$$.fragment,Dht),Dht.forEach(t),jht.forEach(t),_Uo=i(Pje),Xpe=n(Pje,"SPAN",{});var Ght=s(Xpe);bUo=r(Ght,"AutoModelForAudioClassification"),Ght.forEach(t),Pje.forEach(t),xqe=i(f),Vo=n(f,"DIV",{class:!0});var sl=s(Vo);T(ny.$$.fragment,sl),vUo=i(sl),_d=n(sl,"P",{});var hZ=s(_d);FUo=r(hZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),vX=n(hZ,"A",{href:!0});var Oht=s(vX);TUo=r(Oht,"from_pretrained()"),Oht.forEach(t),MUo=r(hZ," class method or the "),FX=n(hZ,"A",{href:!0});var Vht=s(FX);EUo=r(Vht,"from_config()"),Vht.forEach(t),CUo=r(hZ,` class
method.`),hZ.forEach(t),wUo=i(sl),sy=n(sl,"P",{});var Bje=s(sy);AUo=r(Bje,"This class cannot be instantiated directly using "),zpe=n(Bje,"CODE",{});var Xht=s(zpe);yUo=r(Xht,"__init__()"),Xht.forEach(t),LUo=r(Bje," (throws an error)."),Bje.forEach(t),xUo=i(sl),bt=n(sl,"DIV",{class:!0});var z3=s(bt);T(ly.$$.fragment,z3),$Uo=i(z3),Qpe=n(z3,"P",{});var zht=s(Qpe);kUo=r(zht,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),zht.forEach(t),SUo=i(z3),bd=n(z3,"P",{});var pZ=s(bd);RUo=r(pZ,`Note:
Loading a model from its configuration file does `),Wpe=n(pZ,"STRONG",{});var Qht=s(Wpe);PUo=r(Qht,"not"),Qht.forEach(t),BUo=r(pZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),TX=n(pZ,"A",{href:!0});var Wht=s(TX);IUo=r(Wht,"from_pretrained()"),Wht.forEach(t),qUo=r(pZ," to load the model weights."),pZ.forEach(t),NUo=i(z3),T(b6.$$.fragment,z3),z3.forEach(t),jUo=i(sl),io=n(sl,"DIV",{class:!0});var ua=s(io);T(iy.$$.fragment,ua),DUo=i(ua),Hpe=n(ua,"P",{});var Hht=s(Hpe);GUo=r(Hht,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Hht.forEach(t),OUo=i(ua),Xa=n(ua,"P",{});var Q3=s(Xa);VUo=r(Q3,"The model class to instantiate is selected based on the "),Upe=n(Q3,"CODE",{});var Uht=s(Upe);XUo=r(Uht,"model_type"),Uht.forEach(t),zUo=r(Q3,` property of the config object (either
passed as an argument or loaded from `),Jpe=n(Q3,"CODE",{});var Jht=s(Jpe);QUo=r(Jht,"pretrained_model_name_or_path"),Jht.forEach(t),WUo=r(Q3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ype=n(Q3,"CODE",{});var Yht=s(Ype);HUo=r(Yht,"pretrained_model_name_or_path"),Yht.forEach(t),UUo=r(Q3,":"),Q3.forEach(t),JUo=i(ua),Ne=n(ua,"UL",{});var vo=s(Ne);v6=n(vo,"LI",{});var g$e=s(v6);Kpe=n(g$e,"STRONG",{});var Kht=s(Kpe);YUo=r(Kht,"data2vec-audio"),Kht.forEach(t),KUo=r(g$e," \u2014 "),MX=n(g$e,"A",{href:!0});var Zht=s(MX);ZUo=r(Zht,"Data2VecAudioForSequenceClassification"),Zht.forEach(t),eJo=r(g$e," (Data2VecAudio model)"),g$e.forEach(t),oJo=i(vo),F6=n(vo,"LI",{});var h$e=s(F6);Zpe=n(h$e,"STRONG",{});var ept=s(Zpe);rJo=r(ept,"hubert"),ept.forEach(t),tJo=r(h$e," \u2014 "),EX=n(h$e,"A",{href:!0});var opt=s(EX);aJo=r(opt,"HubertForSequenceClassification"),opt.forEach(t),nJo=r(h$e," (Hubert model)"),h$e.forEach(t),sJo=i(vo),T6=n(vo,"LI",{});var p$e=s(T6);eue=n(p$e,"STRONG",{});var rpt=s(eue);lJo=r(rpt,"sew"),rpt.forEach(t),iJo=r(p$e," \u2014 "),CX=n(p$e,"A",{href:!0});var tpt=s(CX);dJo=r(tpt,"SEWForSequenceClassification"),tpt.forEach(t),cJo=r(p$e," (SEW model)"),p$e.forEach(t),fJo=i(vo),M6=n(vo,"LI",{});var u$e=s(M6);oue=n(u$e,"STRONG",{});var apt=s(oue);mJo=r(apt,"sew-d"),apt.forEach(t),gJo=r(u$e," \u2014 "),wX=n(u$e,"A",{href:!0});var npt=s(wX);hJo=r(npt,"SEWDForSequenceClassification"),npt.forEach(t),pJo=r(u$e," (SEW-D model)"),u$e.forEach(t),uJo=i(vo),E6=n(vo,"LI",{});var _$e=s(E6);rue=n(_$e,"STRONG",{});var spt=s(rue);_Jo=r(spt,"unispeech"),spt.forEach(t),bJo=r(_$e," \u2014 "),AX=n(_$e,"A",{href:!0});var lpt=s(AX);vJo=r(lpt,"UniSpeechForSequenceClassification"),lpt.forEach(t),FJo=r(_$e," (UniSpeech model)"),_$e.forEach(t),TJo=i(vo),C6=n(vo,"LI",{});var b$e=s(C6);tue=n(b$e,"STRONG",{});var ipt=s(tue);MJo=r(ipt,"unispeech-sat"),ipt.forEach(t),EJo=r(b$e," \u2014 "),yX=n(b$e,"A",{href:!0});var dpt=s(yX);CJo=r(dpt,"UniSpeechSatForSequenceClassification"),dpt.forEach(t),wJo=r(b$e," (UniSpeechSat model)"),b$e.forEach(t),AJo=i(vo),w6=n(vo,"LI",{});var v$e=s(w6);aue=n(v$e,"STRONG",{});var cpt=s(aue);yJo=r(cpt,"wav2vec2"),cpt.forEach(t),LJo=r(v$e," \u2014 "),LX=n(v$e,"A",{href:!0});var fpt=s(LX);xJo=r(fpt,"Wav2Vec2ForSequenceClassification"),fpt.forEach(t),$Jo=r(v$e," (Wav2Vec2 model)"),v$e.forEach(t),kJo=i(vo),A6=n(vo,"LI",{});var F$e=s(A6);nue=n(F$e,"STRONG",{});var mpt=s(nue);SJo=r(mpt,"wavlm"),mpt.forEach(t),RJo=r(F$e," \u2014 "),xX=n(F$e,"A",{href:!0});var gpt=s(xX);PJo=r(gpt,"WavLMForSequenceClassification"),gpt.forEach(t),BJo=r(F$e," (WavLM model)"),F$e.forEach(t),vo.forEach(t),IJo=i(ua),y6=n(ua,"P",{});var T$e=s(y6);qJo=r(T$e,"The model is set in evaluation mode by default using "),sue=n(T$e,"CODE",{});var hpt=s(sue);NJo=r(hpt,"model.eval()"),hpt.forEach(t),jJo=r(T$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lue=n(T$e,"CODE",{});var ppt=s(lue);DJo=r(ppt,"model.train()"),ppt.forEach(t),T$e.forEach(t),GJo=i(ua),T(L6.$$.fragment,ua),ua.forEach(t),sl.forEach(t),$qe=i(f),vd=n(f,"H2",{class:!0});var Ije=s(vd);x6=n(Ije,"A",{id:!0,class:!0,href:!0});var upt=s(x6);iue=n(upt,"SPAN",{});var _pt=s(iue);T(dy.$$.fragment,_pt),_pt.forEach(t),upt.forEach(t),OJo=i(Ije),due=n(Ije,"SPAN",{});var bpt=s(due);VJo=r(bpt,"AutoModelForAudioFrameClassification"),bpt.forEach(t),Ije.forEach(t),kqe=i(f),Xo=n(f,"DIV",{class:!0});var ll=s(Xo);T(cy.$$.fragment,ll),XJo=i(ll),Fd=n(ll,"P",{});var uZ=s(Fd);zJo=r(uZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),$X=n(uZ,"A",{href:!0});var vpt=s($X);QJo=r(vpt,"from_pretrained()"),vpt.forEach(t),WJo=r(uZ," class method or the "),kX=n(uZ,"A",{href:!0});var Fpt=s(kX);HJo=r(Fpt,"from_config()"),Fpt.forEach(t),UJo=r(uZ,` class
method.`),uZ.forEach(t),JJo=i(ll),fy=n(ll,"P",{});var qje=s(fy);YJo=r(qje,"This class cannot be instantiated directly using "),cue=n(qje,"CODE",{});var Tpt=s(cue);KJo=r(Tpt,"__init__()"),Tpt.forEach(t),ZJo=r(qje," (throws an error)."),qje.forEach(t),eYo=i(ll),vt=n(ll,"DIV",{class:!0});var W3=s(vt);T(my.$$.fragment,W3),oYo=i(W3),fue=n(W3,"P",{});var Mpt=s(fue);rYo=r(Mpt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),Mpt.forEach(t),tYo=i(W3),Td=n(W3,"P",{});var _Z=s(Td);aYo=r(_Z,`Note:
Loading a model from its configuration file does `),mue=n(_Z,"STRONG",{});var Ept=s(mue);nYo=r(Ept,"not"),Ept.forEach(t),sYo=r(_Z,` load the model weights. It only affects the
model\u2019s configuration. Use `),SX=n(_Z,"A",{href:!0});var Cpt=s(SX);lYo=r(Cpt,"from_pretrained()"),Cpt.forEach(t),iYo=r(_Z," to load the model weights."),_Z.forEach(t),dYo=i(W3),T($6.$$.fragment,W3),W3.forEach(t),cYo=i(ll),co=n(ll,"DIV",{class:!0});var _a=s(co);T(gy.$$.fragment,_a),fYo=i(_a),gue=n(_a,"P",{});var wpt=s(gue);mYo=r(wpt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),wpt.forEach(t),gYo=i(_a),za=n(_a,"P",{});var H3=s(za);hYo=r(H3,"The model class to instantiate is selected based on the "),hue=n(H3,"CODE",{});var Apt=s(hue);pYo=r(Apt,"model_type"),Apt.forEach(t),uYo=r(H3,` property of the config object (either
passed as an argument or loaded from `),pue=n(H3,"CODE",{});var ypt=s(pue);_Yo=r(ypt,"pretrained_model_name_or_path"),ypt.forEach(t),bYo=r(H3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uue=n(H3,"CODE",{});var Lpt=s(uue);vYo=r(Lpt,"pretrained_model_name_or_path"),Lpt.forEach(t),FYo=r(H3,":"),H3.forEach(t),TYo=i(_a),Qa=n(_a,"UL",{});var U3=s(Qa);k6=n(U3,"LI",{});var M$e=s(k6);_ue=n(M$e,"STRONG",{});var xpt=s(_ue);MYo=r(xpt,"data2vec-audio"),xpt.forEach(t),EYo=r(M$e," \u2014 "),RX=n(M$e,"A",{href:!0});var $pt=s(RX);CYo=r($pt,"Data2VecAudioForAudioFrameClassification"),$pt.forEach(t),wYo=r(M$e," (Data2VecAudio model)"),M$e.forEach(t),AYo=i(U3),S6=n(U3,"LI",{});var E$e=s(S6);bue=n(E$e,"STRONG",{});var kpt=s(bue);yYo=r(kpt,"unispeech-sat"),kpt.forEach(t),LYo=r(E$e," \u2014 "),PX=n(E$e,"A",{href:!0});var Spt=s(PX);xYo=r(Spt,"UniSpeechSatForAudioFrameClassification"),Spt.forEach(t),$Yo=r(E$e," (UniSpeechSat model)"),E$e.forEach(t),kYo=i(U3),R6=n(U3,"LI",{});var C$e=s(R6);vue=n(C$e,"STRONG",{});var Rpt=s(vue);SYo=r(Rpt,"wav2vec2"),Rpt.forEach(t),RYo=r(C$e," \u2014 "),BX=n(C$e,"A",{href:!0});var Ppt=s(BX);PYo=r(Ppt,"Wav2Vec2ForAudioFrameClassification"),Ppt.forEach(t),BYo=r(C$e," (Wav2Vec2 model)"),C$e.forEach(t),IYo=i(U3),P6=n(U3,"LI",{});var w$e=s(P6);Fue=n(w$e,"STRONG",{});var Bpt=s(Fue);qYo=r(Bpt,"wavlm"),Bpt.forEach(t),NYo=r(w$e," \u2014 "),IX=n(w$e,"A",{href:!0});var Ipt=s(IX);jYo=r(Ipt,"WavLMForAudioFrameClassification"),Ipt.forEach(t),DYo=r(w$e," (WavLM model)"),w$e.forEach(t),U3.forEach(t),GYo=i(_a),B6=n(_a,"P",{});var A$e=s(B6);OYo=r(A$e,"The model is set in evaluation mode by default using "),Tue=n(A$e,"CODE",{});var qpt=s(Tue);VYo=r(qpt,"model.eval()"),qpt.forEach(t),XYo=r(A$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mue=n(A$e,"CODE",{});var Npt=s(Mue);zYo=r(Npt,"model.train()"),Npt.forEach(t),A$e.forEach(t),QYo=i(_a),T(I6.$$.fragment,_a),_a.forEach(t),ll.forEach(t),Sqe=i(f),Md=n(f,"H2",{class:!0});var Nje=s(Md);q6=n(Nje,"A",{id:!0,class:!0,href:!0});var jpt=s(q6);Eue=n(jpt,"SPAN",{});var Dpt=s(Eue);T(hy.$$.fragment,Dpt),Dpt.forEach(t),jpt.forEach(t),WYo=i(Nje),Cue=n(Nje,"SPAN",{});var Gpt=s(Cue);HYo=r(Gpt,"AutoModelForCTC"),Gpt.forEach(t),Nje.forEach(t),Rqe=i(f),zo=n(f,"DIV",{class:!0});var il=s(zo);T(py.$$.fragment,il),UYo=i(il),Ed=n(il,"P",{});var bZ=s(Ed);JYo=r(bZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),qX=n(bZ,"A",{href:!0});var Opt=s(qX);YYo=r(Opt,"from_pretrained()"),Opt.forEach(t),KYo=r(bZ," class method or the "),NX=n(bZ,"A",{href:!0});var Vpt=s(NX);ZYo=r(Vpt,"from_config()"),Vpt.forEach(t),eKo=r(bZ,` class
method.`),bZ.forEach(t),oKo=i(il),uy=n(il,"P",{});var jje=s(uy);rKo=r(jje,"This class cannot be instantiated directly using "),wue=n(jje,"CODE",{});var Xpt=s(wue);tKo=r(Xpt,"__init__()"),Xpt.forEach(t),aKo=r(jje," (throws an error)."),jje.forEach(t),nKo=i(il),Ft=n(il,"DIV",{class:!0});var J3=s(Ft);T(_y.$$.fragment,J3),sKo=i(J3),Aue=n(J3,"P",{});var zpt=s(Aue);lKo=r(zpt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),zpt.forEach(t),iKo=i(J3),Cd=n(J3,"P",{});var vZ=s(Cd);dKo=r(vZ,`Note:
Loading a model from its configuration file does `),yue=n(vZ,"STRONG",{});var Qpt=s(yue);cKo=r(Qpt,"not"),Qpt.forEach(t),fKo=r(vZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),jX=n(vZ,"A",{href:!0});var Wpt=s(jX);mKo=r(Wpt,"from_pretrained()"),Wpt.forEach(t),gKo=r(vZ," to load the model weights."),vZ.forEach(t),hKo=i(J3),T(N6.$$.fragment,J3),J3.forEach(t),pKo=i(il),fo=n(il,"DIV",{class:!0});var ba=s(fo);T(by.$$.fragment,ba),uKo=i(ba),Lue=n(ba,"P",{});var Hpt=s(Lue);_Ko=r(Hpt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Hpt.forEach(t),bKo=i(ba),Wa=n(ba,"P",{});var Y3=s(Wa);vKo=r(Y3,"The model class to instantiate is selected based on the "),xue=n(Y3,"CODE",{});var Upt=s(xue);FKo=r(Upt,"model_type"),Upt.forEach(t),TKo=r(Y3,` property of the config object (either
passed as an argument or loaded from `),$ue=n(Y3,"CODE",{});var Jpt=s($ue);MKo=r(Jpt,"pretrained_model_name_or_path"),Jpt.forEach(t),EKo=r(Y3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kue=n(Y3,"CODE",{});var Ypt=s(kue);CKo=r(Ypt,"pretrained_model_name_or_path"),Ypt.forEach(t),wKo=r(Y3,":"),Y3.forEach(t),AKo=i(ba),je=n(ba,"UL",{});var Fo=s(je);j6=n(Fo,"LI",{});var y$e=s(j6);Sue=n(y$e,"STRONG",{});var Kpt=s(Sue);yKo=r(Kpt,"data2vec-audio"),Kpt.forEach(t),LKo=r(y$e," \u2014 "),DX=n(y$e,"A",{href:!0});var Zpt=s(DX);xKo=r(Zpt,"Data2VecAudioForCTC"),Zpt.forEach(t),$Ko=r(y$e," (Data2VecAudio model)"),y$e.forEach(t),kKo=i(Fo),D6=n(Fo,"LI",{});var L$e=s(D6);Rue=n(L$e,"STRONG",{});var eut=s(Rue);SKo=r(eut,"hubert"),eut.forEach(t),RKo=r(L$e," \u2014 "),GX=n(L$e,"A",{href:!0});var out=s(GX);PKo=r(out,"HubertForCTC"),out.forEach(t),BKo=r(L$e," (Hubert model)"),L$e.forEach(t),IKo=i(Fo),G6=n(Fo,"LI",{});var x$e=s(G6);Pue=n(x$e,"STRONG",{});var rut=s(Pue);qKo=r(rut,"sew"),rut.forEach(t),NKo=r(x$e," \u2014 "),OX=n(x$e,"A",{href:!0});var tut=s(OX);jKo=r(tut,"SEWForCTC"),tut.forEach(t),DKo=r(x$e," (SEW model)"),x$e.forEach(t),GKo=i(Fo),O6=n(Fo,"LI",{});var $$e=s(O6);Bue=n($$e,"STRONG",{});var aut=s(Bue);OKo=r(aut,"sew-d"),aut.forEach(t),VKo=r($$e," \u2014 "),VX=n($$e,"A",{href:!0});var nut=s(VX);XKo=r(nut,"SEWDForCTC"),nut.forEach(t),zKo=r($$e," (SEW-D model)"),$$e.forEach(t),QKo=i(Fo),V6=n(Fo,"LI",{});var k$e=s(V6);Iue=n(k$e,"STRONG",{});var sut=s(Iue);WKo=r(sut,"unispeech"),sut.forEach(t),HKo=r(k$e," \u2014 "),XX=n(k$e,"A",{href:!0});var lut=s(XX);UKo=r(lut,"UniSpeechForCTC"),lut.forEach(t),JKo=r(k$e," (UniSpeech model)"),k$e.forEach(t),YKo=i(Fo),X6=n(Fo,"LI",{});var S$e=s(X6);que=n(S$e,"STRONG",{});var iut=s(que);KKo=r(iut,"unispeech-sat"),iut.forEach(t),ZKo=r(S$e," \u2014 "),zX=n(S$e,"A",{href:!0});var dut=s(zX);eZo=r(dut,"UniSpeechSatForCTC"),dut.forEach(t),oZo=r(S$e," (UniSpeechSat model)"),S$e.forEach(t),rZo=i(Fo),z6=n(Fo,"LI",{});var R$e=s(z6);Nue=n(R$e,"STRONG",{});var cut=s(Nue);tZo=r(cut,"wav2vec2"),cut.forEach(t),aZo=r(R$e," \u2014 "),QX=n(R$e,"A",{href:!0});var fut=s(QX);nZo=r(fut,"Wav2Vec2ForCTC"),fut.forEach(t),sZo=r(R$e," (Wav2Vec2 model)"),R$e.forEach(t),lZo=i(Fo),Q6=n(Fo,"LI",{});var P$e=s(Q6);jue=n(P$e,"STRONG",{});var mut=s(jue);iZo=r(mut,"wavlm"),mut.forEach(t),dZo=r(P$e," \u2014 "),WX=n(P$e,"A",{href:!0});var gut=s(WX);cZo=r(gut,"WavLMForCTC"),gut.forEach(t),fZo=r(P$e," (WavLM model)"),P$e.forEach(t),Fo.forEach(t),mZo=i(ba),W6=n(ba,"P",{});var B$e=s(W6);gZo=r(B$e,"The model is set in evaluation mode by default using "),Due=n(B$e,"CODE",{});var hut=s(Due);hZo=r(hut,"model.eval()"),hut.forEach(t),pZo=r(B$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gue=n(B$e,"CODE",{});var put=s(Gue);uZo=r(put,"model.train()"),put.forEach(t),B$e.forEach(t),_Zo=i(ba),T(H6.$$.fragment,ba),ba.forEach(t),il.forEach(t),Pqe=i(f),wd=n(f,"H2",{class:!0});var Dje=s(wd);U6=n(Dje,"A",{id:!0,class:!0,href:!0});var uut=s(U6);Oue=n(uut,"SPAN",{});var _ut=s(Oue);T(vy.$$.fragment,_ut),_ut.forEach(t),uut.forEach(t),bZo=i(Dje),Vue=n(Dje,"SPAN",{});var but=s(Vue);vZo=r(but,"AutoModelForSpeechSeq2Seq"),but.forEach(t),Dje.forEach(t),Bqe=i(f),Qo=n(f,"DIV",{class:!0});var dl=s(Qo);T(Fy.$$.fragment,dl),FZo=i(dl),Ad=n(dl,"P",{});var FZ=s(Ad);TZo=r(FZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),HX=n(FZ,"A",{href:!0});var vut=s(HX);MZo=r(vut,"from_pretrained()"),vut.forEach(t),EZo=r(FZ," class method or the "),UX=n(FZ,"A",{href:!0});var Fut=s(UX);CZo=r(Fut,"from_config()"),Fut.forEach(t),wZo=r(FZ,` class
method.`),FZ.forEach(t),AZo=i(dl),Ty=n(dl,"P",{});var Gje=s(Ty);yZo=r(Gje,"This class cannot be instantiated directly using "),Xue=n(Gje,"CODE",{});var Tut=s(Xue);LZo=r(Tut,"__init__()"),Tut.forEach(t),xZo=r(Gje," (throws an error)."),Gje.forEach(t),$Zo=i(dl),Tt=n(dl,"DIV",{class:!0});var K3=s(Tt);T(My.$$.fragment,K3),kZo=i(K3),zue=n(K3,"P",{});var Mut=s(zue);SZo=r(Mut,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Mut.forEach(t),RZo=i(K3),yd=n(K3,"P",{});var TZ=s(yd);PZo=r(TZ,`Note:
Loading a model from its configuration file does `),Que=n(TZ,"STRONG",{});var Eut=s(Que);BZo=r(Eut,"not"),Eut.forEach(t),IZo=r(TZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),JX=n(TZ,"A",{href:!0});var Cut=s(JX);qZo=r(Cut,"from_pretrained()"),Cut.forEach(t),NZo=r(TZ," to load the model weights."),TZ.forEach(t),jZo=i(K3),T(J6.$$.fragment,K3),K3.forEach(t),DZo=i(dl),mo=n(dl,"DIV",{class:!0});var va=s(mo);T(Ey.$$.fragment,va),GZo=i(va),Wue=n(va,"P",{});var wut=s(Wue);OZo=r(wut,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),wut.forEach(t),VZo=i(va),Ha=n(va,"P",{});var Z3=s(Ha);XZo=r(Z3,"The model class to instantiate is selected based on the "),Hue=n(Z3,"CODE",{});var Aut=s(Hue);zZo=r(Aut,"model_type"),Aut.forEach(t),QZo=r(Z3,` property of the config object (either
passed as an argument or loaded from `),Uue=n(Z3,"CODE",{});var yut=s(Uue);WZo=r(yut,"pretrained_model_name_or_path"),yut.forEach(t),HZo=r(Z3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jue=n(Z3,"CODE",{});var Lut=s(Jue);UZo=r(Lut,"pretrained_model_name_or_path"),Lut.forEach(t),JZo=r(Z3,":"),Z3.forEach(t),YZo=i(va),Cy=n(va,"UL",{});var Oje=s(Cy);Y6=n(Oje,"LI",{});var I$e=s(Y6);Yue=n(I$e,"STRONG",{});var xut=s(Yue);KZo=r(xut,"speech-encoder-decoder"),xut.forEach(t),ZZo=r(I$e," \u2014 "),YX=n(I$e,"A",{href:!0});var $ut=s(YX);eer=r($ut,"SpeechEncoderDecoderModel"),$ut.forEach(t),oer=r(I$e," (Speech Encoder decoder model)"),I$e.forEach(t),rer=i(Oje),K6=n(Oje,"LI",{});var q$e=s(K6);Kue=n(q$e,"STRONG",{});var kut=s(Kue);ter=r(kut,"speech_to_text"),kut.forEach(t),aer=r(q$e," \u2014 "),KX=n(q$e,"A",{href:!0});var Sut=s(KX);ner=r(Sut,"Speech2TextForConditionalGeneration"),Sut.forEach(t),ser=r(q$e," (Speech2Text model)"),q$e.forEach(t),Oje.forEach(t),ler=i(va),Z6=n(va,"P",{});var N$e=s(Z6);ier=r(N$e,"The model is set in evaluation mode by default using "),Zue=n(N$e,"CODE",{});var Rut=s(Zue);der=r(Rut,"model.eval()"),Rut.forEach(t),cer=r(N$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),e_e=n(N$e,"CODE",{});var Put=s(e_e);fer=r(Put,"model.train()"),Put.forEach(t),N$e.forEach(t),mer=i(va),T(eT.$$.fragment,va),va.forEach(t),dl.forEach(t),Iqe=i(f),Ld=n(f,"H2",{class:!0});var Vje=s(Ld);oT=n(Vje,"A",{id:!0,class:!0,href:!0});var But=s(oT);o_e=n(But,"SPAN",{});var Iut=s(o_e);T(wy.$$.fragment,Iut),Iut.forEach(t),But.forEach(t),ger=i(Vje),r_e=n(Vje,"SPAN",{});var qut=s(r_e);her=r(qut,"AutoModelForAudioXVector"),qut.forEach(t),Vje.forEach(t),qqe=i(f),Wo=n(f,"DIV",{class:!0});var cl=s(Wo);T(Ay.$$.fragment,cl),per=i(cl),xd=n(cl,"P",{});var MZ=s(xd);uer=r(MZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),ZX=n(MZ,"A",{href:!0});var Nut=s(ZX);_er=r(Nut,"from_pretrained()"),Nut.forEach(t),ber=r(MZ," class method or the "),ez=n(MZ,"A",{href:!0});var jut=s(ez);ver=r(jut,"from_config()"),jut.forEach(t),Fer=r(MZ,` class
method.`),MZ.forEach(t),Ter=i(cl),yy=n(cl,"P",{});var Xje=s(yy);Mer=r(Xje,"This class cannot be instantiated directly using "),t_e=n(Xje,"CODE",{});var Dut=s(t_e);Eer=r(Dut,"__init__()"),Dut.forEach(t),Cer=r(Xje," (throws an error)."),Xje.forEach(t),wer=i(cl),Mt=n(cl,"DIV",{class:!0});var ew=s(Mt);T(Ly.$$.fragment,ew),Aer=i(ew),a_e=n(ew,"P",{});var Gut=s(a_e);yer=r(Gut,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Gut.forEach(t),Ler=i(ew),$d=n(ew,"P",{});var EZ=s($d);xer=r(EZ,`Note:
Loading a model from its configuration file does `),n_e=n(EZ,"STRONG",{});var Out=s(n_e);$er=r(Out,"not"),Out.forEach(t),ker=r(EZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),oz=n(EZ,"A",{href:!0});var Vut=s(oz);Ser=r(Vut,"from_pretrained()"),Vut.forEach(t),Rer=r(EZ," to load the model weights."),EZ.forEach(t),Per=i(ew),T(rT.$$.fragment,ew),ew.forEach(t),Ber=i(cl),go=n(cl,"DIV",{class:!0});var Fa=s(go);T(xy.$$.fragment,Fa),Ier=i(Fa),s_e=n(Fa,"P",{});var Xut=s(s_e);qer=r(Xut,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Xut.forEach(t),Ner=i(Fa),Ua=n(Fa,"P",{});var ow=s(Ua);jer=r(ow,"The model class to instantiate is selected based on the "),l_e=n(ow,"CODE",{});var zut=s(l_e);Der=r(zut,"model_type"),zut.forEach(t),Ger=r(ow,` property of the config object (either
passed as an argument or loaded from `),i_e=n(ow,"CODE",{});var Qut=s(i_e);Oer=r(Qut,"pretrained_model_name_or_path"),Qut.forEach(t),Ver=r(ow,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d_e=n(ow,"CODE",{});var Wut=s(d_e);Xer=r(Wut,"pretrained_model_name_or_path"),Wut.forEach(t),zer=r(ow,":"),ow.forEach(t),Qer=i(Fa),Ja=n(Fa,"UL",{});var rw=s(Ja);tT=n(rw,"LI",{});var j$e=s(tT);c_e=n(j$e,"STRONG",{});var Hut=s(c_e);Wer=r(Hut,"data2vec-audio"),Hut.forEach(t),Her=r(j$e," \u2014 "),rz=n(j$e,"A",{href:!0});var Uut=s(rz);Uer=r(Uut,"Data2VecAudioForXVector"),Uut.forEach(t),Jer=r(j$e," (Data2VecAudio model)"),j$e.forEach(t),Yer=i(rw),aT=n(rw,"LI",{});var D$e=s(aT);f_e=n(D$e,"STRONG",{});var Jut=s(f_e);Ker=r(Jut,"unispeech-sat"),Jut.forEach(t),Zer=r(D$e," \u2014 "),tz=n(D$e,"A",{href:!0});var Yut=s(tz);eor=r(Yut,"UniSpeechSatForXVector"),Yut.forEach(t),oor=r(D$e," (UniSpeechSat model)"),D$e.forEach(t),ror=i(rw),nT=n(rw,"LI",{});var G$e=s(nT);m_e=n(G$e,"STRONG",{});var Kut=s(m_e);tor=r(Kut,"wav2vec2"),Kut.forEach(t),aor=r(G$e," \u2014 "),az=n(G$e,"A",{href:!0});var Zut=s(az);nor=r(Zut,"Wav2Vec2ForXVector"),Zut.forEach(t),sor=r(G$e," (Wav2Vec2 model)"),G$e.forEach(t),lor=i(rw),sT=n(rw,"LI",{});var O$e=s(sT);g_e=n(O$e,"STRONG",{});var e_t=s(g_e);ior=r(e_t,"wavlm"),e_t.forEach(t),dor=r(O$e," \u2014 "),nz=n(O$e,"A",{href:!0});var o_t=s(nz);cor=r(o_t,"WavLMForXVector"),o_t.forEach(t),mor=r(O$e," (WavLM model)"),O$e.forEach(t),rw.forEach(t),gor=i(Fa),lT=n(Fa,"P",{});var V$e=s(lT);hor=r(V$e,"The model is set in evaluation mode by default using "),h_e=n(V$e,"CODE",{});var r_t=s(h_e);por=r(r_t,"model.eval()"),r_t.forEach(t),uor=r(V$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),p_e=n(V$e,"CODE",{});var t_t=s(p_e);_or=r(t_t,"model.train()"),t_t.forEach(t),V$e.forEach(t),bor=i(Fa),T(iT.$$.fragment,Fa),Fa.forEach(t),cl.forEach(t),Nqe=i(f),kd=n(f,"H2",{class:!0});var zje=s(kd);dT=n(zje,"A",{id:!0,class:!0,href:!0});var a_t=s(dT);u_e=n(a_t,"SPAN",{});var n_t=s(u_e);T($y.$$.fragment,n_t),n_t.forEach(t),a_t.forEach(t),vor=i(zje),__e=n(zje,"SPAN",{});var s_t=s(__e);For=r(s_t,"AutoModelForMaskedImageModeling"),s_t.forEach(t),zje.forEach(t),jqe=i(f),Ho=n(f,"DIV",{class:!0});var fl=s(Ho);T(ky.$$.fragment,fl),Tor=i(fl),Sd=n(fl,"P",{});var CZ=s(Sd);Mor=r(CZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),sz=n(CZ,"A",{href:!0});var l_t=s(sz);Eor=r(l_t,"from_pretrained()"),l_t.forEach(t),Cor=r(CZ," class method or the "),lz=n(CZ,"A",{href:!0});var i_t=s(lz);wor=r(i_t,"from_config()"),i_t.forEach(t),Aor=r(CZ,` class
method.`),CZ.forEach(t),yor=i(fl),Sy=n(fl,"P",{});var Qje=s(Sy);Lor=r(Qje,"This class cannot be instantiated directly using "),b_e=n(Qje,"CODE",{});var d_t=s(b_e);xor=r(d_t,"__init__()"),d_t.forEach(t),$or=r(Qje," (throws an error)."),Qje.forEach(t),kor=i(fl),Et=n(fl,"DIV",{class:!0});var tw=s(Et);T(Ry.$$.fragment,tw),Sor=i(tw),v_e=n(tw,"P",{});var c_t=s(v_e);Ror=r(c_t,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),c_t.forEach(t),Por=i(tw),Rd=n(tw,"P",{});var wZ=s(Rd);Bor=r(wZ,`Note:
Loading a model from its configuration file does `),F_e=n(wZ,"STRONG",{});var f_t=s(F_e);Ior=r(f_t,"not"),f_t.forEach(t),qor=r(wZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),iz=n(wZ,"A",{href:!0});var m_t=s(iz);Nor=r(m_t,"from_pretrained()"),m_t.forEach(t),jor=r(wZ," to load the model weights."),wZ.forEach(t),Dor=i(tw),T(cT.$$.fragment,tw),tw.forEach(t),Gor=i(fl),ho=n(fl,"DIV",{class:!0});var Ta=s(ho);T(Py.$$.fragment,Ta),Oor=i(Ta),T_e=n(Ta,"P",{});var g_t=s(T_e);Vor=r(g_t,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),g_t.forEach(t),Xor=i(Ta),Ya=n(Ta,"P",{});var aw=s(Ya);zor=r(aw,"The model class to instantiate is selected based on the "),M_e=n(aw,"CODE",{});var h_t=s(M_e);Qor=r(h_t,"model_type"),h_t.forEach(t),Wor=r(aw,` property of the config object (either
passed as an argument or loaded from `),E_e=n(aw,"CODE",{});var p_t=s(E_e);Hor=r(p_t,"pretrained_model_name_or_path"),p_t.forEach(t),Uor=r(aw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C_e=n(aw,"CODE",{});var u_t=s(C_e);Jor=r(u_t,"pretrained_model_name_or_path"),u_t.forEach(t),Yor=r(aw,":"),aw.forEach(t),Kor=i(Ta),Pd=n(Ta,"UL",{});var AZ=s(Pd);fT=n(AZ,"LI",{});var X$e=s(fT);w_e=n(X$e,"STRONG",{});var __t=s(w_e);Zor=r(__t,"deit"),__t.forEach(t),err=r(X$e," \u2014 "),dz=n(X$e,"A",{href:!0});var b_t=s(dz);orr=r(b_t,"DeiTForMaskedImageModeling"),b_t.forEach(t),rrr=r(X$e," (DeiT model)"),X$e.forEach(t),trr=i(AZ),mT=n(AZ,"LI",{});var z$e=s(mT);A_e=n(z$e,"STRONG",{});var v_t=s(A_e);arr=r(v_t,"swin"),v_t.forEach(t),nrr=r(z$e," \u2014 "),cz=n(z$e,"A",{href:!0});var F_t=s(cz);srr=r(F_t,"SwinForMaskedImageModeling"),F_t.forEach(t),lrr=r(z$e," (Swin model)"),z$e.forEach(t),irr=i(AZ),gT=n(AZ,"LI",{});var Q$e=s(gT);y_e=n(Q$e,"STRONG",{});var T_t=s(y_e);drr=r(T_t,"vit"),T_t.forEach(t),crr=r(Q$e," \u2014 "),fz=n(Q$e,"A",{href:!0});var M_t=s(fz);frr=r(M_t,"ViTForMaskedImageModeling"),M_t.forEach(t),mrr=r(Q$e," (ViT model)"),Q$e.forEach(t),AZ.forEach(t),grr=i(Ta),hT=n(Ta,"P",{});var W$e=s(hT);hrr=r(W$e,"The model is set in evaluation mode by default using "),L_e=n(W$e,"CODE",{});var E_t=s(L_e);prr=r(E_t,"model.eval()"),E_t.forEach(t),urr=r(W$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),x_e=n(W$e,"CODE",{});var C_t=s(x_e);_rr=r(C_t,"model.train()"),C_t.forEach(t),W$e.forEach(t),brr=i(Ta),T(pT.$$.fragment,Ta),Ta.forEach(t),fl.forEach(t),Dqe=i(f),Bd=n(f,"H2",{class:!0});var Wje=s(Bd);uT=n(Wje,"A",{id:!0,class:!0,href:!0});var w_t=s(uT);$_e=n(w_t,"SPAN",{});var A_t=s($_e);T(By.$$.fragment,A_t),A_t.forEach(t),w_t.forEach(t),vrr=i(Wje),k_e=n(Wje,"SPAN",{});var y_t=s(k_e);Frr=r(y_t,"AutoModelForObjectDetection"),y_t.forEach(t),Wje.forEach(t),Gqe=i(f),Uo=n(f,"DIV",{class:!0});var ml=s(Uo);T(Iy.$$.fragment,ml),Trr=i(ml),Id=n(ml,"P",{});var yZ=s(Id);Mrr=r(yZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),mz=n(yZ,"A",{href:!0});var L_t=s(mz);Err=r(L_t,"from_pretrained()"),L_t.forEach(t),Crr=r(yZ," class method or the "),gz=n(yZ,"A",{href:!0});var x_t=s(gz);wrr=r(x_t,"from_config()"),x_t.forEach(t),Arr=r(yZ,` class
method.`),yZ.forEach(t),yrr=i(ml),qy=n(ml,"P",{});var Hje=s(qy);Lrr=r(Hje,"This class cannot be instantiated directly using "),S_e=n(Hje,"CODE",{});var $_t=s(S_e);xrr=r($_t,"__init__()"),$_t.forEach(t),$rr=r(Hje," (throws an error)."),Hje.forEach(t),krr=i(ml),Ct=n(ml,"DIV",{class:!0});var nw=s(Ct);T(Ny.$$.fragment,nw),Srr=i(nw),R_e=n(nw,"P",{});var k_t=s(R_e);Rrr=r(k_t,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),k_t.forEach(t),Prr=i(nw),qd=n(nw,"P",{});var LZ=s(qd);Brr=r(LZ,`Note:
Loading a model from its configuration file does `),P_e=n(LZ,"STRONG",{});var S_t=s(P_e);Irr=r(S_t,"not"),S_t.forEach(t),qrr=r(LZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),hz=n(LZ,"A",{href:!0});var R_t=s(hz);Nrr=r(R_t,"from_pretrained()"),R_t.forEach(t),jrr=r(LZ," to load the model weights."),LZ.forEach(t),Drr=i(nw),T(_T.$$.fragment,nw),nw.forEach(t),Grr=i(ml),po=n(ml,"DIV",{class:!0});var Ma=s(po);T(jy.$$.fragment,Ma),Orr=i(Ma),B_e=n(Ma,"P",{});var P_t=s(B_e);Vrr=r(P_t,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),P_t.forEach(t),Xrr=i(Ma),Ka=n(Ma,"P",{});var sw=s(Ka);zrr=r(sw,"The model class to instantiate is selected based on the "),I_e=n(sw,"CODE",{});var B_t=s(I_e);Qrr=r(B_t,"model_type"),B_t.forEach(t),Wrr=r(sw,` property of the config object (either
passed as an argument or loaded from `),q_e=n(sw,"CODE",{});var I_t=s(q_e);Hrr=r(I_t,"pretrained_model_name_or_path"),I_t.forEach(t),Urr=r(sw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N_e=n(sw,"CODE",{});var q_t=s(N_e);Jrr=r(q_t,"pretrained_model_name_or_path"),q_t.forEach(t),Yrr=r(sw,":"),sw.forEach(t),Krr=i(Ma),Dy=n(Ma,"UL",{});var Uje=s(Dy);bT=n(Uje,"LI",{});var H$e=s(bT);j_e=n(H$e,"STRONG",{});var N_t=s(j_e);Zrr=r(N_t,"detr"),N_t.forEach(t),etr=r(H$e," \u2014 "),pz=n(H$e,"A",{href:!0});var j_t=s(pz);otr=r(j_t,"DetrForObjectDetection"),j_t.forEach(t),rtr=r(H$e," (DETR model)"),H$e.forEach(t),ttr=i(Uje),vT=n(Uje,"LI",{});var U$e=s(vT);D_e=n(U$e,"STRONG",{});var D_t=s(D_e);atr=r(D_t,"yolos"),D_t.forEach(t),ntr=r(U$e," \u2014 "),uz=n(U$e,"A",{href:!0});var G_t=s(uz);str=r(G_t,"YolosForObjectDetection"),G_t.forEach(t),ltr=r(U$e," (YOLOS model)"),U$e.forEach(t),Uje.forEach(t),itr=i(Ma),FT=n(Ma,"P",{});var J$e=s(FT);dtr=r(J$e,"The model is set in evaluation mode by default using "),G_e=n(J$e,"CODE",{});var O_t=s(G_e);ctr=r(O_t,"model.eval()"),O_t.forEach(t),ftr=r(J$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),O_e=n(J$e,"CODE",{});var V_t=s(O_e);mtr=r(V_t,"model.train()"),V_t.forEach(t),J$e.forEach(t),gtr=i(Ma),T(TT.$$.fragment,Ma),Ma.forEach(t),ml.forEach(t),Oqe=i(f),Nd=n(f,"H2",{class:!0});var Jje=s(Nd);MT=n(Jje,"A",{id:!0,class:!0,href:!0});var X_t=s(MT);V_e=n(X_t,"SPAN",{});var z_t=s(V_e);T(Gy.$$.fragment,z_t),z_t.forEach(t),X_t.forEach(t),htr=i(Jje),X_e=n(Jje,"SPAN",{});var Q_t=s(X_e);ptr=r(Q_t,"AutoModelForImageSegmentation"),Q_t.forEach(t),Jje.forEach(t),Vqe=i(f),Jo=n(f,"DIV",{class:!0});var gl=s(Jo);T(Oy.$$.fragment,gl),utr=i(gl),jd=n(gl,"P",{});var xZ=s(jd);_tr=r(xZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),_z=n(xZ,"A",{href:!0});var W_t=s(_z);btr=r(W_t,"from_pretrained()"),W_t.forEach(t),vtr=r(xZ," class method or the "),bz=n(xZ,"A",{href:!0});var H_t=s(bz);Ftr=r(H_t,"from_config()"),H_t.forEach(t),Ttr=r(xZ,` class
method.`),xZ.forEach(t),Mtr=i(gl),Vy=n(gl,"P",{});var Yje=s(Vy);Etr=r(Yje,"This class cannot be instantiated directly using "),z_e=n(Yje,"CODE",{});var U_t=s(z_e);Ctr=r(U_t,"__init__()"),U_t.forEach(t),wtr=r(Yje," (throws an error)."),Yje.forEach(t),Atr=i(gl),wt=n(gl,"DIV",{class:!0});var lw=s(wt);T(Xy.$$.fragment,lw),ytr=i(lw),Q_e=n(lw,"P",{});var J_t=s(Q_e);Ltr=r(J_t,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),J_t.forEach(t),xtr=i(lw),Dd=n(lw,"P",{});var $Z=s(Dd);$tr=r($Z,`Note:
Loading a model from its configuration file does `),W_e=n($Z,"STRONG",{});var Y_t=s(W_e);ktr=r(Y_t,"not"),Y_t.forEach(t),Str=r($Z,` load the model weights. It only affects the
model\u2019s configuration. Use `),vz=n($Z,"A",{href:!0});var K_t=s(vz);Rtr=r(K_t,"from_pretrained()"),K_t.forEach(t),Ptr=r($Z," to load the model weights."),$Z.forEach(t),Btr=i(lw),T(ET.$$.fragment,lw),lw.forEach(t),Itr=i(gl),uo=n(gl,"DIV",{class:!0});var Ea=s(uo);T(zy.$$.fragment,Ea),qtr=i(Ea),H_e=n(Ea,"P",{});var Z_t=s(H_e);Ntr=r(Z_t,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),Z_t.forEach(t),jtr=i(Ea),Za=n(Ea,"P",{});var iw=s(Za);Dtr=r(iw,"The model class to instantiate is selected based on the "),U_e=n(iw,"CODE",{});var e2t=s(U_e);Gtr=r(e2t,"model_type"),e2t.forEach(t),Otr=r(iw,` property of the config object (either
passed as an argument or loaded from `),J_e=n(iw,"CODE",{});var o2t=s(J_e);Vtr=r(o2t,"pretrained_model_name_or_path"),o2t.forEach(t),Xtr=r(iw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Y_e=n(iw,"CODE",{});var r2t=s(Y_e);ztr=r(r2t,"pretrained_model_name_or_path"),r2t.forEach(t),Qtr=r(iw,":"),iw.forEach(t),Wtr=i(Ea),K_e=n(Ea,"UL",{});var t2t=s(K_e);CT=n(t2t,"LI",{});var Y$e=s(CT);Z_e=n(Y$e,"STRONG",{});var a2t=s(Z_e);Htr=r(a2t,"detr"),a2t.forEach(t),Utr=r(Y$e," \u2014 "),Fz=n(Y$e,"A",{href:!0});var n2t=s(Fz);Jtr=r(n2t,"DetrForSegmentation"),n2t.forEach(t),Ytr=r(Y$e," (DETR model)"),Y$e.forEach(t),t2t.forEach(t),Ktr=i(Ea),wT=n(Ea,"P",{});var K$e=s(wT);Ztr=r(K$e,"The model is set in evaluation mode by default using "),e2e=n(K$e,"CODE",{});var s2t=s(e2e);ear=r(s2t,"model.eval()"),s2t.forEach(t),oar=r(K$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o2e=n(K$e,"CODE",{});var l2t=s(o2e);rar=r(l2t,"model.train()"),l2t.forEach(t),K$e.forEach(t),tar=i(Ea),T(AT.$$.fragment,Ea),Ea.forEach(t),gl.forEach(t),Xqe=i(f),Gd=n(f,"H2",{class:!0});var Kje=s(Gd);yT=n(Kje,"A",{id:!0,class:!0,href:!0});var i2t=s(yT);r2e=n(i2t,"SPAN",{});var d2t=s(r2e);T(Qy.$$.fragment,d2t),d2t.forEach(t),i2t.forEach(t),aar=i(Kje),t2e=n(Kje,"SPAN",{});var c2t=s(t2e);nar=r(c2t,"AutoModelForSemanticSegmentation"),c2t.forEach(t),Kje.forEach(t),zqe=i(f),Yo=n(f,"DIV",{class:!0});var hl=s(Yo);T(Wy.$$.fragment,hl),sar=i(hl),Od=n(hl,"P",{});var kZ=s(Od);lar=r(kZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Tz=n(kZ,"A",{href:!0});var f2t=s(Tz);iar=r(f2t,"from_pretrained()"),f2t.forEach(t),dar=r(kZ," class method or the "),Mz=n(kZ,"A",{href:!0});var m2t=s(Mz);car=r(m2t,"from_config()"),m2t.forEach(t),far=r(kZ,` class
method.`),kZ.forEach(t),mar=i(hl),Hy=n(hl,"P",{});var Zje=s(Hy);gar=r(Zje,"This class cannot be instantiated directly using "),a2e=n(Zje,"CODE",{});var g2t=s(a2e);har=r(g2t,"__init__()"),g2t.forEach(t),par=r(Zje," (throws an error)."),Zje.forEach(t),uar=i(hl),At=n(hl,"DIV",{class:!0});var dw=s(At);T(Uy.$$.fragment,dw),_ar=i(dw),n2e=n(dw,"P",{});var h2t=s(n2e);bar=r(h2t,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),h2t.forEach(t),Far=i(dw),Vd=n(dw,"P",{});var SZ=s(Vd);Tar=r(SZ,`Note:
Loading a model from its configuration file does `),s2e=n(SZ,"STRONG",{});var p2t=s(s2e);Mar=r(p2t,"not"),p2t.forEach(t),Ear=r(SZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ez=n(SZ,"A",{href:!0});var u2t=s(Ez);Car=r(u2t,"from_pretrained()"),u2t.forEach(t),war=r(SZ," to load the model weights."),SZ.forEach(t),Aar=i(dw),T(LT.$$.fragment,dw),dw.forEach(t),yar=i(hl),_o=n(hl,"DIV",{class:!0});var Ca=s(_o);T(Jy.$$.fragment,Ca),Lar=i(Ca),l2e=n(Ca,"P",{});var _2t=s(l2e);xar=r(_2t,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),_2t.forEach(t),$ar=i(Ca),en=n(Ca,"P",{});var cw=s(en);kar=r(cw,"The model class to instantiate is selected based on the "),i2e=n(cw,"CODE",{});var b2t=s(i2e);Sar=r(b2t,"model_type"),b2t.forEach(t),Rar=r(cw,` property of the config object (either
passed as an argument or loaded from `),d2e=n(cw,"CODE",{});var v2t=s(d2e);Par=r(v2t,"pretrained_model_name_or_path"),v2t.forEach(t),Bar=r(cw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c2e=n(cw,"CODE",{});var F2t=s(c2e);Iar=r(F2t,"pretrained_model_name_or_path"),F2t.forEach(t),qar=r(cw,":"),cw.forEach(t),Nar=i(Ca),on=n(Ca,"UL",{});var fw=s(on);xT=n(fw,"LI",{});var Z$e=s(xT);f2e=n(Z$e,"STRONG",{});var T2t=s(f2e);jar=r(T2t,"beit"),T2t.forEach(t),Dar=r(Z$e," \u2014 "),Cz=n(Z$e,"A",{href:!0});var M2t=s(Cz);Gar=r(M2t,"BeitForSemanticSegmentation"),M2t.forEach(t),Oar=r(Z$e," (BEiT model)"),Z$e.forEach(t),Var=i(fw),$T=n(fw,"LI",{});var eke=s($T);m2e=n(eke,"STRONG",{});var E2t=s(m2e);Xar=r(E2t,"data2vec-vision"),E2t.forEach(t),zar=r(eke," \u2014 "),wz=n(eke,"A",{href:!0});var C2t=s(wz);Qar=r(C2t,"Data2VecVisionForSemanticSegmentation"),C2t.forEach(t),War=r(eke," (Data2VecVision model)"),eke.forEach(t),Har=i(fw),kT=n(fw,"LI",{});var oke=s(kT);g2e=n(oke,"STRONG",{});var w2t=s(g2e);Uar=r(w2t,"dpt"),w2t.forEach(t),Jar=r(oke," \u2014 "),Az=n(oke,"A",{href:!0});var A2t=s(Az);Yar=r(A2t,"DPTForSemanticSegmentation"),A2t.forEach(t),Kar=r(oke," (DPT model)"),oke.forEach(t),Zar=i(fw),ST=n(fw,"LI",{});var rke=s(ST);h2e=n(rke,"STRONG",{});var y2t=s(h2e);enr=r(y2t,"segformer"),y2t.forEach(t),onr=r(rke," \u2014 "),yz=n(rke,"A",{href:!0});var L2t=s(yz);rnr=r(L2t,"SegformerForSemanticSegmentation"),L2t.forEach(t),tnr=r(rke," (SegFormer model)"),rke.forEach(t),fw.forEach(t),anr=i(Ca),RT=n(Ca,"P",{});var tke=s(RT);nnr=r(tke,"The model is set in evaluation mode by default using "),p2e=n(tke,"CODE",{});var x2t=s(p2e);snr=r(x2t,"model.eval()"),x2t.forEach(t),lnr=r(tke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u2e=n(tke,"CODE",{});var $2t=s(u2e);inr=r($2t,"model.train()"),$2t.forEach(t),tke.forEach(t),dnr=i(Ca),T(PT.$$.fragment,Ca),Ca.forEach(t),hl.forEach(t),Qqe=i(f),Xd=n(f,"H2",{class:!0});var eDe=s(Xd);BT=n(eDe,"A",{id:!0,class:!0,href:!0});var k2t=s(BT);_2e=n(k2t,"SPAN",{});var S2t=s(_2e);T(Yy.$$.fragment,S2t),S2t.forEach(t),k2t.forEach(t),cnr=i(eDe),b2e=n(eDe,"SPAN",{});var R2t=s(b2e);fnr=r(R2t,"AutoModelForInstanceSegmentation"),R2t.forEach(t),eDe.forEach(t),Wqe=i(f),Ko=n(f,"DIV",{class:!0});var pl=s(Ko);T(Ky.$$.fragment,pl),mnr=i(pl),zd=n(pl,"P",{});var RZ=s(zd);gnr=r(RZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Lz=n(RZ,"A",{href:!0});var P2t=s(Lz);hnr=r(P2t,"from_pretrained()"),P2t.forEach(t),pnr=r(RZ," class method or the "),xz=n(RZ,"A",{href:!0});var B2t=s(xz);unr=r(B2t,"from_config()"),B2t.forEach(t),_nr=r(RZ,` class
method.`),RZ.forEach(t),bnr=i(pl),Zy=n(pl,"P",{});var oDe=s(Zy);vnr=r(oDe,"This class cannot be instantiated directly using "),v2e=n(oDe,"CODE",{});var I2t=s(v2e);Fnr=r(I2t,"__init__()"),I2t.forEach(t),Tnr=r(oDe," (throws an error)."),oDe.forEach(t),Mnr=i(pl),yt=n(pl,"DIV",{class:!0});var mw=s(yt);T(eL.$$.fragment,mw),Enr=i(mw),F2e=n(mw,"P",{});var q2t=s(F2e);Cnr=r(q2t,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),q2t.forEach(t),wnr=i(mw),Qd=n(mw,"P",{});var PZ=s(Qd);Anr=r(PZ,`Note:
Loading a model from its configuration file does `),T2e=n(PZ,"STRONG",{});var N2t=s(T2e);ynr=r(N2t,"not"),N2t.forEach(t),Lnr=r(PZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),$z=n(PZ,"A",{href:!0});var j2t=s($z);xnr=r(j2t,"from_pretrained()"),j2t.forEach(t),$nr=r(PZ," to load the model weights."),PZ.forEach(t),knr=i(mw),T(IT.$$.fragment,mw),mw.forEach(t),Snr=i(pl),bo=n(pl,"DIV",{class:!0});var wa=s(bo);T(oL.$$.fragment,wa),Rnr=i(wa),M2e=n(wa,"P",{});var D2t=s(M2e);Pnr=r(D2t,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),D2t.forEach(t),Bnr=i(wa),rn=n(wa,"P",{});var gw=s(rn);Inr=r(gw,"The model class to instantiate is selected based on the "),E2e=n(gw,"CODE",{});var G2t=s(E2e);qnr=r(G2t,"model_type"),G2t.forEach(t),Nnr=r(gw,` property of the config object (either
passed as an argument or loaded from `),C2e=n(gw,"CODE",{});var O2t=s(C2e);jnr=r(O2t,"pretrained_model_name_or_path"),O2t.forEach(t),Dnr=r(gw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w2e=n(gw,"CODE",{});var V2t=s(w2e);Gnr=r(V2t,"pretrained_model_name_or_path"),V2t.forEach(t),Onr=r(gw,":"),gw.forEach(t),Vnr=i(wa),A2e=n(wa,"UL",{});var X2t=s(A2e);qT=n(X2t,"LI",{});var ake=s(qT);y2e=n(ake,"STRONG",{});var z2t=s(y2e);Xnr=r(z2t,"maskformer"),z2t.forEach(t),znr=r(ake," \u2014 "),kz=n(ake,"A",{href:!0});var Q2t=s(kz);Qnr=r(Q2t,"MaskFormerForInstanceSegmentation"),Q2t.forEach(t),Wnr=r(ake," (MaskFormer model)"),ake.forEach(t),X2t.forEach(t),Hnr=i(wa),NT=n(wa,"P",{});var nke=s(NT);Unr=r(nke,"The model is set in evaluation mode by default using "),L2e=n(nke,"CODE",{});var W2t=s(L2e);Jnr=r(W2t,"model.eval()"),W2t.forEach(t),Ynr=r(nke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),x2e=n(nke,"CODE",{});var H2t=s(x2e);Knr=r(H2t,"model.train()"),H2t.forEach(t),nke.forEach(t),Znr=i(wa),T(jT.$$.fragment,wa),wa.forEach(t),pl.forEach(t),Hqe=i(f),Wd=n(f,"H2",{class:!0});var rDe=s(Wd);DT=n(rDe,"A",{id:!0,class:!0,href:!0});var U2t=s(DT);$2e=n(U2t,"SPAN",{});var J2t=s($2e);T(rL.$$.fragment,J2t),J2t.forEach(t),U2t.forEach(t),esr=i(rDe),k2e=n(rDe,"SPAN",{});var Y2t=s(k2e);osr=r(Y2t,"TFAutoModel"),Y2t.forEach(t),rDe.forEach(t),Uqe=i(f),Zo=n(f,"DIV",{class:!0});var ul=s(Zo);T(tL.$$.fragment,ul),rsr=i(ul),Hd=n(ul,"P",{});var BZ=s(Hd);tsr=r(BZ,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Sz=n(BZ,"A",{href:!0});var K2t=s(Sz);asr=r(K2t,"from_pretrained()"),K2t.forEach(t),nsr=r(BZ," class method or the "),Rz=n(BZ,"A",{href:!0});var Z2t=s(Rz);ssr=r(Z2t,"from_config()"),Z2t.forEach(t),lsr=r(BZ,` class
method.`),BZ.forEach(t),isr=i(ul),aL=n(ul,"P",{});var tDe=s(aL);dsr=r(tDe,"This class cannot be instantiated directly using "),S2e=n(tDe,"CODE",{});var e1t=s(S2e);csr=r(e1t,"__init__()"),e1t.forEach(t),fsr=r(tDe," (throws an error)."),tDe.forEach(t),msr=i(ul),Lt=n(ul,"DIV",{class:!0});var hw=s(Lt);T(nL.$$.fragment,hw),gsr=i(hw),R2e=n(hw,"P",{});var o1t=s(R2e);hsr=r(o1t,"Instantiates one of the base model classes of the library from a configuration."),o1t.forEach(t),psr=i(hw),Ud=n(hw,"P",{});var IZ=s(Ud);usr=r(IZ,`Note:
Loading a model from its configuration file does `),P2e=n(IZ,"STRONG",{});var r1t=s(P2e);_sr=r(r1t,"not"),r1t.forEach(t),bsr=r(IZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Pz=n(IZ,"A",{href:!0});var t1t=s(Pz);vsr=r(t1t,"from_pretrained()"),t1t.forEach(t),Fsr=r(IZ," to load the model weights."),IZ.forEach(t),Tsr=i(hw),T(GT.$$.fragment,hw),hw.forEach(t),Msr=i(ul),yr=n(ul,"DIV",{class:!0});var _l=s(yr);T(sL.$$.fragment,_l),Esr=i(_l),B2e=n(_l,"P",{});var a1t=s(B2e);Csr=r(a1t,"Instantiate one of the base model classes of the library from a pretrained model."),a1t.forEach(t),wsr=i(_l),tn=n(_l,"P",{});var pw=s(tn);Asr=r(pw,"The model class to instantiate is selected based on the "),I2e=n(pw,"CODE",{});var n1t=s(I2e);ysr=r(n1t,"model_type"),n1t.forEach(t),Lsr=r(pw,` property of the config object (either
passed as an argument or loaded from `),q2e=n(pw,"CODE",{});var s1t=s(q2e);xsr=r(s1t,"pretrained_model_name_or_path"),s1t.forEach(t),$sr=r(pw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N2e=n(pw,"CODE",{});var l1t=s(N2e);ksr=r(l1t,"pretrained_model_name_or_path"),l1t.forEach(t),Ssr=r(pw,":"),pw.forEach(t),Rsr=i(_l),j=n(_l,"UL",{});var D=s(j);OT=n(D,"LI",{});var ske=s(OT);j2e=n(ske,"STRONG",{});var i1t=s(j2e);Psr=r(i1t,"albert"),i1t.forEach(t),Bsr=r(ske," \u2014 "),Bz=n(ske,"A",{href:!0});var d1t=s(Bz);Isr=r(d1t,"TFAlbertModel"),d1t.forEach(t),qsr=r(ske," (ALBERT model)"),ske.forEach(t),Nsr=i(D),VT=n(D,"LI",{});var lke=s(VT);D2e=n(lke,"STRONG",{});var c1t=s(D2e);jsr=r(c1t,"bart"),c1t.forEach(t),Dsr=r(lke," \u2014 "),Iz=n(lke,"A",{href:!0});var f1t=s(Iz);Gsr=r(f1t,"TFBartModel"),f1t.forEach(t),Osr=r(lke," (BART model)"),lke.forEach(t),Vsr=i(D),XT=n(D,"LI",{});var ike=s(XT);G2e=n(ike,"STRONG",{});var m1t=s(G2e);Xsr=r(m1t,"bert"),m1t.forEach(t),zsr=r(ike," \u2014 "),qz=n(ike,"A",{href:!0});var g1t=s(qz);Qsr=r(g1t,"TFBertModel"),g1t.forEach(t),Wsr=r(ike," (BERT model)"),ike.forEach(t),Hsr=i(D),zT=n(D,"LI",{});var dke=s(zT);O2e=n(dke,"STRONG",{});var h1t=s(O2e);Usr=r(h1t,"blenderbot"),h1t.forEach(t),Jsr=r(dke," \u2014 "),Nz=n(dke,"A",{href:!0});var p1t=s(Nz);Ysr=r(p1t,"TFBlenderbotModel"),p1t.forEach(t),Ksr=r(dke," (Blenderbot model)"),dke.forEach(t),Zsr=i(D),QT=n(D,"LI",{});var cke=s(QT);V2e=n(cke,"STRONG",{});var u1t=s(V2e);elr=r(u1t,"blenderbot-small"),u1t.forEach(t),olr=r(cke," \u2014 "),jz=n(cke,"A",{href:!0});var _1t=s(jz);rlr=r(_1t,"TFBlenderbotSmallModel"),_1t.forEach(t),tlr=r(cke," (BlenderbotSmall model)"),cke.forEach(t),alr=i(D),WT=n(D,"LI",{});var fke=s(WT);X2e=n(fke,"STRONG",{});var b1t=s(X2e);nlr=r(b1t,"camembert"),b1t.forEach(t),slr=r(fke," \u2014 "),Dz=n(fke,"A",{href:!0});var v1t=s(Dz);llr=r(v1t,"TFCamembertModel"),v1t.forEach(t),ilr=r(fke," (CamemBERT model)"),fke.forEach(t),dlr=i(D),HT=n(D,"LI",{});var mke=s(HT);z2e=n(mke,"STRONG",{});var F1t=s(z2e);clr=r(F1t,"clip"),F1t.forEach(t),flr=r(mke," \u2014 "),Gz=n(mke,"A",{href:!0});var T1t=s(Gz);mlr=r(T1t,"TFCLIPModel"),T1t.forEach(t),glr=r(mke," (CLIP model)"),mke.forEach(t),hlr=i(D),UT=n(D,"LI",{});var gke=s(UT);Q2e=n(gke,"STRONG",{});var M1t=s(Q2e);plr=r(M1t,"convbert"),M1t.forEach(t),ulr=r(gke," \u2014 "),Oz=n(gke,"A",{href:!0});var E1t=s(Oz);_lr=r(E1t,"TFConvBertModel"),E1t.forEach(t),blr=r(gke," (ConvBERT model)"),gke.forEach(t),vlr=i(D),JT=n(D,"LI",{});var hke=s(JT);W2e=n(hke,"STRONG",{});var C1t=s(W2e);Flr=r(C1t,"convnext"),C1t.forEach(t),Tlr=r(hke," \u2014 "),Vz=n(hke,"A",{href:!0});var w1t=s(Vz);Mlr=r(w1t,"TFConvNextModel"),w1t.forEach(t),Elr=r(hke," (ConvNext model)"),hke.forEach(t),Clr=i(D),YT=n(D,"LI",{});var pke=s(YT);H2e=n(pke,"STRONG",{});var A1t=s(H2e);wlr=r(A1t,"ctrl"),A1t.forEach(t),Alr=r(pke," \u2014 "),Xz=n(pke,"A",{href:!0});var y1t=s(Xz);ylr=r(y1t,"TFCTRLModel"),y1t.forEach(t),Llr=r(pke," (CTRL model)"),pke.forEach(t),xlr=i(D),KT=n(D,"LI",{});var uke=s(KT);U2e=n(uke,"STRONG",{});var L1t=s(U2e);$lr=r(L1t,"data2vec-vision"),L1t.forEach(t),klr=r(uke," \u2014 "),zz=n(uke,"A",{href:!0});var x1t=s(zz);Slr=r(x1t,"TFData2VecVisionModel"),x1t.forEach(t),Rlr=r(uke," (Data2VecVision model)"),uke.forEach(t),Plr=i(D),ZT=n(D,"LI",{});var _ke=s(ZT);J2e=n(_ke,"STRONG",{});var $1t=s(J2e);Blr=r($1t,"deberta"),$1t.forEach(t),Ilr=r(_ke," \u2014 "),Qz=n(_ke,"A",{href:!0});var k1t=s(Qz);qlr=r(k1t,"TFDebertaModel"),k1t.forEach(t),Nlr=r(_ke," (DeBERTa model)"),_ke.forEach(t),jlr=i(D),e8=n(D,"LI",{});var bke=s(e8);Y2e=n(bke,"STRONG",{});var S1t=s(Y2e);Dlr=r(S1t,"deberta-v2"),S1t.forEach(t),Glr=r(bke," \u2014 "),Wz=n(bke,"A",{href:!0});var R1t=s(Wz);Olr=r(R1t,"TFDebertaV2Model"),R1t.forEach(t),Vlr=r(bke," (DeBERTa-v2 model)"),bke.forEach(t),Xlr=i(D),o8=n(D,"LI",{});var vke=s(o8);K2e=n(vke,"STRONG",{});var P1t=s(K2e);zlr=r(P1t,"distilbert"),P1t.forEach(t),Qlr=r(vke," \u2014 "),Hz=n(vke,"A",{href:!0});var B1t=s(Hz);Wlr=r(B1t,"TFDistilBertModel"),B1t.forEach(t),Hlr=r(vke," (DistilBERT model)"),vke.forEach(t),Ulr=i(D),r8=n(D,"LI",{});var Fke=s(r8);Z2e=n(Fke,"STRONG",{});var I1t=s(Z2e);Jlr=r(I1t,"dpr"),I1t.forEach(t),Ylr=r(Fke," \u2014 "),Uz=n(Fke,"A",{href:!0});var q1t=s(Uz);Klr=r(q1t,"TFDPRQuestionEncoder"),q1t.forEach(t),Zlr=r(Fke," (DPR model)"),Fke.forEach(t),eir=i(D),t8=n(D,"LI",{});var Tke=s(t8);e1e=n(Tke,"STRONG",{});var N1t=s(e1e);oir=r(N1t,"electra"),N1t.forEach(t),rir=r(Tke," \u2014 "),Jz=n(Tke,"A",{href:!0});var j1t=s(Jz);tir=r(j1t,"TFElectraModel"),j1t.forEach(t),air=r(Tke," (ELECTRA model)"),Tke.forEach(t),nir=i(D),a8=n(D,"LI",{});var Mke=s(a8);o1e=n(Mke,"STRONG",{});var D1t=s(o1e);sir=r(D1t,"flaubert"),D1t.forEach(t),lir=r(Mke," \u2014 "),Yz=n(Mke,"A",{href:!0});var G1t=s(Yz);iir=r(G1t,"TFFlaubertModel"),G1t.forEach(t),dir=r(Mke," (FlauBERT model)"),Mke.forEach(t),cir=i(D),Ds=n(D,"LI",{});var N$=s(Ds);r1e=n(N$,"STRONG",{});var O1t=s(r1e);fir=r(O1t,"funnel"),O1t.forEach(t),mir=r(N$," \u2014 "),Kz=n(N$,"A",{href:!0});var V1t=s(Kz);gir=r(V1t,"TFFunnelModel"),V1t.forEach(t),hir=r(N$," or "),Zz=n(N$,"A",{href:!0});var X1t=s(Zz);pir=r(X1t,"TFFunnelBaseModel"),X1t.forEach(t),uir=r(N$," (Funnel Transformer model)"),N$.forEach(t),_ir=i(D),n8=n(D,"LI",{});var Eke=s(n8);t1e=n(Eke,"STRONG",{});var z1t=s(t1e);bir=r(z1t,"gpt2"),z1t.forEach(t),vir=r(Eke," \u2014 "),eQ=n(Eke,"A",{href:!0});var Q1t=s(eQ);Fir=r(Q1t,"TFGPT2Model"),Q1t.forEach(t),Tir=r(Eke," (OpenAI GPT-2 model)"),Eke.forEach(t),Mir=i(D),s8=n(D,"LI",{});var Cke=s(s8);a1e=n(Cke,"STRONG",{});var W1t=s(a1e);Eir=r(W1t,"gptj"),W1t.forEach(t),Cir=r(Cke," \u2014 "),oQ=n(Cke,"A",{href:!0});var H1t=s(oQ);wir=r(H1t,"TFGPTJModel"),H1t.forEach(t),Air=r(Cke," (GPT-J model)"),Cke.forEach(t),yir=i(D),l8=n(D,"LI",{});var wke=s(l8);n1e=n(wke,"STRONG",{});var U1t=s(n1e);Lir=r(U1t,"hubert"),U1t.forEach(t),xir=r(wke," \u2014 "),rQ=n(wke,"A",{href:!0});var J1t=s(rQ);$ir=r(J1t,"TFHubertModel"),J1t.forEach(t),kir=r(wke," (Hubert model)"),wke.forEach(t),Sir=i(D),i8=n(D,"LI",{});var Ake=s(i8);s1e=n(Ake,"STRONG",{});var Y1t=s(s1e);Rir=r(Y1t,"layoutlm"),Y1t.forEach(t),Pir=r(Ake," \u2014 "),tQ=n(Ake,"A",{href:!0});var K1t=s(tQ);Bir=r(K1t,"TFLayoutLMModel"),K1t.forEach(t),Iir=r(Ake," (LayoutLM model)"),Ake.forEach(t),qir=i(D),d8=n(D,"LI",{});var yke=s(d8);l1e=n(yke,"STRONG",{});var Z1t=s(l1e);Nir=r(Z1t,"led"),Z1t.forEach(t),jir=r(yke," \u2014 "),aQ=n(yke,"A",{href:!0});var ebt=s(aQ);Dir=r(ebt,"TFLEDModel"),ebt.forEach(t),Gir=r(yke," (LED model)"),yke.forEach(t),Oir=i(D),c8=n(D,"LI",{});var Lke=s(c8);i1e=n(Lke,"STRONG",{});var obt=s(i1e);Vir=r(obt,"longformer"),obt.forEach(t),Xir=r(Lke," \u2014 "),nQ=n(Lke,"A",{href:!0});var rbt=s(nQ);zir=r(rbt,"TFLongformerModel"),rbt.forEach(t),Qir=r(Lke," (Longformer model)"),Lke.forEach(t),Wir=i(D),f8=n(D,"LI",{});var xke=s(f8);d1e=n(xke,"STRONG",{});var tbt=s(d1e);Hir=r(tbt,"lxmert"),tbt.forEach(t),Uir=r(xke," \u2014 "),sQ=n(xke,"A",{href:!0});var abt=s(sQ);Jir=r(abt,"TFLxmertModel"),abt.forEach(t),Yir=r(xke," (LXMERT model)"),xke.forEach(t),Kir=i(D),m8=n(D,"LI",{});var $ke=s(m8);c1e=n($ke,"STRONG",{});var nbt=s(c1e);Zir=r(nbt,"marian"),nbt.forEach(t),edr=r($ke," \u2014 "),lQ=n($ke,"A",{href:!0});var sbt=s(lQ);odr=r(sbt,"TFMarianModel"),sbt.forEach(t),rdr=r($ke," (Marian model)"),$ke.forEach(t),tdr=i(D),g8=n(D,"LI",{});var kke=s(g8);f1e=n(kke,"STRONG",{});var lbt=s(f1e);adr=r(lbt,"mbart"),lbt.forEach(t),ndr=r(kke," \u2014 "),iQ=n(kke,"A",{href:!0});var ibt=s(iQ);sdr=r(ibt,"TFMBartModel"),ibt.forEach(t),ldr=r(kke," (mBART model)"),kke.forEach(t),idr=i(D),h8=n(D,"LI",{});var Ske=s(h8);m1e=n(Ske,"STRONG",{});var dbt=s(m1e);ddr=r(dbt,"mobilebert"),dbt.forEach(t),cdr=r(Ske," \u2014 "),dQ=n(Ske,"A",{href:!0});var cbt=s(dQ);fdr=r(cbt,"TFMobileBertModel"),cbt.forEach(t),mdr=r(Ske," (MobileBERT model)"),Ske.forEach(t),gdr=i(D),p8=n(D,"LI",{});var Rke=s(p8);g1e=n(Rke,"STRONG",{});var fbt=s(g1e);hdr=r(fbt,"mpnet"),fbt.forEach(t),pdr=r(Rke," \u2014 "),cQ=n(Rke,"A",{href:!0});var mbt=s(cQ);udr=r(mbt,"TFMPNetModel"),mbt.forEach(t),_dr=r(Rke," (MPNet model)"),Rke.forEach(t),bdr=i(D),u8=n(D,"LI",{});var Pke=s(u8);h1e=n(Pke,"STRONG",{});var gbt=s(h1e);vdr=r(gbt,"mt5"),gbt.forEach(t),Fdr=r(Pke," \u2014 "),fQ=n(Pke,"A",{href:!0});var hbt=s(fQ);Tdr=r(hbt,"TFMT5Model"),hbt.forEach(t),Mdr=r(Pke," (mT5 model)"),Pke.forEach(t),Edr=i(D),_8=n(D,"LI",{});var Bke=s(_8);p1e=n(Bke,"STRONG",{});var pbt=s(p1e);Cdr=r(pbt,"openai-gpt"),pbt.forEach(t),wdr=r(Bke," \u2014 "),mQ=n(Bke,"A",{href:!0});var ubt=s(mQ);Adr=r(ubt,"TFOpenAIGPTModel"),ubt.forEach(t),ydr=r(Bke," (OpenAI GPT model)"),Bke.forEach(t),Ldr=i(D),b8=n(D,"LI",{});var Ike=s(b8);u1e=n(Ike,"STRONG",{});var _bt=s(u1e);xdr=r(_bt,"pegasus"),_bt.forEach(t),$dr=r(Ike," \u2014 "),gQ=n(Ike,"A",{href:!0});var bbt=s(gQ);kdr=r(bbt,"TFPegasusModel"),bbt.forEach(t),Sdr=r(Ike," (Pegasus model)"),Ike.forEach(t),Rdr=i(D),v8=n(D,"LI",{});var qke=s(v8);_1e=n(qke,"STRONG",{});var vbt=s(_1e);Pdr=r(vbt,"rembert"),vbt.forEach(t),Bdr=r(qke," \u2014 "),hQ=n(qke,"A",{href:!0});var Fbt=s(hQ);Idr=r(Fbt,"TFRemBertModel"),Fbt.forEach(t),qdr=r(qke," (RemBERT model)"),qke.forEach(t),Ndr=i(D),F8=n(D,"LI",{});var Nke=s(F8);b1e=n(Nke,"STRONG",{});var Tbt=s(b1e);jdr=r(Tbt,"roberta"),Tbt.forEach(t),Ddr=r(Nke," \u2014 "),pQ=n(Nke,"A",{href:!0});var Mbt=s(pQ);Gdr=r(Mbt,"TFRobertaModel"),Mbt.forEach(t),Odr=r(Nke," (RoBERTa model)"),Nke.forEach(t),Vdr=i(D),T8=n(D,"LI",{});var jke=s(T8);v1e=n(jke,"STRONG",{});var Ebt=s(v1e);Xdr=r(Ebt,"roformer"),Ebt.forEach(t),zdr=r(jke," \u2014 "),uQ=n(jke,"A",{href:!0});var Cbt=s(uQ);Qdr=r(Cbt,"TFRoFormerModel"),Cbt.forEach(t),Wdr=r(jke," (RoFormer model)"),jke.forEach(t),Hdr=i(D),M8=n(D,"LI",{});var Dke=s(M8);F1e=n(Dke,"STRONG",{});var wbt=s(F1e);Udr=r(wbt,"speech_to_text"),wbt.forEach(t),Jdr=r(Dke," \u2014 "),_Q=n(Dke,"A",{href:!0});var Abt=s(_Q);Ydr=r(Abt,"TFSpeech2TextModel"),Abt.forEach(t),Kdr=r(Dke," (Speech2Text model)"),Dke.forEach(t),Zdr=i(D),E8=n(D,"LI",{});var Gke=s(E8);T1e=n(Gke,"STRONG",{});var ybt=s(T1e);ecr=r(ybt,"t5"),ybt.forEach(t),ocr=r(Gke," \u2014 "),bQ=n(Gke,"A",{href:!0});var Lbt=s(bQ);rcr=r(Lbt,"TFT5Model"),Lbt.forEach(t),tcr=r(Gke," (T5 model)"),Gke.forEach(t),acr=i(D),C8=n(D,"LI",{});var Oke=s(C8);M1e=n(Oke,"STRONG",{});var xbt=s(M1e);ncr=r(xbt,"tapas"),xbt.forEach(t),scr=r(Oke," \u2014 "),vQ=n(Oke,"A",{href:!0});var $bt=s(vQ);lcr=r($bt,"TFTapasModel"),$bt.forEach(t),icr=r(Oke," (TAPAS model)"),Oke.forEach(t),dcr=i(D),w8=n(D,"LI",{});var Vke=s(w8);E1e=n(Vke,"STRONG",{});var kbt=s(E1e);ccr=r(kbt,"transfo-xl"),kbt.forEach(t),fcr=r(Vke," \u2014 "),FQ=n(Vke,"A",{href:!0});var Sbt=s(FQ);mcr=r(Sbt,"TFTransfoXLModel"),Sbt.forEach(t),gcr=r(Vke," (Transformer-XL model)"),Vke.forEach(t),hcr=i(D),A8=n(D,"LI",{});var Xke=s(A8);C1e=n(Xke,"STRONG",{});var Rbt=s(C1e);pcr=r(Rbt,"vit"),Rbt.forEach(t),ucr=r(Xke," \u2014 "),TQ=n(Xke,"A",{href:!0});var Pbt=s(TQ);_cr=r(Pbt,"TFViTModel"),Pbt.forEach(t),bcr=r(Xke," (ViT model)"),Xke.forEach(t),vcr=i(D),y8=n(D,"LI",{});var zke=s(y8);w1e=n(zke,"STRONG",{});var Bbt=s(w1e);Fcr=r(Bbt,"vit_mae"),Bbt.forEach(t),Tcr=r(zke," \u2014 "),MQ=n(zke,"A",{href:!0});var Ibt=s(MQ);Mcr=r(Ibt,"TFViTMAEModel"),Ibt.forEach(t),Ecr=r(zke," (ViTMAE model)"),zke.forEach(t),Ccr=i(D),L8=n(D,"LI",{});var Qke=s(L8);A1e=n(Qke,"STRONG",{});var qbt=s(A1e);wcr=r(qbt,"wav2vec2"),qbt.forEach(t),Acr=r(Qke," \u2014 "),EQ=n(Qke,"A",{href:!0});var Nbt=s(EQ);ycr=r(Nbt,"TFWav2Vec2Model"),Nbt.forEach(t),Lcr=r(Qke," (Wav2Vec2 model)"),Qke.forEach(t),xcr=i(D),x8=n(D,"LI",{});var Wke=s(x8);y1e=n(Wke,"STRONG",{});var jbt=s(y1e);$cr=r(jbt,"xlm"),jbt.forEach(t),kcr=r(Wke," \u2014 "),CQ=n(Wke,"A",{href:!0});var Dbt=s(CQ);Scr=r(Dbt,"TFXLMModel"),Dbt.forEach(t),Rcr=r(Wke," (XLM model)"),Wke.forEach(t),Pcr=i(D),$8=n(D,"LI",{});var Hke=s($8);L1e=n(Hke,"STRONG",{});var Gbt=s(L1e);Bcr=r(Gbt,"xlm-roberta"),Gbt.forEach(t),Icr=r(Hke," \u2014 "),wQ=n(Hke,"A",{href:!0});var Obt=s(wQ);qcr=r(Obt,"TFXLMRobertaModel"),Obt.forEach(t),Ncr=r(Hke," (XLM-RoBERTa model)"),Hke.forEach(t),jcr=i(D),k8=n(D,"LI",{});var Uke=s(k8);x1e=n(Uke,"STRONG",{});var Vbt=s(x1e);Dcr=r(Vbt,"xlnet"),Vbt.forEach(t),Gcr=r(Uke," \u2014 "),AQ=n(Uke,"A",{href:!0});var Xbt=s(AQ);Ocr=r(Xbt,"TFXLNetModel"),Xbt.forEach(t),Vcr=r(Uke," (XLNet model)"),Uke.forEach(t),D.forEach(t),Xcr=i(_l),T(S8.$$.fragment,_l),_l.forEach(t),ul.forEach(t),Jqe=i(f),Jd=n(f,"H2",{class:!0});var aDe=s(Jd);R8=n(aDe,"A",{id:!0,class:!0,href:!0});var zbt=s(R8);$1e=n(zbt,"SPAN",{});var Qbt=s($1e);T(lL.$$.fragment,Qbt),Qbt.forEach(t),zbt.forEach(t),zcr=i(aDe),k1e=n(aDe,"SPAN",{});var Wbt=s(k1e);Qcr=r(Wbt,"TFAutoModelForPreTraining"),Wbt.forEach(t),aDe.forEach(t),Yqe=i(f),er=n(f,"DIV",{class:!0});var bl=s(er);T(iL.$$.fragment,bl),Wcr=i(bl),Yd=n(bl,"P",{});var qZ=s(Yd);Hcr=r(qZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),yQ=n(qZ,"A",{href:!0});var Hbt=s(yQ);Ucr=r(Hbt,"from_pretrained()"),Hbt.forEach(t),Jcr=r(qZ," class method or the "),LQ=n(qZ,"A",{href:!0});var Ubt=s(LQ);Ycr=r(Ubt,"from_config()"),Ubt.forEach(t),Kcr=r(qZ,` class
method.`),qZ.forEach(t),Zcr=i(bl),dL=n(bl,"P",{});var nDe=s(dL);efr=r(nDe,"This class cannot be instantiated directly using "),S1e=n(nDe,"CODE",{});var Jbt=s(S1e);ofr=r(Jbt,"__init__()"),Jbt.forEach(t),rfr=r(nDe," (throws an error)."),nDe.forEach(t),tfr=i(bl),xt=n(bl,"DIV",{class:!0});var uw=s(xt);T(cL.$$.fragment,uw),afr=i(uw),R1e=n(uw,"P",{});var Ybt=s(R1e);nfr=r(Ybt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Ybt.forEach(t),sfr=i(uw),Kd=n(uw,"P",{});var NZ=s(Kd);lfr=r(NZ,`Note:
Loading a model from its configuration file does `),P1e=n(NZ,"STRONG",{});var Kbt=s(P1e);ifr=r(Kbt,"not"),Kbt.forEach(t),dfr=r(NZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),xQ=n(NZ,"A",{href:!0});var Zbt=s(xQ);cfr=r(Zbt,"from_pretrained()"),Zbt.forEach(t),ffr=r(NZ," to load the model weights."),NZ.forEach(t),mfr=i(uw),T(P8.$$.fragment,uw),uw.forEach(t),gfr=i(bl),Lr=n(bl,"DIV",{class:!0});var vl=s(Lr);T(fL.$$.fragment,vl),hfr=i(vl),B1e=n(vl,"P",{});var evt=s(B1e);pfr=r(evt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),evt.forEach(t),ufr=i(vl),an=n(vl,"P",{});var _w=s(an);_fr=r(_w,"The model class to instantiate is selected based on the "),I1e=n(_w,"CODE",{});var ovt=s(I1e);bfr=r(ovt,"model_type"),ovt.forEach(t),vfr=r(_w,` property of the config object (either
passed as an argument or loaded from `),q1e=n(_w,"CODE",{});var rvt=s(q1e);Ffr=r(rvt,"pretrained_model_name_or_path"),rvt.forEach(t),Tfr=r(_w,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N1e=n(_w,"CODE",{});var tvt=s(N1e);Mfr=r(tvt,"pretrained_model_name_or_path"),tvt.forEach(t),Efr=r(_w,":"),_w.forEach(t),Cfr=i(vl),se=n(vl,"UL",{});var le=s(se);B8=n(le,"LI",{});var Jke=s(B8);j1e=n(Jke,"STRONG",{});var avt=s(j1e);wfr=r(avt,"albert"),avt.forEach(t),Afr=r(Jke," \u2014 "),$Q=n(Jke,"A",{href:!0});var nvt=s($Q);yfr=r(nvt,"TFAlbertForPreTraining"),nvt.forEach(t),Lfr=r(Jke," (ALBERT model)"),Jke.forEach(t),xfr=i(le),I8=n(le,"LI",{});var Yke=s(I8);D1e=n(Yke,"STRONG",{});var svt=s(D1e);$fr=r(svt,"bart"),svt.forEach(t),kfr=r(Yke," \u2014 "),kQ=n(Yke,"A",{href:!0});var lvt=s(kQ);Sfr=r(lvt,"TFBartForConditionalGeneration"),lvt.forEach(t),Rfr=r(Yke," (BART model)"),Yke.forEach(t),Pfr=i(le),q8=n(le,"LI",{});var Kke=s(q8);G1e=n(Kke,"STRONG",{});var ivt=s(G1e);Bfr=r(ivt,"bert"),ivt.forEach(t),Ifr=r(Kke," \u2014 "),SQ=n(Kke,"A",{href:!0});var dvt=s(SQ);qfr=r(dvt,"TFBertForPreTraining"),dvt.forEach(t),Nfr=r(Kke," (BERT model)"),Kke.forEach(t),jfr=i(le),N8=n(le,"LI",{});var Zke=s(N8);O1e=n(Zke,"STRONG",{});var cvt=s(O1e);Dfr=r(cvt,"camembert"),cvt.forEach(t),Gfr=r(Zke," \u2014 "),RQ=n(Zke,"A",{href:!0});var fvt=s(RQ);Ofr=r(fvt,"TFCamembertForMaskedLM"),fvt.forEach(t),Vfr=r(Zke," (CamemBERT model)"),Zke.forEach(t),Xfr=i(le),j8=n(le,"LI",{});var eSe=s(j8);V1e=n(eSe,"STRONG",{});var mvt=s(V1e);zfr=r(mvt,"ctrl"),mvt.forEach(t),Qfr=r(eSe," \u2014 "),PQ=n(eSe,"A",{href:!0});var gvt=s(PQ);Wfr=r(gvt,"TFCTRLLMHeadModel"),gvt.forEach(t),Hfr=r(eSe," (CTRL model)"),eSe.forEach(t),Ufr=i(le),D8=n(le,"LI",{});var oSe=s(D8);X1e=n(oSe,"STRONG",{});var hvt=s(X1e);Jfr=r(hvt,"distilbert"),hvt.forEach(t),Yfr=r(oSe," \u2014 "),BQ=n(oSe,"A",{href:!0});var pvt=s(BQ);Kfr=r(pvt,"TFDistilBertForMaskedLM"),pvt.forEach(t),Zfr=r(oSe," (DistilBERT model)"),oSe.forEach(t),emr=i(le),G8=n(le,"LI",{});var rSe=s(G8);z1e=n(rSe,"STRONG",{});var uvt=s(z1e);omr=r(uvt,"electra"),uvt.forEach(t),rmr=r(rSe," \u2014 "),IQ=n(rSe,"A",{href:!0});var _vt=s(IQ);tmr=r(_vt,"TFElectraForPreTraining"),_vt.forEach(t),amr=r(rSe," (ELECTRA model)"),rSe.forEach(t),nmr=i(le),O8=n(le,"LI",{});var tSe=s(O8);Q1e=n(tSe,"STRONG",{});var bvt=s(Q1e);smr=r(bvt,"flaubert"),bvt.forEach(t),lmr=r(tSe," \u2014 "),qQ=n(tSe,"A",{href:!0});var vvt=s(qQ);imr=r(vvt,"TFFlaubertWithLMHeadModel"),vvt.forEach(t),dmr=r(tSe," (FlauBERT model)"),tSe.forEach(t),cmr=i(le),V8=n(le,"LI",{});var aSe=s(V8);W1e=n(aSe,"STRONG",{});var Fvt=s(W1e);fmr=r(Fvt,"funnel"),Fvt.forEach(t),mmr=r(aSe," \u2014 "),NQ=n(aSe,"A",{href:!0});var Tvt=s(NQ);gmr=r(Tvt,"TFFunnelForPreTraining"),Tvt.forEach(t),hmr=r(aSe," (Funnel Transformer model)"),aSe.forEach(t),pmr=i(le),X8=n(le,"LI",{});var nSe=s(X8);H1e=n(nSe,"STRONG",{});var Mvt=s(H1e);umr=r(Mvt,"gpt2"),Mvt.forEach(t),_mr=r(nSe," \u2014 "),jQ=n(nSe,"A",{href:!0});var Evt=s(jQ);bmr=r(Evt,"TFGPT2LMHeadModel"),Evt.forEach(t),vmr=r(nSe," (OpenAI GPT-2 model)"),nSe.forEach(t),Fmr=i(le),z8=n(le,"LI",{});var sSe=s(z8);U1e=n(sSe,"STRONG",{});var Cvt=s(U1e);Tmr=r(Cvt,"layoutlm"),Cvt.forEach(t),Mmr=r(sSe," \u2014 "),DQ=n(sSe,"A",{href:!0});var wvt=s(DQ);Emr=r(wvt,"TFLayoutLMForMaskedLM"),wvt.forEach(t),Cmr=r(sSe," (LayoutLM model)"),sSe.forEach(t),wmr=i(le),Q8=n(le,"LI",{});var lSe=s(Q8);J1e=n(lSe,"STRONG",{});var Avt=s(J1e);Amr=r(Avt,"lxmert"),Avt.forEach(t),ymr=r(lSe," \u2014 "),GQ=n(lSe,"A",{href:!0});var yvt=s(GQ);Lmr=r(yvt,"TFLxmertForPreTraining"),yvt.forEach(t),xmr=r(lSe," (LXMERT model)"),lSe.forEach(t),$mr=i(le),W8=n(le,"LI",{});var iSe=s(W8);Y1e=n(iSe,"STRONG",{});var Lvt=s(Y1e);kmr=r(Lvt,"mobilebert"),Lvt.forEach(t),Smr=r(iSe," \u2014 "),OQ=n(iSe,"A",{href:!0});var xvt=s(OQ);Rmr=r(xvt,"TFMobileBertForPreTraining"),xvt.forEach(t),Pmr=r(iSe," (MobileBERT model)"),iSe.forEach(t),Bmr=i(le),H8=n(le,"LI",{});var dSe=s(H8);K1e=n(dSe,"STRONG",{});var $vt=s(K1e);Imr=r($vt,"mpnet"),$vt.forEach(t),qmr=r(dSe," \u2014 "),VQ=n(dSe,"A",{href:!0});var kvt=s(VQ);Nmr=r(kvt,"TFMPNetForMaskedLM"),kvt.forEach(t),jmr=r(dSe," (MPNet model)"),dSe.forEach(t),Dmr=i(le),U8=n(le,"LI",{});var cSe=s(U8);Z1e=n(cSe,"STRONG",{});var Svt=s(Z1e);Gmr=r(Svt,"openai-gpt"),Svt.forEach(t),Omr=r(cSe," \u2014 "),XQ=n(cSe,"A",{href:!0});var Rvt=s(XQ);Vmr=r(Rvt,"TFOpenAIGPTLMHeadModel"),Rvt.forEach(t),Xmr=r(cSe," (OpenAI GPT model)"),cSe.forEach(t),zmr=i(le),J8=n(le,"LI",{});var fSe=s(J8);ebe=n(fSe,"STRONG",{});var Pvt=s(ebe);Qmr=r(Pvt,"roberta"),Pvt.forEach(t),Wmr=r(fSe," \u2014 "),zQ=n(fSe,"A",{href:!0});var Bvt=s(zQ);Hmr=r(Bvt,"TFRobertaForMaskedLM"),Bvt.forEach(t),Umr=r(fSe," (RoBERTa model)"),fSe.forEach(t),Jmr=i(le),Y8=n(le,"LI",{});var mSe=s(Y8);obe=n(mSe,"STRONG",{});var Ivt=s(obe);Ymr=r(Ivt,"t5"),Ivt.forEach(t),Kmr=r(mSe," \u2014 "),QQ=n(mSe,"A",{href:!0});var qvt=s(QQ);Zmr=r(qvt,"TFT5ForConditionalGeneration"),qvt.forEach(t),egr=r(mSe," (T5 model)"),mSe.forEach(t),ogr=i(le),K8=n(le,"LI",{});var gSe=s(K8);rbe=n(gSe,"STRONG",{});var Nvt=s(rbe);rgr=r(Nvt,"tapas"),Nvt.forEach(t),tgr=r(gSe," \u2014 "),WQ=n(gSe,"A",{href:!0});var jvt=s(WQ);agr=r(jvt,"TFTapasForMaskedLM"),jvt.forEach(t),ngr=r(gSe," (TAPAS model)"),gSe.forEach(t),sgr=i(le),Z8=n(le,"LI",{});var hSe=s(Z8);tbe=n(hSe,"STRONG",{});var Dvt=s(tbe);lgr=r(Dvt,"transfo-xl"),Dvt.forEach(t),igr=r(hSe," \u2014 "),HQ=n(hSe,"A",{href:!0});var Gvt=s(HQ);dgr=r(Gvt,"TFTransfoXLLMHeadModel"),Gvt.forEach(t),cgr=r(hSe," (Transformer-XL model)"),hSe.forEach(t),fgr=i(le),e7=n(le,"LI",{});var pSe=s(e7);abe=n(pSe,"STRONG",{});var Ovt=s(abe);mgr=r(Ovt,"vit_mae"),Ovt.forEach(t),ggr=r(pSe," \u2014 "),UQ=n(pSe,"A",{href:!0});var Vvt=s(UQ);hgr=r(Vvt,"TFViTMAEForPreTraining"),Vvt.forEach(t),pgr=r(pSe," (ViTMAE model)"),pSe.forEach(t),ugr=i(le),o7=n(le,"LI",{});var uSe=s(o7);nbe=n(uSe,"STRONG",{});var Xvt=s(nbe);_gr=r(Xvt,"xlm"),Xvt.forEach(t),bgr=r(uSe," \u2014 "),JQ=n(uSe,"A",{href:!0});var zvt=s(JQ);vgr=r(zvt,"TFXLMWithLMHeadModel"),zvt.forEach(t),Fgr=r(uSe," (XLM model)"),uSe.forEach(t),Tgr=i(le),r7=n(le,"LI",{});var _Se=s(r7);sbe=n(_Se,"STRONG",{});var Qvt=s(sbe);Mgr=r(Qvt,"xlm-roberta"),Qvt.forEach(t),Egr=r(_Se," \u2014 "),YQ=n(_Se,"A",{href:!0});var Wvt=s(YQ);Cgr=r(Wvt,"TFXLMRobertaForMaskedLM"),Wvt.forEach(t),wgr=r(_Se," (XLM-RoBERTa model)"),_Se.forEach(t),Agr=i(le),t7=n(le,"LI",{});var bSe=s(t7);lbe=n(bSe,"STRONG",{});var Hvt=s(lbe);ygr=r(Hvt,"xlnet"),Hvt.forEach(t),Lgr=r(bSe," \u2014 "),KQ=n(bSe,"A",{href:!0});var Uvt=s(KQ);xgr=r(Uvt,"TFXLNetLMHeadModel"),Uvt.forEach(t),$gr=r(bSe," (XLNet model)"),bSe.forEach(t),le.forEach(t),kgr=i(vl),T(a7.$$.fragment,vl),vl.forEach(t),bl.forEach(t),Kqe=i(f),Zd=n(f,"H2",{class:!0});var sDe=s(Zd);n7=n(sDe,"A",{id:!0,class:!0,href:!0});var Jvt=s(n7);ibe=n(Jvt,"SPAN",{});var Yvt=s(ibe);T(mL.$$.fragment,Yvt),Yvt.forEach(t),Jvt.forEach(t),Sgr=i(sDe),dbe=n(sDe,"SPAN",{});var Kvt=s(dbe);Rgr=r(Kvt,"TFAutoModelForCausalLM"),Kvt.forEach(t),sDe.forEach(t),Zqe=i(f),or=n(f,"DIV",{class:!0});var Fl=s(or);T(gL.$$.fragment,Fl),Pgr=i(Fl),ec=n(Fl,"P",{});var jZ=s(ec);Bgr=r(jZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),ZQ=n(jZ,"A",{href:!0});var Zvt=s(ZQ);Igr=r(Zvt,"from_pretrained()"),Zvt.forEach(t),qgr=r(jZ," class method or the "),eW=n(jZ,"A",{href:!0});var eFt=s(eW);Ngr=r(eFt,"from_config()"),eFt.forEach(t),jgr=r(jZ,` class
method.`),jZ.forEach(t),Dgr=i(Fl),hL=n(Fl,"P",{});var lDe=s(hL);Ggr=r(lDe,"This class cannot be instantiated directly using "),cbe=n(lDe,"CODE",{});var oFt=s(cbe);Ogr=r(oFt,"__init__()"),oFt.forEach(t),Vgr=r(lDe," (throws an error)."),lDe.forEach(t),Xgr=i(Fl),$t=n(Fl,"DIV",{class:!0});var bw=s($t);T(pL.$$.fragment,bw),zgr=i(bw),fbe=n(bw,"P",{});var rFt=s(fbe);Qgr=r(rFt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),rFt.forEach(t),Wgr=i(bw),oc=n(bw,"P",{});var DZ=s(oc);Hgr=r(DZ,`Note:
Loading a model from its configuration file does `),mbe=n(DZ,"STRONG",{});var tFt=s(mbe);Ugr=r(tFt,"not"),tFt.forEach(t),Jgr=r(DZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),oW=n(DZ,"A",{href:!0});var aFt=s(oW);Ygr=r(aFt,"from_pretrained()"),aFt.forEach(t),Kgr=r(DZ," to load the model weights."),DZ.forEach(t),Zgr=i(bw),T(s7.$$.fragment,bw),bw.forEach(t),ehr=i(Fl),xr=n(Fl,"DIV",{class:!0});var Tl=s(xr);T(uL.$$.fragment,Tl),ohr=i(Tl),gbe=n(Tl,"P",{});var nFt=s(gbe);rhr=r(nFt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),nFt.forEach(t),thr=i(Tl),nn=n(Tl,"P",{});var vw=s(nn);ahr=r(vw,"The model class to instantiate is selected based on the "),hbe=n(vw,"CODE",{});var sFt=s(hbe);nhr=r(sFt,"model_type"),sFt.forEach(t),shr=r(vw,` property of the config object (either
passed as an argument or loaded from `),pbe=n(vw,"CODE",{});var lFt=s(pbe);lhr=r(lFt,"pretrained_model_name_or_path"),lFt.forEach(t),ihr=r(vw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ube=n(vw,"CODE",{});var iFt=s(ube);dhr=r(iFt,"pretrained_model_name_or_path"),iFt.forEach(t),chr=r(vw,":"),vw.forEach(t),fhr=i(Tl),Te=n(Tl,"UL",{});var Ce=s(Te);l7=n(Ce,"LI",{});var vSe=s(l7);_be=n(vSe,"STRONG",{});var dFt=s(_be);mhr=r(dFt,"bert"),dFt.forEach(t),ghr=r(vSe," \u2014 "),rW=n(vSe,"A",{href:!0});var cFt=s(rW);hhr=r(cFt,"TFBertLMHeadModel"),cFt.forEach(t),phr=r(vSe," (BERT model)"),vSe.forEach(t),uhr=i(Ce),i7=n(Ce,"LI",{});var FSe=s(i7);bbe=n(FSe,"STRONG",{});var fFt=s(bbe);_hr=r(fFt,"camembert"),fFt.forEach(t),bhr=r(FSe," \u2014 "),tW=n(FSe,"A",{href:!0});var mFt=s(tW);vhr=r(mFt,"TFCamembertForCausalLM"),mFt.forEach(t),Fhr=r(FSe," (CamemBERT model)"),FSe.forEach(t),Thr=i(Ce),d7=n(Ce,"LI",{});var TSe=s(d7);vbe=n(TSe,"STRONG",{});var gFt=s(vbe);Mhr=r(gFt,"ctrl"),gFt.forEach(t),Ehr=r(TSe," \u2014 "),aW=n(TSe,"A",{href:!0});var hFt=s(aW);Chr=r(hFt,"TFCTRLLMHeadModel"),hFt.forEach(t),whr=r(TSe," (CTRL model)"),TSe.forEach(t),Ahr=i(Ce),c7=n(Ce,"LI",{});var MSe=s(c7);Fbe=n(MSe,"STRONG",{});var pFt=s(Fbe);yhr=r(pFt,"gpt2"),pFt.forEach(t),Lhr=r(MSe," \u2014 "),nW=n(MSe,"A",{href:!0});var uFt=s(nW);xhr=r(uFt,"TFGPT2LMHeadModel"),uFt.forEach(t),$hr=r(MSe," (OpenAI GPT-2 model)"),MSe.forEach(t),khr=i(Ce),f7=n(Ce,"LI",{});var ESe=s(f7);Tbe=n(ESe,"STRONG",{});var _Ft=s(Tbe);Shr=r(_Ft,"gptj"),_Ft.forEach(t),Rhr=r(ESe," \u2014 "),sW=n(ESe,"A",{href:!0});var bFt=s(sW);Phr=r(bFt,"TFGPTJForCausalLM"),bFt.forEach(t),Bhr=r(ESe," (GPT-J model)"),ESe.forEach(t),Ihr=i(Ce),m7=n(Ce,"LI",{});var CSe=s(m7);Mbe=n(CSe,"STRONG",{});var vFt=s(Mbe);qhr=r(vFt,"openai-gpt"),vFt.forEach(t),Nhr=r(CSe," \u2014 "),lW=n(CSe,"A",{href:!0});var FFt=s(lW);jhr=r(FFt,"TFOpenAIGPTLMHeadModel"),FFt.forEach(t),Dhr=r(CSe," (OpenAI GPT model)"),CSe.forEach(t),Ghr=i(Ce),g7=n(Ce,"LI",{});var wSe=s(g7);Ebe=n(wSe,"STRONG",{});var TFt=s(Ebe);Ohr=r(TFt,"rembert"),TFt.forEach(t),Vhr=r(wSe," \u2014 "),iW=n(wSe,"A",{href:!0});var MFt=s(iW);Xhr=r(MFt,"TFRemBertForCausalLM"),MFt.forEach(t),zhr=r(wSe," (RemBERT model)"),wSe.forEach(t),Qhr=i(Ce),h7=n(Ce,"LI",{});var ASe=s(h7);Cbe=n(ASe,"STRONG",{});var EFt=s(Cbe);Whr=r(EFt,"roberta"),EFt.forEach(t),Hhr=r(ASe," \u2014 "),dW=n(ASe,"A",{href:!0});var CFt=s(dW);Uhr=r(CFt,"TFRobertaForCausalLM"),CFt.forEach(t),Jhr=r(ASe," (RoBERTa model)"),ASe.forEach(t),Yhr=i(Ce),p7=n(Ce,"LI",{});var ySe=s(p7);wbe=n(ySe,"STRONG",{});var wFt=s(wbe);Khr=r(wFt,"roformer"),wFt.forEach(t),Zhr=r(ySe," \u2014 "),cW=n(ySe,"A",{href:!0});var AFt=s(cW);epr=r(AFt,"TFRoFormerForCausalLM"),AFt.forEach(t),opr=r(ySe," (RoFormer model)"),ySe.forEach(t),rpr=i(Ce),u7=n(Ce,"LI",{});var LSe=s(u7);Abe=n(LSe,"STRONG",{});var yFt=s(Abe);tpr=r(yFt,"transfo-xl"),yFt.forEach(t),apr=r(LSe," \u2014 "),fW=n(LSe,"A",{href:!0});var LFt=s(fW);npr=r(LFt,"TFTransfoXLLMHeadModel"),LFt.forEach(t),spr=r(LSe," (Transformer-XL model)"),LSe.forEach(t),lpr=i(Ce),_7=n(Ce,"LI",{});var xSe=s(_7);ybe=n(xSe,"STRONG",{});var xFt=s(ybe);ipr=r(xFt,"xlm"),xFt.forEach(t),dpr=r(xSe," \u2014 "),mW=n(xSe,"A",{href:!0});var $Ft=s(mW);cpr=r($Ft,"TFXLMWithLMHeadModel"),$Ft.forEach(t),fpr=r(xSe," (XLM model)"),xSe.forEach(t),mpr=i(Ce),b7=n(Ce,"LI",{});var $Se=s(b7);Lbe=n($Se,"STRONG",{});var kFt=s(Lbe);gpr=r(kFt,"xlnet"),kFt.forEach(t),hpr=r($Se," \u2014 "),gW=n($Se,"A",{href:!0});var SFt=s(gW);ppr=r(SFt,"TFXLNetLMHeadModel"),SFt.forEach(t),upr=r($Se," (XLNet model)"),$Se.forEach(t),Ce.forEach(t),_pr=i(Tl),T(v7.$$.fragment,Tl),Tl.forEach(t),Fl.forEach(t),eNe=i(f),rc=n(f,"H2",{class:!0});var iDe=s(rc);F7=n(iDe,"A",{id:!0,class:!0,href:!0});var RFt=s(F7);xbe=n(RFt,"SPAN",{});var PFt=s(xbe);T(_L.$$.fragment,PFt),PFt.forEach(t),RFt.forEach(t),bpr=i(iDe),$be=n(iDe,"SPAN",{});var BFt=s($be);vpr=r(BFt,"TFAutoModelForImageClassification"),BFt.forEach(t),iDe.forEach(t),oNe=i(f),rr=n(f,"DIV",{class:!0});var Ml=s(rr);T(bL.$$.fragment,Ml),Fpr=i(Ml),tc=n(Ml,"P",{});var GZ=s(tc);Tpr=r(GZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),hW=n(GZ,"A",{href:!0});var IFt=s(hW);Mpr=r(IFt,"from_pretrained()"),IFt.forEach(t),Epr=r(GZ," class method or the "),pW=n(GZ,"A",{href:!0});var qFt=s(pW);Cpr=r(qFt,"from_config()"),qFt.forEach(t),wpr=r(GZ,` class
method.`),GZ.forEach(t),Apr=i(Ml),vL=n(Ml,"P",{});var dDe=s(vL);ypr=r(dDe,"This class cannot be instantiated directly using "),kbe=n(dDe,"CODE",{});var NFt=s(kbe);Lpr=r(NFt,"__init__()"),NFt.forEach(t),xpr=r(dDe," (throws an error)."),dDe.forEach(t),$pr=i(Ml),kt=n(Ml,"DIV",{class:!0});var Fw=s(kt);T(FL.$$.fragment,Fw),kpr=i(Fw),Sbe=n(Fw,"P",{});var jFt=s(Sbe);Spr=r(jFt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),jFt.forEach(t),Rpr=i(Fw),ac=n(Fw,"P",{});var OZ=s(ac);Ppr=r(OZ,`Note:
Loading a model from its configuration file does `),Rbe=n(OZ,"STRONG",{});var DFt=s(Rbe);Bpr=r(DFt,"not"),DFt.forEach(t),Ipr=r(OZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),uW=n(OZ,"A",{href:!0});var GFt=s(uW);qpr=r(GFt,"from_pretrained()"),GFt.forEach(t),Npr=r(OZ," to load the model weights."),OZ.forEach(t),jpr=i(Fw),T(T7.$$.fragment,Fw),Fw.forEach(t),Dpr=i(Ml),$r=n(Ml,"DIV",{class:!0});var El=s($r);T(TL.$$.fragment,El),Gpr=i(El),Pbe=n(El,"P",{});var OFt=s(Pbe);Opr=r(OFt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),OFt.forEach(t),Vpr=i(El),sn=n(El,"P",{});var Tw=s(sn);Xpr=r(Tw,"The model class to instantiate is selected based on the "),Bbe=n(Tw,"CODE",{});var VFt=s(Bbe);zpr=r(VFt,"model_type"),VFt.forEach(t),Qpr=r(Tw,` property of the config object (either
passed as an argument or loaded from `),Ibe=n(Tw,"CODE",{});var XFt=s(Ibe);Wpr=r(XFt,"pretrained_model_name_or_path"),XFt.forEach(t),Hpr=r(Tw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qbe=n(Tw,"CODE",{});var zFt=s(qbe);Upr=r(zFt,"pretrained_model_name_or_path"),zFt.forEach(t),Jpr=r(Tw,":"),Tw.forEach(t),Ypr=i(El),nc=n(El,"UL",{});var VZ=s(nc);M7=n(VZ,"LI",{});var kSe=s(M7);Nbe=n(kSe,"STRONG",{});var QFt=s(Nbe);Kpr=r(QFt,"convnext"),QFt.forEach(t),Zpr=r(kSe," \u2014 "),_W=n(kSe,"A",{href:!0});var WFt=s(_W);eur=r(WFt,"TFConvNextForImageClassification"),WFt.forEach(t),our=r(kSe," (ConvNext model)"),kSe.forEach(t),rur=i(VZ),E7=n(VZ,"LI",{});var SSe=s(E7);jbe=n(SSe,"STRONG",{});var HFt=s(jbe);tur=r(HFt,"data2vec-vision"),HFt.forEach(t),aur=r(SSe," \u2014 "),bW=n(SSe,"A",{href:!0});var UFt=s(bW);nur=r(UFt,"TFData2VecVisionForImageClassification"),UFt.forEach(t),sur=r(SSe," (Data2VecVision model)"),SSe.forEach(t),lur=i(VZ),C7=n(VZ,"LI",{});var RSe=s(C7);Dbe=n(RSe,"STRONG",{});var JFt=s(Dbe);iur=r(JFt,"vit"),JFt.forEach(t),dur=r(RSe," \u2014 "),vW=n(RSe,"A",{href:!0});var YFt=s(vW);cur=r(YFt,"TFViTForImageClassification"),YFt.forEach(t),fur=r(RSe," (ViT model)"),RSe.forEach(t),VZ.forEach(t),mur=i(El),T(w7.$$.fragment,El),El.forEach(t),Ml.forEach(t),rNe=i(f),sc=n(f,"H2",{class:!0});var cDe=s(sc);A7=n(cDe,"A",{id:!0,class:!0,href:!0});var KFt=s(A7);Gbe=n(KFt,"SPAN",{});var ZFt=s(Gbe);T(ML.$$.fragment,ZFt),ZFt.forEach(t),KFt.forEach(t),gur=i(cDe),Obe=n(cDe,"SPAN",{});var e6t=s(Obe);hur=r(e6t,"TFAutoModelForMaskedLM"),e6t.forEach(t),cDe.forEach(t),tNe=i(f),tr=n(f,"DIV",{class:!0});var Cl=s(tr);T(EL.$$.fragment,Cl),pur=i(Cl),lc=n(Cl,"P",{});var XZ=s(lc);uur=r(XZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),FW=n(XZ,"A",{href:!0});var o6t=s(FW);_ur=r(o6t,"from_pretrained()"),o6t.forEach(t),bur=r(XZ," class method or the "),TW=n(XZ,"A",{href:!0});var r6t=s(TW);vur=r(r6t,"from_config()"),r6t.forEach(t),Fur=r(XZ,` class
method.`),XZ.forEach(t),Tur=i(Cl),CL=n(Cl,"P",{});var fDe=s(CL);Mur=r(fDe,"This class cannot be instantiated directly using "),Vbe=n(fDe,"CODE",{});var t6t=s(Vbe);Eur=r(t6t,"__init__()"),t6t.forEach(t),Cur=r(fDe," (throws an error)."),fDe.forEach(t),wur=i(Cl),St=n(Cl,"DIV",{class:!0});var Mw=s(St);T(wL.$$.fragment,Mw),Aur=i(Mw),Xbe=n(Mw,"P",{});var a6t=s(Xbe);yur=r(a6t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),a6t.forEach(t),Lur=i(Mw),ic=n(Mw,"P",{});var zZ=s(ic);xur=r(zZ,`Note:
Loading a model from its configuration file does `),zbe=n(zZ,"STRONG",{});var n6t=s(zbe);$ur=r(n6t,"not"),n6t.forEach(t),kur=r(zZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),MW=n(zZ,"A",{href:!0});var s6t=s(MW);Sur=r(s6t,"from_pretrained()"),s6t.forEach(t),Rur=r(zZ," to load the model weights."),zZ.forEach(t),Pur=i(Mw),T(y7.$$.fragment,Mw),Mw.forEach(t),Bur=i(Cl),kr=n(Cl,"DIV",{class:!0});var wl=s(kr);T(AL.$$.fragment,wl),Iur=i(wl),Qbe=n(wl,"P",{});var l6t=s(Qbe);qur=r(l6t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),l6t.forEach(t),Nur=i(wl),ln=n(wl,"P",{});var Ew=s(ln);jur=r(Ew,"The model class to instantiate is selected based on the "),Wbe=n(Ew,"CODE",{});var i6t=s(Wbe);Dur=r(i6t,"model_type"),i6t.forEach(t),Gur=r(Ew,` property of the config object (either
passed as an argument or loaded from `),Hbe=n(Ew,"CODE",{});var d6t=s(Hbe);Our=r(d6t,"pretrained_model_name_or_path"),d6t.forEach(t),Vur=r(Ew,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ube=n(Ew,"CODE",{});var c6t=s(Ube);Xur=r(c6t,"pretrained_model_name_or_path"),c6t.forEach(t),zur=r(Ew,":"),Ew.forEach(t),Qur=i(wl),ie=n(wl,"UL",{});var fe=s(ie);L7=n(fe,"LI",{});var PSe=s(L7);Jbe=n(PSe,"STRONG",{});var f6t=s(Jbe);Wur=r(f6t,"albert"),f6t.forEach(t),Hur=r(PSe," \u2014 "),EW=n(PSe,"A",{href:!0});var m6t=s(EW);Uur=r(m6t,"TFAlbertForMaskedLM"),m6t.forEach(t),Jur=r(PSe," (ALBERT model)"),PSe.forEach(t),Yur=i(fe),x7=n(fe,"LI",{});var BSe=s(x7);Ybe=n(BSe,"STRONG",{});var g6t=s(Ybe);Kur=r(g6t,"bert"),g6t.forEach(t),Zur=r(BSe," \u2014 "),CW=n(BSe,"A",{href:!0});var h6t=s(CW);e_r=r(h6t,"TFBertForMaskedLM"),h6t.forEach(t),o_r=r(BSe," (BERT model)"),BSe.forEach(t),r_r=i(fe),$7=n(fe,"LI",{});var ISe=s($7);Kbe=n(ISe,"STRONG",{});var p6t=s(Kbe);t_r=r(p6t,"camembert"),p6t.forEach(t),a_r=r(ISe," \u2014 "),wW=n(ISe,"A",{href:!0});var u6t=s(wW);n_r=r(u6t,"TFCamembertForMaskedLM"),u6t.forEach(t),s_r=r(ISe," (CamemBERT model)"),ISe.forEach(t),l_r=i(fe),k7=n(fe,"LI",{});var qSe=s(k7);Zbe=n(qSe,"STRONG",{});var _6t=s(Zbe);i_r=r(_6t,"convbert"),_6t.forEach(t),d_r=r(qSe," \u2014 "),AW=n(qSe,"A",{href:!0});var b6t=s(AW);c_r=r(b6t,"TFConvBertForMaskedLM"),b6t.forEach(t),f_r=r(qSe," (ConvBERT model)"),qSe.forEach(t),m_r=i(fe),S7=n(fe,"LI",{});var NSe=s(S7);eve=n(NSe,"STRONG",{});var v6t=s(eve);g_r=r(v6t,"deberta"),v6t.forEach(t),h_r=r(NSe," \u2014 "),yW=n(NSe,"A",{href:!0});var F6t=s(yW);p_r=r(F6t,"TFDebertaForMaskedLM"),F6t.forEach(t),u_r=r(NSe," (DeBERTa model)"),NSe.forEach(t),__r=i(fe),R7=n(fe,"LI",{});var jSe=s(R7);ove=n(jSe,"STRONG",{});var T6t=s(ove);b_r=r(T6t,"deberta-v2"),T6t.forEach(t),v_r=r(jSe," \u2014 "),LW=n(jSe,"A",{href:!0});var M6t=s(LW);F_r=r(M6t,"TFDebertaV2ForMaskedLM"),M6t.forEach(t),T_r=r(jSe," (DeBERTa-v2 model)"),jSe.forEach(t),M_r=i(fe),P7=n(fe,"LI",{});var DSe=s(P7);rve=n(DSe,"STRONG",{});var E6t=s(rve);E_r=r(E6t,"distilbert"),E6t.forEach(t),C_r=r(DSe," \u2014 "),xW=n(DSe,"A",{href:!0});var C6t=s(xW);w_r=r(C6t,"TFDistilBertForMaskedLM"),C6t.forEach(t),A_r=r(DSe," (DistilBERT model)"),DSe.forEach(t),y_r=i(fe),B7=n(fe,"LI",{});var GSe=s(B7);tve=n(GSe,"STRONG",{});var w6t=s(tve);L_r=r(w6t,"electra"),w6t.forEach(t),x_r=r(GSe," \u2014 "),$W=n(GSe,"A",{href:!0});var A6t=s($W);$_r=r(A6t,"TFElectraForMaskedLM"),A6t.forEach(t),k_r=r(GSe," (ELECTRA model)"),GSe.forEach(t),S_r=i(fe),I7=n(fe,"LI",{});var OSe=s(I7);ave=n(OSe,"STRONG",{});var y6t=s(ave);R_r=r(y6t,"flaubert"),y6t.forEach(t),P_r=r(OSe," \u2014 "),kW=n(OSe,"A",{href:!0});var L6t=s(kW);B_r=r(L6t,"TFFlaubertWithLMHeadModel"),L6t.forEach(t),I_r=r(OSe," (FlauBERT model)"),OSe.forEach(t),q_r=i(fe),q7=n(fe,"LI",{});var VSe=s(q7);nve=n(VSe,"STRONG",{});var x6t=s(nve);N_r=r(x6t,"funnel"),x6t.forEach(t),j_r=r(VSe," \u2014 "),SW=n(VSe,"A",{href:!0});var $6t=s(SW);D_r=r($6t,"TFFunnelForMaskedLM"),$6t.forEach(t),G_r=r(VSe," (Funnel Transformer model)"),VSe.forEach(t),O_r=i(fe),N7=n(fe,"LI",{});var XSe=s(N7);sve=n(XSe,"STRONG",{});var k6t=s(sve);V_r=r(k6t,"layoutlm"),k6t.forEach(t),X_r=r(XSe," \u2014 "),RW=n(XSe,"A",{href:!0});var S6t=s(RW);z_r=r(S6t,"TFLayoutLMForMaskedLM"),S6t.forEach(t),Q_r=r(XSe," (LayoutLM model)"),XSe.forEach(t),W_r=i(fe),j7=n(fe,"LI",{});var zSe=s(j7);lve=n(zSe,"STRONG",{});var R6t=s(lve);H_r=r(R6t,"longformer"),R6t.forEach(t),U_r=r(zSe," \u2014 "),PW=n(zSe,"A",{href:!0});var P6t=s(PW);J_r=r(P6t,"TFLongformerForMaskedLM"),P6t.forEach(t),Y_r=r(zSe," (Longformer model)"),zSe.forEach(t),K_r=i(fe),D7=n(fe,"LI",{});var QSe=s(D7);ive=n(QSe,"STRONG",{});var B6t=s(ive);Z_r=r(B6t,"mobilebert"),B6t.forEach(t),e2r=r(QSe," \u2014 "),BW=n(QSe,"A",{href:!0});var I6t=s(BW);o2r=r(I6t,"TFMobileBertForMaskedLM"),I6t.forEach(t),r2r=r(QSe," (MobileBERT model)"),QSe.forEach(t),t2r=i(fe),G7=n(fe,"LI",{});var WSe=s(G7);dve=n(WSe,"STRONG",{});var q6t=s(dve);a2r=r(q6t,"mpnet"),q6t.forEach(t),n2r=r(WSe," \u2014 "),IW=n(WSe,"A",{href:!0});var N6t=s(IW);s2r=r(N6t,"TFMPNetForMaskedLM"),N6t.forEach(t),l2r=r(WSe," (MPNet model)"),WSe.forEach(t),i2r=i(fe),O7=n(fe,"LI",{});var HSe=s(O7);cve=n(HSe,"STRONG",{});var j6t=s(cve);d2r=r(j6t,"rembert"),j6t.forEach(t),c2r=r(HSe," \u2014 "),qW=n(HSe,"A",{href:!0});var D6t=s(qW);f2r=r(D6t,"TFRemBertForMaskedLM"),D6t.forEach(t),m2r=r(HSe," (RemBERT model)"),HSe.forEach(t),g2r=i(fe),V7=n(fe,"LI",{});var USe=s(V7);fve=n(USe,"STRONG",{});var G6t=s(fve);h2r=r(G6t,"roberta"),G6t.forEach(t),p2r=r(USe," \u2014 "),NW=n(USe,"A",{href:!0});var O6t=s(NW);u2r=r(O6t,"TFRobertaForMaskedLM"),O6t.forEach(t),_2r=r(USe," (RoBERTa model)"),USe.forEach(t),b2r=i(fe),X7=n(fe,"LI",{});var JSe=s(X7);mve=n(JSe,"STRONG",{});var V6t=s(mve);v2r=r(V6t,"roformer"),V6t.forEach(t),F2r=r(JSe," \u2014 "),jW=n(JSe,"A",{href:!0});var X6t=s(jW);T2r=r(X6t,"TFRoFormerForMaskedLM"),X6t.forEach(t),M2r=r(JSe," (RoFormer model)"),JSe.forEach(t),E2r=i(fe),z7=n(fe,"LI",{});var YSe=s(z7);gve=n(YSe,"STRONG",{});var z6t=s(gve);C2r=r(z6t,"tapas"),z6t.forEach(t),w2r=r(YSe," \u2014 "),DW=n(YSe,"A",{href:!0});var Q6t=s(DW);A2r=r(Q6t,"TFTapasForMaskedLM"),Q6t.forEach(t),y2r=r(YSe," (TAPAS model)"),YSe.forEach(t),L2r=i(fe),Q7=n(fe,"LI",{});var KSe=s(Q7);hve=n(KSe,"STRONG",{});var W6t=s(hve);x2r=r(W6t,"xlm"),W6t.forEach(t),$2r=r(KSe," \u2014 "),GW=n(KSe,"A",{href:!0});var H6t=s(GW);k2r=r(H6t,"TFXLMWithLMHeadModel"),H6t.forEach(t),S2r=r(KSe," (XLM model)"),KSe.forEach(t),R2r=i(fe),W7=n(fe,"LI",{});var ZSe=s(W7);pve=n(ZSe,"STRONG",{});var U6t=s(pve);P2r=r(U6t,"xlm-roberta"),U6t.forEach(t),B2r=r(ZSe," \u2014 "),OW=n(ZSe,"A",{href:!0});var J6t=s(OW);I2r=r(J6t,"TFXLMRobertaForMaskedLM"),J6t.forEach(t),q2r=r(ZSe," (XLM-RoBERTa model)"),ZSe.forEach(t),fe.forEach(t),N2r=i(wl),T(H7.$$.fragment,wl),wl.forEach(t),Cl.forEach(t),aNe=i(f),dc=n(f,"H2",{class:!0});var mDe=s(dc);U7=n(mDe,"A",{id:!0,class:!0,href:!0});var Y6t=s(U7);uve=n(Y6t,"SPAN",{});var K6t=s(uve);T(yL.$$.fragment,K6t),K6t.forEach(t),Y6t.forEach(t),j2r=i(mDe),_ve=n(mDe,"SPAN",{});var Z6t=s(_ve);D2r=r(Z6t,"TFAutoModelForSeq2SeqLM"),Z6t.forEach(t),mDe.forEach(t),nNe=i(f),ar=n(f,"DIV",{class:!0});var Al=s(ar);T(LL.$$.fragment,Al),G2r=i(Al),cc=n(Al,"P",{});var QZ=s(cc);O2r=r(QZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),VW=n(QZ,"A",{href:!0});var eTt=s(VW);V2r=r(eTt,"from_pretrained()"),eTt.forEach(t),X2r=r(QZ," class method or the "),XW=n(QZ,"A",{href:!0});var oTt=s(XW);z2r=r(oTt,"from_config()"),oTt.forEach(t),Q2r=r(QZ,` class
method.`),QZ.forEach(t),W2r=i(Al),xL=n(Al,"P",{});var gDe=s(xL);H2r=r(gDe,"This class cannot be instantiated directly using "),bve=n(gDe,"CODE",{});var rTt=s(bve);U2r=r(rTt,"__init__()"),rTt.forEach(t),J2r=r(gDe," (throws an error)."),gDe.forEach(t),Y2r=i(Al),Rt=n(Al,"DIV",{class:!0});var Cw=s(Rt);T($L.$$.fragment,Cw),K2r=i(Cw),vve=n(Cw,"P",{});var tTt=s(vve);Z2r=r(tTt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),tTt.forEach(t),e1r=i(Cw),fc=n(Cw,"P",{});var WZ=s(fc);o1r=r(WZ,`Note:
Loading a model from its configuration file does `),Fve=n(WZ,"STRONG",{});var aTt=s(Fve);r1r=r(aTt,"not"),aTt.forEach(t),t1r=r(WZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),zW=n(WZ,"A",{href:!0});var nTt=s(zW);a1r=r(nTt,"from_pretrained()"),nTt.forEach(t),n1r=r(WZ," to load the model weights."),WZ.forEach(t),s1r=i(Cw),T(J7.$$.fragment,Cw),Cw.forEach(t),l1r=i(Al),Sr=n(Al,"DIV",{class:!0});var yl=s(Sr);T(kL.$$.fragment,yl),i1r=i(yl),Tve=n(yl,"P",{});var sTt=s(Tve);d1r=r(sTt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),sTt.forEach(t),c1r=i(yl),dn=n(yl,"P",{});var ww=s(dn);f1r=r(ww,"The model class to instantiate is selected based on the "),Mve=n(ww,"CODE",{});var lTt=s(Mve);m1r=r(lTt,"model_type"),lTt.forEach(t),g1r=r(ww,` property of the config object (either
passed as an argument or loaded from `),Eve=n(ww,"CODE",{});var iTt=s(Eve);h1r=r(iTt,"pretrained_model_name_or_path"),iTt.forEach(t),p1r=r(ww,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cve=n(ww,"CODE",{});var dTt=s(Cve);u1r=r(dTt,"pretrained_model_name_or_path"),dTt.forEach(t),_1r=r(ww,":"),ww.forEach(t),b1r=i(yl),ye=n(yl,"UL",{});var Re=s(ye);Y7=n(Re,"LI",{});var eRe=s(Y7);wve=n(eRe,"STRONG",{});var cTt=s(wve);v1r=r(cTt,"bart"),cTt.forEach(t),F1r=r(eRe," \u2014 "),QW=n(eRe,"A",{href:!0});var fTt=s(QW);T1r=r(fTt,"TFBartForConditionalGeneration"),fTt.forEach(t),M1r=r(eRe," (BART model)"),eRe.forEach(t),E1r=i(Re),K7=n(Re,"LI",{});var oRe=s(K7);Ave=n(oRe,"STRONG",{});var mTt=s(Ave);C1r=r(mTt,"blenderbot"),mTt.forEach(t),w1r=r(oRe," \u2014 "),WW=n(oRe,"A",{href:!0});var gTt=s(WW);A1r=r(gTt,"TFBlenderbotForConditionalGeneration"),gTt.forEach(t),y1r=r(oRe," (Blenderbot model)"),oRe.forEach(t),L1r=i(Re),Z7=n(Re,"LI",{});var rRe=s(Z7);yve=n(rRe,"STRONG",{});var hTt=s(yve);x1r=r(hTt,"blenderbot-small"),hTt.forEach(t),$1r=r(rRe," \u2014 "),HW=n(rRe,"A",{href:!0});var pTt=s(HW);k1r=r(pTt,"TFBlenderbotSmallForConditionalGeneration"),pTt.forEach(t),S1r=r(rRe," (BlenderbotSmall model)"),rRe.forEach(t),R1r=i(Re),eM=n(Re,"LI",{});var tRe=s(eM);Lve=n(tRe,"STRONG",{});var uTt=s(Lve);P1r=r(uTt,"encoder-decoder"),uTt.forEach(t),B1r=r(tRe," \u2014 "),UW=n(tRe,"A",{href:!0});var _Tt=s(UW);I1r=r(_Tt,"TFEncoderDecoderModel"),_Tt.forEach(t),q1r=r(tRe," (Encoder decoder model)"),tRe.forEach(t),N1r=i(Re),oM=n(Re,"LI",{});var aRe=s(oM);xve=n(aRe,"STRONG",{});var bTt=s(xve);j1r=r(bTt,"led"),bTt.forEach(t),D1r=r(aRe," \u2014 "),JW=n(aRe,"A",{href:!0});var vTt=s(JW);G1r=r(vTt,"TFLEDForConditionalGeneration"),vTt.forEach(t),O1r=r(aRe," (LED model)"),aRe.forEach(t),V1r=i(Re),rM=n(Re,"LI",{});var nRe=s(rM);$ve=n(nRe,"STRONG",{});var FTt=s($ve);X1r=r(FTt,"marian"),FTt.forEach(t),z1r=r(nRe," \u2014 "),YW=n(nRe,"A",{href:!0});var TTt=s(YW);Q1r=r(TTt,"TFMarianMTModel"),TTt.forEach(t),W1r=r(nRe," (Marian model)"),nRe.forEach(t),H1r=i(Re),tM=n(Re,"LI",{});var sRe=s(tM);kve=n(sRe,"STRONG",{});var MTt=s(kve);U1r=r(MTt,"mbart"),MTt.forEach(t),J1r=r(sRe," \u2014 "),KW=n(sRe,"A",{href:!0});var ETt=s(KW);Y1r=r(ETt,"TFMBartForConditionalGeneration"),ETt.forEach(t),K1r=r(sRe," (mBART model)"),sRe.forEach(t),Z1r=i(Re),aM=n(Re,"LI",{});var lRe=s(aM);Sve=n(lRe,"STRONG",{});var CTt=s(Sve);ebr=r(CTt,"mt5"),CTt.forEach(t),obr=r(lRe," \u2014 "),ZW=n(lRe,"A",{href:!0});var wTt=s(ZW);rbr=r(wTt,"TFMT5ForConditionalGeneration"),wTt.forEach(t),tbr=r(lRe," (mT5 model)"),lRe.forEach(t),abr=i(Re),nM=n(Re,"LI",{});var iRe=s(nM);Rve=n(iRe,"STRONG",{});var ATt=s(Rve);nbr=r(ATt,"pegasus"),ATt.forEach(t),sbr=r(iRe," \u2014 "),eH=n(iRe,"A",{href:!0});var yTt=s(eH);lbr=r(yTt,"TFPegasusForConditionalGeneration"),yTt.forEach(t),ibr=r(iRe," (Pegasus model)"),iRe.forEach(t),dbr=i(Re),sM=n(Re,"LI",{});var dRe=s(sM);Pve=n(dRe,"STRONG",{});var LTt=s(Pve);cbr=r(LTt,"t5"),LTt.forEach(t),fbr=r(dRe," \u2014 "),oH=n(dRe,"A",{href:!0});var xTt=s(oH);mbr=r(xTt,"TFT5ForConditionalGeneration"),xTt.forEach(t),gbr=r(dRe," (T5 model)"),dRe.forEach(t),Re.forEach(t),hbr=i(yl),T(lM.$$.fragment,yl),yl.forEach(t),Al.forEach(t),sNe=i(f),mc=n(f,"H2",{class:!0});var hDe=s(mc);iM=n(hDe,"A",{id:!0,class:!0,href:!0});var $Tt=s(iM);Bve=n($Tt,"SPAN",{});var kTt=s(Bve);T(SL.$$.fragment,kTt),kTt.forEach(t),$Tt.forEach(t),pbr=i(hDe),Ive=n(hDe,"SPAN",{});var STt=s(Ive);ubr=r(STt,"TFAutoModelForSequenceClassification"),STt.forEach(t),hDe.forEach(t),lNe=i(f),nr=n(f,"DIV",{class:!0});var Ll=s(nr);T(RL.$$.fragment,Ll),_br=i(Ll),gc=n(Ll,"P",{});var HZ=s(gc);bbr=r(HZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),rH=n(HZ,"A",{href:!0});var RTt=s(rH);vbr=r(RTt,"from_pretrained()"),RTt.forEach(t),Fbr=r(HZ," class method or the "),tH=n(HZ,"A",{href:!0});var PTt=s(tH);Tbr=r(PTt,"from_config()"),PTt.forEach(t),Mbr=r(HZ,` class
method.`),HZ.forEach(t),Ebr=i(Ll),PL=n(Ll,"P",{});var pDe=s(PL);Cbr=r(pDe,"This class cannot be instantiated directly using "),qve=n(pDe,"CODE",{});var BTt=s(qve);wbr=r(BTt,"__init__()"),BTt.forEach(t),Abr=r(pDe," (throws an error)."),pDe.forEach(t),ybr=i(Ll),Pt=n(Ll,"DIV",{class:!0});var Aw=s(Pt);T(BL.$$.fragment,Aw),Lbr=i(Aw),Nve=n(Aw,"P",{});var ITt=s(Nve);xbr=r(ITt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),ITt.forEach(t),$br=i(Aw),hc=n(Aw,"P",{});var UZ=s(hc);kbr=r(UZ,`Note:
Loading a model from its configuration file does `),jve=n(UZ,"STRONG",{});var qTt=s(jve);Sbr=r(qTt,"not"),qTt.forEach(t),Rbr=r(UZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),aH=n(UZ,"A",{href:!0});var NTt=s(aH);Pbr=r(NTt,"from_pretrained()"),NTt.forEach(t),Bbr=r(UZ," to load the model weights."),UZ.forEach(t),Ibr=i(Aw),T(dM.$$.fragment,Aw),Aw.forEach(t),qbr=i(Ll),Rr=n(Ll,"DIV",{class:!0});var xl=s(Rr);T(IL.$$.fragment,xl),Nbr=i(xl),Dve=n(xl,"P",{});var jTt=s(Dve);jbr=r(jTt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),jTt.forEach(t),Dbr=i(xl),cn=n(xl,"P",{});var yw=s(cn);Gbr=r(yw,"The model class to instantiate is selected based on the "),Gve=n(yw,"CODE",{});var DTt=s(Gve);Obr=r(DTt,"model_type"),DTt.forEach(t),Vbr=r(yw,` property of the config object (either
passed as an argument or loaded from `),Ove=n(yw,"CODE",{});var GTt=s(Ove);Xbr=r(GTt,"pretrained_model_name_or_path"),GTt.forEach(t),zbr=r(yw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vve=n(yw,"CODE",{});var OTt=s(Vve);Qbr=r(OTt,"pretrained_model_name_or_path"),OTt.forEach(t),Wbr=r(yw,":"),yw.forEach(t),Hbr=i(xl),oe=n(xl,"UL",{});var ae=s(oe);cM=n(ae,"LI",{});var cRe=s(cM);Xve=n(cRe,"STRONG",{});var VTt=s(Xve);Ubr=r(VTt,"albert"),VTt.forEach(t),Jbr=r(cRe," \u2014 "),nH=n(cRe,"A",{href:!0});var XTt=s(nH);Ybr=r(XTt,"TFAlbertForSequenceClassification"),XTt.forEach(t),Kbr=r(cRe," (ALBERT model)"),cRe.forEach(t),Zbr=i(ae),fM=n(ae,"LI",{});var fRe=s(fM);zve=n(fRe,"STRONG",{});var zTt=s(zve);evr=r(zTt,"bert"),zTt.forEach(t),ovr=r(fRe," \u2014 "),sH=n(fRe,"A",{href:!0});var QTt=s(sH);rvr=r(QTt,"TFBertForSequenceClassification"),QTt.forEach(t),tvr=r(fRe," (BERT model)"),fRe.forEach(t),avr=i(ae),mM=n(ae,"LI",{});var mRe=s(mM);Qve=n(mRe,"STRONG",{});var WTt=s(Qve);nvr=r(WTt,"camembert"),WTt.forEach(t),svr=r(mRe," \u2014 "),lH=n(mRe,"A",{href:!0});var HTt=s(lH);lvr=r(HTt,"TFCamembertForSequenceClassification"),HTt.forEach(t),ivr=r(mRe," (CamemBERT model)"),mRe.forEach(t),dvr=i(ae),gM=n(ae,"LI",{});var gRe=s(gM);Wve=n(gRe,"STRONG",{});var UTt=s(Wve);cvr=r(UTt,"convbert"),UTt.forEach(t),fvr=r(gRe," \u2014 "),iH=n(gRe,"A",{href:!0});var JTt=s(iH);mvr=r(JTt,"TFConvBertForSequenceClassification"),JTt.forEach(t),gvr=r(gRe," (ConvBERT model)"),gRe.forEach(t),hvr=i(ae),hM=n(ae,"LI",{});var hRe=s(hM);Hve=n(hRe,"STRONG",{});var YTt=s(Hve);pvr=r(YTt,"ctrl"),YTt.forEach(t),uvr=r(hRe," \u2014 "),dH=n(hRe,"A",{href:!0});var KTt=s(dH);_vr=r(KTt,"TFCTRLForSequenceClassification"),KTt.forEach(t),bvr=r(hRe," (CTRL model)"),hRe.forEach(t),vvr=i(ae),pM=n(ae,"LI",{});var pRe=s(pM);Uve=n(pRe,"STRONG",{});var ZTt=s(Uve);Fvr=r(ZTt,"deberta"),ZTt.forEach(t),Tvr=r(pRe," \u2014 "),cH=n(pRe,"A",{href:!0});var e8t=s(cH);Mvr=r(e8t,"TFDebertaForSequenceClassification"),e8t.forEach(t),Evr=r(pRe," (DeBERTa model)"),pRe.forEach(t),Cvr=i(ae),uM=n(ae,"LI",{});var uRe=s(uM);Jve=n(uRe,"STRONG",{});var o8t=s(Jve);wvr=r(o8t,"deberta-v2"),o8t.forEach(t),Avr=r(uRe," \u2014 "),fH=n(uRe,"A",{href:!0});var r8t=s(fH);yvr=r(r8t,"TFDebertaV2ForSequenceClassification"),r8t.forEach(t),Lvr=r(uRe," (DeBERTa-v2 model)"),uRe.forEach(t),xvr=i(ae),_M=n(ae,"LI",{});var _Re=s(_M);Yve=n(_Re,"STRONG",{});var t8t=s(Yve);$vr=r(t8t,"distilbert"),t8t.forEach(t),kvr=r(_Re," \u2014 "),mH=n(_Re,"A",{href:!0});var a8t=s(mH);Svr=r(a8t,"TFDistilBertForSequenceClassification"),a8t.forEach(t),Rvr=r(_Re," (DistilBERT model)"),_Re.forEach(t),Pvr=i(ae),bM=n(ae,"LI",{});var bRe=s(bM);Kve=n(bRe,"STRONG",{});var n8t=s(Kve);Bvr=r(n8t,"electra"),n8t.forEach(t),Ivr=r(bRe," \u2014 "),gH=n(bRe,"A",{href:!0});var s8t=s(gH);qvr=r(s8t,"TFElectraForSequenceClassification"),s8t.forEach(t),Nvr=r(bRe," (ELECTRA model)"),bRe.forEach(t),jvr=i(ae),vM=n(ae,"LI",{});var vRe=s(vM);Zve=n(vRe,"STRONG",{});var l8t=s(Zve);Dvr=r(l8t,"flaubert"),l8t.forEach(t),Gvr=r(vRe," \u2014 "),hH=n(vRe,"A",{href:!0});var i8t=s(hH);Ovr=r(i8t,"TFFlaubertForSequenceClassification"),i8t.forEach(t),Vvr=r(vRe," (FlauBERT model)"),vRe.forEach(t),Xvr=i(ae),FM=n(ae,"LI",{});var FRe=s(FM);eFe=n(FRe,"STRONG",{});var d8t=s(eFe);zvr=r(d8t,"funnel"),d8t.forEach(t),Qvr=r(FRe," \u2014 "),pH=n(FRe,"A",{href:!0});var c8t=s(pH);Wvr=r(c8t,"TFFunnelForSequenceClassification"),c8t.forEach(t),Hvr=r(FRe," (Funnel Transformer model)"),FRe.forEach(t),Uvr=i(ae),TM=n(ae,"LI",{});var TRe=s(TM);oFe=n(TRe,"STRONG",{});var f8t=s(oFe);Jvr=r(f8t,"gpt2"),f8t.forEach(t),Yvr=r(TRe," \u2014 "),uH=n(TRe,"A",{href:!0});var m8t=s(uH);Kvr=r(m8t,"TFGPT2ForSequenceClassification"),m8t.forEach(t),Zvr=r(TRe," (OpenAI GPT-2 model)"),TRe.forEach(t),eFr=i(ae),MM=n(ae,"LI",{});var MRe=s(MM);rFe=n(MRe,"STRONG",{});var g8t=s(rFe);oFr=r(g8t,"gptj"),g8t.forEach(t),rFr=r(MRe," \u2014 "),_H=n(MRe,"A",{href:!0});var h8t=s(_H);tFr=r(h8t,"TFGPTJForSequenceClassification"),h8t.forEach(t),aFr=r(MRe," (GPT-J model)"),MRe.forEach(t),nFr=i(ae),EM=n(ae,"LI",{});var ERe=s(EM);tFe=n(ERe,"STRONG",{});var p8t=s(tFe);sFr=r(p8t,"layoutlm"),p8t.forEach(t),lFr=r(ERe," \u2014 "),bH=n(ERe,"A",{href:!0});var u8t=s(bH);iFr=r(u8t,"TFLayoutLMForSequenceClassification"),u8t.forEach(t),dFr=r(ERe," (LayoutLM model)"),ERe.forEach(t),cFr=i(ae),CM=n(ae,"LI",{});var CRe=s(CM);aFe=n(CRe,"STRONG",{});var _8t=s(aFe);fFr=r(_8t,"longformer"),_8t.forEach(t),mFr=r(CRe," \u2014 "),vH=n(CRe,"A",{href:!0});var b8t=s(vH);gFr=r(b8t,"TFLongformerForSequenceClassification"),b8t.forEach(t),hFr=r(CRe," (Longformer model)"),CRe.forEach(t),pFr=i(ae),wM=n(ae,"LI",{});var wRe=s(wM);nFe=n(wRe,"STRONG",{});var v8t=s(nFe);uFr=r(v8t,"mobilebert"),v8t.forEach(t),_Fr=r(wRe," \u2014 "),FH=n(wRe,"A",{href:!0});var F8t=s(FH);bFr=r(F8t,"TFMobileBertForSequenceClassification"),F8t.forEach(t),vFr=r(wRe," (MobileBERT model)"),wRe.forEach(t),FFr=i(ae),AM=n(ae,"LI",{});var ARe=s(AM);sFe=n(ARe,"STRONG",{});var T8t=s(sFe);TFr=r(T8t,"mpnet"),T8t.forEach(t),MFr=r(ARe," \u2014 "),TH=n(ARe,"A",{href:!0});var M8t=s(TH);EFr=r(M8t,"TFMPNetForSequenceClassification"),M8t.forEach(t),CFr=r(ARe," (MPNet model)"),ARe.forEach(t),wFr=i(ae),yM=n(ae,"LI",{});var yRe=s(yM);lFe=n(yRe,"STRONG",{});var E8t=s(lFe);AFr=r(E8t,"openai-gpt"),E8t.forEach(t),yFr=r(yRe," \u2014 "),MH=n(yRe,"A",{href:!0});var C8t=s(MH);LFr=r(C8t,"TFOpenAIGPTForSequenceClassification"),C8t.forEach(t),xFr=r(yRe," (OpenAI GPT model)"),yRe.forEach(t),$Fr=i(ae),LM=n(ae,"LI",{});var LRe=s(LM);iFe=n(LRe,"STRONG",{});var w8t=s(iFe);kFr=r(w8t,"rembert"),w8t.forEach(t),SFr=r(LRe," \u2014 "),EH=n(LRe,"A",{href:!0});var A8t=s(EH);RFr=r(A8t,"TFRemBertForSequenceClassification"),A8t.forEach(t),PFr=r(LRe," (RemBERT model)"),LRe.forEach(t),BFr=i(ae),xM=n(ae,"LI",{});var xRe=s(xM);dFe=n(xRe,"STRONG",{});var y8t=s(dFe);IFr=r(y8t,"roberta"),y8t.forEach(t),qFr=r(xRe," \u2014 "),CH=n(xRe,"A",{href:!0});var L8t=s(CH);NFr=r(L8t,"TFRobertaForSequenceClassification"),L8t.forEach(t),jFr=r(xRe," (RoBERTa model)"),xRe.forEach(t),DFr=i(ae),$M=n(ae,"LI",{});var $Re=s($M);cFe=n($Re,"STRONG",{});var x8t=s(cFe);GFr=r(x8t,"roformer"),x8t.forEach(t),OFr=r($Re," \u2014 "),wH=n($Re,"A",{href:!0});var $8t=s(wH);VFr=r($8t,"TFRoFormerForSequenceClassification"),$8t.forEach(t),XFr=r($Re," (RoFormer model)"),$Re.forEach(t),zFr=i(ae),kM=n(ae,"LI",{});var kRe=s(kM);fFe=n(kRe,"STRONG",{});var k8t=s(fFe);QFr=r(k8t,"tapas"),k8t.forEach(t),WFr=r(kRe," \u2014 "),AH=n(kRe,"A",{href:!0});var S8t=s(AH);HFr=r(S8t,"TFTapasForSequenceClassification"),S8t.forEach(t),UFr=r(kRe," (TAPAS model)"),kRe.forEach(t),JFr=i(ae),SM=n(ae,"LI",{});var SRe=s(SM);mFe=n(SRe,"STRONG",{});var R8t=s(mFe);YFr=r(R8t,"transfo-xl"),R8t.forEach(t),KFr=r(SRe," \u2014 "),yH=n(SRe,"A",{href:!0});var P8t=s(yH);ZFr=r(P8t,"TFTransfoXLForSequenceClassification"),P8t.forEach(t),e6r=r(SRe," (Transformer-XL model)"),SRe.forEach(t),o6r=i(ae),RM=n(ae,"LI",{});var RRe=s(RM);gFe=n(RRe,"STRONG",{});var B8t=s(gFe);r6r=r(B8t,"xlm"),B8t.forEach(t),t6r=r(RRe," \u2014 "),LH=n(RRe,"A",{href:!0});var I8t=s(LH);a6r=r(I8t,"TFXLMForSequenceClassification"),I8t.forEach(t),n6r=r(RRe," (XLM model)"),RRe.forEach(t),s6r=i(ae),PM=n(ae,"LI",{});var PRe=s(PM);hFe=n(PRe,"STRONG",{});var q8t=s(hFe);l6r=r(q8t,"xlm-roberta"),q8t.forEach(t),i6r=r(PRe," \u2014 "),xH=n(PRe,"A",{href:!0});var N8t=s(xH);d6r=r(N8t,"TFXLMRobertaForSequenceClassification"),N8t.forEach(t),c6r=r(PRe," (XLM-RoBERTa model)"),PRe.forEach(t),f6r=i(ae),BM=n(ae,"LI",{});var BRe=s(BM);pFe=n(BRe,"STRONG",{});var j8t=s(pFe);m6r=r(j8t,"xlnet"),j8t.forEach(t),g6r=r(BRe," \u2014 "),$H=n(BRe,"A",{href:!0});var D8t=s($H);h6r=r(D8t,"TFXLNetForSequenceClassification"),D8t.forEach(t),p6r=r(BRe," (XLNet model)"),BRe.forEach(t),ae.forEach(t),u6r=i(xl),T(IM.$$.fragment,xl),xl.forEach(t),Ll.forEach(t),iNe=i(f),pc=n(f,"H2",{class:!0});var uDe=s(pc);qM=n(uDe,"A",{id:!0,class:!0,href:!0});var G8t=s(qM);uFe=n(G8t,"SPAN",{});var O8t=s(uFe);T(qL.$$.fragment,O8t),O8t.forEach(t),G8t.forEach(t),_6r=i(uDe),_Fe=n(uDe,"SPAN",{});var V8t=s(_Fe);b6r=r(V8t,"TFAutoModelForMultipleChoice"),V8t.forEach(t),uDe.forEach(t),dNe=i(f),sr=n(f,"DIV",{class:!0});var $l=s(sr);T(NL.$$.fragment,$l),v6r=i($l),uc=n($l,"P",{});var JZ=s(uc);F6r=r(JZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),kH=n(JZ,"A",{href:!0});var X8t=s(kH);T6r=r(X8t,"from_pretrained()"),X8t.forEach(t),M6r=r(JZ," class method or the "),SH=n(JZ,"A",{href:!0});var z8t=s(SH);E6r=r(z8t,"from_config()"),z8t.forEach(t),C6r=r(JZ,` class
method.`),JZ.forEach(t),w6r=i($l),jL=n($l,"P",{});var _De=s(jL);A6r=r(_De,"This class cannot be instantiated directly using "),bFe=n(_De,"CODE",{});var Q8t=s(bFe);y6r=r(Q8t,"__init__()"),Q8t.forEach(t),L6r=r(_De," (throws an error)."),_De.forEach(t),x6r=i($l),Bt=n($l,"DIV",{class:!0});var Lw=s(Bt);T(DL.$$.fragment,Lw),$6r=i(Lw),vFe=n(Lw,"P",{});var W8t=s(vFe);k6r=r(W8t,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),W8t.forEach(t),S6r=i(Lw),_c=n(Lw,"P",{});var YZ=s(_c);R6r=r(YZ,`Note:
Loading a model from its configuration file does `),FFe=n(YZ,"STRONG",{});var H8t=s(FFe);P6r=r(H8t,"not"),H8t.forEach(t),B6r=r(YZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),RH=n(YZ,"A",{href:!0});var U8t=s(RH);I6r=r(U8t,"from_pretrained()"),U8t.forEach(t),q6r=r(YZ," to load the model weights."),YZ.forEach(t),N6r=i(Lw),T(NM.$$.fragment,Lw),Lw.forEach(t),j6r=i($l),Pr=n($l,"DIV",{class:!0});var kl=s(Pr);T(GL.$$.fragment,kl),D6r=i(kl),TFe=n(kl,"P",{});var J8t=s(TFe);G6r=r(J8t,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),J8t.forEach(t),O6r=i(kl),fn=n(kl,"P",{});var xw=s(fn);V6r=r(xw,"The model class to instantiate is selected based on the "),MFe=n(xw,"CODE",{});var Y8t=s(MFe);X6r=r(Y8t,"model_type"),Y8t.forEach(t),z6r=r(xw,` property of the config object (either
passed as an argument or loaded from `),EFe=n(xw,"CODE",{});var K8t=s(EFe);Q6r=r(K8t,"pretrained_model_name_or_path"),K8t.forEach(t),W6r=r(xw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CFe=n(xw,"CODE",{});var Z8t=s(CFe);H6r=r(Z8t,"pretrained_model_name_or_path"),Z8t.forEach(t),U6r=r(xw,":"),xw.forEach(t),J6r=i(kl),pe=n(kl,"UL",{});var _e=s(pe);jM=n(_e,"LI",{});var IRe=s(jM);wFe=n(IRe,"STRONG",{});var e7t=s(wFe);Y6r=r(e7t,"albert"),e7t.forEach(t),K6r=r(IRe," \u2014 "),PH=n(IRe,"A",{href:!0});var o7t=s(PH);Z6r=r(o7t,"TFAlbertForMultipleChoice"),o7t.forEach(t),eTr=r(IRe," (ALBERT model)"),IRe.forEach(t),oTr=i(_e),DM=n(_e,"LI",{});var qRe=s(DM);AFe=n(qRe,"STRONG",{});var r7t=s(AFe);rTr=r(r7t,"bert"),r7t.forEach(t),tTr=r(qRe," \u2014 "),BH=n(qRe,"A",{href:!0});var t7t=s(BH);aTr=r(t7t,"TFBertForMultipleChoice"),t7t.forEach(t),nTr=r(qRe," (BERT model)"),qRe.forEach(t),sTr=i(_e),GM=n(_e,"LI",{});var NRe=s(GM);yFe=n(NRe,"STRONG",{});var a7t=s(yFe);lTr=r(a7t,"camembert"),a7t.forEach(t),iTr=r(NRe," \u2014 "),IH=n(NRe,"A",{href:!0});var n7t=s(IH);dTr=r(n7t,"TFCamembertForMultipleChoice"),n7t.forEach(t),cTr=r(NRe," (CamemBERT model)"),NRe.forEach(t),fTr=i(_e),OM=n(_e,"LI",{});var jRe=s(OM);LFe=n(jRe,"STRONG",{});var s7t=s(LFe);mTr=r(s7t,"convbert"),s7t.forEach(t),gTr=r(jRe," \u2014 "),qH=n(jRe,"A",{href:!0});var l7t=s(qH);hTr=r(l7t,"TFConvBertForMultipleChoice"),l7t.forEach(t),pTr=r(jRe," (ConvBERT model)"),jRe.forEach(t),uTr=i(_e),VM=n(_e,"LI",{});var DRe=s(VM);xFe=n(DRe,"STRONG",{});var i7t=s(xFe);_Tr=r(i7t,"distilbert"),i7t.forEach(t),bTr=r(DRe," \u2014 "),NH=n(DRe,"A",{href:!0});var d7t=s(NH);vTr=r(d7t,"TFDistilBertForMultipleChoice"),d7t.forEach(t),FTr=r(DRe," (DistilBERT model)"),DRe.forEach(t),TTr=i(_e),XM=n(_e,"LI",{});var GRe=s(XM);$Fe=n(GRe,"STRONG",{});var c7t=s($Fe);MTr=r(c7t,"electra"),c7t.forEach(t),ETr=r(GRe," \u2014 "),jH=n(GRe,"A",{href:!0});var f7t=s(jH);CTr=r(f7t,"TFElectraForMultipleChoice"),f7t.forEach(t),wTr=r(GRe," (ELECTRA model)"),GRe.forEach(t),ATr=i(_e),zM=n(_e,"LI",{});var ORe=s(zM);kFe=n(ORe,"STRONG",{});var m7t=s(kFe);yTr=r(m7t,"flaubert"),m7t.forEach(t),LTr=r(ORe," \u2014 "),DH=n(ORe,"A",{href:!0});var g7t=s(DH);xTr=r(g7t,"TFFlaubertForMultipleChoice"),g7t.forEach(t),$Tr=r(ORe," (FlauBERT model)"),ORe.forEach(t),kTr=i(_e),QM=n(_e,"LI",{});var VRe=s(QM);SFe=n(VRe,"STRONG",{});var h7t=s(SFe);STr=r(h7t,"funnel"),h7t.forEach(t),RTr=r(VRe," \u2014 "),GH=n(VRe,"A",{href:!0});var p7t=s(GH);PTr=r(p7t,"TFFunnelForMultipleChoice"),p7t.forEach(t),BTr=r(VRe," (Funnel Transformer model)"),VRe.forEach(t),ITr=i(_e),WM=n(_e,"LI",{});var XRe=s(WM);RFe=n(XRe,"STRONG",{});var u7t=s(RFe);qTr=r(u7t,"longformer"),u7t.forEach(t),NTr=r(XRe," \u2014 "),OH=n(XRe,"A",{href:!0});var _7t=s(OH);jTr=r(_7t,"TFLongformerForMultipleChoice"),_7t.forEach(t),DTr=r(XRe," (Longformer model)"),XRe.forEach(t),GTr=i(_e),HM=n(_e,"LI",{});var zRe=s(HM);PFe=n(zRe,"STRONG",{});var b7t=s(PFe);OTr=r(b7t,"mobilebert"),b7t.forEach(t),VTr=r(zRe," \u2014 "),VH=n(zRe,"A",{href:!0});var v7t=s(VH);XTr=r(v7t,"TFMobileBertForMultipleChoice"),v7t.forEach(t),zTr=r(zRe," (MobileBERT model)"),zRe.forEach(t),QTr=i(_e),UM=n(_e,"LI",{});var QRe=s(UM);BFe=n(QRe,"STRONG",{});var F7t=s(BFe);WTr=r(F7t,"mpnet"),F7t.forEach(t),HTr=r(QRe," \u2014 "),XH=n(QRe,"A",{href:!0});var T7t=s(XH);UTr=r(T7t,"TFMPNetForMultipleChoice"),T7t.forEach(t),JTr=r(QRe," (MPNet model)"),QRe.forEach(t),YTr=i(_e),JM=n(_e,"LI",{});var WRe=s(JM);IFe=n(WRe,"STRONG",{});var M7t=s(IFe);KTr=r(M7t,"rembert"),M7t.forEach(t),ZTr=r(WRe," \u2014 "),zH=n(WRe,"A",{href:!0});var E7t=s(zH);e8r=r(E7t,"TFRemBertForMultipleChoice"),E7t.forEach(t),o8r=r(WRe," (RemBERT model)"),WRe.forEach(t),r8r=i(_e),YM=n(_e,"LI",{});var HRe=s(YM);qFe=n(HRe,"STRONG",{});var C7t=s(qFe);t8r=r(C7t,"roberta"),C7t.forEach(t),a8r=r(HRe," \u2014 "),QH=n(HRe,"A",{href:!0});var w7t=s(QH);n8r=r(w7t,"TFRobertaForMultipleChoice"),w7t.forEach(t),s8r=r(HRe," (RoBERTa model)"),HRe.forEach(t),l8r=i(_e),KM=n(_e,"LI",{});var URe=s(KM);NFe=n(URe,"STRONG",{});var A7t=s(NFe);i8r=r(A7t,"roformer"),A7t.forEach(t),d8r=r(URe," \u2014 "),WH=n(URe,"A",{href:!0});var y7t=s(WH);c8r=r(y7t,"TFRoFormerForMultipleChoice"),y7t.forEach(t),f8r=r(URe," (RoFormer model)"),URe.forEach(t),m8r=i(_e),ZM=n(_e,"LI",{});var JRe=s(ZM);jFe=n(JRe,"STRONG",{});var L7t=s(jFe);g8r=r(L7t,"xlm"),L7t.forEach(t),h8r=r(JRe," \u2014 "),HH=n(JRe,"A",{href:!0});var x7t=s(HH);p8r=r(x7t,"TFXLMForMultipleChoice"),x7t.forEach(t),u8r=r(JRe," (XLM model)"),JRe.forEach(t),_8r=i(_e),e4=n(_e,"LI",{});var YRe=s(e4);DFe=n(YRe,"STRONG",{});var $7t=s(DFe);b8r=r($7t,"xlm-roberta"),$7t.forEach(t),v8r=r(YRe," \u2014 "),UH=n(YRe,"A",{href:!0});var k7t=s(UH);F8r=r(k7t,"TFXLMRobertaForMultipleChoice"),k7t.forEach(t),T8r=r(YRe," (XLM-RoBERTa model)"),YRe.forEach(t),M8r=i(_e),o4=n(_e,"LI",{});var KRe=s(o4);GFe=n(KRe,"STRONG",{});var S7t=s(GFe);E8r=r(S7t,"xlnet"),S7t.forEach(t),C8r=r(KRe," \u2014 "),JH=n(KRe,"A",{href:!0});var R7t=s(JH);w8r=r(R7t,"TFXLNetForMultipleChoice"),R7t.forEach(t),A8r=r(KRe," (XLNet model)"),KRe.forEach(t),_e.forEach(t),y8r=i(kl),T(r4.$$.fragment,kl),kl.forEach(t),$l.forEach(t),cNe=i(f),bc=n(f,"H2",{class:!0});var bDe=s(bc);t4=n(bDe,"A",{id:!0,class:!0,href:!0});var P7t=s(t4);OFe=n(P7t,"SPAN",{});var B7t=s(OFe);T(OL.$$.fragment,B7t),B7t.forEach(t),P7t.forEach(t),L8r=i(bDe),VFe=n(bDe,"SPAN",{});var I7t=s(VFe);x8r=r(I7t,"TFAutoModelForNextSentencePrediction"),I7t.forEach(t),bDe.forEach(t),fNe=i(f),lr=n(f,"DIV",{class:!0});var Sl=s(lr);T(VL.$$.fragment,Sl),$8r=i(Sl),vc=n(Sl,"P",{});var KZ=s(vc);k8r=r(KZ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),YH=n(KZ,"A",{href:!0});var q7t=s(YH);S8r=r(q7t,"from_pretrained()"),q7t.forEach(t),R8r=r(KZ," class method or the "),KH=n(KZ,"A",{href:!0});var N7t=s(KH);P8r=r(N7t,"from_config()"),N7t.forEach(t),B8r=r(KZ,` class
method.`),KZ.forEach(t),I8r=i(Sl),XL=n(Sl,"P",{});var vDe=s(XL);q8r=r(vDe,"This class cannot be instantiated directly using "),XFe=n(vDe,"CODE",{});var j7t=s(XFe);N8r=r(j7t,"__init__()"),j7t.forEach(t),j8r=r(vDe," (throws an error)."),vDe.forEach(t),D8r=i(Sl),It=n(Sl,"DIV",{class:!0});var $w=s(It);T(zL.$$.fragment,$w),G8r=i($w),zFe=n($w,"P",{});var D7t=s(zFe);O8r=r(D7t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),D7t.forEach(t),V8r=i($w),Fc=n($w,"P",{});var ZZ=s(Fc);X8r=r(ZZ,`Note:
Loading a model from its configuration file does `),QFe=n(ZZ,"STRONG",{});var G7t=s(QFe);z8r=r(G7t,"not"),G7t.forEach(t),Q8r=r(ZZ,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZH=n(ZZ,"A",{href:!0});var O7t=s(ZH);W8r=r(O7t,"from_pretrained()"),O7t.forEach(t),H8r=r(ZZ," to load the model weights."),ZZ.forEach(t),U8r=i($w),T(a4.$$.fragment,$w),$w.forEach(t),J8r=i(Sl),Br=n(Sl,"DIV",{class:!0});var Rl=s(Br);T(QL.$$.fragment,Rl),Y8r=i(Rl),WFe=n(Rl,"P",{});var V7t=s(WFe);K8r=r(V7t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),V7t.forEach(t),Z8r=i(Rl),mn=n(Rl,"P",{});var kw=s(mn);e7r=r(kw,"The model class to instantiate is selected based on the "),HFe=n(kw,"CODE",{});var X7t=s(HFe);o7r=r(X7t,"model_type"),X7t.forEach(t),r7r=r(kw,` property of the config object (either
passed as an argument or loaded from `),UFe=n(kw,"CODE",{});var z7t=s(UFe);t7r=r(z7t,"pretrained_model_name_or_path"),z7t.forEach(t),a7r=r(kw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JFe=n(kw,"CODE",{});var Q7t=s(JFe);n7r=r(Q7t,"pretrained_model_name_or_path"),Q7t.forEach(t),s7r=r(kw,":"),kw.forEach(t),l7r=i(Rl),WL=n(Rl,"UL",{});var FDe=s(WL);n4=n(FDe,"LI",{});var ZRe=s(n4);YFe=n(ZRe,"STRONG",{});var W7t=s(YFe);i7r=r(W7t,"bert"),W7t.forEach(t),d7r=r(ZRe," \u2014 "),eU=n(ZRe,"A",{href:!0});var H7t=s(eU);c7r=r(H7t,"TFBertForNextSentencePrediction"),H7t.forEach(t),f7r=r(ZRe," (BERT model)"),ZRe.forEach(t),m7r=i(FDe),s4=n(FDe,"LI",{});var ePe=s(s4);KFe=n(ePe,"STRONG",{});var U7t=s(KFe);g7r=r(U7t,"mobilebert"),U7t.forEach(t),h7r=r(ePe," \u2014 "),oU=n(ePe,"A",{href:!0});var J7t=s(oU);p7r=r(J7t,"TFMobileBertForNextSentencePrediction"),J7t.forEach(t),u7r=r(ePe," (MobileBERT model)"),ePe.forEach(t),FDe.forEach(t),_7r=i(Rl),T(l4.$$.fragment,Rl),Rl.forEach(t),Sl.forEach(t),mNe=i(f),Tc=n(f,"H2",{class:!0});var TDe=s(Tc);i4=n(TDe,"A",{id:!0,class:!0,href:!0});var Y7t=s(i4);ZFe=n(Y7t,"SPAN",{});var K7t=s(ZFe);T(HL.$$.fragment,K7t),K7t.forEach(t),Y7t.forEach(t),b7r=i(TDe),e6e=n(TDe,"SPAN",{});var Z7t=s(e6e);v7r=r(Z7t,"TFAutoModelForTableQuestionAnswering"),Z7t.forEach(t),TDe.forEach(t),gNe=i(f),ir=n(f,"DIV",{class:!0});var Pl=s(ir);T(UL.$$.fragment,Pl),F7r=i(Pl),Mc=n(Pl,"P",{});var eee=s(Mc);T7r=r(eee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),rU=n(eee,"A",{href:!0});var eMt=s(rU);M7r=r(eMt,"from_pretrained()"),eMt.forEach(t),E7r=r(eee," class method or the "),tU=n(eee,"A",{href:!0});var oMt=s(tU);C7r=r(oMt,"from_config()"),oMt.forEach(t),w7r=r(eee,` class
method.`),eee.forEach(t),A7r=i(Pl),JL=n(Pl,"P",{});var MDe=s(JL);y7r=r(MDe,"This class cannot be instantiated directly using "),o6e=n(MDe,"CODE",{});var rMt=s(o6e);L7r=r(rMt,"__init__()"),rMt.forEach(t),x7r=r(MDe," (throws an error)."),MDe.forEach(t),$7r=i(Pl),qt=n(Pl,"DIV",{class:!0});var Sw=s(qt);T(YL.$$.fragment,Sw),k7r=i(Sw),r6e=n(Sw,"P",{});var tMt=s(r6e);S7r=r(tMt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),tMt.forEach(t),R7r=i(Sw),Ec=n(Sw,"P",{});var oee=s(Ec);P7r=r(oee,`Note:
Loading a model from its configuration file does `),t6e=n(oee,"STRONG",{});var aMt=s(t6e);B7r=r(aMt,"not"),aMt.forEach(t),I7r=r(oee,` load the model weights. It only affects the
model\u2019s configuration. Use `),aU=n(oee,"A",{href:!0});var nMt=s(aU);q7r=r(nMt,"from_pretrained()"),nMt.forEach(t),N7r=r(oee," to load the model weights."),oee.forEach(t),j7r=i(Sw),T(d4.$$.fragment,Sw),Sw.forEach(t),D7r=i(Pl),Ir=n(Pl,"DIV",{class:!0});var Bl=s(Ir);T(KL.$$.fragment,Bl),G7r=i(Bl),a6e=n(Bl,"P",{});var sMt=s(a6e);O7r=r(sMt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),sMt.forEach(t),V7r=i(Bl),gn=n(Bl,"P",{});var Rw=s(gn);X7r=r(Rw,"The model class to instantiate is selected based on the "),n6e=n(Rw,"CODE",{});var lMt=s(n6e);z7r=r(lMt,"model_type"),lMt.forEach(t),Q7r=r(Rw,` property of the config object (either
passed as an argument or loaded from `),s6e=n(Rw,"CODE",{});var iMt=s(s6e);W7r=r(iMt,"pretrained_model_name_or_path"),iMt.forEach(t),H7r=r(Rw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l6e=n(Rw,"CODE",{});var dMt=s(l6e);U7r=r(dMt,"pretrained_model_name_or_path"),dMt.forEach(t),J7r=r(Rw,":"),Rw.forEach(t),Y7r=i(Bl),i6e=n(Bl,"UL",{});var cMt=s(i6e);c4=n(cMt,"LI",{});var oPe=s(c4);d6e=n(oPe,"STRONG",{});var fMt=s(d6e);K7r=r(fMt,"tapas"),fMt.forEach(t),Z7r=r(oPe," \u2014 "),nU=n(oPe,"A",{href:!0});var mMt=s(nU);eMr=r(mMt,"TFTapasForQuestionAnswering"),mMt.forEach(t),oMr=r(oPe," (TAPAS model)"),oPe.forEach(t),cMt.forEach(t),rMr=i(Bl),T(f4.$$.fragment,Bl),Bl.forEach(t),Pl.forEach(t),hNe=i(f),Cc=n(f,"H2",{class:!0});var EDe=s(Cc);m4=n(EDe,"A",{id:!0,class:!0,href:!0});var gMt=s(m4);c6e=n(gMt,"SPAN",{});var hMt=s(c6e);T(ZL.$$.fragment,hMt),hMt.forEach(t),gMt.forEach(t),tMr=i(EDe),f6e=n(EDe,"SPAN",{});var pMt=s(f6e);aMr=r(pMt,"TFAutoModelForTokenClassification"),pMt.forEach(t),EDe.forEach(t),pNe=i(f),dr=n(f,"DIV",{class:!0});var Il=s(dr);T(ex.$$.fragment,Il),nMr=i(Il),wc=n(Il,"P",{});var ree=s(wc);sMr=r(ree,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),sU=n(ree,"A",{href:!0});var uMt=s(sU);lMr=r(uMt,"from_pretrained()"),uMt.forEach(t),iMr=r(ree," class method or the "),lU=n(ree,"A",{href:!0});var _Mt=s(lU);dMr=r(_Mt,"from_config()"),_Mt.forEach(t),cMr=r(ree,` class
method.`),ree.forEach(t),fMr=i(Il),ox=n(Il,"P",{});var CDe=s(ox);mMr=r(CDe,"This class cannot be instantiated directly using "),m6e=n(CDe,"CODE",{});var bMt=s(m6e);gMr=r(bMt,"__init__()"),bMt.forEach(t),hMr=r(CDe," (throws an error)."),CDe.forEach(t),pMr=i(Il),Nt=n(Il,"DIV",{class:!0});var Pw=s(Nt);T(rx.$$.fragment,Pw),uMr=i(Pw),g6e=n(Pw,"P",{});var vMt=s(g6e);_Mr=r(vMt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),vMt.forEach(t),bMr=i(Pw),Ac=n(Pw,"P",{});var tee=s(Ac);vMr=r(tee,`Note:
Loading a model from its configuration file does `),h6e=n(tee,"STRONG",{});var FMt=s(h6e);FMr=r(FMt,"not"),FMt.forEach(t),TMr=r(tee,` load the model weights. It only affects the
model\u2019s configuration. Use `),iU=n(tee,"A",{href:!0});var TMt=s(iU);MMr=r(TMt,"from_pretrained()"),TMt.forEach(t),EMr=r(tee," to load the model weights."),tee.forEach(t),CMr=i(Pw),T(g4.$$.fragment,Pw),Pw.forEach(t),wMr=i(Il),qr=n(Il,"DIV",{class:!0});var ql=s(qr);T(tx.$$.fragment,ql),AMr=i(ql),p6e=n(ql,"P",{});var MMt=s(p6e);yMr=r(MMt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),MMt.forEach(t),LMr=i(ql),hn=n(ql,"P",{});var Bw=s(hn);xMr=r(Bw,"The model class to instantiate is selected based on the "),u6e=n(Bw,"CODE",{});var EMt=s(u6e);$Mr=r(EMt,"model_type"),EMt.forEach(t),kMr=r(Bw,` property of the config object (either
passed as an argument or loaded from `),_6e=n(Bw,"CODE",{});var CMt=s(_6e);SMr=r(CMt,"pretrained_model_name_or_path"),CMt.forEach(t),RMr=r(Bw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b6e=n(Bw,"CODE",{});var wMt=s(b6e);PMr=r(wMt,"pretrained_model_name_or_path"),wMt.forEach(t),BMr=r(Bw,":"),Bw.forEach(t),IMr=i(ql),de=n(ql,"UL",{});var me=s(de);h4=n(me,"LI",{});var rPe=s(h4);v6e=n(rPe,"STRONG",{});var AMt=s(v6e);qMr=r(AMt,"albert"),AMt.forEach(t),NMr=r(rPe," \u2014 "),dU=n(rPe,"A",{href:!0});var yMt=s(dU);jMr=r(yMt,"TFAlbertForTokenClassification"),yMt.forEach(t),DMr=r(rPe," (ALBERT model)"),rPe.forEach(t),GMr=i(me),p4=n(me,"LI",{});var tPe=s(p4);F6e=n(tPe,"STRONG",{});var LMt=s(F6e);OMr=r(LMt,"bert"),LMt.forEach(t),VMr=r(tPe," \u2014 "),cU=n(tPe,"A",{href:!0});var xMt=s(cU);XMr=r(xMt,"TFBertForTokenClassification"),xMt.forEach(t),zMr=r(tPe," (BERT model)"),tPe.forEach(t),QMr=i(me),u4=n(me,"LI",{});var aPe=s(u4);T6e=n(aPe,"STRONG",{});var $Mt=s(T6e);WMr=r($Mt,"camembert"),$Mt.forEach(t),HMr=r(aPe," \u2014 "),fU=n(aPe,"A",{href:!0});var kMt=s(fU);UMr=r(kMt,"TFCamembertForTokenClassification"),kMt.forEach(t),JMr=r(aPe," (CamemBERT model)"),aPe.forEach(t),YMr=i(me),_4=n(me,"LI",{});var nPe=s(_4);M6e=n(nPe,"STRONG",{});var SMt=s(M6e);KMr=r(SMt,"convbert"),SMt.forEach(t),ZMr=r(nPe," \u2014 "),mU=n(nPe,"A",{href:!0});var RMt=s(mU);e4r=r(RMt,"TFConvBertForTokenClassification"),RMt.forEach(t),o4r=r(nPe," (ConvBERT model)"),nPe.forEach(t),r4r=i(me),b4=n(me,"LI",{});var sPe=s(b4);E6e=n(sPe,"STRONG",{});var PMt=s(E6e);t4r=r(PMt,"deberta"),PMt.forEach(t),a4r=r(sPe," \u2014 "),gU=n(sPe,"A",{href:!0});var BMt=s(gU);n4r=r(BMt,"TFDebertaForTokenClassification"),BMt.forEach(t),s4r=r(sPe," (DeBERTa model)"),sPe.forEach(t),l4r=i(me),v4=n(me,"LI",{});var lPe=s(v4);C6e=n(lPe,"STRONG",{});var IMt=s(C6e);i4r=r(IMt,"deberta-v2"),IMt.forEach(t),d4r=r(lPe," \u2014 "),hU=n(lPe,"A",{href:!0});var qMt=s(hU);c4r=r(qMt,"TFDebertaV2ForTokenClassification"),qMt.forEach(t),f4r=r(lPe," (DeBERTa-v2 model)"),lPe.forEach(t),m4r=i(me),F4=n(me,"LI",{});var iPe=s(F4);w6e=n(iPe,"STRONG",{});var NMt=s(w6e);g4r=r(NMt,"distilbert"),NMt.forEach(t),h4r=r(iPe," \u2014 "),pU=n(iPe,"A",{href:!0});var jMt=s(pU);p4r=r(jMt,"TFDistilBertForTokenClassification"),jMt.forEach(t),u4r=r(iPe," (DistilBERT model)"),iPe.forEach(t),_4r=i(me),T4=n(me,"LI",{});var dPe=s(T4);A6e=n(dPe,"STRONG",{});var DMt=s(A6e);b4r=r(DMt,"electra"),DMt.forEach(t),v4r=r(dPe," \u2014 "),uU=n(dPe,"A",{href:!0});var GMt=s(uU);F4r=r(GMt,"TFElectraForTokenClassification"),GMt.forEach(t),T4r=r(dPe," (ELECTRA model)"),dPe.forEach(t),M4r=i(me),M4=n(me,"LI",{});var cPe=s(M4);y6e=n(cPe,"STRONG",{});var OMt=s(y6e);E4r=r(OMt,"flaubert"),OMt.forEach(t),C4r=r(cPe," \u2014 "),_U=n(cPe,"A",{href:!0});var VMt=s(_U);w4r=r(VMt,"TFFlaubertForTokenClassification"),VMt.forEach(t),A4r=r(cPe," (FlauBERT model)"),cPe.forEach(t),y4r=i(me),E4=n(me,"LI",{});var fPe=s(E4);L6e=n(fPe,"STRONG",{});var XMt=s(L6e);L4r=r(XMt,"funnel"),XMt.forEach(t),x4r=r(fPe," \u2014 "),bU=n(fPe,"A",{href:!0});var zMt=s(bU);$4r=r(zMt,"TFFunnelForTokenClassification"),zMt.forEach(t),k4r=r(fPe," (Funnel Transformer model)"),fPe.forEach(t),S4r=i(me),C4=n(me,"LI",{});var mPe=s(C4);x6e=n(mPe,"STRONG",{});var QMt=s(x6e);R4r=r(QMt,"layoutlm"),QMt.forEach(t),P4r=r(mPe," \u2014 "),vU=n(mPe,"A",{href:!0});var WMt=s(vU);B4r=r(WMt,"TFLayoutLMForTokenClassification"),WMt.forEach(t),I4r=r(mPe," (LayoutLM model)"),mPe.forEach(t),q4r=i(me),w4=n(me,"LI",{});var gPe=s(w4);$6e=n(gPe,"STRONG",{});var HMt=s($6e);N4r=r(HMt,"longformer"),HMt.forEach(t),j4r=r(gPe," \u2014 "),FU=n(gPe,"A",{href:!0});var UMt=s(FU);D4r=r(UMt,"TFLongformerForTokenClassification"),UMt.forEach(t),G4r=r(gPe," (Longformer model)"),gPe.forEach(t),O4r=i(me),A4=n(me,"LI",{});var hPe=s(A4);k6e=n(hPe,"STRONG",{});var JMt=s(k6e);V4r=r(JMt,"mobilebert"),JMt.forEach(t),X4r=r(hPe," \u2014 "),TU=n(hPe,"A",{href:!0});var YMt=s(TU);z4r=r(YMt,"TFMobileBertForTokenClassification"),YMt.forEach(t),Q4r=r(hPe," (MobileBERT model)"),hPe.forEach(t),W4r=i(me),y4=n(me,"LI",{});var pPe=s(y4);S6e=n(pPe,"STRONG",{});var KMt=s(S6e);H4r=r(KMt,"mpnet"),KMt.forEach(t),U4r=r(pPe," \u2014 "),MU=n(pPe,"A",{href:!0});var ZMt=s(MU);J4r=r(ZMt,"TFMPNetForTokenClassification"),ZMt.forEach(t),Y4r=r(pPe," (MPNet model)"),pPe.forEach(t),K4r=i(me),L4=n(me,"LI",{});var uPe=s(L4);R6e=n(uPe,"STRONG",{});var e4t=s(R6e);Z4r=r(e4t,"rembert"),e4t.forEach(t),eEr=r(uPe," \u2014 "),EU=n(uPe,"A",{href:!0});var o4t=s(EU);oEr=r(o4t,"TFRemBertForTokenClassification"),o4t.forEach(t),rEr=r(uPe," (RemBERT model)"),uPe.forEach(t),tEr=i(me),x4=n(me,"LI",{});var _Pe=s(x4);P6e=n(_Pe,"STRONG",{});var r4t=s(P6e);aEr=r(r4t,"roberta"),r4t.forEach(t),nEr=r(_Pe," \u2014 "),CU=n(_Pe,"A",{href:!0});var t4t=s(CU);sEr=r(t4t,"TFRobertaForTokenClassification"),t4t.forEach(t),lEr=r(_Pe," (RoBERTa model)"),_Pe.forEach(t),iEr=i(me),$4=n(me,"LI",{});var bPe=s($4);B6e=n(bPe,"STRONG",{});var a4t=s(B6e);dEr=r(a4t,"roformer"),a4t.forEach(t),cEr=r(bPe," \u2014 "),wU=n(bPe,"A",{href:!0});var n4t=s(wU);fEr=r(n4t,"TFRoFormerForTokenClassification"),n4t.forEach(t),mEr=r(bPe," (RoFormer model)"),bPe.forEach(t),gEr=i(me),k4=n(me,"LI",{});var vPe=s(k4);I6e=n(vPe,"STRONG",{});var s4t=s(I6e);hEr=r(s4t,"xlm"),s4t.forEach(t),pEr=r(vPe," \u2014 "),AU=n(vPe,"A",{href:!0});var l4t=s(AU);uEr=r(l4t,"TFXLMForTokenClassification"),l4t.forEach(t),_Er=r(vPe," (XLM model)"),vPe.forEach(t),bEr=i(me),S4=n(me,"LI",{});var FPe=s(S4);q6e=n(FPe,"STRONG",{});var i4t=s(q6e);vEr=r(i4t,"xlm-roberta"),i4t.forEach(t),FEr=r(FPe," \u2014 "),yU=n(FPe,"A",{href:!0});var d4t=s(yU);TEr=r(d4t,"TFXLMRobertaForTokenClassification"),d4t.forEach(t),MEr=r(FPe," (XLM-RoBERTa model)"),FPe.forEach(t),EEr=i(me),R4=n(me,"LI",{});var TPe=s(R4);N6e=n(TPe,"STRONG",{});var c4t=s(N6e);CEr=r(c4t,"xlnet"),c4t.forEach(t),wEr=r(TPe," \u2014 "),LU=n(TPe,"A",{href:!0});var f4t=s(LU);AEr=r(f4t,"TFXLNetForTokenClassification"),f4t.forEach(t),yEr=r(TPe," (XLNet model)"),TPe.forEach(t),me.forEach(t),LEr=i(ql),T(P4.$$.fragment,ql),ql.forEach(t),Il.forEach(t),uNe=i(f),yc=n(f,"H2",{class:!0});var wDe=s(yc);B4=n(wDe,"A",{id:!0,class:!0,href:!0});var m4t=s(B4);j6e=n(m4t,"SPAN",{});var g4t=s(j6e);T(ax.$$.fragment,g4t),g4t.forEach(t),m4t.forEach(t),xEr=i(wDe),D6e=n(wDe,"SPAN",{});var h4t=s(D6e);$Er=r(h4t,"TFAutoModelForQuestionAnswering"),h4t.forEach(t),wDe.forEach(t),_Ne=i(f),cr=n(f,"DIV",{class:!0});var Nl=s(cr);T(nx.$$.fragment,Nl),kEr=i(Nl),Lc=n(Nl,"P",{});var aee=s(Lc);SEr=r(aee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),xU=n(aee,"A",{href:!0});var p4t=s(xU);REr=r(p4t,"from_pretrained()"),p4t.forEach(t),PEr=r(aee," class method or the "),$U=n(aee,"A",{href:!0});var u4t=s($U);BEr=r(u4t,"from_config()"),u4t.forEach(t),IEr=r(aee,` class
method.`),aee.forEach(t),qEr=i(Nl),sx=n(Nl,"P",{});var ADe=s(sx);NEr=r(ADe,"This class cannot be instantiated directly using "),G6e=n(ADe,"CODE",{});var _4t=s(G6e);jEr=r(_4t,"__init__()"),_4t.forEach(t),DEr=r(ADe," (throws an error)."),ADe.forEach(t),GEr=i(Nl),jt=n(Nl,"DIV",{class:!0});var Iw=s(jt);T(lx.$$.fragment,Iw),OEr=i(Iw),O6e=n(Iw,"P",{});var b4t=s(O6e);VEr=r(b4t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),b4t.forEach(t),XEr=i(Iw),xc=n(Iw,"P",{});var nee=s(xc);zEr=r(nee,`Note:
Loading a model from its configuration file does `),V6e=n(nee,"STRONG",{});var v4t=s(V6e);QEr=r(v4t,"not"),v4t.forEach(t),WEr=r(nee,` load the model weights. It only affects the
model\u2019s configuration. Use `),kU=n(nee,"A",{href:!0});var F4t=s(kU);HEr=r(F4t,"from_pretrained()"),F4t.forEach(t),UEr=r(nee," to load the model weights."),nee.forEach(t),JEr=i(Iw),T(I4.$$.fragment,Iw),Iw.forEach(t),YEr=i(Nl),Nr=n(Nl,"DIV",{class:!0});var jl=s(Nr);T(ix.$$.fragment,jl),KEr=i(jl),X6e=n(jl,"P",{});var T4t=s(X6e);ZEr=r(T4t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),T4t.forEach(t),e5r=i(jl),pn=n(jl,"P",{});var qw=s(pn);o5r=r(qw,"The model class to instantiate is selected based on the "),z6e=n(qw,"CODE",{});var M4t=s(z6e);r5r=r(M4t,"model_type"),M4t.forEach(t),t5r=r(qw,` property of the config object (either
passed as an argument or loaded from `),Q6e=n(qw,"CODE",{});var E4t=s(Q6e);a5r=r(E4t,"pretrained_model_name_or_path"),E4t.forEach(t),n5r=r(qw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W6e=n(qw,"CODE",{});var C4t=s(W6e);s5r=r(C4t,"pretrained_model_name_or_path"),C4t.forEach(t),l5r=r(qw,":"),qw.forEach(t),i5r=i(jl),ce=n(jl,"UL",{});var ge=s(ce);q4=n(ge,"LI",{});var MPe=s(q4);H6e=n(MPe,"STRONG",{});var w4t=s(H6e);d5r=r(w4t,"albert"),w4t.forEach(t),c5r=r(MPe," \u2014 "),SU=n(MPe,"A",{href:!0});var A4t=s(SU);f5r=r(A4t,"TFAlbertForQuestionAnswering"),A4t.forEach(t),m5r=r(MPe," (ALBERT model)"),MPe.forEach(t),g5r=i(ge),N4=n(ge,"LI",{});var EPe=s(N4);U6e=n(EPe,"STRONG",{});var y4t=s(U6e);h5r=r(y4t,"bert"),y4t.forEach(t),p5r=r(EPe," \u2014 "),RU=n(EPe,"A",{href:!0});var L4t=s(RU);u5r=r(L4t,"TFBertForQuestionAnswering"),L4t.forEach(t),_5r=r(EPe," (BERT model)"),EPe.forEach(t),b5r=i(ge),j4=n(ge,"LI",{});var CPe=s(j4);J6e=n(CPe,"STRONG",{});var x4t=s(J6e);v5r=r(x4t,"camembert"),x4t.forEach(t),F5r=r(CPe," \u2014 "),PU=n(CPe,"A",{href:!0});var $4t=s(PU);T5r=r($4t,"TFCamembertForQuestionAnswering"),$4t.forEach(t),M5r=r(CPe," (CamemBERT model)"),CPe.forEach(t),E5r=i(ge),D4=n(ge,"LI",{});var wPe=s(D4);Y6e=n(wPe,"STRONG",{});var k4t=s(Y6e);C5r=r(k4t,"convbert"),k4t.forEach(t),w5r=r(wPe," \u2014 "),BU=n(wPe,"A",{href:!0});var S4t=s(BU);A5r=r(S4t,"TFConvBertForQuestionAnswering"),S4t.forEach(t),y5r=r(wPe," (ConvBERT model)"),wPe.forEach(t),L5r=i(ge),G4=n(ge,"LI",{});var APe=s(G4);K6e=n(APe,"STRONG",{});var R4t=s(K6e);x5r=r(R4t,"deberta"),R4t.forEach(t),$5r=r(APe," \u2014 "),IU=n(APe,"A",{href:!0});var P4t=s(IU);k5r=r(P4t,"TFDebertaForQuestionAnswering"),P4t.forEach(t),S5r=r(APe," (DeBERTa model)"),APe.forEach(t),R5r=i(ge),O4=n(ge,"LI",{});var yPe=s(O4);Z6e=n(yPe,"STRONG",{});var B4t=s(Z6e);P5r=r(B4t,"deberta-v2"),B4t.forEach(t),B5r=r(yPe," \u2014 "),qU=n(yPe,"A",{href:!0});var I4t=s(qU);I5r=r(I4t,"TFDebertaV2ForQuestionAnswering"),I4t.forEach(t),q5r=r(yPe," (DeBERTa-v2 model)"),yPe.forEach(t),N5r=i(ge),V4=n(ge,"LI",{});var LPe=s(V4);eTe=n(LPe,"STRONG",{});var q4t=s(eTe);j5r=r(q4t,"distilbert"),q4t.forEach(t),D5r=r(LPe," \u2014 "),NU=n(LPe,"A",{href:!0});var N4t=s(NU);G5r=r(N4t,"TFDistilBertForQuestionAnswering"),N4t.forEach(t),O5r=r(LPe," (DistilBERT model)"),LPe.forEach(t),V5r=i(ge),X4=n(ge,"LI",{});var xPe=s(X4);oTe=n(xPe,"STRONG",{});var j4t=s(oTe);X5r=r(j4t,"electra"),j4t.forEach(t),z5r=r(xPe," \u2014 "),jU=n(xPe,"A",{href:!0});var D4t=s(jU);Q5r=r(D4t,"TFElectraForQuestionAnswering"),D4t.forEach(t),W5r=r(xPe," (ELECTRA model)"),xPe.forEach(t),H5r=i(ge),z4=n(ge,"LI",{});var $Pe=s(z4);rTe=n($Pe,"STRONG",{});var G4t=s(rTe);U5r=r(G4t,"flaubert"),G4t.forEach(t),J5r=r($Pe," \u2014 "),DU=n($Pe,"A",{href:!0});var O4t=s(DU);Y5r=r(O4t,"TFFlaubertForQuestionAnsweringSimple"),O4t.forEach(t),K5r=r($Pe," (FlauBERT model)"),$Pe.forEach(t),Z5r=i(ge),Q4=n(ge,"LI",{});var kPe=s(Q4);tTe=n(kPe,"STRONG",{});var V4t=s(tTe);eCr=r(V4t,"funnel"),V4t.forEach(t),oCr=r(kPe," \u2014 "),GU=n(kPe,"A",{href:!0});var X4t=s(GU);rCr=r(X4t,"TFFunnelForQuestionAnswering"),X4t.forEach(t),tCr=r(kPe," (Funnel Transformer model)"),kPe.forEach(t),aCr=i(ge),W4=n(ge,"LI",{});var SPe=s(W4);aTe=n(SPe,"STRONG",{});var z4t=s(aTe);nCr=r(z4t,"gptj"),z4t.forEach(t),sCr=r(SPe," \u2014 "),OU=n(SPe,"A",{href:!0});var Q4t=s(OU);lCr=r(Q4t,"TFGPTJForQuestionAnswering"),Q4t.forEach(t),iCr=r(SPe," (GPT-J model)"),SPe.forEach(t),dCr=i(ge),H4=n(ge,"LI",{});var RPe=s(H4);nTe=n(RPe,"STRONG",{});var W4t=s(nTe);cCr=r(W4t,"longformer"),W4t.forEach(t),fCr=r(RPe," \u2014 "),VU=n(RPe,"A",{href:!0});var H4t=s(VU);mCr=r(H4t,"TFLongformerForQuestionAnswering"),H4t.forEach(t),gCr=r(RPe," (Longformer model)"),RPe.forEach(t),hCr=i(ge),U4=n(ge,"LI",{});var PPe=s(U4);sTe=n(PPe,"STRONG",{});var U4t=s(sTe);pCr=r(U4t,"mobilebert"),U4t.forEach(t),uCr=r(PPe," \u2014 "),XU=n(PPe,"A",{href:!0});var J4t=s(XU);_Cr=r(J4t,"TFMobileBertForQuestionAnswering"),J4t.forEach(t),bCr=r(PPe," (MobileBERT model)"),PPe.forEach(t),vCr=i(ge),J4=n(ge,"LI",{});var BPe=s(J4);lTe=n(BPe,"STRONG",{});var Y4t=s(lTe);FCr=r(Y4t,"mpnet"),Y4t.forEach(t),TCr=r(BPe," \u2014 "),zU=n(BPe,"A",{href:!0});var K4t=s(zU);MCr=r(K4t,"TFMPNetForQuestionAnswering"),K4t.forEach(t),ECr=r(BPe," (MPNet model)"),BPe.forEach(t),CCr=i(ge),Y4=n(ge,"LI",{});var IPe=s(Y4);iTe=n(IPe,"STRONG",{});var Z4t=s(iTe);wCr=r(Z4t,"rembert"),Z4t.forEach(t),ACr=r(IPe," \u2014 "),QU=n(IPe,"A",{href:!0});var eEt=s(QU);yCr=r(eEt,"TFRemBertForQuestionAnswering"),eEt.forEach(t),LCr=r(IPe," (RemBERT model)"),IPe.forEach(t),xCr=i(ge),K4=n(ge,"LI",{});var qPe=s(K4);dTe=n(qPe,"STRONG",{});var oEt=s(dTe);$Cr=r(oEt,"roberta"),oEt.forEach(t),kCr=r(qPe," \u2014 "),WU=n(qPe,"A",{href:!0});var rEt=s(WU);SCr=r(rEt,"TFRobertaForQuestionAnswering"),rEt.forEach(t),RCr=r(qPe," (RoBERTa model)"),qPe.forEach(t),PCr=i(ge),Z4=n(ge,"LI",{});var NPe=s(Z4);cTe=n(NPe,"STRONG",{});var tEt=s(cTe);BCr=r(tEt,"roformer"),tEt.forEach(t),ICr=r(NPe," \u2014 "),HU=n(NPe,"A",{href:!0});var aEt=s(HU);qCr=r(aEt,"TFRoFormerForQuestionAnswering"),aEt.forEach(t),NCr=r(NPe," (RoFormer model)"),NPe.forEach(t),jCr=i(ge),eE=n(ge,"LI",{});var jPe=s(eE);fTe=n(jPe,"STRONG",{});var nEt=s(fTe);DCr=r(nEt,"xlm"),nEt.forEach(t),GCr=r(jPe," \u2014 "),UU=n(jPe,"A",{href:!0});var sEt=s(UU);OCr=r(sEt,"TFXLMForQuestionAnsweringSimple"),sEt.forEach(t),VCr=r(jPe," (XLM model)"),jPe.forEach(t),XCr=i(ge),oE=n(ge,"LI",{});var DPe=s(oE);mTe=n(DPe,"STRONG",{});var lEt=s(mTe);zCr=r(lEt,"xlm-roberta"),lEt.forEach(t),QCr=r(DPe," \u2014 "),JU=n(DPe,"A",{href:!0});var iEt=s(JU);WCr=r(iEt,"TFXLMRobertaForQuestionAnswering"),iEt.forEach(t),HCr=r(DPe," (XLM-RoBERTa model)"),DPe.forEach(t),UCr=i(ge),rE=n(ge,"LI",{});var GPe=s(rE);gTe=n(GPe,"STRONG",{});var dEt=s(gTe);JCr=r(dEt,"xlnet"),dEt.forEach(t),YCr=r(GPe," \u2014 "),YU=n(GPe,"A",{href:!0});var cEt=s(YU);KCr=r(cEt,"TFXLNetForQuestionAnsweringSimple"),cEt.forEach(t),ZCr=r(GPe," (XLNet model)"),GPe.forEach(t),ge.forEach(t),e3r=i(jl),T(tE.$$.fragment,jl),jl.forEach(t),Nl.forEach(t),bNe=i(f),$c=n(f,"H2",{class:!0});var yDe=s($c);aE=n(yDe,"A",{id:!0,class:!0,href:!0});var fEt=s(aE);hTe=n(fEt,"SPAN",{});var mEt=s(hTe);T(dx.$$.fragment,mEt),mEt.forEach(t),fEt.forEach(t),o3r=i(yDe),pTe=n(yDe,"SPAN",{});var gEt=s(pTe);r3r=r(gEt,"TFAutoModelForVision2Seq"),gEt.forEach(t),yDe.forEach(t),vNe=i(f),fr=n(f,"DIV",{class:!0});var Dl=s(fr);T(cx.$$.fragment,Dl),t3r=i(Dl),kc=n(Dl,"P",{});var see=s(kc);a3r=r(see,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),KU=n(see,"A",{href:!0});var hEt=s(KU);n3r=r(hEt,"from_pretrained()"),hEt.forEach(t),s3r=r(see," class method or the "),ZU=n(see,"A",{href:!0});var pEt=s(ZU);l3r=r(pEt,"from_config()"),pEt.forEach(t),i3r=r(see,` class
method.`),see.forEach(t),d3r=i(Dl),fx=n(Dl,"P",{});var LDe=s(fx);c3r=r(LDe,"This class cannot be instantiated directly using "),uTe=n(LDe,"CODE",{});var uEt=s(uTe);f3r=r(uEt,"__init__()"),uEt.forEach(t),m3r=r(LDe," (throws an error)."),LDe.forEach(t),g3r=i(Dl),Dt=n(Dl,"DIV",{class:!0});var Nw=s(Dt);T(mx.$$.fragment,Nw),h3r=i(Nw),_Te=n(Nw,"P",{});var _Et=s(_Te);p3r=r(_Et,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),_Et.forEach(t),u3r=i(Nw),Sc=n(Nw,"P",{});var lee=s(Sc);_3r=r(lee,`Note:
Loading a model from its configuration file does `),bTe=n(lee,"STRONG",{});var bEt=s(bTe);b3r=r(bEt,"not"),bEt.forEach(t),v3r=r(lee,` load the model weights. It only affects the
model\u2019s configuration. Use `),eJ=n(lee,"A",{href:!0});var vEt=s(eJ);F3r=r(vEt,"from_pretrained()"),vEt.forEach(t),T3r=r(lee," to load the model weights."),lee.forEach(t),M3r=i(Nw),T(nE.$$.fragment,Nw),Nw.forEach(t),E3r=i(Dl),jr=n(Dl,"DIV",{class:!0});var Gl=s(jr);T(gx.$$.fragment,Gl),C3r=i(Gl),vTe=n(Gl,"P",{});var FEt=s(vTe);w3r=r(FEt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),FEt.forEach(t),A3r=i(Gl),un=n(Gl,"P",{});var jw=s(un);y3r=r(jw,"The model class to instantiate is selected based on the "),FTe=n(jw,"CODE",{});var TEt=s(FTe);L3r=r(TEt,"model_type"),TEt.forEach(t),x3r=r(jw,` property of the config object (either
passed as an argument or loaded from `),TTe=n(jw,"CODE",{});var MEt=s(TTe);$3r=r(MEt,"pretrained_model_name_or_path"),MEt.forEach(t),k3r=r(jw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MTe=n(jw,"CODE",{});var EEt=s(MTe);S3r=r(EEt,"pretrained_model_name_or_path"),EEt.forEach(t),R3r=r(jw,":"),jw.forEach(t),P3r=i(Gl),ETe=n(Gl,"UL",{});var CEt=s(ETe);sE=n(CEt,"LI",{});var OPe=s(sE);CTe=n(OPe,"STRONG",{});var wEt=s(CTe);B3r=r(wEt,"vision-encoder-decoder"),wEt.forEach(t),I3r=r(OPe," \u2014 "),oJ=n(OPe,"A",{href:!0});var AEt=s(oJ);q3r=r(AEt,"TFVisionEncoderDecoderModel"),AEt.forEach(t),N3r=r(OPe," (Vision Encoder decoder model)"),OPe.forEach(t),CEt.forEach(t),j3r=i(Gl),T(lE.$$.fragment,Gl),Gl.forEach(t),Dl.forEach(t),FNe=i(f),Rc=n(f,"H2",{class:!0});var xDe=s(Rc);iE=n(xDe,"A",{id:!0,class:!0,href:!0});var yEt=s(iE);wTe=n(yEt,"SPAN",{});var LEt=s(wTe);T(hx.$$.fragment,LEt),LEt.forEach(t),yEt.forEach(t),D3r=i(xDe),ATe=n(xDe,"SPAN",{});var xEt=s(ATe);G3r=r(xEt,"TFAutoModelForSpeechSeq2Seq"),xEt.forEach(t),xDe.forEach(t),TNe=i(f),mr=n(f,"DIV",{class:!0});var Ol=s(mr);T(px.$$.fragment,Ol),O3r=i(Ol),Pc=n(Ol,"P",{});var iee=s(Pc);V3r=r(iee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),rJ=n(iee,"A",{href:!0});var $Et=s(rJ);X3r=r($Et,"from_pretrained()"),$Et.forEach(t),z3r=r(iee," class method or the "),tJ=n(iee,"A",{href:!0});var kEt=s(tJ);Q3r=r(kEt,"from_config()"),kEt.forEach(t),W3r=r(iee,` class
method.`),iee.forEach(t),H3r=i(Ol),ux=n(Ol,"P",{});var $De=s(ux);U3r=r($De,"This class cannot be instantiated directly using "),yTe=n($De,"CODE",{});var SEt=s(yTe);J3r=r(SEt,"__init__()"),SEt.forEach(t),Y3r=r($De," (throws an error)."),$De.forEach(t),K3r=i(Ol),Gt=n(Ol,"DIV",{class:!0});var Dw=s(Gt);T(_x.$$.fragment,Dw),Z3r=i(Dw),LTe=n(Dw,"P",{});var REt=s(LTe);ewr=r(REt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),REt.forEach(t),owr=i(Dw),Bc=n(Dw,"P",{});var dee=s(Bc);rwr=r(dee,`Note:
Loading a model from its configuration file does `),xTe=n(dee,"STRONG",{});var PEt=s(xTe);twr=r(PEt,"not"),PEt.forEach(t),awr=r(dee,` load the model weights. It only affects the
model\u2019s configuration. Use `),aJ=n(dee,"A",{href:!0});var BEt=s(aJ);nwr=r(BEt,"from_pretrained()"),BEt.forEach(t),swr=r(dee," to load the model weights."),dee.forEach(t),lwr=i(Dw),T(dE.$$.fragment,Dw),Dw.forEach(t),iwr=i(Ol),Dr=n(Ol,"DIV",{class:!0});var Vl=s(Dr);T(bx.$$.fragment,Vl),dwr=i(Vl),$Te=n(Vl,"P",{});var IEt=s($Te);cwr=r(IEt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),IEt.forEach(t),fwr=i(Vl),_n=n(Vl,"P",{});var Gw=s(_n);mwr=r(Gw,"The model class to instantiate is selected based on the "),kTe=n(Gw,"CODE",{});var qEt=s(kTe);gwr=r(qEt,"model_type"),qEt.forEach(t),hwr=r(Gw,` property of the config object (either
passed as an argument or loaded from `),STe=n(Gw,"CODE",{});var NEt=s(STe);pwr=r(NEt,"pretrained_model_name_or_path"),NEt.forEach(t),uwr=r(Gw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RTe=n(Gw,"CODE",{});var jEt=s(RTe);_wr=r(jEt,"pretrained_model_name_or_path"),jEt.forEach(t),bwr=r(Gw,":"),Gw.forEach(t),vwr=i(Vl),PTe=n(Vl,"UL",{});var DEt=s(PTe);cE=n(DEt,"LI",{});var VPe=s(cE);BTe=n(VPe,"STRONG",{});var GEt=s(BTe);Fwr=r(GEt,"speech_to_text"),GEt.forEach(t),Twr=r(VPe," \u2014 "),nJ=n(VPe,"A",{href:!0});var OEt=s(nJ);Mwr=r(OEt,"TFSpeech2TextForConditionalGeneration"),OEt.forEach(t),Ewr=r(VPe," (Speech2Text model)"),VPe.forEach(t),DEt.forEach(t),Cwr=i(Vl),T(fE.$$.fragment,Vl),Vl.forEach(t),Ol.forEach(t),MNe=i(f),Ic=n(f,"H2",{class:!0});var kDe=s(Ic);mE=n(kDe,"A",{id:!0,class:!0,href:!0});var VEt=s(mE);ITe=n(VEt,"SPAN",{});var XEt=s(ITe);T(vx.$$.fragment,XEt),XEt.forEach(t),VEt.forEach(t),wwr=i(kDe),qTe=n(kDe,"SPAN",{});var zEt=s(qTe);Awr=r(zEt,"FlaxAutoModel"),zEt.forEach(t),kDe.forEach(t),ENe=i(f),gr=n(f,"DIV",{class:!0});var Xl=s(gr);T(Fx.$$.fragment,Xl),ywr=i(Xl),qc=n(Xl,"P",{});var cee=s(qc);Lwr=r(cee,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),sJ=n(cee,"A",{href:!0});var QEt=s(sJ);xwr=r(QEt,"from_pretrained()"),QEt.forEach(t),$wr=r(cee," class method or the "),lJ=n(cee,"A",{href:!0});var WEt=s(lJ);kwr=r(WEt,"from_config()"),WEt.forEach(t),Swr=r(cee,` class
method.`),cee.forEach(t),Rwr=i(Xl),Tx=n(Xl,"P",{});var SDe=s(Tx);Pwr=r(SDe,"This class cannot be instantiated directly using "),NTe=n(SDe,"CODE",{});var HEt=s(NTe);Bwr=r(HEt,"__init__()"),HEt.forEach(t),Iwr=r(SDe," (throws an error)."),SDe.forEach(t),qwr=i(Xl),Ot=n(Xl,"DIV",{class:!0});var Ow=s(Ot);T(Mx.$$.fragment,Ow),Nwr=i(Ow),jTe=n(Ow,"P",{});var UEt=s(jTe);jwr=r(UEt,"Instantiates one of the base model classes of the library from a configuration."),UEt.forEach(t),Dwr=i(Ow),Nc=n(Ow,"P",{});var fee=s(Nc);Gwr=r(fee,`Note:
Loading a model from its configuration file does `),DTe=n(fee,"STRONG",{});var JEt=s(DTe);Owr=r(JEt,"not"),JEt.forEach(t),Vwr=r(fee,` load the model weights. It only affects the
model\u2019s configuration. Use `),iJ=n(fee,"A",{href:!0});var YEt=s(iJ);Xwr=r(YEt,"from_pretrained()"),YEt.forEach(t),zwr=r(fee," to load the model weights."),fee.forEach(t),Qwr=i(Ow),T(gE.$$.fragment,Ow),Ow.forEach(t),Wwr=i(Xl),Gr=n(Xl,"DIV",{class:!0});var zl=s(Gr);T(Ex.$$.fragment,zl),Hwr=i(zl),GTe=n(zl,"P",{});var KEt=s(GTe);Uwr=r(KEt,"Instantiate one of the base model classes of the library from a pretrained model."),KEt.forEach(t),Jwr=i(zl),bn=n(zl,"P",{});var Vw=s(bn);Ywr=r(Vw,"The model class to instantiate is selected based on the "),OTe=n(Vw,"CODE",{});var ZEt=s(OTe);Kwr=r(ZEt,"model_type"),ZEt.forEach(t),Zwr=r(Vw,` property of the config object (either
passed as an argument or loaded from `),VTe=n(Vw,"CODE",{});var e5t=s(VTe);eAr=r(e5t,"pretrained_model_name_or_path"),e5t.forEach(t),oAr=r(Vw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),XTe=n(Vw,"CODE",{});var o5t=s(XTe);rAr=r(o5t,"pretrained_model_name_or_path"),o5t.forEach(t),tAr=r(Vw,":"),Vw.forEach(t),aAr=i(zl),re=n(zl,"UL",{});var ne=s(re);hE=n(ne,"LI",{});var XPe=s(hE);zTe=n(XPe,"STRONG",{});var r5t=s(zTe);nAr=r(r5t,"albert"),r5t.forEach(t),sAr=r(XPe," \u2014 "),dJ=n(XPe,"A",{href:!0});var t5t=s(dJ);lAr=r(t5t,"FlaxAlbertModel"),t5t.forEach(t),iAr=r(XPe," (ALBERT model)"),XPe.forEach(t),dAr=i(ne),pE=n(ne,"LI",{});var zPe=s(pE);QTe=n(zPe,"STRONG",{});var a5t=s(QTe);cAr=r(a5t,"bart"),a5t.forEach(t),fAr=r(zPe," \u2014 "),cJ=n(zPe,"A",{href:!0});var n5t=s(cJ);mAr=r(n5t,"FlaxBartModel"),n5t.forEach(t),gAr=r(zPe," (BART model)"),zPe.forEach(t),hAr=i(ne),uE=n(ne,"LI",{});var QPe=s(uE);WTe=n(QPe,"STRONG",{});var s5t=s(WTe);pAr=r(s5t,"beit"),s5t.forEach(t),uAr=r(QPe," \u2014 "),fJ=n(QPe,"A",{href:!0});var l5t=s(fJ);_Ar=r(l5t,"FlaxBeitModel"),l5t.forEach(t),bAr=r(QPe," (BEiT model)"),QPe.forEach(t),vAr=i(ne),_E=n(ne,"LI",{});var WPe=s(_E);HTe=n(WPe,"STRONG",{});var i5t=s(HTe);FAr=r(i5t,"bert"),i5t.forEach(t),TAr=r(WPe," \u2014 "),mJ=n(WPe,"A",{href:!0});var d5t=s(mJ);MAr=r(d5t,"FlaxBertModel"),d5t.forEach(t),EAr=r(WPe," (BERT model)"),WPe.forEach(t),CAr=i(ne),bE=n(ne,"LI",{});var HPe=s(bE);UTe=n(HPe,"STRONG",{});var c5t=s(UTe);wAr=r(c5t,"big_bird"),c5t.forEach(t),AAr=r(HPe," \u2014 "),gJ=n(HPe,"A",{href:!0});var f5t=s(gJ);yAr=r(f5t,"FlaxBigBirdModel"),f5t.forEach(t),LAr=r(HPe," (BigBird model)"),HPe.forEach(t),xAr=i(ne),vE=n(ne,"LI",{});var UPe=s(vE);JTe=n(UPe,"STRONG",{});var m5t=s(JTe);$Ar=r(m5t,"blenderbot"),m5t.forEach(t),kAr=r(UPe," \u2014 "),hJ=n(UPe,"A",{href:!0});var g5t=s(hJ);SAr=r(g5t,"FlaxBlenderbotModel"),g5t.forEach(t),RAr=r(UPe," (Blenderbot model)"),UPe.forEach(t),PAr=i(ne),FE=n(ne,"LI",{});var JPe=s(FE);YTe=n(JPe,"STRONG",{});var h5t=s(YTe);BAr=r(h5t,"blenderbot-small"),h5t.forEach(t),IAr=r(JPe," \u2014 "),pJ=n(JPe,"A",{href:!0});var p5t=s(pJ);qAr=r(p5t,"FlaxBlenderbotSmallModel"),p5t.forEach(t),NAr=r(JPe," (BlenderbotSmall model)"),JPe.forEach(t),jAr=i(ne),TE=n(ne,"LI",{});var YPe=s(TE);KTe=n(YPe,"STRONG",{});var u5t=s(KTe);DAr=r(u5t,"clip"),u5t.forEach(t),GAr=r(YPe," \u2014 "),uJ=n(YPe,"A",{href:!0});var _5t=s(uJ);OAr=r(_5t,"FlaxCLIPModel"),_5t.forEach(t),VAr=r(YPe," (CLIP model)"),YPe.forEach(t),XAr=i(ne),ME=n(ne,"LI",{});var KPe=s(ME);ZTe=n(KPe,"STRONG",{});var b5t=s(ZTe);zAr=r(b5t,"distilbert"),b5t.forEach(t),QAr=r(KPe," \u2014 "),_J=n(KPe,"A",{href:!0});var v5t=s(_J);WAr=r(v5t,"FlaxDistilBertModel"),v5t.forEach(t),HAr=r(KPe," (DistilBERT model)"),KPe.forEach(t),UAr=i(ne),EE=n(ne,"LI",{});var ZPe=s(EE);e8e=n(ZPe,"STRONG",{});var F5t=s(e8e);JAr=r(F5t,"electra"),F5t.forEach(t),YAr=r(ZPe," \u2014 "),bJ=n(ZPe,"A",{href:!0});var T5t=s(bJ);KAr=r(T5t,"FlaxElectraModel"),T5t.forEach(t),ZAr=r(ZPe," (ELECTRA model)"),ZPe.forEach(t),e0r=i(ne),CE=n(ne,"LI",{});var eBe=s(CE);o8e=n(eBe,"STRONG",{});var M5t=s(o8e);o0r=r(M5t,"gpt2"),M5t.forEach(t),r0r=r(eBe," \u2014 "),vJ=n(eBe,"A",{href:!0});var E5t=s(vJ);t0r=r(E5t,"FlaxGPT2Model"),E5t.forEach(t),a0r=r(eBe," (OpenAI GPT-2 model)"),eBe.forEach(t),n0r=i(ne),wE=n(ne,"LI",{});var oBe=s(wE);r8e=n(oBe,"STRONG",{});var C5t=s(r8e);s0r=r(C5t,"gpt_neo"),C5t.forEach(t),l0r=r(oBe," \u2014 "),FJ=n(oBe,"A",{href:!0});var w5t=s(FJ);i0r=r(w5t,"FlaxGPTNeoModel"),w5t.forEach(t),d0r=r(oBe," (GPT Neo model)"),oBe.forEach(t),c0r=i(ne),AE=n(ne,"LI",{});var rBe=s(AE);t8e=n(rBe,"STRONG",{});var A5t=s(t8e);f0r=r(A5t,"gptj"),A5t.forEach(t),m0r=r(rBe," \u2014 "),TJ=n(rBe,"A",{href:!0});var y5t=s(TJ);g0r=r(y5t,"FlaxGPTJModel"),y5t.forEach(t),h0r=r(rBe," (GPT-J model)"),rBe.forEach(t),p0r=i(ne),yE=n(ne,"LI",{});var tBe=s(yE);a8e=n(tBe,"STRONG",{});var L5t=s(a8e);u0r=r(L5t,"marian"),L5t.forEach(t),_0r=r(tBe," \u2014 "),MJ=n(tBe,"A",{href:!0});var x5t=s(MJ);b0r=r(x5t,"FlaxMarianModel"),x5t.forEach(t),v0r=r(tBe," (Marian model)"),tBe.forEach(t),F0r=i(ne),LE=n(ne,"LI",{});var aBe=s(LE);n8e=n(aBe,"STRONG",{});var $5t=s(n8e);T0r=r($5t,"mbart"),$5t.forEach(t),M0r=r(aBe," \u2014 "),EJ=n(aBe,"A",{href:!0});var k5t=s(EJ);E0r=r(k5t,"FlaxMBartModel"),k5t.forEach(t),C0r=r(aBe," (mBART model)"),aBe.forEach(t),w0r=i(ne),xE=n(ne,"LI",{});var nBe=s(xE);s8e=n(nBe,"STRONG",{});var S5t=s(s8e);A0r=r(S5t,"mt5"),S5t.forEach(t),y0r=r(nBe," \u2014 "),CJ=n(nBe,"A",{href:!0});var R5t=s(CJ);L0r=r(R5t,"FlaxMT5Model"),R5t.forEach(t),x0r=r(nBe," (mT5 model)"),nBe.forEach(t),$0r=i(ne),$E=n(ne,"LI",{});var sBe=s($E);l8e=n(sBe,"STRONG",{});var P5t=s(l8e);k0r=r(P5t,"pegasus"),P5t.forEach(t),S0r=r(sBe," \u2014 "),wJ=n(sBe,"A",{href:!0});var B5t=s(wJ);R0r=r(B5t,"FlaxPegasusModel"),B5t.forEach(t),P0r=r(sBe," (Pegasus model)"),sBe.forEach(t),B0r=i(ne),kE=n(ne,"LI",{});var lBe=s(kE);i8e=n(lBe,"STRONG",{});var I5t=s(i8e);I0r=r(I5t,"roberta"),I5t.forEach(t),q0r=r(lBe," \u2014 "),AJ=n(lBe,"A",{href:!0});var q5t=s(AJ);N0r=r(q5t,"FlaxRobertaModel"),q5t.forEach(t),j0r=r(lBe," (RoBERTa model)"),lBe.forEach(t),D0r=i(ne),SE=n(ne,"LI",{});var iBe=s(SE);d8e=n(iBe,"STRONG",{});var N5t=s(d8e);G0r=r(N5t,"roformer"),N5t.forEach(t),O0r=r(iBe," \u2014 "),yJ=n(iBe,"A",{href:!0});var j5t=s(yJ);V0r=r(j5t,"FlaxRoFormerModel"),j5t.forEach(t),X0r=r(iBe," (RoFormer model)"),iBe.forEach(t),z0r=i(ne),RE=n(ne,"LI",{});var dBe=s(RE);c8e=n(dBe,"STRONG",{});var D5t=s(c8e);Q0r=r(D5t,"t5"),D5t.forEach(t),W0r=r(dBe," \u2014 "),LJ=n(dBe,"A",{href:!0});var G5t=s(LJ);H0r=r(G5t,"FlaxT5Model"),G5t.forEach(t),U0r=r(dBe," (T5 model)"),dBe.forEach(t),J0r=i(ne),PE=n(ne,"LI",{});var cBe=s(PE);f8e=n(cBe,"STRONG",{});var O5t=s(f8e);Y0r=r(O5t,"vision-text-dual-encoder"),O5t.forEach(t),K0r=r(cBe," \u2014 "),xJ=n(cBe,"A",{href:!0});var V5t=s(xJ);Z0r=r(V5t,"FlaxVisionTextDualEncoderModel"),V5t.forEach(t),eyr=r(cBe," (VisionTextDualEncoder model)"),cBe.forEach(t),oyr=i(ne),BE=n(ne,"LI",{});var fBe=s(BE);m8e=n(fBe,"STRONG",{});var X5t=s(m8e);ryr=r(X5t,"vit"),X5t.forEach(t),tyr=r(fBe," \u2014 "),$J=n(fBe,"A",{href:!0});var z5t=s($J);ayr=r(z5t,"FlaxViTModel"),z5t.forEach(t),nyr=r(fBe," (ViT model)"),fBe.forEach(t),syr=i(ne),IE=n(ne,"LI",{});var mBe=s(IE);g8e=n(mBe,"STRONG",{});var Q5t=s(g8e);lyr=r(Q5t,"wav2vec2"),Q5t.forEach(t),iyr=r(mBe," \u2014 "),kJ=n(mBe,"A",{href:!0});var W5t=s(kJ);dyr=r(W5t,"FlaxWav2Vec2Model"),W5t.forEach(t),cyr=r(mBe," (Wav2Vec2 model)"),mBe.forEach(t),fyr=i(ne),qE=n(ne,"LI",{});var gBe=s(qE);h8e=n(gBe,"STRONG",{});var H5t=s(h8e);myr=r(H5t,"xglm"),H5t.forEach(t),gyr=r(gBe," \u2014 "),SJ=n(gBe,"A",{href:!0});var U5t=s(SJ);hyr=r(U5t,"FlaxXGLMModel"),U5t.forEach(t),pyr=r(gBe," (XGLM model)"),gBe.forEach(t),uyr=i(ne),NE=n(ne,"LI",{});var hBe=s(NE);p8e=n(hBe,"STRONG",{});var J5t=s(p8e);_yr=r(J5t,"xlm-roberta"),J5t.forEach(t),byr=r(hBe," \u2014 "),RJ=n(hBe,"A",{href:!0});var Y5t=s(RJ);vyr=r(Y5t,"FlaxXLMRobertaModel"),Y5t.forEach(t),Fyr=r(hBe," (XLM-RoBERTa model)"),hBe.forEach(t),ne.forEach(t),Tyr=i(zl),T(jE.$$.fragment,zl),zl.forEach(t),Xl.forEach(t),CNe=i(f),jc=n(f,"H2",{class:!0});var RDe=s(jc);DE=n(RDe,"A",{id:!0,class:!0,href:!0});var K5t=s(DE);u8e=n(K5t,"SPAN",{});var Z5t=s(u8e);T(Cx.$$.fragment,Z5t),Z5t.forEach(t),K5t.forEach(t),Myr=i(RDe),_8e=n(RDe,"SPAN",{});var eCt=s(_8e);Eyr=r(eCt,"FlaxAutoModelForCausalLM"),eCt.forEach(t),RDe.forEach(t),wNe=i(f),hr=n(f,"DIV",{class:!0});var Ql=s(hr);T(wx.$$.fragment,Ql),Cyr=i(Ql),Dc=n(Ql,"P",{});var mee=s(Dc);wyr=r(mee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),PJ=n(mee,"A",{href:!0});var oCt=s(PJ);Ayr=r(oCt,"from_pretrained()"),oCt.forEach(t),yyr=r(mee," class method or the "),BJ=n(mee,"A",{href:!0});var rCt=s(BJ);Lyr=r(rCt,"from_config()"),rCt.forEach(t),xyr=r(mee,` class
method.`),mee.forEach(t),$yr=i(Ql),Ax=n(Ql,"P",{});var PDe=s(Ax);kyr=r(PDe,"This class cannot be instantiated directly using "),b8e=n(PDe,"CODE",{});var tCt=s(b8e);Syr=r(tCt,"__init__()"),tCt.forEach(t),Ryr=r(PDe," (throws an error)."),PDe.forEach(t),Pyr=i(Ql),Vt=n(Ql,"DIV",{class:!0});var Xw=s(Vt);T(yx.$$.fragment,Xw),Byr=i(Xw),v8e=n(Xw,"P",{});var aCt=s(v8e);Iyr=r(aCt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),aCt.forEach(t),qyr=i(Xw),Gc=n(Xw,"P",{});var gee=s(Gc);Nyr=r(gee,`Note:
Loading a model from its configuration file does `),F8e=n(gee,"STRONG",{});var nCt=s(F8e);jyr=r(nCt,"not"),nCt.forEach(t),Dyr=r(gee,` load the model weights. It only affects the
model\u2019s configuration. Use `),IJ=n(gee,"A",{href:!0});var sCt=s(IJ);Gyr=r(sCt,"from_pretrained()"),sCt.forEach(t),Oyr=r(gee," to load the model weights."),gee.forEach(t),Vyr=i(Xw),T(GE.$$.fragment,Xw),Xw.forEach(t),Xyr=i(Ql),Or=n(Ql,"DIV",{class:!0});var Wl=s(Or);T(Lx.$$.fragment,Wl),zyr=i(Wl),T8e=n(Wl,"P",{});var lCt=s(T8e);Qyr=r(lCt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),lCt.forEach(t),Wyr=i(Wl),vn=n(Wl,"P",{});var zw=s(vn);Hyr=r(zw,"The model class to instantiate is selected based on the "),M8e=n(zw,"CODE",{});var iCt=s(M8e);Uyr=r(iCt,"model_type"),iCt.forEach(t),Jyr=r(zw,` property of the config object (either
passed as an argument or loaded from `),E8e=n(zw,"CODE",{});var dCt=s(E8e);Yyr=r(dCt,"pretrained_model_name_or_path"),dCt.forEach(t),Kyr=r(zw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C8e=n(zw,"CODE",{});var cCt=s(C8e);Zyr=r(cCt,"pretrained_model_name_or_path"),cCt.forEach(t),eLr=r(zw,":"),zw.forEach(t),oLr=i(Wl),ke=n(Wl,"UL",{});var Oe=s(ke);OE=n(Oe,"LI",{});var pBe=s(OE);w8e=n(pBe,"STRONG",{});var fCt=s(w8e);rLr=r(fCt,"bart"),fCt.forEach(t),tLr=r(pBe," \u2014 "),qJ=n(pBe,"A",{href:!0});var mCt=s(qJ);aLr=r(mCt,"FlaxBartForCausalLM"),mCt.forEach(t),nLr=r(pBe," (BART model)"),pBe.forEach(t),sLr=i(Oe),VE=n(Oe,"LI",{});var uBe=s(VE);A8e=n(uBe,"STRONG",{});var gCt=s(A8e);lLr=r(gCt,"bert"),gCt.forEach(t),iLr=r(uBe," \u2014 "),NJ=n(uBe,"A",{href:!0});var hCt=s(NJ);dLr=r(hCt,"FlaxBertForCausalLM"),hCt.forEach(t),cLr=r(uBe," (BERT model)"),uBe.forEach(t),fLr=i(Oe),XE=n(Oe,"LI",{});var _Be=s(XE);y8e=n(_Be,"STRONG",{});var pCt=s(y8e);mLr=r(pCt,"big_bird"),pCt.forEach(t),gLr=r(_Be," \u2014 "),jJ=n(_Be,"A",{href:!0});var uCt=s(jJ);hLr=r(uCt,"FlaxBigBirdForCausalLM"),uCt.forEach(t),pLr=r(_Be," (BigBird model)"),_Be.forEach(t),uLr=i(Oe),zE=n(Oe,"LI",{});var bBe=s(zE);L8e=n(bBe,"STRONG",{});var _Ct=s(L8e);_Lr=r(_Ct,"electra"),_Ct.forEach(t),bLr=r(bBe," \u2014 "),DJ=n(bBe,"A",{href:!0});var bCt=s(DJ);vLr=r(bCt,"FlaxElectraForCausalLM"),bCt.forEach(t),FLr=r(bBe," (ELECTRA model)"),bBe.forEach(t),TLr=i(Oe),QE=n(Oe,"LI",{});var vBe=s(QE);x8e=n(vBe,"STRONG",{});var vCt=s(x8e);MLr=r(vCt,"gpt2"),vCt.forEach(t),ELr=r(vBe," \u2014 "),GJ=n(vBe,"A",{href:!0});var FCt=s(GJ);CLr=r(FCt,"FlaxGPT2LMHeadModel"),FCt.forEach(t),wLr=r(vBe," (OpenAI GPT-2 model)"),vBe.forEach(t),ALr=i(Oe),WE=n(Oe,"LI",{});var FBe=s(WE);$8e=n(FBe,"STRONG",{});var TCt=s($8e);yLr=r(TCt,"gpt_neo"),TCt.forEach(t),LLr=r(FBe," \u2014 "),OJ=n(FBe,"A",{href:!0});var MCt=s(OJ);xLr=r(MCt,"FlaxGPTNeoForCausalLM"),MCt.forEach(t),$Lr=r(FBe," (GPT Neo model)"),FBe.forEach(t),kLr=i(Oe),HE=n(Oe,"LI",{});var TBe=s(HE);k8e=n(TBe,"STRONG",{});var ECt=s(k8e);SLr=r(ECt,"gptj"),ECt.forEach(t),RLr=r(TBe," \u2014 "),VJ=n(TBe,"A",{href:!0});var CCt=s(VJ);PLr=r(CCt,"FlaxGPTJForCausalLM"),CCt.forEach(t),BLr=r(TBe," (GPT-J model)"),TBe.forEach(t),ILr=i(Oe),UE=n(Oe,"LI",{});var MBe=s(UE);S8e=n(MBe,"STRONG",{});var wCt=s(S8e);qLr=r(wCt,"roberta"),wCt.forEach(t),NLr=r(MBe," \u2014 "),XJ=n(MBe,"A",{href:!0});var ACt=s(XJ);jLr=r(ACt,"FlaxRobertaForCausalLM"),ACt.forEach(t),DLr=r(MBe," (RoBERTa model)"),MBe.forEach(t),GLr=i(Oe),JE=n(Oe,"LI",{});var EBe=s(JE);R8e=n(EBe,"STRONG",{});var yCt=s(R8e);OLr=r(yCt,"xglm"),yCt.forEach(t),VLr=r(EBe," \u2014 "),zJ=n(EBe,"A",{href:!0});var LCt=s(zJ);XLr=r(LCt,"FlaxXGLMForCausalLM"),LCt.forEach(t),zLr=r(EBe," (XGLM model)"),EBe.forEach(t),Oe.forEach(t),QLr=i(Wl),T(YE.$$.fragment,Wl),Wl.forEach(t),Ql.forEach(t),ANe=i(f),Oc=n(f,"H2",{class:!0});var BDe=s(Oc);KE=n(BDe,"A",{id:!0,class:!0,href:!0});var xCt=s(KE);P8e=n(xCt,"SPAN",{});var $Ct=s(P8e);T(xx.$$.fragment,$Ct),$Ct.forEach(t),xCt.forEach(t),WLr=i(BDe),B8e=n(BDe,"SPAN",{});var kCt=s(B8e);HLr=r(kCt,"FlaxAutoModelForPreTraining"),kCt.forEach(t),BDe.forEach(t),yNe=i(f),pr=n(f,"DIV",{class:!0});var Hl=s(pr);T($x.$$.fragment,Hl),ULr=i(Hl),Vc=n(Hl,"P",{});var hee=s(Vc);JLr=r(hee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),QJ=n(hee,"A",{href:!0});var SCt=s(QJ);YLr=r(SCt,"from_pretrained()"),SCt.forEach(t),KLr=r(hee," class method or the "),WJ=n(hee,"A",{href:!0});var RCt=s(WJ);ZLr=r(RCt,"from_config()"),RCt.forEach(t),exr=r(hee,` class
method.`),hee.forEach(t),oxr=i(Hl),kx=n(Hl,"P",{});var IDe=s(kx);rxr=r(IDe,"This class cannot be instantiated directly using "),I8e=n(IDe,"CODE",{});var PCt=s(I8e);txr=r(PCt,"__init__()"),PCt.forEach(t),axr=r(IDe," (throws an error)."),IDe.forEach(t),nxr=i(Hl),Xt=n(Hl,"DIV",{class:!0});var Qw=s(Xt);T(Sx.$$.fragment,Qw),sxr=i(Qw),q8e=n(Qw,"P",{});var BCt=s(q8e);lxr=r(BCt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),BCt.forEach(t),ixr=i(Qw),Xc=n(Qw,"P",{});var pee=s(Xc);dxr=r(pee,`Note:
Loading a model from its configuration file does `),N8e=n(pee,"STRONG",{});var ICt=s(N8e);cxr=r(ICt,"not"),ICt.forEach(t),fxr=r(pee,` load the model weights. It only affects the
model\u2019s configuration. Use `),HJ=n(pee,"A",{href:!0});var qCt=s(HJ);mxr=r(qCt,"from_pretrained()"),qCt.forEach(t),gxr=r(pee," to load the model weights."),pee.forEach(t),hxr=i(Qw),T(ZE.$$.fragment,Qw),Qw.forEach(t),pxr=i(Hl),Vr=n(Hl,"DIV",{class:!0});var Ul=s(Vr);T(Rx.$$.fragment,Ul),uxr=i(Ul),j8e=n(Ul,"P",{});var NCt=s(j8e);_xr=r(NCt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),NCt.forEach(t),bxr=i(Ul),Fn=n(Ul,"P",{});var Ww=s(Fn);vxr=r(Ww,"The model class to instantiate is selected based on the "),D8e=n(Ww,"CODE",{});var jCt=s(D8e);Fxr=r(jCt,"model_type"),jCt.forEach(t),Txr=r(Ww,` property of the config object (either
passed as an argument or loaded from `),G8e=n(Ww,"CODE",{});var DCt=s(G8e);Mxr=r(DCt,"pretrained_model_name_or_path"),DCt.forEach(t),Exr=r(Ww,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O8e=n(Ww,"CODE",{});var GCt=s(O8e);Cxr=r(GCt,"pretrained_model_name_or_path"),GCt.forEach(t),wxr=r(Ww,":"),Ww.forEach(t),Axr=i(Ul),Me=n(Ul,"UL",{});var we=s(Me);e5=n(we,"LI",{});var CBe=s(e5);V8e=n(CBe,"STRONG",{});var OCt=s(V8e);yxr=r(OCt,"albert"),OCt.forEach(t),Lxr=r(CBe," \u2014 "),UJ=n(CBe,"A",{href:!0});var VCt=s(UJ);xxr=r(VCt,"FlaxAlbertForPreTraining"),VCt.forEach(t),$xr=r(CBe," (ALBERT model)"),CBe.forEach(t),kxr=i(we),o5=n(we,"LI",{});var wBe=s(o5);X8e=n(wBe,"STRONG",{});var XCt=s(X8e);Sxr=r(XCt,"bart"),XCt.forEach(t),Rxr=r(wBe," \u2014 "),JJ=n(wBe,"A",{href:!0});var zCt=s(JJ);Pxr=r(zCt,"FlaxBartForConditionalGeneration"),zCt.forEach(t),Bxr=r(wBe," (BART model)"),wBe.forEach(t),Ixr=i(we),r5=n(we,"LI",{});var ABe=s(r5);z8e=n(ABe,"STRONG",{});var QCt=s(z8e);qxr=r(QCt,"bert"),QCt.forEach(t),Nxr=r(ABe," \u2014 "),YJ=n(ABe,"A",{href:!0});var WCt=s(YJ);jxr=r(WCt,"FlaxBertForPreTraining"),WCt.forEach(t),Dxr=r(ABe," (BERT model)"),ABe.forEach(t),Gxr=i(we),t5=n(we,"LI",{});var yBe=s(t5);Q8e=n(yBe,"STRONG",{});var HCt=s(Q8e);Oxr=r(HCt,"big_bird"),HCt.forEach(t),Vxr=r(yBe," \u2014 "),KJ=n(yBe,"A",{href:!0});var UCt=s(KJ);Xxr=r(UCt,"FlaxBigBirdForPreTraining"),UCt.forEach(t),zxr=r(yBe," (BigBird model)"),yBe.forEach(t),Qxr=i(we),a5=n(we,"LI",{});var LBe=s(a5);W8e=n(LBe,"STRONG",{});var JCt=s(W8e);Wxr=r(JCt,"electra"),JCt.forEach(t),Hxr=r(LBe," \u2014 "),ZJ=n(LBe,"A",{href:!0});var YCt=s(ZJ);Uxr=r(YCt,"FlaxElectraForPreTraining"),YCt.forEach(t),Jxr=r(LBe," (ELECTRA model)"),LBe.forEach(t),Yxr=i(we),n5=n(we,"LI",{});var xBe=s(n5);H8e=n(xBe,"STRONG",{});var KCt=s(H8e);Kxr=r(KCt,"mbart"),KCt.forEach(t),Zxr=r(xBe," \u2014 "),eY=n(xBe,"A",{href:!0});var ZCt=s(eY);e9r=r(ZCt,"FlaxMBartForConditionalGeneration"),ZCt.forEach(t),o9r=r(xBe," (mBART model)"),xBe.forEach(t),r9r=i(we),s5=n(we,"LI",{});var $Be=s(s5);U8e=n($Be,"STRONG",{});var e3t=s(U8e);t9r=r(e3t,"mt5"),e3t.forEach(t),a9r=r($Be," \u2014 "),oY=n($Be,"A",{href:!0});var o3t=s(oY);n9r=r(o3t,"FlaxMT5ForConditionalGeneration"),o3t.forEach(t),s9r=r($Be," (mT5 model)"),$Be.forEach(t),l9r=i(we),l5=n(we,"LI",{});var kBe=s(l5);J8e=n(kBe,"STRONG",{});var r3t=s(J8e);i9r=r(r3t,"roberta"),r3t.forEach(t),d9r=r(kBe," \u2014 "),rY=n(kBe,"A",{href:!0});var t3t=s(rY);c9r=r(t3t,"FlaxRobertaForMaskedLM"),t3t.forEach(t),f9r=r(kBe," (RoBERTa model)"),kBe.forEach(t),m9r=i(we),i5=n(we,"LI",{});var SBe=s(i5);Y8e=n(SBe,"STRONG",{});var a3t=s(Y8e);g9r=r(a3t,"roformer"),a3t.forEach(t),h9r=r(SBe," \u2014 "),tY=n(SBe,"A",{href:!0});var n3t=s(tY);p9r=r(n3t,"FlaxRoFormerForMaskedLM"),n3t.forEach(t),u9r=r(SBe," (RoFormer model)"),SBe.forEach(t),_9r=i(we),d5=n(we,"LI",{});var RBe=s(d5);K8e=n(RBe,"STRONG",{});var s3t=s(K8e);b9r=r(s3t,"t5"),s3t.forEach(t),v9r=r(RBe," \u2014 "),aY=n(RBe,"A",{href:!0});var l3t=s(aY);F9r=r(l3t,"FlaxT5ForConditionalGeneration"),l3t.forEach(t),T9r=r(RBe," (T5 model)"),RBe.forEach(t),M9r=i(we),c5=n(we,"LI",{});var PBe=s(c5);Z8e=n(PBe,"STRONG",{});var i3t=s(Z8e);E9r=r(i3t,"wav2vec2"),i3t.forEach(t),C9r=r(PBe," \u2014 "),nY=n(PBe,"A",{href:!0});var d3t=s(nY);w9r=r(d3t,"FlaxWav2Vec2ForPreTraining"),d3t.forEach(t),A9r=r(PBe," (Wav2Vec2 model)"),PBe.forEach(t),y9r=i(we),f5=n(we,"LI",{});var BBe=s(f5);e7e=n(BBe,"STRONG",{});var c3t=s(e7e);L9r=r(c3t,"xlm-roberta"),c3t.forEach(t),x9r=r(BBe," \u2014 "),sY=n(BBe,"A",{href:!0});var f3t=s(sY);$9r=r(f3t,"FlaxXLMRobertaForMaskedLM"),f3t.forEach(t),k9r=r(BBe," (XLM-RoBERTa model)"),BBe.forEach(t),we.forEach(t),S9r=i(Ul),T(m5.$$.fragment,Ul),Ul.forEach(t),Hl.forEach(t),LNe=i(f),zc=n(f,"H2",{class:!0});var qDe=s(zc);g5=n(qDe,"A",{id:!0,class:!0,href:!0});var m3t=s(g5);o7e=n(m3t,"SPAN",{});var g3t=s(o7e);T(Px.$$.fragment,g3t),g3t.forEach(t),m3t.forEach(t),R9r=i(qDe),r7e=n(qDe,"SPAN",{});var h3t=s(r7e);P9r=r(h3t,"FlaxAutoModelForMaskedLM"),h3t.forEach(t),qDe.forEach(t),xNe=i(f),ur=n(f,"DIV",{class:!0});var Jl=s(ur);T(Bx.$$.fragment,Jl),B9r=i(Jl),Qc=n(Jl,"P",{});var uee=s(Qc);I9r=r(uee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),lY=n(uee,"A",{href:!0});var p3t=s(lY);q9r=r(p3t,"from_pretrained()"),p3t.forEach(t),N9r=r(uee," class method or the "),iY=n(uee,"A",{href:!0});var u3t=s(iY);j9r=r(u3t,"from_config()"),u3t.forEach(t),D9r=r(uee,` class
method.`),uee.forEach(t),G9r=i(Jl),Ix=n(Jl,"P",{});var NDe=s(Ix);O9r=r(NDe,"This class cannot be instantiated directly using "),t7e=n(NDe,"CODE",{});var _3t=s(t7e);V9r=r(_3t,"__init__()"),_3t.forEach(t),X9r=r(NDe," (throws an error)."),NDe.forEach(t),z9r=i(Jl),zt=n(Jl,"DIV",{class:!0});var Hw=s(zt);T(qx.$$.fragment,Hw),Q9r=i(Hw),a7e=n(Hw,"P",{});var b3t=s(a7e);W9r=r(b3t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),b3t.forEach(t),H9r=i(Hw),Wc=n(Hw,"P",{});var _ee=s(Wc);U9r=r(_ee,`Note:
Loading a model from its configuration file does `),n7e=n(_ee,"STRONG",{});var v3t=s(n7e);J9r=r(v3t,"not"),v3t.forEach(t),Y9r=r(_ee,` load the model weights. It only affects the
model\u2019s configuration. Use `),dY=n(_ee,"A",{href:!0});var F3t=s(dY);K9r=r(F3t,"from_pretrained()"),F3t.forEach(t),Z9r=r(_ee," to load the model weights."),_ee.forEach(t),e$r=i(Hw),T(h5.$$.fragment,Hw),Hw.forEach(t),o$r=i(Jl),Xr=n(Jl,"DIV",{class:!0});var Yl=s(Xr);T(Nx.$$.fragment,Yl),r$r=i(Yl),s7e=n(Yl,"P",{});var T3t=s(s7e);t$r=r(T3t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),T3t.forEach(t),a$r=i(Yl),Tn=n(Yl,"P",{});var Uw=s(Tn);n$r=r(Uw,"The model class to instantiate is selected based on the "),l7e=n(Uw,"CODE",{});var M3t=s(l7e);s$r=r(M3t,"model_type"),M3t.forEach(t),l$r=r(Uw,` property of the config object (either
passed as an argument or loaded from `),i7e=n(Uw,"CODE",{});var E3t=s(i7e);i$r=r(E3t,"pretrained_model_name_or_path"),E3t.forEach(t),d$r=r(Uw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d7e=n(Uw,"CODE",{});var C3t=s(d7e);c$r=r(C3t,"pretrained_model_name_or_path"),C3t.forEach(t),f$r=r(Uw,":"),Uw.forEach(t),m$r=i(Yl),Le=n(Yl,"UL",{});var Pe=s(Le);p5=n(Pe,"LI",{});var IBe=s(p5);c7e=n(IBe,"STRONG",{});var w3t=s(c7e);g$r=r(w3t,"albert"),w3t.forEach(t),h$r=r(IBe," \u2014 "),cY=n(IBe,"A",{href:!0});var A3t=s(cY);p$r=r(A3t,"FlaxAlbertForMaskedLM"),A3t.forEach(t),u$r=r(IBe," (ALBERT model)"),IBe.forEach(t),_$r=i(Pe),u5=n(Pe,"LI",{});var qBe=s(u5);f7e=n(qBe,"STRONG",{});var y3t=s(f7e);b$r=r(y3t,"bart"),y3t.forEach(t),v$r=r(qBe," \u2014 "),fY=n(qBe,"A",{href:!0});var L3t=s(fY);F$r=r(L3t,"FlaxBartForConditionalGeneration"),L3t.forEach(t),T$r=r(qBe," (BART model)"),qBe.forEach(t),M$r=i(Pe),_5=n(Pe,"LI",{});var NBe=s(_5);m7e=n(NBe,"STRONG",{});var x3t=s(m7e);E$r=r(x3t,"bert"),x3t.forEach(t),C$r=r(NBe," \u2014 "),mY=n(NBe,"A",{href:!0});var $3t=s(mY);w$r=r($3t,"FlaxBertForMaskedLM"),$3t.forEach(t),A$r=r(NBe," (BERT model)"),NBe.forEach(t),y$r=i(Pe),b5=n(Pe,"LI",{});var jBe=s(b5);g7e=n(jBe,"STRONG",{});var k3t=s(g7e);L$r=r(k3t,"big_bird"),k3t.forEach(t),x$r=r(jBe," \u2014 "),gY=n(jBe,"A",{href:!0});var S3t=s(gY);$$r=r(S3t,"FlaxBigBirdForMaskedLM"),S3t.forEach(t),k$r=r(jBe," (BigBird model)"),jBe.forEach(t),S$r=i(Pe),v5=n(Pe,"LI",{});var DBe=s(v5);h7e=n(DBe,"STRONG",{});var R3t=s(h7e);R$r=r(R3t,"distilbert"),R3t.forEach(t),P$r=r(DBe," \u2014 "),hY=n(DBe,"A",{href:!0});var P3t=s(hY);B$r=r(P3t,"FlaxDistilBertForMaskedLM"),P3t.forEach(t),I$r=r(DBe," (DistilBERT model)"),DBe.forEach(t),q$r=i(Pe),F5=n(Pe,"LI",{});var GBe=s(F5);p7e=n(GBe,"STRONG",{});var B3t=s(p7e);N$r=r(B3t,"electra"),B3t.forEach(t),j$r=r(GBe," \u2014 "),pY=n(GBe,"A",{href:!0});var I3t=s(pY);D$r=r(I3t,"FlaxElectraForMaskedLM"),I3t.forEach(t),G$r=r(GBe," (ELECTRA model)"),GBe.forEach(t),O$r=i(Pe),T5=n(Pe,"LI",{});var OBe=s(T5);u7e=n(OBe,"STRONG",{});var q3t=s(u7e);V$r=r(q3t,"mbart"),q3t.forEach(t),X$r=r(OBe," \u2014 "),uY=n(OBe,"A",{href:!0});var N3t=s(uY);z$r=r(N3t,"FlaxMBartForConditionalGeneration"),N3t.forEach(t),Q$r=r(OBe," (mBART model)"),OBe.forEach(t),W$r=i(Pe),M5=n(Pe,"LI",{});var VBe=s(M5);_7e=n(VBe,"STRONG",{});var j3t=s(_7e);H$r=r(j3t,"roberta"),j3t.forEach(t),U$r=r(VBe," \u2014 "),_Y=n(VBe,"A",{href:!0});var D3t=s(_Y);J$r=r(D3t,"FlaxRobertaForMaskedLM"),D3t.forEach(t),Y$r=r(VBe," (RoBERTa model)"),VBe.forEach(t),K$r=i(Pe),E5=n(Pe,"LI",{});var XBe=s(E5);b7e=n(XBe,"STRONG",{});var G3t=s(b7e);Z$r=r(G3t,"roformer"),G3t.forEach(t),ekr=r(XBe," \u2014 "),bY=n(XBe,"A",{href:!0});var O3t=s(bY);okr=r(O3t,"FlaxRoFormerForMaskedLM"),O3t.forEach(t),rkr=r(XBe," (RoFormer model)"),XBe.forEach(t),tkr=i(Pe),C5=n(Pe,"LI",{});var zBe=s(C5);v7e=n(zBe,"STRONG",{});var V3t=s(v7e);akr=r(V3t,"xlm-roberta"),V3t.forEach(t),nkr=r(zBe," \u2014 "),vY=n(zBe,"A",{href:!0});var X3t=s(vY);skr=r(X3t,"FlaxXLMRobertaForMaskedLM"),X3t.forEach(t),lkr=r(zBe," (XLM-RoBERTa model)"),zBe.forEach(t),Pe.forEach(t),ikr=i(Yl),T(w5.$$.fragment,Yl),Yl.forEach(t),Jl.forEach(t),$Ne=i(f),Hc=n(f,"H2",{class:!0});var jDe=s(Hc);A5=n(jDe,"A",{id:!0,class:!0,href:!0});var z3t=s(A5);F7e=n(z3t,"SPAN",{});var Q3t=s(F7e);T(jx.$$.fragment,Q3t),Q3t.forEach(t),z3t.forEach(t),dkr=i(jDe),T7e=n(jDe,"SPAN",{});var W3t=s(T7e);ckr=r(W3t,"FlaxAutoModelForSeq2SeqLM"),W3t.forEach(t),jDe.forEach(t),kNe=i(f),_r=n(f,"DIV",{class:!0});var Kl=s(_r);T(Dx.$$.fragment,Kl),fkr=i(Kl),Uc=n(Kl,"P",{});var bee=s(Uc);mkr=r(bee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),FY=n(bee,"A",{href:!0});var H3t=s(FY);gkr=r(H3t,"from_pretrained()"),H3t.forEach(t),hkr=r(bee," class method or the "),TY=n(bee,"A",{href:!0});var U3t=s(TY);pkr=r(U3t,"from_config()"),U3t.forEach(t),ukr=r(bee,` class
method.`),bee.forEach(t),_kr=i(Kl),Gx=n(Kl,"P",{});var DDe=s(Gx);bkr=r(DDe,"This class cannot be instantiated directly using "),M7e=n(DDe,"CODE",{});var J3t=s(M7e);vkr=r(J3t,"__init__()"),J3t.forEach(t),Fkr=r(DDe," (throws an error)."),DDe.forEach(t),Tkr=i(Kl),Qt=n(Kl,"DIV",{class:!0});var Jw=s(Qt);T(Ox.$$.fragment,Jw),Mkr=i(Jw),E7e=n(Jw,"P",{});var Y3t=s(E7e);Ekr=r(Y3t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Y3t.forEach(t),Ckr=i(Jw),Jc=n(Jw,"P",{});var vee=s(Jc);wkr=r(vee,`Note:
Loading a model from its configuration file does `),C7e=n(vee,"STRONG",{});var K3t=s(C7e);Akr=r(K3t,"not"),K3t.forEach(t),ykr=r(vee,` load the model weights. It only affects the
model\u2019s configuration. Use `),MY=n(vee,"A",{href:!0});var Z3t=s(MY);Lkr=r(Z3t,"from_pretrained()"),Z3t.forEach(t),xkr=r(vee," to load the model weights."),vee.forEach(t),$kr=i(Jw),T(y5.$$.fragment,Jw),Jw.forEach(t),kkr=i(Kl),zr=n(Kl,"DIV",{class:!0});var Zl=s(zr);T(Vx.$$.fragment,Zl),Skr=i(Zl),w7e=n(Zl,"P",{});var ewt=s(w7e);Rkr=r(ewt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),ewt.forEach(t),Pkr=i(Zl),Mn=n(Zl,"P",{});var Yw=s(Mn);Bkr=r(Yw,"The model class to instantiate is selected based on the "),A7e=n(Yw,"CODE",{});var owt=s(A7e);Ikr=r(owt,"model_type"),owt.forEach(t),qkr=r(Yw,` property of the config object (either
passed as an argument or loaded from `),y7e=n(Yw,"CODE",{});var rwt=s(y7e);Nkr=r(rwt,"pretrained_model_name_or_path"),rwt.forEach(t),jkr=r(Yw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L7e=n(Yw,"CODE",{});var twt=s(L7e);Dkr=r(twt,"pretrained_model_name_or_path"),twt.forEach(t),Gkr=r(Yw,":"),Yw.forEach(t),Okr=i(Zl),Se=n(Zl,"UL",{});var Ve=s(Se);L5=n(Ve,"LI",{});var QBe=s(L5);x7e=n(QBe,"STRONG",{});var awt=s(x7e);Vkr=r(awt,"bart"),awt.forEach(t),Xkr=r(QBe," \u2014 "),EY=n(QBe,"A",{href:!0});var nwt=s(EY);zkr=r(nwt,"FlaxBartForConditionalGeneration"),nwt.forEach(t),Qkr=r(QBe," (BART model)"),QBe.forEach(t),Wkr=i(Ve),x5=n(Ve,"LI",{});var WBe=s(x5);$7e=n(WBe,"STRONG",{});var swt=s($7e);Hkr=r(swt,"blenderbot"),swt.forEach(t),Ukr=r(WBe," \u2014 "),CY=n(WBe,"A",{href:!0});var lwt=s(CY);Jkr=r(lwt,"FlaxBlenderbotForConditionalGeneration"),lwt.forEach(t),Ykr=r(WBe," (Blenderbot model)"),WBe.forEach(t),Kkr=i(Ve),$5=n(Ve,"LI",{});var HBe=s($5);k7e=n(HBe,"STRONG",{});var iwt=s(k7e);Zkr=r(iwt,"blenderbot-small"),iwt.forEach(t),eSr=r(HBe," \u2014 "),wY=n(HBe,"A",{href:!0});var dwt=s(wY);oSr=r(dwt,"FlaxBlenderbotSmallForConditionalGeneration"),dwt.forEach(t),rSr=r(HBe," (BlenderbotSmall model)"),HBe.forEach(t),tSr=i(Ve),k5=n(Ve,"LI",{});var UBe=s(k5);S7e=n(UBe,"STRONG",{});var cwt=s(S7e);aSr=r(cwt,"encoder-decoder"),cwt.forEach(t),nSr=r(UBe," \u2014 "),AY=n(UBe,"A",{href:!0});var fwt=s(AY);sSr=r(fwt,"FlaxEncoderDecoderModel"),fwt.forEach(t),lSr=r(UBe," (Encoder decoder model)"),UBe.forEach(t),iSr=i(Ve),S5=n(Ve,"LI",{});var JBe=s(S5);R7e=n(JBe,"STRONG",{});var mwt=s(R7e);dSr=r(mwt,"marian"),mwt.forEach(t),cSr=r(JBe," \u2014 "),yY=n(JBe,"A",{href:!0});var gwt=s(yY);fSr=r(gwt,"FlaxMarianMTModel"),gwt.forEach(t),mSr=r(JBe," (Marian model)"),JBe.forEach(t),gSr=i(Ve),R5=n(Ve,"LI",{});var YBe=s(R5);P7e=n(YBe,"STRONG",{});var hwt=s(P7e);hSr=r(hwt,"mbart"),hwt.forEach(t),pSr=r(YBe," \u2014 "),LY=n(YBe,"A",{href:!0});var pwt=s(LY);uSr=r(pwt,"FlaxMBartForConditionalGeneration"),pwt.forEach(t),_Sr=r(YBe," (mBART model)"),YBe.forEach(t),bSr=i(Ve),P5=n(Ve,"LI",{});var KBe=s(P5);B7e=n(KBe,"STRONG",{});var uwt=s(B7e);vSr=r(uwt,"mt5"),uwt.forEach(t),FSr=r(KBe," \u2014 "),xY=n(KBe,"A",{href:!0});var _wt=s(xY);TSr=r(_wt,"FlaxMT5ForConditionalGeneration"),_wt.forEach(t),MSr=r(KBe," (mT5 model)"),KBe.forEach(t),ESr=i(Ve),B5=n(Ve,"LI",{});var ZBe=s(B5);I7e=n(ZBe,"STRONG",{});var bwt=s(I7e);CSr=r(bwt,"pegasus"),bwt.forEach(t),wSr=r(ZBe," \u2014 "),$Y=n(ZBe,"A",{href:!0});var vwt=s($Y);ASr=r(vwt,"FlaxPegasusForConditionalGeneration"),vwt.forEach(t),ySr=r(ZBe," (Pegasus model)"),ZBe.forEach(t),LSr=i(Ve),I5=n(Ve,"LI",{});var eIe=s(I5);q7e=n(eIe,"STRONG",{});var Fwt=s(q7e);xSr=r(Fwt,"t5"),Fwt.forEach(t),$Sr=r(eIe," \u2014 "),kY=n(eIe,"A",{href:!0});var Twt=s(kY);kSr=r(Twt,"FlaxT5ForConditionalGeneration"),Twt.forEach(t),SSr=r(eIe," (T5 model)"),eIe.forEach(t),Ve.forEach(t),RSr=i(Zl),T(q5.$$.fragment,Zl),Zl.forEach(t),Kl.forEach(t),SNe=i(f),Yc=n(f,"H2",{class:!0});var GDe=s(Yc);N5=n(GDe,"A",{id:!0,class:!0,href:!0});var Mwt=s(N5);N7e=n(Mwt,"SPAN",{});var Ewt=s(N7e);T(Xx.$$.fragment,Ewt),Ewt.forEach(t),Mwt.forEach(t),PSr=i(GDe),j7e=n(GDe,"SPAN",{});var Cwt=s(j7e);BSr=r(Cwt,"FlaxAutoModelForSequenceClassification"),Cwt.forEach(t),GDe.forEach(t),RNe=i(f),br=n(f,"DIV",{class:!0});var ei=s(br);T(zx.$$.fragment,ei),ISr=i(ei),Kc=n(ei,"P",{});var Fee=s(Kc);qSr=r(Fee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),SY=n(Fee,"A",{href:!0});var wwt=s(SY);NSr=r(wwt,"from_pretrained()"),wwt.forEach(t),jSr=r(Fee," class method or the "),RY=n(Fee,"A",{href:!0});var Awt=s(RY);DSr=r(Awt,"from_config()"),Awt.forEach(t),GSr=r(Fee,` class
method.`),Fee.forEach(t),OSr=i(ei),Qx=n(ei,"P",{});var ODe=s(Qx);VSr=r(ODe,"This class cannot be instantiated directly using "),D7e=n(ODe,"CODE",{});var ywt=s(D7e);XSr=r(ywt,"__init__()"),ywt.forEach(t),zSr=r(ODe," (throws an error)."),ODe.forEach(t),QSr=i(ei),Wt=n(ei,"DIV",{class:!0});var Kw=s(Wt);T(Wx.$$.fragment,Kw),WSr=i(Kw),G7e=n(Kw,"P",{});var Lwt=s(G7e);HSr=r(Lwt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Lwt.forEach(t),USr=i(Kw),Zc=n(Kw,"P",{});var Tee=s(Zc);JSr=r(Tee,`Note:
Loading a model from its configuration file does `),O7e=n(Tee,"STRONG",{});var xwt=s(O7e);YSr=r(xwt,"not"),xwt.forEach(t),KSr=r(Tee,` load the model weights. It only affects the
model\u2019s configuration. Use `),PY=n(Tee,"A",{href:!0});var $wt=s(PY);ZSr=r($wt,"from_pretrained()"),$wt.forEach(t),eRr=r(Tee," to load the model weights."),Tee.forEach(t),oRr=i(Kw),T(j5.$$.fragment,Kw),Kw.forEach(t),rRr=i(ei),Qr=n(ei,"DIV",{class:!0});var oi=s(Qr);T(Hx.$$.fragment,oi),tRr=i(oi),V7e=n(oi,"P",{});var kwt=s(V7e);aRr=r(kwt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),kwt.forEach(t),nRr=i(oi),En=n(oi,"P",{});var Zw=s(En);sRr=r(Zw,"The model class to instantiate is selected based on the "),X7e=n(Zw,"CODE",{});var Swt=s(X7e);lRr=r(Swt,"model_type"),Swt.forEach(t),iRr=r(Zw,` property of the config object (either
passed as an argument or loaded from `),z7e=n(Zw,"CODE",{});var Rwt=s(z7e);dRr=r(Rwt,"pretrained_model_name_or_path"),Rwt.forEach(t),cRr=r(Zw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q7e=n(Zw,"CODE",{});var Pwt=s(Q7e);fRr=r(Pwt,"pretrained_model_name_or_path"),Pwt.forEach(t),mRr=r(Zw,":"),Zw.forEach(t),gRr=i(oi),xe=n(oi,"UL",{});var Be=s(xe);D5=n(Be,"LI",{});var oIe=s(D5);W7e=n(oIe,"STRONG",{});var Bwt=s(W7e);hRr=r(Bwt,"albert"),Bwt.forEach(t),pRr=r(oIe," \u2014 "),BY=n(oIe,"A",{href:!0});var Iwt=s(BY);uRr=r(Iwt,"FlaxAlbertForSequenceClassification"),Iwt.forEach(t),_Rr=r(oIe," (ALBERT model)"),oIe.forEach(t),bRr=i(Be),G5=n(Be,"LI",{});var rIe=s(G5);H7e=n(rIe,"STRONG",{});var qwt=s(H7e);vRr=r(qwt,"bart"),qwt.forEach(t),FRr=r(rIe," \u2014 "),IY=n(rIe,"A",{href:!0});var Nwt=s(IY);TRr=r(Nwt,"FlaxBartForSequenceClassification"),Nwt.forEach(t),MRr=r(rIe," (BART model)"),rIe.forEach(t),ERr=i(Be),O5=n(Be,"LI",{});var tIe=s(O5);U7e=n(tIe,"STRONG",{});var jwt=s(U7e);CRr=r(jwt,"bert"),jwt.forEach(t),wRr=r(tIe," \u2014 "),qY=n(tIe,"A",{href:!0});var Dwt=s(qY);ARr=r(Dwt,"FlaxBertForSequenceClassification"),Dwt.forEach(t),yRr=r(tIe," (BERT model)"),tIe.forEach(t),LRr=i(Be),V5=n(Be,"LI",{});var aIe=s(V5);J7e=n(aIe,"STRONG",{});var Gwt=s(J7e);xRr=r(Gwt,"big_bird"),Gwt.forEach(t),$Rr=r(aIe," \u2014 "),NY=n(aIe,"A",{href:!0});var Owt=s(NY);kRr=r(Owt,"FlaxBigBirdForSequenceClassification"),Owt.forEach(t),SRr=r(aIe," (BigBird model)"),aIe.forEach(t),RRr=i(Be),X5=n(Be,"LI",{});var nIe=s(X5);Y7e=n(nIe,"STRONG",{});var Vwt=s(Y7e);PRr=r(Vwt,"distilbert"),Vwt.forEach(t),BRr=r(nIe," \u2014 "),jY=n(nIe,"A",{href:!0});var Xwt=s(jY);IRr=r(Xwt,"FlaxDistilBertForSequenceClassification"),Xwt.forEach(t),qRr=r(nIe," (DistilBERT model)"),nIe.forEach(t),NRr=i(Be),z5=n(Be,"LI",{});var sIe=s(z5);K7e=n(sIe,"STRONG",{});var zwt=s(K7e);jRr=r(zwt,"electra"),zwt.forEach(t),DRr=r(sIe," \u2014 "),DY=n(sIe,"A",{href:!0});var Qwt=s(DY);GRr=r(Qwt,"FlaxElectraForSequenceClassification"),Qwt.forEach(t),ORr=r(sIe," (ELECTRA model)"),sIe.forEach(t),VRr=i(Be),Q5=n(Be,"LI",{});var lIe=s(Q5);Z7e=n(lIe,"STRONG",{});var Wwt=s(Z7e);XRr=r(Wwt,"mbart"),Wwt.forEach(t),zRr=r(lIe," \u2014 "),GY=n(lIe,"A",{href:!0});var Hwt=s(GY);QRr=r(Hwt,"FlaxMBartForSequenceClassification"),Hwt.forEach(t),WRr=r(lIe," (mBART model)"),lIe.forEach(t),HRr=i(Be),W5=n(Be,"LI",{});var iIe=s(W5);eMe=n(iIe,"STRONG",{});var Uwt=s(eMe);URr=r(Uwt,"roberta"),Uwt.forEach(t),JRr=r(iIe," \u2014 "),OY=n(iIe,"A",{href:!0});var Jwt=s(OY);YRr=r(Jwt,"FlaxRobertaForSequenceClassification"),Jwt.forEach(t),KRr=r(iIe," (RoBERTa model)"),iIe.forEach(t),ZRr=i(Be),H5=n(Be,"LI",{});var dIe=s(H5);oMe=n(dIe,"STRONG",{});var Ywt=s(oMe);ePr=r(Ywt,"roformer"),Ywt.forEach(t),oPr=r(dIe," \u2014 "),VY=n(dIe,"A",{href:!0});var Kwt=s(VY);rPr=r(Kwt,"FlaxRoFormerForSequenceClassification"),Kwt.forEach(t),tPr=r(dIe," (RoFormer model)"),dIe.forEach(t),aPr=i(Be),U5=n(Be,"LI",{});var cIe=s(U5);rMe=n(cIe,"STRONG",{});var Zwt=s(rMe);nPr=r(Zwt,"xlm-roberta"),Zwt.forEach(t),sPr=r(cIe," \u2014 "),XY=n(cIe,"A",{href:!0});var eAt=s(XY);lPr=r(eAt,"FlaxXLMRobertaForSequenceClassification"),eAt.forEach(t),iPr=r(cIe," (XLM-RoBERTa model)"),cIe.forEach(t),Be.forEach(t),dPr=i(oi),T(J5.$$.fragment,oi),oi.forEach(t),ei.forEach(t),PNe=i(f),ef=n(f,"H2",{class:!0});var VDe=s(ef);Y5=n(VDe,"A",{id:!0,class:!0,href:!0});var oAt=s(Y5);tMe=n(oAt,"SPAN",{});var rAt=s(tMe);T(Ux.$$.fragment,rAt),rAt.forEach(t),oAt.forEach(t),cPr=i(VDe),aMe=n(VDe,"SPAN",{});var tAt=s(aMe);fPr=r(tAt,"FlaxAutoModelForQuestionAnswering"),tAt.forEach(t),VDe.forEach(t),BNe=i(f),vr=n(f,"DIV",{class:!0});var ri=s(vr);T(Jx.$$.fragment,ri),mPr=i(ri),of=n(ri,"P",{});var Mee=s(of);gPr=r(Mee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),zY=n(Mee,"A",{href:!0});var aAt=s(zY);hPr=r(aAt,"from_pretrained()"),aAt.forEach(t),pPr=r(Mee," class method or the "),QY=n(Mee,"A",{href:!0});var nAt=s(QY);uPr=r(nAt,"from_config()"),nAt.forEach(t),_Pr=r(Mee,` class
method.`),Mee.forEach(t),bPr=i(ri),Yx=n(ri,"P",{});var XDe=s(Yx);vPr=r(XDe,"This class cannot be instantiated directly using "),nMe=n(XDe,"CODE",{});var sAt=s(nMe);FPr=r(sAt,"__init__()"),sAt.forEach(t),TPr=r(XDe," (throws an error)."),XDe.forEach(t),MPr=i(ri),Ht=n(ri,"DIV",{class:!0});var eA=s(Ht);T(Kx.$$.fragment,eA),EPr=i(eA),sMe=n(eA,"P",{});var lAt=s(sMe);CPr=r(lAt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),lAt.forEach(t),wPr=i(eA),rf=n(eA,"P",{});var Eee=s(rf);APr=r(Eee,`Note:
Loading a model from its configuration file does `),lMe=n(Eee,"STRONG",{});var iAt=s(lMe);yPr=r(iAt,"not"),iAt.forEach(t),LPr=r(Eee,` load the model weights. It only affects the
model\u2019s configuration. Use `),WY=n(Eee,"A",{href:!0});var dAt=s(WY);xPr=r(dAt,"from_pretrained()"),dAt.forEach(t),$Pr=r(Eee," to load the model weights."),Eee.forEach(t),kPr=i(eA),T(K5.$$.fragment,eA),eA.forEach(t),SPr=i(ri),Wr=n(ri,"DIV",{class:!0});var ti=s(Wr);T(Zx.$$.fragment,ti),RPr=i(ti),iMe=n(ti,"P",{});var cAt=s(iMe);PPr=r(cAt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),cAt.forEach(t),BPr=i(ti),Cn=n(ti,"P",{});var oA=s(Cn);IPr=r(oA,"The model class to instantiate is selected based on the "),dMe=n(oA,"CODE",{});var fAt=s(dMe);qPr=r(fAt,"model_type"),fAt.forEach(t),NPr=r(oA,` property of the config object (either
passed as an argument or loaded from `),cMe=n(oA,"CODE",{});var mAt=s(cMe);jPr=r(mAt,"pretrained_model_name_or_path"),mAt.forEach(t),DPr=r(oA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fMe=n(oA,"CODE",{});var gAt=s(fMe);GPr=r(gAt,"pretrained_model_name_or_path"),gAt.forEach(t),OPr=r(oA,":"),oA.forEach(t),VPr=i(ti),$e=n(ti,"UL",{});var Ie=s($e);Z5=n(Ie,"LI",{});var fIe=s(Z5);mMe=n(fIe,"STRONG",{});var hAt=s(mMe);XPr=r(hAt,"albert"),hAt.forEach(t),zPr=r(fIe," \u2014 "),HY=n(fIe,"A",{href:!0});var pAt=s(HY);QPr=r(pAt,"FlaxAlbertForQuestionAnswering"),pAt.forEach(t),WPr=r(fIe," (ALBERT model)"),fIe.forEach(t),HPr=i(Ie),eC=n(Ie,"LI",{});var mIe=s(eC);gMe=n(mIe,"STRONG",{});var uAt=s(gMe);UPr=r(uAt,"bart"),uAt.forEach(t),JPr=r(mIe," \u2014 "),UY=n(mIe,"A",{href:!0});var _At=s(UY);YPr=r(_At,"FlaxBartForQuestionAnswering"),_At.forEach(t),KPr=r(mIe," (BART model)"),mIe.forEach(t),ZPr=i(Ie),oC=n(Ie,"LI",{});var gIe=s(oC);hMe=n(gIe,"STRONG",{});var bAt=s(hMe);eBr=r(bAt,"bert"),bAt.forEach(t),oBr=r(gIe," \u2014 "),JY=n(gIe,"A",{href:!0});var vAt=s(JY);rBr=r(vAt,"FlaxBertForQuestionAnswering"),vAt.forEach(t),tBr=r(gIe," (BERT model)"),gIe.forEach(t),aBr=i(Ie),rC=n(Ie,"LI",{});var hIe=s(rC);pMe=n(hIe,"STRONG",{});var FAt=s(pMe);nBr=r(FAt,"big_bird"),FAt.forEach(t),sBr=r(hIe," \u2014 "),YY=n(hIe,"A",{href:!0});var TAt=s(YY);lBr=r(TAt,"FlaxBigBirdForQuestionAnswering"),TAt.forEach(t),iBr=r(hIe," (BigBird model)"),hIe.forEach(t),dBr=i(Ie),tC=n(Ie,"LI",{});var pIe=s(tC);uMe=n(pIe,"STRONG",{});var MAt=s(uMe);cBr=r(MAt,"distilbert"),MAt.forEach(t),fBr=r(pIe," \u2014 "),KY=n(pIe,"A",{href:!0});var EAt=s(KY);mBr=r(EAt,"FlaxDistilBertForQuestionAnswering"),EAt.forEach(t),gBr=r(pIe," (DistilBERT model)"),pIe.forEach(t),hBr=i(Ie),aC=n(Ie,"LI",{});var uIe=s(aC);_Me=n(uIe,"STRONG",{});var CAt=s(_Me);pBr=r(CAt,"electra"),CAt.forEach(t),uBr=r(uIe," \u2014 "),ZY=n(uIe,"A",{href:!0});var wAt=s(ZY);_Br=r(wAt,"FlaxElectraForQuestionAnswering"),wAt.forEach(t),bBr=r(uIe," (ELECTRA model)"),uIe.forEach(t),vBr=i(Ie),nC=n(Ie,"LI",{});var _Ie=s(nC);bMe=n(_Ie,"STRONG",{});var AAt=s(bMe);FBr=r(AAt,"mbart"),AAt.forEach(t),TBr=r(_Ie," \u2014 "),eK=n(_Ie,"A",{href:!0});var yAt=s(eK);MBr=r(yAt,"FlaxMBartForQuestionAnswering"),yAt.forEach(t),EBr=r(_Ie," (mBART model)"),_Ie.forEach(t),CBr=i(Ie),sC=n(Ie,"LI",{});var bIe=s(sC);vMe=n(bIe,"STRONG",{});var LAt=s(vMe);wBr=r(LAt,"roberta"),LAt.forEach(t),ABr=r(bIe," \u2014 "),oK=n(bIe,"A",{href:!0});var xAt=s(oK);yBr=r(xAt,"FlaxRobertaForQuestionAnswering"),xAt.forEach(t),LBr=r(bIe," (RoBERTa model)"),bIe.forEach(t),xBr=i(Ie),lC=n(Ie,"LI",{});var vIe=s(lC);FMe=n(vIe,"STRONG",{});var $At=s(FMe);$Br=r($At,"roformer"),$At.forEach(t),kBr=r(vIe," \u2014 "),rK=n(vIe,"A",{href:!0});var kAt=s(rK);SBr=r(kAt,"FlaxRoFormerForQuestionAnswering"),kAt.forEach(t),RBr=r(vIe," (RoFormer model)"),vIe.forEach(t),PBr=i(Ie),iC=n(Ie,"LI",{});var FIe=s(iC);TMe=n(FIe,"STRONG",{});var SAt=s(TMe);BBr=r(SAt,"xlm-roberta"),SAt.forEach(t),IBr=r(FIe," \u2014 "),tK=n(FIe,"A",{href:!0});var RAt=s(tK);qBr=r(RAt,"FlaxXLMRobertaForQuestionAnswering"),RAt.forEach(t),NBr=r(FIe," (XLM-RoBERTa model)"),FIe.forEach(t),Ie.forEach(t),jBr=i(ti),T(dC.$$.fragment,ti),ti.forEach(t),ri.forEach(t),INe=i(f),tf=n(f,"H2",{class:!0});var zDe=s(tf);cC=n(zDe,"A",{id:!0,class:!0,href:!0});var PAt=s(cC);MMe=n(PAt,"SPAN",{});var BAt=s(MMe);T(e9.$$.fragment,BAt),BAt.forEach(t),PAt.forEach(t),DBr=i(zDe),EMe=n(zDe,"SPAN",{});var IAt=s(EMe);GBr=r(IAt,"FlaxAutoModelForTokenClassification"),IAt.forEach(t),zDe.forEach(t),qNe=i(f),Fr=n(f,"DIV",{class:!0});var ai=s(Fr);T(o9.$$.fragment,ai),OBr=i(ai),af=n(ai,"P",{});var Cee=s(af);VBr=r(Cee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),aK=n(Cee,"A",{href:!0});var qAt=s(aK);XBr=r(qAt,"from_pretrained()"),qAt.forEach(t),zBr=r(Cee," class method or the "),nK=n(Cee,"A",{href:!0});var NAt=s(nK);QBr=r(NAt,"from_config()"),NAt.forEach(t),WBr=r(Cee,` class
method.`),Cee.forEach(t),HBr=i(ai),r9=n(ai,"P",{});var QDe=s(r9);UBr=r(QDe,"This class cannot be instantiated directly using "),CMe=n(QDe,"CODE",{});var jAt=s(CMe);JBr=r(jAt,"__init__()"),jAt.forEach(t),YBr=r(QDe," (throws an error)."),QDe.forEach(t),KBr=i(ai),Ut=n(ai,"DIV",{class:!0});var rA=s(Ut);T(t9.$$.fragment,rA),ZBr=i(rA),wMe=n(rA,"P",{});var DAt=s(wMe);eIr=r(DAt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),DAt.forEach(t),oIr=i(rA),nf=n(rA,"P",{});var wee=s(nf);rIr=r(wee,`Note:
Loading a model from its configuration file does `),AMe=n(wee,"STRONG",{});var GAt=s(AMe);tIr=r(GAt,"not"),GAt.forEach(t),aIr=r(wee,` load the model weights. It only affects the
model\u2019s configuration. Use `),sK=n(wee,"A",{href:!0});var OAt=s(sK);nIr=r(OAt,"from_pretrained()"),OAt.forEach(t),sIr=r(wee," to load the model weights."),wee.forEach(t),lIr=i(rA),T(fC.$$.fragment,rA),rA.forEach(t),iIr=i(ai),Hr=n(ai,"DIV",{class:!0});var ni=s(Hr);T(a9.$$.fragment,ni),dIr=i(ni),yMe=n(ni,"P",{});var VAt=s(yMe);cIr=r(VAt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),VAt.forEach(t),fIr=i(ni),wn=n(ni,"P",{});var tA=s(wn);mIr=r(tA,"The model class to instantiate is selected based on the "),LMe=n(tA,"CODE",{});var XAt=s(LMe);gIr=r(XAt,"model_type"),XAt.forEach(t),hIr=r(tA,` property of the config object (either
passed as an argument or loaded from `),xMe=n(tA,"CODE",{});var zAt=s(xMe);pIr=r(zAt,"pretrained_model_name_or_path"),zAt.forEach(t),uIr=r(tA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Me=n(tA,"CODE",{});var QAt=s($Me);_Ir=r(QAt,"pretrained_model_name_or_path"),QAt.forEach(t),bIr=r(tA,":"),tA.forEach(t),vIr=i(ni),De=n(ni,"UL",{});var To=s(De);mC=n(To,"LI",{});var TIe=s(mC);kMe=n(TIe,"STRONG",{});var WAt=s(kMe);FIr=r(WAt,"albert"),WAt.forEach(t),TIr=r(TIe," \u2014 "),lK=n(TIe,"A",{href:!0});var HAt=s(lK);MIr=r(HAt,"FlaxAlbertForTokenClassification"),HAt.forEach(t),EIr=r(TIe," (ALBERT model)"),TIe.forEach(t),CIr=i(To),gC=n(To,"LI",{});var MIe=s(gC);SMe=n(MIe,"STRONG",{});var UAt=s(SMe);wIr=r(UAt,"bert"),UAt.forEach(t),AIr=r(MIe," \u2014 "),iK=n(MIe,"A",{href:!0});var JAt=s(iK);yIr=r(JAt,"FlaxBertForTokenClassification"),JAt.forEach(t),LIr=r(MIe," (BERT model)"),MIe.forEach(t),xIr=i(To),hC=n(To,"LI",{});var EIe=s(hC);RMe=n(EIe,"STRONG",{});var YAt=s(RMe);$Ir=r(YAt,"big_bird"),YAt.forEach(t),kIr=r(EIe," \u2014 "),dK=n(EIe,"A",{href:!0});var KAt=s(dK);SIr=r(KAt,"FlaxBigBirdForTokenClassification"),KAt.forEach(t),RIr=r(EIe," (BigBird model)"),EIe.forEach(t),PIr=i(To),pC=n(To,"LI",{});var CIe=s(pC);PMe=n(CIe,"STRONG",{});var ZAt=s(PMe);BIr=r(ZAt,"distilbert"),ZAt.forEach(t),IIr=r(CIe," \u2014 "),cK=n(CIe,"A",{href:!0});var e0t=s(cK);qIr=r(e0t,"FlaxDistilBertForTokenClassification"),e0t.forEach(t),NIr=r(CIe," (DistilBERT model)"),CIe.forEach(t),jIr=i(To),uC=n(To,"LI",{});var wIe=s(uC);BMe=n(wIe,"STRONG",{});var o0t=s(BMe);DIr=r(o0t,"electra"),o0t.forEach(t),GIr=r(wIe," \u2014 "),fK=n(wIe,"A",{href:!0});var r0t=s(fK);OIr=r(r0t,"FlaxElectraForTokenClassification"),r0t.forEach(t),VIr=r(wIe," (ELECTRA model)"),wIe.forEach(t),XIr=i(To),_C=n(To,"LI",{});var AIe=s(_C);IMe=n(AIe,"STRONG",{});var t0t=s(IMe);zIr=r(t0t,"roberta"),t0t.forEach(t),QIr=r(AIe," \u2014 "),mK=n(AIe,"A",{href:!0});var a0t=s(mK);WIr=r(a0t,"FlaxRobertaForTokenClassification"),a0t.forEach(t),HIr=r(AIe," (RoBERTa model)"),AIe.forEach(t),UIr=i(To),bC=n(To,"LI",{});var yIe=s(bC);qMe=n(yIe,"STRONG",{});var n0t=s(qMe);JIr=r(n0t,"roformer"),n0t.forEach(t),YIr=r(yIe," \u2014 "),gK=n(yIe,"A",{href:!0});var s0t=s(gK);KIr=r(s0t,"FlaxRoFormerForTokenClassification"),s0t.forEach(t),ZIr=r(yIe," (RoFormer model)"),yIe.forEach(t),eqr=i(To),vC=n(To,"LI",{});var LIe=s(vC);NMe=n(LIe,"STRONG",{});var l0t=s(NMe);oqr=r(l0t,"xlm-roberta"),l0t.forEach(t),rqr=r(LIe," \u2014 "),hK=n(LIe,"A",{href:!0});var i0t=s(hK);tqr=r(i0t,"FlaxXLMRobertaForTokenClassification"),i0t.forEach(t),aqr=r(LIe," (XLM-RoBERTa model)"),LIe.forEach(t),To.forEach(t),nqr=i(ni),T(FC.$$.fragment,ni),ni.forEach(t),ai.forEach(t),NNe=i(f),sf=n(f,"H2",{class:!0});var WDe=s(sf);TC=n(WDe,"A",{id:!0,class:!0,href:!0});var d0t=s(TC);jMe=n(d0t,"SPAN",{});var c0t=s(jMe);T(n9.$$.fragment,c0t),c0t.forEach(t),d0t.forEach(t),sqr=i(WDe),DMe=n(WDe,"SPAN",{});var f0t=s(DMe);lqr=r(f0t,"FlaxAutoModelForMultipleChoice"),f0t.forEach(t),WDe.forEach(t),jNe=i(f),Tr=n(f,"DIV",{class:!0});var si=s(Tr);T(s9.$$.fragment,si),iqr=i(si),lf=n(si,"P",{});var Aee=s(lf);dqr=r(Aee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),pK=n(Aee,"A",{href:!0});var m0t=s(pK);cqr=r(m0t,"from_pretrained()"),m0t.forEach(t),fqr=r(Aee," class method or the "),uK=n(Aee,"A",{href:!0});var g0t=s(uK);mqr=r(g0t,"from_config()"),g0t.forEach(t),gqr=r(Aee,` class
method.`),Aee.forEach(t),hqr=i(si),l9=n(si,"P",{});var HDe=s(l9);pqr=r(HDe,"This class cannot be instantiated directly using "),GMe=n(HDe,"CODE",{});var h0t=s(GMe);uqr=r(h0t,"__init__()"),h0t.forEach(t),_qr=r(HDe," (throws an error)."),HDe.forEach(t),bqr=i(si),Jt=n(si,"DIV",{class:!0});var aA=s(Jt);T(i9.$$.fragment,aA),vqr=i(aA),OMe=n(aA,"P",{});var p0t=s(OMe);Fqr=r(p0t,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),p0t.forEach(t),Tqr=i(aA),df=n(aA,"P",{});var yee=s(df);Mqr=r(yee,`Note:
Loading a model from its configuration file does `),VMe=n(yee,"STRONG",{});var u0t=s(VMe);Eqr=r(u0t,"not"),u0t.forEach(t),Cqr=r(yee,` load the model weights. It only affects the
model\u2019s configuration. Use `),_K=n(yee,"A",{href:!0});var _0t=s(_K);wqr=r(_0t,"from_pretrained()"),_0t.forEach(t),Aqr=r(yee," to load the model weights."),yee.forEach(t),yqr=i(aA),T(MC.$$.fragment,aA),aA.forEach(t),Lqr=i(si),Ur=n(si,"DIV",{class:!0});var li=s(Ur);T(d9.$$.fragment,li),xqr=i(li),XMe=n(li,"P",{});var b0t=s(XMe);$qr=r(b0t,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),b0t.forEach(t),kqr=i(li),An=n(li,"P",{});var nA=s(An);Sqr=r(nA,"The model class to instantiate is selected based on the "),zMe=n(nA,"CODE",{});var v0t=s(zMe);Rqr=r(v0t,"model_type"),v0t.forEach(t),Pqr=r(nA,` property of the config object (either
passed as an argument or loaded from `),QMe=n(nA,"CODE",{});var F0t=s(QMe);Bqr=r(F0t,"pretrained_model_name_or_path"),F0t.forEach(t),Iqr=r(nA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WMe=n(nA,"CODE",{});var T0t=s(WMe);qqr=r(T0t,"pretrained_model_name_or_path"),T0t.forEach(t),Nqr=r(nA,":"),nA.forEach(t),jqr=i(li),Ge=n(li,"UL",{});var Mo=s(Ge);EC=n(Mo,"LI",{});var xIe=s(EC);HMe=n(xIe,"STRONG",{});var M0t=s(HMe);Dqr=r(M0t,"albert"),M0t.forEach(t),Gqr=r(xIe," \u2014 "),bK=n(xIe,"A",{href:!0});var E0t=s(bK);Oqr=r(E0t,"FlaxAlbertForMultipleChoice"),E0t.forEach(t),Vqr=r(xIe," (ALBERT model)"),xIe.forEach(t),Xqr=i(Mo),CC=n(Mo,"LI",{});var $Ie=s(CC);UMe=n($Ie,"STRONG",{});var C0t=s(UMe);zqr=r(C0t,"bert"),C0t.forEach(t),Qqr=r($Ie," \u2014 "),vK=n($Ie,"A",{href:!0});var w0t=s(vK);Wqr=r(w0t,"FlaxBertForMultipleChoice"),w0t.forEach(t),Hqr=r($Ie," (BERT model)"),$Ie.forEach(t),Uqr=i(Mo),wC=n(Mo,"LI",{});var kIe=s(wC);JMe=n(kIe,"STRONG",{});var A0t=s(JMe);Jqr=r(A0t,"big_bird"),A0t.forEach(t),Yqr=r(kIe," \u2014 "),FK=n(kIe,"A",{href:!0});var y0t=s(FK);Kqr=r(y0t,"FlaxBigBirdForMultipleChoice"),y0t.forEach(t),Zqr=r(kIe," (BigBird model)"),kIe.forEach(t),eNr=i(Mo),AC=n(Mo,"LI",{});var SIe=s(AC);YMe=n(SIe,"STRONG",{});var L0t=s(YMe);oNr=r(L0t,"distilbert"),L0t.forEach(t),rNr=r(SIe," \u2014 "),TK=n(SIe,"A",{href:!0});var x0t=s(TK);tNr=r(x0t,"FlaxDistilBertForMultipleChoice"),x0t.forEach(t),aNr=r(SIe," (DistilBERT model)"),SIe.forEach(t),nNr=i(Mo),yC=n(Mo,"LI",{});var RIe=s(yC);KMe=n(RIe,"STRONG",{});var $0t=s(KMe);sNr=r($0t,"electra"),$0t.forEach(t),lNr=r(RIe," \u2014 "),MK=n(RIe,"A",{href:!0});var k0t=s(MK);iNr=r(k0t,"FlaxElectraForMultipleChoice"),k0t.forEach(t),dNr=r(RIe," (ELECTRA model)"),RIe.forEach(t),cNr=i(Mo),LC=n(Mo,"LI",{});var PIe=s(LC);ZMe=n(PIe,"STRONG",{});var S0t=s(ZMe);fNr=r(S0t,"roberta"),S0t.forEach(t),mNr=r(PIe," \u2014 "),EK=n(PIe,"A",{href:!0});var R0t=s(EK);gNr=r(R0t,"FlaxRobertaForMultipleChoice"),R0t.forEach(t),hNr=r(PIe," (RoBERTa model)"),PIe.forEach(t),pNr=i(Mo),xC=n(Mo,"LI",{});var BIe=s(xC);e4e=n(BIe,"STRONG",{});var P0t=s(e4e);uNr=r(P0t,"roformer"),P0t.forEach(t),_Nr=r(BIe," \u2014 "),CK=n(BIe,"A",{href:!0});var B0t=s(CK);bNr=r(B0t,"FlaxRoFormerForMultipleChoice"),B0t.forEach(t),vNr=r(BIe," (RoFormer model)"),BIe.forEach(t),FNr=i(Mo),$C=n(Mo,"LI",{});var IIe=s($C);o4e=n(IIe,"STRONG",{});var I0t=s(o4e);TNr=r(I0t,"xlm-roberta"),I0t.forEach(t),MNr=r(IIe," \u2014 "),wK=n(IIe,"A",{href:!0});var q0t=s(wK);ENr=r(q0t,"FlaxXLMRobertaForMultipleChoice"),q0t.forEach(t),CNr=r(IIe," (XLM-RoBERTa model)"),IIe.forEach(t),Mo.forEach(t),wNr=i(li),T(kC.$$.fragment,li),li.forEach(t),si.forEach(t),DNe=i(f),cf=n(f,"H2",{class:!0});var UDe=s(cf);SC=n(UDe,"A",{id:!0,class:!0,href:!0});var N0t=s(SC);r4e=n(N0t,"SPAN",{});var j0t=s(r4e);T(c9.$$.fragment,j0t),j0t.forEach(t),N0t.forEach(t),ANr=i(UDe),t4e=n(UDe,"SPAN",{});var D0t=s(t4e);yNr=r(D0t,"FlaxAutoModelForNextSentencePrediction"),D0t.forEach(t),UDe.forEach(t),GNe=i(f),Mr=n(f,"DIV",{class:!0});var ii=s(Mr);T(f9.$$.fragment,ii),LNr=i(ii),ff=n(ii,"P",{});var Lee=s(ff);xNr=r(Lee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),AK=n(Lee,"A",{href:!0});var G0t=s(AK);$Nr=r(G0t,"from_pretrained()"),G0t.forEach(t),kNr=r(Lee," class method or the "),yK=n(Lee,"A",{href:!0});var O0t=s(yK);SNr=r(O0t,"from_config()"),O0t.forEach(t),RNr=r(Lee,` class
method.`),Lee.forEach(t),PNr=i(ii),m9=n(ii,"P",{});var JDe=s(m9);BNr=r(JDe,"This class cannot be instantiated directly using "),a4e=n(JDe,"CODE",{});var V0t=s(a4e);INr=r(V0t,"__init__()"),V0t.forEach(t),qNr=r(JDe," (throws an error)."),JDe.forEach(t),NNr=i(ii),Yt=n(ii,"DIV",{class:!0});var sA=s(Yt);T(g9.$$.fragment,sA),jNr=i(sA),n4e=n(sA,"P",{});var X0t=s(n4e);DNr=r(X0t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),X0t.forEach(t),GNr=i(sA),mf=n(sA,"P",{});var xee=s(mf);ONr=r(xee,`Note:
Loading a model from its configuration file does `),s4e=n(xee,"STRONG",{});var z0t=s(s4e);VNr=r(z0t,"not"),z0t.forEach(t),XNr=r(xee,` load the model weights. It only affects the
model\u2019s configuration. Use `),LK=n(xee,"A",{href:!0});var Q0t=s(LK);zNr=r(Q0t,"from_pretrained()"),Q0t.forEach(t),QNr=r(xee," to load the model weights."),xee.forEach(t),WNr=i(sA),T(RC.$$.fragment,sA),sA.forEach(t),HNr=i(ii),Jr=n(ii,"DIV",{class:!0});var di=s(Jr);T(h9.$$.fragment,di),UNr=i(di),l4e=n(di,"P",{});var W0t=s(l4e);JNr=r(W0t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),W0t.forEach(t),YNr=i(di),yn=n(di,"P",{});var lA=s(yn);KNr=r(lA,"The model class to instantiate is selected based on the "),i4e=n(lA,"CODE",{});var H0t=s(i4e);ZNr=r(H0t,"model_type"),H0t.forEach(t),ejr=r(lA,` property of the config object (either
passed as an argument or loaded from `),d4e=n(lA,"CODE",{});var U0t=s(d4e);ojr=r(U0t,"pretrained_model_name_or_path"),U0t.forEach(t),rjr=r(lA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c4e=n(lA,"CODE",{});var J0t=s(c4e);tjr=r(J0t,"pretrained_model_name_or_path"),J0t.forEach(t),ajr=r(lA,":"),lA.forEach(t),njr=i(di),f4e=n(di,"UL",{});var Y0t=s(f4e);PC=n(Y0t,"LI",{});var qIe=s(PC);m4e=n(qIe,"STRONG",{});var K0t=s(m4e);sjr=r(K0t,"bert"),K0t.forEach(t),ljr=r(qIe," \u2014 "),xK=n(qIe,"A",{href:!0});var Z0t=s(xK);ijr=r(Z0t,"FlaxBertForNextSentencePrediction"),Z0t.forEach(t),djr=r(qIe," (BERT model)"),qIe.forEach(t),Y0t.forEach(t),cjr=i(di),T(BC.$$.fragment,di),di.forEach(t),ii.forEach(t),ONe=i(f),gf=n(f,"H2",{class:!0});var YDe=s(gf);IC=n(YDe,"A",{id:!0,class:!0,href:!0});var eyt=s(IC);g4e=n(eyt,"SPAN",{});var oyt=s(g4e);T(p9.$$.fragment,oyt),oyt.forEach(t),eyt.forEach(t),fjr=i(YDe),h4e=n(YDe,"SPAN",{});var ryt=s(h4e);mjr=r(ryt,"FlaxAutoModelForImageClassification"),ryt.forEach(t),YDe.forEach(t),VNe=i(f),Er=n(f,"DIV",{class:!0});var ci=s(Er);T(u9.$$.fragment,ci),gjr=i(ci),hf=n(ci,"P",{});var $ee=s(hf);hjr=r($ee,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),$K=n($ee,"A",{href:!0});var tyt=s($K);pjr=r(tyt,"from_pretrained()"),tyt.forEach(t),ujr=r($ee," class method or the "),kK=n($ee,"A",{href:!0});var ayt=s(kK);_jr=r(ayt,"from_config()"),ayt.forEach(t),bjr=r($ee,` class
method.`),$ee.forEach(t),vjr=i(ci),_9=n(ci,"P",{});var KDe=s(_9);Fjr=r(KDe,"This class cannot be instantiated directly using "),p4e=n(KDe,"CODE",{});var nyt=s(p4e);Tjr=r(nyt,"__init__()"),nyt.forEach(t),Mjr=r(KDe," (throws an error)."),KDe.forEach(t),Ejr=i(ci),Kt=n(ci,"DIV",{class:!0});var iA=s(Kt);T(b9.$$.fragment,iA),Cjr=i(iA),u4e=n(iA,"P",{});var syt=s(u4e);wjr=r(syt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),syt.forEach(t),Ajr=i(iA),pf=n(iA,"P",{});var kee=s(pf);yjr=r(kee,`Note:
Loading a model from its configuration file does `),_4e=n(kee,"STRONG",{});var lyt=s(_4e);Ljr=r(lyt,"not"),lyt.forEach(t),xjr=r(kee,` load the model weights. It only affects the
model\u2019s configuration. Use `),SK=n(kee,"A",{href:!0});var iyt=s(SK);$jr=r(iyt,"from_pretrained()"),iyt.forEach(t),kjr=r(kee," to load the model weights."),kee.forEach(t),Sjr=i(iA),T(qC.$$.fragment,iA),iA.forEach(t),Rjr=i(ci),Yr=n(ci,"DIV",{class:!0});var fi=s(Yr);T(v9.$$.fragment,fi),Pjr=i(fi),b4e=n(fi,"P",{});var dyt=s(b4e);Bjr=r(dyt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),dyt.forEach(t),Ijr=i(fi),Ln=n(fi,"P",{});var dA=s(Ln);qjr=r(dA,"The model class to instantiate is selected based on the "),v4e=n(dA,"CODE",{});var cyt=s(v4e);Njr=r(cyt,"model_type"),cyt.forEach(t),jjr=r(dA,` property of the config object (either
passed as an argument or loaded from `),F4e=n(dA,"CODE",{});var fyt=s(F4e);Djr=r(fyt,"pretrained_model_name_or_path"),fyt.forEach(t),Gjr=r(dA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T4e=n(dA,"CODE",{});var myt=s(T4e);Ojr=r(myt,"pretrained_model_name_or_path"),myt.forEach(t),Vjr=r(dA,":"),dA.forEach(t),Xjr=i(fi),F9=n(fi,"UL",{});var ZDe=s(F9);NC=n(ZDe,"LI",{});var NIe=s(NC);M4e=n(NIe,"STRONG",{});var gyt=s(M4e);zjr=r(gyt,"beit"),gyt.forEach(t),Qjr=r(NIe," \u2014 "),RK=n(NIe,"A",{href:!0});var hyt=s(RK);Wjr=r(hyt,"FlaxBeitForImageClassification"),hyt.forEach(t),Hjr=r(NIe," (BEiT model)"),NIe.forEach(t),Ujr=i(ZDe),jC=n(ZDe,"LI",{});var jIe=s(jC);E4e=n(jIe,"STRONG",{});var pyt=s(E4e);Jjr=r(pyt,"vit"),pyt.forEach(t),Yjr=r(jIe," \u2014 "),PK=n(jIe,"A",{href:!0});var uyt=s(PK);Kjr=r(uyt,"FlaxViTForImageClassification"),uyt.forEach(t),Zjr=r(jIe," (ViT model)"),jIe.forEach(t),ZDe.forEach(t),eDr=i(fi),T(DC.$$.fragment,fi),fi.forEach(t),ci.forEach(t),XNe=i(f),uf=n(f,"H2",{class:!0});var eGe=s(uf);GC=n(eGe,"A",{id:!0,class:!0,href:!0});var _yt=s(GC);C4e=n(_yt,"SPAN",{});var byt=s(C4e);T(T9.$$.fragment,byt),byt.forEach(t),_yt.forEach(t),oDr=i(eGe),w4e=n(eGe,"SPAN",{});var vyt=s(w4e);rDr=r(vyt,"FlaxAutoModelForVision2Seq"),vyt.forEach(t),eGe.forEach(t),zNe=i(f),Cr=n(f,"DIV",{class:!0});var mi=s(Cr);T(M9.$$.fragment,mi),tDr=i(mi),_f=n(mi,"P",{});var See=s(_f);aDr=r(See,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),BK=n(See,"A",{href:!0});var Fyt=s(BK);nDr=r(Fyt,"from_pretrained()"),Fyt.forEach(t),sDr=r(See," class method or the "),IK=n(See,"A",{href:!0});var Tyt=s(IK);lDr=r(Tyt,"from_config()"),Tyt.forEach(t),iDr=r(See,` class
method.`),See.forEach(t),dDr=i(mi),E9=n(mi,"P",{});var oGe=s(E9);cDr=r(oGe,"This class cannot be instantiated directly using "),A4e=n(oGe,"CODE",{});var Myt=s(A4e);fDr=r(Myt,"__init__()"),Myt.forEach(t),mDr=r(oGe," (throws an error)."),oGe.forEach(t),gDr=i(mi),Zt=n(mi,"DIV",{class:!0});var cA=s(Zt);T(C9.$$.fragment,cA),hDr=i(cA),y4e=n(cA,"P",{});var Eyt=s(y4e);pDr=r(Eyt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Eyt.forEach(t),uDr=i(cA),bf=n(cA,"P",{});var Ree=s(bf);_Dr=r(Ree,`Note:
Loading a model from its configuration file does `),L4e=n(Ree,"STRONG",{});var Cyt=s(L4e);bDr=r(Cyt,"not"),Cyt.forEach(t),vDr=r(Ree,` load the model weights. It only affects the
model\u2019s configuration. Use `),qK=n(Ree,"A",{href:!0});var wyt=s(qK);FDr=r(wyt,"from_pretrained()"),wyt.forEach(t),TDr=r(Ree," to load the model weights."),Ree.forEach(t),MDr=i(cA),T(OC.$$.fragment,cA),cA.forEach(t),EDr=i(mi),Kr=n(mi,"DIV",{class:!0});var gi=s(Kr);T(w9.$$.fragment,gi),CDr=i(gi),x4e=n(gi,"P",{});var Ayt=s(x4e);wDr=r(Ayt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Ayt.forEach(t),ADr=i(gi),xn=n(gi,"P",{});var fA=s(xn);yDr=r(fA,"The model class to instantiate is selected based on the "),$4e=n(fA,"CODE",{});var yyt=s($4e);LDr=r(yyt,"model_type"),yyt.forEach(t),xDr=r(fA,` property of the config object (either
passed as an argument or loaded from `),k4e=n(fA,"CODE",{});var Lyt=s(k4e);$Dr=r(Lyt,"pretrained_model_name_or_path"),Lyt.forEach(t),kDr=r(fA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S4e=n(fA,"CODE",{});var xyt=s(S4e);SDr=r(xyt,"pretrained_model_name_or_path"),xyt.forEach(t),RDr=r(fA,":"),fA.forEach(t),PDr=i(gi),R4e=n(gi,"UL",{});var $yt=s(R4e);VC=n($yt,"LI",{});var DIe=s(VC);P4e=n(DIe,"STRONG",{});var kyt=s(P4e);BDr=r(kyt,"vision-encoder-decoder"),kyt.forEach(t),IDr=r(DIe," \u2014 "),NK=n(DIe,"A",{href:!0});var Syt=s(NK);qDr=r(Syt,"FlaxVisionEncoderDecoderModel"),Syt.forEach(t),NDr=r(DIe," (Vision Encoder decoder model)"),DIe.forEach(t),$yt.forEach(t),jDr=i(gi),T(XC.$$.fragment,gi),gi.forEach(t),mi.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(Nxt)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(kn,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.AutoConfig"),c(Rn,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.AutoModel"),c(Pn,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.AutoTokenizer"),c(Fi,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertModel"),c(Af,"id","extending-the-auto-classes"),c(Af,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Af,"href","#extending-the-auto-classes"),c(Ti,"class","relative group"),c(Lf,"id","transformers.AutoConfig"),c(Lf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Lf,"href","#transformers.AutoConfig"),c(Mi,"class","relative group"),c(z$,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(Q$,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertConfig"),c(W$,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartConfig"),c(H$,"href","/docs/transformers/pr_17286/en/model_doc/beit#transformers.BeitConfig"),c(U$,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertConfig"),c(J$,"href","/docs/transformers/pr_17286/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(Y$,"href","/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdConfig"),c(K$,"href","/docs/transformers/pr_17286/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(Z$,"href","/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(ek,"href","/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(ok,"href","/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertConfig"),c(rk,"href","/docs/transformers/pr_17286/en/model_doc/canine#transformers.CanineConfig"),c(tk,"href","/docs/transformers/pr_17286/en/model_doc/clip#transformers.CLIPConfig"),c(ak,"href","/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertConfig"),c(nk,"href","/docs/transformers/pr_17286/en/model_doc/convnext#transformers.ConvNextConfig"),c(sk,"href","/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.CTRLConfig"),c(lk,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(ik,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(dk,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(ck,"href","/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaConfig"),c(fk,"href","/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(mk,"href","/docs/transformers/pr_17286/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(gk,"href","/docs/transformers/pr_17286/en/model_doc/deit#transformers.DeiTConfig"),c(hk,"href","/docs/transformers/pr_17286/en/model_doc/detr#transformers.DetrConfig"),c(pk,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertConfig"),c(uk,"href","/docs/transformers/pr_17286/en/model_doc/dpr#transformers.DPRConfig"),c(_k,"href","/docs/transformers/pr_17286/en/model_doc/dpt#transformers.DPTConfig"),c(bk,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraConfig"),c(vk,"href","/docs/transformers/pr_17286/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(Fk,"href","/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertConfig"),c(Tk,"href","/docs/transformers/pr_17286/en/model_doc/flava#transformers.FlavaConfig"),c(Mk,"href","/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetConfig"),c(Ek,"href","/docs/transformers/pr_17286/en/model_doc/fsmt#transformers.FSMTConfig"),c(Ck,"href","/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelConfig"),c(wk,"href","/docs/transformers/pr_17286/en/model_doc/glpn#transformers.GLPNConfig"),c(Ak,"href","/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2Config"),c(yk,"href","/docs/transformers/pr_17286/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(Lk,"href","/docs/transformers/pr_17286/en/model_doc/gptj#transformers.GPTJConfig"),c(xk,"href","/docs/transformers/pr_17286/en/model_doc/hubert#transformers.HubertConfig"),c($k,"href","/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertConfig"),c(kk,"href","/docs/transformers/pr_17286/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(Sk,"href","/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(Rk,"href","/docs/transformers/pr_17286/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(Pk,"href","/docs/transformers/pr_17286/en/model_doc/led#transformers.LEDConfig"),c(Bk,"href","/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerConfig"),c(Ik,"href","/docs/transformers/pr_17286/en/model_doc/luke#transformers.LukeConfig"),c(qk,"href","/docs/transformers/pr_17286/en/model_doc/lxmert#transformers.LxmertConfig"),c(Nk,"href","/docs/transformers/pr_17286/en/model_doc/m2m_100#transformers.M2M100Config"),c(jk,"href","/docs/transformers/pr_17286/en/model_doc/marian#transformers.MarianConfig"),c(Dk,"href","/docs/transformers/pr_17286/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(Gk,"href","/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartConfig"),c(Ok,"href","/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(Vk,"href","/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(Xk,"href","/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetConfig"),c(zk,"href","/docs/transformers/pr_17286/en/model_doc/mt5#transformers.MT5Config"),c(Qk,"href","/docs/transformers/pr_17286/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(Wk,"href","/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(Hk,"href","/docs/transformers/pr_17286/en/model_doc/opt#transformers.OPTConfig"),c(Uk,"href","/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.PegasusConfig"),c(Jk,"href","/docs/transformers/pr_17286/en/model_doc/perceiver#transformers.PerceiverConfig"),c(Yk,"href","/docs/transformers/pr_17286/en/model_doc/plbart#transformers.PLBartConfig"),c(Kk,"href","/docs/transformers/pr_17286/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(Zk,"href","/docs/transformers/pr_17286/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(eS,"href","/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(oS,"href","/docs/transformers/pr_17286/en/model_doc/rag#transformers.RagConfig"),c(rS,"href","/docs/transformers/pr_17286/en/model_doc/realm#transformers.RealmConfig"),c(tS,"href","/docs/transformers/pr_17286/en/model_doc/reformer#transformers.ReformerConfig"),c(aS,"href","/docs/transformers/pr_17286/en/model_doc/regnet#transformers.RegNetConfig"),c(nS,"href","/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertConfig"),c(sS,"href","/docs/transformers/pr_17286/en/model_doc/resnet#transformers.ResNetConfig"),c(lS,"href","/docs/transformers/pr_17286/en/model_doc/retribert#transformers.RetriBertConfig"),c(iS,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaConfig"),c(dS,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerConfig"),c(cS,"href","/docs/transformers/pr_17286/en/model_doc/segformer#transformers.SegformerConfig"),c(fS,"href","/docs/transformers/pr_17286/en/model_doc/sew#transformers.SEWConfig"),c(mS,"href","/docs/transformers/pr_17286/en/model_doc/sew-d#transformers.SEWDConfig"),c(gS,"href","/docs/transformers/pr_17286/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(hS,"href","/docs/transformers/pr_17286/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(pS,"href","/docs/transformers/pr_17286/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(uS,"href","/docs/transformers/pr_17286/en/model_doc/splinter#transformers.SplinterConfig"),c(_S,"href","/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(bS,"href","/docs/transformers/pr_17286/en/model_doc/swin#transformers.SwinConfig"),c(vS,"href","/docs/transformers/pr_17286/en/model_doc/t5#transformers.T5Config"),c(FS,"href","/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasConfig"),c(TS,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartConfig"),c(MS,"href","/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(ES,"href","/docs/transformers/pr_17286/en/model_doc/trocr#transformers.TrOCRConfig"),c(CS,"href","/docs/transformers/pr_17286/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(wS,"href","/docs/transformers/pr_17286/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(AS,"href","/docs/transformers/pr_17286/en/model_doc/van#transformers.VanConfig"),c(yS,"href","/docs/transformers/pr_17286/en/model_doc/vilt#transformers.ViltConfig"),c(LS,"href","/docs/transformers/pr_17286/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(xS,"href","/docs/transformers/pr_17286/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c($S,"href","/docs/transformers/pr_17286/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(kS,"href","/docs/transformers/pr_17286/en/model_doc/vit#transformers.ViTConfig"),c(SS,"href","/docs/transformers/pr_17286/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(RS,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(PS,"href","/docs/transformers/pr_17286/en/model_doc/wavlm#transformers.WavLMConfig"),c(BS,"href","/docs/transformers/pr_17286/en/model_doc/xglm#transformers.XGLMConfig"),c(IS,"href","/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMConfig"),c(qS,"href","/docs/transformers/pr_17286/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(NS,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(jS,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(DS,"href","/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetConfig"),c(GS,"href","/docs/transformers/pr_17286/en/model_doc/yolos#transformers.YolosConfig"),c(OS,"href","/docs/transformers/pr_17286/en/model_doc/yoso#transformers.YosoConfig"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yg,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lg,"id","transformers.AutoTokenizer"),c(Lg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Lg,"href","#transformers.AutoTokenizer"),c(Ci,"class","relative group"),c(VS,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(XS,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertTokenizer"),c(zS,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(QS,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartTokenizer"),c(WS,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartTokenizerFast"),c(HS,"href","/docs/transformers/pr_17286/en/model_doc/barthez#transformers.BarthezTokenizer"),c(US,"href","/docs/transformers/pr_17286/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(JS,"href","/docs/transformers/pr_17286/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(YS,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertTokenizer"),c(KS,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertTokenizerFast"),c(ZS,"href","/docs/transformers/pr_17286/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(eR,"href","/docs/transformers/pr_17286/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(oR,"href","/docs/transformers/pr_17286/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(rR,"href","/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(tR,"href","/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(aR,"href","/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(nR,"href","/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(sR,"href","/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(lR,"href","/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(iR,"href","/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(dR,"href","/docs/transformers/pr_17286/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(cR,"href","/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertTokenizer"),c(fR,"href","/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(mR,"href","/docs/transformers/pr_17286/en/model_doc/canine#transformers.CanineTokenizer"),c(gR,"href","/docs/transformers/pr_17286/en/model_doc/clip#transformers.CLIPTokenizer"),c(hR,"href","/docs/transformers/pr_17286/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(pR,"href","/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(uR,"href","/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(_R,"href","/docs/transformers/pr_17286/en/model_doc/cpm#transformers.CpmTokenizer"),c(bR,"href","/docs/transformers/pr_17286/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(vR,"href","/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(FR,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaTokenizer"),c(TR,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(MR,"href","/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaTokenizer"),c(ER,"href","/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(CR,"href","/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(wR,"href","/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(AR,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(yR,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(LR,"href","/docs/transformers/pr_17286/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(xR,"href","/docs/transformers/pr_17286/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c($R,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraTokenizer"),c(kR,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(SR,"href","/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(RR,"href","/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetTokenizer"),c(PR,"href","/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(BR,"href","/docs/transformers/pr_17286/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(IR,"href","/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelTokenizer"),c(qR,"href","/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(NR,"href","/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(jR,"href","/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(DR,"href","/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(GR,"href","/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(OR,"href","/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(VR,"href","/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(XR,"href","/docs/transformers/pr_17286/en/model_doc/herbert#transformers.HerbertTokenizer"),c(zR,"href","/docs/transformers/pr_17286/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(QR,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(WR,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaTokenizer"),c(HR,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(UR,"href","/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(JR,"href","/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(YR,"href","/docs/transformers/pr_17286/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(KR,"href","/docs/transformers/pr_17286/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(ZR,"href","/docs/transformers/pr_17286/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(eP,"href","/docs/transformers/pr_17286/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(oP,"href","/docs/transformers/pr_17286/en/model_doc/led#transformers.LEDTokenizer"),c(rP,"href","/docs/transformers/pr_17286/en/model_doc/led#transformers.LEDTokenizerFast"),c(tP,"href","/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerTokenizer"),c(aP,"href","/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(nP,"href","/docs/transformers/pr_17286/en/model_doc/luke#transformers.LukeTokenizer"),c(sP,"href","/docs/transformers/pr_17286/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(lP,"href","/docs/transformers/pr_17286/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(iP,"href","/docs/transformers/pr_17286/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(dP,"href","/docs/transformers/pr_17286/en/model_doc/marian#transformers.MarianTokenizer"),c(cP,"href","/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartTokenizer"),c(fP,"href","/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(mP,"href","/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(gP,"href","/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(hP,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertTokenizer"),c(pP,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertTokenizerFast"),c(uP,"href","/docs/transformers/pr_17286/en/model_doc/mluke#transformers.MLukeTokenizer"),c(_P,"href","/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(bP,"href","/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(vP,"href","/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(FP,"href","/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(TP,"href","/docs/transformers/pr_17286/en/model_doc/mt5#transformers.T5Tokenizer"),c(MP,"href","/docs/transformers/pr_17286/en/model_doc/mt5#transformers.T5TokenizerFast"),c(EP,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertTokenizer"),c(CP,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(wP,"href","/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(AP,"href","/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(yP,"href","/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(LP,"href","/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(xP,"href","/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c($P,"href","/docs/transformers/pr_17286/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(kP,"href","/docs/transformers/pr_17286/en/model_doc/phobert#transformers.PhobertTokenizer"),c(SP,"href","/docs/transformers/pr_17286/en/model_doc/plbart#transformers.PLBartTokenizer"),c(RP,"href","/docs/transformers/pr_17286/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(PP,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertTokenizer"),c(BP,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertTokenizerFast"),c(IP,"href","/docs/transformers/pr_17286/en/model_doc/rag#transformers.RagTokenizer"),c(qP,"href","/docs/transformers/pr_17286/en/model_doc/realm#transformers.RealmTokenizer"),c(NP,"href","/docs/transformers/pr_17286/en/model_doc/realm#transformers.RealmTokenizerFast"),c(jP,"href","/docs/transformers/pr_17286/en/model_doc/reformer#transformers.ReformerTokenizer"),c(DP,"href","/docs/transformers/pr_17286/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(GP,"href","/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertTokenizer"),c(OP,"href","/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(VP,"href","/docs/transformers/pr_17286/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(XP,"href","/docs/transformers/pr_17286/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(zP,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaTokenizer"),c(QP,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(WP,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(HP,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(UP,"href","/docs/transformers/pr_17286/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(JP,"href","/docs/transformers/pr_17286/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(YP,"href","/docs/transformers/pr_17286/en/model_doc/splinter#transformers.SplinterTokenizer"),c(KP,"href","/docs/transformers/pr_17286/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(ZP,"href","/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(eB,"href","/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(oB,"href","/docs/transformers/pr_17286/en/model_doc/mt5#transformers.T5Tokenizer"),c(rB,"href","/docs/transformers/pr_17286/en/model_doc/mt5#transformers.T5TokenizerFast"),c(tB,"href","/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasTokenizer"),c(aB,"href","/docs/transformers/pr_17286/en/model_doc/tapex#transformers.TapexTokenizer"),c(nB,"href","/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(sB,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertTokenizer"),c(lB,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertTokenizerFast"),c(iB,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertTokenizer"),c(dB,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertTokenizerFast"),c(cB,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(fB,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(mB,"href","/docs/transformers/pr_17286/en/model_doc/xglm#transformers.XGLMTokenizer"),c(gB,"href","/docs/transformers/pr_17286/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(hB,"href","/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMTokenizer"),c(pB,"href","/docs/transformers/pr_17286/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(uB,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(_B,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(bB,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaTokenizer"),c(vB,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(FB,"href","/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(TB,"href","/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(MB,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertTokenizer"),c(EB,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lh,"id","transformers.AutoFeatureExtractor"),c(lh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lh,"href","#transformers.AutoFeatureExtractor"),c(wi,"class","relative group"),c(CB,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(wB,"href","/docs/transformers/pr_17286/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(AB,"href","/docs/transformers/pr_17286/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(yB,"href","/docs/transformers/pr_17286/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(LB,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(xB,"href","/docs/transformers/pr_17286/en/model_doc/beit#transformers.BeitFeatureExtractor"),c($B,"href","/docs/transformers/pr_17286/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(kB,"href","/docs/transformers/pr_17286/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(SB,"href","/docs/transformers/pr_17286/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(RB,"href","/docs/transformers/pr_17286/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(PB,"href","/docs/transformers/pr_17286/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(BB,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(IB,"href","/docs/transformers/pr_17286/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(qB,"href","/docs/transformers/pr_17286/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(NB,"href","/docs/transformers/pr_17286/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(jB,"href","/docs/transformers/pr_17286/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(DB,"href","/docs/transformers/pr_17286/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(GB,"href","/docs/transformers/pr_17286/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(OB,"href","/docs/transformers/pr_17286/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(VB,"href","/docs/transformers/pr_17286/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(XB,"href","/docs/transformers/pr_17286/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(zB,"href","/docs/transformers/pr_17286/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(QB,"href","/docs/transformers/pr_17286/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(WB,"href","/docs/transformers/pr_17286/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(HB,"href","/docs/transformers/pr_17286/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(UB,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(JB,"href","/docs/transformers/pr_17286/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(Qe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ih,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qh,"id","transformers.AutoProcessor"),c(qh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qh,"href","#transformers.AutoProcessor"),c(Ai,"class","relative group"),c(YB,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(KB,"href","/docs/transformers/pr_17286/en/model_doc/clip#transformers.CLIPProcessor"),c(ZB,"href","/docs/transformers/pr_17286/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(eI,"href","/docs/transformers/pr_17286/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(oI,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(rI,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(tI,"href","/docs/transformers/pr_17286/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(aI,"href","/docs/transformers/pr_17286/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(nI,"href","/docs/transformers/pr_17286/en/model_doc/trocr#transformers.TrOCRProcessor"),c(sI,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(lI,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(iI,"href","/docs/transformers/pr_17286/en/model_doc/vilt#transformers.ViltProcessor"),c(dI,"href","/docs/transformers/pr_17286/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(cI,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(fI,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(We,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(op,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rp,"id","transformers.AutoModel"),c(rp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(rp,"href","#transformers.AutoModel"),c(Li,"class","relative group"),c(mI,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gI,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hI,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pI,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertModel"),c(uI,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartModel"),c(_I,"href","/docs/transformers/pr_17286/en/model_doc/beit#transformers.BeitModel"),c(bI,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertModel"),c(vI,"href","/docs/transformers/pr_17286/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(FI,"href","/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdModel"),c(TI,"href","/docs/transformers/pr_17286/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(MI,"href","/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(EI,"href","/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(CI,"href","/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertModel"),c(wI,"href","/docs/transformers/pr_17286/en/model_doc/canine#transformers.CanineModel"),c(AI,"href","/docs/transformers/pr_17286/en/model_doc/clip#transformers.CLIPModel"),c(yI,"href","/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertModel"),c(LI,"href","/docs/transformers/pr_17286/en/model_doc/convnext#transformers.ConvNextModel"),c(xI,"href","/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.CTRLModel"),c($I,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(kI,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(SI,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(RI,"href","/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaModel"),c(PI,"href","/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(BI,"href","/docs/transformers/pr_17286/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(II,"href","/docs/transformers/pr_17286/en/model_doc/deit#transformers.DeiTModel"),c(qI,"href","/docs/transformers/pr_17286/en/model_doc/detr#transformers.DetrModel"),c(NI,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertModel"),c(jI,"href","/docs/transformers/pr_17286/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(DI,"href","/docs/transformers/pr_17286/en/model_doc/dpt#transformers.DPTModel"),c(GI,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraModel"),c(OI,"href","/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertModel"),c(VI,"href","/docs/transformers/pr_17286/en/model_doc/flava#transformers.FlavaModel"),c(XI,"href","/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetModel"),c(zI,"href","/docs/transformers/pr_17286/en/model_doc/fsmt#transformers.FSMTModel"),c(QI,"href","/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelModel"),c(WI,"href","/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelBaseModel"),c(HI,"href","/docs/transformers/pr_17286/en/model_doc/glpn#transformers.GLPNModel"),c(UI,"href","/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2Model"),c(JI,"href","/docs/transformers/pr_17286/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(YI,"href","/docs/transformers/pr_17286/en/model_doc/gptj#transformers.GPTJModel"),c(KI,"href","/docs/transformers/pr_17286/en/model_doc/hubert#transformers.HubertModel"),c(ZI,"href","/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertModel"),c(eq,"href","/docs/transformers/pr_17286/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(oq,"href","/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(rq,"href","/docs/transformers/pr_17286/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(tq,"href","/docs/transformers/pr_17286/en/model_doc/led#transformers.LEDModel"),c(aq,"href","/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerModel"),c(nq,"href","/docs/transformers/pr_17286/en/model_doc/luke#transformers.LukeModel"),c(sq,"href","/docs/transformers/pr_17286/en/model_doc/lxmert#transformers.LxmertModel"),c(lq,"href","/docs/transformers/pr_17286/en/model_doc/m2m_100#transformers.M2M100Model"),c(iq,"href","/docs/transformers/pr_17286/en/model_doc/marian#transformers.MarianModel"),c(dq,"href","/docs/transformers/pr_17286/en/model_doc/maskformer#transformers.MaskFormerModel"),c(cq,"href","/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartModel"),c(fq,"href","/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(mq,"href","/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertModel"),c(gq,"href","/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetModel"),c(hq,"href","/docs/transformers/pr_17286/en/model_doc/mt5#transformers.MT5Model"),c(pq,"href","/docs/transformers/pr_17286/en/model_doc/nystromformer#transformers.NystromformerModel"),c(uq,"href","/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(_q,"href","/docs/transformers/pr_17286/en/model_doc/opt#transformers.OPTModel"),c(bq,"href","/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.PegasusModel"),c(vq,"href","/docs/transformers/pr_17286/en/model_doc/perceiver#transformers.PerceiverModel"),c(Fq,"href","/docs/transformers/pr_17286/en/model_doc/plbart#transformers.PLBartModel"),c(Tq,"href","/docs/transformers/pr_17286/en/model_doc/poolformer#transformers.PoolFormerModel"),c(Mq,"href","/docs/transformers/pr_17286/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(Eq,"href","/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertModel"),c(Cq,"href","/docs/transformers/pr_17286/en/model_doc/reformer#transformers.ReformerModel"),c(wq,"href","/docs/transformers/pr_17286/en/model_doc/regnet#transformers.RegNetModel"),c(Aq,"href","/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertModel"),c(yq,"href","/docs/transformers/pr_17286/en/model_doc/resnet#transformers.ResNetModel"),c(Lq,"href","/docs/transformers/pr_17286/en/model_doc/retribert#transformers.RetriBertModel"),c(xq,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaModel"),c($q,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerModel"),c(kq,"href","/docs/transformers/pr_17286/en/model_doc/segformer#transformers.SegformerModel"),c(Sq,"href","/docs/transformers/pr_17286/en/model_doc/sew#transformers.SEWModel"),c(Rq,"href","/docs/transformers/pr_17286/en/model_doc/sew-d#transformers.SEWDModel"),c(Pq,"href","/docs/transformers/pr_17286/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(Bq,"href","/docs/transformers/pr_17286/en/model_doc/splinter#transformers.SplinterModel"),c(Iq,"href","/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(qq,"href","/docs/transformers/pr_17286/en/model_doc/swin#transformers.SwinModel"),c(Nq,"href","/docs/transformers/pr_17286/en/model_doc/t5#transformers.T5Model"),c(jq,"href","/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasModel"),c(Dq,"href","/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(Gq,"href","/docs/transformers/pr_17286/en/model_doc/unispeech#transformers.UniSpeechModel"),c(Oq,"href","/docs/transformers/pr_17286/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(Vq,"href","/docs/transformers/pr_17286/en/model_doc/van#transformers.VanModel"),c(Xq,"href","/docs/transformers/pr_17286/en/model_doc/vilt#transformers.ViltModel"),c(zq,"href","/docs/transformers/pr_17286/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(Qq,"href","/docs/transformers/pr_17286/en/model_doc/visual_bert#transformers.VisualBertModel"),c(Wq,"href","/docs/transformers/pr_17286/en/model_doc/vit#transformers.ViTModel"),c(Hq,"href","/docs/transformers/pr_17286/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(Uq,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(Jq,"href","/docs/transformers/pr_17286/en/model_doc/wavlm#transformers.WavLMModel"),c(Yq,"href","/docs/transformers/pr_17286/en/model_doc/xglm#transformers.XGLMModel"),c(Kq,"href","/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMModel"),c(Zq,"href","/docs/transformers/pr_17286/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(eN,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(oN,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(rN,"href","/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetModel"),c(tN,"href","/docs/transformers/pr_17286/en/model_doc/yolos#transformers.YolosModel"),c(aN,"href","/docs/transformers/pr_17286/en/model_doc/yoso#transformers.YosoModel"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Hu,"id","transformers.AutoModelForPreTraining"),c(Hu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Hu,"href","#transformers.AutoModelForPreTraining"),c(ki,"class","relative group"),c(nN,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sN,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lN,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iN,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertForPreTraining"),c(dN,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(cN,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertForPreTraining"),c(fN,"href","/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(mN,"href","/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(gN,"href","/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(hN,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(pN,"href","/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(uN,"href","/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(_N,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(bN,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraForPreTraining"),c(vN,"href","/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(FN,"href","/docs/transformers/pr_17286/en/model_doc/flava#transformers.FlavaForPreTraining"),c(TN,"href","/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetForPreTraining"),c(MN,"href","/docs/transformers/pr_17286/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(EN,"href","/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(CN,"href","/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(wN,"href","/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(AN,"href","/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(yN,"href","/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(LN,"href","/docs/transformers/pr_17286/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(xN,"href","/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c($N,"href","/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(kN,"href","/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(SN,"href","/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(RN,"href","/docs/transformers/pr_17286/en/model_doc/retribert#transformers.RetriBertModel"),c(PN,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(BN,"href","/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(IN,"href","/docs/transformers/pr_17286/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(qN,"href","/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(NN,"href","/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(jN,"href","/docs/transformers/pr_17286/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(DN,"href","/docs/transformers/pr_17286/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(GN,"href","/docs/transformers/pr_17286/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(ON,"href","/docs/transformers/pr_17286/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(VN,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(XN,"href","/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(zN,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(QN,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(WN,"href","/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(N_,"id","transformers.AutoModelForCausalLM"),c(N_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N_,"href","#transformers.AutoModelForCausalLM"),c(Pi,"class","relative group"),c(HN,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UN,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JN,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YN,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartForCausalLM"),c(KN,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertLMHeadModel"),c(ZN,"href","/docs/transformers/pr_17286/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(ej,"href","/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(oj,"href","/docs/transformers/pr_17286/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(rj,"href","/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(tj,"href","/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(aj,"href","/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(nj,"href","/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(sj,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(lj,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraForCausalLM"),c(ij,"href","/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(dj,"href","/docs/transformers/pr_17286/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(cj,"href","/docs/transformers/pr_17286/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(fj,"href","/docs/transformers/pr_17286/en/model_doc/marian#transformers.MarianForCausalLM"),c(mj,"href","/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartForCausalLM"),c(gj,"href","/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(hj,"href","/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(pj,"href","/docs/transformers/pr_17286/en/model_doc/opt#transformers.OPTForCausalLM"),c(uj,"href","/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(_j,"href","/docs/transformers/pr_17286/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(bj,"href","/docs/transformers/pr_17286/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(vj,"href","/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(Fj,"href","/docs/transformers/pr_17286/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(Tj,"href","/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(Mj,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(Ej,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(Cj,"href","/docs/transformers/pr_17286/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(wj,"href","/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(Aj,"href","/docs/transformers/pr_17286/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(yj,"href","/docs/transformers/pr_17286/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(Lj,"href","/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(xj,"href","/docs/transformers/pr_17286/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c($j,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(kj,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(Sj,"href","/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C2,"id","transformers.AutoModelForMaskedLM"),c(C2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C2,"href","#transformers.AutoModelForMaskedLM"),c(qi,"class","relative group"),c(Rj,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pj,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Bj,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ij,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(qj,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(Nj,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertForMaskedLM"),c(jj,"href","/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(Dj,"href","/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(Gj,"href","/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(Oj,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(Vj,"href","/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(Xj,"href","/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(zj,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(Qj,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(Wj,"href","/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(Hj,"href","/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(Uj,"href","/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(Jj,"href","/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(Yj,"href","/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(Kj,"href","/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(Zj,"href","/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(eD,"href","/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(oD,"href","/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(rD,"href","/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(tD,"href","/docs/transformers/pr_17286/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(aD,"href","/docs/transformers/pr_17286/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(nD,"href","/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(sD,"href","/docs/transformers/pr_17286/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(lD,"href","/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(iD,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(dD,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(cD,"href","/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(fD,"href","/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(mD,"href","/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(gD,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(hD,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(pD,"href","/docs/transformers/pr_17286/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(d1,"id","transformers.AutoModelForSeq2SeqLM"),c(d1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(d1,"href","#transformers.AutoModelForSeq2SeqLM"),c(Di,"class","relative group"),c(uD,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_D,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bD,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vD,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(FD,"href","/docs/transformers/pr_17286/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(TD,"href","/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(MD,"href","/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(ED,"href","/docs/transformers/pr_17286/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(CD,"href","/docs/transformers/pr_17286/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(wD,"href","/docs/transformers/pr_17286/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(AD,"href","/docs/transformers/pr_17286/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(yD,"href","/docs/transformers/pr_17286/en/model_doc/marian#transformers.MarianMTModel"),c(LD,"href","/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(xD,"href","/docs/transformers/pr_17286/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c($D,"href","/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(kD,"href","/docs/transformers/pr_17286/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(SD,"href","/docs/transformers/pr_17286/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(RD,"href","/docs/transformers/pr_17286/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(PD,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(BD,"href","/docs/transformers/pr_17286/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($1,"id","transformers.AutoModelForSequenceClassification"),c($1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($1,"href","#transformers.AutoModelForSequenceClassification"),c(Vi,"class","relative group"),c(ID,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qD,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ND,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jD,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(DD,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartForSequenceClassification"),c(GD,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertForSequenceClassification"),c(OD,"href","/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(VD,"href","/docs/transformers/pr_17286/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(XD,"href","/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(zD,"href","/docs/transformers/pr_17286/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(QD,"href","/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(WD,"href","/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(HD,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(UD,"href","/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(JD,"href","/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(YD,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(KD,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(ZD,"href","/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(eG,"href","/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(oG,"href","/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(rG,"href","/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(tG,"href","/docs/transformers/pr_17286/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(aG,"href","/docs/transformers/pr_17286/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(nG,"href","/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(sG,"href","/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(lG,"href","/docs/transformers/pr_17286/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(iG,"href","/docs/transformers/pr_17286/en/model_doc/led#transformers.LEDForSequenceClassification"),c(dG,"href","/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(cG,"href","/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(fG,"href","/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(mG,"href","/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(gG,"href","/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(hG,"href","/docs/transformers/pr_17286/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(pG,"href","/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(uG,"href","/docs/transformers/pr_17286/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(_G,"href","/docs/transformers/pr_17286/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(bG,"href","/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(vG,"href","/docs/transformers/pr_17286/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(FG,"href","/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(TG,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(MG,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(EG,"href","/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(CG,"href","/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(wG,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartForSequenceClassification"),c(AG,"href","/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(yG,"href","/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(LG,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(xG,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c($G,"href","/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(kG,"href","/docs/transformers/pr_17286/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yb,"id","transformers.AutoModelForMultipleChoice"),c(yb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yb,"href","#transformers.AutoModelForMultipleChoice"),c(Qi,"class","relative group"),c(SG,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(RG,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(PG,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BG,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(IG,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertForMultipleChoice"),c(qG,"href","/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(NG,"href","/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(jG,"href","/docs/transformers/pr_17286/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(DG,"href","/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(GG,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(OG,"href","/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(VG,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(XG,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(zG,"href","/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(QG,"href","/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(WG,"href","/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(HG,"href","/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(UG,"href","/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(JG,"href","/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(YG,"href","/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(KG,"href","/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(ZG,"href","/docs/transformers/pr_17286/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(eO,"href","/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(oO,"href","/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(rO,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(tO,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(aO,"href","/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(nO,"href","/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(sO,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(lO,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(iO,"href","/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(dO,"href","/docs/transformers/pr_17286/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sv,"id","transformers.AutoModelForNextSentencePrediction"),c(sv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sv,"href","#transformers.AutoModelForNextSentencePrediction"),c(Ui,"class","relative group"),c(cO,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fO,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mO,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gO,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(hO,"href","/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(pO,"href","/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(uO,"href","/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(_O,"href","/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pv,"id","transformers.AutoModelForTokenClassification"),c(pv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(pv,"href","#transformers.AutoModelForTokenClassification"),c(Ki,"class","relative group"),c(bO,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vO,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(FO,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TO,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(MO,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertForTokenClassification"),c(EO,"href","/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(CO,"href","/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(wO,"href","/docs/transformers/pr_17286/en/model_doc/canine#transformers.CanineForTokenClassification"),c(AO,"href","/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(yO,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(LO,"href","/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(xO,"href","/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c($O,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(kO,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(SO,"href","/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(RO,"href","/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(PO,"href","/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(BO,"href","/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(IO,"href","/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(qO,"href","/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(NO,"href","/docs/transformers/pr_17286/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(jO,"href","/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(DO,"href","/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(GO,"href","/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(OO,"href","/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(VO,"href","/docs/transformers/pr_17286/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(XO,"href","/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(zO,"href","/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(QO,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(WO,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(HO,"href","/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(UO,"href","/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(JO,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(YO,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(KO,"href","/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(ZO,"href","/docs/transformers/pr_17286/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Kv,"id","transformers.AutoModelForQuestionAnswering"),c(Kv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Kv,"href","#transformers.AutoModelForQuestionAnswering"),c(od,"class","relative group"),c(eV,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oV,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rV,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tV,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(aV,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(nV,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(sV,"href","/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(lV,"href","/docs/transformers/pr_17286/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(iV,"href","/docs/transformers/pr_17286/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(dV,"href","/docs/transformers/pr_17286/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(cV,"href","/docs/transformers/pr_17286/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(fV,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(mV,"href","/docs/transformers/pr_17286/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(gV,"href","/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(hV,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(pV,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(uV,"href","/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(_V,"href","/docs/transformers/pr_17286/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(bV,"href","/docs/transformers/pr_17286/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(vV,"href","/docs/transformers/pr_17286/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(FV,"href","/docs/transformers/pr_17286/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(TV,"href","/docs/transformers/pr_17286/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(MV,"href","/docs/transformers/pr_17286/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(EV,"href","/docs/transformers/pr_17286/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(CV,"href","/docs/transformers/pr_17286/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(wV,"href","/docs/transformers/pr_17286/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(AV,"href","/docs/transformers/pr_17286/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(yV,"href","/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(LV,"href","/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(xV,"href","/docs/transformers/pr_17286/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c($V,"href","/docs/transformers/pr_17286/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(kV,"href","/docs/transformers/pr_17286/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(SV,"href","/docs/transformers/pr_17286/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(RV,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(PV,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(BV,"href","/docs/transformers/pr_17286/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(IV,"href","/docs/transformers/pr_17286/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(qV,"href","/docs/transformers/pr_17286/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(NV,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(jV,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(DV,"href","/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(GV,"href","/docs/transformers/pr_17286/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GF,"id","transformers.AutoModelForTableQuestionAnswering"),c(GF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(GF,"href","#transformers.AutoModelForTableQuestionAnswering"),c(ad,"class","relative group"),c(OV,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VV,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XV,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zV,"href","/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QF,"id","transformers.AutoModelForImageClassification"),c(QF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(QF,"href","#transformers.AutoModelForImageClassification"),c(ld,"class","relative group"),c(QV,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(WV,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(HV,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UV,"href","/docs/transformers/pr_17286/en/model_doc/beit#transformers.BeitForImageClassification"),c(JV,"href","/docs/transformers/pr_17286/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(YV,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(KV,"href","/docs/transformers/pr_17286/en/model_doc/deit#transformers.DeiTForImageClassification"),c(ZV,"href","/docs/transformers/pr_17286/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(eX,"href","/docs/transformers/pr_17286/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(oX,"href","/docs/transformers/pr_17286/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(rX,"href","/docs/transformers/pr_17286/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(tX,"href","/docs/transformers/pr_17286/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(aX,"href","/docs/transformers/pr_17286/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(nX,"href","/docs/transformers/pr_17286/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(sX,"href","/docs/transformers/pr_17286/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(lX,"href","/docs/transformers/pr_17286/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(iX,"href","/docs/transformers/pr_17286/en/model_doc/swin#transformers.SwinForImageClassification"),c(dX,"href","/docs/transformers/pr_17286/en/model_doc/van#transformers.VanForImageClassification"),c(cX,"href","/docs/transformers/pr_17286/en/model_doc/vit#transformers.ViTForImageClassification"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(l6,"id","transformers.AutoModelForVision2Seq"),c(l6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(l6,"href","#transformers.AutoModelForVision2Seq"),c(cd,"class","relative group"),c(fX,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mX,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gX,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hX,"href","/docs/transformers/pr_17286/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m6,"id","transformers.AutoModelForVisualQuestionAnswering"),c(m6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m6,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(gd,"class","relative group"),c(pX,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uX,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_X,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bX,"href","/docs/transformers/pr_17286/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_6,"id","transformers.AutoModelForAudioClassification"),c(_6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_6,"href","#transformers.AutoModelForAudioClassification"),c(ud,"class","relative group"),c(vX,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(FX,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(TX,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(MX,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(EX,"href","/docs/transformers/pr_17286/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(CX,"href","/docs/transformers/pr_17286/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(wX,"href","/docs/transformers/pr_17286/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(AX,"href","/docs/transformers/pr_17286/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(yX,"href","/docs/transformers/pr_17286/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(LX,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(xX,"href","/docs/transformers/pr_17286/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(x6,"id","transformers.AutoModelForAudioFrameClassification"),c(x6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(x6,"href","#transformers.AutoModelForAudioFrameClassification"),c(vd,"class","relative group"),c($X,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kX,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SX,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RX,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(PX,"href","/docs/transformers/pr_17286/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(BX,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(IX,"href","/docs/transformers/pr_17286/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(q6,"id","transformers.AutoModelForCTC"),c(q6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(q6,"href","#transformers.AutoModelForCTC"),c(Md,"class","relative group"),c(qX,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NX,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jX,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DX,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(GX,"href","/docs/transformers/pr_17286/en/model_doc/hubert#transformers.HubertForCTC"),c(OX,"href","/docs/transformers/pr_17286/en/model_doc/sew#transformers.SEWForCTC"),c(VX,"href","/docs/transformers/pr_17286/en/model_doc/sew-d#transformers.SEWDForCTC"),c(XX,"href","/docs/transformers/pr_17286/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(zX,"href","/docs/transformers/pr_17286/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(QX,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(WX,"href","/docs/transformers/pr_17286/en/model_doc/wavlm#transformers.WavLMForCTC"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(U6,"id","transformers.AutoModelForSpeechSeq2Seq"),c(U6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(U6,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(wd,"class","relative group"),c(HX,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UX,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JX,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YX,"href","/docs/transformers/pr_17286/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(KX,"href","/docs/transformers/pr_17286/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oT,"id","transformers.AutoModelForAudioXVector"),c(oT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oT,"href","#transformers.AutoModelForAudioXVector"),c(Ld,"class","relative group"),c(ZX,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ez,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oz,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rz,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(tz,"href","/docs/transformers/pr_17286/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(az,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(nz,"href","/docs/transformers/pr_17286/en/model_doc/wavlm#transformers.WavLMForXVector"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dT,"id","transformers.AutoModelForMaskedImageModeling"),c(dT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dT,"href","#transformers.AutoModelForMaskedImageModeling"),c(kd,"class","relative group"),c(sz,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lz,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iz,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dz,"href","/docs/transformers/pr_17286/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(cz,"href","/docs/transformers/pr_17286/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(fz,"href","/docs/transformers/pr_17286/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uT,"id","transformers.AutoModelForObjectDetection"),c(uT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uT,"href","#transformers.AutoModelForObjectDetection"),c(Bd,"class","relative group"),c(mz,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gz,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hz,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pz,"href","/docs/transformers/pr_17286/en/model_doc/detr#transformers.DetrForObjectDetection"),c(uz,"href","/docs/transformers/pr_17286/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(MT,"id","transformers.AutoModelForImageSegmentation"),c(MT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(MT,"href","#transformers.AutoModelForImageSegmentation"),c(Nd,"class","relative group"),c(_z,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bz,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vz,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fz,"href","/docs/transformers/pr_17286/en/model_doc/detr#transformers.DetrForSegmentation"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yT,"id","transformers.AutoModelForSemanticSegmentation"),c(yT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yT,"href","#transformers.AutoModelForSemanticSegmentation"),c(Gd,"class","relative group"),c(Tz,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mz,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Ez,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cz,"href","/docs/transformers/pr_17286/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(wz,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(Az,"href","/docs/transformers/pr_17286/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(yz,"href","/docs/transformers/pr_17286/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BT,"id","transformers.AutoModelForInstanceSegmentation"),c(BT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(BT,"href","#transformers.AutoModelForInstanceSegmentation"),c(Xd,"class","relative group"),c(Lz,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xz,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($z,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kz,"href","/docs/transformers/pr_17286/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DT,"id","transformers.TFAutoModel"),c(DT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DT,"href","#transformers.TFAutoModel"),c(Wd,"class","relative group"),c(Sz,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rz,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Pz,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bz,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.TFAlbertModel"),c(Iz,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.TFBartModel"),c(qz,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.TFBertModel"),c(Nz,"href","/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(jz,"href","/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(Dz,"href","/docs/transformers/pr_17286/en/model_doc/camembert#transformers.TFCamembertModel"),c(Gz,"href","/docs/transformers/pr_17286/en/model_doc/clip#transformers.TFCLIPModel"),c(Oz,"href","/docs/transformers/pr_17286/en/model_doc/convbert#transformers.TFConvBertModel"),c(Vz,"href","/docs/transformers/pr_17286/en/model_doc/convnext#transformers.TFConvNextModel"),c(Xz,"href","/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.TFCTRLModel"),c(zz,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(Qz,"href","/docs/transformers/pr_17286/en/model_doc/deberta#transformers.TFDebertaModel"),c(Wz,"href","/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(Hz,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(Uz,"href","/docs/transformers/pr_17286/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(Jz,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.TFElectraModel"),c(Yz,"href","/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(Kz,"href","/docs/transformers/pr_17286/en/model_doc/funnel#transformers.TFFunnelModel"),c(Zz,"href","/docs/transformers/pr_17286/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(eQ,"href","/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.TFGPT2Model"),c(oQ,"href","/docs/transformers/pr_17286/en/model_doc/gptj#transformers.TFGPTJModel"),c(rQ,"href","/docs/transformers/pr_17286/en/model_doc/hubert#transformers.TFHubertModel"),c(tQ,"href","/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(aQ,"href","/docs/transformers/pr_17286/en/model_doc/led#transformers.TFLEDModel"),c(nQ,"href","/docs/transformers/pr_17286/en/model_doc/longformer#transformers.TFLongformerModel"),c(sQ,"href","/docs/transformers/pr_17286/en/model_doc/lxmert#transformers.TFLxmertModel"),c(lQ,"href","/docs/transformers/pr_17286/en/model_doc/marian#transformers.TFMarianModel"),c(iQ,"href","/docs/transformers/pr_17286/en/model_doc/mbart#transformers.TFMBartModel"),c(dQ,"href","/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(cQ,"href","/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.TFMPNetModel"),c(fQ,"href","/docs/transformers/pr_17286/en/model_doc/mt5#transformers.TFMT5Model"),c(mQ,"href","/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(gQ,"href","/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.TFPegasusModel"),c(hQ,"href","/docs/transformers/pr_17286/en/model_doc/rembert#transformers.TFRemBertModel"),c(pQ,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.TFRobertaModel"),c(uQ,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.TFRoFormerModel"),c(_Q,"href","/docs/transformers/pr_17286/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(bQ,"href","/docs/transformers/pr_17286/en/model_doc/t5#transformers.TFT5Model"),c(vQ,"href","/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TFTapasModel"),c(FQ,"href","/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(TQ,"href","/docs/transformers/pr_17286/en/model_doc/vit#transformers.TFViTModel"),c(MQ,"href","/docs/transformers/pr_17286/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(EQ,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(CQ,"href","/docs/transformers/pr_17286/en/model_doc/xlm#transformers.TFXLMModel"),c(wQ,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(AQ,"href","/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.TFXLNetModel"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(R8,"id","transformers.TFAutoModelForPreTraining"),c(R8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(R8,"href","#transformers.TFAutoModelForPreTraining"),c(Jd,"class","relative group"),c(yQ,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LQ,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xQ,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($Q,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(kQ,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(SQ,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.TFBertForPreTraining"),c(RQ,"href","/docs/transformers/pr_17286/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(PQ,"href","/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(BQ,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(IQ,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(qQ,"href","/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(NQ,"href","/docs/transformers/pr_17286/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(jQ,"href","/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(DQ,"href","/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(GQ,"href","/docs/transformers/pr_17286/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(OQ,"href","/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(VQ,"href","/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(XQ,"href","/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(zQ,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(QQ,"href","/docs/transformers/pr_17286/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(WQ,"href","/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(HQ,"href","/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(UQ,"href","/docs/transformers/pr_17286/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(JQ,"href","/docs/transformers/pr_17286/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(YQ,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(KQ,"href","/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(n7,"id","transformers.TFAutoModelForCausalLM"),c(n7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(n7,"href","#transformers.TFAutoModelForCausalLM"),c(Zd,"class","relative group"),c(ZQ,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eW,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oW,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rW,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(tW,"href","/docs/transformers/pr_17286/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(aW,"href","/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(nW,"href","/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(sW,"href","/docs/transformers/pr_17286/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(lW,"href","/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(iW,"href","/docs/transformers/pr_17286/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(dW,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(cW,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(fW,"href","/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(mW,"href","/docs/transformers/pr_17286/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(gW,"href","/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(F7,"id","transformers.TFAutoModelForImageClassification"),c(F7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(F7,"href","#transformers.TFAutoModelForImageClassification"),c(rc,"class","relative group"),c(hW,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pW,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(uW,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_W,"href","/docs/transformers/pr_17286/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(bW,"href","/docs/transformers/pr_17286/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(vW,"href","/docs/transformers/pr_17286/en/model_doc/vit#transformers.TFViTForImageClassification"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(A7,"id","transformers.TFAutoModelForMaskedLM"),c(A7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(A7,"href","#transformers.TFAutoModelForMaskedLM"),c(sc,"class","relative group"),c(FW,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TW,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MW,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EW,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(CW,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(wW,"href","/docs/transformers/pr_17286/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(AW,"href","/docs/transformers/pr_17286/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(yW,"href","/docs/transformers/pr_17286/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(LW,"href","/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(xW,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c($W,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(kW,"href","/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(SW,"href","/docs/transformers/pr_17286/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(RW,"href","/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(PW,"href","/docs/transformers/pr_17286/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(BW,"href","/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(IW,"href","/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(qW,"href","/docs/transformers/pr_17286/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(NW,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(jW,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(DW,"href","/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(GW,"href","/docs/transformers/pr_17286/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(OW,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(U7,"id","transformers.TFAutoModelForSeq2SeqLM"),c(U7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(U7,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(dc,"class","relative group"),c(VW,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(XW,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zW,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QW,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(WW,"href","/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(HW,"href","/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(UW,"href","/docs/transformers/pr_17286/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(JW,"href","/docs/transformers/pr_17286/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(YW,"href","/docs/transformers/pr_17286/en/model_doc/marian#transformers.TFMarianMTModel"),c(KW,"href","/docs/transformers/pr_17286/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(ZW,"href","/docs/transformers/pr_17286/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(eH,"href","/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(oH,"href","/docs/transformers/pr_17286/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iM,"id","transformers.TFAutoModelForSequenceClassification"),c(iM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(iM,"href","#transformers.TFAutoModelForSequenceClassification"),c(mc,"class","relative group"),c(rH,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tH,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aH,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nH,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(sH,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(lH,"href","/docs/transformers/pr_17286/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(iH,"href","/docs/transformers/pr_17286/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(dH,"href","/docs/transformers/pr_17286/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(cH,"href","/docs/transformers/pr_17286/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(fH,"href","/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(mH,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(gH,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(hH,"href","/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(pH,"href","/docs/transformers/pr_17286/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(uH,"href","/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(_H,"href","/docs/transformers/pr_17286/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(bH,"href","/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(vH,"href","/docs/transformers/pr_17286/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(FH,"href","/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(TH,"href","/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(MH,"href","/docs/transformers/pr_17286/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(EH,"href","/docs/transformers/pr_17286/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(CH,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(wH,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(AH,"href","/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(yH,"href","/docs/transformers/pr_17286/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(LH,"href","/docs/transformers/pr_17286/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(xH,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c($H,"href","/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qM,"id","transformers.TFAutoModelForMultipleChoice"),c(qM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qM,"href","#transformers.TFAutoModelForMultipleChoice"),c(pc,"class","relative group"),c(kH,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(SH,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(RH,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PH,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(BH,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(IH,"href","/docs/transformers/pr_17286/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(qH,"href","/docs/transformers/pr_17286/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(NH,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(jH,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(DH,"href","/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(GH,"href","/docs/transformers/pr_17286/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(OH,"href","/docs/transformers/pr_17286/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(VH,"href","/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(XH,"href","/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(zH,"href","/docs/transformers/pr_17286/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(QH,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(WH,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(HH,"href","/docs/transformers/pr_17286/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(UH,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(JH,"href","/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(t4,"id","transformers.TFAutoModelForNextSentencePrediction"),c(t4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(t4,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(bc,"class","relative group"),c(YH,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KH,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ZH,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eU,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(oU,"href","/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(i4,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(i4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(i4,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(Tc,"class","relative group"),c(rU,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tU,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aU,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nU,"href","/docs/transformers/pr_17286/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m4,"id","transformers.TFAutoModelForTokenClassification"),c(m4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m4,"href","#transformers.TFAutoModelForTokenClassification"),c(Cc,"class","relative group"),c(sU,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lU,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iU,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dU,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(cU,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(fU,"href","/docs/transformers/pr_17286/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(mU,"href","/docs/transformers/pr_17286/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(gU,"href","/docs/transformers/pr_17286/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(hU,"href","/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(pU,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(uU,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(_U,"href","/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(bU,"href","/docs/transformers/pr_17286/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(vU,"href","/docs/transformers/pr_17286/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(FU,"href","/docs/transformers/pr_17286/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(TU,"href","/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(MU,"href","/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(EU,"href","/docs/transformers/pr_17286/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(CU,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(wU,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(AU,"href","/docs/transformers/pr_17286/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(yU,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(LU,"href","/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(B4,"id","transformers.TFAutoModelForQuestionAnswering"),c(B4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(B4,"href","#transformers.TFAutoModelForQuestionAnswering"),c(yc,"class","relative group"),c(xU,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($U,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kU,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SU,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(RU,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(PU,"href","/docs/transformers/pr_17286/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(BU,"href","/docs/transformers/pr_17286/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(IU,"href","/docs/transformers/pr_17286/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(qU,"href","/docs/transformers/pr_17286/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(NU,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(jU,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(DU,"href","/docs/transformers/pr_17286/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(GU,"href","/docs/transformers/pr_17286/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(OU,"href","/docs/transformers/pr_17286/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(VU,"href","/docs/transformers/pr_17286/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(XU,"href","/docs/transformers/pr_17286/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(zU,"href","/docs/transformers/pr_17286/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(QU,"href","/docs/transformers/pr_17286/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(WU,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(HU,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(UU,"href","/docs/transformers/pr_17286/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(JU,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(YU,"href","/docs/transformers/pr_17286/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aE,"id","transformers.TFAutoModelForVision2Seq"),c(aE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aE,"href","#transformers.TFAutoModelForVision2Seq"),c($c,"class","relative group"),c(KU,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZU,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eJ,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oJ,"href","/docs/transformers/pr_17286/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iE,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(iE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(iE,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(Rc,"class","relative group"),c(rJ,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tJ,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aJ,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nJ,"href","/docs/transformers/pr_17286/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mE,"id","transformers.FlaxAutoModel"),c(mE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mE,"href","#transformers.FlaxAutoModel"),c(Ic,"class","relative group"),c(sJ,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lJ,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iJ,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dJ,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.FlaxAlbertModel"),c(cJ,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.FlaxBartModel"),c(fJ,"href","/docs/transformers/pr_17286/en/model_doc/beit#transformers.FlaxBeitModel"),c(mJ,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.FlaxBertModel"),c(gJ,"href","/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(hJ,"href","/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(pJ,"href","/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(uJ,"href","/docs/transformers/pr_17286/en/model_doc/clip#transformers.FlaxCLIPModel"),c(_J,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(bJ,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.FlaxElectraModel"),c(vJ,"href","/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(FJ,"href","/docs/transformers/pr_17286/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(TJ,"href","/docs/transformers/pr_17286/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(MJ,"href","/docs/transformers/pr_17286/en/model_doc/marian#transformers.FlaxMarianModel"),c(EJ,"href","/docs/transformers/pr_17286/en/model_doc/mbart#transformers.FlaxMBartModel"),c(CJ,"href","/docs/transformers/pr_17286/en/model_doc/mt5#transformers.FlaxMT5Model"),c(wJ,"href","/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(AJ,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(yJ,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(LJ,"href","/docs/transformers/pr_17286/en/model_doc/t5#transformers.FlaxT5Model"),c(xJ,"href","/docs/transformers/pr_17286/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c($J,"href","/docs/transformers/pr_17286/en/model_doc/vit#transformers.FlaxViTModel"),c(kJ,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(SJ,"href","/docs/transformers/pr_17286/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(RJ,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DE,"id","transformers.FlaxAutoModelForCausalLM"),c(DE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DE,"href","#transformers.FlaxAutoModelForCausalLM"),c(jc,"class","relative group"),c(PJ,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BJ,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IJ,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qJ,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(NJ,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(jJ,"href","/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(DJ,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(GJ,"href","/docs/transformers/pr_17286/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(OJ,"href","/docs/transformers/pr_17286/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(VJ,"href","/docs/transformers/pr_17286/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(XJ,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(zJ,"href","/docs/transformers/pr_17286/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KE,"id","transformers.FlaxAutoModelForPreTraining"),c(KE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(KE,"href","#transformers.FlaxAutoModelForPreTraining"),c(Oc,"class","relative group"),c(QJ,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(WJ,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(HJ,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UJ,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(JJ,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(YJ,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(KJ,"href","/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(ZJ,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(eY,"href","/docs/transformers/pr_17286/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(oY,"href","/docs/transformers/pr_17286/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(rY,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(tY,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(aY,"href","/docs/transformers/pr_17286/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(nY,"href","/docs/transformers/pr_17286/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(sY,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(g5,"id","transformers.FlaxAutoModelForMaskedLM"),c(g5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(g5,"href","#transformers.FlaxAutoModelForMaskedLM"),c(zc,"class","relative group"),c(lY,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iY,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dY,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cY,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(fY,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(mY,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(gY,"href","/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(hY,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(pY,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(uY,"href","/docs/transformers/pr_17286/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(_Y,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(bY,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(vY,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(A5,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(A5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(A5,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(Hc,"class","relative group"),c(FY,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TY,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MY,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EY,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(CY,"href","/docs/transformers/pr_17286/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(wY,"href","/docs/transformers/pr_17286/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(AY,"href","/docs/transformers/pr_17286/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(yY,"href","/docs/transformers/pr_17286/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(LY,"href","/docs/transformers/pr_17286/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(xY,"href","/docs/transformers/pr_17286/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c($Y,"href","/docs/transformers/pr_17286/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(kY,"href","/docs/transformers/pr_17286/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(N5,"id","transformers.FlaxAutoModelForSequenceClassification"),c(N5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N5,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(Yc,"class","relative group"),c(SY,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(RY,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(PY,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BY,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(IY,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(qY,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(NY,"href","/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(jY,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(DY,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(GY,"href","/docs/transformers/pr_17286/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(OY,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(VY,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(XY,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Y5,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(Y5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Y5,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(ef,"class","relative group"),c(zY,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QY,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WY,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HY,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(UY,"href","/docs/transformers/pr_17286/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(JY,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(YY,"href","/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(KY,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(ZY,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(eK,"href","/docs/transformers/pr_17286/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(oK,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(rK,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(tK,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cC,"id","transformers.FlaxAutoModelForTokenClassification"),c(cC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cC,"href","#transformers.FlaxAutoModelForTokenClassification"),c(tf,"class","relative group"),c(aK,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nK,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sK,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lK,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(iK,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(dK,"href","/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(cK,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(fK,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(mK,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(gK,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(hK,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TC,"id","transformers.FlaxAutoModelForMultipleChoice"),c(TC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(TC,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(sf,"class","relative group"),c(pK,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uK,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_K,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bK,"href","/docs/transformers/pr_17286/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(vK,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(FK,"href","/docs/transformers/pr_17286/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(TK,"href","/docs/transformers/pr_17286/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(MK,"href","/docs/transformers/pr_17286/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(EK,"href","/docs/transformers/pr_17286/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(CK,"href","/docs/transformers/pr_17286/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(wK,"href","/docs/transformers/pr_17286/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SC,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(SC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(SC,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(cf,"class","relative group"),c(AK,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yK,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LK,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xK,"href","/docs/transformers/pr_17286/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IC,"id","transformers.FlaxAutoModelForImageClassification"),c(IC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(IC,"href","#transformers.FlaxAutoModelForImageClassification"),c(gf,"class","relative group"),c($K,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kK,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SK,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RK,"href","/docs/transformers/pr_17286/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(PK,"href","/docs/transformers/pr_17286/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GC,"id","transformers.FlaxAutoModelForVision2Seq"),c(GC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(GC,"href","#transformers.FlaxAutoModelForVision2Seq"),c(uf,"class","relative group"),c(BK,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(IK,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qK,"href","/docs/transformers/pr_17286/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NK,"href","/docs/transformers/pr_17286/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,_){e(document.head,g),b(f,v,_),b(f,p,_),e(p,m),e(m,u),M(d,u,null),e(p,h),e(p,Eo),e(Eo,hi),b(f,Mf,_),b(f,rt,_),e(rt,pi),e(rt,ui),e(ui,mA),e(rt,Ef),b(f,qe,_),b(f,Xe,_),e(Xe,_i),e(Xe,kn),e(kn,gA),e(Xe,Sn),e(Xe,Rn),e(Rn,hA),e(Xe,bi),e(Xe,Pn),e(Pn,pA),e(Xe,vi),b(f,Cf,_),M(Aa,f,_),b(f,ze,_),b(f,Ae,_),e(Ae,j$),e(Ae,Fi),e(Fi,D$),e(Ae,G$),b(f,Co,_),b(f,ya,_),e(ya,O$),e(ya,wf),e(wf,V$),e(ya,rGe),b(f,GIe,_),b(f,Ti,_),e(Ti,Af),e(Af,Pee),M(uA,Pee,null),e(Ti,tGe),e(Ti,Bee),e(Bee,aGe),b(f,OIe,_),b(f,Bn,_),e(Bn,nGe),e(Bn,Iee),e(Iee,sGe),e(Bn,lGe),e(Bn,qee),e(qee,iGe),e(Bn,dGe),b(f,VIe,_),M(_A,f,_),b(f,XIe,_),b(f,X$,_),e(X$,cGe),b(f,zIe,_),M(yf,f,_),b(f,QIe,_),b(f,Mi,_),e(Mi,Lf),e(Lf,Nee),M(bA,Nee,null),e(Mi,fGe),e(Mi,jee),e(jee,mGe),b(f,WIe,_),b(f,wo,_),M(vA,wo,null),e(wo,gGe),e(wo,FA),e(FA,hGe),e(FA,z$),e(z$,pGe),e(FA,uGe),e(wo,_Ge),e(wo,TA),e(TA,bGe),e(TA,Dee),e(Dee,vGe),e(TA,FGe),e(wo,TGe),e(wo,wr),M(MA,wr,null),e(wr,MGe),e(wr,Gee),e(Gee,EGe),e(wr,CGe),e(wr,Ei),e(Ei,wGe),e(Ei,Oee),e(Oee,AGe),e(Ei,yGe),e(Ei,Vee),e(Vee,LGe),e(Ei,xGe),e(wr,$Ge),e(wr,y),e(y,xf),e(xf,Xee),e(Xee,kGe),e(xf,SGe),e(xf,Q$),e(Q$,RGe),e(xf,PGe),e(y,BGe),e(y,$f),e($f,zee),e(zee,IGe),e($f,qGe),e($f,W$),e(W$,NGe),e($f,jGe),e(y,DGe),e(y,kf),e(kf,Qee),e(Qee,GGe),e(kf,OGe),e(kf,H$),e(H$,VGe),e(kf,XGe),e(y,zGe),e(y,Sf),e(Sf,Wee),e(Wee,QGe),e(Sf,WGe),e(Sf,U$),e(U$,HGe),e(Sf,UGe),e(y,JGe),e(y,Rf),e(Rf,Hee),e(Hee,YGe),e(Rf,KGe),e(Rf,J$),e(J$,ZGe),e(Rf,eOe),e(y,oOe),e(y,Pf),e(Pf,Uee),e(Uee,rOe),e(Pf,tOe),e(Pf,Y$),e(Y$,aOe),e(Pf,nOe),e(y,sOe),e(y,Bf),e(Bf,Jee),e(Jee,lOe),e(Bf,iOe),e(Bf,K$),e(K$,dOe),e(Bf,cOe),e(y,fOe),e(y,If),e(If,Yee),e(Yee,mOe),e(If,gOe),e(If,Z$),e(Z$,hOe),e(If,pOe),e(y,uOe),e(y,qf),e(qf,Kee),e(Kee,_Oe),e(qf,bOe),e(qf,ek),e(ek,vOe),e(qf,FOe),e(y,TOe),e(y,Nf),e(Nf,Zee),e(Zee,MOe),e(Nf,EOe),e(Nf,ok),e(ok,COe),e(Nf,wOe),e(y,AOe),e(y,jf),e(jf,eoe),e(eoe,yOe),e(jf,LOe),e(jf,rk),e(rk,xOe),e(jf,$Oe),e(y,kOe),e(y,Df),e(Df,ooe),e(ooe,SOe),e(Df,ROe),e(Df,tk),e(tk,POe),e(Df,BOe),e(y,IOe),e(y,Gf),e(Gf,roe),e(roe,qOe),e(Gf,NOe),e(Gf,ak),e(ak,jOe),e(Gf,DOe),e(y,GOe),e(y,Of),e(Of,toe),e(toe,OOe),e(Of,VOe),e(Of,nk),e(nk,XOe),e(Of,zOe),e(y,QOe),e(y,Vf),e(Vf,aoe),e(aoe,WOe),e(Vf,HOe),e(Vf,sk),e(sk,UOe),e(Vf,JOe),e(y,YOe),e(y,Xf),e(Xf,noe),e(noe,KOe),e(Xf,ZOe),e(Xf,lk),e(lk,eVe),e(Xf,oVe),e(y,rVe),e(y,zf),e(zf,soe),e(soe,tVe),e(zf,aVe),e(zf,ik),e(ik,nVe),e(zf,sVe),e(y,lVe),e(y,Qf),e(Qf,loe),e(loe,iVe),e(Qf,dVe),e(Qf,dk),e(dk,cVe),e(Qf,fVe),e(y,mVe),e(y,Wf),e(Wf,ioe),e(ioe,gVe),e(Wf,hVe),e(Wf,ck),e(ck,pVe),e(Wf,uVe),e(y,_Ve),e(y,Hf),e(Hf,doe),e(doe,bVe),e(Hf,vVe),e(Hf,fk),e(fk,FVe),e(Hf,TVe),e(y,MVe),e(y,Uf),e(Uf,coe),e(coe,EVe),e(Uf,CVe),e(Uf,mk),e(mk,wVe),e(Uf,AVe),e(y,yVe),e(y,Jf),e(Jf,foe),e(foe,LVe),e(Jf,xVe),e(Jf,gk),e(gk,$Ve),e(Jf,kVe),e(y,SVe),e(y,Yf),e(Yf,moe),e(moe,RVe),e(Yf,PVe),e(Yf,hk),e(hk,BVe),e(Yf,IVe),e(y,qVe),e(y,Kf),e(Kf,goe),e(goe,NVe),e(Kf,jVe),e(Kf,pk),e(pk,DVe),e(Kf,GVe),e(y,OVe),e(y,Zf),e(Zf,hoe),e(hoe,VVe),e(Zf,XVe),e(Zf,uk),e(uk,zVe),e(Zf,QVe),e(y,WVe),e(y,em),e(em,poe),e(poe,HVe),e(em,UVe),e(em,_k),e(_k,JVe),e(em,YVe),e(y,KVe),e(y,om),e(om,uoe),e(uoe,ZVe),e(om,eXe),e(om,bk),e(bk,oXe),e(om,rXe),e(y,tXe),e(y,rm),e(rm,_oe),e(_oe,aXe),e(rm,nXe),e(rm,vk),e(vk,sXe),e(rm,lXe),e(y,iXe),e(y,tm),e(tm,boe),e(boe,dXe),e(tm,cXe),e(tm,Fk),e(Fk,fXe),e(tm,mXe),e(y,gXe),e(y,am),e(am,voe),e(voe,hXe),e(am,pXe),e(am,Tk),e(Tk,uXe),e(am,_Xe),e(y,bXe),e(y,nm),e(nm,Foe),e(Foe,vXe),e(nm,FXe),e(nm,Mk),e(Mk,TXe),e(nm,MXe),e(y,EXe),e(y,sm),e(sm,Toe),e(Toe,CXe),e(sm,wXe),e(sm,Ek),e(Ek,AXe),e(sm,yXe),e(y,LXe),e(y,lm),e(lm,Moe),e(Moe,xXe),e(lm,$Xe),e(lm,Ck),e(Ck,kXe),e(lm,SXe),e(y,RXe),e(y,im),e(im,Eoe),e(Eoe,PXe),e(im,BXe),e(im,wk),e(wk,IXe),e(im,qXe),e(y,NXe),e(y,dm),e(dm,Coe),e(Coe,jXe),e(dm,DXe),e(dm,Ak),e(Ak,GXe),e(dm,OXe),e(y,VXe),e(y,cm),e(cm,woe),e(woe,XXe),e(cm,zXe),e(cm,yk),e(yk,QXe),e(cm,WXe),e(y,HXe),e(y,fm),e(fm,Aoe),e(Aoe,UXe),e(fm,JXe),e(fm,Lk),e(Lk,YXe),e(fm,KXe),e(y,ZXe),e(y,mm),e(mm,yoe),e(yoe,eze),e(mm,oze),e(mm,xk),e(xk,rze),e(mm,tze),e(y,aze),e(y,gm),e(gm,Loe),e(Loe,nze),e(gm,sze),e(gm,$k),e($k,lze),e(gm,ize),e(y,dze),e(y,hm),e(hm,xoe),e(xoe,cze),e(hm,fze),e(hm,kk),e(kk,mze),e(hm,gze),e(y,hze),e(y,pm),e(pm,$oe),e($oe,pze),e(pm,uze),e(pm,Sk),e(Sk,_ze),e(pm,bze),e(y,vze),e(y,um),e(um,koe),e(koe,Fze),e(um,Tze),e(um,Rk),e(Rk,Mze),e(um,Eze),e(y,Cze),e(y,_m),e(_m,Soe),e(Soe,wze),e(_m,Aze),e(_m,Pk),e(Pk,yze),e(_m,Lze),e(y,xze),e(y,bm),e(bm,Roe),e(Roe,$ze),e(bm,kze),e(bm,Bk),e(Bk,Sze),e(bm,Rze),e(y,Pze),e(y,vm),e(vm,Poe),e(Poe,Bze),e(vm,Ize),e(vm,Ik),e(Ik,qze),e(vm,Nze),e(y,jze),e(y,Fm),e(Fm,Boe),e(Boe,Dze),e(Fm,Gze),e(Fm,qk),e(qk,Oze),e(Fm,Vze),e(y,Xze),e(y,Tm),e(Tm,Ioe),e(Ioe,zze),e(Tm,Qze),e(Tm,Nk),e(Nk,Wze),e(Tm,Hze),e(y,Uze),e(y,Mm),e(Mm,qoe),e(qoe,Jze),e(Mm,Yze),e(Mm,jk),e(jk,Kze),e(Mm,Zze),e(y,eQe),e(y,Em),e(Em,Noe),e(Noe,oQe),e(Em,rQe),e(Em,Dk),e(Dk,tQe),e(Em,aQe),e(y,nQe),e(y,Cm),e(Cm,joe),e(joe,sQe),e(Cm,lQe),e(Cm,Gk),e(Gk,iQe),e(Cm,dQe),e(y,cQe),e(y,wm),e(wm,Doe),e(Doe,fQe),e(wm,mQe),e(wm,Ok),e(Ok,gQe),e(wm,hQe),e(y,pQe),e(y,Am),e(Am,Goe),e(Goe,uQe),e(Am,_Qe),e(Am,Vk),e(Vk,bQe),e(Am,vQe),e(y,FQe),e(y,ym),e(ym,Ooe),e(Ooe,TQe),e(ym,MQe),e(ym,Xk),e(Xk,EQe),e(ym,CQe),e(y,wQe),e(y,Lm),e(Lm,Voe),e(Voe,AQe),e(Lm,yQe),e(Lm,zk),e(zk,LQe),e(Lm,xQe),e(y,$Qe),e(y,xm),e(xm,Xoe),e(Xoe,kQe),e(xm,SQe),e(xm,Qk),e(Qk,RQe),e(xm,PQe),e(y,BQe),e(y,$m),e($m,zoe),e(zoe,IQe),e($m,qQe),e($m,Wk),e(Wk,NQe),e($m,jQe),e(y,DQe),e(y,km),e(km,Qoe),e(Qoe,GQe),e(km,OQe),e(km,Hk),e(Hk,VQe),e(km,XQe),e(y,zQe),e(y,Sm),e(Sm,Woe),e(Woe,QQe),e(Sm,WQe),e(Sm,Uk),e(Uk,HQe),e(Sm,UQe),e(y,JQe),e(y,Rm),e(Rm,Hoe),e(Hoe,YQe),e(Rm,KQe),e(Rm,Jk),e(Jk,ZQe),e(Rm,eWe),e(y,oWe),e(y,Pm),e(Pm,Uoe),e(Uoe,rWe),e(Pm,tWe),e(Pm,Yk),e(Yk,aWe),e(Pm,nWe),e(y,sWe),e(y,Bm),e(Bm,Joe),e(Joe,lWe),e(Bm,iWe),e(Bm,Kk),e(Kk,dWe),e(Bm,cWe),e(y,fWe),e(y,Im),e(Im,Yoe),e(Yoe,mWe),e(Im,gWe),e(Im,Zk),e(Zk,hWe),e(Im,pWe),e(y,uWe),e(y,qm),e(qm,Koe),e(Koe,_We),e(qm,bWe),e(qm,eS),e(eS,vWe),e(qm,FWe),e(y,TWe),e(y,Nm),e(Nm,Zoe),e(Zoe,MWe),e(Nm,EWe),e(Nm,oS),e(oS,CWe),e(Nm,wWe),e(y,AWe),e(y,jm),e(jm,ere),e(ere,yWe),e(jm,LWe),e(jm,rS),e(rS,xWe),e(jm,$We),e(y,kWe),e(y,Dm),e(Dm,ore),e(ore,SWe),e(Dm,RWe),e(Dm,tS),e(tS,PWe),e(Dm,BWe),e(y,IWe),e(y,Gm),e(Gm,rre),e(rre,qWe),e(Gm,NWe),e(Gm,aS),e(aS,jWe),e(Gm,DWe),e(y,GWe),e(y,Om),e(Om,tre),e(tre,OWe),e(Om,VWe),e(Om,nS),e(nS,XWe),e(Om,zWe),e(y,QWe),e(y,Vm),e(Vm,are),e(are,WWe),e(Vm,HWe),e(Vm,sS),e(sS,UWe),e(Vm,JWe),e(y,YWe),e(y,Xm),e(Xm,nre),e(nre,KWe),e(Xm,ZWe),e(Xm,lS),e(lS,eHe),e(Xm,oHe),e(y,rHe),e(y,zm),e(zm,sre),e(sre,tHe),e(zm,aHe),e(zm,iS),e(iS,nHe),e(zm,sHe),e(y,lHe),e(y,Qm),e(Qm,lre),e(lre,iHe),e(Qm,dHe),e(Qm,dS),e(dS,cHe),e(Qm,fHe),e(y,mHe),e(y,Wm),e(Wm,ire),e(ire,gHe),e(Wm,hHe),e(Wm,cS),e(cS,pHe),e(Wm,uHe),e(y,_He),e(y,Hm),e(Hm,dre),e(dre,bHe),e(Hm,vHe),e(Hm,fS),e(fS,FHe),e(Hm,THe),e(y,MHe),e(y,Um),e(Um,cre),e(cre,EHe),e(Um,CHe),e(Um,mS),e(mS,wHe),e(Um,AHe),e(y,yHe),e(y,Jm),e(Jm,fre),e(fre,LHe),e(Jm,xHe),e(Jm,gS),e(gS,$He),e(Jm,kHe),e(y,SHe),e(y,Ym),e(Ym,mre),e(mre,RHe),e(Ym,PHe),e(Ym,hS),e(hS,BHe),e(Ym,IHe),e(y,qHe),e(y,Km),e(Km,gre),e(gre,NHe),e(Km,jHe),e(Km,pS),e(pS,DHe),e(Km,GHe),e(y,OHe),e(y,Zm),e(Zm,hre),e(hre,VHe),e(Zm,XHe),e(Zm,uS),e(uS,zHe),e(Zm,QHe),e(y,WHe),e(y,eg),e(eg,pre),e(pre,HHe),e(eg,UHe),e(eg,_S),e(_S,JHe),e(eg,YHe),e(y,KHe),e(y,og),e(og,ure),e(ure,ZHe),e(og,eUe),e(og,bS),e(bS,oUe),e(og,rUe),e(y,tUe),e(y,rg),e(rg,_re),e(_re,aUe),e(rg,nUe),e(rg,vS),e(vS,sUe),e(rg,lUe),e(y,iUe),e(y,tg),e(tg,bre),e(bre,dUe),e(tg,cUe),e(tg,FS),e(FS,fUe),e(tg,mUe),e(y,gUe),e(y,ag),e(ag,vre),e(vre,hUe),e(ag,pUe),e(ag,TS),e(TS,uUe),e(ag,_Ue),e(y,bUe),e(y,ng),e(ng,Fre),e(Fre,vUe),e(ng,FUe),e(ng,MS),e(MS,TUe),e(ng,MUe),e(y,EUe),e(y,sg),e(sg,Tre),e(Tre,CUe),e(sg,wUe),e(sg,ES),e(ES,AUe),e(sg,yUe),e(y,LUe),e(y,lg),e(lg,Mre),e(Mre,xUe),e(lg,$Ue),e(lg,CS),e(CS,kUe),e(lg,SUe),e(y,RUe),e(y,ig),e(ig,Ere),e(Ere,PUe),e(ig,BUe),e(ig,wS),e(wS,IUe),e(ig,qUe),e(y,NUe),e(y,dg),e(dg,Cre),e(Cre,jUe),e(dg,DUe),e(dg,AS),e(AS,GUe),e(dg,OUe),e(y,VUe),e(y,cg),e(cg,wre),e(wre,XUe),e(cg,zUe),e(cg,yS),e(yS,QUe),e(cg,WUe),e(y,HUe),e(y,fg),e(fg,Are),e(Are,UUe),e(fg,JUe),e(fg,LS),e(LS,YUe),e(fg,KUe),e(y,ZUe),e(y,mg),e(mg,yre),e(yre,eJe),e(mg,oJe),e(mg,xS),e(xS,rJe),e(mg,tJe),e(y,aJe),e(y,gg),e(gg,Lre),e(Lre,nJe),e(gg,sJe),e(gg,$S),e($S,lJe),e(gg,iJe),e(y,dJe),e(y,hg),e(hg,xre),e(xre,cJe),e(hg,fJe),e(hg,kS),e(kS,mJe),e(hg,gJe),e(y,hJe),e(y,pg),e(pg,$re),e($re,pJe),e(pg,uJe),e(pg,SS),e(SS,_Je),e(pg,bJe),e(y,vJe),e(y,ug),e(ug,kre),e(kre,FJe),e(ug,TJe),e(ug,RS),e(RS,MJe),e(ug,EJe),e(y,CJe),e(y,_g),e(_g,Sre),e(Sre,wJe),e(_g,AJe),e(_g,PS),e(PS,yJe),e(_g,LJe),e(y,xJe),e(y,bg),e(bg,Rre),e(Rre,$Je),e(bg,kJe),e(bg,BS),e(BS,SJe),e(bg,RJe),e(y,PJe),e(y,vg),e(vg,Pre),e(Pre,BJe),e(vg,IJe),e(vg,IS),e(IS,qJe),e(vg,NJe),e(y,jJe),e(y,Fg),e(Fg,Bre),e(Bre,DJe),e(Fg,GJe),e(Fg,qS),e(qS,OJe),e(Fg,VJe),e(y,XJe),e(y,Tg),e(Tg,Ire),e(Ire,zJe),e(Tg,QJe),e(Tg,NS),e(NS,WJe),e(Tg,HJe),e(y,UJe),e(y,Mg),e(Mg,qre),e(qre,JJe),e(Mg,YJe),e(Mg,jS),e(jS,KJe),e(Mg,ZJe),e(y,eYe),e(y,Eg),e(Eg,Nre),e(Nre,oYe),e(Eg,rYe),e(Eg,DS),e(DS,tYe),e(Eg,aYe),e(y,nYe),e(y,Cg),e(Cg,jre),e(jre,sYe),e(Cg,lYe),e(Cg,GS),e(GS,iYe),e(Cg,dYe),e(y,cYe),e(y,wg),e(wg,Dre),e(Dre,fYe),e(wg,mYe),e(wg,OS),e(OS,gYe),e(wg,hYe),e(wr,pYe),M(Ag,wr,null),e(wo,uYe),e(wo,yg),M(EA,yg,null),e(yg,_Ye),e(yg,Gre),e(Gre,bYe),b(f,HIe,_),b(f,Ci,_),e(Ci,Lg),e(Lg,Ore),M(CA,Ore,null),e(Ci,vYe),e(Ci,Vre),e(Vre,FYe),b(f,UIe,_),b(f,Ao,_),M(wA,Ao,null),e(Ao,TYe),e(Ao,AA),e(AA,MYe),e(AA,VS),e(VS,EYe),e(AA,CYe),e(Ao,wYe),e(Ao,yA),e(yA,AYe),e(yA,Xre),e(Xre,yYe),e(yA,LYe),e(Ao,xYe),e(Ao,Ar),M(LA,Ar,null),e(Ar,$Ye),e(Ar,zre),e(zre,kYe),e(Ar,SYe),e(Ar,La),e(La,RYe),e(La,Qre),e(Qre,PYe),e(La,BYe),e(La,Wre),e(Wre,IYe),e(La,qYe),e(La,Hre),e(Hre,NYe),e(La,jYe),e(Ar,DYe),e(Ar,k),e(k,In),e(In,Ure),e(Ure,GYe),e(In,OYe),e(In,XS),e(XS,VYe),e(In,XYe),e(In,zS),e(zS,zYe),e(In,QYe),e(k,WYe),e(k,qn),e(qn,Jre),e(Jre,HYe),e(qn,UYe),e(qn,QS),e(QS,JYe),e(qn,YYe),e(qn,WS),e(WS,KYe),e(qn,ZYe),e(k,eKe),e(k,Nn),e(Nn,Yre),e(Yre,oKe),e(Nn,rKe),e(Nn,HS),e(HS,tKe),e(Nn,aKe),e(Nn,US),e(US,nKe),e(Nn,sKe),e(k,lKe),e(k,xg),e(xg,Kre),e(Kre,iKe),e(xg,dKe),e(xg,JS),e(JS,cKe),e(xg,fKe),e(k,mKe),e(k,jn),e(jn,Zre),e(Zre,gKe),e(jn,hKe),e(jn,YS),e(YS,pKe),e(jn,uKe),e(jn,KS),e(KS,_Ke),e(jn,bKe),e(k,vKe),e(k,$g),e($g,ete),e(ete,FKe),e($g,TKe),e($g,ZS),e(ZS,MKe),e($g,EKe),e(k,CKe),e(k,kg),e(kg,ote),e(ote,wKe),e(kg,AKe),e(kg,eR),e(eR,yKe),e(kg,LKe),e(k,xKe),e(k,Sg),e(Sg,rte),e(rte,$Ke),e(Sg,kKe),e(Sg,oR),e(oR,SKe),e(Sg,RKe),e(k,PKe),e(k,Dn),e(Dn,tte),e(tte,BKe),e(Dn,IKe),e(Dn,rR),e(rR,qKe),e(Dn,NKe),e(Dn,tR),e(tR,jKe),e(Dn,DKe),e(k,GKe),e(k,Gn),e(Gn,ate),e(ate,OKe),e(Gn,VKe),e(Gn,aR),e(aR,XKe),e(Gn,zKe),e(Gn,nR),e(nR,QKe),e(Gn,WKe),e(k,HKe),e(k,On),e(On,nte),e(nte,UKe),e(On,JKe),e(On,sR),e(sR,YKe),e(On,KKe),e(On,lR),e(lR,ZKe),e(On,eZe),e(k,oZe),e(k,Rg),e(Rg,ste),e(ste,rZe),e(Rg,tZe),e(Rg,iR),e(iR,aZe),e(Rg,nZe),e(k,sZe),e(k,Pg),e(Pg,lte),e(lte,lZe),e(Pg,iZe),e(Pg,dR),e(dR,dZe),e(Pg,cZe),e(k,fZe),e(k,Vn),e(Vn,ite),e(ite,mZe),e(Vn,gZe),e(Vn,cR),e(cR,hZe),e(Vn,pZe),e(Vn,fR),e(fR,uZe),e(Vn,_Ze),e(k,bZe),e(k,Bg),e(Bg,dte),e(dte,vZe),e(Bg,FZe),e(Bg,mR),e(mR,TZe),e(Bg,MZe),e(k,EZe),e(k,Xn),e(Xn,cte),e(cte,CZe),e(Xn,wZe),e(Xn,gR),e(gR,AZe),e(Xn,yZe),e(Xn,hR),e(hR,LZe),e(Xn,xZe),e(k,$Ze),e(k,zn),e(zn,fte),e(fte,kZe),e(zn,SZe),e(zn,pR),e(pR,RZe),e(zn,PZe),e(zn,uR),e(uR,BZe),e(zn,IZe),e(k,qZe),e(k,Qn),e(Qn,mte),e(mte,NZe),e(Qn,jZe),e(Qn,_R),e(_R,DZe),e(Qn,GZe),e(Qn,bR),e(bR,OZe),e(Qn,VZe),e(k,XZe),e(k,Ig),e(Ig,gte),e(gte,zZe),e(Ig,QZe),e(Ig,vR),e(vR,WZe),e(Ig,HZe),e(k,UZe),e(k,Wn),e(Wn,hte),e(hte,JZe),e(Wn,YZe),e(Wn,FR),e(FR,KZe),e(Wn,ZZe),e(Wn,TR),e(TR,eeo),e(Wn,oeo),e(k,reo),e(k,Hn),e(Hn,pte),e(pte,teo),e(Hn,aeo),e(Hn,MR),e(MR,neo),e(Hn,seo),e(Hn,ER),e(ER,leo),e(Hn,ieo),e(k,deo),e(k,Un),e(Un,ute),e(ute,ceo),e(Un,feo),e(Un,CR),e(CR,meo),e(Un,geo),e(Un,wR),e(wR,heo),e(Un,peo),e(k,ueo),e(k,Jn),e(Jn,_te),e(_te,_eo),e(Jn,beo),e(Jn,AR),e(AR,veo),e(Jn,Feo),e(Jn,yR),e(yR,Teo),e(Jn,Meo),e(k,Eeo),e(k,Yn),e(Yn,bte),e(bte,Ceo),e(Yn,weo),e(Yn,LR),e(LR,Aeo),e(Yn,yeo),e(Yn,xR),e(xR,Leo),e(Yn,xeo),e(k,$eo),e(k,Kn),e(Kn,vte),e(vte,keo),e(Kn,Seo),e(Kn,$R),e($R,Reo),e(Kn,Peo),e(Kn,kR),e(kR,Beo),e(Kn,Ieo),e(k,qeo),e(k,qg),e(qg,Fte),e(Fte,Neo),e(qg,jeo),e(qg,SR),e(SR,Deo),e(qg,Geo),e(k,Oeo),e(k,Zn),e(Zn,Tte),e(Tte,Veo),e(Zn,Xeo),e(Zn,RR),e(RR,zeo),e(Zn,Qeo),e(Zn,PR),e(PR,Weo),e(Zn,Heo),e(k,Ueo),e(k,Ng),e(Ng,Mte),e(Mte,Jeo),e(Ng,Yeo),e(Ng,BR),e(BR,Keo),e(Ng,Zeo),e(k,eoo),e(k,es),e(es,Ete),e(Ete,ooo),e(es,roo),e(es,IR),e(IR,too),e(es,aoo),e(es,qR),e(qR,noo),e(es,soo),e(k,loo),e(k,os),e(os,Cte),e(Cte,ioo),e(os,doo),e(os,NR),e(NR,coo),e(os,foo),e(os,jR),e(jR,moo),e(os,goo),e(k,hoo),e(k,rs),e(rs,wte),e(wte,poo),e(rs,uoo),e(rs,DR),e(DR,_oo),e(rs,boo),e(rs,GR),e(GR,voo),e(rs,Foo),e(k,Too),e(k,ts),e(ts,Ate),e(Ate,Moo),e(ts,Eoo),e(ts,OR),e(OR,Coo),e(ts,woo),e(ts,VR),e(VR,Aoo),e(ts,yoo),e(k,Loo),e(k,as),e(as,yte),e(yte,xoo),e(as,$oo),e(as,XR),e(XR,koo),e(as,Soo),e(as,zR),e(zR,Roo),e(as,Poo),e(k,Boo),e(k,jg),e(jg,Lte),e(Lte,Ioo),e(jg,qoo),e(jg,QR),e(QR,Noo),e(jg,joo),e(k,Doo),e(k,ns),e(ns,xte),e(xte,Goo),e(ns,Ooo),e(ns,WR),e(WR,Voo),e(ns,Xoo),e(ns,HR),e(HR,zoo),e(ns,Qoo),e(k,Woo),e(k,ss),e(ss,$te),e($te,Hoo),e(ss,Uoo),e(ss,UR),e(UR,Joo),e(ss,Yoo),e(ss,JR),e(JR,Koo),e(ss,Zoo),e(k,ero),e(k,ls),e(ls,kte),e(kte,oro),e(ls,rro),e(ls,YR),e(YR,tro),e(ls,aro),e(ls,KR),e(KR,nro),e(ls,sro),e(k,lro),e(k,is),e(is,Ste),e(Ste,iro),e(is,dro),e(is,ZR),e(ZR,cro),e(is,fro),e(is,eP),e(eP,mro),e(is,gro),e(k,hro),e(k,ds),e(ds,Rte),e(Rte,pro),e(ds,uro),e(ds,oP),e(oP,_ro),e(ds,bro),e(ds,rP),e(rP,vro),e(ds,Fro),e(k,Tro),e(k,cs),e(cs,Pte),e(Pte,Mro),e(cs,Ero),e(cs,tP),e(tP,Cro),e(cs,wro),e(cs,aP),e(aP,Aro),e(cs,yro),e(k,Lro),e(k,Dg),e(Dg,Bte),e(Bte,xro),e(Dg,$ro),e(Dg,nP),e(nP,kro),e(Dg,Sro),e(k,Rro),e(k,fs),e(fs,Ite),e(Ite,Pro),e(fs,Bro),e(fs,sP),e(sP,Iro),e(fs,qro),e(fs,lP),e(lP,Nro),e(fs,jro),e(k,Dro),e(k,Gg),e(Gg,qte),e(qte,Gro),e(Gg,Oro),e(Gg,iP),e(iP,Vro),e(Gg,Xro),e(k,zro),e(k,Og),e(Og,Nte),e(Nte,Qro),e(Og,Wro),e(Og,dP),e(dP,Hro),e(Og,Uro),e(k,Jro),e(k,ms),e(ms,jte),e(jte,Yro),e(ms,Kro),e(ms,cP),e(cP,Zro),e(ms,eto),e(ms,fP),e(fP,oto),e(ms,rto),e(k,tto),e(k,gs),e(gs,Dte),e(Dte,ato),e(gs,nto),e(gs,mP),e(mP,sto),e(gs,lto),e(gs,gP),e(gP,ito),e(gs,dto),e(k,cto),e(k,hs),e(hs,Gte),e(Gte,fto),e(hs,mto),e(hs,hP),e(hP,gto),e(hs,hto),e(hs,pP),e(pP,pto),e(hs,uto),e(k,_to),e(k,Vg),e(Vg,Ote),e(Ote,bto),e(Vg,vto),e(Vg,uP),e(uP,Fto),e(Vg,Tto),e(k,Mto),e(k,ps),e(ps,Vte),e(Vte,Eto),e(ps,Cto),e(ps,_P),e(_P,wto),e(ps,Ato),e(ps,bP),e(bP,yto),e(ps,Lto),e(k,xto),e(k,us),e(us,Xte),e(Xte,$to),e(us,kto),e(us,vP),e(vP,Sto),e(us,Rto),e(us,FP),e(FP,Pto),e(us,Bto),e(k,Ito),e(k,_s),e(_s,zte),e(zte,qto),e(_s,Nto),e(_s,TP),e(TP,jto),e(_s,Dto),e(_s,MP),e(MP,Gto),e(_s,Oto),e(k,Vto),e(k,bs),e(bs,Qte),e(Qte,Xto),e(bs,zto),e(bs,EP),e(EP,Qto),e(bs,Wto),e(bs,CP),e(CP,Hto),e(bs,Uto),e(k,Jto),e(k,vs),e(vs,Wte),e(Wte,Yto),e(vs,Kto),e(vs,wP),e(wP,Zto),e(vs,eao),e(vs,AP),e(AP,oao),e(vs,rao),e(k,tao),e(k,Xg),e(Xg,Hte),e(Hte,aao),e(Xg,nao),e(Xg,yP),e(yP,sao),e(Xg,lao),e(k,iao),e(k,Fs),e(Fs,Ute),e(Ute,dao),e(Fs,cao),e(Fs,LP),e(LP,fao),e(Fs,mao),e(Fs,xP),e(xP,gao),e(Fs,hao),e(k,pao),e(k,zg),e(zg,Jte),e(Jte,uao),e(zg,_ao),e(zg,$P),e($P,bao),e(zg,vao),e(k,Fao),e(k,Qg),e(Qg,Yte),e(Yte,Tao),e(Qg,Mao),e(Qg,kP),e(kP,Eao),e(Qg,Cao),e(k,wao),e(k,Wg),e(Wg,Kte),e(Kte,Aao),e(Wg,yao),e(Wg,SP),e(SP,Lao),e(Wg,xao),e(k,$ao),e(k,Hg),e(Hg,Zte),e(Zte,kao),e(Hg,Sao),e(Hg,RP),e(RP,Rao),e(Hg,Pao),e(k,Bao),e(k,Ts),e(Ts,eae),e(eae,Iao),e(Ts,qao),e(Ts,PP),e(PP,Nao),e(Ts,jao),e(Ts,BP),e(BP,Dao),e(Ts,Gao),e(k,Oao),e(k,Ug),e(Ug,oae),e(oae,Vao),e(Ug,Xao),e(Ug,IP),e(IP,zao),e(Ug,Qao),e(k,Wao),e(k,Ms),e(Ms,rae),e(rae,Hao),e(Ms,Uao),e(Ms,qP),e(qP,Jao),e(Ms,Yao),e(Ms,NP),e(NP,Kao),e(Ms,Zao),e(k,eno),e(k,Es),e(Es,tae),e(tae,ono),e(Es,rno),e(Es,jP),e(jP,tno),e(Es,ano),e(Es,DP),e(DP,nno),e(Es,sno),e(k,lno),e(k,Cs),e(Cs,aae),e(aae,ino),e(Cs,dno),e(Cs,GP),e(GP,cno),e(Cs,fno),e(Cs,OP),e(OP,mno),e(Cs,gno),e(k,hno),e(k,ws),e(ws,nae),e(nae,pno),e(ws,uno),e(ws,VP),e(VP,_no),e(ws,bno),e(ws,XP),e(XP,vno),e(ws,Fno),e(k,Tno),e(k,As),e(As,sae),e(sae,Mno),e(As,Eno),e(As,zP),e(zP,Cno),e(As,wno),e(As,QP),e(QP,Ano),e(As,yno),e(k,Lno),e(k,ys),e(ys,lae),e(lae,xno),e(ys,$no),e(ys,WP),e(WP,kno),e(ys,Sno),e(ys,HP),e(HP,Rno),e(ys,Pno),e(k,Bno),e(k,Jg),e(Jg,iae),e(iae,Ino),e(Jg,qno),e(Jg,UP),e(UP,Nno),e(Jg,jno),e(k,Dno),e(k,Yg),e(Yg,dae),e(dae,Gno),e(Yg,Ono),e(Yg,JP),e(JP,Vno),e(Yg,Xno),e(k,zno),e(k,Ls),e(Ls,cae),e(cae,Qno),e(Ls,Wno),e(Ls,YP),e(YP,Hno),e(Ls,Uno),e(Ls,KP),e(KP,Jno),e(Ls,Yno),e(k,Kno),e(k,xs),e(xs,fae),e(fae,Zno),e(xs,eso),e(xs,ZP),e(ZP,oso),e(xs,rso),e(xs,eB),e(eB,tso),e(xs,aso),e(k,nso),e(k,$s),e($s,mae),e(mae,sso),e($s,lso),e($s,oB),e(oB,iso),e($s,dso),e($s,rB),e(rB,cso),e($s,fso),e(k,mso),e(k,Kg),e(Kg,gae),e(gae,gso),e(Kg,hso),e(Kg,tB),e(tB,pso),e(Kg,uso),e(k,_so),e(k,Zg),e(Zg,hae),e(hae,bso),e(Zg,vso),e(Zg,aB),e(aB,Fso),e(Zg,Tso),e(k,Mso),e(k,eh),e(eh,pae),e(pae,Eso),e(eh,Cso),e(eh,nB),e(nB,wso),e(eh,Aso),e(k,yso),e(k,ks),e(ks,uae),e(uae,Lso),e(ks,xso),e(ks,sB),e(sB,$so),e(ks,kso),e(ks,lB),e(lB,Sso),e(ks,Rso),e(k,Pso),e(k,Ss),e(Ss,_ae),e(_ae,Bso),e(Ss,Iso),e(Ss,iB),e(iB,qso),e(Ss,Nso),e(Ss,dB),e(dB,jso),e(Ss,Dso),e(k,Gso),e(k,oh),e(oh,bae),e(bae,Oso),e(oh,Vso),e(oh,cB),e(cB,Xso),e(oh,zso),e(k,Qso),e(k,rh),e(rh,vae),e(vae,Wso),e(rh,Hso),e(rh,fB),e(fB,Uso),e(rh,Jso),e(k,Yso),e(k,Rs),e(Rs,Fae),e(Fae,Kso),e(Rs,Zso),e(Rs,mB),e(mB,elo),e(Rs,olo),e(Rs,gB),e(gB,rlo),e(Rs,tlo),e(k,alo),e(k,th),e(th,Tae),e(Tae,nlo),e(th,slo),e(th,hB),e(hB,llo),e(th,ilo),e(k,dlo),e(k,ah),e(ah,Mae),e(Mae,clo),e(ah,flo),e(ah,pB),e(pB,mlo),e(ah,glo),e(k,hlo),e(k,Ps),e(Ps,Eae),e(Eae,plo),e(Ps,ulo),e(Ps,uB),e(uB,_lo),e(Ps,blo),e(Ps,_B),e(_B,vlo),e(Ps,Flo),e(k,Tlo),e(k,Bs),e(Bs,Cae),e(Cae,Mlo),e(Bs,Elo),e(Bs,bB),e(bB,Clo),e(Bs,wlo),e(Bs,vB),e(vB,Alo),e(Bs,ylo),e(k,Llo),e(k,Is),e(Is,wae),e(wae,xlo),e(Is,$lo),e(Is,FB),e(FB,klo),e(Is,Slo),e(Is,TB),e(TB,Rlo),e(Is,Plo),e(k,Blo),e(k,qs),e(qs,Aae),e(Aae,Ilo),e(qs,qlo),e(qs,MB),e(MB,Nlo),e(qs,jlo),e(qs,EB),e(EB,Dlo),e(qs,Glo),e(Ar,Olo),M(nh,Ar,null),e(Ao,Vlo),e(Ao,sh),M(xA,sh,null),e(sh,Xlo),e(sh,yae),e(yae,zlo),b(f,JIe,_),b(f,wi,_),e(wi,lh),e(lh,Lae),M($A,Lae,null),e(wi,Qlo),e(wi,xae),e(xae,Wlo),b(f,YIe,_),b(f,yo,_),M(kA,yo,null),e(yo,Hlo),e(yo,SA),e(SA,Ulo),e(SA,CB),e(CB,Jlo),e(SA,Ylo),e(yo,Klo),e(yo,RA),e(RA,Zlo),e(RA,$ae),e($ae,eio),e(RA,oio),e(yo,rio),e(yo,Qe),M(PA,Qe,null),e(Qe,tio),e(Qe,kae),e(kae,aio),e(Qe,nio),e(Qe,xa),e(xa,sio),e(xa,Sae),e(Sae,lio),e(xa,iio),e(xa,Rae),e(Rae,dio),e(xa,cio),e(xa,Pae),e(Pae,fio),e(xa,mio),e(Qe,gio),e(Qe,ee),e(ee,ih),e(ih,Bae),e(Bae,hio),e(ih,pio),e(ih,wB),e(wB,uio),e(ih,_io),e(ee,bio),e(ee,dh),e(dh,Iae),e(Iae,vio),e(dh,Fio),e(dh,AB),e(AB,Tio),e(dh,Mio),e(ee,Eio),e(ee,ch),e(ch,qae),e(qae,Cio),e(ch,wio),e(ch,yB),e(yB,Aio),e(ch,yio),e(ee,Lio),e(ee,fh),e(fh,Nae),e(Nae,xio),e(fh,$io),e(fh,LB),e(LB,kio),e(fh,Sio),e(ee,Rio),e(ee,mh),e(mh,jae),e(jae,Pio),e(mh,Bio),e(mh,xB),e(xB,Iio),e(mh,qio),e(ee,Nio),e(ee,gh),e(gh,Dae),e(Dae,jio),e(gh,Dio),e(gh,$B),e($B,Gio),e(gh,Oio),e(ee,Vio),e(ee,hh),e(hh,Gae),e(Gae,Xio),e(hh,zio),e(hh,kB),e(kB,Qio),e(hh,Wio),e(ee,Hio),e(ee,ph),e(ph,Oae),e(Oae,Uio),e(ph,Jio),e(ph,SB),e(SB,Yio),e(ph,Kio),e(ee,Zio),e(ee,uh),e(uh,Vae),e(Vae,edo),e(uh,odo),e(uh,RB),e(RB,rdo),e(uh,tdo),e(ee,ado),e(ee,_h),e(_h,Xae),e(Xae,ndo),e(_h,sdo),e(_h,PB),e(PB,ldo),e(_h,ido),e(ee,ddo),e(ee,bh),e(bh,zae),e(zae,cdo),e(bh,fdo),e(bh,BB),e(BB,mdo),e(bh,gdo),e(ee,hdo),e(ee,vh),e(vh,Qae),e(Qae,pdo),e(vh,udo),e(vh,IB),e(IB,_do),e(vh,bdo),e(ee,vdo),e(ee,Fh),e(Fh,Wae),e(Wae,Fdo),e(Fh,Tdo),e(Fh,qB),e(qB,Mdo),e(Fh,Edo),e(ee,Cdo),e(ee,Th),e(Th,Hae),e(Hae,wdo),e(Th,Ado),e(Th,NB),e(NB,ydo),e(Th,Ldo),e(ee,xdo),e(ee,Mh),e(Mh,Uae),e(Uae,$do),e(Mh,kdo),e(Mh,jB),e(jB,Sdo),e(Mh,Rdo),e(ee,Pdo),e(ee,Eh),e(Eh,Jae),e(Jae,Bdo),e(Eh,Ido),e(Eh,DB),e(DB,qdo),e(Eh,Ndo),e(ee,jdo),e(ee,Ch),e(Ch,Yae),e(Yae,Ddo),e(Ch,Gdo),e(Ch,GB),e(GB,Odo),e(Ch,Vdo),e(ee,Xdo),e(ee,wh),e(wh,Kae),e(Kae,zdo),e(wh,Qdo),e(wh,OB),e(OB,Wdo),e(wh,Hdo),e(ee,Udo),e(ee,Ah),e(Ah,Zae),e(Zae,Jdo),e(Ah,Ydo),e(Ah,VB),e(VB,Kdo),e(Ah,Zdo),e(ee,eco),e(ee,yh),e(yh,ene),e(ene,oco),e(yh,rco),e(yh,XB),e(XB,tco),e(yh,aco),e(ee,nco),e(ee,Lh),e(Lh,one),e(one,sco),e(Lh,lco),e(Lh,zB),e(zB,ico),e(Lh,dco),e(ee,cco),e(ee,xh),e(xh,rne),e(rne,fco),e(xh,mco),e(xh,QB),e(QB,gco),e(xh,hco),e(ee,pco),e(ee,$h),e($h,tne),e(tne,uco),e($h,_co),e($h,WB),e(WB,bco),e($h,vco),e(ee,Fco),e(ee,kh),e(kh,ane),e(ane,Tco),e(kh,Mco),e(kh,HB),e(HB,Eco),e(kh,Cco),e(ee,wco),e(ee,Sh),e(Sh,nne),e(nne,Aco),e(Sh,yco),e(Sh,UB),e(UB,Lco),e(Sh,xco),e(ee,$co),e(ee,Rh),e(Rh,sne),e(sne,kco),e(Rh,Sco),e(Rh,JB),e(JB,Rco),e(Rh,Pco),e(Qe,Bco),M(Ph,Qe,null),e(Qe,Ico),M(Bh,Qe,null),e(yo,qco),e(yo,Ih),M(BA,Ih,null),e(Ih,Nco),e(Ih,lne),e(lne,jco),b(f,KIe,_),b(f,Ai,_),e(Ai,qh),e(qh,ine),M(IA,ine,null),e(Ai,Dco),e(Ai,dne),e(dne,Gco),b(f,ZIe,_),b(f,Lo,_),M(qA,Lo,null),e(Lo,Oco),e(Lo,NA),e(NA,Vco),e(NA,YB),e(YB,Xco),e(NA,zco),e(Lo,Qco),e(Lo,jA),e(jA,Wco),e(jA,cne),e(cne,Hco),e(jA,Uco),e(Lo,Jco),e(Lo,We),M(DA,We,null),e(We,Yco),e(We,fne),e(fne,Kco),e(We,Zco),e(We,yi),e(yi,efo),e(yi,mne),e(mne,ofo),e(yi,rfo),e(yi,gne),e(gne,tfo),e(yi,afo),e(We,nfo),e(We,be),e(be,Nh),e(Nh,hne),e(hne,sfo),e(Nh,lfo),e(Nh,KB),e(KB,ifo),e(Nh,dfo),e(be,cfo),e(be,jh),e(jh,pne),e(pne,ffo),e(jh,mfo),e(jh,une),e(une,gfo),e(jh,hfo),e(be,pfo),e(be,Dh),e(Dh,_ne),e(_ne,ufo),e(Dh,_fo),e(Dh,ZB),e(ZB,bfo),e(Dh,vfo),e(be,Ffo),e(be,Gh),e(Gh,bne),e(bne,Tfo),e(Gh,Mfo),e(Gh,eI),e(eI,Efo),e(Gh,Cfo),e(be,wfo),e(be,Oh),e(Oh,vne),e(vne,Afo),e(Oh,yfo),e(Oh,oI),e(oI,Lfo),e(Oh,xfo),e(be,$fo),e(be,Vh),e(Vh,Fne),e(Fne,kfo),e(Vh,Sfo),e(Vh,rI),e(rI,Rfo),e(Vh,Pfo),e(be,Bfo),e(be,Xh),e(Xh,Tne),e(Tne,Ifo),e(Xh,qfo),e(Xh,tI),e(tI,Nfo),e(Xh,jfo),e(be,Dfo),e(be,zh),e(zh,Mne),e(Mne,Gfo),e(zh,Ofo),e(zh,aI),e(aI,Vfo),e(zh,Xfo),e(be,zfo),e(be,Qh),e(Qh,Ene),e(Ene,Qfo),e(Qh,Wfo),e(Qh,nI),e(nI,Hfo),e(Qh,Ufo),e(be,Jfo),e(be,Wh),e(Wh,Cne),e(Cne,Yfo),e(Wh,Kfo),e(Wh,sI),e(sI,Zfo),e(Wh,emo),e(be,omo),e(be,Hh),e(Hh,wne),e(wne,rmo),e(Hh,tmo),e(Hh,lI),e(lI,amo),e(Hh,nmo),e(be,smo),e(be,Uh),e(Uh,Ane),e(Ane,lmo),e(Uh,imo),e(Uh,iI),e(iI,dmo),e(Uh,cmo),e(be,fmo),e(be,Jh),e(Jh,yne),e(yne,mmo),e(Jh,gmo),e(Jh,dI),e(dI,hmo),e(Jh,pmo),e(be,umo),e(be,Yh),e(Yh,Lne),e(Lne,_mo),e(Yh,bmo),e(Yh,cI),e(cI,vmo),e(Yh,Fmo),e(be,Tmo),e(be,Kh),e(Kh,xne),e(xne,Mmo),e(Kh,Emo),e(Kh,fI),e(fI,Cmo),e(Kh,wmo),e(We,Amo),M(Zh,We,null),e(We,ymo),M(ep,We,null),e(Lo,Lmo),e(Lo,op),M(GA,op,null),e(op,xmo),e(op,$ne),e($ne,$mo),b(f,eqe,_),b(f,Li,_),e(Li,rp),e(rp,kne),M(OA,kne,null),e(Li,kmo),e(Li,Sne),e(Sne,Smo),b(f,oqe,_),b(f,xo,_),M(VA,xo,null),e(xo,Rmo),e(xo,xi),e(xi,Pmo),e(xi,mI),e(mI,Bmo),e(xi,Imo),e(xi,gI),e(gI,qmo),e(xi,Nmo),e(xo,jmo),e(xo,XA),e(XA,Dmo),e(XA,Rne),e(Rne,Gmo),e(XA,Omo),e(xo,Vmo),e(xo,tt),M(zA,tt,null),e(tt,Xmo),e(tt,Pne),e(Pne,zmo),e(tt,Qmo),e(tt,$i),e($i,Wmo),e($i,Bne),e(Bne,Hmo),e($i,Umo),e($i,hI),e(hI,Jmo),e($i,Ymo),e(tt,Kmo),M(tp,tt,null),e(xo,Zmo),e(xo,He),M(QA,He,null),e(He,ego),e(He,Ine),e(Ine,ogo),e(He,rgo),e(He,$a),e($a,tgo),e($a,qne),e(qne,ago),e($a,ngo),e($a,Nne),e(Nne,sgo),e($a,lgo),e($a,jne),e(jne,igo),e($a,dgo),e(He,cgo),e(He,x),e(x,ap),e(ap,Dne),e(Dne,fgo),e(ap,mgo),e(ap,pI),e(pI,ggo),e(ap,hgo),e(x,pgo),e(x,np),e(np,Gne),e(Gne,ugo),e(np,_go),e(np,uI),e(uI,bgo),e(np,vgo),e(x,Fgo),e(x,sp),e(sp,One),e(One,Tgo),e(sp,Mgo),e(sp,_I),e(_I,Ego),e(sp,Cgo),e(x,wgo),e(x,lp),e(lp,Vne),e(Vne,Ago),e(lp,ygo),e(lp,bI),e(bI,Lgo),e(lp,xgo),e(x,$go),e(x,ip),e(ip,Xne),e(Xne,kgo),e(ip,Sgo),e(ip,vI),e(vI,Rgo),e(ip,Pgo),e(x,Bgo),e(x,dp),e(dp,zne),e(zne,Igo),e(dp,qgo),e(dp,FI),e(FI,Ngo),e(dp,jgo),e(x,Dgo),e(x,cp),e(cp,Qne),e(Qne,Ggo),e(cp,Ogo),e(cp,TI),e(TI,Vgo),e(cp,Xgo),e(x,zgo),e(x,fp),e(fp,Wne),e(Wne,Qgo),e(fp,Wgo),e(fp,MI),e(MI,Hgo),e(fp,Ugo),e(x,Jgo),e(x,mp),e(mp,Hne),e(Hne,Ygo),e(mp,Kgo),e(mp,EI),e(EI,Zgo),e(mp,eho),e(x,oho),e(x,gp),e(gp,Une),e(Une,rho),e(gp,tho),e(gp,CI),e(CI,aho),e(gp,nho),e(x,sho),e(x,hp),e(hp,Jne),e(Jne,lho),e(hp,iho),e(hp,wI),e(wI,dho),e(hp,cho),e(x,fho),e(x,pp),e(pp,Yne),e(Yne,mho),e(pp,gho),e(pp,AI),e(AI,hho),e(pp,pho),e(x,uho),e(x,up),e(up,Kne),e(Kne,_ho),e(up,bho),e(up,yI),e(yI,vho),e(up,Fho),e(x,Tho),e(x,_p),e(_p,Zne),e(Zne,Mho),e(_p,Eho),e(_p,LI),e(LI,Cho),e(_p,who),e(x,Aho),e(x,bp),e(bp,ese),e(ese,yho),e(bp,Lho),e(bp,xI),e(xI,xho),e(bp,$ho),e(x,kho),e(x,vp),e(vp,ose),e(ose,Sho),e(vp,Rho),e(vp,$I),e($I,Pho),e(vp,Bho),e(x,Iho),e(x,Fp),e(Fp,rse),e(rse,qho),e(Fp,Nho),e(Fp,kI),e(kI,jho),e(Fp,Dho),e(x,Gho),e(x,Tp),e(Tp,tse),e(tse,Oho),e(Tp,Vho),e(Tp,SI),e(SI,Xho),e(Tp,zho),e(x,Qho),e(x,Mp),e(Mp,ase),e(ase,Who),e(Mp,Hho),e(Mp,RI),e(RI,Uho),e(Mp,Jho),e(x,Yho),e(x,Ep),e(Ep,nse),e(nse,Kho),e(Ep,Zho),e(Ep,PI),e(PI,epo),e(Ep,opo),e(x,rpo),e(x,Cp),e(Cp,sse),e(sse,tpo),e(Cp,apo),e(Cp,BI),e(BI,npo),e(Cp,spo),e(x,lpo),e(x,wp),e(wp,lse),e(lse,ipo),e(wp,dpo),e(wp,II),e(II,cpo),e(wp,fpo),e(x,mpo),e(x,Ap),e(Ap,ise),e(ise,gpo),e(Ap,hpo),e(Ap,qI),e(qI,ppo),e(Ap,upo),e(x,_po),e(x,yp),e(yp,dse),e(dse,bpo),e(yp,vpo),e(yp,NI),e(NI,Fpo),e(yp,Tpo),e(x,Mpo),e(x,Lp),e(Lp,cse),e(cse,Epo),e(Lp,Cpo),e(Lp,jI),e(jI,wpo),e(Lp,Apo),e(x,ypo),e(x,xp),e(xp,fse),e(fse,Lpo),e(xp,xpo),e(xp,DI),e(DI,$po),e(xp,kpo),e(x,Spo),e(x,$p),e($p,mse),e(mse,Rpo),e($p,Ppo),e($p,GI),e(GI,Bpo),e($p,Ipo),e(x,qpo),e(x,kp),e(kp,gse),e(gse,Npo),e(kp,jpo),e(kp,OI),e(OI,Dpo),e(kp,Gpo),e(x,Opo),e(x,Sp),e(Sp,hse),e(hse,Vpo),e(Sp,Xpo),e(Sp,VI),e(VI,zpo),e(Sp,Qpo),e(x,Wpo),e(x,Rp),e(Rp,pse),e(pse,Hpo),e(Rp,Upo),e(Rp,XI),e(XI,Jpo),e(Rp,Ypo),e(x,Kpo),e(x,Pp),e(Pp,use),e(use,Zpo),e(Pp,euo),e(Pp,zI),e(zI,ouo),e(Pp,ruo),e(x,tuo),e(x,Ns),e(Ns,_se),e(_se,auo),e(Ns,nuo),e(Ns,QI),e(QI,suo),e(Ns,luo),e(Ns,WI),e(WI,iuo),e(Ns,duo),e(x,cuo),e(x,Bp),e(Bp,bse),e(bse,fuo),e(Bp,muo),e(Bp,HI),e(HI,guo),e(Bp,huo),e(x,puo),e(x,Ip),e(Ip,vse),e(vse,uuo),e(Ip,_uo),e(Ip,UI),e(UI,buo),e(Ip,vuo),e(x,Fuo),e(x,qp),e(qp,Fse),e(Fse,Tuo),e(qp,Muo),e(qp,JI),e(JI,Euo),e(qp,Cuo),e(x,wuo),e(x,Np),e(Np,Tse),e(Tse,Auo),e(Np,yuo),e(Np,YI),e(YI,Luo),e(Np,xuo),e(x,$uo),e(x,jp),e(jp,Mse),e(Mse,kuo),e(jp,Suo),e(jp,KI),e(KI,Ruo),e(jp,Puo),e(x,Buo),e(x,Dp),e(Dp,Ese),e(Ese,Iuo),e(Dp,quo),e(Dp,ZI),e(ZI,Nuo),e(Dp,juo),e(x,Duo),e(x,Gp),e(Gp,Cse),e(Cse,Guo),e(Gp,Ouo),e(Gp,eq),e(eq,Vuo),e(Gp,Xuo),e(x,zuo),e(x,Op),e(Op,wse),e(wse,Quo),e(Op,Wuo),e(Op,oq),e(oq,Huo),e(Op,Uuo),e(x,Juo),e(x,Vp),e(Vp,Ase),e(Ase,Yuo),e(Vp,Kuo),e(Vp,rq),e(rq,Zuo),e(Vp,e_o),e(x,o_o),e(x,Xp),e(Xp,yse),e(yse,r_o),e(Xp,t_o),e(Xp,tq),e(tq,a_o),e(Xp,n_o),e(x,s_o),e(x,zp),e(zp,Lse),e(Lse,l_o),e(zp,i_o),e(zp,aq),e(aq,d_o),e(zp,c_o),e(x,f_o),e(x,Qp),e(Qp,xse),e(xse,m_o),e(Qp,g_o),e(Qp,nq),e(nq,h_o),e(Qp,p_o),e(x,u_o),e(x,Wp),e(Wp,$se),e($se,__o),e(Wp,b_o),e(Wp,sq),e(sq,v_o),e(Wp,F_o),e(x,T_o),e(x,Hp),e(Hp,kse),e(kse,M_o),e(Hp,E_o),e(Hp,lq),e(lq,C_o),e(Hp,w_o),e(x,A_o),e(x,Up),e(Up,Sse),e(Sse,y_o),e(Up,L_o),e(Up,iq),e(iq,x_o),e(Up,$_o),e(x,k_o),e(x,Jp),e(Jp,Rse),e(Rse,S_o),e(Jp,R_o),e(Jp,dq),e(dq,P_o),e(Jp,B_o),e(x,I_o),e(x,Yp),e(Yp,Pse),e(Pse,q_o),e(Yp,N_o),e(Yp,cq),e(cq,j_o),e(Yp,D_o),e(x,G_o),e(x,Kp),e(Kp,Bse),e(Bse,O_o),e(Kp,V_o),e(Kp,fq),e(fq,X_o),e(Kp,z_o),e(x,Q_o),e(x,Zp),e(Zp,Ise),e(Ise,W_o),e(Zp,H_o),e(Zp,mq),e(mq,U_o),e(Zp,J_o),e(x,Y_o),e(x,eu),e(eu,qse),e(qse,K_o),e(eu,Z_o),e(eu,gq),e(gq,e2o),e(eu,o2o),e(x,r2o),e(x,ou),e(ou,Nse),e(Nse,t2o),e(ou,a2o),e(ou,hq),e(hq,n2o),e(ou,s2o),e(x,l2o),e(x,ru),e(ru,jse),e(jse,i2o),e(ru,d2o),e(ru,pq),e(pq,c2o),e(ru,f2o),e(x,m2o),e(x,tu),e(tu,Dse),e(Dse,g2o),e(tu,h2o),e(tu,uq),e(uq,p2o),e(tu,u2o),e(x,_2o),e(x,au),e(au,Gse),e(Gse,b2o),e(au,v2o),e(au,_q),e(_q,F2o),e(au,T2o),e(x,M2o),e(x,nu),e(nu,Ose),e(Ose,E2o),e(nu,C2o),e(nu,bq),e(bq,w2o),e(nu,A2o),e(x,y2o),e(x,su),e(su,Vse),e(Vse,L2o),e(su,x2o),e(su,vq),e(vq,$2o),e(su,k2o),e(x,S2o),e(x,lu),e(lu,Xse),e(Xse,R2o),e(lu,P2o),e(lu,Fq),e(Fq,B2o),e(lu,I2o),e(x,q2o),e(x,iu),e(iu,zse),e(zse,N2o),e(iu,j2o),e(iu,Tq),e(Tq,D2o),e(iu,G2o),e(x,O2o),e(x,du),e(du,Qse),e(Qse,V2o),e(du,X2o),e(du,Mq),e(Mq,z2o),e(du,Q2o),e(x,W2o),e(x,cu),e(cu,Wse),e(Wse,H2o),e(cu,U2o),e(cu,Eq),e(Eq,J2o),e(cu,Y2o),e(x,K2o),e(x,fu),e(fu,Hse),e(Hse,Z2o),e(fu,e1o),e(fu,Cq),e(Cq,o1o),e(fu,r1o),e(x,t1o),e(x,mu),e(mu,Use),e(Use,a1o),e(mu,n1o),e(mu,wq),e(wq,s1o),e(mu,l1o),e(x,i1o),e(x,gu),e(gu,Jse),e(Jse,d1o),e(gu,c1o),e(gu,Aq),e(Aq,f1o),e(gu,m1o),e(x,g1o),e(x,hu),e(hu,Yse),e(Yse,h1o),e(hu,p1o),e(hu,yq),e(yq,u1o),e(hu,_1o),e(x,b1o),e(x,pu),e(pu,Kse),e(Kse,v1o),e(pu,F1o),e(pu,Lq),e(Lq,T1o),e(pu,M1o),e(x,E1o),e(x,uu),e(uu,Zse),e(Zse,C1o),e(uu,w1o),e(uu,xq),e(xq,A1o),e(uu,y1o),e(x,L1o),e(x,_u),e(_u,ele),e(ele,x1o),e(_u,$1o),e(_u,$q),e($q,k1o),e(_u,S1o),e(x,R1o),e(x,bu),e(bu,ole),e(ole,P1o),e(bu,B1o),e(bu,kq),e(kq,I1o),e(bu,q1o),e(x,N1o),e(x,vu),e(vu,rle),e(rle,j1o),e(vu,D1o),e(vu,Sq),e(Sq,G1o),e(vu,O1o),e(x,V1o),e(x,Fu),e(Fu,tle),e(tle,X1o),e(Fu,z1o),e(Fu,Rq),e(Rq,Q1o),e(Fu,W1o),e(x,H1o),e(x,Tu),e(Tu,ale),e(ale,U1o),e(Tu,J1o),e(Tu,Pq),e(Pq,Y1o),e(Tu,K1o),e(x,Z1o),e(x,Mu),e(Mu,nle),e(nle,ebo),e(Mu,obo),e(Mu,Bq),e(Bq,rbo),e(Mu,tbo),e(x,abo),e(x,Eu),e(Eu,sle),e(sle,nbo),e(Eu,sbo),e(Eu,Iq),e(Iq,lbo),e(Eu,ibo),e(x,dbo),e(x,Cu),e(Cu,lle),e(lle,cbo),e(Cu,fbo),e(Cu,qq),e(qq,mbo),e(Cu,gbo),e(x,hbo),e(x,wu),e(wu,ile),e(ile,pbo),e(wu,ubo),e(wu,Nq),e(Nq,_bo),e(wu,bbo),e(x,vbo),e(x,Au),e(Au,dle),e(dle,Fbo),e(Au,Tbo),e(Au,jq),e(jq,Mbo),e(Au,Ebo),e(x,Cbo),e(x,yu),e(yu,cle),e(cle,wbo),e(yu,Abo),e(yu,Dq),e(Dq,ybo),e(yu,Lbo),e(x,xbo),e(x,Lu),e(Lu,fle),e(fle,$bo),e(Lu,kbo),e(Lu,Gq),e(Gq,Sbo),e(Lu,Rbo),e(x,Pbo),e(x,xu),e(xu,mle),e(mle,Bbo),e(xu,Ibo),e(xu,Oq),e(Oq,qbo),e(xu,Nbo),e(x,jbo),e(x,$u),e($u,gle),e(gle,Dbo),e($u,Gbo),e($u,Vq),e(Vq,Obo),e($u,Vbo),e(x,Xbo),e(x,ku),e(ku,hle),e(hle,zbo),e(ku,Qbo),e(ku,Xq),e(Xq,Wbo),e(ku,Hbo),e(x,Ubo),e(x,Su),e(Su,ple),e(ple,Jbo),e(Su,Ybo),e(Su,zq),e(zq,Kbo),e(Su,Zbo),e(x,evo),e(x,Ru),e(Ru,ule),e(ule,ovo),e(Ru,rvo),e(Ru,Qq),e(Qq,tvo),e(Ru,avo),e(x,nvo),e(x,Pu),e(Pu,_le),e(_le,svo),e(Pu,lvo),e(Pu,Wq),e(Wq,ivo),e(Pu,dvo),e(x,cvo),e(x,Bu),e(Bu,ble),e(ble,fvo),e(Bu,mvo),e(Bu,Hq),e(Hq,gvo),e(Bu,hvo),e(x,pvo),e(x,Iu),e(Iu,vle),e(vle,uvo),e(Iu,_vo),e(Iu,Uq),e(Uq,bvo),e(Iu,vvo),e(x,Fvo),e(x,qu),e(qu,Fle),e(Fle,Tvo),e(qu,Mvo),e(qu,Jq),e(Jq,Evo),e(qu,Cvo),e(x,wvo),e(x,Nu),e(Nu,Tle),e(Tle,Avo),e(Nu,yvo),e(Nu,Yq),e(Yq,Lvo),e(Nu,xvo),e(x,$vo),e(x,ju),e(ju,Mle),e(Mle,kvo),e(ju,Svo),e(ju,Kq),e(Kq,Rvo),e(ju,Pvo),e(x,Bvo),e(x,Du),e(Du,Ele),e(Ele,Ivo),e(Du,qvo),e(Du,Zq),e(Zq,Nvo),e(Du,jvo),e(x,Dvo),e(x,Gu),e(Gu,Cle),e(Cle,Gvo),e(Gu,Ovo),e(Gu,eN),e(eN,Vvo),e(Gu,Xvo),e(x,zvo),e(x,Ou),e(Ou,wle),e(wle,Qvo),e(Ou,Wvo),e(Ou,oN),e(oN,Hvo),e(Ou,Uvo),e(x,Jvo),e(x,Vu),e(Vu,Ale),e(Ale,Yvo),e(Vu,Kvo),e(Vu,rN),e(rN,Zvo),e(Vu,eFo),e(x,oFo),e(x,Xu),e(Xu,yle),e(yle,rFo),e(Xu,tFo),e(Xu,tN),e(tN,aFo),e(Xu,nFo),e(x,sFo),e(x,zu),e(zu,Lle),e(Lle,lFo),e(zu,iFo),e(zu,aN),e(aN,dFo),e(zu,cFo),e(He,fFo),e(He,Qu),e(Qu,mFo),e(Qu,xle),e(xle,gFo),e(Qu,hFo),e(Qu,$le),e($le,pFo),e(He,uFo),M(Wu,He,null),b(f,rqe,_),b(f,ki,_),e(ki,Hu),e(Hu,kle),M(WA,kle,null),e(ki,_Fo),e(ki,Sle),e(Sle,bFo),b(f,tqe,_),b(f,$o,_),M(HA,$o,null),e($o,vFo),e($o,Si),e(Si,FFo),e(Si,nN),e(nN,TFo),e(Si,MFo),e(Si,sN),e(sN,EFo),e(Si,CFo),e($o,wFo),e($o,UA),e(UA,AFo),e(UA,Rle),e(Rle,yFo),e(UA,LFo),e($o,xFo),e($o,at),M(JA,at,null),e(at,$Fo),e(at,Ple),e(Ple,kFo),e(at,SFo),e(at,Ri),e(Ri,RFo),e(Ri,Ble),e(Ble,PFo),e(Ri,BFo),e(Ri,lN),e(lN,IFo),e(Ri,qFo),e(at,NFo),M(Uu,at,null),e($o,jFo),e($o,Ue),M(YA,Ue,null),e(Ue,DFo),e(Ue,Ile),e(Ile,GFo),e(Ue,OFo),e(Ue,ka),e(ka,VFo),e(ka,qle),e(qle,XFo),e(ka,zFo),e(ka,Nle),e(Nle,QFo),e(ka,WFo),e(ka,jle),e(jle,HFo),e(ka,UFo),e(Ue,JFo),e(Ue,G),e(G,Ju),e(Ju,Dle),e(Dle,YFo),e(Ju,KFo),e(Ju,iN),e(iN,ZFo),e(Ju,e6o),e(G,o6o),e(G,Yu),e(Yu,Gle),e(Gle,r6o),e(Yu,t6o),e(Yu,dN),e(dN,a6o),e(Yu,n6o),e(G,s6o),e(G,Ku),e(Ku,Ole),e(Ole,l6o),e(Ku,i6o),e(Ku,cN),e(cN,d6o),e(Ku,c6o),e(G,f6o),e(G,Zu),e(Zu,Vle),e(Vle,m6o),e(Zu,g6o),e(Zu,fN),e(fN,h6o),e(Zu,p6o),e(G,u6o),e(G,e_),e(e_,Xle),e(Xle,_6o),e(e_,b6o),e(e_,mN),e(mN,v6o),e(e_,F6o),e(G,T6o),e(G,o_),e(o_,zle),e(zle,M6o),e(o_,E6o),e(o_,gN),e(gN,C6o),e(o_,w6o),e(G,A6o),e(G,r_),e(r_,Qle),e(Qle,y6o),e(r_,L6o),e(r_,hN),e(hN,x6o),e(r_,$6o),e(G,k6o),e(G,t_),e(t_,Wle),e(Wle,S6o),e(t_,R6o),e(t_,pN),e(pN,P6o),e(t_,B6o),e(G,I6o),e(G,a_),e(a_,Hle),e(Hle,q6o),e(a_,N6o),e(a_,uN),e(uN,j6o),e(a_,D6o),e(G,G6o),e(G,n_),e(n_,Ule),e(Ule,O6o),e(n_,V6o),e(n_,_N),e(_N,X6o),e(n_,z6o),e(G,Q6o),e(G,s_),e(s_,Jle),e(Jle,W6o),e(s_,H6o),e(s_,bN),e(bN,U6o),e(s_,J6o),e(G,Y6o),e(G,l_),e(l_,Yle),e(Yle,K6o),e(l_,Z6o),e(l_,vN),e(vN,eTo),e(l_,oTo),e(G,rTo),e(G,i_),e(i_,Kle),e(Kle,tTo),e(i_,aTo),e(i_,FN),e(FN,nTo),e(i_,sTo),e(G,lTo),e(G,d_),e(d_,Zle),e(Zle,iTo),e(d_,dTo),e(d_,TN),e(TN,cTo),e(d_,fTo),e(G,mTo),e(G,c_),e(c_,eie),e(eie,gTo),e(c_,hTo),e(c_,MN),e(MN,pTo),e(c_,uTo),e(G,_To),e(G,f_),e(f_,oie),e(oie,bTo),e(f_,vTo),e(f_,EN),e(EN,FTo),e(f_,TTo),e(G,MTo),e(G,m_),e(m_,rie),e(rie,ETo),e(m_,CTo),e(m_,CN),e(CN,wTo),e(m_,ATo),e(G,yTo),e(G,g_),e(g_,tie),e(tie,LTo),e(g_,xTo),e(g_,wN),e(wN,$To),e(g_,kTo),e(G,STo),e(G,h_),e(h_,aie),e(aie,RTo),e(h_,PTo),e(h_,AN),e(AN,BTo),e(h_,ITo),e(G,qTo),e(G,p_),e(p_,nie),e(nie,NTo),e(p_,jTo),e(p_,yN),e(yN,DTo),e(p_,GTo),e(G,OTo),e(G,u_),e(u_,sie),e(sie,VTo),e(u_,XTo),e(u_,LN),e(LN,zTo),e(u_,QTo),e(G,WTo),e(G,__),e(__,lie),e(lie,HTo),e(__,UTo),e(__,xN),e(xN,JTo),e(__,YTo),e(G,KTo),e(G,b_),e(b_,iie),e(iie,ZTo),e(b_,e8o),e(b_,$N),e($N,o8o),e(b_,r8o),e(G,t8o),e(G,v_),e(v_,die),e(die,a8o),e(v_,n8o),e(v_,kN),e(kN,s8o),e(v_,l8o),e(G,i8o),e(G,F_),e(F_,cie),e(cie,d8o),e(F_,c8o),e(F_,SN),e(SN,f8o),e(F_,m8o),e(G,g8o),e(G,T_),e(T_,fie),e(fie,h8o),e(T_,p8o),e(T_,RN),e(RN,u8o),e(T_,_8o),e(G,b8o),e(G,M_),e(M_,mie),e(mie,v8o),e(M_,F8o),e(M_,PN),e(PN,T8o),e(M_,M8o),e(G,E8o),e(G,E_),e(E_,gie),e(gie,C8o),e(E_,w8o),e(E_,BN),e(BN,A8o),e(E_,y8o),e(G,L8o),e(G,C_),e(C_,hie),e(hie,x8o),e(C_,$8o),e(C_,IN),e(IN,k8o),e(C_,S8o),e(G,R8o),e(G,w_),e(w_,pie),e(pie,P8o),e(w_,B8o),e(w_,qN),e(qN,I8o),e(w_,q8o),e(G,N8o),e(G,A_),e(A_,uie),e(uie,j8o),e(A_,D8o),e(A_,NN),e(NN,G8o),e(A_,O8o),e(G,V8o),e(G,y_),e(y_,_ie),e(_ie,X8o),e(y_,z8o),e(y_,jN),e(jN,Q8o),e(y_,W8o),e(G,H8o),e(G,L_),e(L_,bie),e(bie,U8o),e(L_,J8o),e(L_,DN),e(DN,Y8o),e(L_,K8o),e(G,Z8o),e(G,x_),e(x_,vie),e(vie,e7o),e(x_,o7o),e(x_,GN),e(GN,r7o),e(x_,t7o),e(G,a7o),e(G,$_),e($_,Fie),e(Fie,n7o),e($_,s7o),e($_,ON),e(ON,l7o),e($_,i7o),e(G,d7o),e(G,k_),e(k_,Tie),e(Tie,c7o),e(k_,f7o),e(k_,VN),e(VN,m7o),e(k_,g7o),e(G,h7o),e(G,S_),e(S_,Mie),e(Mie,p7o),e(S_,u7o),e(S_,XN),e(XN,_7o),e(S_,b7o),e(G,v7o),e(G,R_),e(R_,Eie),e(Eie,F7o),e(R_,T7o),e(R_,zN),e(zN,M7o),e(R_,E7o),e(G,C7o),e(G,P_),e(P_,Cie),e(Cie,w7o),e(P_,A7o),e(P_,QN),e(QN,y7o),e(P_,L7o),e(G,x7o),e(G,B_),e(B_,wie),e(wie,$7o),e(B_,k7o),e(B_,WN),e(WN,S7o),e(B_,R7o),e(Ue,P7o),e(Ue,I_),e(I_,B7o),e(I_,Aie),e(Aie,I7o),e(I_,q7o),e(I_,yie),e(yie,N7o),e(Ue,j7o),M(q_,Ue,null),b(f,aqe,_),b(f,Pi,_),e(Pi,N_),e(N_,Lie),M(KA,Lie,null),e(Pi,D7o),e(Pi,xie),e(xie,G7o),b(f,nqe,_),b(f,ko,_),M(ZA,ko,null),e(ko,O7o),e(ko,Bi),e(Bi,V7o),e(Bi,HN),e(HN,X7o),e(Bi,z7o),e(Bi,UN),e(UN,Q7o),e(Bi,W7o),e(ko,H7o),e(ko,e0),e(e0,U7o),e(e0,$ie),e($ie,J7o),e(e0,Y7o),e(ko,K7o),e(ko,nt),M(o0,nt,null),e(nt,Z7o),e(nt,kie),e(kie,eMo),e(nt,oMo),e(nt,Ii),e(Ii,rMo),e(Ii,Sie),e(Sie,tMo),e(Ii,aMo),e(Ii,JN),e(JN,nMo),e(Ii,sMo),e(nt,lMo),M(j_,nt,null),e(ko,iMo),e(ko,Je),M(r0,Je,null),e(Je,dMo),e(Je,Rie),e(Rie,cMo),e(Je,fMo),e(Je,Sa),e(Sa,mMo),e(Sa,Pie),e(Pie,gMo),e(Sa,hMo),e(Sa,Bie),e(Bie,pMo),e(Sa,uMo),e(Sa,Iie),e(Iie,_Mo),e(Sa,bMo),e(Je,vMo),e(Je,z),e(z,D_),e(D_,qie),e(qie,FMo),e(D_,TMo),e(D_,YN),e(YN,MMo),e(D_,EMo),e(z,CMo),e(z,G_),e(G_,Nie),e(Nie,wMo),e(G_,AMo),e(G_,KN),e(KN,yMo),e(G_,LMo),e(z,xMo),e(z,O_),e(O_,jie),e(jie,$Mo),e(O_,kMo),e(O_,ZN),e(ZN,SMo),e(O_,RMo),e(z,PMo),e(z,V_),e(V_,Die),e(Die,BMo),e(V_,IMo),e(V_,ej),e(ej,qMo),e(V_,NMo),e(z,jMo),e(z,X_),e(X_,Gie),e(Gie,DMo),e(X_,GMo),e(X_,oj),e(oj,OMo),e(X_,VMo),e(z,XMo),e(z,z_),e(z_,Oie),e(Oie,zMo),e(z_,QMo),e(z_,rj),e(rj,WMo),e(z_,HMo),e(z,UMo),e(z,Q_),e(Q_,Vie),e(Vie,JMo),e(Q_,YMo),e(Q_,tj),e(tj,KMo),e(Q_,ZMo),e(z,e4o),e(z,W_),e(W_,Xie),e(Xie,o4o),e(W_,r4o),e(W_,aj),e(aj,t4o),e(W_,a4o),e(z,n4o),e(z,H_),e(H_,zie),e(zie,s4o),e(H_,l4o),e(H_,nj),e(nj,i4o),e(H_,d4o),e(z,c4o),e(z,U_),e(U_,Qie),e(Qie,f4o),e(U_,m4o),e(U_,sj),e(sj,g4o),e(U_,h4o),e(z,p4o),e(z,J_),e(J_,Wie),e(Wie,u4o),e(J_,_4o),e(J_,lj),e(lj,b4o),e(J_,v4o),e(z,F4o),e(z,Y_),e(Y_,Hie),e(Hie,T4o),e(Y_,M4o),e(Y_,ij),e(ij,E4o),e(Y_,C4o),e(z,w4o),e(z,K_),e(K_,Uie),e(Uie,A4o),e(K_,y4o),e(K_,dj),e(dj,L4o),e(K_,x4o),e(z,$4o),e(z,Z_),e(Z_,Jie),e(Jie,k4o),e(Z_,S4o),e(Z_,cj),e(cj,R4o),e(Z_,P4o),e(z,B4o),e(z,e2),e(e2,Yie),e(Yie,I4o),e(e2,q4o),e(e2,fj),e(fj,N4o),e(e2,j4o),e(z,D4o),e(z,o2),e(o2,Kie),e(Kie,G4o),e(o2,O4o),e(o2,mj),e(mj,V4o),e(o2,X4o),e(z,z4o),e(z,r2),e(r2,Zie),e(Zie,Q4o),e(r2,W4o),e(r2,gj),e(gj,H4o),e(r2,U4o),e(z,J4o),e(z,t2),e(t2,ede),e(ede,Y4o),e(t2,K4o),e(t2,hj),e(hj,Z4o),e(t2,eEo),e(z,oEo),e(z,a2),e(a2,ode),e(ode,rEo),e(a2,tEo),e(a2,pj),e(pj,aEo),e(a2,nEo),e(z,sEo),e(z,n2),e(n2,rde),e(rde,lEo),e(n2,iEo),e(n2,uj),e(uj,dEo),e(n2,cEo),e(z,fEo),e(z,s2),e(s2,tde),e(tde,mEo),e(s2,gEo),e(s2,_j),e(_j,hEo),e(s2,pEo),e(z,uEo),e(z,l2),e(l2,ade),e(ade,_Eo),e(l2,bEo),e(l2,bj),e(bj,vEo),e(l2,FEo),e(z,TEo),e(z,i2),e(i2,nde),e(nde,MEo),e(i2,EEo),e(i2,vj),e(vj,CEo),e(i2,wEo),e(z,AEo),e(z,d2),e(d2,sde),e(sde,yEo),e(d2,LEo),e(d2,Fj),e(Fj,xEo),e(d2,$Eo),e(z,kEo),e(z,c2),e(c2,lde),e(lde,SEo),e(c2,REo),e(c2,Tj),e(Tj,PEo),e(c2,BEo),e(z,IEo),e(z,f2),e(f2,ide),e(ide,qEo),e(f2,NEo),e(f2,Mj),e(Mj,jEo),e(f2,DEo),e(z,GEo),e(z,m2),e(m2,dde),e(dde,OEo),e(m2,VEo),e(m2,Ej),e(Ej,XEo),e(m2,zEo),e(z,QEo),e(z,g2),e(g2,cde),e(cde,WEo),e(g2,HEo),e(g2,Cj),e(Cj,UEo),e(g2,JEo),e(z,YEo),e(z,h2),e(h2,fde),e(fde,KEo),e(h2,ZEo),e(h2,wj),e(wj,e5o),e(h2,o5o),e(z,r5o),e(z,p2),e(p2,mde),e(mde,t5o),e(p2,a5o),e(p2,Aj),e(Aj,n5o),e(p2,s5o),e(z,l5o),e(z,u2),e(u2,gde),e(gde,i5o),e(u2,d5o),e(u2,yj),e(yj,c5o),e(u2,f5o),e(z,m5o),e(z,_2),e(_2,hde),e(hde,g5o),e(_2,h5o),e(_2,Lj),e(Lj,p5o),e(_2,u5o),e(z,_5o),e(z,b2),e(b2,pde),e(pde,b5o),e(b2,v5o),e(b2,xj),e(xj,F5o),e(b2,T5o),e(z,M5o),e(z,v2),e(v2,ude),e(ude,E5o),e(v2,C5o),e(v2,$j),e($j,w5o),e(v2,A5o),e(z,y5o),e(z,F2),e(F2,_de),e(_de,L5o),e(F2,x5o),e(F2,kj),e(kj,$5o),e(F2,k5o),e(z,S5o),e(z,T2),e(T2,bde),e(bde,R5o),e(T2,P5o),e(T2,Sj),e(Sj,B5o),e(T2,I5o),e(Je,q5o),e(Je,M2),e(M2,N5o),e(M2,vde),e(vde,j5o),e(M2,D5o),e(M2,Fde),e(Fde,G5o),e(Je,O5o),M(E2,Je,null),b(f,sqe,_),b(f,qi,_),e(qi,C2),e(C2,Tde),M(t0,Tde,null),e(qi,V5o),e(qi,Mde),e(Mde,X5o),b(f,lqe,_),b(f,So,_),M(a0,So,null),e(So,z5o),e(So,Ni),e(Ni,Q5o),e(Ni,Rj),e(Rj,W5o),e(Ni,H5o),e(Ni,Pj),e(Pj,U5o),e(Ni,J5o),e(So,Y5o),e(So,n0),e(n0,K5o),e(n0,Ede),e(Ede,Z5o),e(n0,eCo),e(So,oCo),e(So,st),M(s0,st,null),e(st,rCo),e(st,Cde),e(Cde,tCo),e(st,aCo),e(st,ji),e(ji,nCo),e(ji,wde),e(wde,sCo),e(ji,lCo),e(ji,Bj),e(Bj,iCo),e(ji,dCo),e(st,cCo),M(w2,st,null),e(So,fCo),e(So,Ye),M(l0,Ye,null),e(Ye,mCo),e(Ye,Ade),e(Ade,gCo),e(Ye,hCo),e(Ye,Ra),e(Ra,pCo),e(Ra,yde),e(yde,uCo),e(Ra,_Co),e(Ra,Lde),e(Lde,bCo),e(Ra,vCo),e(Ra,xde),e(xde,FCo),e(Ra,TCo),e(Ye,MCo),e(Ye,Q),e(Q,A2),e(A2,$de),e($de,ECo),e(A2,CCo),e(A2,Ij),e(Ij,wCo),e(A2,ACo),e(Q,yCo),e(Q,y2),e(y2,kde),e(kde,LCo),e(y2,xCo),e(y2,qj),e(qj,$Co),e(y2,kCo),e(Q,SCo),e(Q,L2),e(L2,Sde),e(Sde,RCo),e(L2,PCo),e(L2,Nj),e(Nj,BCo),e(L2,ICo),e(Q,qCo),e(Q,x2),e(x2,Rde),e(Rde,NCo),e(x2,jCo),e(x2,jj),e(jj,DCo),e(x2,GCo),e(Q,OCo),e(Q,$2),e($2,Pde),e(Pde,VCo),e($2,XCo),e($2,Dj),e(Dj,zCo),e($2,QCo),e(Q,WCo),e(Q,k2),e(k2,Bde),e(Bde,HCo),e(k2,UCo),e(k2,Gj),e(Gj,JCo),e(k2,YCo),e(Q,KCo),e(Q,S2),e(S2,Ide),e(Ide,ZCo),e(S2,e3o),e(S2,Oj),e(Oj,o3o),e(S2,r3o),e(Q,t3o),e(Q,R2),e(R2,qde),e(qde,a3o),e(R2,n3o),e(R2,Vj),e(Vj,s3o),e(R2,l3o),e(Q,i3o),e(Q,P2),e(P2,Nde),e(Nde,d3o),e(P2,c3o),e(P2,Xj),e(Xj,f3o),e(P2,m3o),e(Q,g3o),e(Q,B2),e(B2,jde),e(jde,h3o),e(B2,p3o),e(B2,zj),e(zj,u3o),e(B2,_3o),e(Q,b3o),e(Q,I2),e(I2,Dde),e(Dde,v3o),e(I2,F3o),e(I2,Qj),e(Qj,T3o),e(I2,M3o),e(Q,E3o),e(Q,q2),e(q2,Gde),e(Gde,C3o),e(q2,w3o),e(q2,Wj),e(Wj,A3o),e(q2,y3o),e(Q,L3o),e(Q,N2),e(N2,Ode),e(Ode,x3o),e(N2,$3o),e(N2,Hj),e(Hj,k3o),e(N2,S3o),e(Q,R3o),e(Q,j2),e(j2,Vde),e(Vde,P3o),e(j2,B3o),e(j2,Uj),e(Uj,I3o),e(j2,q3o),e(Q,N3o),e(Q,D2),e(D2,Xde),e(Xde,j3o),e(D2,D3o),e(D2,Jj),e(Jj,G3o),e(D2,O3o),e(Q,V3o),e(Q,G2),e(G2,zde),e(zde,X3o),e(G2,z3o),e(G2,Yj),e(Yj,Q3o),e(G2,W3o),e(Q,H3o),e(Q,O2),e(O2,Qde),e(Qde,U3o),e(O2,J3o),e(O2,Kj),e(Kj,Y3o),e(O2,K3o),e(Q,Z3o),e(Q,V2),e(V2,Wde),e(Wde,ewo),e(V2,owo),e(V2,Zj),e(Zj,rwo),e(V2,two),e(Q,awo),e(Q,X2),e(X2,Hde),e(Hde,nwo),e(X2,swo),e(X2,eD),e(eD,lwo),e(X2,iwo),e(Q,dwo),e(Q,z2),e(z2,Ude),e(Ude,cwo),e(z2,fwo),e(z2,oD),e(oD,mwo),e(z2,gwo),e(Q,hwo),e(Q,Q2),e(Q2,Jde),e(Jde,pwo),e(Q2,uwo),e(Q2,rD),e(rD,_wo),e(Q2,bwo),e(Q,vwo),e(Q,W2),e(W2,Yde),e(Yde,Fwo),e(W2,Two),e(W2,tD),e(tD,Mwo),e(W2,Ewo),e(Q,Cwo),e(Q,H2),e(H2,Kde),e(Kde,wwo),e(H2,Awo),e(H2,aD),e(aD,ywo),e(H2,Lwo),e(Q,xwo),e(Q,U2),e(U2,Zde),e(Zde,$wo),e(U2,kwo),e(U2,nD),e(nD,Swo),e(U2,Rwo),e(Q,Pwo),e(Q,J2),e(J2,ece),e(ece,Bwo),e(J2,Iwo),e(J2,sD),e(sD,qwo),e(J2,Nwo),e(Q,jwo),e(Q,Y2),e(Y2,oce),e(oce,Dwo),e(Y2,Gwo),e(Y2,lD),e(lD,Owo),e(Y2,Vwo),e(Q,Xwo),e(Q,K2),e(K2,rce),e(rce,zwo),e(K2,Qwo),e(K2,iD),e(iD,Wwo),e(K2,Hwo),e(Q,Uwo),e(Q,Z2),e(Z2,tce),e(tce,Jwo),e(Z2,Ywo),e(Z2,dD),e(dD,Kwo),e(Z2,Zwo),e(Q,eAo),e(Q,e1),e(e1,ace),e(ace,oAo),e(e1,rAo),e(e1,cD),e(cD,tAo),e(e1,aAo),e(Q,nAo),e(Q,o1),e(o1,nce),e(nce,sAo),e(o1,lAo),e(o1,fD),e(fD,iAo),e(o1,dAo),e(Q,cAo),e(Q,r1),e(r1,sce),e(sce,fAo),e(r1,mAo),e(r1,lce),e(lce,gAo),e(r1,hAo),e(Q,pAo),e(Q,t1),e(t1,ice),e(ice,uAo),e(t1,_Ao),e(t1,mD),e(mD,bAo),e(t1,vAo),e(Q,FAo),e(Q,a1),e(a1,dce),e(dce,TAo),e(a1,MAo),e(a1,gD),e(gD,EAo),e(a1,CAo),e(Q,wAo),e(Q,n1),e(n1,cce),e(cce,AAo),e(n1,yAo),e(n1,hD),e(hD,LAo),e(n1,xAo),e(Q,$Ao),e(Q,s1),e(s1,fce),e(fce,kAo),e(s1,SAo),e(s1,pD),e(pD,RAo),e(s1,PAo),e(Ye,BAo),e(Ye,l1),e(l1,IAo),e(l1,mce),e(mce,qAo),e(l1,NAo),e(l1,gce),e(gce,jAo),e(Ye,DAo),M(i1,Ye,null),b(f,iqe,_),b(f,Di,_),e(Di,d1),e(d1,hce),M(i0,hce,null),e(Di,GAo),e(Di,pce),e(pce,OAo),b(f,dqe,_),b(f,Ro,_),M(d0,Ro,null),e(Ro,VAo),e(Ro,Gi),e(Gi,XAo),e(Gi,uD),e(uD,zAo),e(Gi,QAo),e(Gi,_D),e(_D,WAo),e(Gi,HAo),e(Ro,UAo),e(Ro,c0),e(c0,JAo),e(c0,uce),e(uce,YAo),e(c0,KAo),e(Ro,ZAo),e(Ro,lt),M(f0,lt,null),e(lt,e0o),e(lt,_ce),e(_ce,o0o),e(lt,r0o),e(lt,Oi),e(Oi,t0o),e(Oi,bce),e(bce,a0o),e(Oi,n0o),e(Oi,bD),e(bD,s0o),e(Oi,l0o),e(lt,i0o),M(c1,lt,null),e(Ro,d0o),e(Ro,Ke),M(m0,Ke,null),e(Ke,c0o),e(Ke,vce),e(vce,f0o),e(Ke,m0o),e(Ke,Pa),e(Pa,g0o),e(Pa,Fce),e(Fce,h0o),e(Pa,p0o),e(Pa,Tce),e(Tce,u0o),e(Pa,_0o),e(Pa,Mce),e(Mce,b0o),e(Pa,v0o),e(Ke,F0o),e(Ke,he),e(he,f1),e(f1,Ece),e(Ece,T0o),e(f1,M0o),e(f1,vD),e(vD,E0o),e(f1,C0o),e(he,w0o),e(he,m1),e(m1,Cce),e(Cce,A0o),e(m1,y0o),e(m1,FD),e(FD,L0o),e(m1,x0o),e(he,$0o),e(he,g1),e(g1,wce),e(wce,k0o),e(g1,S0o),e(g1,TD),e(TD,R0o),e(g1,P0o),e(he,B0o),e(he,h1),e(h1,Ace),e(Ace,I0o),e(h1,q0o),e(h1,MD),e(MD,N0o),e(h1,j0o),e(he,D0o),e(he,p1),e(p1,yce),e(yce,G0o),e(p1,O0o),e(p1,ED),e(ED,V0o),e(p1,X0o),e(he,z0o),e(he,u1),e(u1,Lce),e(Lce,Q0o),e(u1,W0o),e(u1,CD),e(CD,H0o),e(u1,U0o),e(he,J0o),e(he,_1),e(_1,xce),e(xce,Y0o),e(_1,K0o),e(_1,wD),e(wD,Z0o),e(_1,eyo),e(he,oyo),e(he,b1),e(b1,$ce),e($ce,ryo),e(b1,tyo),e(b1,AD),e(AD,ayo),e(b1,nyo),e(he,syo),e(he,v1),e(v1,kce),e(kce,lyo),e(v1,iyo),e(v1,yD),e(yD,dyo),e(v1,cyo),e(he,fyo),e(he,F1),e(F1,Sce),e(Sce,myo),e(F1,gyo),e(F1,LD),e(LD,hyo),e(F1,pyo),e(he,uyo),e(he,T1),e(T1,Rce),e(Rce,_yo),e(T1,byo),e(T1,xD),e(xD,vyo),e(T1,Fyo),e(he,Tyo),e(he,M1),e(M1,Pce),e(Pce,Myo),e(M1,Eyo),e(M1,$D),e($D,Cyo),e(M1,wyo),e(he,Ayo),e(he,E1),e(E1,Bce),e(Bce,yyo),e(E1,Lyo),e(E1,kD),e(kD,xyo),e(E1,$yo),e(he,kyo),e(he,C1),e(C1,Ice),e(Ice,Syo),e(C1,Ryo),e(C1,SD),e(SD,Pyo),e(C1,Byo),e(he,Iyo),e(he,w1),e(w1,qce),e(qce,qyo),e(w1,Nyo),e(w1,RD),e(RD,jyo),e(w1,Dyo),e(he,Gyo),e(he,A1),e(A1,Nce),e(Nce,Oyo),e(A1,Vyo),e(A1,PD),e(PD,Xyo),e(A1,zyo),e(he,Qyo),e(he,y1),e(y1,jce),e(jce,Wyo),e(y1,Hyo),e(y1,BD),e(BD,Uyo),e(y1,Jyo),e(Ke,Yyo),e(Ke,L1),e(L1,Kyo),e(L1,Dce),e(Dce,Zyo),e(L1,eLo),e(L1,Gce),e(Gce,oLo),e(Ke,rLo),M(x1,Ke,null),b(f,cqe,_),b(f,Vi,_),e(Vi,$1),e($1,Oce),M(g0,Oce,null),e(Vi,tLo),e(Vi,Vce),e(Vce,aLo),b(f,fqe,_),b(f,Po,_),M(h0,Po,null),e(Po,nLo),e(Po,Xi),e(Xi,sLo),e(Xi,ID),e(ID,lLo),e(Xi,iLo),e(Xi,qD),e(qD,dLo),e(Xi,cLo),e(Po,fLo),e(Po,p0),e(p0,mLo),e(p0,Xce),e(Xce,gLo),e(p0,hLo),e(Po,pLo),e(Po,it),M(u0,it,null),e(it,uLo),e(it,zce),e(zce,_Lo),e(it,bLo),e(it,zi),e(zi,vLo),e(zi,Qce),e(Qce,FLo),e(zi,TLo),e(zi,ND),e(ND,MLo),e(zi,ELo),e(it,CLo),M(k1,it,null),e(Po,wLo),e(Po,Ze),M(_0,Ze,null),e(Ze,ALo),e(Ze,Wce),e(Wce,yLo),e(Ze,LLo),e(Ze,Ba),e(Ba,xLo),e(Ba,Hce),e(Hce,$Lo),e(Ba,kLo),e(Ba,Uce),e(Uce,SLo),e(Ba,RLo),e(Ba,Jce),e(Jce,PLo),e(Ba,BLo),e(Ze,ILo),e(Ze,q),e(q,S1),e(S1,Yce),e(Yce,qLo),e(S1,NLo),e(S1,jD),e(jD,jLo),e(S1,DLo),e(q,GLo),e(q,R1),e(R1,Kce),e(Kce,OLo),e(R1,VLo),e(R1,DD),e(DD,XLo),e(R1,zLo),e(q,QLo),e(q,P1),e(P1,Zce),e(Zce,WLo),e(P1,HLo),e(P1,GD),e(GD,ULo),e(P1,JLo),e(q,YLo),e(q,B1),e(B1,efe),e(efe,KLo),e(B1,ZLo),e(B1,OD),e(OD,exo),e(B1,oxo),e(q,rxo),e(q,I1),e(I1,ofe),e(ofe,txo),e(I1,axo),e(I1,VD),e(VD,nxo),e(I1,sxo),e(q,lxo),e(q,q1),e(q1,rfe),e(rfe,ixo),e(q1,dxo),e(q1,XD),e(XD,cxo),e(q1,fxo),e(q,mxo),e(q,N1),e(N1,tfe),e(tfe,gxo),e(N1,hxo),e(N1,zD),e(zD,pxo),e(N1,uxo),e(q,_xo),e(q,j1),e(j1,afe),e(afe,bxo),e(j1,vxo),e(j1,QD),e(QD,Fxo),e(j1,Txo),e(q,Mxo),e(q,D1),e(D1,nfe),e(nfe,Exo),e(D1,Cxo),e(D1,WD),e(WD,wxo),e(D1,Axo),e(q,yxo),e(q,G1),e(G1,sfe),e(sfe,Lxo),e(G1,xxo),e(G1,HD),e(HD,$xo),e(G1,kxo),e(q,Sxo),e(q,O1),e(O1,lfe),e(lfe,Rxo),e(O1,Pxo),e(O1,UD),e(UD,Bxo),e(O1,Ixo),e(q,qxo),e(q,V1),e(V1,ife),e(ife,Nxo),e(V1,jxo),e(V1,JD),e(JD,Dxo),e(V1,Gxo),e(q,Oxo),e(q,X1),e(X1,dfe),e(dfe,Vxo),e(X1,Xxo),e(X1,YD),e(YD,zxo),e(X1,Qxo),e(q,Wxo),e(q,z1),e(z1,cfe),e(cfe,Hxo),e(z1,Uxo),e(z1,KD),e(KD,Jxo),e(z1,Yxo),e(q,Kxo),e(q,Q1),e(Q1,ffe),e(ffe,Zxo),e(Q1,e9o),e(Q1,ZD),e(ZD,o9o),e(Q1,r9o),e(q,t9o),e(q,W1),e(W1,mfe),e(mfe,a9o),e(W1,n9o),e(W1,eG),e(eG,s9o),e(W1,l9o),e(q,i9o),e(q,H1),e(H1,gfe),e(gfe,d9o),e(H1,c9o),e(H1,oG),e(oG,f9o),e(H1,m9o),e(q,g9o),e(q,U1),e(U1,hfe),e(hfe,h9o),e(U1,p9o),e(U1,rG),e(rG,u9o),e(U1,_9o),e(q,b9o),e(q,J1),e(J1,pfe),e(pfe,v9o),e(J1,F9o),e(J1,tG),e(tG,T9o),e(J1,M9o),e(q,E9o),e(q,Y1),e(Y1,ufe),e(ufe,C9o),e(Y1,w9o),e(Y1,aG),e(aG,A9o),e(Y1,y9o),e(q,L9o),e(q,K1),e(K1,_fe),e(_fe,x9o),e(K1,$9o),e(K1,nG),e(nG,k9o),e(K1,S9o),e(q,R9o),e(q,Z1),e(Z1,bfe),e(bfe,P9o),e(Z1,B9o),e(Z1,sG),e(sG,I9o),e(Z1,q9o),e(q,N9o),e(q,eb),e(eb,vfe),e(vfe,j9o),e(eb,D9o),e(eb,lG),e(lG,G9o),e(eb,O9o),e(q,V9o),e(q,ob),e(ob,Ffe),e(Ffe,X9o),e(ob,z9o),e(ob,iG),e(iG,Q9o),e(ob,W9o),e(q,H9o),e(q,rb),e(rb,Tfe),e(Tfe,U9o),e(rb,J9o),e(rb,dG),e(dG,Y9o),e(rb,K9o),e(q,Z9o),e(q,tb),e(tb,Mfe),e(Mfe,e$o),e(tb,o$o),e(tb,cG),e(cG,r$o),e(tb,t$o),e(q,a$o),e(q,ab),e(ab,Efe),e(Efe,n$o),e(ab,s$o),e(ab,fG),e(fG,l$o),e(ab,i$o),e(q,d$o),e(q,nb),e(nb,Cfe),e(Cfe,c$o),e(nb,f$o),e(nb,mG),e(mG,m$o),e(nb,g$o),e(q,h$o),e(q,sb),e(sb,wfe),e(wfe,p$o),e(sb,u$o),e(sb,gG),e(gG,_$o),e(sb,b$o),e(q,v$o),e(q,lb),e(lb,Afe),e(Afe,F$o),e(lb,T$o),e(lb,hG),e(hG,M$o),e(lb,E$o),e(q,C$o),e(q,ib),e(ib,yfe),e(yfe,w$o),e(ib,A$o),e(ib,pG),e(pG,y$o),e(ib,L$o),e(q,x$o),e(q,db),e(db,Lfe),e(Lfe,$$o),e(db,k$o),e(db,uG),e(uG,S$o),e(db,R$o),e(q,P$o),e(q,cb),e(cb,xfe),e(xfe,B$o),e(cb,I$o),e(cb,_G),e(_G,q$o),e(cb,N$o),e(q,j$o),e(q,fb),e(fb,$fe),e($fe,D$o),e(fb,G$o),e(fb,bG),e(bG,O$o),e(fb,V$o),e(q,X$o),e(q,mb),e(mb,kfe),e(kfe,z$o),e(mb,Q$o),e(mb,vG),e(vG,W$o),e(mb,H$o),e(q,U$o),e(q,gb),e(gb,Sfe),e(Sfe,J$o),e(gb,Y$o),e(gb,FG),e(FG,K$o),e(gb,Z$o),e(q,eko),e(q,hb),e(hb,Rfe),e(Rfe,oko),e(hb,rko),e(hb,TG),e(TG,tko),e(hb,ako),e(q,nko),e(q,pb),e(pb,Pfe),e(Pfe,sko),e(pb,lko),e(pb,MG),e(MG,iko),e(pb,dko),e(q,cko),e(q,ub),e(ub,Bfe),e(Bfe,fko),e(ub,mko),e(ub,EG),e(EG,gko),e(ub,hko),e(q,pko),e(q,_b),e(_b,Ife),e(Ife,uko),e(_b,_ko),e(_b,CG),e(CG,bko),e(_b,vko),e(q,Fko),e(q,bb),e(bb,qfe),e(qfe,Tko),e(bb,Mko),e(bb,wG),e(wG,Eko),e(bb,Cko),e(q,wko),e(q,vb),e(vb,Nfe),e(Nfe,Ako),e(vb,yko),e(vb,AG),e(AG,Lko),e(vb,xko),e(q,$ko),e(q,Fb),e(Fb,jfe),e(jfe,kko),e(Fb,Sko),e(Fb,yG),e(yG,Rko),e(Fb,Pko),e(q,Bko),e(q,Tb),e(Tb,Dfe),e(Dfe,Iko),e(Tb,qko),e(Tb,LG),e(LG,Nko),e(Tb,jko),e(q,Dko),e(q,Mb),e(Mb,Gfe),e(Gfe,Gko),e(Mb,Oko),e(Mb,xG),e(xG,Vko),e(Mb,Xko),e(q,zko),e(q,Eb),e(Eb,Ofe),e(Ofe,Qko),e(Eb,Wko),e(Eb,$G),e($G,Hko),e(Eb,Uko),e(q,Jko),e(q,Cb),e(Cb,Vfe),e(Vfe,Yko),e(Cb,Kko),e(Cb,kG),e(kG,Zko),e(Cb,eSo),e(Ze,oSo),e(Ze,wb),e(wb,rSo),e(wb,Xfe),e(Xfe,tSo),e(wb,aSo),e(wb,zfe),e(zfe,nSo),e(Ze,sSo),M(Ab,Ze,null),b(f,mqe,_),b(f,Qi,_),e(Qi,yb),e(yb,Qfe),M(b0,Qfe,null),e(Qi,lSo),e(Qi,Wfe),e(Wfe,iSo),b(f,gqe,_),b(f,Bo,_),M(v0,Bo,null),e(Bo,dSo),e(Bo,Wi),e(Wi,cSo),e(Wi,SG),e(SG,fSo),e(Wi,mSo),e(Wi,RG),e(RG,gSo),e(Wi,hSo),e(Bo,pSo),e(Bo,F0),e(F0,uSo),e(F0,Hfe),e(Hfe,_So),e(F0,bSo),e(Bo,vSo),e(Bo,dt),M(T0,dt,null),e(dt,FSo),e(dt,Ufe),e(Ufe,TSo),e(dt,MSo),e(dt,Hi),e(Hi,ESo),e(Hi,Jfe),e(Jfe,CSo),e(Hi,wSo),e(Hi,PG),e(PG,ASo),e(Hi,ySo),e(dt,LSo),M(Lb,dt,null),e(Bo,xSo),e(Bo,eo),M(M0,eo,null),e(eo,$So),e(eo,Yfe),e(Yfe,kSo),e(eo,SSo),e(eo,Ia),e(Ia,RSo),e(Ia,Kfe),e(Kfe,PSo),e(Ia,BSo),e(Ia,Zfe),e(Zfe,ISo),e(Ia,qSo),e(Ia,eme),e(eme,NSo),e(Ia,jSo),e(eo,DSo),e(eo,Y),e(Y,xb),e(xb,ome),e(ome,GSo),e(xb,OSo),e(xb,BG),e(BG,VSo),e(xb,XSo),e(Y,zSo),e(Y,$b),e($b,rme),e(rme,QSo),e($b,WSo),e($b,IG),e(IG,HSo),e($b,USo),e(Y,JSo),e(Y,kb),e(kb,tme),e(tme,YSo),e(kb,KSo),e(kb,qG),e(qG,ZSo),e(kb,eRo),e(Y,oRo),e(Y,Sb),e(Sb,ame),e(ame,rRo),e(Sb,tRo),e(Sb,NG),e(NG,aRo),e(Sb,nRo),e(Y,sRo),e(Y,Rb),e(Rb,nme),e(nme,lRo),e(Rb,iRo),e(Rb,jG),e(jG,dRo),e(Rb,cRo),e(Y,fRo),e(Y,Pb),e(Pb,sme),e(sme,mRo),e(Pb,gRo),e(Pb,DG),e(DG,hRo),e(Pb,pRo),e(Y,uRo),e(Y,Bb),e(Bb,lme),e(lme,_Ro),e(Bb,bRo),e(Bb,GG),e(GG,vRo),e(Bb,FRo),e(Y,TRo),e(Y,Ib),e(Ib,ime),e(ime,MRo),e(Ib,ERo),e(Ib,OG),e(OG,CRo),e(Ib,wRo),e(Y,ARo),e(Y,qb),e(qb,dme),e(dme,yRo),e(qb,LRo),e(qb,VG),e(VG,xRo),e(qb,$Ro),e(Y,kRo),e(Y,Nb),e(Nb,cme),e(cme,SRo),e(Nb,RRo),e(Nb,XG),e(XG,PRo),e(Nb,BRo),e(Y,IRo),e(Y,jb),e(jb,fme),e(fme,qRo),e(jb,NRo),e(jb,zG),e(zG,jRo),e(jb,DRo),e(Y,GRo),e(Y,Db),e(Db,mme),e(mme,ORo),e(Db,VRo),e(Db,QG),e(QG,XRo),e(Db,zRo),e(Y,QRo),e(Y,Gb),e(Gb,gme),e(gme,WRo),e(Gb,HRo),e(Gb,WG),e(WG,URo),e(Gb,JRo),e(Y,YRo),e(Y,Ob),e(Ob,hme),e(hme,KRo),e(Ob,ZRo),e(Ob,HG),e(HG,ePo),e(Ob,oPo),e(Y,rPo),e(Y,Vb),e(Vb,pme),e(pme,tPo),e(Vb,aPo),e(Vb,UG),e(UG,nPo),e(Vb,sPo),e(Y,lPo),e(Y,Xb),e(Xb,ume),e(ume,iPo),e(Xb,dPo),e(Xb,JG),e(JG,cPo),e(Xb,fPo),e(Y,mPo),e(Y,zb),e(zb,_me),e(_me,gPo),e(zb,hPo),e(zb,YG),e(YG,pPo),e(zb,uPo),e(Y,_Po),e(Y,Qb),e(Qb,bme),e(bme,bPo),e(Qb,vPo),e(Qb,KG),e(KG,FPo),e(Qb,TPo),e(Y,MPo),e(Y,Wb),e(Wb,vme),e(vme,EPo),e(Wb,CPo),e(Wb,ZG),e(ZG,wPo),e(Wb,APo),e(Y,yPo),e(Y,Hb),e(Hb,Fme),e(Fme,LPo),e(Hb,xPo),e(Hb,eO),e(eO,$Po),e(Hb,kPo),e(Y,SPo),e(Y,Ub),e(Ub,Tme),e(Tme,RPo),e(Ub,PPo),e(Ub,oO),e(oO,BPo),e(Ub,IPo),e(Y,qPo),e(Y,Jb),e(Jb,Mme),e(Mme,NPo),e(Jb,jPo),e(Jb,rO),e(rO,DPo),e(Jb,GPo),e(Y,OPo),e(Y,Yb),e(Yb,Eme),e(Eme,VPo),e(Yb,XPo),e(Yb,tO),e(tO,zPo),e(Yb,QPo),e(Y,WPo),e(Y,Kb),e(Kb,Cme),e(Cme,HPo),e(Kb,UPo),e(Kb,aO),e(aO,JPo),e(Kb,YPo),e(Y,KPo),e(Y,Zb),e(Zb,wme),e(wme,ZPo),e(Zb,eBo),e(Zb,nO),e(nO,oBo),e(Zb,rBo),e(Y,tBo),e(Y,ev),e(ev,Ame),e(Ame,aBo),e(ev,nBo),e(ev,sO),e(sO,sBo),e(ev,lBo),e(Y,iBo),e(Y,ov),e(ov,yme),e(yme,dBo),e(ov,cBo),e(ov,lO),e(lO,fBo),e(ov,mBo),e(Y,gBo),e(Y,rv),e(rv,Lme),e(Lme,hBo),e(rv,pBo),e(rv,iO),e(iO,uBo),e(rv,_Bo),e(Y,bBo),e(Y,tv),e(tv,xme),e(xme,vBo),e(tv,FBo),e(tv,dO),e(dO,TBo),e(tv,MBo),e(eo,EBo),e(eo,av),e(av,CBo),e(av,$me),e($me,wBo),e(av,ABo),e(av,kme),e(kme,yBo),e(eo,LBo),M(nv,eo,null),b(f,hqe,_),b(f,Ui,_),e(Ui,sv),e(sv,Sme),M(E0,Sme,null),e(Ui,xBo),e(Ui,Rme),e(Rme,$Bo),b(f,pqe,_),b(f,Io,_),M(C0,Io,null),e(Io,kBo),e(Io,Ji),e(Ji,SBo),e(Ji,cO),e(cO,RBo),e(Ji,PBo),e(Ji,fO),e(fO,BBo),e(Ji,IBo),e(Io,qBo),e(Io,w0),e(w0,NBo),e(w0,Pme),e(Pme,jBo),e(w0,DBo),e(Io,GBo),e(Io,ct),M(A0,ct,null),e(ct,OBo),e(ct,Bme),e(Bme,VBo),e(ct,XBo),e(ct,Yi),e(Yi,zBo),e(Yi,Ime),e(Ime,QBo),e(Yi,WBo),e(Yi,mO),e(mO,HBo),e(Yi,UBo),e(ct,JBo),M(lv,ct,null),e(Io,YBo),e(Io,oo),M(y0,oo,null),e(oo,KBo),e(oo,qme),e(qme,ZBo),e(oo,eIo),e(oo,qa),e(qa,oIo),e(qa,Nme),e(Nme,rIo),e(qa,tIo),e(qa,jme),e(jme,aIo),e(qa,nIo),e(qa,Dme),e(Dme,sIo),e(qa,lIo),e(oo,iIo),e(oo,Zr),e(Zr,iv),e(iv,Gme),e(Gme,dIo),e(iv,cIo),e(iv,gO),e(gO,fIo),e(iv,mIo),e(Zr,gIo),e(Zr,dv),e(dv,Ome),e(Ome,hIo),e(dv,pIo),e(dv,hO),e(hO,uIo),e(dv,_Io),e(Zr,bIo),e(Zr,cv),e(cv,Vme),e(Vme,vIo),e(cv,FIo),e(cv,pO),e(pO,TIo),e(cv,MIo),e(Zr,EIo),e(Zr,fv),e(fv,Xme),e(Xme,CIo),e(fv,wIo),e(fv,uO),e(uO,AIo),e(fv,yIo),e(Zr,LIo),e(Zr,mv),e(mv,zme),e(zme,xIo),e(mv,$Io),e(mv,_O),e(_O,kIo),e(mv,SIo),e(oo,RIo),e(oo,gv),e(gv,PIo),e(gv,Qme),e(Qme,BIo),e(gv,IIo),e(gv,Wme),e(Wme,qIo),e(oo,NIo),M(hv,oo,null),b(f,uqe,_),b(f,Ki,_),e(Ki,pv),e(pv,Hme),M(L0,Hme,null),e(Ki,jIo),e(Ki,Ume),e(Ume,DIo),b(f,_qe,_),b(f,qo,_),M(x0,qo,null),e(qo,GIo),e(qo,Zi),e(Zi,OIo),e(Zi,bO),e(bO,VIo),e(Zi,XIo),e(Zi,vO),e(vO,zIo),e(Zi,QIo),e(qo,WIo),e(qo,$0),e($0,HIo),e($0,Jme),e(Jme,UIo),e($0,JIo),e(qo,YIo),e(qo,ft),M(k0,ft,null),e(ft,KIo),e(ft,Yme),e(Yme,ZIo),e(ft,eqo),e(ft,ed),e(ed,oqo),e(ed,Kme),e(Kme,rqo),e(ed,tqo),e(ed,FO),e(FO,aqo),e(ed,nqo),e(ft,sqo),M(uv,ft,null),e(qo,lqo),e(qo,ro),M(S0,ro,null),e(ro,iqo),e(ro,Zme),e(Zme,dqo),e(ro,cqo),e(ro,Na),e(Na,fqo),e(Na,ege),e(ege,mqo),e(Na,gqo),e(Na,oge),e(oge,hqo),e(Na,pqo),e(Na,rge),e(rge,uqo),e(Na,_qo),e(ro,bqo),e(ro,U),e(U,_v),e(_v,tge),e(tge,vqo),e(_v,Fqo),e(_v,TO),e(TO,Tqo),e(_v,Mqo),e(U,Eqo),e(U,bv),e(bv,age),e(age,Cqo),e(bv,wqo),e(bv,MO),e(MO,Aqo),e(bv,yqo),e(U,Lqo),e(U,vv),e(vv,nge),e(nge,xqo),e(vv,$qo),e(vv,EO),e(EO,kqo),e(vv,Sqo),e(U,Rqo),e(U,Fv),e(Fv,sge),e(sge,Pqo),e(Fv,Bqo),e(Fv,CO),e(CO,Iqo),e(Fv,qqo),e(U,Nqo),e(U,Tv),e(Tv,lge),e(lge,jqo),e(Tv,Dqo),e(Tv,wO),e(wO,Gqo),e(Tv,Oqo),e(U,Vqo),e(U,Mv),e(Mv,ige),e(ige,Xqo),e(Mv,zqo),e(Mv,AO),e(AO,Qqo),e(Mv,Wqo),e(U,Hqo),e(U,Ev),e(Ev,dge),e(dge,Uqo),e(Ev,Jqo),e(Ev,yO),e(yO,Yqo),e(Ev,Kqo),e(U,Zqo),e(U,Cv),e(Cv,cge),e(cge,eNo),e(Cv,oNo),e(Cv,LO),e(LO,rNo),e(Cv,tNo),e(U,aNo),e(U,wv),e(wv,fge),e(fge,nNo),e(wv,sNo),e(wv,xO),e(xO,lNo),e(wv,iNo),e(U,dNo),e(U,Av),e(Av,mge),e(mge,cNo),e(Av,fNo),e(Av,$O),e($O,mNo),e(Av,gNo),e(U,hNo),e(U,yv),e(yv,gge),e(gge,pNo),e(yv,uNo),e(yv,kO),e(kO,_No),e(yv,bNo),e(U,vNo),e(U,Lv),e(Lv,hge),e(hge,FNo),e(Lv,TNo),e(Lv,SO),e(SO,MNo),e(Lv,ENo),e(U,CNo),e(U,xv),e(xv,pge),e(pge,wNo),e(xv,ANo),e(xv,RO),e(RO,yNo),e(xv,LNo),e(U,xNo),e(U,$v),e($v,uge),e(uge,$No),e($v,kNo),e($v,PO),e(PO,SNo),e($v,RNo),e(U,PNo),e(U,kv),e(kv,_ge),e(_ge,BNo),e(kv,INo),e(kv,BO),e(BO,qNo),e(kv,NNo),e(U,jNo),e(U,Sv),e(Sv,bge),e(bge,DNo),e(Sv,GNo),e(Sv,IO),e(IO,ONo),e(Sv,VNo),e(U,XNo),e(U,Rv),e(Rv,vge),e(vge,zNo),e(Rv,QNo),e(Rv,qO),e(qO,WNo),e(Rv,HNo),e(U,UNo),e(U,Pv),e(Pv,Fge),e(Fge,JNo),e(Pv,YNo),e(Pv,NO),e(NO,KNo),e(Pv,ZNo),e(U,ejo),e(U,Bv),e(Bv,Tge),e(Tge,ojo),e(Bv,rjo),e(Bv,jO),e(jO,tjo),e(Bv,ajo),e(U,njo),e(U,Iv),e(Iv,Mge),e(Mge,sjo),e(Iv,ljo),e(Iv,DO),e(DO,ijo),e(Iv,djo),e(U,cjo),e(U,qv),e(qv,Ege),e(Ege,fjo),e(qv,mjo),e(qv,GO),e(GO,gjo),e(qv,hjo),e(U,pjo),e(U,Nv),e(Nv,Cge),e(Cge,ujo),e(Nv,_jo),e(Nv,OO),e(OO,bjo),e(Nv,vjo),e(U,Fjo),e(U,jv),e(jv,wge),e(wge,Tjo),e(jv,Mjo),e(jv,VO),e(VO,Ejo),e(jv,Cjo),e(U,wjo),e(U,Dv),e(Dv,Age),e(Age,Ajo),e(Dv,yjo),e(Dv,XO),e(XO,Ljo),e(Dv,xjo),e(U,$jo),e(U,Gv),e(Gv,yge),e(yge,kjo),e(Gv,Sjo),e(Gv,zO),e(zO,Rjo),e(Gv,Pjo),e(U,Bjo),e(U,Ov),e(Ov,Lge),e(Lge,Ijo),e(Ov,qjo),e(Ov,QO),e(QO,Njo),e(Ov,jjo),e(U,Djo),e(U,Vv),e(Vv,xge),e(xge,Gjo),e(Vv,Ojo),e(Vv,WO),e(WO,Vjo),e(Vv,Xjo),e(U,zjo),e(U,Xv),e(Xv,$ge),e($ge,Qjo),e(Xv,Wjo),e(Xv,HO),e(HO,Hjo),e(Xv,Ujo),e(U,Jjo),e(U,zv),e(zv,kge),e(kge,Yjo),e(zv,Kjo),e(zv,UO),e(UO,Zjo),e(zv,eDo),e(U,oDo),e(U,Qv),e(Qv,Sge),e(Sge,rDo),e(Qv,tDo),e(Qv,JO),e(JO,aDo),e(Qv,nDo),e(U,sDo),e(U,Wv),e(Wv,Rge),e(Rge,lDo),e(Wv,iDo),e(Wv,YO),e(YO,dDo),e(Wv,cDo),e(U,fDo),e(U,Hv),e(Hv,Pge),e(Pge,mDo),e(Hv,gDo),e(Hv,KO),e(KO,hDo),e(Hv,pDo),e(U,uDo),e(U,Uv),e(Uv,Bge),e(Bge,_Do),e(Uv,bDo),e(Uv,ZO),e(ZO,vDo),e(Uv,FDo),e(ro,TDo),e(ro,Jv),e(Jv,MDo),e(Jv,Ige),e(Ige,EDo),e(Jv,CDo),e(Jv,qge),e(qge,wDo),e(ro,ADo),M(Yv,ro,null),b(f,bqe,_),b(f,od,_),e(od,Kv),e(Kv,Nge),M(R0,Nge,null),e(od,yDo),e(od,jge),e(jge,LDo),b(f,vqe,_),b(f,No,_),M(P0,No,null),e(No,xDo),e(No,rd),e(rd,$Do),e(rd,eV),e(eV,kDo),e(rd,SDo),e(rd,oV),e(oV,RDo),e(rd,PDo),e(No,BDo),e(No,B0),e(B0,IDo),e(B0,Dge),e(Dge,qDo),e(B0,NDo),e(No,jDo),e(No,mt),M(I0,mt,null),e(mt,DDo),e(mt,Gge),e(Gge,GDo),e(mt,ODo),e(mt,td),e(td,VDo),e(td,Oge),e(Oge,XDo),e(td,zDo),e(td,rV),e(rV,QDo),e(td,WDo),e(mt,HDo),M(Zv,mt,null),e(No,UDo),e(No,to),M(q0,to,null),e(to,JDo),e(to,Vge),e(Vge,YDo),e(to,KDo),e(to,ja),e(ja,ZDo),e(ja,Xge),e(Xge,eGo),e(ja,oGo),e(ja,zge),e(zge,rGo),e(ja,tGo),e(ja,Qge),e(Qge,aGo),e(ja,nGo),e(to,sGo),e(to,O),e(O,eF),e(eF,Wge),e(Wge,lGo),e(eF,iGo),e(eF,tV),e(tV,dGo),e(eF,cGo),e(O,fGo),e(O,oF),e(oF,Hge),e(Hge,mGo),e(oF,gGo),e(oF,aV),e(aV,hGo),e(oF,pGo),e(O,uGo),e(O,rF),e(rF,Uge),e(Uge,_Go),e(rF,bGo),e(rF,nV),e(nV,vGo),e(rF,FGo),e(O,TGo),e(O,tF),e(tF,Jge),e(Jge,MGo),e(tF,EGo),e(tF,sV),e(sV,CGo),e(tF,wGo),e(O,AGo),e(O,aF),e(aF,Yge),e(Yge,yGo),e(aF,LGo),e(aF,lV),e(lV,xGo),e(aF,$Go),e(O,kGo),e(O,nF),e(nF,Kge),e(Kge,SGo),e(nF,RGo),e(nF,iV),e(iV,PGo),e(nF,BGo),e(O,IGo),e(O,sF),e(sF,Zge),e(Zge,qGo),e(sF,NGo),e(sF,dV),e(dV,jGo),e(sF,DGo),e(O,GGo),e(O,lF),e(lF,ehe),e(ehe,OGo),e(lF,VGo),e(lF,cV),e(cV,XGo),e(lF,zGo),e(O,QGo),e(O,iF),e(iF,ohe),e(ohe,WGo),e(iF,HGo),e(iF,fV),e(fV,UGo),e(iF,JGo),e(O,YGo),e(O,dF),e(dF,rhe),e(rhe,KGo),e(dF,ZGo),e(dF,mV),e(mV,eOo),e(dF,oOo),e(O,rOo),e(O,cF),e(cF,the),e(the,tOo),e(cF,aOo),e(cF,gV),e(gV,nOo),e(cF,sOo),e(O,lOo),e(O,fF),e(fF,ahe),e(ahe,iOo),e(fF,dOo),e(fF,hV),e(hV,cOo),e(fF,fOo),e(O,mOo),e(O,mF),e(mF,nhe),e(nhe,gOo),e(mF,hOo),e(mF,pV),e(pV,pOo),e(mF,uOo),e(O,_Oo),e(O,gF),e(gF,she),e(she,bOo),e(gF,vOo),e(gF,uV),e(uV,FOo),e(gF,TOo),e(O,MOo),e(O,hF),e(hF,lhe),e(lhe,EOo),e(hF,COo),e(hF,_V),e(_V,wOo),e(hF,AOo),e(O,yOo),e(O,pF),e(pF,ihe),e(ihe,LOo),e(pF,xOo),e(pF,bV),e(bV,$Oo),e(pF,kOo),e(O,SOo),e(O,uF),e(uF,dhe),e(dhe,ROo),e(uF,POo),e(uF,vV),e(vV,BOo),e(uF,IOo),e(O,qOo),e(O,_F),e(_F,che),e(che,NOo),e(_F,jOo),e(_F,FV),e(FV,DOo),e(_F,GOo),e(O,OOo),e(O,bF),e(bF,fhe),e(fhe,VOo),e(bF,XOo),e(bF,TV),e(TV,zOo),e(bF,QOo),e(O,WOo),e(O,vF),e(vF,mhe),e(mhe,HOo),e(vF,UOo),e(vF,MV),e(MV,JOo),e(vF,YOo),e(O,KOo),e(O,FF),e(FF,ghe),e(ghe,ZOo),e(FF,eVo),e(FF,EV),e(EV,oVo),e(FF,rVo),e(O,tVo),e(O,TF),e(TF,hhe),e(hhe,aVo),e(TF,nVo),e(TF,CV),e(CV,sVo),e(TF,lVo),e(O,iVo),e(O,MF),e(MF,phe),e(phe,dVo),e(MF,cVo),e(MF,wV),e(wV,fVo),e(MF,mVo),e(O,gVo),e(O,EF),e(EF,uhe),e(uhe,hVo),e(EF,pVo),e(EF,AV),e(AV,uVo),e(EF,_Vo),e(O,bVo),e(O,CF),e(CF,_he),e(_he,vVo),e(CF,FVo),e(CF,yV),e(yV,TVo),e(CF,MVo),e(O,EVo),e(O,wF),e(wF,bhe),e(bhe,CVo),e(wF,wVo),e(wF,LV),e(LV,AVo),e(wF,yVo),e(O,LVo),e(O,AF),e(AF,vhe),e(vhe,xVo),e(AF,$Vo),e(AF,xV),e(xV,kVo),e(AF,SVo),e(O,RVo),e(O,yF),e(yF,Fhe),e(Fhe,PVo),e(yF,BVo),e(yF,$V),e($V,IVo),e(yF,qVo),e(O,NVo),e(O,LF),e(LF,The),e(The,jVo),e(LF,DVo),e(LF,kV),e(kV,GVo),e(LF,OVo),e(O,VVo),e(O,xF),e(xF,Mhe),e(Mhe,XVo),e(xF,zVo),e(xF,SV),e(SV,QVo),e(xF,WVo),e(O,HVo),e(O,$F),e($F,Ehe),e(Ehe,UVo),e($F,JVo),e($F,RV),e(RV,YVo),e($F,KVo),e(O,ZVo),e(O,kF),e(kF,Che),e(Che,eXo),e(kF,oXo),e(kF,PV),e(PV,rXo),e(kF,tXo),e(O,aXo),e(O,SF),e(SF,whe),e(whe,nXo),e(SF,sXo),e(SF,BV),e(BV,lXo),e(SF,iXo),e(O,dXo),e(O,RF),e(RF,Ahe),e(Ahe,cXo),e(RF,fXo),e(RF,IV),e(IV,mXo),e(RF,gXo),e(O,hXo),e(O,PF),e(PF,yhe),e(yhe,pXo),e(PF,uXo),e(PF,qV),e(qV,_Xo),e(PF,bXo),e(O,vXo),e(O,BF),e(BF,Lhe),e(Lhe,FXo),e(BF,TXo),e(BF,NV),e(NV,MXo),e(BF,EXo),e(O,CXo),e(O,IF),e(IF,xhe),e(xhe,wXo),e(IF,AXo),e(IF,jV),e(jV,yXo),e(IF,LXo),e(O,xXo),e(O,qF),e(qF,$he),e($he,$Xo),e(qF,kXo),e(qF,DV),e(DV,SXo),e(qF,RXo),e(O,PXo),e(O,NF),e(NF,khe),e(khe,BXo),e(NF,IXo),e(NF,GV),e(GV,qXo),e(NF,NXo),e(to,jXo),e(to,jF),e(jF,DXo),e(jF,She),e(She,GXo),e(jF,OXo),e(jF,Rhe),e(Rhe,VXo),e(to,XXo),M(DF,to,null),b(f,Fqe,_),b(f,ad,_),e(ad,GF),e(GF,Phe),M(N0,Phe,null),e(ad,zXo),e(ad,Bhe),e(Bhe,QXo),b(f,Tqe,_),b(f,jo,_),M(j0,jo,null),e(jo,WXo),e(jo,nd),e(nd,HXo),e(nd,OV),e(OV,UXo),e(nd,JXo),e(nd,VV),e(VV,YXo),e(nd,KXo),e(jo,ZXo),e(jo,D0),e(D0,ezo),e(D0,Ihe),e(Ihe,ozo),e(D0,rzo),e(jo,tzo),e(jo,gt),M(G0,gt,null),e(gt,azo),e(gt,qhe),e(qhe,nzo),e(gt,szo),e(gt,sd),e(sd,lzo),e(sd,Nhe),e(Nhe,izo),e(sd,dzo),e(sd,XV),e(XV,czo),e(sd,fzo),e(gt,mzo),M(OF,gt,null),e(jo,gzo),e(jo,ao),M(O0,ao,null),e(ao,hzo),e(ao,jhe),e(jhe,pzo),e(ao,uzo),e(ao,Da),e(Da,_zo),e(Da,Dhe),e(Dhe,bzo),e(Da,vzo),e(Da,Ghe),e(Ghe,Fzo),e(Da,Tzo),e(Da,Ohe),e(Ohe,Mzo),e(Da,Ezo),e(ao,Czo),e(ao,Vhe),e(Vhe,VF),e(VF,Xhe),e(Xhe,wzo),e(VF,Azo),e(VF,zV),e(zV,yzo),e(VF,Lzo),e(ao,xzo),e(ao,XF),e(XF,$zo),e(XF,zhe),e(zhe,kzo),e(XF,Szo),e(XF,Qhe),e(Qhe,Rzo),e(ao,Pzo),M(zF,ao,null),b(f,Mqe,_),b(f,ld,_),e(ld,QF),e(QF,Whe),M(V0,Whe,null),e(ld,Bzo),e(ld,Hhe),e(Hhe,Izo),b(f,Eqe,_),b(f,Do,_),M(X0,Do,null),e(Do,qzo),e(Do,id),e(id,Nzo),e(id,QV),e(QV,jzo),e(id,Dzo),e(id,WV),e(WV,Gzo),e(id,Ozo),e(Do,Vzo),e(Do,z0),e(z0,Xzo),e(z0,Uhe),e(Uhe,zzo),e(z0,Qzo),e(Do,Wzo),e(Do,ht),M(Q0,ht,null),e(ht,Hzo),e(ht,Jhe),e(Jhe,Uzo),e(ht,Jzo),e(ht,dd),e(dd,Yzo),e(dd,Yhe),e(Yhe,Kzo),e(dd,Zzo),e(dd,HV),e(HV,eQo),e(dd,oQo),e(ht,rQo),M(WF,ht,null),e(Do,tQo),e(Do,no),M(W0,no,null),e(no,aQo),e(no,Khe),e(Khe,nQo),e(no,sQo),e(no,Ga),e(Ga,lQo),e(Ga,Zhe),e(Zhe,iQo),e(Ga,dQo),e(Ga,epe),e(epe,cQo),e(Ga,fQo),e(Ga,ope),e(ope,mQo),e(Ga,gQo),e(no,hQo),e(no,Fe),e(Fe,HF),e(HF,rpe),e(rpe,pQo),e(HF,uQo),e(HF,UV),e(UV,_Qo),e(HF,bQo),e(Fe,vQo),e(Fe,UF),e(UF,tpe),e(tpe,FQo),e(UF,TQo),e(UF,JV),e(JV,MQo),e(UF,EQo),e(Fe,CQo),e(Fe,JF),e(JF,ape),e(ape,wQo),e(JF,AQo),e(JF,YV),e(YV,yQo),e(JF,LQo),e(Fe,xQo),e(Fe,js),e(js,npe),e(npe,$Qo),e(js,kQo),e(js,KV),e(KV,SQo),e(js,RQo),e(js,ZV),e(ZV,PQo),e(js,BQo),e(Fe,IQo),e(Fe,YF),e(YF,spe),e(spe,qQo),e(YF,NQo),e(YF,eX),e(eX,jQo),e(YF,DQo),e(Fe,GQo),e(Fe,pt),e(pt,lpe),e(lpe,OQo),e(pt,VQo),e(pt,oX),e(oX,XQo),e(pt,zQo),e(pt,rX),e(rX,QQo),e(pt,WQo),e(pt,tX),e(tX,HQo),e(pt,UQo),e(Fe,JQo),e(Fe,KF),e(KF,ipe),e(ipe,YQo),e(KF,KQo),e(KF,aX),e(aX,ZQo),e(KF,eWo),e(Fe,oWo),e(Fe,ZF),e(ZF,dpe),e(dpe,rWo),e(ZF,tWo),e(ZF,nX),e(nX,aWo),e(ZF,nWo),e(Fe,sWo),e(Fe,e6),e(e6,cpe),e(cpe,lWo),e(e6,iWo),e(e6,sX),e(sX,dWo),e(e6,cWo),e(Fe,fWo),e(Fe,o6),e(o6,fpe),e(fpe,mWo),e(o6,gWo),e(o6,lX),e(lX,hWo),e(o6,pWo),e(Fe,uWo),e(Fe,r6),e(r6,mpe),e(mpe,_Wo),e(r6,bWo),e(r6,iX),e(iX,vWo),e(r6,FWo),e(Fe,TWo),e(Fe,t6),e(t6,gpe),e(gpe,MWo),e(t6,EWo),e(t6,dX),e(dX,CWo),e(t6,wWo),e(Fe,AWo),e(Fe,a6),e(a6,hpe),e(hpe,yWo),e(a6,LWo),e(a6,cX),e(cX,xWo),e(a6,$Wo),e(no,kWo),e(no,n6),e(n6,SWo),e(n6,ppe),e(ppe,RWo),e(n6,PWo),e(n6,upe),e(upe,BWo),e(no,IWo),M(s6,no,null),b(f,Cqe,_),b(f,cd,_),e(cd,l6),e(l6,_pe),M(H0,_pe,null),e(cd,qWo),e(cd,bpe),e(bpe,NWo),b(f,wqe,_),b(f,Go,_),M(U0,Go,null),e(Go,jWo),e(Go,fd),e(fd,DWo),e(fd,fX),e(fX,GWo),e(fd,OWo),e(fd,mX),e(mX,VWo),e(fd,XWo),e(Go,zWo),e(Go,J0),e(J0,QWo),e(J0,vpe),e(vpe,WWo),e(J0,HWo),e(Go,UWo),e(Go,ut),M(Y0,ut,null),e(ut,JWo),e(ut,Fpe),e(Fpe,YWo),e(ut,KWo),e(ut,md),e(md,ZWo),e(md,Tpe),e(Tpe,eHo),e(md,oHo),e(md,gX),e(gX,rHo),e(md,tHo),e(ut,aHo),M(i6,ut,null),e(Go,nHo),e(Go,so),M(K0,so,null),e(so,sHo),e(so,Mpe),e(Mpe,lHo),e(so,iHo),e(so,Oa),e(Oa,dHo),e(Oa,Epe),e(Epe,cHo),e(Oa,fHo),e(Oa,Cpe),e(Cpe,mHo),e(Oa,gHo),e(Oa,wpe),e(wpe,hHo),e(Oa,pHo),e(so,uHo),e(so,Ape),e(Ape,d6),e(d6,ype),e(ype,_Ho),e(d6,bHo),e(d6,hX),e(hX,vHo),e(d6,FHo),e(so,THo),e(so,c6),e(c6,MHo),e(c6,Lpe),e(Lpe,EHo),e(c6,CHo),e(c6,xpe),e(xpe,wHo),e(so,AHo),M(f6,so,null),b(f,Aqe,_),b(f,gd,_),e(gd,m6),e(m6,$pe),M(Z0,$pe,null),e(gd,yHo),e(gd,kpe),e(kpe,LHo),b(f,yqe,_),b(f,Oo,_),M(ey,Oo,null),e(Oo,xHo),e(Oo,hd),e(hd,$Ho),e(hd,pX),e(pX,kHo),e(hd,SHo),e(hd,uX),e(uX,RHo),e(hd,PHo),e(Oo,BHo),e(Oo,oy),e(oy,IHo),e(oy,Spe),e(Spe,qHo),e(oy,NHo),e(Oo,jHo),e(Oo,_t),M(ry,_t,null),e(_t,DHo),e(_t,Rpe),e(Rpe,GHo),e(_t,OHo),e(_t,pd),e(pd,VHo),e(pd,Ppe),e(Ppe,XHo),e(pd,zHo),e(pd,_X),e(_X,QHo),e(pd,WHo),e(_t,HHo),M(g6,_t,null),e(Oo,UHo),e(Oo,lo),M(ty,lo,null),e(lo,JHo),e(lo,Bpe),e(Bpe,YHo),e(lo,KHo),e(lo,Va),e(Va,ZHo),e(Va,Ipe),e(Ipe,eUo),e(Va,oUo),e(Va,qpe),e(qpe,rUo),e(Va,tUo),e(Va,Npe),e(Npe,aUo),e(Va,nUo),e(lo,sUo),e(lo,jpe),e(jpe,h6),e(h6,Dpe),e(Dpe,lUo),e(h6,iUo),e(h6,bX),e(bX,dUo),e(h6,cUo),e(lo,fUo),e(lo,p6),e(p6,mUo),e(p6,Gpe),e(Gpe,gUo),e(p6,hUo),e(p6,Ope),e(Ope,pUo),e(lo,uUo),M(u6,lo,null),b(f,Lqe,_),b(f,ud,_),e(ud,_6),e(_6,Vpe),M(ay,Vpe,null),e(ud,_Uo),e(ud,Xpe),e(Xpe,bUo),b(f,xqe,_),b(f,Vo,_),M(ny,Vo,null),e(Vo,vUo),e(Vo,_d),e(_d,FUo),e(_d,vX),e(vX,TUo),e(_d,MUo),e(_d,FX),e(FX,EUo),e(_d,CUo),e(Vo,wUo),e(Vo,sy),e(sy,AUo),e(sy,zpe),e(zpe,yUo),e(sy,LUo),e(Vo,xUo),e(Vo,bt),M(ly,bt,null),e(bt,$Uo),e(bt,Qpe),e(Qpe,kUo),e(bt,SUo),e(bt,bd),e(bd,RUo),e(bd,Wpe),e(Wpe,PUo),e(bd,BUo),e(bd,TX),e(TX,IUo),e(bd,qUo),e(bt,NUo),M(b6,bt,null),e(Vo,jUo),e(Vo,io),M(iy,io,null),e(io,DUo),e(io,Hpe),e(Hpe,GUo),e(io,OUo),e(io,Xa),e(Xa,VUo),e(Xa,Upe),e(Upe,XUo),e(Xa,zUo),e(Xa,Jpe),e(Jpe,QUo),e(Xa,WUo),e(Xa,Ype),e(Ype,HUo),e(Xa,UUo),e(io,JUo),e(io,Ne),e(Ne,v6),e(v6,Kpe),e(Kpe,YUo),e(v6,KUo),e(v6,MX),e(MX,ZUo),e(v6,eJo),e(Ne,oJo),e(Ne,F6),e(F6,Zpe),e(Zpe,rJo),e(F6,tJo),e(F6,EX),e(EX,aJo),e(F6,nJo),e(Ne,sJo),e(Ne,T6),e(T6,eue),e(eue,lJo),e(T6,iJo),e(T6,CX),e(CX,dJo),e(T6,cJo),e(Ne,fJo),e(Ne,M6),e(M6,oue),e(oue,mJo),e(M6,gJo),e(M6,wX),e(wX,hJo),e(M6,pJo),e(Ne,uJo),e(Ne,E6),e(E6,rue),e(rue,_Jo),e(E6,bJo),e(E6,AX),e(AX,vJo),e(E6,FJo),e(Ne,TJo),e(Ne,C6),e(C6,tue),e(tue,MJo),e(C6,EJo),e(C6,yX),e(yX,CJo),e(C6,wJo),e(Ne,AJo),e(Ne,w6),e(w6,aue),e(aue,yJo),e(w6,LJo),e(w6,LX),e(LX,xJo),e(w6,$Jo),e(Ne,kJo),e(Ne,A6),e(A6,nue),e(nue,SJo),e(A6,RJo),e(A6,xX),e(xX,PJo),e(A6,BJo),e(io,IJo),e(io,y6),e(y6,qJo),e(y6,sue),e(sue,NJo),e(y6,jJo),e(y6,lue),e(lue,DJo),e(io,GJo),M(L6,io,null),b(f,$qe,_),b(f,vd,_),e(vd,x6),e(x6,iue),M(dy,iue,null),e(vd,OJo),e(vd,due),e(due,VJo),b(f,kqe,_),b(f,Xo,_),M(cy,Xo,null),e(Xo,XJo),e(Xo,Fd),e(Fd,zJo),e(Fd,$X),e($X,QJo),e(Fd,WJo),e(Fd,kX),e(kX,HJo),e(Fd,UJo),e(Xo,JJo),e(Xo,fy),e(fy,YJo),e(fy,cue),e(cue,KJo),e(fy,ZJo),e(Xo,eYo),e(Xo,vt),M(my,vt,null),e(vt,oYo),e(vt,fue),e(fue,rYo),e(vt,tYo),e(vt,Td),e(Td,aYo),e(Td,mue),e(mue,nYo),e(Td,sYo),e(Td,SX),e(SX,lYo),e(Td,iYo),e(vt,dYo),M($6,vt,null),e(Xo,cYo),e(Xo,co),M(gy,co,null),e(co,fYo),e(co,gue),e(gue,mYo),e(co,gYo),e(co,za),e(za,hYo),e(za,hue),e(hue,pYo),e(za,uYo),e(za,pue),e(pue,_Yo),e(za,bYo),e(za,uue),e(uue,vYo),e(za,FYo),e(co,TYo),e(co,Qa),e(Qa,k6),e(k6,_ue),e(_ue,MYo),e(k6,EYo),e(k6,RX),e(RX,CYo),e(k6,wYo),e(Qa,AYo),e(Qa,S6),e(S6,bue),e(bue,yYo),e(S6,LYo),e(S6,PX),e(PX,xYo),e(S6,$Yo),e(Qa,kYo),e(Qa,R6),e(R6,vue),e(vue,SYo),e(R6,RYo),e(R6,BX),e(BX,PYo),e(R6,BYo),e(Qa,IYo),e(Qa,P6),e(P6,Fue),e(Fue,qYo),e(P6,NYo),e(P6,IX),e(IX,jYo),e(P6,DYo),e(co,GYo),e(co,B6),e(B6,OYo),e(B6,Tue),e(Tue,VYo),e(B6,XYo),e(B6,Mue),e(Mue,zYo),e(co,QYo),M(I6,co,null),b(f,Sqe,_),b(f,Md,_),e(Md,q6),e(q6,Eue),M(hy,Eue,null),e(Md,WYo),e(Md,Cue),e(Cue,HYo),b(f,Rqe,_),b(f,zo,_),M(py,zo,null),e(zo,UYo),e(zo,Ed),e(Ed,JYo),e(Ed,qX),e(qX,YYo),e(Ed,KYo),e(Ed,NX),e(NX,ZYo),e(Ed,eKo),e(zo,oKo),e(zo,uy),e(uy,rKo),e(uy,wue),e(wue,tKo),e(uy,aKo),e(zo,nKo),e(zo,Ft),M(_y,Ft,null),e(Ft,sKo),e(Ft,Aue),e(Aue,lKo),e(Ft,iKo),e(Ft,Cd),e(Cd,dKo),e(Cd,yue),e(yue,cKo),e(Cd,fKo),e(Cd,jX),e(jX,mKo),e(Cd,gKo),e(Ft,hKo),M(N6,Ft,null),e(zo,pKo),e(zo,fo),M(by,fo,null),e(fo,uKo),e(fo,Lue),e(Lue,_Ko),e(fo,bKo),e(fo,Wa),e(Wa,vKo),e(Wa,xue),e(xue,FKo),e(Wa,TKo),e(Wa,$ue),e($ue,MKo),e(Wa,EKo),e(Wa,kue),e(kue,CKo),e(Wa,wKo),e(fo,AKo),e(fo,je),e(je,j6),e(j6,Sue),e(Sue,yKo),e(j6,LKo),e(j6,DX),e(DX,xKo),e(j6,$Ko),e(je,kKo),e(je,D6),e(D6,Rue),e(Rue,SKo),e(D6,RKo),e(D6,GX),e(GX,PKo),e(D6,BKo),e(je,IKo),e(je,G6),e(G6,Pue),e(Pue,qKo),e(G6,NKo),e(G6,OX),e(OX,jKo),e(G6,DKo),e(je,GKo),e(je,O6),e(O6,Bue),e(Bue,OKo),e(O6,VKo),e(O6,VX),e(VX,XKo),e(O6,zKo),e(je,QKo),e(je,V6),e(V6,Iue),e(Iue,WKo),e(V6,HKo),e(V6,XX),e(XX,UKo),e(V6,JKo),e(je,YKo),e(je,X6),e(X6,que),e(que,KKo),e(X6,ZKo),e(X6,zX),e(zX,eZo),e(X6,oZo),e(je,rZo),e(je,z6),e(z6,Nue),e(Nue,tZo),e(z6,aZo),e(z6,QX),e(QX,nZo),e(z6,sZo),e(je,lZo),e(je,Q6),e(Q6,jue),e(jue,iZo),e(Q6,dZo),e(Q6,WX),e(WX,cZo),e(Q6,fZo),e(fo,mZo),e(fo,W6),e(W6,gZo),e(W6,Due),e(Due,hZo),e(W6,pZo),e(W6,Gue),e(Gue,uZo),e(fo,_Zo),M(H6,fo,null),b(f,Pqe,_),b(f,wd,_),e(wd,U6),e(U6,Oue),M(vy,Oue,null),e(wd,bZo),e(wd,Vue),e(Vue,vZo),b(f,Bqe,_),b(f,Qo,_),M(Fy,Qo,null),e(Qo,FZo),e(Qo,Ad),e(Ad,TZo),e(Ad,HX),e(HX,MZo),e(Ad,EZo),e(Ad,UX),e(UX,CZo),e(Ad,wZo),e(Qo,AZo),e(Qo,Ty),e(Ty,yZo),e(Ty,Xue),e(Xue,LZo),e(Ty,xZo),e(Qo,$Zo),e(Qo,Tt),M(My,Tt,null),e(Tt,kZo),e(Tt,zue),e(zue,SZo),e(Tt,RZo),e(Tt,yd),e(yd,PZo),e(yd,Que),e(Que,BZo),e(yd,IZo),e(yd,JX),e(JX,qZo),e(yd,NZo),e(Tt,jZo),M(J6,Tt,null),e(Qo,DZo),e(Qo,mo),M(Ey,mo,null),e(mo,GZo),e(mo,Wue),e(Wue,OZo),e(mo,VZo),e(mo,Ha),e(Ha,XZo),e(Ha,Hue),e(Hue,zZo),e(Ha,QZo),e(Ha,Uue),e(Uue,WZo),e(Ha,HZo),e(Ha,Jue),e(Jue,UZo),e(Ha,JZo),e(mo,YZo),e(mo,Cy),e(Cy,Y6),e(Y6,Yue),e(Yue,KZo),e(Y6,ZZo),e(Y6,YX),e(YX,eer),e(Y6,oer),e(Cy,rer),e(Cy,K6),e(K6,Kue),e(Kue,ter),e(K6,aer),e(K6,KX),e(KX,ner),e(K6,ser),e(mo,ler),e(mo,Z6),e(Z6,ier),e(Z6,Zue),e(Zue,der),e(Z6,cer),e(Z6,e_e),e(e_e,fer),e(mo,mer),M(eT,mo,null),b(f,Iqe,_),b(f,Ld,_),e(Ld,oT),e(oT,o_e),M(wy,o_e,null),e(Ld,ger),e(Ld,r_e),e(r_e,her),b(f,qqe,_),b(f,Wo,_),M(Ay,Wo,null),e(Wo,per),e(Wo,xd),e(xd,uer),e(xd,ZX),e(ZX,_er),e(xd,ber),e(xd,ez),e(ez,ver),e(xd,Fer),e(Wo,Ter),e(Wo,yy),e(yy,Mer),e(yy,t_e),e(t_e,Eer),e(yy,Cer),e(Wo,wer),e(Wo,Mt),M(Ly,Mt,null),e(Mt,Aer),e(Mt,a_e),e(a_e,yer),e(Mt,Ler),e(Mt,$d),e($d,xer),e($d,n_e),e(n_e,$er),e($d,ker),e($d,oz),e(oz,Ser),e($d,Rer),e(Mt,Per),M(rT,Mt,null),e(Wo,Ber),e(Wo,go),M(xy,go,null),e(go,Ier),e(go,s_e),e(s_e,qer),e(go,Ner),e(go,Ua),e(Ua,jer),e(Ua,l_e),e(l_e,Der),e(Ua,Ger),e(Ua,i_e),e(i_e,Oer),e(Ua,Ver),e(Ua,d_e),e(d_e,Xer),e(Ua,zer),e(go,Qer),e(go,Ja),e(Ja,tT),e(tT,c_e),e(c_e,Wer),e(tT,Her),e(tT,rz),e(rz,Uer),e(tT,Jer),e(Ja,Yer),e(Ja,aT),e(aT,f_e),e(f_e,Ker),e(aT,Zer),e(aT,tz),e(tz,eor),e(aT,oor),e(Ja,ror),e(Ja,nT),e(nT,m_e),e(m_e,tor),e(nT,aor),e(nT,az),e(az,nor),e(nT,sor),e(Ja,lor),e(Ja,sT),e(sT,g_e),e(g_e,ior),e(sT,dor),e(sT,nz),e(nz,cor),e(sT,mor),e(go,gor),e(go,lT),e(lT,hor),e(lT,h_e),e(h_e,por),e(lT,uor),e(lT,p_e),e(p_e,_or),e(go,bor),M(iT,go,null),b(f,Nqe,_),b(f,kd,_),e(kd,dT),e(dT,u_e),M($y,u_e,null),e(kd,vor),e(kd,__e),e(__e,For),b(f,jqe,_),b(f,Ho,_),M(ky,Ho,null),e(Ho,Tor),e(Ho,Sd),e(Sd,Mor),e(Sd,sz),e(sz,Eor),e(Sd,Cor),e(Sd,lz),e(lz,wor),e(Sd,Aor),e(Ho,yor),e(Ho,Sy),e(Sy,Lor),e(Sy,b_e),e(b_e,xor),e(Sy,$or),e(Ho,kor),e(Ho,Et),M(Ry,Et,null),e(Et,Sor),e(Et,v_e),e(v_e,Ror),e(Et,Por),e(Et,Rd),e(Rd,Bor),e(Rd,F_e),e(F_e,Ior),e(Rd,qor),e(Rd,iz),e(iz,Nor),e(Rd,jor),e(Et,Dor),M(cT,Et,null),e(Ho,Gor),e(Ho,ho),M(Py,ho,null),e(ho,Oor),e(ho,T_e),e(T_e,Vor),e(ho,Xor),e(ho,Ya),e(Ya,zor),e(Ya,M_e),e(M_e,Qor),e(Ya,Wor),e(Ya,E_e),e(E_e,Hor),e(Ya,Uor),e(Ya,C_e),e(C_e,Jor),e(Ya,Yor),e(ho,Kor),e(ho,Pd),e(Pd,fT),e(fT,w_e),e(w_e,Zor),e(fT,err),e(fT,dz),e(dz,orr),e(fT,rrr),e(Pd,trr),e(Pd,mT),e(mT,A_e),e(A_e,arr),e(mT,nrr),e(mT,cz),e(cz,srr),e(mT,lrr),e(Pd,irr),e(Pd,gT),e(gT,y_e),e(y_e,drr),e(gT,crr),e(gT,fz),e(fz,frr),e(gT,mrr),e(ho,grr),e(ho,hT),e(hT,hrr),e(hT,L_e),e(L_e,prr),e(hT,urr),e(hT,x_e),e(x_e,_rr),e(ho,brr),M(pT,ho,null),b(f,Dqe,_),b(f,Bd,_),e(Bd,uT),e(uT,$_e),M(By,$_e,null),e(Bd,vrr),e(Bd,k_e),e(k_e,Frr),b(f,Gqe,_),b(f,Uo,_),M(Iy,Uo,null),e(Uo,Trr),e(Uo,Id),e(Id,Mrr),e(Id,mz),e(mz,Err),e(Id,Crr),e(Id,gz),e(gz,wrr),e(Id,Arr),e(Uo,yrr),e(Uo,qy),e(qy,Lrr),e(qy,S_e),e(S_e,xrr),e(qy,$rr),e(Uo,krr),e(Uo,Ct),M(Ny,Ct,null),e(Ct,Srr),e(Ct,R_e),e(R_e,Rrr),e(Ct,Prr),e(Ct,qd),e(qd,Brr),e(qd,P_e),e(P_e,Irr),e(qd,qrr),e(qd,hz),e(hz,Nrr),e(qd,jrr),e(Ct,Drr),M(_T,Ct,null),e(Uo,Grr),e(Uo,po),M(jy,po,null),e(po,Orr),e(po,B_e),e(B_e,Vrr),e(po,Xrr),e(po,Ka),e(Ka,zrr),e(Ka,I_e),e(I_e,Qrr),e(Ka,Wrr),e(Ka,q_e),e(q_e,Hrr),e(Ka,Urr),e(Ka,N_e),e(N_e,Jrr),e(Ka,Yrr),e(po,Krr),e(po,Dy),e(Dy,bT),e(bT,j_e),e(j_e,Zrr),e(bT,etr),e(bT,pz),e(pz,otr),e(bT,rtr),e(Dy,ttr),e(Dy,vT),e(vT,D_e),e(D_e,atr),e(vT,ntr),e(vT,uz),e(uz,str),e(vT,ltr),e(po,itr),e(po,FT),e(FT,dtr),e(FT,G_e),e(G_e,ctr),e(FT,ftr),e(FT,O_e),e(O_e,mtr),e(po,gtr),M(TT,po,null),b(f,Oqe,_),b(f,Nd,_),e(Nd,MT),e(MT,V_e),M(Gy,V_e,null),e(Nd,htr),e(Nd,X_e),e(X_e,ptr),b(f,Vqe,_),b(f,Jo,_),M(Oy,Jo,null),e(Jo,utr),e(Jo,jd),e(jd,_tr),e(jd,_z),e(_z,btr),e(jd,vtr),e(jd,bz),e(bz,Ftr),e(jd,Ttr),e(Jo,Mtr),e(Jo,Vy),e(Vy,Etr),e(Vy,z_e),e(z_e,Ctr),e(Vy,wtr),e(Jo,Atr),e(Jo,wt),M(Xy,wt,null),e(wt,ytr),e(wt,Q_e),e(Q_e,Ltr),e(wt,xtr),e(wt,Dd),e(Dd,$tr),e(Dd,W_e),e(W_e,ktr),e(Dd,Str),e(Dd,vz),e(vz,Rtr),e(Dd,Ptr),e(wt,Btr),M(ET,wt,null),e(Jo,Itr),e(Jo,uo),M(zy,uo,null),e(uo,qtr),e(uo,H_e),e(H_e,Ntr),e(uo,jtr),e(uo,Za),e(Za,Dtr),e(Za,U_e),e(U_e,Gtr),e(Za,Otr),e(Za,J_e),e(J_e,Vtr),e(Za,Xtr),e(Za,Y_e),e(Y_e,ztr),e(Za,Qtr),e(uo,Wtr),e(uo,K_e),e(K_e,CT),e(CT,Z_e),e(Z_e,Htr),e(CT,Utr),e(CT,Fz),e(Fz,Jtr),e(CT,Ytr),e(uo,Ktr),e(uo,wT),e(wT,Ztr),e(wT,e2e),e(e2e,ear),e(wT,oar),e(wT,o2e),e(o2e,rar),e(uo,tar),M(AT,uo,null),b(f,Xqe,_),b(f,Gd,_),e(Gd,yT),e(yT,r2e),M(Qy,r2e,null),e(Gd,aar),e(Gd,t2e),e(t2e,nar),b(f,zqe,_),b(f,Yo,_),M(Wy,Yo,null),e(Yo,sar),e(Yo,Od),e(Od,lar),e(Od,Tz),e(Tz,iar),e(Od,dar),e(Od,Mz),e(Mz,car),e(Od,far),e(Yo,mar),e(Yo,Hy),e(Hy,gar),e(Hy,a2e),e(a2e,har),e(Hy,par),e(Yo,uar),e(Yo,At),M(Uy,At,null),e(At,_ar),e(At,n2e),e(n2e,bar),e(At,Far),e(At,Vd),e(Vd,Tar),e(Vd,s2e),e(s2e,Mar),e(Vd,Ear),e(Vd,Ez),e(Ez,Car),e(Vd,war),e(At,Aar),M(LT,At,null),e(Yo,yar),e(Yo,_o),M(Jy,_o,null),e(_o,Lar),e(_o,l2e),e(l2e,xar),e(_o,$ar),e(_o,en),e(en,kar),e(en,i2e),e(i2e,Sar),e(en,Rar),e(en,d2e),e(d2e,Par),e(en,Bar),e(en,c2e),e(c2e,Iar),e(en,qar),e(_o,Nar),e(_o,on),e(on,xT),e(xT,f2e),e(f2e,jar),e(xT,Dar),e(xT,Cz),e(Cz,Gar),e(xT,Oar),e(on,Var),e(on,$T),e($T,m2e),e(m2e,Xar),e($T,zar),e($T,wz),e(wz,Qar),e($T,War),e(on,Har),e(on,kT),e(kT,g2e),e(g2e,Uar),e(kT,Jar),e(kT,Az),e(Az,Yar),e(kT,Kar),e(on,Zar),e(on,ST),e(ST,h2e),e(h2e,enr),e(ST,onr),e(ST,yz),e(yz,rnr),e(ST,tnr),e(_o,anr),e(_o,RT),e(RT,nnr),e(RT,p2e),e(p2e,snr),e(RT,lnr),e(RT,u2e),e(u2e,inr),e(_o,dnr),M(PT,_o,null),b(f,Qqe,_),b(f,Xd,_),e(Xd,BT),e(BT,_2e),M(Yy,_2e,null),e(Xd,cnr),e(Xd,b2e),e(b2e,fnr),b(f,Wqe,_),b(f,Ko,_),M(Ky,Ko,null),e(Ko,mnr),e(Ko,zd),e(zd,gnr),e(zd,Lz),e(Lz,hnr),e(zd,pnr),e(zd,xz),e(xz,unr),e(zd,_nr),e(Ko,bnr),e(Ko,Zy),e(Zy,vnr),e(Zy,v2e),e(v2e,Fnr),e(Zy,Tnr),e(Ko,Mnr),e(Ko,yt),M(eL,yt,null),e(yt,Enr),e(yt,F2e),e(F2e,Cnr),e(yt,wnr),e(yt,Qd),e(Qd,Anr),e(Qd,T2e),e(T2e,ynr),e(Qd,Lnr),e(Qd,$z),e($z,xnr),e(Qd,$nr),e(yt,knr),M(IT,yt,null),e(Ko,Snr),e(Ko,bo),M(oL,bo,null),e(bo,Rnr),e(bo,M2e),e(M2e,Pnr),e(bo,Bnr),e(bo,rn),e(rn,Inr),e(rn,E2e),e(E2e,qnr),e(rn,Nnr),e(rn,C2e),e(C2e,jnr),e(rn,Dnr),e(rn,w2e),e(w2e,Gnr),e(rn,Onr),e(bo,Vnr),e(bo,A2e),e(A2e,qT),e(qT,y2e),e(y2e,Xnr),e(qT,znr),e(qT,kz),e(kz,Qnr),e(qT,Wnr),e(bo,Hnr),e(bo,NT),e(NT,Unr),e(NT,L2e),e(L2e,Jnr),e(NT,Ynr),e(NT,x2e),e(x2e,Knr),e(bo,Znr),M(jT,bo,null),b(f,Hqe,_),b(f,Wd,_),e(Wd,DT),e(DT,$2e),M(rL,$2e,null),e(Wd,esr),e(Wd,k2e),e(k2e,osr),b(f,Uqe,_),b(f,Zo,_),M(tL,Zo,null),e(Zo,rsr),e(Zo,Hd),e(Hd,tsr),e(Hd,Sz),e(Sz,asr),e(Hd,nsr),e(Hd,Rz),e(Rz,ssr),e(Hd,lsr),e(Zo,isr),e(Zo,aL),e(aL,dsr),e(aL,S2e),e(S2e,csr),e(aL,fsr),e(Zo,msr),e(Zo,Lt),M(nL,Lt,null),e(Lt,gsr),e(Lt,R2e),e(R2e,hsr),e(Lt,psr),e(Lt,Ud),e(Ud,usr),e(Ud,P2e),e(P2e,_sr),e(Ud,bsr),e(Ud,Pz),e(Pz,vsr),e(Ud,Fsr),e(Lt,Tsr),M(GT,Lt,null),e(Zo,Msr),e(Zo,yr),M(sL,yr,null),e(yr,Esr),e(yr,B2e),e(B2e,Csr),e(yr,wsr),e(yr,tn),e(tn,Asr),e(tn,I2e),e(I2e,ysr),e(tn,Lsr),e(tn,q2e),e(q2e,xsr),e(tn,$sr),e(tn,N2e),e(N2e,ksr),e(tn,Ssr),e(yr,Rsr),e(yr,j),e(j,OT),e(OT,j2e),e(j2e,Psr),e(OT,Bsr),e(OT,Bz),e(Bz,Isr),e(OT,qsr),e(j,Nsr),e(j,VT),e(VT,D2e),e(D2e,jsr),e(VT,Dsr),e(VT,Iz),e(Iz,Gsr),e(VT,Osr),e(j,Vsr),e(j,XT),e(XT,G2e),e(G2e,Xsr),e(XT,zsr),e(XT,qz),e(qz,Qsr),e(XT,Wsr),e(j,Hsr),e(j,zT),e(zT,O2e),e(O2e,Usr),e(zT,Jsr),e(zT,Nz),e(Nz,Ysr),e(zT,Ksr),e(j,Zsr),e(j,QT),e(QT,V2e),e(V2e,elr),e(QT,olr),e(QT,jz),e(jz,rlr),e(QT,tlr),e(j,alr),e(j,WT),e(WT,X2e),e(X2e,nlr),e(WT,slr),e(WT,Dz),e(Dz,llr),e(WT,ilr),e(j,dlr),e(j,HT),e(HT,z2e),e(z2e,clr),e(HT,flr),e(HT,Gz),e(Gz,mlr),e(HT,glr),e(j,hlr),e(j,UT),e(UT,Q2e),e(Q2e,plr),e(UT,ulr),e(UT,Oz),e(Oz,_lr),e(UT,blr),e(j,vlr),e(j,JT),e(JT,W2e),e(W2e,Flr),e(JT,Tlr),e(JT,Vz),e(Vz,Mlr),e(JT,Elr),e(j,Clr),e(j,YT),e(YT,H2e),e(H2e,wlr),e(YT,Alr),e(YT,Xz),e(Xz,ylr),e(YT,Llr),e(j,xlr),e(j,KT),e(KT,U2e),e(U2e,$lr),e(KT,klr),e(KT,zz),e(zz,Slr),e(KT,Rlr),e(j,Plr),e(j,ZT),e(ZT,J2e),e(J2e,Blr),e(ZT,Ilr),e(ZT,Qz),e(Qz,qlr),e(ZT,Nlr),e(j,jlr),e(j,e8),e(e8,Y2e),e(Y2e,Dlr),e(e8,Glr),e(e8,Wz),e(Wz,Olr),e(e8,Vlr),e(j,Xlr),e(j,o8),e(o8,K2e),e(K2e,zlr),e(o8,Qlr),e(o8,Hz),e(Hz,Wlr),e(o8,Hlr),e(j,Ulr),e(j,r8),e(r8,Z2e),e(Z2e,Jlr),e(r8,Ylr),e(r8,Uz),e(Uz,Klr),e(r8,Zlr),e(j,eir),e(j,t8),e(t8,e1e),e(e1e,oir),e(t8,rir),e(t8,Jz),e(Jz,tir),e(t8,air),e(j,nir),e(j,a8),e(a8,o1e),e(o1e,sir),e(a8,lir),e(a8,Yz),e(Yz,iir),e(a8,dir),e(j,cir),e(j,Ds),e(Ds,r1e),e(r1e,fir),e(Ds,mir),e(Ds,Kz),e(Kz,gir),e(Ds,hir),e(Ds,Zz),e(Zz,pir),e(Ds,uir),e(j,_ir),e(j,n8),e(n8,t1e),e(t1e,bir),e(n8,vir),e(n8,eQ),e(eQ,Fir),e(n8,Tir),e(j,Mir),e(j,s8),e(s8,a1e),e(a1e,Eir),e(s8,Cir),e(s8,oQ),e(oQ,wir),e(s8,Air),e(j,yir),e(j,l8),e(l8,n1e),e(n1e,Lir),e(l8,xir),e(l8,rQ),e(rQ,$ir),e(l8,kir),e(j,Sir),e(j,i8),e(i8,s1e),e(s1e,Rir),e(i8,Pir),e(i8,tQ),e(tQ,Bir),e(i8,Iir),e(j,qir),e(j,d8),e(d8,l1e),e(l1e,Nir),e(d8,jir),e(d8,aQ),e(aQ,Dir),e(d8,Gir),e(j,Oir),e(j,c8),e(c8,i1e),e(i1e,Vir),e(c8,Xir),e(c8,nQ),e(nQ,zir),e(c8,Qir),e(j,Wir),e(j,f8),e(f8,d1e),e(d1e,Hir),e(f8,Uir),e(f8,sQ),e(sQ,Jir),e(f8,Yir),e(j,Kir),e(j,m8),e(m8,c1e),e(c1e,Zir),e(m8,edr),e(m8,lQ),e(lQ,odr),e(m8,rdr),e(j,tdr),e(j,g8),e(g8,f1e),e(f1e,adr),e(g8,ndr),e(g8,iQ),e(iQ,sdr),e(g8,ldr),e(j,idr),e(j,h8),e(h8,m1e),e(m1e,ddr),e(h8,cdr),e(h8,dQ),e(dQ,fdr),e(h8,mdr),e(j,gdr),e(j,p8),e(p8,g1e),e(g1e,hdr),e(p8,pdr),e(p8,cQ),e(cQ,udr),e(p8,_dr),e(j,bdr),e(j,u8),e(u8,h1e),e(h1e,vdr),e(u8,Fdr),e(u8,fQ),e(fQ,Tdr),e(u8,Mdr),e(j,Edr),e(j,_8),e(_8,p1e),e(p1e,Cdr),e(_8,wdr),e(_8,mQ),e(mQ,Adr),e(_8,ydr),e(j,Ldr),e(j,b8),e(b8,u1e),e(u1e,xdr),e(b8,$dr),e(b8,gQ),e(gQ,kdr),e(b8,Sdr),e(j,Rdr),e(j,v8),e(v8,_1e),e(_1e,Pdr),e(v8,Bdr),e(v8,hQ),e(hQ,Idr),e(v8,qdr),e(j,Ndr),e(j,F8),e(F8,b1e),e(b1e,jdr),e(F8,Ddr),e(F8,pQ),e(pQ,Gdr),e(F8,Odr),e(j,Vdr),e(j,T8),e(T8,v1e),e(v1e,Xdr),e(T8,zdr),e(T8,uQ),e(uQ,Qdr),e(T8,Wdr),e(j,Hdr),e(j,M8),e(M8,F1e),e(F1e,Udr),e(M8,Jdr),e(M8,_Q),e(_Q,Ydr),e(M8,Kdr),e(j,Zdr),e(j,E8),e(E8,T1e),e(T1e,ecr),e(E8,ocr),e(E8,bQ),e(bQ,rcr),e(E8,tcr),e(j,acr),e(j,C8),e(C8,M1e),e(M1e,ncr),e(C8,scr),e(C8,vQ),e(vQ,lcr),e(C8,icr),e(j,dcr),e(j,w8),e(w8,E1e),e(E1e,ccr),e(w8,fcr),e(w8,FQ),e(FQ,mcr),e(w8,gcr),e(j,hcr),e(j,A8),e(A8,C1e),e(C1e,pcr),e(A8,ucr),e(A8,TQ),e(TQ,_cr),e(A8,bcr),e(j,vcr),e(j,y8),e(y8,w1e),e(w1e,Fcr),e(y8,Tcr),e(y8,MQ),e(MQ,Mcr),e(y8,Ecr),e(j,Ccr),e(j,L8),e(L8,A1e),e(A1e,wcr),e(L8,Acr),e(L8,EQ),e(EQ,ycr),e(L8,Lcr),e(j,xcr),e(j,x8),e(x8,y1e),e(y1e,$cr),e(x8,kcr),e(x8,CQ),e(CQ,Scr),e(x8,Rcr),e(j,Pcr),e(j,$8),e($8,L1e),e(L1e,Bcr),e($8,Icr),e($8,wQ),e(wQ,qcr),e($8,Ncr),e(j,jcr),e(j,k8),e(k8,x1e),e(x1e,Dcr),e(k8,Gcr),e(k8,AQ),e(AQ,Ocr),e(k8,Vcr),e(yr,Xcr),M(S8,yr,null),b(f,Jqe,_),b(f,Jd,_),e(Jd,R8),e(R8,$1e),M(lL,$1e,null),e(Jd,zcr),e(Jd,k1e),e(k1e,Qcr),b(f,Yqe,_),b(f,er,_),M(iL,er,null),e(er,Wcr),e(er,Yd),e(Yd,Hcr),e(Yd,yQ),e(yQ,Ucr),e(Yd,Jcr),e(Yd,LQ),e(LQ,Ycr),e(Yd,Kcr),e(er,Zcr),e(er,dL),e(dL,efr),e(dL,S1e),e(S1e,ofr),e(dL,rfr),e(er,tfr),e(er,xt),M(cL,xt,null),e(xt,afr),e(xt,R1e),e(R1e,nfr),e(xt,sfr),e(xt,Kd),e(Kd,lfr),e(Kd,P1e),e(P1e,ifr),e(Kd,dfr),e(Kd,xQ),e(xQ,cfr),e(Kd,ffr),e(xt,mfr),M(P8,xt,null),e(er,gfr),e(er,Lr),M(fL,Lr,null),e(Lr,hfr),e(Lr,B1e),e(B1e,pfr),e(Lr,ufr),e(Lr,an),e(an,_fr),e(an,I1e),e(I1e,bfr),e(an,vfr),e(an,q1e),e(q1e,Ffr),e(an,Tfr),e(an,N1e),e(N1e,Mfr),e(an,Efr),e(Lr,Cfr),e(Lr,se),e(se,B8),e(B8,j1e),e(j1e,wfr),e(B8,Afr),e(B8,$Q),e($Q,yfr),e(B8,Lfr),e(se,xfr),e(se,I8),e(I8,D1e),e(D1e,$fr),e(I8,kfr),e(I8,kQ),e(kQ,Sfr),e(I8,Rfr),e(se,Pfr),e(se,q8),e(q8,G1e),e(G1e,Bfr),e(q8,Ifr),e(q8,SQ),e(SQ,qfr),e(q8,Nfr),e(se,jfr),e(se,N8),e(N8,O1e),e(O1e,Dfr),e(N8,Gfr),e(N8,RQ),e(RQ,Ofr),e(N8,Vfr),e(se,Xfr),e(se,j8),e(j8,V1e),e(V1e,zfr),e(j8,Qfr),e(j8,PQ),e(PQ,Wfr),e(j8,Hfr),e(se,Ufr),e(se,D8),e(D8,X1e),e(X1e,Jfr),e(D8,Yfr),e(D8,BQ),e(BQ,Kfr),e(D8,Zfr),e(se,emr),e(se,G8),e(G8,z1e),e(z1e,omr),e(G8,rmr),e(G8,IQ),e(IQ,tmr),e(G8,amr),e(se,nmr),e(se,O8),e(O8,Q1e),e(Q1e,smr),e(O8,lmr),e(O8,qQ),e(qQ,imr),e(O8,dmr),e(se,cmr),e(se,V8),e(V8,W1e),e(W1e,fmr),e(V8,mmr),e(V8,NQ),e(NQ,gmr),e(V8,hmr),e(se,pmr),e(se,X8),e(X8,H1e),e(H1e,umr),e(X8,_mr),e(X8,jQ),e(jQ,bmr),e(X8,vmr),e(se,Fmr),e(se,z8),e(z8,U1e),e(U1e,Tmr),e(z8,Mmr),e(z8,DQ),e(DQ,Emr),e(z8,Cmr),e(se,wmr),e(se,Q8),e(Q8,J1e),e(J1e,Amr),e(Q8,ymr),e(Q8,GQ),e(GQ,Lmr),e(Q8,xmr),e(se,$mr),e(se,W8),e(W8,Y1e),e(Y1e,kmr),e(W8,Smr),e(W8,OQ),e(OQ,Rmr),e(W8,Pmr),e(se,Bmr),e(se,H8),e(H8,K1e),e(K1e,Imr),e(H8,qmr),e(H8,VQ),e(VQ,Nmr),e(H8,jmr),e(se,Dmr),e(se,U8),e(U8,Z1e),e(Z1e,Gmr),e(U8,Omr),e(U8,XQ),e(XQ,Vmr),e(U8,Xmr),e(se,zmr),e(se,J8),e(J8,ebe),e(ebe,Qmr),e(J8,Wmr),e(J8,zQ),e(zQ,Hmr),e(J8,Umr),e(se,Jmr),e(se,Y8),e(Y8,obe),e(obe,Ymr),e(Y8,Kmr),e(Y8,QQ),e(QQ,Zmr),e(Y8,egr),e(se,ogr),e(se,K8),e(K8,rbe),e(rbe,rgr),e(K8,tgr),e(K8,WQ),e(WQ,agr),e(K8,ngr),e(se,sgr),e(se,Z8),e(Z8,tbe),e(tbe,lgr),e(Z8,igr),e(Z8,HQ),e(HQ,dgr),e(Z8,cgr),e(se,fgr),e(se,e7),e(e7,abe),e(abe,mgr),e(e7,ggr),e(e7,UQ),e(UQ,hgr),e(e7,pgr),e(se,ugr),e(se,o7),e(o7,nbe),e(nbe,_gr),e(o7,bgr),e(o7,JQ),e(JQ,vgr),e(o7,Fgr),e(se,Tgr),e(se,r7),e(r7,sbe),e(sbe,Mgr),e(r7,Egr),e(r7,YQ),e(YQ,Cgr),e(r7,wgr),e(se,Agr),e(se,t7),e(t7,lbe),e(lbe,ygr),e(t7,Lgr),e(t7,KQ),e(KQ,xgr),e(t7,$gr),e(Lr,kgr),M(a7,Lr,null),b(f,Kqe,_),b(f,Zd,_),e(Zd,n7),e(n7,ibe),M(mL,ibe,null),e(Zd,Sgr),e(Zd,dbe),e(dbe,Rgr),b(f,Zqe,_),b(f,or,_),M(gL,or,null),e(or,Pgr),e(or,ec),e(ec,Bgr),e(ec,ZQ),e(ZQ,Igr),e(ec,qgr),e(ec,eW),e(eW,Ngr),e(ec,jgr),e(or,Dgr),e(or,hL),e(hL,Ggr),e(hL,cbe),e(cbe,Ogr),e(hL,Vgr),e(or,Xgr),e(or,$t),M(pL,$t,null),e($t,zgr),e($t,fbe),e(fbe,Qgr),e($t,Wgr),e($t,oc),e(oc,Hgr),e(oc,mbe),e(mbe,Ugr),e(oc,Jgr),e(oc,oW),e(oW,Ygr),e(oc,Kgr),e($t,Zgr),M(s7,$t,null),e(or,ehr),e(or,xr),M(uL,xr,null),e(xr,ohr),e(xr,gbe),e(gbe,rhr),e(xr,thr),e(xr,nn),e(nn,ahr),e(nn,hbe),e(hbe,nhr),e(nn,shr),e(nn,pbe),e(pbe,lhr),e(nn,ihr),e(nn,ube),e(ube,dhr),e(nn,chr),e(xr,fhr),e(xr,Te),e(Te,l7),e(l7,_be),e(_be,mhr),e(l7,ghr),e(l7,rW),e(rW,hhr),e(l7,phr),e(Te,uhr),e(Te,i7),e(i7,bbe),e(bbe,_hr),e(i7,bhr),e(i7,tW),e(tW,vhr),e(i7,Fhr),e(Te,Thr),e(Te,d7),e(d7,vbe),e(vbe,Mhr),e(d7,Ehr),e(d7,aW),e(aW,Chr),e(d7,whr),e(Te,Ahr),e(Te,c7),e(c7,Fbe),e(Fbe,yhr),e(c7,Lhr),e(c7,nW),e(nW,xhr),e(c7,$hr),e(Te,khr),e(Te,f7),e(f7,Tbe),e(Tbe,Shr),e(f7,Rhr),e(f7,sW),e(sW,Phr),e(f7,Bhr),e(Te,Ihr),e(Te,m7),e(m7,Mbe),e(Mbe,qhr),e(m7,Nhr),e(m7,lW),e(lW,jhr),e(m7,Dhr),e(Te,Ghr),e(Te,g7),e(g7,Ebe),e(Ebe,Ohr),e(g7,Vhr),e(g7,iW),e(iW,Xhr),e(g7,zhr),e(Te,Qhr),e(Te,h7),e(h7,Cbe),e(Cbe,Whr),e(h7,Hhr),e(h7,dW),e(dW,Uhr),e(h7,Jhr),e(Te,Yhr),e(Te,p7),e(p7,wbe),e(wbe,Khr),e(p7,Zhr),e(p7,cW),e(cW,epr),e(p7,opr),e(Te,rpr),e(Te,u7),e(u7,Abe),e(Abe,tpr),e(u7,apr),e(u7,fW),e(fW,npr),e(u7,spr),e(Te,lpr),e(Te,_7),e(_7,ybe),e(ybe,ipr),e(_7,dpr),e(_7,mW),e(mW,cpr),e(_7,fpr),e(Te,mpr),e(Te,b7),e(b7,Lbe),e(Lbe,gpr),e(b7,hpr),e(b7,gW),e(gW,ppr),e(b7,upr),e(xr,_pr),M(v7,xr,null),b(f,eNe,_),b(f,rc,_),e(rc,F7),e(F7,xbe),M(_L,xbe,null),e(rc,bpr),e(rc,$be),e($be,vpr),b(f,oNe,_),b(f,rr,_),M(bL,rr,null),e(rr,Fpr),e(rr,tc),e(tc,Tpr),e(tc,hW),e(hW,Mpr),e(tc,Epr),e(tc,pW),e(pW,Cpr),e(tc,wpr),e(rr,Apr),e(rr,vL),e(vL,ypr),e(vL,kbe),e(kbe,Lpr),e(vL,xpr),e(rr,$pr),e(rr,kt),M(FL,kt,null),e(kt,kpr),e(kt,Sbe),e(Sbe,Spr),e(kt,Rpr),e(kt,ac),e(ac,Ppr),e(ac,Rbe),e(Rbe,Bpr),e(ac,Ipr),e(ac,uW),e(uW,qpr),e(ac,Npr),e(kt,jpr),M(T7,kt,null),e(rr,Dpr),e(rr,$r),M(TL,$r,null),e($r,Gpr),e($r,Pbe),e(Pbe,Opr),e($r,Vpr),e($r,sn),e(sn,Xpr),e(sn,Bbe),e(Bbe,zpr),e(sn,Qpr),e(sn,Ibe),e(Ibe,Wpr),e(sn,Hpr),e(sn,qbe),e(qbe,Upr),e(sn,Jpr),e($r,Ypr),e($r,nc),e(nc,M7),e(M7,Nbe),e(Nbe,Kpr),e(M7,Zpr),e(M7,_W),e(_W,eur),e(M7,our),e(nc,rur),e(nc,E7),e(E7,jbe),e(jbe,tur),e(E7,aur),e(E7,bW),e(bW,nur),e(E7,sur),e(nc,lur),e(nc,C7),e(C7,Dbe),e(Dbe,iur),e(C7,dur),e(C7,vW),e(vW,cur),e(C7,fur),e($r,mur),M(w7,$r,null),b(f,rNe,_),b(f,sc,_),e(sc,A7),e(A7,Gbe),M(ML,Gbe,null),e(sc,gur),e(sc,Obe),e(Obe,hur),b(f,tNe,_),b(f,tr,_),M(EL,tr,null),e(tr,pur),e(tr,lc),e(lc,uur),e(lc,FW),e(FW,_ur),e(lc,bur),e(lc,TW),e(TW,vur),e(lc,Fur),e(tr,Tur),e(tr,CL),e(CL,Mur),e(CL,Vbe),e(Vbe,Eur),e(CL,Cur),e(tr,wur),e(tr,St),M(wL,St,null),e(St,Aur),e(St,Xbe),e(Xbe,yur),e(St,Lur),e(St,ic),e(ic,xur),e(ic,zbe),e(zbe,$ur),e(ic,kur),e(ic,MW),e(MW,Sur),e(ic,Rur),e(St,Pur),M(y7,St,null),e(tr,Bur),e(tr,kr),M(AL,kr,null),e(kr,Iur),e(kr,Qbe),e(Qbe,qur),e(kr,Nur),e(kr,ln),e(ln,jur),e(ln,Wbe),e(Wbe,Dur),e(ln,Gur),e(ln,Hbe),e(Hbe,Our),e(ln,Vur),e(ln,Ube),e(Ube,Xur),e(ln,zur),e(kr,Qur),e(kr,ie),e(ie,L7),e(L7,Jbe),e(Jbe,Wur),e(L7,Hur),e(L7,EW),e(EW,Uur),e(L7,Jur),e(ie,Yur),e(ie,x7),e(x7,Ybe),e(Ybe,Kur),e(x7,Zur),e(x7,CW),e(CW,e_r),e(x7,o_r),e(ie,r_r),e(ie,$7),e($7,Kbe),e(Kbe,t_r),e($7,a_r),e($7,wW),e(wW,n_r),e($7,s_r),e(ie,l_r),e(ie,k7),e(k7,Zbe),e(Zbe,i_r),e(k7,d_r),e(k7,AW),e(AW,c_r),e(k7,f_r),e(ie,m_r),e(ie,S7),e(S7,eve),e(eve,g_r),e(S7,h_r),e(S7,yW),e(yW,p_r),e(S7,u_r),e(ie,__r),e(ie,R7),e(R7,ove),e(ove,b_r),e(R7,v_r),e(R7,LW),e(LW,F_r),e(R7,T_r),e(ie,M_r),e(ie,P7),e(P7,rve),e(rve,E_r),e(P7,C_r),e(P7,xW),e(xW,w_r),e(P7,A_r),e(ie,y_r),e(ie,B7),e(B7,tve),e(tve,L_r),e(B7,x_r),e(B7,$W),e($W,$_r),e(B7,k_r),e(ie,S_r),e(ie,I7),e(I7,ave),e(ave,R_r),e(I7,P_r),e(I7,kW),e(kW,B_r),e(I7,I_r),e(ie,q_r),e(ie,q7),e(q7,nve),e(nve,N_r),e(q7,j_r),e(q7,SW),e(SW,D_r),e(q7,G_r),e(ie,O_r),e(ie,N7),e(N7,sve),e(sve,V_r),e(N7,X_r),e(N7,RW),e(RW,z_r),e(N7,Q_r),e(ie,W_r),e(ie,j7),e(j7,lve),e(lve,H_r),e(j7,U_r),e(j7,PW),e(PW,J_r),e(j7,Y_r),e(ie,K_r),e(ie,D7),e(D7,ive),e(ive,Z_r),e(D7,e2r),e(D7,BW),e(BW,o2r),e(D7,r2r),e(ie,t2r),e(ie,G7),e(G7,dve),e(dve,a2r),e(G7,n2r),e(G7,IW),e(IW,s2r),e(G7,l2r),e(ie,i2r),e(ie,O7),e(O7,cve),e(cve,d2r),e(O7,c2r),e(O7,qW),e(qW,f2r),e(O7,m2r),e(ie,g2r),e(ie,V7),e(V7,fve),e(fve,h2r),e(V7,p2r),e(V7,NW),e(NW,u2r),e(V7,_2r),e(ie,b2r),e(ie,X7),e(X7,mve),e(mve,v2r),e(X7,F2r),e(X7,jW),e(jW,T2r),e(X7,M2r),e(ie,E2r),e(ie,z7),e(z7,gve),e(gve,C2r),e(z7,w2r),e(z7,DW),e(DW,A2r),e(z7,y2r),e(ie,L2r),e(ie,Q7),e(Q7,hve),e(hve,x2r),e(Q7,$2r),e(Q7,GW),e(GW,k2r),e(Q7,S2r),e(ie,R2r),e(ie,W7),e(W7,pve),e(pve,P2r),e(W7,B2r),e(W7,OW),e(OW,I2r),e(W7,q2r),e(kr,N2r),M(H7,kr,null),b(f,aNe,_),b(f,dc,_),e(dc,U7),e(U7,uve),M(yL,uve,null),e(dc,j2r),e(dc,_ve),e(_ve,D2r),b(f,nNe,_),b(f,ar,_),M(LL,ar,null),e(ar,G2r),e(ar,cc),e(cc,O2r),e(cc,VW),e(VW,V2r),e(cc,X2r),e(cc,XW),e(XW,z2r),e(cc,Q2r),e(ar,W2r),e(ar,xL),e(xL,H2r),e(xL,bve),e(bve,U2r),e(xL,J2r),e(ar,Y2r),e(ar,Rt),M($L,Rt,null),e(Rt,K2r),e(Rt,vve),e(vve,Z2r),e(Rt,e1r),e(Rt,fc),e(fc,o1r),e(fc,Fve),e(Fve,r1r),e(fc,t1r),e(fc,zW),e(zW,a1r),e(fc,n1r),e(Rt,s1r),M(J7,Rt,null),e(ar,l1r),e(ar,Sr),M(kL,Sr,null),e(Sr,i1r),e(Sr,Tve),e(Tve,d1r),e(Sr,c1r),e(Sr,dn),e(dn,f1r),e(dn,Mve),e(Mve,m1r),e(dn,g1r),e(dn,Eve),e(Eve,h1r),e(dn,p1r),e(dn,Cve),e(Cve,u1r),e(dn,_1r),e(Sr,b1r),e(Sr,ye),e(ye,Y7),e(Y7,wve),e(wve,v1r),e(Y7,F1r),e(Y7,QW),e(QW,T1r),e(Y7,M1r),e(ye,E1r),e(ye,K7),e(K7,Ave),e(Ave,C1r),e(K7,w1r),e(K7,WW),e(WW,A1r),e(K7,y1r),e(ye,L1r),e(ye,Z7),e(Z7,yve),e(yve,x1r),e(Z7,$1r),e(Z7,HW),e(HW,k1r),e(Z7,S1r),e(ye,R1r),e(ye,eM),e(eM,Lve),e(Lve,P1r),e(eM,B1r),e(eM,UW),e(UW,I1r),e(eM,q1r),e(ye,N1r),e(ye,oM),e(oM,xve),e(xve,j1r),e(oM,D1r),e(oM,JW),e(JW,G1r),e(oM,O1r),e(ye,V1r),e(ye,rM),e(rM,$ve),e($ve,X1r),e(rM,z1r),e(rM,YW),e(YW,Q1r),e(rM,W1r),e(ye,H1r),e(ye,tM),e(tM,kve),e(kve,U1r),e(tM,J1r),e(tM,KW),e(KW,Y1r),e(tM,K1r),e(ye,Z1r),e(ye,aM),e(aM,Sve),e(Sve,ebr),e(aM,obr),e(aM,ZW),e(ZW,rbr),e(aM,tbr),e(ye,abr),e(ye,nM),e(nM,Rve),e(Rve,nbr),e(nM,sbr),e(nM,eH),e(eH,lbr),e(nM,ibr),e(ye,dbr),e(ye,sM),e(sM,Pve),e(Pve,cbr),e(sM,fbr),e(sM,oH),e(oH,mbr),e(sM,gbr),e(Sr,hbr),M(lM,Sr,null),b(f,sNe,_),b(f,mc,_),e(mc,iM),e(iM,Bve),M(SL,Bve,null),e(mc,pbr),e(mc,Ive),e(Ive,ubr),b(f,lNe,_),b(f,nr,_),M(RL,nr,null),e(nr,_br),e(nr,gc),e(gc,bbr),e(gc,rH),e(rH,vbr),e(gc,Fbr),e(gc,tH),e(tH,Tbr),e(gc,Mbr),e(nr,Ebr),e(nr,PL),e(PL,Cbr),e(PL,qve),e(qve,wbr),e(PL,Abr),e(nr,ybr),e(nr,Pt),M(BL,Pt,null),e(Pt,Lbr),e(Pt,Nve),e(Nve,xbr),e(Pt,$br),e(Pt,hc),e(hc,kbr),e(hc,jve),e(jve,Sbr),e(hc,Rbr),e(hc,aH),e(aH,Pbr),e(hc,Bbr),e(Pt,Ibr),M(dM,Pt,null),e(nr,qbr),e(nr,Rr),M(IL,Rr,null),e(Rr,Nbr),e(Rr,Dve),e(Dve,jbr),e(Rr,Dbr),e(Rr,cn),e(cn,Gbr),e(cn,Gve),e(Gve,Obr),e(cn,Vbr),e(cn,Ove),e(Ove,Xbr),e(cn,zbr),e(cn,Vve),e(Vve,Qbr),e(cn,Wbr),e(Rr,Hbr),e(Rr,oe),e(oe,cM),e(cM,Xve),e(Xve,Ubr),e(cM,Jbr),e(cM,nH),e(nH,Ybr),e(cM,Kbr),e(oe,Zbr),e(oe,fM),e(fM,zve),e(zve,evr),e(fM,ovr),e(fM,sH),e(sH,rvr),e(fM,tvr),e(oe,avr),e(oe,mM),e(mM,Qve),e(Qve,nvr),e(mM,svr),e(mM,lH),e(lH,lvr),e(mM,ivr),e(oe,dvr),e(oe,gM),e(gM,Wve),e(Wve,cvr),e(gM,fvr),e(gM,iH),e(iH,mvr),e(gM,gvr),e(oe,hvr),e(oe,hM),e(hM,Hve),e(Hve,pvr),e(hM,uvr),e(hM,dH),e(dH,_vr),e(hM,bvr),e(oe,vvr),e(oe,pM),e(pM,Uve),e(Uve,Fvr),e(pM,Tvr),e(pM,cH),e(cH,Mvr),e(pM,Evr),e(oe,Cvr),e(oe,uM),e(uM,Jve),e(Jve,wvr),e(uM,Avr),e(uM,fH),e(fH,yvr),e(uM,Lvr),e(oe,xvr),e(oe,_M),e(_M,Yve),e(Yve,$vr),e(_M,kvr),e(_M,mH),e(mH,Svr),e(_M,Rvr),e(oe,Pvr),e(oe,bM),e(bM,Kve),e(Kve,Bvr),e(bM,Ivr),e(bM,gH),e(gH,qvr),e(bM,Nvr),e(oe,jvr),e(oe,vM),e(vM,Zve),e(Zve,Dvr),e(vM,Gvr),e(vM,hH),e(hH,Ovr),e(vM,Vvr),e(oe,Xvr),e(oe,FM),e(FM,eFe),e(eFe,zvr),e(FM,Qvr),e(FM,pH),e(pH,Wvr),e(FM,Hvr),e(oe,Uvr),e(oe,TM),e(TM,oFe),e(oFe,Jvr),e(TM,Yvr),e(TM,uH),e(uH,Kvr),e(TM,Zvr),e(oe,eFr),e(oe,MM),e(MM,rFe),e(rFe,oFr),e(MM,rFr),e(MM,_H),e(_H,tFr),e(MM,aFr),e(oe,nFr),e(oe,EM),e(EM,tFe),e(tFe,sFr),e(EM,lFr),e(EM,bH),e(bH,iFr),e(EM,dFr),e(oe,cFr),e(oe,CM),e(CM,aFe),e(aFe,fFr),e(CM,mFr),e(CM,vH),e(vH,gFr),e(CM,hFr),e(oe,pFr),e(oe,wM),e(wM,nFe),e(nFe,uFr),e(wM,_Fr),e(wM,FH),e(FH,bFr),e(wM,vFr),e(oe,FFr),e(oe,AM),e(AM,sFe),e(sFe,TFr),e(AM,MFr),e(AM,TH),e(TH,EFr),e(AM,CFr),e(oe,wFr),e(oe,yM),e(yM,lFe),e(lFe,AFr),e(yM,yFr),e(yM,MH),e(MH,LFr),e(yM,xFr),e(oe,$Fr),e(oe,LM),e(LM,iFe),e(iFe,kFr),e(LM,SFr),e(LM,EH),e(EH,RFr),e(LM,PFr),e(oe,BFr),e(oe,xM),e(xM,dFe),e(dFe,IFr),e(xM,qFr),e(xM,CH),e(CH,NFr),e(xM,jFr),e(oe,DFr),e(oe,$M),e($M,cFe),e(cFe,GFr),e($M,OFr),e($M,wH),e(wH,VFr),e($M,XFr),e(oe,zFr),e(oe,kM),e(kM,fFe),e(fFe,QFr),e(kM,WFr),e(kM,AH),e(AH,HFr),e(kM,UFr),e(oe,JFr),e(oe,SM),e(SM,mFe),e(mFe,YFr),e(SM,KFr),e(SM,yH),e(yH,ZFr),e(SM,e6r),e(oe,o6r),e(oe,RM),e(RM,gFe),e(gFe,r6r),e(RM,t6r),e(RM,LH),e(LH,a6r),e(RM,n6r),e(oe,s6r),e(oe,PM),e(PM,hFe),e(hFe,l6r),e(PM,i6r),e(PM,xH),e(xH,d6r),e(PM,c6r),e(oe,f6r),e(oe,BM),e(BM,pFe),e(pFe,m6r),e(BM,g6r),e(BM,$H),e($H,h6r),e(BM,p6r),e(Rr,u6r),M(IM,Rr,null),b(f,iNe,_),b(f,pc,_),e(pc,qM),e(qM,uFe),M(qL,uFe,null),e(pc,_6r),e(pc,_Fe),e(_Fe,b6r),b(f,dNe,_),b(f,sr,_),M(NL,sr,null),e(sr,v6r),e(sr,uc),e(uc,F6r),e(uc,kH),e(kH,T6r),e(uc,M6r),e(uc,SH),e(SH,E6r),e(uc,C6r),e(sr,w6r),e(sr,jL),e(jL,A6r),e(jL,bFe),e(bFe,y6r),e(jL,L6r),e(sr,x6r),e(sr,Bt),M(DL,Bt,null),e(Bt,$6r),e(Bt,vFe),e(vFe,k6r),e(Bt,S6r),e(Bt,_c),e(_c,R6r),e(_c,FFe),e(FFe,P6r),e(_c,B6r),e(_c,RH),e(RH,I6r),e(_c,q6r),e(Bt,N6r),M(NM,Bt,null),e(sr,j6r),e(sr,Pr),M(GL,Pr,null),e(Pr,D6r),e(Pr,TFe),e(TFe,G6r),e(Pr,O6r),e(Pr,fn),e(fn,V6r),e(fn,MFe),e(MFe,X6r),e(fn,z6r),e(fn,EFe),e(EFe,Q6r),e(fn,W6r),e(fn,CFe),e(CFe,H6r),e(fn,U6r),e(Pr,J6r),e(Pr,pe),e(pe,jM),e(jM,wFe),e(wFe,Y6r),e(jM,K6r),e(jM,PH),e(PH,Z6r),e(jM,eTr),e(pe,oTr),e(pe,DM),e(DM,AFe),e(AFe,rTr),e(DM,tTr),e(DM,BH),e(BH,aTr),e(DM,nTr),e(pe,sTr),e(pe,GM),e(GM,yFe),e(yFe,lTr),e(GM,iTr),e(GM,IH),e(IH,dTr),e(GM,cTr),e(pe,fTr),e(pe,OM),e(OM,LFe),e(LFe,mTr),e(OM,gTr),e(OM,qH),e(qH,hTr),e(OM,pTr),e(pe,uTr),e(pe,VM),e(VM,xFe),e(xFe,_Tr),e(VM,bTr),e(VM,NH),e(NH,vTr),e(VM,FTr),e(pe,TTr),e(pe,XM),e(XM,$Fe),e($Fe,MTr),e(XM,ETr),e(XM,jH),e(jH,CTr),e(XM,wTr),e(pe,ATr),e(pe,zM),e(zM,kFe),e(kFe,yTr),e(zM,LTr),e(zM,DH),e(DH,xTr),e(zM,$Tr),e(pe,kTr),e(pe,QM),e(QM,SFe),e(SFe,STr),e(QM,RTr),e(QM,GH),e(GH,PTr),e(QM,BTr),e(pe,ITr),e(pe,WM),e(WM,RFe),e(RFe,qTr),e(WM,NTr),e(WM,OH),e(OH,jTr),e(WM,DTr),e(pe,GTr),e(pe,HM),e(HM,PFe),e(PFe,OTr),e(HM,VTr),e(HM,VH),e(VH,XTr),e(HM,zTr),e(pe,QTr),e(pe,UM),e(UM,BFe),e(BFe,WTr),e(UM,HTr),e(UM,XH),e(XH,UTr),e(UM,JTr),e(pe,YTr),e(pe,JM),e(JM,IFe),e(IFe,KTr),e(JM,ZTr),e(JM,zH),e(zH,e8r),e(JM,o8r),e(pe,r8r),e(pe,YM),e(YM,qFe),e(qFe,t8r),e(YM,a8r),e(YM,QH),e(QH,n8r),e(YM,s8r),e(pe,l8r),e(pe,KM),e(KM,NFe),e(NFe,i8r),e(KM,d8r),e(KM,WH),e(WH,c8r),e(KM,f8r),e(pe,m8r),e(pe,ZM),e(ZM,jFe),e(jFe,g8r),e(ZM,h8r),e(ZM,HH),e(HH,p8r),e(ZM,u8r),e(pe,_8r),e(pe,e4),e(e4,DFe),e(DFe,b8r),e(e4,v8r),e(e4,UH),e(UH,F8r),e(e4,T8r),e(pe,M8r),e(pe,o4),e(o4,GFe),e(GFe,E8r),e(o4,C8r),e(o4,JH),e(JH,w8r),e(o4,A8r),e(Pr,y8r),M(r4,Pr,null),b(f,cNe,_),b(f,bc,_),e(bc,t4),e(t4,OFe),M(OL,OFe,null),e(bc,L8r),e(bc,VFe),e(VFe,x8r),b(f,fNe,_),b(f,lr,_),M(VL,lr,null),e(lr,$8r),e(lr,vc),e(vc,k8r),e(vc,YH),e(YH,S8r),e(vc,R8r),e(vc,KH),e(KH,P8r),e(vc,B8r),e(lr,I8r),e(lr,XL),e(XL,q8r),e(XL,XFe),e(XFe,N8r),e(XL,j8r),e(lr,D8r),e(lr,It),M(zL,It,null),e(It,G8r),e(It,zFe),e(zFe,O8r),e(It,V8r),e(It,Fc),e(Fc,X8r),e(Fc,QFe),e(QFe,z8r),e(Fc,Q8r),e(Fc,ZH),e(ZH,W8r),e(Fc,H8r),e(It,U8r),M(a4,It,null),e(lr,J8r),e(lr,Br),M(QL,Br,null),e(Br,Y8r),e(Br,WFe),e(WFe,K8r),e(Br,Z8r),e(Br,mn),e(mn,e7r),e(mn,HFe),e(HFe,o7r),e(mn,r7r),e(mn,UFe),e(UFe,t7r),e(mn,a7r),e(mn,JFe),e(JFe,n7r),e(mn,s7r),e(Br,l7r),e(Br,WL),e(WL,n4),e(n4,YFe),e(YFe,i7r),e(n4,d7r),e(n4,eU),e(eU,c7r),e(n4,f7r),e(WL,m7r),e(WL,s4),e(s4,KFe),e(KFe,g7r),e(s4,h7r),e(s4,oU),e(oU,p7r),e(s4,u7r),e(Br,_7r),M(l4,Br,null),b(f,mNe,_),b(f,Tc,_),e(Tc,i4),e(i4,ZFe),M(HL,ZFe,null),e(Tc,b7r),e(Tc,e6e),e(e6e,v7r),b(f,gNe,_),b(f,ir,_),M(UL,ir,null),e(ir,F7r),e(ir,Mc),e(Mc,T7r),e(Mc,rU),e(rU,M7r),e(Mc,E7r),e(Mc,tU),e(tU,C7r),e(Mc,w7r),e(ir,A7r),e(ir,JL),e(JL,y7r),e(JL,o6e),e(o6e,L7r),e(JL,x7r),e(ir,$7r),e(ir,qt),M(YL,qt,null),e(qt,k7r),e(qt,r6e),e(r6e,S7r),e(qt,R7r),e(qt,Ec),e(Ec,P7r),e(Ec,t6e),e(t6e,B7r),e(Ec,I7r),e(Ec,aU),e(aU,q7r),e(Ec,N7r),e(qt,j7r),M(d4,qt,null),e(ir,D7r),e(ir,Ir),M(KL,Ir,null),e(Ir,G7r),e(Ir,a6e),e(a6e,O7r),e(Ir,V7r),e(Ir,gn),e(gn,X7r),e(gn,n6e),e(n6e,z7r),e(gn,Q7r),e(gn,s6e),e(s6e,W7r),e(gn,H7r),e(gn,l6e),e(l6e,U7r),e(gn,J7r),e(Ir,Y7r),e(Ir,i6e),e(i6e,c4),e(c4,d6e),e(d6e,K7r),e(c4,Z7r),e(c4,nU),e(nU,eMr),e(c4,oMr),e(Ir,rMr),M(f4,Ir,null),b(f,hNe,_),b(f,Cc,_),e(Cc,m4),e(m4,c6e),M(ZL,c6e,null),e(Cc,tMr),e(Cc,f6e),e(f6e,aMr),b(f,pNe,_),b(f,dr,_),M(ex,dr,null),e(dr,nMr),e(dr,wc),e(wc,sMr),e(wc,sU),e(sU,lMr),e(wc,iMr),e(wc,lU),e(lU,dMr),e(wc,cMr),e(dr,fMr),e(dr,ox),e(ox,mMr),e(ox,m6e),e(m6e,gMr),e(ox,hMr),e(dr,pMr),e(dr,Nt),M(rx,Nt,null),e(Nt,uMr),e(Nt,g6e),e(g6e,_Mr),e(Nt,bMr),e(Nt,Ac),e(Ac,vMr),e(Ac,h6e),e(h6e,FMr),e(Ac,TMr),e(Ac,iU),e(iU,MMr),e(Ac,EMr),e(Nt,CMr),M(g4,Nt,null),e(dr,wMr),e(dr,qr),M(tx,qr,null),e(qr,AMr),e(qr,p6e),e(p6e,yMr),e(qr,LMr),e(qr,hn),e(hn,xMr),e(hn,u6e),e(u6e,$Mr),e(hn,kMr),e(hn,_6e),e(_6e,SMr),e(hn,RMr),e(hn,b6e),e(b6e,PMr),e(hn,BMr),e(qr,IMr),e(qr,de),e(de,h4),e(h4,v6e),e(v6e,qMr),e(h4,NMr),e(h4,dU),e(dU,jMr),e(h4,DMr),e(de,GMr),e(de,p4),e(p4,F6e),e(F6e,OMr),e(p4,VMr),e(p4,cU),e(cU,XMr),e(p4,zMr),e(de,QMr),e(de,u4),e(u4,T6e),e(T6e,WMr),e(u4,HMr),e(u4,fU),e(fU,UMr),e(u4,JMr),e(de,YMr),e(de,_4),e(_4,M6e),e(M6e,KMr),e(_4,ZMr),e(_4,mU),e(mU,e4r),e(_4,o4r),e(de,r4r),e(de,b4),e(b4,E6e),e(E6e,t4r),e(b4,a4r),e(b4,gU),e(gU,n4r),e(b4,s4r),e(de,l4r),e(de,v4),e(v4,C6e),e(C6e,i4r),e(v4,d4r),e(v4,hU),e(hU,c4r),e(v4,f4r),e(de,m4r),e(de,F4),e(F4,w6e),e(w6e,g4r),e(F4,h4r),e(F4,pU),e(pU,p4r),e(F4,u4r),e(de,_4r),e(de,T4),e(T4,A6e),e(A6e,b4r),e(T4,v4r),e(T4,uU),e(uU,F4r),e(T4,T4r),e(de,M4r),e(de,M4),e(M4,y6e),e(y6e,E4r),e(M4,C4r),e(M4,_U),e(_U,w4r),e(M4,A4r),e(de,y4r),e(de,E4),e(E4,L6e),e(L6e,L4r),e(E4,x4r),e(E4,bU),e(bU,$4r),e(E4,k4r),e(de,S4r),e(de,C4),e(C4,x6e),e(x6e,R4r),e(C4,P4r),e(C4,vU),e(vU,B4r),e(C4,I4r),e(de,q4r),e(de,w4),e(w4,$6e),e($6e,N4r),e(w4,j4r),e(w4,FU),e(FU,D4r),e(w4,G4r),e(de,O4r),e(de,A4),e(A4,k6e),e(k6e,V4r),e(A4,X4r),e(A4,TU),e(TU,z4r),e(A4,Q4r),e(de,W4r),e(de,y4),e(y4,S6e),e(S6e,H4r),e(y4,U4r),e(y4,MU),e(MU,J4r),e(y4,Y4r),e(de,K4r),e(de,L4),e(L4,R6e),e(R6e,Z4r),e(L4,eEr),e(L4,EU),e(EU,oEr),e(L4,rEr),e(de,tEr),e(de,x4),e(x4,P6e),e(P6e,aEr),e(x4,nEr),e(x4,CU),e(CU,sEr),e(x4,lEr),e(de,iEr),e(de,$4),e($4,B6e),e(B6e,dEr),e($4,cEr),e($4,wU),e(wU,fEr),e($4,mEr),e(de,gEr),e(de,k4),e(k4,I6e),e(I6e,hEr),e(k4,pEr),e(k4,AU),e(AU,uEr),e(k4,_Er),e(de,bEr),e(de,S4),e(S4,q6e),e(q6e,vEr),e(S4,FEr),e(S4,yU),e(yU,TEr),e(S4,MEr),e(de,EEr),e(de,R4),e(R4,N6e),e(N6e,CEr),e(R4,wEr),e(R4,LU),e(LU,AEr),e(R4,yEr),e(qr,LEr),M(P4,qr,null),b(f,uNe,_),b(f,yc,_),e(yc,B4),e(B4,j6e),M(ax,j6e,null),e(yc,xEr),e(yc,D6e),e(D6e,$Er),b(f,_Ne,_),b(f,cr,_),M(nx,cr,null),e(cr,kEr),e(cr,Lc),e(Lc,SEr),e(Lc,xU),e(xU,REr),e(Lc,PEr),e(Lc,$U),e($U,BEr),e(Lc,IEr),e(cr,qEr),e(cr,sx),e(sx,NEr),e(sx,G6e),e(G6e,jEr),e(sx,DEr),e(cr,GEr),e(cr,jt),M(lx,jt,null),e(jt,OEr),e(jt,O6e),e(O6e,VEr),e(jt,XEr),e(jt,xc),e(xc,zEr),e(xc,V6e),e(V6e,QEr),e(xc,WEr),e(xc,kU),e(kU,HEr),e(xc,UEr),e(jt,JEr),M(I4,jt,null),e(cr,YEr),e(cr,Nr),M(ix,Nr,null),e(Nr,KEr),e(Nr,X6e),e(X6e,ZEr),e(Nr,e5r),e(Nr,pn),e(pn,o5r),e(pn,z6e),e(z6e,r5r),e(pn,t5r),e(pn,Q6e),e(Q6e,a5r),e(pn,n5r),e(pn,W6e),e(W6e,s5r),e(pn,l5r),e(Nr,i5r),e(Nr,ce),e(ce,q4),e(q4,H6e),e(H6e,d5r),e(q4,c5r),e(q4,SU),e(SU,f5r),e(q4,m5r),e(ce,g5r),e(ce,N4),e(N4,U6e),e(U6e,h5r),e(N4,p5r),e(N4,RU),e(RU,u5r),e(N4,_5r),e(ce,b5r),e(ce,j4),e(j4,J6e),e(J6e,v5r),e(j4,F5r),e(j4,PU),e(PU,T5r),e(j4,M5r),e(ce,E5r),e(ce,D4),e(D4,Y6e),e(Y6e,C5r),e(D4,w5r),e(D4,BU),e(BU,A5r),e(D4,y5r),e(ce,L5r),e(ce,G4),e(G4,K6e),e(K6e,x5r),e(G4,$5r),e(G4,IU),e(IU,k5r),e(G4,S5r),e(ce,R5r),e(ce,O4),e(O4,Z6e),e(Z6e,P5r),e(O4,B5r),e(O4,qU),e(qU,I5r),e(O4,q5r),e(ce,N5r),e(ce,V4),e(V4,eTe),e(eTe,j5r),e(V4,D5r),e(V4,NU),e(NU,G5r),e(V4,O5r),e(ce,V5r),e(ce,X4),e(X4,oTe),e(oTe,X5r),e(X4,z5r),e(X4,jU),e(jU,Q5r),e(X4,W5r),e(ce,H5r),e(ce,z4),e(z4,rTe),e(rTe,U5r),e(z4,J5r),e(z4,DU),e(DU,Y5r),e(z4,K5r),e(ce,Z5r),e(ce,Q4),e(Q4,tTe),e(tTe,eCr),e(Q4,oCr),e(Q4,GU),e(GU,rCr),e(Q4,tCr),e(ce,aCr),e(ce,W4),e(W4,aTe),e(aTe,nCr),e(W4,sCr),e(W4,OU),e(OU,lCr),e(W4,iCr),e(ce,dCr),e(ce,H4),e(H4,nTe),e(nTe,cCr),e(H4,fCr),e(H4,VU),e(VU,mCr),e(H4,gCr),e(ce,hCr),e(ce,U4),e(U4,sTe),e(sTe,pCr),e(U4,uCr),e(U4,XU),e(XU,_Cr),e(U4,bCr),e(ce,vCr),e(ce,J4),e(J4,lTe),e(lTe,FCr),e(J4,TCr),e(J4,zU),e(zU,MCr),e(J4,ECr),e(ce,CCr),e(ce,Y4),e(Y4,iTe),e(iTe,wCr),e(Y4,ACr),e(Y4,QU),e(QU,yCr),e(Y4,LCr),e(ce,xCr),e(ce,K4),e(K4,dTe),e(dTe,$Cr),e(K4,kCr),e(K4,WU),e(WU,SCr),e(K4,RCr),e(ce,PCr),e(ce,Z4),e(Z4,cTe),e(cTe,BCr),e(Z4,ICr),e(Z4,HU),e(HU,qCr),e(Z4,NCr),e(ce,jCr),e(ce,eE),e(eE,fTe),e(fTe,DCr),e(eE,GCr),e(eE,UU),e(UU,OCr),e(eE,VCr),e(ce,XCr),e(ce,oE),e(oE,mTe),e(mTe,zCr),e(oE,QCr),e(oE,JU),e(JU,WCr),e(oE,HCr),e(ce,UCr),e(ce,rE),e(rE,gTe),e(gTe,JCr),e(rE,YCr),e(rE,YU),e(YU,KCr),e(rE,ZCr),e(Nr,e3r),M(tE,Nr,null),b(f,bNe,_),b(f,$c,_),e($c,aE),e(aE,hTe),M(dx,hTe,null),e($c,o3r),e($c,pTe),e(pTe,r3r),b(f,vNe,_),b(f,fr,_),M(cx,fr,null),e(fr,t3r),e(fr,kc),e(kc,a3r),e(kc,KU),e(KU,n3r),e(kc,s3r),e(kc,ZU),e(ZU,l3r),e(kc,i3r),e(fr,d3r),e(fr,fx),e(fx,c3r),e(fx,uTe),e(uTe,f3r),e(fx,m3r),e(fr,g3r),e(fr,Dt),M(mx,Dt,null),e(Dt,h3r),e(Dt,_Te),e(_Te,p3r),e(Dt,u3r),e(Dt,Sc),e(Sc,_3r),e(Sc,bTe),e(bTe,b3r),e(Sc,v3r),e(Sc,eJ),e(eJ,F3r),e(Sc,T3r),e(Dt,M3r),M(nE,Dt,null),e(fr,E3r),e(fr,jr),M(gx,jr,null),e(jr,C3r),e(jr,vTe),e(vTe,w3r),e(jr,A3r),e(jr,un),e(un,y3r),e(un,FTe),e(FTe,L3r),e(un,x3r),e(un,TTe),e(TTe,$3r),e(un,k3r),e(un,MTe),e(MTe,S3r),e(un,R3r),e(jr,P3r),e(jr,ETe),e(ETe,sE),e(sE,CTe),e(CTe,B3r),e(sE,I3r),e(sE,oJ),e(oJ,q3r),e(sE,N3r),e(jr,j3r),M(lE,jr,null),b(f,FNe,_),b(f,Rc,_),e(Rc,iE),e(iE,wTe),M(hx,wTe,null),e(Rc,D3r),e(Rc,ATe),e(ATe,G3r),b(f,TNe,_),b(f,mr,_),M(px,mr,null),e(mr,O3r),e(mr,Pc),e(Pc,V3r),e(Pc,rJ),e(rJ,X3r),e(Pc,z3r),e(Pc,tJ),e(tJ,Q3r),e(Pc,W3r),e(mr,H3r),e(mr,ux),e(ux,U3r),e(ux,yTe),e(yTe,J3r),e(ux,Y3r),e(mr,K3r),e(mr,Gt),M(_x,Gt,null),e(Gt,Z3r),e(Gt,LTe),e(LTe,ewr),e(Gt,owr),e(Gt,Bc),e(Bc,rwr),e(Bc,xTe),e(xTe,twr),e(Bc,awr),e(Bc,aJ),e(aJ,nwr),e(Bc,swr),e(Gt,lwr),M(dE,Gt,null),e(mr,iwr),e(mr,Dr),M(bx,Dr,null),e(Dr,dwr),e(Dr,$Te),e($Te,cwr),e(Dr,fwr),e(Dr,_n),e(_n,mwr),e(_n,kTe),e(kTe,gwr),e(_n,hwr),e(_n,STe),e(STe,pwr),e(_n,uwr),e(_n,RTe),e(RTe,_wr),e(_n,bwr),e(Dr,vwr),e(Dr,PTe),e(PTe,cE),e(cE,BTe),e(BTe,Fwr),e(cE,Twr),e(cE,nJ),e(nJ,Mwr),e(cE,Ewr),e(Dr,Cwr),M(fE,Dr,null),b(f,MNe,_),b(f,Ic,_),e(Ic,mE),e(mE,ITe),M(vx,ITe,null),e(Ic,wwr),e(Ic,qTe),e(qTe,Awr),b(f,ENe,_),b(f,gr,_),M(Fx,gr,null),e(gr,ywr),e(gr,qc),e(qc,Lwr),e(qc,sJ),e(sJ,xwr),e(qc,$wr),e(qc,lJ),e(lJ,kwr),e(qc,Swr),e(gr,Rwr),e(gr,Tx),e(Tx,Pwr),e(Tx,NTe),e(NTe,Bwr),e(Tx,Iwr),e(gr,qwr),e(gr,Ot),M(Mx,Ot,null),e(Ot,Nwr),e(Ot,jTe),e(jTe,jwr),e(Ot,Dwr),e(Ot,Nc),e(Nc,Gwr),e(Nc,DTe),e(DTe,Owr),e(Nc,Vwr),e(Nc,iJ),e(iJ,Xwr),e(Nc,zwr),e(Ot,Qwr),M(gE,Ot,null),e(gr,Wwr),e(gr,Gr),M(Ex,Gr,null),e(Gr,Hwr),e(Gr,GTe),e(GTe,Uwr),e(Gr,Jwr),e(Gr,bn),e(bn,Ywr),e(bn,OTe),e(OTe,Kwr),e(bn,Zwr),e(bn,VTe),e(VTe,eAr),e(bn,oAr),e(bn,XTe),e(XTe,rAr),e(bn,tAr),e(Gr,aAr),e(Gr,re),e(re,hE),e(hE,zTe),e(zTe,nAr),e(hE,sAr),e(hE,dJ),e(dJ,lAr),e(hE,iAr),e(re,dAr),e(re,pE),e(pE,QTe),e(QTe,cAr),e(pE,fAr),e(pE,cJ),e(cJ,mAr),e(pE,gAr),e(re,hAr),e(re,uE),e(uE,WTe),e(WTe,pAr),e(uE,uAr),e(uE,fJ),e(fJ,_Ar),e(uE,bAr),e(re,vAr),e(re,_E),e(_E,HTe),e(HTe,FAr),e(_E,TAr),e(_E,mJ),e(mJ,MAr),e(_E,EAr),e(re,CAr),e(re,bE),e(bE,UTe),e(UTe,wAr),e(bE,AAr),e(bE,gJ),e(gJ,yAr),e(bE,LAr),e(re,xAr),e(re,vE),e(vE,JTe),e(JTe,$Ar),e(vE,kAr),e(vE,hJ),e(hJ,SAr),e(vE,RAr),e(re,PAr),e(re,FE),e(FE,YTe),e(YTe,BAr),e(FE,IAr),e(FE,pJ),e(pJ,qAr),e(FE,NAr),e(re,jAr),e(re,TE),e(TE,KTe),e(KTe,DAr),e(TE,GAr),e(TE,uJ),e(uJ,OAr),e(TE,VAr),e(re,XAr),e(re,ME),e(ME,ZTe),e(ZTe,zAr),e(ME,QAr),e(ME,_J),e(_J,WAr),e(ME,HAr),e(re,UAr),e(re,EE),e(EE,e8e),e(e8e,JAr),e(EE,YAr),e(EE,bJ),e(bJ,KAr),e(EE,ZAr),e(re,e0r),e(re,CE),e(CE,o8e),e(o8e,o0r),e(CE,r0r),e(CE,vJ),e(vJ,t0r),e(CE,a0r),e(re,n0r),e(re,wE),e(wE,r8e),e(r8e,s0r),e(wE,l0r),e(wE,FJ),e(FJ,i0r),e(wE,d0r),e(re,c0r),e(re,AE),e(AE,t8e),e(t8e,f0r),e(AE,m0r),e(AE,TJ),e(TJ,g0r),e(AE,h0r),e(re,p0r),e(re,yE),e(yE,a8e),e(a8e,u0r),e(yE,_0r),e(yE,MJ),e(MJ,b0r),e(yE,v0r),e(re,F0r),e(re,LE),e(LE,n8e),e(n8e,T0r),e(LE,M0r),e(LE,EJ),e(EJ,E0r),e(LE,C0r),e(re,w0r),e(re,xE),e(xE,s8e),e(s8e,A0r),e(xE,y0r),e(xE,CJ),e(CJ,L0r),e(xE,x0r),e(re,$0r),e(re,$E),e($E,l8e),e(l8e,k0r),e($E,S0r),e($E,wJ),e(wJ,R0r),e($E,P0r),e(re,B0r),e(re,kE),e(kE,i8e),e(i8e,I0r),e(kE,q0r),e(kE,AJ),e(AJ,N0r),e(kE,j0r),e(re,D0r),e(re,SE),e(SE,d8e),e(d8e,G0r),e(SE,O0r),e(SE,yJ),e(yJ,V0r),e(SE,X0r),e(re,z0r),e(re,RE),e(RE,c8e),e(c8e,Q0r),e(RE,W0r),e(RE,LJ),e(LJ,H0r),e(RE,U0r),e(re,J0r),e(re,PE),e(PE,f8e),e(f8e,Y0r),e(PE,K0r),e(PE,xJ),e(xJ,Z0r),e(PE,eyr),e(re,oyr),e(re,BE),e(BE,m8e),e(m8e,ryr),e(BE,tyr),e(BE,$J),e($J,ayr),e(BE,nyr),e(re,syr),e(re,IE),e(IE,g8e),e(g8e,lyr),e(IE,iyr),e(IE,kJ),e(kJ,dyr),e(IE,cyr),e(re,fyr),e(re,qE),e(qE,h8e),e(h8e,myr),e(qE,gyr),e(qE,SJ),e(SJ,hyr),e(qE,pyr),e(re,uyr),e(re,NE),e(NE,p8e),e(p8e,_yr),e(NE,byr),e(NE,RJ),e(RJ,vyr),e(NE,Fyr),e(Gr,Tyr),M(jE,Gr,null),b(f,CNe,_),b(f,jc,_),e(jc,DE),e(DE,u8e),M(Cx,u8e,null),e(jc,Myr),e(jc,_8e),e(_8e,Eyr),b(f,wNe,_),b(f,hr,_),M(wx,hr,null),e(hr,Cyr),e(hr,Dc),e(Dc,wyr),e(Dc,PJ),e(PJ,Ayr),e(Dc,yyr),e(Dc,BJ),e(BJ,Lyr),e(Dc,xyr),e(hr,$yr),e(hr,Ax),e(Ax,kyr),e(Ax,b8e),e(b8e,Syr),e(Ax,Ryr),e(hr,Pyr),e(hr,Vt),M(yx,Vt,null),e(Vt,Byr),e(Vt,v8e),e(v8e,Iyr),e(Vt,qyr),e(Vt,Gc),e(Gc,Nyr),e(Gc,F8e),e(F8e,jyr),e(Gc,Dyr),e(Gc,IJ),e(IJ,Gyr),e(Gc,Oyr),e(Vt,Vyr),M(GE,Vt,null),e(hr,Xyr),e(hr,Or),M(Lx,Or,null),e(Or,zyr),e(Or,T8e),e(T8e,Qyr),e(Or,Wyr),e(Or,vn),e(vn,Hyr),e(vn,M8e),e(M8e,Uyr),e(vn,Jyr),e(vn,E8e),e(E8e,Yyr),e(vn,Kyr),e(vn,C8e),e(C8e,Zyr),e(vn,eLr),e(Or,oLr),e(Or,ke),e(ke,OE),e(OE,w8e),e(w8e,rLr),e(OE,tLr),e(OE,qJ),e(qJ,aLr),e(OE,nLr),e(ke,sLr),e(ke,VE),e(VE,A8e),e(A8e,lLr),e(VE,iLr),e(VE,NJ),e(NJ,dLr),e(VE,cLr),e(ke,fLr),e(ke,XE),e(XE,y8e),e(y8e,mLr),e(XE,gLr),e(XE,jJ),e(jJ,hLr),e(XE,pLr),e(ke,uLr),e(ke,zE),e(zE,L8e),e(L8e,_Lr),e(zE,bLr),e(zE,DJ),e(DJ,vLr),e(zE,FLr),e(ke,TLr),e(ke,QE),e(QE,x8e),e(x8e,MLr),e(QE,ELr),e(QE,GJ),e(GJ,CLr),e(QE,wLr),e(ke,ALr),e(ke,WE),e(WE,$8e),e($8e,yLr),e(WE,LLr),e(WE,OJ),e(OJ,xLr),e(WE,$Lr),e(ke,kLr),e(ke,HE),e(HE,k8e),e(k8e,SLr),e(HE,RLr),e(HE,VJ),e(VJ,PLr),e(HE,BLr),e(ke,ILr),e(ke,UE),e(UE,S8e),e(S8e,qLr),e(UE,NLr),e(UE,XJ),e(XJ,jLr),e(UE,DLr),e(ke,GLr),e(ke,JE),e(JE,R8e),e(R8e,OLr),e(JE,VLr),e(JE,zJ),e(zJ,XLr),e(JE,zLr),e(Or,QLr),M(YE,Or,null),b(f,ANe,_),b(f,Oc,_),e(Oc,KE),e(KE,P8e),M(xx,P8e,null),e(Oc,WLr),e(Oc,B8e),e(B8e,HLr),b(f,yNe,_),b(f,pr,_),M($x,pr,null),e(pr,ULr),e(pr,Vc),e(Vc,JLr),e(Vc,QJ),e(QJ,YLr),e(Vc,KLr),e(Vc,WJ),e(WJ,ZLr),e(Vc,exr),e(pr,oxr),e(pr,kx),e(kx,rxr),e(kx,I8e),e(I8e,txr),e(kx,axr),e(pr,nxr),e(pr,Xt),M(Sx,Xt,null),e(Xt,sxr),e(Xt,q8e),e(q8e,lxr),e(Xt,ixr),e(Xt,Xc),e(Xc,dxr),e(Xc,N8e),e(N8e,cxr),e(Xc,fxr),e(Xc,HJ),e(HJ,mxr),e(Xc,gxr),e(Xt,hxr),M(ZE,Xt,null),e(pr,pxr),e(pr,Vr),M(Rx,Vr,null),e(Vr,uxr),e(Vr,j8e),e(j8e,_xr),e(Vr,bxr),e(Vr,Fn),e(Fn,vxr),e(Fn,D8e),e(D8e,Fxr),e(Fn,Txr),e(Fn,G8e),e(G8e,Mxr),e(Fn,Exr),e(Fn,O8e),e(O8e,Cxr),e(Fn,wxr),e(Vr,Axr),e(Vr,Me),e(Me,e5),e(e5,V8e),e(V8e,yxr),e(e5,Lxr),e(e5,UJ),e(UJ,xxr),e(e5,$xr),e(Me,kxr),e(Me,o5),e(o5,X8e),e(X8e,Sxr),e(o5,Rxr),e(o5,JJ),e(JJ,Pxr),e(o5,Bxr),e(Me,Ixr),e(Me,r5),e(r5,z8e),e(z8e,qxr),e(r5,Nxr),e(r5,YJ),e(YJ,jxr),e(r5,Dxr),e(Me,Gxr),e(Me,t5),e(t5,Q8e),e(Q8e,Oxr),e(t5,Vxr),e(t5,KJ),e(KJ,Xxr),e(t5,zxr),e(Me,Qxr),e(Me,a5),e(a5,W8e),e(W8e,Wxr),e(a5,Hxr),e(a5,ZJ),e(ZJ,Uxr),e(a5,Jxr),e(Me,Yxr),e(Me,n5),e(n5,H8e),e(H8e,Kxr),e(n5,Zxr),e(n5,eY),e(eY,e9r),e(n5,o9r),e(Me,r9r),e(Me,s5),e(s5,U8e),e(U8e,t9r),e(s5,a9r),e(s5,oY),e(oY,n9r),e(s5,s9r),e(Me,l9r),e(Me,l5),e(l5,J8e),e(J8e,i9r),e(l5,d9r),e(l5,rY),e(rY,c9r),e(l5,f9r),e(Me,m9r),e(Me,i5),e(i5,Y8e),e(Y8e,g9r),e(i5,h9r),e(i5,tY),e(tY,p9r),e(i5,u9r),e(Me,_9r),e(Me,d5),e(d5,K8e),e(K8e,b9r),e(d5,v9r),e(d5,aY),e(aY,F9r),e(d5,T9r),e(Me,M9r),e(Me,c5),e(c5,Z8e),e(Z8e,E9r),e(c5,C9r),e(c5,nY),e(nY,w9r),e(c5,A9r),e(Me,y9r),e(Me,f5),e(f5,e7e),e(e7e,L9r),e(f5,x9r),e(f5,sY),e(sY,$9r),e(f5,k9r),e(Vr,S9r),M(m5,Vr,null),b(f,LNe,_),b(f,zc,_),e(zc,g5),e(g5,o7e),M(Px,o7e,null),e(zc,R9r),e(zc,r7e),e(r7e,P9r),b(f,xNe,_),b(f,ur,_),M(Bx,ur,null),e(ur,B9r),e(ur,Qc),e(Qc,I9r),e(Qc,lY),e(lY,q9r),e(Qc,N9r),e(Qc,iY),e(iY,j9r),e(Qc,D9r),e(ur,G9r),e(ur,Ix),e(Ix,O9r),e(Ix,t7e),e(t7e,V9r),e(Ix,X9r),e(ur,z9r),e(ur,zt),M(qx,zt,null),e(zt,Q9r),e(zt,a7e),e(a7e,W9r),e(zt,H9r),e(zt,Wc),e(Wc,U9r),e(Wc,n7e),e(n7e,J9r),e(Wc,Y9r),e(Wc,dY),e(dY,K9r),e(Wc,Z9r),e(zt,e$r),M(h5,zt,null),e(ur,o$r),e(ur,Xr),M(Nx,Xr,null),e(Xr,r$r),e(Xr,s7e),e(s7e,t$r),e(Xr,a$r),e(Xr,Tn),e(Tn,n$r),e(Tn,l7e),e(l7e,s$r),e(Tn,l$r),e(Tn,i7e),e(i7e,i$r),e(Tn,d$r),e(Tn,d7e),e(d7e,c$r),e(Tn,f$r),e(Xr,m$r),e(Xr,Le),e(Le,p5),e(p5,c7e),e(c7e,g$r),e(p5,h$r),e(p5,cY),e(cY,p$r),e(p5,u$r),e(Le,_$r),e(Le,u5),e(u5,f7e),e(f7e,b$r),e(u5,v$r),e(u5,fY),e(fY,F$r),e(u5,T$r),e(Le,M$r),e(Le,_5),e(_5,m7e),e(m7e,E$r),e(_5,C$r),e(_5,mY),e(mY,w$r),e(_5,A$r),e(Le,y$r),e(Le,b5),e(b5,g7e),e(g7e,L$r),e(b5,x$r),e(b5,gY),e(gY,$$r),e(b5,k$r),e(Le,S$r),e(Le,v5),e(v5,h7e),e(h7e,R$r),e(v5,P$r),e(v5,hY),e(hY,B$r),e(v5,I$r),e(Le,q$r),e(Le,F5),e(F5,p7e),e(p7e,N$r),e(F5,j$r),e(F5,pY),e(pY,D$r),e(F5,G$r),e(Le,O$r),e(Le,T5),e(T5,u7e),e(u7e,V$r),e(T5,X$r),e(T5,uY),e(uY,z$r),e(T5,Q$r),e(Le,W$r),e(Le,M5),e(M5,_7e),e(_7e,H$r),e(M5,U$r),e(M5,_Y),e(_Y,J$r),e(M5,Y$r),e(Le,K$r),e(Le,E5),e(E5,b7e),e(b7e,Z$r),e(E5,ekr),e(E5,bY),e(bY,okr),e(E5,rkr),e(Le,tkr),e(Le,C5),e(C5,v7e),e(v7e,akr),e(C5,nkr),e(C5,vY),e(vY,skr),e(C5,lkr),e(Xr,ikr),M(w5,Xr,null),b(f,$Ne,_),b(f,Hc,_),e(Hc,A5),e(A5,F7e),M(jx,F7e,null),e(Hc,dkr),e(Hc,T7e),e(T7e,ckr),b(f,kNe,_),b(f,_r,_),M(Dx,_r,null),e(_r,fkr),e(_r,Uc),e(Uc,mkr),e(Uc,FY),e(FY,gkr),e(Uc,hkr),e(Uc,TY),e(TY,pkr),e(Uc,ukr),e(_r,_kr),e(_r,Gx),e(Gx,bkr),e(Gx,M7e),e(M7e,vkr),e(Gx,Fkr),e(_r,Tkr),e(_r,Qt),M(Ox,Qt,null),e(Qt,Mkr),e(Qt,E7e),e(E7e,Ekr),e(Qt,Ckr),e(Qt,Jc),e(Jc,wkr),e(Jc,C7e),e(C7e,Akr),e(Jc,ykr),e(Jc,MY),e(MY,Lkr),e(Jc,xkr),e(Qt,$kr),M(y5,Qt,null),e(_r,kkr),e(_r,zr),M(Vx,zr,null),e(zr,Skr),e(zr,w7e),e(w7e,Rkr),e(zr,Pkr),e(zr,Mn),e(Mn,Bkr),e(Mn,A7e),e(A7e,Ikr),e(Mn,qkr),e(Mn,y7e),e(y7e,Nkr),e(Mn,jkr),e(Mn,L7e),e(L7e,Dkr),e(Mn,Gkr),e(zr,Okr),e(zr,Se),e(Se,L5),e(L5,x7e),e(x7e,Vkr),e(L5,Xkr),e(L5,EY),e(EY,zkr),e(L5,Qkr),e(Se,Wkr),e(Se,x5),e(x5,$7e),e($7e,Hkr),e(x5,Ukr),e(x5,CY),e(CY,Jkr),e(x5,Ykr),e(Se,Kkr),e(Se,$5),e($5,k7e),e(k7e,Zkr),e($5,eSr),e($5,wY),e(wY,oSr),e($5,rSr),e(Se,tSr),e(Se,k5),e(k5,S7e),e(S7e,aSr),e(k5,nSr),e(k5,AY),e(AY,sSr),e(k5,lSr),e(Se,iSr),e(Se,S5),e(S5,R7e),e(R7e,dSr),e(S5,cSr),e(S5,yY),e(yY,fSr),e(S5,mSr),e(Se,gSr),e(Se,R5),e(R5,P7e),e(P7e,hSr),e(R5,pSr),e(R5,LY),e(LY,uSr),e(R5,_Sr),e(Se,bSr),e(Se,P5),e(P5,B7e),e(B7e,vSr),e(P5,FSr),e(P5,xY),e(xY,TSr),e(P5,MSr),e(Se,ESr),e(Se,B5),e(B5,I7e),e(I7e,CSr),e(B5,wSr),e(B5,$Y),e($Y,ASr),e(B5,ySr),e(Se,LSr),e(Se,I5),e(I5,q7e),e(q7e,xSr),e(I5,$Sr),e(I5,kY),e(kY,kSr),e(I5,SSr),e(zr,RSr),M(q5,zr,null),b(f,SNe,_),b(f,Yc,_),e(Yc,N5),e(N5,N7e),M(Xx,N7e,null),e(Yc,PSr),e(Yc,j7e),e(j7e,BSr),b(f,RNe,_),b(f,br,_),M(zx,br,null),e(br,ISr),e(br,Kc),e(Kc,qSr),e(Kc,SY),e(SY,NSr),e(Kc,jSr),e(Kc,RY),e(RY,DSr),e(Kc,GSr),e(br,OSr),e(br,Qx),e(Qx,VSr),e(Qx,D7e),e(D7e,XSr),e(Qx,zSr),e(br,QSr),e(br,Wt),M(Wx,Wt,null),e(Wt,WSr),e(Wt,G7e),e(G7e,HSr),e(Wt,USr),e(Wt,Zc),e(Zc,JSr),e(Zc,O7e),e(O7e,YSr),e(Zc,KSr),e(Zc,PY),e(PY,ZSr),e(Zc,eRr),e(Wt,oRr),M(j5,Wt,null),e(br,rRr),e(br,Qr),M(Hx,Qr,null),e(Qr,tRr),e(Qr,V7e),e(V7e,aRr),e(Qr,nRr),e(Qr,En),e(En,sRr),e(En,X7e),e(X7e,lRr),e(En,iRr),e(En,z7e),e(z7e,dRr),e(En,cRr),e(En,Q7e),e(Q7e,fRr),e(En,mRr),e(Qr,gRr),e(Qr,xe),e(xe,D5),e(D5,W7e),e(W7e,hRr),e(D5,pRr),e(D5,BY),e(BY,uRr),e(D5,_Rr),e(xe,bRr),e(xe,G5),e(G5,H7e),e(H7e,vRr),e(G5,FRr),e(G5,IY),e(IY,TRr),e(G5,MRr),e(xe,ERr),e(xe,O5),e(O5,U7e),e(U7e,CRr),e(O5,wRr),e(O5,qY),e(qY,ARr),e(O5,yRr),e(xe,LRr),e(xe,V5),e(V5,J7e),e(J7e,xRr),e(V5,$Rr),e(V5,NY),e(NY,kRr),e(V5,SRr),e(xe,RRr),e(xe,X5),e(X5,Y7e),e(Y7e,PRr),e(X5,BRr),e(X5,jY),e(jY,IRr),e(X5,qRr),e(xe,NRr),e(xe,z5),e(z5,K7e),e(K7e,jRr),e(z5,DRr),e(z5,DY),e(DY,GRr),e(z5,ORr),e(xe,VRr),e(xe,Q5),e(Q5,Z7e),e(Z7e,XRr),e(Q5,zRr),e(Q5,GY),e(GY,QRr),e(Q5,WRr),e(xe,HRr),e(xe,W5),e(W5,eMe),e(eMe,URr),e(W5,JRr),e(W5,OY),e(OY,YRr),e(W5,KRr),e(xe,ZRr),e(xe,H5),e(H5,oMe),e(oMe,ePr),e(H5,oPr),e(H5,VY),e(VY,rPr),e(H5,tPr),e(xe,aPr),e(xe,U5),e(U5,rMe),e(rMe,nPr),e(U5,sPr),e(U5,XY),e(XY,lPr),e(U5,iPr),e(Qr,dPr),M(J5,Qr,null),b(f,PNe,_),b(f,ef,_),e(ef,Y5),e(Y5,tMe),M(Ux,tMe,null),e(ef,cPr),e(ef,aMe),e(aMe,fPr),b(f,BNe,_),b(f,vr,_),M(Jx,vr,null),e(vr,mPr),e(vr,of),e(of,gPr),e(of,zY),e(zY,hPr),e(of,pPr),e(of,QY),e(QY,uPr),e(of,_Pr),e(vr,bPr),e(vr,Yx),e(Yx,vPr),e(Yx,nMe),e(nMe,FPr),e(Yx,TPr),e(vr,MPr),e(vr,Ht),M(Kx,Ht,null),e(Ht,EPr),e(Ht,sMe),e(sMe,CPr),e(Ht,wPr),e(Ht,rf),e(rf,APr),e(rf,lMe),e(lMe,yPr),e(rf,LPr),e(rf,WY),e(WY,xPr),e(rf,$Pr),e(Ht,kPr),M(K5,Ht,null),e(vr,SPr),e(vr,Wr),M(Zx,Wr,null),e(Wr,RPr),e(Wr,iMe),e(iMe,PPr),e(Wr,BPr),e(Wr,Cn),e(Cn,IPr),e(Cn,dMe),e(dMe,qPr),e(Cn,NPr),e(Cn,cMe),e(cMe,jPr),e(Cn,DPr),e(Cn,fMe),e(fMe,GPr),e(Cn,OPr),e(Wr,VPr),e(Wr,$e),e($e,Z5),e(Z5,mMe),e(mMe,XPr),e(Z5,zPr),e(Z5,HY),e(HY,QPr),e(Z5,WPr),e($e,HPr),e($e,eC),e(eC,gMe),e(gMe,UPr),e(eC,JPr),e(eC,UY),e(UY,YPr),e(eC,KPr),e($e,ZPr),e($e,oC),e(oC,hMe),e(hMe,eBr),e(oC,oBr),e(oC,JY),e(JY,rBr),e(oC,tBr),e($e,aBr),e($e,rC),e(rC,pMe),e(pMe,nBr),e(rC,sBr),e(rC,YY),e(YY,lBr),e(rC,iBr),e($e,dBr),e($e,tC),e(tC,uMe),e(uMe,cBr),e(tC,fBr),e(tC,KY),e(KY,mBr),e(tC,gBr),e($e,hBr),e($e,aC),e(aC,_Me),e(_Me,pBr),e(aC,uBr),e(aC,ZY),e(ZY,_Br),e(aC,bBr),e($e,vBr),e($e,nC),e(nC,bMe),e(bMe,FBr),e(nC,TBr),e(nC,eK),e(eK,MBr),e(nC,EBr),e($e,CBr),e($e,sC),e(sC,vMe),e(vMe,wBr),e(sC,ABr),e(sC,oK),e(oK,yBr),e(sC,LBr),e($e,xBr),e($e,lC),e(lC,FMe),e(FMe,$Br),e(lC,kBr),e(lC,rK),e(rK,SBr),e(lC,RBr),e($e,PBr),e($e,iC),e(iC,TMe),e(TMe,BBr),e(iC,IBr),e(iC,tK),e(tK,qBr),e(iC,NBr),e(Wr,jBr),M(dC,Wr,null),b(f,INe,_),b(f,tf,_),e(tf,cC),e(cC,MMe),M(e9,MMe,null),e(tf,DBr),e(tf,EMe),e(EMe,GBr),b(f,qNe,_),b(f,Fr,_),M(o9,Fr,null),e(Fr,OBr),e(Fr,af),e(af,VBr),e(af,aK),e(aK,XBr),e(af,zBr),e(af,nK),e(nK,QBr),e(af,WBr),e(Fr,HBr),e(Fr,r9),e(r9,UBr),e(r9,CMe),e(CMe,JBr),e(r9,YBr),e(Fr,KBr),e(Fr,Ut),M(t9,Ut,null),e(Ut,ZBr),e(Ut,wMe),e(wMe,eIr),e(Ut,oIr),e(Ut,nf),e(nf,rIr),e(nf,AMe),e(AMe,tIr),e(nf,aIr),e(nf,sK),e(sK,nIr),e(nf,sIr),e(Ut,lIr),M(fC,Ut,null),e(Fr,iIr),e(Fr,Hr),M(a9,Hr,null),e(Hr,dIr),e(Hr,yMe),e(yMe,cIr),e(Hr,fIr),e(Hr,wn),e(wn,mIr),e(wn,LMe),e(LMe,gIr),e(wn,hIr),e(wn,xMe),e(xMe,pIr),e(wn,uIr),e(wn,$Me),e($Me,_Ir),e(wn,bIr),e(Hr,vIr),e(Hr,De),e(De,mC),e(mC,kMe),e(kMe,FIr),e(mC,TIr),e(mC,lK),e(lK,MIr),e(mC,EIr),e(De,CIr),e(De,gC),e(gC,SMe),e(SMe,wIr),e(gC,AIr),e(gC,iK),e(iK,yIr),e(gC,LIr),e(De,xIr),e(De,hC),e(hC,RMe),e(RMe,$Ir),e(hC,kIr),e(hC,dK),e(dK,SIr),e(hC,RIr),e(De,PIr),e(De,pC),e(pC,PMe),e(PMe,BIr),e(pC,IIr),e(pC,cK),e(cK,qIr),e(pC,NIr),e(De,jIr),e(De,uC),e(uC,BMe),e(BMe,DIr),e(uC,GIr),e(uC,fK),e(fK,OIr),e(uC,VIr),e(De,XIr),e(De,_C),e(_C,IMe),e(IMe,zIr),e(_C,QIr),e(_C,mK),e(mK,WIr),e(_C,HIr),e(De,UIr),e(De,bC),e(bC,qMe),e(qMe,JIr),e(bC,YIr),e(bC,gK),e(gK,KIr),e(bC,ZIr),e(De,eqr),e(De,vC),e(vC,NMe),e(NMe,oqr),e(vC,rqr),e(vC,hK),e(hK,tqr),e(vC,aqr),e(Hr,nqr),M(FC,Hr,null),b(f,NNe,_),b(f,sf,_),e(sf,TC),e(TC,jMe),M(n9,jMe,null),e(sf,sqr),e(sf,DMe),e(DMe,lqr),b(f,jNe,_),b(f,Tr,_),M(s9,Tr,null),e(Tr,iqr),e(Tr,lf),e(lf,dqr),e(lf,pK),e(pK,cqr),e(lf,fqr),e(lf,uK),e(uK,mqr),e(lf,gqr),e(Tr,hqr),e(Tr,l9),e(l9,pqr),e(l9,GMe),e(GMe,uqr),e(l9,_qr),e(Tr,bqr),e(Tr,Jt),M(i9,Jt,null),e(Jt,vqr),e(Jt,OMe),e(OMe,Fqr),e(Jt,Tqr),e(Jt,df),e(df,Mqr),e(df,VMe),e(VMe,Eqr),e(df,Cqr),e(df,_K),e(_K,wqr),e(df,Aqr),e(Jt,yqr),M(MC,Jt,null),e(Tr,Lqr),e(Tr,Ur),M(d9,Ur,null),e(Ur,xqr),e(Ur,XMe),e(XMe,$qr),e(Ur,kqr),e(Ur,An),e(An,Sqr),e(An,zMe),e(zMe,Rqr),e(An,Pqr),e(An,QMe),e(QMe,Bqr),e(An,Iqr),e(An,WMe),e(WMe,qqr),e(An,Nqr),e(Ur,jqr),e(Ur,Ge),e(Ge,EC),e(EC,HMe),e(HMe,Dqr),e(EC,Gqr),e(EC,bK),e(bK,Oqr),e(EC,Vqr),e(Ge,Xqr),e(Ge,CC),e(CC,UMe),e(UMe,zqr),e(CC,Qqr),e(CC,vK),e(vK,Wqr),e(CC,Hqr),e(Ge,Uqr),e(Ge,wC),e(wC,JMe),e(JMe,Jqr),e(wC,Yqr),e(wC,FK),e(FK,Kqr),e(wC,Zqr),e(Ge,eNr),e(Ge,AC),e(AC,YMe),e(YMe,oNr),e(AC,rNr),e(AC,TK),e(TK,tNr),e(AC,aNr),e(Ge,nNr),e(Ge,yC),e(yC,KMe),e(KMe,sNr),e(yC,lNr),e(yC,MK),e(MK,iNr),e(yC,dNr),e(Ge,cNr),e(Ge,LC),e(LC,ZMe),e(ZMe,fNr),e(LC,mNr),e(LC,EK),e(EK,gNr),e(LC,hNr),e(Ge,pNr),e(Ge,xC),e(xC,e4e),e(e4e,uNr),e(xC,_Nr),e(xC,CK),e(CK,bNr),e(xC,vNr),e(Ge,FNr),e(Ge,$C),e($C,o4e),e(o4e,TNr),e($C,MNr),e($C,wK),e(wK,ENr),e($C,CNr),e(Ur,wNr),M(kC,Ur,null),b(f,DNe,_),b(f,cf,_),e(cf,SC),e(SC,r4e),M(c9,r4e,null),e(cf,ANr),e(cf,t4e),e(t4e,yNr),b(f,GNe,_),b(f,Mr,_),M(f9,Mr,null),e(Mr,LNr),e(Mr,ff),e(ff,xNr),e(ff,AK),e(AK,$Nr),e(ff,kNr),e(ff,yK),e(yK,SNr),e(ff,RNr),e(Mr,PNr),e(Mr,m9),e(m9,BNr),e(m9,a4e),e(a4e,INr),e(m9,qNr),e(Mr,NNr),e(Mr,Yt),M(g9,Yt,null),e(Yt,jNr),e(Yt,n4e),e(n4e,DNr),e(Yt,GNr),e(Yt,mf),e(mf,ONr),e(mf,s4e),e(s4e,VNr),e(mf,XNr),e(mf,LK),e(LK,zNr),e(mf,QNr),e(Yt,WNr),M(RC,Yt,null),e(Mr,HNr),e(Mr,Jr),M(h9,Jr,null),e(Jr,UNr),e(Jr,l4e),e(l4e,JNr),e(Jr,YNr),e(Jr,yn),e(yn,KNr),e(yn,i4e),e(i4e,ZNr),e(yn,ejr),e(yn,d4e),e(d4e,ojr),e(yn,rjr),e(yn,c4e),e(c4e,tjr),e(yn,ajr),e(Jr,njr),e(Jr,f4e),e(f4e,PC),e(PC,m4e),e(m4e,sjr),e(PC,ljr),e(PC,xK),e(xK,ijr),e(PC,djr),e(Jr,cjr),M(BC,Jr,null),b(f,ONe,_),b(f,gf,_),e(gf,IC),e(IC,g4e),M(p9,g4e,null),e(gf,fjr),e(gf,h4e),e(h4e,mjr),b(f,VNe,_),b(f,Er,_),M(u9,Er,null),e(Er,gjr),e(Er,hf),e(hf,hjr),e(hf,$K),e($K,pjr),e(hf,ujr),e(hf,kK),e(kK,_jr),e(hf,bjr),e(Er,vjr),e(Er,_9),e(_9,Fjr),e(_9,p4e),e(p4e,Tjr),e(_9,Mjr),e(Er,Ejr),e(Er,Kt),M(b9,Kt,null),e(Kt,Cjr),e(Kt,u4e),e(u4e,wjr),e(Kt,Ajr),e(Kt,pf),e(pf,yjr),e(pf,_4e),e(_4e,Ljr),e(pf,xjr),e(pf,SK),e(SK,$jr),e(pf,kjr),e(Kt,Sjr),M(qC,Kt,null),e(Er,Rjr),e(Er,Yr),M(v9,Yr,null),e(Yr,Pjr),e(Yr,b4e),e(b4e,Bjr),e(Yr,Ijr),e(Yr,Ln),e(Ln,qjr),e(Ln,v4e),e(v4e,Njr),e(Ln,jjr),e(Ln,F4e),e(F4e,Djr),e(Ln,Gjr),e(Ln,T4e),e(T4e,Ojr),e(Ln,Vjr),e(Yr,Xjr),e(Yr,F9),e(F9,NC),e(NC,M4e),e(M4e,zjr),e(NC,Qjr),e(NC,RK),e(RK,Wjr),e(NC,Hjr),e(F9,Ujr),e(F9,jC),e(jC,E4e),e(E4e,Jjr),e(jC,Yjr),e(jC,PK),e(PK,Kjr),e(jC,Zjr),e(Yr,eDr),M(DC,Yr,null),b(f,XNe,_),b(f,uf,_),e(uf,GC),e(GC,C4e),M(T9,C4e,null),e(uf,oDr),e(uf,w4e),e(w4e,rDr),b(f,zNe,_),b(f,Cr,_),M(M9,Cr,null),e(Cr,tDr),e(Cr,_f),e(_f,aDr),e(_f,BK),e(BK,nDr),e(_f,sDr),e(_f,IK),e(IK,lDr),e(_f,iDr),e(Cr,dDr),e(Cr,E9),e(E9,cDr),e(E9,A4e),e(A4e,fDr),e(E9,mDr),e(Cr,gDr),e(Cr,Zt),M(C9,Zt,null),e(Zt,hDr),e(Zt,y4e),e(y4e,pDr),e(Zt,uDr),e(Zt,bf),e(bf,_Dr),e(bf,L4e),e(L4e,bDr),e(bf,vDr),e(bf,qK),e(qK,FDr),e(bf,TDr),e(Zt,MDr),M(OC,Zt,null),e(Cr,EDr),e(Cr,Kr),M(w9,Kr,null),e(Kr,CDr),e(Kr,x4e),e(x4e,wDr),e(Kr,ADr),e(Kr,xn),e(xn,yDr),e(xn,$4e),e($4e,LDr),e(xn,xDr),e(xn,k4e),e(k4e,$Dr),e(xn,kDr),e(xn,S4e),e(S4e,SDr),e(xn,RDr),e(Kr,PDr),e(Kr,R4e),e(R4e,VC),e(VC,P4e),e(P4e,BDr),e(VC,IDr),e(VC,NK),e(NK,qDr),e(VC,NDr),e(Kr,jDr),M(XC,Kr,null),QNe=!0},p(f,[_]){const A9={};_&2&&(A9.$$scope={dirty:_,ctx:f}),yf.$set(A9);const B4e={};_&2&&(B4e.$$scope={dirty:_,ctx:f}),Ag.$set(B4e);const I4e={};_&2&&(I4e.$$scope={dirty:_,ctx:f}),nh.$set(I4e);const q4e={};_&2&&(q4e.$$scope={dirty:_,ctx:f}),Ph.$set(q4e);const y9={};_&2&&(y9.$$scope={dirty:_,ctx:f}),Bh.$set(y9);const N4e={};_&2&&(N4e.$$scope={dirty:_,ctx:f}),Zh.$set(N4e);const $n={};_&2&&($n.$$scope={dirty:_,ctx:f}),ep.$set($n);const j4e={};_&2&&(j4e.$$scope={dirty:_,ctx:f}),tp.$set(j4e);const D4e={};_&2&&(D4e.$$scope={dirty:_,ctx:f}),Wu.$set(D4e);const G4e={};_&2&&(G4e.$$scope={dirty:_,ctx:f}),Uu.$set(G4e);const L9={};_&2&&(L9.$$scope={dirty:_,ctx:f}),q_.$set(L9);const O4e={};_&2&&(O4e.$$scope={dirty:_,ctx:f}),j_.$set(O4e);const x9={};_&2&&(x9.$$scope={dirty:_,ctx:f}),E2.$set(x9);const V4e={};_&2&&(V4e.$$scope={dirty:_,ctx:f}),w2.$set(V4e);const $9={};_&2&&($9.$$scope={dirty:_,ctx:f}),i1.$set($9);const X4e={};_&2&&(X4e.$$scope={dirty:_,ctx:f}),c1.$set(X4e);const z4e={};_&2&&(z4e.$$scope={dirty:_,ctx:f}),x1.$set(z4e);const Q4e={};_&2&&(Q4e.$$scope={dirty:_,ctx:f}),k1.$set(Q4e);const vf={};_&2&&(vf.$$scope={dirty:_,ctx:f}),Ab.$set(vf);const W4e={};_&2&&(W4e.$$scope={dirty:_,ctx:f}),Lb.$set(W4e);const H4e={};_&2&&(H4e.$$scope={dirty:_,ctx:f}),nv.$set(H4e);const U4e={};_&2&&(U4e.$$scope={dirty:_,ctx:f}),lv.$set(U4e);const k9={};_&2&&(k9.$$scope={dirty:_,ctx:f}),hv.$set(k9);const J4e={};_&2&&(J4e.$$scope={dirty:_,ctx:f}),uv.$set(J4e);const Y4e={};_&2&&(Y4e.$$scope={dirty:_,ctx:f}),Yv.$set(Y4e);const K4e={};_&2&&(K4e.$$scope={dirty:_,ctx:f}),Zv.$set(K4e);const et={};_&2&&(et.$$scope={dirty:_,ctx:f}),DF.$set(et);const S9={};_&2&&(S9.$$scope={dirty:_,ctx:f}),OF.$set(S9);const Z4e={};_&2&&(Z4e.$$scope={dirty:_,ctx:f}),zF.$set(Z4e);const R9={};_&2&&(R9.$$scope={dirty:_,ctx:f}),WF.$set(R9);const eEe={};_&2&&(eEe.$$scope={dirty:_,ctx:f}),s6.$set(eEe);const ot={};_&2&&(ot.$$scope={dirty:_,ctx:f}),i6.$set(ot);const oEe={};_&2&&(oEe.$$scope={dirty:_,ctx:f}),f6.$set(oEe);const Ff={};_&2&&(Ff.$$scope={dirty:_,ctx:f}),g6.$set(Ff);const rEe={};_&2&&(rEe.$$scope={dirty:_,ctx:f}),u6.$set(rEe);const tEe={};_&2&&(tEe.$$scope={dirty:_,ctx:f}),b6.$set(tEe);const L={};_&2&&(L.$$scope={dirty:_,ctx:f}),L6.$set(L);const zC={};_&2&&(zC.$$scope={dirty:_,ctx:f}),$6.$set(zC);const aEe={};_&2&&(aEe.$$scope={dirty:_,ctx:f}),I6.$set(aEe);const nEe={};_&2&&(nEe.$$scope={dirty:_,ctx:f}),N6.$set(nEe);const QC={};_&2&&(QC.$$scope={dirty:_,ctx:f}),H6.$set(QC);const sEe={};_&2&&(sEe.$$scope={dirty:_,ctx:f}),J6.$set(sEe);const lEe={};_&2&&(lEe.$$scope={dirty:_,ctx:f}),eT.$set(lEe);const WC={};_&2&&(WC.$$scope={dirty:_,ctx:f}),rT.$set(WC);const iEe={};_&2&&(iEe.$$scope={dirty:_,ctx:f}),iT.$set(iEe);const dEe={};_&2&&(dEe.$$scope={dirty:_,ctx:f}),cT.$set(dEe);const HC={};_&2&&(HC.$$scope={dirty:_,ctx:f}),pT.$set(HC);const cEe={};_&2&&(cEe.$$scope={dirty:_,ctx:f}),_T.$set(cEe);const fEe={};_&2&&(fEe.$$scope={dirty:_,ctx:f}),TT.$set(fEe);const UC={};_&2&&(UC.$$scope={dirty:_,ctx:f}),ET.$set(UC);const mEe={};_&2&&(mEe.$$scope={dirty:_,ctx:f}),AT.$set(mEe);const gEe={};_&2&&(gEe.$$scope={dirty:_,ctx:f}),LT.$set(gEe);const JC={};_&2&&(JC.$$scope={dirty:_,ctx:f}),PT.$set(JC);const hEe={};_&2&&(hEe.$$scope={dirty:_,ctx:f}),IT.$set(hEe);const pEe={};_&2&&(pEe.$$scope={dirty:_,ctx:f}),jT.$set(pEe);const YC={};_&2&&(YC.$$scope={dirty:_,ctx:f}),GT.$set(YC);const uEe={};_&2&&(uEe.$$scope={dirty:_,ctx:f}),S8.$set(uEe);const _Ee={};_&2&&(_Ee.$$scope={dirty:_,ctx:f}),P8.$set(_Ee);const KC={};_&2&&(KC.$$scope={dirty:_,ctx:f}),a7.$set(KC);const bEe={};_&2&&(bEe.$$scope={dirty:_,ctx:f}),s7.$set(bEe);const vEe={};_&2&&(vEe.$$scope={dirty:_,ctx:f}),v7.$set(vEe);const ZC={};_&2&&(ZC.$$scope={dirty:_,ctx:f}),T7.$set(ZC);const FEe={};_&2&&(FEe.$$scope={dirty:_,ctx:f}),w7.$set(FEe);const TEe={};_&2&&(TEe.$$scope={dirty:_,ctx:f}),y7.$set(TEe);const e3={};_&2&&(e3.$$scope={dirty:_,ctx:f}),H7.$set(e3);const MEe={};_&2&&(MEe.$$scope={dirty:_,ctx:f}),J7.$set(MEe);const EEe={};_&2&&(EEe.$$scope={dirty:_,ctx:f}),lM.$set(EEe);const o3={};_&2&&(o3.$$scope={dirty:_,ctx:f}),dM.$set(o3);const CEe={};_&2&&(CEe.$$scope={dirty:_,ctx:f}),IM.$set(CEe);const wEe={};_&2&&(wEe.$$scope={dirty:_,ctx:f}),NM.$set(wEe);const r3={};_&2&&(r3.$$scope={dirty:_,ctx:f}),r4.$set(r3);const AEe={};_&2&&(AEe.$$scope={dirty:_,ctx:f}),a4.$set(AEe);const yEe={};_&2&&(yEe.$$scope={dirty:_,ctx:f}),l4.$set(yEe);const t3={};_&2&&(t3.$$scope={dirty:_,ctx:f}),d4.$set(t3);const LEe={};_&2&&(LEe.$$scope={dirty:_,ctx:f}),f4.$set(LEe);const xEe={};_&2&&(xEe.$$scope={dirty:_,ctx:f}),g4.$set(xEe);const a3={};_&2&&(a3.$$scope={dirty:_,ctx:f}),P4.$set(a3);const $Ee={};_&2&&($Ee.$$scope={dirty:_,ctx:f}),I4.$set($Ee);const kEe={};_&2&&(kEe.$$scope={dirty:_,ctx:f}),tE.$set(kEe);const n3={};_&2&&(n3.$$scope={dirty:_,ctx:f}),nE.$set(n3);const SEe={};_&2&&(SEe.$$scope={dirty:_,ctx:f}),lE.$set(SEe);const REe={};_&2&&(REe.$$scope={dirty:_,ctx:f}),dE.$set(REe);const s3={};_&2&&(s3.$$scope={dirty:_,ctx:f}),fE.$set(s3);const PEe={};_&2&&(PEe.$$scope={dirty:_,ctx:f}),gE.$set(PEe);const BEe={};_&2&&(BEe.$$scope={dirty:_,ctx:f}),jE.$set(BEe);const l3={};_&2&&(l3.$$scope={dirty:_,ctx:f}),GE.$set(l3);const IEe={};_&2&&(IEe.$$scope={dirty:_,ctx:f}),YE.$set(IEe);const qEe={};_&2&&(qEe.$$scope={dirty:_,ctx:f}),ZE.$set(qEe);const i3={};_&2&&(i3.$$scope={dirty:_,ctx:f}),m5.$set(i3);const NEe={};_&2&&(NEe.$$scope={dirty:_,ctx:f}),h5.$set(NEe);const jEe={};_&2&&(jEe.$$scope={dirty:_,ctx:f}),w5.$set(jEe);const d3={};_&2&&(d3.$$scope={dirty:_,ctx:f}),y5.$set(d3);const DEe={};_&2&&(DEe.$$scope={dirty:_,ctx:f}),q5.$set(DEe);const GEe={};_&2&&(GEe.$$scope={dirty:_,ctx:f}),j5.$set(GEe);const c3={};_&2&&(c3.$$scope={dirty:_,ctx:f}),J5.$set(c3);const OEe={};_&2&&(OEe.$$scope={dirty:_,ctx:f}),K5.$set(OEe);const VEe={};_&2&&(VEe.$$scope={dirty:_,ctx:f}),dC.$set(VEe);const f3={};_&2&&(f3.$$scope={dirty:_,ctx:f}),fC.$set(f3);const XEe={};_&2&&(XEe.$$scope={dirty:_,ctx:f}),FC.$set(XEe);const zEe={};_&2&&(zEe.$$scope={dirty:_,ctx:f}),MC.$set(zEe);const m3={};_&2&&(m3.$$scope={dirty:_,ctx:f}),kC.$set(m3);const QEe={};_&2&&(QEe.$$scope={dirty:_,ctx:f}),RC.$set(QEe);const WEe={};_&2&&(WEe.$$scope={dirty:_,ctx:f}),BC.$set(WEe);const g3={};_&2&&(g3.$$scope={dirty:_,ctx:f}),qC.$set(g3);const HEe={};_&2&&(HEe.$$scope={dirty:_,ctx:f}),DC.$set(HEe);const UEe={};_&2&&(UEe.$$scope={dirty:_,ctx:f}),OC.$set(UEe);const h3={};_&2&&(h3.$$scope={dirty:_,ctx:f}),XC.$set(h3)},i(f){QNe||(E(d.$$.fragment,f),E(Aa.$$.fragment,f),E(uA.$$.fragment,f),E(_A.$$.fragment,f),E(yf.$$.fragment,f),E(bA.$$.fragment,f),E(vA.$$.fragment,f),E(MA.$$.fragment,f),E(Ag.$$.fragment,f),E(EA.$$.fragment,f),E(CA.$$.fragment,f),E(wA.$$.fragment,f),E(LA.$$.fragment,f),E(nh.$$.fragment,f),E(xA.$$.fragment,f),E($A.$$.fragment,f),E(kA.$$.fragment,f),E(PA.$$.fragment,f),E(Ph.$$.fragment,f),E(Bh.$$.fragment,f),E(BA.$$.fragment,f),E(IA.$$.fragment,f),E(qA.$$.fragment,f),E(DA.$$.fragment,f),E(Zh.$$.fragment,f),E(ep.$$.fragment,f),E(GA.$$.fragment,f),E(OA.$$.fragment,f),E(VA.$$.fragment,f),E(zA.$$.fragment,f),E(tp.$$.fragment,f),E(QA.$$.fragment,f),E(Wu.$$.fragment,f),E(WA.$$.fragment,f),E(HA.$$.fragment,f),E(JA.$$.fragment,f),E(Uu.$$.fragment,f),E(YA.$$.fragment,f),E(q_.$$.fragment,f),E(KA.$$.fragment,f),E(ZA.$$.fragment,f),E(o0.$$.fragment,f),E(j_.$$.fragment,f),E(r0.$$.fragment,f),E(E2.$$.fragment,f),E(t0.$$.fragment,f),E(a0.$$.fragment,f),E(s0.$$.fragment,f),E(w2.$$.fragment,f),E(l0.$$.fragment,f),E(i1.$$.fragment,f),E(i0.$$.fragment,f),E(d0.$$.fragment,f),E(f0.$$.fragment,f),E(c1.$$.fragment,f),E(m0.$$.fragment,f),E(x1.$$.fragment,f),E(g0.$$.fragment,f),E(h0.$$.fragment,f),E(u0.$$.fragment,f),E(k1.$$.fragment,f),E(_0.$$.fragment,f),E(Ab.$$.fragment,f),E(b0.$$.fragment,f),E(v0.$$.fragment,f),E(T0.$$.fragment,f),E(Lb.$$.fragment,f),E(M0.$$.fragment,f),E(nv.$$.fragment,f),E(E0.$$.fragment,f),E(C0.$$.fragment,f),E(A0.$$.fragment,f),E(lv.$$.fragment,f),E(y0.$$.fragment,f),E(hv.$$.fragment,f),E(L0.$$.fragment,f),E(x0.$$.fragment,f),E(k0.$$.fragment,f),E(uv.$$.fragment,f),E(S0.$$.fragment,f),E(Yv.$$.fragment,f),E(R0.$$.fragment,f),E(P0.$$.fragment,f),E(I0.$$.fragment,f),E(Zv.$$.fragment,f),E(q0.$$.fragment,f),E(DF.$$.fragment,f),E(N0.$$.fragment,f),E(j0.$$.fragment,f),E(G0.$$.fragment,f),E(OF.$$.fragment,f),E(O0.$$.fragment,f),E(zF.$$.fragment,f),E(V0.$$.fragment,f),E(X0.$$.fragment,f),E(Q0.$$.fragment,f),E(WF.$$.fragment,f),E(W0.$$.fragment,f),E(s6.$$.fragment,f),E(H0.$$.fragment,f),E(U0.$$.fragment,f),E(Y0.$$.fragment,f),E(i6.$$.fragment,f),E(K0.$$.fragment,f),E(f6.$$.fragment,f),E(Z0.$$.fragment,f),E(ey.$$.fragment,f),E(ry.$$.fragment,f),E(g6.$$.fragment,f),E(ty.$$.fragment,f),E(u6.$$.fragment,f),E(ay.$$.fragment,f),E(ny.$$.fragment,f),E(ly.$$.fragment,f),E(b6.$$.fragment,f),E(iy.$$.fragment,f),E(L6.$$.fragment,f),E(dy.$$.fragment,f),E(cy.$$.fragment,f),E(my.$$.fragment,f),E($6.$$.fragment,f),E(gy.$$.fragment,f),E(I6.$$.fragment,f),E(hy.$$.fragment,f),E(py.$$.fragment,f),E(_y.$$.fragment,f),E(N6.$$.fragment,f),E(by.$$.fragment,f),E(H6.$$.fragment,f),E(vy.$$.fragment,f),E(Fy.$$.fragment,f),E(My.$$.fragment,f),E(J6.$$.fragment,f),E(Ey.$$.fragment,f),E(eT.$$.fragment,f),E(wy.$$.fragment,f),E(Ay.$$.fragment,f),E(Ly.$$.fragment,f),E(rT.$$.fragment,f),E(xy.$$.fragment,f),E(iT.$$.fragment,f),E($y.$$.fragment,f),E(ky.$$.fragment,f),E(Ry.$$.fragment,f),E(cT.$$.fragment,f),E(Py.$$.fragment,f),E(pT.$$.fragment,f),E(By.$$.fragment,f),E(Iy.$$.fragment,f),E(Ny.$$.fragment,f),E(_T.$$.fragment,f),E(jy.$$.fragment,f),E(TT.$$.fragment,f),E(Gy.$$.fragment,f),E(Oy.$$.fragment,f),E(Xy.$$.fragment,f),E(ET.$$.fragment,f),E(zy.$$.fragment,f),E(AT.$$.fragment,f),E(Qy.$$.fragment,f),E(Wy.$$.fragment,f),E(Uy.$$.fragment,f),E(LT.$$.fragment,f),E(Jy.$$.fragment,f),E(PT.$$.fragment,f),E(Yy.$$.fragment,f),E(Ky.$$.fragment,f),E(eL.$$.fragment,f),E(IT.$$.fragment,f),E(oL.$$.fragment,f),E(jT.$$.fragment,f),E(rL.$$.fragment,f),E(tL.$$.fragment,f),E(nL.$$.fragment,f),E(GT.$$.fragment,f),E(sL.$$.fragment,f),E(S8.$$.fragment,f),E(lL.$$.fragment,f),E(iL.$$.fragment,f),E(cL.$$.fragment,f),E(P8.$$.fragment,f),E(fL.$$.fragment,f),E(a7.$$.fragment,f),E(mL.$$.fragment,f),E(gL.$$.fragment,f),E(pL.$$.fragment,f),E(s7.$$.fragment,f),E(uL.$$.fragment,f),E(v7.$$.fragment,f),E(_L.$$.fragment,f),E(bL.$$.fragment,f),E(FL.$$.fragment,f),E(T7.$$.fragment,f),E(TL.$$.fragment,f),E(w7.$$.fragment,f),E(ML.$$.fragment,f),E(EL.$$.fragment,f),E(wL.$$.fragment,f),E(y7.$$.fragment,f),E(AL.$$.fragment,f),E(H7.$$.fragment,f),E(yL.$$.fragment,f),E(LL.$$.fragment,f),E($L.$$.fragment,f),E(J7.$$.fragment,f),E(kL.$$.fragment,f),E(lM.$$.fragment,f),E(SL.$$.fragment,f),E(RL.$$.fragment,f),E(BL.$$.fragment,f),E(dM.$$.fragment,f),E(IL.$$.fragment,f),E(IM.$$.fragment,f),E(qL.$$.fragment,f),E(NL.$$.fragment,f),E(DL.$$.fragment,f),E(NM.$$.fragment,f),E(GL.$$.fragment,f),E(r4.$$.fragment,f),E(OL.$$.fragment,f),E(VL.$$.fragment,f),E(zL.$$.fragment,f),E(a4.$$.fragment,f),E(QL.$$.fragment,f),E(l4.$$.fragment,f),E(HL.$$.fragment,f),E(UL.$$.fragment,f),E(YL.$$.fragment,f),E(d4.$$.fragment,f),E(KL.$$.fragment,f),E(f4.$$.fragment,f),E(ZL.$$.fragment,f),E(ex.$$.fragment,f),E(rx.$$.fragment,f),E(g4.$$.fragment,f),E(tx.$$.fragment,f),E(P4.$$.fragment,f),E(ax.$$.fragment,f),E(nx.$$.fragment,f),E(lx.$$.fragment,f),E(I4.$$.fragment,f),E(ix.$$.fragment,f),E(tE.$$.fragment,f),E(dx.$$.fragment,f),E(cx.$$.fragment,f),E(mx.$$.fragment,f),E(nE.$$.fragment,f),E(gx.$$.fragment,f),E(lE.$$.fragment,f),E(hx.$$.fragment,f),E(px.$$.fragment,f),E(_x.$$.fragment,f),E(dE.$$.fragment,f),E(bx.$$.fragment,f),E(fE.$$.fragment,f),E(vx.$$.fragment,f),E(Fx.$$.fragment,f),E(Mx.$$.fragment,f),E(gE.$$.fragment,f),E(Ex.$$.fragment,f),E(jE.$$.fragment,f),E(Cx.$$.fragment,f),E(wx.$$.fragment,f),E(yx.$$.fragment,f),E(GE.$$.fragment,f),E(Lx.$$.fragment,f),E(YE.$$.fragment,f),E(xx.$$.fragment,f),E($x.$$.fragment,f),E(Sx.$$.fragment,f),E(ZE.$$.fragment,f),E(Rx.$$.fragment,f),E(m5.$$.fragment,f),E(Px.$$.fragment,f),E(Bx.$$.fragment,f),E(qx.$$.fragment,f),E(h5.$$.fragment,f),E(Nx.$$.fragment,f),E(w5.$$.fragment,f),E(jx.$$.fragment,f),E(Dx.$$.fragment,f),E(Ox.$$.fragment,f),E(y5.$$.fragment,f),E(Vx.$$.fragment,f),E(q5.$$.fragment,f),E(Xx.$$.fragment,f),E(zx.$$.fragment,f),E(Wx.$$.fragment,f),E(j5.$$.fragment,f),E(Hx.$$.fragment,f),E(J5.$$.fragment,f),E(Ux.$$.fragment,f),E(Jx.$$.fragment,f),E(Kx.$$.fragment,f),E(K5.$$.fragment,f),E(Zx.$$.fragment,f),E(dC.$$.fragment,f),E(e9.$$.fragment,f),E(o9.$$.fragment,f),E(t9.$$.fragment,f),E(fC.$$.fragment,f),E(a9.$$.fragment,f),E(FC.$$.fragment,f),E(n9.$$.fragment,f),E(s9.$$.fragment,f),E(i9.$$.fragment,f),E(MC.$$.fragment,f),E(d9.$$.fragment,f),E(kC.$$.fragment,f),E(c9.$$.fragment,f),E(f9.$$.fragment,f),E(g9.$$.fragment,f),E(RC.$$.fragment,f),E(h9.$$.fragment,f),E(BC.$$.fragment,f),E(p9.$$.fragment,f),E(u9.$$.fragment,f),E(b9.$$.fragment,f),E(qC.$$.fragment,f),E(v9.$$.fragment,f),E(DC.$$.fragment,f),E(T9.$$.fragment,f),E(M9.$$.fragment,f),E(C9.$$.fragment,f),E(OC.$$.fragment,f),E(w9.$$.fragment,f),E(XC.$$.fragment,f),QNe=!0)},o(f){C(d.$$.fragment,f),C(Aa.$$.fragment,f),C(uA.$$.fragment,f),C(_A.$$.fragment,f),C(yf.$$.fragment,f),C(bA.$$.fragment,f),C(vA.$$.fragment,f),C(MA.$$.fragment,f),C(Ag.$$.fragment,f),C(EA.$$.fragment,f),C(CA.$$.fragment,f),C(wA.$$.fragment,f),C(LA.$$.fragment,f),C(nh.$$.fragment,f),C(xA.$$.fragment,f),C($A.$$.fragment,f),C(kA.$$.fragment,f),C(PA.$$.fragment,f),C(Ph.$$.fragment,f),C(Bh.$$.fragment,f),C(BA.$$.fragment,f),C(IA.$$.fragment,f),C(qA.$$.fragment,f),C(DA.$$.fragment,f),C(Zh.$$.fragment,f),C(ep.$$.fragment,f),C(GA.$$.fragment,f),C(OA.$$.fragment,f),C(VA.$$.fragment,f),C(zA.$$.fragment,f),C(tp.$$.fragment,f),C(QA.$$.fragment,f),C(Wu.$$.fragment,f),C(WA.$$.fragment,f),C(HA.$$.fragment,f),C(JA.$$.fragment,f),C(Uu.$$.fragment,f),C(YA.$$.fragment,f),C(q_.$$.fragment,f),C(KA.$$.fragment,f),C(ZA.$$.fragment,f),C(o0.$$.fragment,f),C(j_.$$.fragment,f),C(r0.$$.fragment,f),C(E2.$$.fragment,f),C(t0.$$.fragment,f),C(a0.$$.fragment,f),C(s0.$$.fragment,f),C(w2.$$.fragment,f),C(l0.$$.fragment,f),C(i1.$$.fragment,f),C(i0.$$.fragment,f),C(d0.$$.fragment,f),C(f0.$$.fragment,f),C(c1.$$.fragment,f),C(m0.$$.fragment,f),C(x1.$$.fragment,f),C(g0.$$.fragment,f),C(h0.$$.fragment,f),C(u0.$$.fragment,f),C(k1.$$.fragment,f),C(_0.$$.fragment,f),C(Ab.$$.fragment,f),C(b0.$$.fragment,f),C(v0.$$.fragment,f),C(T0.$$.fragment,f),C(Lb.$$.fragment,f),C(M0.$$.fragment,f),C(nv.$$.fragment,f),C(E0.$$.fragment,f),C(C0.$$.fragment,f),C(A0.$$.fragment,f),C(lv.$$.fragment,f),C(y0.$$.fragment,f),C(hv.$$.fragment,f),C(L0.$$.fragment,f),C(x0.$$.fragment,f),C(k0.$$.fragment,f),C(uv.$$.fragment,f),C(S0.$$.fragment,f),C(Yv.$$.fragment,f),C(R0.$$.fragment,f),C(P0.$$.fragment,f),C(I0.$$.fragment,f),C(Zv.$$.fragment,f),C(q0.$$.fragment,f),C(DF.$$.fragment,f),C(N0.$$.fragment,f),C(j0.$$.fragment,f),C(G0.$$.fragment,f),C(OF.$$.fragment,f),C(O0.$$.fragment,f),C(zF.$$.fragment,f),C(V0.$$.fragment,f),C(X0.$$.fragment,f),C(Q0.$$.fragment,f),C(WF.$$.fragment,f),C(W0.$$.fragment,f),C(s6.$$.fragment,f),C(H0.$$.fragment,f),C(U0.$$.fragment,f),C(Y0.$$.fragment,f),C(i6.$$.fragment,f),C(K0.$$.fragment,f),C(f6.$$.fragment,f),C(Z0.$$.fragment,f),C(ey.$$.fragment,f),C(ry.$$.fragment,f),C(g6.$$.fragment,f),C(ty.$$.fragment,f),C(u6.$$.fragment,f),C(ay.$$.fragment,f),C(ny.$$.fragment,f),C(ly.$$.fragment,f),C(b6.$$.fragment,f),C(iy.$$.fragment,f),C(L6.$$.fragment,f),C(dy.$$.fragment,f),C(cy.$$.fragment,f),C(my.$$.fragment,f),C($6.$$.fragment,f),C(gy.$$.fragment,f),C(I6.$$.fragment,f),C(hy.$$.fragment,f),C(py.$$.fragment,f),C(_y.$$.fragment,f),C(N6.$$.fragment,f),C(by.$$.fragment,f),C(H6.$$.fragment,f),C(vy.$$.fragment,f),C(Fy.$$.fragment,f),C(My.$$.fragment,f),C(J6.$$.fragment,f),C(Ey.$$.fragment,f),C(eT.$$.fragment,f),C(wy.$$.fragment,f),C(Ay.$$.fragment,f),C(Ly.$$.fragment,f),C(rT.$$.fragment,f),C(xy.$$.fragment,f),C(iT.$$.fragment,f),C($y.$$.fragment,f),C(ky.$$.fragment,f),C(Ry.$$.fragment,f),C(cT.$$.fragment,f),C(Py.$$.fragment,f),C(pT.$$.fragment,f),C(By.$$.fragment,f),C(Iy.$$.fragment,f),C(Ny.$$.fragment,f),C(_T.$$.fragment,f),C(jy.$$.fragment,f),C(TT.$$.fragment,f),C(Gy.$$.fragment,f),C(Oy.$$.fragment,f),C(Xy.$$.fragment,f),C(ET.$$.fragment,f),C(zy.$$.fragment,f),C(AT.$$.fragment,f),C(Qy.$$.fragment,f),C(Wy.$$.fragment,f),C(Uy.$$.fragment,f),C(LT.$$.fragment,f),C(Jy.$$.fragment,f),C(PT.$$.fragment,f),C(Yy.$$.fragment,f),C(Ky.$$.fragment,f),C(eL.$$.fragment,f),C(IT.$$.fragment,f),C(oL.$$.fragment,f),C(jT.$$.fragment,f),C(rL.$$.fragment,f),C(tL.$$.fragment,f),C(nL.$$.fragment,f),C(GT.$$.fragment,f),C(sL.$$.fragment,f),C(S8.$$.fragment,f),C(lL.$$.fragment,f),C(iL.$$.fragment,f),C(cL.$$.fragment,f),C(P8.$$.fragment,f),C(fL.$$.fragment,f),C(a7.$$.fragment,f),C(mL.$$.fragment,f),C(gL.$$.fragment,f),C(pL.$$.fragment,f),C(s7.$$.fragment,f),C(uL.$$.fragment,f),C(v7.$$.fragment,f),C(_L.$$.fragment,f),C(bL.$$.fragment,f),C(FL.$$.fragment,f),C(T7.$$.fragment,f),C(TL.$$.fragment,f),C(w7.$$.fragment,f),C(ML.$$.fragment,f),C(EL.$$.fragment,f),C(wL.$$.fragment,f),C(y7.$$.fragment,f),C(AL.$$.fragment,f),C(H7.$$.fragment,f),C(yL.$$.fragment,f),C(LL.$$.fragment,f),C($L.$$.fragment,f),C(J7.$$.fragment,f),C(kL.$$.fragment,f),C(lM.$$.fragment,f),C(SL.$$.fragment,f),C(RL.$$.fragment,f),C(BL.$$.fragment,f),C(dM.$$.fragment,f),C(IL.$$.fragment,f),C(IM.$$.fragment,f),C(qL.$$.fragment,f),C(NL.$$.fragment,f),C(DL.$$.fragment,f),C(NM.$$.fragment,f),C(GL.$$.fragment,f),C(r4.$$.fragment,f),C(OL.$$.fragment,f),C(VL.$$.fragment,f),C(zL.$$.fragment,f),C(a4.$$.fragment,f),C(QL.$$.fragment,f),C(l4.$$.fragment,f),C(HL.$$.fragment,f),C(UL.$$.fragment,f),C(YL.$$.fragment,f),C(d4.$$.fragment,f),C(KL.$$.fragment,f),C(f4.$$.fragment,f),C(ZL.$$.fragment,f),C(ex.$$.fragment,f),C(rx.$$.fragment,f),C(g4.$$.fragment,f),C(tx.$$.fragment,f),C(P4.$$.fragment,f),C(ax.$$.fragment,f),C(nx.$$.fragment,f),C(lx.$$.fragment,f),C(I4.$$.fragment,f),C(ix.$$.fragment,f),C(tE.$$.fragment,f),C(dx.$$.fragment,f),C(cx.$$.fragment,f),C(mx.$$.fragment,f),C(nE.$$.fragment,f),C(gx.$$.fragment,f),C(lE.$$.fragment,f),C(hx.$$.fragment,f),C(px.$$.fragment,f),C(_x.$$.fragment,f),C(dE.$$.fragment,f),C(bx.$$.fragment,f),C(fE.$$.fragment,f),C(vx.$$.fragment,f),C(Fx.$$.fragment,f),C(Mx.$$.fragment,f),C(gE.$$.fragment,f),C(Ex.$$.fragment,f),C(jE.$$.fragment,f),C(Cx.$$.fragment,f),C(wx.$$.fragment,f),C(yx.$$.fragment,f),C(GE.$$.fragment,f),C(Lx.$$.fragment,f),C(YE.$$.fragment,f),C(xx.$$.fragment,f),C($x.$$.fragment,f),C(Sx.$$.fragment,f),C(ZE.$$.fragment,f),C(Rx.$$.fragment,f),C(m5.$$.fragment,f),C(Px.$$.fragment,f),C(Bx.$$.fragment,f),C(qx.$$.fragment,f),C(h5.$$.fragment,f),C(Nx.$$.fragment,f),C(w5.$$.fragment,f),C(jx.$$.fragment,f),C(Dx.$$.fragment,f),C(Ox.$$.fragment,f),C(y5.$$.fragment,f),C(Vx.$$.fragment,f),C(q5.$$.fragment,f),C(Xx.$$.fragment,f),C(zx.$$.fragment,f),C(Wx.$$.fragment,f),C(j5.$$.fragment,f),C(Hx.$$.fragment,f),C(J5.$$.fragment,f),C(Ux.$$.fragment,f),C(Jx.$$.fragment,f),C(Kx.$$.fragment,f),C(K5.$$.fragment,f),C(Zx.$$.fragment,f),C(dC.$$.fragment,f),C(e9.$$.fragment,f),C(o9.$$.fragment,f),C(t9.$$.fragment,f),C(fC.$$.fragment,f),C(a9.$$.fragment,f),C(FC.$$.fragment,f),C(n9.$$.fragment,f),C(s9.$$.fragment,f),C(i9.$$.fragment,f),C(MC.$$.fragment,f),C(d9.$$.fragment,f),C(kC.$$.fragment,f),C(c9.$$.fragment,f),C(f9.$$.fragment,f),C(g9.$$.fragment,f),C(RC.$$.fragment,f),C(h9.$$.fragment,f),C(BC.$$.fragment,f),C(p9.$$.fragment,f),C(u9.$$.fragment,f),C(b9.$$.fragment,f),C(qC.$$.fragment,f),C(v9.$$.fragment,f),C(DC.$$.fragment,f),C(T9.$$.fragment,f),C(M9.$$.fragment,f),C(C9.$$.fragment,f),C(OC.$$.fragment,f),C(w9.$$.fragment,f),C(XC.$$.fragment,f),QNe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(Mf),f&&t(rt),f&&t(qe),f&&t(Xe),f&&t(Cf),w(Aa,f),f&&t(ze),f&&t(Ae),f&&t(Co),f&&t(ya),f&&t(GIe),f&&t(Ti),w(uA),f&&t(OIe),f&&t(Bn),f&&t(VIe),w(_A,f),f&&t(XIe),f&&t(X$),f&&t(zIe),w(yf,f),f&&t(QIe),f&&t(Mi),w(bA),f&&t(WIe),f&&t(wo),w(vA),w(MA),w(Ag),w(EA),f&&t(HIe),f&&t(Ci),w(CA),f&&t(UIe),f&&t(Ao),w(wA),w(LA),w(nh),w(xA),f&&t(JIe),f&&t(wi),w($A),f&&t(YIe),f&&t(yo),w(kA),w(PA),w(Ph),w(Bh),w(BA),f&&t(KIe),f&&t(Ai),w(IA),f&&t(ZIe),f&&t(Lo),w(qA),w(DA),w(Zh),w(ep),w(GA),f&&t(eqe),f&&t(Li),w(OA),f&&t(oqe),f&&t(xo),w(VA),w(zA),w(tp),w(QA),w(Wu),f&&t(rqe),f&&t(ki),w(WA),f&&t(tqe),f&&t($o),w(HA),w(JA),w(Uu),w(YA),w(q_),f&&t(aqe),f&&t(Pi),w(KA),f&&t(nqe),f&&t(ko),w(ZA),w(o0),w(j_),w(r0),w(E2),f&&t(sqe),f&&t(qi),w(t0),f&&t(lqe),f&&t(So),w(a0),w(s0),w(w2),w(l0),w(i1),f&&t(iqe),f&&t(Di),w(i0),f&&t(dqe),f&&t(Ro),w(d0),w(f0),w(c1),w(m0),w(x1),f&&t(cqe),f&&t(Vi),w(g0),f&&t(fqe),f&&t(Po),w(h0),w(u0),w(k1),w(_0),w(Ab),f&&t(mqe),f&&t(Qi),w(b0),f&&t(gqe),f&&t(Bo),w(v0),w(T0),w(Lb),w(M0),w(nv),f&&t(hqe),f&&t(Ui),w(E0),f&&t(pqe),f&&t(Io),w(C0),w(A0),w(lv),w(y0),w(hv),f&&t(uqe),f&&t(Ki),w(L0),f&&t(_qe),f&&t(qo),w(x0),w(k0),w(uv),w(S0),w(Yv),f&&t(bqe),f&&t(od),w(R0),f&&t(vqe),f&&t(No),w(P0),w(I0),w(Zv),w(q0),w(DF),f&&t(Fqe),f&&t(ad),w(N0),f&&t(Tqe),f&&t(jo),w(j0),w(G0),w(OF),w(O0),w(zF),f&&t(Mqe),f&&t(ld),w(V0),f&&t(Eqe),f&&t(Do),w(X0),w(Q0),w(WF),w(W0),w(s6),f&&t(Cqe),f&&t(cd),w(H0),f&&t(wqe),f&&t(Go),w(U0),w(Y0),w(i6),w(K0),w(f6),f&&t(Aqe),f&&t(gd),w(Z0),f&&t(yqe),f&&t(Oo),w(ey),w(ry),w(g6),w(ty),w(u6),f&&t(Lqe),f&&t(ud),w(ay),f&&t(xqe),f&&t(Vo),w(ny),w(ly),w(b6),w(iy),w(L6),f&&t($qe),f&&t(vd),w(dy),f&&t(kqe),f&&t(Xo),w(cy),w(my),w($6),w(gy),w(I6),f&&t(Sqe),f&&t(Md),w(hy),f&&t(Rqe),f&&t(zo),w(py),w(_y),w(N6),w(by),w(H6),f&&t(Pqe),f&&t(wd),w(vy),f&&t(Bqe),f&&t(Qo),w(Fy),w(My),w(J6),w(Ey),w(eT),f&&t(Iqe),f&&t(Ld),w(wy),f&&t(qqe),f&&t(Wo),w(Ay),w(Ly),w(rT),w(xy),w(iT),f&&t(Nqe),f&&t(kd),w($y),f&&t(jqe),f&&t(Ho),w(ky),w(Ry),w(cT),w(Py),w(pT),f&&t(Dqe),f&&t(Bd),w(By),f&&t(Gqe),f&&t(Uo),w(Iy),w(Ny),w(_T),w(jy),w(TT),f&&t(Oqe),f&&t(Nd),w(Gy),f&&t(Vqe),f&&t(Jo),w(Oy),w(Xy),w(ET),w(zy),w(AT),f&&t(Xqe),f&&t(Gd),w(Qy),f&&t(zqe),f&&t(Yo),w(Wy),w(Uy),w(LT),w(Jy),w(PT),f&&t(Qqe),f&&t(Xd),w(Yy),f&&t(Wqe),f&&t(Ko),w(Ky),w(eL),w(IT),w(oL),w(jT),f&&t(Hqe),f&&t(Wd),w(rL),f&&t(Uqe),f&&t(Zo),w(tL),w(nL),w(GT),w(sL),w(S8),f&&t(Jqe),f&&t(Jd),w(lL),f&&t(Yqe),f&&t(er),w(iL),w(cL),w(P8),w(fL),w(a7),f&&t(Kqe),f&&t(Zd),w(mL),f&&t(Zqe),f&&t(or),w(gL),w(pL),w(s7),w(uL),w(v7),f&&t(eNe),f&&t(rc),w(_L),f&&t(oNe),f&&t(rr),w(bL),w(FL),w(T7),w(TL),w(w7),f&&t(rNe),f&&t(sc),w(ML),f&&t(tNe),f&&t(tr),w(EL),w(wL),w(y7),w(AL),w(H7),f&&t(aNe),f&&t(dc),w(yL),f&&t(nNe),f&&t(ar),w(LL),w($L),w(J7),w(kL),w(lM),f&&t(sNe),f&&t(mc),w(SL),f&&t(lNe),f&&t(nr),w(RL),w(BL),w(dM),w(IL),w(IM),f&&t(iNe),f&&t(pc),w(qL),f&&t(dNe),f&&t(sr),w(NL),w(DL),w(NM),w(GL),w(r4),f&&t(cNe),f&&t(bc),w(OL),f&&t(fNe),f&&t(lr),w(VL),w(zL),w(a4),w(QL),w(l4),f&&t(mNe),f&&t(Tc),w(HL),f&&t(gNe),f&&t(ir),w(UL),w(YL),w(d4),w(KL),w(f4),f&&t(hNe),f&&t(Cc),w(ZL),f&&t(pNe),f&&t(dr),w(ex),w(rx),w(g4),w(tx),w(P4),f&&t(uNe),f&&t(yc),w(ax),f&&t(_Ne),f&&t(cr),w(nx),w(lx),w(I4),w(ix),w(tE),f&&t(bNe),f&&t($c),w(dx),f&&t(vNe),f&&t(fr),w(cx),w(mx),w(nE),w(gx),w(lE),f&&t(FNe),f&&t(Rc),w(hx),f&&t(TNe),f&&t(mr),w(px),w(_x),w(dE),w(bx),w(fE),f&&t(MNe),f&&t(Ic),w(vx),f&&t(ENe),f&&t(gr),w(Fx),w(Mx),w(gE),w(Ex),w(jE),f&&t(CNe),f&&t(jc),w(Cx),f&&t(wNe),f&&t(hr),w(wx),w(yx),w(GE),w(Lx),w(YE),f&&t(ANe),f&&t(Oc),w(xx),f&&t(yNe),f&&t(pr),w($x),w(Sx),w(ZE),w(Rx),w(m5),f&&t(LNe),f&&t(zc),w(Px),f&&t(xNe),f&&t(ur),w(Bx),w(qx),w(h5),w(Nx),w(w5),f&&t($Ne),f&&t(Hc),w(jx),f&&t(kNe),f&&t(_r),w(Dx),w(Ox),w(y5),w(Vx),w(q5),f&&t(SNe),f&&t(Yc),w(Xx),f&&t(RNe),f&&t(br),w(zx),w(Wx),w(j5),w(Hx),w(J5),f&&t(PNe),f&&t(ef),w(Ux),f&&t(BNe),f&&t(vr),w(Jx),w(Kx),w(K5),w(Zx),w(dC),f&&t(INe),f&&t(tf),w(e9),f&&t(qNe),f&&t(Fr),w(o9),w(t9),w(fC),w(a9),w(FC),f&&t(NNe),f&&t(sf),w(n9),f&&t(jNe),f&&t(Tr),w(s9),w(i9),w(MC),w(d9),w(kC),f&&t(DNe),f&&t(cf),w(c9),f&&t(GNe),f&&t(Mr),w(f9),w(g9),w(RC),w(h9),w(BC),f&&t(ONe),f&&t(gf),w(p9),f&&t(VNe),f&&t(Er),w(u9),w(b9),w(qC),w(v9),w(DC),f&&t(XNe),f&&t(uf),w(T9),f&&t(zNe),f&&t(Cr),w(M9),w(C9),w(OC),w(w9),w(XC)}}}const Nxt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function jxt(A){return qyt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Qxt extends Ryt{constructor(g){super();Pyt(this,g,jxt,qxt,Byt,{})}}export{Qxt as default,Nxt as metadata};
