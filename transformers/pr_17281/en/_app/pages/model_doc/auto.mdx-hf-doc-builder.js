import{S as Wzt,i as Hzt,s as Uzt,e as a,k as l,w as F,t as o,M as Jzt,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as Yzt,L as I}from"../../chunks/vendor-hf-doc-builder.js";import{T as Art}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as re}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function Kzt($){let g,v,p,m,_,d,h,Eo,Ai,Rf,st,Li,yi,Y6,Pf,Oe,Qe,xi,Rn,K6,Pn,Bn,Z6,$i,In,eL,ki,Bf,ka;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),_=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Eo=o(`, make sure its
`),Ai=a("code"),Rf=o("model_type"),st=o(" attribute is set to the same key you use when registering the config (here "),Li=a("code"),yi=o('"new-model"'),Y6=o(")."),Pf=l(),Oe=a("p"),Qe=o("Likewise, if your "),xi=a("code"),Rn=o("NewModel"),K6=o(" is a subclass of "),Pn=a("a"),Bn=o("PreTrainedModel"),Z6=o(`, make sure its
`),$i=a("code"),In=o("config_class"),eL=o(` attribute is set to the same class you use when registering the model (here
`),ki=a("code"),Bf=o("NewModelConfig"),ka=o(")."),this.h()},l(We){g=n(We,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var kS=s(p);m=r(kS,"NewModelConfig"),kS.forEach(t),_=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var Si=s(d);h=r(Si,"PretrainedConfig"),Si.forEach(t),Eo=r(Ae,`, make sure its
`),Ai=n(Ae,"CODE",{});var SS=s(Ai);Rf=r(SS,"model_type"),SS.forEach(t),st=r(Ae," attribute is set to the same key you use when registering the config (here "),Li=n(Ae,"CODE",{});var RS=s(Li);yi=r(RS,'"new-model"'),RS.forEach(t),Y6=r(Ae,")."),Ae.forEach(t),Pf=i(We),Oe=n(We,"P",{});var Co=s(Oe);Qe=r(Co,"Likewise, if your "),xi=n(Co,"CODE",{});var Sa=s(xi);Rn=r(Sa,"NewModel"),Sa.forEach(t),K6=r(Co," is a subclass of "),Pn=n(Co,"A",{href:!0});var PS=s(Pn);Bn=r(PS,"PreTrainedModel"),PS.forEach(t),Z6=r(Co,`, make sure its
`),$i=n(Co,"CODE",{});var If=s($i);In=r(If,"config_class"),If.forEach(t),eL=r(Co,` attribute is set to the same class you use when registering the model (here
`),ki=n(Co,"CODE",{});var BS=s(ki);Bf=r(BS,"NewModelConfig"),BS.forEach(t),ka=r(Co,")."),Co.forEach(t),this.h()},h(){c(Pn,"href","/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel")},m(We,Ae){b(We,g,Ae),e(g,v),e(g,p),e(p,m),e(g,_),e(g,d),e(d,h),e(g,Eo),e(g,Ai),e(Ai,Rf),e(g,st),e(g,Li),e(Li,yi),e(g,Y6),b(We,Pf,Ae),b(We,Oe,Ae),e(Oe,Qe),e(Oe,xi),e(xi,Rn),e(Oe,K6),e(Oe,Pn),e(Pn,Bn),e(Oe,Z6),e(Oe,$i),e($i,In),e(Oe,eL),e(Oe,ki),e(ki,Bf),e(Oe,ka)},d(We){We&&t(g),We&&t(Pf),We&&t(Oe)}}}function Zzt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oQt($){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function rQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tQt($){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function aQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Qt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function EQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function AQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $Qt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function OQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function UQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZQt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Wt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function EWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function AWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $Wt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function OWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function UWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JWt($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YWt($){let g,v,p,m,_,d,h,Eo,Ai,Rf,st,Li,yi,Y6,Pf,Oe,Qe,xi,Rn,K6,Pn,Bn,Z6,$i,In,eL,ki,Bf,ka,We,Ae,kS,Si,SS,RS,Co,Sa,PS,If,BS,ZWe,qVe,Ri,Nf,_ae,oL,eHe,uae,oHe,jVe,Nn,rHe,bae,tHe,aHe,vae,nHe,sHe,DVe,rL,GVe,IS,lHe,OVe,qf,VVe,Pi,jf,Fae,tL,iHe,Tae,dHe,XVe,wo,aL,cHe,nL,fHe,NS,mHe,gHe,hHe,sL,pHe,Mae,_He,uHe,bHe,Ar,lL,vHe,Eae,FHe,THe,Bi,MHe,Cae,EHe,CHe,wae,wHe,AHe,LHe,A,Df,Aae,yHe,xHe,qS,$He,kHe,SHe,Gf,Lae,RHe,PHe,jS,BHe,IHe,NHe,Of,yae,qHe,jHe,DS,DHe,GHe,OHe,Vf,xae,VHe,XHe,GS,zHe,QHe,WHe,Xf,$ae,HHe,UHe,OS,JHe,YHe,KHe,zf,kae,ZHe,eUe,VS,oUe,rUe,tUe,Qf,Sae,aUe,nUe,XS,sUe,lUe,iUe,Wf,Rae,dUe,cUe,zS,fUe,mUe,gUe,Hf,Pae,hUe,pUe,QS,_Ue,uUe,bUe,Uf,Bae,vUe,FUe,WS,TUe,MUe,EUe,Jf,Iae,CUe,wUe,HS,AUe,LUe,yUe,Yf,Nae,xUe,$Ue,US,kUe,SUe,RUe,Kf,qae,PUe,BUe,JS,IUe,NUe,qUe,Zf,jae,jUe,DUe,YS,GUe,OUe,VUe,em,Dae,XUe,zUe,KS,QUe,WUe,HUe,om,Gae,UUe,JUe,ZS,YUe,KUe,ZUe,rm,Oae,eJe,oJe,eR,rJe,tJe,aJe,tm,Vae,nJe,sJe,oR,lJe,iJe,dJe,am,Xae,cJe,fJe,rR,mJe,gJe,hJe,nm,zae,pJe,_Je,tR,uJe,bJe,vJe,sm,Qae,FJe,TJe,aR,MJe,EJe,CJe,lm,Wae,wJe,AJe,nR,LJe,yJe,xJe,im,Hae,$Je,kJe,sR,SJe,RJe,PJe,dm,Uae,BJe,IJe,lR,NJe,qJe,jJe,cm,Jae,DJe,GJe,iR,OJe,VJe,XJe,fm,Yae,zJe,QJe,dR,WJe,HJe,UJe,mm,Kae,JJe,YJe,cR,KJe,ZJe,eYe,gm,Zae,oYe,rYe,fR,tYe,aYe,nYe,hm,ene,sYe,lYe,mR,iYe,dYe,cYe,pm,one,fYe,mYe,gR,gYe,hYe,pYe,_m,rne,_Ye,uYe,hR,bYe,vYe,FYe,um,tne,TYe,MYe,pR,EYe,CYe,wYe,bm,ane,AYe,LYe,_R,yYe,xYe,$Ye,vm,nne,kYe,SYe,uR,RYe,PYe,BYe,Fm,sne,IYe,NYe,bR,qYe,jYe,DYe,Tm,lne,GYe,OYe,vR,VYe,XYe,zYe,Mm,ine,QYe,WYe,FR,HYe,UYe,JYe,Em,dne,YYe,KYe,TR,ZYe,eKe,oKe,Cm,cne,rKe,tKe,MR,aKe,nKe,sKe,wm,fne,lKe,iKe,ER,dKe,cKe,fKe,Am,mne,mKe,gKe,CR,hKe,pKe,_Ke,Lm,gne,uKe,bKe,wR,vKe,FKe,TKe,ym,hne,MKe,EKe,AR,CKe,wKe,AKe,xm,pne,LKe,yKe,LR,xKe,$Ke,kKe,$m,_ne,SKe,RKe,yR,PKe,BKe,IKe,km,une,NKe,qKe,xR,jKe,DKe,GKe,Sm,bne,OKe,VKe,$R,XKe,zKe,QKe,Rm,vne,WKe,HKe,kR,UKe,JKe,YKe,Pm,Fne,KKe,ZKe,SR,eZe,oZe,rZe,Bm,Tne,tZe,aZe,RR,nZe,sZe,lZe,Im,Mne,iZe,dZe,PR,cZe,fZe,mZe,Nm,Ene,gZe,hZe,BR,pZe,_Ze,uZe,qm,Cne,bZe,vZe,IR,FZe,TZe,MZe,jm,wne,EZe,CZe,NR,wZe,AZe,LZe,Dm,Ane,yZe,xZe,qR,$Ze,kZe,SZe,Gm,Lne,RZe,PZe,jR,BZe,IZe,NZe,Om,yne,qZe,jZe,DR,DZe,GZe,OZe,Vm,xne,VZe,XZe,GR,zZe,QZe,WZe,Xm,$ne,HZe,UZe,OR,JZe,YZe,KZe,zm,kne,ZZe,eeo,VR,oeo,reo,teo,Qm,Sne,aeo,neo,XR,seo,leo,ieo,Wm,Rne,deo,ceo,zR,feo,meo,geo,Hm,Pne,heo,peo,QR,_eo,ueo,beo,Um,Bne,veo,Feo,WR,Teo,Meo,Eeo,Jm,Ine,Ceo,weo,HR,Aeo,Leo,yeo,Ym,Nne,xeo,$eo,UR,keo,Seo,Reo,Km,qne,Peo,Beo,JR,Ieo,Neo,qeo,Zm,jne,jeo,Deo,YR,Geo,Oeo,Veo,eg,Dne,Xeo,zeo,KR,Qeo,Weo,Heo,og,Gne,Ueo,Jeo,ZR,Yeo,Keo,Zeo,rg,One,eoo,ooo,eP,roo,too,aoo,tg,Vne,noo,soo,oP,loo,ioo,doo,ag,Xne,coo,foo,rP,moo,goo,hoo,ng,zne,poo,_oo,tP,uoo,boo,voo,sg,Qne,Foo,Too,aP,Moo,Eoo,Coo,lg,Wne,woo,Aoo,nP,Loo,yoo,xoo,ig,Hne,$oo,koo,sP,Soo,Roo,Poo,dg,Une,Boo,Ioo,lP,Noo,qoo,joo,cg,Jne,Doo,Goo,iP,Ooo,Voo,Xoo,fg,Yne,zoo,Qoo,dP,Woo,Hoo,Uoo,mg,Kne,Joo,Yoo,cP,Koo,Zoo,ero,gg,Zne,oro,rro,fP,tro,aro,nro,hg,ese,sro,lro,mP,iro,dro,cro,pg,ose,fro,mro,gP,gro,hro,pro,_g,rse,_ro,uro,hP,bro,vro,Fro,ug,tse,Tro,Mro,pP,Ero,Cro,wro,bg,ase,Aro,Lro,_P,yro,xro,$ro,vg,nse,kro,Sro,uP,Rro,Pro,Bro,Fg,sse,Iro,Nro,bP,qro,jro,Dro,Tg,lse,Gro,Oro,vP,Vro,Xro,zro,Mg,ise,Qro,Wro,FP,Hro,Uro,Jro,Eg,dse,Yro,Kro,TP,Zro,eto,oto,Cg,cse,rto,tto,MP,ato,nto,sto,wg,fse,lto,ito,EP,dto,cto,fto,Ag,mse,mto,gto,CP,hto,pto,_to,Lg,gse,uto,bto,wP,vto,Fto,Tto,yg,hse,Mto,Eto,AP,Cto,wto,Ato,xg,pse,Lto,yto,LP,xto,$to,kto,$g,_se,Sto,Rto,yP,Pto,Bto,Ito,kg,use,Nto,qto,xP,jto,Dto,Gto,Sg,bse,Oto,Vto,$P,Xto,zto,Qto,Rg,vse,Wto,Hto,kP,Uto,Jto,Yto,Pg,Fse,Kto,Zto,SP,eao,oao,rao,Bg,Tse,tao,aao,RP,nao,sao,lao,Ig,Mse,iao,dao,PP,cao,fao,mao,Ng,Ese,gao,hao,BP,pao,_ao,uao,qg,Cse,bao,vao,IP,Fao,Tao,Mao,jg,wse,Eao,Cao,NP,wao,Aao,Lao,Dg,Ase,yao,xao,qP,$ao,kao,Sao,Gg,Lse,Rao,Pao,jP,Bao,Iao,Nao,Og,yse,qao,jao,DP,Dao,Gao,Oao,Vg,xse,Vao,Xao,GP,zao,Qao,Wao,Xg,$se,Hao,Uao,OP,Jao,Yao,Kao,zg,kse,Zao,eno,VP,ono,rno,tno,Qg,Sse,ano,nno,XP,sno,lno,ino,Wg,Rse,dno,cno,zP,fno,mno,gno,Hg,Pse,hno,pno,QP,_no,uno,bno,Ug,Bse,vno,Fno,WP,Tno,Mno,Eno,Jg,Ise,Cno,wno,HP,Ano,Lno,yno,Yg,xno,Kg,iL,$no,Nse,kno,zVe,Ii,Zg,qse,dL,Sno,jse,Rno,QVe,Ao,cL,Pno,fL,Bno,UP,Ino,Nno,qno,mL,jno,Dse,Dno,Gno,Ono,Lr,gL,Vno,Gse,Xno,zno,Ra,Qno,Ose,Wno,Hno,Vse,Uno,Jno,Xse,Yno,Kno,Zno,k,qn,zse,eso,oso,JP,rso,tso,YP,aso,nso,sso,jn,Qse,lso,iso,KP,dso,cso,ZP,fso,mso,gso,Dn,Wse,hso,pso,eB,_so,uso,oB,bso,vso,Fso,eh,Hse,Tso,Mso,rB,Eso,Cso,wso,Gn,Use,Aso,Lso,tB,yso,xso,aB,$so,kso,Sso,oh,Jse,Rso,Pso,nB,Bso,Iso,Nso,rh,Yse,qso,jso,sB,Dso,Gso,Oso,th,Kse,Vso,Xso,lB,zso,Qso,Wso,On,Zse,Hso,Uso,iB,Jso,Yso,dB,Kso,Zso,elo,Vn,ele,olo,rlo,cB,tlo,alo,fB,nlo,slo,llo,Xn,ole,ilo,dlo,mB,clo,flo,gB,mlo,glo,hlo,ah,rle,plo,_lo,hB,ulo,blo,vlo,nh,tle,Flo,Tlo,pB,Mlo,Elo,Clo,sh,ale,wlo,Alo,_B,Llo,ylo,xlo,zn,nle,$lo,klo,uB,Slo,Rlo,bB,Plo,Blo,Ilo,lh,sle,Nlo,qlo,vB,jlo,Dlo,Glo,Qn,lle,Olo,Vlo,FB,Xlo,zlo,TB,Qlo,Wlo,Hlo,Wn,ile,Ulo,Jlo,MB,Ylo,Klo,EB,Zlo,eio,oio,Hn,dle,rio,tio,CB,aio,nio,wB,sio,lio,iio,Un,cle,dio,cio,AB,fio,mio,LB,gio,hio,pio,ih,fle,_io,uio,yB,bio,vio,Fio,Jn,mle,Tio,Mio,xB,Eio,Cio,$B,wio,Aio,Lio,Yn,gle,yio,xio,kB,$io,kio,SB,Sio,Rio,Pio,Kn,hle,Bio,Iio,RB,Nio,qio,PB,jio,Dio,Gio,Zn,ple,Oio,Vio,BB,Xio,zio,IB,Qio,Wio,Hio,es,_le,Uio,Jio,NB,Yio,Kio,qB,Zio,edo,odo,os,ule,rdo,tdo,jB,ado,ndo,DB,sdo,ldo,ido,dh,ble,ddo,cdo,GB,fdo,mdo,gdo,rs,vle,hdo,pdo,OB,_do,udo,VB,bdo,vdo,Fdo,ch,Fle,Tdo,Mdo,XB,Edo,Cdo,wdo,ts,Tle,Ado,Ldo,zB,ydo,xdo,QB,$do,kdo,Sdo,as,Mle,Rdo,Pdo,WB,Bdo,Ido,HB,Ndo,qdo,jdo,ns,Ele,Ddo,Gdo,UB,Odo,Vdo,JB,Xdo,zdo,Qdo,fh,Cle,Wdo,Hdo,YB,Udo,Jdo,Ydo,ss,wle,Kdo,Zdo,KB,eco,oco,ZB,rco,tco,aco,ls,Ale,nco,sco,eI,lco,ico,oI,dco,cco,fco,is,Lle,mco,gco,rI,hco,pco,tI,_co,uco,bco,mh,yle,vco,Fco,aI,Tco,Mco,Eco,ds,xle,Cco,wco,nI,Aco,Lco,sI,yco,xco,$co,cs,$le,kco,Sco,lI,Rco,Pco,iI,Bco,Ico,Nco,fs,kle,qco,jco,dI,Dco,Gco,cI,Oco,Vco,Xco,ms,Sle,zco,Qco,fI,Wco,Hco,mI,Uco,Jco,Yco,gs,Rle,Kco,Zco,gI,efo,ofo,hI,rfo,tfo,afo,hs,Ple,nfo,sfo,pI,lfo,ifo,_I,dfo,cfo,ffo,ps,Ble,mfo,gfo,uI,hfo,pfo,bI,_fo,ufo,bfo,_s,Ile,vfo,Ffo,vI,Tfo,Mfo,FI,Efo,Cfo,wfo,gh,Nle,Afo,Lfo,TI,yfo,xfo,$fo,us,qle,kfo,Sfo,MI,Rfo,Pfo,EI,Bfo,Ifo,Nfo,hh,jle,qfo,jfo,CI,Dfo,Gfo,Ofo,ph,Dle,Vfo,Xfo,wI,zfo,Qfo,Wfo,bs,Gle,Hfo,Ufo,AI,Jfo,Yfo,LI,Kfo,Zfo,emo,vs,Ole,omo,rmo,yI,tmo,amo,xI,nmo,smo,lmo,Fs,Vle,imo,dmo,$I,cmo,fmo,kI,mmo,gmo,hmo,_h,Xle,pmo,_mo,SI,umo,bmo,vmo,Ts,zle,Fmo,Tmo,RI,Mmo,Emo,PI,Cmo,wmo,Amo,Ms,Qle,Lmo,ymo,BI,xmo,$mo,II,kmo,Smo,Rmo,Es,Wle,Pmo,Bmo,NI,Imo,Nmo,qI,qmo,jmo,Dmo,Cs,Hle,Gmo,Omo,jI,Vmo,Xmo,DI,zmo,Qmo,Wmo,ws,Ule,Hmo,Umo,GI,Jmo,Ymo,OI,Kmo,Zmo,ego,As,Jle,ogo,rgo,VI,tgo,ago,XI,ngo,sgo,lgo,Ls,Yle,igo,dgo,zI,cgo,fgo,QI,mgo,ggo,hgo,uh,Kle,pgo,_go,WI,ugo,bgo,vgo,ys,Zle,Fgo,Tgo,HI,Mgo,Ego,UI,Cgo,wgo,Ago,bh,eie,Lgo,ygo,JI,xgo,$go,kgo,vh,oie,Sgo,Rgo,YI,Pgo,Bgo,Igo,Fh,rie,Ngo,qgo,KI,jgo,Dgo,Ggo,Th,tie,Ogo,Vgo,ZI,Xgo,zgo,Qgo,xs,aie,Wgo,Hgo,eN,Ugo,Jgo,oN,Ygo,Kgo,Zgo,Mh,nie,eho,oho,rN,rho,tho,aho,$s,sie,nho,sho,tN,lho,iho,aN,dho,cho,fho,ks,lie,mho,gho,nN,hho,pho,sN,_ho,uho,bho,Ss,iie,vho,Fho,lN,Tho,Mho,iN,Eho,Cho,who,Rs,die,Aho,Lho,dN,yho,xho,cN,$ho,kho,Sho,Ps,cie,Rho,Pho,fN,Bho,Iho,mN,Nho,qho,jho,Bs,fie,Dho,Gho,gN,Oho,Vho,hN,Xho,zho,Qho,Eh,mie,Who,Hho,pN,Uho,Jho,Yho,Ch,gie,Kho,Zho,_N,epo,opo,rpo,Is,hie,tpo,apo,uN,npo,spo,bN,lpo,ipo,dpo,Ns,pie,cpo,fpo,vN,mpo,gpo,FN,hpo,ppo,_po,qs,_ie,upo,bpo,TN,vpo,Fpo,MN,Tpo,Mpo,Epo,wh,uie,Cpo,wpo,EN,Apo,Lpo,ypo,Ah,bie,xpo,$po,CN,kpo,Spo,Rpo,Lh,vie,Ppo,Bpo,wN,Ipo,Npo,qpo,js,Fie,jpo,Dpo,AN,Gpo,Opo,LN,Vpo,Xpo,zpo,Ds,Tie,Qpo,Wpo,yN,Hpo,Upo,xN,Jpo,Ypo,Kpo,yh,Mie,Zpo,e_o,$N,o_o,r_o,t_o,xh,Eie,a_o,n_o,kN,s_o,l_o,i_o,$h,Cie,d_o,c_o,SN,f_o,m_o,g_o,Gs,wie,h_o,p_o,RN,__o,u_o,PN,b_o,v_o,F_o,kh,Aie,T_o,M_o,BN,E_o,C_o,w_o,Sh,Lie,A_o,L_o,IN,y_o,x_o,$_o,Os,yie,k_o,S_o,NN,R_o,P_o,qN,B_o,I_o,N_o,Vs,xie,q_o,j_o,jN,D_o,G_o,DN,O_o,V_o,X_o,Xs,$ie,z_o,Q_o,GN,W_o,H_o,ON,U_o,J_o,Y_o,zs,kie,K_o,Z_o,VN,euo,ouo,XN,ruo,tuo,auo,Rh,nuo,Ph,hL,suo,Sie,luo,WVe,Ni,Bh,Rie,pL,iuo,Pie,duo,HVe,Lo,_L,cuo,uL,fuo,zN,muo,guo,huo,bL,puo,Bie,_uo,uuo,buo,He,vL,vuo,Iie,Fuo,Tuo,Pa,Muo,Nie,Euo,Cuo,qie,wuo,Auo,jie,Luo,yuo,xuo,Y,Ih,Die,$uo,kuo,QN,Suo,Ruo,Puo,Nh,Gie,Buo,Iuo,WN,Nuo,quo,juo,qh,Oie,Duo,Guo,HN,Ouo,Vuo,Xuo,jh,Vie,zuo,Quo,UN,Wuo,Huo,Uuo,Dh,Xie,Juo,Yuo,JN,Kuo,Zuo,e1o,Gh,zie,o1o,r1o,YN,t1o,a1o,n1o,Oh,Qie,s1o,l1o,KN,i1o,d1o,c1o,Vh,Wie,f1o,m1o,ZN,g1o,h1o,p1o,Xh,Hie,_1o,u1o,eq,b1o,v1o,F1o,zh,Uie,T1o,M1o,oq,E1o,C1o,w1o,Qh,Jie,A1o,L1o,rq,y1o,x1o,$1o,Wh,Yie,k1o,S1o,tq,R1o,P1o,B1o,Hh,Kie,I1o,N1o,aq,q1o,j1o,D1o,Uh,Zie,G1o,O1o,nq,V1o,X1o,z1o,Jh,ede,Q1o,W1o,sq,H1o,U1o,J1o,Yh,ode,Y1o,K1o,lq,Z1o,e2o,o2o,Kh,rde,r2o,t2o,iq,a2o,n2o,s2o,Zh,tde,l2o,i2o,dq,d2o,c2o,f2o,ep,ade,m2o,g2o,cq,h2o,p2o,_2o,op,nde,u2o,b2o,fq,v2o,F2o,T2o,rp,sde,M2o,E2o,mq,C2o,w2o,A2o,tp,lde,L2o,y2o,gq,x2o,$2o,k2o,ap,ide,S2o,R2o,hq,P2o,B2o,I2o,np,dde,N2o,q2o,pq,j2o,D2o,G2o,sp,cde,O2o,V2o,_q,X2o,z2o,Q2o,lp,fde,W2o,H2o,uq,U2o,J2o,Y2o,ip,mde,K2o,Z2o,bq,ebo,obo,rbo,dp,gde,tbo,abo,vq,nbo,sbo,lbo,cp,hde,ibo,dbo,Fq,cbo,fbo,mbo,fp,pde,gbo,hbo,Tq,pbo,_bo,ubo,mp,_de,bbo,vbo,Mq,Fbo,Tbo,Mbo,gp,ude,Ebo,Cbo,Eq,wbo,Abo,Lbo,hp,bde,ybo,xbo,Cq,$bo,kbo,Sbo,pp,vde,Rbo,Pbo,wq,Bbo,Ibo,Nbo,_p,qbo,up,jbo,bp,FL,Dbo,Fde,Gbo,UVe,qi,vp,Tde,TL,Obo,Mde,Vbo,JVe,yo,ML,Xbo,EL,zbo,Aq,Qbo,Wbo,Hbo,CL,Ubo,Ede,Jbo,Ybo,Kbo,Ue,wL,Zbo,Cde,evo,ovo,ji,rvo,wde,tvo,avo,Ade,nvo,svo,lvo,he,Fp,Lde,ivo,dvo,Lq,cvo,fvo,mvo,Tp,yde,gvo,hvo,xde,pvo,_vo,uvo,Mp,$de,bvo,vvo,yq,Fvo,Tvo,Mvo,Ep,kde,Evo,Cvo,xq,wvo,Avo,Lvo,Cp,Sde,yvo,xvo,$q,$vo,kvo,Svo,wp,Rde,Rvo,Pvo,kq,Bvo,Ivo,Nvo,Ap,Pde,qvo,jvo,Sq,Dvo,Gvo,Ovo,Lp,Bde,Vvo,Xvo,Rq,zvo,Qvo,Wvo,yp,Ide,Hvo,Uvo,Pq,Jvo,Yvo,Kvo,xp,Nde,Zvo,eFo,Bq,oFo,rFo,tFo,$p,qde,aFo,nFo,Iq,sFo,lFo,iFo,kp,jde,dFo,cFo,Nq,fFo,mFo,gFo,Sp,Dde,hFo,pFo,qq,_Fo,uFo,bFo,Rp,Gde,vFo,FFo,jq,TFo,MFo,EFo,Pp,Ode,CFo,wFo,Dq,AFo,LFo,yFo,Bp,Vde,xFo,$Fo,Gq,kFo,SFo,RFo,Ip,Xde,PFo,BFo,Oq,IFo,NFo,qFo,Np,zde,jFo,DFo,Vq,GFo,OFo,VFo,qp,XFo,jp,zFo,Dp,AL,QFo,Qde,WFo,YVe,Di,Gp,Wde,LL,HFo,Hde,UFo,KVe,xo,yL,JFo,Gi,YFo,Xq,KFo,ZFo,zq,eTo,oTo,rTo,xL,tTo,Ude,aTo,nTo,sTo,lt,$L,lTo,Jde,iTo,dTo,Oi,cTo,Yde,fTo,mTo,Qq,gTo,hTo,pTo,Op,_To,Je,kL,uTo,Kde,bTo,vTo,Ba,FTo,Zde,TTo,MTo,ece,ETo,CTo,oce,wTo,ATo,LTo,y,Vp,rce,yTo,xTo,Wq,$To,kTo,STo,Xp,tce,RTo,PTo,Hq,BTo,ITo,NTo,zp,ace,qTo,jTo,Uq,DTo,GTo,OTo,Qp,nce,VTo,XTo,Jq,zTo,QTo,WTo,Wp,sce,HTo,UTo,Yq,JTo,YTo,KTo,Hp,lce,ZTo,e7o,Kq,o7o,r7o,t7o,Up,ice,a7o,n7o,Zq,s7o,l7o,i7o,Jp,dce,d7o,c7o,ej,f7o,m7o,g7o,Yp,cce,h7o,p7o,oj,_7o,u7o,b7o,Kp,fce,v7o,F7o,rj,T7o,M7o,E7o,Zp,mce,C7o,w7o,tj,A7o,L7o,y7o,e_,gce,x7o,$7o,aj,k7o,S7o,R7o,o_,hce,P7o,B7o,nj,I7o,N7o,q7o,r_,pce,j7o,D7o,sj,G7o,O7o,V7o,t_,_ce,X7o,z7o,lj,Q7o,W7o,H7o,a_,uce,U7o,J7o,ij,Y7o,K7o,Z7o,n_,bce,e8o,o8o,dj,r8o,t8o,a8o,s_,vce,n8o,s8o,cj,l8o,i8o,d8o,l_,Fce,c8o,f8o,fj,m8o,g8o,h8o,i_,Tce,p8o,_8o,mj,u8o,b8o,v8o,d_,Mce,F8o,T8o,gj,M8o,E8o,C8o,c_,Ece,w8o,A8o,hj,L8o,y8o,x8o,f_,Cce,$8o,k8o,pj,S8o,R8o,P8o,m_,wce,B8o,I8o,_j,N8o,q8o,j8o,g_,Ace,D8o,G8o,uj,O8o,V8o,X8o,h_,Lce,z8o,Q8o,bj,W8o,H8o,U8o,p_,yce,J8o,Y8o,vj,K8o,Z8o,eMo,__,xce,oMo,rMo,Fj,tMo,aMo,nMo,u_,$ce,sMo,lMo,Tj,iMo,dMo,cMo,b_,kce,fMo,mMo,Mj,gMo,hMo,pMo,v_,Sce,_Mo,uMo,Ej,bMo,vMo,FMo,F_,Rce,TMo,MMo,Cj,EMo,CMo,wMo,T_,Pce,AMo,LMo,wj,yMo,xMo,$Mo,M_,Bce,kMo,SMo,Aj,RMo,PMo,BMo,Qs,Ice,IMo,NMo,Lj,qMo,jMo,yj,DMo,GMo,OMo,E_,Nce,VMo,XMo,xj,zMo,QMo,WMo,C_,qce,HMo,UMo,$j,JMo,YMo,KMo,w_,jce,ZMo,e4o,kj,o4o,r4o,t4o,A_,Dce,a4o,n4o,Sj,s4o,l4o,i4o,L_,Gce,d4o,c4o,Rj,f4o,m4o,g4o,y_,Oce,h4o,p4o,Pj,_4o,u4o,b4o,x_,Vce,v4o,F4o,Bj,T4o,M4o,E4o,$_,Xce,C4o,w4o,Ij,A4o,L4o,y4o,k_,zce,x4o,$4o,Nj,k4o,S4o,R4o,S_,Qce,P4o,B4o,qj,I4o,N4o,q4o,R_,Wce,j4o,D4o,jj,G4o,O4o,V4o,P_,Hce,X4o,z4o,Dj,Q4o,W4o,H4o,B_,Uce,U4o,J4o,Gj,Y4o,K4o,Z4o,I_,Jce,eEo,oEo,Oj,rEo,tEo,aEo,N_,Yce,nEo,sEo,Vj,lEo,iEo,dEo,q_,Kce,cEo,fEo,Xj,mEo,gEo,hEo,j_,Zce,pEo,_Eo,zj,uEo,bEo,vEo,D_,efe,FEo,TEo,Qj,MEo,EEo,CEo,G_,ofe,wEo,AEo,Wj,LEo,yEo,xEo,O_,rfe,$Eo,kEo,Hj,SEo,REo,PEo,V_,tfe,BEo,IEo,Uj,NEo,qEo,jEo,X_,afe,DEo,GEo,Jj,OEo,VEo,XEo,z_,nfe,zEo,QEo,Yj,WEo,HEo,UEo,Q_,sfe,JEo,YEo,Kj,KEo,ZEo,eCo,W_,lfe,oCo,rCo,Zj,tCo,aCo,nCo,H_,ife,sCo,lCo,eD,iCo,dCo,cCo,U_,dfe,fCo,mCo,oD,gCo,hCo,pCo,J_,cfe,_Co,uCo,rD,bCo,vCo,FCo,Y_,ffe,TCo,MCo,tD,ECo,CCo,wCo,K_,mfe,ACo,LCo,aD,yCo,xCo,$Co,Z_,gfe,kCo,SCo,nD,RCo,PCo,BCo,eu,hfe,ICo,NCo,sD,qCo,jCo,DCo,ou,pfe,GCo,OCo,lD,VCo,XCo,zCo,ru,_fe,QCo,WCo,iD,HCo,UCo,JCo,tu,ufe,YCo,KCo,dD,ZCo,e3o,o3o,au,bfe,r3o,t3o,cD,a3o,n3o,s3o,nu,vfe,l3o,i3o,fD,d3o,c3o,f3o,su,Ffe,m3o,g3o,mD,h3o,p3o,_3o,lu,Tfe,u3o,b3o,gD,v3o,F3o,T3o,iu,Mfe,M3o,E3o,hD,C3o,w3o,A3o,du,Efe,L3o,y3o,pD,x3o,$3o,k3o,cu,Cfe,S3o,R3o,_D,P3o,B3o,I3o,fu,wfe,N3o,q3o,uD,j3o,D3o,G3o,mu,Afe,O3o,V3o,bD,X3o,z3o,Q3o,gu,Lfe,W3o,H3o,vD,U3o,J3o,Y3o,hu,yfe,K3o,Z3o,FD,e5o,o5o,r5o,pu,xfe,t5o,a5o,TD,n5o,s5o,l5o,_u,$fe,i5o,d5o,MD,c5o,f5o,m5o,uu,kfe,g5o,h5o,ED,p5o,_5o,u5o,bu,Sfe,b5o,v5o,CD,F5o,T5o,M5o,vu,Rfe,E5o,C5o,wD,w5o,A5o,L5o,Fu,Pfe,y5o,x5o,AD,$5o,k5o,S5o,Tu,Bfe,R5o,P5o,LD,B5o,I5o,N5o,Mu,Ife,q5o,j5o,yD,D5o,G5o,O5o,Eu,Nfe,V5o,X5o,xD,z5o,Q5o,W5o,Cu,qfe,H5o,U5o,$D,J5o,Y5o,K5o,wu,jfe,Z5o,e0o,kD,o0o,r0o,t0o,Au,Dfe,a0o,n0o,SD,s0o,l0o,i0o,Lu,Gfe,d0o,c0o,RD,f0o,m0o,g0o,yu,Ofe,h0o,p0o,PD,_0o,u0o,b0o,xu,Vfe,v0o,F0o,BD,T0o,M0o,E0o,$u,Xfe,C0o,w0o,ID,A0o,L0o,y0o,ku,zfe,x0o,$0o,ND,k0o,S0o,R0o,Su,Qfe,P0o,B0o,qD,I0o,N0o,q0o,Ru,Wfe,j0o,D0o,jD,G0o,O0o,V0o,Pu,Hfe,X0o,z0o,DD,Q0o,W0o,H0o,Bu,Ufe,U0o,J0o,GD,Y0o,K0o,Z0o,Iu,Jfe,ewo,owo,OD,rwo,two,awo,Nu,Yfe,nwo,swo,VD,lwo,iwo,dwo,qu,Kfe,cwo,fwo,XD,mwo,gwo,hwo,ju,Zfe,pwo,_wo,zD,uwo,bwo,vwo,Du,eme,Fwo,Two,QD,Mwo,Ewo,Cwo,Gu,ome,wwo,Awo,WD,Lwo,ywo,xwo,Ou,rme,$wo,kwo,HD,Swo,Rwo,Pwo,Vu,tme,Bwo,Iwo,UD,Nwo,qwo,jwo,Xu,ame,Dwo,Gwo,JD,Owo,Vwo,Xwo,zu,zwo,nme,Qwo,Wwo,sme,Hwo,Uwo,Qu,ZVe,Vi,Wu,lme,SL,Jwo,ime,Ywo,eXe,$o,RL,Kwo,Xi,Zwo,YD,eAo,oAo,KD,rAo,tAo,aAo,PL,nAo,dme,sAo,lAo,iAo,it,BL,dAo,cme,cAo,fAo,zi,mAo,fme,gAo,hAo,ZD,pAo,_Ao,uAo,Hu,bAo,Ye,IL,vAo,mme,FAo,TAo,Ia,MAo,gme,EAo,CAo,hme,wAo,AAo,pme,LAo,yAo,xAo,G,Uu,_me,$Ao,kAo,eG,SAo,RAo,PAo,Ju,ume,BAo,IAo,oG,NAo,qAo,jAo,Yu,bme,DAo,GAo,rG,OAo,VAo,XAo,Ku,vme,zAo,QAo,tG,WAo,HAo,UAo,Zu,Fme,JAo,YAo,aG,KAo,ZAo,e6o,e1,Tme,o6o,r6o,nG,t6o,a6o,n6o,o1,Mme,s6o,l6o,sG,i6o,d6o,c6o,r1,Eme,f6o,m6o,lG,g6o,h6o,p6o,t1,Cme,_6o,u6o,iG,b6o,v6o,F6o,a1,wme,T6o,M6o,dG,E6o,C6o,w6o,n1,Ame,A6o,L6o,cG,y6o,x6o,$6o,s1,Lme,k6o,S6o,fG,R6o,P6o,B6o,l1,yme,I6o,N6o,mG,q6o,j6o,D6o,i1,xme,G6o,O6o,gG,V6o,X6o,z6o,d1,$me,Q6o,W6o,hG,H6o,U6o,J6o,c1,kme,Y6o,K6o,pG,Z6o,eLo,oLo,f1,Sme,rLo,tLo,_G,aLo,nLo,sLo,m1,Rme,lLo,iLo,uG,dLo,cLo,fLo,g1,Pme,mLo,gLo,bG,hLo,pLo,_Lo,h1,Bme,uLo,bLo,vG,vLo,FLo,TLo,p1,Ime,MLo,ELo,FG,CLo,wLo,ALo,_1,Nme,LLo,yLo,TG,xLo,$Lo,kLo,u1,qme,SLo,RLo,MG,PLo,BLo,ILo,b1,jme,NLo,qLo,EG,jLo,DLo,GLo,v1,Dme,OLo,VLo,CG,XLo,zLo,QLo,F1,Gme,WLo,HLo,wG,ULo,JLo,YLo,T1,Ome,KLo,ZLo,AG,eyo,oyo,ryo,M1,Vme,tyo,ayo,LG,nyo,syo,lyo,E1,Xme,iyo,dyo,yG,cyo,fyo,myo,C1,zme,gyo,hyo,xG,pyo,_yo,uyo,w1,Qme,byo,vyo,$G,Fyo,Tyo,Myo,A1,Wme,Eyo,Cyo,kG,wyo,Ayo,Lyo,L1,Hme,yyo,xyo,SG,$yo,kyo,Syo,y1,Ume,Ryo,Pyo,RG,Byo,Iyo,Nyo,x1,Jme,qyo,jyo,PG,Dyo,Gyo,Oyo,$1,Yme,Vyo,Xyo,BG,zyo,Qyo,Wyo,k1,Kme,Hyo,Uyo,IG,Jyo,Yyo,Kyo,S1,Zme,Zyo,e9o,NG,o9o,r9o,t9o,R1,ege,a9o,n9o,qG,s9o,l9o,i9o,P1,oge,d9o,c9o,jG,f9o,m9o,g9o,B1,rge,h9o,p9o,DG,_9o,u9o,b9o,I1,tge,v9o,F9o,GG,T9o,M9o,E9o,N1,age,C9o,w9o,OG,A9o,L9o,y9o,q1,nge,x9o,$9o,VG,k9o,S9o,R9o,j1,sge,P9o,B9o,XG,I9o,N9o,q9o,D1,j9o,lge,D9o,G9o,ige,O9o,V9o,G1,oXe,Qi,O1,dge,NL,X9o,cge,z9o,rXe,ko,qL,Q9o,Wi,W9o,zG,H9o,U9o,QG,J9o,Y9o,K9o,jL,Z9o,fge,exo,oxo,rxo,dt,DL,txo,mge,axo,nxo,Hi,sxo,gge,lxo,ixo,WG,dxo,cxo,fxo,V1,mxo,Ke,GL,gxo,hge,hxo,pxo,Na,_xo,pge,uxo,bxo,_ge,vxo,Fxo,uge,Txo,Mxo,Exo,z,X1,bge,Cxo,wxo,HG,Axo,Lxo,yxo,z1,vge,xxo,$xo,UG,kxo,Sxo,Rxo,Q1,Fge,Pxo,Bxo,JG,Ixo,Nxo,qxo,W1,Tge,jxo,Dxo,YG,Gxo,Oxo,Vxo,H1,Mge,Xxo,zxo,KG,Qxo,Wxo,Hxo,U1,Ege,Uxo,Jxo,ZG,Yxo,Kxo,Zxo,J1,Cge,e$o,o$o,eO,r$o,t$o,a$o,Y1,wge,n$o,s$o,oO,l$o,i$o,d$o,K1,Age,c$o,f$o,rO,m$o,g$o,h$o,Z1,Lge,p$o,_$o,tO,u$o,b$o,v$o,e2,yge,F$o,T$o,aO,M$o,E$o,C$o,o2,xge,w$o,A$o,nO,L$o,y$o,x$o,r2,$ge,$$o,k$o,sO,S$o,R$o,P$o,t2,kge,B$o,I$o,lO,N$o,q$o,j$o,a2,Sge,D$o,G$o,iO,O$o,V$o,X$o,n2,Rge,z$o,Q$o,dO,W$o,H$o,U$o,s2,Pge,J$o,Y$o,cO,K$o,Z$o,eko,l2,Bge,oko,rko,fO,tko,ako,nko,i2,Ige,sko,lko,mO,iko,dko,cko,d2,Nge,fko,mko,gO,gko,hko,pko,c2,qge,_ko,uko,hO,bko,vko,Fko,f2,jge,Tko,Mko,pO,Eko,Cko,wko,m2,Dge,Ako,Lko,_O,yko,xko,$ko,g2,Gge,kko,Sko,uO,Rko,Pko,Bko,h2,Oge,Iko,Nko,bO,qko,jko,Dko,p2,Vge,Gko,Oko,vO,Vko,Xko,zko,_2,Xge,Qko,Wko,FO,Hko,Uko,Jko,u2,zge,Yko,Kko,TO,Zko,eSo,oSo,b2,Qge,rSo,tSo,MO,aSo,nSo,sSo,v2,Wge,lSo,iSo,EO,dSo,cSo,fSo,F2,Hge,mSo,gSo,CO,hSo,pSo,_So,T2,Uge,uSo,bSo,wO,vSo,FSo,TSo,M2,Jge,MSo,ESo,AO,CSo,wSo,ASo,E2,Yge,LSo,ySo,LO,xSo,$So,kSo,C2,Kge,SSo,RSo,yO,PSo,BSo,ISo,w2,Zge,NSo,qSo,xO,jSo,DSo,GSo,A2,ehe,OSo,VSo,$O,XSo,zSo,QSo,L2,ohe,WSo,HSo,kO,USo,JSo,YSo,y2,rhe,KSo,ZSo,SO,eRo,oRo,rRo,x2,the,tRo,aRo,RO,nRo,sRo,lRo,$2,iRo,ahe,dRo,cRo,nhe,fRo,mRo,k2,tXe,Ui,S2,she,OL,gRo,lhe,hRo,aXe,So,VL,pRo,Ji,_Ro,PO,uRo,bRo,BO,vRo,FRo,TRo,XL,MRo,ihe,ERo,CRo,wRo,ct,zL,ARo,dhe,LRo,yRo,Yi,xRo,che,$Ro,kRo,IO,SRo,RRo,PRo,R2,BRo,Ze,QL,IRo,fhe,NRo,qRo,qa,jRo,mhe,DRo,GRo,ghe,ORo,VRo,hhe,XRo,zRo,QRo,W,P2,phe,WRo,HRo,NO,URo,JRo,YRo,B2,_he,KRo,ZRo,qO,ePo,oPo,rPo,I2,uhe,tPo,aPo,jO,nPo,sPo,lPo,N2,bhe,iPo,dPo,DO,cPo,fPo,mPo,q2,vhe,gPo,hPo,GO,pPo,_Po,uPo,j2,Fhe,bPo,vPo,OO,FPo,TPo,MPo,D2,The,EPo,CPo,VO,wPo,APo,LPo,G2,Mhe,yPo,xPo,XO,$Po,kPo,SPo,O2,Ehe,RPo,PPo,zO,BPo,IPo,NPo,V2,Che,qPo,jPo,QO,DPo,GPo,OPo,X2,whe,VPo,XPo,WO,zPo,QPo,WPo,z2,Ahe,HPo,UPo,HO,JPo,YPo,KPo,Q2,Lhe,ZPo,eBo,UO,oBo,rBo,tBo,W2,yhe,aBo,nBo,JO,sBo,lBo,iBo,H2,xhe,dBo,cBo,YO,fBo,mBo,gBo,U2,$he,hBo,pBo,KO,_Bo,uBo,bBo,J2,khe,vBo,FBo,ZO,TBo,MBo,EBo,Y2,She,CBo,wBo,eV,ABo,LBo,yBo,K2,Rhe,xBo,$Bo,oV,kBo,SBo,RBo,Z2,Phe,PBo,BBo,rV,IBo,NBo,qBo,eb,Bhe,jBo,DBo,tV,GBo,OBo,VBo,ob,Ihe,XBo,zBo,aV,QBo,WBo,HBo,rb,Nhe,UBo,JBo,nV,YBo,KBo,ZBo,tb,qhe,eIo,oIo,sV,rIo,tIo,aIo,ab,jhe,nIo,sIo,lV,lIo,iIo,dIo,nb,Dhe,cIo,fIo,iV,mIo,gIo,hIo,sb,Ghe,pIo,_Io,dV,uIo,bIo,vIo,lb,Ohe,FIo,TIo,cV,MIo,EIo,CIo,ib,Vhe,wIo,AIo,fV,LIo,yIo,xIo,db,Xhe,$Io,kIo,mV,SIo,RIo,PIo,cb,zhe,BIo,IIo,gV,NIo,qIo,jIo,fb,Qhe,DIo,GIo,hV,OIo,VIo,XIo,mb,Whe,zIo,QIo,pV,WIo,HIo,UIo,gb,Hhe,JIo,YIo,Uhe,KIo,ZIo,eNo,hb,Jhe,oNo,rNo,_V,tNo,aNo,nNo,pb,Yhe,sNo,lNo,uV,iNo,dNo,cNo,_b,Khe,fNo,mNo,bV,gNo,hNo,pNo,ub,Zhe,_No,uNo,vV,bNo,vNo,FNo,bb,TNo,epe,MNo,ENo,ope,CNo,wNo,vb,nXe,Ki,Fb,rpe,WL,ANo,tpe,LNo,sXe,Ro,HL,yNo,Zi,xNo,FV,$No,kNo,TV,SNo,RNo,PNo,UL,BNo,ape,INo,NNo,qNo,ft,JL,jNo,npe,DNo,GNo,ed,ONo,spe,VNo,XNo,MV,zNo,QNo,WNo,Tb,HNo,eo,YL,UNo,lpe,JNo,YNo,ja,KNo,ipe,ZNo,eqo,dpe,oqo,rqo,cpe,tqo,aqo,nqo,pe,Mb,fpe,sqo,lqo,EV,iqo,dqo,cqo,Eb,mpe,fqo,mqo,CV,gqo,hqo,pqo,Cb,gpe,_qo,uqo,wV,bqo,vqo,Fqo,wb,hpe,Tqo,Mqo,AV,Eqo,Cqo,wqo,Ab,ppe,Aqo,Lqo,LV,yqo,xqo,$qo,Lb,_pe,kqo,Sqo,yV,Rqo,Pqo,Bqo,yb,upe,Iqo,Nqo,xV,qqo,jqo,Dqo,xb,bpe,Gqo,Oqo,$V,Vqo,Xqo,zqo,$b,vpe,Qqo,Wqo,kV,Hqo,Uqo,Jqo,kb,Fpe,Yqo,Kqo,SV,Zqo,ejo,ojo,Sb,Tpe,rjo,tjo,RV,ajo,njo,sjo,Rb,Mpe,ljo,ijo,PV,djo,cjo,fjo,Pb,Epe,mjo,gjo,BV,hjo,pjo,_jo,Bb,Cpe,ujo,bjo,IV,vjo,Fjo,Tjo,Ib,wpe,Mjo,Ejo,NV,Cjo,wjo,Ajo,Nb,Ape,Ljo,yjo,qV,xjo,$jo,kjo,qb,Lpe,Sjo,Rjo,jV,Pjo,Bjo,Ijo,jb,ype,Njo,qjo,DV,jjo,Djo,Gjo,Db,Ojo,xpe,Vjo,Xjo,$pe,zjo,Qjo,Gb,lXe,od,Ob,kpe,KL,Wjo,Spe,Hjo,iXe,Po,ZL,Ujo,rd,Jjo,GV,Yjo,Kjo,OV,Zjo,eDo,oDo,ey,rDo,Rpe,tDo,aDo,nDo,mt,oy,sDo,Ppe,lDo,iDo,td,dDo,Bpe,cDo,fDo,VV,mDo,gDo,hDo,Vb,pDo,oo,ry,_Do,Ipe,uDo,bDo,Da,vDo,Npe,FDo,TDo,qpe,MDo,EDo,jpe,CDo,wDo,ADo,N,Xb,Dpe,LDo,yDo,XV,xDo,$Do,kDo,zb,Gpe,SDo,RDo,zV,PDo,BDo,IDo,Qb,Ope,NDo,qDo,QV,jDo,DDo,GDo,Wb,Vpe,ODo,VDo,WV,XDo,zDo,QDo,Hb,Xpe,WDo,HDo,HV,UDo,JDo,YDo,Ub,zpe,KDo,ZDo,UV,eGo,oGo,rGo,Jb,Qpe,tGo,aGo,JV,nGo,sGo,lGo,Yb,Wpe,iGo,dGo,YV,cGo,fGo,mGo,Kb,Hpe,gGo,hGo,KV,pGo,_Go,uGo,Zb,Upe,bGo,vGo,ZV,FGo,TGo,MGo,ev,Jpe,EGo,CGo,eX,wGo,AGo,LGo,ov,Ype,yGo,xGo,oX,$Go,kGo,SGo,rv,Kpe,RGo,PGo,rX,BGo,IGo,NGo,tv,Zpe,qGo,jGo,tX,DGo,GGo,OGo,av,e_e,VGo,XGo,aX,zGo,QGo,WGo,nv,o_e,HGo,UGo,nX,JGo,YGo,KGo,sv,r_e,ZGo,eOo,sX,oOo,rOo,tOo,lv,t_e,aOo,nOo,lX,sOo,lOo,iOo,iv,a_e,dOo,cOo,iX,fOo,mOo,gOo,dv,n_e,hOo,pOo,dX,_Oo,uOo,bOo,cv,s_e,vOo,FOo,cX,TOo,MOo,EOo,fv,l_e,COo,wOo,fX,AOo,LOo,yOo,mv,i_e,xOo,$Oo,mX,kOo,SOo,ROo,gv,d_e,POo,BOo,gX,IOo,NOo,qOo,hv,c_e,jOo,DOo,hX,GOo,OOo,VOo,pv,f_e,XOo,zOo,pX,QOo,WOo,HOo,_v,m_e,UOo,JOo,_X,YOo,KOo,ZOo,uv,g_e,eVo,oVo,uX,rVo,tVo,aVo,bv,h_e,nVo,sVo,bX,lVo,iVo,dVo,vv,p_e,cVo,fVo,vX,mVo,gVo,hVo,Fv,__e,pVo,_Vo,FX,uVo,bVo,vVo,Tv,u_e,FVo,TVo,TX,MVo,EVo,CVo,Mv,b_e,wVo,AVo,MX,LVo,yVo,xVo,Ev,v_e,$Vo,kVo,EX,SVo,RVo,PVo,Cv,F_e,BVo,IVo,CX,NVo,qVo,jVo,wv,T_e,DVo,GVo,wX,OVo,VVo,XVo,Av,M_e,zVo,QVo,AX,WVo,HVo,UVo,Lv,E_e,JVo,YVo,LX,KVo,ZVo,eXo,yv,C_e,oXo,rXo,yX,tXo,aXo,nXo,xv,w_e,sXo,lXo,xX,iXo,dXo,cXo,$v,A_e,fXo,mXo,$X,gXo,hXo,pXo,kv,L_e,_Xo,uXo,kX,bXo,vXo,FXo,Sv,y_e,TXo,MXo,SX,EXo,CXo,wXo,Rv,x_e,AXo,LXo,RX,yXo,xXo,$Xo,Pv,$_e,kXo,SXo,PX,RXo,PXo,BXo,Bv,k_e,IXo,NXo,BX,qXo,jXo,DXo,Iv,S_e,GXo,OXo,IX,VXo,XXo,zXo,Nv,R_e,QXo,WXo,NX,HXo,UXo,JXo,qv,P_e,YXo,KXo,qX,ZXo,ezo,ozo,jv,B_e,rzo,tzo,jX,azo,nzo,szo,Dv,lzo,I_e,izo,dzo,N_e,czo,fzo,Gv,dXe,ad,Ov,q_e,ty,mzo,j_e,gzo,cXe,Bo,ay,hzo,nd,pzo,DX,_zo,uzo,GX,bzo,vzo,Fzo,ny,Tzo,D_e,Mzo,Ezo,Czo,gt,sy,wzo,G_e,Azo,Lzo,sd,yzo,O_e,xzo,$zo,OX,kzo,Szo,Rzo,Vv,Pzo,ro,ly,Bzo,V_e,Izo,Nzo,Ga,qzo,X_e,jzo,Dzo,z_e,Gzo,Ozo,Q_e,Vzo,Xzo,zzo,Z,Xv,W_e,Qzo,Wzo,VX,Hzo,Uzo,Jzo,zv,H_e,Yzo,Kzo,XX,Zzo,eQo,oQo,Qv,U_e,rQo,tQo,zX,aQo,nQo,sQo,Wv,J_e,lQo,iQo,QX,dQo,cQo,fQo,Hv,Y_e,mQo,gQo,WX,hQo,pQo,_Qo,Uv,K_e,uQo,bQo,HX,vQo,FQo,TQo,Jv,Z_e,MQo,EQo,UX,CQo,wQo,AQo,Yv,eue,LQo,yQo,JX,xQo,$Qo,kQo,Kv,oue,SQo,RQo,YX,PQo,BQo,IQo,Zv,rue,NQo,qQo,KX,jQo,DQo,GQo,eF,tue,OQo,VQo,ZX,XQo,zQo,QQo,oF,aue,WQo,HQo,ez,UQo,JQo,YQo,rF,nue,KQo,ZQo,oz,eWo,oWo,rWo,tF,sue,tWo,aWo,rz,nWo,sWo,lWo,aF,lue,iWo,dWo,tz,cWo,fWo,mWo,nF,iue,gWo,hWo,az,pWo,_Wo,uWo,sF,due,bWo,vWo,nz,FWo,TWo,MWo,lF,cue,EWo,CWo,sz,wWo,AWo,LWo,iF,fue,yWo,xWo,lz,$Wo,kWo,SWo,dF,mue,RWo,PWo,iz,BWo,IWo,NWo,cF,gue,qWo,jWo,dz,DWo,GWo,OWo,fF,hue,VWo,XWo,cz,zWo,QWo,WWo,mF,pue,HWo,UWo,fz,JWo,YWo,KWo,gF,_ue,ZWo,eHo,mz,oHo,rHo,tHo,hF,uue,aHo,nHo,gz,sHo,lHo,iHo,pF,bue,dHo,cHo,hz,fHo,mHo,gHo,_F,vue,hHo,pHo,pz,_Ho,uHo,bHo,uF,Fue,vHo,FHo,_z,THo,MHo,EHo,bF,Tue,CHo,wHo,uz,AHo,LHo,yHo,vF,Mue,xHo,$Ho,bz,kHo,SHo,RHo,FF,PHo,Eue,BHo,IHo,Cue,NHo,qHo,TF,fXe,ld,MF,wue,iy,jHo,Aue,DHo,mXe,Io,dy,GHo,id,OHo,vz,VHo,XHo,Fz,zHo,QHo,WHo,cy,HHo,Lue,UHo,JHo,YHo,ht,fy,KHo,yue,ZHo,eUo,dd,oUo,xue,rUo,tUo,Tz,aUo,nUo,sUo,EF,lUo,to,my,iUo,$ue,dUo,cUo,Oa,fUo,kue,mUo,gUo,Sue,hUo,pUo,Rue,_Uo,uUo,bUo,No,CF,Pue,vUo,FUo,Mz,TUo,MUo,EUo,wF,Bue,CUo,wUo,Ez,AUo,LUo,yUo,AF,Iue,xUo,$Uo,Cz,kUo,SUo,RUo,LF,Nue,PUo,BUo,wz,IUo,NUo,qUo,yF,que,jUo,DUo,Az,GUo,OUo,VUo,xF,jue,XUo,zUo,Lz,QUo,WUo,HUo,$F,UUo,Due,JUo,YUo,Gue,KUo,ZUo,kF,gXe,cd,SF,Oue,gy,eJo,Vue,oJo,hXe,qo,hy,rJo,fd,tJo,yz,aJo,nJo,xz,sJo,lJo,iJo,py,dJo,Xue,cJo,fJo,mJo,pt,_y,gJo,zue,hJo,pJo,md,_Jo,Que,uJo,bJo,$z,vJo,FJo,TJo,RF,MJo,ao,uy,EJo,Wue,CJo,wJo,Va,AJo,Hue,LJo,yJo,Uue,xJo,$Jo,Jue,kJo,SJo,RJo,U,PF,Yue,PJo,BJo,kz,IJo,NJo,qJo,BF,Kue,jJo,DJo,Sz,GJo,OJo,VJo,IF,Zue,XJo,zJo,Rz,QJo,WJo,HJo,NF,e1e,UJo,JJo,Pz,YJo,KJo,ZJo,qF,o1e,eYo,oYo,Bz,rYo,tYo,aYo,jF,r1e,nYo,sYo,Iz,lYo,iYo,dYo,DF,t1e,cYo,fYo,Nz,mYo,gYo,hYo,GF,a1e,pYo,_Yo,qz,uYo,bYo,vYo,OF,n1e,FYo,TYo,jz,MYo,EYo,CYo,VF,s1e,wYo,AYo,Dz,LYo,yYo,xYo,XF,l1e,$Yo,kYo,Gz,SYo,RYo,PYo,zF,i1e,BYo,IYo,Oz,NYo,qYo,jYo,QF,d1e,DYo,GYo,Vz,OYo,VYo,XYo,WF,c1e,zYo,QYo,Xz,WYo,HYo,UYo,HF,f1e,JYo,YYo,zz,KYo,ZYo,eKo,UF,m1e,oKo,rKo,Qz,tKo,aKo,nKo,JF,g1e,sKo,lKo,Wz,iKo,dKo,cKo,YF,h1e,fKo,mKo,Hz,gKo,hKo,pKo,KF,p1e,_Ko,uKo,Uz,bKo,vKo,FKo,ZF,_1e,TKo,MKo,Jz,EKo,CKo,wKo,eT,u1e,AKo,LKo,Yz,yKo,xKo,$Ko,oT,b1e,kKo,SKo,Kz,RKo,PKo,BKo,rT,v1e,IKo,NKo,Zz,qKo,jKo,DKo,tT,F1e,GKo,OKo,eQ,VKo,XKo,zKo,aT,T1e,QKo,WKo,oQ,HKo,UKo,JKo,nT,M1e,YKo,KKo,rQ,ZKo,eZo,oZo,sT,E1e,rZo,tZo,tQ,aZo,nZo,sZo,lT,C1e,lZo,iZo,aQ,dZo,cZo,fZo,iT,w1e,mZo,gZo,nQ,hZo,pZo,_Zo,dT,A1e,uZo,bZo,sQ,vZo,FZo,TZo,cT,L1e,MZo,EZo,lQ,CZo,wZo,AZo,fT,y1e,LZo,yZo,iQ,xZo,$Zo,kZo,mT,x1e,SZo,RZo,dQ,PZo,BZo,IZo,gT,$1e,NZo,qZo,cQ,jZo,DZo,GZo,hT,k1e,OZo,VZo,fQ,XZo,zZo,QZo,pT,S1e,WZo,HZo,mQ,UZo,JZo,YZo,_T,KZo,R1e,ZZo,eer,P1e,oer,rer,uT,pXe,gd,bT,B1e,by,ter,I1e,aer,_Xe,jo,vy,ner,hd,ser,gQ,ler,ier,hQ,der,cer,fer,Fy,mer,N1e,ger,her,per,_t,Ty,_er,q1e,uer,ber,pd,ver,j1e,Fer,Ter,pQ,Mer,Eer,Cer,vT,wer,no,My,Aer,D1e,Ler,yer,Xa,xer,G1e,$er,ker,O1e,Ser,Rer,V1e,Per,Ber,Ier,V,FT,X1e,Ner,qer,_Q,jer,Der,Ger,TT,z1e,Oer,Ver,uQ,Xer,zer,Qer,MT,Q1e,Wer,Her,bQ,Uer,Jer,Yer,ET,W1e,Ker,Zer,vQ,eor,oor,ror,CT,H1e,tor,aor,FQ,nor,sor,lor,wT,U1e,ior,dor,TQ,cor,mor,gor,AT,J1e,hor,por,MQ,_or,uor,bor,LT,Y1e,vor,For,EQ,Tor,Mor,Eor,yT,K1e,Cor,wor,CQ,Aor,Lor,yor,xT,Z1e,xor,$or,wQ,kor,Sor,Ror,$T,e2e,Por,Bor,AQ,Ior,Nor,qor,kT,o2e,jor,Dor,LQ,Gor,Oor,Vor,ST,r2e,Xor,zor,yQ,Qor,Wor,Hor,RT,t2e,Uor,Jor,xQ,Yor,Kor,Zor,PT,a2e,err,orr,$Q,rrr,trr,arr,BT,n2e,nrr,srr,kQ,lrr,irr,drr,IT,s2e,crr,frr,SQ,mrr,grr,hrr,NT,l2e,prr,_rr,RQ,urr,brr,vrr,qT,i2e,Frr,Trr,PQ,Mrr,Err,Crr,jT,d2e,wrr,Arr,BQ,Lrr,yrr,xrr,DT,c2e,$rr,krr,IQ,Srr,Rrr,Prr,GT,f2e,Brr,Irr,NQ,Nrr,qrr,jrr,OT,m2e,Drr,Grr,qQ,Orr,Vrr,Xrr,VT,g2e,zrr,Qrr,jQ,Wrr,Hrr,Urr,XT,h2e,Jrr,Yrr,DQ,Krr,Zrr,etr,zT,p2e,otr,rtr,GQ,ttr,atr,ntr,QT,_2e,str,ltr,OQ,itr,dtr,ctr,WT,u2e,ftr,mtr,VQ,gtr,htr,ptr,HT,b2e,_tr,utr,XQ,btr,vtr,Ftr,UT,v2e,Ttr,Mtr,zQ,Etr,Ctr,wtr,JT,F2e,Atr,Ltr,QQ,ytr,xtr,$tr,YT,T2e,ktr,Str,WQ,Rtr,Ptr,Btr,KT,M2e,Itr,Ntr,HQ,qtr,jtr,Dtr,ZT,E2e,Gtr,Otr,UQ,Vtr,Xtr,ztr,e7,C2e,Qtr,Wtr,JQ,Htr,Utr,Jtr,o7,w2e,Ytr,Ktr,YQ,Ztr,ear,oar,r7,A2e,rar,tar,KQ,aar,nar,sar,t7,L2e,lar,iar,ZQ,dar,car,far,a7,y2e,mar,gar,eW,har,par,_ar,n7,x2e,uar,bar,oW,Far,Tar,Mar,s7,$2e,Ear,Car,rW,war,Aar,Lar,l7,k2e,yar,xar,tW,$ar,kar,Sar,i7,Rar,S2e,Par,Bar,R2e,Iar,Nar,d7,uXe,_d,c7,P2e,Ey,qar,B2e,jar,bXe,Do,Cy,Dar,ud,Gar,aW,Oar,Var,nW,Xar,zar,Qar,wy,War,I2e,Har,Uar,Jar,ut,Ay,Yar,N2e,Kar,Zar,bd,enr,q2e,onr,rnr,sW,tnr,anr,nnr,f7,snr,so,Ly,lnr,j2e,inr,dnr,za,cnr,D2e,fnr,mnr,G2e,gnr,hnr,O2e,pnr,_nr,unr,V2e,m7,X2e,bnr,vnr,lW,Fnr,Tnr,Mnr,g7,Enr,z2e,Cnr,wnr,Q2e,Anr,Lnr,h7,vXe,vd,p7,W2e,yy,ynr,H2e,xnr,FXe,Go,xy,$nr,Fd,knr,iW,Snr,Rnr,dW,Pnr,Bnr,Inr,$y,Nnr,U2e,qnr,jnr,Dnr,bt,ky,Gnr,J2e,Onr,Vnr,Td,Xnr,Y2e,znr,Qnr,cW,Wnr,Hnr,Unr,_7,Jnr,lo,Sy,Ynr,K2e,Knr,Znr,Qa,esr,Z2e,osr,rsr,ebe,tsr,asr,obe,nsr,ssr,lsr,ve,u7,rbe,isr,dsr,fW,csr,fsr,msr,b7,tbe,gsr,hsr,mW,psr,_sr,usr,v7,abe,bsr,vsr,gW,Fsr,Tsr,Msr,F7,nbe,Esr,Csr,hW,wsr,Asr,Lsr,Ws,sbe,ysr,xsr,pW,$sr,ksr,_W,Ssr,Rsr,Psr,T7,lbe,Bsr,Isr,uW,Nsr,qsr,jsr,Hs,ibe,Dsr,Gsr,bW,Osr,Vsr,vW,Xsr,zsr,Qsr,M7,dbe,Wsr,Hsr,FW,Usr,Jsr,Ysr,vt,cbe,Ksr,Zsr,TW,elr,olr,MW,rlr,tlr,EW,alr,nlr,slr,E7,fbe,llr,ilr,CW,dlr,clr,flr,C7,mbe,mlr,glr,wW,hlr,plr,_lr,w7,gbe,ulr,blr,AW,vlr,Flr,Tlr,A7,hbe,Mlr,Elr,LW,Clr,wlr,Alr,L7,pbe,Llr,ylr,yW,xlr,$lr,klr,y7,_be,Slr,Rlr,xW,Plr,Blr,Ilr,x7,ube,Nlr,qlr,$W,jlr,Dlr,Glr,$7,Olr,bbe,Vlr,Xlr,vbe,zlr,Qlr,k7,TXe,Md,S7,Fbe,Ry,Wlr,Tbe,Hlr,MXe,Oo,Py,Ulr,Ed,Jlr,kW,Ylr,Klr,SW,Zlr,eir,oir,By,rir,Mbe,tir,air,nir,Ft,Iy,sir,Ebe,lir,iir,Cd,dir,Cbe,cir,fir,RW,mir,gir,hir,R7,pir,io,Ny,_ir,wbe,uir,bir,Wa,vir,Abe,Fir,Tir,Lbe,Mir,Eir,ybe,Cir,wir,Air,xbe,P7,$be,Lir,yir,PW,xir,$ir,kir,B7,Sir,kbe,Rir,Pir,Sbe,Bir,Iir,I7,EXe,wd,N7,Rbe,qy,Nir,Pbe,qir,CXe,Vo,jy,jir,Ad,Dir,BW,Gir,Oir,IW,Vir,Xir,zir,Dy,Qir,Bbe,Wir,Hir,Uir,Tt,Gy,Jir,Ibe,Yir,Kir,Ld,Zir,Nbe,edr,odr,NW,rdr,tdr,adr,q7,ndr,co,Oy,sdr,qbe,ldr,idr,Ha,ddr,jbe,cdr,fdr,Dbe,mdr,gdr,Gbe,hdr,pdr,_dr,Obe,j7,Vbe,udr,bdr,qW,vdr,Fdr,Tdr,D7,Mdr,Xbe,Edr,Cdr,zbe,wdr,Adr,G7,wXe,yd,O7,Qbe,Vy,Ldr,Wbe,ydr,AXe,Xo,Xy,xdr,xd,$dr,jW,kdr,Sdr,DW,Rdr,Pdr,Bdr,zy,Idr,Hbe,Ndr,qdr,jdr,Mt,Qy,Ddr,Ube,Gdr,Odr,$d,Vdr,Jbe,Xdr,zdr,GW,Qdr,Wdr,Hdr,V7,Udr,fo,Wy,Jdr,Ybe,Ydr,Kdr,Ua,Zdr,Kbe,ecr,ocr,Zbe,rcr,tcr,eve,acr,ncr,scr,Pe,X7,ove,lcr,icr,OW,dcr,ccr,fcr,z7,rve,mcr,gcr,VW,hcr,pcr,_cr,Q7,tve,ucr,bcr,XW,vcr,Fcr,Tcr,W7,ave,Mcr,Ecr,zW,Ccr,wcr,Acr,H7,nve,Lcr,ycr,QW,xcr,$cr,kcr,U7,sve,Scr,Rcr,WW,Pcr,Bcr,Icr,J7,lve,Ncr,qcr,HW,jcr,Dcr,Gcr,Y7,ive,Ocr,Vcr,UW,Xcr,zcr,Qcr,K7,dve,Wcr,Hcr,JW,Ucr,Jcr,Ycr,Z7,Kcr,cve,Zcr,efr,fve,ofr,rfr,e8,LXe,kd,o8,mve,Hy,tfr,gve,afr,yXe,zo,Uy,nfr,Sd,sfr,YW,lfr,ifr,KW,dfr,cfr,ffr,Jy,mfr,hve,gfr,hfr,pfr,Et,Yy,_fr,pve,ufr,bfr,Rd,vfr,_ve,Ffr,Tfr,ZW,Mfr,Efr,Cfr,r8,wfr,mo,Ky,Afr,uve,Lfr,yfr,Ja,xfr,bve,$fr,kfr,vve,Sfr,Rfr,Fve,Pfr,Bfr,Ifr,et,t8,Tve,Nfr,qfr,eH,jfr,Dfr,Gfr,a8,Mve,Ofr,Vfr,oH,Xfr,zfr,Qfr,n8,Eve,Wfr,Hfr,rH,Ufr,Jfr,Yfr,s8,Cve,Kfr,Zfr,tH,emr,omr,rmr,l8,wve,tmr,amr,aH,nmr,smr,lmr,i8,imr,Ave,dmr,cmr,Lve,fmr,mmr,d8,xXe,Pd,c8,yve,Zy,gmr,xve,hmr,$Xe,Qo,e9,pmr,Bd,_mr,nH,umr,bmr,sH,vmr,Fmr,Tmr,o9,Mmr,$ve,Emr,Cmr,wmr,Ct,r9,Amr,kve,Lmr,ymr,Id,xmr,Sve,$mr,kmr,lH,Smr,Rmr,Pmr,f8,Bmr,go,t9,Imr,Rve,Nmr,qmr,Ya,jmr,Pve,Dmr,Gmr,Bve,Omr,Vmr,Ive,Xmr,zmr,Qmr,Le,m8,Nve,Wmr,Hmr,iH,Umr,Jmr,Ymr,g8,qve,Kmr,Zmr,dH,egr,ogr,rgr,h8,jve,tgr,agr,cH,ngr,sgr,lgr,p8,Dve,igr,dgr,fH,cgr,fgr,mgr,_8,Gve,ggr,hgr,mH,pgr,_gr,ugr,u8,Ove,bgr,vgr,gH,Fgr,Tgr,Mgr,b8,Vve,Egr,Cgr,hH,wgr,Agr,Lgr,v8,Xve,ygr,xgr,pH,$gr,kgr,Sgr,F8,zve,Rgr,Pgr,_H,Bgr,Igr,Ngr,T8,Qve,qgr,jgr,uH,Dgr,Ggr,Ogr,M8,Vgr,Wve,Xgr,zgr,Hve,Qgr,Wgr,E8,kXe,Nd,C8,Uve,a9,Hgr,Jve,Ugr,SXe,Wo,n9,Jgr,qd,Ygr,bH,Kgr,Zgr,vH,ehr,ohr,rhr,s9,thr,Yve,ahr,nhr,shr,wt,l9,lhr,Kve,ihr,dhr,jd,chr,Zve,fhr,mhr,FH,ghr,hhr,phr,w8,_hr,ho,i9,uhr,eFe,bhr,vhr,Ka,Fhr,oFe,Thr,Mhr,rFe,Ehr,Chr,tFe,whr,Ahr,Lhr,d9,A8,aFe,yhr,xhr,TH,$hr,khr,Shr,L8,nFe,Rhr,Phr,MH,Bhr,Ihr,Nhr,y8,qhr,sFe,jhr,Dhr,lFe,Ghr,Ohr,x8,RXe,Dd,$8,iFe,c9,Vhr,dFe,Xhr,PXe,Ho,f9,zhr,Gd,Qhr,EH,Whr,Hhr,CH,Uhr,Jhr,Yhr,m9,Khr,cFe,Zhr,epr,opr,At,g9,rpr,fFe,tpr,apr,Od,npr,mFe,spr,lpr,wH,ipr,dpr,cpr,k8,fpr,po,h9,mpr,gFe,gpr,hpr,Za,ppr,hFe,_pr,upr,pFe,bpr,vpr,_Fe,Fpr,Tpr,Mpr,ot,S8,uFe,Epr,Cpr,AH,wpr,Apr,Lpr,R8,bFe,ypr,xpr,LH,$pr,kpr,Spr,P8,vFe,Rpr,Ppr,yH,Bpr,Ipr,Npr,B8,FFe,qpr,jpr,xH,Dpr,Gpr,Opr,I8,TFe,Vpr,Xpr,$H,zpr,Qpr,Wpr,N8,Hpr,MFe,Upr,Jpr,EFe,Ypr,Kpr,q8,BXe,Vd,j8,CFe,p9,Zpr,wFe,e_r,IXe,Uo,_9,o_r,Xd,r_r,kH,t_r,a_r,SH,n_r,s_r,l_r,u9,i_r,AFe,d_r,c_r,f_r,Lt,b9,m_r,LFe,g_r,h_r,zd,p_r,yFe,__r,u_r,RH,b_r,v_r,F_r,D8,T_r,_o,v9,M_r,xFe,E_r,C_r,en,w_r,$Fe,A_r,L_r,kFe,y_r,x_r,SFe,$_r,k_r,S_r,Qd,G8,RFe,R_r,P_r,PH,B_r,I_r,N_r,O8,PFe,q_r,j_r,BH,D_r,G_r,O_r,V8,BFe,V_r,X_r,IH,z_r,Q_r,W_r,X8,H_r,IFe,U_r,J_r,NFe,Y_r,K_r,z8,NXe,Wd,Q8,qFe,F9,Z_r,jFe,eur,qXe,Jo,T9,our,Hd,rur,NH,tur,aur,qH,nur,sur,lur,M9,iur,DFe,dur,cur,fur,yt,E9,mur,GFe,gur,hur,Ud,pur,OFe,_ur,uur,jH,bur,vur,Fur,W8,Tur,uo,C9,Mur,VFe,Eur,Cur,on,wur,XFe,Aur,Lur,zFe,yur,xur,QFe,$ur,kur,Sur,w9,H8,WFe,Rur,Pur,DH,Bur,Iur,Nur,U8,HFe,qur,jur,GH,Dur,Gur,Our,J8,Vur,UFe,Xur,zur,JFe,Qur,Wur,Y8,jXe,Jd,K8,YFe,A9,Hur,KFe,Uur,DXe,Yo,L9,Jur,Yd,Yur,OH,Kur,Zur,VH,e1r,o1r,r1r,y9,t1r,ZFe,a1r,n1r,s1r,xt,x9,l1r,eTe,i1r,d1r,Kd,c1r,oTe,f1r,m1r,XH,g1r,h1r,p1r,Z8,_1r,bo,$9,u1r,rTe,b1r,v1r,rn,F1r,tTe,T1r,M1r,aTe,E1r,C1r,nTe,w1r,A1r,L1r,sTe,eM,lTe,y1r,x1r,zH,$1r,k1r,S1r,oM,R1r,iTe,P1r,B1r,dTe,I1r,N1r,rM,GXe,Zd,tM,cTe,k9,q1r,fTe,j1r,OXe,Ko,S9,D1r,ec,G1r,QH,O1r,V1r,WH,X1r,z1r,Q1r,R9,W1r,mTe,H1r,U1r,J1r,$t,P9,Y1r,gTe,K1r,Z1r,oc,e2r,hTe,o2r,r2r,HH,t2r,a2r,n2r,aM,s2r,vo,B9,l2r,pTe,i2r,d2r,tn,c2r,_Te,f2r,m2r,uTe,g2r,h2r,bTe,p2r,_2r,u2r,rt,nM,vTe,b2r,v2r,UH,F2r,T2r,M2r,sM,FTe,E2r,C2r,JH,w2r,A2r,L2r,lM,TTe,y2r,x2r,YH,$2r,k2r,S2r,iM,MTe,R2r,P2r,KH,B2r,I2r,N2r,dM,ETe,q2r,j2r,ZH,D2r,G2r,O2r,cM,V2r,CTe,X2r,z2r,wTe,Q2r,W2r,fM,VXe,rc,mM,ATe,I9,H2r,LTe,U2r,XXe,Zo,N9,J2r,tc,Y2r,eU,K2r,Z2r,oU,ebr,obr,rbr,q9,tbr,yTe,abr,nbr,sbr,kt,j9,lbr,xTe,ibr,dbr,ac,cbr,$Te,fbr,mbr,rU,gbr,hbr,pbr,gM,_br,Fo,D9,ubr,kTe,bbr,vbr,an,Fbr,STe,Tbr,Mbr,RTe,Ebr,Cbr,PTe,wbr,Abr,Lbr,BTe,hM,ITe,ybr,xbr,tU,$br,kbr,Sbr,pM,Rbr,NTe,Pbr,Bbr,qTe,Ibr,Nbr,_M,zXe,nc,uM,jTe,G9,qbr,DTe,jbr,QXe,er,O9,Dbr,sc,Gbr,aU,Obr,Vbr,nU,Xbr,zbr,Qbr,V9,Wbr,GTe,Hbr,Ubr,Jbr,St,X9,Ybr,OTe,Kbr,Zbr,lc,evr,VTe,ovr,rvr,sU,tvr,avr,nvr,bM,svr,yr,z9,lvr,XTe,ivr,dvr,nn,cvr,zTe,fvr,mvr,QTe,gvr,hvr,WTe,pvr,_vr,uvr,j,vM,HTe,bvr,vvr,lU,Fvr,Tvr,Mvr,FM,UTe,Evr,Cvr,iU,wvr,Avr,Lvr,TM,JTe,yvr,xvr,dU,$vr,kvr,Svr,MM,YTe,Rvr,Pvr,cU,Bvr,Ivr,Nvr,EM,KTe,qvr,jvr,fU,Dvr,Gvr,Ovr,CM,ZTe,Vvr,Xvr,mU,zvr,Qvr,Wvr,wM,e7e,Hvr,Uvr,gU,Jvr,Yvr,Kvr,AM,o7e,Zvr,eFr,hU,oFr,rFr,tFr,LM,r7e,aFr,nFr,pU,sFr,lFr,iFr,yM,t7e,dFr,cFr,_U,fFr,mFr,gFr,xM,a7e,hFr,pFr,uU,_Fr,uFr,bFr,$M,n7e,vFr,FFr,bU,TFr,MFr,EFr,kM,s7e,CFr,wFr,vU,AFr,LFr,yFr,SM,l7e,xFr,$Fr,FU,kFr,SFr,RFr,RM,i7e,PFr,BFr,TU,IFr,NFr,qFr,PM,d7e,jFr,DFr,MU,GFr,OFr,VFr,BM,c7e,XFr,zFr,EU,QFr,WFr,HFr,Us,f7e,UFr,JFr,CU,YFr,KFr,wU,ZFr,eTr,oTr,IM,m7e,rTr,tTr,AU,aTr,nTr,sTr,NM,g7e,lTr,iTr,LU,dTr,cTr,fTr,qM,h7e,mTr,gTr,yU,hTr,pTr,_Tr,jM,p7e,uTr,bTr,xU,vTr,FTr,TTr,DM,_7e,MTr,ETr,$U,CTr,wTr,ATr,GM,u7e,LTr,yTr,kU,xTr,$Tr,kTr,OM,b7e,STr,RTr,SU,PTr,BTr,ITr,VM,v7e,NTr,qTr,RU,jTr,DTr,GTr,XM,F7e,OTr,VTr,PU,XTr,zTr,QTr,zM,T7e,WTr,HTr,BU,UTr,JTr,YTr,QM,M7e,KTr,ZTr,IU,e7r,o7r,r7r,WM,E7e,t7r,a7r,NU,n7r,s7r,l7r,HM,C7e,i7r,d7r,qU,c7r,f7r,m7r,UM,w7e,g7r,h7r,jU,p7r,_7r,u7r,JM,A7e,b7r,v7r,DU,F7r,T7r,M7r,YM,L7e,E7r,C7r,GU,w7r,A7r,L7r,KM,y7e,y7r,x7r,OU,$7r,k7r,S7r,ZM,x7e,R7r,P7r,VU,B7r,I7r,N7r,e4,$7e,q7r,j7r,XU,D7r,G7r,O7r,o4,k7e,V7r,X7r,zU,z7r,Q7r,W7r,r4,S7e,H7r,U7r,QU,J7r,Y7r,K7r,t4,R7e,Z7r,e8r,WU,o8r,r8r,t8r,a4,P7e,a8r,n8r,HU,s8r,l8r,i8r,n4,B7e,d8r,c8r,UU,f8r,m8r,g8r,s4,I7e,h8r,p8r,JU,_8r,u8r,b8r,l4,N7e,v8r,F8r,YU,T8r,M8r,E8r,i4,q7e,C8r,w8r,KU,A8r,L8r,y8r,d4,j7e,x8r,$8r,ZU,k8r,S8r,R8r,c4,D7e,P8r,B8r,eJ,I8r,N8r,q8r,f4,G7e,j8r,D8r,oJ,G8r,O8r,V8r,m4,WXe,ic,g4,O7e,Q9,X8r,V7e,z8r,HXe,or,W9,Q8r,dc,W8r,rJ,H8r,U8r,tJ,J8r,Y8r,K8r,H9,Z8r,X7e,eMr,oMr,rMr,Rt,U9,tMr,z7e,aMr,nMr,cc,sMr,Q7e,lMr,iMr,aJ,dMr,cMr,fMr,h4,mMr,xr,J9,gMr,W7e,hMr,pMr,sn,_Mr,H7e,uMr,bMr,U7e,vMr,FMr,J7e,TMr,MMr,EMr,se,p4,Y7e,CMr,wMr,nJ,AMr,LMr,yMr,_4,K7e,xMr,$Mr,sJ,kMr,SMr,RMr,u4,Z7e,PMr,BMr,lJ,IMr,NMr,qMr,b4,e8e,jMr,DMr,iJ,GMr,OMr,VMr,v4,o8e,XMr,zMr,dJ,QMr,WMr,HMr,F4,r8e,UMr,JMr,cJ,YMr,KMr,ZMr,T4,t8e,e4r,o4r,fJ,r4r,t4r,a4r,M4,a8e,n4r,s4r,mJ,l4r,i4r,d4r,E4,n8e,c4r,f4r,gJ,m4r,g4r,h4r,C4,s8e,p4r,_4r,hJ,u4r,b4r,v4r,w4,l8e,F4r,T4r,pJ,M4r,E4r,C4r,A4,i8e,w4r,A4r,_J,L4r,y4r,x4r,L4,d8e,$4r,k4r,uJ,S4r,R4r,P4r,y4,c8e,B4r,I4r,bJ,N4r,q4r,j4r,x4,f8e,D4r,G4r,vJ,O4r,V4r,X4r,$4,m8e,z4r,Q4r,FJ,W4r,H4r,U4r,k4,g8e,J4r,Y4r,TJ,K4r,Z4r,eEr,S4,h8e,oEr,rEr,MJ,tEr,aEr,nEr,R4,p8e,sEr,lEr,EJ,iEr,dEr,cEr,P4,_8e,fEr,mEr,CJ,gEr,hEr,pEr,B4,u8e,_Er,uEr,wJ,bEr,vEr,FEr,I4,b8e,TEr,MEr,AJ,EEr,CEr,wEr,N4,v8e,AEr,LEr,LJ,yEr,xEr,$Er,q4,UXe,fc,j4,F8e,Y9,kEr,T8e,SEr,JXe,rr,K9,REr,mc,PEr,yJ,BEr,IEr,xJ,NEr,qEr,jEr,Z9,DEr,M8e,GEr,OEr,VEr,Pt,ex,XEr,E8e,zEr,QEr,gc,WEr,C8e,HEr,UEr,$J,JEr,YEr,KEr,D4,ZEr,$r,ox,eCr,w8e,oCr,rCr,ln,tCr,A8e,aCr,nCr,L8e,sCr,lCr,y8e,iCr,dCr,cCr,Me,G4,x8e,fCr,mCr,kJ,gCr,hCr,pCr,O4,$8e,_Cr,uCr,SJ,bCr,vCr,FCr,V4,k8e,TCr,MCr,RJ,ECr,CCr,wCr,X4,S8e,ACr,LCr,PJ,yCr,xCr,$Cr,z4,R8e,kCr,SCr,BJ,RCr,PCr,BCr,Q4,P8e,ICr,NCr,IJ,qCr,jCr,DCr,W4,B8e,GCr,OCr,NJ,VCr,XCr,zCr,H4,I8e,QCr,WCr,qJ,HCr,UCr,JCr,U4,N8e,YCr,KCr,jJ,ZCr,e3r,o3r,J4,q8e,r3r,t3r,DJ,a3r,n3r,s3r,Y4,j8e,l3r,i3r,GJ,d3r,c3r,f3r,K4,D8e,m3r,g3r,OJ,h3r,p3r,_3r,Z4,G8e,u3r,b3r,VJ,v3r,F3r,T3r,eE,YXe,hc,oE,O8e,rx,M3r,V8e,E3r,KXe,tr,tx,C3r,pc,w3r,XJ,A3r,L3r,zJ,y3r,x3r,$3r,ax,k3r,X8e,S3r,R3r,P3r,Bt,nx,B3r,z8e,I3r,N3r,_c,q3r,Q8e,j3r,D3r,QJ,G3r,O3r,V3r,rE,X3r,kr,sx,z3r,W8e,Q3r,W3r,dn,H3r,H8e,U3r,J3r,U8e,Y3r,K3r,J8e,Z3r,e5r,o5r,tt,tE,Y8e,r5r,t5r,WJ,a5r,n5r,s5r,aE,K8e,l5r,i5r,HJ,d5r,c5r,f5r,nE,Z8e,m5r,g5r,UJ,h5r,p5r,_5r,sE,eMe,u5r,b5r,JJ,v5r,F5r,T5r,lE,oMe,M5r,E5r,YJ,C5r,w5r,A5r,iE,ZXe,uc,dE,rMe,lx,L5r,tMe,y5r,eze,ar,ix,x5r,bc,$5r,KJ,k5r,S5r,ZJ,R5r,P5r,B5r,dx,I5r,aMe,N5r,q5r,j5r,It,cx,D5r,nMe,G5r,O5r,vc,V5r,sMe,X5r,z5r,eY,Q5r,W5r,H5r,cE,U5r,Sr,fx,J5r,lMe,Y5r,K5r,cn,Z5r,iMe,e0r,o0r,dMe,r0r,t0r,cMe,a0r,n0r,s0r,ie,fE,fMe,l0r,i0r,oY,d0r,c0r,f0r,mE,mMe,m0r,g0r,rY,h0r,p0r,_0r,gE,gMe,u0r,b0r,tY,v0r,F0r,T0r,hE,hMe,M0r,E0r,aY,C0r,w0r,A0r,pE,pMe,L0r,y0r,nY,x0r,$0r,k0r,_E,_Me,S0r,R0r,sY,P0r,B0r,I0r,uE,uMe,N0r,q0r,lY,j0r,D0r,G0r,bE,bMe,O0r,V0r,iY,X0r,z0r,Q0r,vE,vMe,W0r,H0r,dY,U0r,J0r,Y0r,FE,FMe,K0r,Z0r,cY,ewr,owr,rwr,TE,TMe,twr,awr,fY,nwr,swr,lwr,ME,MMe,iwr,dwr,mY,cwr,fwr,mwr,EE,EMe,gwr,hwr,gY,pwr,_wr,uwr,CE,CMe,bwr,vwr,hY,Fwr,Twr,Mwr,wE,wMe,Ewr,Cwr,pY,wwr,Awr,Lwr,AE,AMe,ywr,xwr,_Y,$wr,kwr,Swr,LE,LMe,Rwr,Pwr,uY,Bwr,Iwr,Nwr,yE,yMe,qwr,jwr,bY,Dwr,Gwr,Owr,xE,xMe,Vwr,Xwr,vY,zwr,Qwr,Wwr,$E,$Me,Hwr,Uwr,FY,Jwr,Ywr,Kwr,kE,oze,Fc,SE,kMe,mx,Zwr,SMe,eAr,rze,nr,gx,oAr,Tc,rAr,TY,tAr,aAr,MY,nAr,sAr,lAr,hx,iAr,RMe,dAr,cAr,fAr,Nt,px,mAr,PMe,gAr,hAr,Mc,pAr,BMe,_Ar,uAr,EY,bAr,vAr,FAr,RE,TAr,Rr,_x,MAr,IMe,EAr,CAr,fn,wAr,NMe,AAr,LAr,qMe,yAr,xAr,jMe,$Ar,kAr,SAr,ye,PE,DMe,RAr,PAr,CY,BAr,IAr,NAr,BE,GMe,qAr,jAr,wY,DAr,GAr,OAr,IE,OMe,VAr,XAr,AY,zAr,QAr,WAr,NE,VMe,HAr,UAr,LY,JAr,YAr,KAr,qE,XMe,ZAr,e6r,yY,o6r,r6r,t6r,jE,zMe,a6r,n6r,xY,s6r,l6r,i6r,DE,QMe,d6r,c6r,$Y,f6r,m6r,g6r,GE,WMe,h6r,p6r,kY,_6r,u6r,b6r,OE,HMe,v6r,F6r,SY,T6r,M6r,E6r,VE,UMe,C6r,w6r,RY,A6r,L6r,y6r,XE,tze,Ec,zE,JMe,ux,x6r,YMe,$6r,aze,sr,bx,k6r,Cc,S6r,PY,R6r,P6r,BY,B6r,I6r,N6r,vx,q6r,KMe,j6r,D6r,G6r,qt,Fx,O6r,ZMe,V6r,X6r,wc,z6r,e4e,Q6r,W6r,IY,H6r,U6r,J6r,QE,Y6r,Pr,Tx,K6r,o4e,Z6r,eLr,mn,oLr,r4e,rLr,tLr,t4e,aLr,nLr,a4e,sLr,lLr,iLr,te,WE,n4e,dLr,cLr,NY,fLr,mLr,gLr,HE,s4e,hLr,pLr,qY,_Lr,uLr,bLr,UE,l4e,vLr,FLr,jY,TLr,MLr,ELr,JE,i4e,CLr,wLr,DY,ALr,LLr,yLr,YE,d4e,xLr,$Lr,GY,kLr,SLr,RLr,KE,c4e,PLr,BLr,OY,ILr,NLr,qLr,ZE,f4e,jLr,DLr,VY,GLr,OLr,VLr,eC,m4e,XLr,zLr,XY,QLr,WLr,HLr,oC,g4e,ULr,JLr,zY,YLr,KLr,ZLr,rC,h4e,eyr,oyr,QY,ryr,tyr,ayr,tC,p4e,nyr,syr,WY,lyr,iyr,dyr,aC,_4e,cyr,fyr,HY,myr,gyr,hyr,nC,u4e,pyr,_yr,UY,uyr,byr,vyr,sC,b4e,Fyr,Tyr,JY,Myr,Eyr,Cyr,lC,v4e,wyr,Ayr,YY,Lyr,yyr,xyr,iC,F4e,$yr,kyr,KY,Syr,Ryr,Pyr,dC,T4e,Byr,Iyr,ZY,Nyr,qyr,jyr,cC,M4e,Dyr,Gyr,eK,Oyr,Vyr,Xyr,fC,E4e,zyr,Qyr,oK,Wyr,Hyr,Uyr,mC,C4e,Jyr,Yyr,rK,Kyr,Zyr,e9r,gC,w4e,o9r,r9r,tK,t9r,a9r,n9r,hC,A4e,s9r,l9r,aK,i9r,d9r,c9r,pC,L4e,f9r,m9r,nK,g9r,h9r,p9r,_C,y4e,_9r,u9r,sK,b9r,v9r,F9r,uC,x4e,T9r,M9r,lK,E9r,C9r,w9r,bC,$4e,A9r,L9r,iK,y9r,x9r,$9r,vC,nze,Ac,FC,k4e,Mx,k9r,S4e,S9r,sze,lr,Ex,R9r,Lc,P9r,dK,B9r,I9r,cK,N9r,q9r,j9r,Cx,D9r,R4e,G9r,O9r,V9r,jt,wx,X9r,P4e,z9r,Q9r,yc,W9r,B4e,H9r,U9r,fK,J9r,Y9r,K9r,TC,Z9r,Br,Ax,exr,I4e,oxr,rxr,gn,txr,N4e,axr,nxr,q4e,sxr,lxr,j4e,ixr,dxr,cxr,_e,MC,D4e,fxr,mxr,mK,gxr,hxr,pxr,EC,G4e,_xr,uxr,gK,bxr,vxr,Fxr,CC,O4e,Txr,Mxr,hK,Exr,Cxr,wxr,wC,V4e,Axr,Lxr,pK,yxr,xxr,$xr,AC,X4e,kxr,Sxr,_K,Rxr,Pxr,Bxr,LC,z4e,Ixr,Nxr,uK,qxr,jxr,Dxr,yC,Q4e,Gxr,Oxr,bK,Vxr,Xxr,zxr,xC,W4e,Qxr,Wxr,vK,Hxr,Uxr,Jxr,$C,H4e,Yxr,Kxr,FK,Zxr,e$r,o$r,kC,U4e,r$r,t$r,TK,a$r,n$r,s$r,SC,J4e,l$r,i$r,MK,d$r,c$r,f$r,RC,Y4e,m$r,g$r,EK,h$r,p$r,_$r,PC,K4e,u$r,b$r,CK,v$r,F$r,T$r,BC,Z4e,M$r,E$r,wK,C$r,w$r,A$r,IC,eEe,L$r,y$r,AK,x$r,$$r,k$r,NC,oEe,S$r,R$r,LK,P$r,B$r,I$r,qC,rEe,N$r,q$r,yK,j$r,D$r,G$r,jC,lze,xc,DC,tEe,Lx,O$r,aEe,V$r,ize,ir,yx,X$r,$c,z$r,xK,Q$r,W$r,$K,H$r,U$r,J$r,xx,Y$r,nEe,K$r,Z$r,ekr,Dt,$x,okr,sEe,rkr,tkr,kc,akr,lEe,nkr,skr,kK,lkr,ikr,dkr,GC,ckr,Ir,kx,fkr,iEe,mkr,gkr,hn,hkr,dEe,pkr,_kr,cEe,ukr,bkr,fEe,vkr,Fkr,Tkr,Sx,OC,mEe,Mkr,Ekr,SK,Ckr,wkr,Akr,VC,gEe,Lkr,ykr,RK,xkr,$kr,kkr,XC,dze,Sc,zC,hEe,Rx,Skr,pEe,Rkr,cze,dr,Px,Pkr,Rc,Bkr,PK,Ikr,Nkr,BK,qkr,jkr,Dkr,Bx,Gkr,_Ee,Okr,Vkr,Xkr,Gt,Ix,zkr,uEe,Qkr,Wkr,Pc,Hkr,bEe,Ukr,Jkr,IK,Ykr,Kkr,Zkr,QC,eSr,Nr,Nx,oSr,vEe,rSr,tSr,pn,aSr,FEe,nSr,sSr,TEe,lSr,iSr,MEe,dSr,cSr,fSr,EEe,WC,CEe,mSr,gSr,NK,hSr,pSr,_Sr,HC,fze,Bc,UC,wEe,qx,uSr,AEe,bSr,mze,cr,jx,vSr,Ic,FSr,qK,TSr,MSr,jK,ESr,CSr,wSr,Dx,ASr,LEe,LSr,ySr,xSr,Ot,Gx,$Sr,yEe,kSr,SSr,Nc,RSr,xEe,PSr,BSr,DK,ISr,NSr,qSr,JC,jSr,qr,Ox,DSr,$Ee,GSr,OSr,_n,VSr,kEe,XSr,zSr,SEe,QSr,WSr,REe,HSr,USr,JSr,de,YC,PEe,YSr,KSr,GK,ZSr,eRr,oRr,KC,BEe,rRr,tRr,OK,aRr,nRr,sRr,ZC,IEe,lRr,iRr,VK,dRr,cRr,fRr,e3,NEe,mRr,gRr,XK,hRr,pRr,_Rr,o3,qEe,uRr,bRr,zK,vRr,FRr,TRr,r3,jEe,MRr,ERr,QK,CRr,wRr,ARr,t3,DEe,LRr,yRr,WK,xRr,$Rr,kRr,a3,GEe,SRr,RRr,HK,PRr,BRr,IRr,n3,OEe,NRr,qRr,UK,jRr,DRr,GRr,s3,VEe,ORr,VRr,JK,XRr,zRr,QRr,l3,XEe,WRr,HRr,YK,URr,JRr,YRr,i3,zEe,KRr,ZRr,KK,ePr,oPr,rPr,d3,QEe,tPr,aPr,ZK,nPr,sPr,lPr,c3,WEe,iPr,dPr,eZ,cPr,fPr,mPr,f3,HEe,gPr,hPr,oZ,pPr,_Pr,uPr,m3,UEe,bPr,vPr,rZ,FPr,TPr,MPr,g3,JEe,EPr,CPr,tZ,wPr,APr,LPr,h3,YEe,yPr,xPr,aZ,$Pr,kPr,SPr,p3,KEe,RPr,PPr,nZ,BPr,IPr,NPr,_3,ZEe,qPr,jPr,sZ,DPr,GPr,OPr,u3,gze,qc,b3,eCe,Vx,VPr,oCe,XPr,hze,fr,Xx,zPr,jc,QPr,lZ,WPr,HPr,iZ,UPr,JPr,YPr,zx,KPr,rCe,ZPr,eBr,oBr,Vt,Qx,rBr,tCe,tBr,aBr,Dc,nBr,aCe,sBr,lBr,dZ,iBr,dBr,cBr,v3,fBr,jr,Wx,mBr,nCe,gBr,hBr,un,pBr,sCe,_Br,uBr,lCe,bBr,vBr,iCe,FBr,TBr,MBr,ce,F3,dCe,EBr,CBr,cZ,wBr,ABr,LBr,T3,cCe,yBr,xBr,fZ,$Br,kBr,SBr,M3,fCe,RBr,PBr,mZ,BBr,IBr,NBr,E3,mCe,qBr,jBr,gZ,DBr,GBr,OBr,C3,gCe,VBr,XBr,hZ,zBr,QBr,WBr,w3,hCe,HBr,UBr,pZ,JBr,YBr,KBr,A3,pCe,ZBr,eIr,_Z,oIr,rIr,tIr,L3,_Ce,aIr,nIr,uZ,sIr,lIr,iIr,y3,uCe,dIr,cIr,bZ,fIr,mIr,gIr,x3,bCe,hIr,pIr,vZ,_Ir,uIr,bIr,$3,vCe,vIr,FIr,FZ,TIr,MIr,EIr,k3,FCe,CIr,wIr,TZ,AIr,LIr,yIr,S3,TCe,xIr,$Ir,MZ,kIr,SIr,RIr,R3,MCe,PIr,BIr,EZ,IIr,NIr,qIr,P3,ECe,jIr,DIr,CZ,GIr,OIr,VIr,B3,CCe,XIr,zIr,wZ,QIr,WIr,HIr,I3,wCe,UIr,JIr,AZ,YIr,KIr,ZIr,N3,ACe,eNr,oNr,LZ,rNr,tNr,aNr,q3,LCe,nNr,sNr,yZ,lNr,iNr,dNr,j3,yCe,cNr,fNr,xZ,mNr,gNr,hNr,D3,pze,Gc,G3,xCe,Hx,pNr,$Ce,_Nr,_ze,mr,Ux,uNr,Oc,bNr,$Z,vNr,FNr,kZ,TNr,MNr,ENr,Jx,CNr,kCe,wNr,ANr,LNr,Xt,Yx,yNr,SCe,xNr,$Nr,Vc,kNr,RCe,SNr,RNr,SZ,PNr,BNr,INr,O3,NNr,Dr,Kx,qNr,PCe,jNr,DNr,bn,GNr,BCe,ONr,VNr,ICe,XNr,zNr,NCe,QNr,WNr,HNr,qCe,V3,jCe,UNr,JNr,RZ,YNr,KNr,ZNr,X3,uze,Xc,z3,DCe,Zx,eqr,GCe,oqr,bze,gr,e$,rqr,zc,tqr,PZ,aqr,nqr,BZ,sqr,lqr,iqr,o$,dqr,OCe,cqr,fqr,mqr,zt,r$,gqr,VCe,hqr,pqr,Qc,_qr,XCe,uqr,bqr,IZ,vqr,Fqr,Tqr,Q3,Mqr,Gr,t$,Eqr,zCe,Cqr,wqr,vn,Aqr,QCe,Lqr,yqr,WCe,xqr,$qr,HCe,kqr,Sqr,Rqr,UCe,W3,JCe,Pqr,Bqr,NZ,Iqr,Nqr,qqr,H3,vze,Wc,U3,YCe,a$,jqr,KCe,Dqr,Fze,hr,n$,Gqr,Hc,Oqr,qZ,Vqr,Xqr,jZ,zqr,Qqr,Wqr,s$,Hqr,ZCe,Uqr,Jqr,Yqr,Qt,l$,Kqr,e3e,Zqr,ejr,Uc,ojr,o3e,rjr,tjr,DZ,ajr,njr,sjr,J3,ljr,Or,i$,ijr,r3e,djr,cjr,Fn,fjr,t3e,mjr,gjr,a3e,hjr,pjr,n3e,_jr,ujr,bjr,oe,Y3,s3e,vjr,Fjr,GZ,Tjr,Mjr,Ejr,K3,l3e,Cjr,wjr,OZ,Ajr,Ljr,yjr,Z3,i3e,xjr,$jr,VZ,kjr,Sjr,Rjr,e5,d3e,Pjr,Bjr,XZ,Ijr,Njr,qjr,o5,c3e,jjr,Djr,zZ,Gjr,Ojr,Vjr,r5,f3e,Xjr,zjr,QZ,Qjr,Wjr,Hjr,t5,m3e,Ujr,Jjr,WZ,Yjr,Kjr,Zjr,a5,g3e,eDr,oDr,HZ,rDr,tDr,aDr,n5,h3e,nDr,sDr,UZ,lDr,iDr,dDr,s5,p3e,cDr,fDr,JZ,mDr,gDr,hDr,l5,_3e,pDr,_Dr,YZ,uDr,bDr,vDr,i5,u3e,FDr,TDr,KZ,MDr,EDr,CDr,d5,b3e,wDr,ADr,ZZ,LDr,yDr,xDr,c5,v3e,$Dr,kDr,eee,SDr,RDr,PDr,f5,F3e,BDr,IDr,oee,NDr,qDr,jDr,m5,T3e,DDr,GDr,ree,ODr,VDr,XDr,g5,M3e,zDr,QDr,tee,WDr,HDr,UDr,h5,E3e,JDr,YDr,aee,KDr,ZDr,eGr,p5,C3e,oGr,rGr,nee,tGr,aGr,nGr,_5,w3e,sGr,lGr,see,iGr,dGr,cGr,u5,A3e,fGr,mGr,lee,gGr,hGr,pGr,b5,L3e,_Gr,uGr,iee,bGr,vGr,FGr,v5,y3e,TGr,MGr,dee,EGr,CGr,wGr,F5,x3e,AGr,LGr,cee,yGr,xGr,$Gr,T5,$3e,kGr,SGr,fee,RGr,PGr,BGr,M5,k3e,IGr,NGr,mee,qGr,jGr,DGr,E5,S3e,GGr,OGr,gee,VGr,XGr,zGr,C5,Tze,Jc,w5,R3e,d$,QGr,P3e,WGr,Mze,pr,c$,HGr,Yc,UGr,hee,JGr,YGr,pee,KGr,ZGr,eOr,f$,oOr,B3e,rOr,tOr,aOr,Wt,m$,nOr,I3e,sOr,lOr,Kc,iOr,N3e,dOr,cOr,_ee,fOr,mOr,gOr,A5,hOr,Vr,g$,pOr,q3e,_Or,uOr,Tn,bOr,j3e,vOr,FOr,D3e,TOr,MOr,G3e,EOr,COr,wOr,xe,L5,O3e,AOr,LOr,uee,yOr,xOr,$Or,y5,V3e,kOr,SOr,bee,ROr,POr,BOr,x5,X3e,IOr,NOr,vee,qOr,jOr,DOr,$5,z3e,GOr,OOr,Fee,VOr,XOr,zOr,k5,Q3e,QOr,WOr,Tee,HOr,UOr,JOr,S5,W3e,YOr,KOr,Mee,ZOr,eVr,oVr,R5,H3e,rVr,tVr,Eee,aVr,nVr,sVr,P5,U3e,lVr,iVr,Cee,dVr,cVr,fVr,B5,J3e,mVr,gVr,wee,hVr,pVr,_Vr,I5,Y3e,uVr,bVr,Aee,vVr,FVr,TVr,N5,Eze,Zc,q5,K3e,h$,MVr,Z3e,EVr,Cze,_r,p$,CVr,ef,wVr,Lee,AVr,LVr,yee,yVr,xVr,$Vr,_$,kVr,e5e,SVr,RVr,PVr,Ht,u$,BVr,o5e,IVr,NVr,of,qVr,r5e,jVr,DVr,xee,GVr,OVr,VVr,j5,XVr,Xr,b$,zVr,t5e,QVr,WVr,Mn,HVr,a5e,UVr,JVr,n5e,YVr,KVr,s5e,ZVr,eXr,oXr,Ee,D5,l5e,rXr,tXr,$ee,aXr,nXr,sXr,G5,i5e,lXr,iXr,kee,dXr,cXr,fXr,O5,d5e,mXr,gXr,See,hXr,pXr,_Xr,V5,c5e,uXr,bXr,Ree,vXr,FXr,TXr,X5,f5e,MXr,EXr,Pee,CXr,wXr,AXr,z5,m5e,LXr,yXr,Bee,xXr,$Xr,kXr,Q5,g5e,SXr,RXr,Iee,PXr,BXr,IXr,W5,h5e,NXr,qXr,Nee,jXr,DXr,GXr,H5,p5e,OXr,VXr,qee,XXr,zXr,QXr,U5,_5e,WXr,HXr,jee,UXr,JXr,YXr,J5,u5e,KXr,ZXr,Dee,ezr,ozr,rzr,Y5,b5e,tzr,azr,Gee,nzr,szr,lzr,K5,v5e,izr,dzr,Oee,czr,fzr,mzr,Z5,wze,rf,e0,F5e,v$,gzr,T5e,hzr,Aze,ur,F$,pzr,tf,_zr,Vee,uzr,bzr,Xee,vzr,Fzr,Tzr,T$,Mzr,M5e,Ezr,Czr,wzr,Ut,M$,Azr,E5e,Lzr,yzr,af,xzr,C5e,$zr,kzr,zee,Szr,Rzr,Pzr,o0,Bzr,zr,E$,Izr,w5e,Nzr,qzr,En,jzr,A5e,Dzr,Gzr,L5e,Ozr,Vzr,y5e,Xzr,zzr,Qzr,$e,r0,x5e,Wzr,Hzr,Qee,Uzr,Jzr,Yzr,t0,$5e,Kzr,Zzr,Wee,eQr,oQr,rQr,a0,k5e,tQr,aQr,Hee,nQr,sQr,lQr,n0,S5e,iQr,dQr,Uee,cQr,fQr,mQr,s0,R5e,gQr,hQr,Jee,pQr,_Qr,uQr,l0,P5e,bQr,vQr,Yee,FQr,TQr,MQr,i0,B5e,EQr,CQr,Kee,wQr,AQr,LQr,d0,I5e,yQr,xQr,Zee,$Qr,kQr,SQr,c0,N5e,RQr,PQr,eoe,BQr,IQr,NQr,f0,q5e,qQr,jQr,ooe,DQr,GQr,OQr,m0,Lze,nf,g0,j5e,C$,VQr,D5e,XQr,yze,br,w$,zQr,sf,QQr,roe,WQr,HQr,toe,UQr,JQr,YQr,A$,KQr,G5e,ZQr,eWr,oWr,Jt,L$,rWr,O5e,tWr,aWr,lf,nWr,V5e,sWr,lWr,aoe,iWr,dWr,cWr,h0,fWr,Qr,y$,mWr,X5e,gWr,hWr,Cn,pWr,z5e,_Wr,uWr,Q5e,bWr,vWr,W5e,FWr,TWr,MWr,ke,p0,H5e,EWr,CWr,noe,wWr,AWr,LWr,_0,U5e,yWr,xWr,soe,$Wr,kWr,SWr,u0,J5e,RWr,PWr,loe,BWr,IWr,NWr,b0,Y5e,qWr,jWr,ioe,DWr,GWr,OWr,v0,K5e,VWr,XWr,doe,zWr,QWr,WWr,F0,Z5e,HWr,UWr,coe,JWr,YWr,KWr,T0,e0e,ZWr,eHr,foe,oHr,rHr,tHr,M0,o0e,aHr,nHr,moe,sHr,lHr,iHr,E0,r0e,dHr,cHr,goe,fHr,mHr,gHr,C0,t0e,hHr,pHr,hoe,_Hr,uHr,bHr,w0,xze,df,A0,a0e,x$,vHr,n0e,FHr,$ze,vr,$$,THr,cf,MHr,poe,EHr,CHr,_oe,wHr,AHr,LHr,k$,yHr,s0e,xHr,$Hr,kHr,Yt,S$,SHr,l0e,RHr,PHr,ff,BHr,i0e,IHr,NHr,uoe,qHr,jHr,DHr,L0,GHr,Wr,R$,OHr,d0e,VHr,XHr,wn,zHr,c0e,QHr,WHr,f0e,HHr,UHr,m0e,JHr,YHr,KHr,Se,y0,g0e,ZHr,eUr,boe,oUr,rUr,tUr,x0,h0e,aUr,nUr,voe,sUr,lUr,iUr,$0,p0e,dUr,cUr,Foe,fUr,mUr,gUr,k0,_0e,hUr,pUr,Toe,_Ur,uUr,bUr,S0,u0e,vUr,FUr,Moe,TUr,MUr,EUr,R0,b0e,CUr,wUr,Eoe,AUr,LUr,yUr,P0,v0e,xUr,$Ur,Coe,kUr,SUr,RUr,B0,F0e,PUr,BUr,woe,IUr,NUr,qUr,I0,T0e,jUr,DUr,Aoe,GUr,OUr,VUr,N0,M0e,XUr,zUr,Loe,QUr,WUr,HUr,q0,kze,mf,j0,E0e,P$,UUr,C0e,JUr,Sze,Fr,B$,YUr,gf,KUr,yoe,ZUr,eJr,xoe,oJr,rJr,tJr,I$,aJr,w0e,nJr,sJr,lJr,Kt,N$,iJr,A0e,dJr,cJr,hf,fJr,L0e,mJr,gJr,$oe,hJr,pJr,_Jr,D0,uJr,Hr,q$,bJr,y0e,vJr,FJr,An,TJr,x0e,MJr,EJr,$0e,CJr,wJr,k0e,AJr,LJr,yJr,Re,G0,S0e,xJr,$Jr,koe,kJr,SJr,RJr,O0,R0e,PJr,BJr,Soe,IJr,NJr,qJr,V0,P0e,jJr,DJr,Roe,GJr,OJr,VJr,X0,B0e,XJr,zJr,Poe,QJr,WJr,HJr,z0,I0e,UJr,JJr,Boe,YJr,KJr,ZJr,Q0,N0e,eYr,oYr,Ioe,rYr,tYr,aYr,W0,q0e,nYr,sYr,Noe,lYr,iYr,dYr,H0,j0e,cYr,fYr,qoe,mYr,gYr,hYr,U0,D0e,pYr,_Yr,joe,uYr,bYr,vYr,J0,G0e,FYr,TYr,Doe,MYr,EYr,CYr,Y0,Rze,pf,K0,O0e,j$,wYr,V0e,AYr,Pze,Tr,D$,LYr,_f,yYr,Goe,xYr,$Yr,Ooe,kYr,SYr,RYr,G$,PYr,X0e,BYr,IYr,NYr,Zt,O$,qYr,z0e,jYr,DYr,uf,GYr,Q0e,OYr,VYr,Voe,XYr,zYr,QYr,Z0,WYr,Ur,V$,HYr,W0e,UYr,JYr,Ln,YYr,H0e,KYr,ZYr,U0e,eKr,oKr,J0e,rKr,tKr,aKr,Ve,ew,Y0e,nKr,sKr,Xoe,lKr,iKr,dKr,ow,K0e,cKr,fKr,zoe,mKr,gKr,hKr,rw,Z0e,pKr,_Kr,Qoe,uKr,bKr,vKr,tw,ewe,FKr,TKr,Woe,MKr,EKr,CKr,aw,owe,wKr,AKr,Hoe,LKr,yKr,xKr,nw,rwe,$Kr,kKr,Uoe,SKr,RKr,PKr,sw,twe,BKr,IKr,Joe,NKr,qKr,jKr,lw,awe,DKr,GKr,Yoe,OKr,VKr,XKr,iw,Bze,bf,dw,nwe,X$,zKr,swe,QKr,Ize,Mr,z$,WKr,vf,HKr,Koe,UKr,JKr,Zoe,YKr,KKr,ZKr,Q$,eZr,lwe,oZr,rZr,tZr,ea,W$,aZr,iwe,nZr,sZr,Ff,lZr,dwe,iZr,dZr,ere,cZr,fZr,mZr,cw,gZr,Jr,H$,hZr,cwe,pZr,_Zr,yn,uZr,fwe,bZr,vZr,mwe,FZr,TZr,gwe,MZr,EZr,CZr,Xe,fw,hwe,wZr,AZr,ore,LZr,yZr,xZr,mw,pwe,$Zr,kZr,rre,SZr,RZr,PZr,gw,_we,BZr,IZr,tre,NZr,qZr,jZr,hw,uwe,DZr,GZr,are,OZr,VZr,XZr,pw,bwe,zZr,QZr,nre,WZr,HZr,UZr,_w,vwe,JZr,YZr,sre,KZr,ZZr,eet,uw,Fwe,oet,ret,lre,tet,aet,net,bw,Twe,set,iet,ire,det,cet,fet,vw,Nze,Tf,Fw,Mwe,U$,met,Ewe,get,qze,Er,J$,het,Mf,pet,dre,_et,uet,cre,bet,vet,Fet,Y$,Tet,Cwe,Met,Eet,Cet,oa,K$,wet,wwe,Aet,Let,Ef,yet,Awe,xet,$et,fre,ket,Set,Ret,Tw,Pet,Yr,Z$,Bet,Lwe,Iet,Net,xn,qet,ywe,jet,Det,xwe,Get,Oet,$we,Vet,Xet,zet,kwe,Mw,Swe,Qet,Wet,mre,Het,Uet,Jet,Ew,jze,Cf,Cw,Rwe,ek,Yet,Pwe,Ket,Dze,Cr,ok,Zet,wf,eot,gre,oot,rot,hre,tot,aot,not,rk,sot,Bwe,lot,iot,dot,ra,tk,cot,Iwe,fot,mot,Af,got,Nwe,hot,pot,pre,_ot,uot,bot,ww,vot,Kr,ak,Fot,qwe,Tot,Mot,$n,Eot,jwe,Cot,wot,Dwe,Aot,Lot,Gwe,yot,xot,$ot,nk,Aw,Owe,kot,Sot,_re,Rot,Pot,Bot,Lw,Vwe,Iot,Not,ure,qot,jot,Dot,yw,Gze,Lf,xw,Xwe,sk,Got,zwe,Oot,Oze,wr,lk,Vot,yf,Xot,bre,zot,Qot,vre,Wot,Hot,Uot,ik,Jot,Qwe,Yot,Kot,Zot,ta,dk,ert,Wwe,ort,rrt,xf,trt,Hwe,art,nrt,Fre,srt,lrt,irt,$w,drt,Zr,ck,crt,Uwe,frt,mrt,kn,grt,Jwe,hrt,prt,Ywe,_rt,urt,Kwe,brt,vrt,Frt,Zwe,kw,eAe,Trt,Mrt,Tre,Ert,Crt,wrt,Sw,Vze;return d=new re({}),ka=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),oL=new re({}),rL=new P({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),qf=new Art({props:{warning:!0,$$slots:{default:[Kzt]},$$scope:{ctx:$}}}),tL=new re({}),aL=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/configuration_auto.py#L613"}}),lL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/configuration_auto.py#L636"}}),Yg=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[Zzt]},$$scope:{ctx:$}}}),iL=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/configuration_auto.py#L759"}}),dL=new re({}),cL=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/tokenization_auto.py#L403"}}),gL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17281/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/tokenization_auto.py#L417"}}),Rh=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[eQt]},$$scope:{ctx:$}}}),hL=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/tokenization_auto.py#L616"}}),pL=new re({}),_L=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/feature_extraction_auto.py#L195"}}),vL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17281/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/feature_extraction_auto.py#L209"}}),_p=new Art({props:{$$slots:{default:[oQt]},$$scope:{ctx:$}}}),up=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[rQt]},$$scope:{ctx:$}}}),FL=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/feature_extraction_auto.py#L336"}}),TL=new re({}),ML=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/processing_auto.py#L89"}}),wL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/processing_auto.py#L103"}}),qp=new Art({props:{$$slots:{default:[tQt]},$$scope:{ctx:$}}}),jp=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[aQt]},$$scope:{ctx:$}}}),AL=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/processing_auto.py#L256"}}),LL=new re({}),yL=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L782"}}),$L=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),Op=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[nQt]},$$scope:{ctx:$}}}),kL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),Qu=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[sQt]},$$scope:{ctx:$}}}),SL=new re({}),RL=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L789"}}),BL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),Hu=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[lQt]},$$scope:{ctx:$}}}),IL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),G1=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[iQt]},$$scope:{ctx:$}}}),NL=new re({}),qL=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L804"}}),DL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),V1=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[dQt]},$$scope:{ctx:$}}}),GL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),k2=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[cQt]},$$scope:{ctx:$}}}),OL=new re({}),VL=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L811"}}),zL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),R2=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[fQt]},$$scope:{ctx:$}}}),QL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),vb=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[mQt]},$$scope:{ctx:$}}}),WL=new re({}),HL=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L818"}}),JL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),Tb=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[gQt]},$$scope:{ctx:$}}}),YL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),Gb=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[hQt]},$$scope:{ctx:$}}}),KL=new re({}),ZL=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L827"}}),oy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),Vb=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[pQt]},$$scope:{ctx:$}}}),ry=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),Gv=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[_Qt]},$$scope:{ctx:$}}}),ty=new re({}),ay=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L872"}}),sy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),Vv=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[uQt]},$$scope:{ctx:$}}}),ly=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),TF=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[bQt]},$$scope:{ctx:$}}}),iy=new re({}),dy=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L879"}}),fy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),EF=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[vQt]},$$scope:{ctx:$}}}),my=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),kF=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[FQt]},$$scope:{ctx:$}}}),gy=new re({}),hy=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L865"}}),_y=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),RF=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[TQt]},$$scope:{ctx:$}}}),uy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),uT=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[MQt]},$$scope:{ctx:$}}}),by=new re({}),vy=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L836"}}),Ty=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),vT=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[EQt]},$$scope:{ctx:$}}}),My=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),d7=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[CQt]},$$scope:{ctx:$}}}),Ey=new re({}),Cy=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L843"}}),Ay=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),f7=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[wQt]},$$scope:{ctx:$}}}),Ly=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),h7=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[AQt]},$$scope:{ctx:$}}}),yy=new re({}),xy=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L888"}}),ky=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17281/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/pr_17281/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17281/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17281/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),_7=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[LQt]},$$scope:{ctx:$}}}),Sy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),k7=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[yQt]},$$scope:{ctx:$}}}),Ry=new re({}),Py=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L927"}}),Iy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),R7=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[xQt]},$$scope:{ctx:$}}}),Ny=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),I7=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[$Qt]},$$scope:{ctx:$}}}),qy=new re({}),jy=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L854"}}),Gy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),q7=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[kQt]},$$scope:{ctx:$}}}),Oy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),G7=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[SQt]},$$scope:{ctx:$}}}),Vy=new re({}),Xy=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L934"}}),Qy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),V7=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[RQt]},$$scope:{ctx:$}}}),Wy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),e8=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[PQt]},$$scope:{ctx:$}}}),Hy=new re({}),Uy=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L957"}}),Yy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),r8=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[BQt]},$$scope:{ctx:$}}}),Ky=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),d8=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[IQt]},$$scope:{ctx:$}}}),Zy=new re({}),e9=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L941"}}),r9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),f8=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[NQt]},$$scope:{ctx:$}}}),t9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),E8=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[qQt]},$$scope:{ctx:$}}}),a9=new re({}),n9=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L948"}}),l9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),w8=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[jQt]},$$scope:{ctx:$}}}),i9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),x8=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[DQt]},$$scope:{ctx:$}}}),c9=new re({}),f9=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L966"}}),g9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),k8=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[GQt]},$$scope:{ctx:$}}}),h9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),q8=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[OQt]},$$scope:{ctx:$}}}),p9=new re({}),_9=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L973"}}),b9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),D8=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[VQt]},$$scope:{ctx:$}}}),v9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),z8=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[XQt]},$$scope:{ctx:$}}}),F9=new re({}),T9=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L920"}}),E9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),W8=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[zQt]},$$scope:{ctx:$}}}),C9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),Y8=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[QQt]},$$scope:{ctx:$}}}),A9=new re({}),L9=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L895"}}),x9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),Z8=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[WQt]},$$scope:{ctx:$}}}),$9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),rM=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[HQt]},$$scope:{ctx:$}}}),k9=new re({}),S9=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L902"}}),P9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),aM=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[UQt]},$$scope:{ctx:$}}}),B9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),fM=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[JQt]},$$scope:{ctx:$}}}),I9=new re({}),N9=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_auto.py#L911"}}),j9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),gM=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[YQt]},$$scope:{ctx:$}}}),D9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),_M=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[KQt]},$$scope:{ctx:$}}}),G9=new re({}),O9=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_tf_auto.py#L408"}}),X9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),bM=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[ZQt]},$$scope:{ctx:$}}}),z9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),m4=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[eWt]},$$scope:{ctx:$}}}),Q9=new re({}),W9=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_tf_auto.py#L415"}}),U9=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),h4=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[oWt]},$$scope:{ctx:$}}}),J9=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),q4=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[rWt]},$$scope:{ctx:$}}}),Y9=new re({}),K9=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_tf_auto.py#L430"}}),ex=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),D4=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[tWt]},$$scope:{ctx:$}}}),ox=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),eE=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[aWt]},$$scope:{ctx:$}}}),rx=new re({}),tx=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_tf_auto.py#L446"}}),nx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),rE=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[nWt]},$$scope:{ctx:$}}}),sx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),iE=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[sWt]},$$scope:{ctx:$}}}),lx=new re({}),ix=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_tf_auto.py#L471"}}),cx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),cE=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[lWt]},$$scope:{ctx:$}}}),fx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),kE=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[iWt]},$$scope:{ctx:$}}}),mx=new re({}),gx=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_tf_auto.py#L478"}}),px=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),RE=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[dWt]},$$scope:{ctx:$}}}),_x=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),XE=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[cWt]},$$scope:{ctx:$}}}),ux=new re({}),bx=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_tf_auto.py#L487"}}),Fx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),QE=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[fWt]},$$scope:{ctx:$}}}),Tx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),vC=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[mWt]},$$scope:{ctx:$}}}),Mx=new re({}),Ex=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_tf_auto.py#L523"}}),wx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),TC=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[gWt]},$$scope:{ctx:$}}}),Ax=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),jC=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[hWt]},$$scope:{ctx:$}}}),Lx=new re({}),yx=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_tf_auto.py#L530"}}),$x=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),GC=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[pWt]},$$scope:{ctx:$}}}),kx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),XC=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[_Wt]},$$scope:{ctx:$}}}),Rx=new re({}),Px=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_tf_auto.py#L503"}}),Ix=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),QC=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[uWt]},$$scope:{ctx:$}}}),Nx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),HC=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[bWt]},$$scope:{ctx:$}}}),qx=new re({}),jx=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_tf_auto.py#L514"}}),Gx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),JC=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[vWt]},$$scope:{ctx:$}}}),Ox=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),u3=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[FWt]},$$scope:{ctx:$}}}),Vx=new re({}),Xx=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_tf_auto.py#L496"}}),Qx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),v3=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[TWt]},$$scope:{ctx:$}}}),Wx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),D3=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[MWt]},$$scope:{ctx:$}}}),Hx=new re({}),Ux=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_tf_auto.py#L464"}}),Yx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),O3=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[EWt]},$$scope:{ctx:$}}}),Kx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),X3=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[CWt]},$$scope:{ctx:$}}}),Zx=new re({}),e$=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_tf_auto.py#L539"}}),r$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),Q3=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[wWt]},$$scope:{ctx:$}}}),t$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),H3=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[AWt]},$$scope:{ctx:$}}}),a$=new re({}),n$=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),l$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),J3=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[LWt]},$$scope:{ctx:$}}}),i$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),C5=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[yWt]},$$scope:{ctx:$}}}),d$=new re({}),c$=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),m$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),A5=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[xWt]},$$scope:{ctx:$}}}),g$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),N5=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[$Wt]},$$scope:{ctx:$}}}),h$=new re({}),p$=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),u$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),j5=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[kWt]},$$scope:{ctx:$}}}),b$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),Z5=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[SWt]},$$scope:{ctx:$}}}),v$=new re({}),F$=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),M$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),o0=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[RWt]},$$scope:{ctx:$}}}),E$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),m0=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[PWt]},$$scope:{ctx:$}}}),C$=new re({}),w$=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),L$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),h0=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[BWt]},$$scope:{ctx:$}}}),y$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),w0=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[IWt]},$$scope:{ctx:$}}}),x$=new re({}),$$=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),S$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),L0=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[NWt]},$$scope:{ctx:$}}}),R$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),q0=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[qWt]},$$scope:{ctx:$}}}),P$=new re({}),B$=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),N$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),D0=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[jWt]},$$scope:{ctx:$}}}),q$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),Y0=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[DWt]},$$scope:{ctx:$}}}),j$=new re({}),D$=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),O$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),Z0=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[GWt]},$$scope:{ctx:$}}}),V$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),iw=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[OWt]},$$scope:{ctx:$}}}),X$=new re({}),z$=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),W$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),cw=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[VWt]},$$scope:{ctx:$}}}),H$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),vw=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[XWt]},$$scope:{ctx:$}}}),U$=new re({}),J$=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),K$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),Tw=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[zWt]},$$scope:{ctx:$}}}),Z$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),Ew=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[QWt]},$$scope:{ctx:$}}}),ek=new re({}),ok=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),tk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17281/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),ww=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[WWt]},$$scope:{ctx:$}}}),ak=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),yw=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[HWt]},$$scope:{ctx:$}}}),sk=new re({}),lk=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),dk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17281/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17281/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L389"}}),$w=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[UWt]},$$scope:{ctx:$}}}),ck=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17281/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17281/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17281/src/transformers/models/auto/auto_factory.py#L417"}}),Sw=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[JWt]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),_=a("span"),F(d.$$.fragment),h=l(),Eo=a("span"),Ai=o("Auto Classes"),Rf=l(),st=a("p"),Li=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),yi=a("code"),Y6=o("from_pretrained()"),Pf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Oe=l(),Qe=a("p"),xi=o("Instantiating one of "),Rn=a("a"),K6=o("AutoConfig"),Pn=o(", "),Bn=a("a"),Z6=o("AutoModel"),$i=o(`, and
`),In=a("a"),eL=o("AutoTokenizer"),ki=o(" will directly create a class of the relevant architecture. For instance"),Bf=l(),F(ka.$$.fragment),We=l(),Ae=a("p"),kS=o("will create a model that is an instance of "),Si=a("a"),SS=o("BertModel"),RS=o("."),Co=l(),Sa=a("p"),PS=o("There is one class of "),If=a("code"),BS=o("AutoModel"),ZWe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),qVe=l(),Ri=a("h2"),Nf=a("a"),_ae=a("span"),F(oL.$$.fragment),eHe=l(),uae=a("span"),oHe=o("Extending the Auto Classes"),jVe=l(),Nn=a("p"),rHe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),bae=a("code"),tHe=o("NewModel"),aHe=o(", make sure you have a "),vae=a("code"),nHe=o("NewModelConfig"),sHe=o(` then you can add those to the auto
classes like this:`),DVe=l(),F(rL.$$.fragment),GVe=l(),IS=a("p"),lHe=o("You will then be able to use the auto classes like you would usually do!"),OVe=l(),F(qf.$$.fragment),VVe=l(),Pi=a("h2"),jf=a("a"),Fae=a("span"),F(tL.$$.fragment),iHe=l(),Tae=a("span"),dHe=o("AutoConfig"),XVe=l(),wo=a("div"),F(aL.$$.fragment),cHe=l(),nL=a("p"),fHe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),NS=a("a"),mHe=o("from_pretrained()"),gHe=o(" class method."),hHe=l(),sL=a("p"),pHe=o("This class cannot be instantiated directly using "),Mae=a("code"),_He=o("__init__()"),uHe=o(" (throws an error)."),bHe=l(),Ar=a("div"),F(lL.$$.fragment),vHe=l(),Eae=a("p"),FHe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),THe=l(),Bi=a("p"),MHe=o("The configuration class to instantiate is selected based on the "),Cae=a("code"),EHe=o("model_type"),CHe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),wae=a("code"),wHe=o("pretrained_model_name_or_path"),AHe=o(":"),LHe=l(),A=a("ul"),Df=a("li"),Aae=a("strong"),yHe=o("albert"),xHe=o(" \u2014 "),qS=a("a"),$He=o("AlbertConfig"),kHe=o(" (ALBERT model)"),SHe=l(),Gf=a("li"),Lae=a("strong"),RHe=o("bart"),PHe=o(" \u2014 "),jS=a("a"),BHe=o("BartConfig"),IHe=o(" (BART model)"),NHe=l(),Of=a("li"),yae=a("strong"),qHe=o("beit"),jHe=o(" \u2014 "),DS=a("a"),DHe=o("BeitConfig"),GHe=o(" (BEiT model)"),OHe=l(),Vf=a("li"),xae=a("strong"),VHe=o("bert"),XHe=o(" \u2014 "),GS=a("a"),zHe=o("BertConfig"),QHe=o(" (BERT model)"),WHe=l(),Xf=a("li"),$ae=a("strong"),HHe=o("bert-generation"),UHe=o(" \u2014 "),OS=a("a"),JHe=o("BertGenerationConfig"),YHe=o(" (Bert Generation model)"),KHe=l(),zf=a("li"),kae=a("strong"),ZHe=o("big_bird"),eUe=o(" \u2014 "),VS=a("a"),oUe=o("BigBirdConfig"),rUe=o(" (BigBird model)"),tUe=l(),Qf=a("li"),Sae=a("strong"),aUe=o("bigbird_pegasus"),nUe=o(" \u2014 "),XS=a("a"),sUe=o("BigBirdPegasusConfig"),lUe=o(" (BigBird-Pegasus model)"),iUe=l(),Wf=a("li"),Rae=a("strong"),dUe=o("blenderbot"),cUe=o(" \u2014 "),zS=a("a"),fUe=o("BlenderbotConfig"),mUe=o(" (Blenderbot model)"),gUe=l(),Hf=a("li"),Pae=a("strong"),hUe=o("blenderbot-small"),pUe=o(" \u2014 "),QS=a("a"),_Ue=o("BlenderbotSmallConfig"),uUe=o(" (BlenderbotSmall model)"),bUe=l(),Uf=a("li"),Bae=a("strong"),vUe=o("bloom"),FUe=o(" \u2014 "),WS=a("a"),TUe=o("BloomConfig"),MUe=o(" (BLOOM model)"),EUe=l(),Jf=a("li"),Iae=a("strong"),CUe=o("camembert"),wUe=o(" \u2014 "),HS=a("a"),AUe=o("CamembertConfig"),LUe=o(" (CamemBERT model)"),yUe=l(),Yf=a("li"),Nae=a("strong"),xUe=o("canine"),$Ue=o(" \u2014 "),US=a("a"),kUe=o("CanineConfig"),SUe=o(" (CANINE model)"),RUe=l(),Kf=a("li"),qae=a("strong"),PUe=o("clip"),BUe=o(" \u2014 "),JS=a("a"),IUe=o("CLIPConfig"),NUe=o(" (CLIP model)"),qUe=l(),Zf=a("li"),jae=a("strong"),jUe=o("codegen"),DUe=o(" \u2014 "),YS=a("a"),GUe=o("CodeGenConfig"),OUe=o(" (CodeGen model)"),VUe=l(),em=a("li"),Dae=a("strong"),XUe=o("convbert"),zUe=o(" \u2014 "),KS=a("a"),QUe=o("ConvBertConfig"),WUe=o(" (ConvBERT model)"),HUe=l(),om=a("li"),Gae=a("strong"),UUe=o("convnext"),JUe=o(" \u2014 "),ZS=a("a"),YUe=o("ConvNextConfig"),KUe=o(" (ConvNeXT model)"),ZUe=l(),rm=a("li"),Oae=a("strong"),eJe=o("ctrl"),oJe=o(" \u2014 "),eR=a("a"),rJe=o("CTRLConfig"),tJe=o(" (CTRL model)"),aJe=l(),tm=a("li"),Vae=a("strong"),nJe=o("cvt"),sJe=o(" \u2014 "),oR=a("a"),lJe=o("CvtConfig"),iJe=o(" (CvT model)"),dJe=l(),am=a("li"),Xae=a("strong"),cJe=o("data2vec-audio"),fJe=o(" \u2014 "),rR=a("a"),mJe=o("Data2VecAudioConfig"),gJe=o(" (Data2VecAudio model)"),hJe=l(),nm=a("li"),zae=a("strong"),pJe=o("data2vec-text"),_Je=o(" \u2014 "),tR=a("a"),uJe=o("Data2VecTextConfig"),bJe=o(" (Data2VecText model)"),vJe=l(),sm=a("li"),Qae=a("strong"),FJe=o("data2vec-vision"),TJe=o(" \u2014 "),aR=a("a"),MJe=o("Data2VecVisionConfig"),EJe=o(" (Data2VecVision model)"),CJe=l(),lm=a("li"),Wae=a("strong"),wJe=o("deberta"),AJe=o(" \u2014 "),nR=a("a"),LJe=o("DebertaConfig"),yJe=o(" (DeBERTa model)"),xJe=l(),im=a("li"),Hae=a("strong"),$Je=o("deberta-v2"),kJe=o(" \u2014 "),sR=a("a"),SJe=o("DebertaV2Config"),RJe=o(" (DeBERTa-v2 model)"),PJe=l(),dm=a("li"),Uae=a("strong"),BJe=o("decision_transformer"),IJe=o(" \u2014 "),lR=a("a"),NJe=o("DecisionTransformerConfig"),qJe=o(" (Decision Transformer model)"),jJe=l(),cm=a("li"),Jae=a("strong"),DJe=o("deformable_detr"),GJe=o(" \u2014 "),iR=a("a"),OJe=o("DeformableDetrConfig"),VJe=o(" (Deformable DETR model)"),XJe=l(),fm=a("li"),Yae=a("strong"),zJe=o("deit"),QJe=o(" \u2014 "),dR=a("a"),WJe=o("DeiTConfig"),HJe=o(" (DeiT model)"),UJe=l(),mm=a("li"),Kae=a("strong"),JJe=o("detr"),YJe=o(" \u2014 "),cR=a("a"),KJe=o("DetrConfig"),ZJe=o(" (DETR model)"),eYe=l(),gm=a("li"),Zae=a("strong"),oYe=o("distilbert"),rYe=o(" \u2014 "),fR=a("a"),tYe=o("DistilBertConfig"),aYe=o(" (DistilBERT model)"),nYe=l(),hm=a("li"),ene=a("strong"),sYe=o("dpr"),lYe=o(" \u2014 "),mR=a("a"),iYe=o("DPRConfig"),dYe=o(" (DPR model)"),cYe=l(),pm=a("li"),one=a("strong"),fYe=o("dpt"),mYe=o(" \u2014 "),gR=a("a"),gYe=o("DPTConfig"),hYe=o(" (DPT model)"),pYe=l(),_m=a("li"),rne=a("strong"),_Ye=o("electra"),uYe=o(" \u2014 "),hR=a("a"),bYe=o("ElectraConfig"),vYe=o(" (ELECTRA model)"),FYe=l(),um=a("li"),tne=a("strong"),TYe=o("encoder-decoder"),MYe=o(" \u2014 "),pR=a("a"),EYe=o("EncoderDecoderConfig"),CYe=o(" (Encoder decoder model)"),wYe=l(),bm=a("li"),ane=a("strong"),AYe=o("flaubert"),LYe=o(" \u2014 "),_R=a("a"),yYe=o("FlaubertConfig"),xYe=o(" (FlauBERT model)"),$Ye=l(),vm=a("li"),nne=a("strong"),kYe=o("flava"),SYe=o(" \u2014 "),uR=a("a"),RYe=o("FlavaConfig"),PYe=o(" (FLAVA model)"),BYe=l(),Fm=a("li"),sne=a("strong"),IYe=o("fnet"),NYe=o(" \u2014 "),bR=a("a"),qYe=o("FNetConfig"),jYe=o(" (FNet model)"),DYe=l(),Tm=a("li"),lne=a("strong"),GYe=o("fsmt"),OYe=o(" \u2014 "),vR=a("a"),VYe=o("FSMTConfig"),XYe=o(" (FairSeq Machine-Translation model)"),zYe=l(),Mm=a("li"),ine=a("strong"),QYe=o("funnel"),WYe=o(" \u2014 "),FR=a("a"),HYe=o("FunnelConfig"),UYe=o(" (Funnel Transformer model)"),JYe=l(),Em=a("li"),dne=a("strong"),YYe=o("glpn"),KYe=o(" \u2014 "),TR=a("a"),ZYe=o("GLPNConfig"),eKe=o(" (GLPN model)"),oKe=l(),Cm=a("li"),cne=a("strong"),rKe=o("gpt2"),tKe=o(" \u2014 "),MR=a("a"),aKe=o("GPT2Config"),nKe=o(" (OpenAI GPT-2 model)"),sKe=l(),wm=a("li"),fne=a("strong"),lKe=o("gpt_neo"),iKe=o(" \u2014 "),ER=a("a"),dKe=o("GPTNeoConfig"),cKe=o(" (GPT Neo model)"),fKe=l(),Am=a("li"),mne=a("strong"),mKe=o("gpt_neox"),gKe=o(" \u2014 "),CR=a("a"),hKe=o("GPTNeoXConfig"),pKe=o(" (GPT NeoX model)"),_Ke=l(),Lm=a("li"),gne=a("strong"),uKe=o("gptj"),bKe=o(" \u2014 "),wR=a("a"),vKe=o("GPTJConfig"),FKe=o(" (GPT-J model)"),TKe=l(),ym=a("li"),hne=a("strong"),MKe=o("groupvit"),EKe=o(" \u2014 "),AR=a("a"),CKe=o("GroupViTConfig"),wKe=o(" (GroupViT model)"),AKe=l(),xm=a("li"),pne=a("strong"),LKe=o("hubert"),yKe=o(" \u2014 "),LR=a("a"),xKe=o("HubertConfig"),$Ke=o(" (Hubert model)"),kKe=l(),$m=a("li"),_ne=a("strong"),SKe=o("ibert"),RKe=o(" \u2014 "),yR=a("a"),PKe=o("IBertConfig"),BKe=o(" (I-BERT model)"),IKe=l(),km=a("li"),une=a("strong"),NKe=o("imagegpt"),qKe=o(" \u2014 "),xR=a("a"),jKe=o("ImageGPTConfig"),DKe=o(" (ImageGPT model)"),GKe=l(),Sm=a("li"),bne=a("strong"),OKe=o("layoutlm"),VKe=o(" \u2014 "),$R=a("a"),XKe=o("LayoutLMConfig"),zKe=o(" (LayoutLM model)"),QKe=l(),Rm=a("li"),vne=a("strong"),WKe=o("layoutlmv2"),HKe=o(" \u2014 "),kR=a("a"),UKe=o("LayoutLMv2Config"),JKe=o(" (LayoutLMv2 model)"),YKe=l(),Pm=a("li"),Fne=a("strong"),KKe=o("layoutlmv3"),ZKe=o(" \u2014 "),SR=a("a"),eZe=o("LayoutLMv3Config"),oZe=o(" (LayoutLMv3 model)"),rZe=l(),Bm=a("li"),Tne=a("strong"),tZe=o("led"),aZe=o(" \u2014 "),RR=a("a"),nZe=o("LEDConfig"),sZe=o(" (LED model)"),lZe=l(),Im=a("li"),Mne=a("strong"),iZe=o("levit"),dZe=o(" \u2014 "),PR=a("a"),cZe=o("LevitConfig"),fZe=o(" (LeViT model)"),mZe=l(),Nm=a("li"),Ene=a("strong"),gZe=o("longformer"),hZe=o(" \u2014 "),BR=a("a"),pZe=o("LongformerConfig"),_Ze=o(" (Longformer model)"),uZe=l(),qm=a("li"),Cne=a("strong"),bZe=o("longt5"),vZe=o(" \u2014 "),IR=a("a"),FZe=o("LongT5Config"),TZe=o(" (LongT5 model)"),MZe=l(),jm=a("li"),wne=a("strong"),EZe=o("luke"),CZe=o(" \u2014 "),NR=a("a"),wZe=o("LukeConfig"),AZe=o(" (LUKE model)"),LZe=l(),Dm=a("li"),Ane=a("strong"),yZe=o("lxmert"),xZe=o(" \u2014 "),qR=a("a"),$Ze=o("LxmertConfig"),kZe=o(" (LXMERT model)"),SZe=l(),Gm=a("li"),Lne=a("strong"),RZe=o("m2m_100"),PZe=o(" \u2014 "),jR=a("a"),BZe=o("M2M100Config"),IZe=o(" (M2M100 model)"),NZe=l(),Om=a("li"),yne=a("strong"),qZe=o("marian"),jZe=o(" \u2014 "),DR=a("a"),DZe=o("MarianConfig"),GZe=o(" (Marian model)"),OZe=l(),Vm=a("li"),xne=a("strong"),VZe=o("maskformer"),XZe=o(" \u2014 "),GR=a("a"),zZe=o("MaskFormerConfig"),QZe=o(" (MaskFormer model)"),WZe=l(),Xm=a("li"),$ne=a("strong"),HZe=o("mbart"),UZe=o(" \u2014 "),OR=a("a"),JZe=o("MBartConfig"),YZe=o(" (mBART model)"),KZe=l(),zm=a("li"),kne=a("strong"),ZZe=o("mctct"),eeo=o(" \u2014 "),VR=a("a"),oeo=o("MCTCTConfig"),reo=o(" (M-CTC-T model)"),teo=l(),Qm=a("li"),Sne=a("strong"),aeo=o("megatron-bert"),neo=o(" \u2014 "),XR=a("a"),seo=o("MegatronBertConfig"),leo=o(" (Megatron-BERT model)"),ieo=l(),Wm=a("li"),Rne=a("strong"),deo=o("mobilebert"),ceo=o(" \u2014 "),zR=a("a"),feo=o("MobileBertConfig"),meo=o(" (MobileBERT model)"),geo=l(),Hm=a("li"),Pne=a("strong"),heo=o("mobilevit"),peo=o(" \u2014 "),QR=a("a"),_eo=o("MobileViTConfig"),ueo=o(" (MobileViT model)"),beo=l(),Um=a("li"),Bne=a("strong"),veo=o("mpnet"),Feo=o(" \u2014 "),WR=a("a"),Teo=o("MPNetConfig"),Meo=o(" (MPNet model)"),Eeo=l(),Jm=a("li"),Ine=a("strong"),Ceo=o("mt5"),weo=o(" \u2014 "),HR=a("a"),Aeo=o("MT5Config"),Leo=o(" (MT5 model)"),yeo=l(),Ym=a("li"),Nne=a("strong"),xeo=o("mvp"),$eo=o(" \u2014 "),UR=a("a"),keo=o("MvpConfig"),Seo=o(" (MVP model)"),Reo=l(),Km=a("li"),qne=a("strong"),Peo=o("nezha"),Beo=o(" \u2014 "),JR=a("a"),Ieo=o("NezhaConfig"),Neo=o(" (Nezha model)"),qeo=l(),Zm=a("li"),jne=a("strong"),jeo=o("nystromformer"),Deo=o(" \u2014 "),YR=a("a"),Geo=o("NystromformerConfig"),Oeo=o(" (Nystr\xF6mformer model)"),Veo=l(),eg=a("li"),Dne=a("strong"),Xeo=o("openai-gpt"),zeo=o(" \u2014 "),KR=a("a"),Qeo=o("OpenAIGPTConfig"),Weo=o(" (OpenAI GPT model)"),Heo=l(),og=a("li"),Gne=a("strong"),Ueo=o("opt"),Jeo=o(" \u2014 "),ZR=a("a"),Yeo=o("OPTConfig"),Keo=o(" (OPT model)"),Zeo=l(),rg=a("li"),One=a("strong"),eoo=o("pegasus"),ooo=o(" \u2014 "),eP=a("a"),roo=o("PegasusConfig"),too=o(" (Pegasus model)"),aoo=l(),tg=a("li"),Vne=a("strong"),noo=o("perceiver"),soo=o(" \u2014 "),oP=a("a"),loo=o("PerceiverConfig"),ioo=o(" (Perceiver model)"),doo=l(),ag=a("li"),Xne=a("strong"),coo=o("plbart"),foo=o(" \u2014 "),rP=a("a"),moo=o("PLBartConfig"),goo=o(" (PLBart model)"),hoo=l(),ng=a("li"),zne=a("strong"),poo=o("poolformer"),_oo=o(" \u2014 "),tP=a("a"),uoo=o("PoolFormerConfig"),boo=o(" (PoolFormer model)"),voo=l(),sg=a("li"),Qne=a("strong"),Foo=o("prophetnet"),Too=o(" \u2014 "),aP=a("a"),Moo=o("ProphetNetConfig"),Eoo=o(" (ProphetNet model)"),Coo=l(),lg=a("li"),Wne=a("strong"),woo=o("qdqbert"),Aoo=o(" \u2014 "),nP=a("a"),Loo=o("QDQBertConfig"),yoo=o(" (QDQBert model)"),xoo=l(),ig=a("li"),Hne=a("strong"),$oo=o("rag"),koo=o(" \u2014 "),sP=a("a"),Soo=o("RagConfig"),Roo=o(" (RAG model)"),Poo=l(),dg=a("li"),Une=a("strong"),Boo=o("realm"),Ioo=o(" \u2014 "),lP=a("a"),Noo=o("RealmConfig"),qoo=o(" (REALM model)"),joo=l(),cg=a("li"),Jne=a("strong"),Doo=o("reformer"),Goo=o(" \u2014 "),iP=a("a"),Ooo=o("ReformerConfig"),Voo=o(" (Reformer model)"),Xoo=l(),fg=a("li"),Yne=a("strong"),zoo=o("regnet"),Qoo=o(" \u2014 "),dP=a("a"),Woo=o("RegNetConfig"),Hoo=o(" (RegNet model)"),Uoo=l(),mg=a("li"),Kne=a("strong"),Joo=o("rembert"),Yoo=o(" \u2014 "),cP=a("a"),Koo=o("RemBertConfig"),Zoo=o(" (RemBERT model)"),ero=l(),gg=a("li"),Zne=a("strong"),oro=o("resnet"),rro=o(" \u2014 "),fP=a("a"),tro=o("ResNetConfig"),aro=o(" (ResNet model)"),nro=l(),hg=a("li"),ese=a("strong"),sro=o("retribert"),lro=o(" \u2014 "),mP=a("a"),iro=o("RetriBertConfig"),dro=o(" (RetriBERT model)"),cro=l(),pg=a("li"),ose=a("strong"),fro=o("roberta"),mro=o(" \u2014 "),gP=a("a"),gro=o("RobertaConfig"),hro=o(" (RoBERTa model)"),pro=l(),_g=a("li"),rse=a("strong"),_ro=o("roformer"),uro=o(" \u2014 "),hP=a("a"),bro=o("RoFormerConfig"),vro=o(" (RoFormer model)"),Fro=l(),ug=a("li"),tse=a("strong"),Tro=o("segformer"),Mro=o(" \u2014 "),pP=a("a"),Ero=o("SegformerConfig"),Cro=o(" (SegFormer model)"),wro=l(),bg=a("li"),ase=a("strong"),Aro=o("sew"),Lro=o(" \u2014 "),_P=a("a"),yro=o("SEWConfig"),xro=o(" (SEW model)"),$ro=l(),vg=a("li"),nse=a("strong"),kro=o("sew-d"),Sro=o(" \u2014 "),uP=a("a"),Rro=o("SEWDConfig"),Pro=o(" (SEW-D model)"),Bro=l(),Fg=a("li"),sse=a("strong"),Iro=o("speech-encoder-decoder"),Nro=o(" \u2014 "),bP=a("a"),qro=o("SpeechEncoderDecoderConfig"),jro=o(" (Speech Encoder decoder model)"),Dro=l(),Tg=a("li"),lse=a("strong"),Gro=o("speech_to_text"),Oro=o(" \u2014 "),vP=a("a"),Vro=o("Speech2TextConfig"),Xro=o(" (Speech2Text model)"),zro=l(),Mg=a("li"),ise=a("strong"),Qro=o("speech_to_text_2"),Wro=o(" \u2014 "),FP=a("a"),Hro=o("Speech2Text2Config"),Uro=o(" (Speech2Text2 model)"),Jro=l(),Eg=a("li"),dse=a("strong"),Yro=o("splinter"),Kro=o(" \u2014 "),TP=a("a"),Zro=o("SplinterConfig"),eto=o(" (Splinter model)"),oto=l(),Cg=a("li"),cse=a("strong"),rto=o("squeezebert"),tto=o(" \u2014 "),MP=a("a"),ato=o("SqueezeBertConfig"),nto=o(" (SqueezeBERT model)"),sto=l(),wg=a("li"),fse=a("strong"),lto=o("swin"),ito=o(" \u2014 "),EP=a("a"),dto=o("SwinConfig"),cto=o(" (Swin Transformer model)"),fto=l(),Ag=a("li"),mse=a("strong"),mto=o("t5"),gto=o(" \u2014 "),CP=a("a"),hto=o("T5Config"),pto=o(" (T5 model)"),_to=l(),Lg=a("li"),gse=a("strong"),uto=o("tapas"),bto=o(" \u2014 "),wP=a("a"),vto=o("TapasConfig"),Fto=o(" (TAPAS model)"),Tto=l(),yg=a("li"),hse=a("strong"),Mto=o("trajectory_transformer"),Eto=o(" \u2014 "),AP=a("a"),Cto=o("TrajectoryTransformerConfig"),wto=o(" (Trajectory Transformer model)"),Ato=l(),xg=a("li"),pse=a("strong"),Lto=o("transfo-xl"),yto=o(" \u2014 "),LP=a("a"),xto=o("TransfoXLConfig"),$to=o(" (Transformer-XL model)"),kto=l(),$g=a("li"),_se=a("strong"),Sto=o("trocr"),Rto=o(" \u2014 "),yP=a("a"),Pto=o("TrOCRConfig"),Bto=o(" (TrOCR model)"),Ito=l(),kg=a("li"),use=a("strong"),Nto=o("unispeech"),qto=o(" \u2014 "),xP=a("a"),jto=o("UniSpeechConfig"),Dto=o(" (UniSpeech model)"),Gto=l(),Sg=a("li"),bse=a("strong"),Oto=o("unispeech-sat"),Vto=o(" \u2014 "),$P=a("a"),Xto=o("UniSpeechSatConfig"),zto=o(" (UniSpeechSat model)"),Qto=l(),Rg=a("li"),vse=a("strong"),Wto=o("van"),Hto=o(" \u2014 "),kP=a("a"),Uto=o("VanConfig"),Jto=o(" (VAN model)"),Yto=l(),Pg=a("li"),Fse=a("strong"),Kto=o("vilt"),Zto=o(" \u2014 "),SP=a("a"),eao=o("ViltConfig"),oao=o(" (ViLT model)"),rao=l(),Bg=a("li"),Tse=a("strong"),tao=o("vision-encoder-decoder"),aao=o(" \u2014 "),RP=a("a"),nao=o("VisionEncoderDecoderConfig"),sao=o(" (Vision Encoder decoder model)"),lao=l(),Ig=a("li"),Mse=a("strong"),iao=o("vision-text-dual-encoder"),dao=o(" \u2014 "),PP=a("a"),cao=o("VisionTextDualEncoderConfig"),fao=o(" (VisionTextDualEncoder model)"),mao=l(),Ng=a("li"),Ese=a("strong"),gao=o("visual_bert"),hao=o(" \u2014 "),BP=a("a"),pao=o("VisualBertConfig"),_ao=o(" (VisualBERT model)"),uao=l(),qg=a("li"),Cse=a("strong"),bao=o("vit"),vao=o(" \u2014 "),IP=a("a"),Fao=o("ViTConfig"),Tao=o(" (ViT model)"),Mao=l(),jg=a("li"),wse=a("strong"),Eao=o("vit_mae"),Cao=o(" \u2014 "),NP=a("a"),wao=o("ViTMAEConfig"),Aao=o(" (ViTMAE model)"),Lao=l(),Dg=a("li"),Ase=a("strong"),yao=o("wav2vec2"),xao=o(" \u2014 "),qP=a("a"),$ao=o("Wav2Vec2Config"),kao=o(" (Wav2Vec2 model)"),Sao=l(),Gg=a("li"),Lse=a("strong"),Rao=o("wav2vec2-conformer"),Pao=o(" \u2014 "),jP=a("a"),Bao=o("Wav2Vec2ConformerConfig"),Iao=o(" (Wav2Vec2-Conformer model)"),Nao=l(),Og=a("li"),yse=a("strong"),qao=o("wavlm"),jao=o(" \u2014 "),DP=a("a"),Dao=o("WavLMConfig"),Gao=o(" (WavLM model)"),Oao=l(),Vg=a("li"),xse=a("strong"),Vao=o("xglm"),Xao=o(" \u2014 "),GP=a("a"),zao=o("XGLMConfig"),Qao=o(" (XGLM model)"),Wao=l(),Xg=a("li"),$se=a("strong"),Hao=o("xlm"),Uao=o(" \u2014 "),OP=a("a"),Jao=o("XLMConfig"),Yao=o(" (XLM model)"),Kao=l(),zg=a("li"),kse=a("strong"),Zao=o("xlm-prophetnet"),eno=o(" \u2014 "),VP=a("a"),ono=o("XLMProphetNetConfig"),rno=o(" (XLM-ProphetNet model)"),tno=l(),Qg=a("li"),Sse=a("strong"),ano=o("xlm-roberta"),nno=o(" \u2014 "),XP=a("a"),sno=o("XLMRobertaConfig"),lno=o(" (XLM-RoBERTa model)"),ino=l(),Wg=a("li"),Rse=a("strong"),dno=o("xlm-roberta-xl"),cno=o(" \u2014 "),zP=a("a"),fno=o("XLMRobertaXLConfig"),mno=o(" (XLM-RoBERTa-XL model)"),gno=l(),Hg=a("li"),Pse=a("strong"),hno=o("xlnet"),pno=o(" \u2014 "),QP=a("a"),_no=o("XLNetConfig"),uno=o(" (XLNet model)"),bno=l(),Ug=a("li"),Bse=a("strong"),vno=o("yolos"),Fno=o(" \u2014 "),WP=a("a"),Tno=o("YolosConfig"),Mno=o(" (YOLOS model)"),Eno=l(),Jg=a("li"),Ise=a("strong"),Cno=o("yoso"),wno=o(" \u2014 "),HP=a("a"),Ano=o("YosoConfig"),Lno=o(" (YOSO model)"),yno=l(),F(Yg.$$.fragment),xno=l(),Kg=a("div"),F(iL.$$.fragment),$no=l(),Nse=a("p"),kno=o("Register a new configuration for this class."),zVe=l(),Ii=a("h2"),Zg=a("a"),qse=a("span"),F(dL.$$.fragment),Sno=l(),jse=a("span"),Rno=o("AutoTokenizer"),QVe=l(),Ao=a("div"),F(cL.$$.fragment),Pno=l(),fL=a("p"),Bno=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),UP=a("a"),Ino=o("AutoTokenizer.from_pretrained()"),Nno=o(" class method."),qno=l(),mL=a("p"),jno=o("This class cannot be instantiated directly using "),Dse=a("code"),Dno=o("__init__()"),Gno=o(" (throws an error)."),Ono=l(),Lr=a("div"),F(gL.$$.fragment),Vno=l(),Gse=a("p"),Xno=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),zno=l(),Ra=a("p"),Qno=o("The tokenizer class to instantiate is selected based on the "),Ose=a("code"),Wno=o("model_type"),Hno=o(` property of the config object (either
passed as an argument or loaded from `),Vse=a("code"),Uno=o("pretrained_model_name_or_path"),Jno=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xse=a("code"),Yno=o("pretrained_model_name_or_path"),Kno=o(":"),Zno=l(),k=a("ul"),qn=a("li"),zse=a("strong"),eso=o("albert"),oso=o(" \u2014 "),JP=a("a"),rso=o("AlbertTokenizer"),tso=o(" or "),YP=a("a"),aso=o("AlbertTokenizerFast"),nso=o(" (ALBERT model)"),sso=l(),jn=a("li"),Qse=a("strong"),lso=o("bart"),iso=o(" \u2014 "),KP=a("a"),dso=o("BartTokenizer"),cso=o(" or "),ZP=a("a"),fso=o("BartTokenizerFast"),mso=o(" (BART model)"),gso=l(),Dn=a("li"),Wse=a("strong"),hso=o("barthez"),pso=o(" \u2014 "),eB=a("a"),_so=o("BarthezTokenizer"),uso=o(" or "),oB=a("a"),bso=o("BarthezTokenizerFast"),vso=o(" (BARThez model)"),Fso=l(),eh=a("li"),Hse=a("strong"),Tso=o("bartpho"),Mso=o(" \u2014 "),rB=a("a"),Eso=o("BartphoTokenizer"),Cso=o(" (BARTpho model)"),wso=l(),Gn=a("li"),Use=a("strong"),Aso=o("bert"),Lso=o(" \u2014 "),tB=a("a"),yso=o("BertTokenizer"),xso=o(" or "),aB=a("a"),$so=o("BertTokenizerFast"),kso=o(" (BERT model)"),Sso=l(),oh=a("li"),Jse=a("strong"),Rso=o("bert-generation"),Pso=o(" \u2014 "),nB=a("a"),Bso=o("BertGenerationTokenizer"),Iso=o(" (Bert Generation model)"),Nso=l(),rh=a("li"),Yse=a("strong"),qso=o("bert-japanese"),jso=o(" \u2014 "),sB=a("a"),Dso=o("BertJapaneseTokenizer"),Gso=o(" (BertJapanese model)"),Oso=l(),th=a("li"),Kse=a("strong"),Vso=o("bertweet"),Xso=o(" \u2014 "),lB=a("a"),zso=o("BertweetTokenizer"),Qso=o(" (BERTweet model)"),Wso=l(),On=a("li"),Zse=a("strong"),Hso=o("big_bird"),Uso=o(" \u2014 "),iB=a("a"),Jso=o("BigBirdTokenizer"),Yso=o(" or "),dB=a("a"),Kso=o("BigBirdTokenizerFast"),Zso=o(" (BigBird model)"),elo=l(),Vn=a("li"),ele=a("strong"),olo=o("bigbird_pegasus"),rlo=o(" \u2014 "),cB=a("a"),tlo=o("PegasusTokenizer"),alo=o(" or "),fB=a("a"),nlo=o("PegasusTokenizerFast"),slo=o(" (BigBird-Pegasus model)"),llo=l(),Xn=a("li"),ole=a("strong"),ilo=o("blenderbot"),dlo=o(" \u2014 "),mB=a("a"),clo=o("BlenderbotTokenizer"),flo=o(" or "),gB=a("a"),mlo=o("BlenderbotTokenizerFast"),glo=o(" (Blenderbot model)"),hlo=l(),ah=a("li"),rle=a("strong"),plo=o("blenderbot-small"),_lo=o(" \u2014 "),hB=a("a"),ulo=o("BlenderbotSmallTokenizer"),blo=o(" (BlenderbotSmall model)"),vlo=l(),nh=a("li"),tle=a("strong"),Flo=o("bloom"),Tlo=o(" \u2014 "),pB=a("a"),Mlo=o("BloomTokenizerFast"),Elo=o(" (BLOOM model)"),Clo=l(),sh=a("li"),ale=a("strong"),wlo=o("byt5"),Alo=o(" \u2014 "),_B=a("a"),Llo=o("ByT5Tokenizer"),ylo=o(" (ByT5 model)"),xlo=l(),zn=a("li"),nle=a("strong"),$lo=o("camembert"),klo=o(" \u2014 "),uB=a("a"),Slo=o("CamembertTokenizer"),Rlo=o(" or "),bB=a("a"),Plo=o("CamembertTokenizerFast"),Blo=o(" (CamemBERT model)"),Ilo=l(),lh=a("li"),sle=a("strong"),Nlo=o("canine"),qlo=o(" \u2014 "),vB=a("a"),jlo=o("CanineTokenizer"),Dlo=o(" (CANINE model)"),Glo=l(),Qn=a("li"),lle=a("strong"),Olo=o("clip"),Vlo=o(" \u2014 "),FB=a("a"),Xlo=o("CLIPTokenizer"),zlo=o(" or "),TB=a("a"),Qlo=o("CLIPTokenizerFast"),Wlo=o(" (CLIP model)"),Hlo=l(),Wn=a("li"),ile=a("strong"),Ulo=o("codegen"),Jlo=o(" \u2014 "),MB=a("a"),Ylo=o("CodeGenTokenizer"),Klo=o(" or "),EB=a("a"),Zlo=o("CodeGenTokenizerFast"),eio=o(" (CodeGen model)"),oio=l(),Hn=a("li"),dle=a("strong"),rio=o("convbert"),tio=o(" \u2014 "),CB=a("a"),aio=o("ConvBertTokenizer"),nio=o(" or "),wB=a("a"),sio=o("ConvBertTokenizerFast"),lio=o(" (ConvBERT model)"),iio=l(),Un=a("li"),cle=a("strong"),dio=o("cpm"),cio=o(" \u2014 "),AB=a("a"),fio=o("CpmTokenizer"),mio=o(" or "),LB=a("a"),gio=o("CpmTokenizerFast"),hio=o(" (CPM model)"),pio=l(),ih=a("li"),fle=a("strong"),_io=o("ctrl"),uio=o(" \u2014 "),yB=a("a"),bio=o("CTRLTokenizer"),vio=o(" (CTRL model)"),Fio=l(),Jn=a("li"),mle=a("strong"),Tio=o("data2vec-text"),Mio=o(" \u2014 "),xB=a("a"),Eio=o("RobertaTokenizer"),Cio=o(" or "),$B=a("a"),wio=o("RobertaTokenizerFast"),Aio=o(" (Data2VecText model)"),Lio=l(),Yn=a("li"),gle=a("strong"),yio=o("deberta"),xio=o(" \u2014 "),kB=a("a"),$io=o("DebertaTokenizer"),kio=o(" or "),SB=a("a"),Sio=o("DebertaTokenizerFast"),Rio=o(" (DeBERTa model)"),Pio=l(),Kn=a("li"),hle=a("strong"),Bio=o("deberta-v2"),Iio=o(" \u2014 "),RB=a("a"),Nio=o("DebertaV2Tokenizer"),qio=o(" or "),PB=a("a"),jio=o("DebertaV2TokenizerFast"),Dio=o(" (DeBERTa-v2 model)"),Gio=l(),Zn=a("li"),ple=a("strong"),Oio=o("distilbert"),Vio=o(" \u2014 "),BB=a("a"),Xio=o("DistilBertTokenizer"),zio=o(" or "),IB=a("a"),Qio=o("DistilBertTokenizerFast"),Wio=o(" (DistilBERT model)"),Hio=l(),es=a("li"),_le=a("strong"),Uio=o("dpr"),Jio=o(" \u2014 "),NB=a("a"),Yio=o("DPRQuestionEncoderTokenizer"),Kio=o(" or "),qB=a("a"),Zio=o("DPRQuestionEncoderTokenizerFast"),edo=o(" (DPR model)"),odo=l(),os=a("li"),ule=a("strong"),rdo=o("electra"),tdo=o(" \u2014 "),jB=a("a"),ado=o("ElectraTokenizer"),ndo=o(" or "),DB=a("a"),sdo=o("ElectraTokenizerFast"),ldo=o(" (ELECTRA model)"),ido=l(),dh=a("li"),ble=a("strong"),ddo=o("flaubert"),cdo=o(" \u2014 "),GB=a("a"),fdo=o("FlaubertTokenizer"),mdo=o(" (FlauBERT model)"),gdo=l(),rs=a("li"),vle=a("strong"),hdo=o("fnet"),pdo=o(" \u2014 "),OB=a("a"),_do=o("FNetTokenizer"),udo=o(" or "),VB=a("a"),bdo=o("FNetTokenizerFast"),vdo=o(" (FNet model)"),Fdo=l(),ch=a("li"),Fle=a("strong"),Tdo=o("fsmt"),Mdo=o(" \u2014 "),XB=a("a"),Edo=o("FSMTTokenizer"),Cdo=o(" (FairSeq Machine-Translation model)"),wdo=l(),ts=a("li"),Tle=a("strong"),Ado=o("funnel"),Ldo=o(" \u2014 "),zB=a("a"),ydo=o("FunnelTokenizer"),xdo=o(" or "),QB=a("a"),$do=o("FunnelTokenizerFast"),kdo=o(" (Funnel Transformer model)"),Sdo=l(),as=a("li"),Mle=a("strong"),Rdo=o("gpt2"),Pdo=o(" \u2014 "),WB=a("a"),Bdo=o("GPT2Tokenizer"),Ido=o(" or "),HB=a("a"),Ndo=o("GPT2TokenizerFast"),qdo=o(" (OpenAI GPT-2 model)"),jdo=l(),ns=a("li"),Ele=a("strong"),Ddo=o("gpt_neo"),Gdo=o(" \u2014 "),UB=a("a"),Odo=o("GPT2Tokenizer"),Vdo=o(" or "),JB=a("a"),Xdo=o("GPT2TokenizerFast"),zdo=o(" (GPT Neo model)"),Qdo=l(),fh=a("li"),Cle=a("strong"),Wdo=o("gpt_neox"),Hdo=o(" \u2014 "),YB=a("a"),Udo=o("GPTNeoXTokenizerFast"),Jdo=o(" (GPT NeoX model)"),Ydo=l(),ss=a("li"),wle=a("strong"),Kdo=o("gptj"),Zdo=o(" \u2014 "),KB=a("a"),eco=o("GPT2Tokenizer"),oco=o(" or "),ZB=a("a"),rco=o("GPT2TokenizerFast"),tco=o(" (GPT-J model)"),aco=l(),ls=a("li"),Ale=a("strong"),nco=o("groupvit"),sco=o(" \u2014 "),eI=a("a"),lco=o("CLIPTokenizer"),ico=o(" or "),oI=a("a"),dco=o("CLIPTokenizerFast"),cco=o(" (GroupViT model)"),fco=l(),is=a("li"),Lle=a("strong"),mco=o("herbert"),gco=o(" \u2014 "),rI=a("a"),hco=o("HerbertTokenizer"),pco=o(" or "),tI=a("a"),_co=o("HerbertTokenizerFast"),uco=o(" (HerBERT model)"),bco=l(),mh=a("li"),yle=a("strong"),vco=o("hubert"),Fco=o(" \u2014 "),aI=a("a"),Tco=o("Wav2Vec2CTCTokenizer"),Mco=o(" (Hubert model)"),Eco=l(),ds=a("li"),xle=a("strong"),Cco=o("ibert"),wco=o(" \u2014 "),nI=a("a"),Aco=o("RobertaTokenizer"),Lco=o(" or "),sI=a("a"),yco=o("RobertaTokenizerFast"),xco=o(" (I-BERT model)"),$co=l(),cs=a("li"),$le=a("strong"),kco=o("layoutlm"),Sco=o(" \u2014 "),lI=a("a"),Rco=o("LayoutLMTokenizer"),Pco=o(" or "),iI=a("a"),Bco=o("LayoutLMTokenizerFast"),Ico=o(" (LayoutLM model)"),Nco=l(),fs=a("li"),kle=a("strong"),qco=o("layoutlmv2"),jco=o(" \u2014 "),dI=a("a"),Dco=o("LayoutLMv2Tokenizer"),Gco=o(" or "),cI=a("a"),Oco=o("LayoutLMv2TokenizerFast"),Vco=o(" (LayoutLMv2 model)"),Xco=l(),ms=a("li"),Sle=a("strong"),zco=o("layoutlmv3"),Qco=o(" \u2014 "),fI=a("a"),Wco=o("LayoutLMv3Tokenizer"),Hco=o(" or "),mI=a("a"),Uco=o("LayoutLMv3TokenizerFast"),Jco=o(" (LayoutLMv3 model)"),Yco=l(),gs=a("li"),Rle=a("strong"),Kco=o("layoutxlm"),Zco=o(" \u2014 "),gI=a("a"),efo=o("LayoutXLMTokenizer"),ofo=o(" or "),hI=a("a"),rfo=o("LayoutXLMTokenizerFast"),tfo=o(" (LayoutXLM model)"),afo=l(),hs=a("li"),Ple=a("strong"),nfo=o("led"),sfo=o(" \u2014 "),pI=a("a"),lfo=o("LEDTokenizer"),ifo=o(" or "),_I=a("a"),dfo=o("LEDTokenizerFast"),cfo=o(" (LED model)"),ffo=l(),ps=a("li"),Ble=a("strong"),mfo=o("longformer"),gfo=o(" \u2014 "),uI=a("a"),hfo=o("LongformerTokenizer"),pfo=o(" or "),bI=a("a"),_fo=o("LongformerTokenizerFast"),ufo=o(" (Longformer model)"),bfo=l(),_s=a("li"),Ile=a("strong"),vfo=o("longt5"),Ffo=o(" \u2014 "),vI=a("a"),Tfo=o("T5Tokenizer"),Mfo=o(" or "),FI=a("a"),Efo=o("T5TokenizerFast"),Cfo=o(" (LongT5 model)"),wfo=l(),gh=a("li"),Nle=a("strong"),Afo=o("luke"),Lfo=o(" \u2014 "),TI=a("a"),yfo=o("LukeTokenizer"),xfo=o(" (LUKE model)"),$fo=l(),us=a("li"),qle=a("strong"),kfo=o("lxmert"),Sfo=o(" \u2014 "),MI=a("a"),Rfo=o("LxmertTokenizer"),Pfo=o(" or "),EI=a("a"),Bfo=o("LxmertTokenizerFast"),Ifo=o(" (LXMERT model)"),Nfo=l(),hh=a("li"),jle=a("strong"),qfo=o("m2m_100"),jfo=o(" \u2014 "),CI=a("a"),Dfo=o("M2M100Tokenizer"),Gfo=o(" (M2M100 model)"),Ofo=l(),ph=a("li"),Dle=a("strong"),Vfo=o("marian"),Xfo=o(" \u2014 "),wI=a("a"),zfo=o("MarianTokenizer"),Qfo=o(" (Marian model)"),Wfo=l(),bs=a("li"),Gle=a("strong"),Hfo=o("mbart"),Ufo=o(" \u2014 "),AI=a("a"),Jfo=o("MBartTokenizer"),Yfo=o(" or "),LI=a("a"),Kfo=o("MBartTokenizerFast"),Zfo=o(" (mBART model)"),emo=l(),vs=a("li"),Ole=a("strong"),omo=o("mbart50"),rmo=o(" \u2014 "),yI=a("a"),tmo=o("MBart50Tokenizer"),amo=o(" or "),xI=a("a"),nmo=o("MBart50TokenizerFast"),smo=o(" (mBART-50 model)"),lmo=l(),Fs=a("li"),Vle=a("strong"),imo=o("megatron-bert"),dmo=o(" \u2014 "),$I=a("a"),cmo=o("BertTokenizer"),fmo=o(" or "),kI=a("a"),mmo=o("BertTokenizerFast"),gmo=o(" (Megatron-BERT model)"),hmo=l(),_h=a("li"),Xle=a("strong"),pmo=o("mluke"),_mo=o(" \u2014 "),SI=a("a"),umo=o("MLukeTokenizer"),bmo=o(" (mLUKE model)"),vmo=l(),Ts=a("li"),zle=a("strong"),Fmo=o("mobilebert"),Tmo=o(" \u2014 "),RI=a("a"),Mmo=o("MobileBertTokenizer"),Emo=o(" or "),PI=a("a"),Cmo=o("MobileBertTokenizerFast"),wmo=o(" (MobileBERT model)"),Amo=l(),Ms=a("li"),Qle=a("strong"),Lmo=o("mpnet"),ymo=o(" \u2014 "),BI=a("a"),xmo=o("MPNetTokenizer"),$mo=o(" or "),II=a("a"),kmo=o("MPNetTokenizerFast"),Smo=o(" (MPNet model)"),Rmo=l(),Es=a("li"),Wle=a("strong"),Pmo=o("mt5"),Bmo=o(" \u2014 "),NI=a("a"),Imo=o("MT5Tokenizer"),Nmo=o(" or "),qI=a("a"),qmo=o("MT5TokenizerFast"),jmo=o(" (MT5 model)"),Dmo=l(),Cs=a("li"),Hle=a("strong"),Gmo=o("mvp"),Omo=o(" \u2014 "),jI=a("a"),Vmo=o("MvpTokenizer"),Xmo=o(" or "),DI=a("a"),zmo=o("MvpTokenizerFast"),Qmo=o(" (MVP model)"),Wmo=l(),ws=a("li"),Ule=a("strong"),Hmo=o("nezha"),Umo=o(" \u2014 "),GI=a("a"),Jmo=o("BertTokenizer"),Ymo=o(" or "),OI=a("a"),Kmo=o("BertTokenizerFast"),Zmo=o(" (Nezha model)"),ego=l(),As=a("li"),Jle=a("strong"),ogo=o("nystromformer"),rgo=o(" \u2014 "),VI=a("a"),tgo=o("AlbertTokenizer"),ago=o(" or "),XI=a("a"),ngo=o("AlbertTokenizerFast"),sgo=o(" (Nystr\xF6mformer model)"),lgo=l(),Ls=a("li"),Yle=a("strong"),igo=o("openai-gpt"),dgo=o(" \u2014 "),zI=a("a"),cgo=o("OpenAIGPTTokenizer"),fgo=o(" or "),QI=a("a"),mgo=o("OpenAIGPTTokenizerFast"),ggo=o(" (OpenAI GPT model)"),hgo=l(),uh=a("li"),Kle=a("strong"),pgo=o("opt"),_go=o(" \u2014 "),WI=a("a"),ugo=o("GPT2Tokenizer"),bgo=o(" (OPT model)"),vgo=l(),ys=a("li"),Zle=a("strong"),Fgo=o("pegasus"),Tgo=o(" \u2014 "),HI=a("a"),Mgo=o("PegasusTokenizer"),Ego=o(" or "),UI=a("a"),Cgo=o("PegasusTokenizerFast"),wgo=o(" (Pegasus model)"),Ago=l(),bh=a("li"),eie=a("strong"),Lgo=o("perceiver"),ygo=o(" \u2014 "),JI=a("a"),xgo=o("PerceiverTokenizer"),$go=o(" (Perceiver model)"),kgo=l(),vh=a("li"),oie=a("strong"),Sgo=o("phobert"),Rgo=o(" \u2014 "),YI=a("a"),Pgo=o("PhobertTokenizer"),Bgo=o(" (PhoBERT model)"),Igo=l(),Fh=a("li"),rie=a("strong"),Ngo=o("plbart"),qgo=o(" \u2014 "),KI=a("a"),jgo=o("PLBartTokenizer"),Dgo=o(" (PLBart model)"),Ggo=l(),Th=a("li"),tie=a("strong"),Ogo=o("prophetnet"),Vgo=o(" \u2014 "),ZI=a("a"),Xgo=o("ProphetNetTokenizer"),zgo=o(" (ProphetNet model)"),Qgo=l(),xs=a("li"),aie=a("strong"),Wgo=o("qdqbert"),Hgo=o(" \u2014 "),eN=a("a"),Ugo=o("BertTokenizer"),Jgo=o(" or "),oN=a("a"),Ygo=o("BertTokenizerFast"),Kgo=o(" (QDQBert model)"),Zgo=l(),Mh=a("li"),nie=a("strong"),eho=o("rag"),oho=o(" \u2014 "),rN=a("a"),rho=o("RagTokenizer"),tho=o(" (RAG model)"),aho=l(),$s=a("li"),sie=a("strong"),nho=o("realm"),sho=o(" \u2014 "),tN=a("a"),lho=o("RealmTokenizer"),iho=o(" or "),aN=a("a"),dho=o("RealmTokenizerFast"),cho=o(" (REALM model)"),fho=l(),ks=a("li"),lie=a("strong"),mho=o("reformer"),gho=o(" \u2014 "),nN=a("a"),hho=o("ReformerTokenizer"),pho=o(" or "),sN=a("a"),_ho=o("ReformerTokenizerFast"),uho=o(" (Reformer model)"),bho=l(),Ss=a("li"),iie=a("strong"),vho=o("rembert"),Fho=o(" \u2014 "),lN=a("a"),Tho=o("RemBertTokenizer"),Mho=o(" or "),iN=a("a"),Eho=o("RemBertTokenizerFast"),Cho=o(" (RemBERT model)"),who=l(),Rs=a("li"),die=a("strong"),Aho=o("retribert"),Lho=o(" \u2014 "),dN=a("a"),yho=o("RetriBertTokenizer"),xho=o(" or "),cN=a("a"),$ho=o("RetriBertTokenizerFast"),kho=o(" (RetriBERT model)"),Sho=l(),Ps=a("li"),cie=a("strong"),Rho=o("roberta"),Pho=o(" \u2014 "),fN=a("a"),Bho=o("RobertaTokenizer"),Iho=o(" or "),mN=a("a"),Nho=o("RobertaTokenizerFast"),qho=o(" (RoBERTa model)"),jho=l(),Bs=a("li"),fie=a("strong"),Dho=o("roformer"),Gho=o(" \u2014 "),gN=a("a"),Oho=o("RoFormerTokenizer"),Vho=o(" or "),hN=a("a"),Xho=o("RoFormerTokenizerFast"),zho=o(" (RoFormer model)"),Qho=l(),Eh=a("li"),mie=a("strong"),Who=o("speech_to_text"),Hho=o(" \u2014 "),pN=a("a"),Uho=o("Speech2TextTokenizer"),Jho=o(" (Speech2Text model)"),Yho=l(),Ch=a("li"),gie=a("strong"),Kho=o("speech_to_text_2"),Zho=o(" \u2014 "),_N=a("a"),epo=o("Speech2Text2Tokenizer"),opo=o(" (Speech2Text2 model)"),rpo=l(),Is=a("li"),hie=a("strong"),tpo=o("splinter"),apo=o(" \u2014 "),uN=a("a"),npo=o("SplinterTokenizer"),spo=o(" or "),bN=a("a"),lpo=o("SplinterTokenizerFast"),ipo=o(" (Splinter model)"),dpo=l(),Ns=a("li"),pie=a("strong"),cpo=o("squeezebert"),fpo=o(" \u2014 "),vN=a("a"),mpo=o("SqueezeBertTokenizer"),gpo=o(" or "),FN=a("a"),hpo=o("SqueezeBertTokenizerFast"),ppo=o(" (SqueezeBERT model)"),_po=l(),qs=a("li"),_ie=a("strong"),upo=o("t5"),bpo=o(" \u2014 "),TN=a("a"),vpo=o("T5Tokenizer"),Fpo=o(" or "),MN=a("a"),Tpo=o("T5TokenizerFast"),Mpo=o(" (T5 model)"),Epo=l(),wh=a("li"),uie=a("strong"),Cpo=o("tapas"),wpo=o(" \u2014 "),EN=a("a"),Apo=o("TapasTokenizer"),Lpo=o(" (TAPAS model)"),ypo=l(),Ah=a("li"),bie=a("strong"),xpo=o("tapex"),$po=o(" \u2014 "),CN=a("a"),kpo=o("TapexTokenizer"),Spo=o(" (TAPEX model)"),Rpo=l(),Lh=a("li"),vie=a("strong"),Ppo=o("transfo-xl"),Bpo=o(" \u2014 "),wN=a("a"),Ipo=o("TransfoXLTokenizer"),Npo=o(" (Transformer-XL model)"),qpo=l(),js=a("li"),Fie=a("strong"),jpo=o("vilt"),Dpo=o(" \u2014 "),AN=a("a"),Gpo=o("BertTokenizer"),Opo=o(" or "),LN=a("a"),Vpo=o("BertTokenizerFast"),Xpo=o(" (ViLT model)"),zpo=l(),Ds=a("li"),Tie=a("strong"),Qpo=o("visual_bert"),Wpo=o(" \u2014 "),yN=a("a"),Hpo=o("BertTokenizer"),Upo=o(" or "),xN=a("a"),Jpo=o("BertTokenizerFast"),Ypo=o(" (VisualBERT model)"),Kpo=l(),yh=a("li"),Mie=a("strong"),Zpo=o("wav2vec2"),e_o=o(" \u2014 "),$N=a("a"),o_o=o("Wav2Vec2CTCTokenizer"),r_o=o(" (Wav2Vec2 model)"),t_o=l(),xh=a("li"),Eie=a("strong"),a_o=o("wav2vec2-conformer"),n_o=o(" \u2014 "),kN=a("a"),s_o=o("Wav2Vec2CTCTokenizer"),l_o=o(" (Wav2Vec2-Conformer model)"),i_o=l(),$h=a("li"),Cie=a("strong"),d_o=o("wav2vec2_phoneme"),c_o=o(" \u2014 "),SN=a("a"),f_o=o("Wav2Vec2PhonemeCTCTokenizer"),m_o=o(" (Wav2Vec2Phoneme model)"),g_o=l(),Gs=a("li"),wie=a("strong"),h_o=o("xglm"),p_o=o(" \u2014 "),RN=a("a"),__o=o("XGLMTokenizer"),u_o=o(" or "),PN=a("a"),b_o=o("XGLMTokenizerFast"),v_o=o(" (XGLM model)"),F_o=l(),kh=a("li"),Aie=a("strong"),T_o=o("xlm"),M_o=o(" \u2014 "),BN=a("a"),E_o=o("XLMTokenizer"),C_o=o(" (XLM model)"),w_o=l(),Sh=a("li"),Lie=a("strong"),A_o=o("xlm-prophetnet"),L_o=o(" \u2014 "),IN=a("a"),y_o=o("XLMProphetNetTokenizer"),x_o=o(" (XLM-ProphetNet model)"),$_o=l(),Os=a("li"),yie=a("strong"),k_o=o("xlm-roberta"),S_o=o(" \u2014 "),NN=a("a"),R_o=o("XLMRobertaTokenizer"),P_o=o(" or "),qN=a("a"),B_o=o("XLMRobertaTokenizerFast"),I_o=o(" (XLM-RoBERTa model)"),N_o=l(),Vs=a("li"),xie=a("strong"),q_o=o("xlm-roberta-xl"),j_o=o(" \u2014 "),jN=a("a"),D_o=o("RobertaTokenizer"),G_o=o(" or "),DN=a("a"),O_o=o("RobertaTokenizerFast"),V_o=o(" (XLM-RoBERTa-XL model)"),X_o=l(),Xs=a("li"),$ie=a("strong"),z_o=o("xlnet"),Q_o=o(" \u2014 "),GN=a("a"),W_o=o("XLNetTokenizer"),H_o=o(" or "),ON=a("a"),U_o=o("XLNetTokenizerFast"),J_o=o(" (XLNet model)"),Y_o=l(),zs=a("li"),kie=a("strong"),K_o=o("yoso"),Z_o=o(" \u2014 "),VN=a("a"),euo=o("AlbertTokenizer"),ouo=o(" or "),XN=a("a"),ruo=o("AlbertTokenizerFast"),tuo=o(" (YOSO model)"),auo=l(),F(Rh.$$.fragment),nuo=l(),Ph=a("div"),F(hL.$$.fragment),suo=l(),Sie=a("p"),luo=o("Register a new tokenizer in this mapping."),WVe=l(),Ni=a("h2"),Bh=a("a"),Rie=a("span"),F(pL.$$.fragment),iuo=l(),Pie=a("span"),duo=o("AutoFeatureExtractor"),HVe=l(),Lo=a("div"),F(_L.$$.fragment),cuo=l(),uL=a("p"),fuo=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),zN=a("a"),muo=o("AutoFeatureExtractor.from_pretrained()"),guo=o(" class method."),huo=l(),bL=a("p"),puo=o("This class cannot be instantiated directly using "),Bie=a("code"),_uo=o("__init__()"),uuo=o(" (throws an error)."),buo=l(),He=a("div"),F(vL.$$.fragment),vuo=l(),Iie=a("p"),Fuo=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Tuo=l(),Pa=a("p"),Muo=o("The feature extractor class to instantiate is selected based on the "),Nie=a("code"),Euo=o("model_type"),Cuo=o(` property of the config object
(either passed as an argument or loaded from `),qie=a("code"),wuo=o("pretrained_model_name_or_path"),Auo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),jie=a("code"),Luo=o("pretrained_model_name_or_path"),yuo=o(":"),xuo=l(),Y=a("ul"),Ih=a("li"),Die=a("strong"),$uo=o("beit"),kuo=o(" \u2014 "),QN=a("a"),Suo=o("BeitFeatureExtractor"),Ruo=o(" (BEiT model)"),Puo=l(),Nh=a("li"),Gie=a("strong"),Buo=o("clip"),Iuo=o(" \u2014 "),WN=a("a"),Nuo=o("CLIPFeatureExtractor"),quo=o(" (CLIP model)"),juo=l(),qh=a("li"),Oie=a("strong"),Duo=o("convnext"),Guo=o(" \u2014 "),HN=a("a"),Ouo=o("ConvNextFeatureExtractor"),Vuo=o(" (ConvNeXT model)"),Xuo=l(),jh=a("li"),Vie=a("strong"),zuo=o("cvt"),Quo=o(" \u2014 "),UN=a("a"),Wuo=o("ConvNextFeatureExtractor"),Huo=o(" (CvT model)"),Uuo=l(),Dh=a("li"),Xie=a("strong"),Juo=o("data2vec-audio"),Yuo=o(" \u2014 "),JN=a("a"),Kuo=o("Wav2Vec2FeatureExtractor"),Zuo=o(" (Data2VecAudio model)"),e1o=l(),Gh=a("li"),zie=a("strong"),o1o=o("data2vec-vision"),r1o=o(" \u2014 "),YN=a("a"),t1o=o("BeitFeatureExtractor"),a1o=o(" (Data2VecVision model)"),n1o=l(),Oh=a("li"),Qie=a("strong"),s1o=o("deit"),l1o=o(" \u2014 "),KN=a("a"),i1o=o("DeiTFeatureExtractor"),d1o=o(" (DeiT model)"),c1o=l(),Vh=a("li"),Wie=a("strong"),f1o=o("detr"),m1o=o(" \u2014 "),ZN=a("a"),g1o=o("DetrFeatureExtractor"),h1o=o(" (DETR model)"),p1o=l(),Xh=a("li"),Hie=a("strong"),_1o=o("dpt"),u1o=o(" \u2014 "),eq=a("a"),b1o=o("DPTFeatureExtractor"),v1o=o(" (DPT model)"),F1o=l(),zh=a("li"),Uie=a("strong"),T1o=o("flava"),M1o=o(" \u2014 "),oq=a("a"),E1o=o("FlavaFeatureExtractor"),C1o=o(" (FLAVA model)"),w1o=l(),Qh=a("li"),Jie=a("strong"),A1o=o("glpn"),L1o=o(" \u2014 "),rq=a("a"),y1o=o("GLPNFeatureExtractor"),x1o=o(" (GLPN model)"),$1o=l(),Wh=a("li"),Yie=a("strong"),k1o=o("groupvit"),S1o=o(" \u2014 "),tq=a("a"),R1o=o("CLIPFeatureExtractor"),P1o=o(" (GroupViT model)"),B1o=l(),Hh=a("li"),Kie=a("strong"),I1o=o("hubert"),N1o=o(" \u2014 "),aq=a("a"),q1o=o("Wav2Vec2FeatureExtractor"),j1o=o(" (Hubert model)"),D1o=l(),Uh=a("li"),Zie=a("strong"),G1o=o("imagegpt"),O1o=o(" \u2014 "),nq=a("a"),V1o=o("ImageGPTFeatureExtractor"),X1o=o(" (ImageGPT model)"),z1o=l(),Jh=a("li"),ede=a("strong"),Q1o=o("layoutlmv2"),W1o=o(" \u2014 "),sq=a("a"),H1o=o("LayoutLMv2FeatureExtractor"),U1o=o(" (LayoutLMv2 model)"),J1o=l(),Yh=a("li"),ode=a("strong"),Y1o=o("layoutlmv3"),K1o=o(" \u2014 "),lq=a("a"),Z1o=o("LayoutLMv3FeatureExtractor"),e2o=o(" (LayoutLMv3 model)"),o2o=l(),Kh=a("li"),rde=a("strong"),r2o=o("levit"),t2o=o(" \u2014 "),iq=a("a"),a2o=o("LevitFeatureExtractor"),n2o=o(" (LeViT model)"),s2o=l(),Zh=a("li"),tde=a("strong"),l2o=o("maskformer"),i2o=o(" \u2014 "),dq=a("a"),d2o=o("MaskFormerFeatureExtractor"),c2o=o(" (MaskFormer model)"),f2o=l(),ep=a("li"),ade=a("strong"),m2o=o("mctct"),g2o=o(" \u2014 "),cq=a("a"),h2o=o("MCTCTFeatureExtractor"),p2o=o(" (M-CTC-T model)"),_2o=l(),op=a("li"),nde=a("strong"),u2o=o("mobilevit"),b2o=o(" \u2014 "),fq=a("a"),v2o=o("MobileViTFeatureExtractor"),F2o=o(" (MobileViT model)"),T2o=l(),rp=a("li"),sde=a("strong"),M2o=o("perceiver"),E2o=o(" \u2014 "),mq=a("a"),C2o=o("PerceiverFeatureExtractor"),w2o=o(" (Perceiver model)"),A2o=l(),tp=a("li"),lde=a("strong"),L2o=o("poolformer"),y2o=o(" \u2014 "),gq=a("a"),x2o=o("PoolFormerFeatureExtractor"),$2o=o(" (PoolFormer model)"),k2o=l(),ap=a("li"),ide=a("strong"),S2o=o("regnet"),R2o=o(" \u2014 "),hq=a("a"),P2o=o("ConvNextFeatureExtractor"),B2o=o(" (RegNet model)"),I2o=l(),np=a("li"),dde=a("strong"),N2o=o("resnet"),q2o=o(" \u2014 "),pq=a("a"),j2o=o("ConvNextFeatureExtractor"),D2o=o(" (ResNet model)"),G2o=l(),sp=a("li"),cde=a("strong"),O2o=o("segformer"),V2o=o(" \u2014 "),_q=a("a"),X2o=o("SegformerFeatureExtractor"),z2o=o(" (SegFormer model)"),Q2o=l(),lp=a("li"),fde=a("strong"),W2o=o("speech_to_text"),H2o=o(" \u2014 "),uq=a("a"),U2o=o("Speech2TextFeatureExtractor"),J2o=o(" (Speech2Text model)"),Y2o=l(),ip=a("li"),mde=a("strong"),K2o=o("swin"),Z2o=o(" \u2014 "),bq=a("a"),ebo=o("ViTFeatureExtractor"),obo=o(" (Swin Transformer model)"),rbo=l(),dp=a("li"),gde=a("strong"),tbo=o("van"),abo=o(" \u2014 "),vq=a("a"),nbo=o("ConvNextFeatureExtractor"),sbo=o(" (VAN model)"),lbo=l(),cp=a("li"),hde=a("strong"),ibo=o("vilt"),dbo=o(" \u2014 "),Fq=a("a"),cbo=o("ViltFeatureExtractor"),fbo=o(" (ViLT model)"),mbo=l(),fp=a("li"),pde=a("strong"),gbo=o("vit"),hbo=o(" \u2014 "),Tq=a("a"),pbo=o("ViTFeatureExtractor"),_bo=o(" (ViT model)"),ubo=l(),mp=a("li"),_de=a("strong"),bbo=o("vit_mae"),vbo=o(" \u2014 "),Mq=a("a"),Fbo=o("ViTFeatureExtractor"),Tbo=o(" (ViTMAE model)"),Mbo=l(),gp=a("li"),ude=a("strong"),Ebo=o("wav2vec2"),Cbo=o(" \u2014 "),Eq=a("a"),wbo=o("Wav2Vec2FeatureExtractor"),Abo=o(" (Wav2Vec2 model)"),Lbo=l(),hp=a("li"),bde=a("strong"),ybo=o("wav2vec2-conformer"),xbo=o(" \u2014 "),Cq=a("a"),$bo=o("Wav2Vec2FeatureExtractor"),kbo=o(" (Wav2Vec2-Conformer model)"),Sbo=l(),pp=a("li"),vde=a("strong"),Rbo=o("yolos"),Pbo=o(" \u2014 "),wq=a("a"),Bbo=o("YolosFeatureExtractor"),Ibo=o(" (YOLOS model)"),Nbo=l(),F(_p.$$.fragment),qbo=l(),F(up.$$.fragment),jbo=l(),bp=a("div"),F(FL.$$.fragment),Dbo=l(),Fde=a("p"),Gbo=o("Register a new feature extractor for this class."),UVe=l(),qi=a("h2"),vp=a("a"),Tde=a("span"),F(TL.$$.fragment),Obo=l(),Mde=a("span"),Vbo=o("AutoProcessor"),JVe=l(),yo=a("div"),F(ML.$$.fragment),Xbo=l(),EL=a("p"),zbo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),Aq=a("a"),Qbo=o("AutoProcessor.from_pretrained()"),Wbo=o(" class method."),Hbo=l(),CL=a("p"),Ubo=o("This class cannot be instantiated directly using "),Ede=a("code"),Jbo=o("__init__()"),Ybo=o(" (throws an error)."),Kbo=l(),Ue=a("div"),F(wL.$$.fragment),Zbo=l(),Cde=a("p"),evo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),ovo=l(),ji=a("p"),rvo=o("The processor class to instantiate is selected based on the "),wde=a("code"),tvo=o("model_type"),avo=o(` property of the config object (either
passed as an argument or loaded from `),Ade=a("code"),nvo=o("pretrained_model_name_or_path"),svo=o(" if possible):"),lvo=l(),he=a("ul"),Fp=a("li"),Lde=a("strong"),ivo=o("clip"),dvo=o(" \u2014 "),Lq=a("a"),cvo=o("CLIPProcessor"),fvo=o(" (CLIP model)"),mvo=l(),Tp=a("li"),yde=a("strong"),gvo=o("flava"),hvo=o(" \u2014 "),xde=a("code"),pvo=o("FLAVAProcessor"),_vo=o(" (FLAVA model)"),uvo=l(),Mp=a("li"),$de=a("strong"),bvo=o("groupvit"),vvo=o(" \u2014 "),yq=a("a"),Fvo=o("CLIPProcessor"),Tvo=o(" (GroupViT model)"),Mvo=l(),Ep=a("li"),kde=a("strong"),Evo=o("layoutlmv2"),Cvo=o(" \u2014 "),xq=a("a"),wvo=o("LayoutLMv2Processor"),Avo=o(" (LayoutLMv2 model)"),Lvo=l(),Cp=a("li"),Sde=a("strong"),yvo=o("layoutlmv3"),xvo=o(" \u2014 "),$q=a("a"),$vo=o("LayoutLMv3Processor"),kvo=o(" (LayoutLMv3 model)"),Svo=l(),wp=a("li"),Rde=a("strong"),Rvo=o("layoutxlm"),Pvo=o(" \u2014 "),kq=a("a"),Bvo=o("LayoutXLMProcessor"),Ivo=o(" (LayoutXLM model)"),Nvo=l(),Ap=a("li"),Pde=a("strong"),qvo=o("sew"),jvo=o(" \u2014 "),Sq=a("a"),Dvo=o("Wav2Vec2Processor"),Gvo=o(" (SEW model)"),Ovo=l(),Lp=a("li"),Bde=a("strong"),Vvo=o("sew-d"),Xvo=o(" \u2014 "),Rq=a("a"),zvo=o("Wav2Vec2Processor"),Qvo=o(" (SEW-D model)"),Wvo=l(),yp=a("li"),Ide=a("strong"),Hvo=o("speech_to_text"),Uvo=o(" \u2014 "),Pq=a("a"),Jvo=o("Speech2TextProcessor"),Yvo=o(" (Speech2Text model)"),Kvo=l(),xp=a("li"),Nde=a("strong"),Zvo=o("speech_to_text_2"),eFo=o(" \u2014 "),Bq=a("a"),oFo=o("Speech2Text2Processor"),rFo=o(" (Speech2Text2 model)"),tFo=l(),$p=a("li"),qde=a("strong"),aFo=o("trocr"),nFo=o(" \u2014 "),Iq=a("a"),sFo=o("TrOCRProcessor"),lFo=o(" (TrOCR model)"),iFo=l(),kp=a("li"),jde=a("strong"),dFo=o("unispeech"),cFo=o(" \u2014 "),Nq=a("a"),fFo=o("Wav2Vec2Processor"),mFo=o(" (UniSpeech model)"),gFo=l(),Sp=a("li"),Dde=a("strong"),hFo=o("unispeech-sat"),pFo=o(" \u2014 "),qq=a("a"),_Fo=o("Wav2Vec2Processor"),uFo=o(" (UniSpeechSat model)"),bFo=l(),Rp=a("li"),Gde=a("strong"),vFo=o("vilt"),FFo=o(" \u2014 "),jq=a("a"),TFo=o("ViltProcessor"),MFo=o(" (ViLT model)"),EFo=l(),Pp=a("li"),Ode=a("strong"),CFo=o("vision-text-dual-encoder"),wFo=o(" \u2014 "),Dq=a("a"),AFo=o("VisionTextDualEncoderProcessor"),LFo=o(" (VisionTextDualEncoder model)"),yFo=l(),Bp=a("li"),Vde=a("strong"),xFo=o("wav2vec2"),$Fo=o(" \u2014 "),Gq=a("a"),kFo=o("Wav2Vec2Processor"),SFo=o(" (Wav2Vec2 model)"),RFo=l(),Ip=a("li"),Xde=a("strong"),PFo=o("wav2vec2-conformer"),BFo=o(" \u2014 "),Oq=a("a"),IFo=o("Wav2Vec2Processor"),NFo=o(" (Wav2Vec2-Conformer model)"),qFo=l(),Np=a("li"),zde=a("strong"),jFo=o("wavlm"),DFo=o(" \u2014 "),Vq=a("a"),GFo=o("Wav2Vec2Processor"),OFo=o(" (WavLM model)"),VFo=l(),F(qp.$$.fragment),XFo=l(),F(jp.$$.fragment),zFo=l(),Dp=a("div"),F(AL.$$.fragment),QFo=l(),Qde=a("p"),WFo=o("Register a new processor for this class."),YVe=l(),Di=a("h2"),Gp=a("a"),Wde=a("span"),F(LL.$$.fragment),HFo=l(),Hde=a("span"),UFo=o("AutoModel"),KVe=l(),xo=a("div"),F(yL.$$.fragment),JFo=l(),Gi=a("p"),YFo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Xq=a("a"),KFo=o("from_pretrained()"),ZFo=o(" class method or the "),zq=a("a"),eTo=o("from_config()"),oTo=o(` class
method.`),rTo=l(),xL=a("p"),tTo=o("This class cannot be instantiated directly using "),Ude=a("code"),aTo=o("__init__()"),nTo=o(" (throws an error)."),sTo=l(),lt=a("div"),F($L.$$.fragment),lTo=l(),Jde=a("p"),iTo=o("Instantiates one of the base model classes of the library from a configuration."),dTo=l(),Oi=a("p"),cTo=o(`Note:
Loading a model from its configuration file does `),Yde=a("strong"),fTo=o("not"),mTo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qq=a("a"),gTo=o("from_pretrained()"),hTo=o(" to load the model weights."),pTo=l(),F(Op.$$.fragment),_To=l(),Je=a("div"),F(kL.$$.fragment),uTo=l(),Kde=a("p"),bTo=o("Instantiate one of the base model classes of the library from a pretrained model."),vTo=l(),Ba=a("p"),FTo=o("The model class to instantiate is selected based on the "),Zde=a("code"),TTo=o("model_type"),MTo=o(` property of the config object (either
passed as an argument or loaded from `),ece=a("code"),ETo=o("pretrained_model_name_or_path"),CTo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oce=a("code"),wTo=o("pretrained_model_name_or_path"),ATo=o(":"),LTo=l(),y=a("ul"),Vp=a("li"),rce=a("strong"),yTo=o("albert"),xTo=o(" \u2014 "),Wq=a("a"),$To=o("AlbertModel"),kTo=o(" (ALBERT model)"),STo=l(),Xp=a("li"),tce=a("strong"),RTo=o("bart"),PTo=o(" \u2014 "),Hq=a("a"),BTo=o("BartModel"),ITo=o(" (BART model)"),NTo=l(),zp=a("li"),ace=a("strong"),qTo=o("beit"),jTo=o(" \u2014 "),Uq=a("a"),DTo=o("BeitModel"),GTo=o(" (BEiT model)"),OTo=l(),Qp=a("li"),nce=a("strong"),VTo=o("bert"),XTo=o(" \u2014 "),Jq=a("a"),zTo=o("BertModel"),QTo=o(" (BERT model)"),WTo=l(),Wp=a("li"),sce=a("strong"),HTo=o("bert-generation"),UTo=o(" \u2014 "),Yq=a("a"),JTo=o("BertGenerationEncoder"),YTo=o(" (Bert Generation model)"),KTo=l(),Hp=a("li"),lce=a("strong"),ZTo=o("big_bird"),e7o=o(" \u2014 "),Kq=a("a"),o7o=o("BigBirdModel"),r7o=o(" (BigBird model)"),t7o=l(),Up=a("li"),ice=a("strong"),a7o=o("bigbird_pegasus"),n7o=o(" \u2014 "),Zq=a("a"),s7o=o("BigBirdPegasusModel"),l7o=o(" (BigBird-Pegasus model)"),i7o=l(),Jp=a("li"),dce=a("strong"),d7o=o("blenderbot"),c7o=o(" \u2014 "),ej=a("a"),f7o=o("BlenderbotModel"),m7o=o(" (Blenderbot model)"),g7o=l(),Yp=a("li"),cce=a("strong"),h7o=o("blenderbot-small"),p7o=o(" \u2014 "),oj=a("a"),_7o=o("BlenderbotSmallModel"),u7o=o(" (BlenderbotSmall model)"),b7o=l(),Kp=a("li"),fce=a("strong"),v7o=o("bloom"),F7o=o(" \u2014 "),rj=a("a"),T7o=o("BloomModel"),M7o=o(" (BLOOM model)"),E7o=l(),Zp=a("li"),mce=a("strong"),C7o=o("camembert"),w7o=o(" \u2014 "),tj=a("a"),A7o=o("CamembertModel"),L7o=o(" (CamemBERT model)"),y7o=l(),e_=a("li"),gce=a("strong"),x7o=o("canine"),$7o=o(" \u2014 "),aj=a("a"),k7o=o("CanineModel"),S7o=o(" (CANINE model)"),R7o=l(),o_=a("li"),hce=a("strong"),P7o=o("clip"),B7o=o(" \u2014 "),nj=a("a"),I7o=o("CLIPModel"),N7o=o(" (CLIP model)"),q7o=l(),r_=a("li"),pce=a("strong"),j7o=o("codegen"),D7o=o(" \u2014 "),sj=a("a"),G7o=o("CodeGenModel"),O7o=o(" (CodeGen model)"),V7o=l(),t_=a("li"),_ce=a("strong"),X7o=o("convbert"),z7o=o(" \u2014 "),lj=a("a"),Q7o=o("ConvBertModel"),W7o=o(" (ConvBERT model)"),H7o=l(),a_=a("li"),uce=a("strong"),U7o=o("convnext"),J7o=o(" \u2014 "),ij=a("a"),Y7o=o("ConvNextModel"),K7o=o(" (ConvNeXT model)"),Z7o=l(),n_=a("li"),bce=a("strong"),e8o=o("ctrl"),o8o=o(" \u2014 "),dj=a("a"),r8o=o("CTRLModel"),t8o=o(" (CTRL model)"),a8o=l(),s_=a("li"),vce=a("strong"),n8o=o("cvt"),s8o=o(" \u2014 "),cj=a("a"),l8o=o("CvtModel"),i8o=o(" (CvT model)"),d8o=l(),l_=a("li"),Fce=a("strong"),c8o=o("data2vec-audio"),f8o=o(" \u2014 "),fj=a("a"),m8o=o("Data2VecAudioModel"),g8o=o(" (Data2VecAudio model)"),h8o=l(),i_=a("li"),Tce=a("strong"),p8o=o("data2vec-text"),_8o=o(" \u2014 "),mj=a("a"),u8o=o("Data2VecTextModel"),b8o=o(" (Data2VecText model)"),v8o=l(),d_=a("li"),Mce=a("strong"),F8o=o("data2vec-vision"),T8o=o(" \u2014 "),gj=a("a"),M8o=o("Data2VecVisionModel"),E8o=o(" (Data2VecVision model)"),C8o=l(),c_=a("li"),Ece=a("strong"),w8o=o("deberta"),A8o=o(" \u2014 "),hj=a("a"),L8o=o("DebertaModel"),y8o=o(" (DeBERTa model)"),x8o=l(),f_=a("li"),Cce=a("strong"),$8o=o("deberta-v2"),k8o=o(" \u2014 "),pj=a("a"),S8o=o("DebertaV2Model"),R8o=o(" (DeBERTa-v2 model)"),P8o=l(),m_=a("li"),wce=a("strong"),B8o=o("decision_transformer"),I8o=o(" \u2014 "),_j=a("a"),N8o=o("DecisionTransformerModel"),q8o=o(" (Decision Transformer model)"),j8o=l(),g_=a("li"),Ace=a("strong"),D8o=o("deit"),G8o=o(" \u2014 "),uj=a("a"),O8o=o("DeiTModel"),V8o=o(" (DeiT model)"),X8o=l(),h_=a("li"),Lce=a("strong"),z8o=o("detr"),Q8o=o(" \u2014 "),bj=a("a"),W8o=o("DetrModel"),H8o=o(" (DETR model)"),U8o=l(),p_=a("li"),yce=a("strong"),J8o=o("distilbert"),Y8o=o(" \u2014 "),vj=a("a"),K8o=o("DistilBertModel"),Z8o=o(" (DistilBERT model)"),eMo=l(),__=a("li"),xce=a("strong"),oMo=o("dpr"),rMo=o(" \u2014 "),Fj=a("a"),tMo=o("DPRQuestionEncoder"),aMo=o(" (DPR model)"),nMo=l(),u_=a("li"),$ce=a("strong"),sMo=o("dpt"),lMo=o(" \u2014 "),Tj=a("a"),iMo=o("DPTModel"),dMo=o(" (DPT model)"),cMo=l(),b_=a("li"),kce=a("strong"),fMo=o("electra"),mMo=o(" \u2014 "),Mj=a("a"),gMo=o("ElectraModel"),hMo=o(" (ELECTRA model)"),pMo=l(),v_=a("li"),Sce=a("strong"),_Mo=o("flaubert"),uMo=o(" \u2014 "),Ej=a("a"),bMo=o("FlaubertModel"),vMo=o(" (FlauBERT model)"),FMo=l(),F_=a("li"),Rce=a("strong"),TMo=o("flava"),MMo=o(" \u2014 "),Cj=a("a"),EMo=o("FlavaModel"),CMo=o(" (FLAVA model)"),wMo=l(),T_=a("li"),Pce=a("strong"),AMo=o("fnet"),LMo=o(" \u2014 "),wj=a("a"),yMo=o("FNetModel"),xMo=o(" (FNet model)"),$Mo=l(),M_=a("li"),Bce=a("strong"),kMo=o("fsmt"),SMo=o(" \u2014 "),Aj=a("a"),RMo=o("FSMTModel"),PMo=o(" (FairSeq Machine-Translation model)"),BMo=l(),Qs=a("li"),Ice=a("strong"),IMo=o("funnel"),NMo=o(" \u2014 "),Lj=a("a"),qMo=o("FunnelModel"),jMo=o(" or "),yj=a("a"),DMo=o("FunnelBaseModel"),GMo=o(" (Funnel Transformer model)"),OMo=l(),E_=a("li"),Nce=a("strong"),VMo=o("glpn"),XMo=o(" \u2014 "),xj=a("a"),zMo=o("GLPNModel"),QMo=o(" (GLPN model)"),WMo=l(),C_=a("li"),qce=a("strong"),HMo=o("gpt2"),UMo=o(" \u2014 "),$j=a("a"),JMo=o("GPT2Model"),YMo=o(" (OpenAI GPT-2 model)"),KMo=l(),w_=a("li"),jce=a("strong"),ZMo=o("gpt_neo"),e4o=o(" \u2014 "),kj=a("a"),o4o=o("GPTNeoModel"),r4o=o(" (GPT Neo model)"),t4o=l(),A_=a("li"),Dce=a("strong"),a4o=o("gpt_neox"),n4o=o(" \u2014 "),Sj=a("a"),s4o=o("GPTNeoXModel"),l4o=o(" (GPT NeoX model)"),i4o=l(),L_=a("li"),Gce=a("strong"),d4o=o("gptj"),c4o=o(" \u2014 "),Rj=a("a"),f4o=o("GPTJModel"),m4o=o(" (GPT-J model)"),g4o=l(),y_=a("li"),Oce=a("strong"),h4o=o("groupvit"),p4o=o(" \u2014 "),Pj=a("a"),_4o=o("GroupViTModel"),u4o=o(" (GroupViT model)"),b4o=l(),x_=a("li"),Vce=a("strong"),v4o=o("hubert"),F4o=o(" \u2014 "),Bj=a("a"),T4o=o("HubertModel"),M4o=o(" (Hubert model)"),E4o=l(),$_=a("li"),Xce=a("strong"),C4o=o("ibert"),w4o=o(" \u2014 "),Ij=a("a"),A4o=o("IBertModel"),L4o=o(" (I-BERT model)"),y4o=l(),k_=a("li"),zce=a("strong"),x4o=o("imagegpt"),$4o=o(" \u2014 "),Nj=a("a"),k4o=o("ImageGPTModel"),S4o=o(" (ImageGPT model)"),R4o=l(),S_=a("li"),Qce=a("strong"),P4o=o("layoutlm"),B4o=o(" \u2014 "),qj=a("a"),I4o=o("LayoutLMModel"),N4o=o(" (LayoutLM model)"),q4o=l(),R_=a("li"),Wce=a("strong"),j4o=o("layoutlmv2"),D4o=o(" \u2014 "),jj=a("a"),G4o=o("LayoutLMv2Model"),O4o=o(" (LayoutLMv2 model)"),V4o=l(),P_=a("li"),Hce=a("strong"),X4o=o("layoutlmv3"),z4o=o(" \u2014 "),Dj=a("a"),Q4o=o("LayoutLMv3Model"),W4o=o(" (LayoutLMv3 model)"),H4o=l(),B_=a("li"),Uce=a("strong"),U4o=o("led"),J4o=o(" \u2014 "),Gj=a("a"),Y4o=o("LEDModel"),K4o=o(" (LED model)"),Z4o=l(),I_=a("li"),Jce=a("strong"),eEo=o("levit"),oEo=o(" \u2014 "),Oj=a("a"),rEo=o("LevitModel"),tEo=o(" (LeViT model)"),aEo=l(),N_=a("li"),Yce=a("strong"),nEo=o("longformer"),sEo=o(" \u2014 "),Vj=a("a"),lEo=o("LongformerModel"),iEo=o(" (Longformer model)"),dEo=l(),q_=a("li"),Kce=a("strong"),cEo=o("longt5"),fEo=o(" \u2014 "),Xj=a("a"),mEo=o("LongT5Model"),gEo=o(" (LongT5 model)"),hEo=l(),j_=a("li"),Zce=a("strong"),pEo=o("luke"),_Eo=o(" \u2014 "),zj=a("a"),uEo=o("LukeModel"),bEo=o(" (LUKE model)"),vEo=l(),D_=a("li"),efe=a("strong"),FEo=o("lxmert"),TEo=o(" \u2014 "),Qj=a("a"),MEo=o("LxmertModel"),EEo=o(" (LXMERT model)"),CEo=l(),G_=a("li"),ofe=a("strong"),wEo=o("m2m_100"),AEo=o(" \u2014 "),Wj=a("a"),LEo=o("M2M100Model"),yEo=o(" (M2M100 model)"),xEo=l(),O_=a("li"),rfe=a("strong"),$Eo=o("marian"),kEo=o(" \u2014 "),Hj=a("a"),SEo=o("MarianModel"),REo=o(" (Marian model)"),PEo=l(),V_=a("li"),tfe=a("strong"),BEo=o("maskformer"),IEo=o(" \u2014 "),Uj=a("a"),NEo=o("MaskFormerModel"),qEo=o(" (MaskFormer model)"),jEo=l(),X_=a("li"),afe=a("strong"),DEo=o("mbart"),GEo=o(" \u2014 "),Jj=a("a"),OEo=o("MBartModel"),VEo=o(" (mBART model)"),XEo=l(),z_=a("li"),nfe=a("strong"),zEo=o("mctct"),QEo=o(" \u2014 "),Yj=a("a"),WEo=o("MCTCTModel"),HEo=o(" (M-CTC-T model)"),UEo=l(),Q_=a("li"),sfe=a("strong"),JEo=o("megatron-bert"),YEo=o(" \u2014 "),Kj=a("a"),KEo=o("MegatronBertModel"),ZEo=o(" (Megatron-BERT model)"),eCo=l(),W_=a("li"),lfe=a("strong"),oCo=o("mobilebert"),rCo=o(" \u2014 "),Zj=a("a"),tCo=o("MobileBertModel"),aCo=o(" (MobileBERT model)"),nCo=l(),H_=a("li"),ife=a("strong"),sCo=o("mobilevit"),lCo=o(" \u2014 "),eD=a("a"),iCo=o("MobileViTModel"),dCo=o(" (MobileViT model)"),cCo=l(),U_=a("li"),dfe=a("strong"),fCo=o("mpnet"),mCo=o(" \u2014 "),oD=a("a"),gCo=o("MPNetModel"),hCo=o(" (MPNet model)"),pCo=l(),J_=a("li"),cfe=a("strong"),_Co=o("mt5"),uCo=o(" \u2014 "),rD=a("a"),bCo=o("MT5Model"),vCo=o(" (MT5 model)"),FCo=l(),Y_=a("li"),ffe=a("strong"),TCo=o("mvp"),MCo=o(" \u2014 "),tD=a("a"),ECo=o("MvpModel"),CCo=o(" (MVP model)"),wCo=l(),K_=a("li"),mfe=a("strong"),ACo=o("nezha"),LCo=o(" \u2014 "),aD=a("a"),yCo=o("NezhaModel"),xCo=o(" (Nezha model)"),$Co=l(),Z_=a("li"),gfe=a("strong"),kCo=o("nystromformer"),SCo=o(" \u2014 "),nD=a("a"),RCo=o("NystromformerModel"),PCo=o(" (Nystr\xF6mformer model)"),BCo=l(),eu=a("li"),hfe=a("strong"),ICo=o("openai-gpt"),NCo=o(" \u2014 "),sD=a("a"),qCo=o("OpenAIGPTModel"),jCo=o(" (OpenAI GPT model)"),DCo=l(),ou=a("li"),pfe=a("strong"),GCo=o("opt"),OCo=o(" \u2014 "),lD=a("a"),VCo=o("OPTModel"),XCo=o(" (OPT model)"),zCo=l(),ru=a("li"),_fe=a("strong"),QCo=o("pegasus"),WCo=o(" \u2014 "),iD=a("a"),HCo=o("PegasusModel"),UCo=o(" (Pegasus model)"),JCo=l(),tu=a("li"),ufe=a("strong"),YCo=o("perceiver"),KCo=o(" \u2014 "),dD=a("a"),ZCo=o("PerceiverModel"),e3o=o(" (Perceiver model)"),o3o=l(),au=a("li"),bfe=a("strong"),r3o=o("plbart"),t3o=o(" \u2014 "),cD=a("a"),a3o=o("PLBartModel"),n3o=o(" (PLBart model)"),s3o=l(),nu=a("li"),vfe=a("strong"),l3o=o("poolformer"),i3o=o(" \u2014 "),fD=a("a"),d3o=o("PoolFormerModel"),c3o=o(" (PoolFormer model)"),f3o=l(),su=a("li"),Ffe=a("strong"),m3o=o("prophetnet"),g3o=o(" \u2014 "),mD=a("a"),h3o=o("ProphetNetModel"),p3o=o(" (ProphetNet model)"),_3o=l(),lu=a("li"),Tfe=a("strong"),u3o=o("qdqbert"),b3o=o(" \u2014 "),gD=a("a"),v3o=o("QDQBertModel"),F3o=o(" (QDQBert model)"),T3o=l(),iu=a("li"),Mfe=a("strong"),M3o=o("reformer"),E3o=o(" \u2014 "),hD=a("a"),C3o=o("ReformerModel"),w3o=o(" (Reformer model)"),A3o=l(),du=a("li"),Efe=a("strong"),L3o=o("regnet"),y3o=o(" \u2014 "),pD=a("a"),x3o=o("RegNetModel"),$3o=o(" (RegNet model)"),k3o=l(),cu=a("li"),Cfe=a("strong"),S3o=o("rembert"),R3o=o(" \u2014 "),_D=a("a"),P3o=o("RemBertModel"),B3o=o(" (RemBERT model)"),I3o=l(),fu=a("li"),wfe=a("strong"),N3o=o("resnet"),q3o=o(" \u2014 "),uD=a("a"),j3o=o("ResNetModel"),D3o=o(" (ResNet model)"),G3o=l(),mu=a("li"),Afe=a("strong"),O3o=o("retribert"),V3o=o(" \u2014 "),bD=a("a"),X3o=o("RetriBertModel"),z3o=o(" (RetriBERT model)"),Q3o=l(),gu=a("li"),Lfe=a("strong"),W3o=o("roberta"),H3o=o(" \u2014 "),vD=a("a"),U3o=o("RobertaModel"),J3o=o(" (RoBERTa model)"),Y3o=l(),hu=a("li"),yfe=a("strong"),K3o=o("roformer"),Z3o=o(" \u2014 "),FD=a("a"),e5o=o("RoFormerModel"),o5o=o(" (RoFormer model)"),r5o=l(),pu=a("li"),xfe=a("strong"),t5o=o("segformer"),a5o=o(" \u2014 "),TD=a("a"),n5o=o("SegformerModel"),s5o=o(" (SegFormer model)"),l5o=l(),_u=a("li"),$fe=a("strong"),i5o=o("sew"),d5o=o(" \u2014 "),MD=a("a"),c5o=o("SEWModel"),f5o=o(" (SEW model)"),m5o=l(),uu=a("li"),kfe=a("strong"),g5o=o("sew-d"),h5o=o(" \u2014 "),ED=a("a"),p5o=o("SEWDModel"),_5o=o(" (SEW-D model)"),u5o=l(),bu=a("li"),Sfe=a("strong"),b5o=o("speech_to_text"),v5o=o(" \u2014 "),CD=a("a"),F5o=o("Speech2TextModel"),T5o=o(" (Speech2Text model)"),M5o=l(),vu=a("li"),Rfe=a("strong"),E5o=o("splinter"),C5o=o(" \u2014 "),wD=a("a"),w5o=o("SplinterModel"),A5o=o(" (Splinter model)"),L5o=l(),Fu=a("li"),Pfe=a("strong"),y5o=o("squeezebert"),x5o=o(" \u2014 "),AD=a("a"),$5o=o("SqueezeBertModel"),k5o=o(" (SqueezeBERT model)"),S5o=l(),Tu=a("li"),Bfe=a("strong"),R5o=o("swin"),P5o=o(" \u2014 "),LD=a("a"),B5o=o("SwinModel"),I5o=o(" (Swin Transformer model)"),N5o=l(),Mu=a("li"),Ife=a("strong"),q5o=o("t5"),j5o=o(" \u2014 "),yD=a("a"),D5o=o("T5Model"),G5o=o(" (T5 model)"),O5o=l(),Eu=a("li"),Nfe=a("strong"),V5o=o("tapas"),X5o=o(" \u2014 "),xD=a("a"),z5o=o("TapasModel"),Q5o=o(" (TAPAS model)"),W5o=l(),Cu=a("li"),qfe=a("strong"),H5o=o("trajectory_transformer"),U5o=o(" \u2014 "),$D=a("a"),J5o=o("TrajectoryTransformerModel"),Y5o=o(" (Trajectory Transformer model)"),K5o=l(),wu=a("li"),jfe=a("strong"),Z5o=o("transfo-xl"),e0o=o(" \u2014 "),kD=a("a"),o0o=o("TransfoXLModel"),r0o=o(" (Transformer-XL model)"),t0o=l(),Au=a("li"),Dfe=a("strong"),a0o=o("unispeech"),n0o=o(" \u2014 "),SD=a("a"),s0o=o("UniSpeechModel"),l0o=o(" (UniSpeech model)"),i0o=l(),Lu=a("li"),Gfe=a("strong"),d0o=o("unispeech-sat"),c0o=o(" \u2014 "),RD=a("a"),f0o=o("UniSpeechSatModel"),m0o=o(" (UniSpeechSat model)"),g0o=l(),yu=a("li"),Ofe=a("strong"),h0o=o("van"),p0o=o(" \u2014 "),PD=a("a"),_0o=o("VanModel"),u0o=o(" (VAN model)"),b0o=l(),xu=a("li"),Vfe=a("strong"),v0o=o("vilt"),F0o=o(" \u2014 "),BD=a("a"),T0o=o("ViltModel"),M0o=o(" (ViLT model)"),E0o=l(),$u=a("li"),Xfe=a("strong"),C0o=o("vision-text-dual-encoder"),w0o=o(" \u2014 "),ID=a("a"),A0o=o("VisionTextDualEncoderModel"),L0o=o(" (VisionTextDualEncoder model)"),y0o=l(),ku=a("li"),zfe=a("strong"),x0o=o("visual_bert"),$0o=o(" \u2014 "),ND=a("a"),k0o=o("VisualBertModel"),S0o=o(" (VisualBERT model)"),R0o=l(),Su=a("li"),Qfe=a("strong"),P0o=o("vit"),B0o=o(" \u2014 "),qD=a("a"),I0o=o("ViTModel"),N0o=o(" (ViT model)"),q0o=l(),Ru=a("li"),Wfe=a("strong"),j0o=o("vit_mae"),D0o=o(" \u2014 "),jD=a("a"),G0o=o("ViTMAEModel"),O0o=o(" (ViTMAE model)"),V0o=l(),Pu=a("li"),Hfe=a("strong"),X0o=o("wav2vec2"),z0o=o(" \u2014 "),DD=a("a"),Q0o=o("Wav2Vec2Model"),W0o=o(" (Wav2Vec2 model)"),H0o=l(),Bu=a("li"),Ufe=a("strong"),U0o=o("wav2vec2-conformer"),J0o=o(" \u2014 "),GD=a("a"),Y0o=o("Wav2Vec2ConformerModel"),K0o=o(" (Wav2Vec2-Conformer model)"),Z0o=l(),Iu=a("li"),Jfe=a("strong"),ewo=o("wavlm"),owo=o(" \u2014 "),OD=a("a"),rwo=o("WavLMModel"),two=o(" (WavLM model)"),awo=l(),Nu=a("li"),Yfe=a("strong"),nwo=o("xglm"),swo=o(" \u2014 "),VD=a("a"),lwo=o("XGLMModel"),iwo=o(" (XGLM model)"),dwo=l(),qu=a("li"),Kfe=a("strong"),cwo=o("xlm"),fwo=o(" \u2014 "),XD=a("a"),mwo=o("XLMModel"),gwo=o(" (XLM model)"),hwo=l(),ju=a("li"),Zfe=a("strong"),pwo=o("xlm-prophetnet"),_wo=o(" \u2014 "),zD=a("a"),uwo=o("XLMProphetNetModel"),bwo=o(" (XLM-ProphetNet model)"),vwo=l(),Du=a("li"),eme=a("strong"),Fwo=o("xlm-roberta"),Two=o(" \u2014 "),QD=a("a"),Mwo=o("XLMRobertaModel"),Ewo=o(" (XLM-RoBERTa model)"),Cwo=l(),Gu=a("li"),ome=a("strong"),wwo=o("xlm-roberta-xl"),Awo=o(" \u2014 "),WD=a("a"),Lwo=o("XLMRobertaXLModel"),ywo=o(" (XLM-RoBERTa-XL model)"),xwo=l(),Ou=a("li"),rme=a("strong"),$wo=o("xlnet"),kwo=o(" \u2014 "),HD=a("a"),Swo=o("XLNetModel"),Rwo=o(" (XLNet model)"),Pwo=l(),Vu=a("li"),tme=a("strong"),Bwo=o("yolos"),Iwo=o(" \u2014 "),UD=a("a"),Nwo=o("YolosModel"),qwo=o(" (YOLOS model)"),jwo=l(),Xu=a("li"),ame=a("strong"),Dwo=o("yoso"),Gwo=o(" \u2014 "),JD=a("a"),Owo=o("YosoModel"),Vwo=o(" (YOSO model)"),Xwo=l(),zu=a("p"),zwo=o("The model is set in evaluation mode by default using "),nme=a("code"),Qwo=o("model.eval()"),Wwo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sme=a("code"),Hwo=o("model.train()"),Uwo=l(),F(Qu.$$.fragment),ZVe=l(),Vi=a("h2"),Wu=a("a"),lme=a("span"),F(SL.$$.fragment),Jwo=l(),ime=a("span"),Ywo=o("AutoModelForPreTraining"),eXe=l(),$o=a("div"),F(RL.$$.fragment),Kwo=l(),Xi=a("p"),Zwo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),YD=a("a"),eAo=o("from_pretrained()"),oAo=o(" class method or the "),KD=a("a"),rAo=o("from_config()"),tAo=o(` class
method.`),aAo=l(),PL=a("p"),nAo=o("This class cannot be instantiated directly using "),dme=a("code"),sAo=o("__init__()"),lAo=o(" (throws an error)."),iAo=l(),it=a("div"),F(BL.$$.fragment),dAo=l(),cme=a("p"),cAo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),fAo=l(),zi=a("p"),mAo=o(`Note:
Loading a model from its configuration file does `),fme=a("strong"),gAo=o("not"),hAo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZD=a("a"),pAo=o("from_pretrained()"),_Ao=o(" to load the model weights."),uAo=l(),F(Hu.$$.fragment),bAo=l(),Ye=a("div"),F(IL.$$.fragment),vAo=l(),mme=a("p"),FAo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),TAo=l(),Ia=a("p"),MAo=o("The model class to instantiate is selected based on the "),gme=a("code"),EAo=o("model_type"),CAo=o(` property of the config object (either
passed as an argument or loaded from `),hme=a("code"),wAo=o("pretrained_model_name_or_path"),AAo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pme=a("code"),LAo=o("pretrained_model_name_or_path"),yAo=o(":"),xAo=l(),G=a("ul"),Uu=a("li"),_me=a("strong"),$Ao=o("albert"),kAo=o(" \u2014 "),eG=a("a"),SAo=o("AlbertForPreTraining"),RAo=o(" (ALBERT model)"),PAo=l(),Ju=a("li"),ume=a("strong"),BAo=o("bart"),IAo=o(" \u2014 "),oG=a("a"),NAo=o("BartForConditionalGeneration"),qAo=o(" (BART model)"),jAo=l(),Yu=a("li"),bme=a("strong"),DAo=o("bert"),GAo=o(" \u2014 "),rG=a("a"),OAo=o("BertForPreTraining"),VAo=o(" (BERT model)"),XAo=l(),Ku=a("li"),vme=a("strong"),zAo=o("big_bird"),QAo=o(" \u2014 "),tG=a("a"),WAo=o("BigBirdForPreTraining"),HAo=o(" (BigBird model)"),UAo=l(),Zu=a("li"),Fme=a("strong"),JAo=o("bloom"),YAo=o(" \u2014 "),aG=a("a"),KAo=o("BloomForCausalLM"),ZAo=o(" (BLOOM model)"),e6o=l(),e1=a("li"),Tme=a("strong"),o6o=o("camembert"),r6o=o(" \u2014 "),nG=a("a"),t6o=o("CamembertForMaskedLM"),a6o=o(" (CamemBERT model)"),n6o=l(),o1=a("li"),Mme=a("strong"),s6o=o("ctrl"),l6o=o(" \u2014 "),sG=a("a"),i6o=o("CTRLLMHeadModel"),d6o=o(" (CTRL model)"),c6o=l(),r1=a("li"),Eme=a("strong"),f6o=o("data2vec-text"),m6o=o(" \u2014 "),lG=a("a"),g6o=o("Data2VecTextForMaskedLM"),h6o=o(" (Data2VecText model)"),p6o=l(),t1=a("li"),Cme=a("strong"),_6o=o("deberta"),u6o=o(" \u2014 "),iG=a("a"),b6o=o("DebertaForMaskedLM"),v6o=o(" (DeBERTa model)"),F6o=l(),a1=a("li"),wme=a("strong"),T6o=o("deberta-v2"),M6o=o(" \u2014 "),dG=a("a"),E6o=o("DebertaV2ForMaskedLM"),C6o=o(" (DeBERTa-v2 model)"),w6o=l(),n1=a("li"),Ame=a("strong"),A6o=o("distilbert"),L6o=o(" \u2014 "),cG=a("a"),y6o=o("DistilBertForMaskedLM"),x6o=o(" (DistilBERT model)"),$6o=l(),s1=a("li"),Lme=a("strong"),k6o=o("electra"),S6o=o(" \u2014 "),fG=a("a"),R6o=o("ElectraForPreTraining"),P6o=o(" (ELECTRA model)"),B6o=l(),l1=a("li"),yme=a("strong"),I6o=o("flaubert"),N6o=o(" \u2014 "),mG=a("a"),q6o=o("FlaubertWithLMHeadModel"),j6o=o(" (FlauBERT model)"),D6o=l(),i1=a("li"),xme=a("strong"),G6o=o("flava"),O6o=o(" \u2014 "),gG=a("a"),V6o=o("FlavaForPreTraining"),X6o=o(" (FLAVA model)"),z6o=l(),d1=a("li"),$me=a("strong"),Q6o=o("fnet"),W6o=o(" \u2014 "),hG=a("a"),H6o=o("FNetForPreTraining"),U6o=o(" (FNet model)"),J6o=l(),c1=a("li"),kme=a("strong"),Y6o=o("fsmt"),K6o=o(" \u2014 "),pG=a("a"),Z6o=o("FSMTForConditionalGeneration"),eLo=o(" (FairSeq Machine-Translation model)"),oLo=l(),f1=a("li"),Sme=a("strong"),rLo=o("funnel"),tLo=o(" \u2014 "),_G=a("a"),aLo=o("FunnelForPreTraining"),nLo=o(" (Funnel Transformer model)"),sLo=l(),m1=a("li"),Rme=a("strong"),lLo=o("gpt2"),iLo=o(" \u2014 "),uG=a("a"),dLo=o("GPT2LMHeadModel"),cLo=o(" (OpenAI GPT-2 model)"),fLo=l(),g1=a("li"),Pme=a("strong"),mLo=o("ibert"),gLo=o(" \u2014 "),bG=a("a"),hLo=o("IBertForMaskedLM"),pLo=o(" (I-BERT model)"),_Lo=l(),h1=a("li"),Bme=a("strong"),uLo=o("layoutlm"),bLo=o(" \u2014 "),vG=a("a"),vLo=o("LayoutLMForMaskedLM"),FLo=o(" (LayoutLM model)"),TLo=l(),p1=a("li"),Ime=a("strong"),MLo=o("longformer"),ELo=o(" \u2014 "),FG=a("a"),CLo=o("LongformerForMaskedLM"),wLo=o(" (Longformer model)"),ALo=l(),_1=a("li"),Nme=a("strong"),LLo=o("lxmert"),yLo=o(" \u2014 "),TG=a("a"),xLo=o("LxmertForPreTraining"),$Lo=o(" (LXMERT model)"),kLo=l(),u1=a("li"),qme=a("strong"),SLo=o("megatron-bert"),RLo=o(" \u2014 "),MG=a("a"),PLo=o("MegatronBertForPreTraining"),BLo=o(" (Megatron-BERT model)"),ILo=l(),b1=a("li"),jme=a("strong"),NLo=o("mobilebert"),qLo=o(" \u2014 "),EG=a("a"),jLo=o("MobileBertForPreTraining"),DLo=o(" (MobileBERT model)"),GLo=l(),v1=a("li"),Dme=a("strong"),OLo=o("mpnet"),VLo=o(" \u2014 "),CG=a("a"),XLo=o("MPNetForMaskedLM"),zLo=o(" (MPNet model)"),QLo=l(),F1=a("li"),Gme=a("strong"),WLo=o("mvp"),HLo=o(" \u2014 "),wG=a("a"),ULo=o("MvpForConditionalGeneration"),JLo=o(" (MVP model)"),YLo=l(),T1=a("li"),Ome=a("strong"),KLo=o("nezha"),ZLo=o(" \u2014 "),AG=a("a"),eyo=o("NezhaForPreTraining"),oyo=o(" (Nezha model)"),ryo=l(),M1=a("li"),Vme=a("strong"),tyo=o("openai-gpt"),ayo=o(" \u2014 "),LG=a("a"),nyo=o("OpenAIGPTLMHeadModel"),syo=o(" (OpenAI GPT model)"),lyo=l(),E1=a("li"),Xme=a("strong"),iyo=o("retribert"),dyo=o(" \u2014 "),yG=a("a"),cyo=o("RetriBertModel"),fyo=o(" (RetriBERT model)"),myo=l(),C1=a("li"),zme=a("strong"),gyo=o("roberta"),hyo=o(" \u2014 "),xG=a("a"),pyo=o("RobertaForMaskedLM"),_yo=o(" (RoBERTa model)"),uyo=l(),w1=a("li"),Qme=a("strong"),byo=o("splinter"),vyo=o(" \u2014 "),$G=a("a"),Fyo=o("SplinterForPreTraining"),Tyo=o(" (Splinter model)"),Myo=l(),A1=a("li"),Wme=a("strong"),Eyo=o("squeezebert"),Cyo=o(" \u2014 "),kG=a("a"),wyo=o("SqueezeBertForMaskedLM"),Ayo=o(" (SqueezeBERT model)"),Lyo=l(),L1=a("li"),Hme=a("strong"),yyo=o("t5"),xyo=o(" \u2014 "),SG=a("a"),$yo=o("T5ForConditionalGeneration"),kyo=o(" (T5 model)"),Syo=l(),y1=a("li"),Ume=a("strong"),Ryo=o("tapas"),Pyo=o(" \u2014 "),RG=a("a"),Byo=o("TapasForMaskedLM"),Iyo=o(" (TAPAS model)"),Nyo=l(),x1=a("li"),Jme=a("strong"),qyo=o("transfo-xl"),jyo=o(" \u2014 "),PG=a("a"),Dyo=o("TransfoXLLMHeadModel"),Gyo=o(" (Transformer-XL model)"),Oyo=l(),$1=a("li"),Yme=a("strong"),Vyo=o("unispeech"),Xyo=o(" \u2014 "),BG=a("a"),zyo=o("UniSpeechForPreTraining"),Qyo=o(" (UniSpeech model)"),Wyo=l(),k1=a("li"),Kme=a("strong"),Hyo=o("unispeech-sat"),Uyo=o(" \u2014 "),IG=a("a"),Jyo=o("UniSpeechSatForPreTraining"),Yyo=o(" (UniSpeechSat model)"),Kyo=l(),S1=a("li"),Zme=a("strong"),Zyo=o("visual_bert"),e9o=o(" \u2014 "),NG=a("a"),o9o=o("VisualBertForPreTraining"),r9o=o(" (VisualBERT model)"),t9o=l(),R1=a("li"),ege=a("strong"),a9o=o("vit_mae"),n9o=o(" \u2014 "),qG=a("a"),s9o=o("ViTMAEForPreTraining"),l9o=o(" (ViTMAE model)"),i9o=l(),P1=a("li"),oge=a("strong"),d9o=o("wav2vec2"),c9o=o(" \u2014 "),jG=a("a"),f9o=o("Wav2Vec2ForPreTraining"),m9o=o(" (Wav2Vec2 model)"),g9o=l(),B1=a("li"),rge=a("strong"),h9o=o("wav2vec2-conformer"),p9o=o(" \u2014 "),DG=a("a"),_9o=o("Wav2Vec2ConformerForPreTraining"),u9o=o(" (Wav2Vec2-Conformer model)"),b9o=l(),I1=a("li"),tge=a("strong"),v9o=o("xlm"),F9o=o(" \u2014 "),GG=a("a"),T9o=o("XLMWithLMHeadModel"),M9o=o(" (XLM model)"),E9o=l(),N1=a("li"),age=a("strong"),C9o=o("xlm-roberta"),w9o=o(" \u2014 "),OG=a("a"),A9o=o("XLMRobertaForMaskedLM"),L9o=o(" (XLM-RoBERTa model)"),y9o=l(),q1=a("li"),nge=a("strong"),x9o=o("xlm-roberta-xl"),$9o=o(" \u2014 "),VG=a("a"),k9o=o("XLMRobertaXLForMaskedLM"),S9o=o(" (XLM-RoBERTa-XL model)"),R9o=l(),j1=a("li"),sge=a("strong"),P9o=o("xlnet"),B9o=o(" \u2014 "),XG=a("a"),I9o=o("XLNetLMHeadModel"),N9o=o(" (XLNet model)"),q9o=l(),D1=a("p"),j9o=o("The model is set in evaluation mode by default using "),lge=a("code"),D9o=o("model.eval()"),G9o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ige=a("code"),O9o=o("model.train()"),V9o=l(),F(G1.$$.fragment),oXe=l(),Qi=a("h2"),O1=a("a"),dge=a("span"),F(NL.$$.fragment),X9o=l(),cge=a("span"),z9o=o("AutoModelForCausalLM"),rXe=l(),ko=a("div"),F(qL.$$.fragment),Q9o=l(),Wi=a("p"),W9o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),zG=a("a"),H9o=o("from_pretrained()"),U9o=o(" class method or the "),QG=a("a"),J9o=o("from_config()"),Y9o=o(` class
method.`),K9o=l(),jL=a("p"),Z9o=o("This class cannot be instantiated directly using "),fge=a("code"),exo=o("__init__()"),oxo=o(" (throws an error)."),rxo=l(),dt=a("div"),F(DL.$$.fragment),txo=l(),mge=a("p"),axo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),nxo=l(),Hi=a("p"),sxo=o(`Note:
Loading a model from its configuration file does `),gge=a("strong"),lxo=o("not"),ixo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WG=a("a"),dxo=o("from_pretrained()"),cxo=o(" to load the model weights."),fxo=l(),F(V1.$$.fragment),mxo=l(),Ke=a("div"),F(GL.$$.fragment),gxo=l(),hge=a("p"),hxo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),pxo=l(),Na=a("p"),_xo=o("The model class to instantiate is selected based on the "),pge=a("code"),uxo=o("model_type"),bxo=o(` property of the config object (either
passed as an argument or loaded from `),_ge=a("code"),vxo=o("pretrained_model_name_or_path"),Fxo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uge=a("code"),Txo=o("pretrained_model_name_or_path"),Mxo=o(":"),Exo=l(),z=a("ul"),X1=a("li"),bge=a("strong"),Cxo=o("bart"),wxo=o(" \u2014 "),HG=a("a"),Axo=o("BartForCausalLM"),Lxo=o(" (BART model)"),yxo=l(),z1=a("li"),vge=a("strong"),xxo=o("bert"),$xo=o(" \u2014 "),UG=a("a"),kxo=o("BertLMHeadModel"),Sxo=o(" (BERT model)"),Rxo=l(),Q1=a("li"),Fge=a("strong"),Pxo=o("bert-generation"),Bxo=o(" \u2014 "),JG=a("a"),Ixo=o("BertGenerationDecoder"),Nxo=o(" (Bert Generation model)"),qxo=l(),W1=a("li"),Tge=a("strong"),jxo=o("big_bird"),Dxo=o(" \u2014 "),YG=a("a"),Gxo=o("BigBirdForCausalLM"),Oxo=o(" (BigBird model)"),Vxo=l(),H1=a("li"),Mge=a("strong"),Xxo=o("bigbird_pegasus"),zxo=o(" \u2014 "),KG=a("a"),Qxo=o("BigBirdPegasusForCausalLM"),Wxo=o(" (BigBird-Pegasus model)"),Hxo=l(),U1=a("li"),Ege=a("strong"),Uxo=o("blenderbot"),Jxo=o(" \u2014 "),ZG=a("a"),Yxo=o("BlenderbotForCausalLM"),Kxo=o(" (Blenderbot model)"),Zxo=l(),J1=a("li"),Cge=a("strong"),e$o=o("blenderbot-small"),o$o=o(" \u2014 "),eO=a("a"),r$o=o("BlenderbotSmallForCausalLM"),t$o=o(" (BlenderbotSmall model)"),a$o=l(),Y1=a("li"),wge=a("strong"),n$o=o("bloom"),s$o=o(" \u2014 "),oO=a("a"),l$o=o("BloomForCausalLM"),i$o=o(" (BLOOM model)"),d$o=l(),K1=a("li"),Age=a("strong"),c$o=o("camembert"),f$o=o(" \u2014 "),rO=a("a"),m$o=o("CamembertForCausalLM"),g$o=o(" (CamemBERT model)"),h$o=l(),Z1=a("li"),Lge=a("strong"),p$o=o("codegen"),_$o=o(" \u2014 "),tO=a("a"),u$o=o("CodeGenForCausalLM"),b$o=o(" (CodeGen model)"),v$o=l(),e2=a("li"),yge=a("strong"),F$o=o("ctrl"),T$o=o(" \u2014 "),aO=a("a"),M$o=o("CTRLLMHeadModel"),E$o=o(" (CTRL model)"),C$o=l(),o2=a("li"),xge=a("strong"),w$o=o("data2vec-text"),A$o=o(" \u2014 "),nO=a("a"),L$o=o("Data2VecTextForCausalLM"),y$o=o(" (Data2VecText model)"),x$o=l(),r2=a("li"),$ge=a("strong"),$$o=o("electra"),k$o=o(" \u2014 "),sO=a("a"),S$o=o("ElectraForCausalLM"),R$o=o(" (ELECTRA model)"),P$o=l(),t2=a("li"),kge=a("strong"),B$o=o("gpt2"),I$o=o(" \u2014 "),lO=a("a"),N$o=o("GPT2LMHeadModel"),q$o=o(" (OpenAI GPT-2 model)"),j$o=l(),a2=a("li"),Sge=a("strong"),D$o=o("gpt_neo"),G$o=o(" \u2014 "),iO=a("a"),O$o=o("GPTNeoForCausalLM"),V$o=o(" (GPT Neo model)"),X$o=l(),n2=a("li"),Rge=a("strong"),z$o=o("gpt_neox"),Q$o=o(" \u2014 "),dO=a("a"),W$o=o("GPTNeoXForCausalLM"),H$o=o(" (GPT NeoX model)"),U$o=l(),s2=a("li"),Pge=a("strong"),J$o=o("gptj"),Y$o=o(" \u2014 "),cO=a("a"),K$o=o("GPTJForCausalLM"),Z$o=o(" (GPT-J model)"),eko=l(),l2=a("li"),Bge=a("strong"),oko=o("marian"),rko=o(" \u2014 "),fO=a("a"),tko=o("MarianForCausalLM"),ako=o(" (Marian model)"),nko=l(),i2=a("li"),Ige=a("strong"),sko=o("mbart"),lko=o(" \u2014 "),mO=a("a"),iko=o("MBartForCausalLM"),dko=o(" (mBART model)"),cko=l(),d2=a("li"),Nge=a("strong"),fko=o("megatron-bert"),mko=o(" \u2014 "),gO=a("a"),gko=o("MegatronBertForCausalLM"),hko=o(" (Megatron-BERT model)"),pko=l(),c2=a("li"),qge=a("strong"),_ko=o("mvp"),uko=o(" \u2014 "),hO=a("a"),bko=o("MvpForCausalLM"),vko=o(" (MVP model)"),Fko=l(),f2=a("li"),jge=a("strong"),Tko=o("openai-gpt"),Mko=o(" \u2014 "),pO=a("a"),Eko=o("OpenAIGPTLMHeadModel"),Cko=o(" (OpenAI GPT model)"),wko=l(),m2=a("li"),Dge=a("strong"),Ako=o("opt"),Lko=o(" \u2014 "),_O=a("a"),yko=o("OPTForCausalLM"),xko=o(" (OPT model)"),$ko=l(),g2=a("li"),Gge=a("strong"),kko=o("pegasus"),Sko=o(" \u2014 "),uO=a("a"),Rko=o("PegasusForCausalLM"),Pko=o(" (Pegasus model)"),Bko=l(),h2=a("li"),Oge=a("strong"),Iko=o("plbart"),Nko=o(" \u2014 "),bO=a("a"),qko=o("PLBartForCausalLM"),jko=o(" (PLBart model)"),Dko=l(),p2=a("li"),Vge=a("strong"),Gko=o("prophetnet"),Oko=o(" \u2014 "),vO=a("a"),Vko=o("ProphetNetForCausalLM"),Xko=o(" (ProphetNet model)"),zko=l(),_2=a("li"),Xge=a("strong"),Qko=o("qdqbert"),Wko=o(" \u2014 "),FO=a("a"),Hko=o("QDQBertLMHeadModel"),Uko=o(" (QDQBert model)"),Jko=l(),u2=a("li"),zge=a("strong"),Yko=o("reformer"),Kko=o(" \u2014 "),TO=a("a"),Zko=o("ReformerModelWithLMHead"),eSo=o(" (Reformer model)"),oSo=l(),b2=a("li"),Qge=a("strong"),rSo=o("rembert"),tSo=o(" \u2014 "),MO=a("a"),aSo=o("RemBertForCausalLM"),nSo=o(" (RemBERT model)"),sSo=l(),v2=a("li"),Wge=a("strong"),lSo=o("roberta"),iSo=o(" \u2014 "),EO=a("a"),dSo=o("RobertaForCausalLM"),cSo=o(" (RoBERTa model)"),fSo=l(),F2=a("li"),Hge=a("strong"),mSo=o("roformer"),gSo=o(" \u2014 "),CO=a("a"),hSo=o("RoFormerForCausalLM"),pSo=o(" (RoFormer model)"),_So=l(),T2=a("li"),Uge=a("strong"),uSo=o("speech_to_text_2"),bSo=o(" \u2014 "),wO=a("a"),vSo=o("Speech2Text2ForCausalLM"),FSo=o(" (Speech2Text2 model)"),TSo=l(),M2=a("li"),Jge=a("strong"),MSo=o("transfo-xl"),ESo=o(" \u2014 "),AO=a("a"),CSo=o("TransfoXLLMHeadModel"),wSo=o(" (Transformer-XL model)"),ASo=l(),E2=a("li"),Yge=a("strong"),LSo=o("trocr"),ySo=o(" \u2014 "),LO=a("a"),xSo=o("TrOCRForCausalLM"),$So=o(" (TrOCR model)"),kSo=l(),C2=a("li"),Kge=a("strong"),SSo=o("xglm"),RSo=o(" \u2014 "),yO=a("a"),PSo=o("XGLMForCausalLM"),BSo=o(" (XGLM model)"),ISo=l(),w2=a("li"),Zge=a("strong"),NSo=o("xlm"),qSo=o(" \u2014 "),xO=a("a"),jSo=o("XLMWithLMHeadModel"),DSo=o(" (XLM model)"),GSo=l(),A2=a("li"),ehe=a("strong"),OSo=o("xlm-prophetnet"),VSo=o(" \u2014 "),$O=a("a"),XSo=o("XLMProphetNetForCausalLM"),zSo=o(" (XLM-ProphetNet model)"),QSo=l(),L2=a("li"),ohe=a("strong"),WSo=o("xlm-roberta"),HSo=o(" \u2014 "),kO=a("a"),USo=o("XLMRobertaForCausalLM"),JSo=o(" (XLM-RoBERTa model)"),YSo=l(),y2=a("li"),rhe=a("strong"),KSo=o("xlm-roberta-xl"),ZSo=o(" \u2014 "),SO=a("a"),eRo=o("XLMRobertaXLForCausalLM"),oRo=o(" (XLM-RoBERTa-XL model)"),rRo=l(),x2=a("li"),the=a("strong"),tRo=o("xlnet"),aRo=o(" \u2014 "),RO=a("a"),nRo=o("XLNetLMHeadModel"),sRo=o(" (XLNet model)"),lRo=l(),$2=a("p"),iRo=o("The model is set in evaluation mode by default using "),ahe=a("code"),dRo=o("model.eval()"),cRo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nhe=a("code"),fRo=o("model.train()"),mRo=l(),F(k2.$$.fragment),tXe=l(),Ui=a("h2"),S2=a("a"),she=a("span"),F(OL.$$.fragment),gRo=l(),lhe=a("span"),hRo=o("AutoModelForMaskedLM"),aXe=l(),So=a("div"),F(VL.$$.fragment),pRo=l(),Ji=a("p"),_Ro=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),PO=a("a"),uRo=o("from_pretrained()"),bRo=o(" class method or the "),BO=a("a"),vRo=o("from_config()"),FRo=o(` class
method.`),TRo=l(),XL=a("p"),MRo=o("This class cannot be instantiated directly using "),ihe=a("code"),ERo=o("__init__()"),CRo=o(" (throws an error)."),wRo=l(),ct=a("div"),F(zL.$$.fragment),ARo=l(),dhe=a("p"),LRo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),yRo=l(),Yi=a("p"),xRo=o(`Note:
Loading a model from its configuration file does `),che=a("strong"),$Ro=o("not"),kRo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IO=a("a"),SRo=o("from_pretrained()"),RRo=o(" to load the model weights."),PRo=l(),F(R2.$$.fragment),BRo=l(),Ze=a("div"),F(QL.$$.fragment),IRo=l(),fhe=a("p"),NRo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),qRo=l(),qa=a("p"),jRo=o("The model class to instantiate is selected based on the "),mhe=a("code"),DRo=o("model_type"),GRo=o(` property of the config object (either
passed as an argument or loaded from `),ghe=a("code"),ORo=o("pretrained_model_name_or_path"),VRo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hhe=a("code"),XRo=o("pretrained_model_name_or_path"),zRo=o(":"),QRo=l(),W=a("ul"),P2=a("li"),phe=a("strong"),WRo=o("albert"),HRo=o(" \u2014 "),NO=a("a"),URo=o("AlbertForMaskedLM"),JRo=o(" (ALBERT model)"),YRo=l(),B2=a("li"),_he=a("strong"),KRo=o("bart"),ZRo=o(" \u2014 "),qO=a("a"),ePo=o("BartForConditionalGeneration"),oPo=o(" (BART model)"),rPo=l(),I2=a("li"),uhe=a("strong"),tPo=o("bert"),aPo=o(" \u2014 "),jO=a("a"),nPo=o("BertForMaskedLM"),sPo=o(" (BERT model)"),lPo=l(),N2=a("li"),bhe=a("strong"),iPo=o("big_bird"),dPo=o(" \u2014 "),DO=a("a"),cPo=o("BigBirdForMaskedLM"),fPo=o(" (BigBird model)"),mPo=l(),q2=a("li"),vhe=a("strong"),gPo=o("camembert"),hPo=o(" \u2014 "),GO=a("a"),pPo=o("CamembertForMaskedLM"),_Po=o(" (CamemBERT model)"),uPo=l(),j2=a("li"),Fhe=a("strong"),bPo=o("convbert"),vPo=o(" \u2014 "),OO=a("a"),FPo=o("ConvBertForMaskedLM"),TPo=o(" (ConvBERT model)"),MPo=l(),D2=a("li"),The=a("strong"),EPo=o("data2vec-text"),CPo=o(" \u2014 "),VO=a("a"),wPo=o("Data2VecTextForMaskedLM"),APo=o(" (Data2VecText model)"),LPo=l(),G2=a("li"),Mhe=a("strong"),yPo=o("deberta"),xPo=o(" \u2014 "),XO=a("a"),$Po=o("DebertaForMaskedLM"),kPo=o(" (DeBERTa model)"),SPo=l(),O2=a("li"),Ehe=a("strong"),RPo=o("deberta-v2"),PPo=o(" \u2014 "),zO=a("a"),BPo=o("DebertaV2ForMaskedLM"),IPo=o(" (DeBERTa-v2 model)"),NPo=l(),V2=a("li"),Che=a("strong"),qPo=o("distilbert"),jPo=o(" \u2014 "),QO=a("a"),DPo=o("DistilBertForMaskedLM"),GPo=o(" (DistilBERT model)"),OPo=l(),X2=a("li"),whe=a("strong"),VPo=o("electra"),XPo=o(" \u2014 "),WO=a("a"),zPo=o("ElectraForMaskedLM"),QPo=o(" (ELECTRA model)"),WPo=l(),z2=a("li"),Ahe=a("strong"),HPo=o("flaubert"),UPo=o(" \u2014 "),HO=a("a"),JPo=o("FlaubertWithLMHeadModel"),YPo=o(" (FlauBERT model)"),KPo=l(),Q2=a("li"),Lhe=a("strong"),ZPo=o("fnet"),eBo=o(" \u2014 "),UO=a("a"),oBo=o("FNetForMaskedLM"),rBo=o(" (FNet model)"),tBo=l(),W2=a("li"),yhe=a("strong"),aBo=o("funnel"),nBo=o(" \u2014 "),JO=a("a"),sBo=o("FunnelForMaskedLM"),lBo=o(" (Funnel Transformer model)"),iBo=l(),H2=a("li"),xhe=a("strong"),dBo=o("ibert"),cBo=o(" \u2014 "),YO=a("a"),fBo=o("IBertForMaskedLM"),mBo=o(" (I-BERT model)"),gBo=l(),U2=a("li"),$he=a("strong"),hBo=o("layoutlm"),pBo=o(" \u2014 "),KO=a("a"),_Bo=o("LayoutLMForMaskedLM"),uBo=o(" (LayoutLM model)"),bBo=l(),J2=a("li"),khe=a("strong"),vBo=o("longformer"),FBo=o(" \u2014 "),ZO=a("a"),TBo=o("LongformerForMaskedLM"),MBo=o(" (Longformer model)"),EBo=l(),Y2=a("li"),She=a("strong"),CBo=o("luke"),wBo=o(" \u2014 "),eV=a("a"),ABo=o("LukeForMaskedLM"),LBo=o(" (LUKE model)"),yBo=l(),K2=a("li"),Rhe=a("strong"),xBo=o("mbart"),$Bo=o(" \u2014 "),oV=a("a"),kBo=o("MBartForConditionalGeneration"),SBo=o(" (mBART model)"),RBo=l(),Z2=a("li"),Phe=a("strong"),PBo=o("megatron-bert"),BBo=o(" \u2014 "),rV=a("a"),IBo=o("MegatronBertForMaskedLM"),NBo=o(" (Megatron-BERT model)"),qBo=l(),eb=a("li"),Bhe=a("strong"),jBo=o("mobilebert"),DBo=o(" \u2014 "),tV=a("a"),GBo=o("MobileBertForMaskedLM"),OBo=o(" (MobileBERT model)"),VBo=l(),ob=a("li"),Ihe=a("strong"),XBo=o("mpnet"),zBo=o(" \u2014 "),aV=a("a"),QBo=o("MPNetForMaskedLM"),WBo=o(" (MPNet model)"),HBo=l(),rb=a("li"),Nhe=a("strong"),UBo=o("mvp"),JBo=o(" \u2014 "),nV=a("a"),YBo=o("MvpForConditionalGeneration"),KBo=o(" (MVP model)"),ZBo=l(),tb=a("li"),qhe=a("strong"),eIo=o("nezha"),oIo=o(" \u2014 "),sV=a("a"),rIo=o("NezhaForMaskedLM"),tIo=o(" (Nezha model)"),aIo=l(),ab=a("li"),jhe=a("strong"),nIo=o("nystromformer"),sIo=o(" \u2014 "),lV=a("a"),lIo=o("NystromformerForMaskedLM"),iIo=o(" (Nystr\xF6mformer model)"),dIo=l(),nb=a("li"),Dhe=a("strong"),cIo=o("perceiver"),fIo=o(" \u2014 "),iV=a("a"),mIo=o("PerceiverForMaskedLM"),gIo=o(" (Perceiver model)"),hIo=l(),sb=a("li"),Ghe=a("strong"),pIo=o("qdqbert"),_Io=o(" \u2014 "),dV=a("a"),uIo=o("QDQBertForMaskedLM"),bIo=o(" (QDQBert model)"),vIo=l(),lb=a("li"),Ohe=a("strong"),FIo=o("reformer"),TIo=o(" \u2014 "),cV=a("a"),MIo=o("ReformerForMaskedLM"),EIo=o(" (Reformer model)"),CIo=l(),ib=a("li"),Vhe=a("strong"),wIo=o("rembert"),AIo=o(" \u2014 "),fV=a("a"),LIo=o("RemBertForMaskedLM"),yIo=o(" (RemBERT model)"),xIo=l(),db=a("li"),Xhe=a("strong"),$Io=o("roberta"),kIo=o(" \u2014 "),mV=a("a"),SIo=o("RobertaForMaskedLM"),RIo=o(" (RoBERTa model)"),PIo=l(),cb=a("li"),zhe=a("strong"),BIo=o("roformer"),IIo=o(" \u2014 "),gV=a("a"),NIo=o("RoFormerForMaskedLM"),qIo=o(" (RoFormer model)"),jIo=l(),fb=a("li"),Qhe=a("strong"),DIo=o("squeezebert"),GIo=o(" \u2014 "),hV=a("a"),OIo=o("SqueezeBertForMaskedLM"),VIo=o(" (SqueezeBERT model)"),XIo=l(),mb=a("li"),Whe=a("strong"),zIo=o("tapas"),QIo=o(" \u2014 "),pV=a("a"),WIo=o("TapasForMaskedLM"),HIo=o(" (TAPAS model)"),UIo=l(),gb=a("li"),Hhe=a("strong"),JIo=o("wav2vec2"),YIo=o(" \u2014 "),Uhe=a("code"),KIo=o("Wav2Vec2ForMaskedLM"),ZIo=o(" (Wav2Vec2 model)"),eNo=l(),hb=a("li"),Jhe=a("strong"),oNo=o("xlm"),rNo=o(" \u2014 "),_V=a("a"),tNo=o("XLMWithLMHeadModel"),aNo=o(" (XLM model)"),nNo=l(),pb=a("li"),Yhe=a("strong"),sNo=o("xlm-roberta"),lNo=o(" \u2014 "),uV=a("a"),iNo=o("XLMRobertaForMaskedLM"),dNo=o(" (XLM-RoBERTa model)"),cNo=l(),_b=a("li"),Khe=a("strong"),fNo=o("xlm-roberta-xl"),mNo=o(" \u2014 "),bV=a("a"),gNo=o("XLMRobertaXLForMaskedLM"),hNo=o(" (XLM-RoBERTa-XL model)"),pNo=l(),ub=a("li"),Zhe=a("strong"),_No=o("yoso"),uNo=o(" \u2014 "),vV=a("a"),bNo=o("YosoForMaskedLM"),vNo=o(" (YOSO model)"),FNo=l(),bb=a("p"),TNo=o("The model is set in evaluation mode by default using "),epe=a("code"),MNo=o("model.eval()"),ENo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ope=a("code"),CNo=o("model.train()"),wNo=l(),F(vb.$$.fragment),nXe=l(),Ki=a("h2"),Fb=a("a"),rpe=a("span"),F(WL.$$.fragment),ANo=l(),tpe=a("span"),LNo=o("AutoModelForSeq2SeqLM"),sXe=l(),Ro=a("div"),F(HL.$$.fragment),yNo=l(),Zi=a("p"),xNo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),FV=a("a"),$No=o("from_pretrained()"),kNo=o(" class method or the "),TV=a("a"),SNo=o("from_config()"),RNo=o(` class
method.`),PNo=l(),UL=a("p"),BNo=o("This class cannot be instantiated directly using "),ape=a("code"),INo=o("__init__()"),NNo=o(" (throws an error)."),qNo=l(),ft=a("div"),F(JL.$$.fragment),jNo=l(),npe=a("p"),DNo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),GNo=l(),ed=a("p"),ONo=o(`Note:
Loading a model from its configuration file does `),spe=a("strong"),VNo=o("not"),XNo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MV=a("a"),zNo=o("from_pretrained()"),QNo=o(" to load the model weights."),WNo=l(),F(Tb.$$.fragment),HNo=l(),eo=a("div"),F(YL.$$.fragment),UNo=l(),lpe=a("p"),JNo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),YNo=l(),ja=a("p"),KNo=o("The model class to instantiate is selected based on the "),ipe=a("code"),ZNo=o("model_type"),eqo=o(` property of the config object (either
passed as an argument or loaded from `),dpe=a("code"),oqo=o("pretrained_model_name_or_path"),rqo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cpe=a("code"),tqo=o("pretrained_model_name_or_path"),aqo=o(":"),nqo=l(),pe=a("ul"),Mb=a("li"),fpe=a("strong"),sqo=o("bart"),lqo=o(" \u2014 "),EV=a("a"),iqo=o("BartForConditionalGeneration"),dqo=o(" (BART model)"),cqo=l(),Eb=a("li"),mpe=a("strong"),fqo=o("bigbird_pegasus"),mqo=o(" \u2014 "),CV=a("a"),gqo=o("BigBirdPegasusForConditionalGeneration"),hqo=o(" (BigBird-Pegasus model)"),pqo=l(),Cb=a("li"),gpe=a("strong"),_qo=o("blenderbot"),uqo=o(" \u2014 "),wV=a("a"),bqo=o("BlenderbotForConditionalGeneration"),vqo=o(" (Blenderbot model)"),Fqo=l(),wb=a("li"),hpe=a("strong"),Tqo=o("blenderbot-small"),Mqo=o(" \u2014 "),AV=a("a"),Eqo=o("BlenderbotSmallForConditionalGeneration"),Cqo=o(" (BlenderbotSmall model)"),wqo=l(),Ab=a("li"),ppe=a("strong"),Aqo=o("encoder-decoder"),Lqo=o(" \u2014 "),LV=a("a"),yqo=o("EncoderDecoderModel"),xqo=o(" (Encoder decoder model)"),$qo=l(),Lb=a("li"),_pe=a("strong"),kqo=o("fsmt"),Sqo=o(" \u2014 "),yV=a("a"),Rqo=o("FSMTForConditionalGeneration"),Pqo=o(" (FairSeq Machine-Translation model)"),Bqo=l(),yb=a("li"),upe=a("strong"),Iqo=o("led"),Nqo=o(" \u2014 "),xV=a("a"),qqo=o("LEDForConditionalGeneration"),jqo=o(" (LED model)"),Dqo=l(),xb=a("li"),bpe=a("strong"),Gqo=o("longt5"),Oqo=o(" \u2014 "),$V=a("a"),Vqo=o("LongT5ForConditionalGeneration"),Xqo=o(" (LongT5 model)"),zqo=l(),$b=a("li"),vpe=a("strong"),Qqo=o("m2m_100"),Wqo=o(" \u2014 "),kV=a("a"),Hqo=o("M2M100ForConditionalGeneration"),Uqo=o(" (M2M100 model)"),Jqo=l(),kb=a("li"),Fpe=a("strong"),Yqo=o("marian"),Kqo=o(" \u2014 "),SV=a("a"),Zqo=o("MarianMTModel"),ejo=o(" (Marian model)"),ojo=l(),Sb=a("li"),Tpe=a("strong"),rjo=o("mbart"),tjo=o(" \u2014 "),RV=a("a"),ajo=o("MBartForConditionalGeneration"),njo=o(" (mBART model)"),sjo=l(),Rb=a("li"),Mpe=a("strong"),ljo=o("mt5"),ijo=o(" \u2014 "),PV=a("a"),djo=o("MT5ForConditionalGeneration"),cjo=o(" (MT5 model)"),fjo=l(),Pb=a("li"),Epe=a("strong"),mjo=o("mvp"),gjo=o(" \u2014 "),BV=a("a"),hjo=o("MvpForConditionalGeneration"),pjo=o(" (MVP model)"),_jo=l(),Bb=a("li"),Cpe=a("strong"),ujo=o("pegasus"),bjo=o(" \u2014 "),IV=a("a"),vjo=o("PegasusForConditionalGeneration"),Fjo=o(" (Pegasus model)"),Tjo=l(),Ib=a("li"),wpe=a("strong"),Mjo=o("plbart"),Ejo=o(" \u2014 "),NV=a("a"),Cjo=o("PLBartForConditionalGeneration"),wjo=o(" (PLBart model)"),Ajo=l(),Nb=a("li"),Ape=a("strong"),Ljo=o("prophetnet"),yjo=o(" \u2014 "),qV=a("a"),xjo=o("ProphetNetForConditionalGeneration"),$jo=o(" (ProphetNet model)"),kjo=l(),qb=a("li"),Lpe=a("strong"),Sjo=o("t5"),Rjo=o(" \u2014 "),jV=a("a"),Pjo=o("T5ForConditionalGeneration"),Bjo=o(" (T5 model)"),Ijo=l(),jb=a("li"),ype=a("strong"),Njo=o("xlm-prophetnet"),qjo=o(" \u2014 "),DV=a("a"),jjo=o("XLMProphetNetForConditionalGeneration"),Djo=o(" (XLM-ProphetNet model)"),Gjo=l(),Db=a("p"),Ojo=o("The model is set in evaluation mode by default using "),xpe=a("code"),Vjo=o("model.eval()"),Xjo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$pe=a("code"),zjo=o("model.train()"),Qjo=l(),F(Gb.$$.fragment),lXe=l(),od=a("h2"),Ob=a("a"),kpe=a("span"),F(KL.$$.fragment),Wjo=l(),Spe=a("span"),Hjo=o("AutoModelForSequenceClassification"),iXe=l(),Po=a("div"),F(ZL.$$.fragment),Ujo=l(),rd=a("p"),Jjo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),GV=a("a"),Yjo=o("from_pretrained()"),Kjo=o(" class method or the "),OV=a("a"),Zjo=o("from_config()"),eDo=o(` class
method.`),oDo=l(),ey=a("p"),rDo=o("This class cannot be instantiated directly using "),Rpe=a("code"),tDo=o("__init__()"),aDo=o(" (throws an error)."),nDo=l(),mt=a("div"),F(oy.$$.fragment),sDo=l(),Ppe=a("p"),lDo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),iDo=l(),td=a("p"),dDo=o(`Note:
Loading a model from its configuration file does `),Bpe=a("strong"),cDo=o("not"),fDo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VV=a("a"),mDo=o("from_pretrained()"),gDo=o(" to load the model weights."),hDo=l(),F(Vb.$$.fragment),pDo=l(),oo=a("div"),F(ry.$$.fragment),_Do=l(),Ipe=a("p"),uDo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),bDo=l(),Da=a("p"),vDo=o("The model class to instantiate is selected based on the "),Npe=a("code"),FDo=o("model_type"),TDo=o(` property of the config object (either
passed as an argument or loaded from `),qpe=a("code"),MDo=o("pretrained_model_name_or_path"),EDo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jpe=a("code"),CDo=o("pretrained_model_name_or_path"),wDo=o(":"),ADo=l(),N=a("ul"),Xb=a("li"),Dpe=a("strong"),LDo=o("albert"),yDo=o(" \u2014 "),XV=a("a"),xDo=o("AlbertForSequenceClassification"),$Do=o(" (ALBERT model)"),kDo=l(),zb=a("li"),Gpe=a("strong"),SDo=o("bart"),RDo=o(" \u2014 "),zV=a("a"),PDo=o("BartForSequenceClassification"),BDo=o(" (BART model)"),IDo=l(),Qb=a("li"),Ope=a("strong"),NDo=o("bert"),qDo=o(" \u2014 "),QV=a("a"),jDo=o("BertForSequenceClassification"),DDo=o(" (BERT model)"),GDo=l(),Wb=a("li"),Vpe=a("strong"),ODo=o("big_bird"),VDo=o(" \u2014 "),WV=a("a"),XDo=o("BigBirdForSequenceClassification"),zDo=o(" (BigBird model)"),QDo=l(),Hb=a("li"),Xpe=a("strong"),WDo=o("bigbird_pegasus"),HDo=o(" \u2014 "),HV=a("a"),UDo=o("BigBirdPegasusForSequenceClassification"),JDo=o(" (BigBird-Pegasus model)"),YDo=l(),Ub=a("li"),zpe=a("strong"),KDo=o("bloom"),ZDo=o(" \u2014 "),UV=a("a"),eGo=o("BloomForSequenceClassification"),oGo=o(" (BLOOM model)"),rGo=l(),Jb=a("li"),Qpe=a("strong"),tGo=o("camembert"),aGo=o(" \u2014 "),JV=a("a"),nGo=o("CamembertForSequenceClassification"),sGo=o(" (CamemBERT model)"),lGo=l(),Yb=a("li"),Wpe=a("strong"),iGo=o("canine"),dGo=o(" \u2014 "),YV=a("a"),cGo=o("CanineForSequenceClassification"),fGo=o(" (CANINE model)"),mGo=l(),Kb=a("li"),Hpe=a("strong"),gGo=o("convbert"),hGo=o(" \u2014 "),KV=a("a"),pGo=o("ConvBertForSequenceClassification"),_Go=o(" (ConvBERT model)"),uGo=l(),Zb=a("li"),Upe=a("strong"),bGo=o("ctrl"),vGo=o(" \u2014 "),ZV=a("a"),FGo=o("CTRLForSequenceClassification"),TGo=o(" (CTRL model)"),MGo=l(),ev=a("li"),Jpe=a("strong"),EGo=o("data2vec-text"),CGo=o(" \u2014 "),eX=a("a"),wGo=o("Data2VecTextForSequenceClassification"),AGo=o(" (Data2VecText model)"),LGo=l(),ov=a("li"),Ype=a("strong"),yGo=o("deberta"),xGo=o(" \u2014 "),oX=a("a"),$Go=o("DebertaForSequenceClassification"),kGo=o(" (DeBERTa model)"),SGo=l(),rv=a("li"),Kpe=a("strong"),RGo=o("deberta-v2"),PGo=o(" \u2014 "),rX=a("a"),BGo=o("DebertaV2ForSequenceClassification"),IGo=o(" (DeBERTa-v2 model)"),NGo=l(),tv=a("li"),Zpe=a("strong"),qGo=o("distilbert"),jGo=o(" \u2014 "),tX=a("a"),DGo=o("DistilBertForSequenceClassification"),GGo=o(" (DistilBERT model)"),OGo=l(),av=a("li"),e_e=a("strong"),VGo=o("electra"),XGo=o(" \u2014 "),aX=a("a"),zGo=o("ElectraForSequenceClassification"),QGo=o(" (ELECTRA model)"),WGo=l(),nv=a("li"),o_e=a("strong"),HGo=o("flaubert"),UGo=o(" \u2014 "),nX=a("a"),JGo=o("FlaubertForSequenceClassification"),YGo=o(" (FlauBERT model)"),KGo=l(),sv=a("li"),r_e=a("strong"),ZGo=o("fnet"),eOo=o(" \u2014 "),sX=a("a"),oOo=o("FNetForSequenceClassification"),rOo=o(" (FNet model)"),tOo=l(),lv=a("li"),t_e=a("strong"),aOo=o("funnel"),nOo=o(" \u2014 "),lX=a("a"),sOo=o("FunnelForSequenceClassification"),lOo=o(" (Funnel Transformer model)"),iOo=l(),iv=a("li"),a_e=a("strong"),dOo=o("gpt2"),cOo=o(" \u2014 "),iX=a("a"),fOo=o("GPT2ForSequenceClassification"),mOo=o(" (OpenAI GPT-2 model)"),gOo=l(),dv=a("li"),n_e=a("strong"),hOo=o("gpt_neo"),pOo=o(" \u2014 "),dX=a("a"),_Oo=o("GPTNeoForSequenceClassification"),uOo=o(" (GPT Neo model)"),bOo=l(),cv=a("li"),s_e=a("strong"),vOo=o("gptj"),FOo=o(" \u2014 "),cX=a("a"),TOo=o("GPTJForSequenceClassification"),MOo=o(" (GPT-J model)"),EOo=l(),fv=a("li"),l_e=a("strong"),COo=o("ibert"),wOo=o(" \u2014 "),fX=a("a"),AOo=o("IBertForSequenceClassification"),LOo=o(" (I-BERT model)"),yOo=l(),mv=a("li"),i_e=a("strong"),xOo=o("layoutlm"),$Oo=o(" \u2014 "),mX=a("a"),kOo=o("LayoutLMForSequenceClassification"),SOo=o(" (LayoutLM model)"),ROo=l(),gv=a("li"),d_e=a("strong"),POo=o("layoutlmv2"),BOo=o(" \u2014 "),gX=a("a"),IOo=o("LayoutLMv2ForSequenceClassification"),NOo=o(" (LayoutLMv2 model)"),qOo=l(),hv=a("li"),c_e=a("strong"),jOo=o("layoutlmv3"),DOo=o(" \u2014 "),hX=a("a"),GOo=o("LayoutLMv3ForSequenceClassification"),OOo=o(" (LayoutLMv3 model)"),VOo=l(),pv=a("li"),f_e=a("strong"),XOo=o("led"),zOo=o(" \u2014 "),pX=a("a"),QOo=o("LEDForSequenceClassification"),WOo=o(" (LED model)"),HOo=l(),_v=a("li"),m_e=a("strong"),UOo=o("longformer"),JOo=o(" \u2014 "),_X=a("a"),YOo=o("LongformerForSequenceClassification"),KOo=o(" (Longformer model)"),ZOo=l(),uv=a("li"),g_e=a("strong"),eVo=o("mbart"),oVo=o(" \u2014 "),uX=a("a"),rVo=o("MBartForSequenceClassification"),tVo=o(" (mBART model)"),aVo=l(),bv=a("li"),h_e=a("strong"),nVo=o("megatron-bert"),sVo=o(" \u2014 "),bX=a("a"),lVo=o("MegatronBertForSequenceClassification"),iVo=o(" (Megatron-BERT model)"),dVo=l(),vv=a("li"),p_e=a("strong"),cVo=o("mobilebert"),fVo=o(" \u2014 "),vX=a("a"),mVo=o("MobileBertForSequenceClassification"),gVo=o(" (MobileBERT model)"),hVo=l(),Fv=a("li"),__e=a("strong"),pVo=o("mpnet"),_Vo=o(" \u2014 "),FX=a("a"),uVo=o("MPNetForSequenceClassification"),bVo=o(" (MPNet model)"),vVo=l(),Tv=a("li"),u_e=a("strong"),FVo=o("mvp"),TVo=o(" \u2014 "),TX=a("a"),MVo=o("MvpForSequenceClassification"),EVo=o(" (MVP model)"),CVo=l(),Mv=a("li"),b_e=a("strong"),wVo=o("nezha"),AVo=o(" \u2014 "),MX=a("a"),LVo=o("NezhaForSequenceClassification"),yVo=o(" (Nezha model)"),xVo=l(),Ev=a("li"),v_e=a("strong"),$Vo=o("nystromformer"),kVo=o(" \u2014 "),EX=a("a"),SVo=o("NystromformerForSequenceClassification"),RVo=o(" (Nystr\xF6mformer model)"),PVo=l(),Cv=a("li"),F_e=a("strong"),BVo=o("openai-gpt"),IVo=o(" \u2014 "),CX=a("a"),NVo=o("OpenAIGPTForSequenceClassification"),qVo=o(" (OpenAI GPT model)"),jVo=l(),wv=a("li"),T_e=a("strong"),DVo=o("perceiver"),GVo=o(" \u2014 "),wX=a("a"),OVo=o("PerceiverForSequenceClassification"),VVo=o(" (Perceiver model)"),XVo=l(),Av=a("li"),M_e=a("strong"),zVo=o("plbart"),QVo=o(" \u2014 "),AX=a("a"),WVo=o("PLBartForSequenceClassification"),HVo=o(" (PLBart model)"),UVo=l(),Lv=a("li"),E_e=a("strong"),JVo=o("qdqbert"),YVo=o(" \u2014 "),LX=a("a"),KVo=o("QDQBertForSequenceClassification"),ZVo=o(" (QDQBert model)"),eXo=l(),yv=a("li"),C_e=a("strong"),oXo=o("reformer"),rXo=o(" \u2014 "),yX=a("a"),tXo=o("ReformerForSequenceClassification"),aXo=o(" (Reformer model)"),nXo=l(),xv=a("li"),w_e=a("strong"),sXo=o("rembert"),lXo=o(" \u2014 "),xX=a("a"),iXo=o("RemBertForSequenceClassification"),dXo=o(" (RemBERT model)"),cXo=l(),$v=a("li"),A_e=a("strong"),fXo=o("roberta"),mXo=o(" \u2014 "),$X=a("a"),gXo=o("RobertaForSequenceClassification"),hXo=o(" (RoBERTa model)"),pXo=l(),kv=a("li"),L_e=a("strong"),_Xo=o("roformer"),uXo=o(" \u2014 "),kX=a("a"),bXo=o("RoFormerForSequenceClassification"),vXo=o(" (RoFormer model)"),FXo=l(),Sv=a("li"),y_e=a("strong"),TXo=o("squeezebert"),MXo=o(" \u2014 "),SX=a("a"),EXo=o("SqueezeBertForSequenceClassification"),CXo=o(" (SqueezeBERT model)"),wXo=l(),Rv=a("li"),x_e=a("strong"),AXo=o("tapas"),LXo=o(" \u2014 "),RX=a("a"),yXo=o("TapasForSequenceClassification"),xXo=o(" (TAPAS model)"),$Xo=l(),Pv=a("li"),$_e=a("strong"),kXo=o("transfo-xl"),SXo=o(" \u2014 "),PX=a("a"),RXo=o("TransfoXLForSequenceClassification"),PXo=o(" (Transformer-XL model)"),BXo=l(),Bv=a("li"),k_e=a("strong"),IXo=o("xlm"),NXo=o(" \u2014 "),BX=a("a"),qXo=o("XLMForSequenceClassification"),jXo=o(" (XLM model)"),DXo=l(),Iv=a("li"),S_e=a("strong"),GXo=o("xlm-roberta"),OXo=o(" \u2014 "),IX=a("a"),VXo=o("XLMRobertaForSequenceClassification"),XXo=o(" (XLM-RoBERTa model)"),zXo=l(),Nv=a("li"),R_e=a("strong"),QXo=o("xlm-roberta-xl"),WXo=o(" \u2014 "),NX=a("a"),HXo=o("XLMRobertaXLForSequenceClassification"),UXo=o(" (XLM-RoBERTa-XL model)"),JXo=l(),qv=a("li"),P_e=a("strong"),YXo=o("xlnet"),KXo=o(" \u2014 "),qX=a("a"),ZXo=o("XLNetForSequenceClassification"),ezo=o(" (XLNet model)"),ozo=l(),jv=a("li"),B_e=a("strong"),rzo=o("yoso"),tzo=o(" \u2014 "),jX=a("a"),azo=o("YosoForSequenceClassification"),nzo=o(" (YOSO model)"),szo=l(),Dv=a("p"),lzo=o("The model is set in evaluation mode by default using "),I_e=a("code"),izo=o("model.eval()"),dzo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),N_e=a("code"),czo=o("model.train()"),fzo=l(),F(Gv.$$.fragment),dXe=l(),ad=a("h2"),Ov=a("a"),q_e=a("span"),F(ty.$$.fragment),mzo=l(),j_e=a("span"),gzo=o("AutoModelForMultipleChoice"),cXe=l(),Bo=a("div"),F(ay.$$.fragment),hzo=l(),nd=a("p"),pzo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),DX=a("a"),_zo=o("from_pretrained()"),uzo=o(" class method or the "),GX=a("a"),bzo=o("from_config()"),vzo=o(` class
method.`),Fzo=l(),ny=a("p"),Tzo=o("This class cannot be instantiated directly using "),D_e=a("code"),Mzo=o("__init__()"),Ezo=o(" (throws an error)."),Czo=l(),gt=a("div"),F(sy.$$.fragment),wzo=l(),G_e=a("p"),Azo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Lzo=l(),sd=a("p"),yzo=o(`Note:
Loading a model from its configuration file does `),O_e=a("strong"),xzo=o("not"),$zo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OX=a("a"),kzo=o("from_pretrained()"),Szo=o(" to load the model weights."),Rzo=l(),F(Vv.$$.fragment),Pzo=l(),ro=a("div"),F(ly.$$.fragment),Bzo=l(),V_e=a("p"),Izo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Nzo=l(),Ga=a("p"),qzo=o("The model class to instantiate is selected based on the "),X_e=a("code"),jzo=o("model_type"),Dzo=o(` property of the config object (either
passed as an argument or loaded from `),z_e=a("code"),Gzo=o("pretrained_model_name_or_path"),Ozo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q_e=a("code"),Vzo=o("pretrained_model_name_or_path"),Xzo=o(":"),zzo=l(),Z=a("ul"),Xv=a("li"),W_e=a("strong"),Qzo=o("albert"),Wzo=o(" \u2014 "),VX=a("a"),Hzo=o("AlbertForMultipleChoice"),Uzo=o(" (ALBERT model)"),Jzo=l(),zv=a("li"),H_e=a("strong"),Yzo=o("bert"),Kzo=o(" \u2014 "),XX=a("a"),Zzo=o("BertForMultipleChoice"),eQo=o(" (BERT model)"),oQo=l(),Qv=a("li"),U_e=a("strong"),rQo=o("big_bird"),tQo=o(" \u2014 "),zX=a("a"),aQo=o("BigBirdForMultipleChoice"),nQo=o(" (BigBird model)"),sQo=l(),Wv=a("li"),J_e=a("strong"),lQo=o("camembert"),iQo=o(" \u2014 "),QX=a("a"),dQo=o("CamembertForMultipleChoice"),cQo=o(" (CamemBERT model)"),fQo=l(),Hv=a("li"),Y_e=a("strong"),mQo=o("canine"),gQo=o(" \u2014 "),WX=a("a"),hQo=o("CanineForMultipleChoice"),pQo=o(" (CANINE model)"),_Qo=l(),Uv=a("li"),K_e=a("strong"),uQo=o("convbert"),bQo=o(" \u2014 "),HX=a("a"),vQo=o("ConvBertForMultipleChoice"),FQo=o(" (ConvBERT model)"),TQo=l(),Jv=a("li"),Z_e=a("strong"),MQo=o("data2vec-text"),EQo=o(" \u2014 "),UX=a("a"),CQo=o("Data2VecTextForMultipleChoice"),wQo=o(" (Data2VecText model)"),AQo=l(),Yv=a("li"),eue=a("strong"),LQo=o("deberta-v2"),yQo=o(" \u2014 "),JX=a("a"),xQo=o("DebertaV2ForMultipleChoice"),$Qo=o(" (DeBERTa-v2 model)"),kQo=l(),Kv=a("li"),oue=a("strong"),SQo=o("distilbert"),RQo=o(" \u2014 "),YX=a("a"),PQo=o("DistilBertForMultipleChoice"),BQo=o(" (DistilBERT model)"),IQo=l(),Zv=a("li"),rue=a("strong"),NQo=o("electra"),qQo=o(" \u2014 "),KX=a("a"),jQo=o("ElectraForMultipleChoice"),DQo=o(" (ELECTRA model)"),GQo=l(),eF=a("li"),tue=a("strong"),OQo=o("flaubert"),VQo=o(" \u2014 "),ZX=a("a"),XQo=o("FlaubertForMultipleChoice"),zQo=o(" (FlauBERT model)"),QQo=l(),oF=a("li"),aue=a("strong"),WQo=o("fnet"),HQo=o(" \u2014 "),ez=a("a"),UQo=o("FNetForMultipleChoice"),JQo=o(" (FNet model)"),YQo=l(),rF=a("li"),nue=a("strong"),KQo=o("funnel"),ZQo=o(" \u2014 "),oz=a("a"),eWo=o("FunnelForMultipleChoice"),oWo=o(" (Funnel Transformer model)"),rWo=l(),tF=a("li"),sue=a("strong"),tWo=o("ibert"),aWo=o(" \u2014 "),rz=a("a"),nWo=o("IBertForMultipleChoice"),sWo=o(" (I-BERT model)"),lWo=l(),aF=a("li"),lue=a("strong"),iWo=o("longformer"),dWo=o(" \u2014 "),tz=a("a"),cWo=o("LongformerForMultipleChoice"),fWo=o(" (Longformer model)"),mWo=l(),nF=a("li"),iue=a("strong"),gWo=o("megatron-bert"),hWo=o(" \u2014 "),az=a("a"),pWo=o("MegatronBertForMultipleChoice"),_Wo=o(" (Megatron-BERT model)"),uWo=l(),sF=a("li"),due=a("strong"),bWo=o("mobilebert"),vWo=o(" \u2014 "),nz=a("a"),FWo=o("MobileBertForMultipleChoice"),TWo=o(" (MobileBERT model)"),MWo=l(),lF=a("li"),cue=a("strong"),EWo=o("mpnet"),CWo=o(" \u2014 "),sz=a("a"),wWo=o("MPNetForMultipleChoice"),AWo=o(" (MPNet model)"),LWo=l(),iF=a("li"),fue=a("strong"),yWo=o("nezha"),xWo=o(" \u2014 "),lz=a("a"),$Wo=o("NezhaForMultipleChoice"),kWo=o(" (Nezha model)"),SWo=l(),dF=a("li"),mue=a("strong"),RWo=o("nystromformer"),PWo=o(" \u2014 "),iz=a("a"),BWo=o("NystromformerForMultipleChoice"),IWo=o(" (Nystr\xF6mformer model)"),NWo=l(),cF=a("li"),gue=a("strong"),qWo=o("qdqbert"),jWo=o(" \u2014 "),dz=a("a"),DWo=o("QDQBertForMultipleChoice"),GWo=o(" (QDQBert model)"),OWo=l(),fF=a("li"),hue=a("strong"),VWo=o("rembert"),XWo=o(" \u2014 "),cz=a("a"),zWo=o("RemBertForMultipleChoice"),QWo=o(" (RemBERT model)"),WWo=l(),mF=a("li"),pue=a("strong"),HWo=o("roberta"),UWo=o(" \u2014 "),fz=a("a"),JWo=o("RobertaForMultipleChoice"),YWo=o(" (RoBERTa model)"),KWo=l(),gF=a("li"),_ue=a("strong"),ZWo=o("roformer"),eHo=o(" \u2014 "),mz=a("a"),oHo=o("RoFormerForMultipleChoice"),rHo=o(" (RoFormer model)"),tHo=l(),hF=a("li"),uue=a("strong"),aHo=o("squeezebert"),nHo=o(" \u2014 "),gz=a("a"),sHo=o("SqueezeBertForMultipleChoice"),lHo=o(" (SqueezeBERT model)"),iHo=l(),pF=a("li"),bue=a("strong"),dHo=o("xlm"),cHo=o(" \u2014 "),hz=a("a"),fHo=o("XLMForMultipleChoice"),mHo=o(" (XLM model)"),gHo=l(),_F=a("li"),vue=a("strong"),hHo=o("xlm-roberta"),pHo=o(" \u2014 "),pz=a("a"),_Ho=o("XLMRobertaForMultipleChoice"),uHo=o(" (XLM-RoBERTa model)"),bHo=l(),uF=a("li"),Fue=a("strong"),vHo=o("xlm-roberta-xl"),FHo=o(" \u2014 "),_z=a("a"),THo=o("XLMRobertaXLForMultipleChoice"),MHo=o(" (XLM-RoBERTa-XL model)"),EHo=l(),bF=a("li"),Tue=a("strong"),CHo=o("xlnet"),wHo=o(" \u2014 "),uz=a("a"),AHo=o("XLNetForMultipleChoice"),LHo=o(" (XLNet model)"),yHo=l(),vF=a("li"),Mue=a("strong"),xHo=o("yoso"),$Ho=o(" \u2014 "),bz=a("a"),kHo=o("YosoForMultipleChoice"),SHo=o(" (YOSO model)"),RHo=l(),FF=a("p"),PHo=o("The model is set in evaluation mode by default using "),Eue=a("code"),BHo=o("model.eval()"),IHo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cue=a("code"),NHo=o("model.train()"),qHo=l(),F(TF.$$.fragment),fXe=l(),ld=a("h2"),MF=a("a"),wue=a("span"),F(iy.$$.fragment),jHo=l(),Aue=a("span"),DHo=o("AutoModelForNextSentencePrediction"),mXe=l(),Io=a("div"),F(dy.$$.fragment),GHo=l(),id=a("p"),OHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),vz=a("a"),VHo=o("from_pretrained()"),XHo=o(" class method or the "),Fz=a("a"),zHo=o("from_config()"),QHo=o(` class
method.`),WHo=l(),cy=a("p"),HHo=o("This class cannot be instantiated directly using "),Lue=a("code"),UHo=o("__init__()"),JHo=o(" (throws an error)."),YHo=l(),ht=a("div"),F(fy.$$.fragment),KHo=l(),yue=a("p"),ZHo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),eUo=l(),dd=a("p"),oUo=o(`Note:
Loading a model from its configuration file does `),xue=a("strong"),rUo=o("not"),tUo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Tz=a("a"),aUo=o("from_pretrained()"),nUo=o(" to load the model weights."),sUo=l(),F(EF.$$.fragment),lUo=l(),to=a("div"),F(my.$$.fragment),iUo=l(),$ue=a("p"),dUo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),cUo=l(),Oa=a("p"),fUo=o("The model class to instantiate is selected based on the "),kue=a("code"),mUo=o("model_type"),gUo=o(` property of the config object (either
passed as an argument or loaded from `),Sue=a("code"),hUo=o("pretrained_model_name_or_path"),pUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rue=a("code"),_Uo=o("pretrained_model_name_or_path"),uUo=o(":"),bUo=l(),No=a("ul"),CF=a("li"),Pue=a("strong"),vUo=o("bert"),FUo=o(" \u2014 "),Mz=a("a"),TUo=o("BertForNextSentencePrediction"),MUo=o(" (BERT model)"),EUo=l(),wF=a("li"),Bue=a("strong"),CUo=o("fnet"),wUo=o(" \u2014 "),Ez=a("a"),AUo=o("FNetForNextSentencePrediction"),LUo=o(" (FNet model)"),yUo=l(),AF=a("li"),Iue=a("strong"),xUo=o("megatron-bert"),$Uo=o(" \u2014 "),Cz=a("a"),kUo=o("MegatronBertForNextSentencePrediction"),SUo=o(" (Megatron-BERT model)"),RUo=l(),LF=a("li"),Nue=a("strong"),PUo=o("mobilebert"),BUo=o(" \u2014 "),wz=a("a"),IUo=o("MobileBertForNextSentencePrediction"),NUo=o(" (MobileBERT model)"),qUo=l(),yF=a("li"),que=a("strong"),jUo=o("nezha"),DUo=o(" \u2014 "),Az=a("a"),GUo=o("NezhaForNextSentencePrediction"),OUo=o(" (Nezha model)"),VUo=l(),xF=a("li"),jue=a("strong"),XUo=o("qdqbert"),zUo=o(" \u2014 "),Lz=a("a"),QUo=o("QDQBertForNextSentencePrediction"),WUo=o(" (QDQBert model)"),HUo=l(),$F=a("p"),UUo=o("The model is set in evaluation mode by default using "),Due=a("code"),JUo=o("model.eval()"),YUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gue=a("code"),KUo=o("model.train()"),ZUo=l(),F(kF.$$.fragment),gXe=l(),cd=a("h2"),SF=a("a"),Oue=a("span"),F(gy.$$.fragment),eJo=l(),Vue=a("span"),oJo=o("AutoModelForTokenClassification"),hXe=l(),qo=a("div"),F(hy.$$.fragment),rJo=l(),fd=a("p"),tJo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),yz=a("a"),aJo=o("from_pretrained()"),nJo=o(" class method or the "),xz=a("a"),sJo=o("from_config()"),lJo=o(` class
method.`),iJo=l(),py=a("p"),dJo=o("This class cannot be instantiated directly using "),Xue=a("code"),cJo=o("__init__()"),fJo=o(" (throws an error)."),mJo=l(),pt=a("div"),F(_y.$$.fragment),gJo=l(),zue=a("p"),hJo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),pJo=l(),md=a("p"),_Jo=o(`Note:
Loading a model from its configuration file does `),Que=a("strong"),uJo=o("not"),bJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$z=a("a"),vJo=o("from_pretrained()"),FJo=o(" to load the model weights."),TJo=l(),F(RF.$$.fragment),MJo=l(),ao=a("div"),F(uy.$$.fragment),EJo=l(),Wue=a("p"),CJo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),wJo=l(),Va=a("p"),AJo=o("The model class to instantiate is selected based on the "),Hue=a("code"),LJo=o("model_type"),yJo=o(` property of the config object (either
passed as an argument or loaded from `),Uue=a("code"),xJo=o("pretrained_model_name_or_path"),$Jo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jue=a("code"),kJo=o("pretrained_model_name_or_path"),SJo=o(":"),RJo=l(),U=a("ul"),PF=a("li"),Yue=a("strong"),PJo=o("albert"),BJo=o(" \u2014 "),kz=a("a"),IJo=o("AlbertForTokenClassification"),NJo=o(" (ALBERT model)"),qJo=l(),BF=a("li"),Kue=a("strong"),jJo=o("bert"),DJo=o(" \u2014 "),Sz=a("a"),GJo=o("BertForTokenClassification"),OJo=o(" (BERT model)"),VJo=l(),IF=a("li"),Zue=a("strong"),XJo=o("big_bird"),zJo=o(" \u2014 "),Rz=a("a"),QJo=o("BigBirdForTokenClassification"),WJo=o(" (BigBird model)"),HJo=l(),NF=a("li"),e1e=a("strong"),UJo=o("bloom"),JJo=o(" \u2014 "),Pz=a("a"),YJo=o("BloomForTokenClassification"),KJo=o(" (BLOOM model)"),ZJo=l(),qF=a("li"),o1e=a("strong"),eYo=o("camembert"),oYo=o(" \u2014 "),Bz=a("a"),rYo=o("CamembertForTokenClassification"),tYo=o(" (CamemBERT model)"),aYo=l(),jF=a("li"),r1e=a("strong"),nYo=o("canine"),sYo=o(" \u2014 "),Iz=a("a"),lYo=o("CanineForTokenClassification"),iYo=o(" (CANINE model)"),dYo=l(),DF=a("li"),t1e=a("strong"),cYo=o("convbert"),fYo=o(" \u2014 "),Nz=a("a"),mYo=o("ConvBertForTokenClassification"),gYo=o(" (ConvBERT model)"),hYo=l(),GF=a("li"),a1e=a("strong"),pYo=o("data2vec-text"),_Yo=o(" \u2014 "),qz=a("a"),uYo=o("Data2VecTextForTokenClassification"),bYo=o(" (Data2VecText model)"),vYo=l(),OF=a("li"),n1e=a("strong"),FYo=o("deberta"),TYo=o(" \u2014 "),jz=a("a"),MYo=o("DebertaForTokenClassification"),EYo=o(" (DeBERTa model)"),CYo=l(),VF=a("li"),s1e=a("strong"),wYo=o("deberta-v2"),AYo=o(" \u2014 "),Dz=a("a"),LYo=o("DebertaV2ForTokenClassification"),yYo=o(" (DeBERTa-v2 model)"),xYo=l(),XF=a("li"),l1e=a("strong"),$Yo=o("distilbert"),kYo=o(" \u2014 "),Gz=a("a"),SYo=o("DistilBertForTokenClassification"),RYo=o(" (DistilBERT model)"),PYo=l(),zF=a("li"),i1e=a("strong"),BYo=o("electra"),IYo=o(" \u2014 "),Oz=a("a"),NYo=o("ElectraForTokenClassification"),qYo=o(" (ELECTRA model)"),jYo=l(),QF=a("li"),d1e=a("strong"),DYo=o("flaubert"),GYo=o(" \u2014 "),Vz=a("a"),OYo=o("FlaubertForTokenClassification"),VYo=o(" (FlauBERT model)"),XYo=l(),WF=a("li"),c1e=a("strong"),zYo=o("fnet"),QYo=o(" \u2014 "),Xz=a("a"),WYo=o("FNetForTokenClassification"),HYo=o(" (FNet model)"),UYo=l(),HF=a("li"),f1e=a("strong"),JYo=o("funnel"),YYo=o(" \u2014 "),zz=a("a"),KYo=o("FunnelForTokenClassification"),ZYo=o(" (Funnel Transformer model)"),eKo=l(),UF=a("li"),m1e=a("strong"),oKo=o("gpt2"),rKo=o(" \u2014 "),Qz=a("a"),tKo=o("GPT2ForTokenClassification"),aKo=o(" (OpenAI GPT-2 model)"),nKo=l(),JF=a("li"),g1e=a("strong"),sKo=o("ibert"),lKo=o(" \u2014 "),Wz=a("a"),iKo=o("IBertForTokenClassification"),dKo=o(" (I-BERT model)"),cKo=l(),YF=a("li"),h1e=a("strong"),fKo=o("layoutlm"),mKo=o(" \u2014 "),Hz=a("a"),gKo=o("LayoutLMForTokenClassification"),hKo=o(" (LayoutLM model)"),pKo=l(),KF=a("li"),p1e=a("strong"),_Ko=o("layoutlmv2"),uKo=o(" \u2014 "),Uz=a("a"),bKo=o("LayoutLMv2ForTokenClassification"),vKo=o(" (LayoutLMv2 model)"),FKo=l(),ZF=a("li"),_1e=a("strong"),TKo=o("layoutlmv3"),MKo=o(" \u2014 "),Jz=a("a"),EKo=o("LayoutLMv3ForTokenClassification"),CKo=o(" (LayoutLMv3 model)"),wKo=l(),eT=a("li"),u1e=a("strong"),AKo=o("longformer"),LKo=o(" \u2014 "),Yz=a("a"),yKo=o("LongformerForTokenClassification"),xKo=o(" (Longformer model)"),$Ko=l(),oT=a("li"),b1e=a("strong"),kKo=o("megatron-bert"),SKo=o(" \u2014 "),Kz=a("a"),RKo=o("MegatronBertForTokenClassification"),PKo=o(" (Megatron-BERT model)"),BKo=l(),rT=a("li"),v1e=a("strong"),IKo=o("mobilebert"),NKo=o(" \u2014 "),Zz=a("a"),qKo=o("MobileBertForTokenClassification"),jKo=o(" (MobileBERT model)"),DKo=l(),tT=a("li"),F1e=a("strong"),GKo=o("mpnet"),OKo=o(" \u2014 "),eQ=a("a"),VKo=o("MPNetForTokenClassification"),XKo=o(" (MPNet model)"),zKo=l(),aT=a("li"),T1e=a("strong"),QKo=o("nezha"),WKo=o(" \u2014 "),oQ=a("a"),HKo=o("NezhaForTokenClassification"),UKo=o(" (Nezha model)"),JKo=l(),nT=a("li"),M1e=a("strong"),YKo=o("nystromformer"),KKo=o(" \u2014 "),rQ=a("a"),ZKo=o("NystromformerForTokenClassification"),eZo=o(" (Nystr\xF6mformer model)"),oZo=l(),sT=a("li"),E1e=a("strong"),rZo=o("qdqbert"),tZo=o(" \u2014 "),tQ=a("a"),aZo=o("QDQBertForTokenClassification"),nZo=o(" (QDQBert model)"),sZo=l(),lT=a("li"),C1e=a("strong"),lZo=o("rembert"),iZo=o(" \u2014 "),aQ=a("a"),dZo=o("RemBertForTokenClassification"),cZo=o(" (RemBERT model)"),fZo=l(),iT=a("li"),w1e=a("strong"),mZo=o("roberta"),gZo=o(" \u2014 "),nQ=a("a"),hZo=o("RobertaForTokenClassification"),pZo=o(" (RoBERTa model)"),_Zo=l(),dT=a("li"),A1e=a("strong"),uZo=o("roformer"),bZo=o(" \u2014 "),sQ=a("a"),vZo=o("RoFormerForTokenClassification"),FZo=o(" (RoFormer model)"),TZo=l(),cT=a("li"),L1e=a("strong"),MZo=o("squeezebert"),EZo=o(" \u2014 "),lQ=a("a"),CZo=o("SqueezeBertForTokenClassification"),wZo=o(" (SqueezeBERT model)"),AZo=l(),fT=a("li"),y1e=a("strong"),LZo=o("xlm"),yZo=o(" \u2014 "),iQ=a("a"),xZo=o("XLMForTokenClassification"),$Zo=o(" (XLM model)"),kZo=l(),mT=a("li"),x1e=a("strong"),SZo=o("xlm-roberta"),RZo=o(" \u2014 "),dQ=a("a"),PZo=o("XLMRobertaForTokenClassification"),BZo=o(" (XLM-RoBERTa model)"),IZo=l(),gT=a("li"),$1e=a("strong"),NZo=o("xlm-roberta-xl"),qZo=o(" \u2014 "),cQ=a("a"),jZo=o("XLMRobertaXLForTokenClassification"),DZo=o(" (XLM-RoBERTa-XL model)"),GZo=l(),hT=a("li"),k1e=a("strong"),OZo=o("xlnet"),VZo=o(" \u2014 "),fQ=a("a"),XZo=o("XLNetForTokenClassification"),zZo=o(" (XLNet model)"),QZo=l(),pT=a("li"),S1e=a("strong"),WZo=o("yoso"),HZo=o(" \u2014 "),mQ=a("a"),UZo=o("YosoForTokenClassification"),JZo=o(" (YOSO model)"),YZo=l(),_T=a("p"),KZo=o("The model is set in evaluation mode by default using "),R1e=a("code"),ZZo=o("model.eval()"),eer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P1e=a("code"),oer=o("model.train()"),rer=l(),F(uT.$$.fragment),pXe=l(),gd=a("h2"),bT=a("a"),B1e=a("span"),F(by.$$.fragment),ter=l(),I1e=a("span"),aer=o("AutoModelForQuestionAnswering"),_Xe=l(),jo=a("div"),F(vy.$$.fragment),ner=l(),hd=a("p"),ser=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),gQ=a("a"),ler=o("from_pretrained()"),ier=o(" class method or the "),hQ=a("a"),der=o("from_config()"),cer=o(` class
method.`),fer=l(),Fy=a("p"),mer=o("This class cannot be instantiated directly using "),N1e=a("code"),ger=o("__init__()"),her=o(" (throws an error)."),per=l(),_t=a("div"),F(Ty.$$.fragment),_er=l(),q1e=a("p"),uer=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),ber=l(),pd=a("p"),ver=o(`Note:
Loading a model from its configuration file does `),j1e=a("strong"),Fer=o("not"),Ter=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pQ=a("a"),Mer=o("from_pretrained()"),Eer=o(" to load the model weights."),Cer=l(),F(vT.$$.fragment),wer=l(),no=a("div"),F(My.$$.fragment),Aer=l(),D1e=a("p"),Ler=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),yer=l(),Xa=a("p"),xer=o("The model class to instantiate is selected based on the "),G1e=a("code"),$er=o("model_type"),ker=o(` property of the config object (either
passed as an argument or loaded from `),O1e=a("code"),Ser=o("pretrained_model_name_or_path"),Rer=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V1e=a("code"),Per=o("pretrained_model_name_or_path"),Ber=o(":"),Ier=l(),V=a("ul"),FT=a("li"),X1e=a("strong"),Ner=o("albert"),qer=o(" \u2014 "),_Q=a("a"),jer=o("AlbertForQuestionAnswering"),Der=o(" (ALBERT model)"),Ger=l(),TT=a("li"),z1e=a("strong"),Oer=o("bart"),Ver=o(" \u2014 "),uQ=a("a"),Xer=o("BartForQuestionAnswering"),zer=o(" (BART model)"),Qer=l(),MT=a("li"),Q1e=a("strong"),Wer=o("bert"),Her=o(" \u2014 "),bQ=a("a"),Uer=o("BertForQuestionAnswering"),Jer=o(" (BERT model)"),Yer=l(),ET=a("li"),W1e=a("strong"),Ker=o("big_bird"),Zer=o(" \u2014 "),vQ=a("a"),eor=o("BigBirdForQuestionAnswering"),oor=o(" (BigBird model)"),ror=l(),CT=a("li"),H1e=a("strong"),tor=o("bigbird_pegasus"),aor=o(" \u2014 "),FQ=a("a"),nor=o("BigBirdPegasusForQuestionAnswering"),sor=o(" (BigBird-Pegasus model)"),lor=l(),wT=a("li"),U1e=a("strong"),ior=o("camembert"),dor=o(" \u2014 "),TQ=a("a"),cor=o("CamembertForQuestionAnswering"),mor=o(" (CamemBERT model)"),gor=l(),AT=a("li"),J1e=a("strong"),hor=o("canine"),por=o(" \u2014 "),MQ=a("a"),_or=o("CanineForQuestionAnswering"),uor=o(" (CANINE model)"),bor=l(),LT=a("li"),Y1e=a("strong"),vor=o("convbert"),For=o(" \u2014 "),EQ=a("a"),Tor=o("ConvBertForQuestionAnswering"),Mor=o(" (ConvBERT model)"),Eor=l(),yT=a("li"),K1e=a("strong"),Cor=o("data2vec-text"),wor=o(" \u2014 "),CQ=a("a"),Aor=o("Data2VecTextForQuestionAnswering"),Lor=o(" (Data2VecText model)"),yor=l(),xT=a("li"),Z1e=a("strong"),xor=o("deberta"),$or=o(" \u2014 "),wQ=a("a"),kor=o("DebertaForQuestionAnswering"),Sor=o(" (DeBERTa model)"),Ror=l(),$T=a("li"),e2e=a("strong"),Por=o("deberta-v2"),Bor=o(" \u2014 "),AQ=a("a"),Ior=o("DebertaV2ForQuestionAnswering"),Nor=o(" (DeBERTa-v2 model)"),qor=l(),kT=a("li"),o2e=a("strong"),jor=o("distilbert"),Dor=o(" \u2014 "),LQ=a("a"),Gor=o("DistilBertForQuestionAnswering"),Oor=o(" (DistilBERT model)"),Vor=l(),ST=a("li"),r2e=a("strong"),Xor=o("electra"),zor=o(" \u2014 "),yQ=a("a"),Qor=o("ElectraForQuestionAnswering"),Wor=o(" (ELECTRA model)"),Hor=l(),RT=a("li"),t2e=a("strong"),Uor=o("flaubert"),Jor=o(" \u2014 "),xQ=a("a"),Yor=o("FlaubertForQuestionAnsweringSimple"),Kor=o(" (FlauBERT model)"),Zor=l(),PT=a("li"),a2e=a("strong"),err=o("fnet"),orr=o(" \u2014 "),$Q=a("a"),rrr=o("FNetForQuestionAnswering"),trr=o(" (FNet model)"),arr=l(),BT=a("li"),n2e=a("strong"),nrr=o("funnel"),srr=o(" \u2014 "),kQ=a("a"),lrr=o("FunnelForQuestionAnswering"),irr=o(" (Funnel Transformer model)"),drr=l(),IT=a("li"),s2e=a("strong"),crr=o("gptj"),frr=o(" \u2014 "),SQ=a("a"),mrr=o("GPTJForQuestionAnswering"),grr=o(" (GPT-J model)"),hrr=l(),NT=a("li"),l2e=a("strong"),prr=o("ibert"),_rr=o(" \u2014 "),RQ=a("a"),urr=o("IBertForQuestionAnswering"),brr=o(" (I-BERT model)"),vrr=l(),qT=a("li"),i2e=a("strong"),Frr=o("layoutlmv2"),Trr=o(" \u2014 "),PQ=a("a"),Mrr=o("LayoutLMv2ForQuestionAnswering"),Err=o(" (LayoutLMv2 model)"),Crr=l(),jT=a("li"),d2e=a("strong"),wrr=o("layoutlmv3"),Arr=o(" \u2014 "),BQ=a("a"),Lrr=o("LayoutLMv3ForQuestionAnswering"),yrr=o(" (LayoutLMv3 model)"),xrr=l(),DT=a("li"),c2e=a("strong"),$rr=o("led"),krr=o(" \u2014 "),IQ=a("a"),Srr=o("LEDForQuestionAnswering"),Rrr=o(" (LED model)"),Prr=l(),GT=a("li"),f2e=a("strong"),Brr=o("longformer"),Irr=o(" \u2014 "),NQ=a("a"),Nrr=o("LongformerForQuestionAnswering"),qrr=o(" (Longformer model)"),jrr=l(),OT=a("li"),m2e=a("strong"),Drr=o("lxmert"),Grr=o(" \u2014 "),qQ=a("a"),Orr=o("LxmertForQuestionAnswering"),Vrr=o(" (LXMERT model)"),Xrr=l(),VT=a("li"),g2e=a("strong"),zrr=o("mbart"),Qrr=o(" \u2014 "),jQ=a("a"),Wrr=o("MBartForQuestionAnswering"),Hrr=o(" (mBART model)"),Urr=l(),XT=a("li"),h2e=a("strong"),Jrr=o("megatron-bert"),Yrr=o(" \u2014 "),DQ=a("a"),Krr=o("MegatronBertForQuestionAnswering"),Zrr=o(" (Megatron-BERT model)"),etr=l(),zT=a("li"),p2e=a("strong"),otr=o("mobilebert"),rtr=o(" \u2014 "),GQ=a("a"),ttr=o("MobileBertForQuestionAnswering"),atr=o(" (MobileBERT model)"),ntr=l(),QT=a("li"),_2e=a("strong"),str=o("mpnet"),ltr=o(" \u2014 "),OQ=a("a"),itr=o("MPNetForQuestionAnswering"),dtr=o(" (MPNet model)"),ctr=l(),WT=a("li"),u2e=a("strong"),ftr=o("mvp"),mtr=o(" \u2014 "),VQ=a("a"),gtr=o("MvpForQuestionAnswering"),htr=o(" (MVP model)"),ptr=l(),HT=a("li"),b2e=a("strong"),_tr=o("nezha"),utr=o(" \u2014 "),XQ=a("a"),btr=o("NezhaForQuestionAnswering"),vtr=o(" (Nezha model)"),Ftr=l(),UT=a("li"),v2e=a("strong"),Ttr=o("nystromformer"),Mtr=o(" \u2014 "),zQ=a("a"),Etr=o("NystromformerForQuestionAnswering"),Ctr=o(" (Nystr\xF6mformer model)"),wtr=l(),JT=a("li"),F2e=a("strong"),Atr=o("qdqbert"),Ltr=o(" \u2014 "),QQ=a("a"),ytr=o("QDQBertForQuestionAnswering"),xtr=o(" (QDQBert model)"),$tr=l(),YT=a("li"),T2e=a("strong"),ktr=o("reformer"),Str=o(" \u2014 "),WQ=a("a"),Rtr=o("ReformerForQuestionAnswering"),Ptr=o(" (Reformer model)"),Btr=l(),KT=a("li"),M2e=a("strong"),Itr=o("rembert"),Ntr=o(" \u2014 "),HQ=a("a"),qtr=o("RemBertForQuestionAnswering"),jtr=o(" (RemBERT model)"),Dtr=l(),ZT=a("li"),E2e=a("strong"),Gtr=o("roberta"),Otr=o(" \u2014 "),UQ=a("a"),Vtr=o("RobertaForQuestionAnswering"),Xtr=o(" (RoBERTa model)"),ztr=l(),e7=a("li"),C2e=a("strong"),Qtr=o("roformer"),Wtr=o(" \u2014 "),JQ=a("a"),Htr=o("RoFormerForQuestionAnswering"),Utr=o(" (RoFormer model)"),Jtr=l(),o7=a("li"),w2e=a("strong"),Ytr=o("splinter"),Ktr=o(" \u2014 "),YQ=a("a"),Ztr=o("SplinterForQuestionAnswering"),ear=o(" (Splinter model)"),oar=l(),r7=a("li"),A2e=a("strong"),rar=o("squeezebert"),tar=o(" \u2014 "),KQ=a("a"),aar=o("SqueezeBertForQuestionAnswering"),nar=o(" (SqueezeBERT model)"),sar=l(),t7=a("li"),L2e=a("strong"),lar=o("xlm"),iar=o(" \u2014 "),ZQ=a("a"),dar=o("XLMForQuestionAnsweringSimple"),car=o(" (XLM model)"),far=l(),a7=a("li"),y2e=a("strong"),mar=o("xlm-roberta"),gar=o(" \u2014 "),eW=a("a"),har=o("XLMRobertaForQuestionAnswering"),par=o(" (XLM-RoBERTa model)"),_ar=l(),n7=a("li"),x2e=a("strong"),uar=o("xlm-roberta-xl"),bar=o(" \u2014 "),oW=a("a"),Far=o("XLMRobertaXLForQuestionAnswering"),Tar=o(" (XLM-RoBERTa-XL model)"),Mar=l(),s7=a("li"),$2e=a("strong"),Ear=o("xlnet"),Car=o(" \u2014 "),rW=a("a"),war=o("XLNetForQuestionAnsweringSimple"),Aar=o(" (XLNet model)"),Lar=l(),l7=a("li"),k2e=a("strong"),yar=o("yoso"),xar=o(" \u2014 "),tW=a("a"),$ar=o("YosoForQuestionAnswering"),kar=o(" (YOSO model)"),Sar=l(),i7=a("p"),Rar=o("The model is set in evaluation mode by default using "),S2e=a("code"),Par=o("model.eval()"),Bar=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),R2e=a("code"),Iar=o("model.train()"),Nar=l(),F(d7.$$.fragment),uXe=l(),_d=a("h2"),c7=a("a"),P2e=a("span"),F(Ey.$$.fragment),qar=l(),B2e=a("span"),jar=o("AutoModelForTableQuestionAnswering"),bXe=l(),Do=a("div"),F(Cy.$$.fragment),Dar=l(),ud=a("p"),Gar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),aW=a("a"),Oar=o("from_pretrained()"),Var=o(" class method or the "),nW=a("a"),Xar=o("from_config()"),zar=o(` class
method.`),Qar=l(),wy=a("p"),War=o("This class cannot be instantiated directly using "),I2e=a("code"),Har=o("__init__()"),Uar=o(" (throws an error)."),Jar=l(),ut=a("div"),F(Ay.$$.fragment),Yar=l(),N2e=a("p"),Kar=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Zar=l(),bd=a("p"),enr=o(`Note:
Loading a model from its configuration file does `),q2e=a("strong"),onr=o("not"),rnr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sW=a("a"),tnr=o("from_pretrained()"),anr=o(" to load the model weights."),nnr=l(),F(f7.$$.fragment),snr=l(),so=a("div"),F(Ly.$$.fragment),lnr=l(),j2e=a("p"),inr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),dnr=l(),za=a("p"),cnr=o("The model class to instantiate is selected based on the "),D2e=a("code"),fnr=o("model_type"),mnr=o(` property of the config object (either
passed as an argument or loaded from `),G2e=a("code"),gnr=o("pretrained_model_name_or_path"),hnr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O2e=a("code"),pnr=o("pretrained_model_name_or_path"),_nr=o(":"),unr=l(),V2e=a("ul"),m7=a("li"),X2e=a("strong"),bnr=o("tapas"),vnr=o(" \u2014 "),lW=a("a"),Fnr=o("TapasForQuestionAnswering"),Tnr=o(" (TAPAS model)"),Mnr=l(),g7=a("p"),Enr=o("The model is set in evaluation mode by default using "),z2e=a("code"),Cnr=o("model.eval()"),wnr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q2e=a("code"),Anr=o("model.train()"),Lnr=l(),F(h7.$$.fragment),vXe=l(),vd=a("h2"),p7=a("a"),W2e=a("span"),F(yy.$$.fragment),ynr=l(),H2e=a("span"),xnr=o("AutoModelForImageClassification"),FXe=l(),Go=a("div"),F(xy.$$.fragment),$nr=l(),Fd=a("p"),knr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),iW=a("a"),Snr=o("from_pretrained()"),Rnr=o(" class method or the "),dW=a("a"),Pnr=o("from_config()"),Bnr=o(` class
method.`),Inr=l(),$y=a("p"),Nnr=o("This class cannot be instantiated directly using "),U2e=a("code"),qnr=o("__init__()"),jnr=o(" (throws an error)."),Dnr=l(),bt=a("div"),F(ky.$$.fragment),Gnr=l(),J2e=a("p"),Onr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Vnr=l(),Td=a("p"),Xnr=o(`Note:
Loading a model from its configuration file does `),Y2e=a("strong"),znr=o("not"),Qnr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cW=a("a"),Wnr=o("from_pretrained()"),Hnr=o(" to load the model weights."),Unr=l(),F(_7.$$.fragment),Jnr=l(),lo=a("div"),F(Sy.$$.fragment),Ynr=l(),K2e=a("p"),Knr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Znr=l(),Qa=a("p"),esr=o("The model class to instantiate is selected based on the "),Z2e=a("code"),osr=o("model_type"),rsr=o(` property of the config object (either
passed as an argument or loaded from `),ebe=a("code"),tsr=o("pretrained_model_name_or_path"),asr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),obe=a("code"),nsr=o("pretrained_model_name_or_path"),ssr=o(":"),lsr=l(),ve=a("ul"),u7=a("li"),rbe=a("strong"),isr=o("beit"),dsr=o(" \u2014 "),fW=a("a"),csr=o("BeitForImageClassification"),fsr=o(" (BEiT model)"),msr=l(),b7=a("li"),tbe=a("strong"),gsr=o("convnext"),hsr=o(" \u2014 "),mW=a("a"),psr=o("ConvNextForImageClassification"),_sr=o(" (ConvNeXT model)"),usr=l(),v7=a("li"),abe=a("strong"),bsr=o("cvt"),vsr=o(" \u2014 "),gW=a("a"),Fsr=o("CvtForImageClassification"),Tsr=o(" (CvT model)"),Msr=l(),F7=a("li"),nbe=a("strong"),Esr=o("data2vec-vision"),Csr=o(" \u2014 "),hW=a("a"),wsr=o("Data2VecVisionForImageClassification"),Asr=o(" (Data2VecVision model)"),Lsr=l(),Ws=a("li"),sbe=a("strong"),ysr=o("deit"),xsr=o(" \u2014 "),pW=a("a"),$sr=o("DeiTForImageClassification"),ksr=o(" or "),_W=a("a"),Ssr=o("DeiTForImageClassificationWithTeacher"),Rsr=o(" (DeiT model)"),Psr=l(),T7=a("li"),lbe=a("strong"),Bsr=o("imagegpt"),Isr=o(" \u2014 "),uW=a("a"),Nsr=o("ImageGPTForImageClassification"),qsr=o(" (ImageGPT model)"),jsr=l(),Hs=a("li"),ibe=a("strong"),Dsr=o("levit"),Gsr=o(" \u2014 "),bW=a("a"),Osr=o("LevitForImageClassification"),Vsr=o(" or "),vW=a("a"),Xsr=o("LevitForImageClassificationWithTeacher"),zsr=o(" (LeViT model)"),Qsr=l(),M7=a("li"),dbe=a("strong"),Wsr=o("mobilevit"),Hsr=o(" \u2014 "),FW=a("a"),Usr=o("MobileViTForImageClassification"),Jsr=o(" (MobileViT model)"),Ysr=l(),vt=a("li"),cbe=a("strong"),Ksr=o("perceiver"),Zsr=o(" \u2014 "),TW=a("a"),elr=o("PerceiverForImageClassificationLearned"),olr=o(" or "),MW=a("a"),rlr=o("PerceiverForImageClassificationFourier"),tlr=o(" or "),EW=a("a"),alr=o("PerceiverForImageClassificationConvProcessing"),nlr=o(" (Perceiver model)"),slr=l(),E7=a("li"),fbe=a("strong"),llr=o("poolformer"),ilr=o(" \u2014 "),CW=a("a"),dlr=o("PoolFormerForImageClassification"),clr=o(" (PoolFormer model)"),flr=l(),C7=a("li"),mbe=a("strong"),mlr=o("regnet"),glr=o(" \u2014 "),wW=a("a"),hlr=o("RegNetForImageClassification"),plr=o(" (RegNet model)"),_lr=l(),w7=a("li"),gbe=a("strong"),ulr=o("resnet"),blr=o(" \u2014 "),AW=a("a"),vlr=o("ResNetForImageClassification"),Flr=o(" (ResNet model)"),Tlr=l(),A7=a("li"),hbe=a("strong"),Mlr=o("segformer"),Elr=o(" \u2014 "),LW=a("a"),Clr=o("SegformerForImageClassification"),wlr=o(" (SegFormer model)"),Alr=l(),L7=a("li"),pbe=a("strong"),Llr=o("swin"),ylr=o(" \u2014 "),yW=a("a"),xlr=o("SwinForImageClassification"),$lr=o(" (Swin Transformer model)"),klr=l(),y7=a("li"),_be=a("strong"),Slr=o("van"),Rlr=o(" \u2014 "),xW=a("a"),Plr=o("VanForImageClassification"),Blr=o(" (VAN model)"),Ilr=l(),x7=a("li"),ube=a("strong"),Nlr=o("vit"),qlr=o(" \u2014 "),$W=a("a"),jlr=o("ViTForImageClassification"),Dlr=o(" (ViT model)"),Glr=l(),$7=a("p"),Olr=o("The model is set in evaluation mode by default using "),bbe=a("code"),Vlr=o("model.eval()"),Xlr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vbe=a("code"),zlr=o("model.train()"),Qlr=l(),F(k7.$$.fragment),TXe=l(),Md=a("h2"),S7=a("a"),Fbe=a("span"),F(Ry.$$.fragment),Wlr=l(),Tbe=a("span"),Hlr=o("AutoModelForVision2Seq"),MXe=l(),Oo=a("div"),F(Py.$$.fragment),Ulr=l(),Ed=a("p"),Jlr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),kW=a("a"),Ylr=o("from_pretrained()"),Klr=o(" class method or the "),SW=a("a"),Zlr=o("from_config()"),eir=o(` class
method.`),oir=l(),By=a("p"),rir=o("This class cannot be instantiated directly using "),Mbe=a("code"),tir=o("__init__()"),air=o(" (throws an error)."),nir=l(),Ft=a("div"),F(Iy.$$.fragment),sir=l(),Ebe=a("p"),lir=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),iir=l(),Cd=a("p"),dir=o(`Note:
Loading a model from its configuration file does `),Cbe=a("strong"),cir=o("not"),fir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RW=a("a"),mir=o("from_pretrained()"),gir=o(" to load the model weights."),hir=l(),F(R7.$$.fragment),pir=l(),io=a("div"),F(Ny.$$.fragment),_ir=l(),wbe=a("p"),uir=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),bir=l(),Wa=a("p"),vir=o("The model class to instantiate is selected based on the "),Abe=a("code"),Fir=o("model_type"),Tir=o(` property of the config object (either
passed as an argument or loaded from `),Lbe=a("code"),Mir=o("pretrained_model_name_or_path"),Eir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ybe=a("code"),Cir=o("pretrained_model_name_or_path"),wir=o(":"),Air=l(),xbe=a("ul"),P7=a("li"),$be=a("strong"),Lir=o("vision-encoder-decoder"),yir=o(" \u2014 "),PW=a("a"),xir=o("VisionEncoderDecoderModel"),$ir=o(" (Vision Encoder decoder model)"),kir=l(),B7=a("p"),Sir=o("The model is set in evaluation mode by default using "),kbe=a("code"),Rir=o("model.eval()"),Pir=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Sbe=a("code"),Bir=o("model.train()"),Iir=l(),F(I7.$$.fragment),EXe=l(),wd=a("h2"),N7=a("a"),Rbe=a("span"),F(qy.$$.fragment),Nir=l(),Pbe=a("span"),qir=o("AutoModelForVisualQuestionAnswering"),CXe=l(),Vo=a("div"),F(jy.$$.fragment),jir=l(),Ad=a("p"),Dir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),BW=a("a"),Gir=o("from_pretrained()"),Oir=o(" class method or the "),IW=a("a"),Vir=o("from_config()"),Xir=o(` class
method.`),zir=l(),Dy=a("p"),Qir=o("This class cannot be instantiated directly using "),Bbe=a("code"),Wir=o("__init__()"),Hir=o(" (throws an error)."),Uir=l(),Tt=a("div"),F(Gy.$$.fragment),Jir=l(),Ibe=a("p"),Yir=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Kir=l(),Ld=a("p"),Zir=o(`Note:
Loading a model from its configuration file does `),Nbe=a("strong"),edr=o("not"),odr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),NW=a("a"),rdr=o("from_pretrained()"),tdr=o(" to load the model weights."),adr=l(),F(q7.$$.fragment),ndr=l(),co=a("div"),F(Oy.$$.fragment),sdr=l(),qbe=a("p"),ldr=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),idr=l(),Ha=a("p"),ddr=o("The model class to instantiate is selected based on the "),jbe=a("code"),cdr=o("model_type"),fdr=o(` property of the config object (either
passed as an argument or loaded from `),Dbe=a("code"),mdr=o("pretrained_model_name_or_path"),gdr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gbe=a("code"),hdr=o("pretrained_model_name_or_path"),pdr=o(":"),_dr=l(),Obe=a("ul"),j7=a("li"),Vbe=a("strong"),udr=o("vilt"),bdr=o(" \u2014 "),qW=a("a"),vdr=o("ViltForQuestionAnswering"),Fdr=o(" (ViLT model)"),Tdr=l(),D7=a("p"),Mdr=o("The model is set in evaluation mode by default using "),Xbe=a("code"),Edr=o("model.eval()"),Cdr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zbe=a("code"),wdr=o("model.train()"),Adr=l(),F(G7.$$.fragment),wXe=l(),yd=a("h2"),O7=a("a"),Qbe=a("span"),F(Vy.$$.fragment),Ldr=l(),Wbe=a("span"),ydr=o("AutoModelForAudioClassification"),AXe=l(),Xo=a("div"),F(Xy.$$.fragment),xdr=l(),xd=a("p"),$dr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),jW=a("a"),kdr=o("from_pretrained()"),Sdr=o(" class method or the "),DW=a("a"),Rdr=o("from_config()"),Pdr=o(` class
method.`),Bdr=l(),zy=a("p"),Idr=o("This class cannot be instantiated directly using "),Hbe=a("code"),Ndr=o("__init__()"),qdr=o(" (throws an error)."),jdr=l(),Mt=a("div"),F(Qy.$$.fragment),Ddr=l(),Ube=a("p"),Gdr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),Odr=l(),$d=a("p"),Vdr=o(`Note:
Loading a model from its configuration file does `),Jbe=a("strong"),Xdr=o("not"),zdr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GW=a("a"),Qdr=o("from_pretrained()"),Wdr=o(" to load the model weights."),Hdr=l(),F(V7.$$.fragment),Udr=l(),fo=a("div"),F(Wy.$$.fragment),Jdr=l(),Ybe=a("p"),Ydr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Kdr=l(),Ua=a("p"),Zdr=o("The model class to instantiate is selected based on the "),Kbe=a("code"),ecr=o("model_type"),ocr=o(` property of the config object (either
passed as an argument or loaded from `),Zbe=a("code"),rcr=o("pretrained_model_name_or_path"),tcr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eve=a("code"),acr=o("pretrained_model_name_or_path"),ncr=o(":"),scr=l(),Pe=a("ul"),X7=a("li"),ove=a("strong"),lcr=o("data2vec-audio"),icr=o(" \u2014 "),OW=a("a"),dcr=o("Data2VecAudioForSequenceClassification"),ccr=o(" (Data2VecAudio model)"),fcr=l(),z7=a("li"),rve=a("strong"),mcr=o("hubert"),gcr=o(" \u2014 "),VW=a("a"),hcr=o("HubertForSequenceClassification"),pcr=o(" (Hubert model)"),_cr=l(),Q7=a("li"),tve=a("strong"),ucr=o("sew"),bcr=o(" \u2014 "),XW=a("a"),vcr=o("SEWForSequenceClassification"),Fcr=o(" (SEW model)"),Tcr=l(),W7=a("li"),ave=a("strong"),Mcr=o("sew-d"),Ecr=o(" \u2014 "),zW=a("a"),Ccr=o("SEWDForSequenceClassification"),wcr=o(" (SEW-D model)"),Acr=l(),H7=a("li"),nve=a("strong"),Lcr=o("unispeech"),ycr=o(" \u2014 "),QW=a("a"),xcr=o("UniSpeechForSequenceClassification"),$cr=o(" (UniSpeech model)"),kcr=l(),U7=a("li"),sve=a("strong"),Scr=o("unispeech-sat"),Rcr=o(" \u2014 "),WW=a("a"),Pcr=o("UniSpeechSatForSequenceClassification"),Bcr=o(" (UniSpeechSat model)"),Icr=l(),J7=a("li"),lve=a("strong"),Ncr=o("wav2vec2"),qcr=o(" \u2014 "),HW=a("a"),jcr=o("Wav2Vec2ForSequenceClassification"),Dcr=o(" (Wav2Vec2 model)"),Gcr=l(),Y7=a("li"),ive=a("strong"),Ocr=o("wav2vec2-conformer"),Vcr=o(" \u2014 "),UW=a("a"),Xcr=o("Wav2Vec2ConformerForSequenceClassification"),zcr=o(" (Wav2Vec2-Conformer model)"),Qcr=l(),K7=a("li"),dve=a("strong"),Wcr=o("wavlm"),Hcr=o(" \u2014 "),JW=a("a"),Ucr=o("WavLMForSequenceClassification"),Jcr=o(" (WavLM model)"),Ycr=l(),Z7=a("p"),Kcr=o("The model is set in evaluation mode by default using "),cve=a("code"),Zcr=o("model.eval()"),efr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fve=a("code"),ofr=o("model.train()"),rfr=l(),F(e8.$$.fragment),LXe=l(),kd=a("h2"),o8=a("a"),mve=a("span"),F(Hy.$$.fragment),tfr=l(),gve=a("span"),afr=o("AutoModelForAudioFrameClassification"),yXe=l(),zo=a("div"),F(Uy.$$.fragment),nfr=l(),Sd=a("p"),sfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),YW=a("a"),lfr=o("from_pretrained()"),ifr=o(" class method or the "),KW=a("a"),dfr=o("from_config()"),cfr=o(` class
method.`),ffr=l(),Jy=a("p"),mfr=o("This class cannot be instantiated directly using "),hve=a("code"),gfr=o("__init__()"),hfr=o(" (throws an error)."),pfr=l(),Et=a("div"),F(Yy.$$.fragment),_fr=l(),pve=a("p"),ufr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),bfr=l(),Rd=a("p"),vfr=o(`Note:
Loading a model from its configuration file does `),_ve=a("strong"),Ffr=o("not"),Tfr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZW=a("a"),Mfr=o("from_pretrained()"),Efr=o(" to load the model weights."),Cfr=l(),F(r8.$$.fragment),wfr=l(),mo=a("div"),F(Ky.$$.fragment),Afr=l(),uve=a("p"),Lfr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),yfr=l(),Ja=a("p"),xfr=o("The model class to instantiate is selected based on the "),bve=a("code"),$fr=o("model_type"),kfr=o(` property of the config object (either
passed as an argument or loaded from `),vve=a("code"),Sfr=o("pretrained_model_name_or_path"),Rfr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fve=a("code"),Pfr=o("pretrained_model_name_or_path"),Bfr=o(":"),Ifr=l(),et=a("ul"),t8=a("li"),Tve=a("strong"),Nfr=o("data2vec-audio"),qfr=o(" \u2014 "),eH=a("a"),jfr=o("Data2VecAudioForAudioFrameClassification"),Dfr=o(" (Data2VecAudio model)"),Gfr=l(),a8=a("li"),Mve=a("strong"),Ofr=o("unispeech-sat"),Vfr=o(" \u2014 "),oH=a("a"),Xfr=o("UniSpeechSatForAudioFrameClassification"),zfr=o(" (UniSpeechSat model)"),Qfr=l(),n8=a("li"),Eve=a("strong"),Wfr=o("wav2vec2"),Hfr=o(" \u2014 "),rH=a("a"),Ufr=o("Wav2Vec2ForAudioFrameClassification"),Jfr=o(" (Wav2Vec2 model)"),Yfr=l(),s8=a("li"),Cve=a("strong"),Kfr=o("wav2vec2-conformer"),Zfr=o(" \u2014 "),tH=a("a"),emr=o("Wav2Vec2ConformerForAudioFrameClassification"),omr=o(" (Wav2Vec2-Conformer model)"),rmr=l(),l8=a("li"),wve=a("strong"),tmr=o("wavlm"),amr=o(" \u2014 "),aH=a("a"),nmr=o("WavLMForAudioFrameClassification"),smr=o(" (WavLM model)"),lmr=l(),i8=a("p"),imr=o("The model is set in evaluation mode by default using "),Ave=a("code"),dmr=o("model.eval()"),cmr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lve=a("code"),fmr=o("model.train()"),mmr=l(),F(d8.$$.fragment),xXe=l(),Pd=a("h2"),c8=a("a"),yve=a("span"),F(Zy.$$.fragment),gmr=l(),xve=a("span"),hmr=o("AutoModelForCTC"),$Xe=l(),Qo=a("div"),F(e9.$$.fragment),pmr=l(),Bd=a("p"),_mr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),nH=a("a"),umr=o("from_pretrained()"),bmr=o(" class method or the "),sH=a("a"),vmr=o("from_config()"),Fmr=o(` class
method.`),Tmr=l(),o9=a("p"),Mmr=o("This class cannot be instantiated directly using "),$ve=a("code"),Emr=o("__init__()"),Cmr=o(" (throws an error)."),wmr=l(),Ct=a("div"),F(r9.$$.fragment),Amr=l(),kve=a("p"),Lmr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),ymr=l(),Id=a("p"),xmr=o(`Note:
Loading a model from its configuration file does `),Sve=a("strong"),$mr=o("not"),kmr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lH=a("a"),Smr=o("from_pretrained()"),Rmr=o(" to load the model weights."),Pmr=l(),F(f8.$$.fragment),Bmr=l(),go=a("div"),F(t9.$$.fragment),Imr=l(),Rve=a("p"),Nmr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),qmr=l(),Ya=a("p"),jmr=o("The model class to instantiate is selected based on the "),Pve=a("code"),Dmr=o("model_type"),Gmr=o(` property of the config object (either
passed as an argument or loaded from `),Bve=a("code"),Omr=o("pretrained_model_name_or_path"),Vmr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ive=a("code"),Xmr=o("pretrained_model_name_or_path"),zmr=o(":"),Qmr=l(),Le=a("ul"),m8=a("li"),Nve=a("strong"),Wmr=o("data2vec-audio"),Hmr=o(" \u2014 "),iH=a("a"),Umr=o("Data2VecAudioForCTC"),Jmr=o(" (Data2VecAudio model)"),Ymr=l(),g8=a("li"),qve=a("strong"),Kmr=o("hubert"),Zmr=o(" \u2014 "),dH=a("a"),egr=o("HubertForCTC"),ogr=o(" (Hubert model)"),rgr=l(),h8=a("li"),jve=a("strong"),tgr=o("mctct"),agr=o(" \u2014 "),cH=a("a"),ngr=o("MCTCTForCTC"),sgr=o(" (M-CTC-T model)"),lgr=l(),p8=a("li"),Dve=a("strong"),igr=o("sew"),dgr=o(" \u2014 "),fH=a("a"),cgr=o("SEWForCTC"),fgr=o(" (SEW model)"),mgr=l(),_8=a("li"),Gve=a("strong"),ggr=o("sew-d"),hgr=o(" \u2014 "),mH=a("a"),pgr=o("SEWDForCTC"),_gr=o(" (SEW-D model)"),ugr=l(),u8=a("li"),Ove=a("strong"),bgr=o("unispeech"),vgr=o(" \u2014 "),gH=a("a"),Fgr=o("UniSpeechForCTC"),Tgr=o(" (UniSpeech model)"),Mgr=l(),b8=a("li"),Vve=a("strong"),Egr=o("unispeech-sat"),Cgr=o(" \u2014 "),hH=a("a"),wgr=o("UniSpeechSatForCTC"),Agr=o(" (UniSpeechSat model)"),Lgr=l(),v8=a("li"),Xve=a("strong"),ygr=o("wav2vec2"),xgr=o(" \u2014 "),pH=a("a"),$gr=o("Wav2Vec2ForCTC"),kgr=o(" (Wav2Vec2 model)"),Sgr=l(),F8=a("li"),zve=a("strong"),Rgr=o("wav2vec2-conformer"),Pgr=o(" \u2014 "),_H=a("a"),Bgr=o("Wav2Vec2ConformerForCTC"),Igr=o(" (Wav2Vec2-Conformer model)"),Ngr=l(),T8=a("li"),Qve=a("strong"),qgr=o("wavlm"),jgr=o(" \u2014 "),uH=a("a"),Dgr=o("WavLMForCTC"),Ggr=o(" (WavLM model)"),Ogr=l(),M8=a("p"),Vgr=o("The model is set in evaluation mode by default using "),Wve=a("code"),Xgr=o("model.eval()"),zgr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Hve=a("code"),Qgr=o("model.train()"),Wgr=l(),F(E8.$$.fragment),kXe=l(),Nd=a("h2"),C8=a("a"),Uve=a("span"),F(a9.$$.fragment),Hgr=l(),Jve=a("span"),Ugr=o("AutoModelForSpeechSeq2Seq"),SXe=l(),Wo=a("div"),F(n9.$$.fragment),Jgr=l(),qd=a("p"),Ygr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),bH=a("a"),Kgr=o("from_pretrained()"),Zgr=o(" class method or the "),vH=a("a"),ehr=o("from_config()"),ohr=o(` class
method.`),rhr=l(),s9=a("p"),thr=o("This class cannot be instantiated directly using "),Yve=a("code"),ahr=o("__init__()"),nhr=o(" (throws an error)."),shr=l(),wt=a("div"),F(l9.$$.fragment),lhr=l(),Kve=a("p"),ihr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),dhr=l(),jd=a("p"),chr=o(`Note:
Loading a model from its configuration file does `),Zve=a("strong"),fhr=o("not"),mhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),FH=a("a"),ghr=o("from_pretrained()"),hhr=o(" to load the model weights."),phr=l(),F(w8.$$.fragment),_hr=l(),ho=a("div"),F(i9.$$.fragment),uhr=l(),eFe=a("p"),bhr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),vhr=l(),Ka=a("p"),Fhr=o("The model class to instantiate is selected based on the "),oFe=a("code"),Thr=o("model_type"),Mhr=o(` property of the config object (either
passed as an argument or loaded from `),rFe=a("code"),Ehr=o("pretrained_model_name_or_path"),Chr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tFe=a("code"),whr=o("pretrained_model_name_or_path"),Ahr=o(":"),Lhr=l(),d9=a("ul"),A8=a("li"),aFe=a("strong"),yhr=o("speech-encoder-decoder"),xhr=o(" \u2014 "),TH=a("a"),$hr=o("SpeechEncoderDecoderModel"),khr=o(" (Speech Encoder decoder model)"),Shr=l(),L8=a("li"),nFe=a("strong"),Rhr=o("speech_to_text"),Phr=o(" \u2014 "),MH=a("a"),Bhr=o("Speech2TextForConditionalGeneration"),Ihr=o(" (Speech2Text model)"),Nhr=l(),y8=a("p"),qhr=o("The model is set in evaluation mode by default using "),sFe=a("code"),jhr=o("model.eval()"),Dhr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lFe=a("code"),Ghr=o("model.train()"),Ohr=l(),F(x8.$$.fragment),RXe=l(),Dd=a("h2"),$8=a("a"),iFe=a("span"),F(c9.$$.fragment),Vhr=l(),dFe=a("span"),Xhr=o("AutoModelForAudioXVector"),PXe=l(),Ho=a("div"),F(f9.$$.fragment),zhr=l(),Gd=a("p"),Qhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),EH=a("a"),Whr=o("from_pretrained()"),Hhr=o(" class method or the "),CH=a("a"),Uhr=o("from_config()"),Jhr=o(` class
method.`),Yhr=l(),m9=a("p"),Khr=o("This class cannot be instantiated directly using "),cFe=a("code"),Zhr=o("__init__()"),epr=o(" (throws an error)."),opr=l(),At=a("div"),F(g9.$$.fragment),rpr=l(),fFe=a("p"),tpr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),apr=l(),Od=a("p"),npr=o(`Note:
Loading a model from its configuration file does `),mFe=a("strong"),spr=o("not"),lpr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wH=a("a"),ipr=o("from_pretrained()"),dpr=o(" to load the model weights."),cpr=l(),F(k8.$$.fragment),fpr=l(),po=a("div"),F(h9.$$.fragment),mpr=l(),gFe=a("p"),gpr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),hpr=l(),Za=a("p"),ppr=o("The model class to instantiate is selected based on the "),hFe=a("code"),_pr=o("model_type"),upr=o(` property of the config object (either
passed as an argument or loaded from `),pFe=a("code"),bpr=o("pretrained_model_name_or_path"),vpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Fe=a("code"),Fpr=o("pretrained_model_name_or_path"),Tpr=o(":"),Mpr=l(),ot=a("ul"),S8=a("li"),uFe=a("strong"),Epr=o("data2vec-audio"),Cpr=o(" \u2014 "),AH=a("a"),wpr=o("Data2VecAudioForXVector"),Apr=o(" (Data2VecAudio model)"),Lpr=l(),R8=a("li"),bFe=a("strong"),ypr=o("unispeech-sat"),xpr=o(" \u2014 "),LH=a("a"),$pr=o("UniSpeechSatForXVector"),kpr=o(" (UniSpeechSat model)"),Spr=l(),P8=a("li"),vFe=a("strong"),Rpr=o("wav2vec2"),Ppr=o(" \u2014 "),yH=a("a"),Bpr=o("Wav2Vec2ForXVector"),Ipr=o(" (Wav2Vec2 model)"),Npr=l(),B8=a("li"),FFe=a("strong"),qpr=o("wav2vec2-conformer"),jpr=o(" \u2014 "),xH=a("a"),Dpr=o("Wav2Vec2ConformerForXVector"),Gpr=o(" (Wav2Vec2-Conformer model)"),Opr=l(),I8=a("li"),TFe=a("strong"),Vpr=o("wavlm"),Xpr=o(" \u2014 "),$H=a("a"),zpr=o("WavLMForXVector"),Qpr=o(" (WavLM model)"),Wpr=l(),N8=a("p"),Hpr=o("The model is set in evaluation mode by default using "),MFe=a("code"),Upr=o("model.eval()"),Jpr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),EFe=a("code"),Ypr=o("model.train()"),Kpr=l(),F(q8.$$.fragment),BXe=l(),Vd=a("h2"),j8=a("a"),CFe=a("span"),F(p9.$$.fragment),Zpr=l(),wFe=a("span"),e_r=o("AutoModelForMaskedImageModeling"),IXe=l(),Uo=a("div"),F(_9.$$.fragment),o_r=l(),Xd=a("p"),r_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),kH=a("a"),t_r=o("from_pretrained()"),a_r=o(" class method or the "),SH=a("a"),n_r=o("from_config()"),s_r=o(` class
method.`),l_r=l(),u9=a("p"),i_r=o("This class cannot be instantiated directly using "),AFe=a("code"),d_r=o("__init__()"),c_r=o(" (throws an error)."),f_r=l(),Lt=a("div"),F(b9.$$.fragment),m_r=l(),LFe=a("p"),g_r=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),h_r=l(),zd=a("p"),p_r=o(`Note:
Loading a model from its configuration file does `),yFe=a("strong"),__r=o("not"),u_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RH=a("a"),b_r=o("from_pretrained()"),v_r=o(" to load the model weights."),F_r=l(),F(D8.$$.fragment),T_r=l(),_o=a("div"),F(v9.$$.fragment),M_r=l(),xFe=a("p"),E_r=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),C_r=l(),en=a("p"),w_r=o("The model class to instantiate is selected based on the "),$Fe=a("code"),A_r=o("model_type"),L_r=o(` property of the config object (either
passed as an argument or loaded from `),kFe=a("code"),y_r=o("pretrained_model_name_or_path"),x_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SFe=a("code"),$_r=o("pretrained_model_name_or_path"),k_r=o(":"),S_r=l(),Qd=a("ul"),G8=a("li"),RFe=a("strong"),R_r=o("deit"),P_r=o(" \u2014 "),PH=a("a"),B_r=o("DeiTForMaskedImageModeling"),I_r=o(" (DeiT model)"),N_r=l(),O8=a("li"),PFe=a("strong"),q_r=o("swin"),j_r=o(" \u2014 "),BH=a("a"),D_r=o("SwinForMaskedImageModeling"),G_r=o(" (Swin Transformer model)"),O_r=l(),V8=a("li"),BFe=a("strong"),V_r=o("vit"),X_r=o(" \u2014 "),IH=a("a"),z_r=o("ViTForMaskedImageModeling"),Q_r=o(" (ViT model)"),W_r=l(),X8=a("p"),H_r=o("The model is set in evaluation mode by default using "),IFe=a("code"),U_r=o("model.eval()"),J_r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),NFe=a("code"),Y_r=o("model.train()"),K_r=l(),F(z8.$$.fragment),NXe=l(),Wd=a("h2"),Q8=a("a"),qFe=a("span"),F(F9.$$.fragment),Z_r=l(),jFe=a("span"),eur=o("AutoModelForObjectDetection"),qXe=l(),Jo=a("div"),F(T9.$$.fragment),our=l(),Hd=a("p"),rur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),NH=a("a"),tur=o("from_pretrained()"),aur=o(" class method or the "),qH=a("a"),nur=o("from_config()"),sur=o(` class
method.`),lur=l(),M9=a("p"),iur=o("This class cannot be instantiated directly using "),DFe=a("code"),dur=o("__init__()"),cur=o(" (throws an error)."),fur=l(),yt=a("div"),F(E9.$$.fragment),mur=l(),GFe=a("p"),gur=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),hur=l(),Ud=a("p"),pur=o(`Note:
Loading a model from its configuration file does `),OFe=a("strong"),_ur=o("not"),uur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jH=a("a"),bur=o("from_pretrained()"),vur=o(" to load the model weights."),Fur=l(),F(W8.$$.fragment),Tur=l(),uo=a("div"),F(C9.$$.fragment),Mur=l(),VFe=a("p"),Eur=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),Cur=l(),on=a("p"),wur=o("The model class to instantiate is selected based on the "),XFe=a("code"),Aur=o("model_type"),Lur=o(` property of the config object (either
passed as an argument or loaded from `),zFe=a("code"),yur=o("pretrained_model_name_or_path"),xur=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QFe=a("code"),$ur=o("pretrained_model_name_or_path"),kur=o(":"),Sur=l(),w9=a("ul"),H8=a("li"),WFe=a("strong"),Rur=o("detr"),Pur=o(" \u2014 "),DH=a("a"),Bur=o("DetrForObjectDetection"),Iur=o(" (DETR model)"),Nur=l(),U8=a("li"),HFe=a("strong"),qur=o("yolos"),jur=o(" \u2014 "),GH=a("a"),Dur=o("YolosForObjectDetection"),Gur=o(" (YOLOS model)"),Our=l(),J8=a("p"),Vur=o("The model is set in evaluation mode by default using "),UFe=a("code"),Xur=o("model.eval()"),zur=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),JFe=a("code"),Qur=o("model.train()"),Wur=l(),F(Y8.$$.fragment),jXe=l(),Jd=a("h2"),K8=a("a"),YFe=a("span"),F(A9.$$.fragment),Hur=l(),KFe=a("span"),Uur=o("AutoModelForImageSegmentation"),DXe=l(),Yo=a("div"),F(L9.$$.fragment),Jur=l(),Yd=a("p"),Yur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),OH=a("a"),Kur=o("from_pretrained()"),Zur=o(" class method or the "),VH=a("a"),e1r=o("from_config()"),o1r=o(` class
method.`),r1r=l(),y9=a("p"),t1r=o("This class cannot be instantiated directly using "),ZFe=a("code"),a1r=o("__init__()"),n1r=o(" (throws an error)."),s1r=l(),xt=a("div"),F(x9.$$.fragment),l1r=l(),eTe=a("p"),i1r=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),d1r=l(),Kd=a("p"),c1r=o(`Note:
Loading a model from its configuration file does `),oTe=a("strong"),f1r=o("not"),m1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XH=a("a"),g1r=o("from_pretrained()"),h1r=o(" to load the model weights."),p1r=l(),F(Z8.$$.fragment),_1r=l(),bo=a("div"),F($9.$$.fragment),u1r=l(),rTe=a("p"),b1r=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),v1r=l(),rn=a("p"),F1r=o("The model class to instantiate is selected based on the "),tTe=a("code"),T1r=o("model_type"),M1r=o(` property of the config object (either
passed as an argument or loaded from `),aTe=a("code"),E1r=o("pretrained_model_name_or_path"),C1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nTe=a("code"),w1r=o("pretrained_model_name_or_path"),A1r=o(":"),L1r=l(),sTe=a("ul"),eM=a("li"),lTe=a("strong"),y1r=o("detr"),x1r=o(" \u2014 "),zH=a("a"),$1r=o("DetrForSegmentation"),k1r=o(" (DETR model)"),S1r=l(),oM=a("p"),R1r=o("The model is set in evaluation mode by default using "),iTe=a("code"),P1r=o("model.eval()"),B1r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dTe=a("code"),I1r=o("model.train()"),N1r=l(),F(rM.$$.fragment),GXe=l(),Zd=a("h2"),tM=a("a"),cTe=a("span"),F(k9.$$.fragment),q1r=l(),fTe=a("span"),j1r=o("AutoModelForSemanticSegmentation"),OXe=l(),Ko=a("div"),F(S9.$$.fragment),D1r=l(),ec=a("p"),G1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),QH=a("a"),O1r=o("from_pretrained()"),V1r=o(" class method or the "),WH=a("a"),X1r=o("from_config()"),z1r=o(` class
method.`),Q1r=l(),R9=a("p"),W1r=o("This class cannot be instantiated directly using "),mTe=a("code"),H1r=o("__init__()"),U1r=o(" (throws an error)."),J1r=l(),$t=a("div"),F(P9.$$.fragment),Y1r=l(),gTe=a("p"),K1r=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Z1r=l(),oc=a("p"),e2r=o(`Note:
Loading a model from its configuration file does `),hTe=a("strong"),o2r=o("not"),r2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HH=a("a"),t2r=o("from_pretrained()"),a2r=o(" to load the model weights."),n2r=l(),F(aM.$$.fragment),s2r=l(),vo=a("div"),F(B9.$$.fragment),l2r=l(),pTe=a("p"),i2r=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),d2r=l(),tn=a("p"),c2r=o("The model class to instantiate is selected based on the "),_Te=a("code"),f2r=o("model_type"),m2r=o(` property of the config object (either
passed as an argument or loaded from `),uTe=a("code"),g2r=o("pretrained_model_name_or_path"),h2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bTe=a("code"),p2r=o("pretrained_model_name_or_path"),_2r=o(":"),u2r=l(),rt=a("ul"),nM=a("li"),vTe=a("strong"),b2r=o("beit"),v2r=o(" \u2014 "),UH=a("a"),F2r=o("BeitForSemanticSegmentation"),T2r=o(" (BEiT model)"),M2r=l(),sM=a("li"),FTe=a("strong"),E2r=o("data2vec-vision"),C2r=o(" \u2014 "),JH=a("a"),w2r=o("Data2VecVisionForSemanticSegmentation"),A2r=o(" (Data2VecVision model)"),L2r=l(),lM=a("li"),TTe=a("strong"),y2r=o("dpt"),x2r=o(" \u2014 "),YH=a("a"),$2r=o("DPTForSemanticSegmentation"),k2r=o(" (DPT model)"),S2r=l(),iM=a("li"),MTe=a("strong"),R2r=o("mobilevit"),P2r=o(" \u2014 "),KH=a("a"),B2r=o("MobileViTForSemanticSegmentation"),I2r=o(" (MobileViT model)"),N2r=l(),dM=a("li"),ETe=a("strong"),q2r=o("segformer"),j2r=o(" \u2014 "),ZH=a("a"),D2r=o("SegformerForSemanticSegmentation"),G2r=o(" (SegFormer model)"),O2r=l(),cM=a("p"),V2r=o("The model is set in evaluation mode by default using "),CTe=a("code"),X2r=o("model.eval()"),z2r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),wTe=a("code"),Q2r=o("model.train()"),W2r=l(),F(fM.$$.fragment),VXe=l(),rc=a("h2"),mM=a("a"),ATe=a("span"),F(I9.$$.fragment),H2r=l(),LTe=a("span"),U2r=o("AutoModelForInstanceSegmentation"),XXe=l(),Zo=a("div"),F(N9.$$.fragment),J2r=l(),tc=a("p"),Y2r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),eU=a("a"),K2r=o("from_pretrained()"),Z2r=o(" class method or the "),oU=a("a"),ebr=o("from_config()"),obr=o(` class
method.`),rbr=l(),q9=a("p"),tbr=o("This class cannot be instantiated directly using "),yTe=a("code"),abr=o("__init__()"),nbr=o(" (throws an error)."),sbr=l(),kt=a("div"),F(j9.$$.fragment),lbr=l(),xTe=a("p"),ibr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),dbr=l(),ac=a("p"),cbr=o(`Note:
Loading a model from its configuration file does `),$Te=a("strong"),fbr=o("not"),mbr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rU=a("a"),gbr=o("from_pretrained()"),hbr=o(" to load the model weights."),pbr=l(),F(gM.$$.fragment),_br=l(),Fo=a("div"),F(D9.$$.fragment),ubr=l(),kTe=a("p"),bbr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),vbr=l(),an=a("p"),Fbr=o("The model class to instantiate is selected based on the "),STe=a("code"),Tbr=o("model_type"),Mbr=o(` property of the config object (either
passed as an argument or loaded from `),RTe=a("code"),Ebr=o("pretrained_model_name_or_path"),Cbr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PTe=a("code"),wbr=o("pretrained_model_name_or_path"),Abr=o(":"),Lbr=l(),BTe=a("ul"),hM=a("li"),ITe=a("strong"),ybr=o("maskformer"),xbr=o(" \u2014 "),tU=a("a"),$br=o("MaskFormerForInstanceSegmentation"),kbr=o(" (MaskFormer model)"),Sbr=l(),pM=a("p"),Rbr=o("The model is set in evaluation mode by default using "),NTe=a("code"),Pbr=o("model.eval()"),Bbr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qTe=a("code"),Ibr=o("model.train()"),Nbr=l(),F(_M.$$.fragment),zXe=l(),nc=a("h2"),uM=a("a"),jTe=a("span"),F(G9.$$.fragment),qbr=l(),DTe=a("span"),jbr=o("TFAutoModel"),QXe=l(),er=a("div"),F(O9.$$.fragment),Dbr=l(),sc=a("p"),Gbr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),aU=a("a"),Obr=o("from_pretrained()"),Vbr=o(" class method or the "),nU=a("a"),Xbr=o("from_config()"),zbr=o(` class
method.`),Qbr=l(),V9=a("p"),Wbr=o("This class cannot be instantiated directly using "),GTe=a("code"),Hbr=o("__init__()"),Ubr=o(" (throws an error)."),Jbr=l(),St=a("div"),F(X9.$$.fragment),Ybr=l(),OTe=a("p"),Kbr=o("Instantiates one of the base model classes of the library from a configuration."),Zbr=l(),lc=a("p"),evr=o(`Note:
Loading a model from its configuration file does `),VTe=a("strong"),ovr=o("not"),rvr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sU=a("a"),tvr=o("from_pretrained()"),avr=o(" to load the model weights."),nvr=l(),F(bM.$$.fragment),svr=l(),yr=a("div"),F(z9.$$.fragment),lvr=l(),XTe=a("p"),ivr=o("Instantiate one of the base model classes of the library from a pretrained model."),dvr=l(),nn=a("p"),cvr=o("The model class to instantiate is selected based on the "),zTe=a("code"),fvr=o("model_type"),mvr=o(` property of the config object (either
passed as an argument or loaded from `),QTe=a("code"),gvr=o("pretrained_model_name_or_path"),hvr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WTe=a("code"),pvr=o("pretrained_model_name_or_path"),_vr=o(":"),uvr=l(),j=a("ul"),vM=a("li"),HTe=a("strong"),bvr=o("albert"),vvr=o(" \u2014 "),lU=a("a"),Fvr=o("TFAlbertModel"),Tvr=o(" (ALBERT model)"),Mvr=l(),FM=a("li"),UTe=a("strong"),Evr=o("bart"),Cvr=o(" \u2014 "),iU=a("a"),wvr=o("TFBartModel"),Avr=o(" (BART model)"),Lvr=l(),TM=a("li"),JTe=a("strong"),yvr=o("bert"),xvr=o(" \u2014 "),dU=a("a"),$vr=o("TFBertModel"),kvr=o(" (BERT model)"),Svr=l(),MM=a("li"),YTe=a("strong"),Rvr=o("blenderbot"),Pvr=o(" \u2014 "),cU=a("a"),Bvr=o("TFBlenderbotModel"),Ivr=o(" (Blenderbot model)"),Nvr=l(),EM=a("li"),KTe=a("strong"),qvr=o("blenderbot-small"),jvr=o(" \u2014 "),fU=a("a"),Dvr=o("TFBlenderbotSmallModel"),Gvr=o(" (BlenderbotSmall model)"),Ovr=l(),CM=a("li"),ZTe=a("strong"),Vvr=o("camembert"),Xvr=o(" \u2014 "),mU=a("a"),zvr=o("TFCamembertModel"),Qvr=o(" (CamemBERT model)"),Wvr=l(),wM=a("li"),e7e=a("strong"),Hvr=o("clip"),Uvr=o(" \u2014 "),gU=a("a"),Jvr=o("TFCLIPModel"),Yvr=o(" (CLIP model)"),Kvr=l(),AM=a("li"),o7e=a("strong"),Zvr=o("convbert"),eFr=o(" \u2014 "),hU=a("a"),oFr=o("TFConvBertModel"),rFr=o(" (ConvBERT model)"),tFr=l(),LM=a("li"),r7e=a("strong"),aFr=o("convnext"),nFr=o(" \u2014 "),pU=a("a"),sFr=o("TFConvNextModel"),lFr=o(" (ConvNeXT model)"),iFr=l(),yM=a("li"),t7e=a("strong"),dFr=o("ctrl"),cFr=o(" \u2014 "),_U=a("a"),fFr=o("TFCTRLModel"),mFr=o(" (CTRL model)"),gFr=l(),xM=a("li"),a7e=a("strong"),hFr=o("data2vec-vision"),pFr=o(" \u2014 "),uU=a("a"),_Fr=o("TFData2VecVisionModel"),uFr=o(" (Data2VecVision model)"),bFr=l(),$M=a("li"),n7e=a("strong"),vFr=o("deberta"),FFr=o(" \u2014 "),bU=a("a"),TFr=o("TFDebertaModel"),MFr=o(" (DeBERTa model)"),EFr=l(),kM=a("li"),s7e=a("strong"),CFr=o("deberta-v2"),wFr=o(" \u2014 "),vU=a("a"),AFr=o("TFDebertaV2Model"),LFr=o(" (DeBERTa-v2 model)"),yFr=l(),SM=a("li"),l7e=a("strong"),xFr=o("distilbert"),$Fr=o(" \u2014 "),FU=a("a"),kFr=o("TFDistilBertModel"),SFr=o(" (DistilBERT model)"),RFr=l(),RM=a("li"),i7e=a("strong"),PFr=o("dpr"),BFr=o(" \u2014 "),TU=a("a"),IFr=o("TFDPRQuestionEncoder"),NFr=o(" (DPR model)"),qFr=l(),PM=a("li"),d7e=a("strong"),jFr=o("electra"),DFr=o(" \u2014 "),MU=a("a"),GFr=o("TFElectraModel"),OFr=o(" (ELECTRA model)"),VFr=l(),BM=a("li"),c7e=a("strong"),XFr=o("flaubert"),zFr=o(" \u2014 "),EU=a("a"),QFr=o("TFFlaubertModel"),WFr=o(" (FlauBERT model)"),HFr=l(),Us=a("li"),f7e=a("strong"),UFr=o("funnel"),JFr=o(" \u2014 "),CU=a("a"),YFr=o("TFFunnelModel"),KFr=o(" or "),wU=a("a"),ZFr=o("TFFunnelBaseModel"),eTr=o(" (Funnel Transformer model)"),oTr=l(),IM=a("li"),m7e=a("strong"),rTr=o("gpt2"),tTr=o(" \u2014 "),AU=a("a"),aTr=o("TFGPT2Model"),nTr=o(" (OpenAI GPT-2 model)"),sTr=l(),NM=a("li"),g7e=a("strong"),lTr=o("gptj"),iTr=o(" \u2014 "),LU=a("a"),dTr=o("TFGPTJModel"),cTr=o(" (GPT-J model)"),fTr=l(),qM=a("li"),h7e=a("strong"),mTr=o("hubert"),gTr=o(" \u2014 "),yU=a("a"),hTr=o("TFHubertModel"),pTr=o(" (Hubert model)"),_Tr=l(),jM=a("li"),p7e=a("strong"),uTr=o("layoutlm"),bTr=o(" \u2014 "),xU=a("a"),vTr=o("TFLayoutLMModel"),FTr=o(" (LayoutLM model)"),TTr=l(),DM=a("li"),_7e=a("strong"),MTr=o("led"),ETr=o(" \u2014 "),$U=a("a"),CTr=o("TFLEDModel"),wTr=o(" (LED model)"),ATr=l(),GM=a("li"),u7e=a("strong"),LTr=o("longformer"),yTr=o(" \u2014 "),kU=a("a"),xTr=o("TFLongformerModel"),$Tr=o(" (Longformer model)"),kTr=l(),OM=a("li"),b7e=a("strong"),STr=o("lxmert"),RTr=o(" \u2014 "),SU=a("a"),PTr=o("TFLxmertModel"),BTr=o(" (LXMERT model)"),ITr=l(),VM=a("li"),v7e=a("strong"),NTr=o("marian"),qTr=o(" \u2014 "),RU=a("a"),jTr=o("TFMarianModel"),DTr=o(" (Marian model)"),GTr=l(),XM=a("li"),F7e=a("strong"),OTr=o("mbart"),VTr=o(" \u2014 "),PU=a("a"),XTr=o("TFMBartModel"),zTr=o(" (mBART model)"),QTr=l(),zM=a("li"),T7e=a("strong"),WTr=o("mobilebert"),HTr=o(" \u2014 "),BU=a("a"),UTr=o("TFMobileBertModel"),JTr=o(" (MobileBERT model)"),YTr=l(),QM=a("li"),M7e=a("strong"),KTr=o("mpnet"),ZTr=o(" \u2014 "),IU=a("a"),e7r=o("TFMPNetModel"),o7r=o(" (MPNet model)"),r7r=l(),WM=a("li"),E7e=a("strong"),t7r=o("mt5"),a7r=o(" \u2014 "),NU=a("a"),n7r=o("TFMT5Model"),s7r=o(" (MT5 model)"),l7r=l(),HM=a("li"),C7e=a("strong"),i7r=o("openai-gpt"),d7r=o(" \u2014 "),qU=a("a"),c7r=o("TFOpenAIGPTModel"),f7r=o(" (OpenAI GPT model)"),m7r=l(),UM=a("li"),w7e=a("strong"),g7r=o("opt"),h7r=o(" \u2014 "),jU=a("a"),p7r=o("TFOPTModel"),_7r=o(" (OPT model)"),u7r=l(),JM=a("li"),A7e=a("strong"),b7r=o("pegasus"),v7r=o(" \u2014 "),DU=a("a"),F7r=o("TFPegasusModel"),T7r=o(" (Pegasus model)"),M7r=l(),YM=a("li"),L7e=a("strong"),E7r=o("regnet"),C7r=o(" \u2014 "),GU=a("a"),w7r=o("TFRegNetModel"),A7r=o(" (RegNet model)"),L7r=l(),KM=a("li"),y7e=a("strong"),y7r=o("rembert"),x7r=o(" \u2014 "),OU=a("a"),$7r=o("TFRemBertModel"),k7r=o(" (RemBERT model)"),S7r=l(),ZM=a("li"),x7e=a("strong"),R7r=o("roberta"),P7r=o(" \u2014 "),VU=a("a"),B7r=o("TFRobertaModel"),I7r=o(" (RoBERTa model)"),N7r=l(),e4=a("li"),$7e=a("strong"),q7r=o("roformer"),j7r=o(" \u2014 "),XU=a("a"),D7r=o("TFRoFormerModel"),G7r=o(" (RoFormer model)"),O7r=l(),o4=a("li"),k7e=a("strong"),V7r=o("speech_to_text"),X7r=o(" \u2014 "),zU=a("a"),z7r=o("TFSpeech2TextModel"),Q7r=o(" (Speech2Text model)"),W7r=l(),r4=a("li"),S7e=a("strong"),H7r=o("swin"),U7r=o(" \u2014 "),QU=a("a"),J7r=o("TFSwinModel"),Y7r=o(" (Swin Transformer model)"),K7r=l(),t4=a("li"),R7e=a("strong"),Z7r=o("t5"),e8r=o(" \u2014 "),WU=a("a"),o8r=o("TFT5Model"),r8r=o(" (T5 model)"),t8r=l(),a4=a("li"),P7e=a("strong"),a8r=o("tapas"),n8r=o(" \u2014 "),HU=a("a"),s8r=o("TFTapasModel"),l8r=o(" (TAPAS model)"),i8r=l(),n4=a("li"),B7e=a("strong"),d8r=o("transfo-xl"),c8r=o(" \u2014 "),UU=a("a"),f8r=o("TFTransfoXLModel"),m8r=o(" (Transformer-XL model)"),g8r=l(),s4=a("li"),I7e=a("strong"),h8r=o("vit"),p8r=o(" \u2014 "),JU=a("a"),_8r=o("TFViTModel"),u8r=o(" (ViT model)"),b8r=l(),l4=a("li"),N7e=a("strong"),v8r=o("vit_mae"),F8r=o(" \u2014 "),YU=a("a"),T8r=o("TFViTMAEModel"),M8r=o(" (ViTMAE model)"),E8r=l(),i4=a("li"),q7e=a("strong"),C8r=o("wav2vec2"),w8r=o(" \u2014 "),KU=a("a"),A8r=o("TFWav2Vec2Model"),L8r=o(" (Wav2Vec2 model)"),y8r=l(),d4=a("li"),j7e=a("strong"),x8r=o("xlm"),$8r=o(" \u2014 "),ZU=a("a"),k8r=o("TFXLMModel"),S8r=o(" (XLM model)"),R8r=l(),c4=a("li"),D7e=a("strong"),P8r=o("xlm-roberta"),B8r=o(" \u2014 "),eJ=a("a"),I8r=o("TFXLMRobertaModel"),N8r=o(" (XLM-RoBERTa model)"),q8r=l(),f4=a("li"),G7e=a("strong"),j8r=o("xlnet"),D8r=o(" \u2014 "),oJ=a("a"),G8r=o("TFXLNetModel"),O8r=o(" (XLNet model)"),V8r=l(),F(m4.$$.fragment),WXe=l(),ic=a("h2"),g4=a("a"),O7e=a("span"),F(Q9.$$.fragment),X8r=l(),V7e=a("span"),z8r=o("TFAutoModelForPreTraining"),HXe=l(),or=a("div"),F(W9.$$.fragment),Q8r=l(),dc=a("p"),W8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),rJ=a("a"),H8r=o("from_pretrained()"),U8r=o(" class method or the "),tJ=a("a"),J8r=o("from_config()"),Y8r=o(` class
method.`),K8r=l(),H9=a("p"),Z8r=o("This class cannot be instantiated directly using "),X7e=a("code"),eMr=o("__init__()"),oMr=o(" (throws an error)."),rMr=l(),Rt=a("div"),F(U9.$$.fragment),tMr=l(),z7e=a("p"),aMr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),nMr=l(),cc=a("p"),sMr=o(`Note:
Loading a model from its configuration file does `),Q7e=a("strong"),lMr=o("not"),iMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aJ=a("a"),dMr=o("from_pretrained()"),cMr=o(" to load the model weights."),fMr=l(),F(h4.$$.fragment),mMr=l(),xr=a("div"),F(J9.$$.fragment),gMr=l(),W7e=a("p"),hMr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),pMr=l(),sn=a("p"),_Mr=o("The model class to instantiate is selected based on the "),H7e=a("code"),uMr=o("model_type"),bMr=o(` property of the config object (either
passed as an argument or loaded from `),U7e=a("code"),vMr=o("pretrained_model_name_or_path"),FMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J7e=a("code"),TMr=o("pretrained_model_name_or_path"),MMr=o(":"),EMr=l(),se=a("ul"),p4=a("li"),Y7e=a("strong"),CMr=o("albert"),wMr=o(" \u2014 "),nJ=a("a"),AMr=o("TFAlbertForPreTraining"),LMr=o(" (ALBERT model)"),yMr=l(),_4=a("li"),K7e=a("strong"),xMr=o("bart"),$Mr=o(" \u2014 "),sJ=a("a"),kMr=o("TFBartForConditionalGeneration"),SMr=o(" (BART model)"),RMr=l(),u4=a("li"),Z7e=a("strong"),PMr=o("bert"),BMr=o(" \u2014 "),lJ=a("a"),IMr=o("TFBertForPreTraining"),NMr=o(" (BERT model)"),qMr=l(),b4=a("li"),e8e=a("strong"),jMr=o("camembert"),DMr=o(" \u2014 "),iJ=a("a"),GMr=o("TFCamembertForMaskedLM"),OMr=o(" (CamemBERT model)"),VMr=l(),v4=a("li"),o8e=a("strong"),XMr=o("ctrl"),zMr=o(" \u2014 "),dJ=a("a"),QMr=o("TFCTRLLMHeadModel"),WMr=o(" (CTRL model)"),HMr=l(),F4=a("li"),r8e=a("strong"),UMr=o("distilbert"),JMr=o(" \u2014 "),cJ=a("a"),YMr=o("TFDistilBertForMaskedLM"),KMr=o(" (DistilBERT model)"),ZMr=l(),T4=a("li"),t8e=a("strong"),e4r=o("electra"),o4r=o(" \u2014 "),fJ=a("a"),r4r=o("TFElectraForPreTraining"),t4r=o(" (ELECTRA model)"),a4r=l(),M4=a("li"),a8e=a("strong"),n4r=o("flaubert"),s4r=o(" \u2014 "),mJ=a("a"),l4r=o("TFFlaubertWithLMHeadModel"),i4r=o(" (FlauBERT model)"),d4r=l(),E4=a("li"),n8e=a("strong"),c4r=o("funnel"),f4r=o(" \u2014 "),gJ=a("a"),m4r=o("TFFunnelForPreTraining"),g4r=o(" (Funnel Transformer model)"),h4r=l(),C4=a("li"),s8e=a("strong"),p4r=o("gpt2"),_4r=o(" \u2014 "),hJ=a("a"),u4r=o("TFGPT2LMHeadModel"),b4r=o(" (OpenAI GPT-2 model)"),v4r=l(),w4=a("li"),l8e=a("strong"),F4r=o("layoutlm"),T4r=o(" \u2014 "),pJ=a("a"),M4r=o("TFLayoutLMForMaskedLM"),E4r=o(" (LayoutLM model)"),C4r=l(),A4=a("li"),i8e=a("strong"),w4r=o("lxmert"),A4r=o(" \u2014 "),_J=a("a"),L4r=o("TFLxmertForPreTraining"),y4r=o(" (LXMERT model)"),x4r=l(),L4=a("li"),d8e=a("strong"),$4r=o("mobilebert"),k4r=o(" \u2014 "),uJ=a("a"),S4r=o("TFMobileBertForPreTraining"),R4r=o(" (MobileBERT model)"),P4r=l(),y4=a("li"),c8e=a("strong"),B4r=o("mpnet"),I4r=o(" \u2014 "),bJ=a("a"),N4r=o("TFMPNetForMaskedLM"),q4r=o(" (MPNet model)"),j4r=l(),x4=a("li"),f8e=a("strong"),D4r=o("openai-gpt"),G4r=o(" \u2014 "),vJ=a("a"),O4r=o("TFOpenAIGPTLMHeadModel"),V4r=o(" (OpenAI GPT model)"),X4r=l(),$4=a("li"),m8e=a("strong"),z4r=o("roberta"),Q4r=o(" \u2014 "),FJ=a("a"),W4r=o("TFRobertaForMaskedLM"),H4r=o(" (RoBERTa model)"),U4r=l(),k4=a("li"),g8e=a("strong"),J4r=o("t5"),Y4r=o(" \u2014 "),TJ=a("a"),K4r=o("TFT5ForConditionalGeneration"),Z4r=o(" (T5 model)"),eEr=l(),S4=a("li"),h8e=a("strong"),oEr=o("tapas"),rEr=o(" \u2014 "),MJ=a("a"),tEr=o("TFTapasForMaskedLM"),aEr=o(" (TAPAS model)"),nEr=l(),R4=a("li"),p8e=a("strong"),sEr=o("transfo-xl"),lEr=o(" \u2014 "),EJ=a("a"),iEr=o("TFTransfoXLLMHeadModel"),dEr=o(" (Transformer-XL model)"),cEr=l(),P4=a("li"),_8e=a("strong"),fEr=o("vit_mae"),mEr=o(" \u2014 "),CJ=a("a"),gEr=o("TFViTMAEForPreTraining"),hEr=o(" (ViTMAE model)"),pEr=l(),B4=a("li"),u8e=a("strong"),_Er=o("xlm"),uEr=o(" \u2014 "),wJ=a("a"),bEr=o("TFXLMWithLMHeadModel"),vEr=o(" (XLM model)"),FEr=l(),I4=a("li"),b8e=a("strong"),TEr=o("xlm-roberta"),MEr=o(" \u2014 "),AJ=a("a"),EEr=o("TFXLMRobertaForMaskedLM"),CEr=o(" (XLM-RoBERTa model)"),wEr=l(),N4=a("li"),v8e=a("strong"),AEr=o("xlnet"),LEr=o(" \u2014 "),LJ=a("a"),yEr=o("TFXLNetLMHeadModel"),xEr=o(" (XLNet model)"),$Er=l(),F(q4.$$.fragment),UXe=l(),fc=a("h2"),j4=a("a"),F8e=a("span"),F(Y9.$$.fragment),kEr=l(),T8e=a("span"),SEr=o("TFAutoModelForCausalLM"),JXe=l(),rr=a("div"),F(K9.$$.fragment),REr=l(),mc=a("p"),PEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),yJ=a("a"),BEr=o("from_pretrained()"),IEr=o(" class method or the "),xJ=a("a"),NEr=o("from_config()"),qEr=o(` class
method.`),jEr=l(),Z9=a("p"),DEr=o("This class cannot be instantiated directly using "),M8e=a("code"),GEr=o("__init__()"),OEr=o(" (throws an error)."),VEr=l(),Pt=a("div"),F(ex.$$.fragment),XEr=l(),E8e=a("p"),zEr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),QEr=l(),gc=a("p"),WEr=o(`Note:
Loading a model from its configuration file does `),C8e=a("strong"),HEr=o("not"),UEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$J=a("a"),JEr=o("from_pretrained()"),YEr=o(" to load the model weights."),KEr=l(),F(D4.$$.fragment),ZEr=l(),$r=a("div"),F(ox.$$.fragment),eCr=l(),w8e=a("p"),oCr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),rCr=l(),ln=a("p"),tCr=o("The model class to instantiate is selected based on the "),A8e=a("code"),aCr=o("model_type"),nCr=o(` property of the config object (either
passed as an argument or loaded from `),L8e=a("code"),sCr=o("pretrained_model_name_or_path"),lCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y8e=a("code"),iCr=o("pretrained_model_name_or_path"),dCr=o(":"),cCr=l(),Me=a("ul"),G4=a("li"),x8e=a("strong"),fCr=o("bert"),mCr=o(" \u2014 "),kJ=a("a"),gCr=o("TFBertLMHeadModel"),hCr=o(" (BERT model)"),pCr=l(),O4=a("li"),$8e=a("strong"),_Cr=o("camembert"),uCr=o(" \u2014 "),SJ=a("a"),bCr=o("TFCamembertForCausalLM"),vCr=o(" (CamemBERT model)"),FCr=l(),V4=a("li"),k8e=a("strong"),TCr=o("ctrl"),MCr=o(" \u2014 "),RJ=a("a"),ECr=o("TFCTRLLMHeadModel"),CCr=o(" (CTRL model)"),wCr=l(),X4=a("li"),S8e=a("strong"),ACr=o("gpt2"),LCr=o(" \u2014 "),PJ=a("a"),yCr=o("TFGPT2LMHeadModel"),xCr=o(" (OpenAI GPT-2 model)"),$Cr=l(),z4=a("li"),R8e=a("strong"),kCr=o("gptj"),SCr=o(" \u2014 "),BJ=a("a"),RCr=o("TFGPTJForCausalLM"),PCr=o(" (GPT-J model)"),BCr=l(),Q4=a("li"),P8e=a("strong"),ICr=o("openai-gpt"),NCr=o(" \u2014 "),IJ=a("a"),qCr=o("TFOpenAIGPTLMHeadModel"),jCr=o(" (OpenAI GPT model)"),DCr=l(),W4=a("li"),B8e=a("strong"),GCr=o("opt"),OCr=o(" \u2014 "),NJ=a("a"),VCr=o("TFOPTForCausalLM"),XCr=o(" (OPT model)"),zCr=l(),H4=a("li"),I8e=a("strong"),QCr=o("rembert"),WCr=o(" \u2014 "),qJ=a("a"),HCr=o("TFRemBertForCausalLM"),UCr=o(" (RemBERT model)"),JCr=l(),U4=a("li"),N8e=a("strong"),YCr=o("roberta"),KCr=o(" \u2014 "),jJ=a("a"),ZCr=o("TFRobertaForCausalLM"),e3r=o(" (RoBERTa model)"),o3r=l(),J4=a("li"),q8e=a("strong"),r3r=o("roformer"),t3r=o(" \u2014 "),DJ=a("a"),a3r=o("TFRoFormerForCausalLM"),n3r=o(" (RoFormer model)"),s3r=l(),Y4=a("li"),j8e=a("strong"),l3r=o("transfo-xl"),i3r=o(" \u2014 "),GJ=a("a"),d3r=o("TFTransfoXLLMHeadModel"),c3r=o(" (Transformer-XL model)"),f3r=l(),K4=a("li"),D8e=a("strong"),m3r=o("xlm"),g3r=o(" \u2014 "),OJ=a("a"),h3r=o("TFXLMWithLMHeadModel"),p3r=o(" (XLM model)"),_3r=l(),Z4=a("li"),G8e=a("strong"),u3r=o("xlnet"),b3r=o(" \u2014 "),VJ=a("a"),v3r=o("TFXLNetLMHeadModel"),F3r=o(" (XLNet model)"),T3r=l(),F(eE.$$.fragment),YXe=l(),hc=a("h2"),oE=a("a"),O8e=a("span"),F(rx.$$.fragment),M3r=l(),V8e=a("span"),E3r=o("TFAutoModelForImageClassification"),KXe=l(),tr=a("div"),F(tx.$$.fragment),C3r=l(),pc=a("p"),w3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),XJ=a("a"),A3r=o("from_pretrained()"),L3r=o(" class method or the "),zJ=a("a"),y3r=o("from_config()"),x3r=o(` class
method.`),$3r=l(),ax=a("p"),k3r=o("This class cannot be instantiated directly using "),X8e=a("code"),S3r=o("__init__()"),R3r=o(" (throws an error)."),P3r=l(),Bt=a("div"),F(nx.$$.fragment),B3r=l(),z8e=a("p"),I3r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),N3r=l(),_c=a("p"),q3r=o(`Note:
Loading a model from its configuration file does `),Q8e=a("strong"),j3r=o("not"),D3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QJ=a("a"),G3r=o("from_pretrained()"),O3r=o(" to load the model weights."),V3r=l(),F(rE.$$.fragment),X3r=l(),kr=a("div"),F(sx.$$.fragment),z3r=l(),W8e=a("p"),Q3r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),W3r=l(),dn=a("p"),H3r=o("The model class to instantiate is selected based on the "),H8e=a("code"),U3r=o("model_type"),J3r=o(` property of the config object (either
passed as an argument or loaded from `),U8e=a("code"),Y3r=o("pretrained_model_name_or_path"),K3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J8e=a("code"),Z3r=o("pretrained_model_name_or_path"),e5r=o(":"),o5r=l(),tt=a("ul"),tE=a("li"),Y8e=a("strong"),r5r=o("convnext"),t5r=o(" \u2014 "),WJ=a("a"),a5r=o("TFConvNextForImageClassification"),n5r=o(" (ConvNeXT model)"),s5r=l(),aE=a("li"),K8e=a("strong"),l5r=o("data2vec-vision"),i5r=o(" \u2014 "),HJ=a("a"),d5r=o("TFData2VecVisionForImageClassification"),c5r=o(" (Data2VecVision model)"),f5r=l(),nE=a("li"),Z8e=a("strong"),m5r=o("regnet"),g5r=o(" \u2014 "),UJ=a("a"),h5r=o("TFRegNetForImageClassification"),p5r=o(" (RegNet model)"),_5r=l(),sE=a("li"),eMe=a("strong"),u5r=o("swin"),b5r=o(" \u2014 "),JJ=a("a"),v5r=o("TFSwinForImageClassification"),F5r=o(" (Swin Transformer model)"),T5r=l(),lE=a("li"),oMe=a("strong"),M5r=o("vit"),E5r=o(" \u2014 "),YJ=a("a"),C5r=o("TFViTForImageClassification"),w5r=o(" (ViT model)"),A5r=l(),F(iE.$$.fragment),ZXe=l(),uc=a("h2"),dE=a("a"),rMe=a("span"),F(lx.$$.fragment),L5r=l(),tMe=a("span"),y5r=o("TFAutoModelForMaskedLM"),eze=l(),ar=a("div"),F(ix.$$.fragment),x5r=l(),bc=a("p"),$5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),KJ=a("a"),k5r=o("from_pretrained()"),S5r=o(" class method or the "),ZJ=a("a"),R5r=o("from_config()"),P5r=o(` class
method.`),B5r=l(),dx=a("p"),I5r=o("This class cannot be instantiated directly using "),aMe=a("code"),N5r=o("__init__()"),q5r=o(" (throws an error)."),j5r=l(),It=a("div"),F(cx.$$.fragment),D5r=l(),nMe=a("p"),G5r=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),O5r=l(),vc=a("p"),V5r=o(`Note:
Loading a model from its configuration file does `),sMe=a("strong"),X5r=o("not"),z5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eY=a("a"),Q5r=o("from_pretrained()"),W5r=o(" to load the model weights."),H5r=l(),F(cE.$$.fragment),U5r=l(),Sr=a("div"),F(fx.$$.fragment),J5r=l(),lMe=a("p"),Y5r=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),K5r=l(),cn=a("p"),Z5r=o("The model class to instantiate is selected based on the "),iMe=a("code"),e0r=o("model_type"),o0r=o(` property of the config object (either
passed as an argument or loaded from `),dMe=a("code"),r0r=o("pretrained_model_name_or_path"),t0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cMe=a("code"),a0r=o("pretrained_model_name_or_path"),n0r=o(":"),s0r=l(),ie=a("ul"),fE=a("li"),fMe=a("strong"),l0r=o("albert"),i0r=o(" \u2014 "),oY=a("a"),d0r=o("TFAlbertForMaskedLM"),c0r=o(" (ALBERT model)"),f0r=l(),mE=a("li"),mMe=a("strong"),m0r=o("bert"),g0r=o(" \u2014 "),rY=a("a"),h0r=o("TFBertForMaskedLM"),p0r=o(" (BERT model)"),_0r=l(),gE=a("li"),gMe=a("strong"),u0r=o("camembert"),b0r=o(" \u2014 "),tY=a("a"),v0r=o("TFCamembertForMaskedLM"),F0r=o(" (CamemBERT model)"),T0r=l(),hE=a("li"),hMe=a("strong"),M0r=o("convbert"),E0r=o(" \u2014 "),aY=a("a"),C0r=o("TFConvBertForMaskedLM"),w0r=o(" (ConvBERT model)"),A0r=l(),pE=a("li"),pMe=a("strong"),L0r=o("deberta"),y0r=o(" \u2014 "),nY=a("a"),x0r=o("TFDebertaForMaskedLM"),$0r=o(" (DeBERTa model)"),k0r=l(),_E=a("li"),_Me=a("strong"),S0r=o("deberta-v2"),R0r=o(" \u2014 "),sY=a("a"),P0r=o("TFDebertaV2ForMaskedLM"),B0r=o(" (DeBERTa-v2 model)"),I0r=l(),uE=a("li"),uMe=a("strong"),N0r=o("distilbert"),q0r=o(" \u2014 "),lY=a("a"),j0r=o("TFDistilBertForMaskedLM"),D0r=o(" (DistilBERT model)"),G0r=l(),bE=a("li"),bMe=a("strong"),O0r=o("electra"),V0r=o(" \u2014 "),iY=a("a"),X0r=o("TFElectraForMaskedLM"),z0r=o(" (ELECTRA model)"),Q0r=l(),vE=a("li"),vMe=a("strong"),W0r=o("flaubert"),H0r=o(" \u2014 "),dY=a("a"),U0r=o("TFFlaubertWithLMHeadModel"),J0r=o(" (FlauBERT model)"),Y0r=l(),FE=a("li"),FMe=a("strong"),K0r=o("funnel"),Z0r=o(" \u2014 "),cY=a("a"),ewr=o("TFFunnelForMaskedLM"),owr=o(" (Funnel Transformer model)"),rwr=l(),TE=a("li"),TMe=a("strong"),twr=o("layoutlm"),awr=o(" \u2014 "),fY=a("a"),nwr=o("TFLayoutLMForMaskedLM"),swr=o(" (LayoutLM model)"),lwr=l(),ME=a("li"),MMe=a("strong"),iwr=o("longformer"),dwr=o(" \u2014 "),mY=a("a"),cwr=o("TFLongformerForMaskedLM"),fwr=o(" (Longformer model)"),mwr=l(),EE=a("li"),EMe=a("strong"),gwr=o("mobilebert"),hwr=o(" \u2014 "),gY=a("a"),pwr=o("TFMobileBertForMaskedLM"),_wr=o(" (MobileBERT model)"),uwr=l(),CE=a("li"),CMe=a("strong"),bwr=o("mpnet"),vwr=o(" \u2014 "),hY=a("a"),Fwr=o("TFMPNetForMaskedLM"),Twr=o(" (MPNet model)"),Mwr=l(),wE=a("li"),wMe=a("strong"),Ewr=o("rembert"),Cwr=o(" \u2014 "),pY=a("a"),wwr=o("TFRemBertForMaskedLM"),Awr=o(" (RemBERT model)"),Lwr=l(),AE=a("li"),AMe=a("strong"),ywr=o("roberta"),xwr=o(" \u2014 "),_Y=a("a"),$wr=o("TFRobertaForMaskedLM"),kwr=o(" (RoBERTa model)"),Swr=l(),LE=a("li"),LMe=a("strong"),Rwr=o("roformer"),Pwr=o(" \u2014 "),uY=a("a"),Bwr=o("TFRoFormerForMaskedLM"),Iwr=o(" (RoFormer model)"),Nwr=l(),yE=a("li"),yMe=a("strong"),qwr=o("tapas"),jwr=o(" \u2014 "),bY=a("a"),Dwr=o("TFTapasForMaskedLM"),Gwr=o(" (TAPAS model)"),Owr=l(),xE=a("li"),xMe=a("strong"),Vwr=o("xlm"),Xwr=o(" \u2014 "),vY=a("a"),zwr=o("TFXLMWithLMHeadModel"),Qwr=o(" (XLM model)"),Wwr=l(),$E=a("li"),$Me=a("strong"),Hwr=o("xlm-roberta"),Uwr=o(" \u2014 "),FY=a("a"),Jwr=o("TFXLMRobertaForMaskedLM"),Ywr=o(" (XLM-RoBERTa model)"),Kwr=l(),F(kE.$$.fragment),oze=l(),Fc=a("h2"),SE=a("a"),kMe=a("span"),F(mx.$$.fragment),Zwr=l(),SMe=a("span"),eAr=o("TFAutoModelForSeq2SeqLM"),rze=l(),nr=a("div"),F(gx.$$.fragment),oAr=l(),Tc=a("p"),rAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),TY=a("a"),tAr=o("from_pretrained()"),aAr=o(" class method or the "),MY=a("a"),nAr=o("from_config()"),sAr=o(` class
method.`),lAr=l(),hx=a("p"),iAr=o("This class cannot be instantiated directly using "),RMe=a("code"),dAr=o("__init__()"),cAr=o(" (throws an error)."),fAr=l(),Nt=a("div"),F(px.$$.fragment),mAr=l(),PMe=a("p"),gAr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),hAr=l(),Mc=a("p"),pAr=o(`Note:
Loading a model from its configuration file does `),BMe=a("strong"),_Ar=o("not"),uAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EY=a("a"),bAr=o("from_pretrained()"),vAr=o(" to load the model weights."),FAr=l(),F(RE.$$.fragment),TAr=l(),Rr=a("div"),F(_x.$$.fragment),MAr=l(),IMe=a("p"),EAr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),CAr=l(),fn=a("p"),wAr=o("The model class to instantiate is selected based on the "),NMe=a("code"),AAr=o("model_type"),LAr=o(` property of the config object (either
passed as an argument or loaded from `),qMe=a("code"),yAr=o("pretrained_model_name_or_path"),xAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jMe=a("code"),$Ar=o("pretrained_model_name_or_path"),kAr=o(":"),SAr=l(),ye=a("ul"),PE=a("li"),DMe=a("strong"),RAr=o("bart"),PAr=o(" \u2014 "),CY=a("a"),BAr=o("TFBartForConditionalGeneration"),IAr=o(" (BART model)"),NAr=l(),BE=a("li"),GMe=a("strong"),qAr=o("blenderbot"),jAr=o(" \u2014 "),wY=a("a"),DAr=o("TFBlenderbotForConditionalGeneration"),GAr=o(" (Blenderbot model)"),OAr=l(),IE=a("li"),OMe=a("strong"),VAr=o("blenderbot-small"),XAr=o(" \u2014 "),AY=a("a"),zAr=o("TFBlenderbotSmallForConditionalGeneration"),QAr=o(" (BlenderbotSmall model)"),WAr=l(),NE=a("li"),VMe=a("strong"),HAr=o("encoder-decoder"),UAr=o(" \u2014 "),LY=a("a"),JAr=o("TFEncoderDecoderModel"),YAr=o(" (Encoder decoder model)"),KAr=l(),qE=a("li"),XMe=a("strong"),ZAr=o("led"),e6r=o(" \u2014 "),yY=a("a"),o6r=o("TFLEDForConditionalGeneration"),r6r=o(" (LED model)"),t6r=l(),jE=a("li"),zMe=a("strong"),a6r=o("marian"),n6r=o(" \u2014 "),xY=a("a"),s6r=o("TFMarianMTModel"),l6r=o(" (Marian model)"),i6r=l(),DE=a("li"),QMe=a("strong"),d6r=o("mbart"),c6r=o(" \u2014 "),$Y=a("a"),f6r=o("TFMBartForConditionalGeneration"),m6r=o(" (mBART model)"),g6r=l(),GE=a("li"),WMe=a("strong"),h6r=o("mt5"),p6r=o(" \u2014 "),kY=a("a"),_6r=o("TFMT5ForConditionalGeneration"),u6r=o(" (MT5 model)"),b6r=l(),OE=a("li"),HMe=a("strong"),v6r=o("pegasus"),F6r=o(" \u2014 "),SY=a("a"),T6r=o("TFPegasusForConditionalGeneration"),M6r=o(" (Pegasus model)"),E6r=l(),VE=a("li"),UMe=a("strong"),C6r=o("t5"),w6r=o(" \u2014 "),RY=a("a"),A6r=o("TFT5ForConditionalGeneration"),L6r=o(" (T5 model)"),y6r=l(),F(XE.$$.fragment),tze=l(),Ec=a("h2"),zE=a("a"),JMe=a("span"),F(ux.$$.fragment),x6r=l(),YMe=a("span"),$6r=o("TFAutoModelForSequenceClassification"),aze=l(),sr=a("div"),F(bx.$$.fragment),k6r=l(),Cc=a("p"),S6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),PY=a("a"),R6r=o("from_pretrained()"),P6r=o(" class method or the "),BY=a("a"),B6r=o("from_config()"),I6r=o(` class
method.`),N6r=l(),vx=a("p"),q6r=o("This class cannot be instantiated directly using "),KMe=a("code"),j6r=o("__init__()"),D6r=o(" (throws an error)."),G6r=l(),qt=a("div"),F(Fx.$$.fragment),O6r=l(),ZMe=a("p"),V6r=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),X6r=l(),wc=a("p"),z6r=o(`Note:
Loading a model from its configuration file does `),e4e=a("strong"),Q6r=o("not"),W6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=a("a"),H6r=o("from_pretrained()"),U6r=o(" to load the model weights."),J6r=l(),F(QE.$$.fragment),Y6r=l(),Pr=a("div"),F(Tx.$$.fragment),K6r=l(),o4e=a("p"),Z6r=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),eLr=l(),mn=a("p"),oLr=o("The model class to instantiate is selected based on the "),r4e=a("code"),rLr=o("model_type"),tLr=o(` property of the config object (either
passed as an argument or loaded from `),t4e=a("code"),aLr=o("pretrained_model_name_or_path"),nLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a4e=a("code"),sLr=o("pretrained_model_name_or_path"),lLr=o(":"),iLr=l(),te=a("ul"),WE=a("li"),n4e=a("strong"),dLr=o("albert"),cLr=o(" \u2014 "),NY=a("a"),fLr=o("TFAlbertForSequenceClassification"),mLr=o(" (ALBERT model)"),gLr=l(),HE=a("li"),s4e=a("strong"),hLr=o("bert"),pLr=o(" \u2014 "),qY=a("a"),_Lr=o("TFBertForSequenceClassification"),uLr=o(" (BERT model)"),bLr=l(),UE=a("li"),l4e=a("strong"),vLr=o("camembert"),FLr=o(" \u2014 "),jY=a("a"),TLr=o("TFCamembertForSequenceClassification"),MLr=o(" (CamemBERT model)"),ELr=l(),JE=a("li"),i4e=a("strong"),CLr=o("convbert"),wLr=o(" \u2014 "),DY=a("a"),ALr=o("TFConvBertForSequenceClassification"),LLr=o(" (ConvBERT model)"),yLr=l(),YE=a("li"),d4e=a("strong"),xLr=o("ctrl"),$Lr=o(" \u2014 "),GY=a("a"),kLr=o("TFCTRLForSequenceClassification"),SLr=o(" (CTRL model)"),RLr=l(),KE=a("li"),c4e=a("strong"),PLr=o("deberta"),BLr=o(" \u2014 "),OY=a("a"),ILr=o("TFDebertaForSequenceClassification"),NLr=o(" (DeBERTa model)"),qLr=l(),ZE=a("li"),f4e=a("strong"),jLr=o("deberta-v2"),DLr=o(" \u2014 "),VY=a("a"),GLr=o("TFDebertaV2ForSequenceClassification"),OLr=o(" (DeBERTa-v2 model)"),VLr=l(),eC=a("li"),m4e=a("strong"),XLr=o("distilbert"),zLr=o(" \u2014 "),XY=a("a"),QLr=o("TFDistilBertForSequenceClassification"),WLr=o(" (DistilBERT model)"),HLr=l(),oC=a("li"),g4e=a("strong"),ULr=o("electra"),JLr=o(" \u2014 "),zY=a("a"),YLr=o("TFElectraForSequenceClassification"),KLr=o(" (ELECTRA model)"),ZLr=l(),rC=a("li"),h4e=a("strong"),eyr=o("flaubert"),oyr=o(" \u2014 "),QY=a("a"),ryr=o("TFFlaubertForSequenceClassification"),tyr=o(" (FlauBERT model)"),ayr=l(),tC=a("li"),p4e=a("strong"),nyr=o("funnel"),syr=o(" \u2014 "),WY=a("a"),lyr=o("TFFunnelForSequenceClassification"),iyr=o(" (Funnel Transformer model)"),dyr=l(),aC=a("li"),_4e=a("strong"),cyr=o("gpt2"),fyr=o(" \u2014 "),HY=a("a"),myr=o("TFGPT2ForSequenceClassification"),gyr=o(" (OpenAI GPT-2 model)"),hyr=l(),nC=a("li"),u4e=a("strong"),pyr=o("gptj"),_yr=o(" \u2014 "),UY=a("a"),uyr=o("TFGPTJForSequenceClassification"),byr=o(" (GPT-J model)"),vyr=l(),sC=a("li"),b4e=a("strong"),Fyr=o("layoutlm"),Tyr=o(" \u2014 "),JY=a("a"),Myr=o("TFLayoutLMForSequenceClassification"),Eyr=o(" (LayoutLM model)"),Cyr=l(),lC=a("li"),v4e=a("strong"),wyr=o("longformer"),Ayr=o(" \u2014 "),YY=a("a"),Lyr=o("TFLongformerForSequenceClassification"),yyr=o(" (Longformer model)"),xyr=l(),iC=a("li"),F4e=a("strong"),$yr=o("mobilebert"),kyr=o(" \u2014 "),KY=a("a"),Syr=o("TFMobileBertForSequenceClassification"),Ryr=o(" (MobileBERT model)"),Pyr=l(),dC=a("li"),T4e=a("strong"),Byr=o("mpnet"),Iyr=o(" \u2014 "),ZY=a("a"),Nyr=o("TFMPNetForSequenceClassification"),qyr=o(" (MPNet model)"),jyr=l(),cC=a("li"),M4e=a("strong"),Dyr=o("openai-gpt"),Gyr=o(" \u2014 "),eK=a("a"),Oyr=o("TFOpenAIGPTForSequenceClassification"),Vyr=o(" (OpenAI GPT model)"),Xyr=l(),fC=a("li"),E4e=a("strong"),zyr=o("rembert"),Qyr=o(" \u2014 "),oK=a("a"),Wyr=o("TFRemBertForSequenceClassification"),Hyr=o(" (RemBERT model)"),Uyr=l(),mC=a("li"),C4e=a("strong"),Jyr=o("roberta"),Yyr=o(" \u2014 "),rK=a("a"),Kyr=o("TFRobertaForSequenceClassification"),Zyr=o(" (RoBERTa model)"),e9r=l(),gC=a("li"),w4e=a("strong"),o9r=o("roformer"),r9r=o(" \u2014 "),tK=a("a"),t9r=o("TFRoFormerForSequenceClassification"),a9r=o(" (RoFormer model)"),n9r=l(),hC=a("li"),A4e=a("strong"),s9r=o("tapas"),l9r=o(" \u2014 "),aK=a("a"),i9r=o("TFTapasForSequenceClassification"),d9r=o(" (TAPAS model)"),c9r=l(),pC=a("li"),L4e=a("strong"),f9r=o("transfo-xl"),m9r=o(" \u2014 "),nK=a("a"),g9r=o("TFTransfoXLForSequenceClassification"),h9r=o(" (Transformer-XL model)"),p9r=l(),_C=a("li"),y4e=a("strong"),_9r=o("xlm"),u9r=o(" \u2014 "),sK=a("a"),b9r=o("TFXLMForSequenceClassification"),v9r=o(" (XLM model)"),F9r=l(),uC=a("li"),x4e=a("strong"),T9r=o("xlm-roberta"),M9r=o(" \u2014 "),lK=a("a"),E9r=o("TFXLMRobertaForSequenceClassification"),C9r=o(" (XLM-RoBERTa model)"),w9r=l(),bC=a("li"),$4e=a("strong"),A9r=o("xlnet"),L9r=o(" \u2014 "),iK=a("a"),y9r=o("TFXLNetForSequenceClassification"),x9r=o(" (XLNet model)"),$9r=l(),F(vC.$$.fragment),nze=l(),Ac=a("h2"),FC=a("a"),k4e=a("span"),F(Mx.$$.fragment),k9r=l(),S4e=a("span"),S9r=o("TFAutoModelForMultipleChoice"),sze=l(),lr=a("div"),F(Ex.$$.fragment),R9r=l(),Lc=a("p"),P9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),dK=a("a"),B9r=o("from_pretrained()"),I9r=o(" class method or the "),cK=a("a"),N9r=o("from_config()"),q9r=o(` class
method.`),j9r=l(),Cx=a("p"),D9r=o("This class cannot be instantiated directly using "),R4e=a("code"),G9r=o("__init__()"),O9r=o(" (throws an error)."),V9r=l(),jt=a("div"),F(wx.$$.fragment),X9r=l(),P4e=a("p"),z9r=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Q9r=l(),yc=a("p"),W9r=o(`Note:
Loading a model from its configuration file does `),B4e=a("strong"),H9r=o("not"),U9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fK=a("a"),J9r=o("from_pretrained()"),Y9r=o(" to load the model weights."),K9r=l(),F(TC.$$.fragment),Z9r=l(),Br=a("div"),F(Ax.$$.fragment),exr=l(),I4e=a("p"),oxr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),rxr=l(),gn=a("p"),txr=o("The model class to instantiate is selected based on the "),N4e=a("code"),axr=o("model_type"),nxr=o(` property of the config object (either
passed as an argument or loaded from `),q4e=a("code"),sxr=o("pretrained_model_name_or_path"),lxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j4e=a("code"),ixr=o("pretrained_model_name_or_path"),dxr=o(":"),cxr=l(),_e=a("ul"),MC=a("li"),D4e=a("strong"),fxr=o("albert"),mxr=o(" \u2014 "),mK=a("a"),gxr=o("TFAlbertForMultipleChoice"),hxr=o(" (ALBERT model)"),pxr=l(),EC=a("li"),G4e=a("strong"),_xr=o("bert"),uxr=o(" \u2014 "),gK=a("a"),bxr=o("TFBertForMultipleChoice"),vxr=o(" (BERT model)"),Fxr=l(),CC=a("li"),O4e=a("strong"),Txr=o("camembert"),Mxr=o(" \u2014 "),hK=a("a"),Exr=o("TFCamembertForMultipleChoice"),Cxr=o(" (CamemBERT model)"),wxr=l(),wC=a("li"),V4e=a("strong"),Axr=o("convbert"),Lxr=o(" \u2014 "),pK=a("a"),yxr=o("TFConvBertForMultipleChoice"),xxr=o(" (ConvBERT model)"),$xr=l(),AC=a("li"),X4e=a("strong"),kxr=o("distilbert"),Sxr=o(" \u2014 "),_K=a("a"),Rxr=o("TFDistilBertForMultipleChoice"),Pxr=o(" (DistilBERT model)"),Bxr=l(),LC=a("li"),z4e=a("strong"),Ixr=o("electra"),Nxr=o(" \u2014 "),uK=a("a"),qxr=o("TFElectraForMultipleChoice"),jxr=o(" (ELECTRA model)"),Dxr=l(),yC=a("li"),Q4e=a("strong"),Gxr=o("flaubert"),Oxr=o(" \u2014 "),bK=a("a"),Vxr=o("TFFlaubertForMultipleChoice"),Xxr=o(" (FlauBERT model)"),zxr=l(),xC=a("li"),W4e=a("strong"),Qxr=o("funnel"),Wxr=o(" \u2014 "),vK=a("a"),Hxr=o("TFFunnelForMultipleChoice"),Uxr=o(" (Funnel Transformer model)"),Jxr=l(),$C=a("li"),H4e=a("strong"),Yxr=o("longformer"),Kxr=o(" \u2014 "),FK=a("a"),Zxr=o("TFLongformerForMultipleChoice"),e$r=o(" (Longformer model)"),o$r=l(),kC=a("li"),U4e=a("strong"),r$r=o("mobilebert"),t$r=o(" \u2014 "),TK=a("a"),a$r=o("TFMobileBertForMultipleChoice"),n$r=o(" (MobileBERT model)"),s$r=l(),SC=a("li"),J4e=a("strong"),l$r=o("mpnet"),i$r=o(" \u2014 "),MK=a("a"),d$r=o("TFMPNetForMultipleChoice"),c$r=o(" (MPNet model)"),f$r=l(),RC=a("li"),Y4e=a("strong"),m$r=o("rembert"),g$r=o(" \u2014 "),EK=a("a"),h$r=o("TFRemBertForMultipleChoice"),p$r=o(" (RemBERT model)"),_$r=l(),PC=a("li"),K4e=a("strong"),u$r=o("roberta"),b$r=o(" \u2014 "),CK=a("a"),v$r=o("TFRobertaForMultipleChoice"),F$r=o(" (RoBERTa model)"),T$r=l(),BC=a("li"),Z4e=a("strong"),M$r=o("roformer"),E$r=o(" \u2014 "),wK=a("a"),C$r=o("TFRoFormerForMultipleChoice"),w$r=o(" (RoFormer model)"),A$r=l(),IC=a("li"),eEe=a("strong"),L$r=o("xlm"),y$r=o(" \u2014 "),AK=a("a"),x$r=o("TFXLMForMultipleChoice"),$$r=o(" (XLM model)"),k$r=l(),NC=a("li"),oEe=a("strong"),S$r=o("xlm-roberta"),R$r=o(" \u2014 "),LK=a("a"),P$r=o("TFXLMRobertaForMultipleChoice"),B$r=o(" (XLM-RoBERTa model)"),I$r=l(),qC=a("li"),rEe=a("strong"),N$r=o("xlnet"),q$r=o(" \u2014 "),yK=a("a"),j$r=o("TFXLNetForMultipleChoice"),D$r=o(" (XLNet model)"),G$r=l(),F(jC.$$.fragment),lze=l(),xc=a("h2"),DC=a("a"),tEe=a("span"),F(Lx.$$.fragment),O$r=l(),aEe=a("span"),V$r=o("TFAutoModelForNextSentencePrediction"),ize=l(),ir=a("div"),F(yx.$$.fragment),X$r=l(),$c=a("p"),z$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),xK=a("a"),Q$r=o("from_pretrained()"),W$r=o(" class method or the "),$K=a("a"),H$r=o("from_config()"),U$r=o(` class
method.`),J$r=l(),xx=a("p"),Y$r=o("This class cannot be instantiated directly using "),nEe=a("code"),K$r=o("__init__()"),Z$r=o(" (throws an error)."),ekr=l(),Dt=a("div"),F($x.$$.fragment),okr=l(),sEe=a("p"),rkr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),tkr=l(),kc=a("p"),akr=o(`Note:
Loading a model from its configuration file does `),lEe=a("strong"),nkr=o("not"),skr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kK=a("a"),lkr=o("from_pretrained()"),ikr=o(" to load the model weights."),dkr=l(),F(GC.$$.fragment),ckr=l(),Ir=a("div"),F(kx.$$.fragment),fkr=l(),iEe=a("p"),mkr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),gkr=l(),hn=a("p"),hkr=o("The model class to instantiate is selected based on the "),dEe=a("code"),pkr=o("model_type"),_kr=o(` property of the config object (either
passed as an argument or loaded from `),cEe=a("code"),ukr=o("pretrained_model_name_or_path"),bkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fEe=a("code"),vkr=o("pretrained_model_name_or_path"),Fkr=o(":"),Tkr=l(),Sx=a("ul"),OC=a("li"),mEe=a("strong"),Mkr=o("bert"),Ekr=o(" \u2014 "),SK=a("a"),Ckr=o("TFBertForNextSentencePrediction"),wkr=o(" (BERT model)"),Akr=l(),VC=a("li"),gEe=a("strong"),Lkr=o("mobilebert"),ykr=o(" \u2014 "),RK=a("a"),xkr=o("TFMobileBertForNextSentencePrediction"),$kr=o(" (MobileBERT model)"),kkr=l(),F(XC.$$.fragment),dze=l(),Sc=a("h2"),zC=a("a"),hEe=a("span"),F(Rx.$$.fragment),Skr=l(),pEe=a("span"),Rkr=o("TFAutoModelForTableQuestionAnswering"),cze=l(),dr=a("div"),F(Px.$$.fragment),Pkr=l(),Rc=a("p"),Bkr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),PK=a("a"),Ikr=o("from_pretrained()"),Nkr=o(" class method or the "),BK=a("a"),qkr=o("from_config()"),jkr=o(` class
method.`),Dkr=l(),Bx=a("p"),Gkr=o("This class cannot be instantiated directly using "),_Ee=a("code"),Okr=o("__init__()"),Vkr=o(" (throws an error)."),Xkr=l(),Gt=a("div"),F(Ix.$$.fragment),zkr=l(),uEe=a("p"),Qkr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Wkr=l(),Pc=a("p"),Hkr=o(`Note:
Loading a model from its configuration file does `),bEe=a("strong"),Ukr=o("not"),Jkr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=a("a"),Ykr=o("from_pretrained()"),Kkr=o(" to load the model weights."),Zkr=l(),F(QC.$$.fragment),eSr=l(),Nr=a("div"),F(Nx.$$.fragment),oSr=l(),vEe=a("p"),rSr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),tSr=l(),pn=a("p"),aSr=o("The model class to instantiate is selected based on the "),FEe=a("code"),nSr=o("model_type"),sSr=o(` property of the config object (either
passed as an argument or loaded from `),TEe=a("code"),lSr=o("pretrained_model_name_or_path"),iSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MEe=a("code"),dSr=o("pretrained_model_name_or_path"),cSr=o(":"),fSr=l(),EEe=a("ul"),WC=a("li"),CEe=a("strong"),mSr=o("tapas"),gSr=o(" \u2014 "),NK=a("a"),hSr=o("TFTapasForQuestionAnswering"),pSr=o(" (TAPAS model)"),_Sr=l(),F(HC.$$.fragment),fze=l(),Bc=a("h2"),UC=a("a"),wEe=a("span"),F(qx.$$.fragment),uSr=l(),AEe=a("span"),bSr=o("TFAutoModelForTokenClassification"),mze=l(),cr=a("div"),F(jx.$$.fragment),vSr=l(),Ic=a("p"),FSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),qK=a("a"),TSr=o("from_pretrained()"),MSr=o(" class method or the "),jK=a("a"),ESr=o("from_config()"),CSr=o(` class
method.`),wSr=l(),Dx=a("p"),ASr=o("This class cannot be instantiated directly using "),LEe=a("code"),LSr=o("__init__()"),ySr=o(" (throws an error)."),xSr=l(),Ot=a("div"),F(Gx.$$.fragment),$Sr=l(),yEe=a("p"),kSr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),SSr=l(),Nc=a("p"),RSr=o(`Note:
Loading a model from its configuration file does `),xEe=a("strong"),PSr=o("not"),BSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DK=a("a"),ISr=o("from_pretrained()"),NSr=o(" to load the model weights."),qSr=l(),F(JC.$$.fragment),jSr=l(),qr=a("div"),F(Ox.$$.fragment),DSr=l(),$Ee=a("p"),GSr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),OSr=l(),_n=a("p"),VSr=o("The model class to instantiate is selected based on the "),kEe=a("code"),XSr=o("model_type"),zSr=o(` property of the config object (either
passed as an argument or loaded from `),SEe=a("code"),QSr=o("pretrained_model_name_or_path"),WSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),REe=a("code"),HSr=o("pretrained_model_name_or_path"),USr=o(":"),JSr=l(),de=a("ul"),YC=a("li"),PEe=a("strong"),YSr=o("albert"),KSr=o(" \u2014 "),GK=a("a"),ZSr=o("TFAlbertForTokenClassification"),eRr=o(" (ALBERT model)"),oRr=l(),KC=a("li"),BEe=a("strong"),rRr=o("bert"),tRr=o(" \u2014 "),OK=a("a"),aRr=o("TFBertForTokenClassification"),nRr=o(" (BERT model)"),sRr=l(),ZC=a("li"),IEe=a("strong"),lRr=o("camembert"),iRr=o(" \u2014 "),VK=a("a"),dRr=o("TFCamembertForTokenClassification"),cRr=o(" (CamemBERT model)"),fRr=l(),e3=a("li"),NEe=a("strong"),mRr=o("convbert"),gRr=o(" \u2014 "),XK=a("a"),hRr=o("TFConvBertForTokenClassification"),pRr=o(" (ConvBERT model)"),_Rr=l(),o3=a("li"),qEe=a("strong"),uRr=o("deberta"),bRr=o(" \u2014 "),zK=a("a"),vRr=o("TFDebertaForTokenClassification"),FRr=o(" (DeBERTa model)"),TRr=l(),r3=a("li"),jEe=a("strong"),MRr=o("deberta-v2"),ERr=o(" \u2014 "),QK=a("a"),CRr=o("TFDebertaV2ForTokenClassification"),wRr=o(" (DeBERTa-v2 model)"),ARr=l(),t3=a("li"),DEe=a("strong"),LRr=o("distilbert"),yRr=o(" \u2014 "),WK=a("a"),xRr=o("TFDistilBertForTokenClassification"),$Rr=o(" (DistilBERT model)"),kRr=l(),a3=a("li"),GEe=a("strong"),SRr=o("electra"),RRr=o(" \u2014 "),HK=a("a"),PRr=o("TFElectraForTokenClassification"),BRr=o(" (ELECTRA model)"),IRr=l(),n3=a("li"),OEe=a("strong"),NRr=o("flaubert"),qRr=o(" \u2014 "),UK=a("a"),jRr=o("TFFlaubertForTokenClassification"),DRr=o(" (FlauBERT model)"),GRr=l(),s3=a("li"),VEe=a("strong"),ORr=o("funnel"),VRr=o(" \u2014 "),JK=a("a"),XRr=o("TFFunnelForTokenClassification"),zRr=o(" (Funnel Transformer model)"),QRr=l(),l3=a("li"),XEe=a("strong"),WRr=o("layoutlm"),HRr=o(" \u2014 "),YK=a("a"),URr=o("TFLayoutLMForTokenClassification"),JRr=o(" (LayoutLM model)"),YRr=l(),i3=a("li"),zEe=a("strong"),KRr=o("longformer"),ZRr=o(" \u2014 "),KK=a("a"),ePr=o("TFLongformerForTokenClassification"),oPr=o(" (Longformer model)"),rPr=l(),d3=a("li"),QEe=a("strong"),tPr=o("mobilebert"),aPr=o(" \u2014 "),ZK=a("a"),nPr=o("TFMobileBertForTokenClassification"),sPr=o(" (MobileBERT model)"),lPr=l(),c3=a("li"),WEe=a("strong"),iPr=o("mpnet"),dPr=o(" \u2014 "),eZ=a("a"),cPr=o("TFMPNetForTokenClassification"),fPr=o(" (MPNet model)"),mPr=l(),f3=a("li"),HEe=a("strong"),gPr=o("rembert"),hPr=o(" \u2014 "),oZ=a("a"),pPr=o("TFRemBertForTokenClassification"),_Pr=o(" (RemBERT model)"),uPr=l(),m3=a("li"),UEe=a("strong"),bPr=o("roberta"),vPr=o(" \u2014 "),rZ=a("a"),FPr=o("TFRobertaForTokenClassification"),TPr=o(" (RoBERTa model)"),MPr=l(),g3=a("li"),JEe=a("strong"),EPr=o("roformer"),CPr=o(" \u2014 "),tZ=a("a"),wPr=o("TFRoFormerForTokenClassification"),APr=o(" (RoFormer model)"),LPr=l(),h3=a("li"),YEe=a("strong"),yPr=o("xlm"),xPr=o(" \u2014 "),aZ=a("a"),$Pr=o("TFXLMForTokenClassification"),kPr=o(" (XLM model)"),SPr=l(),p3=a("li"),KEe=a("strong"),RPr=o("xlm-roberta"),PPr=o(" \u2014 "),nZ=a("a"),BPr=o("TFXLMRobertaForTokenClassification"),IPr=o(" (XLM-RoBERTa model)"),NPr=l(),_3=a("li"),ZEe=a("strong"),qPr=o("xlnet"),jPr=o(" \u2014 "),sZ=a("a"),DPr=o("TFXLNetForTokenClassification"),GPr=o(" (XLNet model)"),OPr=l(),F(u3.$$.fragment),gze=l(),qc=a("h2"),b3=a("a"),eCe=a("span"),F(Vx.$$.fragment),VPr=l(),oCe=a("span"),XPr=o("TFAutoModelForQuestionAnswering"),hze=l(),fr=a("div"),F(Xx.$$.fragment),zPr=l(),jc=a("p"),QPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),lZ=a("a"),WPr=o("from_pretrained()"),HPr=o(" class method or the "),iZ=a("a"),UPr=o("from_config()"),JPr=o(` class
method.`),YPr=l(),zx=a("p"),KPr=o("This class cannot be instantiated directly using "),rCe=a("code"),ZPr=o("__init__()"),eBr=o(" (throws an error)."),oBr=l(),Vt=a("div"),F(Qx.$$.fragment),rBr=l(),tCe=a("p"),tBr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),aBr=l(),Dc=a("p"),nBr=o(`Note:
Loading a model from its configuration file does `),aCe=a("strong"),sBr=o("not"),lBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dZ=a("a"),iBr=o("from_pretrained()"),dBr=o(" to load the model weights."),cBr=l(),F(v3.$$.fragment),fBr=l(),jr=a("div"),F(Wx.$$.fragment),mBr=l(),nCe=a("p"),gBr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),hBr=l(),un=a("p"),pBr=o("The model class to instantiate is selected based on the "),sCe=a("code"),_Br=o("model_type"),uBr=o(` property of the config object (either
passed as an argument or loaded from `),lCe=a("code"),bBr=o("pretrained_model_name_or_path"),vBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iCe=a("code"),FBr=o("pretrained_model_name_or_path"),TBr=o(":"),MBr=l(),ce=a("ul"),F3=a("li"),dCe=a("strong"),EBr=o("albert"),CBr=o(" \u2014 "),cZ=a("a"),wBr=o("TFAlbertForQuestionAnswering"),ABr=o(" (ALBERT model)"),LBr=l(),T3=a("li"),cCe=a("strong"),yBr=o("bert"),xBr=o(" \u2014 "),fZ=a("a"),$Br=o("TFBertForQuestionAnswering"),kBr=o(" (BERT model)"),SBr=l(),M3=a("li"),fCe=a("strong"),RBr=o("camembert"),PBr=o(" \u2014 "),mZ=a("a"),BBr=o("TFCamembertForQuestionAnswering"),IBr=o(" (CamemBERT model)"),NBr=l(),E3=a("li"),mCe=a("strong"),qBr=o("convbert"),jBr=o(" \u2014 "),gZ=a("a"),DBr=o("TFConvBertForQuestionAnswering"),GBr=o(" (ConvBERT model)"),OBr=l(),C3=a("li"),gCe=a("strong"),VBr=o("deberta"),XBr=o(" \u2014 "),hZ=a("a"),zBr=o("TFDebertaForQuestionAnswering"),QBr=o(" (DeBERTa model)"),WBr=l(),w3=a("li"),hCe=a("strong"),HBr=o("deberta-v2"),UBr=o(" \u2014 "),pZ=a("a"),JBr=o("TFDebertaV2ForQuestionAnswering"),YBr=o(" (DeBERTa-v2 model)"),KBr=l(),A3=a("li"),pCe=a("strong"),ZBr=o("distilbert"),eIr=o(" \u2014 "),_Z=a("a"),oIr=o("TFDistilBertForQuestionAnswering"),rIr=o(" (DistilBERT model)"),tIr=l(),L3=a("li"),_Ce=a("strong"),aIr=o("electra"),nIr=o(" \u2014 "),uZ=a("a"),sIr=o("TFElectraForQuestionAnswering"),lIr=o(" (ELECTRA model)"),iIr=l(),y3=a("li"),uCe=a("strong"),dIr=o("flaubert"),cIr=o(" \u2014 "),bZ=a("a"),fIr=o("TFFlaubertForQuestionAnsweringSimple"),mIr=o(" (FlauBERT model)"),gIr=l(),x3=a("li"),bCe=a("strong"),hIr=o("funnel"),pIr=o(" \u2014 "),vZ=a("a"),_Ir=o("TFFunnelForQuestionAnswering"),uIr=o(" (Funnel Transformer model)"),bIr=l(),$3=a("li"),vCe=a("strong"),vIr=o("gptj"),FIr=o(" \u2014 "),FZ=a("a"),TIr=o("TFGPTJForQuestionAnswering"),MIr=o(" (GPT-J model)"),EIr=l(),k3=a("li"),FCe=a("strong"),CIr=o("longformer"),wIr=o(" \u2014 "),TZ=a("a"),AIr=o("TFLongformerForQuestionAnswering"),LIr=o(" (Longformer model)"),yIr=l(),S3=a("li"),TCe=a("strong"),xIr=o("mobilebert"),$Ir=o(" \u2014 "),MZ=a("a"),kIr=o("TFMobileBertForQuestionAnswering"),SIr=o(" (MobileBERT model)"),RIr=l(),R3=a("li"),MCe=a("strong"),PIr=o("mpnet"),BIr=o(" \u2014 "),EZ=a("a"),IIr=o("TFMPNetForQuestionAnswering"),NIr=o(" (MPNet model)"),qIr=l(),P3=a("li"),ECe=a("strong"),jIr=o("rembert"),DIr=o(" \u2014 "),CZ=a("a"),GIr=o("TFRemBertForQuestionAnswering"),OIr=o(" (RemBERT model)"),VIr=l(),B3=a("li"),CCe=a("strong"),XIr=o("roberta"),zIr=o(" \u2014 "),wZ=a("a"),QIr=o("TFRobertaForQuestionAnswering"),WIr=o(" (RoBERTa model)"),HIr=l(),I3=a("li"),wCe=a("strong"),UIr=o("roformer"),JIr=o(" \u2014 "),AZ=a("a"),YIr=o("TFRoFormerForQuestionAnswering"),KIr=o(" (RoFormer model)"),ZIr=l(),N3=a("li"),ACe=a("strong"),eNr=o("xlm"),oNr=o(" \u2014 "),LZ=a("a"),rNr=o("TFXLMForQuestionAnsweringSimple"),tNr=o(" (XLM model)"),aNr=l(),q3=a("li"),LCe=a("strong"),nNr=o("xlm-roberta"),sNr=o(" \u2014 "),yZ=a("a"),lNr=o("TFXLMRobertaForQuestionAnswering"),iNr=o(" (XLM-RoBERTa model)"),dNr=l(),j3=a("li"),yCe=a("strong"),cNr=o("xlnet"),fNr=o(" \u2014 "),xZ=a("a"),mNr=o("TFXLNetForQuestionAnsweringSimple"),gNr=o(" (XLNet model)"),hNr=l(),F(D3.$$.fragment),pze=l(),Gc=a("h2"),G3=a("a"),xCe=a("span"),F(Hx.$$.fragment),pNr=l(),$Ce=a("span"),_Nr=o("TFAutoModelForVision2Seq"),_ze=l(),mr=a("div"),F(Ux.$$.fragment),uNr=l(),Oc=a("p"),bNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),$Z=a("a"),vNr=o("from_pretrained()"),FNr=o(" class method or the "),kZ=a("a"),TNr=o("from_config()"),MNr=o(` class
method.`),ENr=l(),Jx=a("p"),CNr=o("This class cannot be instantiated directly using "),kCe=a("code"),wNr=o("__init__()"),ANr=o(" (throws an error)."),LNr=l(),Xt=a("div"),F(Yx.$$.fragment),yNr=l(),SCe=a("p"),xNr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),$Nr=l(),Vc=a("p"),kNr=o(`Note:
Loading a model from its configuration file does `),RCe=a("strong"),SNr=o("not"),RNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SZ=a("a"),PNr=o("from_pretrained()"),BNr=o(" to load the model weights."),INr=l(),F(O3.$$.fragment),NNr=l(),Dr=a("div"),F(Kx.$$.fragment),qNr=l(),PCe=a("p"),jNr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),DNr=l(),bn=a("p"),GNr=o("The model class to instantiate is selected based on the "),BCe=a("code"),ONr=o("model_type"),VNr=o(` property of the config object (either
passed as an argument or loaded from `),ICe=a("code"),XNr=o("pretrained_model_name_or_path"),zNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NCe=a("code"),QNr=o("pretrained_model_name_or_path"),WNr=o(":"),HNr=l(),qCe=a("ul"),V3=a("li"),jCe=a("strong"),UNr=o("vision-encoder-decoder"),JNr=o(" \u2014 "),RZ=a("a"),YNr=o("TFVisionEncoderDecoderModel"),KNr=o(" (Vision Encoder decoder model)"),ZNr=l(),F(X3.$$.fragment),uze=l(),Xc=a("h2"),z3=a("a"),DCe=a("span"),F(Zx.$$.fragment),eqr=l(),GCe=a("span"),oqr=o("TFAutoModelForSpeechSeq2Seq"),bze=l(),gr=a("div"),F(e$.$$.fragment),rqr=l(),zc=a("p"),tqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),PZ=a("a"),aqr=o("from_pretrained()"),nqr=o(" class method or the "),BZ=a("a"),sqr=o("from_config()"),lqr=o(` class
method.`),iqr=l(),o$=a("p"),dqr=o("This class cannot be instantiated directly using "),OCe=a("code"),cqr=o("__init__()"),fqr=o(" (throws an error)."),mqr=l(),zt=a("div"),F(r$.$$.fragment),gqr=l(),VCe=a("p"),hqr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),pqr=l(),Qc=a("p"),_qr=o(`Note:
Loading a model from its configuration file does `),XCe=a("strong"),uqr=o("not"),bqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IZ=a("a"),vqr=o("from_pretrained()"),Fqr=o(" to load the model weights."),Tqr=l(),F(Q3.$$.fragment),Mqr=l(),Gr=a("div"),F(t$.$$.fragment),Eqr=l(),zCe=a("p"),Cqr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),wqr=l(),vn=a("p"),Aqr=o("The model class to instantiate is selected based on the "),QCe=a("code"),Lqr=o("model_type"),yqr=o(` property of the config object (either
passed as an argument or loaded from `),WCe=a("code"),xqr=o("pretrained_model_name_or_path"),$qr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HCe=a("code"),kqr=o("pretrained_model_name_or_path"),Sqr=o(":"),Rqr=l(),UCe=a("ul"),W3=a("li"),JCe=a("strong"),Pqr=o("speech_to_text"),Bqr=o(" \u2014 "),NZ=a("a"),Iqr=o("TFSpeech2TextForConditionalGeneration"),Nqr=o(" (Speech2Text model)"),qqr=l(),F(H3.$$.fragment),vze=l(),Wc=a("h2"),U3=a("a"),YCe=a("span"),F(a$.$$.fragment),jqr=l(),KCe=a("span"),Dqr=o("FlaxAutoModel"),Fze=l(),hr=a("div"),F(n$.$$.fragment),Gqr=l(),Hc=a("p"),Oqr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),qZ=a("a"),Vqr=o("from_pretrained()"),Xqr=o(" class method or the "),jZ=a("a"),zqr=o("from_config()"),Qqr=o(` class
method.`),Wqr=l(),s$=a("p"),Hqr=o("This class cannot be instantiated directly using "),ZCe=a("code"),Uqr=o("__init__()"),Jqr=o(" (throws an error)."),Yqr=l(),Qt=a("div"),F(l$.$$.fragment),Kqr=l(),e3e=a("p"),Zqr=o("Instantiates one of the base model classes of the library from a configuration."),ejr=l(),Uc=a("p"),ojr=o(`Note:
Loading a model from its configuration file does `),o3e=a("strong"),rjr=o("not"),tjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DZ=a("a"),ajr=o("from_pretrained()"),njr=o(" to load the model weights."),sjr=l(),F(J3.$$.fragment),ljr=l(),Or=a("div"),F(i$.$$.fragment),ijr=l(),r3e=a("p"),djr=o("Instantiate one of the base model classes of the library from a pretrained model."),cjr=l(),Fn=a("p"),fjr=o("The model class to instantiate is selected based on the "),t3e=a("code"),mjr=o("model_type"),gjr=o(` property of the config object (either
passed as an argument or loaded from `),a3e=a("code"),hjr=o("pretrained_model_name_or_path"),pjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n3e=a("code"),_jr=o("pretrained_model_name_or_path"),ujr=o(":"),bjr=l(),oe=a("ul"),Y3=a("li"),s3e=a("strong"),vjr=o("albert"),Fjr=o(" \u2014 "),GZ=a("a"),Tjr=o("FlaxAlbertModel"),Mjr=o(" (ALBERT model)"),Ejr=l(),K3=a("li"),l3e=a("strong"),Cjr=o("bart"),wjr=o(" \u2014 "),OZ=a("a"),Ajr=o("FlaxBartModel"),Ljr=o(" (BART model)"),yjr=l(),Z3=a("li"),i3e=a("strong"),xjr=o("beit"),$jr=o(" \u2014 "),VZ=a("a"),kjr=o("FlaxBeitModel"),Sjr=o(" (BEiT model)"),Rjr=l(),e5=a("li"),d3e=a("strong"),Pjr=o("bert"),Bjr=o(" \u2014 "),XZ=a("a"),Ijr=o("FlaxBertModel"),Njr=o(" (BERT model)"),qjr=l(),o5=a("li"),c3e=a("strong"),jjr=o("big_bird"),Djr=o(" \u2014 "),zZ=a("a"),Gjr=o("FlaxBigBirdModel"),Ojr=o(" (BigBird model)"),Vjr=l(),r5=a("li"),f3e=a("strong"),Xjr=o("blenderbot"),zjr=o(" \u2014 "),QZ=a("a"),Qjr=o("FlaxBlenderbotModel"),Wjr=o(" (Blenderbot model)"),Hjr=l(),t5=a("li"),m3e=a("strong"),Ujr=o("blenderbot-small"),Jjr=o(" \u2014 "),WZ=a("a"),Yjr=o("FlaxBlenderbotSmallModel"),Kjr=o(" (BlenderbotSmall model)"),Zjr=l(),a5=a("li"),g3e=a("strong"),eDr=o("clip"),oDr=o(" \u2014 "),HZ=a("a"),rDr=o("FlaxCLIPModel"),tDr=o(" (CLIP model)"),aDr=l(),n5=a("li"),h3e=a("strong"),nDr=o("distilbert"),sDr=o(" \u2014 "),UZ=a("a"),lDr=o("FlaxDistilBertModel"),iDr=o(" (DistilBERT model)"),dDr=l(),s5=a("li"),p3e=a("strong"),cDr=o("electra"),fDr=o(" \u2014 "),JZ=a("a"),mDr=o("FlaxElectraModel"),gDr=o(" (ELECTRA model)"),hDr=l(),l5=a("li"),_3e=a("strong"),pDr=o("gpt2"),_Dr=o(" \u2014 "),YZ=a("a"),uDr=o("FlaxGPT2Model"),bDr=o(" (OpenAI GPT-2 model)"),vDr=l(),i5=a("li"),u3e=a("strong"),FDr=o("gpt_neo"),TDr=o(" \u2014 "),KZ=a("a"),MDr=o("FlaxGPTNeoModel"),EDr=o(" (GPT Neo model)"),CDr=l(),d5=a("li"),b3e=a("strong"),wDr=o("gptj"),ADr=o(" \u2014 "),ZZ=a("a"),LDr=o("FlaxGPTJModel"),yDr=o(" (GPT-J model)"),xDr=l(),c5=a("li"),v3e=a("strong"),$Dr=o("longt5"),kDr=o(" \u2014 "),eee=a("a"),SDr=o("FlaxLongT5Model"),RDr=o(" (LongT5 model)"),PDr=l(),f5=a("li"),F3e=a("strong"),BDr=o("marian"),IDr=o(" \u2014 "),oee=a("a"),NDr=o("FlaxMarianModel"),qDr=o(" (Marian model)"),jDr=l(),m5=a("li"),T3e=a("strong"),DDr=o("mbart"),GDr=o(" \u2014 "),ree=a("a"),ODr=o("FlaxMBartModel"),VDr=o(" (mBART model)"),XDr=l(),g5=a("li"),M3e=a("strong"),zDr=o("mt5"),QDr=o(" \u2014 "),tee=a("a"),WDr=o("FlaxMT5Model"),HDr=o(" (MT5 model)"),UDr=l(),h5=a("li"),E3e=a("strong"),JDr=o("opt"),YDr=o(" \u2014 "),aee=a("a"),KDr=o("FlaxOPTModel"),ZDr=o(" (OPT model)"),eGr=l(),p5=a("li"),C3e=a("strong"),oGr=o("pegasus"),rGr=o(" \u2014 "),nee=a("a"),tGr=o("FlaxPegasusModel"),aGr=o(" (Pegasus model)"),nGr=l(),_5=a("li"),w3e=a("strong"),sGr=o("roberta"),lGr=o(" \u2014 "),see=a("a"),iGr=o("FlaxRobertaModel"),dGr=o(" (RoBERTa model)"),cGr=l(),u5=a("li"),A3e=a("strong"),fGr=o("roformer"),mGr=o(" \u2014 "),lee=a("a"),gGr=o("FlaxRoFormerModel"),hGr=o(" (RoFormer model)"),pGr=l(),b5=a("li"),L3e=a("strong"),_Gr=o("t5"),uGr=o(" \u2014 "),iee=a("a"),bGr=o("FlaxT5Model"),vGr=o(" (T5 model)"),FGr=l(),v5=a("li"),y3e=a("strong"),TGr=o("vision-text-dual-encoder"),MGr=o(" \u2014 "),dee=a("a"),EGr=o("FlaxVisionTextDualEncoderModel"),CGr=o(" (VisionTextDualEncoder model)"),wGr=l(),F5=a("li"),x3e=a("strong"),AGr=o("vit"),LGr=o(" \u2014 "),cee=a("a"),yGr=o("FlaxViTModel"),xGr=o(" (ViT model)"),$Gr=l(),T5=a("li"),$3e=a("strong"),kGr=o("wav2vec2"),SGr=o(" \u2014 "),fee=a("a"),RGr=o("FlaxWav2Vec2Model"),PGr=o(" (Wav2Vec2 model)"),BGr=l(),M5=a("li"),k3e=a("strong"),IGr=o("xglm"),NGr=o(" \u2014 "),mee=a("a"),qGr=o("FlaxXGLMModel"),jGr=o(" (XGLM model)"),DGr=l(),E5=a("li"),S3e=a("strong"),GGr=o("xlm-roberta"),OGr=o(" \u2014 "),gee=a("a"),VGr=o("FlaxXLMRobertaModel"),XGr=o(" (XLM-RoBERTa model)"),zGr=l(),F(C5.$$.fragment),Tze=l(),Jc=a("h2"),w5=a("a"),R3e=a("span"),F(d$.$$.fragment),QGr=l(),P3e=a("span"),WGr=o("FlaxAutoModelForCausalLM"),Mze=l(),pr=a("div"),F(c$.$$.fragment),HGr=l(),Yc=a("p"),UGr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),hee=a("a"),JGr=o("from_pretrained()"),YGr=o(" class method or the "),pee=a("a"),KGr=o("from_config()"),ZGr=o(` class
method.`),eOr=l(),f$=a("p"),oOr=o("This class cannot be instantiated directly using "),B3e=a("code"),rOr=o("__init__()"),tOr=o(" (throws an error)."),aOr=l(),Wt=a("div"),F(m$.$$.fragment),nOr=l(),I3e=a("p"),sOr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),lOr=l(),Kc=a("p"),iOr=o(`Note:
Loading a model from its configuration file does `),N3e=a("strong"),dOr=o("not"),cOr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_ee=a("a"),fOr=o("from_pretrained()"),mOr=o(" to load the model weights."),gOr=l(),F(A5.$$.fragment),hOr=l(),Vr=a("div"),F(g$.$$.fragment),pOr=l(),q3e=a("p"),_Or=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),uOr=l(),Tn=a("p"),bOr=o("The model class to instantiate is selected based on the "),j3e=a("code"),vOr=o("model_type"),FOr=o(` property of the config object (either
passed as an argument or loaded from `),D3e=a("code"),TOr=o("pretrained_model_name_or_path"),MOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G3e=a("code"),EOr=o("pretrained_model_name_or_path"),COr=o(":"),wOr=l(),xe=a("ul"),L5=a("li"),O3e=a("strong"),AOr=o("bart"),LOr=o(" \u2014 "),uee=a("a"),yOr=o("FlaxBartForCausalLM"),xOr=o(" (BART model)"),$Or=l(),y5=a("li"),V3e=a("strong"),kOr=o("bert"),SOr=o(" \u2014 "),bee=a("a"),ROr=o("FlaxBertForCausalLM"),POr=o(" (BERT model)"),BOr=l(),x5=a("li"),X3e=a("strong"),IOr=o("big_bird"),NOr=o(" \u2014 "),vee=a("a"),qOr=o("FlaxBigBirdForCausalLM"),jOr=o(" (BigBird model)"),DOr=l(),$5=a("li"),z3e=a("strong"),GOr=o("electra"),OOr=o(" \u2014 "),Fee=a("a"),VOr=o("FlaxElectraForCausalLM"),XOr=o(" (ELECTRA model)"),zOr=l(),k5=a("li"),Q3e=a("strong"),QOr=o("gpt2"),WOr=o(" \u2014 "),Tee=a("a"),HOr=o("FlaxGPT2LMHeadModel"),UOr=o(" (OpenAI GPT-2 model)"),JOr=l(),S5=a("li"),W3e=a("strong"),YOr=o("gpt_neo"),KOr=o(" \u2014 "),Mee=a("a"),ZOr=o("FlaxGPTNeoForCausalLM"),eVr=o(" (GPT Neo model)"),oVr=l(),R5=a("li"),H3e=a("strong"),rVr=o("gptj"),tVr=o(" \u2014 "),Eee=a("a"),aVr=o("FlaxGPTJForCausalLM"),nVr=o(" (GPT-J model)"),sVr=l(),P5=a("li"),U3e=a("strong"),lVr=o("opt"),iVr=o(" \u2014 "),Cee=a("a"),dVr=o("FlaxOPTForCausalLM"),cVr=o(" (OPT model)"),fVr=l(),B5=a("li"),J3e=a("strong"),mVr=o("roberta"),gVr=o(" \u2014 "),wee=a("a"),hVr=o("FlaxRobertaForCausalLM"),pVr=o(" (RoBERTa model)"),_Vr=l(),I5=a("li"),Y3e=a("strong"),uVr=o("xglm"),bVr=o(" \u2014 "),Aee=a("a"),vVr=o("FlaxXGLMForCausalLM"),FVr=o(" (XGLM model)"),TVr=l(),F(N5.$$.fragment),Eze=l(),Zc=a("h2"),q5=a("a"),K3e=a("span"),F(h$.$$.fragment),MVr=l(),Z3e=a("span"),EVr=o("FlaxAutoModelForPreTraining"),Cze=l(),_r=a("div"),F(p$.$$.fragment),CVr=l(),ef=a("p"),wVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Lee=a("a"),AVr=o("from_pretrained()"),LVr=o(" class method or the "),yee=a("a"),yVr=o("from_config()"),xVr=o(` class
method.`),$Vr=l(),_$=a("p"),kVr=o("This class cannot be instantiated directly using "),e5e=a("code"),SVr=o("__init__()"),RVr=o(" (throws an error)."),PVr=l(),Ht=a("div"),F(u$.$$.fragment),BVr=l(),o5e=a("p"),IVr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),NVr=l(),of=a("p"),qVr=o(`Note:
Loading a model from its configuration file does `),r5e=a("strong"),jVr=o("not"),DVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xee=a("a"),GVr=o("from_pretrained()"),OVr=o(" to load the model weights."),VVr=l(),F(j5.$$.fragment),XVr=l(),Xr=a("div"),F(b$.$$.fragment),zVr=l(),t5e=a("p"),QVr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),WVr=l(),Mn=a("p"),HVr=o("The model class to instantiate is selected based on the "),a5e=a("code"),UVr=o("model_type"),JVr=o(` property of the config object (either
passed as an argument or loaded from `),n5e=a("code"),YVr=o("pretrained_model_name_or_path"),KVr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s5e=a("code"),ZVr=o("pretrained_model_name_or_path"),eXr=o(":"),oXr=l(),Ee=a("ul"),D5=a("li"),l5e=a("strong"),rXr=o("albert"),tXr=o(" \u2014 "),$ee=a("a"),aXr=o("FlaxAlbertForPreTraining"),nXr=o(" (ALBERT model)"),sXr=l(),G5=a("li"),i5e=a("strong"),lXr=o("bart"),iXr=o(" \u2014 "),kee=a("a"),dXr=o("FlaxBartForConditionalGeneration"),cXr=o(" (BART model)"),fXr=l(),O5=a("li"),d5e=a("strong"),mXr=o("bert"),gXr=o(" \u2014 "),See=a("a"),hXr=o("FlaxBertForPreTraining"),pXr=o(" (BERT model)"),_Xr=l(),V5=a("li"),c5e=a("strong"),uXr=o("big_bird"),bXr=o(" \u2014 "),Ree=a("a"),vXr=o("FlaxBigBirdForPreTraining"),FXr=o(" (BigBird model)"),TXr=l(),X5=a("li"),f5e=a("strong"),MXr=o("electra"),EXr=o(" \u2014 "),Pee=a("a"),CXr=o("FlaxElectraForPreTraining"),wXr=o(" (ELECTRA model)"),AXr=l(),z5=a("li"),m5e=a("strong"),LXr=o("longt5"),yXr=o(" \u2014 "),Bee=a("a"),xXr=o("FlaxLongT5ForConditionalGeneration"),$Xr=o(" (LongT5 model)"),kXr=l(),Q5=a("li"),g5e=a("strong"),SXr=o("mbart"),RXr=o(" \u2014 "),Iee=a("a"),PXr=o("FlaxMBartForConditionalGeneration"),BXr=o(" (mBART model)"),IXr=l(),W5=a("li"),h5e=a("strong"),NXr=o("mt5"),qXr=o(" \u2014 "),Nee=a("a"),jXr=o("FlaxMT5ForConditionalGeneration"),DXr=o(" (MT5 model)"),GXr=l(),H5=a("li"),p5e=a("strong"),OXr=o("roberta"),VXr=o(" \u2014 "),qee=a("a"),XXr=o("FlaxRobertaForMaskedLM"),zXr=o(" (RoBERTa model)"),QXr=l(),U5=a("li"),_5e=a("strong"),WXr=o("roformer"),HXr=o(" \u2014 "),jee=a("a"),UXr=o("FlaxRoFormerForMaskedLM"),JXr=o(" (RoFormer model)"),YXr=l(),J5=a("li"),u5e=a("strong"),KXr=o("t5"),ZXr=o(" \u2014 "),Dee=a("a"),ezr=o("FlaxT5ForConditionalGeneration"),ozr=o(" (T5 model)"),rzr=l(),Y5=a("li"),b5e=a("strong"),tzr=o("wav2vec2"),azr=o(" \u2014 "),Gee=a("a"),nzr=o("FlaxWav2Vec2ForPreTraining"),szr=o(" (Wav2Vec2 model)"),lzr=l(),K5=a("li"),v5e=a("strong"),izr=o("xlm-roberta"),dzr=o(" \u2014 "),Oee=a("a"),czr=o("FlaxXLMRobertaForMaskedLM"),fzr=o(" (XLM-RoBERTa model)"),mzr=l(),F(Z5.$$.fragment),wze=l(),rf=a("h2"),e0=a("a"),F5e=a("span"),F(v$.$$.fragment),gzr=l(),T5e=a("span"),hzr=o("FlaxAutoModelForMaskedLM"),Aze=l(),ur=a("div"),F(F$.$$.fragment),pzr=l(),tf=a("p"),_zr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Vee=a("a"),uzr=o("from_pretrained()"),bzr=o(" class method or the "),Xee=a("a"),vzr=o("from_config()"),Fzr=o(` class
method.`),Tzr=l(),T$=a("p"),Mzr=o("This class cannot be instantiated directly using "),M5e=a("code"),Ezr=o("__init__()"),Czr=o(" (throws an error)."),wzr=l(),Ut=a("div"),F(M$.$$.fragment),Azr=l(),E5e=a("p"),Lzr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),yzr=l(),af=a("p"),xzr=o(`Note:
Loading a model from its configuration file does `),C5e=a("strong"),$zr=o("not"),kzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zee=a("a"),Szr=o("from_pretrained()"),Rzr=o(" to load the model weights."),Pzr=l(),F(o0.$$.fragment),Bzr=l(),zr=a("div"),F(E$.$$.fragment),Izr=l(),w5e=a("p"),Nzr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),qzr=l(),En=a("p"),jzr=o("The model class to instantiate is selected based on the "),A5e=a("code"),Dzr=o("model_type"),Gzr=o(` property of the config object (either
passed as an argument or loaded from `),L5e=a("code"),Ozr=o("pretrained_model_name_or_path"),Vzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y5e=a("code"),Xzr=o("pretrained_model_name_or_path"),zzr=o(":"),Qzr=l(),$e=a("ul"),r0=a("li"),x5e=a("strong"),Wzr=o("albert"),Hzr=o(" \u2014 "),Qee=a("a"),Uzr=o("FlaxAlbertForMaskedLM"),Jzr=o(" (ALBERT model)"),Yzr=l(),t0=a("li"),$5e=a("strong"),Kzr=o("bart"),Zzr=o(" \u2014 "),Wee=a("a"),eQr=o("FlaxBartForConditionalGeneration"),oQr=o(" (BART model)"),rQr=l(),a0=a("li"),k5e=a("strong"),tQr=o("bert"),aQr=o(" \u2014 "),Hee=a("a"),nQr=o("FlaxBertForMaskedLM"),sQr=o(" (BERT model)"),lQr=l(),n0=a("li"),S5e=a("strong"),iQr=o("big_bird"),dQr=o(" \u2014 "),Uee=a("a"),cQr=o("FlaxBigBirdForMaskedLM"),fQr=o(" (BigBird model)"),mQr=l(),s0=a("li"),R5e=a("strong"),gQr=o("distilbert"),hQr=o(" \u2014 "),Jee=a("a"),pQr=o("FlaxDistilBertForMaskedLM"),_Qr=o(" (DistilBERT model)"),uQr=l(),l0=a("li"),P5e=a("strong"),bQr=o("electra"),vQr=o(" \u2014 "),Yee=a("a"),FQr=o("FlaxElectraForMaskedLM"),TQr=o(" (ELECTRA model)"),MQr=l(),i0=a("li"),B5e=a("strong"),EQr=o("mbart"),CQr=o(" \u2014 "),Kee=a("a"),wQr=o("FlaxMBartForConditionalGeneration"),AQr=o(" (mBART model)"),LQr=l(),d0=a("li"),I5e=a("strong"),yQr=o("roberta"),xQr=o(" \u2014 "),Zee=a("a"),$Qr=o("FlaxRobertaForMaskedLM"),kQr=o(" (RoBERTa model)"),SQr=l(),c0=a("li"),N5e=a("strong"),RQr=o("roformer"),PQr=o(" \u2014 "),eoe=a("a"),BQr=o("FlaxRoFormerForMaskedLM"),IQr=o(" (RoFormer model)"),NQr=l(),f0=a("li"),q5e=a("strong"),qQr=o("xlm-roberta"),jQr=o(" \u2014 "),ooe=a("a"),DQr=o("FlaxXLMRobertaForMaskedLM"),GQr=o(" (XLM-RoBERTa model)"),OQr=l(),F(m0.$$.fragment),Lze=l(),nf=a("h2"),g0=a("a"),j5e=a("span"),F(C$.$$.fragment),VQr=l(),D5e=a("span"),XQr=o("FlaxAutoModelForSeq2SeqLM"),yze=l(),br=a("div"),F(w$.$$.fragment),zQr=l(),sf=a("p"),QQr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),roe=a("a"),WQr=o("from_pretrained()"),HQr=o(" class method or the "),toe=a("a"),UQr=o("from_config()"),JQr=o(` class
method.`),YQr=l(),A$=a("p"),KQr=o("This class cannot be instantiated directly using "),G5e=a("code"),ZQr=o("__init__()"),eWr=o(" (throws an error)."),oWr=l(),Jt=a("div"),F(L$.$$.fragment),rWr=l(),O5e=a("p"),tWr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),aWr=l(),lf=a("p"),nWr=o(`Note:
Loading a model from its configuration file does `),V5e=a("strong"),sWr=o("not"),lWr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aoe=a("a"),iWr=o("from_pretrained()"),dWr=o(" to load the model weights."),cWr=l(),F(h0.$$.fragment),fWr=l(),Qr=a("div"),F(y$.$$.fragment),mWr=l(),X5e=a("p"),gWr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),hWr=l(),Cn=a("p"),pWr=o("The model class to instantiate is selected based on the "),z5e=a("code"),_Wr=o("model_type"),uWr=o(` property of the config object (either
passed as an argument or loaded from `),Q5e=a("code"),bWr=o("pretrained_model_name_or_path"),vWr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W5e=a("code"),FWr=o("pretrained_model_name_or_path"),TWr=o(":"),MWr=l(),ke=a("ul"),p0=a("li"),H5e=a("strong"),EWr=o("bart"),CWr=o(" \u2014 "),noe=a("a"),wWr=o("FlaxBartForConditionalGeneration"),AWr=o(" (BART model)"),LWr=l(),_0=a("li"),U5e=a("strong"),yWr=o("blenderbot"),xWr=o(" \u2014 "),soe=a("a"),$Wr=o("FlaxBlenderbotForConditionalGeneration"),kWr=o(" (Blenderbot model)"),SWr=l(),u0=a("li"),J5e=a("strong"),RWr=o("blenderbot-small"),PWr=o(" \u2014 "),loe=a("a"),BWr=o("FlaxBlenderbotSmallForConditionalGeneration"),IWr=o(" (BlenderbotSmall model)"),NWr=l(),b0=a("li"),Y5e=a("strong"),qWr=o("encoder-decoder"),jWr=o(" \u2014 "),ioe=a("a"),DWr=o("FlaxEncoderDecoderModel"),GWr=o(" (Encoder decoder model)"),OWr=l(),v0=a("li"),K5e=a("strong"),VWr=o("longt5"),XWr=o(" \u2014 "),doe=a("a"),zWr=o("FlaxLongT5ForConditionalGeneration"),QWr=o(" (LongT5 model)"),WWr=l(),F0=a("li"),Z5e=a("strong"),HWr=o("marian"),UWr=o(" \u2014 "),coe=a("a"),JWr=o("FlaxMarianMTModel"),YWr=o(" (Marian model)"),KWr=l(),T0=a("li"),e0e=a("strong"),ZWr=o("mbart"),eHr=o(" \u2014 "),foe=a("a"),oHr=o("FlaxMBartForConditionalGeneration"),rHr=o(" (mBART model)"),tHr=l(),M0=a("li"),o0e=a("strong"),aHr=o("mt5"),nHr=o(" \u2014 "),moe=a("a"),sHr=o("FlaxMT5ForConditionalGeneration"),lHr=o(" (MT5 model)"),iHr=l(),E0=a("li"),r0e=a("strong"),dHr=o("pegasus"),cHr=o(" \u2014 "),goe=a("a"),fHr=o("FlaxPegasusForConditionalGeneration"),mHr=o(" (Pegasus model)"),gHr=l(),C0=a("li"),t0e=a("strong"),hHr=o("t5"),pHr=o(" \u2014 "),hoe=a("a"),_Hr=o("FlaxT5ForConditionalGeneration"),uHr=o(" (T5 model)"),bHr=l(),F(w0.$$.fragment),xze=l(),df=a("h2"),A0=a("a"),a0e=a("span"),F(x$.$$.fragment),vHr=l(),n0e=a("span"),FHr=o("FlaxAutoModelForSequenceClassification"),$ze=l(),vr=a("div"),F($$.$$.fragment),THr=l(),cf=a("p"),MHr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),poe=a("a"),EHr=o("from_pretrained()"),CHr=o(" class method or the "),_oe=a("a"),wHr=o("from_config()"),AHr=o(` class
method.`),LHr=l(),k$=a("p"),yHr=o("This class cannot be instantiated directly using "),s0e=a("code"),xHr=o("__init__()"),$Hr=o(" (throws an error)."),kHr=l(),Yt=a("div"),F(S$.$$.fragment),SHr=l(),l0e=a("p"),RHr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),PHr=l(),ff=a("p"),BHr=o(`Note:
Loading a model from its configuration file does `),i0e=a("strong"),IHr=o("not"),NHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uoe=a("a"),qHr=o("from_pretrained()"),jHr=o(" to load the model weights."),DHr=l(),F(L0.$$.fragment),GHr=l(),Wr=a("div"),F(R$.$$.fragment),OHr=l(),d0e=a("p"),VHr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),XHr=l(),wn=a("p"),zHr=o("The model class to instantiate is selected based on the "),c0e=a("code"),QHr=o("model_type"),WHr=o(` property of the config object (either
passed as an argument or loaded from `),f0e=a("code"),HHr=o("pretrained_model_name_or_path"),UHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m0e=a("code"),JHr=o("pretrained_model_name_or_path"),YHr=o(":"),KHr=l(),Se=a("ul"),y0=a("li"),g0e=a("strong"),ZHr=o("albert"),eUr=o(" \u2014 "),boe=a("a"),oUr=o("FlaxAlbertForSequenceClassification"),rUr=o(" (ALBERT model)"),tUr=l(),x0=a("li"),h0e=a("strong"),aUr=o("bart"),nUr=o(" \u2014 "),voe=a("a"),sUr=o("FlaxBartForSequenceClassification"),lUr=o(" (BART model)"),iUr=l(),$0=a("li"),p0e=a("strong"),dUr=o("bert"),cUr=o(" \u2014 "),Foe=a("a"),fUr=o("FlaxBertForSequenceClassification"),mUr=o(" (BERT model)"),gUr=l(),k0=a("li"),_0e=a("strong"),hUr=o("big_bird"),pUr=o(" \u2014 "),Toe=a("a"),_Ur=o("FlaxBigBirdForSequenceClassification"),uUr=o(" (BigBird model)"),bUr=l(),S0=a("li"),u0e=a("strong"),vUr=o("distilbert"),FUr=o(" \u2014 "),Moe=a("a"),TUr=o("FlaxDistilBertForSequenceClassification"),MUr=o(" (DistilBERT model)"),EUr=l(),R0=a("li"),b0e=a("strong"),CUr=o("electra"),wUr=o(" \u2014 "),Eoe=a("a"),AUr=o("FlaxElectraForSequenceClassification"),LUr=o(" (ELECTRA model)"),yUr=l(),P0=a("li"),v0e=a("strong"),xUr=o("mbart"),$Ur=o(" \u2014 "),Coe=a("a"),kUr=o("FlaxMBartForSequenceClassification"),SUr=o(" (mBART model)"),RUr=l(),B0=a("li"),F0e=a("strong"),PUr=o("roberta"),BUr=o(" \u2014 "),woe=a("a"),IUr=o("FlaxRobertaForSequenceClassification"),NUr=o(" (RoBERTa model)"),qUr=l(),I0=a("li"),T0e=a("strong"),jUr=o("roformer"),DUr=o(" \u2014 "),Aoe=a("a"),GUr=o("FlaxRoFormerForSequenceClassification"),OUr=o(" (RoFormer model)"),VUr=l(),N0=a("li"),M0e=a("strong"),XUr=o("xlm-roberta"),zUr=o(" \u2014 "),Loe=a("a"),QUr=o("FlaxXLMRobertaForSequenceClassification"),WUr=o(" (XLM-RoBERTa model)"),HUr=l(),F(q0.$$.fragment),kze=l(),mf=a("h2"),j0=a("a"),E0e=a("span"),F(P$.$$.fragment),UUr=l(),C0e=a("span"),JUr=o("FlaxAutoModelForQuestionAnswering"),Sze=l(),Fr=a("div"),F(B$.$$.fragment),YUr=l(),gf=a("p"),KUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),yoe=a("a"),ZUr=o("from_pretrained()"),eJr=o(" class method or the "),xoe=a("a"),oJr=o("from_config()"),rJr=o(` class
method.`),tJr=l(),I$=a("p"),aJr=o("This class cannot be instantiated directly using "),w0e=a("code"),nJr=o("__init__()"),sJr=o(" (throws an error)."),lJr=l(),Kt=a("div"),F(N$.$$.fragment),iJr=l(),A0e=a("p"),dJr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),cJr=l(),hf=a("p"),fJr=o(`Note:
Loading a model from its configuration file does `),L0e=a("strong"),mJr=o("not"),gJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$oe=a("a"),hJr=o("from_pretrained()"),pJr=o(" to load the model weights."),_Jr=l(),F(D0.$$.fragment),uJr=l(),Hr=a("div"),F(q$.$$.fragment),bJr=l(),y0e=a("p"),vJr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),FJr=l(),An=a("p"),TJr=o("The model class to instantiate is selected based on the "),x0e=a("code"),MJr=o("model_type"),EJr=o(` property of the config object (either
passed as an argument or loaded from `),$0e=a("code"),CJr=o("pretrained_model_name_or_path"),wJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k0e=a("code"),AJr=o("pretrained_model_name_or_path"),LJr=o(":"),yJr=l(),Re=a("ul"),G0=a("li"),S0e=a("strong"),xJr=o("albert"),$Jr=o(" \u2014 "),koe=a("a"),kJr=o("FlaxAlbertForQuestionAnswering"),SJr=o(" (ALBERT model)"),RJr=l(),O0=a("li"),R0e=a("strong"),PJr=o("bart"),BJr=o(" \u2014 "),Soe=a("a"),IJr=o("FlaxBartForQuestionAnswering"),NJr=o(" (BART model)"),qJr=l(),V0=a("li"),P0e=a("strong"),jJr=o("bert"),DJr=o(" \u2014 "),Roe=a("a"),GJr=o("FlaxBertForQuestionAnswering"),OJr=o(" (BERT model)"),VJr=l(),X0=a("li"),B0e=a("strong"),XJr=o("big_bird"),zJr=o(" \u2014 "),Poe=a("a"),QJr=o("FlaxBigBirdForQuestionAnswering"),WJr=o(" (BigBird model)"),HJr=l(),z0=a("li"),I0e=a("strong"),UJr=o("distilbert"),JJr=o(" \u2014 "),Boe=a("a"),YJr=o("FlaxDistilBertForQuestionAnswering"),KJr=o(" (DistilBERT model)"),ZJr=l(),Q0=a("li"),N0e=a("strong"),eYr=o("electra"),oYr=o(" \u2014 "),Ioe=a("a"),rYr=o("FlaxElectraForQuestionAnswering"),tYr=o(" (ELECTRA model)"),aYr=l(),W0=a("li"),q0e=a("strong"),nYr=o("mbart"),sYr=o(" \u2014 "),Noe=a("a"),lYr=o("FlaxMBartForQuestionAnswering"),iYr=o(" (mBART model)"),dYr=l(),H0=a("li"),j0e=a("strong"),cYr=o("roberta"),fYr=o(" \u2014 "),qoe=a("a"),mYr=o("FlaxRobertaForQuestionAnswering"),gYr=o(" (RoBERTa model)"),hYr=l(),U0=a("li"),D0e=a("strong"),pYr=o("roformer"),_Yr=o(" \u2014 "),joe=a("a"),uYr=o("FlaxRoFormerForQuestionAnswering"),bYr=o(" (RoFormer model)"),vYr=l(),J0=a("li"),G0e=a("strong"),FYr=o("xlm-roberta"),TYr=o(" \u2014 "),Doe=a("a"),MYr=o("FlaxXLMRobertaForQuestionAnswering"),EYr=o(" (XLM-RoBERTa model)"),CYr=l(),F(Y0.$$.fragment),Rze=l(),pf=a("h2"),K0=a("a"),O0e=a("span"),F(j$.$$.fragment),wYr=l(),V0e=a("span"),AYr=o("FlaxAutoModelForTokenClassification"),Pze=l(),Tr=a("div"),F(D$.$$.fragment),LYr=l(),_f=a("p"),yYr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Goe=a("a"),xYr=o("from_pretrained()"),$Yr=o(" class method or the "),Ooe=a("a"),kYr=o("from_config()"),SYr=o(` class
method.`),RYr=l(),G$=a("p"),PYr=o("This class cannot be instantiated directly using "),X0e=a("code"),BYr=o("__init__()"),IYr=o(" (throws an error)."),NYr=l(),Zt=a("div"),F(O$.$$.fragment),qYr=l(),z0e=a("p"),jYr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),DYr=l(),uf=a("p"),GYr=o(`Note:
Loading a model from its configuration file does `),Q0e=a("strong"),OYr=o("not"),VYr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Voe=a("a"),XYr=o("from_pretrained()"),zYr=o(" to load the model weights."),QYr=l(),F(Z0.$$.fragment),WYr=l(),Ur=a("div"),F(V$.$$.fragment),HYr=l(),W0e=a("p"),UYr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),JYr=l(),Ln=a("p"),YYr=o("The model class to instantiate is selected based on the "),H0e=a("code"),KYr=o("model_type"),ZYr=o(` property of the config object (either
passed as an argument or loaded from `),U0e=a("code"),eKr=o("pretrained_model_name_or_path"),oKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J0e=a("code"),rKr=o("pretrained_model_name_or_path"),tKr=o(":"),aKr=l(),Ve=a("ul"),ew=a("li"),Y0e=a("strong"),nKr=o("albert"),sKr=o(" \u2014 "),Xoe=a("a"),lKr=o("FlaxAlbertForTokenClassification"),iKr=o(" (ALBERT model)"),dKr=l(),ow=a("li"),K0e=a("strong"),cKr=o("bert"),fKr=o(" \u2014 "),zoe=a("a"),mKr=o("FlaxBertForTokenClassification"),gKr=o(" (BERT model)"),hKr=l(),rw=a("li"),Z0e=a("strong"),pKr=o("big_bird"),_Kr=o(" \u2014 "),Qoe=a("a"),uKr=o("FlaxBigBirdForTokenClassification"),bKr=o(" (BigBird model)"),vKr=l(),tw=a("li"),ewe=a("strong"),FKr=o("distilbert"),TKr=o(" \u2014 "),Woe=a("a"),MKr=o("FlaxDistilBertForTokenClassification"),EKr=o(" (DistilBERT model)"),CKr=l(),aw=a("li"),owe=a("strong"),wKr=o("electra"),AKr=o(" \u2014 "),Hoe=a("a"),LKr=o("FlaxElectraForTokenClassification"),yKr=o(" (ELECTRA model)"),xKr=l(),nw=a("li"),rwe=a("strong"),$Kr=o("roberta"),kKr=o(" \u2014 "),Uoe=a("a"),SKr=o("FlaxRobertaForTokenClassification"),RKr=o(" (RoBERTa model)"),PKr=l(),sw=a("li"),twe=a("strong"),BKr=o("roformer"),IKr=o(" \u2014 "),Joe=a("a"),NKr=o("FlaxRoFormerForTokenClassification"),qKr=o(" (RoFormer model)"),jKr=l(),lw=a("li"),awe=a("strong"),DKr=o("xlm-roberta"),GKr=o(" \u2014 "),Yoe=a("a"),OKr=o("FlaxXLMRobertaForTokenClassification"),VKr=o(" (XLM-RoBERTa model)"),XKr=l(),F(iw.$$.fragment),Bze=l(),bf=a("h2"),dw=a("a"),nwe=a("span"),F(X$.$$.fragment),zKr=l(),swe=a("span"),QKr=o("FlaxAutoModelForMultipleChoice"),Ize=l(),Mr=a("div"),F(z$.$$.fragment),WKr=l(),vf=a("p"),HKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Koe=a("a"),UKr=o("from_pretrained()"),JKr=o(" class method or the "),Zoe=a("a"),YKr=o("from_config()"),KKr=o(` class
method.`),ZKr=l(),Q$=a("p"),eZr=o("This class cannot be instantiated directly using "),lwe=a("code"),oZr=o("__init__()"),rZr=o(" (throws an error)."),tZr=l(),ea=a("div"),F(W$.$$.fragment),aZr=l(),iwe=a("p"),nZr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),sZr=l(),Ff=a("p"),lZr=o(`Note:
Loading a model from its configuration file does `),dwe=a("strong"),iZr=o("not"),dZr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ere=a("a"),cZr=o("from_pretrained()"),fZr=o(" to load the model weights."),mZr=l(),F(cw.$$.fragment),gZr=l(),Jr=a("div"),F(H$.$$.fragment),hZr=l(),cwe=a("p"),pZr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),_Zr=l(),yn=a("p"),uZr=o("The model class to instantiate is selected based on the "),fwe=a("code"),bZr=o("model_type"),vZr=o(` property of the config object (either
passed as an argument or loaded from `),mwe=a("code"),FZr=o("pretrained_model_name_or_path"),TZr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gwe=a("code"),MZr=o("pretrained_model_name_or_path"),EZr=o(":"),CZr=l(),Xe=a("ul"),fw=a("li"),hwe=a("strong"),wZr=o("albert"),AZr=o(" \u2014 "),ore=a("a"),LZr=o("FlaxAlbertForMultipleChoice"),yZr=o(" (ALBERT model)"),xZr=l(),mw=a("li"),pwe=a("strong"),$Zr=o("bert"),kZr=o(" \u2014 "),rre=a("a"),SZr=o("FlaxBertForMultipleChoice"),RZr=o(" (BERT model)"),PZr=l(),gw=a("li"),_we=a("strong"),BZr=o("big_bird"),IZr=o(" \u2014 "),tre=a("a"),NZr=o("FlaxBigBirdForMultipleChoice"),qZr=o(" (BigBird model)"),jZr=l(),hw=a("li"),uwe=a("strong"),DZr=o("distilbert"),GZr=o(" \u2014 "),are=a("a"),OZr=o("FlaxDistilBertForMultipleChoice"),VZr=o(" (DistilBERT model)"),XZr=l(),pw=a("li"),bwe=a("strong"),zZr=o("electra"),QZr=o(" \u2014 "),nre=a("a"),WZr=o("FlaxElectraForMultipleChoice"),HZr=o(" (ELECTRA model)"),UZr=l(),_w=a("li"),vwe=a("strong"),JZr=o("roberta"),YZr=o(" \u2014 "),sre=a("a"),KZr=o("FlaxRobertaForMultipleChoice"),ZZr=o(" (RoBERTa model)"),eet=l(),uw=a("li"),Fwe=a("strong"),oet=o("roformer"),ret=o(" \u2014 "),lre=a("a"),tet=o("FlaxRoFormerForMultipleChoice"),aet=o(" (RoFormer model)"),net=l(),bw=a("li"),Twe=a("strong"),set=o("xlm-roberta"),iet=o(" \u2014 "),ire=a("a"),det=o("FlaxXLMRobertaForMultipleChoice"),cet=o(" (XLM-RoBERTa model)"),fet=l(),F(vw.$$.fragment),Nze=l(),Tf=a("h2"),Fw=a("a"),Mwe=a("span"),F(U$.$$.fragment),met=l(),Ewe=a("span"),get=o("FlaxAutoModelForNextSentencePrediction"),qze=l(),Er=a("div"),F(J$.$$.fragment),het=l(),Mf=a("p"),pet=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),dre=a("a"),_et=o("from_pretrained()"),uet=o(" class method or the "),cre=a("a"),bet=o("from_config()"),vet=o(` class
method.`),Fet=l(),Y$=a("p"),Tet=o("This class cannot be instantiated directly using "),Cwe=a("code"),Met=o("__init__()"),Eet=o(" (throws an error)."),Cet=l(),oa=a("div"),F(K$.$$.fragment),wet=l(),wwe=a("p"),Aet=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Let=l(),Ef=a("p"),yet=o(`Note:
Loading a model from its configuration file does `),Awe=a("strong"),xet=o("not"),$et=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fre=a("a"),ket=o("from_pretrained()"),Set=o(" to load the model weights."),Ret=l(),F(Tw.$$.fragment),Pet=l(),Yr=a("div"),F(Z$.$$.fragment),Bet=l(),Lwe=a("p"),Iet=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Net=l(),xn=a("p"),qet=o("The model class to instantiate is selected based on the "),ywe=a("code"),jet=o("model_type"),Det=o(` property of the config object (either
passed as an argument or loaded from `),xwe=a("code"),Get=o("pretrained_model_name_or_path"),Oet=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$we=a("code"),Vet=o("pretrained_model_name_or_path"),Xet=o(":"),zet=l(),kwe=a("ul"),Mw=a("li"),Swe=a("strong"),Qet=o("bert"),Wet=o(" \u2014 "),mre=a("a"),Het=o("FlaxBertForNextSentencePrediction"),Uet=o(" (BERT model)"),Jet=l(),F(Ew.$$.fragment),jze=l(),Cf=a("h2"),Cw=a("a"),Rwe=a("span"),F(ek.$$.fragment),Yet=l(),Pwe=a("span"),Ket=o("FlaxAutoModelForImageClassification"),Dze=l(),Cr=a("div"),F(ok.$$.fragment),Zet=l(),wf=a("p"),eot=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),gre=a("a"),oot=o("from_pretrained()"),rot=o(" class method or the "),hre=a("a"),tot=o("from_config()"),aot=o(` class
method.`),not=l(),rk=a("p"),sot=o("This class cannot be instantiated directly using "),Bwe=a("code"),lot=o("__init__()"),iot=o(" (throws an error)."),dot=l(),ra=a("div"),F(tk.$$.fragment),cot=l(),Iwe=a("p"),fot=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),mot=l(),Af=a("p"),got=o(`Note:
Loading a model from its configuration file does `),Nwe=a("strong"),hot=o("not"),pot=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pre=a("a"),_ot=o("from_pretrained()"),uot=o(" to load the model weights."),bot=l(),F(ww.$$.fragment),vot=l(),Kr=a("div"),F(ak.$$.fragment),Fot=l(),qwe=a("p"),Tot=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Mot=l(),$n=a("p"),Eot=o("The model class to instantiate is selected based on the "),jwe=a("code"),Cot=o("model_type"),wot=o(` property of the config object (either
passed as an argument or loaded from `),Dwe=a("code"),Aot=o("pretrained_model_name_or_path"),Lot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gwe=a("code"),yot=o("pretrained_model_name_or_path"),xot=o(":"),$ot=l(),nk=a("ul"),Aw=a("li"),Owe=a("strong"),kot=o("beit"),Sot=o(" \u2014 "),_re=a("a"),Rot=o("FlaxBeitForImageClassification"),Pot=o(" (BEiT model)"),Bot=l(),Lw=a("li"),Vwe=a("strong"),Iot=o("vit"),Not=o(" \u2014 "),ure=a("a"),qot=o("FlaxViTForImageClassification"),jot=o(" (ViT model)"),Dot=l(),F(yw.$$.fragment),Gze=l(),Lf=a("h2"),xw=a("a"),Xwe=a("span"),F(sk.$$.fragment),Got=l(),zwe=a("span"),Oot=o("FlaxAutoModelForVision2Seq"),Oze=l(),wr=a("div"),F(lk.$$.fragment),Vot=l(),yf=a("p"),Xot=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),bre=a("a"),zot=o("from_pretrained()"),Qot=o(" class method or the "),vre=a("a"),Wot=o("from_config()"),Hot=o(` class
method.`),Uot=l(),ik=a("p"),Jot=o("This class cannot be instantiated directly using "),Qwe=a("code"),Yot=o("__init__()"),Kot=o(" (throws an error)."),Zot=l(),ta=a("div"),F(dk.$$.fragment),ert=l(),Wwe=a("p"),ort=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),rrt=l(),xf=a("p"),trt=o(`Note:
Loading a model from its configuration file does `),Hwe=a("strong"),art=o("not"),nrt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fre=a("a"),srt=o("from_pretrained()"),lrt=o(" to load the model weights."),irt=l(),F($w.$$.fragment),drt=l(),Zr=a("div"),F(ck.$$.fragment),crt=l(),Uwe=a("p"),frt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),mrt=l(),kn=a("p"),grt=o("The model class to instantiate is selected based on the "),Jwe=a("code"),hrt=o("model_type"),prt=o(` property of the config object (either
passed as an argument or loaded from `),Ywe=a("code"),_rt=o("pretrained_model_name_or_path"),urt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kwe=a("code"),brt=o("pretrained_model_name_or_path"),vrt=o(":"),Frt=l(),Zwe=a("ul"),kw=a("li"),eAe=a("strong"),Trt=o("vision-encoder-decoder"),Mrt=o(" \u2014 "),Tre=a("a"),Ert=o("FlaxVisionEncoderDecoderModel"),Crt=o(" (Vision Encoder decoder model)"),wrt=l(),F(Sw.$$.fragment),this.h()},l(f){const u=Jzt('[data-svelte="svelte-1phssyn"]',document.head);g=n(u,"META",{name:!0,content:!0}),u.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var fk=s(p);m=n(fk,"A",{id:!0,class:!0,href:!0});var oAe=s(m);_=n(oAe,"SPAN",{});var rAe=s(_);T(d.$$.fragment,rAe),rAe.forEach(t),oAe.forEach(t),h=i(fk),Eo=n(fk,"SPAN",{});var tAe=s(Eo);Ai=r(tAe,"Auto Classes"),tAe.forEach(t),fk.forEach(t),Rf=i(f),st=n(f,"P",{});var mk=s(st);Li=r(mk,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),yi=n(mk,"CODE",{});var aAe=s(yi);Y6=r(aAe,"from_pretrained()"),aAe.forEach(t),Pf=r(mk,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),mk.forEach(t),Oe=i(f),Qe=n(f,"P",{});var Sn=s(Qe);xi=r(Sn,"Instantiating one of "),Rn=n(Sn,"A",{href:!0});var nAe=s(Rn);K6=r(nAe,"AutoConfig"),nAe.forEach(t),Pn=r(Sn,", "),Bn=n(Sn,"A",{href:!0});var sAe=s(Bn);Z6=r(sAe,"AutoModel"),sAe.forEach(t),$i=r(Sn,`, and
`),In=n(Sn,"A",{href:!0});var lAe=s(In);eL=r(lAe,"AutoTokenizer"),lAe.forEach(t),ki=r(Sn," will directly create a class of the relevant architecture. For instance"),Sn.forEach(t),Bf=i(f),T(ka.$$.fragment,f),We=i(f),Ae=n(f,"P",{});var gk=s(Ae);kS=r(gk,"will create a model that is an instance of "),Si=n(gk,"A",{href:!0});var iAe=s(Si);SS=r(iAe,"BertModel"),iAe.forEach(t),RS=r(gk,"."),gk.forEach(t),Co=i(f),Sa=n(f,"P",{});var hk=s(Sa);PS=r(hk,"There is one class of "),If=n(hk,"CODE",{});var dAe=s(If);BS=r(dAe,"AutoModel"),dAe.forEach(t),ZWe=r(hk," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),hk.forEach(t),qVe=i(f),Ri=n(f,"H2",{class:!0});var pk=s(Ri);Nf=n(pk,"A",{id:!0,class:!0,href:!0});var cAe=s(Nf);_ae=n(cAe,"SPAN",{});var fAe=s(_ae);T(oL.$$.fragment,fAe),fAe.forEach(t),cAe.forEach(t),eHe=i(pk),uae=n(pk,"SPAN",{});var mAe=s(uae);oHe=r(mAe,"Extending the Auto Classes"),mAe.forEach(t),pk.forEach(t),jVe=i(f),Nn=n(f,"P",{});var $f=s(Nn);rHe=r($f,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),bae=n($f,"CODE",{});var gAe=s(bae);tHe=r(gAe,"NewModel"),gAe.forEach(t),aHe=r($f,", make sure you have a "),vae=n($f,"CODE",{});var hAe=s(vae);nHe=r(hAe,"NewModelConfig"),hAe.forEach(t),sHe=r($f,` then you can add those to the auto
classes like this:`),$f.forEach(t),DVe=i(f),T(rL.$$.fragment,f),GVe=i(f),IS=n(f,"P",{});var pAe=s(IS);lHe=r(pAe,"You will then be able to use the auto classes like you would usually do!"),pAe.forEach(t),OVe=i(f),T(qf.$$.fragment,f),VVe=i(f),Pi=n(f,"H2",{class:!0});var _k=s(Pi);jf=n(_k,"A",{id:!0,class:!0,href:!0});var _Ae=s(jf);Fae=n(_Ae,"SPAN",{});var uAe=s(Fae);T(tL.$$.fragment,uAe),uAe.forEach(t),_Ae.forEach(t),iHe=i(_k),Tae=n(_k,"SPAN",{});var bAe=s(Tae);dHe=r(bAe,"AutoConfig"),bAe.forEach(t),_k.forEach(t),XVe=i(f),wo=n(f,"DIV",{class:!0});var at=s(wo);T(aL.$$.fragment,at),cHe=i(at),nL=n(at,"P",{});var uk=s(nL);fHe=r(uk,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),NS=n(uk,"A",{href:!0});var vAe=s(NS);mHe=r(vAe,"from_pretrained()"),vAe.forEach(t),gHe=r(uk," class method."),uk.forEach(t),hHe=i(at),sL=n(at,"P",{});var bk=s(sL);pHe=r(bk,"This class cannot be instantiated directly using "),Mae=n(bk,"CODE",{});var FAe=s(Mae);_He=r(FAe,"__init__()"),FAe.forEach(t),uHe=r(bk," (throws an error)."),bk.forEach(t),bHe=i(at),Ar=n(at,"DIV",{class:!0});var nt=s(Ar);T(lL.$$.fragment,nt),vHe=i(nt),Eae=n(nt,"P",{});var TAe=s(Eae);FHe=r(TAe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),TAe.forEach(t),THe=i(nt),Bi=n(nt,"P",{});var kf=s(Bi);MHe=r(kf,"The configuration class to instantiate is selected based on the "),Cae=n(kf,"CODE",{});var MAe=s(Cae);EHe=r(MAe,"model_type"),MAe.forEach(t),CHe=r(kf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),wae=n(kf,"CODE",{});var EAe=s(wae);wHe=r(EAe,"pretrained_model_name_or_path"),EAe.forEach(t),AHe=r(kf,":"),kf.forEach(t),LHe=i(nt),A=n(nt,"UL",{});var L=s(A);Df=n(L,"LI",{});var Rw=s(Df);Aae=n(Rw,"STRONG",{});var CAe=s(Aae);yHe=r(CAe,"albert"),CAe.forEach(t),xHe=r(Rw," \u2014 "),qS=n(Rw,"A",{href:!0});var wAe=s(qS);$He=r(wAe,"AlbertConfig"),wAe.forEach(t),kHe=r(Rw," (ALBERT model)"),Rw.forEach(t),SHe=i(L),Gf=n(L,"LI",{});var Pw=s(Gf);Lae=n(Pw,"STRONG",{});var AAe=s(Lae);RHe=r(AAe,"bart"),AAe.forEach(t),PHe=r(Pw," \u2014 "),jS=n(Pw,"A",{href:!0});var LAe=s(jS);BHe=r(LAe,"BartConfig"),LAe.forEach(t),IHe=r(Pw," (BART model)"),Pw.forEach(t),NHe=i(L),Of=n(L,"LI",{});var Bw=s(Of);yae=n(Bw,"STRONG",{});var yAe=s(yae);qHe=r(yAe,"beit"),yAe.forEach(t),jHe=r(Bw," \u2014 "),DS=n(Bw,"A",{href:!0});var xAe=s(DS);DHe=r(xAe,"BeitConfig"),xAe.forEach(t),GHe=r(Bw," (BEiT model)"),Bw.forEach(t),OHe=i(L),Vf=n(L,"LI",{});var Iw=s(Vf);xae=n(Iw,"STRONG",{});var $Ae=s(xae);VHe=r($Ae,"bert"),$Ae.forEach(t),XHe=r(Iw," \u2014 "),GS=n(Iw,"A",{href:!0});var kAe=s(GS);zHe=r(kAe,"BertConfig"),kAe.forEach(t),QHe=r(Iw," (BERT model)"),Iw.forEach(t),WHe=i(L),Xf=n(L,"LI",{});var Nw=s(Xf);$ae=n(Nw,"STRONG",{});var SAe=s($ae);HHe=r(SAe,"bert-generation"),SAe.forEach(t),UHe=r(Nw," \u2014 "),OS=n(Nw,"A",{href:!0});var RAe=s(OS);JHe=r(RAe,"BertGenerationConfig"),RAe.forEach(t),YHe=r(Nw," (Bert Generation model)"),Nw.forEach(t),KHe=i(L),zf=n(L,"LI",{});var qw=s(zf);kae=n(qw,"STRONG",{});var PAe=s(kae);ZHe=r(PAe,"big_bird"),PAe.forEach(t),eUe=r(qw," \u2014 "),VS=n(qw,"A",{href:!0});var BAe=s(VS);oUe=r(BAe,"BigBirdConfig"),BAe.forEach(t),rUe=r(qw," (BigBird model)"),qw.forEach(t),tUe=i(L),Qf=n(L,"LI",{});var jw=s(Qf);Sae=n(jw,"STRONG",{});var IAe=s(Sae);aUe=r(IAe,"bigbird_pegasus"),IAe.forEach(t),nUe=r(jw," \u2014 "),XS=n(jw,"A",{href:!0});var NAe=s(XS);sUe=r(NAe,"BigBirdPegasusConfig"),NAe.forEach(t),lUe=r(jw," (BigBird-Pegasus model)"),jw.forEach(t),iUe=i(L),Wf=n(L,"LI",{});var Dw=s(Wf);Rae=n(Dw,"STRONG",{});var qAe=s(Rae);dUe=r(qAe,"blenderbot"),qAe.forEach(t),cUe=r(Dw," \u2014 "),zS=n(Dw,"A",{href:!0});var jAe=s(zS);fUe=r(jAe,"BlenderbotConfig"),jAe.forEach(t),mUe=r(Dw," (Blenderbot model)"),Dw.forEach(t),gUe=i(L),Hf=n(L,"LI",{});var Gw=s(Hf);Pae=n(Gw,"STRONG",{});var DAe=s(Pae);hUe=r(DAe,"blenderbot-small"),DAe.forEach(t),pUe=r(Gw," \u2014 "),QS=n(Gw,"A",{href:!0});var GAe=s(QS);_Ue=r(GAe,"BlenderbotSmallConfig"),GAe.forEach(t),uUe=r(Gw," (BlenderbotSmall model)"),Gw.forEach(t),bUe=i(L),Uf=n(L,"LI",{});var Ow=s(Uf);Bae=n(Ow,"STRONG",{});var OAe=s(Bae);vUe=r(OAe,"bloom"),OAe.forEach(t),FUe=r(Ow," \u2014 "),WS=n(Ow,"A",{href:!0});var VAe=s(WS);TUe=r(VAe,"BloomConfig"),VAe.forEach(t),MUe=r(Ow," (BLOOM model)"),Ow.forEach(t),EUe=i(L),Jf=n(L,"LI",{});var Vw=s(Jf);Iae=n(Vw,"STRONG",{});var XAe=s(Iae);CUe=r(XAe,"camembert"),XAe.forEach(t),wUe=r(Vw," \u2014 "),HS=n(Vw,"A",{href:!0});var zAe=s(HS);AUe=r(zAe,"CamembertConfig"),zAe.forEach(t),LUe=r(Vw," (CamemBERT model)"),Vw.forEach(t),yUe=i(L),Yf=n(L,"LI",{});var Xw=s(Yf);Nae=n(Xw,"STRONG",{});var QAe=s(Nae);xUe=r(QAe,"canine"),QAe.forEach(t),$Ue=r(Xw," \u2014 "),US=n(Xw,"A",{href:!0});var WAe=s(US);kUe=r(WAe,"CanineConfig"),WAe.forEach(t),SUe=r(Xw," (CANINE model)"),Xw.forEach(t),RUe=i(L),Kf=n(L,"LI",{});var zw=s(Kf);qae=n(zw,"STRONG",{});var HAe=s(qae);PUe=r(HAe,"clip"),HAe.forEach(t),BUe=r(zw," \u2014 "),JS=n(zw,"A",{href:!0});var UAe=s(JS);IUe=r(UAe,"CLIPConfig"),UAe.forEach(t),NUe=r(zw," (CLIP model)"),zw.forEach(t),qUe=i(L),Zf=n(L,"LI",{});var Qw=s(Zf);jae=n(Qw,"STRONG",{});var JAe=s(jae);jUe=r(JAe,"codegen"),JAe.forEach(t),DUe=r(Qw," \u2014 "),YS=n(Qw,"A",{href:!0});var YAe=s(YS);GUe=r(YAe,"CodeGenConfig"),YAe.forEach(t),OUe=r(Qw," (CodeGen model)"),Qw.forEach(t),VUe=i(L),em=n(L,"LI",{});var Ww=s(em);Dae=n(Ww,"STRONG",{});var KAe=s(Dae);XUe=r(KAe,"convbert"),KAe.forEach(t),zUe=r(Ww," \u2014 "),KS=n(Ww,"A",{href:!0});var ZAe=s(KS);QUe=r(ZAe,"ConvBertConfig"),ZAe.forEach(t),WUe=r(Ww," (ConvBERT model)"),Ww.forEach(t),HUe=i(L),om=n(L,"LI",{});var Hw=s(om);Gae=n(Hw,"STRONG",{});var e6e=s(Gae);UUe=r(e6e,"convnext"),e6e.forEach(t),JUe=r(Hw," \u2014 "),ZS=n(Hw,"A",{href:!0});var o6e=s(ZS);YUe=r(o6e,"ConvNextConfig"),o6e.forEach(t),KUe=r(Hw," (ConvNeXT model)"),Hw.forEach(t),ZUe=i(L),rm=n(L,"LI",{});var Uw=s(rm);Oae=n(Uw,"STRONG",{});var r6e=s(Oae);eJe=r(r6e,"ctrl"),r6e.forEach(t),oJe=r(Uw," \u2014 "),eR=n(Uw,"A",{href:!0});var t6e=s(eR);rJe=r(t6e,"CTRLConfig"),t6e.forEach(t),tJe=r(Uw," (CTRL model)"),Uw.forEach(t),aJe=i(L),tm=n(L,"LI",{});var Jw=s(tm);Vae=n(Jw,"STRONG",{});var a6e=s(Vae);nJe=r(a6e,"cvt"),a6e.forEach(t),sJe=r(Jw," \u2014 "),oR=n(Jw,"A",{href:!0});var n6e=s(oR);lJe=r(n6e,"CvtConfig"),n6e.forEach(t),iJe=r(Jw," (CvT model)"),Jw.forEach(t),dJe=i(L),am=n(L,"LI",{});var Yw=s(am);Xae=n(Yw,"STRONG",{});var s6e=s(Xae);cJe=r(s6e,"data2vec-audio"),s6e.forEach(t),fJe=r(Yw," \u2014 "),rR=n(Yw,"A",{href:!0});var l6e=s(rR);mJe=r(l6e,"Data2VecAudioConfig"),l6e.forEach(t),gJe=r(Yw," (Data2VecAudio model)"),Yw.forEach(t),hJe=i(L),nm=n(L,"LI",{});var Kw=s(nm);zae=n(Kw,"STRONG",{});var i6e=s(zae);pJe=r(i6e,"data2vec-text"),i6e.forEach(t),_Je=r(Kw," \u2014 "),tR=n(Kw,"A",{href:!0});var d6e=s(tR);uJe=r(d6e,"Data2VecTextConfig"),d6e.forEach(t),bJe=r(Kw," (Data2VecText model)"),Kw.forEach(t),vJe=i(L),sm=n(L,"LI",{});var Zw=s(sm);Qae=n(Zw,"STRONG",{});var c6e=s(Qae);FJe=r(c6e,"data2vec-vision"),c6e.forEach(t),TJe=r(Zw," \u2014 "),aR=n(Zw,"A",{href:!0});var f6e=s(aR);MJe=r(f6e,"Data2VecVisionConfig"),f6e.forEach(t),EJe=r(Zw," (Data2VecVision model)"),Zw.forEach(t),CJe=i(L),lm=n(L,"LI",{});var eA=s(lm);Wae=n(eA,"STRONG",{});var m6e=s(Wae);wJe=r(m6e,"deberta"),m6e.forEach(t),AJe=r(eA," \u2014 "),nR=n(eA,"A",{href:!0});var g6e=s(nR);LJe=r(g6e,"DebertaConfig"),g6e.forEach(t),yJe=r(eA," (DeBERTa model)"),eA.forEach(t),xJe=i(L),im=n(L,"LI",{});var oA=s(im);Hae=n(oA,"STRONG",{});var h6e=s(Hae);$Je=r(h6e,"deberta-v2"),h6e.forEach(t),kJe=r(oA," \u2014 "),sR=n(oA,"A",{href:!0});var p6e=s(sR);SJe=r(p6e,"DebertaV2Config"),p6e.forEach(t),RJe=r(oA," (DeBERTa-v2 model)"),oA.forEach(t),PJe=i(L),dm=n(L,"LI",{});var rA=s(dm);Uae=n(rA,"STRONG",{});var Lrt=s(Uae);BJe=r(Lrt,"decision_transformer"),Lrt.forEach(t),IJe=r(rA," \u2014 "),lR=n(rA,"A",{href:!0});var yrt=s(lR);NJe=r(yrt,"DecisionTransformerConfig"),yrt.forEach(t),qJe=r(rA," (Decision Transformer model)"),rA.forEach(t),jJe=i(L),cm=n(L,"LI",{});var _6e=s(cm);Jae=n(_6e,"STRONG",{});var xrt=s(Jae);DJe=r(xrt,"deformable_detr"),xrt.forEach(t),GJe=r(_6e," \u2014 "),iR=n(_6e,"A",{href:!0});var $rt=s(iR);OJe=r($rt,"DeformableDetrConfig"),$rt.forEach(t),VJe=r(_6e," (Deformable DETR model)"),_6e.forEach(t),XJe=i(L),fm=n(L,"LI",{});var u6e=s(fm);Yae=n(u6e,"STRONG",{});var krt=s(Yae);zJe=r(krt,"deit"),krt.forEach(t),QJe=r(u6e," \u2014 "),dR=n(u6e,"A",{href:!0});var Srt=s(dR);WJe=r(Srt,"DeiTConfig"),Srt.forEach(t),HJe=r(u6e," (DeiT model)"),u6e.forEach(t),UJe=i(L),mm=n(L,"LI",{});var b6e=s(mm);Kae=n(b6e,"STRONG",{});var Rrt=s(Kae);JJe=r(Rrt,"detr"),Rrt.forEach(t),YJe=r(b6e," \u2014 "),cR=n(b6e,"A",{href:!0});var Prt=s(cR);KJe=r(Prt,"DetrConfig"),Prt.forEach(t),ZJe=r(b6e," (DETR model)"),b6e.forEach(t),eYe=i(L),gm=n(L,"LI",{});var v6e=s(gm);Zae=n(v6e,"STRONG",{});var Brt=s(Zae);oYe=r(Brt,"distilbert"),Brt.forEach(t),rYe=r(v6e," \u2014 "),fR=n(v6e,"A",{href:!0});var Irt=s(fR);tYe=r(Irt,"DistilBertConfig"),Irt.forEach(t),aYe=r(v6e," (DistilBERT model)"),v6e.forEach(t),nYe=i(L),hm=n(L,"LI",{});var F6e=s(hm);ene=n(F6e,"STRONG",{});var Nrt=s(ene);sYe=r(Nrt,"dpr"),Nrt.forEach(t),lYe=r(F6e," \u2014 "),mR=n(F6e,"A",{href:!0});var qrt=s(mR);iYe=r(qrt,"DPRConfig"),qrt.forEach(t),dYe=r(F6e," (DPR model)"),F6e.forEach(t),cYe=i(L),pm=n(L,"LI",{});var T6e=s(pm);one=n(T6e,"STRONG",{});var jrt=s(one);fYe=r(jrt,"dpt"),jrt.forEach(t),mYe=r(T6e," \u2014 "),gR=n(T6e,"A",{href:!0});var Drt=s(gR);gYe=r(Drt,"DPTConfig"),Drt.forEach(t),hYe=r(T6e," (DPT model)"),T6e.forEach(t),pYe=i(L),_m=n(L,"LI",{});var M6e=s(_m);rne=n(M6e,"STRONG",{});var Grt=s(rne);_Ye=r(Grt,"electra"),Grt.forEach(t),uYe=r(M6e," \u2014 "),hR=n(M6e,"A",{href:!0});var Ort=s(hR);bYe=r(Ort,"ElectraConfig"),Ort.forEach(t),vYe=r(M6e," (ELECTRA model)"),M6e.forEach(t),FYe=i(L),um=n(L,"LI",{});var E6e=s(um);tne=n(E6e,"STRONG",{});var Vrt=s(tne);TYe=r(Vrt,"encoder-decoder"),Vrt.forEach(t),MYe=r(E6e," \u2014 "),pR=n(E6e,"A",{href:!0});var Xrt=s(pR);EYe=r(Xrt,"EncoderDecoderConfig"),Xrt.forEach(t),CYe=r(E6e," (Encoder decoder model)"),E6e.forEach(t),wYe=i(L),bm=n(L,"LI",{});var C6e=s(bm);ane=n(C6e,"STRONG",{});var zrt=s(ane);AYe=r(zrt,"flaubert"),zrt.forEach(t),LYe=r(C6e," \u2014 "),_R=n(C6e,"A",{href:!0});var Qrt=s(_R);yYe=r(Qrt,"FlaubertConfig"),Qrt.forEach(t),xYe=r(C6e," (FlauBERT model)"),C6e.forEach(t),$Ye=i(L),vm=n(L,"LI",{});var w6e=s(vm);nne=n(w6e,"STRONG",{});var Wrt=s(nne);kYe=r(Wrt,"flava"),Wrt.forEach(t),SYe=r(w6e," \u2014 "),uR=n(w6e,"A",{href:!0});var Hrt=s(uR);RYe=r(Hrt,"FlavaConfig"),Hrt.forEach(t),PYe=r(w6e," (FLAVA model)"),w6e.forEach(t),BYe=i(L),Fm=n(L,"LI",{});var A6e=s(Fm);sne=n(A6e,"STRONG",{});var Urt=s(sne);IYe=r(Urt,"fnet"),Urt.forEach(t),NYe=r(A6e," \u2014 "),bR=n(A6e,"A",{href:!0});var Jrt=s(bR);qYe=r(Jrt,"FNetConfig"),Jrt.forEach(t),jYe=r(A6e," (FNet model)"),A6e.forEach(t),DYe=i(L),Tm=n(L,"LI",{});var L6e=s(Tm);lne=n(L6e,"STRONG",{});var Yrt=s(lne);GYe=r(Yrt,"fsmt"),Yrt.forEach(t),OYe=r(L6e," \u2014 "),vR=n(L6e,"A",{href:!0});var Krt=s(vR);VYe=r(Krt,"FSMTConfig"),Krt.forEach(t),XYe=r(L6e," (FairSeq Machine-Translation model)"),L6e.forEach(t),zYe=i(L),Mm=n(L,"LI",{});var y6e=s(Mm);ine=n(y6e,"STRONG",{});var Zrt=s(ine);QYe=r(Zrt,"funnel"),Zrt.forEach(t),WYe=r(y6e," \u2014 "),FR=n(y6e,"A",{href:!0});var ett=s(FR);HYe=r(ett,"FunnelConfig"),ett.forEach(t),UYe=r(y6e," (Funnel Transformer model)"),y6e.forEach(t),JYe=i(L),Em=n(L,"LI",{});var x6e=s(Em);dne=n(x6e,"STRONG",{});var ott=s(dne);YYe=r(ott,"glpn"),ott.forEach(t),KYe=r(x6e," \u2014 "),TR=n(x6e,"A",{href:!0});var rtt=s(TR);ZYe=r(rtt,"GLPNConfig"),rtt.forEach(t),eKe=r(x6e," (GLPN model)"),x6e.forEach(t),oKe=i(L),Cm=n(L,"LI",{});var $6e=s(Cm);cne=n($6e,"STRONG",{});var ttt=s(cne);rKe=r(ttt,"gpt2"),ttt.forEach(t),tKe=r($6e," \u2014 "),MR=n($6e,"A",{href:!0});var att=s(MR);aKe=r(att,"GPT2Config"),att.forEach(t),nKe=r($6e," (OpenAI GPT-2 model)"),$6e.forEach(t),sKe=i(L),wm=n(L,"LI",{});var k6e=s(wm);fne=n(k6e,"STRONG",{});var ntt=s(fne);lKe=r(ntt,"gpt_neo"),ntt.forEach(t),iKe=r(k6e," \u2014 "),ER=n(k6e,"A",{href:!0});var stt=s(ER);dKe=r(stt,"GPTNeoConfig"),stt.forEach(t),cKe=r(k6e," (GPT Neo model)"),k6e.forEach(t),fKe=i(L),Am=n(L,"LI",{});var S6e=s(Am);mne=n(S6e,"STRONG",{});var ltt=s(mne);mKe=r(ltt,"gpt_neox"),ltt.forEach(t),gKe=r(S6e," \u2014 "),CR=n(S6e,"A",{href:!0});var itt=s(CR);hKe=r(itt,"GPTNeoXConfig"),itt.forEach(t),pKe=r(S6e," (GPT NeoX model)"),S6e.forEach(t),_Ke=i(L),Lm=n(L,"LI",{});var R6e=s(Lm);gne=n(R6e,"STRONG",{});var dtt=s(gne);uKe=r(dtt,"gptj"),dtt.forEach(t),bKe=r(R6e," \u2014 "),wR=n(R6e,"A",{href:!0});var ctt=s(wR);vKe=r(ctt,"GPTJConfig"),ctt.forEach(t),FKe=r(R6e," (GPT-J model)"),R6e.forEach(t),TKe=i(L),ym=n(L,"LI",{});var P6e=s(ym);hne=n(P6e,"STRONG",{});var ftt=s(hne);MKe=r(ftt,"groupvit"),ftt.forEach(t),EKe=r(P6e," \u2014 "),AR=n(P6e,"A",{href:!0});var mtt=s(AR);CKe=r(mtt,"GroupViTConfig"),mtt.forEach(t),wKe=r(P6e," (GroupViT model)"),P6e.forEach(t),AKe=i(L),xm=n(L,"LI",{});var B6e=s(xm);pne=n(B6e,"STRONG",{});var gtt=s(pne);LKe=r(gtt,"hubert"),gtt.forEach(t),yKe=r(B6e," \u2014 "),LR=n(B6e,"A",{href:!0});var htt=s(LR);xKe=r(htt,"HubertConfig"),htt.forEach(t),$Ke=r(B6e," (Hubert model)"),B6e.forEach(t),kKe=i(L),$m=n(L,"LI",{});var I6e=s($m);_ne=n(I6e,"STRONG",{});var ptt=s(_ne);SKe=r(ptt,"ibert"),ptt.forEach(t),RKe=r(I6e," \u2014 "),yR=n(I6e,"A",{href:!0});var _tt=s(yR);PKe=r(_tt,"IBertConfig"),_tt.forEach(t),BKe=r(I6e," (I-BERT model)"),I6e.forEach(t),IKe=i(L),km=n(L,"LI",{});var N6e=s(km);une=n(N6e,"STRONG",{});var utt=s(une);NKe=r(utt,"imagegpt"),utt.forEach(t),qKe=r(N6e," \u2014 "),xR=n(N6e,"A",{href:!0});var btt=s(xR);jKe=r(btt,"ImageGPTConfig"),btt.forEach(t),DKe=r(N6e," (ImageGPT model)"),N6e.forEach(t),GKe=i(L),Sm=n(L,"LI",{});var q6e=s(Sm);bne=n(q6e,"STRONG",{});var vtt=s(bne);OKe=r(vtt,"layoutlm"),vtt.forEach(t),VKe=r(q6e," \u2014 "),$R=n(q6e,"A",{href:!0});var Ftt=s($R);XKe=r(Ftt,"LayoutLMConfig"),Ftt.forEach(t),zKe=r(q6e," (LayoutLM model)"),q6e.forEach(t),QKe=i(L),Rm=n(L,"LI",{});var j6e=s(Rm);vne=n(j6e,"STRONG",{});var Ttt=s(vne);WKe=r(Ttt,"layoutlmv2"),Ttt.forEach(t),HKe=r(j6e," \u2014 "),kR=n(j6e,"A",{href:!0});var Mtt=s(kR);UKe=r(Mtt,"LayoutLMv2Config"),Mtt.forEach(t),JKe=r(j6e," (LayoutLMv2 model)"),j6e.forEach(t),YKe=i(L),Pm=n(L,"LI",{});var D6e=s(Pm);Fne=n(D6e,"STRONG",{});var Ett=s(Fne);KKe=r(Ett,"layoutlmv3"),Ett.forEach(t),ZKe=r(D6e," \u2014 "),SR=n(D6e,"A",{href:!0});var Ctt=s(SR);eZe=r(Ctt,"LayoutLMv3Config"),Ctt.forEach(t),oZe=r(D6e," (LayoutLMv3 model)"),D6e.forEach(t),rZe=i(L),Bm=n(L,"LI",{});var G6e=s(Bm);Tne=n(G6e,"STRONG",{});var wtt=s(Tne);tZe=r(wtt,"led"),wtt.forEach(t),aZe=r(G6e," \u2014 "),RR=n(G6e,"A",{href:!0});var Att=s(RR);nZe=r(Att,"LEDConfig"),Att.forEach(t),sZe=r(G6e," (LED model)"),G6e.forEach(t),lZe=i(L),Im=n(L,"LI",{});var O6e=s(Im);Mne=n(O6e,"STRONG",{});var Ltt=s(Mne);iZe=r(Ltt,"levit"),Ltt.forEach(t),dZe=r(O6e," \u2014 "),PR=n(O6e,"A",{href:!0});var ytt=s(PR);cZe=r(ytt,"LevitConfig"),ytt.forEach(t),fZe=r(O6e," (LeViT model)"),O6e.forEach(t),mZe=i(L),Nm=n(L,"LI",{});var V6e=s(Nm);Ene=n(V6e,"STRONG",{});var xtt=s(Ene);gZe=r(xtt,"longformer"),xtt.forEach(t),hZe=r(V6e," \u2014 "),BR=n(V6e,"A",{href:!0});var $tt=s(BR);pZe=r($tt,"LongformerConfig"),$tt.forEach(t),_Ze=r(V6e," (Longformer model)"),V6e.forEach(t),uZe=i(L),qm=n(L,"LI",{});var X6e=s(qm);Cne=n(X6e,"STRONG",{});var ktt=s(Cne);bZe=r(ktt,"longt5"),ktt.forEach(t),vZe=r(X6e," \u2014 "),IR=n(X6e,"A",{href:!0});var Stt=s(IR);FZe=r(Stt,"LongT5Config"),Stt.forEach(t),TZe=r(X6e," (LongT5 model)"),X6e.forEach(t),MZe=i(L),jm=n(L,"LI",{});var z6e=s(jm);wne=n(z6e,"STRONG",{});var Rtt=s(wne);EZe=r(Rtt,"luke"),Rtt.forEach(t),CZe=r(z6e," \u2014 "),NR=n(z6e,"A",{href:!0});var Ptt=s(NR);wZe=r(Ptt,"LukeConfig"),Ptt.forEach(t),AZe=r(z6e," (LUKE model)"),z6e.forEach(t),LZe=i(L),Dm=n(L,"LI",{});var Q6e=s(Dm);Ane=n(Q6e,"STRONG",{});var Btt=s(Ane);yZe=r(Btt,"lxmert"),Btt.forEach(t),xZe=r(Q6e," \u2014 "),qR=n(Q6e,"A",{href:!0});var Itt=s(qR);$Ze=r(Itt,"LxmertConfig"),Itt.forEach(t),kZe=r(Q6e," (LXMERT model)"),Q6e.forEach(t),SZe=i(L),Gm=n(L,"LI",{});var W6e=s(Gm);Lne=n(W6e,"STRONG",{});var Ntt=s(Lne);RZe=r(Ntt,"m2m_100"),Ntt.forEach(t),PZe=r(W6e," \u2014 "),jR=n(W6e,"A",{href:!0});var qtt=s(jR);BZe=r(qtt,"M2M100Config"),qtt.forEach(t),IZe=r(W6e," (M2M100 model)"),W6e.forEach(t),NZe=i(L),Om=n(L,"LI",{});var H6e=s(Om);yne=n(H6e,"STRONG",{});var jtt=s(yne);qZe=r(jtt,"marian"),jtt.forEach(t),jZe=r(H6e," \u2014 "),DR=n(H6e,"A",{href:!0});var Dtt=s(DR);DZe=r(Dtt,"MarianConfig"),Dtt.forEach(t),GZe=r(H6e," (Marian model)"),H6e.forEach(t),OZe=i(L),Vm=n(L,"LI",{});var U6e=s(Vm);xne=n(U6e,"STRONG",{});var Gtt=s(xne);VZe=r(Gtt,"maskformer"),Gtt.forEach(t),XZe=r(U6e," \u2014 "),GR=n(U6e,"A",{href:!0});var Ott=s(GR);zZe=r(Ott,"MaskFormerConfig"),Ott.forEach(t),QZe=r(U6e," (MaskFormer model)"),U6e.forEach(t),WZe=i(L),Xm=n(L,"LI",{});var J6e=s(Xm);$ne=n(J6e,"STRONG",{});var Vtt=s($ne);HZe=r(Vtt,"mbart"),Vtt.forEach(t),UZe=r(J6e," \u2014 "),OR=n(J6e,"A",{href:!0});var Xtt=s(OR);JZe=r(Xtt,"MBartConfig"),Xtt.forEach(t),YZe=r(J6e," (mBART model)"),J6e.forEach(t),KZe=i(L),zm=n(L,"LI",{});var Y6e=s(zm);kne=n(Y6e,"STRONG",{});var ztt=s(kne);ZZe=r(ztt,"mctct"),ztt.forEach(t),eeo=r(Y6e," \u2014 "),VR=n(Y6e,"A",{href:!0});var Qtt=s(VR);oeo=r(Qtt,"MCTCTConfig"),Qtt.forEach(t),reo=r(Y6e," (M-CTC-T model)"),Y6e.forEach(t),teo=i(L),Qm=n(L,"LI",{});var K6e=s(Qm);Sne=n(K6e,"STRONG",{});var Wtt=s(Sne);aeo=r(Wtt,"megatron-bert"),Wtt.forEach(t),neo=r(K6e," \u2014 "),XR=n(K6e,"A",{href:!0});var Htt=s(XR);seo=r(Htt,"MegatronBertConfig"),Htt.forEach(t),leo=r(K6e," (Megatron-BERT model)"),K6e.forEach(t),ieo=i(L),Wm=n(L,"LI",{});var Z6e=s(Wm);Rne=n(Z6e,"STRONG",{});var Utt=s(Rne);deo=r(Utt,"mobilebert"),Utt.forEach(t),ceo=r(Z6e," \u2014 "),zR=n(Z6e,"A",{href:!0});var Jtt=s(zR);feo=r(Jtt,"MobileBertConfig"),Jtt.forEach(t),meo=r(Z6e," (MobileBERT model)"),Z6e.forEach(t),geo=i(L),Hm=n(L,"LI",{});var eLe=s(Hm);Pne=n(eLe,"STRONG",{});var Ytt=s(Pne);heo=r(Ytt,"mobilevit"),Ytt.forEach(t),peo=r(eLe," \u2014 "),QR=n(eLe,"A",{href:!0});var Ktt=s(QR);_eo=r(Ktt,"MobileViTConfig"),Ktt.forEach(t),ueo=r(eLe," (MobileViT model)"),eLe.forEach(t),beo=i(L),Um=n(L,"LI",{});var oLe=s(Um);Bne=n(oLe,"STRONG",{});var Ztt=s(Bne);veo=r(Ztt,"mpnet"),Ztt.forEach(t),Feo=r(oLe," \u2014 "),WR=n(oLe,"A",{href:!0});var eat=s(WR);Teo=r(eat,"MPNetConfig"),eat.forEach(t),Meo=r(oLe," (MPNet model)"),oLe.forEach(t),Eeo=i(L),Jm=n(L,"LI",{});var rLe=s(Jm);Ine=n(rLe,"STRONG",{});var oat=s(Ine);Ceo=r(oat,"mt5"),oat.forEach(t),weo=r(rLe," \u2014 "),HR=n(rLe,"A",{href:!0});var rat=s(HR);Aeo=r(rat,"MT5Config"),rat.forEach(t),Leo=r(rLe," (MT5 model)"),rLe.forEach(t),yeo=i(L),Ym=n(L,"LI",{});var tLe=s(Ym);Nne=n(tLe,"STRONG",{});var tat=s(Nne);xeo=r(tat,"mvp"),tat.forEach(t),$eo=r(tLe," \u2014 "),UR=n(tLe,"A",{href:!0});var aat=s(UR);keo=r(aat,"MvpConfig"),aat.forEach(t),Seo=r(tLe," (MVP model)"),tLe.forEach(t),Reo=i(L),Km=n(L,"LI",{});var aLe=s(Km);qne=n(aLe,"STRONG",{});var nat=s(qne);Peo=r(nat,"nezha"),nat.forEach(t),Beo=r(aLe," \u2014 "),JR=n(aLe,"A",{href:!0});var sat=s(JR);Ieo=r(sat,"NezhaConfig"),sat.forEach(t),Neo=r(aLe," (Nezha model)"),aLe.forEach(t),qeo=i(L),Zm=n(L,"LI",{});var nLe=s(Zm);jne=n(nLe,"STRONG",{});var lat=s(jne);jeo=r(lat,"nystromformer"),lat.forEach(t),Deo=r(nLe," \u2014 "),YR=n(nLe,"A",{href:!0});var iat=s(YR);Geo=r(iat,"NystromformerConfig"),iat.forEach(t),Oeo=r(nLe," (Nystr\xF6mformer model)"),nLe.forEach(t),Veo=i(L),eg=n(L,"LI",{});var sLe=s(eg);Dne=n(sLe,"STRONG",{});var dat=s(Dne);Xeo=r(dat,"openai-gpt"),dat.forEach(t),zeo=r(sLe," \u2014 "),KR=n(sLe,"A",{href:!0});var cat=s(KR);Qeo=r(cat,"OpenAIGPTConfig"),cat.forEach(t),Weo=r(sLe," (OpenAI GPT model)"),sLe.forEach(t),Heo=i(L),og=n(L,"LI",{});var lLe=s(og);Gne=n(lLe,"STRONG",{});var fat=s(Gne);Ueo=r(fat,"opt"),fat.forEach(t),Jeo=r(lLe," \u2014 "),ZR=n(lLe,"A",{href:!0});var mat=s(ZR);Yeo=r(mat,"OPTConfig"),mat.forEach(t),Keo=r(lLe," (OPT model)"),lLe.forEach(t),Zeo=i(L),rg=n(L,"LI",{});var iLe=s(rg);One=n(iLe,"STRONG",{});var gat=s(One);eoo=r(gat,"pegasus"),gat.forEach(t),ooo=r(iLe," \u2014 "),eP=n(iLe,"A",{href:!0});var hat=s(eP);roo=r(hat,"PegasusConfig"),hat.forEach(t),too=r(iLe," (Pegasus model)"),iLe.forEach(t),aoo=i(L),tg=n(L,"LI",{});var dLe=s(tg);Vne=n(dLe,"STRONG",{});var pat=s(Vne);noo=r(pat,"perceiver"),pat.forEach(t),soo=r(dLe," \u2014 "),oP=n(dLe,"A",{href:!0});var _at=s(oP);loo=r(_at,"PerceiverConfig"),_at.forEach(t),ioo=r(dLe," (Perceiver model)"),dLe.forEach(t),doo=i(L),ag=n(L,"LI",{});var cLe=s(ag);Xne=n(cLe,"STRONG",{});var uat=s(Xne);coo=r(uat,"plbart"),uat.forEach(t),foo=r(cLe," \u2014 "),rP=n(cLe,"A",{href:!0});var bat=s(rP);moo=r(bat,"PLBartConfig"),bat.forEach(t),goo=r(cLe," (PLBart model)"),cLe.forEach(t),hoo=i(L),ng=n(L,"LI",{});var fLe=s(ng);zne=n(fLe,"STRONG",{});var vat=s(zne);poo=r(vat,"poolformer"),vat.forEach(t),_oo=r(fLe," \u2014 "),tP=n(fLe,"A",{href:!0});var Fat=s(tP);uoo=r(Fat,"PoolFormerConfig"),Fat.forEach(t),boo=r(fLe," (PoolFormer model)"),fLe.forEach(t),voo=i(L),sg=n(L,"LI",{});var mLe=s(sg);Qne=n(mLe,"STRONG",{});var Tat=s(Qne);Foo=r(Tat,"prophetnet"),Tat.forEach(t),Too=r(mLe," \u2014 "),aP=n(mLe,"A",{href:!0});var Mat=s(aP);Moo=r(Mat,"ProphetNetConfig"),Mat.forEach(t),Eoo=r(mLe," (ProphetNet model)"),mLe.forEach(t),Coo=i(L),lg=n(L,"LI",{});var gLe=s(lg);Wne=n(gLe,"STRONG",{});var Eat=s(Wne);woo=r(Eat,"qdqbert"),Eat.forEach(t),Aoo=r(gLe," \u2014 "),nP=n(gLe,"A",{href:!0});var Cat=s(nP);Loo=r(Cat,"QDQBertConfig"),Cat.forEach(t),yoo=r(gLe," (QDQBert model)"),gLe.forEach(t),xoo=i(L),ig=n(L,"LI",{});var hLe=s(ig);Hne=n(hLe,"STRONG",{});var wat=s(Hne);$oo=r(wat,"rag"),wat.forEach(t),koo=r(hLe," \u2014 "),sP=n(hLe,"A",{href:!0});var Aat=s(sP);Soo=r(Aat,"RagConfig"),Aat.forEach(t),Roo=r(hLe," (RAG model)"),hLe.forEach(t),Poo=i(L),dg=n(L,"LI",{});var pLe=s(dg);Une=n(pLe,"STRONG",{});var Lat=s(Une);Boo=r(Lat,"realm"),Lat.forEach(t),Ioo=r(pLe," \u2014 "),lP=n(pLe,"A",{href:!0});var yat=s(lP);Noo=r(yat,"RealmConfig"),yat.forEach(t),qoo=r(pLe," (REALM model)"),pLe.forEach(t),joo=i(L),cg=n(L,"LI",{});var _Le=s(cg);Jne=n(_Le,"STRONG",{});var xat=s(Jne);Doo=r(xat,"reformer"),xat.forEach(t),Goo=r(_Le," \u2014 "),iP=n(_Le,"A",{href:!0});var $at=s(iP);Ooo=r($at,"ReformerConfig"),$at.forEach(t),Voo=r(_Le," (Reformer model)"),_Le.forEach(t),Xoo=i(L),fg=n(L,"LI",{});var uLe=s(fg);Yne=n(uLe,"STRONG",{});var kat=s(Yne);zoo=r(kat,"regnet"),kat.forEach(t),Qoo=r(uLe," \u2014 "),dP=n(uLe,"A",{href:!0});var Sat=s(dP);Woo=r(Sat,"RegNetConfig"),Sat.forEach(t),Hoo=r(uLe," (RegNet model)"),uLe.forEach(t),Uoo=i(L),mg=n(L,"LI",{});var bLe=s(mg);Kne=n(bLe,"STRONG",{});var Rat=s(Kne);Joo=r(Rat,"rembert"),Rat.forEach(t),Yoo=r(bLe," \u2014 "),cP=n(bLe,"A",{href:!0});var Pat=s(cP);Koo=r(Pat,"RemBertConfig"),Pat.forEach(t),Zoo=r(bLe," (RemBERT model)"),bLe.forEach(t),ero=i(L),gg=n(L,"LI",{});var vLe=s(gg);Zne=n(vLe,"STRONG",{});var Bat=s(Zne);oro=r(Bat,"resnet"),Bat.forEach(t),rro=r(vLe," \u2014 "),fP=n(vLe,"A",{href:!0});var Iat=s(fP);tro=r(Iat,"ResNetConfig"),Iat.forEach(t),aro=r(vLe," (ResNet model)"),vLe.forEach(t),nro=i(L),hg=n(L,"LI",{});var FLe=s(hg);ese=n(FLe,"STRONG",{});var Nat=s(ese);sro=r(Nat,"retribert"),Nat.forEach(t),lro=r(FLe," \u2014 "),mP=n(FLe,"A",{href:!0});var qat=s(mP);iro=r(qat,"RetriBertConfig"),qat.forEach(t),dro=r(FLe," (RetriBERT model)"),FLe.forEach(t),cro=i(L),pg=n(L,"LI",{});var TLe=s(pg);ose=n(TLe,"STRONG",{});var jat=s(ose);fro=r(jat,"roberta"),jat.forEach(t),mro=r(TLe," \u2014 "),gP=n(TLe,"A",{href:!0});var Dat=s(gP);gro=r(Dat,"RobertaConfig"),Dat.forEach(t),hro=r(TLe," (RoBERTa model)"),TLe.forEach(t),pro=i(L),_g=n(L,"LI",{});var MLe=s(_g);rse=n(MLe,"STRONG",{});var Gat=s(rse);_ro=r(Gat,"roformer"),Gat.forEach(t),uro=r(MLe," \u2014 "),hP=n(MLe,"A",{href:!0});var Oat=s(hP);bro=r(Oat,"RoFormerConfig"),Oat.forEach(t),vro=r(MLe," (RoFormer model)"),MLe.forEach(t),Fro=i(L),ug=n(L,"LI",{});var ELe=s(ug);tse=n(ELe,"STRONG",{});var Vat=s(tse);Tro=r(Vat,"segformer"),Vat.forEach(t),Mro=r(ELe," \u2014 "),pP=n(ELe,"A",{href:!0});var Xat=s(pP);Ero=r(Xat,"SegformerConfig"),Xat.forEach(t),Cro=r(ELe," (SegFormer model)"),ELe.forEach(t),wro=i(L),bg=n(L,"LI",{});var CLe=s(bg);ase=n(CLe,"STRONG",{});var zat=s(ase);Aro=r(zat,"sew"),zat.forEach(t),Lro=r(CLe," \u2014 "),_P=n(CLe,"A",{href:!0});var Qat=s(_P);yro=r(Qat,"SEWConfig"),Qat.forEach(t),xro=r(CLe," (SEW model)"),CLe.forEach(t),$ro=i(L),vg=n(L,"LI",{});var wLe=s(vg);nse=n(wLe,"STRONG",{});var Wat=s(nse);kro=r(Wat,"sew-d"),Wat.forEach(t),Sro=r(wLe," \u2014 "),uP=n(wLe,"A",{href:!0});var Hat=s(uP);Rro=r(Hat,"SEWDConfig"),Hat.forEach(t),Pro=r(wLe," (SEW-D model)"),wLe.forEach(t),Bro=i(L),Fg=n(L,"LI",{});var ALe=s(Fg);sse=n(ALe,"STRONG",{});var Uat=s(sse);Iro=r(Uat,"speech-encoder-decoder"),Uat.forEach(t),Nro=r(ALe," \u2014 "),bP=n(ALe,"A",{href:!0});var Jat=s(bP);qro=r(Jat,"SpeechEncoderDecoderConfig"),Jat.forEach(t),jro=r(ALe," (Speech Encoder decoder model)"),ALe.forEach(t),Dro=i(L),Tg=n(L,"LI",{});var LLe=s(Tg);lse=n(LLe,"STRONG",{});var Yat=s(lse);Gro=r(Yat,"speech_to_text"),Yat.forEach(t),Oro=r(LLe," \u2014 "),vP=n(LLe,"A",{href:!0});var Kat=s(vP);Vro=r(Kat,"Speech2TextConfig"),Kat.forEach(t),Xro=r(LLe," (Speech2Text model)"),LLe.forEach(t),zro=i(L),Mg=n(L,"LI",{});var yLe=s(Mg);ise=n(yLe,"STRONG",{});var Zat=s(ise);Qro=r(Zat,"speech_to_text_2"),Zat.forEach(t),Wro=r(yLe," \u2014 "),FP=n(yLe,"A",{href:!0});var ent=s(FP);Hro=r(ent,"Speech2Text2Config"),ent.forEach(t),Uro=r(yLe," (Speech2Text2 model)"),yLe.forEach(t),Jro=i(L),Eg=n(L,"LI",{});var xLe=s(Eg);dse=n(xLe,"STRONG",{});var ont=s(dse);Yro=r(ont,"splinter"),ont.forEach(t),Kro=r(xLe," \u2014 "),TP=n(xLe,"A",{href:!0});var rnt=s(TP);Zro=r(rnt,"SplinterConfig"),rnt.forEach(t),eto=r(xLe," (Splinter model)"),xLe.forEach(t),oto=i(L),Cg=n(L,"LI",{});var $Le=s(Cg);cse=n($Le,"STRONG",{});var tnt=s(cse);rto=r(tnt,"squeezebert"),tnt.forEach(t),tto=r($Le," \u2014 "),MP=n($Le,"A",{href:!0});var ant=s(MP);ato=r(ant,"SqueezeBertConfig"),ant.forEach(t),nto=r($Le," (SqueezeBERT model)"),$Le.forEach(t),sto=i(L),wg=n(L,"LI",{});var kLe=s(wg);fse=n(kLe,"STRONG",{});var nnt=s(fse);lto=r(nnt,"swin"),nnt.forEach(t),ito=r(kLe," \u2014 "),EP=n(kLe,"A",{href:!0});var snt=s(EP);dto=r(snt,"SwinConfig"),snt.forEach(t),cto=r(kLe," (Swin Transformer model)"),kLe.forEach(t),fto=i(L),Ag=n(L,"LI",{});var SLe=s(Ag);mse=n(SLe,"STRONG",{});var lnt=s(mse);mto=r(lnt,"t5"),lnt.forEach(t),gto=r(SLe," \u2014 "),CP=n(SLe,"A",{href:!0});var int=s(CP);hto=r(int,"T5Config"),int.forEach(t),pto=r(SLe," (T5 model)"),SLe.forEach(t),_to=i(L),Lg=n(L,"LI",{});var RLe=s(Lg);gse=n(RLe,"STRONG",{});var dnt=s(gse);uto=r(dnt,"tapas"),dnt.forEach(t),bto=r(RLe," \u2014 "),wP=n(RLe,"A",{href:!0});var cnt=s(wP);vto=r(cnt,"TapasConfig"),cnt.forEach(t),Fto=r(RLe," (TAPAS model)"),RLe.forEach(t),Tto=i(L),yg=n(L,"LI",{});var PLe=s(yg);hse=n(PLe,"STRONG",{});var fnt=s(hse);Mto=r(fnt,"trajectory_transformer"),fnt.forEach(t),Eto=r(PLe," \u2014 "),AP=n(PLe,"A",{href:!0});var mnt=s(AP);Cto=r(mnt,"TrajectoryTransformerConfig"),mnt.forEach(t),wto=r(PLe," (Trajectory Transformer model)"),PLe.forEach(t),Ato=i(L),xg=n(L,"LI",{});var BLe=s(xg);pse=n(BLe,"STRONG",{});var gnt=s(pse);Lto=r(gnt,"transfo-xl"),gnt.forEach(t),yto=r(BLe," \u2014 "),LP=n(BLe,"A",{href:!0});var hnt=s(LP);xto=r(hnt,"TransfoXLConfig"),hnt.forEach(t),$to=r(BLe," (Transformer-XL model)"),BLe.forEach(t),kto=i(L),$g=n(L,"LI",{});var ILe=s($g);_se=n(ILe,"STRONG",{});var pnt=s(_se);Sto=r(pnt,"trocr"),pnt.forEach(t),Rto=r(ILe," \u2014 "),yP=n(ILe,"A",{href:!0});var _nt=s(yP);Pto=r(_nt,"TrOCRConfig"),_nt.forEach(t),Bto=r(ILe," (TrOCR model)"),ILe.forEach(t),Ito=i(L),kg=n(L,"LI",{});var NLe=s(kg);use=n(NLe,"STRONG",{});var unt=s(use);Nto=r(unt,"unispeech"),unt.forEach(t),qto=r(NLe," \u2014 "),xP=n(NLe,"A",{href:!0});var bnt=s(xP);jto=r(bnt,"UniSpeechConfig"),bnt.forEach(t),Dto=r(NLe," (UniSpeech model)"),NLe.forEach(t),Gto=i(L),Sg=n(L,"LI",{});var qLe=s(Sg);bse=n(qLe,"STRONG",{});var vnt=s(bse);Oto=r(vnt,"unispeech-sat"),vnt.forEach(t),Vto=r(qLe," \u2014 "),$P=n(qLe,"A",{href:!0});var Fnt=s($P);Xto=r(Fnt,"UniSpeechSatConfig"),Fnt.forEach(t),zto=r(qLe," (UniSpeechSat model)"),qLe.forEach(t),Qto=i(L),Rg=n(L,"LI",{});var jLe=s(Rg);vse=n(jLe,"STRONG",{});var Tnt=s(vse);Wto=r(Tnt,"van"),Tnt.forEach(t),Hto=r(jLe," \u2014 "),kP=n(jLe,"A",{href:!0});var Mnt=s(kP);Uto=r(Mnt,"VanConfig"),Mnt.forEach(t),Jto=r(jLe," (VAN model)"),jLe.forEach(t),Yto=i(L),Pg=n(L,"LI",{});var DLe=s(Pg);Fse=n(DLe,"STRONG",{});var Ent=s(Fse);Kto=r(Ent,"vilt"),Ent.forEach(t),Zto=r(DLe," \u2014 "),SP=n(DLe,"A",{href:!0});var Cnt=s(SP);eao=r(Cnt,"ViltConfig"),Cnt.forEach(t),oao=r(DLe," (ViLT model)"),DLe.forEach(t),rao=i(L),Bg=n(L,"LI",{});var GLe=s(Bg);Tse=n(GLe,"STRONG",{});var wnt=s(Tse);tao=r(wnt,"vision-encoder-decoder"),wnt.forEach(t),aao=r(GLe," \u2014 "),RP=n(GLe,"A",{href:!0});var Ant=s(RP);nao=r(Ant,"VisionEncoderDecoderConfig"),Ant.forEach(t),sao=r(GLe," (Vision Encoder decoder model)"),GLe.forEach(t),lao=i(L),Ig=n(L,"LI",{});var OLe=s(Ig);Mse=n(OLe,"STRONG",{});var Lnt=s(Mse);iao=r(Lnt,"vision-text-dual-encoder"),Lnt.forEach(t),dao=r(OLe," \u2014 "),PP=n(OLe,"A",{href:!0});var ynt=s(PP);cao=r(ynt,"VisionTextDualEncoderConfig"),ynt.forEach(t),fao=r(OLe," (VisionTextDualEncoder model)"),OLe.forEach(t),mao=i(L),Ng=n(L,"LI",{});var VLe=s(Ng);Ese=n(VLe,"STRONG",{});var xnt=s(Ese);gao=r(xnt,"visual_bert"),xnt.forEach(t),hao=r(VLe," \u2014 "),BP=n(VLe,"A",{href:!0});var $nt=s(BP);pao=r($nt,"VisualBertConfig"),$nt.forEach(t),_ao=r(VLe," (VisualBERT model)"),VLe.forEach(t),uao=i(L),qg=n(L,"LI",{});var XLe=s(qg);Cse=n(XLe,"STRONG",{});var knt=s(Cse);bao=r(knt,"vit"),knt.forEach(t),vao=r(XLe," \u2014 "),IP=n(XLe,"A",{href:!0});var Snt=s(IP);Fao=r(Snt,"ViTConfig"),Snt.forEach(t),Tao=r(XLe," (ViT model)"),XLe.forEach(t),Mao=i(L),jg=n(L,"LI",{});var zLe=s(jg);wse=n(zLe,"STRONG",{});var Rnt=s(wse);Eao=r(Rnt,"vit_mae"),Rnt.forEach(t),Cao=r(zLe," \u2014 "),NP=n(zLe,"A",{href:!0});var Pnt=s(NP);wao=r(Pnt,"ViTMAEConfig"),Pnt.forEach(t),Aao=r(zLe," (ViTMAE model)"),zLe.forEach(t),Lao=i(L),Dg=n(L,"LI",{});var QLe=s(Dg);Ase=n(QLe,"STRONG",{});var Bnt=s(Ase);yao=r(Bnt,"wav2vec2"),Bnt.forEach(t),xao=r(QLe," \u2014 "),qP=n(QLe,"A",{href:!0});var Int=s(qP);$ao=r(Int,"Wav2Vec2Config"),Int.forEach(t),kao=r(QLe," (Wav2Vec2 model)"),QLe.forEach(t),Sao=i(L),Gg=n(L,"LI",{});var WLe=s(Gg);Lse=n(WLe,"STRONG",{});var Nnt=s(Lse);Rao=r(Nnt,"wav2vec2-conformer"),Nnt.forEach(t),Pao=r(WLe," \u2014 "),jP=n(WLe,"A",{href:!0});var qnt=s(jP);Bao=r(qnt,"Wav2Vec2ConformerConfig"),qnt.forEach(t),Iao=r(WLe," (Wav2Vec2-Conformer model)"),WLe.forEach(t),Nao=i(L),Og=n(L,"LI",{});var HLe=s(Og);yse=n(HLe,"STRONG",{});var jnt=s(yse);qao=r(jnt,"wavlm"),jnt.forEach(t),jao=r(HLe," \u2014 "),DP=n(HLe,"A",{href:!0});var Dnt=s(DP);Dao=r(Dnt,"WavLMConfig"),Dnt.forEach(t),Gao=r(HLe," (WavLM model)"),HLe.forEach(t),Oao=i(L),Vg=n(L,"LI",{});var ULe=s(Vg);xse=n(ULe,"STRONG",{});var Gnt=s(xse);Vao=r(Gnt,"xglm"),Gnt.forEach(t),Xao=r(ULe," \u2014 "),GP=n(ULe,"A",{href:!0});var Ont=s(GP);zao=r(Ont,"XGLMConfig"),Ont.forEach(t),Qao=r(ULe," (XGLM model)"),ULe.forEach(t),Wao=i(L),Xg=n(L,"LI",{});var JLe=s(Xg);$se=n(JLe,"STRONG",{});var Vnt=s($se);Hao=r(Vnt,"xlm"),Vnt.forEach(t),Uao=r(JLe," \u2014 "),OP=n(JLe,"A",{href:!0});var Xnt=s(OP);Jao=r(Xnt,"XLMConfig"),Xnt.forEach(t),Yao=r(JLe," (XLM model)"),JLe.forEach(t),Kao=i(L),zg=n(L,"LI",{});var YLe=s(zg);kse=n(YLe,"STRONG",{});var znt=s(kse);Zao=r(znt,"xlm-prophetnet"),znt.forEach(t),eno=r(YLe," \u2014 "),VP=n(YLe,"A",{href:!0});var Qnt=s(VP);ono=r(Qnt,"XLMProphetNetConfig"),Qnt.forEach(t),rno=r(YLe," (XLM-ProphetNet model)"),YLe.forEach(t),tno=i(L),Qg=n(L,"LI",{});var KLe=s(Qg);Sse=n(KLe,"STRONG",{});var Wnt=s(Sse);ano=r(Wnt,"xlm-roberta"),Wnt.forEach(t),nno=r(KLe," \u2014 "),XP=n(KLe,"A",{href:!0});var Hnt=s(XP);sno=r(Hnt,"XLMRobertaConfig"),Hnt.forEach(t),lno=r(KLe," (XLM-RoBERTa model)"),KLe.forEach(t),ino=i(L),Wg=n(L,"LI",{});var ZLe=s(Wg);Rse=n(ZLe,"STRONG",{});var Unt=s(Rse);dno=r(Unt,"xlm-roberta-xl"),Unt.forEach(t),cno=r(ZLe," \u2014 "),zP=n(ZLe,"A",{href:!0});var Jnt=s(zP);fno=r(Jnt,"XLMRobertaXLConfig"),Jnt.forEach(t),mno=r(ZLe," (XLM-RoBERTa-XL model)"),ZLe.forEach(t),gno=i(L),Hg=n(L,"LI",{});var eye=s(Hg);Pse=n(eye,"STRONG",{});var Ynt=s(Pse);hno=r(Ynt,"xlnet"),Ynt.forEach(t),pno=r(eye," \u2014 "),QP=n(eye,"A",{href:!0});var Knt=s(QP);_no=r(Knt,"XLNetConfig"),Knt.forEach(t),uno=r(eye," (XLNet model)"),eye.forEach(t),bno=i(L),Ug=n(L,"LI",{});var oye=s(Ug);Bse=n(oye,"STRONG",{});var Znt=s(Bse);vno=r(Znt,"yolos"),Znt.forEach(t),Fno=r(oye," \u2014 "),WP=n(oye,"A",{href:!0});var est=s(WP);Tno=r(est,"YolosConfig"),est.forEach(t),Mno=r(oye," (YOLOS model)"),oye.forEach(t),Eno=i(L),Jg=n(L,"LI",{});var rye=s(Jg);Ise=n(rye,"STRONG",{});var ost=s(Ise);Cno=r(ost,"yoso"),ost.forEach(t),wno=r(rye," \u2014 "),HP=n(rye,"A",{href:!0});var rst=s(HP);Ano=r(rst,"YosoConfig"),rst.forEach(t),Lno=r(rye," (YOSO model)"),rye.forEach(t),L.forEach(t),yno=i(nt),T(Yg.$$.fragment,nt),nt.forEach(t),xno=i(at),Kg=n(at,"DIV",{class:!0});var Xze=s(Kg);T(iL.$$.fragment,Xze),$no=i(Xze),Nse=n(Xze,"P",{});var tst=s(Nse);kno=r(tst,"Register a new configuration for this class."),tst.forEach(t),Xze.forEach(t),at.forEach(t),zVe=i(f),Ii=n(f,"H2",{class:!0});var zze=s(Ii);Zg=n(zze,"A",{id:!0,class:!0,href:!0});var ast=s(Zg);qse=n(ast,"SPAN",{});var nst=s(qse);T(dL.$$.fragment,nst),nst.forEach(t),ast.forEach(t),Sno=i(zze),jse=n(zze,"SPAN",{});var sst=s(jse);Rno=r(sst,"AutoTokenizer"),sst.forEach(t),zze.forEach(t),QVe=i(f),Ao=n(f,"DIV",{class:!0});var Js=s(Ao);T(cL.$$.fragment,Js),Pno=i(Js),fL=n(Js,"P",{});var Qze=s(fL);Bno=r(Qze,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),UP=n(Qze,"A",{href:!0});var lst=s(UP);Ino=r(lst,"AutoTokenizer.from_pretrained()"),lst.forEach(t),Nno=r(Qze," class method."),Qze.forEach(t),qno=i(Js),mL=n(Js,"P",{});var Wze=s(mL);jno=r(Wze,"This class cannot be instantiated directly using "),Dse=n(Wze,"CODE",{});var ist=s(Dse);Dno=r(ist,"__init__()"),ist.forEach(t),Gno=r(Wze," (throws an error)."),Wze.forEach(t),Ono=i(Js),Lr=n(Js,"DIV",{class:!0});var Ys=s(Lr);T(gL.$$.fragment,Ys),Vno=i(Ys),Gse=n(Ys,"P",{});var dst=s(Gse);Xno=r(dst,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),dst.forEach(t),zno=i(Ys),Ra=n(Ys,"P",{});var tA=s(Ra);Qno=r(tA,"The tokenizer class to instantiate is selected based on the "),Ose=n(tA,"CODE",{});var cst=s(Ose);Wno=r(cst,"model_type"),cst.forEach(t),Hno=r(tA,` property of the config object (either
passed as an argument or loaded from `),Vse=n(tA,"CODE",{});var fst=s(Vse);Uno=r(fst,"pretrained_model_name_or_path"),fst.forEach(t),Jno=r(tA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xse=n(tA,"CODE",{});var mst=s(Xse);Yno=r(mst,"pretrained_model_name_or_path"),mst.forEach(t),Kno=r(tA,":"),tA.forEach(t),Zno=i(Ys),k=n(Ys,"UL",{});var S=s(k);qn=n(S,"LI",{});var vk=s(qn);zse=n(vk,"STRONG",{});var gst=s(zse);eso=r(gst,"albert"),gst.forEach(t),oso=r(vk," \u2014 "),JP=n(vk,"A",{href:!0});var hst=s(JP);rso=r(hst,"AlbertTokenizer"),hst.forEach(t),tso=r(vk," or "),YP=n(vk,"A",{href:!0});var pst=s(YP);aso=r(pst,"AlbertTokenizerFast"),pst.forEach(t),nso=r(vk," (ALBERT model)"),vk.forEach(t),sso=i(S),jn=n(S,"LI",{});var Fk=s(jn);Qse=n(Fk,"STRONG",{});var _st=s(Qse);lso=r(_st,"bart"),_st.forEach(t),iso=r(Fk," \u2014 "),KP=n(Fk,"A",{href:!0});var ust=s(KP);dso=r(ust,"BartTokenizer"),ust.forEach(t),cso=r(Fk," or "),ZP=n(Fk,"A",{href:!0});var bst=s(ZP);fso=r(bst,"BartTokenizerFast"),bst.forEach(t),mso=r(Fk," (BART model)"),Fk.forEach(t),gso=i(S),Dn=n(S,"LI",{});var Tk=s(Dn);Wse=n(Tk,"STRONG",{});var vst=s(Wse);hso=r(vst,"barthez"),vst.forEach(t),pso=r(Tk," \u2014 "),eB=n(Tk,"A",{href:!0});var Fst=s(eB);_so=r(Fst,"BarthezTokenizer"),Fst.forEach(t),uso=r(Tk," or "),oB=n(Tk,"A",{href:!0});var Tst=s(oB);bso=r(Tst,"BarthezTokenizerFast"),Tst.forEach(t),vso=r(Tk," (BARThez model)"),Tk.forEach(t),Fso=i(S),eh=n(S,"LI",{});var tye=s(eh);Hse=n(tye,"STRONG",{});var Mst=s(Hse);Tso=r(Mst,"bartpho"),Mst.forEach(t),Mso=r(tye," \u2014 "),rB=n(tye,"A",{href:!0});var Est=s(rB);Eso=r(Est,"BartphoTokenizer"),Est.forEach(t),Cso=r(tye," (BARTpho model)"),tye.forEach(t),wso=i(S),Gn=n(S,"LI",{});var Mk=s(Gn);Use=n(Mk,"STRONG",{});var Cst=s(Use);Aso=r(Cst,"bert"),Cst.forEach(t),Lso=r(Mk," \u2014 "),tB=n(Mk,"A",{href:!0});var wst=s(tB);yso=r(wst,"BertTokenizer"),wst.forEach(t),xso=r(Mk," or "),aB=n(Mk,"A",{href:!0});var Ast=s(aB);$so=r(Ast,"BertTokenizerFast"),Ast.forEach(t),kso=r(Mk," (BERT model)"),Mk.forEach(t),Sso=i(S),oh=n(S,"LI",{});var aye=s(oh);Jse=n(aye,"STRONG",{});var Lst=s(Jse);Rso=r(Lst,"bert-generation"),Lst.forEach(t),Pso=r(aye," \u2014 "),nB=n(aye,"A",{href:!0});var yst=s(nB);Bso=r(yst,"BertGenerationTokenizer"),yst.forEach(t),Iso=r(aye," (Bert Generation model)"),aye.forEach(t),Nso=i(S),rh=n(S,"LI",{});var nye=s(rh);Yse=n(nye,"STRONG",{});var xst=s(Yse);qso=r(xst,"bert-japanese"),xst.forEach(t),jso=r(nye," \u2014 "),sB=n(nye,"A",{href:!0});var $st=s(sB);Dso=r($st,"BertJapaneseTokenizer"),$st.forEach(t),Gso=r(nye," (BertJapanese model)"),nye.forEach(t),Oso=i(S),th=n(S,"LI",{});var sye=s(th);Kse=n(sye,"STRONG",{});var kst=s(Kse);Vso=r(kst,"bertweet"),kst.forEach(t),Xso=r(sye," \u2014 "),lB=n(sye,"A",{href:!0});var Sst=s(lB);zso=r(Sst,"BertweetTokenizer"),Sst.forEach(t),Qso=r(sye," (BERTweet model)"),sye.forEach(t),Wso=i(S),On=n(S,"LI",{});var Ek=s(On);Zse=n(Ek,"STRONG",{});var Rst=s(Zse);Hso=r(Rst,"big_bird"),Rst.forEach(t),Uso=r(Ek," \u2014 "),iB=n(Ek,"A",{href:!0});var Pst=s(iB);Jso=r(Pst,"BigBirdTokenizer"),Pst.forEach(t),Yso=r(Ek," or "),dB=n(Ek,"A",{href:!0});var Bst=s(dB);Kso=r(Bst,"BigBirdTokenizerFast"),Bst.forEach(t),Zso=r(Ek," (BigBird model)"),Ek.forEach(t),elo=i(S),Vn=n(S,"LI",{});var Ck=s(Vn);ele=n(Ck,"STRONG",{});var Ist=s(ele);olo=r(Ist,"bigbird_pegasus"),Ist.forEach(t),rlo=r(Ck," \u2014 "),cB=n(Ck,"A",{href:!0});var Nst=s(cB);tlo=r(Nst,"PegasusTokenizer"),Nst.forEach(t),alo=r(Ck," or "),fB=n(Ck,"A",{href:!0});var qst=s(fB);nlo=r(qst,"PegasusTokenizerFast"),qst.forEach(t),slo=r(Ck," (BigBird-Pegasus model)"),Ck.forEach(t),llo=i(S),Xn=n(S,"LI",{});var wk=s(Xn);ole=n(wk,"STRONG",{});var jst=s(ole);ilo=r(jst,"blenderbot"),jst.forEach(t),dlo=r(wk," \u2014 "),mB=n(wk,"A",{href:!0});var Dst=s(mB);clo=r(Dst,"BlenderbotTokenizer"),Dst.forEach(t),flo=r(wk," or "),gB=n(wk,"A",{href:!0});var Gst=s(gB);mlo=r(Gst,"BlenderbotTokenizerFast"),Gst.forEach(t),glo=r(wk," (Blenderbot model)"),wk.forEach(t),hlo=i(S),ah=n(S,"LI",{});var lye=s(ah);rle=n(lye,"STRONG",{});var Ost=s(rle);plo=r(Ost,"blenderbot-small"),Ost.forEach(t),_lo=r(lye," \u2014 "),hB=n(lye,"A",{href:!0});var Vst=s(hB);ulo=r(Vst,"BlenderbotSmallTokenizer"),Vst.forEach(t),blo=r(lye," (BlenderbotSmall model)"),lye.forEach(t),vlo=i(S),nh=n(S,"LI",{});var iye=s(nh);tle=n(iye,"STRONG",{});var Xst=s(tle);Flo=r(Xst,"bloom"),Xst.forEach(t),Tlo=r(iye," \u2014 "),pB=n(iye,"A",{href:!0});var zst=s(pB);Mlo=r(zst,"BloomTokenizerFast"),zst.forEach(t),Elo=r(iye," (BLOOM model)"),iye.forEach(t),Clo=i(S),sh=n(S,"LI",{});var dye=s(sh);ale=n(dye,"STRONG",{});var Qst=s(ale);wlo=r(Qst,"byt5"),Qst.forEach(t),Alo=r(dye," \u2014 "),_B=n(dye,"A",{href:!0});var Wst=s(_B);Llo=r(Wst,"ByT5Tokenizer"),Wst.forEach(t),ylo=r(dye," (ByT5 model)"),dye.forEach(t),xlo=i(S),zn=n(S,"LI",{});var Ak=s(zn);nle=n(Ak,"STRONG",{});var Hst=s(nle);$lo=r(Hst,"camembert"),Hst.forEach(t),klo=r(Ak," \u2014 "),uB=n(Ak,"A",{href:!0});var Ust=s(uB);Slo=r(Ust,"CamembertTokenizer"),Ust.forEach(t),Rlo=r(Ak," or "),bB=n(Ak,"A",{href:!0});var Jst=s(bB);Plo=r(Jst,"CamembertTokenizerFast"),Jst.forEach(t),Blo=r(Ak," (CamemBERT model)"),Ak.forEach(t),Ilo=i(S),lh=n(S,"LI",{});var cye=s(lh);sle=n(cye,"STRONG",{});var Yst=s(sle);Nlo=r(Yst,"canine"),Yst.forEach(t),qlo=r(cye," \u2014 "),vB=n(cye,"A",{href:!0});var Kst=s(vB);jlo=r(Kst,"CanineTokenizer"),Kst.forEach(t),Dlo=r(cye," (CANINE model)"),cye.forEach(t),Glo=i(S),Qn=n(S,"LI",{});var Lk=s(Qn);lle=n(Lk,"STRONG",{});var Zst=s(lle);Olo=r(Zst,"clip"),Zst.forEach(t),Vlo=r(Lk," \u2014 "),FB=n(Lk,"A",{href:!0});var elt=s(FB);Xlo=r(elt,"CLIPTokenizer"),elt.forEach(t),zlo=r(Lk," or "),TB=n(Lk,"A",{href:!0});var olt=s(TB);Qlo=r(olt,"CLIPTokenizerFast"),olt.forEach(t),Wlo=r(Lk," (CLIP model)"),Lk.forEach(t),Hlo=i(S),Wn=n(S,"LI",{});var yk=s(Wn);ile=n(yk,"STRONG",{});var rlt=s(ile);Ulo=r(rlt,"codegen"),rlt.forEach(t),Jlo=r(yk," \u2014 "),MB=n(yk,"A",{href:!0});var tlt=s(MB);Ylo=r(tlt,"CodeGenTokenizer"),tlt.forEach(t),Klo=r(yk," or "),EB=n(yk,"A",{href:!0});var alt=s(EB);Zlo=r(alt,"CodeGenTokenizerFast"),alt.forEach(t),eio=r(yk," (CodeGen model)"),yk.forEach(t),oio=i(S),Hn=n(S,"LI",{});var xk=s(Hn);dle=n(xk,"STRONG",{});var nlt=s(dle);rio=r(nlt,"convbert"),nlt.forEach(t),tio=r(xk," \u2014 "),CB=n(xk,"A",{href:!0});var slt=s(CB);aio=r(slt,"ConvBertTokenizer"),slt.forEach(t),nio=r(xk," or "),wB=n(xk,"A",{href:!0});var llt=s(wB);sio=r(llt,"ConvBertTokenizerFast"),llt.forEach(t),lio=r(xk," (ConvBERT model)"),xk.forEach(t),iio=i(S),Un=n(S,"LI",{});var $k=s(Un);cle=n($k,"STRONG",{});var ilt=s(cle);dio=r(ilt,"cpm"),ilt.forEach(t),cio=r($k," \u2014 "),AB=n($k,"A",{href:!0});var dlt=s(AB);fio=r(dlt,"CpmTokenizer"),dlt.forEach(t),mio=r($k," or "),LB=n($k,"A",{href:!0});var clt=s(LB);gio=r(clt,"CpmTokenizerFast"),clt.forEach(t),hio=r($k," (CPM model)"),$k.forEach(t),pio=i(S),ih=n(S,"LI",{});var fye=s(ih);fle=n(fye,"STRONG",{});var flt=s(fle);_io=r(flt,"ctrl"),flt.forEach(t),uio=r(fye," \u2014 "),yB=n(fye,"A",{href:!0});var mlt=s(yB);bio=r(mlt,"CTRLTokenizer"),mlt.forEach(t),vio=r(fye," (CTRL model)"),fye.forEach(t),Fio=i(S),Jn=n(S,"LI",{});var kk=s(Jn);mle=n(kk,"STRONG",{});var glt=s(mle);Tio=r(glt,"data2vec-text"),glt.forEach(t),Mio=r(kk," \u2014 "),xB=n(kk,"A",{href:!0});var hlt=s(xB);Eio=r(hlt,"RobertaTokenizer"),hlt.forEach(t),Cio=r(kk," or "),$B=n(kk,"A",{href:!0});var plt=s($B);wio=r(plt,"RobertaTokenizerFast"),plt.forEach(t),Aio=r(kk," (Data2VecText model)"),kk.forEach(t),Lio=i(S),Yn=n(S,"LI",{});var Sk=s(Yn);gle=n(Sk,"STRONG",{});var _lt=s(gle);yio=r(_lt,"deberta"),_lt.forEach(t),xio=r(Sk," \u2014 "),kB=n(Sk,"A",{href:!0});var ult=s(kB);$io=r(ult,"DebertaTokenizer"),ult.forEach(t),kio=r(Sk," or "),SB=n(Sk,"A",{href:!0});var blt=s(SB);Sio=r(blt,"DebertaTokenizerFast"),blt.forEach(t),Rio=r(Sk," (DeBERTa model)"),Sk.forEach(t),Pio=i(S),Kn=n(S,"LI",{});var Rk=s(Kn);hle=n(Rk,"STRONG",{});var vlt=s(hle);Bio=r(vlt,"deberta-v2"),vlt.forEach(t),Iio=r(Rk," \u2014 "),RB=n(Rk,"A",{href:!0});var Flt=s(RB);Nio=r(Flt,"DebertaV2Tokenizer"),Flt.forEach(t),qio=r(Rk," or "),PB=n(Rk,"A",{href:!0});var Tlt=s(PB);jio=r(Tlt,"DebertaV2TokenizerFast"),Tlt.forEach(t),Dio=r(Rk," (DeBERTa-v2 model)"),Rk.forEach(t),Gio=i(S),Zn=n(S,"LI",{});var Pk=s(Zn);ple=n(Pk,"STRONG",{});var Mlt=s(ple);Oio=r(Mlt,"distilbert"),Mlt.forEach(t),Vio=r(Pk," \u2014 "),BB=n(Pk,"A",{href:!0});var Elt=s(BB);Xio=r(Elt,"DistilBertTokenizer"),Elt.forEach(t),zio=r(Pk," or "),IB=n(Pk,"A",{href:!0});var Clt=s(IB);Qio=r(Clt,"DistilBertTokenizerFast"),Clt.forEach(t),Wio=r(Pk," (DistilBERT model)"),Pk.forEach(t),Hio=i(S),es=n(S,"LI",{});var Bk=s(es);_le=n(Bk,"STRONG",{});var wlt=s(_le);Uio=r(wlt,"dpr"),wlt.forEach(t),Jio=r(Bk," \u2014 "),NB=n(Bk,"A",{href:!0});var Alt=s(NB);Yio=r(Alt,"DPRQuestionEncoderTokenizer"),Alt.forEach(t),Kio=r(Bk," or "),qB=n(Bk,"A",{href:!0});var Llt=s(qB);Zio=r(Llt,"DPRQuestionEncoderTokenizerFast"),Llt.forEach(t),edo=r(Bk," (DPR model)"),Bk.forEach(t),odo=i(S),os=n(S,"LI",{});var Ik=s(os);ule=n(Ik,"STRONG",{});var ylt=s(ule);rdo=r(ylt,"electra"),ylt.forEach(t),tdo=r(Ik," \u2014 "),jB=n(Ik,"A",{href:!0});var xlt=s(jB);ado=r(xlt,"ElectraTokenizer"),xlt.forEach(t),ndo=r(Ik," or "),DB=n(Ik,"A",{href:!0});var $lt=s(DB);sdo=r($lt,"ElectraTokenizerFast"),$lt.forEach(t),ldo=r(Ik," (ELECTRA model)"),Ik.forEach(t),ido=i(S),dh=n(S,"LI",{});var mye=s(dh);ble=n(mye,"STRONG",{});var klt=s(ble);ddo=r(klt,"flaubert"),klt.forEach(t),cdo=r(mye," \u2014 "),GB=n(mye,"A",{href:!0});var Slt=s(GB);fdo=r(Slt,"FlaubertTokenizer"),Slt.forEach(t),mdo=r(mye," (FlauBERT model)"),mye.forEach(t),gdo=i(S),rs=n(S,"LI",{});var Nk=s(rs);vle=n(Nk,"STRONG",{});var Rlt=s(vle);hdo=r(Rlt,"fnet"),Rlt.forEach(t),pdo=r(Nk," \u2014 "),OB=n(Nk,"A",{href:!0});var Plt=s(OB);_do=r(Plt,"FNetTokenizer"),Plt.forEach(t),udo=r(Nk," or "),VB=n(Nk,"A",{href:!0});var Blt=s(VB);bdo=r(Blt,"FNetTokenizerFast"),Blt.forEach(t),vdo=r(Nk," (FNet model)"),Nk.forEach(t),Fdo=i(S),ch=n(S,"LI",{});var gye=s(ch);Fle=n(gye,"STRONG",{});var Ilt=s(Fle);Tdo=r(Ilt,"fsmt"),Ilt.forEach(t),Mdo=r(gye," \u2014 "),XB=n(gye,"A",{href:!0});var Nlt=s(XB);Edo=r(Nlt,"FSMTTokenizer"),Nlt.forEach(t),Cdo=r(gye," (FairSeq Machine-Translation model)"),gye.forEach(t),wdo=i(S),ts=n(S,"LI",{});var qk=s(ts);Tle=n(qk,"STRONG",{});var qlt=s(Tle);Ado=r(qlt,"funnel"),qlt.forEach(t),Ldo=r(qk," \u2014 "),zB=n(qk,"A",{href:!0});var jlt=s(zB);ydo=r(jlt,"FunnelTokenizer"),jlt.forEach(t),xdo=r(qk," or "),QB=n(qk,"A",{href:!0});var Dlt=s(QB);$do=r(Dlt,"FunnelTokenizerFast"),Dlt.forEach(t),kdo=r(qk," (Funnel Transformer model)"),qk.forEach(t),Sdo=i(S),as=n(S,"LI",{});var jk=s(as);Mle=n(jk,"STRONG",{});var Glt=s(Mle);Rdo=r(Glt,"gpt2"),Glt.forEach(t),Pdo=r(jk," \u2014 "),WB=n(jk,"A",{href:!0});var Olt=s(WB);Bdo=r(Olt,"GPT2Tokenizer"),Olt.forEach(t),Ido=r(jk," or "),HB=n(jk,"A",{href:!0});var Vlt=s(HB);Ndo=r(Vlt,"GPT2TokenizerFast"),Vlt.forEach(t),qdo=r(jk," (OpenAI GPT-2 model)"),jk.forEach(t),jdo=i(S),ns=n(S,"LI",{});var Dk=s(ns);Ele=n(Dk,"STRONG",{});var Xlt=s(Ele);Ddo=r(Xlt,"gpt_neo"),Xlt.forEach(t),Gdo=r(Dk," \u2014 "),UB=n(Dk,"A",{href:!0});var zlt=s(UB);Odo=r(zlt,"GPT2Tokenizer"),zlt.forEach(t),Vdo=r(Dk," or "),JB=n(Dk,"A",{href:!0});var Qlt=s(JB);Xdo=r(Qlt,"GPT2TokenizerFast"),Qlt.forEach(t),zdo=r(Dk," (GPT Neo model)"),Dk.forEach(t),Qdo=i(S),fh=n(S,"LI",{});var hye=s(fh);Cle=n(hye,"STRONG",{});var Wlt=s(Cle);Wdo=r(Wlt,"gpt_neox"),Wlt.forEach(t),Hdo=r(hye," \u2014 "),YB=n(hye,"A",{href:!0});var Hlt=s(YB);Udo=r(Hlt,"GPTNeoXTokenizerFast"),Hlt.forEach(t),Jdo=r(hye," (GPT NeoX model)"),hye.forEach(t),Ydo=i(S),ss=n(S,"LI",{});var Gk=s(ss);wle=n(Gk,"STRONG",{});var Ult=s(wle);Kdo=r(Ult,"gptj"),Ult.forEach(t),Zdo=r(Gk," \u2014 "),KB=n(Gk,"A",{href:!0});var Jlt=s(KB);eco=r(Jlt,"GPT2Tokenizer"),Jlt.forEach(t),oco=r(Gk," or "),ZB=n(Gk,"A",{href:!0});var Ylt=s(ZB);rco=r(Ylt,"GPT2TokenizerFast"),Ylt.forEach(t),tco=r(Gk," (GPT-J model)"),Gk.forEach(t),aco=i(S),ls=n(S,"LI",{});var Ok=s(ls);Ale=n(Ok,"STRONG",{});var Klt=s(Ale);nco=r(Klt,"groupvit"),Klt.forEach(t),sco=r(Ok," \u2014 "),eI=n(Ok,"A",{href:!0});var Zlt=s(eI);lco=r(Zlt,"CLIPTokenizer"),Zlt.forEach(t),ico=r(Ok," or "),oI=n(Ok,"A",{href:!0});var eit=s(oI);dco=r(eit,"CLIPTokenizerFast"),eit.forEach(t),cco=r(Ok," (GroupViT model)"),Ok.forEach(t),fco=i(S),is=n(S,"LI",{});var Vk=s(is);Lle=n(Vk,"STRONG",{});var oit=s(Lle);mco=r(oit,"herbert"),oit.forEach(t),gco=r(Vk," \u2014 "),rI=n(Vk,"A",{href:!0});var rit=s(rI);hco=r(rit,"HerbertTokenizer"),rit.forEach(t),pco=r(Vk," or "),tI=n(Vk,"A",{href:!0});var tit=s(tI);_co=r(tit,"HerbertTokenizerFast"),tit.forEach(t),uco=r(Vk," (HerBERT model)"),Vk.forEach(t),bco=i(S),mh=n(S,"LI",{});var pye=s(mh);yle=n(pye,"STRONG",{});var ait=s(yle);vco=r(ait,"hubert"),ait.forEach(t),Fco=r(pye," \u2014 "),aI=n(pye,"A",{href:!0});var nit=s(aI);Tco=r(nit,"Wav2Vec2CTCTokenizer"),nit.forEach(t),Mco=r(pye," (Hubert model)"),pye.forEach(t),Eco=i(S),ds=n(S,"LI",{});var Xk=s(ds);xle=n(Xk,"STRONG",{});var sit=s(xle);Cco=r(sit,"ibert"),sit.forEach(t),wco=r(Xk," \u2014 "),nI=n(Xk,"A",{href:!0});var lit=s(nI);Aco=r(lit,"RobertaTokenizer"),lit.forEach(t),Lco=r(Xk," or "),sI=n(Xk,"A",{href:!0});var iit=s(sI);yco=r(iit,"RobertaTokenizerFast"),iit.forEach(t),xco=r(Xk," (I-BERT model)"),Xk.forEach(t),$co=i(S),cs=n(S,"LI",{});var zk=s(cs);$le=n(zk,"STRONG",{});var dit=s($le);kco=r(dit,"layoutlm"),dit.forEach(t),Sco=r(zk," \u2014 "),lI=n(zk,"A",{href:!0});var cit=s(lI);Rco=r(cit,"LayoutLMTokenizer"),cit.forEach(t),Pco=r(zk," or "),iI=n(zk,"A",{href:!0});var fit=s(iI);Bco=r(fit,"LayoutLMTokenizerFast"),fit.forEach(t),Ico=r(zk," (LayoutLM model)"),zk.forEach(t),Nco=i(S),fs=n(S,"LI",{});var Qk=s(fs);kle=n(Qk,"STRONG",{});var mit=s(kle);qco=r(mit,"layoutlmv2"),mit.forEach(t),jco=r(Qk," \u2014 "),dI=n(Qk,"A",{href:!0});var git=s(dI);Dco=r(git,"LayoutLMv2Tokenizer"),git.forEach(t),Gco=r(Qk," or "),cI=n(Qk,"A",{href:!0});var hit=s(cI);Oco=r(hit,"LayoutLMv2TokenizerFast"),hit.forEach(t),Vco=r(Qk," (LayoutLMv2 model)"),Qk.forEach(t),Xco=i(S),ms=n(S,"LI",{});var Wk=s(ms);Sle=n(Wk,"STRONG",{});var pit=s(Sle);zco=r(pit,"layoutlmv3"),pit.forEach(t),Qco=r(Wk," \u2014 "),fI=n(Wk,"A",{href:!0});var _it=s(fI);Wco=r(_it,"LayoutLMv3Tokenizer"),_it.forEach(t),Hco=r(Wk," or "),mI=n(Wk,"A",{href:!0});var uit=s(mI);Uco=r(uit,"LayoutLMv3TokenizerFast"),uit.forEach(t),Jco=r(Wk," (LayoutLMv3 model)"),Wk.forEach(t),Yco=i(S),gs=n(S,"LI",{});var Hk=s(gs);Rle=n(Hk,"STRONG",{});var bit=s(Rle);Kco=r(bit,"layoutxlm"),bit.forEach(t),Zco=r(Hk," \u2014 "),gI=n(Hk,"A",{href:!0});var vit=s(gI);efo=r(vit,"LayoutXLMTokenizer"),vit.forEach(t),ofo=r(Hk," or "),hI=n(Hk,"A",{href:!0});var Fit=s(hI);rfo=r(Fit,"LayoutXLMTokenizerFast"),Fit.forEach(t),tfo=r(Hk," (LayoutXLM model)"),Hk.forEach(t),afo=i(S),hs=n(S,"LI",{});var Uk=s(hs);Ple=n(Uk,"STRONG",{});var Tit=s(Ple);nfo=r(Tit,"led"),Tit.forEach(t),sfo=r(Uk," \u2014 "),pI=n(Uk,"A",{href:!0});var Mit=s(pI);lfo=r(Mit,"LEDTokenizer"),Mit.forEach(t),ifo=r(Uk," or "),_I=n(Uk,"A",{href:!0});var Eit=s(_I);dfo=r(Eit,"LEDTokenizerFast"),Eit.forEach(t),cfo=r(Uk," (LED model)"),Uk.forEach(t),ffo=i(S),ps=n(S,"LI",{});var Jk=s(ps);Ble=n(Jk,"STRONG",{});var Cit=s(Ble);mfo=r(Cit,"longformer"),Cit.forEach(t),gfo=r(Jk," \u2014 "),uI=n(Jk,"A",{href:!0});var wit=s(uI);hfo=r(wit,"LongformerTokenizer"),wit.forEach(t),pfo=r(Jk," or "),bI=n(Jk,"A",{href:!0});var Ait=s(bI);_fo=r(Ait,"LongformerTokenizerFast"),Ait.forEach(t),ufo=r(Jk," (Longformer model)"),Jk.forEach(t),bfo=i(S),_s=n(S,"LI",{});var Yk=s(_s);Ile=n(Yk,"STRONG",{});var Lit=s(Ile);vfo=r(Lit,"longt5"),Lit.forEach(t),Ffo=r(Yk," \u2014 "),vI=n(Yk,"A",{href:!0});var yit=s(vI);Tfo=r(yit,"T5Tokenizer"),yit.forEach(t),Mfo=r(Yk," or "),FI=n(Yk,"A",{href:!0});var xit=s(FI);Efo=r(xit,"T5TokenizerFast"),xit.forEach(t),Cfo=r(Yk," (LongT5 model)"),Yk.forEach(t),wfo=i(S),gh=n(S,"LI",{});var _ye=s(gh);Nle=n(_ye,"STRONG",{});var $it=s(Nle);Afo=r($it,"luke"),$it.forEach(t),Lfo=r(_ye," \u2014 "),TI=n(_ye,"A",{href:!0});var kit=s(TI);yfo=r(kit,"LukeTokenizer"),kit.forEach(t),xfo=r(_ye," (LUKE model)"),_ye.forEach(t),$fo=i(S),us=n(S,"LI",{});var Kk=s(us);qle=n(Kk,"STRONG",{});var Sit=s(qle);kfo=r(Sit,"lxmert"),Sit.forEach(t),Sfo=r(Kk," \u2014 "),MI=n(Kk,"A",{href:!0});var Rit=s(MI);Rfo=r(Rit,"LxmertTokenizer"),Rit.forEach(t),Pfo=r(Kk," or "),EI=n(Kk,"A",{href:!0});var Pit=s(EI);Bfo=r(Pit,"LxmertTokenizerFast"),Pit.forEach(t),Ifo=r(Kk," (LXMERT model)"),Kk.forEach(t),Nfo=i(S),hh=n(S,"LI",{});var uye=s(hh);jle=n(uye,"STRONG",{});var Bit=s(jle);qfo=r(Bit,"m2m_100"),Bit.forEach(t),jfo=r(uye," \u2014 "),CI=n(uye,"A",{href:!0});var Iit=s(CI);Dfo=r(Iit,"M2M100Tokenizer"),Iit.forEach(t),Gfo=r(uye," (M2M100 model)"),uye.forEach(t),Ofo=i(S),ph=n(S,"LI",{});var bye=s(ph);Dle=n(bye,"STRONG",{});var Nit=s(Dle);Vfo=r(Nit,"marian"),Nit.forEach(t),Xfo=r(bye," \u2014 "),wI=n(bye,"A",{href:!0});var qit=s(wI);zfo=r(qit,"MarianTokenizer"),qit.forEach(t),Qfo=r(bye," (Marian model)"),bye.forEach(t),Wfo=i(S),bs=n(S,"LI",{});var Zk=s(bs);Gle=n(Zk,"STRONG",{});var jit=s(Gle);Hfo=r(jit,"mbart"),jit.forEach(t),Ufo=r(Zk," \u2014 "),AI=n(Zk,"A",{href:!0});var Dit=s(AI);Jfo=r(Dit,"MBartTokenizer"),Dit.forEach(t),Yfo=r(Zk," or "),LI=n(Zk,"A",{href:!0});var Git=s(LI);Kfo=r(Git,"MBartTokenizerFast"),Git.forEach(t),Zfo=r(Zk," (mBART model)"),Zk.forEach(t),emo=i(S),vs=n(S,"LI",{});var eS=s(vs);Ole=n(eS,"STRONG",{});var Oit=s(Ole);omo=r(Oit,"mbart50"),Oit.forEach(t),rmo=r(eS," \u2014 "),yI=n(eS,"A",{href:!0});var Vit=s(yI);tmo=r(Vit,"MBart50Tokenizer"),Vit.forEach(t),amo=r(eS," or "),xI=n(eS,"A",{href:!0});var Xit=s(xI);nmo=r(Xit,"MBart50TokenizerFast"),Xit.forEach(t),smo=r(eS," (mBART-50 model)"),eS.forEach(t),lmo=i(S),Fs=n(S,"LI",{});var oS=s(Fs);Vle=n(oS,"STRONG",{});var zit=s(Vle);imo=r(zit,"megatron-bert"),zit.forEach(t),dmo=r(oS," \u2014 "),$I=n(oS,"A",{href:!0});var Qit=s($I);cmo=r(Qit,"BertTokenizer"),Qit.forEach(t),fmo=r(oS," or "),kI=n(oS,"A",{href:!0});var Wit=s(kI);mmo=r(Wit,"BertTokenizerFast"),Wit.forEach(t),gmo=r(oS," (Megatron-BERT model)"),oS.forEach(t),hmo=i(S),_h=n(S,"LI",{});var vye=s(_h);Xle=n(vye,"STRONG",{});var Hit=s(Xle);pmo=r(Hit,"mluke"),Hit.forEach(t),_mo=r(vye," \u2014 "),SI=n(vye,"A",{href:!0});var Uit=s(SI);umo=r(Uit,"MLukeTokenizer"),Uit.forEach(t),bmo=r(vye," (mLUKE model)"),vye.forEach(t),vmo=i(S),Ts=n(S,"LI",{});var rS=s(Ts);zle=n(rS,"STRONG",{});var Jit=s(zle);Fmo=r(Jit,"mobilebert"),Jit.forEach(t),Tmo=r(rS," \u2014 "),RI=n(rS,"A",{href:!0});var Yit=s(RI);Mmo=r(Yit,"MobileBertTokenizer"),Yit.forEach(t),Emo=r(rS," or "),PI=n(rS,"A",{href:!0});var Kit=s(PI);Cmo=r(Kit,"MobileBertTokenizerFast"),Kit.forEach(t),wmo=r(rS," (MobileBERT model)"),rS.forEach(t),Amo=i(S),Ms=n(S,"LI",{});var tS=s(Ms);Qle=n(tS,"STRONG",{});var Zit=s(Qle);Lmo=r(Zit,"mpnet"),Zit.forEach(t),ymo=r(tS," \u2014 "),BI=n(tS,"A",{href:!0});var edt=s(BI);xmo=r(edt,"MPNetTokenizer"),edt.forEach(t),$mo=r(tS," or "),II=n(tS,"A",{href:!0});var odt=s(II);kmo=r(odt,"MPNetTokenizerFast"),odt.forEach(t),Smo=r(tS," (MPNet model)"),tS.forEach(t),Rmo=i(S),Es=n(S,"LI",{});var aS=s(Es);Wle=n(aS,"STRONG",{});var rdt=s(Wle);Pmo=r(rdt,"mt5"),rdt.forEach(t),Bmo=r(aS," \u2014 "),NI=n(aS,"A",{href:!0});var tdt=s(NI);Imo=r(tdt,"MT5Tokenizer"),tdt.forEach(t),Nmo=r(aS," or "),qI=n(aS,"A",{href:!0});var adt=s(qI);qmo=r(adt,"MT5TokenizerFast"),adt.forEach(t),jmo=r(aS," (MT5 model)"),aS.forEach(t),Dmo=i(S),Cs=n(S,"LI",{});var nS=s(Cs);Hle=n(nS,"STRONG",{});var ndt=s(Hle);Gmo=r(ndt,"mvp"),ndt.forEach(t),Omo=r(nS," \u2014 "),jI=n(nS,"A",{href:!0});var sdt=s(jI);Vmo=r(sdt,"MvpTokenizer"),sdt.forEach(t),Xmo=r(nS," or "),DI=n(nS,"A",{href:!0});var ldt=s(DI);zmo=r(ldt,"MvpTokenizerFast"),ldt.forEach(t),Qmo=r(nS," (MVP model)"),nS.forEach(t),Wmo=i(S),ws=n(S,"LI",{});var sS=s(ws);Ule=n(sS,"STRONG",{});var idt=s(Ule);Hmo=r(idt,"nezha"),idt.forEach(t),Umo=r(sS," \u2014 "),GI=n(sS,"A",{href:!0});var ddt=s(GI);Jmo=r(ddt,"BertTokenizer"),ddt.forEach(t),Ymo=r(sS," or "),OI=n(sS,"A",{href:!0});var cdt=s(OI);Kmo=r(cdt,"BertTokenizerFast"),cdt.forEach(t),Zmo=r(sS," (Nezha model)"),sS.forEach(t),ego=i(S),As=n(S,"LI",{});var lS=s(As);Jle=n(lS,"STRONG",{});var fdt=s(Jle);ogo=r(fdt,"nystromformer"),fdt.forEach(t),rgo=r(lS," \u2014 "),VI=n(lS,"A",{href:!0});var mdt=s(VI);tgo=r(mdt,"AlbertTokenizer"),mdt.forEach(t),ago=r(lS," or "),XI=n(lS,"A",{href:!0});var gdt=s(XI);ngo=r(gdt,"AlbertTokenizerFast"),gdt.forEach(t),sgo=r(lS," (Nystr\xF6mformer model)"),lS.forEach(t),lgo=i(S),Ls=n(S,"LI",{});var iS=s(Ls);Yle=n(iS,"STRONG",{});var hdt=s(Yle);igo=r(hdt,"openai-gpt"),hdt.forEach(t),dgo=r(iS," \u2014 "),zI=n(iS,"A",{href:!0});var pdt=s(zI);cgo=r(pdt,"OpenAIGPTTokenizer"),pdt.forEach(t),fgo=r(iS," or "),QI=n(iS,"A",{href:!0});var _dt=s(QI);mgo=r(_dt,"OpenAIGPTTokenizerFast"),_dt.forEach(t),ggo=r(iS," (OpenAI GPT model)"),iS.forEach(t),hgo=i(S),uh=n(S,"LI",{});var Fye=s(uh);Kle=n(Fye,"STRONG",{});var udt=s(Kle);pgo=r(udt,"opt"),udt.forEach(t),_go=r(Fye," \u2014 "),WI=n(Fye,"A",{href:!0});var bdt=s(WI);ugo=r(bdt,"GPT2Tokenizer"),bdt.forEach(t),bgo=r(Fye," (OPT model)"),Fye.forEach(t),vgo=i(S),ys=n(S,"LI",{});var dS=s(ys);Zle=n(dS,"STRONG",{});var vdt=s(Zle);Fgo=r(vdt,"pegasus"),vdt.forEach(t),Tgo=r(dS," \u2014 "),HI=n(dS,"A",{href:!0});var Fdt=s(HI);Mgo=r(Fdt,"PegasusTokenizer"),Fdt.forEach(t),Ego=r(dS," or "),UI=n(dS,"A",{href:!0});var Tdt=s(UI);Cgo=r(Tdt,"PegasusTokenizerFast"),Tdt.forEach(t),wgo=r(dS," (Pegasus model)"),dS.forEach(t),Ago=i(S),bh=n(S,"LI",{});var Tye=s(bh);eie=n(Tye,"STRONG",{});var Mdt=s(eie);Lgo=r(Mdt,"perceiver"),Mdt.forEach(t),ygo=r(Tye," \u2014 "),JI=n(Tye,"A",{href:!0});var Edt=s(JI);xgo=r(Edt,"PerceiverTokenizer"),Edt.forEach(t),$go=r(Tye," (Perceiver model)"),Tye.forEach(t),kgo=i(S),vh=n(S,"LI",{});var Mye=s(vh);oie=n(Mye,"STRONG",{});var Cdt=s(oie);Sgo=r(Cdt,"phobert"),Cdt.forEach(t),Rgo=r(Mye," \u2014 "),YI=n(Mye,"A",{href:!0});var wdt=s(YI);Pgo=r(wdt,"PhobertTokenizer"),wdt.forEach(t),Bgo=r(Mye," (PhoBERT model)"),Mye.forEach(t),Igo=i(S),Fh=n(S,"LI",{});var Eye=s(Fh);rie=n(Eye,"STRONG",{});var Adt=s(rie);Ngo=r(Adt,"plbart"),Adt.forEach(t),qgo=r(Eye," \u2014 "),KI=n(Eye,"A",{href:!0});var Ldt=s(KI);jgo=r(Ldt,"PLBartTokenizer"),Ldt.forEach(t),Dgo=r(Eye," (PLBart model)"),Eye.forEach(t),Ggo=i(S),Th=n(S,"LI",{});var Cye=s(Th);tie=n(Cye,"STRONG",{});var ydt=s(tie);Ogo=r(ydt,"prophetnet"),ydt.forEach(t),Vgo=r(Cye," \u2014 "),ZI=n(Cye,"A",{href:!0});var xdt=s(ZI);Xgo=r(xdt,"ProphetNetTokenizer"),xdt.forEach(t),zgo=r(Cye," (ProphetNet model)"),Cye.forEach(t),Qgo=i(S),xs=n(S,"LI",{});var cS=s(xs);aie=n(cS,"STRONG",{});var $dt=s(aie);Wgo=r($dt,"qdqbert"),$dt.forEach(t),Hgo=r(cS," \u2014 "),eN=n(cS,"A",{href:!0});var kdt=s(eN);Ugo=r(kdt,"BertTokenizer"),kdt.forEach(t),Jgo=r(cS," or "),oN=n(cS,"A",{href:!0});var Sdt=s(oN);Ygo=r(Sdt,"BertTokenizerFast"),Sdt.forEach(t),Kgo=r(cS," (QDQBert model)"),cS.forEach(t),Zgo=i(S),Mh=n(S,"LI",{});var wye=s(Mh);nie=n(wye,"STRONG",{});var Rdt=s(nie);eho=r(Rdt,"rag"),Rdt.forEach(t),oho=r(wye," \u2014 "),rN=n(wye,"A",{href:!0});var Pdt=s(rN);rho=r(Pdt,"RagTokenizer"),Pdt.forEach(t),tho=r(wye," (RAG model)"),wye.forEach(t),aho=i(S),$s=n(S,"LI",{});var fS=s($s);sie=n(fS,"STRONG",{});var Bdt=s(sie);nho=r(Bdt,"realm"),Bdt.forEach(t),sho=r(fS," \u2014 "),tN=n(fS,"A",{href:!0});var Idt=s(tN);lho=r(Idt,"RealmTokenizer"),Idt.forEach(t),iho=r(fS," or "),aN=n(fS,"A",{href:!0});var Ndt=s(aN);dho=r(Ndt,"RealmTokenizerFast"),Ndt.forEach(t),cho=r(fS," (REALM model)"),fS.forEach(t),fho=i(S),ks=n(S,"LI",{});var mS=s(ks);lie=n(mS,"STRONG",{});var qdt=s(lie);mho=r(qdt,"reformer"),qdt.forEach(t),gho=r(mS," \u2014 "),nN=n(mS,"A",{href:!0});var jdt=s(nN);hho=r(jdt,"ReformerTokenizer"),jdt.forEach(t),pho=r(mS," or "),sN=n(mS,"A",{href:!0});var Ddt=s(sN);_ho=r(Ddt,"ReformerTokenizerFast"),Ddt.forEach(t),uho=r(mS," (Reformer model)"),mS.forEach(t),bho=i(S),Ss=n(S,"LI",{});var gS=s(Ss);iie=n(gS,"STRONG",{});var Gdt=s(iie);vho=r(Gdt,"rembert"),Gdt.forEach(t),Fho=r(gS," \u2014 "),lN=n(gS,"A",{href:!0});var Odt=s(lN);Tho=r(Odt,"RemBertTokenizer"),Odt.forEach(t),Mho=r(gS," or "),iN=n(gS,"A",{href:!0});var Vdt=s(iN);Eho=r(Vdt,"RemBertTokenizerFast"),Vdt.forEach(t),Cho=r(gS," (RemBERT model)"),gS.forEach(t),who=i(S),Rs=n(S,"LI",{});var hS=s(Rs);die=n(hS,"STRONG",{});var Xdt=s(die);Aho=r(Xdt,"retribert"),Xdt.forEach(t),Lho=r(hS," \u2014 "),dN=n(hS,"A",{href:!0});var zdt=s(dN);yho=r(zdt,"RetriBertTokenizer"),zdt.forEach(t),xho=r(hS," or "),cN=n(hS,"A",{href:!0});var Qdt=s(cN);$ho=r(Qdt,"RetriBertTokenizerFast"),Qdt.forEach(t),kho=r(hS," (RetriBERT model)"),hS.forEach(t),Sho=i(S),Ps=n(S,"LI",{});var pS=s(Ps);cie=n(pS,"STRONG",{});var Wdt=s(cie);Rho=r(Wdt,"roberta"),Wdt.forEach(t),Pho=r(pS," \u2014 "),fN=n(pS,"A",{href:!0});var Hdt=s(fN);Bho=r(Hdt,"RobertaTokenizer"),Hdt.forEach(t),Iho=r(pS," or "),mN=n(pS,"A",{href:!0});var Udt=s(mN);Nho=r(Udt,"RobertaTokenizerFast"),Udt.forEach(t),qho=r(pS," (RoBERTa model)"),pS.forEach(t),jho=i(S),Bs=n(S,"LI",{});var _S=s(Bs);fie=n(_S,"STRONG",{});var Jdt=s(fie);Dho=r(Jdt,"roformer"),Jdt.forEach(t),Gho=r(_S," \u2014 "),gN=n(_S,"A",{href:!0});var Ydt=s(gN);Oho=r(Ydt,"RoFormerTokenizer"),Ydt.forEach(t),Vho=r(_S," or "),hN=n(_S,"A",{href:!0});var Kdt=s(hN);Xho=r(Kdt,"RoFormerTokenizerFast"),Kdt.forEach(t),zho=r(_S," (RoFormer model)"),_S.forEach(t),Qho=i(S),Eh=n(S,"LI",{});var Aye=s(Eh);mie=n(Aye,"STRONG",{});var Zdt=s(mie);Who=r(Zdt,"speech_to_text"),Zdt.forEach(t),Hho=r(Aye," \u2014 "),pN=n(Aye,"A",{href:!0});var ect=s(pN);Uho=r(ect,"Speech2TextTokenizer"),ect.forEach(t),Jho=r(Aye," (Speech2Text model)"),Aye.forEach(t),Yho=i(S),Ch=n(S,"LI",{});var Lye=s(Ch);gie=n(Lye,"STRONG",{});var oct=s(gie);Kho=r(oct,"speech_to_text_2"),oct.forEach(t),Zho=r(Lye," \u2014 "),_N=n(Lye,"A",{href:!0});var rct=s(_N);epo=r(rct,"Speech2Text2Tokenizer"),rct.forEach(t),opo=r(Lye," (Speech2Text2 model)"),Lye.forEach(t),rpo=i(S),Is=n(S,"LI",{});var uS=s(Is);hie=n(uS,"STRONG",{});var tct=s(hie);tpo=r(tct,"splinter"),tct.forEach(t),apo=r(uS," \u2014 "),uN=n(uS,"A",{href:!0});var act=s(uN);npo=r(act,"SplinterTokenizer"),act.forEach(t),spo=r(uS," or "),bN=n(uS,"A",{href:!0});var nct=s(bN);lpo=r(nct,"SplinterTokenizerFast"),nct.forEach(t),ipo=r(uS," (Splinter model)"),uS.forEach(t),dpo=i(S),Ns=n(S,"LI",{});var bS=s(Ns);pie=n(bS,"STRONG",{});var sct=s(pie);cpo=r(sct,"squeezebert"),sct.forEach(t),fpo=r(bS," \u2014 "),vN=n(bS,"A",{href:!0});var lct=s(vN);mpo=r(lct,"SqueezeBertTokenizer"),lct.forEach(t),gpo=r(bS," or "),FN=n(bS,"A",{href:!0});var ict=s(FN);hpo=r(ict,"SqueezeBertTokenizerFast"),ict.forEach(t),ppo=r(bS," (SqueezeBERT model)"),bS.forEach(t),_po=i(S),qs=n(S,"LI",{});var vS=s(qs);_ie=n(vS,"STRONG",{});var dct=s(_ie);upo=r(dct,"t5"),dct.forEach(t),bpo=r(vS," \u2014 "),TN=n(vS,"A",{href:!0});var cct=s(TN);vpo=r(cct,"T5Tokenizer"),cct.forEach(t),Fpo=r(vS," or "),MN=n(vS,"A",{href:!0});var fct=s(MN);Tpo=r(fct,"T5TokenizerFast"),fct.forEach(t),Mpo=r(vS," (T5 model)"),vS.forEach(t),Epo=i(S),wh=n(S,"LI",{});var yye=s(wh);uie=n(yye,"STRONG",{});var mct=s(uie);Cpo=r(mct,"tapas"),mct.forEach(t),wpo=r(yye," \u2014 "),EN=n(yye,"A",{href:!0});var gct=s(EN);Apo=r(gct,"TapasTokenizer"),gct.forEach(t),Lpo=r(yye," (TAPAS model)"),yye.forEach(t),ypo=i(S),Ah=n(S,"LI",{});var xye=s(Ah);bie=n(xye,"STRONG",{});var hct=s(bie);xpo=r(hct,"tapex"),hct.forEach(t),$po=r(xye," \u2014 "),CN=n(xye,"A",{href:!0});var pct=s(CN);kpo=r(pct,"TapexTokenizer"),pct.forEach(t),Spo=r(xye," (TAPEX model)"),xye.forEach(t),Rpo=i(S),Lh=n(S,"LI",{});var $ye=s(Lh);vie=n($ye,"STRONG",{});var _ct=s(vie);Ppo=r(_ct,"transfo-xl"),_ct.forEach(t),Bpo=r($ye," \u2014 "),wN=n($ye,"A",{href:!0});var uct=s(wN);Ipo=r(uct,"TransfoXLTokenizer"),uct.forEach(t),Npo=r($ye," (Transformer-XL model)"),$ye.forEach(t),qpo=i(S),js=n(S,"LI",{});var FS=s(js);Fie=n(FS,"STRONG",{});var bct=s(Fie);jpo=r(bct,"vilt"),bct.forEach(t),Dpo=r(FS," \u2014 "),AN=n(FS,"A",{href:!0});var vct=s(AN);Gpo=r(vct,"BertTokenizer"),vct.forEach(t),Opo=r(FS," or "),LN=n(FS,"A",{href:!0});var Fct=s(LN);Vpo=r(Fct,"BertTokenizerFast"),Fct.forEach(t),Xpo=r(FS," (ViLT model)"),FS.forEach(t),zpo=i(S),Ds=n(S,"LI",{});var TS=s(Ds);Tie=n(TS,"STRONG",{});var Tct=s(Tie);Qpo=r(Tct,"visual_bert"),Tct.forEach(t),Wpo=r(TS," \u2014 "),yN=n(TS,"A",{href:!0});var Mct=s(yN);Hpo=r(Mct,"BertTokenizer"),Mct.forEach(t),Upo=r(TS," or "),xN=n(TS,"A",{href:!0});var Ect=s(xN);Jpo=r(Ect,"BertTokenizerFast"),Ect.forEach(t),Ypo=r(TS," (VisualBERT model)"),TS.forEach(t),Kpo=i(S),yh=n(S,"LI",{});var kye=s(yh);Mie=n(kye,"STRONG",{});var Cct=s(Mie);Zpo=r(Cct,"wav2vec2"),Cct.forEach(t),e_o=r(kye," \u2014 "),$N=n(kye,"A",{href:!0});var wct=s($N);o_o=r(wct,"Wav2Vec2CTCTokenizer"),wct.forEach(t),r_o=r(kye," (Wav2Vec2 model)"),kye.forEach(t),t_o=i(S),xh=n(S,"LI",{});var Sye=s(xh);Eie=n(Sye,"STRONG",{});var Act=s(Eie);a_o=r(Act,"wav2vec2-conformer"),Act.forEach(t),n_o=r(Sye," \u2014 "),kN=n(Sye,"A",{href:!0});var Lct=s(kN);s_o=r(Lct,"Wav2Vec2CTCTokenizer"),Lct.forEach(t),l_o=r(Sye," (Wav2Vec2-Conformer model)"),Sye.forEach(t),i_o=i(S),$h=n(S,"LI",{});var Rye=s($h);Cie=n(Rye,"STRONG",{});var yct=s(Cie);d_o=r(yct,"wav2vec2_phoneme"),yct.forEach(t),c_o=r(Rye," \u2014 "),SN=n(Rye,"A",{href:!0});var xct=s(SN);f_o=r(xct,"Wav2Vec2PhonemeCTCTokenizer"),xct.forEach(t),m_o=r(Rye," (Wav2Vec2Phoneme model)"),Rye.forEach(t),g_o=i(S),Gs=n(S,"LI",{});var MS=s(Gs);wie=n(MS,"STRONG",{});var $ct=s(wie);h_o=r($ct,"xglm"),$ct.forEach(t),p_o=r(MS," \u2014 "),RN=n(MS,"A",{href:!0});var kct=s(RN);__o=r(kct,"XGLMTokenizer"),kct.forEach(t),u_o=r(MS," or "),PN=n(MS,"A",{href:!0});var Sct=s(PN);b_o=r(Sct,"XGLMTokenizerFast"),Sct.forEach(t),v_o=r(MS," (XGLM model)"),MS.forEach(t),F_o=i(S),kh=n(S,"LI",{});var Pye=s(kh);Aie=n(Pye,"STRONG",{});var Rct=s(Aie);T_o=r(Rct,"xlm"),Rct.forEach(t),M_o=r(Pye," \u2014 "),BN=n(Pye,"A",{href:!0});var Pct=s(BN);E_o=r(Pct,"XLMTokenizer"),Pct.forEach(t),C_o=r(Pye," (XLM model)"),Pye.forEach(t),w_o=i(S),Sh=n(S,"LI",{});var Bye=s(Sh);Lie=n(Bye,"STRONG",{});var Bct=s(Lie);A_o=r(Bct,"xlm-prophetnet"),Bct.forEach(t),L_o=r(Bye," \u2014 "),IN=n(Bye,"A",{href:!0});var Ict=s(IN);y_o=r(Ict,"XLMProphetNetTokenizer"),Ict.forEach(t),x_o=r(Bye," (XLM-ProphetNet model)"),Bye.forEach(t),$_o=i(S),Os=n(S,"LI",{});var ES=s(Os);yie=n(ES,"STRONG",{});var Nct=s(yie);k_o=r(Nct,"xlm-roberta"),Nct.forEach(t),S_o=r(ES," \u2014 "),NN=n(ES,"A",{href:!0});var qct=s(NN);R_o=r(qct,"XLMRobertaTokenizer"),qct.forEach(t),P_o=r(ES," or "),qN=n(ES,"A",{href:!0});var jct=s(qN);B_o=r(jct,"XLMRobertaTokenizerFast"),jct.forEach(t),I_o=r(ES," (XLM-RoBERTa model)"),ES.forEach(t),N_o=i(S),Vs=n(S,"LI",{});var CS=s(Vs);xie=n(CS,"STRONG",{});var Dct=s(xie);q_o=r(Dct,"xlm-roberta-xl"),Dct.forEach(t),j_o=r(CS," \u2014 "),jN=n(CS,"A",{href:!0});var Gct=s(jN);D_o=r(Gct,"RobertaTokenizer"),Gct.forEach(t),G_o=r(CS," or "),DN=n(CS,"A",{href:!0});var Oct=s(DN);O_o=r(Oct,"RobertaTokenizerFast"),Oct.forEach(t),V_o=r(CS," (XLM-RoBERTa-XL model)"),CS.forEach(t),X_o=i(S),Xs=n(S,"LI",{});var wS=s(Xs);$ie=n(wS,"STRONG",{});var Vct=s($ie);z_o=r(Vct,"xlnet"),Vct.forEach(t),Q_o=r(wS," \u2014 "),GN=n(wS,"A",{href:!0});var Xct=s(GN);W_o=r(Xct,"XLNetTokenizer"),Xct.forEach(t),H_o=r(wS," or "),ON=n(wS,"A",{href:!0});var zct=s(ON);U_o=r(zct,"XLNetTokenizerFast"),zct.forEach(t),J_o=r(wS," (XLNet model)"),wS.forEach(t),Y_o=i(S),zs=n(S,"LI",{});var AS=s(zs);kie=n(AS,"STRONG",{});var Qct=s(kie);K_o=r(Qct,"yoso"),Qct.forEach(t),Z_o=r(AS," \u2014 "),VN=n(AS,"A",{href:!0});var Wct=s(VN);euo=r(Wct,"AlbertTokenizer"),Wct.forEach(t),ouo=r(AS," or "),XN=n(AS,"A",{href:!0});var Hct=s(XN);ruo=r(Hct,"AlbertTokenizerFast"),Hct.forEach(t),tuo=r(AS," (YOSO model)"),AS.forEach(t),S.forEach(t),auo=i(Ys),T(Rh.$$.fragment,Ys),Ys.forEach(t),nuo=i(Js),Ph=n(Js,"DIV",{class:!0});var Hze=s(Ph);T(hL.$$.fragment,Hze),suo=i(Hze),Sie=n(Hze,"P",{});var Uct=s(Sie);luo=r(Uct,"Register a new tokenizer in this mapping."),Uct.forEach(t),Hze.forEach(t),Js.forEach(t),WVe=i(f),Ni=n(f,"H2",{class:!0});var Uze=s(Ni);Bh=n(Uze,"A",{id:!0,class:!0,href:!0});var Jct=s(Bh);Rie=n(Jct,"SPAN",{});var Yct=s(Rie);T(pL.$$.fragment,Yct),Yct.forEach(t),Jct.forEach(t),iuo=i(Uze),Pie=n(Uze,"SPAN",{});var Kct=s(Pie);duo=r(Kct,"AutoFeatureExtractor"),Kct.forEach(t),Uze.forEach(t),HVe=i(f),Lo=n(f,"DIV",{class:!0});var Ks=s(Lo);T(_L.$$.fragment,Ks),cuo=i(Ks),uL=n(Ks,"P",{});var Jze=s(uL);fuo=r(Jze,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),zN=n(Jze,"A",{href:!0});var Zct=s(zN);muo=r(Zct,"AutoFeatureExtractor.from_pretrained()"),Zct.forEach(t),guo=r(Jze," class method."),Jze.forEach(t),huo=i(Ks),bL=n(Ks,"P",{});var Yze=s(bL);puo=r(Yze,"This class cannot be instantiated directly using "),Bie=n(Yze,"CODE",{});var eft=s(Bie);_uo=r(eft,"__init__()"),eft.forEach(t),uuo=r(Yze," (throws an error)."),Yze.forEach(t),buo=i(Ks),He=n(Ks,"DIV",{class:!0});var aa=s(He);T(vL.$$.fragment,aa),vuo=i(aa),Iie=n(aa,"P",{});var oft=s(Iie);Fuo=r(oft,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),oft.forEach(t),Tuo=i(aa),Pa=n(aa,"P",{});var aA=s(Pa);Muo=r(aA,"The feature extractor class to instantiate is selected based on the "),Nie=n(aA,"CODE",{});var rft=s(Nie);Euo=r(rft,"model_type"),rft.forEach(t),Cuo=r(aA,` property of the config object
(either passed as an argument or loaded from `),qie=n(aA,"CODE",{});var tft=s(qie);wuo=r(tft,"pretrained_model_name_or_path"),tft.forEach(t),Auo=r(aA,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),jie=n(aA,"CODE",{});var aft=s(jie);Luo=r(aft,"pretrained_model_name_or_path"),aft.forEach(t),yuo=r(aA,":"),aA.forEach(t),xuo=i(aa),Y=n(aa,"UL",{});var K=s(Y);Ih=n(K,"LI",{});var Iye=s(Ih);Die=n(Iye,"STRONG",{});var nft=s(Die);$uo=r(nft,"beit"),nft.forEach(t),kuo=r(Iye," \u2014 "),QN=n(Iye,"A",{href:!0});var sft=s(QN);Suo=r(sft,"BeitFeatureExtractor"),sft.forEach(t),Ruo=r(Iye," (BEiT model)"),Iye.forEach(t),Puo=i(K),Nh=n(K,"LI",{});var Nye=s(Nh);Gie=n(Nye,"STRONG",{});var lft=s(Gie);Buo=r(lft,"clip"),lft.forEach(t),Iuo=r(Nye," \u2014 "),WN=n(Nye,"A",{href:!0});var ift=s(WN);Nuo=r(ift,"CLIPFeatureExtractor"),ift.forEach(t),quo=r(Nye," (CLIP model)"),Nye.forEach(t),juo=i(K),qh=n(K,"LI",{});var qye=s(qh);Oie=n(qye,"STRONG",{});var dft=s(Oie);Duo=r(dft,"convnext"),dft.forEach(t),Guo=r(qye," \u2014 "),HN=n(qye,"A",{href:!0});var cft=s(HN);Ouo=r(cft,"ConvNextFeatureExtractor"),cft.forEach(t),Vuo=r(qye," (ConvNeXT model)"),qye.forEach(t),Xuo=i(K),jh=n(K,"LI",{});var jye=s(jh);Vie=n(jye,"STRONG",{});var fft=s(Vie);zuo=r(fft,"cvt"),fft.forEach(t),Quo=r(jye," \u2014 "),UN=n(jye,"A",{href:!0});var mft=s(UN);Wuo=r(mft,"ConvNextFeatureExtractor"),mft.forEach(t),Huo=r(jye," (CvT model)"),jye.forEach(t),Uuo=i(K),Dh=n(K,"LI",{});var Dye=s(Dh);Xie=n(Dye,"STRONG",{});var gft=s(Xie);Juo=r(gft,"data2vec-audio"),gft.forEach(t),Yuo=r(Dye," \u2014 "),JN=n(Dye,"A",{href:!0});var hft=s(JN);Kuo=r(hft,"Wav2Vec2FeatureExtractor"),hft.forEach(t),Zuo=r(Dye," (Data2VecAudio model)"),Dye.forEach(t),e1o=i(K),Gh=n(K,"LI",{});var Gye=s(Gh);zie=n(Gye,"STRONG",{});var pft=s(zie);o1o=r(pft,"data2vec-vision"),pft.forEach(t),r1o=r(Gye," \u2014 "),YN=n(Gye,"A",{href:!0});var _ft=s(YN);t1o=r(_ft,"BeitFeatureExtractor"),_ft.forEach(t),a1o=r(Gye," (Data2VecVision model)"),Gye.forEach(t),n1o=i(K),Oh=n(K,"LI",{});var Oye=s(Oh);Qie=n(Oye,"STRONG",{});var uft=s(Qie);s1o=r(uft,"deit"),uft.forEach(t),l1o=r(Oye," \u2014 "),KN=n(Oye,"A",{href:!0});var bft=s(KN);i1o=r(bft,"DeiTFeatureExtractor"),bft.forEach(t),d1o=r(Oye," (DeiT model)"),Oye.forEach(t),c1o=i(K),Vh=n(K,"LI",{});var Vye=s(Vh);Wie=n(Vye,"STRONG",{});var vft=s(Wie);f1o=r(vft,"detr"),vft.forEach(t),m1o=r(Vye," \u2014 "),ZN=n(Vye,"A",{href:!0});var Fft=s(ZN);g1o=r(Fft,"DetrFeatureExtractor"),Fft.forEach(t),h1o=r(Vye," (DETR model)"),Vye.forEach(t),p1o=i(K),Xh=n(K,"LI",{});var Xye=s(Xh);Hie=n(Xye,"STRONG",{});var Tft=s(Hie);_1o=r(Tft,"dpt"),Tft.forEach(t),u1o=r(Xye," \u2014 "),eq=n(Xye,"A",{href:!0});var Mft=s(eq);b1o=r(Mft,"DPTFeatureExtractor"),Mft.forEach(t),v1o=r(Xye," (DPT model)"),Xye.forEach(t),F1o=i(K),zh=n(K,"LI",{});var zye=s(zh);Uie=n(zye,"STRONG",{});var Eft=s(Uie);T1o=r(Eft,"flava"),Eft.forEach(t),M1o=r(zye," \u2014 "),oq=n(zye,"A",{href:!0});var Cft=s(oq);E1o=r(Cft,"FlavaFeatureExtractor"),Cft.forEach(t),C1o=r(zye," (FLAVA model)"),zye.forEach(t),w1o=i(K),Qh=n(K,"LI",{});var Qye=s(Qh);Jie=n(Qye,"STRONG",{});var wft=s(Jie);A1o=r(wft,"glpn"),wft.forEach(t),L1o=r(Qye," \u2014 "),rq=n(Qye,"A",{href:!0});var Aft=s(rq);y1o=r(Aft,"GLPNFeatureExtractor"),Aft.forEach(t),x1o=r(Qye," (GLPN model)"),Qye.forEach(t),$1o=i(K),Wh=n(K,"LI",{});var Wye=s(Wh);Yie=n(Wye,"STRONG",{});var Lft=s(Yie);k1o=r(Lft,"groupvit"),Lft.forEach(t),S1o=r(Wye," \u2014 "),tq=n(Wye,"A",{href:!0});var yft=s(tq);R1o=r(yft,"CLIPFeatureExtractor"),yft.forEach(t),P1o=r(Wye," (GroupViT model)"),Wye.forEach(t),B1o=i(K),Hh=n(K,"LI",{});var Hye=s(Hh);Kie=n(Hye,"STRONG",{});var xft=s(Kie);I1o=r(xft,"hubert"),xft.forEach(t),N1o=r(Hye," \u2014 "),aq=n(Hye,"A",{href:!0});var $ft=s(aq);q1o=r($ft,"Wav2Vec2FeatureExtractor"),$ft.forEach(t),j1o=r(Hye," (Hubert model)"),Hye.forEach(t),D1o=i(K),Uh=n(K,"LI",{});var Uye=s(Uh);Zie=n(Uye,"STRONG",{});var kft=s(Zie);G1o=r(kft,"imagegpt"),kft.forEach(t),O1o=r(Uye," \u2014 "),nq=n(Uye,"A",{href:!0});var Sft=s(nq);V1o=r(Sft,"ImageGPTFeatureExtractor"),Sft.forEach(t),X1o=r(Uye," (ImageGPT model)"),Uye.forEach(t),z1o=i(K),Jh=n(K,"LI",{});var Jye=s(Jh);ede=n(Jye,"STRONG",{});var Rft=s(ede);Q1o=r(Rft,"layoutlmv2"),Rft.forEach(t),W1o=r(Jye," \u2014 "),sq=n(Jye,"A",{href:!0});var Pft=s(sq);H1o=r(Pft,"LayoutLMv2FeatureExtractor"),Pft.forEach(t),U1o=r(Jye," (LayoutLMv2 model)"),Jye.forEach(t),J1o=i(K),Yh=n(K,"LI",{});var Yye=s(Yh);ode=n(Yye,"STRONG",{});var Bft=s(ode);Y1o=r(Bft,"layoutlmv3"),Bft.forEach(t),K1o=r(Yye," \u2014 "),lq=n(Yye,"A",{href:!0});var Ift=s(lq);Z1o=r(Ift,"LayoutLMv3FeatureExtractor"),Ift.forEach(t),e2o=r(Yye," (LayoutLMv3 model)"),Yye.forEach(t),o2o=i(K),Kh=n(K,"LI",{});var Kye=s(Kh);rde=n(Kye,"STRONG",{});var Nft=s(rde);r2o=r(Nft,"levit"),Nft.forEach(t),t2o=r(Kye," \u2014 "),iq=n(Kye,"A",{href:!0});var qft=s(iq);a2o=r(qft,"LevitFeatureExtractor"),qft.forEach(t),n2o=r(Kye," (LeViT model)"),Kye.forEach(t),s2o=i(K),Zh=n(K,"LI",{});var Zye=s(Zh);tde=n(Zye,"STRONG",{});var jft=s(tde);l2o=r(jft,"maskformer"),jft.forEach(t),i2o=r(Zye," \u2014 "),dq=n(Zye,"A",{href:!0});var Dft=s(dq);d2o=r(Dft,"MaskFormerFeatureExtractor"),Dft.forEach(t),c2o=r(Zye," (MaskFormer model)"),Zye.forEach(t),f2o=i(K),ep=n(K,"LI",{});var e9e=s(ep);ade=n(e9e,"STRONG",{});var Gft=s(ade);m2o=r(Gft,"mctct"),Gft.forEach(t),g2o=r(e9e," \u2014 "),cq=n(e9e,"A",{href:!0});var Oft=s(cq);h2o=r(Oft,"MCTCTFeatureExtractor"),Oft.forEach(t),p2o=r(e9e," (M-CTC-T model)"),e9e.forEach(t),_2o=i(K),op=n(K,"LI",{});var o9e=s(op);nde=n(o9e,"STRONG",{});var Vft=s(nde);u2o=r(Vft,"mobilevit"),Vft.forEach(t),b2o=r(o9e," \u2014 "),fq=n(o9e,"A",{href:!0});var Xft=s(fq);v2o=r(Xft,"MobileViTFeatureExtractor"),Xft.forEach(t),F2o=r(o9e," (MobileViT model)"),o9e.forEach(t),T2o=i(K),rp=n(K,"LI",{});var r9e=s(rp);sde=n(r9e,"STRONG",{});var zft=s(sde);M2o=r(zft,"perceiver"),zft.forEach(t),E2o=r(r9e," \u2014 "),mq=n(r9e,"A",{href:!0});var Qft=s(mq);C2o=r(Qft,"PerceiverFeatureExtractor"),Qft.forEach(t),w2o=r(r9e," (Perceiver model)"),r9e.forEach(t),A2o=i(K),tp=n(K,"LI",{});var t9e=s(tp);lde=n(t9e,"STRONG",{});var Wft=s(lde);L2o=r(Wft,"poolformer"),Wft.forEach(t),y2o=r(t9e," \u2014 "),gq=n(t9e,"A",{href:!0});var Hft=s(gq);x2o=r(Hft,"PoolFormerFeatureExtractor"),Hft.forEach(t),$2o=r(t9e," (PoolFormer model)"),t9e.forEach(t),k2o=i(K),ap=n(K,"LI",{});var a9e=s(ap);ide=n(a9e,"STRONG",{});var Uft=s(ide);S2o=r(Uft,"regnet"),Uft.forEach(t),R2o=r(a9e," \u2014 "),hq=n(a9e,"A",{href:!0});var Jft=s(hq);P2o=r(Jft,"ConvNextFeatureExtractor"),Jft.forEach(t),B2o=r(a9e," (RegNet model)"),a9e.forEach(t),I2o=i(K),np=n(K,"LI",{});var n9e=s(np);dde=n(n9e,"STRONG",{});var Yft=s(dde);N2o=r(Yft,"resnet"),Yft.forEach(t),q2o=r(n9e," \u2014 "),pq=n(n9e,"A",{href:!0});var Kft=s(pq);j2o=r(Kft,"ConvNextFeatureExtractor"),Kft.forEach(t),D2o=r(n9e," (ResNet model)"),n9e.forEach(t),G2o=i(K),sp=n(K,"LI",{});var s9e=s(sp);cde=n(s9e,"STRONG",{});var Zft=s(cde);O2o=r(Zft,"segformer"),Zft.forEach(t),V2o=r(s9e," \u2014 "),_q=n(s9e,"A",{href:!0});var emt=s(_q);X2o=r(emt,"SegformerFeatureExtractor"),emt.forEach(t),z2o=r(s9e," (SegFormer model)"),s9e.forEach(t),Q2o=i(K),lp=n(K,"LI",{});var l9e=s(lp);fde=n(l9e,"STRONG",{});var omt=s(fde);W2o=r(omt,"speech_to_text"),omt.forEach(t),H2o=r(l9e," \u2014 "),uq=n(l9e,"A",{href:!0});var rmt=s(uq);U2o=r(rmt,"Speech2TextFeatureExtractor"),rmt.forEach(t),J2o=r(l9e," (Speech2Text model)"),l9e.forEach(t),Y2o=i(K),ip=n(K,"LI",{});var i9e=s(ip);mde=n(i9e,"STRONG",{});var tmt=s(mde);K2o=r(tmt,"swin"),tmt.forEach(t),Z2o=r(i9e," \u2014 "),bq=n(i9e,"A",{href:!0});var amt=s(bq);ebo=r(amt,"ViTFeatureExtractor"),amt.forEach(t),obo=r(i9e," (Swin Transformer model)"),i9e.forEach(t),rbo=i(K),dp=n(K,"LI",{});var d9e=s(dp);gde=n(d9e,"STRONG",{});var nmt=s(gde);tbo=r(nmt,"van"),nmt.forEach(t),abo=r(d9e," \u2014 "),vq=n(d9e,"A",{href:!0});var smt=s(vq);nbo=r(smt,"ConvNextFeatureExtractor"),smt.forEach(t),sbo=r(d9e," (VAN model)"),d9e.forEach(t),lbo=i(K),cp=n(K,"LI",{});var c9e=s(cp);hde=n(c9e,"STRONG",{});var lmt=s(hde);ibo=r(lmt,"vilt"),lmt.forEach(t),dbo=r(c9e," \u2014 "),Fq=n(c9e,"A",{href:!0});var imt=s(Fq);cbo=r(imt,"ViltFeatureExtractor"),imt.forEach(t),fbo=r(c9e," (ViLT model)"),c9e.forEach(t),mbo=i(K),fp=n(K,"LI",{});var f9e=s(fp);pde=n(f9e,"STRONG",{});var dmt=s(pde);gbo=r(dmt,"vit"),dmt.forEach(t),hbo=r(f9e," \u2014 "),Tq=n(f9e,"A",{href:!0});var cmt=s(Tq);pbo=r(cmt,"ViTFeatureExtractor"),cmt.forEach(t),_bo=r(f9e," (ViT model)"),f9e.forEach(t),ubo=i(K),mp=n(K,"LI",{});var m9e=s(mp);_de=n(m9e,"STRONG",{});var fmt=s(_de);bbo=r(fmt,"vit_mae"),fmt.forEach(t),vbo=r(m9e," \u2014 "),Mq=n(m9e,"A",{href:!0});var mmt=s(Mq);Fbo=r(mmt,"ViTFeatureExtractor"),mmt.forEach(t),Tbo=r(m9e," (ViTMAE model)"),m9e.forEach(t),Mbo=i(K),gp=n(K,"LI",{});var g9e=s(gp);ude=n(g9e,"STRONG",{});var gmt=s(ude);Ebo=r(gmt,"wav2vec2"),gmt.forEach(t),Cbo=r(g9e," \u2014 "),Eq=n(g9e,"A",{href:!0});var hmt=s(Eq);wbo=r(hmt,"Wav2Vec2FeatureExtractor"),hmt.forEach(t),Abo=r(g9e," (Wav2Vec2 model)"),g9e.forEach(t),Lbo=i(K),hp=n(K,"LI",{});var h9e=s(hp);bde=n(h9e,"STRONG",{});var pmt=s(bde);ybo=r(pmt,"wav2vec2-conformer"),pmt.forEach(t),xbo=r(h9e," \u2014 "),Cq=n(h9e,"A",{href:!0});var _mt=s(Cq);$bo=r(_mt,"Wav2Vec2FeatureExtractor"),_mt.forEach(t),kbo=r(h9e," (Wav2Vec2-Conformer model)"),h9e.forEach(t),Sbo=i(K),pp=n(K,"LI",{});var p9e=s(pp);vde=n(p9e,"STRONG",{});var umt=s(vde);Rbo=r(umt,"yolos"),umt.forEach(t),Pbo=r(p9e," \u2014 "),wq=n(p9e,"A",{href:!0});var bmt=s(wq);Bbo=r(bmt,"YolosFeatureExtractor"),bmt.forEach(t),Ibo=r(p9e," (YOLOS model)"),p9e.forEach(t),K.forEach(t),Nbo=i(aa),T(_p.$$.fragment,aa),qbo=i(aa),T(up.$$.fragment,aa),aa.forEach(t),jbo=i(Ks),bp=n(Ks,"DIV",{class:!0});var Kze=s(bp);T(FL.$$.fragment,Kze),Dbo=i(Kze),Fde=n(Kze,"P",{});var vmt=s(Fde);Gbo=r(vmt,"Register a new feature extractor for this class."),vmt.forEach(t),Kze.forEach(t),Ks.forEach(t),UVe=i(f),qi=n(f,"H2",{class:!0});var Zze=s(qi);vp=n(Zze,"A",{id:!0,class:!0,href:!0});var Fmt=s(vp);Tde=n(Fmt,"SPAN",{});var Tmt=s(Tde);T(TL.$$.fragment,Tmt),Tmt.forEach(t),Fmt.forEach(t),Obo=i(Zze),Mde=n(Zze,"SPAN",{});var Mmt=s(Mde);Vbo=r(Mmt,"AutoProcessor"),Mmt.forEach(t),Zze.forEach(t),JVe=i(f),yo=n(f,"DIV",{class:!0});var Zs=s(yo);T(ML.$$.fragment,Zs),Xbo=i(Zs),EL=n(Zs,"P",{});var eQe=s(EL);zbo=r(eQe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),Aq=n(eQe,"A",{href:!0});var Emt=s(Aq);Qbo=r(Emt,"AutoProcessor.from_pretrained()"),Emt.forEach(t),Wbo=r(eQe," class method."),eQe.forEach(t),Hbo=i(Zs),CL=n(Zs,"P",{});var oQe=s(CL);Ubo=r(oQe,"This class cannot be instantiated directly using "),Ede=n(oQe,"CODE",{});var Cmt=s(Ede);Jbo=r(Cmt,"__init__()"),Cmt.forEach(t),Ybo=r(oQe," (throws an error)."),oQe.forEach(t),Kbo=i(Zs),Ue=n(Zs,"DIV",{class:!0});var na=s(Ue);T(wL.$$.fragment,na),Zbo=i(na),Cde=n(na,"P",{});var wmt=s(Cde);evo=r(wmt,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),wmt.forEach(t),ovo=i(na),ji=n(na,"P",{});var Mre=s(ji);rvo=r(Mre,"The processor class to instantiate is selected based on the "),wde=n(Mre,"CODE",{});var Amt=s(wde);tvo=r(Amt,"model_type"),Amt.forEach(t),avo=r(Mre,` property of the config object (either
passed as an argument or loaded from `),Ade=n(Mre,"CODE",{});var Lmt=s(Ade);nvo=r(Lmt,"pretrained_model_name_or_path"),Lmt.forEach(t),svo=r(Mre," if possible):"),Mre.forEach(t),lvo=i(na),he=n(na,"UL",{});var ue=s(he);Fp=n(ue,"LI",{});var _9e=s(Fp);Lde=n(_9e,"STRONG",{});var ymt=s(Lde);ivo=r(ymt,"clip"),ymt.forEach(t),dvo=r(_9e," \u2014 "),Lq=n(_9e,"A",{href:!0});var xmt=s(Lq);cvo=r(xmt,"CLIPProcessor"),xmt.forEach(t),fvo=r(_9e," (CLIP model)"),_9e.forEach(t),mvo=i(ue),Tp=n(ue,"LI",{});var u9e=s(Tp);yde=n(u9e,"STRONG",{});var $mt=s(yde);gvo=r($mt,"flava"),$mt.forEach(t),hvo=r(u9e," \u2014 "),xde=n(u9e,"CODE",{});var kmt=s(xde);pvo=r(kmt,"FLAVAProcessor"),kmt.forEach(t),_vo=r(u9e," (FLAVA model)"),u9e.forEach(t),uvo=i(ue),Mp=n(ue,"LI",{});var b9e=s(Mp);$de=n(b9e,"STRONG",{});var Smt=s($de);bvo=r(Smt,"groupvit"),Smt.forEach(t),vvo=r(b9e," \u2014 "),yq=n(b9e,"A",{href:!0});var Rmt=s(yq);Fvo=r(Rmt,"CLIPProcessor"),Rmt.forEach(t),Tvo=r(b9e," (GroupViT model)"),b9e.forEach(t),Mvo=i(ue),Ep=n(ue,"LI",{});var v9e=s(Ep);kde=n(v9e,"STRONG",{});var Pmt=s(kde);Evo=r(Pmt,"layoutlmv2"),Pmt.forEach(t),Cvo=r(v9e," \u2014 "),xq=n(v9e,"A",{href:!0});var Bmt=s(xq);wvo=r(Bmt,"LayoutLMv2Processor"),Bmt.forEach(t),Avo=r(v9e," (LayoutLMv2 model)"),v9e.forEach(t),Lvo=i(ue),Cp=n(ue,"LI",{});var F9e=s(Cp);Sde=n(F9e,"STRONG",{});var Imt=s(Sde);yvo=r(Imt,"layoutlmv3"),Imt.forEach(t),xvo=r(F9e," \u2014 "),$q=n(F9e,"A",{href:!0});var Nmt=s($q);$vo=r(Nmt,"LayoutLMv3Processor"),Nmt.forEach(t),kvo=r(F9e," (LayoutLMv3 model)"),F9e.forEach(t),Svo=i(ue),wp=n(ue,"LI",{});var T9e=s(wp);Rde=n(T9e,"STRONG",{});var qmt=s(Rde);Rvo=r(qmt,"layoutxlm"),qmt.forEach(t),Pvo=r(T9e," \u2014 "),kq=n(T9e,"A",{href:!0});var jmt=s(kq);Bvo=r(jmt,"LayoutXLMProcessor"),jmt.forEach(t),Ivo=r(T9e," (LayoutXLM model)"),T9e.forEach(t),Nvo=i(ue),Ap=n(ue,"LI",{});var M9e=s(Ap);Pde=n(M9e,"STRONG",{});var Dmt=s(Pde);qvo=r(Dmt,"sew"),Dmt.forEach(t),jvo=r(M9e," \u2014 "),Sq=n(M9e,"A",{href:!0});var Gmt=s(Sq);Dvo=r(Gmt,"Wav2Vec2Processor"),Gmt.forEach(t),Gvo=r(M9e," (SEW model)"),M9e.forEach(t),Ovo=i(ue),Lp=n(ue,"LI",{});var E9e=s(Lp);Bde=n(E9e,"STRONG",{});var Omt=s(Bde);Vvo=r(Omt,"sew-d"),Omt.forEach(t),Xvo=r(E9e," \u2014 "),Rq=n(E9e,"A",{href:!0});var Vmt=s(Rq);zvo=r(Vmt,"Wav2Vec2Processor"),Vmt.forEach(t),Qvo=r(E9e," (SEW-D model)"),E9e.forEach(t),Wvo=i(ue),yp=n(ue,"LI",{});var C9e=s(yp);Ide=n(C9e,"STRONG",{});var Xmt=s(Ide);Hvo=r(Xmt,"speech_to_text"),Xmt.forEach(t),Uvo=r(C9e," \u2014 "),Pq=n(C9e,"A",{href:!0});var zmt=s(Pq);Jvo=r(zmt,"Speech2TextProcessor"),zmt.forEach(t),Yvo=r(C9e," (Speech2Text model)"),C9e.forEach(t),Kvo=i(ue),xp=n(ue,"LI",{});var w9e=s(xp);Nde=n(w9e,"STRONG",{});var Qmt=s(Nde);Zvo=r(Qmt,"speech_to_text_2"),Qmt.forEach(t),eFo=r(w9e," \u2014 "),Bq=n(w9e,"A",{href:!0});var Wmt=s(Bq);oFo=r(Wmt,"Speech2Text2Processor"),Wmt.forEach(t),rFo=r(w9e," (Speech2Text2 model)"),w9e.forEach(t),tFo=i(ue),$p=n(ue,"LI",{});var A9e=s($p);qde=n(A9e,"STRONG",{});var Hmt=s(qde);aFo=r(Hmt,"trocr"),Hmt.forEach(t),nFo=r(A9e," \u2014 "),Iq=n(A9e,"A",{href:!0});var Umt=s(Iq);sFo=r(Umt,"TrOCRProcessor"),Umt.forEach(t),lFo=r(A9e," (TrOCR model)"),A9e.forEach(t),iFo=i(ue),kp=n(ue,"LI",{});var L9e=s(kp);jde=n(L9e,"STRONG",{});var Jmt=s(jde);dFo=r(Jmt,"unispeech"),Jmt.forEach(t),cFo=r(L9e," \u2014 "),Nq=n(L9e,"A",{href:!0});var Ymt=s(Nq);fFo=r(Ymt,"Wav2Vec2Processor"),Ymt.forEach(t),mFo=r(L9e," (UniSpeech model)"),L9e.forEach(t),gFo=i(ue),Sp=n(ue,"LI",{});var y9e=s(Sp);Dde=n(y9e,"STRONG",{});var Kmt=s(Dde);hFo=r(Kmt,"unispeech-sat"),Kmt.forEach(t),pFo=r(y9e," \u2014 "),qq=n(y9e,"A",{href:!0});var Zmt=s(qq);_Fo=r(Zmt,"Wav2Vec2Processor"),Zmt.forEach(t),uFo=r(y9e," (UniSpeechSat model)"),y9e.forEach(t),bFo=i(ue),Rp=n(ue,"LI",{});var x9e=s(Rp);Gde=n(x9e,"STRONG",{});var egt=s(Gde);vFo=r(egt,"vilt"),egt.forEach(t),FFo=r(x9e," \u2014 "),jq=n(x9e,"A",{href:!0});var ogt=s(jq);TFo=r(ogt,"ViltProcessor"),ogt.forEach(t),MFo=r(x9e," (ViLT model)"),x9e.forEach(t),EFo=i(ue),Pp=n(ue,"LI",{});var $9e=s(Pp);Ode=n($9e,"STRONG",{});var rgt=s(Ode);CFo=r(rgt,"vision-text-dual-encoder"),rgt.forEach(t),wFo=r($9e," \u2014 "),Dq=n($9e,"A",{href:!0});var tgt=s(Dq);AFo=r(tgt,"VisionTextDualEncoderProcessor"),tgt.forEach(t),LFo=r($9e," (VisionTextDualEncoder model)"),$9e.forEach(t),yFo=i(ue),Bp=n(ue,"LI",{});var k9e=s(Bp);Vde=n(k9e,"STRONG",{});var agt=s(Vde);xFo=r(agt,"wav2vec2"),agt.forEach(t),$Fo=r(k9e," \u2014 "),Gq=n(k9e,"A",{href:!0});var ngt=s(Gq);kFo=r(ngt,"Wav2Vec2Processor"),ngt.forEach(t),SFo=r(k9e," (Wav2Vec2 model)"),k9e.forEach(t),RFo=i(ue),Ip=n(ue,"LI",{});var S9e=s(Ip);Xde=n(S9e,"STRONG",{});var sgt=s(Xde);PFo=r(sgt,"wav2vec2-conformer"),sgt.forEach(t),BFo=r(S9e," \u2014 "),Oq=n(S9e,"A",{href:!0});var lgt=s(Oq);IFo=r(lgt,"Wav2Vec2Processor"),lgt.forEach(t),NFo=r(S9e," (Wav2Vec2-Conformer model)"),S9e.forEach(t),qFo=i(ue),Np=n(ue,"LI",{});var R9e=s(Np);zde=n(R9e,"STRONG",{});var igt=s(zde);jFo=r(igt,"wavlm"),igt.forEach(t),DFo=r(R9e," \u2014 "),Vq=n(R9e,"A",{href:!0});var dgt=s(Vq);GFo=r(dgt,"Wav2Vec2Processor"),dgt.forEach(t),OFo=r(R9e," (WavLM model)"),R9e.forEach(t),ue.forEach(t),VFo=i(na),T(qp.$$.fragment,na),XFo=i(na),T(jp.$$.fragment,na),na.forEach(t),zFo=i(Zs),Dp=n(Zs,"DIV",{class:!0});var rQe=s(Dp);T(AL.$$.fragment,rQe),QFo=i(rQe),Qde=n(rQe,"P",{});var cgt=s(Qde);WFo=r(cgt,"Register a new processor for this class."),cgt.forEach(t),rQe.forEach(t),Zs.forEach(t),YVe=i(f),Di=n(f,"H2",{class:!0});var tQe=s(Di);Gp=n(tQe,"A",{id:!0,class:!0,href:!0});var fgt=s(Gp);Wde=n(fgt,"SPAN",{});var mgt=s(Wde);T(LL.$$.fragment,mgt),mgt.forEach(t),fgt.forEach(t),HFo=i(tQe),Hde=n(tQe,"SPAN",{});var ggt=s(Hde);UFo=r(ggt,"AutoModel"),ggt.forEach(t),tQe.forEach(t),KVe=i(f),xo=n(f,"DIV",{class:!0});var el=s(xo);T(yL.$$.fragment,el),JFo=i(el),Gi=n(el,"P",{});var Ere=s(Gi);YFo=r(Ere,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Xq=n(Ere,"A",{href:!0});var hgt=s(Xq);KFo=r(hgt,"from_pretrained()"),hgt.forEach(t),ZFo=r(Ere," class method or the "),zq=n(Ere,"A",{href:!0});var pgt=s(zq);eTo=r(pgt,"from_config()"),pgt.forEach(t),oTo=r(Ere,` class
method.`),Ere.forEach(t),rTo=i(el),xL=n(el,"P",{});var aQe=s(xL);tTo=r(aQe,"This class cannot be instantiated directly using "),Ude=n(aQe,"CODE",{});var _gt=s(Ude);aTo=r(_gt,"__init__()"),_gt.forEach(t),nTo=r(aQe," (throws an error)."),aQe.forEach(t),sTo=i(el),lt=n(el,"DIV",{class:!0});var nA=s(lt);T($L.$$.fragment,nA),lTo=i(nA),Jde=n(nA,"P",{});var ugt=s(Jde);iTo=r(ugt,"Instantiates one of the base model classes of the library from a configuration."),ugt.forEach(t),dTo=i(nA),Oi=n(nA,"P",{});var Cre=s(Oi);cTo=r(Cre,`Note:
Loading a model from its configuration file does `),Yde=n(Cre,"STRONG",{});var bgt=s(Yde);fTo=r(bgt,"not"),bgt.forEach(t),mTo=r(Cre,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qq=n(Cre,"A",{href:!0});var vgt=s(Qq);gTo=r(vgt,"from_pretrained()"),vgt.forEach(t),hTo=r(Cre," to load the model weights."),Cre.forEach(t),pTo=i(nA),T(Op.$$.fragment,nA),nA.forEach(t),_To=i(el),Je=n(el,"DIV",{class:!0});var sa=s(Je);T(kL.$$.fragment,sa),uTo=i(sa),Kde=n(sa,"P",{});var Fgt=s(Kde);bTo=r(Fgt,"Instantiate one of the base model classes of the library from a pretrained model."),Fgt.forEach(t),vTo=i(sa),Ba=n(sa,"P",{});var sA=s(Ba);FTo=r(sA,"The model class to instantiate is selected based on the "),Zde=n(sA,"CODE",{});var Tgt=s(Zde);TTo=r(Tgt,"model_type"),Tgt.forEach(t),MTo=r(sA,` property of the config object (either
passed as an argument or loaded from `),ece=n(sA,"CODE",{});var Mgt=s(ece);ETo=r(Mgt,"pretrained_model_name_or_path"),Mgt.forEach(t),CTo=r(sA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oce=n(sA,"CODE",{});var Egt=s(oce);wTo=r(Egt,"pretrained_model_name_or_path"),Egt.forEach(t),ATo=r(sA,":"),sA.forEach(t),LTo=i(sa),y=n(sa,"UL",{});var x=s(y);Vp=n(x,"LI",{});var P9e=s(Vp);rce=n(P9e,"STRONG",{});var Cgt=s(rce);yTo=r(Cgt,"albert"),Cgt.forEach(t),xTo=r(P9e," \u2014 "),Wq=n(P9e,"A",{href:!0});var wgt=s(Wq);$To=r(wgt,"AlbertModel"),wgt.forEach(t),kTo=r(P9e," (ALBERT model)"),P9e.forEach(t),STo=i(x),Xp=n(x,"LI",{});var B9e=s(Xp);tce=n(B9e,"STRONG",{});var Agt=s(tce);RTo=r(Agt,"bart"),Agt.forEach(t),PTo=r(B9e," \u2014 "),Hq=n(B9e,"A",{href:!0});var Lgt=s(Hq);BTo=r(Lgt,"BartModel"),Lgt.forEach(t),ITo=r(B9e," (BART model)"),B9e.forEach(t),NTo=i(x),zp=n(x,"LI",{});var I9e=s(zp);ace=n(I9e,"STRONG",{});var ygt=s(ace);qTo=r(ygt,"beit"),ygt.forEach(t),jTo=r(I9e," \u2014 "),Uq=n(I9e,"A",{href:!0});var xgt=s(Uq);DTo=r(xgt,"BeitModel"),xgt.forEach(t),GTo=r(I9e," (BEiT model)"),I9e.forEach(t),OTo=i(x),Qp=n(x,"LI",{});var N9e=s(Qp);nce=n(N9e,"STRONG",{});var $gt=s(nce);VTo=r($gt,"bert"),$gt.forEach(t),XTo=r(N9e," \u2014 "),Jq=n(N9e,"A",{href:!0});var kgt=s(Jq);zTo=r(kgt,"BertModel"),kgt.forEach(t),QTo=r(N9e," (BERT model)"),N9e.forEach(t),WTo=i(x),Wp=n(x,"LI",{});var q9e=s(Wp);sce=n(q9e,"STRONG",{});var Sgt=s(sce);HTo=r(Sgt,"bert-generation"),Sgt.forEach(t),UTo=r(q9e," \u2014 "),Yq=n(q9e,"A",{href:!0});var Rgt=s(Yq);JTo=r(Rgt,"BertGenerationEncoder"),Rgt.forEach(t),YTo=r(q9e," (Bert Generation model)"),q9e.forEach(t),KTo=i(x),Hp=n(x,"LI",{});var j9e=s(Hp);lce=n(j9e,"STRONG",{});var Pgt=s(lce);ZTo=r(Pgt,"big_bird"),Pgt.forEach(t),e7o=r(j9e," \u2014 "),Kq=n(j9e,"A",{href:!0});var Bgt=s(Kq);o7o=r(Bgt,"BigBirdModel"),Bgt.forEach(t),r7o=r(j9e," (BigBird model)"),j9e.forEach(t),t7o=i(x),Up=n(x,"LI",{});var D9e=s(Up);ice=n(D9e,"STRONG",{});var Igt=s(ice);a7o=r(Igt,"bigbird_pegasus"),Igt.forEach(t),n7o=r(D9e," \u2014 "),Zq=n(D9e,"A",{href:!0});var Ngt=s(Zq);s7o=r(Ngt,"BigBirdPegasusModel"),Ngt.forEach(t),l7o=r(D9e," (BigBird-Pegasus model)"),D9e.forEach(t),i7o=i(x),Jp=n(x,"LI",{});var G9e=s(Jp);dce=n(G9e,"STRONG",{});var qgt=s(dce);d7o=r(qgt,"blenderbot"),qgt.forEach(t),c7o=r(G9e," \u2014 "),ej=n(G9e,"A",{href:!0});var jgt=s(ej);f7o=r(jgt,"BlenderbotModel"),jgt.forEach(t),m7o=r(G9e," (Blenderbot model)"),G9e.forEach(t),g7o=i(x),Yp=n(x,"LI",{});var O9e=s(Yp);cce=n(O9e,"STRONG",{});var Dgt=s(cce);h7o=r(Dgt,"blenderbot-small"),Dgt.forEach(t),p7o=r(O9e," \u2014 "),oj=n(O9e,"A",{href:!0});var Ggt=s(oj);_7o=r(Ggt,"BlenderbotSmallModel"),Ggt.forEach(t),u7o=r(O9e," (BlenderbotSmall model)"),O9e.forEach(t),b7o=i(x),Kp=n(x,"LI",{});var V9e=s(Kp);fce=n(V9e,"STRONG",{});var Ogt=s(fce);v7o=r(Ogt,"bloom"),Ogt.forEach(t),F7o=r(V9e," \u2014 "),rj=n(V9e,"A",{href:!0});var Vgt=s(rj);T7o=r(Vgt,"BloomModel"),Vgt.forEach(t),M7o=r(V9e," (BLOOM model)"),V9e.forEach(t),E7o=i(x),Zp=n(x,"LI",{});var X9e=s(Zp);mce=n(X9e,"STRONG",{});var Xgt=s(mce);C7o=r(Xgt,"camembert"),Xgt.forEach(t),w7o=r(X9e," \u2014 "),tj=n(X9e,"A",{href:!0});var zgt=s(tj);A7o=r(zgt,"CamembertModel"),zgt.forEach(t),L7o=r(X9e," (CamemBERT model)"),X9e.forEach(t),y7o=i(x),e_=n(x,"LI",{});var z9e=s(e_);gce=n(z9e,"STRONG",{});var Qgt=s(gce);x7o=r(Qgt,"canine"),Qgt.forEach(t),$7o=r(z9e," \u2014 "),aj=n(z9e,"A",{href:!0});var Wgt=s(aj);k7o=r(Wgt,"CanineModel"),Wgt.forEach(t),S7o=r(z9e," (CANINE model)"),z9e.forEach(t),R7o=i(x),o_=n(x,"LI",{});var Q9e=s(o_);hce=n(Q9e,"STRONG",{});var Hgt=s(hce);P7o=r(Hgt,"clip"),Hgt.forEach(t),B7o=r(Q9e," \u2014 "),nj=n(Q9e,"A",{href:!0});var Ugt=s(nj);I7o=r(Ugt,"CLIPModel"),Ugt.forEach(t),N7o=r(Q9e," (CLIP model)"),Q9e.forEach(t),q7o=i(x),r_=n(x,"LI",{});var W9e=s(r_);pce=n(W9e,"STRONG",{});var Jgt=s(pce);j7o=r(Jgt,"codegen"),Jgt.forEach(t),D7o=r(W9e," \u2014 "),sj=n(W9e,"A",{href:!0});var Ygt=s(sj);G7o=r(Ygt,"CodeGenModel"),Ygt.forEach(t),O7o=r(W9e," (CodeGen model)"),W9e.forEach(t),V7o=i(x),t_=n(x,"LI",{});var H9e=s(t_);_ce=n(H9e,"STRONG",{});var Kgt=s(_ce);X7o=r(Kgt,"convbert"),Kgt.forEach(t),z7o=r(H9e," \u2014 "),lj=n(H9e,"A",{href:!0});var Zgt=s(lj);Q7o=r(Zgt,"ConvBertModel"),Zgt.forEach(t),W7o=r(H9e," (ConvBERT model)"),H9e.forEach(t),H7o=i(x),a_=n(x,"LI",{});var U9e=s(a_);uce=n(U9e,"STRONG",{});var eht=s(uce);U7o=r(eht,"convnext"),eht.forEach(t),J7o=r(U9e," \u2014 "),ij=n(U9e,"A",{href:!0});var oht=s(ij);Y7o=r(oht,"ConvNextModel"),oht.forEach(t),K7o=r(U9e," (ConvNeXT model)"),U9e.forEach(t),Z7o=i(x),n_=n(x,"LI",{});var J9e=s(n_);bce=n(J9e,"STRONG",{});var rht=s(bce);e8o=r(rht,"ctrl"),rht.forEach(t),o8o=r(J9e," \u2014 "),dj=n(J9e,"A",{href:!0});var tht=s(dj);r8o=r(tht,"CTRLModel"),tht.forEach(t),t8o=r(J9e," (CTRL model)"),J9e.forEach(t),a8o=i(x),s_=n(x,"LI",{});var Y9e=s(s_);vce=n(Y9e,"STRONG",{});var aht=s(vce);n8o=r(aht,"cvt"),aht.forEach(t),s8o=r(Y9e," \u2014 "),cj=n(Y9e,"A",{href:!0});var nht=s(cj);l8o=r(nht,"CvtModel"),nht.forEach(t),i8o=r(Y9e," (CvT model)"),Y9e.forEach(t),d8o=i(x),l_=n(x,"LI",{});var K9e=s(l_);Fce=n(K9e,"STRONG",{});var sht=s(Fce);c8o=r(sht,"data2vec-audio"),sht.forEach(t),f8o=r(K9e," \u2014 "),fj=n(K9e,"A",{href:!0});var lht=s(fj);m8o=r(lht,"Data2VecAudioModel"),lht.forEach(t),g8o=r(K9e," (Data2VecAudio model)"),K9e.forEach(t),h8o=i(x),i_=n(x,"LI",{});var Z9e=s(i_);Tce=n(Z9e,"STRONG",{});var iht=s(Tce);p8o=r(iht,"data2vec-text"),iht.forEach(t),_8o=r(Z9e," \u2014 "),mj=n(Z9e,"A",{href:!0});var dht=s(mj);u8o=r(dht,"Data2VecTextModel"),dht.forEach(t),b8o=r(Z9e," (Data2VecText model)"),Z9e.forEach(t),v8o=i(x),d_=n(x,"LI",{});var exe=s(d_);Mce=n(exe,"STRONG",{});var cht=s(Mce);F8o=r(cht,"data2vec-vision"),cht.forEach(t),T8o=r(exe," \u2014 "),gj=n(exe,"A",{href:!0});var fht=s(gj);M8o=r(fht,"Data2VecVisionModel"),fht.forEach(t),E8o=r(exe," (Data2VecVision model)"),exe.forEach(t),C8o=i(x),c_=n(x,"LI",{});var oxe=s(c_);Ece=n(oxe,"STRONG",{});var mht=s(Ece);w8o=r(mht,"deberta"),mht.forEach(t),A8o=r(oxe," \u2014 "),hj=n(oxe,"A",{href:!0});var ght=s(hj);L8o=r(ght,"DebertaModel"),ght.forEach(t),y8o=r(oxe," (DeBERTa model)"),oxe.forEach(t),x8o=i(x),f_=n(x,"LI",{});var rxe=s(f_);Cce=n(rxe,"STRONG",{});var hht=s(Cce);$8o=r(hht,"deberta-v2"),hht.forEach(t),k8o=r(rxe," \u2014 "),pj=n(rxe,"A",{href:!0});var pht=s(pj);S8o=r(pht,"DebertaV2Model"),pht.forEach(t),R8o=r(rxe," (DeBERTa-v2 model)"),rxe.forEach(t),P8o=i(x),m_=n(x,"LI",{});var txe=s(m_);wce=n(txe,"STRONG",{});var _ht=s(wce);B8o=r(_ht,"decision_transformer"),_ht.forEach(t),I8o=r(txe," \u2014 "),_j=n(txe,"A",{href:!0});var uht=s(_j);N8o=r(uht,"DecisionTransformerModel"),uht.forEach(t),q8o=r(txe," (Decision Transformer model)"),txe.forEach(t),j8o=i(x),g_=n(x,"LI",{});var axe=s(g_);Ace=n(axe,"STRONG",{});var bht=s(Ace);D8o=r(bht,"deit"),bht.forEach(t),G8o=r(axe," \u2014 "),uj=n(axe,"A",{href:!0});var vht=s(uj);O8o=r(vht,"DeiTModel"),vht.forEach(t),V8o=r(axe," (DeiT model)"),axe.forEach(t),X8o=i(x),h_=n(x,"LI",{});var nxe=s(h_);Lce=n(nxe,"STRONG",{});var Fht=s(Lce);z8o=r(Fht,"detr"),Fht.forEach(t),Q8o=r(nxe," \u2014 "),bj=n(nxe,"A",{href:!0});var Tht=s(bj);W8o=r(Tht,"DetrModel"),Tht.forEach(t),H8o=r(nxe," (DETR model)"),nxe.forEach(t),U8o=i(x),p_=n(x,"LI",{});var sxe=s(p_);yce=n(sxe,"STRONG",{});var Mht=s(yce);J8o=r(Mht,"distilbert"),Mht.forEach(t),Y8o=r(sxe," \u2014 "),vj=n(sxe,"A",{href:!0});var Eht=s(vj);K8o=r(Eht,"DistilBertModel"),Eht.forEach(t),Z8o=r(sxe," (DistilBERT model)"),sxe.forEach(t),eMo=i(x),__=n(x,"LI",{});var lxe=s(__);xce=n(lxe,"STRONG",{});var Cht=s(xce);oMo=r(Cht,"dpr"),Cht.forEach(t),rMo=r(lxe," \u2014 "),Fj=n(lxe,"A",{href:!0});var wht=s(Fj);tMo=r(wht,"DPRQuestionEncoder"),wht.forEach(t),aMo=r(lxe," (DPR model)"),lxe.forEach(t),nMo=i(x),u_=n(x,"LI",{});var ixe=s(u_);$ce=n(ixe,"STRONG",{});var Aht=s($ce);sMo=r(Aht,"dpt"),Aht.forEach(t),lMo=r(ixe," \u2014 "),Tj=n(ixe,"A",{href:!0});var Lht=s(Tj);iMo=r(Lht,"DPTModel"),Lht.forEach(t),dMo=r(ixe," (DPT model)"),ixe.forEach(t),cMo=i(x),b_=n(x,"LI",{});var dxe=s(b_);kce=n(dxe,"STRONG",{});var yht=s(kce);fMo=r(yht,"electra"),yht.forEach(t),mMo=r(dxe," \u2014 "),Mj=n(dxe,"A",{href:!0});var xht=s(Mj);gMo=r(xht,"ElectraModel"),xht.forEach(t),hMo=r(dxe," (ELECTRA model)"),dxe.forEach(t),pMo=i(x),v_=n(x,"LI",{});var cxe=s(v_);Sce=n(cxe,"STRONG",{});var $ht=s(Sce);_Mo=r($ht,"flaubert"),$ht.forEach(t),uMo=r(cxe," \u2014 "),Ej=n(cxe,"A",{href:!0});var kht=s(Ej);bMo=r(kht,"FlaubertModel"),kht.forEach(t),vMo=r(cxe," (FlauBERT model)"),cxe.forEach(t),FMo=i(x),F_=n(x,"LI",{});var fxe=s(F_);Rce=n(fxe,"STRONG",{});var Sht=s(Rce);TMo=r(Sht,"flava"),Sht.forEach(t),MMo=r(fxe," \u2014 "),Cj=n(fxe,"A",{href:!0});var Rht=s(Cj);EMo=r(Rht,"FlavaModel"),Rht.forEach(t),CMo=r(fxe," (FLAVA model)"),fxe.forEach(t),wMo=i(x),T_=n(x,"LI",{});var mxe=s(T_);Pce=n(mxe,"STRONG",{});var Pht=s(Pce);AMo=r(Pht,"fnet"),Pht.forEach(t),LMo=r(mxe," \u2014 "),wj=n(mxe,"A",{href:!0});var Bht=s(wj);yMo=r(Bht,"FNetModel"),Bht.forEach(t),xMo=r(mxe," (FNet model)"),mxe.forEach(t),$Mo=i(x),M_=n(x,"LI",{});var gxe=s(M_);Bce=n(gxe,"STRONG",{});var Iht=s(Bce);kMo=r(Iht,"fsmt"),Iht.forEach(t),SMo=r(gxe," \u2014 "),Aj=n(gxe,"A",{href:!0});var Nht=s(Aj);RMo=r(Nht,"FSMTModel"),Nht.forEach(t),PMo=r(gxe," (FairSeq Machine-Translation model)"),gxe.forEach(t),BMo=i(x),Qs=n(x,"LI",{});var LS=s(Qs);Ice=n(LS,"STRONG",{});var qht=s(Ice);IMo=r(qht,"funnel"),qht.forEach(t),NMo=r(LS," \u2014 "),Lj=n(LS,"A",{href:!0});var jht=s(Lj);qMo=r(jht,"FunnelModel"),jht.forEach(t),jMo=r(LS," or "),yj=n(LS,"A",{href:!0});var Dht=s(yj);DMo=r(Dht,"FunnelBaseModel"),Dht.forEach(t),GMo=r(LS," (Funnel Transformer model)"),LS.forEach(t),OMo=i(x),E_=n(x,"LI",{});var hxe=s(E_);Nce=n(hxe,"STRONG",{});var Ght=s(Nce);VMo=r(Ght,"glpn"),Ght.forEach(t),XMo=r(hxe," \u2014 "),xj=n(hxe,"A",{href:!0});var Oht=s(xj);zMo=r(Oht,"GLPNModel"),Oht.forEach(t),QMo=r(hxe," (GLPN model)"),hxe.forEach(t),WMo=i(x),C_=n(x,"LI",{});var pxe=s(C_);qce=n(pxe,"STRONG",{});var Vht=s(qce);HMo=r(Vht,"gpt2"),Vht.forEach(t),UMo=r(pxe," \u2014 "),$j=n(pxe,"A",{href:!0});var Xht=s($j);JMo=r(Xht,"GPT2Model"),Xht.forEach(t),YMo=r(pxe," (OpenAI GPT-2 model)"),pxe.forEach(t),KMo=i(x),w_=n(x,"LI",{});var _xe=s(w_);jce=n(_xe,"STRONG",{});var zht=s(jce);ZMo=r(zht,"gpt_neo"),zht.forEach(t),e4o=r(_xe," \u2014 "),kj=n(_xe,"A",{href:!0});var Qht=s(kj);o4o=r(Qht,"GPTNeoModel"),Qht.forEach(t),r4o=r(_xe," (GPT Neo model)"),_xe.forEach(t),t4o=i(x),A_=n(x,"LI",{});var uxe=s(A_);Dce=n(uxe,"STRONG",{});var Wht=s(Dce);a4o=r(Wht,"gpt_neox"),Wht.forEach(t),n4o=r(uxe," \u2014 "),Sj=n(uxe,"A",{href:!0});var Hht=s(Sj);s4o=r(Hht,"GPTNeoXModel"),Hht.forEach(t),l4o=r(uxe," (GPT NeoX model)"),uxe.forEach(t),i4o=i(x),L_=n(x,"LI",{});var bxe=s(L_);Gce=n(bxe,"STRONG",{});var Uht=s(Gce);d4o=r(Uht,"gptj"),Uht.forEach(t),c4o=r(bxe," \u2014 "),Rj=n(bxe,"A",{href:!0});var Jht=s(Rj);f4o=r(Jht,"GPTJModel"),Jht.forEach(t),m4o=r(bxe," (GPT-J model)"),bxe.forEach(t),g4o=i(x),y_=n(x,"LI",{});var vxe=s(y_);Oce=n(vxe,"STRONG",{});var Yht=s(Oce);h4o=r(Yht,"groupvit"),Yht.forEach(t),p4o=r(vxe," \u2014 "),Pj=n(vxe,"A",{href:!0});var Kht=s(Pj);_4o=r(Kht,"GroupViTModel"),Kht.forEach(t),u4o=r(vxe," (GroupViT model)"),vxe.forEach(t),b4o=i(x),x_=n(x,"LI",{});var Fxe=s(x_);Vce=n(Fxe,"STRONG",{});var Zht=s(Vce);v4o=r(Zht,"hubert"),Zht.forEach(t),F4o=r(Fxe," \u2014 "),Bj=n(Fxe,"A",{href:!0});var ept=s(Bj);T4o=r(ept,"HubertModel"),ept.forEach(t),M4o=r(Fxe," (Hubert model)"),Fxe.forEach(t),E4o=i(x),$_=n(x,"LI",{});var Txe=s($_);Xce=n(Txe,"STRONG",{});var opt=s(Xce);C4o=r(opt,"ibert"),opt.forEach(t),w4o=r(Txe," \u2014 "),Ij=n(Txe,"A",{href:!0});var rpt=s(Ij);A4o=r(rpt,"IBertModel"),rpt.forEach(t),L4o=r(Txe," (I-BERT model)"),Txe.forEach(t),y4o=i(x),k_=n(x,"LI",{});var Mxe=s(k_);zce=n(Mxe,"STRONG",{});var tpt=s(zce);x4o=r(tpt,"imagegpt"),tpt.forEach(t),$4o=r(Mxe," \u2014 "),Nj=n(Mxe,"A",{href:!0});var apt=s(Nj);k4o=r(apt,"ImageGPTModel"),apt.forEach(t),S4o=r(Mxe," (ImageGPT model)"),Mxe.forEach(t),R4o=i(x),S_=n(x,"LI",{});var Exe=s(S_);Qce=n(Exe,"STRONG",{});var npt=s(Qce);P4o=r(npt,"layoutlm"),npt.forEach(t),B4o=r(Exe," \u2014 "),qj=n(Exe,"A",{href:!0});var spt=s(qj);I4o=r(spt,"LayoutLMModel"),spt.forEach(t),N4o=r(Exe," (LayoutLM model)"),Exe.forEach(t),q4o=i(x),R_=n(x,"LI",{});var Cxe=s(R_);Wce=n(Cxe,"STRONG",{});var lpt=s(Wce);j4o=r(lpt,"layoutlmv2"),lpt.forEach(t),D4o=r(Cxe," \u2014 "),jj=n(Cxe,"A",{href:!0});var ipt=s(jj);G4o=r(ipt,"LayoutLMv2Model"),ipt.forEach(t),O4o=r(Cxe," (LayoutLMv2 model)"),Cxe.forEach(t),V4o=i(x),P_=n(x,"LI",{});var wxe=s(P_);Hce=n(wxe,"STRONG",{});var dpt=s(Hce);X4o=r(dpt,"layoutlmv3"),dpt.forEach(t),z4o=r(wxe," \u2014 "),Dj=n(wxe,"A",{href:!0});var cpt=s(Dj);Q4o=r(cpt,"LayoutLMv3Model"),cpt.forEach(t),W4o=r(wxe," (LayoutLMv3 model)"),wxe.forEach(t),H4o=i(x),B_=n(x,"LI",{});var Axe=s(B_);Uce=n(Axe,"STRONG",{});var fpt=s(Uce);U4o=r(fpt,"led"),fpt.forEach(t),J4o=r(Axe," \u2014 "),Gj=n(Axe,"A",{href:!0});var mpt=s(Gj);Y4o=r(mpt,"LEDModel"),mpt.forEach(t),K4o=r(Axe," (LED model)"),Axe.forEach(t),Z4o=i(x),I_=n(x,"LI",{});var Lxe=s(I_);Jce=n(Lxe,"STRONG",{});var gpt=s(Jce);eEo=r(gpt,"levit"),gpt.forEach(t),oEo=r(Lxe," \u2014 "),Oj=n(Lxe,"A",{href:!0});var hpt=s(Oj);rEo=r(hpt,"LevitModel"),hpt.forEach(t),tEo=r(Lxe," (LeViT model)"),Lxe.forEach(t),aEo=i(x),N_=n(x,"LI",{});var yxe=s(N_);Yce=n(yxe,"STRONG",{});var ppt=s(Yce);nEo=r(ppt,"longformer"),ppt.forEach(t),sEo=r(yxe," \u2014 "),Vj=n(yxe,"A",{href:!0});var _pt=s(Vj);lEo=r(_pt,"LongformerModel"),_pt.forEach(t),iEo=r(yxe," (Longformer model)"),yxe.forEach(t),dEo=i(x),q_=n(x,"LI",{});var xxe=s(q_);Kce=n(xxe,"STRONG",{});var upt=s(Kce);cEo=r(upt,"longt5"),upt.forEach(t),fEo=r(xxe," \u2014 "),Xj=n(xxe,"A",{href:!0});var bpt=s(Xj);mEo=r(bpt,"LongT5Model"),bpt.forEach(t),gEo=r(xxe," (LongT5 model)"),xxe.forEach(t),hEo=i(x),j_=n(x,"LI",{});var $xe=s(j_);Zce=n($xe,"STRONG",{});var vpt=s(Zce);pEo=r(vpt,"luke"),vpt.forEach(t),_Eo=r($xe," \u2014 "),zj=n($xe,"A",{href:!0});var Fpt=s(zj);uEo=r(Fpt,"LukeModel"),Fpt.forEach(t),bEo=r($xe," (LUKE model)"),$xe.forEach(t),vEo=i(x),D_=n(x,"LI",{});var kxe=s(D_);efe=n(kxe,"STRONG",{});var Tpt=s(efe);FEo=r(Tpt,"lxmert"),Tpt.forEach(t),TEo=r(kxe," \u2014 "),Qj=n(kxe,"A",{href:!0});var Mpt=s(Qj);MEo=r(Mpt,"LxmertModel"),Mpt.forEach(t),EEo=r(kxe," (LXMERT model)"),kxe.forEach(t),CEo=i(x),G_=n(x,"LI",{});var Sxe=s(G_);ofe=n(Sxe,"STRONG",{});var Ept=s(ofe);wEo=r(Ept,"m2m_100"),Ept.forEach(t),AEo=r(Sxe," \u2014 "),Wj=n(Sxe,"A",{href:!0});var Cpt=s(Wj);LEo=r(Cpt,"M2M100Model"),Cpt.forEach(t),yEo=r(Sxe," (M2M100 model)"),Sxe.forEach(t),xEo=i(x),O_=n(x,"LI",{});var Rxe=s(O_);rfe=n(Rxe,"STRONG",{});var wpt=s(rfe);$Eo=r(wpt,"marian"),wpt.forEach(t),kEo=r(Rxe," \u2014 "),Hj=n(Rxe,"A",{href:!0});var Apt=s(Hj);SEo=r(Apt,"MarianModel"),Apt.forEach(t),REo=r(Rxe," (Marian model)"),Rxe.forEach(t),PEo=i(x),V_=n(x,"LI",{});var Pxe=s(V_);tfe=n(Pxe,"STRONG",{});var Lpt=s(tfe);BEo=r(Lpt,"maskformer"),Lpt.forEach(t),IEo=r(Pxe," \u2014 "),Uj=n(Pxe,"A",{href:!0});var ypt=s(Uj);NEo=r(ypt,"MaskFormerModel"),ypt.forEach(t),qEo=r(Pxe," (MaskFormer model)"),Pxe.forEach(t),jEo=i(x),X_=n(x,"LI",{});var Bxe=s(X_);afe=n(Bxe,"STRONG",{});var xpt=s(afe);DEo=r(xpt,"mbart"),xpt.forEach(t),GEo=r(Bxe," \u2014 "),Jj=n(Bxe,"A",{href:!0});var $pt=s(Jj);OEo=r($pt,"MBartModel"),$pt.forEach(t),VEo=r(Bxe," (mBART model)"),Bxe.forEach(t),XEo=i(x),z_=n(x,"LI",{});var Ixe=s(z_);nfe=n(Ixe,"STRONG",{});var kpt=s(nfe);zEo=r(kpt,"mctct"),kpt.forEach(t),QEo=r(Ixe," \u2014 "),Yj=n(Ixe,"A",{href:!0});var Spt=s(Yj);WEo=r(Spt,"MCTCTModel"),Spt.forEach(t),HEo=r(Ixe," (M-CTC-T model)"),Ixe.forEach(t),UEo=i(x),Q_=n(x,"LI",{});var Nxe=s(Q_);sfe=n(Nxe,"STRONG",{});var Rpt=s(sfe);JEo=r(Rpt,"megatron-bert"),Rpt.forEach(t),YEo=r(Nxe," \u2014 "),Kj=n(Nxe,"A",{href:!0});var Ppt=s(Kj);KEo=r(Ppt,"MegatronBertModel"),Ppt.forEach(t),ZEo=r(Nxe," (Megatron-BERT model)"),Nxe.forEach(t),eCo=i(x),W_=n(x,"LI",{});var qxe=s(W_);lfe=n(qxe,"STRONG",{});var Bpt=s(lfe);oCo=r(Bpt,"mobilebert"),Bpt.forEach(t),rCo=r(qxe," \u2014 "),Zj=n(qxe,"A",{href:!0});var Ipt=s(Zj);tCo=r(Ipt,"MobileBertModel"),Ipt.forEach(t),aCo=r(qxe," (MobileBERT model)"),qxe.forEach(t),nCo=i(x),H_=n(x,"LI",{});var jxe=s(H_);ife=n(jxe,"STRONG",{});var Npt=s(ife);sCo=r(Npt,"mobilevit"),Npt.forEach(t),lCo=r(jxe," \u2014 "),eD=n(jxe,"A",{href:!0});var qpt=s(eD);iCo=r(qpt,"MobileViTModel"),qpt.forEach(t),dCo=r(jxe," (MobileViT model)"),jxe.forEach(t),cCo=i(x),U_=n(x,"LI",{});var Dxe=s(U_);dfe=n(Dxe,"STRONG",{});var jpt=s(dfe);fCo=r(jpt,"mpnet"),jpt.forEach(t),mCo=r(Dxe," \u2014 "),oD=n(Dxe,"A",{href:!0});var Dpt=s(oD);gCo=r(Dpt,"MPNetModel"),Dpt.forEach(t),hCo=r(Dxe," (MPNet model)"),Dxe.forEach(t),pCo=i(x),J_=n(x,"LI",{});var Gxe=s(J_);cfe=n(Gxe,"STRONG",{});var Gpt=s(cfe);_Co=r(Gpt,"mt5"),Gpt.forEach(t),uCo=r(Gxe," \u2014 "),rD=n(Gxe,"A",{href:!0});var Opt=s(rD);bCo=r(Opt,"MT5Model"),Opt.forEach(t),vCo=r(Gxe," (MT5 model)"),Gxe.forEach(t),FCo=i(x),Y_=n(x,"LI",{});var Oxe=s(Y_);ffe=n(Oxe,"STRONG",{});var Vpt=s(ffe);TCo=r(Vpt,"mvp"),Vpt.forEach(t),MCo=r(Oxe," \u2014 "),tD=n(Oxe,"A",{href:!0});var Xpt=s(tD);ECo=r(Xpt,"MvpModel"),Xpt.forEach(t),CCo=r(Oxe," (MVP model)"),Oxe.forEach(t),wCo=i(x),K_=n(x,"LI",{});var Vxe=s(K_);mfe=n(Vxe,"STRONG",{});var zpt=s(mfe);ACo=r(zpt,"nezha"),zpt.forEach(t),LCo=r(Vxe," \u2014 "),aD=n(Vxe,"A",{href:!0});var Qpt=s(aD);yCo=r(Qpt,"NezhaModel"),Qpt.forEach(t),xCo=r(Vxe," (Nezha model)"),Vxe.forEach(t),$Co=i(x),Z_=n(x,"LI",{});var Xxe=s(Z_);gfe=n(Xxe,"STRONG",{});var Wpt=s(gfe);kCo=r(Wpt,"nystromformer"),Wpt.forEach(t),SCo=r(Xxe," \u2014 "),nD=n(Xxe,"A",{href:!0});var Hpt=s(nD);RCo=r(Hpt,"NystromformerModel"),Hpt.forEach(t),PCo=r(Xxe," (Nystr\xF6mformer model)"),Xxe.forEach(t),BCo=i(x),eu=n(x,"LI",{});var zxe=s(eu);hfe=n(zxe,"STRONG",{});var Upt=s(hfe);ICo=r(Upt,"openai-gpt"),Upt.forEach(t),NCo=r(zxe," \u2014 "),sD=n(zxe,"A",{href:!0});var Jpt=s(sD);qCo=r(Jpt,"OpenAIGPTModel"),Jpt.forEach(t),jCo=r(zxe," (OpenAI GPT model)"),zxe.forEach(t),DCo=i(x),ou=n(x,"LI",{});var Qxe=s(ou);pfe=n(Qxe,"STRONG",{});var Ypt=s(pfe);GCo=r(Ypt,"opt"),Ypt.forEach(t),OCo=r(Qxe," \u2014 "),lD=n(Qxe,"A",{href:!0});var Kpt=s(lD);VCo=r(Kpt,"OPTModel"),Kpt.forEach(t),XCo=r(Qxe," (OPT model)"),Qxe.forEach(t),zCo=i(x),ru=n(x,"LI",{});var Wxe=s(ru);_fe=n(Wxe,"STRONG",{});var Zpt=s(_fe);QCo=r(Zpt,"pegasus"),Zpt.forEach(t),WCo=r(Wxe," \u2014 "),iD=n(Wxe,"A",{href:!0});var e_t=s(iD);HCo=r(e_t,"PegasusModel"),e_t.forEach(t),UCo=r(Wxe," (Pegasus model)"),Wxe.forEach(t),JCo=i(x),tu=n(x,"LI",{});var Hxe=s(tu);ufe=n(Hxe,"STRONG",{});var o_t=s(ufe);YCo=r(o_t,"perceiver"),o_t.forEach(t),KCo=r(Hxe," \u2014 "),dD=n(Hxe,"A",{href:!0});var r_t=s(dD);ZCo=r(r_t,"PerceiverModel"),r_t.forEach(t),e3o=r(Hxe," (Perceiver model)"),Hxe.forEach(t),o3o=i(x),au=n(x,"LI",{});var Uxe=s(au);bfe=n(Uxe,"STRONG",{});var t_t=s(bfe);r3o=r(t_t,"plbart"),t_t.forEach(t),t3o=r(Uxe," \u2014 "),cD=n(Uxe,"A",{href:!0});var a_t=s(cD);a3o=r(a_t,"PLBartModel"),a_t.forEach(t),n3o=r(Uxe," (PLBart model)"),Uxe.forEach(t),s3o=i(x),nu=n(x,"LI",{});var Jxe=s(nu);vfe=n(Jxe,"STRONG",{});var n_t=s(vfe);l3o=r(n_t,"poolformer"),n_t.forEach(t),i3o=r(Jxe," \u2014 "),fD=n(Jxe,"A",{href:!0});var s_t=s(fD);d3o=r(s_t,"PoolFormerModel"),s_t.forEach(t),c3o=r(Jxe," (PoolFormer model)"),Jxe.forEach(t),f3o=i(x),su=n(x,"LI",{});var Yxe=s(su);Ffe=n(Yxe,"STRONG",{});var l_t=s(Ffe);m3o=r(l_t,"prophetnet"),l_t.forEach(t),g3o=r(Yxe," \u2014 "),mD=n(Yxe,"A",{href:!0});var i_t=s(mD);h3o=r(i_t,"ProphetNetModel"),i_t.forEach(t),p3o=r(Yxe," (ProphetNet model)"),Yxe.forEach(t),_3o=i(x),lu=n(x,"LI",{});var Kxe=s(lu);Tfe=n(Kxe,"STRONG",{});var d_t=s(Tfe);u3o=r(d_t,"qdqbert"),d_t.forEach(t),b3o=r(Kxe," \u2014 "),gD=n(Kxe,"A",{href:!0});var c_t=s(gD);v3o=r(c_t,"QDQBertModel"),c_t.forEach(t),F3o=r(Kxe," (QDQBert model)"),Kxe.forEach(t),T3o=i(x),iu=n(x,"LI",{});var Zxe=s(iu);Mfe=n(Zxe,"STRONG",{});var f_t=s(Mfe);M3o=r(f_t,"reformer"),f_t.forEach(t),E3o=r(Zxe," \u2014 "),hD=n(Zxe,"A",{href:!0});var m_t=s(hD);C3o=r(m_t,"ReformerModel"),m_t.forEach(t),w3o=r(Zxe," (Reformer model)"),Zxe.forEach(t),A3o=i(x),du=n(x,"LI",{});var e$e=s(du);Efe=n(e$e,"STRONG",{});var g_t=s(Efe);L3o=r(g_t,"regnet"),g_t.forEach(t),y3o=r(e$e," \u2014 "),pD=n(e$e,"A",{href:!0});var h_t=s(pD);x3o=r(h_t,"RegNetModel"),h_t.forEach(t),$3o=r(e$e," (RegNet model)"),e$e.forEach(t),k3o=i(x),cu=n(x,"LI",{});var o$e=s(cu);Cfe=n(o$e,"STRONG",{});var p_t=s(Cfe);S3o=r(p_t,"rembert"),p_t.forEach(t),R3o=r(o$e," \u2014 "),_D=n(o$e,"A",{href:!0});var __t=s(_D);P3o=r(__t,"RemBertModel"),__t.forEach(t),B3o=r(o$e," (RemBERT model)"),o$e.forEach(t),I3o=i(x),fu=n(x,"LI",{});var r$e=s(fu);wfe=n(r$e,"STRONG",{});var u_t=s(wfe);N3o=r(u_t,"resnet"),u_t.forEach(t),q3o=r(r$e," \u2014 "),uD=n(r$e,"A",{href:!0});var b_t=s(uD);j3o=r(b_t,"ResNetModel"),b_t.forEach(t),D3o=r(r$e," (ResNet model)"),r$e.forEach(t),G3o=i(x),mu=n(x,"LI",{});var t$e=s(mu);Afe=n(t$e,"STRONG",{});var v_t=s(Afe);O3o=r(v_t,"retribert"),v_t.forEach(t),V3o=r(t$e," \u2014 "),bD=n(t$e,"A",{href:!0});var F_t=s(bD);X3o=r(F_t,"RetriBertModel"),F_t.forEach(t),z3o=r(t$e," (RetriBERT model)"),t$e.forEach(t),Q3o=i(x),gu=n(x,"LI",{});var a$e=s(gu);Lfe=n(a$e,"STRONG",{});var T_t=s(Lfe);W3o=r(T_t,"roberta"),T_t.forEach(t),H3o=r(a$e," \u2014 "),vD=n(a$e,"A",{href:!0});var M_t=s(vD);U3o=r(M_t,"RobertaModel"),M_t.forEach(t),J3o=r(a$e," (RoBERTa model)"),a$e.forEach(t),Y3o=i(x),hu=n(x,"LI",{});var n$e=s(hu);yfe=n(n$e,"STRONG",{});var E_t=s(yfe);K3o=r(E_t,"roformer"),E_t.forEach(t),Z3o=r(n$e," \u2014 "),FD=n(n$e,"A",{href:!0});var C_t=s(FD);e5o=r(C_t,"RoFormerModel"),C_t.forEach(t),o5o=r(n$e," (RoFormer model)"),n$e.forEach(t),r5o=i(x),pu=n(x,"LI",{});var s$e=s(pu);xfe=n(s$e,"STRONG",{});var w_t=s(xfe);t5o=r(w_t,"segformer"),w_t.forEach(t),a5o=r(s$e," \u2014 "),TD=n(s$e,"A",{href:!0});var A_t=s(TD);n5o=r(A_t,"SegformerModel"),A_t.forEach(t),s5o=r(s$e," (SegFormer model)"),s$e.forEach(t),l5o=i(x),_u=n(x,"LI",{});var l$e=s(_u);$fe=n(l$e,"STRONG",{});var L_t=s($fe);i5o=r(L_t,"sew"),L_t.forEach(t),d5o=r(l$e," \u2014 "),MD=n(l$e,"A",{href:!0});var y_t=s(MD);c5o=r(y_t,"SEWModel"),y_t.forEach(t),f5o=r(l$e," (SEW model)"),l$e.forEach(t),m5o=i(x),uu=n(x,"LI",{});var i$e=s(uu);kfe=n(i$e,"STRONG",{});var x_t=s(kfe);g5o=r(x_t,"sew-d"),x_t.forEach(t),h5o=r(i$e," \u2014 "),ED=n(i$e,"A",{href:!0});var $_t=s(ED);p5o=r($_t,"SEWDModel"),$_t.forEach(t),_5o=r(i$e," (SEW-D model)"),i$e.forEach(t),u5o=i(x),bu=n(x,"LI",{});var d$e=s(bu);Sfe=n(d$e,"STRONG",{});var k_t=s(Sfe);b5o=r(k_t,"speech_to_text"),k_t.forEach(t),v5o=r(d$e," \u2014 "),CD=n(d$e,"A",{href:!0});var S_t=s(CD);F5o=r(S_t,"Speech2TextModel"),S_t.forEach(t),T5o=r(d$e," (Speech2Text model)"),d$e.forEach(t),M5o=i(x),vu=n(x,"LI",{});var c$e=s(vu);Rfe=n(c$e,"STRONG",{});var R_t=s(Rfe);E5o=r(R_t,"splinter"),R_t.forEach(t),C5o=r(c$e," \u2014 "),wD=n(c$e,"A",{href:!0});var P_t=s(wD);w5o=r(P_t,"SplinterModel"),P_t.forEach(t),A5o=r(c$e," (Splinter model)"),c$e.forEach(t),L5o=i(x),Fu=n(x,"LI",{});var f$e=s(Fu);Pfe=n(f$e,"STRONG",{});var B_t=s(Pfe);y5o=r(B_t,"squeezebert"),B_t.forEach(t),x5o=r(f$e," \u2014 "),AD=n(f$e,"A",{href:!0});var I_t=s(AD);$5o=r(I_t,"SqueezeBertModel"),I_t.forEach(t),k5o=r(f$e," (SqueezeBERT model)"),f$e.forEach(t),S5o=i(x),Tu=n(x,"LI",{});var m$e=s(Tu);Bfe=n(m$e,"STRONG",{});var N_t=s(Bfe);R5o=r(N_t,"swin"),N_t.forEach(t),P5o=r(m$e," \u2014 "),LD=n(m$e,"A",{href:!0});var q_t=s(LD);B5o=r(q_t,"SwinModel"),q_t.forEach(t),I5o=r(m$e," (Swin Transformer model)"),m$e.forEach(t),N5o=i(x),Mu=n(x,"LI",{});var g$e=s(Mu);Ife=n(g$e,"STRONG",{});var j_t=s(Ife);q5o=r(j_t,"t5"),j_t.forEach(t),j5o=r(g$e," \u2014 "),yD=n(g$e,"A",{href:!0});var D_t=s(yD);D5o=r(D_t,"T5Model"),D_t.forEach(t),G5o=r(g$e," (T5 model)"),g$e.forEach(t),O5o=i(x),Eu=n(x,"LI",{});var h$e=s(Eu);Nfe=n(h$e,"STRONG",{});var G_t=s(Nfe);V5o=r(G_t,"tapas"),G_t.forEach(t),X5o=r(h$e," \u2014 "),xD=n(h$e,"A",{href:!0});var O_t=s(xD);z5o=r(O_t,"TapasModel"),O_t.forEach(t),Q5o=r(h$e," (TAPAS model)"),h$e.forEach(t),W5o=i(x),Cu=n(x,"LI",{});var p$e=s(Cu);qfe=n(p$e,"STRONG",{});var V_t=s(qfe);H5o=r(V_t,"trajectory_transformer"),V_t.forEach(t),U5o=r(p$e," \u2014 "),$D=n(p$e,"A",{href:!0});var X_t=s($D);J5o=r(X_t,"TrajectoryTransformerModel"),X_t.forEach(t),Y5o=r(p$e," (Trajectory Transformer model)"),p$e.forEach(t),K5o=i(x),wu=n(x,"LI",{});var _$e=s(wu);jfe=n(_$e,"STRONG",{});var z_t=s(jfe);Z5o=r(z_t,"transfo-xl"),z_t.forEach(t),e0o=r(_$e," \u2014 "),kD=n(_$e,"A",{href:!0});var Q_t=s(kD);o0o=r(Q_t,"TransfoXLModel"),Q_t.forEach(t),r0o=r(_$e," (Transformer-XL model)"),_$e.forEach(t),t0o=i(x),Au=n(x,"LI",{});var u$e=s(Au);Dfe=n(u$e,"STRONG",{});var W_t=s(Dfe);a0o=r(W_t,"unispeech"),W_t.forEach(t),n0o=r(u$e," \u2014 "),SD=n(u$e,"A",{href:!0});var H_t=s(SD);s0o=r(H_t,"UniSpeechModel"),H_t.forEach(t),l0o=r(u$e," (UniSpeech model)"),u$e.forEach(t),i0o=i(x),Lu=n(x,"LI",{});var b$e=s(Lu);Gfe=n(b$e,"STRONG",{});var U_t=s(Gfe);d0o=r(U_t,"unispeech-sat"),U_t.forEach(t),c0o=r(b$e," \u2014 "),RD=n(b$e,"A",{href:!0});var J_t=s(RD);f0o=r(J_t,"UniSpeechSatModel"),J_t.forEach(t),m0o=r(b$e," (UniSpeechSat model)"),b$e.forEach(t),g0o=i(x),yu=n(x,"LI",{});var v$e=s(yu);Ofe=n(v$e,"STRONG",{});var Y_t=s(Ofe);h0o=r(Y_t,"van"),Y_t.forEach(t),p0o=r(v$e," \u2014 "),PD=n(v$e,"A",{href:!0});var K_t=s(PD);_0o=r(K_t,"VanModel"),K_t.forEach(t),u0o=r(v$e," (VAN model)"),v$e.forEach(t),b0o=i(x),xu=n(x,"LI",{});var F$e=s(xu);Vfe=n(F$e,"STRONG",{});var Z_t=s(Vfe);v0o=r(Z_t,"vilt"),Z_t.forEach(t),F0o=r(F$e," \u2014 "),BD=n(F$e,"A",{href:!0});var eut=s(BD);T0o=r(eut,"ViltModel"),eut.forEach(t),M0o=r(F$e," (ViLT model)"),F$e.forEach(t),E0o=i(x),$u=n(x,"LI",{});var T$e=s($u);Xfe=n(T$e,"STRONG",{});var out=s(Xfe);C0o=r(out,"vision-text-dual-encoder"),out.forEach(t),w0o=r(T$e," \u2014 "),ID=n(T$e,"A",{href:!0});var rut=s(ID);A0o=r(rut,"VisionTextDualEncoderModel"),rut.forEach(t),L0o=r(T$e," (VisionTextDualEncoder model)"),T$e.forEach(t),y0o=i(x),ku=n(x,"LI",{});var M$e=s(ku);zfe=n(M$e,"STRONG",{});var tut=s(zfe);x0o=r(tut,"visual_bert"),tut.forEach(t),$0o=r(M$e," \u2014 "),ND=n(M$e,"A",{href:!0});var aut=s(ND);k0o=r(aut,"VisualBertModel"),aut.forEach(t),S0o=r(M$e," (VisualBERT model)"),M$e.forEach(t),R0o=i(x),Su=n(x,"LI",{});var E$e=s(Su);Qfe=n(E$e,"STRONG",{});var nut=s(Qfe);P0o=r(nut,"vit"),nut.forEach(t),B0o=r(E$e," \u2014 "),qD=n(E$e,"A",{href:!0});var sut=s(qD);I0o=r(sut,"ViTModel"),sut.forEach(t),N0o=r(E$e," (ViT model)"),E$e.forEach(t),q0o=i(x),Ru=n(x,"LI",{});var C$e=s(Ru);Wfe=n(C$e,"STRONG",{});var lut=s(Wfe);j0o=r(lut,"vit_mae"),lut.forEach(t),D0o=r(C$e," \u2014 "),jD=n(C$e,"A",{href:!0});var iut=s(jD);G0o=r(iut,"ViTMAEModel"),iut.forEach(t),O0o=r(C$e," (ViTMAE model)"),C$e.forEach(t),V0o=i(x),Pu=n(x,"LI",{});var w$e=s(Pu);Hfe=n(w$e,"STRONG",{});var dut=s(Hfe);X0o=r(dut,"wav2vec2"),dut.forEach(t),z0o=r(w$e," \u2014 "),DD=n(w$e,"A",{href:!0});var cut=s(DD);Q0o=r(cut,"Wav2Vec2Model"),cut.forEach(t),W0o=r(w$e," (Wav2Vec2 model)"),w$e.forEach(t),H0o=i(x),Bu=n(x,"LI",{});var A$e=s(Bu);Ufe=n(A$e,"STRONG",{});var fut=s(Ufe);U0o=r(fut,"wav2vec2-conformer"),fut.forEach(t),J0o=r(A$e," \u2014 "),GD=n(A$e,"A",{href:!0});var mut=s(GD);Y0o=r(mut,"Wav2Vec2ConformerModel"),mut.forEach(t),K0o=r(A$e," (Wav2Vec2-Conformer model)"),A$e.forEach(t),Z0o=i(x),Iu=n(x,"LI",{});var L$e=s(Iu);Jfe=n(L$e,"STRONG",{});var gut=s(Jfe);ewo=r(gut,"wavlm"),gut.forEach(t),owo=r(L$e," \u2014 "),OD=n(L$e,"A",{href:!0});var hut=s(OD);rwo=r(hut,"WavLMModel"),hut.forEach(t),two=r(L$e," (WavLM model)"),L$e.forEach(t),awo=i(x),Nu=n(x,"LI",{});var y$e=s(Nu);Yfe=n(y$e,"STRONG",{});var put=s(Yfe);nwo=r(put,"xglm"),put.forEach(t),swo=r(y$e," \u2014 "),VD=n(y$e,"A",{href:!0});var _ut=s(VD);lwo=r(_ut,"XGLMModel"),_ut.forEach(t),iwo=r(y$e," (XGLM model)"),y$e.forEach(t),dwo=i(x),qu=n(x,"LI",{});var x$e=s(qu);Kfe=n(x$e,"STRONG",{});var uut=s(Kfe);cwo=r(uut,"xlm"),uut.forEach(t),fwo=r(x$e," \u2014 "),XD=n(x$e,"A",{href:!0});var but=s(XD);mwo=r(but,"XLMModel"),but.forEach(t),gwo=r(x$e," (XLM model)"),x$e.forEach(t),hwo=i(x),ju=n(x,"LI",{});var $$e=s(ju);Zfe=n($$e,"STRONG",{});var vut=s(Zfe);pwo=r(vut,"xlm-prophetnet"),vut.forEach(t),_wo=r($$e," \u2014 "),zD=n($$e,"A",{href:!0});var Fut=s(zD);uwo=r(Fut,"XLMProphetNetModel"),Fut.forEach(t),bwo=r($$e," (XLM-ProphetNet model)"),$$e.forEach(t),vwo=i(x),Du=n(x,"LI",{});var k$e=s(Du);eme=n(k$e,"STRONG",{});var Tut=s(eme);Fwo=r(Tut,"xlm-roberta"),Tut.forEach(t),Two=r(k$e," \u2014 "),QD=n(k$e,"A",{href:!0});var Mut=s(QD);Mwo=r(Mut,"XLMRobertaModel"),Mut.forEach(t),Ewo=r(k$e," (XLM-RoBERTa model)"),k$e.forEach(t),Cwo=i(x),Gu=n(x,"LI",{});var S$e=s(Gu);ome=n(S$e,"STRONG",{});var Eut=s(ome);wwo=r(Eut,"xlm-roberta-xl"),Eut.forEach(t),Awo=r(S$e," \u2014 "),WD=n(S$e,"A",{href:!0});var Cut=s(WD);Lwo=r(Cut,"XLMRobertaXLModel"),Cut.forEach(t),ywo=r(S$e," (XLM-RoBERTa-XL model)"),S$e.forEach(t),xwo=i(x),Ou=n(x,"LI",{});var R$e=s(Ou);rme=n(R$e,"STRONG",{});var wut=s(rme);$wo=r(wut,"xlnet"),wut.forEach(t),kwo=r(R$e," \u2014 "),HD=n(R$e,"A",{href:!0});var Aut=s(HD);Swo=r(Aut,"XLNetModel"),Aut.forEach(t),Rwo=r(R$e," (XLNet model)"),R$e.forEach(t),Pwo=i(x),Vu=n(x,"LI",{});var P$e=s(Vu);tme=n(P$e,"STRONG",{});var Lut=s(tme);Bwo=r(Lut,"yolos"),Lut.forEach(t),Iwo=r(P$e," \u2014 "),UD=n(P$e,"A",{href:!0});var yut=s(UD);Nwo=r(yut,"YolosModel"),yut.forEach(t),qwo=r(P$e," (YOLOS model)"),P$e.forEach(t),jwo=i(x),Xu=n(x,"LI",{});var B$e=s(Xu);ame=n(B$e,"STRONG",{});var xut=s(ame);Dwo=r(xut,"yoso"),xut.forEach(t),Gwo=r(B$e," \u2014 "),JD=n(B$e,"A",{href:!0});var $ut=s(JD);Owo=r($ut,"YosoModel"),$ut.forEach(t),Vwo=r(B$e," (YOSO model)"),B$e.forEach(t),x.forEach(t),Xwo=i(sa),zu=n(sa,"P",{});var I$e=s(zu);zwo=r(I$e,"The model is set in evaluation mode by default using "),nme=n(I$e,"CODE",{});var kut=s(nme);Qwo=r(kut,"model.eval()"),kut.forEach(t),Wwo=r(I$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sme=n(I$e,"CODE",{});var Sut=s(sme);Hwo=r(Sut,"model.train()"),Sut.forEach(t),I$e.forEach(t),Uwo=i(sa),T(Qu.$$.fragment,sa),sa.forEach(t),el.forEach(t),ZVe=i(f),Vi=n(f,"H2",{class:!0});var nQe=s(Vi);Wu=n(nQe,"A",{id:!0,class:!0,href:!0});var Rut=s(Wu);lme=n(Rut,"SPAN",{});var Put=s(lme);T(SL.$$.fragment,Put),Put.forEach(t),Rut.forEach(t),Jwo=i(nQe),ime=n(nQe,"SPAN",{});var But=s(ime);Ywo=r(But,"AutoModelForPreTraining"),But.forEach(t),nQe.forEach(t),eXe=i(f),$o=n(f,"DIV",{class:!0});var ol=s($o);T(RL.$$.fragment,ol),Kwo=i(ol),Xi=n(ol,"P",{});var wre=s(Xi);Zwo=r(wre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),YD=n(wre,"A",{href:!0});var Iut=s(YD);eAo=r(Iut,"from_pretrained()"),Iut.forEach(t),oAo=r(wre," class method or the "),KD=n(wre,"A",{href:!0});var Nut=s(KD);rAo=r(Nut,"from_config()"),Nut.forEach(t),tAo=r(wre,` class
method.`),wre.forEach(t),aAo=i(ol),PL=n(ol,"P",{});var sQe=s(PL);nAo=r(sQe,"This class cannot be instantiated directly using "),dme=n(sQe,"CODE",{});var qut=s(dme);sAo=r(qut,"__init__()"),qut.forEach(t),lAo=r(sQe," (throws an error)."),sQe.forEach(t),iAo=i(ol),it=n(ol,"DIV",{class:!0});var lA=s(it);T(BL.$$.fragment,lA),dAo=i(lA),cme=n(lA,"P",{});var jut=s(cme);cAo=r(jut,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),jut.forEach(t),fAo=i(lA),zi=n(lA,"P",{});var Are=s(zi);mAo=r(Are,`Note:
Loading a model from its configuration file does `),fme=n(Are,"STRONG",{});var Dut=s(fme);gAo=r(Dut,"not"),Dut.forEach(t),hAo=r(Are,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZD=n(Are,"A",{href:!0});var Gut=s(ZD);pAo=r(Gut,"from_pretrained()"),Gut.forEach(t),_Ao=r(Are," to load the model weights."),Are.forEach(t),uAo=i(lA),T(Hu.$$.fragment,lA),lA.forEach(t),bAo=i(ol),Ye=n(ol,"DIV",{class:!0});var la=s(Ye);T(IL.$$.fragment,la),vAo=i(la),mme=n(la,"P",{});var Out=s(mme);FAo=r(Out,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Out.forEach(t),TAo=i(la),Ia=n(la,"P",{});var iA=s(Ia);MAo=r(iA,"The model class to instantiate is selected based on the "),gme=n(iA,"CODE",{});var Vut=s(gme);EAo=r(Vut,"model_type"),Vut.forEach(t),CAo=r(iA,` property of the config object (either
passed as an argument or loaded from `),hme=n(iA,"CODE",{});var Xut=s(hme);wAo=r(Xut,"pretrained_model_name_or_path"),Xut.forEach(t),AAo=r(iA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pme=n(iA,"CODE",{});var zut=s(pme);LAo=r(zut,"pretrained_model_name_or_path"),zut.forEach(t),yAo=r(iA,":"),iA.forEach(t),xAo=i(la),G=n(la,"UL",{});var O=s(G);Uu=n(O,"LI",{});var N$e=s(Uu);_me=n(N$e,"STRONG",{});var Qut=s(_me);$Ao=r(Qut,"albert"),Qut.forEach(t),kAo=r(N$e," \u2014 "),eG=n(N$e,"A",{href:!0});var Wut=s(eG);SAo=r(Wut,"AlbertForPreTraining"),Wut.forEach(t),RAo=r(N$e," (ALBERT model)"),N$e.forEach(t),PAo=i(O),Ju=n(O,"LI",{});var q$e=s(Ju);ume=n(q$e,"STRONG",{});var Hut=s(ume);BAo=r(Hut,"bart"),Hut.forEach(t),IAo=r(q$e," \u2014 "),oG=n(q$e,"A",{href:!0});var Uut=s(oG);NAo=r(Uut,"BartForConditionalGeneration"),Uut.forEach(t),qAo=r(q$e," (BART model)"),q$e.forEach(t),jAo=i(O),Yu=n(O,"LI",{});var j$e=s(Yu);bme=n(j$e,"STRONG",{});var Jut=s(bme);DAo=r(Jut,"bert"),Jut.forEach(t),GAo=r(j$e," \u2014 "),rG=n(j$e,"A",{href:!0});var Yut=s(rG);OAo=r(Yut,"BertForPreTraining"),Yut.forEach(t),VAo=r(j$e," (BERT model)"),j$e.forEach(t),XAo=i(O),Ku=n(O,"LI",{});var D$e=s(Ku);vme=n(D$e,"STRONG",{});var Kut=s(vme);zAo=r(Kut,"big_bird"),Kut.forEach(t),QAo=r(D$e," \u2014 "),tG=n(D$e,"A",{href:!0});var Zut=s(tG);WAo=r(Zut,"BigBirdForPreTraining"),Zut.forEach(t),HAo=r(D$e," (BigBird model)"),D$e.forEach(t),UAo=i(O),Zu=n(O,"LI",{});var G$e=s(Zu);Fme=n(G$e,"STRONG",{});var e1t=s(Fme);JAo=r(e1t,"bloom"),e1t.forEach(t),YAo=r(G$e," \u2014 "),aG=n(G$e,"A",{href:!0});var o1t=s(aG);KAo=r(o1t,"BloomForCausalLM"),o1t.forEach(t),ZAo=r(G$e," (BLOOM model)"),G$e.forEach(t),e6o=i(O),e1=n(O,"LI",{});var O$e=s(e1);Tme=n(O$e,"STRONG",{});var r1t=s(Tme);o6o=r(r1t,"camembert"),r1t.forEach(t),r6o=r(O$e," \u2014 "),nG=n(O$e,"A",{href:!0});var t1t=s(nG);t6o=r(t1t,"CamembertForMaskedLM"),t1t.forEach(t),a6o=r(O$e," (CamemBERT model)"),O$e.forEach(t),n6o=i(O),o1=n(O,"LI",{});var V$e=s(o1);Mme=n(V$e,"STRONG",{});var a1t=s(Mme);s6o=r(a1t,"ctrl"),a1t.forEach(t),l6o=r(V$e," \u2014 "),sG=n(V$e,"A",{href:!0});var n1t=s(sG);i6o=r(n1t,"CTRLLMHeadModel"),n1t.forEach(t),d6o=r(V$e," (CTRL model)"),V$e.forEach(t),c6o=i(O),r1=n(O,"LI",{});var X$e=s(r1);Eme=n(X$e,"STRONG",{});var s1t=s(Eme);f6o=r(s1t,"data2vec-text"),s1t.forEach(t),m6o=r(X$e," \u2014 "),lG=n(X$e,"A",{href:!0});var l1t=s(lG);g6o=r(l1t,"Data2VecTextForMaskedLM"),l1t.forEach(t),h6o=r(X$e," (Data2VecText model)"),X$e.forEach(t),p6o=i(O),t1=n(O,"LI",{});var z$e=s(t1);Cme=n(z$e,"STRONG",{});var i1t=s(Cme);_6o=r(i1t,"deberta"),i1t.forEach(t),u6o=r(z$e," \u2014 "),iG=n(z$e,"A",{href:!0});var d1t=s(iG);b6o=r(d1t,"DebertaForMaskedLM"),d1t.forEach(t),v6o=r(z$e," (DeBERTa model)"),z$e.forEach(t),F6o=i(O),a1=n(O,"LI",{});var Q$e=s(a1);wme=n(Q$e,"STRONG",{});var c1t=s(wme);T6o=r(c1t,"deberta-v2"),c1t.forEach(t),M6o=r(Q$e," \u2014 "),dG=n(Q$e,"A",{href:!0});var f1t=s(dG);E6o=r(f1t,"DebertaV2ForMaskedLM"),f1t.forEach(t),C6o=r(Q$e," (DeBERTa-v2 model)"),Q$e.forEach(t),w6o=i(O),n1=n(O,"LI",{});var W$e=s(n1);Ame=n(W$e,"STRONG",{});var m1t=s(Ame);A6o=r(m1t,"distilbert"),m1t.forEach(t),L6o=r(W$e," \u2014 "),cG=n(W$e,"A",{href:!0});var g1t=s(cG);y6o=r(g1t,"DistilBertForMaskedLM"),g1t.forEach(t),x6o=r(W$e," (DistilBERT model)"),W$e.forEach(t),$6o=i(O),s1=n(O,"LI",{});var H$e=s(s1);Lme=n(H$e,"STRONG",{});var h1t=s(Lme);k6o=r(h1t,"electra"),h1t.forEach(t),S6o=r(H$e," \u2014 "),fG=n(H$e,"A",{href:!0});var p1t=s(fG);R6o=r(p1t,"ElectraForPreTraining"),p1t.forEach(t),P6o=r(H$e," (ELECTRA model)"),H$e.forEach(t),B6o=i(O),l1=n(O,"LI",{});var U$e=s(l1);yme=n(U$e,"STRONG",{});var _1t=s(yme);I6o=r(_1t,"flaubert"),_1t.forEach(t),N6o=r(U$e," \u2014 "),mG=n(U$e,"A",{href:!0});var u1t=s(mG);q6o=r(u1t,"FlaubertWithLMHeadModel"),u1t.forEach(t),j6o=r(U$e," (FlauBERT model)"),U$e.forEach(t),D6o=i(O),i1=n(O,"LI",{});var J$e=s(i1);xme=n(J$e,"STRONG",{});var b1t=s(xme);G6o=r(b1t,"flava"),b1t.forEach(t),O6o=r(J$e," \u2014 "),gG=n(J$e,"A",{href:!0});var v1t=s(gG);V6o=r(v1t,"FlavaForPreTraining"),v1t.forEach(t),X6o=r(J$e," (FLAVA model)"),J$e.forEach(t),z6o=i(O),d1=n(O,"LI",{});var Y$e=s(d1);$me=n(Y$e,"STRONG",{});var F1t=s($me);Q6o=r(F1t,"fnet"),F1t.forEach(t),W6o=r(Y$e," \u2014 "),hG=n(Y$e,"A",{href:!0});var T1t=s(hG);H6o=r(T1t,"FNetForPreTraining"),T1t.forEach(t),U6o=r(Y$e," (FNet model)"),Y$e.forEach(t),J6o=i(O),c1=n(O,"LI",{});var K$e=s(c1);kme=n(K$e,"STRONG",{});var M1t=s(kme);Y6o=r(M1t,"fsmt"),M1t.forEach(t),K6o=r(K$e," \u2014 "),pG=n(K$e,"A",{href:!0});var E1t=s(pG);Z6o=r(E1t,"FSMTForConditionalGeneration"),E1t.forEach(t),eLo=r(K$e," (FairSeq Machine-Translation model)"),K$e.forEach(t),oLo=i(O),f1=n(O,"LI",{});var Z$e=s(f1);Sme=n(Z$e,"STRONG",{});var C1t=s(Sme);rLo=r(C1t,"funnel"),C1t.forEach(t),tLo=r(Z$e," \u2014 "),_G=n(Z$e,"A",{href:!0});var w1t=s(_G);aLo=r(w1t,"FunnelForPreTraining"),w1t.forEach(t),nLo=r(Z$e," (Funnel Transformer model)"),Z$e.forEach(t),sLo=i(O),m1=n(O,"LI",{});var eke=s(m1);Rme=n(eke,"STRONG",{});var A1t=s(Rme);lLo=r(A1t,"gpt2"),A1t.forEach(t),iLo=r(eke," \u2014 "),uG=n(eke,"A",{href:!0});var L1t=s(uG);dLo=r(L1t,"GPT2LMHeadModel"),L1t.forEach(t),cLo=r(eke," (OpenAI GPT-2 model)"),eke.forEach(t),fLo=i(O),g1=n(O,"LI",{});var oke=s(g1);Pme=n(oke,"STRONG",{});var y1t=s(Pme);mLo=r(y1t,"ibert"),y1t.forEach(t),gLo=r(oke," \u2014 "),bG=n(oke,"A",{href:!0});var x1t=s(bG);hLo=r(x1t,"IBertForMaskedLM"),x1t.forEach(t),pLo=r(oke," (I-BERT model)"),oke.forEach(t),_Lo=i(O),h1=n(O,"LI",{});var rke=s(h1);Bme=n(rke,"STRONG",{});var $1t=s(Bme);uLo=r($1t,"layoutlm"),$1t.forEach(t),bLo=r(rke," \u2014 "),vG=n(rke,"A",{href:!0});var k1t=s(vG);vLo=r(k1t,"LayoutLMForMaskedLM"),k1t.forEach(t),FLo=r(rke," (LayoutLM model)"),rke.forEach(t),TLo=i(O),p1=n(O,"LI",{});var tke=s(p1);Ime=n(tke,"STRONG",{});var S1t=s(Ime);MLo=r(S1t,"longformer"),S1t.forEach(t),ELo=r(tke," \u2014 "),FG=n(tke,"A",{href:!0});var R1t=s(FG);CLo=r(R1t,"LongformerForMaskedLM"),R1t.forEach(t),wLo=r(tke," (Longformer model)"),tke.forEach(t),ALo=i(O),_1=n(O,"LI",{});var ake=s(_1);Nme=n(ake,"STRONG",{});var P1t=s(Nme);LLo=r(P1t,"lxmert"),P1t.forEach(t),yLo=r(ake," \u2014 "),TG=n(ake,"A",{href:!0});var B1t=s(TG);xLo=r(B1t,"LxmertForPreTraining"),B1t.forEach(t),$Lo=r(ake," (LXMERT model)"),ake.forEach(t),kLo=i(O),u1=n(O,"LI",{});var nke=s(u1);qme=n(nke,"STRONG",{});var I1t=s(qme);SLo=r(I1t,"megatron-bert"),I1t.forEach(t),RLo=r(nke," \u2014 "),MG=n(nke,"A",{href:!0});var N1t=s(MG);PLo=r(N1t,"MegatronBertForPreTraining"),N1t.forEach(t),BLo=r(nke," (Megatron-BERT model)"),nke.forEach(t),ILo=i(O),b1=n(O,"LI",{});var ske=s(b1);jme=n(ske,"STRONG",{});var q1t=s(jme);NLo=r(q1t,"mobilebert"),q1t.forEach(t),qLo=r(ske," \u2014 "),EG=n(ske,"A",{href:!0});var j1t=s(EG);jLo=r(j1t,"MobileBertForPreTraining"),j1t.forEach(t),DLo=r(ske," (MobileBERT model)"),ske.forEach(t),GLo=i(O),v1=n(O,"LI",{});var lke=s(v1);Dme=n(lke,"STRONG",{});var D1t=s(Dme);OLo=r(D1t,"mpnet"),D1t.forEach(t),VLo=r(lke," \u2014 "),CG=n(lke,"A",{href:!0});var G1t=s(CG);XLo=r(G1t,"MPNetForMaskedLM"),G1t.forEach(t),zLo=r(lke," (MPNet model)"),lke.forEach(t),QLo=i(O),F1=n(O,"LI",{});var ike=s(F1);Gme=n(ike,"STRONG",{});var O1t=s(Gme);WLo=r(O1t,"mvp"),O1t.forEach(t),HLo=r(ike," \u2014 "),wG=n(ike,"A",{href:!0});var V1t=s(wG);ULo=r(V1t,"MvpForConditionalGeneration"),V1t.forEach(t),JLo=r(ike," (MVP model)"),ike.forEach(t),YLo=i(O),T1=n(O,"LI",{});var dke=s(T1);Ome=n(dke,"STRONG",{});var X1t=s(Ome);KLo=r(X1t,"nezha"),X1t.forEach(t),ZLo=r(dke," \u2014 "),AG=n(dke,"A",{href:!0});var z1t=s(AG);eyo=r(z1t,"NezhaForPreTraining"),z1t.forEach(t),oyo=r(dke," (Nezha model)"),dke.forEach(t),ryo=i(O),M1=n(O,"LI",{});var cke=s(M1);Vme=n(cke,"STRONG",{});var Q1t=s(Vme);tyo=r(Q1t,"openai-gpt"),Q1t.forEach(t),ayo=r(cke," \u2014 "),LG=n(cke,"A",{href:!0});var W1t=s(LG);nyo=r(W1t,"OpenAIGPTLMHeadModel"),W1t.forEach(t),syo=r(cke," (OpenAI GPT model)"),cke.forEach(t),lyo=i(O),E1=n(O,"LI",{});var fke=s(E1);Xme=n(fke,"STRONG",{});var H1t=s(Xme);iyo=r(H1t,"retribert"),H1t.forEach(t),dyo=r(fke," \u2014 "),yG=n(fke,"A",{href:!0});var U1t=s(yG);cyo=r(U1t,"RetriBertModel"),U1t.forEach(t),fyo=r(fke," (RetriBERT model)"),fke.forEach(t),myo=i(O),C1=n(O,"LI",{});var mke=s(C1);zme=n(mke,"STRONG",{});var J1t=s(zme);gyo=r(J1t,"roberta"),J1t.forEach(t),hyo=r(mke," \u2014 "),xG=n(mke,"A",{href:!0});var Y1t=s(xG);pyo=r(Y1t,"RobertaForMaskedLM"),Y1t.forEach(t),_yo=r(mke," (RoBERTa model)"),mke.forEach(t),uyo=i(O),w1=n(O,"LI",{});var gke=s(w1);Qme=n(gke,"STRONG",{});var K1t=s(Qme);byo=r(K1t,"splinter"),K1t.forEach(t),vyo=r(gke," \u2014 "),$G=n(gke,"A",{href:!0});var Z1t=s($G);Fyo=r(Z1t,"SplinterForPreTraining"),Z1t.forEach(t),Tyo=r(gke," (Splinter model)"),gke.forEach(t),Myo=i(O),A1=n(O,"LI",{});var hke=s(A1);Wme=n(hke,"STRONG",{});var e2t=s(Wme);Eyo=r(e2t,"squeezebert"),e2t.forEach(t),Cyo=r(hke," \u2014 "),kG=n(hke,"A",{href:!0});var o2t=s(kG);wyo=r(o2t,"SqueezeBertForMaskedLM"),o2t.forEach(t),Ayo=r(hke," (SqueezeBERT model)"),hke.forEach(t),Lyo=i(O),L1=n(O,"LI",{});var pke=s(L1);Hme=n(pke,"STRONG",{});var r2t=s(Hme);yyo=r(r2t,"t5"),r2t.forEach(t),xyo=r(pke," \u2014 "),SG=n(pke,"A",{href:!0});var t2t=s(SG);$yo=r(t2t,"T5ForConditionalGeneration"),t2t.forEach(t),kyo=r(pke," (T5 model)"),pke.forEach(t),Syo=i(O),y1=n(O,"LI",{});var _ke=s(y1);Ume=n(_ke,"STRONG",{});var a2t=s(Ume);Ryo=r(a2t,"tapas"),a2t.forEach(t),Pyo=r(_ke," \u2014 "),RG=n(_ke,"A",{href:!0});var n2t=s(RG);Byo=r(n2t,"TapasForMaskedLM"),n2t.forEach(t),Iyo=r(_ke," (TAPAS model)"),_ke.forEach(t),Nyo=i(O),x1=n(O,"LI",{});var uke=s(x1);Jme=n(uke,"STRONG",{});var s2t=s(Jme);qyo=r(s2t,"transfo-xl"),s2t.forEach(t),jyo=r(uke," \u2014 "),PG=n(uke,"A",{href:!0});var l2t=s(PG);Dyo=r(l2t,"TransfoXLLMHeadModel"),l2t.forEach(t),Gyo=r(uke," (Transformer-XL model)"),uke.forEach(t),Oyo=i(O),$1=n(O,"LI",{});var bke=s($1);Yme=n(bke,"STRONG",{});var i2t=s(Yme);Vyo=r(i2t,"unispeech"),i2t.forEach(t),Xyo=r(bke," \u2014 "),BG=n(bke,"A",{href:!0});var d2t=s(BG);zyo=r(d2t,"UniSpeechForPreTraining"),d2t.forEach(t),Qyo=r(bke," (UniSpeech model)"),bke.forEach(t),Wyo=i(O),k1=n(O,"LI",{});var vke=s(k1);Kme=n(vke,"STRONG",{});var c2t=s(Kme);Hyo=r(c2t,"unispeech-sat"),c2t.forEach(t),Uyo=r(vke," \u2014 "),IG=n(vke,"A",{href:!0});var f2t=s(IG);Jyo=r(f2t,"UniSpeechSatForPreTraining"),f2t.forEach(t),Yyo=r(vke," (UniSpeechSat model)"),vke.forEach(t),Kyo=i(O),S1=n(O,"LI",{});var Fke=s(S1);Zme=n(Fke,"STRONG",{});var m2t=s(Zme);Zyo=r(m2t,"visual_bert"),m2t.forEach(t),e9o=r(Fke," \u2014 "),NG=n(Fke,"A",{href:!0});var g2t=s(NG);o9o=r(g2t,"VisualBertForPreTraining"),g2t.forEach(t),r9o=r(Fke," (VisualBERT model)"),Fke.forEach(t),t9o=i(O),R1=n(O,"LI",{});var Tke=s(R1);ege=n(Tke,"STRONG",{});var h2t=s(ege);a9o=r(h2t,"vit_mae"),h2t.forEach(t),n9o=r(Tke," \u2014 "),qG=n(Tke,"A",{href:!0});var p2t=s(qG);s9o=r(p2t,"ViTMAEForPreTraining"),p2t.forEach(t),l9o=r(Tke," (ViTMAE model)"),Tke.forEach(t),i9o=i(O),P1=n(O,"LI",{});var Mke=s(P1);oge=n(Mke,"STRONG",{});var _2t=s(oge);d9o=r(_2t,"wav2vec2"),_2t.forEach(t),c9o=r(Mke," \u2014 "),jG=n(Mke,"A",{href:!0});var u2t=s(jG);f9o=r(u2t,"Wav2Vec2ForPreTraining"),u2t.forEach(t),m9o=r(Mke," (Wav2Vec2 model)"),Mke.forEach(t),g9o=i(O),B1=n(O,"LI",{});var Eke=s(B1);rge=n(Eke,"STRONG",{});var b2t=s(rge);h9o=r(b2t,"wav2vec2-conformer"),b2t.forEach(t),p9o=r(Eke," \u2014 "),DG=n(Eke,"A",{href:!0});var v2t=s(DG);_9o=r(v2t,"Wav2Vec2ConformerForPreTraining"),v2t.forEach(t),u9o=r(Eke," (Wav2Vec2-Conformer model)"),Eke.forEach(t),b9o=i(O),I1=n(O,"LI",{});var Cke=s(I1);tge=n(Cke,"STRONG",{});var F2t=s(tge);v9o=r(F2t,"xlm"),F2t.forEach(t),F9o=r(Cke," \u2014 "),GG=n(Cke,"A",{href:!0});var T2t=s(GG);T9o=r(T2t,"XLMWithLMHeadModel"),T2t.forEach(t),M9o=r(Cke," (XLM model)"),Cke.forEach(t),E9o=i(O),N1=n(O,"LI",{});var wke=s(N1);age=n(wke,"STRONG",{});var M2t=s(age);C9o=r(M2t,"xlm-roberta"),M2t.forEach(t),w9o=r(wke," \u2014 "),OG=n(wke,"A",{href:!0});var E2t=s(OG);A9o=r(E2t,"XLMRobertaForMaskedLM"),E2t.forEach(t),L9o=r(wke," (XLM-RoBERTa model)"),wke.forEach(t),y9o=i(O),q1=n(O,"LI",{});var Ake=s(q1);nge=n(Ake,"STRONG",{});var C2t=s(nge);x9o=r(C2t,"xlm-roberta-xl"),C2t.forEach(t),$9o=r(Ake," \u2014 "),VG=n(Ake,"A",{href:!0});var w2t=s(VG);k9o=r(w2t,"XLMRobertaXLForMaskedLM"),w2t.forEach(t),S9o=r(Ake," (XLM-RoBERTa-XL model)"),Ake.forEach(t),R9o=i(O),j1=n(O,"LI",{});var Lke=s(j1);sge=n(Lke,"STRONG",{});var A2t=s(sge);P9o=r(A2t,"xlnet"),A2t.forEach(t),B9o=r(Lke," \u2014 "),XG=n(Lke,"A",{href:!0});var L2t=s(XG);I9o=r(L2t,"XLNetLMHeadModel"),L2t.forEach(t),N9o=r(Lke," (XLNet model)"),Lke.forEach(t),O.forEach(t),q9o=i(la),D1=n(la,"P",{});var yke=s(D1);j9o=r(yke,"The model is set in evaluation mode by default using "),lge=n(yke,"CODE",{});var y2t=s(lge);D9o=r(y2t,"model.eval()"),y2t.forEach(t),G9o=r(yke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ige=n(yke,"CODE",{});var x2t=s(ige);O9o=r(x2t,"model.train()"),x2t.forEach(t),yke.forEach(t),V9o=i(la),T(G1.$$.fragment,la),la.forEach(t),ol.forEach(t),oXe=i(f),Qi=n(f,"H2",{class:!0});var lQe=s(Qi);O1=n(lQe,"A",{id:!0,class:!0,href:!0});var $2t=s(O1);dge=n($2t,"SPAN",{});var k2t=s(dge);T(NL.$$.fragment,k2t),k2t.forEach(t),$2t.forEach(t),X9o=i(lQe),cge=n(lQe,"SPAN",{});var S2t=s(cge);z9o=r(S2t,"AutoModelForCausalLM"),S2t.forEach(t),lQe.forEach(t),rXe=i(f),ko=n(f,"DIV",{class:!0});var rl=s(ko);T(qL.$$.fragment,rl),Q9o=i(rl),Wi=n(rl,"P",{});var Lre=s(Wi);W9o=r(Lre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),zG=n(Lre,"A",{href:!0});var R2t=s(zG);H9o=r(R2t,"from_pretrained()"),R2t.forEach(t),U9o=r(Lre," class method or the "),QG=n(Lre,"A",{href:!0});var P2t=s(QG);J9o=r(P2t,"from_config()"),P2t.forEach(t),Y9o=r(Lre,` class
method.`),Lre.forEach(t),K9o=i(rl),jL=n(rl,"P",{});var iQe=s(jL);Z9o=r(iQe,"This class cannot be instantiated directly using "),fge=n(iQe,"CODE",{});var B2t=s(fge);exo=r(B2t,"__init__()"),B2t.forEach(t),oxo=r(iQe," (throws an error)."),iQe.forEach(t),rxo=i(rl),dt=n(rl,"DIV",{class:!0});var dA=s(dt);T(DL.$$.fragment,dA),txo=i(dA),mge=n(dA,"P",{});var I2t=s(mge);axo=r(I2t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),I2t.forEach(t),nxo=i(dA),Hi=n(dA,"P",{});var yre=s(Hi);sxo=r(yre,`Note:
Loading a model from its configuration file does `),gge=n(yre,"STRONG",{});var N2t=s(gge);lxo=r(N2t,"not"),N2t.forEach(t),ixo=r(yre,` load the model weights. It only affects the
model\u2019s configuration. Use `),WG=n(yre,"A",{href:!0});var q2t=s(WG);dxo=r(q2t,"from_pretrained()"),q2t.forEach(t),cxo=r(yre," to load the model weights."),yre.forEach(t),fxo=i(dA),T(V1.$$.fragment,dA),dA.forEach(t),mxo=i(rl),Ke=n(rl,"DIV",{class:!0});var ia=s(Ke);T(GL.$$.fragment,ia),gxo=i(ia),hge=n(ia,"P",{});var j2t=s(hge);hxo=r(j2t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),j2t.forEach(t),pxo=i(ia),Na=n(ia,"P",{});var cA=s(Na);_xo=r(cA,"The model class to instantiate is selected based on the "),pge=n(cA,"CODE",{});var D2t=s(pge);uxo=r(D2t,"model_type"),D2t.forEach(t),bxo=r(cA,` property of the config object (either
passed as an argument or loaded from `),_ge=n(cA,"CODE",{});var G2t=s(_ge);vxo=r(G2t,"pretrained_model_name_or_path"),G2t.forEach(t),Fxo=r(cA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uge=n(cA,"CODE",{});var O2t=s(uge);Txo=r(O2t,"pretrained_model_name_or_path"),O2t.forEach(t),Mxo=r(cA,":"),cA.forEach(t),Exo=i(ia),z=n(ia,"UL",{});var Q=s(z);X1=n(Q,"LI",{});var xke=s(X1);bge=n(xke,"STRONG",{});var V2t=s(bge);Cxo=r(V2t,"bart"),V2t.forEach(t),wxo=r(xke," \u2014 "),HG=n(xke,"A",{href:!0});var X2t=s(HG);Axo=r(X2t,"BartForCausalLM"),X2t.forEach(t),Lxo=r(xke," (BART model)"),xke.forEach(t),yxo=i(Q),z1=n(Q,"LI",{});var $ke=s(z1);vge=n($ke,"STRONG",{});var z2t=s(vge);xxo=r(z2t,"bert"),z2t.forEach(t),$xo=r($ke," \u2014 "),UG=n($ke,"A",{href:!0});var Q2t=s(UG);kxo=r(Q2t,"BertLMHeadModel"),Q2t.forEach(t),Sxo=r($ke," (BERT model)"),$ke.forEach(t),Rxo=i(Q),Q1=n(Q,"LI",{});var kke=s(Q1);Fge=n(kke,"STRONG",{});var W2t=s(Fge);Pxo=r(W2t,"bert-generation"),W2t.forEach(t),Bxo=r(kke," \u2014 "),JG=n(kke,"A",{href:!0});var H2t=s(JG);Ixo=r(H2t,"BertGenerationDecoder"),H2t.forEach(t),Nxo=r(kke," (Bert Generation model)"),kke.forEach(t),qxo=i(Q),W1=n(Q,"LI",{});var Ske=s(W1);Tge=n(Ske,"STRONG",{});var U2t=s(Tge);jxo=r(U2t,"big_bird"),U2t.forEach(t),Dxo=r(Ske," \u2014 "),YG=n(Ske,"A",{href:!0});var J2t=s(YG);Gxo=r(J2t,"BigBirdForCausalLM"),J2t.forEach(t),Oxo=r(Ske," (BigBird model)"),Ske.forEach(t),Vxo=i(Q),H1=n(Q,"LI",{});var Rke=s(H1);Mge=n(Rke,"STRONG",{});var Y2t=s(Mge);Xxo=r(Y2t,"bigbird_pegasus"),Y2t.forEach(t),zxo=r(Rke," \u2014 "),KG=n(Rke,"A",{href:!0});var K2t=s(KG);Qxo=r(K2t,"BigBirdPegasusForCausalLM"),K2t.forEach(t),Wxo=r(Rke," (BigBird-Pegasus model)"),Rke.forEach(t),Hxo=i(Q),U1=n(Q,"LI",{});var Pke=s(U1);Ege=n(Pke,"STRONG",{});var Z2t=s(Ege);Uxo=r(Z2t,"blenderbot"),Z2t.forEach(t),Jxo=r(Pke," \u2014 "),ZG=n(Pke,"A",{href:!0});var ebt=s(ZG);Yxo=r(ebt,"BlenderbotForCausalLM"),ebt.forEach(t),Kxo=r(Pke," (Blenderbot model)"),Pke.forEach(t),Zxo=i(Q),J1=n(Q,"LI",{});var Bke=s(J1);Cge=n(Bke,"STRONG",{});var obt=s(Cge);e$o=r(obt,"blenderbot-small"),obt.forEach(t),o$o=r(Bke," \u2014 "),eO=n(Bke,"A",{href:!0});var rbt=s(eO);r$o=r(rbt,"BlenderbotSmallForCausalLM"),rbt.forEach(t),t$o=r(Bke," (BlenderbotSmall model)"),Bke.forEach(t),a$o=i(Q),Y1=n(Q,"LI",{});var Ike=s(Y1);wge=n(Ike,"STRONG",{});var tbt=s(wge);n$o=r(tbt,"bloom"),tbt.forEach(t),s$o=r(Ike," \u2014 "),oO=n(Ike,"A",{href:!0});var abt=s(oO);l$o=r(abt,"BloomForCausalLM"),abt.forEach(t),i$o=r(Ike," (BLOOM model)"),Ike.forEach(t),d$o=i(Q),K1=n(Q,"LI",{});var Nke=s(K1);Age=n(Nke,"STRONG",{});var nbt=s(Age);c$o=r(nbt,"camembert"),nbt.forEach(t),f$o=r(Nke," \u2014 "),rO=n(Nke,"A",{href:!0});var sbt=s(rO);m$o=r(sbt,"CamembertForCausalLM"),sbt.forEach(t),g$o=r(Nke," (CamemBERT model)"),Nke.forEach(t),h$o=i(Q),Z1=n(Q,"LI",{});var qke=s(Z1);Lge=n(qke,"STRONG",{});var lbt=s(Lge);p$o=r(lbt,"codegen"),lbt.forEach(t),_$o=r(qke," \u2014 "),tO=n(qke,"A",{href:!0});var ibt=s(tO);u$o=r(ibt,"CodeGenForCausalLM"),ibt.forEach(t),b$o=r(qke," (CodeGen model)"),qke.forEach(t),v$o=i(Q),e2=n(Q,"LI",{});var jke=s(e2);yge=n(jke,"STRONG",{});var dbt=s(yge);F$o=r(dbt,"ctrl"),dbt.forEach(t),T$o=r(jke," \u2014 "),aO=n(jke,"A",{href:!0});var cbt=s(aO);M$o=r(cbt,"CTRLLMHeadModel"),cbt.forEach(t),E$o=r(jke," (CTRL model)"),jke.forEach(t),C$o=i(Q),o2=n(Q,"LI",{});var Dke=s(o2);xge=n(Dke,"STRONG",{});var fbt=s(xge);w$o=r(fbt,"data2vec-text"),fbt.forEach(t),A$o=r(Dke," \u2014 "),nO=n(Dke,"A",{href:!0});var mbt=s(nO);L$o=r(mbt,"Data2VecTextForCausalLM"),mbt.forEach(t),y$o=r(Dke," (Data2VecText model)"),Dke.forEach(t),x$o=i(Q),r2=n(Q,"LI",{});var Gke=s(r2);$ge=n(Gke,"STRONG",{});var gbt=s($ge);$$o=r(gbt,"electra"),gbt.forEach(t),k$o=r(Gke," \u2014 "),sO=n(Gke,"A",{href:!0});var hbt=s(sO);S$o=r(hbt,"ElectraForCausalLM"),hbt.forEach(t),R$o=r(Gke," (ELECTRA model)"),Gke.forEach(t),P$o=i(Q),t2=n(Q,"LI",{});var Oke=s(t2);kge=n(Oke,"STRONG",{});var pbt=s(kge);B$o=r(pbt,"gpt2"),pbt.forEach(t),I$o=r(Oke," \u2014 "),lO=n(Oke,"A",{href:!0});var _bt=s(lO);N$o=r(_bt,"GPT2LMHeadModel"),_bt.forEach(t),q$o=r(Oke," (OpenAI GPT-2 model)"),Oke.forEach(t),j$o=i(Q),a2=n(Q,"LI",{});var Vke=s(a2);Sge=n(Vke,"STRONG",{});var ubt=s(Sge);D$o=r(ubt,"gpt_neo"),ubt.forEach(t),G$o=r(Vke," \u2014 "),iO=n(Vke,"A",{href:!0});var bbt=s(iO);O$o=r(bbt,"GPTNeoForCausalLM"),bbt.forEach(t),V$o=r(Vke," (GPT Neo model)"),Vke.forEach(t),X$o=i(Q),n2=n(Q,"LI",{});var Xke=s(n2);Rge=n(Xke,"STRONG",{});var vbt=s(Rge);z$o=r(vbt,"gpt_neox"),vbt.forEach(t),Q$o=r(Xke," \u2014 "),dO=n(Xke,"A",{href:!0});var Fbt=s(dO);W$o=r(Fbt,"GPTNeoXForCausalLM"),Fbt.forEach(t),H$o=r(Xke," (GPT NeoX model)"),Xke.forEach(t),U$o=i(Q),s2=n(Q,"LI",{});var zke=s(s2);Pge=n(zke,"STRONG",{});var Tbt=s(Pge);J$o=r(Tbt,"gptj"),Tbt.forEach(t),Y$o=r(zke," \u2014 "),cO=n(zke,"A",{href:!0});var Mbt=s(cO);K$o=r(Mbt,"GPTJForCausalLM"),Mbt.forEach(t),Z$o=r(zke," (GPT-J model)"),zke.forEach(t),eko=i(Q),l2=n(Q,"LI",{});var Qke=s(l2);Bge=n(Qke,"STRONG",{});var Ebt=s(Bge);oko=r(Ebt,"marian"),Ebt.forEach(t),rko=r(Qke," \u2014 "),fO=n(Qke,"A",{href:!0});var Cbt=s(fO);tko=r(Cbt,"MarianForCausalLM"),Cbt.forEach(t),ako=r(Qke," (Marian model)"),Qke.forEach(t),nko=i(Q),i2=n(Q,"LI",{});var Wke=s(i2);Ige=n(Wke,"STRONG",{});var wbt=s(Ige);sko=r(wbt,"mbart"),wbt.forEach(t),lko=r(Wke," \u2014 "),mO=n(Wke,"A",{href:!0});var Abt=s(mO);iko=r(Abt,"MBartForCausalLM"),Abt.forEach(t),dko=r(Wke," (mBART model)"),Wke.forEach(t),cko=i(Q),d2=n(Q,"LI",{});var Hke=s(d2);Nge=n(Hke,"STRONG",{});var Lbt=s(Nge);fko=r(Lbt,"megatron-bert"),Lbt.forEach(t),mko=r(Hke," \u2014 "),gO=n(Hke,"A",{href:!0});var ybt=s(gO);gko=r(ybt,"MegatronBertForCausalLM"),ybt.forEach(t),hko=r(Hke," (Megatron-BERT model)"),Hke.forEach(t),pko=i(Q),c2=n(Q,"LI",{});var Uke=s(c2);qge=n(Uke,"STRONG",{});var xbt=s(qge);_ko=r(xbt,"mvp"),xbt.forEach(t),uko=r(Uke," \u2014 "),hO=n(Uke,"A",{href:!0});var $bt=s(hO);bko=r($bt,"MvpForCausalLM"),$bt.forEach(t),vko=r(Uke," (MVP model)"),Uke.forEach(t),Fko=i(Q),f2=n(Q,"LI",{});var Jke=s(f2);jge=n(Jke,"STRONG",{});var kbt=s(jge);Tko=r(kbt,"openai-gpt"),kbt.forEach(t),Mko=r(Jke," \u2014 "),pO=n(Jke,"A",{href:!0});var Sbt=s(pO);Eko=r(Sbt,"OpenAIGPTLMHeadModel"),Sbt.forEach(t),Cko=r(Jke," (OpenAI GPT model)"),Jke.forEach(t),wko=i(Q),m2=n(Q,"LI",{});var Yke=s(m2);Dge=n(Yke,"STRONG",{});var Rbt=s(Dge);Ako=r(Rbt,"opt"),Rbt.forEach(t),Lko=r(Yke," \u2014 "),_O=n(Yke,"A",{href:!0});var Pbt=s(_O);yko=r(Pbt,"OPTForCausalLM"),Pbt.forEach(t),xko=r(Yke," (OPT model)"),Yke.forEach(t),$ko=i(Q),g2=n(Q,"LI",{});var Kke=s(g2);Gge=n(Kke,"STRONG",{});var Bbt=s(Gge);kko=r(Bbt,"pegasus"),Bbt.forEach(t),Sko=r(Kke," \u2014 "),uO=n(Kke,"A",{href:!0});var Ibt=s(uO);Rko=r(Ibt,"PegasusForCausalLM"),Ibt.forEach(t),Pko=r(Kke," (Pegasus model)"),Kke.forEach(t),Bko=i(Q),h2=n(Q,"LI",{});var Zke=s(h2);Oge=n(Zke,"STRONG",{});var Nbt=s(Oge);Iko=r(Nbt,"plbart"),Nbt.forEach(t),Nko=r(Zke," \u2014 "),bO=n(Zke,"A",{href:!0});var qbt=s(bO);qko=r(qbt,"PLBartForCausalLM"),qbt.forEach(t),jko=r(Zke," (PLBart model)"),Zke.forEach(t),Dko=i(Q),p2=n(Q,"LI",{});var eSe=s(p2);Vge=n(eSe,"STRONG",{});var jbt=s(Vge);Gko=r(jbt,"prophetnet"),jbt.forEach(t),Oko=r(eSe," \u2014 "),vO=n(eSe,"A",{href:!0});var Dbt=s(vO);Vko=r(Dbt,"ProphetNetForCausalLM"),Dbt.forEach(t),Xko=r(eSe," (ProphetNet model)"),eSe.forEach(t),zko=i(Q),_2=n(Q,"LI",{});var oSe=s(_2);Xge=n(oSe,"STRONG",{});var Gbt=s(Xge);Qko=r(Gbt,"qdqbert"),Gbt.forEach(t),Wko=r(oSe," \u2014 "),FO=n(oSe,"A",{href:!0});var Obt=s(FO);Hko=r(Obt,"QDQBertLMHeadModel"),Obt.forEach(t),Uko=r(oSe," (QDQBert model)"),oSe.forEach(t),Jko=i(Q),u2=n(Q,"LI",{});var rSe=s(u2);zge=n(rSe,"STRONG",{});var Vbt=s(zge);Yko=r(Vbt,"reformer"),Vbt.forEach(t),Kko=r(rSe," \u2014 "),TO=n(rSe,"A",{href:!0});var Xbt=s(TO);Zko=r(Xbt,"ReformerModelWithLMHead"),Xbt.forEach(t),eSo=r(rSe," (Reformer model)"),rSe.forEach(t),oSo=i(Q),b2=n(Q,"LI",{});var tSe=s(b2);Qge=n(tSe,"STRONG",{});var zbt=s(Qge);rSo=r(zbt,"rembert"),zbt.forEach(t),tSo=r(tSe," \u2014 "),MO=n(tSe,"A",{href:!0});var Qbt=s(MO);aSo=r(Qbt,"RemBertForCausalLM"),Qbt.forEach(t),nSo=r(tSe," (RemBERT model)"),tSe.forEach(t),sSo=i(Q),v2=n(Q,"LI",{});var aSe=s(v2);Wge=n(aSe,"STRONG",{});var Wbt=s(Wge);lSo=r(Wbt,"roberta"),Wbt.forEach(t),iSo=r(aSe," \u2014 "),EO=n(aSe,"A",{href:!0});var Hbt=s(EO);dSo=r(Hbt,"RobertaForCausalLM"),Hbt.forEach(t),cSo=r(aSe," (RoBERTa model)"),aSe.forEach(t),fSo=i(Q),F2=n(Q,"LI",{});var nSe=s(F2);Hge=n(nSe,"STRONG",{});var Ubt=s(Hge);mSo=r(Ubt,"roformer"),Ubt.forEach(t),gSo=r(nSe," \u2014 "),CO=n(nSe,"A",{href:!0});var Jbt=s(CO);hSo=r(Jbt,"RoFormerForCausalLM"),Jbt.forEach(t),pSo=r(nSe," (RoFormer model)"),nSe.forEach(t),_So=i(Q),T2=n(Q,"LI",{});var sSe=s(T2);Uge=n(sSe,"STRONG",{});var Ybt=s(Uge);uSo=r(Ybt,"speech_to_text_2"),Ybt.forEach(t),bSo=r(sSe," \u2014 "),wO=n(sSe,"A",{href:!0});var Kbt=s(wO);vSo=r(Kbt,"Speech2Text2ForCausalLM"),Kbt.forEach(t),FSo=r(sSe," (Speech2Text2 model)"),sSe.forEach(t),TSo=i(Q),M2=n(Q,"LI",{});var lSe=s(M2);Jge=n(lSe,"STRONG",{});var Zbt=s(Jge);MSo=r(Zbt,"transfo-xl"),Zbt.forEach(t),ESo=r(lSe," \u2014 "),AO=n(lSe,"A",{href:!0});var evt=s(AO);CSo=r(evt,"TransfoXLLMHeadModel"),evt.forEach(t),wSo=r(lSe," (Transformer-XL model)"),lSe.forEach(t),ASo=i(Q),E2=n(Q,"LI",{});var iSe=s(E2);Yge=n(iSe,"STRONG",{});var ovt=s(Yge);LSo=r(ovt,"trocr"),ovt.forEach(t),ySo=r(iSe," \u2014 "),LO=n(iSe,"A",{href:!0});var rvt=s(LO);xSo=r(rvt,"TrOCRForCausalLM"),rvt.forEach(t),$So=r(iSe," (TrOCR model)"),iSe.forEach(t),kSo=i(Q),C2=n(Q,"LI",{});var dSe=s(C2);Kge=n(dSe,"STRONG",{});var tvt=s(Kge);SSo=r(tvt,"xglm"),tvt.forEach(t),RSo=r(dSe," \u2014 "),yO=n(dSe,"A",{href:!0});var avt=s(yO);PSo=r(avt,"XGLMForCausalLM"),avt.forEach(t),BSo=r(dSe," (XGLM model)"),dSe.forEach(t),ISo=i(Q),w2=n(Q,"LI",{});var cSe=s(w2);Zge=n(cSe,"STRONG",{});var nvt=s(Zge);NSo=r(nvt,"xlm"),nvt.forEach(t),qSo=r(cSe," \u2014 "),xO=n(cSe,"A",{href:!0});var svt=s(xO);jSo=r(svt,"XLMWithLMHeadModel"),svt.forEach(t),DSo=r(cSe," (XLM model)"),cSe.forEach(t),GSo=i(Q),A2=n(Q,"LI",{});var fSe=s(A2);ehe=n(fSe,"STRONG",{});var lvt=s(ehe);OSo=r(lvt,"xlm-prophetnet"),lvt.forEach(t),VSo=r(fSe," \u2014 "),$O=n(fSe,"A",{href:!0});var ivt=s($O);XSo=r(ivt,"XLMProphetNetForCausalLM"),ivt.forEach(t),zSo=r(fSe," (XLM-ProphetNet model)"),fSe.forEach(t),QSo=i(Q),L2=n(Q,"LI",{});var mSe=s(L2);ohe=n(mSe,"STRONG",{});var dvt=s(ohe);WSo=r(dvt,"xlm-roberta"),dvt.forEach(t),HSo=r(mSe," \u2014 "),kO=n(mSe,"A",{href:!0});var cvt=s(kO);USo=r(cvt,"XLMRobertaForCausalLM"),cvt.forEach(t),JSo=r(mSe," (XLM-RoBERTa model)"),mSe.forEach(t),YSo=i(Q),y2=n(Q,"LI",{});var gSe=s(y2);rhe=n(gSe,"STRONG",{});var fvt=s(rhe);KSo=r(fvt,"xlm-roberta-xl"),fvt.forEach(t),ZSo=r(gSe," \u2014 "),SO=n(gSe,"A",{href:!0});var mvt=s(SO);eRo=r(mvt,"XLMRobertaXLForCausalLM"),mvt.forEach(t),oRo=r(gSe," (XLM-RoBERTa-XL model)"),gSe.forEach(t),rRo=i(Q),x2=n(Q,"LI",{});var hSe=s(x2);the=n(hSe,"STRONG",{});var gvt=s(the);tRo=r(gvt,"xlnet"),gvt.forEach(t),aRo=r(hSe," \u2014 "),RO=n(hSe,"A",{href:!0});var hvt=s(RO);nRo=r(hvt,"XLNetLMHeadModel"),hvt.forEach(t),sRo=r(hSe," (XLNet model)"),hSe.forEach(t),Q.forEach(t),lRo=i(ia),$2=n(ia,"P",{});var pSe=s($2);iRo=r(pSe,"The model is set in evaluation mode by default using "),ahe=n(pSe,"CODE",{});var pvt=s(ahe);dRo=r(pvt,"model.eval()"),pvt.forEach(t),cRo=r(pSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nhe=n(pSe,"CODE",{});var _vt=s(nhe);fRo=r(_vt,"model.train()"),_vt.forEach(t),pSe.forEach(t),mRo=i(ia),T(k2.$$.fragment,ia),ia.forEach(t),rl.forEach(t),tXe=i(f),Ui=n(f,"H2",{class:!0});var dQe=s(Ui);S2=n(dQe,"A",{id:!0,class:!0,href:!0});var uvt=s(S2);she=n(uvt,"SPAN",{});var bvt=s(she);T(OL.$$.fragment,bvt),bvt.forEach(t),uvt.forEach(t),gRo=i(dQe),lhe=n(dQe,"SPAN",{});var vvt=s(lhe);hRo=r(vvt,"AutoModelForMaskedLM"),vvt.forEach(t),dQe.forEach(t),aXe=i(f),So=n(f,"DIV",{class:!0});var tl=s(So);T(VL.$$.fragment,tl),pRo=i(tl),Ji=n(tl,"P",{});var xre=s(Ji);_Ro=r(xre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),PO=n(xre,"A",{href:!0});var Fvt=s(PO);uRo=r(Fvt,"from_pretrained()"),Fvt.forEach(t),bRo=r(xre," class method or the "),BO=n(xre,"A",{href:!0});var Tvt=s(BO);vRo=r(Tvt,"from_config()"),Tvt.forEach(t),FRo=r(xre,` class
method.`),xre.forEach(t),TRo=i(tl),XL=n(tl,"P",{});var cQe=s(XL);MRo=r(cQe,"This class cannot be instantiated directly using "),ihe=n(cQe,"CODE",{});var Mvt=s(ihe);ERo=r(Mvt,"__init__()"),Mvt.forEach(t),CRo=r(cQe," (throws an error)."),cQe.forEach(t),wRo=i(tl),ct=n(tl,"DIV",{class:!0});var fA=s(ct);T(zL.$$.fragment,fA),ARo=i(fA),dhe=n(fA,"P",{});var Evt=s(dhe);LRo=r(Evt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Evt.forEach(t),yRo=i(fA),Yi=n(fA,"P",{});var $re=s(Yi);xRo=r($re,`Note:
Loading a model from its configuration file does `),che=n($re,"STRONG",{});var Cvt=s(che);$Ro=r(Cvt,"not"),Cvt.forEach(t),kRo=r($re,` load the model weights. It only affects the
model\u2019s configuration. Use `),IO=n($re,"A",{href:!0});var wvt=s(IO);SRo=r(wvt,"from_pretrained()"),wvt.forEach(t),RRo=r($re," to load the model weights."),$re.forEach(t),PRo=i(fA),T(R2.$$.fragment,fA),fA.forEach(t),BRo=i(tl),Ze=n(tl,"DIV",{class:!0});var da=s(Ze);T(QL.$$.fragment,da),IRo=i(da),fhe=n(da,"P",{});var Avt=s(fhe);NRo=r(Avt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Avt.forEach(t),qRo=i(da),qa=n(da,"P",{});var mA=s(qa);jRo=r(mA,"The model class to instantiate is selected based on the "),mhe=n(mA,"CODE",{});var Lvt=s(mhe);DRo=r(Lvt,"model_type"),Lvt.forEach(t),GRo=r(mA,` property of the config object (either
passed as an argument or loaded from `),ghe=n(mA,"CODE",{});var yvt=s(ghe);ORo=r(yvt,"pretrained_model_name_or_path"),yvt.forEach(t),VRo=r(mA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hhe=n(mA,"CODE",{});var xvt=s(hhe);XRo=r(xvt,"pretrained_model_name_or_path"),xvt.forEach(t),zRo=r(mA,":"),mA.forEach(t),QRo=i(da),W=n(da,"UL",{});var H=s(W);P2=n(H,"LI",{});var _Se=s(P2);phe=n(_Se,"STRONG",{});var $vt=s(phe);WRo=r($vt,"albert"),$vt.forEach(t),HRo=r(_Se," \u2014 "),NO=n(_Se,"A",{href:!0});var kvt=s(NO);URo=r(kvt,"AlbertForMaskedLM"),kvt.forEach(t),JRo=r(_Se," (ALBERT model)"),_Se.forEach(t),YRo=i(H),B2=n(H,"LI",{});var uSe=s(B2);_he=n(uSe,"STRONG",{});var Svt=s(_he);KRo=r(Svt,"bart"),Svt.forEach(t),ZRo=r(uSe," \u2014 "),qO=n(uSe,"A",{href:!0});var Rvt=s(qO);ePo=r(Rvt,"BartForConditionalGeneration"),Rvt.forEach(t),oPo=r(uSe," (BART model)"),uSe.forEach(t),rPo=i(H),I2=n(H,"LI",{});var bSe=s(I2);uhe=n(bSe,"STRONG",{});var Pvt=s(uhe);tPo=r(Pvt,"bert"),Pvt.forEach(t),aPo=r(bSe," \u2014 "),jO=n(bSe,"A",{href:!0});var Bvt=s(jO);nPo=r(Bvt,"BertForMaskedLM"),Bvt.forEach(t),sPo=r(bSe," (BERT model)"),bSe.forEach(t),lPo=i(H),N2=n(H,"LI",{});var vSe=s(N2);bhe=n(vSe,"STRONG",{});var Ivt=s(bhe);iPo=r(Ivt,"big_bird"),Ivt.forEach(t),dPo=r(vSe," \u2014 "),DO=n(vSe,"A",{href:!0});var Nvt=s(DO);cPo=r(Nvt,"BigBirdForMaskedLM"),Nvt.forEach(t),fPo=r(vSe," (BigBird model)"),vSe.forEach(t),mPo=i(H),q2=n(H,"LI",{});var FSe=s(q2);vhe=n(FSe,"STRONG",{});var qvt=s(vhe);gPo=r(qvt,"camembert"),qvt.forEach(t),hPo=r(FSe," \u2014 "),GO=n(FSe,"A",{href:!0});var jvt=s(GO);pPo=r(jvt,"CamembertForMaskedLM"),jvt.forEach(t),_Po=r(FSe," (CamemBERT model)"),FSe.forEach(t),uPo=i(H),j2=n(H,"LI",{});var TSe=s(j2);Fhe=n(TSe,"STRONG",{});var Dvt=s(Fhe);bPo=r(Dvt,"convbert"),Dvt.forEach(t),vPo=r(TSe," \u2014 "),OO=n(TSe,"A",{href:!0});var Gvt=s(OO);FPo=r(Gvt,"ConvBertForMaskedLM"),Gvt.forEach(t),TPo=r(TSe," (ConvBERT model)"),TSe.forEach(t),MPo=i(H),D2=n(H,"LI",{});var MSe=s(D2);The=n(MSe,"STRONG",{});var Ovt=s(The);EPo=r(Ovt,"data2vec-text"),Ovt.forEach(t),CPo=r(MSe," \u2014 "),VO=n(MSe,"A",{href:!0});var Vvt=s(VO);wPo=r(Vvt,"Data2VecTextForMaskedLM"),Vvt.forEach(t),APo=r(MSe," (Data2VecText model)"),MSe.forEach(t),LPo=i(H),G2=n(H,"LI",{});var ESe=s(G2);Mhe=n(ESe,"STRONG",{});var Xvt=s(Mhe);yPo=r(Xvt,"deberta"),Xvt.forEach(t),xPo=r(ESe," \u2014 "),XO=n(ESe,"A",{href:!0});var zvt=s(XO);$Po=r(zvt,"DebertaForMaskedLM"),zvt.forEach(t),kPo=r(ESe," (DeBERTa model)"),ESe.forEach(t),SPo=i(H),O2=n(H,"LI",{});var CSe=s(O2);Ehe=n(CSe,"STRONG",{});var Qvt=s(Ehe);RPo=r(Qvt,"deberta-v2"),Qvt.forEach(t),PPo=r(CSe," \u2014 "),zO=n(CSe,"A",{href:!0});var Wvt=s(zO);BPo=r(Wvt,"DebertaV2ForMaskedLM"),Wvt.forEach(t),IPo=r(CSe," (DeBERTa-v2 model)"),CSe.forEach(t),NPo=i(H),V2=n(H,"LI",{});var wSe=s(V2);Che=n(wSe,"STRONG",{});var Hvt=s(Che);qPo=r(Hvt,"distilbert"),Hvt.forEach(t),jPo=r(wSe," \u2014 "),QO=n(wSe,"A",{href:!0});var Uvt=s(QO);DPo=r(Uvt,"DistilBertForMaskedLM"),Uvt.forEach(t),GPo=r(wSe," (DistilBERT model)"),wSe.forEach(t),OPo=i(H),X2=n(H,"LI",{});var ASe=s(X2);whe=n(ASe,"STRONG",{});var Jvt=s(whe);VPo=r(Jvt,"electra"),Jvt.forEach(t),XPo=r(ASe," \u2014 "),WO=n(ASe,"A",{href:!0});var Yvt=s(WO);zPo=r(Yvt,"ElectraForMaskedLM"),Yvt.forEach(t),QPo=r(ASe," (ELECTRA model)"),ASe.forEach(t),WPo=i(H),z2=n(H,"LI",{});var LSe=s(z2);Ahe=n(LSe,"STRONG",{});var Kvt=s(Ahe);HPo=r(Kvt,"flaubert"),Kvt.forEach(t),UPo=r(LSe," \u2014 "),HO=n(LSe,"A",{href:!0});var Zvt=s(HO);JPo=r(Zvt,"FlaubertWithLMHeadModel"),Zvt.forEach(t),YPo=r(LSe," (FlauBERT model)"),LSe.forEach(t),KPo=i(H),Q2=n(H,"LI",{});var ySe=s(Q2);Lhe=n(ySe,"STRONG",{});var eFt=s(Lhe);ZPo=r(eFt,"fnet"),eFt.forEach(t),eBo=r(ySe," \u2014 "),UO=n(ySe,"A",{href:!0});var oFt=s(UO);oBo=r(oFt,"FNetForMaskedLM"),oFt.forEach(t),rBo=r(ySe," (FNet model)"),ySe.forEach(t),tBo=i(H),W2=n(H,"LI",{});var xSe=s(W2);yhe=n(xSe,"STRONG",{});var rFt=s(yhe);aBo=r(rFt,"funnel"),rFt.forEach(t),nBo=r(xSe," \u2014 "),JO=n(xSe,"A",{href:!0});var tFt=s(JO);sBo=r(tFt,"FunnelForMaskedLM"),tFt.forEach(t),lBo=r(xSe," (Funnel Transformer model)"),xSe.forEach(t),iBo=i(H),H2=n(H,"LI",{});var $Se=s(H2);xhe=n($Se,"STRONG",{});var aFt=s(xhe);dBo=r(aFt,"ibert"),aFt.forEach(t),cBo=r($Se," \u2014 "),YO=n($Se,"A",{href:!0});var nFt=s(YO);fBo=r(nFt,"IBertForMaskedLM"),nFt.forEach(t),mBo=r($Se," (I-BERT model)"),$Se.forEach(t),gBo=i(H),U2=n(H,"LI",{});var kSe=s(U2);$he=n(kSe,"STRONG",{});var sFt=s($he);hBo=r(sFt,"layoutlm"),sFt.forEach(t),pBo=r(kSe," \u2014 "),KO=n(kSe,"A",{href:!0});var lFt=s(KO);_Bo=r(lFt,"LayoutLMForMaskedLM"),lFt.forEach(t),uBo=r(kSe," (LayoutLM model)"),kSe.forEach(t),bBo=i(H),J2=n(H,"LI",{});var SSe=s(J2);khe=n(SSe,"STRONG",{});var iFt=s(khe);vBo=r(iFt,"longformer"),iFt.forEach(t),FBo=r(SSe," \u2014 "),ZO=n(SSe,"A",{href:!0});var dFt=s(ZO);TBo=r(dFt,"LongformerForMaskedLM"),dFt.forEach(t),MBo=r(SSe," (Longformer model)"),SSe.forEach(t),EBo=i(H),Y2=n(H,"LI",{});var RSe=s(Y2);She=n(RSe,"STRONG",{});var cFt=s(She);CBo=r(cFt,"luke"),cFt.forEach(t),wBo=r(RSe," \u2014 "),eV=n(RSe,"A",{href:!0});var fFt=s(eV);ABo=r(fFt,"LukeForMaskedLM"),fFt.forEach(t),LBo=r(RSe," (LUKE model)"),RSe.forEach(t),yBo=i(H),K2=n(H,"LI",{});var PSe=s(K2);Rhe=n(PSe,"STRONG",{});var mFt=s(Rhe);xBo=r(mFt,"mbart"),mFt.forEach(t),$Bo=r(PSe," \u2014 "),oV=n(PSe,"A",{href:!0});var gFt=s(oV);kBo=r(gFt,"MBartForConditionalGeneration"),gFt.forEach(t),SBo=r(PSe," (mBART model)"),PSe.forEach(t),RBo=i(H),Z2=n(H,"LI",{});var BSe=s(Z2);Phe=n(BSe,"STRONG",{});var hFt=s(Phe);PBo=r(hFt,"megatron-bert"),hFt.forEach(t),BBo=r(BSe," \u2014 "),rV=n(BSe,"A",{href:!0});var pFt=s(rV);IBo=r(pFt,"MegatronBertForMaskedLM"),pFt.forEach(t),NBo=r(BSe," (Megatron-BERT model)"),BSe.forEach(t),qBo=i(H),eb=n(H,"LI",{});var ISe=s(eb);Bhe=n(ISe,"STRONG",{});var _Ft=s(Bhe);jBo=r(_Ft,"mobilebert"),_Ft.forEach(t),DBo=r(ISe," \u2014 "),tV=n(ISe,"A",{href:!0});var uFt=s(tV);GBo=r(uFt,"MobileBertForMaskedLM"),uFt.forEach(t),OBo=r(ISe," (MobileBERT model)"),ISe.forEach(t),VBo=i(H),ob=n(H,"LI",{});var NSe=s(ob);Ihe=n(NSe,"STRONG",{});var bFt=s(Ihe);XBo=r(bFt,"mpnet"),bFt.forEach(t),zBo=r(NSe," \u2014 "),aV=n(NSe,"A",{href:!0});var vFt=s(aV);QBo=r(vFt,"MPNetForMaskedLM"),vFt.forEach(t),WBo=r(NSe," (MPNet model)"),NSe.forEach(t),HBo=i(H),rb=n(H,"LI",{});var qSe=s(rb);Nhe=n(qSe,"STRONG",{});var FFt=s(Nhe);UBo=r(FFt,"mvp"),FFt.forEach(t),JBo=r(qSe," \u2014 "),nV=n(qSe,"A",{href:!0});var TFt=s(nV);YBo=r(TFt,"MvpForConditionalGeneration"),TFt.forEach(t),KBo=r(qSe," (MVP model)"),qSe.forEach(t),ZBo=i(H),tb=n(H,"LI",{});var jSe=s(tb);qhe=n(jSe,"STRONG",{});var MFt=s(qhe);eIo=r(MFt,"nezha"),MFt.forEach(t),oIo=r(jSe," \u2014 "),sV=n(jSe,"A",{href:!0});var EFt=s(sV);rIo=r(EFt,"NezhaForMaskedLM"),EFt.forEach(t),tIo=r(jSe," (Nezha model)"),jSe.forEach(t),aIo=i(H),ab=n(H,"LI",{});var DSe=s(ab);jhe=n(DSe,"STRONG",{});var CFt=s(jhe);nIo=r(CFt,"nystromformer"),CFt.forEach(t),sIo=r(DSe," \u2014 "),lV=n(DSe,"A",{href:!0});var wFt=s(lV);lIo=r(wFt,"NystromformerForMaskedLM"),wFt.forEach(t),iIo=r(DSe," (Nystr\xF6mformer model)"),DSe.forEach(t),dIo=i(H),nb=n(H,"LI",{});var GSe=s(nb);Dhe=n(GSe,"STRONG",{});var AFt=s(Dhe);cIo=r(AFt,"perceiver"),AFt.forEach(t),fIo=r(GSe," \u2014 "),iV=n(GSe,"A",{href:!0});var LFt=s(iV);mIo=r(LFt,"PerceiverForMaskedLM"),LFt.forEach(t),gIo=r(GSe," (Perceiver model)"),GSe.forEach(t),hIo=i(H),sb=n(H,"LI",{});var OSe=s(sb);Ghe=n(OSe,"STRONG",{});var yFt=s(Ghe);pIo=r(yFt,"qdqbert"),yFt.forEach(t),_Io=r(OSe," \u2014 "),dV=n(OSe,"A",{href:!0});var xFt=s(dV);uIo=r(xFt,"QDQBertForMaskedLM"),xFt.forEach(t),bIo=r(OSe," (QDQBert model)"),OSe.forEach(t),vIo=i(H),lb=n(H,"LI",{});var VSe=s(lb);Ohe=n(VSe,"STRONG",{});var $Ft=s(Ohe);FIo=r($Ft,"reformer"),$Ft.forEach(t),TIo=r(VSe," \u2014 "),cV=n(VSe,"A",{href:!0});var kFt=s(cV);MIo=r(kFt,"ReformerForMaskedLM"),kFt.forEach(t),EIo=r(VSe," (Reformer model)"),VSe.forEach(t),CIo=i(H),ib=n(H,"LI",{});var XSe=s(ib);Vhe=n(XSe,"STRONG",{});var SFt=s(Vhe);wIo=r(SFt,"rembert"),SFt.forEach(t),AIo=r(XSe," \u2014 "),fV=n(XSe,"A",{href:!0});var RFt=s(fV);LIo=r(RFt,"RemBertForMaskedLM"),RFt.forEach(t),yIo=r(XSe," (RemBERT model)"),XSe.forEach(t),xIo=i(H),db=n(H,"LI",{});var zSe=s(db);Xhe=n(zSe,"STRONG",{});var PFt=s(Xhe);$Io=r(PFt,"roberta"),PFt.forEach(t),kIo=r(zSe," \u2014 "),mV=n(zSe,"A",{href:!0});var BFt=s(mV);SIo=r(BFt,"RobertaForMaskedLM"),BFt.forEach(t),RIo=r(zSe," (RoBERTa model)"),zSe.forEach(t),PIo=i(H),cb=n(H,"LI",{});var QSe=s(cb);zhe=n(QSe,"STRONG",{});var IFt=s(zhe);BIo=r(IFt,"roformer"),IFt.forEach(t),IIo=r(QSe," \u2014 "),gV=n(QSe,"A",{href:!0});var NFt=s(gV);NIo=r(NFt,"RoFormerForMaskedLM"),NFt.forEach(t),qIo=r(QSe," (RoFormer model)"),QSe.forEach(t),jIo=i(H),fb=n(H,"LI",{});var WSe=s(fb);Qhe=n(WSe,"STRONG",{});var qFt=s(Qhe);DIo=r(qFt,"squeezebert"),qFt.forEach(t),GIo=r(WSe," \u2014 "),hV=n(WSe,"A",{href:!0});var jFt=s(hV);OIo=r(jFt,"SqueezeBertForMaskedLM"),jFt.forEach(t),VIo=r(WSe," (SqueezeBERT model)"),WSe.forEach(t),XIo=i(H),mb=n(H,"LI",{});var HSe=s(mb);Whe=n(HSe,"STRONG",{});var DFt=s(Whe);zIo=r(DFt,"tapas"),DFt.forEach(t),QIo=r(HSe," \u2014 "),pV=n(HSe,"A",{href:!0});var GFt=s(pV);WIo=r(GFt,"TapasForMaskedLM"),GFt.forEach(t),HIo=r(HSe," (TAPAS model)"),HSe.forEach(t),UIo=i(H),gb=n(H,"LI",{});var USe=s(gb);Hhe=n(USe,"STRONG",{});var OFt=s(Hhe);JIo=r(OFt,"wav2vec2"),OFt.forEach(t),YIo=r(USe," \u2014 "),Uhe=n(USe,"CODE",{});var VFt=s(Uhe);KIo=r(VFt,"Wav2Vec2ForMaskedLM"),VFt.forEach(t),ZIo=r(USe," (Wav2Vec2 model)"),USe.forEach(t),eNo=i(H),hb=n(H,"LI",{});var JSe=s(hb);Jhe=n(JSe,"STRONG",{});var XFt=s(Jhe);oNo=r(XFt,"xlm"),XFt.forEach(t),rNo=r(JSe," \u2014 "),_V=n(JSe,"A",{href:!0});var zFt=s(_V);tNo=r(zFt,"XLMWithLMHeadModel"),zFt.forEach(t),aNo=r(JSe," (XLM model)"),JSe.forEach(t),nNo=i(H),pb=n(H,"LI",{});var YSe=s(pb);Yhe=n(YSe,"STRONG",{});var QFt=s(Yhe);sNo=r(QFt,"xlm-roberta"),QFt.forEach(t),lNo=r(YSe," \u2014 "),uV=n(YSe,"A",{href:!0});var WFt=s(uV);iNo=r(WFt,"XLMRobertaForMaskedLM"),WFt.forEach(t),dNo=r(YSe," (XLM-RoBERTa model)"),YSe.forEach(t),cNo=i(H),_b=n(H,"LI",{});var KSe=s(_b);Khe=n(KSe,"STRONG",{});var HFt=s(Khe);fNo=r(HFt,"xlm-roberta-xl"),HFt.forEach(t),mNo=r(KSe," \u2014 "),bV=n(KSe,"A",{href:!0});var UFt=s(bV);gNo=r(UFt,"XLMRobertaXLForMaskedLM"),UFt.forEach(t),hNo=r(KSe," (XLM-RoBERTa-XL model)"),KSe.forEach(t),pNo=i(H),ub=n(H,"LI",{});var ZSe=s(ub);Zhe=n(ZSe,"STRONG",{});var JFt=s(Zhe);_No=r(JFt,"yoso"),JFt.forEach(t),uNo=r(ZSe," \u2014 "),vV=n(ZSe,"A",{href:!0});var YFt=s(vV);bNo=r(YFt,"YosoForMaskedLM"),YFt.forEach(t),vNo=r(ZSe," (YOSO model)"),ZSe.forEach(t),H.forEach(t),FNo=i(da),bb=n(da,"P",{});var eRe=s(bb);TNo=r(eRe,"The model is set in evaluation mode by default using "),epe=n(eRe,"CODE",{});var KFt=s(epe);MNo=r(KFt,"model.eval()"),KFt.forEach(t),ENo=r(eRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ope=n(eRe,"CODE",{});var ZFt=s(ope);CNo=r(ZFt,"model.train()"),ZFt.forEach(t),eRe.forEach(t),wNo=i(da),T(vb.$$.fragment,da),da.forEach(t),tl.forEach(t),nXe=i(f),Ki=n(f,"H2",{class:!0});var fQe=s(Ki);Fb=n(fQe,"A",{id:!0,class:!0,href:!0});var eTt=s(Fb);rpe=n(eTt,"SPAN",{});var oTt=s(rpe);T(WL.$$.fragment,oTt),oTt.forEach(t),eTt.forEach(t),ANo=i(fQe),tpe=n(fQe,"SPAN",{});var rTt=s(tpe);LNo=r(rTt,"AutoModelForSeq2SeqLM"),rTt.forEach(t),fQe.forEach(t),sXe=i(f),Ro=n(f,"DIV",{class:!0});var al=s(Ro);T(HL.$$.fragment,al),yNo=i(al),Zi=n(al,"P",{});var kre=s(Zi);xNo=r(kre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),FV=n(kre,"A",{href:!0});var tTt=s(FV);$No=r(tTt,"from_pretrained()"),tTt.forEach(t),kNo=r(kre," class method or the "),TV=n(kre,"A",{href:!0});var aTt=s(TV);SNo=r(aTt,"from_config()"),aTt.forEach(t),RNo=r(kre,` class
method.`),kre.forEach(t),PNo=i(al),UL=n(al,"P",{});var mQe=s(UL);BNo=r(mQe,"This class cannot be instantiated directly using "),ape=n(mQe,"CODE",{});var nTt=s(ape);INo=r(nTt,"__init__()"),nTt.forEach(t),NNo=r(mQe," (throws an error)."),mQe.forEach(t),qNo=i(al),ft=n(al,"DIV",{class:!0});var gA=s(ft);T(JL.$$.fragment,gA),jNo=i(gA),npe=n(gA,"P",{});var sTt=s(npe);DNo=r(sTt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),sTt.forEach(t),GNo=i(gA),ed=n(gA,"P",{});var Sre=s(ed);ONo=r(Sre,`Note:
Loading a model from its configuration file does `),spe=n(Sre,"STRONG",{});var lTt=s(spe);VNo=r(lTt,"not"),lTt.forEach(t),XNo=r(Sre,` load the model weights. It only affects the
model\u2019s configuration. Use `),MV=n(Sre,"A",{href:!0});var iTt=s(MV);zNo=r(iTt,"from_pretrained()"),iTt.forEach(t),QNo=r(Sre," to load the model weights."),Sre.forEach(t),WNo=i(gA),T(Tb.$$.fragment,gA),gA.forEach(t),HNo=i(al),eo=n(al,"DIV",{class:!0});var ca=s(eo);T(YL.$$.fragment,ca),UNo=i(ca),lpe=n(ca,"P",{});var dTt=s(lpe);JNo=r(dTt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),dTt.forEach(t),YNo=i(ca),ja=n(ca,"P",{});var hA=s(ja);KNo=r(hA,"The model class to instantiate is selected based on the "),ipe=n(hA,"CODE",{});var cTt=s(ipe);ZNo=r(cTt,"model_type"),cTt.forEach(t),eqo=r(hA,` property of the config object (either
passed as an argument or loaded from `),dpe=n(hA,"CODE",{});var fTt=s(dpe);oqo=r(fTt,"pretrained_model_name_or_path"),fTt.forEach(t),rqo=r(hA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cpe=n(hA,"CODE",{});var mTt=s(cpe);tqo=r(mTt,"pretrained_model_name_or_path"),mTt.forEach(t),aqo=r(hA,":"),hA.forEach(t),nqo=i(ca),pe=n(ca,"UL",{});var be=s(pe);Mb=n(be,"LI",{});var oRe=s(Mb);fpe=n(oRe,"STRONG",{});var gTt=s(fpe);sqo=r(gTt,"bart"),gTt.forEach(t),lqo=r(oRe," \u2014 "),EV=n(oRe,"A",{href:!0});var hTt=s(EV);iqo=r(hTt,"BartForConditionalGeneration"),hTt.forEach(t),dqo=r(oRe," (BART model)"),oRe.forEach(t),cqo=i(be),Eb=n(be,"LI",{});var rRe=s(Eb);mpe=n(rRe,"STRONG",{});var pTt=s(mpe);fqo=r(pTt,"bigbird_pegasus"),pTt.forEach(t),mqo=r(rRe," \u2014 "),CV=n(rRe,"A",{href:!0});var _Tt=s(CV);gqo=r(_Tt,"BigBirdPegasusForConditionalGeneration"),_Tt.forEach(t),hqo=r(rRe," (BigBird-Pegasus model)"),rRe.forEach(t),pqo=i(be),Cb=n(be,"LI",{});var tRe=s(Cb);gpe=n(tRe,"STRONG",{});var uTt=s(gpe);_qo=r(uTt,"blenderbot"),uTt.forEach(t),uqo=r(tRe," \u2014 "),wV=n(tRe,"A",{href:!0});var bTt=s(wV);bqo=r(bTt,"BlenderbotForConditionalGeneration"),bTt.forEach(t),vqo=r(tRe," (Blenderbot model)"),tRe.forEach(t),Fqo=i(be),wb=n(be,"LI",{});var aRe=s(wb);hpe=n(aRe,"STRONG",{});var vTt=s(hpe);Tqo=r(vTt,"blenderbot-small"),vTt.forEach(t),Mqo=r(aRe," \u2014 "),AV=n(aRe,"A",{href:!0});var FTt=s(AV);Eqo=r(FTt,"BlenderbotSmallForConditionalGeneration"),FTt.forEach(t),Cqo=r(aRe," (BlenderbotSmall model)"),aRe.forEach(t),wqo=i(be),Ab=n(be,"LI",{});var nRe=s(Ab);ppe=n(nRe,"STRONG",{});var TTt=s(ppe);Aqo=r(TTt,"encoder-decoder"),TTt.forEach(t),Lqo=r(nRe," \u2014 "),LV=n(nRe,"A",{href:!0});var MTt=s(LV);yqo=r(MTt,"EncoderDecoderModel"),MTt.forEach(t),xqo=r(nRe," (Encoder decoder model)"),nRe.forEach(t),$qo=i(be),Lb=n(be,"LI",{});var sRe=s(Lb);_pe=n(sRe,"STRONG",{});var ETt=s(_pe);kqo=r(ETt,"fsmt"),ETt.forEach(t),Sqo=r(sRe," \u2014 "),yV=n(sRe,"A",{href:!0});var CTt=s(yV);Rqo=r(CTt,"FSMTForConditionalGeneration"),CTt.forEach(t),Pqo=r(sRe," (FairSeq Machine-Translation model)"),sRe.forEach(t),Bqo=i(be),yb=n(be,"LI",{});var lRe=s(yb);upe=n(lRe,"STRONG",{});var wTt=s(upe);Iqo=r(wTt,"led"),wTt.forEach(t),Nqo=r(lRe," \u2014 "),xV=n(lRe,"A",{href:!0});var ATt=s(xV);qqo=r(ATt,"LEDForConditionalGeneration"),ATt.forEach(t),jqo=r(lRe," (LED model)"),lRe.forEach(t),Dqo=i(be),xb=n(be,"LI",{});var iRe=s(xb);bpe=n(iRe,"STRONG",{});var LTt=s(bpe);Gqo=r(LTt,"longt5"),LTt.forEach(t),Oqo=r(iRe," \u2014 "),$V=n(iRe,"A",{href:!0});var yTt=s($V);Vqo=r(yTt,"LongT5ForConditionalGeneration"),yTt.forEach(t),Xqo=r(iRe," (LongT5 model)"),iRe.forEach(t),zqo=i(be),$b=n(be,"LI",{});var dRe=s($b);vpe=n(dRe,"STRONG",{});var xTt=s(vpe);Qqo=r(xTt,"m2m_100"),xTt.forEach(t),Wqo=r(dRe," \u2014 "),kV=n(dRe,"A",{href:!0});var $Tt=s(kV);Hqo=r($Tt,"M2M100ForConditionalGeneration"),$Tt.forEach(t),Uqo=r(dRe," (M2M100 model)"),dRe.forEach(t),Jqo=i(be),kb=n(be,"LI",{});var cRe=s(kb);Fpe=n(cRe,"STRONG",{});var kTt=s(Fpe);Yqo=r(kTt,"marian"),kTt.forEach(t),Kqo=r(cRe," \u2014 "),SV=n(cRe,"A",{href:!0});var STt=s(SV);Zqo=r(STt,"MarianMTModel"),STt.forEach(t),ejo=r(cRe," (Marian model)"),cRe.forEach(t),ojo=i(be),Sb=n(be,"LI",{});var fRe=s(Sb);Tpe=n(fRe,"STRONG",{});var RTt=s(Tpe);rjo=r(RTt,"mbart"),RTt.forEach(t),tjo=r(fRe," \u2014 "),RV=n(fRe,"A",{href:!0});var PTt=s(RV);ajo=r(PTt,"MBartForConditionalGeneration"),PTt.forEach(t),njo=r(fRe," (mBART model)"),fRe.forEach(t),sjo=i(be),Rb=n(be,"LI",{});var mRe=s(Rb);Mpe=n(mRe,"STRONG",{});var BTt=s(Mpe);ljo=r(BTt,"mt5"),BTt.forEach(t),ijo=r(mRe," \u2014 "),PV=n(mRe,"A",{href:!0});var ITt=s(PV);djo=r(ITt,"MT5ForConditionalGeneration"),ITt.forEach(t),cjo=r(mRe," (MT5 model)"),mRe.forEach(t),fjo=i(be),Pb=n(be,"LI",{});var gRe=s(Pb);Epe=n(gRe,"STRONG",{});var NTt=s(Epe);mjo=r(NTt,"mvp"),NTt.forEach(t),gjo=r(gRe," \u2014 "),BV=n(gRe,"A",{href:!0});var qTt=s(BV);hjo=r(qTt,"MvpForConditionalGeneration"),qTt.forEach(t),pjo=r(gRe," (MVP model)"),gRe.forEach(t),_jo=i(be),Bb=n(be,"LI",{});var hRe=s(Bb);Cpe=n(hRe,"STRONG",{});var jTt=s(Cpe);ujo=r(jTt,"pegasus"),jTt.forEach(t),bjo=r(hRe," \u2014 "),IV=n(hRe,"A",{href:!0});var DTt=s(IV);vjo=r(DTt,"PegasusForConditionalGeneration"),DTt.forEach(t),Fjo=r(hRe," (Pegasus model)"),hRe.forEach(t),Tjo=i(be),Ib=n(be,"LI",{});var pRe=s(Ib);wpe=n(pRe,"STRONG",{});var GTt=s(wpe);Mjo=r(GTt,"plbart"),GTt.forEach(t),Ejo=r(pRe," \u2014 "),NV=n(pRe,"A",{href:!0});var OTt=s(NV);Cjo=r(OTt,"PLBartForConditionalGeneration"),OTt.forEach(t),wjo=r(pRe," (PLBart model)"),pRe.forEach(t),Ajo=i(be),Nb=n(be,"LI",{});var _Re=s(Nb);Ape=n(_Re,"STRONG",{});var VTt=s(Ape);Ljo=r(VTt,"prophetnet"),VTt.forEach(t),yjo=r(_Re," \u2014 "),qV=n(_Re,"A",{href:!0});var XTt=s(qV);xjo=r(XTt,"ProphetNetForConditionalGeneration"),XTt.forEach(t),$jo=r(_Re," (ProphetNet model)"),_Re.forEach(t),kjo=i(be),qb=n(be,"LI",{});var uRe=s(qb);Lpe=n(uRe,"STRONG",{});var zTt=s(Lpe);Sjo=r(zTt,"t5"),zTt.forEach(t),Rjo=r(uRe," \u2014 "),jV=n(uRe,"A",{href:!0});var QTt=s(jV);Pjo=r(QTt,"T5ForConditionalGeneration"),QTt.forEach(t),Bjo=r(uRe," (T5 model)"),uRe.forEach(t),Ijo=i(be),jb=n(be,"LI",{});var bRe=s(jb);ype=n(bRe,"STRONG",{});var WTt=s(ype);Njo=r(WTt,"xlm-prophetnet"),WTt.forEach(t),qjo=r(bRe," \u2014 "),DV=n(bRe,"A",{href:!0});var HTt=s(DV);jjo=r(HTt,"XLMProphetNetForConditionalGeneration"),HTt.forEach(t),Djo=r(bRe," (XLM-ProphetNet model)"),bRe.forEach(t),be.forEach(t),Gjo=i(ca),Db=n(ca,"P",{});var vRe=s(Db);Ojo=r(vRe,"The model is set in evaluation mode by default using "),xpe=n(vRe,"CODE",{});var UTt=s(xpe);Vjo=r(UTt,"model.eval()"),UTt.forEach(t),Xjo=r(vRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$pe=n(vRe,"CODE",{});var JTt=s($pe);zjo=r(JTt,"model.train()"),JTt.forEach(t),vRe.forEach(t),Qjo=i(ca),T(Gb.$$.fragment,ca),ca.forEach(t),al.forEach(t),lXe=i(f),od=n(f,"H2",{class:!0});var gQe=s(od);Ob=n(gQe,"A",{id:!0,class:!0,href:!0});var YTt=s(Ob);kpe=n(YTt,"SPAN",{});var KTt=s(kpe);T(KL.$$.fragment,KTt),KTt.forEach(t),YTt.forEach(t),Wjo=i(gQe),Spe=n(gQe,"SPAN",{});var ZTt=s(Spe);Hjo=r(ZTt,"AutoModelForSequenceClassification"),ZTt.forEach(t),gQe.forEach(t),iXe=i(f),Po=n(f,"DIV",{class:!0});var nl=s(Po);T(ZL.$$.fragment,nl),Ujo=i(nl),rd=n(nl,"P",{});var Rre=s(rd);Jjo=r(Rre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),GV=n(Rre,"A",{href:!0});var e7t=s(GV);Yjo=r(e7t,"from_pretrained()"),e7t.forEach(t),Kjo=r(Rre," class method or the "),OV=n(Rre,"A",{href:!0});var o7t=s(OV);Zjo=r(o7t,"from_config()"),o7t.forEach(t),eDo=r(Rre,` class
method.`),Rre.forEach(t),oDo=i(nl),ey=n(nl,"P",{});var hQe=s(ey);rDo=r(hQe,"This class cannot be instantiated directly using "),Rpe=n(hQe,"CODE",{});var r7t=s(Rpe);tDo=r(r7t,"__init__()"),r7t.forEach(t),aDo=r(hQe," (throws an error)."),hQe.forEach(t),nDo=i(nl),mt=n(nl,"DIV",{class:!0});var pA=s(mt);T(oy.$$.fragment,pA),sDo=i(pA),Ppe=n(pA,"P",{});var t7t=s(Ppe);lDo=r(t7t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),t7t.forEach(t),iDo=i(pA),td=n(pA,"P",{});var Pre=s(td);dDo=r(Pre,`Note:
Loading a model from its configuration file does `),Bpe=n(Pre,"STRONG",{});var a7t=s(Bpe);cDo=r(a7t,"not"),a7t.forEach(t),fDo=r(Pre,` load the model weights. It only affects the
model\u2019s configuration. Use `),VV=n(Pre,"A",{href:!0});var n7t=s(VV);mDo=r(n7t,"from_pretrained()"),n7t.forEach(t),gDo=r(Pre," to load the model weights."),Pre.forEach(t),hDo=i(pA),T(Vb.$$.fragment,pA),pA.forEach(t),pDo=i(nl),oo=n(nl,"DIV",{class:!0});var fa=s(oo);T(ry.$$.fragment,fa),_Do=i(fa),Ipe=n(fa,"P",{});var s7t=s(Ipe);uDo=r(s7t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),s7t.forEach(t),bDo=i(fa),Da=n(fa,"P",{});var _A=s(Da);vDo=r(_A,"The model class to instantiate is selected based on the "),Npe=n(_A,"CODE",{});var l7t=s(Npe);FDo=r(l7t,"model_type"),l7t.forEach(t),TDo=r(_A,` property of the config object (either
passed as an argument or loaded from `),qpe=n(_A,"CODE",{});var i7t=s(qpe);MDo=r(i7t,"pretrained_model_name_or_path"),i7t.forEach(t),EDo=r(_A,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jpe=n(_A,"CODE",{});var d7t=s(jpe);CDo=r(d7t,"pretrained_model_name_or_path"),d7t.forEach(t),wDo=r(_A,":"),_A.forEach(t),ADo=i(fa),N=n(fa,"UL",{});var q=s(N);Xb=n(q,"LI",{});var FRe=s(Xb);Dpe=n(FRe,"STRONG",{});var c7t=s(Dpe);LDo=r(c7t,"albert"),c7t.forEach(t),yDo=r(FRe," \u2014 "),XV=n(FRe,"A",{href:!0});var f7t=s(XV);xDo=r(f7t,"AlbertForSequenceClassification"),f7t.forEach(t),$Do=r(FRe," (ALBERT model)"),FRe.forEach(t),kDo=i(q),zb=n(q,"LI",{});var TRe=s(zb);Gpe=n(TRe,"STRONG",{});var m7t=s(Gpe);SDo=r(m7t,"bart"),m7t.forEach(t),RDo=r(TRe," \u2014 "),zV=n(TRe,"A",{href:!0});var g7t=s(zV);PDo=r(g7t,"BartForSequenceClassification"),g7t.forEach(t),BDo=r(TRe," (BART model)"),TRe.forEach(t),IDo=i(q),Qb=n(q,"LI",{});var MRe=s(Qb);Ope=n(MRe,"STRONG",{});var h7t=s(Ope);NDo=r(h7t,"bert"),h7t.forEach(t),qDo=r(MRe," \u2014 "),QV=n(MRe,"A",{href:!0});var p7t=s(QV);jDo=r(p7t,"BertForSequenceClassification"),p7t.forEach(t),DDo=r(MRe," (BERT model)"),MRe.forEach(t),GDo=i(q),Wb=n(q,"LI",{});var ERe=s(Wb);Vpe=n(ERe,"STRONG",{});var _7t=s(Vpe);ODo=r(_7t,"big_bird"),_7t.forEach(t),VDo=r(ERe," \u2014 "),WV=n(ERe,"A",{href:!0});var u7t=s(WV);XDo=r(u7t,"BigBirdForSequenceClassification"),u7t.forEach(t),zDo=r(ERe," (BigBird model)"),ERe.forEach(t),QDo=i(q),Hb=n(q,"LI",{});var CRe=s(Hb);Xpe=n(CRe,"STRONG",{});var b7t=s(Xpe);WDo=r(b7t,"bigbird_pegasus"),b7t.forEach(t),HDo=r(CRe," \u2014 "),HV=n(CRe,"A",{href:!0});var v7t=s(HV);UDo=r(v7t,"BigBirdPegasusForSequenceClassification"),v7t.forEach(t),JDo=r(CRe," (BigBird-Pegasus model)"),CRe.forEach(t),YDo=i(q),Ub=n(q,"LI",{});var wRe=s(Ub);zpe=n(wRe,"STRONG",{});var F7t=s(zpe);KDo=r(F7t,"bloom"),F7t.forEach(t),ZDo=r(wRe," \u2014 "),UV=n(wRe,"A",{href:!0});var T7t=s(UV);eGo=r(T7t,"BloomForSequenceClassification"),T7t.forEach(t),oGo=r(wRe," (BLOOM model)"),wRe.forEach(t),rGo=i(q),Jb=n(q,"LI",{});var ARe=s(Jb);Qpe=n(ARe,"STRONG",{});var M7t=s(Qpe);tGo=r(M7t,"camembert"),M7t.forEach(t),aGo=r(ARe," \u2014 "),JV=n(ARe,"A",{href:!0});var E7t=s(JV);nGo=r(E7t,"CamembertForSequenceClassification"),E7t.forEach(t),sGo=r(ARe," (CamemBERT model)"),ARe.forEach(t),lGo=i(q),Yb=n(q,"LI",{});var LRe=s(Yb);Wpe=n(LRe,"STRONG",{});var C7t=s(Wpe);iGo=r(C7t,"canine"),C7t.forEach(t),dGo=r(LRe," \u2014 "),YV=n(LRe,"A",{href:!0});var w7t=s(YV);cGo=r(w7t,"CanineForSequenceClassification"),w7t.forEach(t),fGo=r(LRe," (CANINE model)"),LRe.forEach(t),mGo=i(q),Kb=n(q,"LI",{});var yRe=s(Kb);Hpe=n(yRe,"STRONG",{});var A7t=s(Hpe);gGo=r(A7t,"convbert"),A7t.forEach(t),hGo=r(yRe," \u2014 "),KV=n(yRe,"A",{href:!0});var L7t=s(KV);pGo=r(L7t,"ConvBertForSequenceClassification"),L7t.forEach(t),_Go=r(yRe," (ConvBERT model)"),yRe.forEach(t),uGo=i(q),Zb=n(q,"LI",{});var xRe=s(Zb);Upe=n(xRe,"STRONG",{});var y7t=s(Upe);bGo=r(y7t,"ctrl"),y7t.forEach(t),vGo=r(xRe," \u2014 "),ZV=n(xRe,"A",{href:!0});var x7t=s(ZV);FGo=r(x7t,"CTRLForSequenceClassification"),x7t.forEach(t),TGo=r(xRe," (CTRL model)"),xRe.forEach(t),MGo=i(q),ev=n(q,"LI",{});var $Re=s(ev);Jpe=n($Re,"STRONG",{});var $7t=s(Jpe);EGo=r($7t,"data2vec-text"),$7t.forEach(t),CGo=r($Re," \u2014 "),eX=n($Re,"A",{href:!0});var k7t=s(eX);wGo=r(k7t,"Data2VecTextForSequenceClassification"),k7t.forEach(t),AGo=r($Re," (Data2VecText model)"),$Re.forEach(t),LGo=i(q),ov=n(q,"LI",{});var kRe=s(ov);Ype=n(kRe,"STRONG",{});var S7t=s(Ype);yGo=r(S7t,"deberta"),S7t.forEach(t),xGo=r(kRe," \u2014 "),oX=n(kRe,"A",{href:!0});var R7t=s(oX);$Go=r(R7t,"DebertaForSequenceClassification"),R7t.forEach(t),kGo=r(kRe," (DeBERTa model)"),kRe.forEach(t),SGo=i(q),rv=n(q,"LI",{});var SRe=s(rv);Kpe=n(SRe,"STRONG",{});var P7t=s(Kpe);RGo=r(P7t,"deberta-v2"),P7t.forEach(t),PGo=r(SRe," \u2014 "),rX=n(SRe,"A",{href:!0});var B7t=s(rX);BGo=r(B7t,"DebertaV2ForSequenceClassification"),B7t.forEach(t),IGo=r(SRe," (DeBERTa-v2 model)"),SRe.forEach(t),NGo=i(q),tv=n(q,"LI",{});var RRe=s(tv);Zpe=n(RRe,"STRONG",{});var I7t=s(Zpe);qGo=r(I7t,"distilbert"),I7t.forEach(t),jGo=r(RRe," \u2014 "),tX=n(RRe,"A",{href:!0});var N7t=s(tX);DGo=r(N7t,"DistilBertForSequenceClassification"),N7t.forEach(t),GGo=r(RRe," (DistilBERT model)"),RRe.forEach(t),OGo=i(q),av=n(q,"LI",{});var PRe=s(av);e_e=n(PRe,"STRONG",{});var q7t=s(e_e);VGo=r(q7t,"electra"),q7t.forEach(t),XGo=r(PRe," \u2014 "),aX=n(PRe,"A",{href:!0});var j7t=s(aX);zGo=r(j7t,"ElectraForSequenceClassification"),j7t.forEach(t),QGo=r(PRe," (ELECTRA model)"),PRe.forEach(t),WGo=i(q),nv=n(q,"LI",{});var BRe=s(nv);o_e=n(BRe,"STRONG",{});var D7t=s(o_e);HGo=r(D7t,"flaubert"),D7t.forEach(t),UGo=r(BRe," \u2014 "),nX=n(BRe,"A",{href:!0});var G7t=s(nX);JGo=r(G7t,"FlaubertForSequenceClassification"),G7t.forEach(t),YGo=r(BRe," (FlauBERT model)"),BRe.forEach(t),KGo=i(q),sv=n(q,"LI",{});var IRe=s(sv);r_e=n(IRe,"STRONG",{});var O7t=s(r_e);ZGo=r(O7t,"fnet"),O7t.forEach(t),eOo=r(IRe," \u2014 "),sX=n(IRe,"A",{href:!0});var V7t=s(sX);oOo=r(V7t,"FNetForSequenceClassification"),V7t.forEach(t),rOo=r(IRe," (FNet model)"),IRe.forEach(t),tOo=i(q),lv=n(q,"LI",{});var NRe=s(lv);t_e=n(NRe,"STRONG",{});var X7t=s(t_e);aOo=r(X7t,"funnel"),X7t.forEach(t),nOo=r(NRe," \u2014 "),lX=n(NRe,"A",{href:!0});var z7t=s(lX);sOo=r(z7t,"FunnelForSequenceClassification"),z7t.forEach(t),lOo=r(NRe," (Funnel Transformer model)"),NRe.forEach(t),iOo=i(q),iv=n(q,"LI",{});var qRe=s(iv);a_e=n(qRe,"STRONG",{});var Q7t=s(a_e);dOo=r(Q7t,"gpt2"),Q7t.forEach(t),cOo=r(qRe," \u2014 "),iX=n(qRe,"A",{href:!0});var W7t=s(iX);fOo=r(W7t,"GPT2ForSequenceClassification"),W7t.forEach(t),mOo=r(qRe," (OpenAI GPT-2 model)"),qRe.forEach(t),gOo=i(q),dv=n(q,"LI",{});var jRe=s(dv);n_e=n(jRe,"STRONG",{});var H7t=s(n_e);hOo=r(H7t,"gpt_neo"),H7t.forEach(t),pOo=r(jRe," \u2014 "),dX=n(jRe,"A",{href:!0});var U7t=s(dX);_Oo=r(U7t,"GPTNeoForSequenceClassification"),U7t.forEach(t),uOo=r(jRe," (GPT Neo model)"),jRe.forEach(t),bOo=i(q),cv=n(q,"LI",{});var DRe=s(cv);s_e=n(DRe,"STRONG",{});var J7t=s(s_e);vOo=r(J7t,"gptj"),J7t.forEach(t),FOo=r(DRe," \u2014 "),cX=n(DRe,"A",{href:!0});var Y7t=s(cX);TOo=r(Y7t,"GPTJForSequenceClassification"),Y7t.forEach(t),MOo=r(DRe," (GPT-J model)"),DRe.forEach(t),EOo=i(q),fv=n(q,"LI",{});var GRe=s(fv);l_e=n(GRe,"STRONG",{});var K7t=s(l_e);COo=r(K7t,"ibert"),K7t.forEach(t),wOo=r(GRe," \u2014 "),fX=n(GRe,"A",{href:!0});var Z7t=s(fX);AOo=r(Z7t,"IBertForSequenceClassification"),Z7t.forEach(t),LOo=r(GRe," (I-BERT model)"),GRe.forEach(t),yOo=i(q),mv=n(q,"LI",{});var ORe=s(mv);i_e=n(ORe,"STRONG",{});var e8t=s(i_e);xOo=r(e8t,"layoutlm"),e8t.forEach(t),$Oo=r(ORe," \u2014 "),mX=n(ORe,"A",{href:!0});var o8t=s(mX);kOo=r(o8t,"LayoutLMForSequenceClassification"),o8t.forEach(t),SOo=r(ORe," (LayoutLM model)"),ORe.forEach(t),ROo=i(q),gv=n(q,"LI",{});var VRe=s(gv);d_e=n(VRe,"STRONG",{});var r8t=s(d_e);POo=r(r8t,"layoutlmv2"),r8t.forEach(t),BOo=r(VRe," \u2014 "),gX=n(VRe,"A",{href:!0});var t8t=s(gX);IOo=r(t8t,"LayoutLMv2ForSequenceClassification"),t8t.forEach(t),NOo=r(VRe," (LayoutLMv2 model)"),VRe.forEach(t),qOo=i(q),hv=n(q,"LI",{});var XRe=s(hv);c_e=n(XRe,"STRONG",{});var a8t=s(c_e);jOo=r(a8t,"layoutlmv3"),a8t.forEach(t),DOo=r(XRe," \u2014 "),hX=n(XRe,"A",{href:!0});var n8t=s(hX);GOo=r(n8t,"LayoutLMv3ForSequenceClassification"),n8t.forEach(t),OOo=r(XRe," (LayoutLMv3 model)"),XRe.forEach(t),VOo=i(q),pv=n(q,"LI",{});var zRe=s(pv);f_e=n(zRe,"STRONG",{});var s8t=s(f_e);XOo=r(s8t,"led"),s8t.forEach(t),zOo=r(zRe," \u2014 "),pX=n(zRe,"A",{href:!0});var l8t=s(pX);QOo=r(l8t,"LEDForSequenceClassification"),l8t.forEach(t),WOo=r(zRe," (LED model)"),zRe.forEach(t),HOo=i(q),_v=n(q,"LI",{});var QRe=s(_v);m_e=n(QRe,"STRONG",{});var i8t=s(m_e);UOo=r(i8t,"longformer"),i8t.forEach(t),JOo=r(QRe," \u2014 "),_X=n(QRe,"A",{href:!0});var d8t=s(_X);YOo=r(d8t,"LongformerForSequenceClassification"),d8t.forEach(t),KOo=r(QRe," (Longformer model)"),QRe.forEach(t),ZOo=i(q),uv=n(q,"LI",{});var WRe=s(uv);g_e=n(WRe,"STRONG",{});var c8t=s(g_e);eVo=r(c8t,"mbart"),c8t.forEach(t),oVo=r(WRe," \u2014 "),uX=n(WRe,"A",{href:!0});var f8t=s(uX);rVo=r(f8t,"MBartForSequenceClassification"),f8t.forEach(t),tVo=r(WRe," (mBART model)"),WRe.forEach(t),aVo=i(q),bv=n(q,"LI",{});var HRe=s(bv);h_e=n(HRe,"STRONG",{});var m8t=s(h_e);nVo=r(m8t,"megatron-bert"),m8t.forEach(t),sVo=r(HRe," \u2014 "),bX=n(HRe,"A",{href:!0});var g8t=s(bX);lVo=r(g8t,"MegatronBertForSequenceClassification"),g8t.forEach(t),iVo=r(HRe," (Megatron-BERT model)"),HRe.forEach(t),dVo=i(q),vv=n(q,"LI",{});var URe=s(vv);p_e=n(URe,"STRONG",{});var h8t=s(p_e);cVo=r(h8t,"mobilebert"),h8t.forEach(t),fVo=r(URe," \u2014 "),vX=n(URe,"A",{href:!0});var p8t=s(vX);mVo=r(p8t,"MobileBertForSequenceClassification"),p8t.forEach(t),gVo=r(URe," (MobileBERT model)"),URe.forEach(t),hVo=i(q),Fv=n(q,"LI",{});var JRe=s(Fv);__e=n(JRe,"STRONG",{});var _8t=s(__e);pVo=r(_8t,"mpnet"),_8t.forEach(t),_Vo=r(JRe," \u2014 "),FX=n(JRe,"A",{href:!0});var u8t=s(FX);uVo=r(u8t,"MPNetForSequenceClassification"),u8t.forEach(t),bVo=r(JRe," (MPNet model)"),JRe.forEach(t),vVo=i(q),Tv=n(q,"LI",{});var YRe=s(Tv);u_e=n(YRe,"STRONG",{});var b8t=s(u_e);FVo=r(b8t,"mvp"),b8t.forEach(t),TVo=r(YRe," \u2014 "),TX=n(YRe,"A",{href:!0});var v8t=s(TX);MVo=r(v8t,"MvpForSequenceClassification"),v8t.forEach(t),EVo=r(YRe," (MVP model)"),YRe.forEach(t),CVo=i(q),Mv=n(q,"LI",{});var KRe=s(Mv);b_e=n(KRe,"STRONG",{});var F8t=s(b_e);wVo=r(F8t,"nezha"),F8t.forEach(t),AVo=r(KRe," \u2014 "),MX=n(KRe,"A",{href:!0});var T8t=s(MX);LVo=r(T8t,"NezhaForSequenceClassification"),T8t.forEach(t),yVo=r(KRe," (Nezha model)"),KRe.forEach(t),xVo=i(q),Ev=n(q,"LI",{});var ZRe=s(Ev);v_e=n(ZRe,"STRONG",{});var M8t=s(v_e);$Vo=r(M8t,"nystromformer"),M8t.forEach(t),kVo=r(ZRe," \u2014 "),EX=n(ZRe,"A",{href:!0});var E8t=s(EX);SVo=r(E8t,"NystromformerForSequenceClassification"),E8t.forEach(t),RVo=r(ZRe," (Nystr\xF6mformer model)"),ZRe.forEach(t),PVo=i(q),Cv=n(q,"LI",{});var ePe=s(Cv);F_e=n(ePe,"STRONG",{});var C8t=s(F_e);BVo=r(C8t,"openai-gpt"),C8t.forEach(t),IVo=r(ePe," \u2014 "),CX=n(ePe,"A",{href:!0});var w8t=s(CX);NVo=r(w8t,"OpenAIGPTForSequenceClassification"),w8t.forEach(t),qVo=r(ePe," (OpenAI GPT model)"),ePe.forEach(t),jVo=i(q),wv=n(q,"LI",{});var oPe=s(wv);T_e=n(oPe,"STRONG",{});var A8t=s(T_e);DVo=r(A8t,"perceiver"),A8t.forEach(t),GVo=r(oPe," \u2014 "),wX=n(oPe,"A",{href:!0});var L8t=s(wX);OVo=r(L8t,"PerceiverForSequenceClassification"),L8t.forEach(t),VVo=r(oPe," (Perceiver model)"),oPe.forEach(t),XVo=i(q),Av=n(q,"LI",{});var rPe=s(Av);M_e=n(rPe,"STRONG",{});var y8t=s(M_e);zVo=r(y8t,"plbart"),y8t.forEach(t),QVo=r(rPe," \u2014 "),AX=n(rPe,"A",{href:!0});var x8t=s(AX);WVo=r(x8t,"PLBartForSequenceClassification"),x8t.forEach(t),HVo=r(rPe," (PLBart model)"),rPe.forEach(t),UVo=i(q),Lv=n(q,"LI",{});var tPe=s(Lv);E_e=n(tPe,"STRONG",{});var $8t=s(E_e);JVo=r($8t,"qdqbert"),$8t.forEach(t),YVo=r(tPe," \u2014 "),LX=n(tPe,"A",{href:!0});var k8t=s(LX);KVo=r(k8t,"QDQBertForSequenceClassification"),k8t.forEach(t),ZVo=r(tPe," (QDQBert model)"),tPe.forEach(t),eXo=i(q),yv=n(q,"LI",{});var aPe=s(yv);C_e=n(aPe,"STRONG",{});var S8t=s(C_e);oXo=r(S8t,"reformer"),S8t.forEach(t),rXo=r(aPe," \u2014 "),yX=n(aPe,"A",{href:!0});var R8t=s(yX);tXo=r(R8t,"ReformerForSequenceClassification"),R8t.forEach(t),aXo=r(aPe," (Reformer model)"),aPe.forEach(t),nXo=i(q),xv=n(q,"LI",{});var nPe=s(xv);w_e=n(nPe,"STRONG",{});var P8t=s(w_e);sXo=r(P8t,"rembert"),P8t.forEach(t),lXo=r(nPe," \u2014 "),xX=n(nPe,"A",{href:!0});var B8t=s(xX);iXo=r(B8t,"RemBertForSequenceClassification"),B8t.forEach(t),dXo=r(nPe," (RemBERT model)"),nPe.forEach(t),cXo=i(q),$v=n(q,"LI",{});var sPe=s($v);A_e=n(sPe,"STRONG",{});var I8t=s(A_e);fXo=r(I8t,"roberta"),I8t.forEach(t),mXo=r(sPe," \u2014 "),$X=n(sPe,"A",{href:!0});var N8t=s($X);gXo=r(N8t,"RobertaForSequenceClassification"),N8t.forEach(t),hXo=r(sPe," (RoBERTa model)"),sPe.forEach(t),pXo=i(q),kv=n(q,"LI",{});var lPe=s(kv);L_e=n(lPe,"STRONG",{});var q8t=s(L_e);_Xo=r(q8t,"roformer"),q8t.forEach(t),uXo=r(lPe," \u2014 "),kX=n(lPe,"A",{href:!0});var j8t=s(kX);bXo=r(j8t,"RoFormerForSequenceClassification"),j8t.forEach(t),vXo=r(lPe," (RoFormer model)"),lPe.forEach(t),FXo=i(q),Sv=n(q,"LI",{});var iPe=s(Sv);y_e=n(iPe,"STRONG",{});var D8t=s(y_e);TXo=r(D8t,"squeezebert"),D8t.forEach(t),MXo=r(iPe," \u2014 "),SX=n(iPe,"A",{href:!0});var G8t=s(SX);EXo=r(G8t,"SqueezeBertForSequenceClassification"),G8t.forEach(t),CXo=r(iPe," (SqueezeBERT model)"),iPe.forEach(t),wXo=i(q),Rv=n(q,"LI",{});var dPe=s(Rv);x_e=n(dPe,"STRONG",{});var O8t=s(x_e);AXo=r(O8t,"tapas"),O8t.forEach(t),LXo=r(dPe," \u2014 "),RX=n(dPe,"A",{href:!0});var V8t=s(RX);yXo=r(V8t,"TapasForSequenceClassification"),V8t.forEach(t),xXo=r(dPe," (TAPAS model)"),dPe.forEach(t),$Xo=i(q),Pv=n(q,"LI",{});var cPe=s(Pv);$_e=n(cPe,"STRONG",{});var X8t=s($_e);kXo=r(X8t,"transfo-xl"),X8t.forEach(t),SXo=r(cPe," \u2014 "),PX=n(cPe,"A",{href:!0});var z8t=s(PX);RXo=r(z8t,"TransfoXLForSequenceClassification"),z8t.forEach(t),PXo=r(cPe," (Transformer-XL model)"),cPe.forEach(t),BXo=i(q),Bv=n(q,"LI",{});var fPe=s(Bv);k_e=n(fPe,"STRONG",{});var Q8t=s(k_e);IXo=r(Q8t,"xlm"),Q8t.forEach(t),NXo=r(fPe," \u2014 "),BX=n(fPe,"A",{href:!0});var W8t=s(BX);qXo=r(W8t,"XLMForSequenceClassification"),W8t.forEach(t),jXo=r(fPe," (XLM model)"),fPe.forEach(t),DXo=i(q),Iv=n(q,"LI",{});var mPe=s(Iv);S_e=n(mPe,"STRONG",{});var H8t=s(S_e);GXo=r(H8t,"xlm-roberta"),H8t.forEach(t),OXo=r(mPe," \u2014 "),IX=n(mPe,"A",{href:!0});var U8t=s(IX);VXo=r(U8t,"XLMRobertaForSequenceClassification"),U8t.forEach(t),XXo=r(mPe," (XLM-RoBERTa model)"),mPe.forEach(t),zXo=i(q),Nv=n(q,"LI",{});var gPe=s(Nv);R_e=n(gPe,"STRONG",{});var J8t=s(R_e);QXo=r(J8t,"xlm-roberta-xl"),J8t.forEach(t),WXo=r(gPe," \u2014 "),NX=n(gPe,"A",{href:!0});var Y8t=s(NX);HXo=r(Y8t,"XLMRobertaXLForSequenceClassification"),Y8t.forEach(t),UXo=r(gPe," (XLM-RoBERTa-XL model)"),gPe.forEach(t),JXo=i(q),qv=n(q,"LI",{});var hPe=s(qv);P_e=n(hPe,"STRONG",{});var K8t=s(P_e);YXo=r(K8t,"xlnet"),K8t.forEach(t),KXo=r(hPe," \u2014 "),qX=n(hPe,"A",{href:!0});var Z8t=s(qX);ZXo=r(Z8t,"XLNetForSequenceClassification"),Z8t.forEach(t),ezo=r(hPe," (XLNet model)"),hPe.forEach(t),ozo=i(q),jv=n(q,"LI",{});var pPe=s(jv);B_e=n(pPe,"STRONG",{});var eMt=s(B_e);rzo=r(eMt,"yoso"),eMt.forEach(t),tzo=r(pPe," \u2014 "),jX=n(pPe,"A",{href:!0});var oMt=s(jX);azo=r(oMt,"YosoForSequenceClassification"),oMt.forEach(t),nzo=r(pPe," (YOSO model)"),pPe.forEach(t),q.forEach(t),szo=i(fa),Dv=n(fa,"P",{});var _Pe=s(Dv);lzo=r(_Pe,"The model is set in evaluation mode by default using "),I_e=n(_Pe,"CODE",{});var rMt=s(I_e);izo=r(rMt,"model.eval()"),rMt.forEach(t),dzo=r(_Pe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),N_e=n(_Pe,"CODE",{});var tMt=s(N_e);czo=r(tMt,"model.train()"),tMt.forEach(t),_Pe.forEach(t),fzo=i(fa),T(Gv.$$.fragment,fa),fa.forEach(t),nl.forEach(t),dXe=i(f),ad=n(f,"H2",{class:!0});var pQe=s(ad);Ov=n(pQe,"A",{id:!0,class:!0,href:!0});var aMt=s(Ov);q_e=n(aMt,"SPAN",{});var nMt=s(q_e);T(ty.$$.fragment,nMt),nMt.forEach(t),aMt.forEach(t),mzo=i(pQe),j_e=n(pQe,"SPAN",{});var sMt=s(j_e);gzo=r(sMt,"AutoModelForMultipleChoice"),sMt.forEach(t),pQe.forEach(t),cXe=i(f),Bo=n(f,"DIV",{class:!0});var sl=s(Bo);T(ay.$$.fragment,sl),hzo=i(sl),nd=n(sl,"P",{});var Bre=s(nd);pzo=r(Bre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),DX=n(Bre,"A",{href:!0});var lMt=s(DX);_zo=r(lMt,"from_pretrained()"),lMt.forEach(t),uzo=r(Bre," class method or the "),GX=n(Bre,"A",{href:!0});var iMt=s(GX);bzo=r(iMt,"from_config()"),iMt.forEach(t),vzo=r(Bre,` class
method.`),Bre.forEach(t),Fzo=i(sl),ny=n(sl,"P",{});var _Qe=s(ny);Tzo=r(_Qe,"This class cannot be instantiated directly using "),D_e=n(_Qe,"CODE",{});var dMt=s(D_e);Mzo=r(dMt,"__init__()"),dMt.forEach(t),Ezo=r(_Qe," (throws an error)."),_Qe.forEach(t),Czo=i(sl),gt=n(sl,"DIV",{class:!0});var uA=s(gt);T(sy.$$.fragment,uA),wzo=i(uA),G_e=n(uA,"P",{});var cMt=s(G_e);Azo=r(cMt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),cMt.forEach(t),Lzo=i(uA),sd=n(uA,"P",{});var Ire=s(sd);yzo=r(Ire,`Note:
Loading a model from its configuration file does `),O_e=n(Ire,"STRONG",{});var fMt=s(O_e);xzo=r(fMt,"not"),fMt.forEach(t),$zo=r(Ire,` load the model weights. It only affects the
model\u2019s configuration. Use `),OX=n(Ire,"A",{href:!0});var mMt=s(OX);kzo=r(mMt,"from_pretrained()"),mMt.forEach(t),Szo=r(Ire," to load the model weights."),Ire.forEach(t),Rzo=i(uA),T(Vv.$$.fragment,uA),uA.forEach(t),Pzo=i(sl),ro=n(sl,"DIV",{class:!0});var ma=s(ro);T(ly.$$.fragment,ma),Bzo=i(ma),V_e=n(ma,"P",{});var gMt=s(V_e);Izo=r(gMt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),gMt.forEach(t),Nzo=i(ma),Ga=n(ma,"P",{});var bA=s(Ga);qzo=r(bA,"The model class to instantiate is selected based on the "),X_e=n(bA,"CODE",{});var hMt=s(X_e);jzo=r(hMt,"model_type"),hMt.forEach(t),Dzo=r(bA,` property of the config object (either
passed as an argument or loaded from `),z_e=n(bA,"CODE",{});var pMt=s(z_e);Gzo=r(pMt,"pretrained_model_name_or_path"),pMt.forEach(t),Ozo=r(bA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q_e=n(bA,"CODE",{});var _Mt=s(Q_e);Vzo=r(_Mt,"pretrained_model_name_or_path"),_Mt.forEach(t),Xzo=r(bA,":"),bA.forEach(t),zzo=i(ma),Z=n(ma,"UL",{});var ee=s(Z);Xv=n(ee,"LI",{});var uPe=s(Xv);W_e=n(uPe,"STRONG",{});var uMt=s(W_e);Qzo=r(uMt,"albert"),uMt.forEach(t),Wzo=r(uPe," \u2014 "),VX=n(uPe,"A",{href:!0});var bMt=s(VX);Hzo=r(bMt,"AlbertForMultipleChoice"),bMt.forEach(t),Uzo=r(uPe," (ALBERT model)"),uPe.forEach(t),Jzo=i(ee),zv=n(ee,"LI",{});var bPe=s(zv);H_e=n(bPe,"STRONG",{});var vMt=s(H_e);Yzo=r(vMt,"bert"),vMt.forEach(t),Kzo=r(bPe," \u2014 "),XX=n(bPe,"A",{href:!0});var FMt=s(XX);Zzo=r(FMt,"BertForMultipleChoice"),FMt.forEach(t),eQo=r(bPe," (BERT model)"),bPe.forEach(t),oQo=i(ee),Qv=n(ee,"LI",{});var vPe=s(Qv);U_e=n(vPe,"STRONG",{});var TMt=s(U_e);rQo=r(TMt,"big_bird"),TMt.forEach(t),tQo=r(vPe," \u2014 "),zX=n(vPe,"A",{href:!0});var MMt=s(zX);aQo=r(MMt,"BigBirdForMultipleChoice"),MMt.forEach(t),nQo=r(vPe," (BigBird model)"),vPe.forEach(t),sQo=i(ee),Wv=n(ee,"LI",{});var FPe=s(Wv);J_e=n(FPe,"STRONG",{});var EMt=s(J_e);lQo=r(EMt,"camembert"),EMt.forEach(t),iQo=r(FPe," \u2014 "),QX=n(FPe,"A",{href:!0});var CMt=s(QX);dQo=r(CMt,"CamembertForMultipleChoice"),CMt.forEach(t),cQo=r(FPe," (CamemBERT model)"),FPe.forEach(t),fQo=i(ee),Hv=n(ee,"LI",{});var TPe=s(Hv);Y_e=n(TPe,"STRONG",{});var wMt=s(Y_e);mQo=r(wMt,"canine"),wMt.forEach(t),gQo=r(TPe," \u2014 "),WX=n(TPe,"A",{href:!0});var AMt=s(WX);hQo=r(AMt,"CanineForMultipleChoice"),AMt.forEach(t),pQo=r(TPe," (CANINE model)"),TPe.forEach(t),_Qo=i(ee),Uv=n(ee,"LI",{});var MPe=s(Uv);K_e=n(MPe,"STRONG",{});var LMt=s(K_e);uQo=r(LMt,"convbert"),LMt.forEach(t),bQo=r(MPe," \u2014 "),HX=n(MPe,"A",{href:!0});var yMt=s(HX);vQo=r(yMt,"ConvBertForMultipleChoice"),yMt.forEach(t),FQo=r(MPe," (ConvBERT model)"),MPe.forEach(t),TQo=i(ee),Jv=n(ee,"LI",{});var EPe=s(Jv);Z_e=n(EPe,"STRONG",{});var xMt=s(Z_e);MQo=r(xMt,"data2vec-text"),xMt.forEach(t),EQo=r(EPe," \u2014 "),UX=n(EPe,"A",{href:!0});var $Mt=s(UX);CQo=r($Mt,"Data2VecTextForMultipleChoice"),$Mt.forEach(t),wQo=r(EPe," (Data2VecText model)"),EPe.forEach(t),AQo=i(ee),Yv=n(ee,"LI",{});var CPe=s(Yv);eue=n(CPe,"STRONG",{});var kMt=s(eue);LQo=r(kMt,"deberta-v2"),kMt.forEach(t),yQo=r(CPe," \u2014 "),JX=n(CPe,"A",{href:!0});var SMt=s(JX);xQo=r(SMt,"DebertaV2ForMultipleChoice"),SMt.forEach(t),$Qo=r(CPe," (DeBERTa-v2 model)"),CPe.forEach(t),kQo=i(ee),Kv=n(ee,"LI",{});var wPe=s(Kv);oue=n(wPe,"STRONG",{});var RMt=s(oue);SQo=r(RMt,"distilbert"),RMt.forEach(t),RQo=r(wPe," \u2014 "),YX=n(wPe,"A",{href:!0});var PMt=s(YX);PQo=r(PMt,"DistilBertForMultipleChoice"),PMt.forEach(t),BQo=r(wPe," (DistilBERT model)"),wPe.forEach(t),IQo=i(ee),Zv=n(ee,"LI",{});var APe=s(Zv);rue=n(APe,"STRONG",{});var BMt=s(rue);NQo=r(BMt,"electra"),BMt.forEach(t),qQo=r(APe," \u2014 "),KX=n(APe,"A",{href:!0});var IMt=s(KX);jQo=r(IMt,"ElectraForMultipleChoice"),IMt.forEach(t),DQo=r(APe," (ELECTRA model)"),APe.forEach(t),GQo=i(ee),eF=n(ee,"LI",{});var LPe=s(eF);tue=n(LPe,"STRONG",{});var NMt=s(tue);OQo=r(NMt,"flaubert"),NMt.forEach(t),VQo=r(LPe," \u2014 "),ZX=n(LPe,"A",{href:!0});var qMt=s(ZX);XQo=r(qMt,"FlaubertForMultipleChoice"),qMt.forEach(t),zQo=r(LPe," (FlauBERT model)"),LPe.forEach(t),QQo=i(ee),oF=n(ee,"LI",{});var yPe=s(oF);aue=n(yPe,"STRONG",{});var jMt=s(aue);WQo=r(jMt,"fnet"),jMt.forEach(t),HQo=r(yPe," \u2014 "),ez=n(yPe,"A",{href:!0});var DMt=s(ez);UQo=r(DMt,"FNetForMultipleChoice"),DMt.forEach(t),JQo=r(yPe," (FNet model)"),yPe.forEach(t),YQo=i(ee),rF=n(ee,"LI",{});var xPe=s(rF);nue=n(xPe,"STRONG",{});var GMt=s(nue);KQo=r(GMt,"funnel"),GMt.forEach(t),ZQo=r(xPe," \u2014 "),oz=n(xPe,"A",{href:!0});var OMt=s(oz);eWo=r(OMt,"FunnelForMultipleChoice"),OMt.forEach(t),oWo=r(xPe," (Funnel Transformer model)"),xPe.forEach(t),rWo=i(ee),tF=n(ee,"LI",{});var $Pe=s(tF);sue=n($Pe,"STRONG",{});var VMt=s(sue);tWo=r(VMt,"ibert"),VMt.forEach(t),aWo=r($Pe," \u2014 "),rz=n($Pe,"A",{href:!0});var XMt=s(rz);nWo=r(XMt,"IBertForMultipleChoice"),XMt.forEach(t),sWo=r($Pe," (I-BERT model)"),$Pe.forEach(t),lWo=i(ee),aF=n(ee,"LI",{});var kPe=s(aF);lue=n(kPe,"STRONG",{});var zMt=s(lue);iWo=r(zMt,"longformer"),zMt.forEach(t),dWo=r(kPe," \u2014 "),tz=n(kPe,"A",{href:!0});var QMt=s(tz);cWo=r(QMt,"LongformerForMultipleChoice"),QMt.forEach(t),fWo=r(kPe," (Longformer model)"),kPe.forEach(t),mWo=i(ee),nF=n(ee,"LI",{});var SPe=s(nF);iue=n(SPe,"STRONG",{});var WMt=s(iue);gWo=r(WMt,"megatron-bert"),WMt.forEach(t),hWo=r(SPe," \u2014 "),az=n(SPe,"A",{href:!0});var HMt=s(az);pWo=r(HMt,"MegatronBertForMultipleChoice"),HMt.forEach(t),_Wo=r(SPe," (Megatron-BERT model)"),SPe.forEach(t),uWo=i(ee),sF=n(ee,"LI",{});var RPe=s(sF);due=n(RPe,"STRONG",{});var UMt=s(due);bWo=r(UMt,"mobilebert"),UMt.forEach(t),vWo=r(RPe," \u2014 "),nz=n(RPe,"A",{href:!0});var JMt=s(nz);FWo=r(JMt,"MobileBertForMultipleChoice"),JMt.forEach(t),TWo=r(RPe," (MobileBERT model)"),RPe.forEach(t),MWo=i(ee),lF=n(ee,"LI",{});var PPe=s(lF);cue=n(PPe,"STRONG",{});var YMt=s(cue);EWo=r(YMt,"mpnet"),YMt.forEach(t),CWo=r(PPe," \u2014 "),sz=n(PPe,"A",{href:!0});var KMt=s(sz);wWo=r(KMt,"MPNetForMultipleChoice"),KMt.forEach(t),AWo=r(PPe," (MPNet model)"),PPe.forEach(t),LWo=i(ee),iF=n(ee,"LI",{});var BPe=s(iF);fue=n(BPe,"STRONG",{});var ZMt=s(fue);yWo=r(ZMt,"nezha"),ZMt.forEach(t),xWo=r(BPe," \u2014 "),lz=n(BPe,"A",{href:!0});var e4t=s(lz);$Wo=r(e4t,"NezhaForMultipleChoice"),e4t.forEach(t),kWo=r(BPe," (Nezha model)"),BPe.forEach(t),SWo=i(ee),dF=n(ee,"LI",{});var IPe=s(dF);mue=n(IPe,"STRONG",{});var o4t=s(mue);RWo=r(o4t,"nystromformer"),o4t.forEach(t),PWo=r(IPe," \u2014 "),iz=n(IPe,"A",{href:!0});var r4t=s(iz);BWo=r(r4t,"NystromformerForMultipleChoice"),r4t.forEach(t),IWo=r(IPe," (Nystr\xF6mformer model)"),IPe.forEach(t),NWo=i(ee),cF=n(ee,"LI",{});var NPe=s(cF);gue=n(NPe,"STRONG",{});var t4t=s(gue);qWo=r(t4t,"qdqbert"),t4t.forEach(t),jWo=r(NPe," \u2014 "),dz=n(NPe,"A",{href:!0});var a4t=s(dz);DWo=r(a4t,"QDQBertForMultipleChoice"),a4t.forEach(t),GWo=r(NPe," (QDQBert model)"),NPe.forEach(t),OWo=i(ee),fF=n(ee,"LI",{});var qPe=s(fF);hue=n(qPe,"STRONG",{});var n4t=s(hue);VWo=r(n4t,"rembert"),n4t.forEach(t),XWo=r(qPe," \u2014 "),cz=n(qPe,"A",{href:!0});var s4t=s(cz);zWo=r(s4t,"RemBertForMultipleChoice"),s4t.forEach(t),QWo=r(qPe," (RemBERT model)"),qPe.forEach(t),WWo=i(ee),mF=n(ee,"LI",{});var jPe=s(mF);pue=n(jPe,"STRONG",{});var l4t=s(pue);HWo=r(l4t,"roberta"),l4t.forEach(t),UWo=r(jPe," \u2014 "),fz=n(jPe,"A",{href:!0});var i4t=s(fz);JWo=r(i4t,"RobertaForMultipleChoice"),i4t.forEach(t),YWo=r(jPe," (RoBERTa model)"),jPe.forEach(t),KWo=i(ee),gF=n(ee,"LI",{});var DPe=s(gF);_ue=n(DPe,"STRONG",{});var d4t=s(_ue);ZWo=r(d4t,"roformer"),d4t.forEach(t),eHo=r(DPe," \u2014 "),mz=n(DPe,"A",{href:!0});var c4t=s(mz);oHo=r(c4t,"RoFormerForMultipleChoice"),c4t.forEach(t),rHo=r(DPe," (RoFormer model)"),DPe.forEach(t),tHo=i(ee),hF=n(ee,"LI",{});var GPe=s(hF);uue=n(GPe,"STRONG",{});var f4t=s(uue);aHo=r(f4t,"squeezebert"),f4t.forEach(t),nHo=r(GPe," \u2014 "),gz=n(GPe,"A",{href:!0});var m4t=s(gz);sHo=r(m4t,"SqueezeBertForMultipleChoice"),m4t.forEach(t),lHo=r(GPe," (SqueezeBERT model)"),GPe.forEach(t),iHo=i(ee),pF=n(ee,"LI",{});var OPe=s(pF);bue=n(OPe,"STRONG",{});var g4t=s(bue);dHo=r(g4t,"xlm"),g4t.forEach(t),cHo=r(OPe," \u2014 "),hz=n(OPe,"A",{href:!0});var h4t=s(hz);fHo=r(h4t,"XLMForMultipleChoice"),h4t.forEach(t),mHo=r(OPe," (XLM model)"),OPe.forEach(t),gHo=i(ee),_F=n(ee,"LI",{});var VPe=s(_F);vue=n(VPe,"STRONG",{});var p4t=s(vue);hHo=r(p4t,"xlm-roberta"),p4t.forEach(t),pHo=r(VPe," \u2014 "),pz=n(VPe,"A",{href:!0});var _4t=s(pz);_Ho=r(_4t,"XLMRobertaForMultipleChoice"),_4t.forEach(t),uHo=r(VPe," (XLM-RoBERTa model)"),VPe.forEach(t),bHo=i(ee),uF=n(ee,"LI",{});var XPe=s(uF);Fue=n(XPe,"STRONG",{});var u4t=s(Fue);vHo=r(u4t,"xlm-roberta-xl"),u4t.forEach(t),FHo=r(XPe," \u2014 "),_z=n(XPe,"A",{href:!0});var b4t=s(_z);THo=r(b4t,"XLMRobertaXLForMultipleChoice"),b4t.forEach(t),MHo=r(XPe," (XLM-RoBERTa-XL model)"),XPe.forEach(t),EHo=i(ee),bF=n(ee,"LI",{});var zPe=s(bF);Tue=n(zPe,"STRONG",{});var v4t=s(Tue);CHo=r(v4t,"xlnet"),v4t.forEach(t),wHo=r(zPe," \u2014 "),uz=n(zPe,"A",{href:!0});var F4t=s(uz);AHo=r(F4t,"XLNetForMultipleChoice"),F4t.forEach(t),LHo=r(zPe," (XLNet model)"),zPe.forEach(t),yHo=i(ee),vF=n(ee,"LI",{});var QPe=s(vF);Mue=n(QPe,"STRONG",{});var T4t=s(Mue);xHo=r(T4t,"yoso"),T4t.forEach(t),$Ho=r(QPe," \u2014 "),bz=n(QPe,"A",{href:!0});var M4t=s(bz);kHo=r(M4t,"YosoForMultipleChoice"),M4t.forEach(t),SHo=r(QPe," (YOSO model)"),QPe.forEach(t),ee.forEach(t),RHo=i(ma),FF=n(ma,"P",{});var WPe=s(FF);PHo=r(WPe,"The model is set in evaluation mode by default using "),Eue=n(WPe,"CODE",{});var E4t=s(Eue);BHo=r(E4t,"model.eval()"),E4t.forEach(t),IHo=r(WPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cue=n(WPe,"CODE",{});var C4t=s(Cue);NHo=r(C4t,"model.train()"),C4t.forEach(t),WPe.forEach(t),qHo=i(ma),T(TF.$$.fragment,ma),ma.forEach(t),sl.forEach(t),fXe=i(f),ld=n(f,"H2",{class:!0});var uQe=s(ld);MF=n(uQe,"A",{id:!0,class:!0,href:!0});var w4t=s(MF);wue=n(w4t,"SPAN",{});var A4t=s(wue);T(iy.$$.fragment,A4t),A4t.forEach(t),w4t.forEach(t),jHo=i(uQe),Aue=n(uQe,"SPAN",{});var L4t=s(Aue);DHo=r(L4t,"AutoModelForNextSentencePrediction"),L4t.forEach(t),uQe.forEach(t),mXe=i(f),Io=n(f,"DIV",{class:!0});var ll=s(Io);T(dy.$$.fragment,ll),GHo=i(ll),id=n(ll,"P",{});var Nre=s(id);OHo=r(Nre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),vz=n(Nre,"A",{href:!0});var y4t=s(vz);VHo=r(y4t,"from_pretrained()"),y4t.forEach(t),XHo=r(Nre," class method or the "),Fz=n(Nre,"A",{href:!0});var x4t=s(Fz);zHo=r(x4t,"from_config()"),x4t.forEach(t),QHo=r(Nre,` class
method.`),Nre.forEach(t),WHo=i(ll),cy=n(ll,"P",{});var bQe=s(cy);HHo=r(bQe,"This class cannot be instantiated directly using "),Lue=n(bQe,"CODE",{});var $4t=s(Lue);UHo=r($4t,"__init__()"),$4t.forEach(t),JHo=r(bQe," (throws an error)."),bQe.forEach(t),YHo=i(ll),ht=n(ll,"DIV",{class:!0});var vA=s(ht);T(fy.$$.fragment,vA),KHo=i(vA),yue=n(vA,"P",{});var k4t=s(yue);ZHo=r(k4t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),k4t.forEach(t),eUo=i(vA),dd=n(vA,"P",{});var qre=s(dd);oUo=r(qre,`Note:
Loading a model from its configuration file does `),xue=n(qre,"STRONG",{});var S4t=s(xue);rUo=r(S4t,"not"),S4t.forEach(t),tUo=r(qre,` load the model weights. It only affects the
model\u2019s configuration. Use `),Tz=n(qre,"A",{href:!0});var R4t=s(Tz);aUo=r(R4t,"from_pretrained()"),R4t.forEach(t),nUo=r(qre," to load the model weights."),qre.forEach(t),sUo=i(vA),T(EF.$$.fragment,vA),vA.forEach(t),lUo=i(ll),to=n(ll,"DIV",{class:!0});var ga=s(to);T(my.$$.fragment,ga),iUo=i(ga),$ue=n(ga,"P",{});var P4t=s($ue);dUo=r(P4t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),P4t.forEach(t),cUo=i(ga),Oa=n(ga,"P",{});var FA=s(Oa);fUo=r(FA,"The model class to instantiate is selected based on the "),kue=n(FA,"CODE",{});var B4t=s(kue);mUo=r(B4t,"model_type"),B4t.forEach(t),gUo=r(FA,` property of the config object (either
passed as an argument or loaded from `),Sue=n(FA,"CODE",{});var I4t=s(Sue);hUo=r(I4t,"pretrained_model_name_or_path"),I4t.forEach(t),pUo=r(FA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rue=n(FA,"CODE",{});var N4t=s(Rue);_Uo=r(N4t,"pretrained_model_name_or_path"),N4t.forEach(t),uUo=r(FA,":"),FA.forEach(t),bUo=i(ga),No=n(ga,"UL",{});var ha=s(No);CF=n(ha,"LI",{});var HPe=s(CF);Pue=n(HPe,"STRONG",{});var q4t=s(Pue);vUo=r(q4t,"bert"),q4t.forEach(t),FUo=r(HPe," \u2014 "),Mz=n(HPe,"A",{href:!0});var j4t=s(Mz);TUo=r(j4t,"BertForNextSentencePrediction"),j4t.forEach(t),MUo=r(HPe," (BERT model)"),HPe.forEach(t),EUo=i(ha),wF=n(ha,"LI",{});var UPe=s(wF);Bue=n(UPe,"STRONG",{});var D4t=s(Bue);CUo=r(D4t,"fnet"),D4t.forEach(t),wUo=r(UPe," \u2014 "),Ez=n(UPe,"A",{href:!0});var G4t=s(Ez);AUo=r(G4t,"FNetForNextSentencePrediction"),G4t.forEach(t),LUo=r(UPe," (FNet model)"),UPe.forEach(t),yUo=i(ha),AF=n(ha,"LI",{});var JPe=s(AF);Iue=n(JPe,"STRONG",{});var O4t=s(Iue);xUo=r(O4t,"megatron-bert"),O4t.forEach(t),$Uo=r(JPe," \u2014 "),Cz=n(JPe,"A",{href:!0});var V4t=s(Cz);kUo=r(V4t,"MegatronBertForNextSentencePrediction"),V4t.forEach(t),SUo=r(JPe," (Megatron-BERT model)"),JPe.forEach(t),RUo=i(ha),LF=n(ha,"LI",{});var YPe=s(LF);Nue=n(YPe,"STRONG",{});var X4t=s(Nue);PUo=r(X4t,"mobilebert"),X4t.forEach(t),BUo=r(YPe," \u2014 "),wz=n(YPe,"A",{href:!0});var z4t=s(wz);IUo=r(z4t,"MobileBertForNextSentencePrediction"),z4t.forEach(t),NUo=r(YPe," (MobileBERT model)"),YPe.forEach(t),qUo=i(ha),yF=n(ha,"LI",{});var KPe=s(yF);que=n(KPe,"STRONG",{});var Q4t=s(que);jUo=r(Q4t,"nezha"),Q4t.forEach(t),DUo=r(KPe," \u2014 "),Az=n(KPe,"A",{href:!0});var W4t=s(Az);GUo=r(W4t,"NezhaForNextSentencePrediction"),W4t.forEach(t),OUo=r(KPe," (Nezha model)"),KPe.forEach(t),VUo=i(ha),xF=n(ha,"LI",{});var ZPe=s(xF);jue=n(ZPe,"STRONG",{});var H4t=s(jue);XUo=r(H4t,"qdqbert"),H4t.forEach(t),zUo=r(ZPe," \u2014 "),Lz=n(ZPe,"A",{href:!0});var U4t=s(Lz);QUo=r(U4t,"QDQBertForNextSentencePrediction"),U4t.forEach(t),WUo=r(ZPe," (QDQBert model)"),ZPe.forEach(t),ha.forEach(t),HUo=i(ga),$F=n(ga,"P",{});var eBe=s($F);UUo=r(eBe,"The model is set in evaluation mode by default using "),Due=n(eBe,"CODE",{});var J4t=s(Due);JUo=r(J4t,"model.eval()"),J4t.forEach(t),YUo=r(eBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gue=n(eBe,"CODE",{});var Y4t=s(Gue);KUo=r(Y4t,"model.train()"),Y4t.forEach(t),eBe.forEach(t),ZUo=i(ga),T(kF.$$.fragment,ga),ga.forEach(t),ll.forEach(t),gXe=i(f),cd=n(f,"H2",{class:!0});var vQe=s(cd);SF=n(vQe,"A",{id:!0,class:!0,href:!0});var K4t=s(SF);Oue=n(K4t,"SPAN",{});var Z4t=s(Oue);T(gy.$$.fragment,Z4t),Z4t.forEach(t),K4t.forEach(t),eJo=i(vQe),Vue=n(vQe,"SPAN",{});var eEt=s(Vue);oJo=r(eEt,"AutoModelForTokenClassification"),eEt.forEach(t),vQe.forEach(t),hXe=i(f),qo=n(f,"DIV",{class:!0});var il=s(qo);T(hy.$$.fragment,il),rJo=i(il),fd=n(il,"P",{});var jre=s(fd);tJo=r(jre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),yz=n(jre,"A",{href:!0});var oEt=s(yz);aJo=r(oEt,"from_pretrained()"),oEt.forEach(t),nJo=r(jre," class method or the "),xz=n(jre,"A",{href:!0});var rEt=s(xz);sJo=r(rEt,"from_config()"),rEt.forEach(t),lJo=r(jre,` class
method.`),jre.forEach(t),iJo=i(il),py=n(il,"P",{});var FQe=s(py);dJo=r(FQe,"This class cannot be instantiated directly using "),Xue=n(FQe,"CODE",{});var tEt=s(Xue);cJo=r(tEt,"__init__()"),tEt.forEach(t),fJo=r(FQe," (throws an error)."),FQe.forEach(t),mJo=i(il),pt=n(il,"DIV",{class:!0});var TA=s(pt);T(_y.$$.fragment,TA),gJo=i(TA),zue=n(TA,"P",{});var aEt=s(zue);hJo=r(aEt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),aEt.forEach(t),pJo=i(TA),md=n(TA,"P",{});var Dre=s(md);_Jo=r(Dre,`Note:
Loading a model from its configuration file does `),Que=n(Dre,"STRONG",{});var nEt=s(Que);uJo=r(nEt,"not"),nEt.forEach(t),bJo=r(Dre,` load the model weights. It only affects the
model\u2019s configuration. Use `),$z=n(Dre,"A",{href:!0});var sEt=s($z);vJo=r(sEt,"from_pretrained()"),sEt.forEach(t),FJo=r(Dre," to load the model weights."),Dre.forEach(t),TJo=i(TA),T(RF.$$.fragment,TA),TA.forEach(t),MJo=i(il),ao=n(il,"DIV",{class:!0});var pa=s(ao);T(uy.$$.fragment,pa),EJo=i(pa),Wue=n(pa,"P",{});var lEt=s(Wue);CJo=r(lEt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),lEt.forEach(t),wJo=i(pa),Va=n(pa,"P",{});var MA=s(Va);AJo=r(MA,"The model class to instantiate is selected based on the "),Hue=n(MA,"CODE",{});var iEt=s(Hue);LJo=r(iEt,"model_type"),iEt.forEach(t),yJo=r(MA,` property of the config object (either
passed as an argument or loaded from `),Uue=n(MA,"CODE",{});var dEt=s(Uue);xJo=r(dEt,"pretrained_model_name_or_path"),dEt.forEach(t),$Jo=r(MA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jue=n(MA,"CODE",{});var cEt=s(Jue);kJo=r(cEt,"pretrained_model_name_or_path"),cEt.forEach(t),SJo=r(MA,":"),MA.forEach(t),RJo=i(pa),U=n(pa,"UL",{});var J=s(U);PF=n(J,"LI",{});var oBe=s(PF);Yue=n(oBe,"STRONG",{});var fEt=s(Yue);PJo=r(fEt,"albert"),fEt.forEach(t),BJo=r(oBe," \u2014 "),kz=n(oBe,"A",{href:!0});var mEt=s(kz);IJo=r(mEt,"AlbertForTokenClassification"),mEt.forEach(t),NJo=r(oBe," (ALBERT model)"),oBe.forEach(t),qJo=i(J),BF=n(J,"LI",{});var rBe=s(BF);Kue=n(rBe,"STRONG",{});var gEt=s(Kue);jJo=r(gEt,"bert"),gEt.forEach(t),DJo=r(rBe," \u2014 "),Sz=n(rBe,"A",{href:!0});var hEt=s(Sz);GJo=r(hEt,"BertForTokenClassification"),hEt.forEach(t),OJo=r(rBe," (BERT model)"),rBe.forEach(t),VJo=i(J),IF=n(J,"LI",{});var tBe=s(IF);Zue=n(tBe,"STRONG",{});var pEt=s(Zue);XJo=r(pEt,"big_bird"),pEt.forEach(t),zJo=r(tBe," \u2014 "),Rz=n(tBe,"A",{href:!0});var _Et=s(Rz);QJo=r(_Et,"BigBirdForTokenClassification"),_Et.forEach(t),WJo=r(tBe," (BigBird model)"),tBe.forEach(t),HJo=i(J),NF=n(J,"LI",{});var aBe=s(NF);e1e=n(aBe,"STRONG",{});var uEt=s(e1e);UJo=r(uEt,"bloom"),uEt.forEach(t),JJo=r(aBe," \u2014 "),Pz=n(aBe,"A",{href:!0});var bEt=s(Pz);YJo=r(bEt,"BloomForTokenClassification"),bEt.forEach(t),KJo=r(aBe," (BLOOM model)"),aBe.forEach(t),ZJo=i(J),qF=n(J,"LI",{});var nBe=s(qF);o1e=n(nBe,"STRONG",{});var vEt=s(o1e);eYo=r(vEt,"camembert"),vEt.forEach(t),oYo=r(nBe," \u2014 "),Bz=n(nBe,"A",{href:!0});var FEt=s(Bz);rYo=r(FEt,"CamembertForTokenClassification"),FEt.forEach(t),tYo=r(nBe," (CamemBERT model)"),nBe.forEach(t),aYo=i(J),jF=n(J,"LI",{});var sBe=s(jF);r1e=n(sBe,"STRONG",{});var TEt=s(r1e);nYo=r(TEt,"canine"),TEt.forEach(t),sYo=r(sBe," \u2014 "),Iz=n(sBe,"A",{href:!0});var MEt=s(Iz);lYo=r(MEt,"CanineForTokenClassification"),MEt.forEach(t),iYo=r(sBe," (CANINE model)"),sBe.forEach(t),dYo=i(J),DF=n(J,"LI",{});var lBe=s(DF);t1e=n(lBe,"STRONG",{});var EEt=s(t1e);cYo=r(EEt,"convbert"),EEt.forEach(t),fYo=r(lBe," \u2014 "),Nz=n(lBe,"A",{href:!0});var CEt=s(Nz);mYo=r(CEt,"ConvBertForTokenClassification"),CEt.forEach(t),gYo=r(lBe," (ConvBERT model)"),lBe.forEach(t),hYo=i(J),GF=n(J,"LI",{});var iBe=s(GF);a1e=n(iBe,"STRONG",{});var wEt=s(a1e);pYo=r(wEt,"data2vec-text"),wEt.forEach(t),_Yo=r(iBe," \u2014 "),qz=n(iBe,"A",{href:!0});var AEt=s(qz);uYo=r(AEt,"Data2VecTextForTokenClassification"),AEt.forEach(t),bYo=r(iBe," (Data2VecText model)"),iBe.forEach(t),vYo=i(J),OF=n(J,"LI",{});var dBe=s(OF);n1e=n(dBe,"STRONG",{});var LEt=s(n1e);FYo=r(LEt,"deberta"),LEt.forEach(t),TYo=r(dBe," \u2014 "),jz=n(dBe,"A",{href:!0});var yEt=s(jz);MYo=r(yEt,"DebertaForTokenClassification"),yEt.forEach(t),EYo=r(dBe," (DeBERTa model)"),dBe.forEach(t),CYo=i(J),VF=n(J,"LI",{});var cBe=s(VF);s1e=n(cBe,"STRONG",{});var xEt=s(s1e);wYo=r(xEt,"deberta-v2"),xEt.forEach(t),AYo=r(cBe," \u2014 "),Dz=n(cBe,"A",{href:!0});var $Et=s(Dz);LYo=r($Et,"DebertaV2ForTokenClassification"),$Et.forEach(t),yYo=r(cBe," (DeBERTa-v2 model)"),cBe.forEach(t),xYo=i(J),XF=n(J,"LI",{});var fBe=s(XF);l1e=n(fBe,"STRONG",{});var kEt=s(l1e);$Yo=r(kEt,"distilbert"),kEt.forEach(t),kYo=r(fBe," \u2014 "),Gz=n(fBe,"A",{href:!0});var SEt=s(Gz);SYo=r(SEt,"DistilBertForTokenClassification"),SEt.forEach(t),RYo=r(fBe," (DistilBERT model)"),fBe.forEach(t),PYo=i(J),zF=n(J,"LI",{});var mBe=s(zF);i1e=n(mBe,"STRONG",{});var REt=s(i1e);BYo=r(REt,"electra"),REt.forEach(t),IYo=r(mBe," \u2014 "),Oz=n(mBe,"A",{href:!0});var PEt=s(Oz);NYo=r(PEt,"ElectraForTokenClassification"),PEt.forEach(t),qYo=r(mBe," (ELECTRA model)"),mBe.forEach(t),jYo=i(J),QF=n(J,"LI",{});var gBe=s(QF);d1e=n(gBe,"STRONG",{});var BEt=s(d1e);DYo=r(BEt,"flaubert"),BEt.forEach(t),GYo=r(gBe," \u2014 "),Vz=n(gBe,"A",{href:!0});var IEt=s(Vz);OYo=r(IEt,"FlaubertForTokenClassification"),IEt.forEach(t),VYo=r(gBe," (FlauBERT model)"),gBe.forEach(t),XYo=i(J),WF=n(J,"LI",{});var hBe=s(WF);c1e=n(hBe,"STRONG",{});var NEt=s(c1e);zYo=r(NEt,"fnet"),NEt.forEach(t),QYo=r(hBe," \u2014 "),Xz=n(hBe,"A",{href:!0});var qEt=s(Xz);WYo=r(qEt,"FNetForTokenClassification"),qEt.forEach(t),HYo=r(hBe," (FNet model)"),hBe.forEach(t),UYo=i(J),HF=n(J,"LI",{});var pBe=s(HF);f1e=n(pBe,"STRONG",{});var jEt=s(f1e);JYo=r(jEt,"funnel"),jEt.forEach(t),YYo=r(pBe," \u2014 "),zz=n(pBe,"A",{href:!0});var DEt=s(zz);KYo=r(DEt,"FunnelForTokenClassification"),DEt.forEach(t),ZYo=r(pBe," (Funnel Transformer model)"),pBe.forEach(t),eKo=i(J),UF=n(J,"LI",{});var _Be=s(UF);m1e=n(_Be,"STRONG",{});var GEt=s(m1e);oKo=r(GEt,"gpt2"),GEt.forEach(t),rKo=r(_Be," \u2014 "),Qz=n(_Be,"A",{href:!0});var OEt=s(Qz);tKo=r(OEt,"GPT2ForTokenClassification"),OEt.forEach(t),aKo=r(_Be," (OpenAI GPT-2 model)"),_Be.forEach(t),nKo=i(J),JF=n(J,"LI",{});var uBe=s(JF);g1e=n(uBe,"STRONG",{});var VEt=s(g1e);sKo=r(VEt,"ibert"),VEt.forEach(t),lKo=r(uBe," \u2014 "),Wz=n(uBe,"A",{href:!0});var XEt=s(Wz);iKo=r(XEt,"IBertForTokenClassification"),XEt.forEach(t),dKo=r(uBe," (I-BERT model)"),uBe.forEach(t),cKo=i(J),YF=n(J,"LI",{});var bBe=s(YF);h1e=n(bBe,"STRONG",{});var zEt=s(h1e);fKo=r(zEt,"layoutlm"),zEt.forEach(t),mKo=r(bBe," \u2014 "),Hz=n(bBe,"A",{href:!0});var QEt=s(Hz);gKo=r(QEt,"LayoutLMForTokenClassification"),QEt.forEach(t),hKo=r(bBe," (LayoutLM model)"),bBe.forEach(t),pKo=i(J),KF=n(J,"LI",{});var vBe=s(KF);p1e=n(vBe,"STRONG",{});var WEt=s(p1e);_Ko=r(WEt,"layoutlmv2"),WEt.forEach(t),uKo=r(vBe," \u2014 "),Uz=n(vBe,"A",{href:!0});var HEt=s(Uz);bKo=r(HEt,"LayoutLMv2ForTokenClassification"),HEt.forEach(t),vKo=r(vBe," (LayoutLMv2 model)"),vBe.forEach(t),FKo=i(J),ZF=n(J,"LI",{});var FBe=s(ZF);_1e=n(FBe,"STRONG",{});var UEt=s(_1e);TKo=r(UEt,"layoutlmv3"),UEt.forEach(t),MKo=r(FBe," \u2014 "),Jz=n(FBe,"A",{href:!0});var JEt=s(Jz);EKo=r(JEt,"LayoutLMv3ForTokenClassification"),JEt.forEach(t),CKo=r(FBe," (LayoutLMv3 model)"),FBe.forEach(t),wKo=i(J),eT=n(J,"LI",{});var TBe=s(eT);u1e=n(TBe,"STRONG",{});var YEt=s(u1e);AKo=r(YEt,"longformer"),YEt.forEach(t),LKo=r(TBe," \u2014 "),Yz=n(TBe,"A",{href:!0});var KEt=s(Yz);yKo=r(KEt,"LongformerForTokenClassification"),KEt.forEach(t),xKo=r(TBe," (Longformer model)"),TBe.forEach(t),$Ko=i(J),oT=n(J,"LI",{});var MBe=s(oT);b1e=n(MBe,"STRONG",{});var ZEt=s(b1e);kKo=r(ZEt,"megatron-bert"),ZEt.forEach(t),SKo=r(MBe," \u2014 "),Kz=n(MBe,"A",{href:!0});var eCt=s(Kz);RKo=r(eCt,"MegatronBertForTokenClassification"),eCt.forEach(t),PKo=r(MBe," (Megatron-BERT model)"),MBe.forEach(t),BKo=i(J),rT=n(J,"LI",{});var EBe=s(rT);v1e=n(EBe,"STRONG",{});var oCt=s(v1e);IKo=r(oCt,"mobilebert"),oCt.forEach(t),NKo=r(EBe," \u2014 "),Zz=n(EBe,"A",{href:!0});var rCt=s(Zz);qKo=r(rCt,"MobileBertForTokenClassification"),rCt.forEach(t),jKo=r(EBe," (MobileBERT model)"),EBe.forEach(t),DKo=i(J),tT=n(J,"LI",{});var CBe=s(tT);F1e=n(CBe,"STRONG",{});var tCt=s(F1e);GKo=r(tCt,"mpnet"),tCt.forEach(t),OKo=r(CBe," \u2014 "),eQ=n(CBe,"A",{href:!0});var aCt=s(eQ);VKo=r(aCt,"MPNetForTokenClassification"),aCt.forEach(t),XKo=r(CBe," (MPNet model)"),CBe.forEach(t),zKo=i(J),aT=n(J,"LI",{});var wBe=s(aT);T1e=n(wBe,"STRONG",{});var nCt=s(T1e);QKo=r(nCt,"nezha"),nCt.forEach(t),WKo=r(wBe," \u2014 "),oQ=n(wBe,"A",{href:!0});var sCt=s(oQ);HKo=r(sCt,"NezhaForTokenClassification"),sCt.forEach(t),UKo=r(wBe," (Nezha model)"),wBe.forEach(t),JKo=i(J),nT=n(J,"LI",{});var ABe=s(nT);M1e=n(ABe,"STRONG",{});var lCt=s(M1e);YKo=r(lCt,"nystromformer"),lCt.forEach(t),KKo=r(ABe," \u2014 "),rQ=n(ABe,"A",{href:!0});var iCt=s(rQ);ZKo=r(iCt,"NystromformerForTokenClassification"),iCt.forEach(t),eZo=r(ABe," (Nystr\xF6mformer model)"),ABe.forEach(t),oZo=i(J),sT=n(J,"LI",{});var LBe=s(sT);E1e=n(LBe,"STRONG",{});var dCt=s(E1e);rZo=r(dCt,"qdqbert"),dCt.forEach(t),tZo=r(LBe," \u2014 "),tQ=n(LBe,"A",{href:!0});var cCt=s(tQ);aZo=r(cCt,"QDQBertForTokenClassification"),cCt.forEach(t),nZo=r(LBe," (QDQBert model)"),LBe.forEach(t),sZo=i(J),lT=n(J,"LI",{});var yBe=s(lT);C1e=n(yBe,"STRONG",{});var fCt=s(C1e);lZo=r(fCt,"rembert"),fCt.forEach(t),iZo=r(yBe," \u2014 "),aQ=n(yBe,"A",{href:!0});var mCt=s(aQ);dZo=r(mCt,"RemBertForTokenClassification"),mCt.forEach(t),cZo=r(yBe," (RemBERT model)"),yBe.forEach(t),fZo=i(J),iT=n(J,"LI",{});var xBe=s(iT);w1e=n(xBe,"STRONG",{});var gCt=s(w1e);mZo=r(gCt,"roberta"),gCt.forEach(t),gZo=r(xBe," \u2014 "),nQ=n(xBe,"A",{href:!0});var hCt=s(nQ);hZo=r(hCt,"RobertaForTokenClassification"),hCt.forEach(t),pZo=r(xBe," (RoBERTa model)"),xBe.forEach(t),_Zo=i(J),dT=n(J,"LI",{});var $Be=s(dT);A1e=n($Be,"STRONG",{});var pCt=s(A1e);uZo=r(pCt,"roformer"),pCt.forEach(t),bZo=r($Be," \u2014 "),sQ=n($Be,"A",{href:!0});var _Ct=s(sQ);vZo=r(_Ct,"RoFormerForTokenClassification"),_Ct.forEach(t),FZo=r($Be," (RoFormer model)"),$Be.forEach(t),TZo=i(J),cT=n(J,"LI",{});var kBe=s(cT);L1e=n(kBe,"STRONG",{});var uCt=s(L1e);MZo=r(uCt,"squeezebert"),uCt.forEach(t),EZo=r(kBe," \u2014 "),lQ=n(kBe,"A",{href:!0});var bCt=s(lQ);CZo=r(bCt,"SqueezeBertForTokenClassification"),bCt.forEach(t),wZo=r(kBe," (SqueezeBERT model)"),kBe.forEach(t),AZo=i(J),fT=n(J,"LI",{});var SBe=s(fT);y1e=n(SBe,"STRONG",{});var vCt=s(y1e);LZo=r(vCt,"xlm"),vCt.forEach(t),yZo=r(SBe," \u2014 "),iQ=n(SBe,"A",{href:!0});var FCt=s(iQ);xZo=r(FCt,"XLMForTokenClassification"),FCt.forEach(t),$Zo=r(SBe," (XLM model)"),SBe.forEach(t),kZo=i(J),mT=n(J,"LI",{});var RBe=s(mT);x1e=n(RBe,"STRONG",{});var TCt=s(x1e);SZo=r(TCt,"xlm-roberta"),TCt.forEach(t),RZo=r(RBe," \u2014 "),dQ=n(RBe,"A",{href:!0});var MCt=s(dQ);PZo=r(MCt,"XLMRobertaForTokenClassification"),MCt.forEach(t),BZo=r(RBe," (XLM-RoBERTa model)"),RBe.forEach(t),IZo=i(J),gT=n(J,"LI",{});var PBe=s(gT);$1e=n(PBe,"STRONG",{});var ECt=s($1e);NZo=r(ECt,"xlm-roberta-xl"),ECt.forEach(t),qZo=r(PBe," \u2014 "),cQ=n(PBe,"A",{href:!0});var CCt=s(cQ);jZo=r(CCt,"XLMRobertaXLForTokenClassification"),CCt.forEach(t),DZo=r(PBe," (XLM-RoBERTa-XL model)"),PBe.forEach(t),GZo=i(J),hT=n(J,"LI",{});var BBe=s(hT);k1e=n(BBe,"STRONG",{});var wCt=s(k1e);OZo=r(wCt,"xlnet"),wCt.forEach(t),VZo=r(BBe," \u2014 "),fQ=n(BBe,"A",{href:!0});var ACt=s(fQ);XZo=r(ACt,"XLNetForTokenClassification"),ACt.forEach(t),zZo=r(BBe," (XLNet model)"),BBe.forEach(t),QZo=i(J),pT=n(J,"LI",{});var IBe=s(pT);S1e=n(IBe,"STRONG",{});var LCt=s(S1e);WZo=r(LCt,"yoso"),LCt.forEach(t),HZo=r(IBe," \u2014 "),mQ=n(IBe,"A",{href:!0});var yCt=s(mQ);UZo=r(yCt,"YosoForTokenClassification"),yCt.forEach(t),JZo=r(IBe," (YOSO model)"),IBe.forEach(t),J.forEach(t),YZo=i(pa),_T=n(pa,"P",{});var NBe=s(_T);KZo=r(NBe,"The model is set in evaluation mode by default using "),R1e=n(NBe,"CODE",{});var xCt=s(R1e);ZZo=r(xCt,"model.eval()"),xCt.forEach(t),eer=r(NBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P1e=n(NBe,"CODE",{});var $Ct=s(P1e);oer=r($Ct,"model.train()"),$Ct.forEach(t),NBe.forEach(t),rer=i(pa),T(uT.$$.fragment,pa),pa.forEach(t),il.forEach(t),pXe=i(f),gd=n(f,"H2",{class:!0});var TQe=s(gd);bT=n(TQe,"A",{id:!0,class:!0,href:!0});var kCt=s(bT);B1e=n(kCt,"SPAN",{});var SCt=s(B1e);T(by.$$.fragment,SCt),SCt.forEach(t),kCt.forEach(t),ter=i(TQe),I1e=n(TQe,"SPAN",{});var RCt=s(I1e);aer=r(RCt,"AutoModelForQuestionAnswering"),RCt.forEach(t),TQe.forEach(t),_Xe=i(f),jo=n(f,"DIV",{class:!0});var dl=s(jo);T(vy.$$.fragment,dl),ner=i(dl),hd=n(dl,"P",{});var Gre=s(hd);ser=r(Gre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),gQ=n(Gre,"A",{href:!0});var PCt=s(gQ);ler=r(PCt,"from_pretrained()"),PCt.forEach(t),ier=r(Gre," class method or the "),hQ=n(Gre,"A",{href:!0});var BCt=s(hQ);der=r(BCt,"from_config()"),BCt.forEach(t),cer=r(Gre,` class
method.`),Gre.forEach(t),fer=i(dl),Fy=n(dl,"P",{});var MQe=s(Fy);mer=r(MQe,"This class cannot be instantiated directly using "),N1e=n(MQe,"CODE",{});var ICt=s(N1e);ger=r(ICt,"__init__()"),ICt.forEach(t),her=r(MQe," (throws an error)."),MQe.forEach(t),per=i(dl),_t=n(dl,"DIV",{class:!0});var EA=s(_t);T(Ty.$$.fragment,EA),_er=i(EA),q1e=n(EA,"P",{});var NCt=s(q1e);uer=r(NCt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),NCt.forEach(t),ber=i(EA),pd=n(EA,"P",{});var Ore=s(pd);ver=r(Ore,`Note:
Loading a model from its configuration file does `),j1e=n(Ore,"STRONG",{});var qCt=s(j1e);Fer=r(qCt,"not"),qCt.forEach(t),Ter=r(Ore,` load the model weights. It only affects the
model\u2019s configuration. Use `),pQ=n(Ore,"A",{href:!0});var jCt=s(pQ);Mer=r(jCt,"from_pretrained()"),jCt.forEach(t),Eer=r(Ore," to load the model weights."),Ore.forEach(t),Cer=i(EA),T(vT.$$.fragment,EA),EA.forEach(t),wer=i(dl),no=n(dl,"DIV",{class:!0});var _a=s(no);T(My.$$.fragment,_a),Aer=i(_a),D1e=n(_a,"P",{});var DCt=s(D1e);Ler=r(DCt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),DCt.forEach(t),yer=i(_a),Xa=n(_a,"P",{});var CA=s(Xa);xer=r(CA,"The model class to instantiate is selected based on the "),G1e=n(CA,"CODE",{});var GCt=s(G1e);$er=r(GCt,"model_type"),GCt.forEach(t),ker=r(CA,` property of the config object (either
passed as an argument or loaded from `),O1e=n(CA,"CODE",{});var OCt=s(O1e);Ser=r(OCt,"pretrained_model_name_or_path"),OCt.forEach(t),Rer=r(CA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V1e=n(CA,"CODE",{});var VCt=s(V1e);Per=r(VCt,"pretrained_model_name_or_path"),VCt.forEach(t),Ber=r(CA,":"),CA.forEach(t),Ier=i(_a),V=n(_a,"UL",{});var X=s(V);FT=n(X,"LI",{});var qBe=s(FT);X1e=n(qBe,"STRONG",{});var XCt=s(X1e);Ner=r(XCt,"albert"),XCt.forEach(t),qer=r(qBe," \u2014 "),_Q=n(qBe,"A",{href:!0});var zCt=s(_Q);jer=r(zCt,"AlbertForQuestionAnswering"),zCt.forEach(t),Der=r(qBe," (ALBERT model)"),qBe.forEach(t),Ger=i(X),TT=n(X,"LI",{});var jBe=s(TT);z1e=n(jBe,"STRONG",{});var QCt=s(z1e);Oer=r(QCt,"bart"),QCt.forEach(t),Ver=r(jBe," \u2014 "),uQ=n(jBe,"A",{href:!0});var WCt=s(uQ);Xer=r(WCt,"BartForQuestionAnswering"),WCt.forEach(t),zer=r(jBe," (BART model)"),jBe.forEach(t),Qer=i(X),MT=n(X,"LI",{});var DBe=s(MT);Q1e=n(DBe,"STRONG",{});var HCt=s(Q1e);Wer=r(HCt,"bert"),HCt.forEach(t),Her=r(DBe," \u2014 "),bQ=n(DBe,"A",{href:!0});var UCt=s(bQ);Uer=r(UCt,"BertForQuestionAnswering"),UCt.forEach(t),Jer=r(DBe," (BERT model)"),DBe.forEach(t),Yer=i(X),ET=n(X,"LI",{});var GBe=s(ET);W1e=n(GBe,"STRONG",{});var JCt=s(W1e);Ker=r(JCt,"big_bird"),JCt.forEach(t),Zer=r(GBe," \u2014 "),vQ=n(GBe,"A",{href:!0});var YCt=s(vQ);eor=r(YCt,"BigBirdForQuestionAnswering"),YCt.forEach(t),oor=r(GBe," (BigBird model)"),GBe.forEach(t),ror=i(X),CT=n(X,"LI",{});var OBe=s(CT);H1e=n(OBe,"STRONG",{});var KCt=s(H1e);tor=r(KCt,"bigbird_pegasus"),KCt.forEach(t),aor=r(OBe," \u2014 "),FQ=n(OBe,"A",{href:!0});var ZCt=s(FQ);nor=r(ZCt,"BigBirdPegasusForQuestionAnswering"),ZCt.forEach(t),sor=r(OBe," (BigBird-Pegasus model)"),OBe.forEach(t),lor=i(X),wT=n(X,"LI",{});var VBe=s(wT);U1e=n(VBe,"STRONG",{});var e3t=s(U1e);ior=r(e3t,"camembert"),e3t.forEach(t),dor=r(VBe," \u2014 "),TQ=n(VBe,"A",{href:!0});var o3t=s(TQ);cor=r(o3t,"CamembertForQuestionAnswering"),o3t.forEach(t),mor=r(VBe," (CamemBERT model)"),VBe.forEach(t),gor=i(X),AT=n(X,"LI",{});var XBe=s(AT);J1e=n(XBe,"STRONG",{});var r3t=s(J1e);hor=r(r3t,"canine"),r3t.forEach(t),por=r(XBe," \u2014 "),MQ=n(XBe,"A",{href:!0});var t3t=s(MQ);_or=r(t3t,"CanineForQuestionAnswering"),t3t.forEach(t),uor=r(XBe," (CANINE model)"),XBe.forEach(t),bor=i(X),LT=n(X,"LI",{});var zBe=s(LT);Y1e=n(zBe,"STRONG",{});var a3t=s(Y1e);vor=r(a3t,"convbert"),a3t.forEach(t),For=r(zBe," \u2014 "),EQ=n(zBe,"A",{href:!0});var n3t=s(EQ);Tor=r(n3t,"ConvBertForQuestionAnswering"),n3t.forEach(t),Mor=r(zBe," (ConvBERT model)"),zBe.forEach(t),Eor=i(X),yT=n(X,"LI",{});var QBe=s(yT);K1e=n(QBe,"STRONG",{});var s3t=s(K1e);Cor=r(s3t,"data2vec-text"),s3t.forEach(t),wor=r(QBe," \u2014 "),CQ=n(QBe,"A",{href:!0});var l3t=s(CQ);Aor=r(l3t,"Data2VecTextForQuestionAnswering"),l3t.forEach(t),Lor=r(QBe," (Data2VecText model)"),QBe.forEach(t),yor=i(X),xT=n(X,"LI",{});var WBe=s(xT);Z1e=n(WBe,"STRONG",{});var i3t=s(Z1e);xor=r(i3t,"deberta"),i3t.forEach(t),$or=r(WBe," \u2014 "),wQ=n(WBe,"A",{href:!0});var d3t=s(wQ);kor=r(d3t,"DebertaForQuestionAnswering"),d3t.forEach(t),Sor=r(WBe," (DeBERTa model)"),WBe.forEach(t),Ror=i(X),$T=n(X,"LI",{});var HBe=s($T);e2e=n(HBe,"STRONG",{});var c3t=s(e2e);Por=r(c3t,"deberta-v2"),c3t.forEach(t),Bor=r(HBe," \u2014 "),AQ=n(HBe,"A",{href:!0});var f3t=s(AQ);Ior=r(f3t,"DebertaV2ForQuestionAnswering"),f3t.forEach(t),Nor=r(HBe," (DeBERTa-v2 model)"),HBe.forEach(t),qor=i(X),kT=n(X,"LI",{});var UBe=s(kT);o2e=n(UBe,"STRONG",{});var m3t=s(o2e);jor=r(m3t,"distilbert"),m3t.forEach(t),Dor=r(UBe," \u2014 "),LQ=n(UBe,"A",{href:!0});var g3t=s(LQ);Gor=r(g3t,"DistilBertForQuestionAnswering"),g3t.forEach(t),Oor=r(UBe," (DistilBERT model)"),UBe.forEach(t),Vor=i(X),ST=n(X,"LI",{});var JBe=s(ST);r2e=n(JBe,"STRONG",{});var h3t=s(r2e);Xor=r(h3t,"electra"),h3t.forEach(t),zor=r(JBe," \u2014 "),yQ=n(JBe,"A",{href:!0});var p3t=s(yQ);Qor=r(p3t,"ElectraForQuestionAnswering"),p3t.forEach(t),Wor=r(JBe," (ELECTRA model)"),JBe.forEach(t),Hor=i(X),RT=n(X,"LI",{});var YBe=s(RT);t2e=n(YBe,"STRONG",{});var _3t=s(t2e);Uor=r(_3t,"flaubert"),_3t.forEach(t),Jor=r(YBe," \u2014 "),xQ=n(YBe,"A",{href:!0});var u3t=s(xQ);Yor=r(u3t,"FlaubertForQuestionAnsweringSimple"),u3t.forEach(t),Kor=r(YBe," (FlauBERT model)"),YBe.forEach(t),Zor=i(X),PT=n(X,"LI",{});var KBe=s(PT);a2e=n(KBe,"STRONG",{});var b3t=s(a2e);err=r(b3t,"fnet"),b3t.forEach(t),orr=r(KBe," \u2014 "),$Q=n(KBe,"A",{href:!0});var v3t=s($Q);rrr=r(v3t,"FNetForQuestionAnswering"),v3t.forEach(t),trr=r(KBe," (FNet model)"),KBe.forEach(t),arr=i(X),BT=n(X,"LI",{});var ZBe=s(BT);n2e=n(ZBe,"STRONG",{});var F3t=s(n2e);nrr=r(F3t,"funnel"),F3t.forEach(t),srr=r(ZBe," \u2014 "),kQ=n(ZBe,"A",{href:!0});var T3t=s(kQ);lrr=r(T3t,"FunnelForQuestionAnswering"),T3t.forEach(t),irr=r(ZBe," (Funnel Transformer model)"),ZBe.forEach(t),drr=i(X),IT=n(X,"LI",{});var eIe=s(IT);s2e=n(eIe,"STRONG",{});var M3t=s(s2e);crr=r(M3t,"gptj"),M3t.forEach(t),frr=r(eIe," \u2014 "),SQ=n(eIe,"A",{href:!0});var E3t=s(SQ);mrr=r(E3t,"GPTJForQuestionAnswering"),E3t.forEach(t),grr=r(eIe," (GPT-J model)"),eIe.forEach(t),hrr=i(X),NT=n(X,"LI",{});var oIe=s(NT);l2e=n(oIe,"STRONG",{});var C3t=s(l2e);prr=r(C3t,"ibert"),C3t.forEach(t),_rr=r(oIe," \u2014 "),RQ=n(oIe,"A",{href:!0});var w3t=s(RQ);urr=r(w3t,"IBertForQuestionAnswering"),w3t.forEach(t),brr=r(oIe," (I-BERT model)"),oIe.forEach(t),vrr=i(X),qT=n(X,"LI",{});var rIe=s(qT);i2e=n(rIe,"STRONG",{});var A3t=s(i2e);Frr=r(A3t,"layoutlmv2"),A3t.forEach(t),Trr=r(rIe," \u2014 "),PQ=n(rIe,"A",{href:!0});var L3t=s(PQ);Mrr=r(L3t,"LayoutLMv2ForQuestionAnswering"),L3t.forEach(t),Err=r(rIe," (LayoutLMv2 model)"),rIe.forEach(t),Crr=i(X),jT=n(X,"LI",{});var tIe=s(jT);d2e=n(tIe,"STRONG",{});var y3t=s(d2e);wrr=r(y3t,"layoutlmv3"),y3t.forEach(t),Arr=r(tIe," \u2014 "),BQ=n(tIe,"A",{href:!0});var x3t=s(BQ);Lrr=r(x3t,"LayoutLMv3ForQuestionAnswering"),x3t.forEach(t),yrr=r(tIe," (LayoutLMv3 model)"),tIe.forEach(t),xrr=i(X),DT=n(X,"LI",{});var aIe=s(DT);c2e=n(aIe,"STRONG",{});var $3t=s(c2e);$rr=r($3t,"led"),$3t.forEach(t),krr=r(aIe," \u2014 "),IQ=n(aIe,"A",{href:!0});var k3t=s(IQ);Srr=r(k3t,"LEDForQuestionAnswering"),k3t.forEach(t),Rrr=r(aIe," (LED model)"),aIe.forEach(t),Prr=i(X),GT=n(X,"LI",{});var nIe=s(GT);f2e=n(nIe,"STRONG",{});var S3t=s(f2e);Brr=r(S3t,"longformer"),S3t.forEach(t),Irr=r(nIe," \u2014 "),NQ=n(nIe,"A",{href:!0});var R3t=s(NQ);Nrr=r(R3t,"LongformerForQuestionAnswering"),R3t.forEach(t),qrr=r(nIe," (Longformer model)"),nIe.forEach(t),jrr=i(X),OT=n(X,"LI",{});var sIe=s(OT);m2e=n(sIe,"STRONG",{});var P3t=s(m2e);Drr=r(P3t,"lxmert"),P3t.forEach(t),Grr=r(sIe," \u2014 "),qQ=n(sIe,"A",{href:!0});var B3t=s(qQ);Orr=r(B3t,"LxmertForQuestionAnswering"),B3t.forEach(t),Vrr=r(sIe," (LXMERT model)"),sIe.forEach(t),Xrr=i(X),VT=n(X,"LI",{});var lIe=s(VT);g2e=n(lIe,"STRONG",{});var I3t=s(g2e);zrr=r(I3t,"mbart"),I3t.forEach(t),Qrr=r(lIe," \u2014 "),jQ=n(lIe,"A",{href:!0});var N3t=s(jQ);Wrr=r(N3t,"MBartForQuestionAnswering"),N3t.forEach(t),Hrr=r(lIe," (mBART model)"),lIe.forEach(t),Urr=i(X),XT=n(X,"LI",{});var iIe=s(XT);h2e=n(iIe,"STRONG",{});var q3t=s(h2e);Jrr=r(q3t,"megatron-bert"),q3t.forEach(t),Yrr=r(iIe," \u2014 "),DQ=n(iIe,"A",{href:!0});var j3t=s(DQ);Krr=r(j3t,"MegatronBertForQuestionAnswering"),j3t.forEach(t),Zrr=r(iIe," (Megatron-BERT model)"),iIe.forEach(t),etr=i(X),zT=n(X,"LI",{});var dIe=s(zT);p2e=n(dIe,"STRONG",{});var D3t=s(p2e);otr=r(D3t,"mobilebert"),D3t.forEach(t),rtr=r(dIe," \u2014 "),GQ=n(dIe,"A",{href:!0});var G3t=s(GQ);ttr=r(G3t,"MobileBertForQuestionAnswering"),G3t.forEach(t),atr=r(dIe," (MobileBERT model)"),dIe.forEach(t),ntr=i(X),QT=n(X,"LI",{});var cIe=s(QT);_2e=n(cIe,"STRONG",{});var O3t=s(_2e);str=r(O3t,"mpnet"),O3t.forEach(t),ltr=r(cIe," \u2014 "),OQ=n(cIe,"A",{href:!0});var V3t=s(OQ);itr=r(V3t,"MPNetForQuestionAnswering"),V3t.forEach(t),dtr=r(cIe," (MPNet model)"),cIe.forEach(t),ctr=i(X),WT=n(X,"LI",{});var fIe=s(WT);u2e=n(fIe,"STRONG",{});var X3t=s(u2e);ftr=r(X3t,"mvp"),X3t.forEach(t),mtr=r(fIe," \u2014 "),VQ=n(fIe,"A",{href:!0});var z3t=s(VQ);gtr=r(z3t,"MvpForQuestionAnswering"),z3t.forEach(t),htr=r(fIe," (MVP model)"),fIe.forEach(t),ptr=i(X),HT=n(X,"LI",{});var mIe=s(HT);b2e=n(mIe,"STRONG",{});var Q3t=s(b2e);_tr=r(Q3t,"nezha"),Q3t.forEach(t),utr=r(mIe," \u2014 "),XQ=n(mIe,"A",{href:!0});var W3t=s(XQ);btr=r(W3t,"NezhaForQuestionAnswering"),W3t.forEach(t),vtr=r(mIe," (Nezha model)"),mIe.forEach(t),Ftr=i(X),UT=n(X,"LI",{});var gIe=s(UT);v2e=n(gIe,"STRONG",{});var H3t=s(v2e);Ttr=r(H3t,"nystromformer"),H3t.forEach(t),Mtr=r(gIe," \u2014 "),zQ=n(gIe,"A",{href:!0});var U3t=s(zQ);Etr=r(U3t,"NystromformerForQuestionAnswering"),U3t.forEach(t),Ctr=r(gIe," (Nystr\xF6mformer model)"),gIe.forEach(t),wtr=i(X),JT=n(X,"LI",{});var hIe=s(JT);F2e=n(hIe,"STRONG",{});var J3t=s(F2e);Atr=r(J3t,"qdqbert"),J3t.forEach(t),Ltr=r(hIe," \u2014 "),QQ=n(hIe,"A",{href:!0});var Y3t=s(QQ);ytr=r(Y3t,"QDQBertForQuestionAnswering"),Y3t.forEach(t),xtr=r(hIe," (QDQBert model)"),hIe.forEach(t),$tr=i(X),YT=n(X,"LI",{});var pIe=s(YT);T2e=n(pIe,"STRONG",{});var K3t=s(T2e);ktr=r(K3t,"reformer"),K3t.forEach(t),Str=r(pIe," \u2014 "),WQ=n(pIe,"A",{href:!0});var Z3t=s(WQ);Rtr=r(Z3t,"ReformerForQuestionAnswering"),Z3t.forEach(t),Ptr=r(pIe," (Reformer model)"),pIe.forEach(t),Btr=i(X),KT=n(X,"LI",{});var _Ie=s(KT);M2e=n(_Ie,"STRONG",{});var e5t=s(M2e);Itr=r(e5t,"rembert"),e5t.forEach(t),Ntr=r(_Ie," \u2014 "),HQ=n(_Ie,"A",{href:!0});var o5t=s(HQ);qtr=r(o5t,"RemBertForQuestionAnswering"),o5t.forEach(t),jtr=r(_Ie," (RemBERT model)"),_Ie.forEach(t),Dtr=i(X),ZT=n(X,"LI",{});var uIe=s(ZT);E2e=n(uIe,"STRONG",{});var r5t=s(E2e);Gtr=r(r5t,"roberta"),r5t.forEach(t),Otr=r(uIe," \u2014 "),UQ=n(uIe,"A",{href:!0});var t5t=s(UQ);Vtr=r(t5t,"RobertaForQuestionAnswering"),t5t.forEach(t),Xtr=r(uIe," (RoBERTa model)"),uIe.forEach(t),ztr=i(X),e7=n(X,"LI",{});var bIe=s(e7);C2e=n(bIe,"STRONG",{});var a5t=s(C2e);Qtr=r(a5t,"roformer"),a5t.forEach(t),Wtr=r(bIe," \u2014 "),JQ=n(bIe,"A",{href:!0});var n5t=s(JQ);Htr=r(n5t,"RoFormerForQuestionAnswering"),n5t.forEach(t),Utr=r(bIe," (RoFormer model)"),bIe.forEach(t),Jtr=i(X),o7=n(X,"LI",{});var vIe=s(o7);w2e=n(vIe,"STRONG",{});var s5t=s(w2e);Ytr=r(s5t,"splinter"),s5t.forEach(t),Ktr=r(vIe," \u2014 "),YQ=n(vIe,"A",{href:!0});var l5t=s(YQ);Ztr=r(l5t,"SplinterForQuestionAnswering"),l5t.forEach(t),ear=r(vIe," (Splinter model)"),vIe.forEach(t),oar=i(X),r7=n(X,"LI",{});var FIe=s(r7);A2e=n(FIe,"STRONG",{});var i5t=s(A2e);rar=r(i5t,"squeezebert"),i5t.forEach(t),tar=r(FIe," \u2014 "),KQ=n(FIe,"A",{href:!0});var d5t=s(KQ);aar=r(d5t,"SqueezeBertForQuestionAnswering"),d5t.forEach(t),nar=r(FIe," (SqueezeBERT model)"),FIe.forEach(t),sar=i(X),t7=n(X,"LI",{});var TIe=s(t7);L2e=n(TIe,"STRONG",{});var c5t=s(L2e);lar=r(c5t,"xlm"),c5t.forEach(t),iar=r(TIe," \u2014 "),ZQ=n(TIe,"A",{href:!0});var f5t=s(ZQ);dar=r(f5t,"XLMForQuestionAnsweringSimple"),f5t.forEach(t),car=r(TIe," (XLM model)"),TIe.forEach(t),far=i(X),a7=n(X,"LI",{});var MIe=s(a7);y2e=n(MIe,"STRONG",{});var m5t=s(y2e);mar=r(m5t,"xlm-roberta"),m5t.forEach(t),gar=r(MIe," \u2014 "),eW=n(MIe,"A",{href:!0});var g5t=s(eW);har=r(g5t,"XLMRobertaForQuestionAnswering"),g5t.forEach(t),par=r(MIe," (XLM-RoBERTa model)"),MIe.forEach(t),_ar=i(X),n7=n(X,"LI",{});var EIe=s(n7);x2e=n(EIe,"STRONG",{});var h5t=s(x2e);uar=r(h5t,"xlm-roberta-xl"),h5t.forEach(t),bar=r(EIe," \u2014 "),oW=n(EIe,"A",{href:!0});var p5t=s(oW);Far=r(p5t,"XLMRobertaXLForQuestionAnswering"),p5t.forEach(t),Tar=r(EIe," (XLM-RoBERTa-XL model)"),EIe.forEach(t),Mar=i(X),s7=n(X,"LI",{});var CIe=s(s7);$2e=n(CIe,"STRONG",{});var _5t=s($2e);Ear=r(_5t,"xlnet"),_5t.forEach(t),Car=r(CIe," \u2014 "),rW=n(CIe,"A",{href:!0});var u5t=s(rW);war=r(u5t,"XLNetForQuestionAnsweringSimple"),u5t.forEach(t),Aar=r(CIe," (XLNet model)"),CIe.forEach(t),Lar=i(X),l7=n(X,"LI",{});var wIe=s(l7);k2e=n(wIe,"STRONG",{});var b5t=s(k2e);yar=r(b5t,"yoso"),b5t.forEach(t),xar=r(wIe," \u2014 "),tW=n(wIe,"A",{href:!0});var v5t=s(tW);$ar=r(v5t,"YosoForQuestionAnswering"),v5t.forEach(t),kar=r(wIe," (YOSO model)"),wIe.forEach(t),X.forEach(t),Sar=i(_a),i7=n(_a,"P",{});var AIe=s(i7);Rar=r(AIe,"The model is set in evaluation mode by default using "),S2e=n(AIe,"CODE",{});var F5t=s(S2e);Par=r(F5t,"model.eval()"),F5t.forEach(t),Bar=r(AIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),R2e=n(AIe,"CODE",{});var T5t=s(R2e);Iar=r(T5t,"model.train()"),T5t.forEach(t),AIe.forEach(t),Nar=i(_a),T(d7.$$.fragment,_a),_a.forEach(t),dl.forEach(t),uXe=i(f),_d=n(f,"H2",{class:!0});var EQe=s(_d);c7=n(EQe,"A",{id:!0,class:!0,href:!0});var M5t=s(c7);P2e=n(M5t,"SPAN",{});var E5t=s(P2e);T(Ey.$$.fragment,E5t),E5t.forEach(t),M5t.forEach(t),qar=i(EQe),B2e=n(EQe,"SPAN",{});var C5t=s(B2e);jar=r(C5t,"AutoModelForTableQuestionAnswering"),C5t.forEach(t),EQe.forEach(t),bXe=i(f),Do=n(f,"DIV",{class:!0});var cl=s(Do);T(Cy.$$.fragment,cl),Dar=i(cl),ud=n(cl,"P",{});var Vre=s(ud);Gar=r(Vre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),aW=n(Vre,"A",{href:!0});var w5t=s(aW);Oar=r(w5t,"from_pretrained()"),w5t.forEach(t),Var=r(Vre," class method or the "),nW=n(Vre,"A",{href:!0});var A5t=s(nW);Xar=r(A5t,"from_config()"),A5t.forEach(t),zar=r(Vre,` class
method.`),Vre.forEach(t),Qar=i(cl),wy=n(cl,"P",{});var CQe=s(wy);War=r(CQe,"This class cannot be instantiated directly using "),I2e=n(CQe,"CODE",{});var L5t=s(I2e);Har=r(L5t,"__init__()"),L5t.forEach(t),Uar=r(CQe," (throws an error)."),CQe.forEach(t),Jar=i(cl),ut=n(cl,"DIV",{class:!0});var wA=s(ut);T(Ay.$$.fragment,wA),Yar=i(wA),N2e=n(wA,"P",{});var y5t=s(N2e);Kar=r(y5t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),y5t.forEach(t),Zar=i(wA),bd=n(wA,"P",{});var Xre=s(bd);enr=r(Xre,`Note:
Loading a model from its configuration file does `),q2e=n(Xre,"STRONG",{});var x5t=s(q2e);onr=r(x5t,"not"),x5t.forEach(t),rnr=r(Xre,` load the model weights. It only affects the
model\u2019s configuration. Use `),sW=n(Xre,"A",{href:!0});var $5t=s(sW);tnr=r($5t,"from_pretrained()"),$5t.forEach(t),anr=r(Xre," to load the model weights."),Xre.forEach(t),nnr=i(wA),T(f7.$$.fragment,wA),wA.forEach(t),snr=i(cl),so=n(cl,"DIV",{class:!0});var ua=s(so);T(Ly.$$.fragment,ua),lnr=i(ua),j2e=n(ua,"P",{});var k5t=s(j2e);inr=r(k5t,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),k5t.forEach(t),dnr=i(ua),za=n(ua,"P",{});var AA=s(za);cnr=r(AA,"The model class to instantiate is selected based on the "),D2e=n(AA,"CODE",{});var S5t=s(D2e);fnr=r(S5t,"model_type"),S5t.forEach(t),mnr=r(AA,` property of the config object (either
passed as an argument or loaded from `),G2e=n(AA,"CODE",{});var R5t=s(G2e);gnr=r(R5t,"pretrained_model_name_or_path"),R5t.forEach(t),hnr=r(AA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O2e=n(AA,"CODE",{});var P5t=s(O2e);pnr=r(P5t,"pretrained_model_name_or_path"),P5t.forEach(t),_nr=r(AA,":"),AA.forEach(t),unr=i(ua),V2e=n(ua,"UL",{});var B5t=s(V2e);m7=n(B5t,"LI",{});var LIe=s(m7);X2e=n(LIe,"STRONG",{});var I5t=s(X2e);bnr=r(I5t,"tapas"),I5t.forEach(t),vnr=r(LIe," \u2014 "),lW=n(LIe,"A",{href:!0});var N5t=s(lW);Fnr=r(N5t,"TapasForQuestionAnswering"),N5t.forEach(t),Tnr=r(LIe," (TAPAS model)"),LIe.forEach(t),B5t.forEach(t),Mnr=i(ua),g7=n(ua,"P",{});var yIe=s(g7);Enr=r(yIe,"The model is set in evaluation mode by default using "),z2e=n(yIe,"CODE",{});var q5t=s(z2e);Cnr=r(q5t,"model.eval()"),q5t.forEach(t),wnr=r(yIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q2e=n(yIe,"CODE",{});var j5t=s(Q2e);Anr=r(j5t,"model.train()"),j5t.forEach(t),yIe.forEach(t),Lnr=i(ua),T(h7.$$.fragment,ua),ua.forEach(t),cl.forEach(t),vXe=i(f),vd=n(f,"H2",{class:!0});var wQe=s(vd);p7=n(wQe,"A",{id:!0,class:!0,href:!0});var D5t=s(p7);W2e=n(D5t,"SPAN",{});var G5t=s(W2e);T(yy.$$.fragment,G5t),G5t.forEach(t),D5t.forEach(t),ynr=i(wQe),H2e=n(wQe,"SPAN",{});var O5t=s(H2e);xnr=r(O5t,"AutoModelForImageClassification"),O5t.forEach(t),wQe.forEach(t),FXe=i(f),Go=n(f,"DIV",{class:!0});var fl=s(Go);T(xy.$$.fragment,fl),$nr=i(fl),Fd=n(fl,"P",{});var zre=s(Fd);knr=r(zre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),iW=n(zre,"A",{href:!0});var V5t=s(iW);Snr=r(V5t,"from_pretrained()"),V5t.forEach(t),Rnr=r(zre," class method or the "),dW=n(zre,"A",{href:!0});var X5t=s(dW);Pnr=r(X5t,"from_config()"),X5t.forEach(t),Bnr=r(zre,` class
method.`),zre.forEach(t),Inr=i(fl),$y=n(fl,"P",{});var AQe=s($y);Nnr=r(AQe,"This class cannot be instantiated directly using "),U2e=n(AQe,"CODE",{});var z5t=s(U2e);qnr=r(z5t,"__init__()"),z5t.forEach(t),jnr=r(AQe," (throws an error)."),AQe.forEach(t),Dnr=i(fl),bt=n(fl,"DIV",{class:!0});var LA=s(bt);T(ky.$$.fragment,LA),Gnr=i(LA),J2e=n(LA,"P",{});var Q5t=s(J2e);Onr=r(Q5t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Q5t.forEach(t),Vnr=i(LA),Td=n(LA,"P",{});var Qre=s(Td);Xnr=r(Qre,`Note:
Loading a model from its configuration file does `),Y2e=n(Qre,"STRONG",{});var W5t=s(Y2e);znr=r(W5t,"not"),W5t.forEach(t),Qnr=r(Qre,` load the model weights. It only affects the
model\u2019s configuration. Use `),cW=n(Qre,"A",{href:!0});var H5t=s(cW);Wnr=r(H5t,"from_pretrained()"),H5t.forEach(t),Hnr=r(Qre," to load the model weights."),Qre.forEach(t),Unr=i(LA),T(_7.$$.fragment,LA),LA.forEach(t),Jnr=i(fl),lo=n(fl,"DIV",{class:!0});var ba=s(lo);T(Sy.$$.fragment,ba),Ynr=i(ba),K2e=n(ba,"P",{});var U5t=s(K2e);Knr=r(U5t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),U5t.forEach(t),Znr=i(ba),Qa=n(ba,"P",{});var yA=s(Qa);esr=r(yA,"The model class to instantiate is selected based on the "),Z2e=n(yA,"CODE",{});var J5t=s(Z2e);osr=r(J5t,"model_type"),J5t.forEach(t),rsr=r(yA,` property of the config object (either
passed as an argument or loaded from `),ebe=n(yA,"CODE",{});var Y5t=s(ebe);tsr=r(Y5t,"pretrained_model_name_or_path"),Y5t.forEach(t),asr=r(yA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),obe=n(yA,"CODE",{});var K5t=s(obe);nsr=r(K5t,"pretrained_model_name_or_path"),K5t.forEach(t),ssr=r(yA,":"),yA.forEach(t),lsr=i(ba),ve=n(ba,"UL",{});var Te=s(ve);u7=n(Te,"LI",{});var xIe=s(u7);rbe=n(xIe,"STRONG",{});var Z5t=s(rbe);isr=r(Z5t,"beit"),Z5t.forEach(t),dsr=r(xIe," \u2014 "),fW=n(xIe,"A",{href:!0});var e0t=s(fW);csr=r(e0t,"BeitForImageClassification"),e0t.forEach(t),fsr=r(xIe," (BEiT model)"),xIe.forEach(t),msr=i(Te),b7=n(Te,"LI",{});var $Ie=s(b7);tbe=n($Ie,"STRONG",{});var o0t=s(tbe);gsr=r(o0t,"convnext"),o0t.forEach(t),hsr=r($Ie," \u2014 "),mW=n($Ie,"A",{href:!0});var r0t=s(mW);psr=r(r0t,"ConvNextForImageClassification"),r0t.forEach(t),_sr=r($Ie," (ConvNeXT model)"),$Ie.forEach(t),usr=i(Te),v7=n(Te,"LI",{});var kIe=s(v7);abe=n(kIe,"STRONG",{});var t0t=s(abe);bsr=r(t0t,"cvt"),t0t.forEach(t),vsr=r(kIe," \u2014 "),gW=n(kIe,"A",{href:!0});var a0t=s(gW);Fsr=r(a0t,"CvtForImageClassification"),a0t.forEach(t),Tsr=r(kIe," (CvT model)"),kIe.forEach(t),Msr=i(Te),F7=n(Te,"LI",{});var SIe=s(F7);nbe=n(SIe,"STRONG",{});var n0t=s(nbe);Esr=r(n0t,"data2vec-vision"),n0t.forEach(t),Csr=r(SIe," \u2014 "),hW=n(SIe,"A",{href:!0});var s0t=s(hW);wsr=r(s0t,"Data2VecVisionForImageClassification"),s0t.forEach(t),Asr=r(SIe," (Data2VecVision model)"),SIe.forEach(t),Lsr=i(Te),Ws=n(Te,"LI",{});var yS=s(Ws);sbe=n(yS,"STRONG",{});var l0t=s(sbe);ysr=r(l0t,"deit"),l0t.forEach(t),xsr=r(yS," \u2014 "),pW=n(yS,"A",{href:!0});var i0t=s(pW);$sr=r(i0t,"DeiTForImageClassification"),i0t.forEach(t),ksr=r(yS," or "),_W=n(yS,"A",{href:!0});var d0t=s(_W);Ssr=r(d0t,"DeiTForImageClassificationWithTeacher"),d0t.forEach(t),Rsr=r(yS," (DeiT model)"),yS.forEach(t),Psr=i(Te),T7=n(Te,"LI",{});var RIe=s(T7);lbe=n(RIe,"STRONG",{});var c0t=s(lbe);Bsr=r(c0t,"imagegpt"),c0t.forEach(t),Isr=r(RIe," \u2014 "),uW=n(RIe,"A",{href:!0});var f0t=s(uW);Nsr=r(f0t,"ImageGPTForImageClassification"),f0t.forEach(t),qsr=r(RIe," (ImageGPT model)"),RIe.forEach(t),jsr=i(Te),Hs=n(Te,"LI",{});var xS=s(Hs);ibe=n(xS,"STRONG",{});var m0t=s(ibe);Dsr=r(m0t,"levit"),m0t.forEach(t),Gsr=r(xS," \u2014 "),bW=n(xS,"A",{href:!0});var g0t=s(bW);Osr=r(g0t,"LevitForImageClassification"),g0t.forEach(t),Vsr=r(xS," or "),vW=n(xS,"A",{href:!0});var h0t=s(vW);Xsr=r(h0t,"LevitForImageClassificationWithTeacher"),h0t.forEach(t),zsr=r(xS," (LeViT model)"),xS.forEach(t),Qsr=i(Te),M7=n(Te,"LI",{});var PIe=s(M7);dbe=n(PIe,"STRONG",{});var p0t=s(dbe);Wsr=r(p0t,"mobilevit"),p0t.forEach(t),Hsr=r(PIe," \u2014 "),FW=n(PIe,"A",{href:!0});var _0t=s(FW);Usr=r(_0t,"MobileViTForImageClassification"),_0t.forEach(t),Jsr=r(PIe," (MobileViT model)"),PIe.forEach(t),Ysr=i(Te),vt=n(Te,"LI",{});var Sf=s(vt);cbe=n(Sf,"STRONG",{});var u0t=s(cbe);Ksr=r(u0t,"perceiver"),u0t.forEach(t),Zsr=r(Sf," \u2014 "),TW=n(Sf,"A",{href:!0});var b0t=s(TW);elr=r(b0t,"PerceiverForImageClassificationLearned"),b0t.forEach(t),olr=r(Sf," or "),MW=n(Sf,"A",{href:!0});var v0t=s(MW);rlr=r(v0t,"PerceiverForImageClassificationFourier"),v0t.forEach(t),tlr=r(Sf," or "),EW=n(Sf,"A",{href:!0});var F0t=s(EW);alr=r(F0t,"PerceiverForImageClassificationConvProcessing"),F0t.forEach(t),nlr=r(Sf," (Perceiver model)"),Sf.forEach(t),slr=i(Te),E7=n(Te,"LI",{});var BIe=s(E7);fbe=n(BIe,"STRONG",{});var T0t=s(fbe);llr=r(T0t,"poolformer"),T0t.forEach(t),ilr=r(BIe," \u2014 "),CW=n(BIe,"A",{href:!0});var M0t=s(CW);dlr=r(M0t,"PoolFormerForImageClassification"),M0t.forEach(t),clr=r(BIe," (PoolFormer model)"),BIe.forEach(t),flr=i(Te),C7=n(Te,"LI",{});var IIe=s(C7);mbe=n(IIe,"STRONG",{});var E0t=s(mbe);mlr=r(E0t,"regnet"),E0t.forEach(t),glr=r(IIe," \u2014 "),wW=n(IIe,"A",{href:!0});var C0t=s(wW);hlr=r(C0t,"RegNetForImageClassification"),C0t.forEach(t),plr=r(IIe," (RegNet model)"),IIe.forEach(t),_lr=i(Te),w7=n(Te,"LI",{});var NIe=s(w7);gbe=n(NIe,"STRONG",{});var w0t=s(gbe);ulr=r(w0t,"resnet"),w0t.forEach(t),blr=r(NIe," \u2014 "),AW=n(NIe,"A",{href:!0});var A0t=s(AW);vlr=r(A0t,"ResNetForImageClassification"),A0t.forEach(t),Flr=r(NIe," (ResNet model)"),NIe.forEach(t),Tlr=i(Te),A7=n(Te,"LI",{});var qIe=s(A7);hbe=n(qIe,"STRONG",{});var L0t=s(hbe);Mlr=r(L0t,"segformer"),L0t.forEach(t),Elr=r(qIe," \u2014 "),LW=n(qIe,"A",{href:!0});var y0t=s(LW);Clr=r(y0t,"SegformerForImageClassification"),y0t.forEach(t),wlr=r(qIe," (SegFormer model)"),qIe.forEach(t),Alr=i(Te),L7=n(Te,"LI",{});var jIe=s(L7);pbe=n(jIe,"STRONG",{});var x0t=s(pbe);Llr=r(x0t,"swin"),x0t.forEach(t),ylr=r(jIe," \u2014 "),yW=n(jIe,"A",{href:!0});var $0t=s(yW);xlr=r($0t,"SwinForImageClassification"),$0t.forEach(t),$lr=r(jIe," (Swin Transformer model)"),jIe.forEach(t),klr=i(Te),y7=n(Te,"LI",{});var DIe=s(y7);_be=n(DIe,"STRONG",{});var k0t=s(_be);Slr=r(k0t,"van"),k0t.forEach(t),Rlr=r(DIe," \u2014 "),xW=n(DIe,"A",{href:!0});var S0t=s(xW);Plr=r(S0t,"VanForImageClassification"),S0t.forEach(t),Blr=r(DIe," (VAN model)"),DIe.forEach(t),Ilr=i(Te),x7=n(Te,"LI",{});var GIe=s(x7);ube=n(GIe,"STRONG",{});var R0t=s(ube);Nlr=r(R0t,"vit"),R0t.forEach(t),qlr=r(GIe," \u2014 "),$W=n(GIe,"A",{href:!0});var P0t=s($W);jlr=r(P0t,"ViTForImageClassification"),P0t.forEach(t),Dlr=r(GIe," (ViT model)"),GIe.forEach(t),Te.forEach(t),Glr=i(ba),$7=n(ba,"P",{});var OIe=s($7);Olr=r(OIe,"The model is set in evaluation mode by default using "),bbe=n(OIe,"CODE",{});var B0t=s(bbe);Vlr=r(B0t,"model.eval()"),B0t.forEach(t),Xlr=r(OIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vbe=n(OIe,"CODE",{});var I0t=s(vbe);zlr=r(I0t,"model.train()"),I0t.forEach(t),OIe.forEach(t),Qlr=i(ba),T(k7.$$.fragment,ba),ba.forEach(t),fl.forEach(t),TXe=i(f),Md=n(f,"H2",{class:!0});var LQe=s(Md);S7=n(LQe,"A",{id:!0,class:!0,href:!0});var N0t=s(S7);Fbe=n(N0t,"SPAN",{});var q0t=s(Fbe);T(Ry.$$.fragment,q0t),q0t.forEach(t),N0t.forEach(t),Wlr=i(LQe),Tbe=n(LQe,"SPAN",{});var j0t=s(Tbe);Hlr=r(j0t,"AutoModelForVision2Seq"),j0t.forEach(t),LQe.forEach(t),MXe=i(f),Oo=n(f,"DIV",{class:!0});var ml=s(Oo);T(Py.$$.fragment,ml),Ulr=i(ml),Ed=n(ml,"P",{});var Wre=s(Ed);Jlr=r(Wre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),kW=n(Wre,"A",{href:!0});var D0t=s(kW);Ylr=r(D0t,"from_pretrained()"),D0t.forEach(t),Klr=r(Wre," class method or the "),SW=n(Wre,"A",{href:!0});var G0t=s(SW);Zlr=r(G0t,"from_config()"),G0t.forEach(t),eir=r(Wre,` class
method.`),Wre.forEach(t),oir=i(ml),By=n(ml,"P",{});var yQe=s(By);rir=r(yQe,"This class cannot be instantiated directly using "),Mbe=n(yQe,"CODE",{});var O0t=s(Mbe);tir=r(O0t,"__init__()"),O0t.forEach(t),air=r(yQe," (throws an error)."),yQe.forEach(t),nir=i(ml),Ft=n(ml,"DIV",{class:!0});var xA=s(Ft);T(Iy.$$.fragment,xA),sir=i(xA),Ebe=n(xA,"P",{});var V0t=s(Ebe);lir=r(V0t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),V0t.forEach(t),iir=i(xA),Cd=n(xA,"P",{});var Hre=s(Cd);dir=r(Hre,`Note:
Loading a model from its configuration file does `),Cbe=n(Hre,"STRONG",{});var X0t=s(Cbe);cir=r(X0t,"not"),X0t.forEach(t),fir=r(Hre,` load the model weights. It only affects the
model\u2019s configuration. Use `),RW=n(Hre,"A",{href:!0});var z0t=s(RW);mir=r(z0t,"from_pretrained()"),z0t.forEach(t),gir=r(Hre," to load the model weights."),Hre.forEach(t),hir=i(xA),T(R7.$$.fragment,xA),xA.forEach(t),pir=i(ml),io=n(ml,"DIV",{class:!0});var va=s(io);T(Ny.$$.fragment,va),_ir=i(va),wbe=n(va,"P",{});var Q0t=s(wbe);uir=r(Q0t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Q0t.forEach(t),bir=i(va),Wa=n(va,"P",{});var $A=s(Wa);vir=r($A,"The model class to instantiate is selected based on the "),Abe=n($A,"CODE",{});var W0t=s(Abe);Fir=r(W0t,"model_type"),W0t.forEach(t),Tir=r($A,` property of the config object (either
passed as an argument or loaded from `),Lbe=n($A,"CODE",{});var H0t=s(Lbe);Mir=r(H0t,"pretrained_model_name_or_path"),H0t.forEach(t),Eir=r($A,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ybe=n($A,"CODE",{});var U0t=s(ybe);Cir=r(U0t,"pretrained_model_name_or_path"),U0t.forEach(t),wir=r($A,":"),$A.forEach(t),Air=i(va),xbe=n(va,"UL",{});var J0t=s(xbe);P7=n(J0t,"LI",{});var VIe=s(P7);$be=n(VIe,"STRONG",{});var Y0t=s($be);Lir=r(Y0t,"vision-encoder-decoder"),Y0t.forEach(t),yir=r(VIe," \u2014 "),PW=n(VIe,"A",{href:!0});var K0t=s(PW);xir=r(K0t,"VisionEncoderDecoderModel"),K0t.forEach(t),$ir=r(VIe," (Vision Encoder decoder model)"),VIe.forEach(t),J0t.forEach(t),kir=i(va),B7=n(va,"P",{});var XIe=s(B7);Sir=r(XIe,"The model is set in evaluation mode by default using "),kbe=n(XIe,"CODE",{});var Z0t=s(kbe);Rir=r(Z0t,"model.eval()"),Z0t.forEach(t),Pir=r(XIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Sbe=n(XIe,"CODE",{});var ewt=s(Sbe);Bir=r(ewt,"model.train()"),ewt.forEach(t),XIe.forEach(t),Iir=i(va),T(I7.$$.fragment,va),va.forEach(t),ml.forEach(t),EXe=i(f),wd=n(f,"H2",{class:!0});var xQe=s(wd);N7=n(xQe,"A",{id:!0,class:!0,href:!0});var owt=s(N7);Rbe=n(owt,"SPAN",{});var rwt=s(Rbe);T(qy.$$.fragment,rwt),rwt.forEach(t),owt.forEach(t),Nir=i(xQe),Pbe=n(xQe,"SPAN",{});var twt=s(Pbe);qir=r(twt,"AutoModelForVisualQuestionAnswering"),twt.forEach(t),xQe.forEach(t),CXe=i(f),Vo=n(f,"DIV",{class:!0});var gl=s(Vo);T(jy.$$.fragment,gl),jir=i(gl),Ad=n(gl,"P",{});var Ure=s(Ad);Dir=r(Ure,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),BW=n(Ure,"A",{href:!0});var awt=s(BW);Gir=r(awt,"from_pretrained()"),awt.forEach(t),Oir=r(Ure," class method or the "),IW=n(Ure,"A",{href:!0});var nwt=s(IW);Vir=r(nwt,"from_config()"),nwt.forEach(t),Xir=r(Ure,` class
method.`),Ure.forEach(t),zir=i(gl),Dy=n(gl,"P",{});var $Qe=s(Dy);Qir=r($Qe,"This class cannot be instantiated directly using "),Bbe=n($Qe,"CODE",{});var swt=s(Bbe);Wir=r(swt,"__init__()"),swt.forEach(t),Hir=r($Qe," (throws an error)."),$Qe.forEach(t),Uir=i(gl),Tt=n(gl,"DIV",{class:!0});var kA=s(Tt);T(Gy.$$.fragment,kA),Jir=i(kA),Ibe=n(kA,"P",{});var lwt=s(Ibe);Yir=r(lwt,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),lwt.forEach(t),Kir=i(kA),Ld=n(kA,"P",{});var Jre=s(Ld);Zir=r(Jre,`Note:
Loading a model from its configuration file does `),Nbe=n(Jre,"STRONG",{});var iwt=s(Nbe);edr=r(iwt,"not"),iwt.forEach(t),odr=r(Jre,` load the model weights. It only affects the
model\u2019s configuration. Use `),NW=n(Jre,"A",{href:!0});var dwt=s(NW);rdr=r(dwt,"from_pretrained()"),dwt.forEach(t),tdr=r(Jre," to load the model weights."),Jre.forEach(t),adr=i(kA),T(q7.$$.fragment,kA),kA.forEach(t),ndr=i(gl),co=n(gl,"DIV",{class:!0});var Fa=s(co);T(Oy.$$.fragment,Fa),sdr=i(Fa),qbe=n(Fa,"P",{});var cwt=s(qbe);ldr=r(cwt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),cwt.forEach(t),idr=i(Fa),Ha=n(Fa,"P",{});var SA=s(Ha);ddr=r(SA,"The model class to instantiate is selected based on the "),jbe=n(SA,"CODE",{});var fwt=s(jbe);cdr=r(fwt,"model_type"),fwt.forEach(t),fdr=r(SA,` property of the config object (either
passed as an argument or loaded from `),Dbe=n(SA,"CODE",{});var mwt=s(Dbe);mdr=r(mwt,"pretrained_model_name_or_path"),mwt.forEach(t),gdr=r(SA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gbe=n(SA,"CODE",{});var gwt=s(Gbe);hdr=r(gwt,"pretrained_model_name_or_path"),gwt.forEach(t),pdr=r(SA,":"),SA.forEach(t),_dr=i(Fa),Obe=n(Fa,"UL",{});var hwt=s(Obe);j7=n(hwt,"LI",{});var zIe=s(j7);Vbe=n(zIe,"STRONG",{});var pwt=s(Vbe);udr=r(pwt,"vilt"),pwt.forEach(t),bdr=r(zIe," \u2014 "),qW=n(zIe,"A",{href:!0});var _wt=s(qW);vdr=r(_wt,"ViltForQuestionAnswering"),_wt.forEach(t),Fdr=r(zIe," (ViLT model)"),zIe.forEach(t),hwt.forEach(t),Tdr=i(Fa),D7=n(Fa,"P",{});var QIe=s(D7);Mdr=r(QIe,"The model is set in evaluation mode by default using "),Xbe=n(QIe,"CODE",{});var uwt=s(Xbe);Edr=r(uwt,"model.eval()"),uwt.forEach(t),Cdr=r(QIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zbe=n(QIe,"CODE",{});var bwt=s(zbe);wdr=r(bwt,"model.train()"),bwt.forEach(t),QIe.forEach(t),Adr=i(Fa),T(G7.$$.fragment,Fa),Fa.forEach(t),gl.forEach(t),wXe=i(f),yd=n(f,"H2",{class:!0});var kQe=s(yd);O7=n(kQe,"A",{id:!0,class:!0,href:!0});var vwt=s(O7);Qbe=n(vwt,"SPAN",{});var Fwt=s(Qbe);T(Vy.$$.fragment,Fwt),Fwt.forEach(t),vwt.forEach(t),Ldr=i(kQe),Wbe=n(kQe,"SPAN",{});var Twt=s(Wbe);ydr=r(Twt,"AutoModelForAudioClassification"),Twt.forEach(t),kQe.forEach(t),AXe=i(f),Xo=n(f,"DIV",{class:!0});var hl=s(Xo);T(Xy.$$.fragment,hl),xdr=i(hl),xd=n(hl,"P",{});var Yre=s(xd);$dr=r(Yre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),jW=n(Yre,"A",{href:!0});var Mwt=s(jW);kdr=r(Mwt,"from_pretrained()"),Mwt.forEach(t),Sdr=r(Yre," class method or the "),DW=n(Yre,"A",{href:!0});var Ewt=s(DW);Rdr=r(Ewt,"from_config()"),Ewt.forEach(t),Pdr=r(Yre,` class
method.`),Yre.forEach(t),Bdr=i(hl),zy=n(hl,"P",{});var SQe=s(zy);Idr=r(SQe,"This class cannot be instantiated directly using "),Hbe=n(SQe,"CODE",{});var Cwt=s(Hbe);Ndr=r(Cwt,"__init__()"),Cwt.forEach(t),qdr=r(SQe," (throws an error)."),SQe.forEach(t),jdr=i(hl),Mt=n(hl,"DIV",{class:!0});var RA=s(Mt);T(Qy.$$.fragment,RA),Ddr=i(RA),Ube=n(RA,"P",{});var wwt=s(Ube);Gdr=r(wwt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),wwt.forEach(t),Odr=i(RA),$d=n(RA,"P",{});var Kre=s($d);Vdr=r(Kre,`Note:
Loading a model from its configuration file does `),Jbe=n(Kre,"STRONG",{});var Awt=s(Jbe);Xdr=r(Awt,"not"),Awt.forEach(t),zdr=r(Kre,` load the model weights. It only affects the
model\u2019s configuration. Use `),GW=n(Kre,"A",{href:!0});var Lwt=s(GW);Qdr=r(Lwt,"from_pretrained()"),Lwt.forEach(t),Wdr=r(Kre," to load the model weights."),Kre.forEach(t),Hdr=i(RA),T(V7.$$.fragment,RA),RA.forEach(t),Udr=i(hl),fo=n(hl,"DIV",{class:!0});var Ta=s(fo);T(Wy.$$.fragment,Ta),Jdr=i(Ta),Ybe=n(Ta,"P",{});var ywt=s(Ybe);Ydr=r(ywt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),ywt.forEach(t),Kdr=i(Ta),Ua=n(Ta,"P",{});var PA=s(Ua);Zdr=r(PA,"The model class to instantiate is selected based on the "),Kbe=n(PA,"CODE",{});var xwt=s(Kbe);ecr=r(xwt,"model_type"),xwt.forEach(t),ocr=r(PA,` property of the config object (either
passed as an argument or loaded from `),Zbe=n(PA,"CODE",{});var $wt=s(Zbe);rcr=r($wt,"pretrained_model_name_or_path"),$wt.forEach(t),tcr=r(PA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eve=n(PA,"CODE",{});var kwt=s(eve);acr=r(kwt,"pretrained_model_name_or_path"),kwt.forEach(t),ncr=r(PA,":"),PA.forEach(t),scr=i(Ta),Pe=n(Ta,"UL",{});var ze=s(Pe);X7=n(ze,"LI",{});var WIe=s(X7);ove=n(WIe,"STRONG",{});var Swt=s(ove);lcr=r(Swt,"data2vec-audio"),Swt.forEach(t),icr=r(WIe," \u2014 "),OW=n(WIe,"A",{href:!0});var Rwt=s(OW);dcr=r(Rwt,"Data2VecAudioForSequenceClassification"),Rwt.forEach(t),ccr=r(WIe," (Data2VecAudio model)"),WIe.forEach(t),fcr=i(ze),z7=n(ze,"LI",{});var HIe=s(z7);rve=n(HIe,"STRONG",{});var Pwt=s(rve);mcr=r(Pwt,"hubert"),Pwt.forEach(t),gcr=r(HIe," \u2014 "),VW=n(HIe,"A",{href:!0});var Bwt=s(VW);hcr=r(Bwt,"HubertForSequenceClassification"),Bwt.forEach(t),pcr=r(HIe," (Hubert model)"),HIe.forEach(t),_cr=i(ze),Q7=n(ze,"LI",{});var UIe=s(Q7);tve=n(UIe,"STRONG",{});var Iwt=s(tve);ucr=r(Iwt,"sew"),Iwt.forEach(t),bcr=r(UIe," \u2014 "),XW=n(UIe,"A",{href:!0});var Nwt=s(XW);vcr=r(Nwt,"SEWForSequenceClassification"),Nwt.forEach(t),Fcr=r(UIe," (SEW model)"),UIe.forEach(t),Tcr=i(ze),W7=n(ze,"LI",{});var JIe=s(W7);ave=n(JIe,"STRONG",{});var qwt=s(ave);Mcr=r(qwt,"sew-d"),qwt.forEach(t),Ecr=r(JIe," \u2014 "),zW=n(JIe,"A",{href:!0});var jwt=s(zW);Ccr=r(jwt,"SEWDForSequenceClassification"),jwt.forEach(t),wcr=r(JIe," (SEW-D model)"),JIe.forEach(t),Acr=i(ze),H7=n(ze,"LI",{});var YIe=s(H7);nve=n(YIe,"STRONG",{});var Dwt=s(nve);Lcr=r(Dwt,"unispeech"),Dwt.forEach(t),ycr=r(YIe," \u2014 "),QW=n(YIe,"A",{href:!0});var Gwt=s(QW);xcr=r(Gwt,"UniSpeechForSequenceClassification"),Gwt.forEach(t),$cr=r(YIe," (UniSpeech model)"),YIe.forEach(t),kcr=i(ze),U7=n(ze,"LI",{});var KIe=s(U7);sve=n(KIe,"STRONG",{});var Owt=s(sve);Scr=r(Owt,"unispeech-sat"),Owt.forEach(t),Rcr=r(KIe," \u2014 "),WW=n(KIe,"A",{href:!0});var Vwt=s(WW);Pcr=r(Vwt,"UniSpeechSatForSequenceClassification"),Vwt.forEach(t),Bcr=r(KIe," (UniSpeechSat model)"),KIe.forEach(t),Icr=i(ze),J7=n(ze,"LI",{});var ZIe=s(J7);lve=n(ZIe,"STRONG",{});var Xwt=s(lve);Ncr=r(Xwt,"wav2vec2"),Xwt.forEach(t),qcr=r(ZIe," \u2014 "),HW=n(ZIe,"A",{href:!0});var zwt=s(HW);jcr=r(zwt,"Wav2Vec2ForSequenceClassification"),zwt.forEach(t),Dcr=r(ZIe," (Wav2Vec2 model)"),ZIe.forEach(t),Gcr=i(ze),Y7=n(ze,"LI",{});var eNe=s(Y7);ive=n(eNe,"STRONG",{});var Qwt=s(ive);Ocr=r(Qwt,"wav2vec2-conformer"),Qwt.forEach(t),Vcr=r(eNe," \u2014 "),UW=n(eNe,"A",{href:!0});var Wwt=s(UW);Xcr=r(Wwt,"Wav2Vec2ConformerForSequenceClassification"),Wwt.forEach(t),zcr=r(eNe," (Wav2Vec2-Conformer model)"),eNe.forEach(t),Qcr=i(ze),K7=n(ze,"LI",{});var oNe=s(K7);dve=n(oNe,"STRONG",{});var Hwt=s(dve);Wcr=r(Hwt,"wavlm"),Hwt.forEach(t),Hcr=r(oNe," \u2014 "),JW=n(oNe,"A",{href:!0});var Uwt=s(JW);Ucr=r(Uwt,"WavLMForSequenceClassification"),Uwt.forEach(t),Jcr=r(oNe," (WavLM model)"),oNe.forEach(t),ze.forEach(t),Ycr=i(Ta),Z7=n(Ta,"P",{});var rNe=s(Z7);Kcr=r(rNe,"The model is set in evaluation mode by default using "),cve=n(rNe,"CODE",{});var Jwt=s(cve);Zcr=r(Jwt,"model.eval()"),Jwt.forEach(t),efr=r(rNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fve=n(rNe,"CODE",{});var Ywt=s(fve);ofr=r(Ywt,"model.train()"),Ywt.forEach(t),rNe.forEach(t),rfr=i(Ta),T(e8.$$.fragment,Ta),Ta.forEach(t),hl.forEach(t),LXe=i(f),kd=n(f,"H2",{class:!0});var RQe=s(kd);o8=n(RQe,"A",{id:!0,class:!0,href:!0});var Kwt=s(o8);mve=n(Kwt,"SPAN",{});var Zwt=s(mve);T(Hy.$$.fragment,Zwt),Zwt.forEach(t),Kwt.forEach(t),tfr=i(RQe),gve=n(RQe,"SPAN",{});var eAt=s(gve);afr=r(eAt,"AutoModelForAudioFrameClassification"),eAt.forEach(t),RQe.forEach(t),yXe=i(f),zo=n(f,"DIV",{class:!0});var pl=s(zo);T(Uy.$$.fragment,pl),nfr=i(pl),Sd=n(pl,"P",{});var Zre=s(Sd);sfr=r(Zre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),YW=n(Zre,"A",{href:!0});var oAt=s(YW);lfr=r(oAt,"from_pretrained()"),oAt.forEach(t),ifr=r(Zre," class method or the "),KW=n(Zre,"A",{href:!0});var rAt=s(KW);dfr=r(rAt,"from_config()"),rAt.forEach(t),cfr=r(Zre,` class
method.`),Zre.forEach(t),ffr=i(pl),Jy=n(pl,"P",{});var PQe=s(Jy);mfr=r(PQe,"This class cannot be instantiated directly using "),hve=n(PQe,"CODE",{});var tAt=s(hve);gfr=r(tAt,"__init__()"),tAt.forEach(t),hfr=r(PQe," (throws an error)."),PQe.forEach(t),pfr=i(pl),Et=n(pl,"DIV",{class:!0});var BA=s(Et);T(Yy.$$.fragment,BA),_fr=i(BA),pve=n(BA,"P",{});var aAt=s(pve);ufr=r(aAt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),aAt.forEach(t),bfr=i(BA),Rd=n(BA,"P",{});var ete=s(Rd);vfr=r(ete,`Note:
Loading a model from its configuration file does `),_ve=n(ete,"STRONG",{});var nAt=s(_ve);Ffr=r(nAt,"not"),nAt.forEach(t),Tfr=r(ete,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZW=n(ete,"A",{href:!0});var sAt=s(ZW);Mfr=r(sAt,"from_pretrained()"),sAt.forEach(t),Efr=r(ete," to load the model weights."),ete.forEach(t),Cfr=i(BA),T(r8.$$.fragment,BA),BA.forEach(t),wfr=i(pl),mo=n(pl,"DIV",{class:!0});var Ma=s(mo);T(Ky.$$.fragment,Ma),Afr=i(Ma),uve=n(Ma,"P",{});var lAt=s(uve);Lfr=r(lAt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),lAt.forEach(t),yfr=i(Ma),Ja=n(Ma,"P",{});var IA=s(Ja);xfr=r(IA,"The model class to instantiate is selected based on the "),bve=n(IA,"CODE",{});var iAt=s(bve);$fr=r(iAt,"model_type"),iAt.forEach(t),kfr=r(IA,` property of the config object (either
passed as an argument or loaded from `),vve=n(IA,"CODE",{});var dAt=s(vve);Sfr=r(dAt,"pretrained_model_name_or_path"),dAt.forEach(t),Rfr=r(IA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fve=n(IA,"CODE",{});var cAt=s(Fve);Pfr=r(cAt,"pretrained_model_name_or_path"),cAt.forEach(t),Bfr=r(IA,":"),IA.forEach(t),Ifr=i(Ma),et=n(Ma,"UL",{});var _l=s(et);t8=n(_l,"LI",{});var tNe=s(t8);Tve=n(tNe,"STRONG",{});var fAt=s(Tve);Nfr=r(fAt,"data2vec-audio"),fAt.forEach(t),qfr=r(tNe," \u2014 "),eH=n(tNe,"A",{href:!0});var mAt=s(eH);jfr=r(mAt,"Data2VecAudioForAudioFrameClassification"),mAt.forEach(t),Dfr=r(tNe," (Data2VecAudio model)"),tNe.forEach(t),Gfr=i(_l),a8=n(_l,"LI",{});var aNe=s(a8);Mve=n(aNe,"STRONG",{});var gAt=s(Mve);Ofr=r(gAt,"unispeech-sat"),gAt.forEach(t),Vfr=r(aNe," \u2014 "),oH=n(aNe,"A",{href:!0});var hAt=s(oH);Xfr=r(hAt,"UniSpeechSatForAudioFrameClassification"),hAt.forEach(t),zfr=r(aNe," (UniSpeechSat model)"),aNe.forEach(t),Qfr=i(_l),n8=n(_l,"LI",{});var nNe=s(n8);Eve=n(nNe,"STRONG",{});var pAt=s(Eve);Wfr=r(pAt,"wav2vec2"),pAt.forEach(t),Hfr=r(nNe," \u2014 "),rH=n(nNe,"A",{href:!0});var _At=s(rH);Ufr=r(_At,"Wav2Vec2ForAudioFrameClassification"),_At.forEach(t),Jfr=r(nNe," (Wav2Vec2 model)"),nNe.forEach(t),Yfr=i(_l),s8=n(_l,"LI",{});var sNe=s(s8);Cve=n(sNe,"STRONG",{});var uAt=s(Cve);Kfr=r(uAt,"wav2vec2-conformer"),uAt.forEach(t),Zfr=r(sNe," \u2014 "),tH=n(sNe,"A",{href:!0});var bAt=s(tH);emr=r(bAt,"Wav2Vec2ConformerForAudioFrameClassification"),bAt.forEach(t),omr=r(sNe," (Wav2Vec2-Conformer model)"),sNe.forEach(t),rmr=i(_l),l8=n(_l,"LI",{});var lNe=s(l8);wve=n(lNe,"STRONG",{});var vAt=s(wve);tmr=r(vAt,"wavlm"),vAt.forEach(t),amr=r(lNe," \u2014 "),aH=n(lNe,"A",{href:!0});var FAt=s(aH);nmr=r(FAt,"WavLMForAudioFrameClassification"),FAt.forEach(t),smr=r(lNe," (WavLM model)"),lNe.forEach(t),_l.forEach(t),lmr=i(Ma),i8=n(Ma,"P",{});var iNe=s(i8);imr=r(iNe,"The model is set in evaluation mode by default using "),Ave=n(iNe,"CODE",{});var TAt=s(Ave);dmr=r(TAt,"model.eval()"),TAt.forEach(t),cmr=r(iNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Lve=n(iNe,"CODE",{});var MAt=s(Lve);fmr=r(MAt,"model.train()"),MAt.forEach(t),iNe.forEach(t),mmr=i(Ma),T(d8.$$.fragment,Ma),Ma.forEach(t),pl.forEach(t),xXe=i(f),Pd=n(f,"H2",{class:!0});var BQe=s(Pd);c8=n(BQe,"A",{id:!0,class:!0,href:!0});var EAt=s(c8);yve=n(EAt,"SPAN",{});var CAt=s(yve);T(Zy.$$.fragment,CAt),CAt.forEach(t),EAt.forEach(t),gmr=i(BQe),xve=n(BQe,"SPAN",{});var wAt=s(xve);hmr=r(wAt,"AutoModelForCTC"),wAt.forEach(t),BQe.forEach(t),$Xe=i(f),Qo=n(f,"DIV",{class:!0});var ul=s(Qo);T(e9.$$.fragment,ul),pmr=i(ul),Bd=n(ul,"P",{});var ote=s(Bd);_mr=r(ote,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),nH=n(ote,"A",{href:!0});var AAt=s(nH);umr=r(AAt,"from_pretrained()"),AAt.forEach(t),bmr=r(ote," class method or the "),sH=n(ote,"A",{href:!0});var LAt=s(sH);vmr=r(LAt,"from_config()"),LAt.forEach(t),Fmr=r(ote,` class
method.`),ote.forEach(t),Tmr=i(ul),o9=n(ul,"P",{});var IQe=s(o9);Mmr=r(IQe,"This class cannot be instantiated directly using "),$ve=n(IQe,"CODE",{});var yAt=s($ve);Emr=r(yAt,"__init__()"),yAt.forEach(t),Cmr=r(IQe," (throws an error)."),IQe.forEach(t),wmr=i(ul),Ct=n(ul,"DIV",{class:!0});var NA=s(Ct);T(r9.$$.fragment,NA),Amr=i(NA),kve=n(NA,"P",{});var xAt=s(kve);Lmr=r(xAt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),xAt.forEach(t),ymr=i(NA),Id=n(NA,"P",{});var rte=s(Id);xmr=r(rte,`Note:
Loading a model from its configuration file does `),Sve=n(rte,"STRONG",{});var $At=s(Sve);$mr=r($At,"not"),$At.forEach(t),kmr=r(rte,` load the model weights. It only affects the
model\u2019s configuration. Use `),lH=n(rte,"A",{href:!0});var kAt=s(lH);Smr=r(kAt,"from_pretrained()"),kAt.forEach(t),Rmr=r(rte," to load the model weights."),rte.forEach(t),Pmr=i(NA),T(f8.$$.fragment,NA),NA.forEach(t),Bmr=i(ul),go=n(ul,"DIV",{class:!0});var Ea=s(go);T(t9.$$.fragment,Ea),Imr=i(Ea),Rve=n(Ea,"P",{});var SAt=s(Rve);Nmr=r(SAt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),SAt.forEach(t),qmr=i(Ea),Ya=n(Ea,"P",{});var qA=s(Ya);jmr=r(qA,"The model class to instantiate is selected based on the "),Pve=n(qA,"CODE",{});var RAt=s(Pve);Dmr=r(RAt,"model_type"),RAt.forEach(t),Gmr=r(qA,` property of the config object (either
passed as an argument or loaded from `),Bve=n(qA,"CODE",{});var PAt=s(Bve);Omr=r(PAt,"pretrained_model_name_or_path"),PAt.forEach(t),Vmr=r(qA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ive=n(qA,"CODE",{});var BAt=s(Ive);Xmr=r(BAt,"pretrained_model_name_or_path"),BAt.forEach(t),zmr=r(qA,":"),qA.forEach(t),Qmr=i(Ea),Le=n(Ea,"UL",{});var Be=s(Le);m8=n(Be,"LI",{});var dNe=s(m8);Nve=n(dNe,"STRONG",{});var IAt=s(Nve);Wmr=r(IAt,"data2vec-audio"),IAt.forEach(t),Hmr=r(dNe," \u2014 "),iH=n(dNe,"A",{href:!0});var NAt=s(iH);Umr=r(NAt,"Data2VecAudioForCTC"),NAt.forEach(t),Jmr=r(dNe," (Data2VecAudio model)"),dNe.forEach(t),Ymr=i(Be),g8=n(Be,"LI",{});var cNe=s(g8);qve=n(cNe,"STRONG",{});var qAt=s(qve);Kmr=r(qAt,"hubert"),qAt.forEach(t),Zmr=r(cNe," \u2014 "),dH=n(cNe,"A",{href:!0});var jAt=s(dH);egr=r(jAt,"HubertForCTC"),jAt.forEach(t),ogr=r(cNe," (Hubert model)"),cNe.forEach(t),rgr=i(Be),h8=n(Be,"LI",{});var fNe=s(h8);jve=n(fNe,"STRONG",{});var DAt=s(jve);tgr=r(DAt,"mctct"),DAt.forEach(t),agr=r(fNe," \u2014 "),cH=n(fNe,"A",{href:!0});var GAt=s(cH);ngr=r(GAt,"MCTCTForCTC"),GAt.forEach(t),sgr=r(fNe," (M-CTC-T model)"),fNe.forEach(t),lgr=i(Be),p8=n(Be,"LI",{});var mNe=s(p8);Dve=n(mNe,"STRONG",{});var OAt=s(Dve);igr=r(OAt,"sew"),OAt.forEach(t),dgr=r(mNe," \u2014 "),fH=n(mNe,"A",{href:!0});var VAt=s(fH);cgr=r(VAt,"SEWForCTC"),VAt.forEach(t),fgr=r(mNe," (SEW model)"),mNe.forEach(t),mgr=i(Be),_8=n(Be,"LI",{});var gNe=s(_8);Gve=n(gNe,"STRONG",{});var XAt=s(Gve);ggr=r(XAt,"sew-d"),XAt.forEach(t),hgr=r(gNe," \u2014 "),mH=n(gNe,"A",{href:!0});var zAt=s(mH);pgr=r(zAt,"SEWDForCTC"),zAt.forEach(t),_gr=r(gNe," (SEW-D model)"),gNe.forEach(t),ugr=i(Be),u8=n(Be,"LI",{});var hNe=s(u8);Ove=n(hNe,"STRONG",{});var QAt=s(Ove);bgr=r(QAt,"unispeech"),QAt.forEach(t),vgr=r(hNe," \u2014 "),gH=n(hNe,"A",{href:!0});var WAt=s(gH);Fgr=r(WAt,"UniSpeechForCTC"),WAt.forEach(t),Tgr=r(hNe," (UniSpeech model)"),hNe.forEach(t),Mgr=i(Be),b8=n(Be,"LI",{});var pNe=s(b8);Vve=n(pNe,"STRONG",{});var HAt=s(Vve);Egr=r(HAt,"unispeech-sat"),HAt.forEach(t),Cgr=r(pNe," \u2014 "),hH=n(pNe,"A",{href:!0});var UAt=s(hH);wgr=r(UAt,"UniSpeechSatForCTC"),UAt.forEach(t),Agr=r(pNe," (UniSpeechSat model)"),pNe.forEach(t),Lgr=i(Be),v8=n(Be,"LI",{});var _Ne=s(v8);Xve=n(_Ne,"STRONG",{});var JAt=s(Xve);ygr=r(JAt,"wav2vec2"),JAt.forEach(t),xgr=r(_Ne," \u2014 "),pH=n(_Ne,"A",{href:!0});var YAt=s(pH);$gr=r(YAt,"Wav2Vec2ForCTC"),YAt.forEach(t),kgr=r(_Ne," (Wav2Vec2 model)"),_Ne.forEach(t),Sgr=i(Be),F8=n(Be,"LI",{});var uNe=s(F8);zve=n(uNe,"STRONG",{});var KAt=s(zve);Rgr=r(KAt,"wav2vec2-conformer"),KAt.forEach(t),Pgr=r(uNe," \u2014 "),_H=n(uNe,"A",{href:!0});var ZAt=s(_H);Bgr=r(ZAt,"Wav2Vec2ConformerForCTC"),ZAt.forEach(t),Igr=r(uNe," (Wav2Vec2-Conformer model)"),uNe.forEach(t),Ngr=i(Be),T8=n(Be,"LI",{});var bNe=s(T8);Qve=n(bNe,"STRONG",{});var e6t=s(Qve);qgr=r(e6t,"wavlm"),e6t.forEach(t),jgr=r(bNe," \u2014 "),uH=n(bNe,"A",{href:!0});var o6t=s(uH);Dgr=r(o6t,"WavLMForCTC"),o6t.forEach(t),Ggr=r(bNe," (WavLM model)"),bNe.forEach(t),Be.forEach(t),Ogr=i(Ea),M8=n(Ea,"P",{});var vNe=s(M8);Vgr=r(vNe,"The model is set in evaluation mode by default using "),Wve=n(vNe,"CODE",{});var r6t=s(Wve);Xgr=r(r6t,"model.eval()"),r6t.forEach(t),zgr=r(vNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Hve=n(vNe,"CODE",{});var t6t=s(Hve);Qgr=r(t6t,"model.train()"),t6t.forEach(t),vNe.forEach(t),Wgr=i(Ea),T(E8.$$.fragment,Ea),Ea.forEach(t),ul.forEach(t),kXe=i(f),Nd=n(f,"H2",{class:!0});var NQe=s(Nd);C8=n(NQe,"A",{id:!0,class:!0,href:!0});var a6t=s(C8);Uve=n(a6t,"SPAN",{});var n6t=s(Uve);T(a9.$$.fragment,n6t),n6t.forEach(t),a6t.forEach(t),Hgr=i(NQe),Jve=n(NQe,"SPAN",{});var s6t=s(Jve);Ugr=r(s6t,"AutoModelForSpeechSeq2Seq"),s6t.forEach(t),NQe.forEach(t),SXe=i(f),Wo=n(f,"DIV",{class:!0});var bl=s(Wo);T(n9.$$.fragment,bl),Jgr=i(bl),qd=n(bl,"P",{});var tte=s(qd);Ygr=r(tte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),bH=n(tte,"A",{href:!0});var l6t=s(bH);Kgr=r(l6t,"from_pretrained()"),l6t.forEach(t),Zgr=r(tte," class method or the "),vH=n(tte,"A",{href:!0});var i6t=s(vH);ehr=r(i6t,"from_config()"),i6t.forEach(t),ohr=r(tte,` class
method.`),tte.forEach(t),rhr=i(bl),s9=n(bl,"P",{});var qQe=s(s9);thr=r(qQe,"This class cannot be instantiated directly using "),Yve=n(qQe,"CODE",{});var d6t=s(Yve);ahr=r(d6t,"__init__()"),d6t.forEach(t),nhr=r(qQe," (throws an error)."),qQe.forEach(t),shr=i(bl),wt=n(bl,"DIV",{class:!0});var jA=s(wt);T(l9.$$.fragment,jA),lhr=i(jA),Kve=n(jA,"P",{});var c6t=s(Kve);ihr=r(c6t,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),c6t.forEach(t),dhr=i(jA),jd=n(jA,"P",{});var ate=s(jd);chr=r(ate,`Note:
Loading a model from its configuration file does `),Zve=n(ate,"STRONG",{});var f6t=s(Zve);fhr=r(f6t,"not"),f6t.forEach(t),mhr=r(ate,` load the model weights. It only affects the
model\u2019s configuration. Use `),FH=n(ate,"A",{href:!0});var m6t=s(FH);ghr=r(m6t,"from_pretrained()"),m6t.forEach(t),hhr=r(ate," to load the model weights."),ate.forEach(t),phr=i(jA),T(w8.$$.fragment,jA),jA.forEach(t),_hr=i(bl),ho=n(bl,"DIV",{class:!0});var Ca=s(ho);T(i9.$$.fragment,Ca),uhr=i(Ca),eFe=n(Ca,"P",{});var g6t=s(eFe);bhr=r(g6t,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),g6t.forEach(t),vhr=i(Ca),Ka=n(Ca,"P",{});var DA=s(Ka);Fhr=r(DA,"The model class to instantiate is selected based on the "),oFe=n(DA,"CODE",{});var h6t=s(oFe);Thr=r(h6t,"model_type"),h6t.forEach(t),Mhr=r(DA,` property of the config object (either
passed as an argument or loaded from `),rFe=n(DA,"CODE",{});var p6t=s(rFe);Ehr=r(p6t,"pretrained_model_name_or_path"),p6t.forEach(t),Chr=r(DA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tFe=n(DA,"CODE",{});var _6t=s(tFe);whr=r(_6t,"pretrained_model_name_or_path"),_6t.forEach(t),Ahr=r(DA,":"),DA.forEach(t),Lhr=i(Ca),d9=n(Ca,"UL",{});var jQe=s(d9);A8=n(jQe,"LI",{});var FNe=s(A8);aFe=n(FNe,"STRONG",{});var u6t=s(aFe);yhr=r(u6t,"speech-encoder-decoder"),u6t.forEach(t),xhr=r(FNe," \u2014 "),TH=n(FNe,"A",{href:!0});var b6t=s(TH);$hr=r(b6t,"SpeechEncoderDecoderModel"),b6t.forEach(t),khr=r(FNe," (Speech Encoder decoder model)"),FNe.forEach(t),Shr=i(jQe),L8=n(jQe,"LI",{});var TNe=s(L8);nFe=n(TNe,"STRONG",{});var v6t=s(nFe);Rhr=r(v6t,"speech_to_text"),v6t.forEach(t),Phr=r(TNe," \u2014 "),MH=n(TNe,"A",{href:!0});var F6t=s(MH);Bhr=r(F6t,"Speech2TextForConditionalGeneration"),F6t.forEach(t),Ihr=r(TNe," (Speech2Text model)"),TNe.forEach(t),jQe.forEach(t),Nhr=i(Ca),y8=n(Ca,"P",{});var MNe=s(y8);qhr=r(MNe,"The model is set in evaluation mode by default using "),sFe=n(MNe,"CODE",{});var T6t=s(sFe);jhr=r(T6t,"model.eval()"),T6t.forEach(t),Dhr=r(MNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lFe=n(MNe,"CODE",{});var M6t=s(lFe);Ghr=r(M6t,"model.train()"),M6t.forEach(t),MNe.forEach(t),Ohr=i(Ca),T(x8.$$.fragment,Ca),Ca.forEach(t),bl.forEach(t),RXe=i(f),Dd=n(f,"H2",{class:!0});var DQe=s(Dd);$8=n(DQe,"A",{id:!0,class:!0,href:!0});var E6t=s($8);iFe=n(E6t,"SPAN",{});var C6t=s(iFe);T(c9.$$.fragment,C6t),C6t.forEach(t),E6t.forEach(t),Vhr=i(DQe),dFe=n(DQe,"SPAN",{});var w6t=s(dFe);Xhr=r(w6t,"AutoModelForAudioXVector"),w6t.forEach(t),DQe.forEach(t),PXe=i(f),Ho=n(f,"DIV",{class:!0});var vl=s(Ho);T(f9.$$.fragment,vl),zhr=i(vl),Gd=n(vl,"P",{});var nte=s(Gd);Qhr=r(nte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),EH=n(nte,"A",{href:!0});var A6t=s(EH);Whr=r(A6t,"from_pretrained()"),A6t.forEach(t),Hhr=r(nte," class method or the "),CH=n(nte,"A",{href:!0});var L6t=s(CH);Uhr=r(L6t,"from_config()"),L6t.forEach(t),Jhr=r(nte,` class
method.`),nte.forEach(t),Yhr=i(vl),m9=n(vl,"P",{});var GQe=s(m9);Khr=r(GQe,"This class cannot be instantiated directly using "),cFe=n(GQe,"CODE",{});var y6t=s(cFe);Zhr=r(y6t,"__init__()"),y6t.forEach(t),epr=r(GQe," (throws an error)."),GQe.forEach(t),opr=i(vl),At=n(vl,"DIV",{class:!0});var GA=s(At);T(g9.$$.fragment,GA),rpr=i(GA),fFe=n(GA,"P",{});var x6t=s(fFe);tpr=r(x6t,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),x6t.forEach(t),apr=i(GA),Od=n(GA,"P",{});var ste=s(Od);npr=r(ste,`Note:
Loading a model from its configuration file does `),mFe=n(ste,"STRONG",{});var $6t=s(mFe);spr=r($6t,"not"),$6t.forEach(t),lpr=r(ste,` load the model weights. It only affects the
model\u2019s configuration. Use `),wH=n(ste,"A",{href:!0});var k6t=s(wH);ipr=r(k6t,"from_pretrained()"),k6t.forEach(t),dpr=r(ste," to load the model weights."),ste.forEach(t),cpr=i(GA),T(k8.$$.fragment,GA),GA.forEach(t),fpr=i(vl),po=n(vl,"DIV",{class:!0});var wa=s(po);T(h9.$$.fragment,wa),mpr=i(wa),gFe=n(wa,"P",{});var S6t=s(gFe);gpr=r(S6t,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),S6t.forEach(t),hpr=i(wa),Za=n(wa,"P",{});var OA=s(Za);ppr=r(OA,"The model class to instantiate is selected based on the "),hFe=n(OA,"CODE",{});var R6t=s(hFe);_pr=r(R6t,"model_type"),R6t.forEach(t),upr=r(OA,` property of the config object (either
passed as an argument or loaded from `),pFe=n(OA,"CODE",{});var P6t=s(pFe);bpr=r(P6t,"pretrained_model_name_or_path"),P6t.forEach(t),vpr=r(OA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Fe=n(OA,"CODE",{});var B6t=s(_Fe);Fpr=r(B6t,"pretrained_model_name_or_path"),B6t.forEach(t),Tpr=r(OA,":"),OA.forEach(t),Mpr=i(wa),ot=n(wa,"UL",{});var Fl=s(ot);S8=n(Fl,"LI",{});var ENe=s(S8);uFe=n(ENe,"STRONG",{});var I6t=s(uFe);Epr=r(I6t,"data2vec-audio"),I6t.forEach(t),Cpr=r(ENe," \u2014 "),AH=n(ENe,"A",{href:!0});var N6t=s(AH);wpr=r(N6t,"Data2VecAudioForXVector"),N6t.forEach(t),Apr=r(ENe," (Data2VecAudio model)"),ENe.forEach(t),Lpr=i(Fl),R8=n(Fl,"LI",{});var CNe=s(R8);bFe=n(CNe,"STRONG",{});var q6t=s(bFe);ypr=r(q6t,"unispeech-sat"),q6t.forEach(t),xpr=r(CNe," \u2014 "),LH=n(CNe,"A",{href:!0});var j6t=s(LH);$pr=r(j6t,"UniSpeechSatForXVector"),j6t.forEach(t),kpr=r(CNe," (UniSpeechSat model)"),CNe.forEach(t),Spr=i(Fl),P8=n(Fl,"LI",{});var wNe=s(P8);vFe=n(wNe,"STRONG",{});var D6t=s(vFe);Rpr=r(D6t,"wav2vec2"),D6t.forEach(t),Ppr=r(wNe," \u2014 "),yH=n(wNe,"A",{href:!0});var G6t=s(yH);Bpr=r(G6t,"Wav2Vec2ForXVector"),G6t.forEach(t),Ipr=r(wNe," (Wav2Vec2 model)"),wNe.forEach(t),Npr=i(Fl),B8=n(Fl,"LI",{});var ANe=s(B8);FFe=n(ANe,"STRONG",{});var O6t=s(FFe);qpr=r(O6t,"wav2vec2-conformer"),O6t.forEach(t),jpr=r(ANe," \u2014 "),xH=n(ANe,"A",{href:!0});var V6t=s(xH);Dpr=r(V6t,"Wav2Vec2ConformerForXVector"),V6t.forEach(t),Gpr=r(ANe," (Wav2Vec2-Conformer model)"),ANe.forEach(t),Opr=i(Fl),I8=n(Fl,"LI",{});var LNe=s(I8);TFe=n(LNe,"STRONG",{});var X6t=s(TFe);Vpr=r(X6t,"wavlm"),X6t.forEach(t),Xpr=r(LNe," \u2014 "),$H=n(LNe,"A",{href:!0});var z6t=s($H);zpr=r(z6t,"WavLMForXVector"),z6t.forEach(t),Qpr=r(LNe," (WavLM model)"),LNe.forEach(t),Fl.forEach(t),Wpr=i(wa),N8=n(wa,"P",{});var yNe=s(N8);Hpr=r(yNe,"The model is set in evaluation mode by default using "),MFe=n(yNe,"CODE",{});var Q6t=s(MFe);Upr=r(Q6t,"model.eval()"),Q6t.forEach(t),Jpr=r(yNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),EFe=n(yNe,"CODE",{});var W6t=s(EFe);Ypr=r(W6t,"model.train()"),W6t.forEach(t),yNe.forEach(t),Kpr=i(wa),T(q8.$$.fragment,wa),wa.forEach(t),vl.forEach(t),BXe=i(f),Vd=n(f,"H2",{class:!0});var OQe=s(Vd);j8=n(OQe,"A",{id:!0,class:!0,href:!0});var H6t=s(j8);CFe=n(H6t,"SPAN",{});var U6t=s(CFe);T(p9.$$.fragment,U6t),U6t.forEach(t),H6t.forEach(t),Zpr=i(OQe),wFe=n(OQe,"SPAN",{});var J6t=s(wFe);e_r=r(J6t,"AutoModelForMaskedImageModeling"),J6t.forEach(t),OQe.forEach(t),IXe=i(f),Uo=n(f,"DIV",{class:!0});var Tl=s(Uo);T(_9.$$.fragment,Tl),o_r=i(Tl),Xd=n(Tl,"P",{});var lte=s(Xd);r_r=r(lte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),kH=n(lte,"A",{href:!0});var Y6t=s(kH);t_r=r(Y6t,"from_pretrained()"),Y6t.forEach(t),a_r=r(lte," class method or the "),SH=n(lte,"A",{href:!0});var K6t=s(SH);n_r=r(K6t,"from_config()"),K6t.forEach(t),s_r=r(lte,` class
method.`),lte.forEach(t),l_r=i(Tl),u9=n(Tl,"P",{});var VQe=s(u9);i_r=r(VQe,"This class cannot be instantiated directly using "),AFe=n(VQe,"CODE",{});var Z6t=s(AFe);d_r=r(Z6t,"__init__()"),Z6t.forEach(t),c_r=r(VQe," (throws an error)."),VQe.forEach(t),f_r=i(Tl),Lt=n(Tl,"DIV",{class:!0});var VA=s(Lt);T(b9.$$.fragment,VA),m_r=i(VA),LFe=n(VA,"P",{});var eLt=s(LFe);g_r=r(eLt,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),eLt.forEach(t),h_r=i(VA),zd=n(VA,"P",{});var ite=s(zd);p_r=r(ite,`Note:
Loading a model from its configuration file does `),yFe=n(ite,"STRONG",{});var oLt=s(yFe);__r=r(oLt,"not"),oLt.forEach(t),u_r=r(ite,` load the model weights. It only affects the
model\u2019s configuration. Use `),RH=n(ite,"A",{href:!0});var rLt=s(RH);b_r=r(rLt,"from_pretrained()"),rLt.forEach(t),v_r=r(ite," to load the model weights."),ite.forEach(t),F_r=i(VA),T(D8.$$.fragment,VA),VA.forEach(t),T_r=i(Tl),_o=n(Tl,"DIV",{class:!0});var Aa=s(_o);T(v9.$$.fragment,Aa),M_r=i(Aa),xFe=n(Aa,"P",{});var tLt=s(xFe);E_r=r(tLt,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),tLt.forEach(t),C_r=i(Aa),en=n(Aa,"P",{});var XA=s(en);w_r=r(XA,"The model class to instantiate is selected based on the "),$Fe=n(XA,"CODE",{});var aLt=s($Fe);A_r=r(aLt,"model_type"),aLt.forEach(t),L_r=r(XA,` property of the config object (either
passed as an argument or loaded from `),kFe=n(XA,"CODE",{});var nLt=s(kFe);y_r=r(nLt,"pretrained_model_name_or_path"),nLt.forEach(t),x_r=r(XA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SFe=n(XA,"CODE",{});var sLt=s(SFe);$_r=r(sLt,"pretrained_model_name_or_path"),sLt.forEach(t),k_r=r(XA,":"),XA.forEach(t),S_r=i(Aa),Qd=n(Aa,"UL",{});var dte=s(Qd);G8=n(dte,"LI",{});var xNe=s(G8);RFe=n(xNe,"STRONG",{});var lLt=s(RFe);R_r=r(lLt,"deit"),lLt.forEach(t),P_r=r(xNe," \u2014 "),PH=n(xNe,"A",{href:!0});var iLt=s(PH);B_r=r(iLt,"DeiTForMaskedImageModeling"),iLt.forEach(t),I_r=r(xNe," (DeiT model)"),xNe.forEach(t),N_r=i(dte),O8=n(dte,"LI",{});var $Ne=s(O8);PFe=n($Ne,"STRONG",{});var dLt=s(PFe);q_r=r(dLt,"swin"),dLt.forEach(t),j_r=r($Ne," \u2014 "),BH=n($Ne,"A",{href:!0});var cLt=s(BH);D_r=r(cLt,"SwinForMaskedImageModeling"),cLt.forEach(t),G_r=r($Ne," (Swin Transformer model)"),$Ne.forEach(t),O_r=i(dte),V8=n(dte,"LI",{});var kNe=s(V8);BFe=n(kNe,"STRONG",{});var fLt=s(BFe);V_r=r(fLt,"vit"),fLt.forEach(t),X_r=r(kNe," \u2014 "),IH=n(kNe,"A",{href:!0});var mLt=s(IH);z_r=r(mLt,"ViTForMaskedImageModeling"),mLt.forEach(t),Q_r=r(kNe," (ViT model)"),kNe.forEach(t),dte.forEach(t),W_r=i(Aa),X8=n(Aa,"P",{});var SNe=s(X8);H_r=r(SNe,"The model is set in evaluation mode by default using "),IFe=n(SNe,"CODE",{});var gLt=s(IFe);U_r=r(gLt,"model.eval()"),gLt.forEach(t),J_r=r(SNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),NFe=n(SNe,"CODE",{});var hLt=s(NFe);Y_r=r(hLt,"model.train()"),hLt.forEach(t),SNe.forEach(t),K_r=i(Aa),T(z8.$$.fragment,Aa),Aa.forEach(t),Tl.forEach(t),NXe=i(f),Wd=n(f,"H2",{class:!0});var XQe=s(Wd);Q8=n(XQe,"A",{id:!0,class:!0,href:!0});var pLt=s(Q8);qFe=n(pLt,"SPAN",{});var _Lt=s(qFe);T(F9.$$.fragment,_Lt),_Lt.forEach(t),pLt.forEach(t),Z_r=i(XQe),jFe=n(XQe,"SPAN",{});var uLt=s(jFe);eur=r(uLt,"AutoModelForObjectDetection"),uLt.forEach(t),XQe.forEach(t),qXe=i(f),Jo=n(f,"DIV",{class:!0});var Ml=s(Jo);T(T9.$$.fragment,Ml),our=i(Ml),Hd=n(Ml,"P",{});var cte=s(Hd);rur=r(cte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),NH=n(cte,"A",{href:!0});var bLt=s(NH);tur=r(bLt,"from_pretrained()"),bLt.forEach(t),aur=r(cte," class method or the "),qH=n(cte,"A",{href:!0});var vLt=s(qH);nur=r(vLt,"from_config()"),vLt.forEach(t),sur=r(cte,` class
method.`),cte.forEach(t),lur=i(Ml),M9=n(Ml,"P",{});var zQe=s(M9);iur=r(zQe,"This class cannot be instantiated directly using "),DFe=n(zQe,"CODE",{});var FLt=s(DFe);dur=r(FLt,"__init__()"),FLt.forEach(t),cur=r(zQe," (throws an error)."),zQe.forEach(t),fur=i(Ml),yt=n(Ml,"DIV",{class:!0});var zA=s(yt);T(E9.$$.fragment,zA),mur=i(zA),GFe=n(zA,"P",{});var TLt=s(GFe);gur=r(TLt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),TLt.forEach(t),hur=i(zA),Ud=n(zA,"P",{});var fte=s(Ud);pur=r(fte,`Note:
Loading a model from its configuration file does `),OFe=n(fte,"STRONG",{});var MLt=s(OFe);_ur=r(MLt,"not"),MLt.forEach(t),uur=r(fte,` load the model weights. It only affects the
model\u2019s configuration. Use `),jH=n(fte,"A",{href:!0});var ELt=s(jH);bur=r(ELt,"from_pretrained()"),ELt.forEach(t),vur=r(fte," to load the model weights."),fte.forEach(t),Fur=i(zA),T(W8.$$.fragment,zA),zA.forEach(t),Tur=i(Ml),uo=n(Ml,"DIV",{class:!0});var La=s(uo);T(C9.$$.fragment,La),Mur=i(La),VFe=n(La,"P",{});var CLt=s(VFe);Eur=r(CLt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),CLt.forEach(t),Cur=i(La),on=n(La,"P",{});var QA=s(on);wur=r(QA,"The model class to instantiate is selected based on the "),XFe=n(QA,"CODE",{});var wLt=s(XFe);Aur=r(wLt,"model_type"),wLt.forEach(t),Lur=r(QA,` property of the config object (either
passed as an argument or loaded from `),zFe=n(QA,"CODE",{});var ALt=s(zFe);yur=r(ALt,"pretrained_model_name_or_path"),ALt.forEach(t),xur=r(QA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QFe=n(QA,"CODE",{});var LLt=s(QFe);$ur=r(LLt,"pretrained_model_name_or_path"),LLt.forEach(t),kur=r(QA,":"),QA.forEach(t),Sur=i(La),w9=n(La,"UL",{});var QQe=s(w9);H8=n(QQe,"LI",{});var RNe=s(H8);WFe=n(RNe,"STRONG",{});var yLt=s(WFe);Rur=r(yLt,"detr"),yLt.forEach(t),Pur=r(RNe," \u2014 "),DH=n(RNe,"A",{href:!0});var xLt=s(DH);Bur=r(xLt,"DetrForObjectDetection"),xLt.forEach(t),Iur=r(RNe," (DETR model)"),RNe.forEach(t),Nur=i(QQe),U8=n(QQe,"LI",{});var PNe=s(U8);HFe=n(PNe,"STRONG",{});var $Lt=s(HFe);qur=r($Lt,"yolos"),$Lt.forEach(t),jur=r(PNe," \u2014 "),GH=n(PNe,"A",{href:!0});var kLt=s(GH);Dur=r(kLt,"YolosForObjectDetection"),kLt.forEach(t),Gur=r(PNe," (YOLOS model)"),PNe.forEach(t),QQe.forEach(t),Our=i(La),J8=n(La,"P",{});var BNe=s(J8);Vur=r(BNe,"The model is set in evaluation mode by default using "),UFe=n(BNe,"CODE",{});var SLt=s(UFe);Xur=r(SLt,"model.eval()"),SLt.forEach(t),zur=r(BNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),JFe=n(BNe,"CODE",{});var RLt=s(JFe);Qur=r(RLt,"model.train()"),RLt.forEach(t),BNe.forEach(t),Wur=i(La),T(Y8.$$.fragment,La),La.forEach(t),Ml.forEach(t),jXe=i(f),Jd=n(f,"H2",{class:!0});var WQe=s(Jd);K8=n(WQe,"A",{id:!0,class:!0,href:!0});var PLt=s(K8);YFe=n(PLt,"SPAN",{});var BLt=s(YFe);T(A9.$$.fragment,BLt),BLt.forEach(t),PLt.forEach(t),Hur=i(WQe),KFe=n(WQe,"SPAN",{});var ILt=s(KFe);Uur=r(ILt,"AutoModelForImageSegmentation"),ILt.forEach(t),WQe.forEach(t),DXe=i(f),Yo=n(f,"DIV",{class:!0});var El=s(Yo);T(L9.$$.fragment,El),Jur=i(El),Yd=n(El,"P",{});var mte=s(Yd);Yur=r(mte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),OH=n(mte,"A",{href:!0});var NLt=s(OH);Kur=r(NLt,"from_pretrained()"),NLt.forEach(t),Zur=r(mte," class method or the "),VH=n(mte,"A",{href:!0});var qLt=s(VH);e1r=r(qLt,"from_config()"),qLt.forEach(t),o1r=r(mte,` class
method.`),mte.forEach(t),r1r=i(El),y9=n(El,"P",{});var HQe=s(y9);t1r=r(HQe,"This class cannot be instantiated directly using "),ZFe=n(HQe,"CODE",{});var jLt=s(ZFe);a1r=r(jLt,"__init__()"),jLt.forEach(t),n1r=r(HQe," (throws an error)."),HQe.forEach(t),s1r=i(El),xt=n(El,"DIV",{class:!0});var WA=s(xt);T(x9.$$.fragment,WA),l1r=i(WA),eTe=n(WA,"P",{});var DLt=s(eTe);i1r=r(DLt,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),DLt.forEach(t),d1r=i(WA),Kd=n(WA,"P",{});var gte=s(Kd);c1r=r(gte,`Note:
Loading a model from its configuration file does `),oTe=n(gte,"STRONG",{});var GLt=s(oTe);f1r=r(GLt,"not"),GLt.forEach(t),m1r=r(gte,` load the model weights. It only affects the
model\u2019s configuration. Use `),XH=n(gte,"A",{href:!0});var OLt=s(XH);g1r=r(OLt,"from_pretrained()"),OLt.forEach(t),h1r=r(gte," to load the model weights."),gte.forEach(t),p1r=i(WA),T(Z8.$$.fragment,WA),WA.forEach(t),_1r=i(El),bo=n(El,"DIV",{class:!0});var ya=s(bo);T($9.$$.fragment,ya),u1r=i(ya),rTe=n(ya,"P",{});var VLt=s(rTe);b1r=r(VLt,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),VLt.forEach(t),v1r=i(ya),rn=n(ya,"P",{});var HA=s(rn);F1r=r(HA,"The model class to instantiate is selected based on the "),tTe=n(HA,"CODE",{});var XLt=s(tTe);T1r=r(XLt,"model_type"),XLt.forEach(t),M1r=r(HA,` property of the config object (either
passed as an argument or loaded from `),aTe=n(HA,"CODE",{});var zLt=s(aTe);E1r=r(zLt,"pretrained_model_name_or_path"),zLt.forEach(t),C1r=r(HA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nTe=n(HA,"CODE",{});var QLt=s(nTe);w1r=r(QLt,"pretrained_model_name_or_path"),QLt.forEach(t),A1r=r(HA,":"),HA.forEach(t),L1r=i(ya),sTe=n(ya,"UL",{});var WLt=s(sTe);eM=n(WLt,"LI",{});var INe=s(eM);lTe=n(INe,"STRONG",{});var HLt=s(lTe);y1r=r(HLt,"detr"),HLt.forEach(t),x1r=r(INe," \u2014 "),zH=n(INe,"A",{href:!0});var ULt=s(zH);$1r=r(ULt,"DetrForSegmentation"),ULt.forEach(t),k1r=r(INe," (DETR model)"),INe.forEach(t),WLt.forEach(t),S1r=i(ya),oM=n(ya,"P",{});var NNe=s(oM);R1r=r(NNe,"The model is set in evaluation mode by default using "),iTe=n(NNe,"CODE",{});var JLt=s(iTe);P1r=r(JLt,"model.eval()"),JLt.forEach(t),B1r=r(NNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dTe=n(NNe,"CODE",{});var YLt=s(dTe);I1r=r(YLt,"model.train()"),YLt.forEach(t),NNe.forEach(t),N1r=i(ya),T(rM.$$.fragment,ya),ya.forEach(t),El.forEach(t),GXe=i(f),Zd=n(f,"H2",{class:!0});var UQe=s(Zd);tM=n(UQe,"A",{id:!0,class:!0,href:!0});var KLt=s(tM);cTe=n(KLt,"SPAN",{});var ZLt=s(cTe);T(k9.$$.fragment,ZLt),ZLt.forEach(t),KLt.forEach(t),q1r=i(UQe),fTe=n(UQe,"SPAN",{});var eyt=s(fTe);j1r=r(eyt,"AutoModelForSemanticSegmentation"),eyt.forEach(t),UQe.forEach(t),OXe=i(f),Ko=n(f,"DIV",{class:!0});var Cl=s(Ko);T(S9.$$.fragment,Cl),D1r=i(Cl),ec=n(Cl,"P",{});var hte=s(ec);G1r=r(hte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),QH=n(hte,"A",{href:!0});var oyt=s(QH);O1r=r(oyt,"from_pretrained()"),oyt.forEach(t),V1r=r(hte," class method or the "),WH=n(hte,"A",{href:!0});var ryt=s(WH);X1r=r(ryt,"from_config()"),ryt.forEach(t),z1r=r(hte,` class
method.`),hte.forEach(t),Q1r=i(Cl),R9=n(Cl,"P",{});var JQe=s(R9);W1r=r(JQe,"This class cannot be instantiated directly using "),mTe=n(JQe,"CODE",{});var tyt=s(mTe);H1r=r(tyt,"__init__()"),tyt.forEach(t),U1r=r(JQe," (throws an error)."),JQe.forEach(t),J1r=i(Cl),$t=n(Cl,"DIV",{class:!0});var UA=s($t);T(P9.$$.fragment,UA),Y1r=i(UA),gTe=n(UA,"P",{});var ayt=s(gTe);K1r=r(ayt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),ayt.forEach(t),Z1r=i(UA),oc=n(UA,"P",{});var pte=s(oc);e2r=r(pte,`Note:
Loading a model from its configuration file does `),hTe=n(pte,"STRONG",{});var nyt=s(hTe);o2r=r(nyt,"not"),nyt.forEach(t),r2r=r(pte,` load the model weights. It only affects the
model\u2019s configuration. Use `),HH=n(pte,"A",{href:!0});var syt=s(HH);t2r=r(syt,"from_pretrained()"),syt.forEach(t),a2r=r(pte," to load the model weights."),pte.forEach(t),n2r=i(UA),T(aM.$$.fragment,UA),UA.forEach(t),s2r=i(Cl),vo=n(Cl,"DIV",{class:!0});var xa=s(vo);T(B9.$$.fragment,xa),l2r=i(xa),pTe=n(xa,"P",{});var lyt=s(pTe);i2r=r(lyt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),lyt.forEach(t),d2r=i(xa),tn=n(xa,"P",{});var JA=s(tn);c2r=r(JA,"The model class to instantiate is selected based on the "),_Te=n(JA,"CODE",{});var iyt=s(_Te);f2r=r(iyt,"model_type"),iyt.forEach(t),m2r=r(JA,` property of the config object (either
passed as an argument or loaded from `),uTe=n(JA,"CODE",{});var dyt=s(uTe);g2r=r(dyt,"pretrained_model_name_or_path"),dyt.forEach(t),h2r=r(JA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bTe=n(JA,"CODE",{});var cyt=s(bTe);p2r=r(cyt,"pretrained_model_name_or_path"),cyt.forEach(t),_2r=r(JA,":"),JA.forEach(t),u2r=i(xa),rt=n(xa,"UL",{});var wl=s(rt);nM=n(wl,"LI",{});var qNe=s(nM);vTe=n(qNe,"STRONG",{});var fyt=s(vTe);b2r=r(fyt,"beit"),fyt.forEach(t),v2r=r(qNe," \u2014 "),UH=n(qNe,"A",{href:!0});var myt=s(UH);F2r=r(myt,"BeitForSemanticSegmentation"),myt.forEach(t),T2r=r(qNe," (BEiT model)"),qNe.forEach(t),M2r=i(wl),sM=n(wl,"LI",{});var jNe=s(sM);FTe=n(jNe,"STRONG",{});var gyt=s(FTe);E2r=r(gyt,"data2vec-vision"),gyt.forEach(t),C2r=r(jNe," \u2014 "),JH=n(jNe,"A",{href:!0});var hyt=s(JH);w2r=r(hyt,"Data2VecVisionForSemanticSegmentation"),hyt.forEach(t),A2r=r(jNe," (Data2VecVision model)"),jNe.forEach(t),L2r=i(wl),lM=n(wl,"LI",{});var DNe=s(lM);TTe=n(DNe,"STRONG",{});var pyt=s(TTe);y2r=r(pyt,"dpt"),pyt.forEach(t),x2r=r(DNe," \u2014 "),YH=n(DNe,"A",{href:!0});var _yt=s(YH);$2r=r(_yt,"DPTForSemanticSegmentation"),_yt.forEach(t),k2r=r(DNe," (DPT model)"),DNe.forEach(t),S2r=i(wl),iM=n(wl,"LI",{});var GNe=s(iM);MTe=n(GNe,"STRONG",{});var uyt=s(MTe);R2r=r(uyt,"mobilevit"),uyt.forEach(t),P2r=r(GNe," \u2014 "),KH=n(GNe,"A",{href:!0});var byt=s(KH);B2r=r(byt,"MobileViTForSemanticSegmentation"),byt.forEach(t),I2r=r(GNe," (MobileViT model)"),GNe.forEach(t),N2r=i(wl),dM=n(wl,"LI",{});var ONe=s(dM);ETe=n(ONe,"STRONG",{});var vyt=s(ETe);q2r=r(vyt,"segformer"),vyt.forEach(t),j2r=r(ONe," \u2014 "),ZH=n(ONe,"A",{href:!0});var Fyt=s(ZH);D2r=r(Fyt,"SegformerForSemanticSegmentation"),Fyt.forEach(t),G2r=r(ONe," (SegFormer model)"),ONe.forEach(t),wl.forEach(t),O2r=i(xa),cM=n(xa,"P",{});var VNe=s(cM);V2r=r(VNe,"The model is set in evaluation mode by default using "),CTe=n(VNe,"CODE",{});var Tyt=s(CTe);X2r=r(Tyt,"model.eval()"),Tyt.forEach(t),z2r=r(VNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),wTe=n(VNe,"CODE",{});var Myt=s(wTe);Q2r=r(Myt,"model.train()"),Myt.forEach(t),VNe.forEach(t),W2r=i(xa),T(fM.$$.fragment,xa),xa.forEach(t),Cl.forEach(t),VXe=i(f),rc=n(f,"H2",{class:!0});var YQe=s(rc);mM=n(YQe,"A",{id:!0,class:!0,href:!0});var Eyt=s(mM);ATe=n(Eyt,"SPAN",{});var Cyt=s(ATe);T(I9.$$.fragment,Cyt),Cyt.forEach(t),Eyt.forEach(t),H2r=i(YQe),LTe=n(YQe,"SPAN",{});var wyt=s(LTe);U2r=r(wyt,"AutoModelForInstanceSegmentation"),wyt.forEach(t),YQe.forEach(t),XXe=i(f),Zo=n(f,"DIV",{class:!0});var Al=s(Zo);T(N9.$$.fragment,Al),J2r=i(Al),tc=n(Al,"P",{});var _te=s(tc);Y2r=r(_te,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),eU=n(_te,"A",{href:!0});var Ayt=s(eU);K2r=r(Ayt,"from_pretrained()"),Ayt.forEach(t),Z2r=r(_te," class method or the "),oU=n(_te,"A",{href:!0});var Lyt=s(oU);ebr=r(Lyt,"from_config()"),Lyt.forEach(t),obr=r(_te,` class
method.`),_te.forEach(t),rbr=i(Al),q9=n(Al,"P",{});var KQe=s(q9);tbr=r(KQe,"This class cannot be instantiated directly using "),yTe=n(KQe,"CODE",{});var yyt=s(yTe);abr=r(yyt,"__init__()"),yyt.forEach(t),nbr=r(KQe," (throws an error)."),KQe.forEach(t),sbr=i(Al),kt=n(Al,"DIV",{class:!0});var YA=s(kt);T(j9.$$.fragment,YA),lbr=i(YA),xTe=n(YA,"P",{});var xyt=s(xTe);ibr=r(xyt,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),xyt.forEach(t),dbr=i(YA),ac=n(YA,"P",{});var ute=s(ac);cbr=r(ute,`Note:
Loading a model from its configuration file does `),$Te=n(ute,"STRONG",{});var $yt=s($Te);fbr=r($yt,"not"),$yt.forEach(t),mbr=r(ute,` load the model weights. It only affects the
model\u2019s configuration. Use `),rU=n(ute,"A",{href:!0});var kyt=s(rU);gbr=r(kyt,"from_pretrained()"),kyt.forEach(t),hbr=r(ute," to load the model weights."),ute.forEach(t),pbr=i(YA),T(gM.$$.fragment,YA),YA.forEach(t),_br=i(Al),Fo=n(Al,"DIV",{class:!0});var $a=s(Fo);T(D9.$$.fragment,$a),ubr=i($a),kTe=n($a,"P",{});var Syt=s(kTe);bbr=r(Syt,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Syt.forEach(t),vbr=i($a),an=n($a,"P",{});var KA=s(an);Fbr=r(KA,"The model class to instantiate is selected based on the "),STe=n(KA,"CODE",{});var Ryt=s(STe);Tbr=r(Ryt,"model_type"),Ryt.forEach(t),Mbr=r(KA,` property of the config object (either
passed as an argument or loaded from `),RTe=n(KA,"CODE",{});var Pyt=s(RTe);Ebr=r(Pyt,"pretrained_model_name_or_path"),Pyt.forEach(t),Cbr=r(KA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PTe=n(KA,"CODE",{});var Byt=s(PTe);wbr=r(Byt,"pretrained_model_name_or_path"),Byt.forEach(t),Abr=r(KA,":"),KA.forEach(t),Lbr=i($a),BTe=n($a,"UL",{});var Iyt=s(BTe);hM=n(Iyt,"LI",{});var XNe=s(hM);ITe=n(XNe,"STRONG",{});var Nyt=s(ITe);ybr=r(Nyt,"maskformer"),Nyt.forEach(t),xbr=r(XNe," \u2014 "),tU=n(XNe,"A",{href:!0});var qyt=s(tU);$br=r(qyt,"MaskFormerForInstanceSegmentation"),qyt.forEach(t),kbr=r(XNe," (MaskFormer model)"),XNe.forEach(t),Iyt.forEach(t),Sbr=i($a),pM=n($a,"P",{});var zNe=s(pM);Rbr=r(zNe,"The model is set in evaluation mode by default using "),NTe=n(zNe,"CODE",{});var jyt=s(NTe);Pbr=r(jyt,"model.eval()"),jyt.forEach(t),Bbr=r(zNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qTe=n(zNe,"CODE",{});var Dyt=s(qTe);Ibr=r(Dyt,"model.train()"),Dyt.forEach(t),zNe.forEach(t),Nbr=i($a),T(_M.$$.fragment,$a),$a.forEach(t),Al.forEach(t),zXe=i(f),nc=n(f,"H2",{class:!0});var ZQe=s(nc);uM=n(ZQe,"A",{id:!0,class:!0,href:!0});var Gyt=s(uM);jTe=n(Gyt,"SPAN",{});var Oyt=s(jTe);T(G9.$$.fragment,Oyt),Oyt.forEach(t),Gyt.forEach(t),qbr=i(ZQe),DTe=n(ZQe,"SPAN",{});var Vyt=s(DTe);jbr=r(Vyt,"TFAutoModel"),Vyt.forEach(t),ZQe.forEach(t),QXe=i(f),er=n(f,"DIV",{class:!0});var Ll=s(er);T(O9.$$.fragment,Ll),Dbr=i(Ll),sc=n(Ll,"P",{});var bte=s(sc);Gbr=r(bte,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),aU=n(bte,"A",{href:!0});var Xyt=s(aU);Obr=r(Xyt,"from_pretrained()"),Xyt.forEach(t),Vbr=r(bte," class method or the "),nU=n(bte,"A",{href:!0});var zyt=s(nU);Xbr=r(zyt,"from_config()"),zyt.forEach(t),zbr=r(bte,` class
method.`),bte.forEach(t),Qbr=i(Ll),V9=n(Ll,"P",{});var eWe=s(V9);Wbr=r(eWe,"This class cannot be instantiated directly using "),GTe=n(eWe,"CODE",{});var Qyt=s(GTe);Hbr=r(Qyt,"__init__()"),Qyt.forEach(t),Ubr=r(eWe," (throws an error)."),eWe.forEach(t),Jbr=i(Ll),St=n(Ll,"DIV",{class:!0});var ZA=s(St);T(X9.$$.fragment,ZA),Ybr=i(ZA),OTe=n(ZA,"P",{});var Wyt=s(OTe);Kbr=r(Wyt,"Instantiates one of the base model classes of the library from a configuration."),Wyt.forEach(t),Zbr=i(ZA),lc=n(ZA,"P",{});var vte=s(lc);evr=r(vte,`Note:
Loading a model from its configuration file does `),VTe=n(vte,"STRONG",{});var Hyt=s(VTe);ovr=r(Hyt,"not"),Hyt.forEach(t),rvr=r(vte,` load the model weights. It only affects the
model\u2019s configuration. Use `),sU=n(vte,"A",{href:!0});var Uyt=s(sU);tvr=r(Uyt,"from_pretrained()"),Uyt.forEach(t),avr=r(vte," to load the model weights."),vte.forEach(t),nvr=i(ZA),T(bM.$$.fragment,ZA),ZA.forEach(t),svr=i(Ll),yr=n(Ll,"DIV",{class:!0});var yl=s(yr);T(z9.$$.fragment,yl),lvr=i(yl),XTe=n(yl,"P",{});var Jyt=s(XTe);ivr=r(Jyt,"Instantiate one of the base model classes of the library from a pretrained model."),Jyt.forEach(t),dvr=i(yl),nn=n(yl,"P",{});var e6=s(nn);cvr=r(e6,"The model class to instantiate is selected based on the "),zTe=n(e6,"CODE",{});var Yyt=s(zTe);fvr=r(Yyt,"model_type"),Yyt.forEach(t),mvr=r(e6,` property of the config object (either
passed as an argument or loaded from `),QTe=n(e6,"CODE",{});var Kyt=s(QTe);gvr=r(Kyt,"pretrained_model_name_or_path"),Kyt.forEach(t),hvr=r(e6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WTe=n(e6,"CODE",{});var Zyt=s(WTe);pvr=r(Zyt,"pretrained_model_name_or_path"),Zyt.forEach(t),_vr=r(e6,":"),e6.forEach(t),uvr=i(yl),j=n(yl,"UL",{});var D=s(j);vM=n(D,"LI",{});var QNe=s(vM);HTe=n(QNe,"STRONG",{});var e9t=s(HTe);bvr=r(e9t,"albert"),e9t.forEach(t),vvr=r(QNe," \u2014 "),lU=n(QNe,"A",{href:!0});var o9t=s(lU);Fvr=r(o9t,"TFAlbertModel"),o9t.forEach(t),Tvr=r(QNe," (ALBERT model)"),QNe.forEach(t),Mvr=i(D),FM=n(D,"LI",{});var WNe=s(FM);UTe=n(WNe,"STRONG",{});var r9t=s(UTe);Evr=r(r9t,"bart"),r9t.forEach(t),Cvr=r(WNe," \u2014 "),iU=n(WNe,"A",{href:!0});var t9t=s(iU);wvr=r(t9t,"TFBartModel"),t9t.forEach(t),Avr=r(WNe," (BART model)"),WNe.forEach(t),Lvr=i(D),TM=n(D,"LI",{});var HNe=s(TM);JTe=n(HNe,"STRONG",{});var a9t=s(JTe);yvr=r(a9t,"bert"),a9t.forEach(t),xvr=r(HNe," \u2014 "),dU=n(HNe,"A",{href:!0});var n9t=s(dU);$vr=r(n9t,"TFBertModel"),n9t.forEach(t),kvr=r(HNe," (BERT model)"),HNe.forEach(t),Svr=i(D),MM=n(D,"LI",{});var UNe=s(MM);YTe=n(UNe,"STRONG",{});var s9t=s(YTe);Rvr=r(s9t,"blenderbot"),s9t.forEach(t),Pvr=r(UNe," \u2014 "),cU=n(UNe,"A",{href:!0});var l9t=s(cU);Bvr=r(l9t,"TFBlenderbotModel"),l9t.forEach(t),Ivr=r(UNe," (Blenderbot model)"),UNe.forEach(t),Nvr=i(D),EM=n(D,"LI",{});var JNe=s(EM);KTe=n(JNe,"STRONG",{});var i9t=s(KTe);qvr=r(i9t,"blenderbot-small"),i9t.forEach(t),jvr=r(JNe," \u2014 "),fU=n(JNe,"A",{href:!0});var d9t=s(fU);Dvr=r(d9t,"TFBlenderbotSmallModel"),d9t.forEach(t),Gvr=r(JNe," (BlenderbotSmall model)"),JNe.forEach(t),Ovr=i(D),CM=n(D,"LI",{});var YNe=s(CM);ZTe=n(YNe,"STRONG",{});var c9t=s(ZTe);Vvr=r(c9t,"camembert"),c9t.forEach(t),Xvr=r(YNe," \u2014 "),mU=n(YNe,"A",{href:!0});var f9t=s(mU);zvr=r(f9t,"TFCamembertModel"),f9t.forEach(t),Qvr=r(YNe," (CamemBERT model)"),YNe.forEach(t),Wvr=i(D),wM=n(D,"LI",{});var KNe=s(wM);e7e=n(KNe,"STRONG",{});var m9t=s(e7e);Hvr=r(m9t,"clip"),m9t.forEach(t),Uvr=r(KNe," \u2014 "),gU=n(KNe,"A",{href:!0});var g9t=s(gU);Jvr=r(g9t,"TFCLIPModel"),g9t.forEach(t),Yvr=r(KNe," (CLIP model)"),KNe.forEach(t),Kvr=i(D),AM=n(D,"LI",{});var ZNe=s(AM);o7e=n(ZNe,"STRONG",{});var h9t=s(o7e);Zvr=r(h9t,"convbert"),h9t.forEach(t),eFr=r(ZNe," \u2014 "),hU=n(ZNe,"A",{href:!0});var p9t=s(hU);oFr=r(p9t,"TFConvBertModel"),p9t.forEach(t),rFr=r(ZNe," (ConvBERT model)"),ZNe.forEach(t),tFr=i(D),LM=n(D,"LI",{});var eqe=s(LM);r7e=n(eqe,"STRONG",{});var _9t=s(r7e);aFr=r(_9t,"convnext"),_9t.forEach(t),nFr=r(eqe," \u2014 "),pU=n(eqe,"A",{href:!0});var u9t=s(pU);sFr=r(u9t,"TFConvNextModel"),u9t.forEach(t),lFr=r(eqe," (ConvNeXT model)"),eqe.forEach(t),iFr=i(D),yM=n(D,"LI",{});var oqe=s(yM);t7e=n(oqe,"STRONG",{});var b9t=s(t7e);dFr=r(b9t,"ctrl"),b9t.forEach(t),cFr=r(oqe," \u2014 "),_U=n(oqe,"A",{href:!0});var v9t=s(_U);fFr=r(v9t,"TFCTRLModel"),v9t.forEach(t),mFr=r(oqe," (CTRL model)"),oqe.forEach(t),gFr=i(D),xM=n(D,"LI",{});var rqe=s(xM);a7e=n(rqe,"STRONG",{});var F9t=s(a7e);hFr=r(F9t,"data2vec-vision"),F9t.forEach(t),pFr=r(rqe," \u2014 "),uU=n(rqe,"A",{href:!0});var T9t=s(uU);_Fr=r(T9t,"TFData2VecVisionModel"),T9t.forEach(t),uFr=r(rqe," (Data2VecVision model)"),rqe.forEach(t),bFr=i(D),$M=n(D,"LI",{});var tqe=s($M);n7e=n(tqe,"STRONG",{});var M9t=s(n7e);vFr=r(M9t,"deberta"),M9t.forEach(t),FFr=r(tqe," \u2014 "),bU=n(tqe,"A",{href:!0});var E9t=s(bU);TFr=r(E9t,"TFDebertaModel"),E9t.forEach(t),MFr=r(tqe," (DeBERTa model)"),tqe.forEach(t),EFr=i(D),kM=n(D,"LI",{});var aqe=s(kM);s7e=n(aqe,"STRONG",{});var C9t=s(s7e);CFr=r(C9t,"deberta-v2"),C9t.forEach(t),wFr=r(aqe," \u2014 "),vU=n(aqe,"A",{href:!0});var w9t=s(vU);AFr=r(w9t,"TFDebertaV2Model"),w9t.forEach(t),LFr=r(aqe," (DeBERTa-v2 model)"),aqe.forEach(t),yFr=i(D),SM=n(D,"LI",{});var nqe=s(SM);l7e=n(nqe,"STRONG",{});var A9t=s(l7e);xFr=r(A9t,"distilbert"),A9t.forEach(t),$Fr=r(nqe," \u2014 "),FU=n(nqe,"A",{href:!0});var L9t=s(FU);kFr=r(L9t,"TFDistilBertModel"),L9t.forEach(t),SFr=r(nqe," (DistilBERT model)"),nqe.forEach(t),RFr=i(D),RM=n(D,"LI",{});var sqe=s(RM);i7e=n(sqe,"STRONG",{});var y9t=s(i7e);PFr=r(y9t,"dpr"),y9t.forEach(t),BFr=r(sqe," \u2014 "),TU=n(sqe,"A",{href:!0});var x9t=s(TU);IFr=r(x9t,"TFDPRQuestionEncoder"),x9t.forEach(t),NFr=r(sqe," (DPR model)"),sqe.forEach(t),qFr=i(D),PM=n(D,"LI",{});var lqe=s(PM);d7e=n(lqe,"STRONG",{});var $9t=s(d7e);jFr=r($9t,"electra"),$9t.forEach(t),DFr=r(lqe," \u2014 "),MU=n(lqe,"A",{href:!0});var k9t=s(MU);GFr=r(k9t,"TFElectraModel"),k9t.forEach(t),OFr=r(lqe," (ELECTRA model)"),lqe.forEach(t),VFr=i(D),BM=n(D,"LI",{});var iqe=s(BM);c7e=n(iqe,"STRONG",{});var S9t=s(c7e);XFr=r(S9t,"flaubert"),S9t.forEach(t),zFr=r(iqe," \u2014 "),EU=n(iqe,"A",{href:!0});var R9t=s(EU);QFr=r(R9t,"TFFlaubertModel"),R9t.forEach(t),WFr=r(iqe," (FlauBERT model)"),iqe.forEach(t),HFr=i(D),Us=n(D,"LI",{});var $S=s(Us);f7e=n($S,"STRONG",{});var P9t=s(f7e);UFr=r(P9t,"funnel"),P9t.forEach(t),JFr=r($S," \u2014 "),CU=n($S,"A",{href:!0});var B9t=s(CU);YFr=r(B9t,"TFFunnelModel"),B9t.forEach(t),KFr=r($S," or "),wU=n($S,"A",{href:!0});var I9t=s(wU);ZFr=r(I9t,"TFFunnelBaseModel"),I9t.forEach(t),eTr=r($S," (Funnel Transformer model)"),$S.forEach(t),oTr=i(D),IM=n(D,"LI",{});var dqe=s(IM);m7e=n(dqe,"STRONG",{});var N9t=s(m7e);rTr=r(N9t,"gpt2"),N9t.forEach(t),tTr=r(dqe," \u2014 "),AU=n(dqe,"A",{href:!0});var q9t=s(AU);aTr=r(q9t,"TFGPT2Model"),q9t.forEach(t),nTr=r(dqe," (OpenAI GPT-2 model)"),dqe.forEach(t),sTr=i(D),NM=n(D,"LI",{});var cqe=s(NM);g7e=n(cqe,"STRONG",{});var j9t=s(g7e);lTr=r(j9t,"gptj"),j9t.forEach(t),iTr=r(cqe," \u2014 "),LU=n(cqe,"A",{href:!0});var D9t=s(LU);dTr=r(D9t,"TFGPTJModel"),D9t.forEach(t),cTr=r(cqe," (GPT-J model)"),cqe.forEach(t),fTr=i(D),qM=n(D,"LI",{});var fqe=s(qM);h7e=n(fqe,"STRONG",{});var G9t=s(h7e);mTr=r(G9t,"hubert"),G9t.forEach(t),gTr=r(fqe," \u2014 "),yU=n(fqe,"A",{href:!0});var O9t=s(yU);hTr=r(O9t,"TFHubertModel"),O9t.forEach(t),pTr=r(fqe," (Hubert model)"),fqe.forEach(t),_Tr=i(D),jM=n(D,"LI",{});var mqe=s(jM);p7e=n(mqe,"STRONG",{});var V9t=s(p7e);uTr=r(V9t,"layoutlm"),V9t.forEach(t),bTr=r(mqe," \u2014 "),xU=n(mqe,"A",{href:!0});var X9t=s(xU);vTr=r(X9t,"TFLayoutLMModel"),X9t.forEach(t),FTr=r(mqe," (LayoutLM model)"),mqe.forEach(t),TTr=i(D),DM=n(D,"LI",{});var gqe=s(DM);_7e=n(gqe,"STRONG",{});var z9t=s(_7e);MTr=r(z9t,"led"),z9t.forEach(t),ETr=r(gqe," \u2014 "),$U=n(gqe,"A",{href:!0});var Q9t=s($U);CTr=r(Q9t,"TFLEDModel"),Q9t.forEach(t),wTr=r(gqe," (LED model)"),gqe.forEach(t),ATr=i(D),GM=n(D,"LI",{});var hqe=s(GM);u7e=n(hqe,"STRONG",{});var W9t=s(u7e);LTr=r(W9t,"longformer"),W9t.forEach(t),yTr=r(hqe," \u2014 "),kU=n(hqe,"A",{href:!0});var H9t=s(kU);xTr=r(H9t,"TFLongformerModel"),H9t.forEach(t),$Tr=r(hqe," (Longformer model)"),hqe.forEach(t),kTr=i(D),OM=n(D,"LI",{});var pqe=s(OM);b7e=n(pqe,"STRONG",{});var U9t=s(b7e);STr=r(U9t,"lxmert"),U9t.forEach(t),RTr=r(pqe," \u2014 "),SU=n(pqe,"A",{href:!0});var J9t=s(SU);PTr=r(J9t,"TFLxmertModel"),J9t.forEach(t),BTr=r(pqe," (LXMERT model)"),pqe.forEach(t),ITr=i(D),VM=n(D,"LI",{});var _qe=s(VM);v7e=n(_qe,"STRONG",{});var Y9t=s(v7e);NTr=r(Y9t,"marian"),Y9t.forEach(t),qTr=r(_qe," \u2014 "),RU=n(_qe,"A",{href:!0});var K9t=s(RU);jTr=r(K9t,"TFMarianModel"),K9t.forEach(t),DTr=r(_qe," (Marian model)"),_qe.forEach(t),GTr=i(D),XM=n(D,"LI",{});var uqe=s(XM);F7e=n(uqe,"STRONG",{});var Z9t=s(F7e);OTr=r(Z9t,"mbart"),Z9t.forEach(t),VTr=r(uqe," \u2014 "),PU=n(uqe,"A",{href:!0});var ext=s(PU);XTr=r(ext,"TFMBartModel"),ext.forEach(t),zTr=r(uqe," (mBART model)"),uqe.forEach(t),QTr=i(D),zM=n(D,"LI",{});var bqe=s(zM);T7e=n(bqe,"STRONG",{});var oxt=s(T7e);WTr=r(oxt,"mobilebert"),oxt.forEach(t),HTr=r(bqe," \u2014 "),BU=n(bqe,"A",{href:!0});var rxt=s(BU);UTr=r(rxt,"TFMobileBertModel"),rxt.forEach(t),JTr=r(bqe," (MobileBERT model)"),bqe.forEach(t),YTr=i(D),QM=n(D,"LI",{});var vqe=s(QM);M7e=n(vqe,"STRONG",{});var txt=s(M7e);KTr=r(txt,"mpnet"),txt.forEach(t),ZTr=r(vqe," \u2014 "),IU=n(vqe,"A",{href:!0});var axt=s(IU);e7r=r(axt,"TFMPNetModel"),axt.forEach(t),o7r=r(vqe," (MPNet model)"),vqe.forEach(t),r7r=i(D),WM=n(D,"LI",{});var Fqe=s(WM);E7e=n(Fqe,"STRONG",{});var nxt=s(E7e);t7r=r(nxt,"mt5"),nxt.forEach(t),a7r=r(Fqe," \u2014 "),NU=n(Fqe,"A",{href:!0});var sxt=s(NU);n7r=r(sxt,"TFMT5Model"),sxt.forEach(t),s7r=r(Fqe," (MT5 model)"),Fqe.forEach(t),l7r=i(D),HM=n(D,"LI",{});var Tqe=s(HM);C7e=n(Tqe,"STRONG",{});var lxt=s(C7e);i7r=r(lxt,"openai-gpt"),lxt.forEach(t),d7r=r(Tqe," \u2014 "),qU=n(Tqe,"A",{href:!0});var ixt=s(qU);c7r=r(ixt,"TFOpenAIGPTModel"),ixt.forEach(t),f7r=r(Tqe," (OpenAI GPT model)"),Tqe.forEach(t),m7r=i(D),UM=n(D,"LI",{});var Mqe=s(UM);w7e=n(Mqe,"STRONG",{});var dxt=s(w7e);g7r=r(dxt,"opt"),dxt.forEach(t),h7r=r(Mqe," \u2014 "),jU=n(Mqe,"A",{href:!0});var cxt=s(jU);p7r=r(cxt,"TFOPTModel"),cxt.forEach(t),_7r=r(Mqe," (OPT model)"),Mqe.forEach(t),u7r=i(D),JM=n(D,"LI",{});var Eqe=s(JM);A7e=n(Eqe,"STRONG",{});var fxt=s(A7e);b7r=r(fxt,"pegasus"),fxt.forEach(t),v7r=r(Eqe," \u2014 "),DU=n(Eqe,"A",{href:!0});var mxt=s(DU);F7r=r(mxt,"TFPegasusModel"),mxt.forEach(t),T7r=r(Eqe," (Pegasus model)"),Eqe.forEach(t),M7r=i(D),YM=n(D,"LI",{});var Cqe=s(YM);L7e=n(Cqe,"STRONG",{});var gxt=s(L7e);E7r=r(gxt,"regnet"),gxt.forEach(t),C7r=r(Cqe," \u2014 "),GU=n(Cqe,"A",{href:!0});var hxt=s(GU);w7r=r(hxt,"TFRegNetModel"),hxt.forEach(t),A7r=r(Cqe," (RegNet model)"),Cqe.forEach(t),L7r=i(D),KM=n(D,"LI",{});var wqe=s(KM);y7e=n(wqe,"STRONG",{});var pxt=s(y7e);y7r=r(pxt,"rembert"),pxt.forEach(t),x7r=r(wqe," \u2014 "),OU=n(wqe,"A",{href:!0});var _xt=s(OU);$7r=r(_xt,"TFRemBertModel"),_xt.forEach(t),k7r=r(wqe," (RemBERT model)"),wqe.forEach(t),S7r=i(D),ZM=n(D,"LI",{});var Aqe=s(ZM);x7e=n(Aqe,"STRONG",{});var uxt=s(x7e);R7r=r(uxt,"roberta"),uxt.forEach(t),P7r=r(Aqe," \u2014 "),VU=n(Aqe,"A",{href:!0});var bxt=s(VU);B7r=r(bxt,"TFRobertaModel"),bxt.forEach(t),I7r=r(Aqe," (RoBERTa model)"),Aqe.forEach(t),N7r=i(D),e4=n(D,"LI",{});var Lqe=s(e4);$7e=n(Lqe,"STRONG",{});var vxt=s($7e);q7r=r(vxt,"roformer"),vxt.forEach(t),j7r=r(Lqe," \u2014 "),XU=n(Lqe,"A",{href:!0});var Fxt=s(XU);D7r=r(Fxt,"TFRoFormerModel"),Fxt.forEach(t),G7r=r(Lqe," (RoFormer model)"),Lqe.forEach(t),O7r=i(D),o4=n(D,"LI",{});var yqe=s(o4);k7e=n(yqe,"STRONG",{});var Txt=s(k7e);V7r=r(Txt,"speech_to_text"),Txt.forEach(t),X7r=r(yqe," \u2014 "),zU=n(yqe,"A",{href:!0});var Mxt=s(zU);z7r=r(Mxt,"TFSpeech2TextModel"),Mxt.forEach(t),Q7r=r(yqe," (Speech2Text model)"),yqe.forEach(t),W7r=i(D),r4=n(D,"LI",{});var xqe=s(r4);S7e=n(xqe,"STRONG",{});var Ext=s(S7e);H7r=r(Ext,"swin"),Ext.forEach(t),U7r=r(xqe," \u2014 "),QU=n(xqe,"A",{href:!0});var Cxt=s(QU);J7r=r(Cxt,"TFSwinModel"),Cxt.forEach(t),Y7r=r(xqe," (Swin Transformer model)"),xqe.forEach(t),K7r=i(D),t4=n(D,"LI",{});var $qe=s(t4);R7e=n($qe,"STRONG",{});var wxt=s(R7e);Z7r=r(wxt,"t5"),wxt.forEach(t),e8r=r($qe," \u2014 "),WU=n($qe,"A",{href:!0});var Axt=s(WU);o8r=r(Axt,"TFT5Model"),Axt.forEach(t),r8r=r($qe," (T5 model)"),$qe.forEach(t),t8r=i(D),a4=n(D,"LI",{});var kqe=s(a4);P7e=n(kqe,"STRONG",{});var Lxt=s(P7e);a8r=r(Lxt,"tapas"),Lxt.forEach(t),n8r=r(kqe," \u2014 "),HU=n(kqe,"A",{href:!0});var yxt=s(HU);s8r=r(yxt,"TFTapasModel"),yxt.forEach(t),l8r=r(kqe," (TAPAS model)"),kqe.forEach(t),i8r=i(D),n4=n(D,"LI",{});var Sqe=s(n4);B7e=n(Sqe,"STRONG",{});var xxt=s(B7e);d8r=r(xxt,"transfo-xl"),xxt.forEach(t),c8r=r(Sqe," \u2014 "),UU=n(Sqe,"A",{href:!0});var $xt=s(UU);f8r=r($xt,"TFTransfoXLModel"),$xt.forEach(t),m8r=r(Sqe," (Transformer-XL model)"),Sqe.forEach(t),g8r=i(D),s4=n(D,"LI",{});var Rqe=s(s4);I7e=n(Rqe,"STRONG",{});var kxt=s(I7e);h8r=r(kxt,"vit"),kxt.forEach(t),p8r=r(Rqe," \u2014 "),JU=n(Rqe,"A",{href:!0});var Sxt=s(JU);_8r=r(Sxt,"TFViTModel"),Sxt.forEach(t),u8r=r(Rqe," (ViT model)"),Rqe.forEach(t),b8r=i(D),l4=n(D,"LI",{});var Pqe=s(l4);N7e=n(Pqe,"STRONG",{});var Rxt=s(N7e);v8r=r(Rxt,"vit_mae"),Rxt.forEach(t),F8r=r(Pqe," \u2014 "),YU=n(Pqe,"A",{href:!0});var Pxt=s(YU);T8r=r(Pxt,"TFViTMAEModel"),Pxt.forEach(t),M8r=r(Pqe," (ViTMAE model)"),Pqe.forEach(t),E8r=i(D),i4=n(D,"LI",{});var Bqe=s(i4);q7e=n(Bqe,"STRONG",{});var Bxt=s(q7e);C8r=r(Bxt,"wav2vec2"),Bxt.forEach(t),w8r=r(Bqe," \u2014 "),KU=n(Bqe,"A",{href:!0});var Ixt=s(KU);A8r=r(Ixt,"TFWav2Vec2Model"),Ixt.forEach(t),L8r=r(Bqe," (Wav2Vec2 model)"),Bqe.forEach(t),y8r=i(D),d4=n(D,"LI",{});var Iqe=s(d4);j7e=n(Iqe,"STRONG",{});var Nxt=s(j7e);x8r=r(Nxt,"xlm"),Nxt.forEach(t),$8r=r(Iqe," \u2014 "),ZU=n(Iqe,"A",{href:!0});var qxt=s(ZU);k8r=r(qxt,"TFXLMModel"),qxt.forEach(t),S8r=r(Iqe," (XLM model)"),Iqe.forEach(t),R8r=i(D),c4=n(D,"LI",{});var Nqe=s(c4);D7e=n(Nqe,"STRONG",{});var jxt=s(D7e);P8r=r(jxt,"xlm-roberta"),jxt.forEach(t),B8r=r(Nqe," \u2014 "),eJ=n(Nqe,"A",{href:!0});var Dxt=s(eJ);I8r=r(Dxt,"TFXLMRobertaModel"),Dxt.forEach(t),N8r=r(Nqe," (XLM-RoBERTa model)"),Nqe.forEach(t),q8r=i(D),f4=n(D,"LI",{});var qqe=s(f4);G7e=n(qqe,"STRONG",{});var Gxt=s(G7e);j8r=r(Gxt,"xlnet"),Gxt.forEach(t),D8r=r(qqe," \u2014 "),oJ=n(qqe,"A",{href:!0});var Oxt=s(oJ);G8r=r(Oxt,"TFXLNetModel"),Oxt.forEach(t),O8r=r(qqe," (XLNet model)"),qqe.forEach(t),D.forEach(t),V8r=i(yl),T(m4.$$.fragment,yl),yl.forEach(t),Ll.forEach(t),WXe=i(f),ic=n(f,"H2",{class:!0});var oWe=s(ic);g4=n(oWe,"A",{id:!0,class:!0,href:!0});var Vxt=s(g4);O7e=n(Vxt,"SPAN",{});var Xxt=s(O7e);T(Q9.$$.fragment,Xxt),Xxt.forEach(t),Vxt.forEach(t),X8r=i(oWe),V7e=n(oWe,"SPAN",{});var zxt=s(V7e);z8r=r(zxt,"TFAutoModelForPreTraining"),zxt.forEach(t),oWe.forEach(t),HXe=i(f),or=n(f,"DIV",{class:!0});var xl=s(or);T(W9.$$.fragment,xl),Q8r=i(xl),dc=n(xl,"P",{});var Fte=s(dc);W8r=r(Fte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),rJ=n(Fte,"A",{href:!0});var Qxt=s(rJ);H8r=r(Qxt,"from_pretrained()"),Qxt.forEach(t),U8r=r(Fte," class method or the "),tJ=n(Fte,"A",{href:!0});var Wxt=s(tJ);J8r=r(Wxt,"from_config()"),Wxt.forEach(t),Y8r=r(Fte,` class
method.`),Fte.forEach(t),K8r=i(xl),H9=n(xl,"P",{});var rWe=s(H9);Z8r=r(rWe,"This class cannot be instantiated directly using "),X7e=n(rWe,"CODE",{});var Hxt=s(X7e);eMr=r(Hxt,"__init__()"),Hxt.forEach(t),oMr=r(rWe," (throws an error)."),rWe.forEach(t),rMr=i(xl),Rt=n(xl,"DIV",{class:!0});var o6=s(Rt);T(U9.$$.fragment,o6),tMr=i(o6),z7e=n(o6,"P",{});var Uxt=s(z7e);aMr=r(Uxt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Uxt.forEach(t),nMr=i(o6),cc=n(o6,"P",{});var Tte=s(cc);sMr=r(Tte,`Note:
Loading a model from its configuration file does `),Q7e=n(Tte,"STRONG",{});var Jxt=s(Q7e);lMr=r(Jxt,"not"),Jxt.forEach(t),iMr=r(Tte,` load the model weights. It only affects the
model\u2019s configuration. Use `),aJ=n(Tte,"A",{href:!0});var Yxt=s(aJ);dMr=r(Yxt,"from_pretrained()"),Yxt.forEach(t),cMr=r(Tte," to load the model weights."),Tte.forEach(t),fMr=i(o6),T(h4.$$.fragment,o6),o6.forEach(t),mMr=i(xl),xr=n(xl,"DIV",{class:!0});var $l=s(xr);T(J9.$$.fragment,$l),gMr=i($l),W7e=n($l,"P",{});var Kxt=s(W7e);hMr=r(Kxt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Kxt.forEach(t),pMr=i($l),sn=n($l,"P",{});var r6=s(sn);_Mr=r(r6,"The model class to instantiate is selected based on the "),H7e=n(r6,"CODE",{});var Zxt=s(H7e);uMr=r(Zxt,"model_type"),Zxt.forEach(t),bMr=r(r6,` property of the config object (either
passed as an argument or loaded from `),U7e=n(r6,"CODE",{});var e$t=s(U7e);vMr=r(e$t,"pretrained_model_name_or_path"),e$t.forEach(t),FMr=r(r6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J7e=n(r6,"CODE",{});var o$t=s(J7e);TMr=r(o$t,"pretrained_model_name_or_path"),o$t.forEach(t),MMr=r(r6,":"),r6.forEach(t),EMr=i($l),se=n($l,"UL",{});var le=s(se);p4=n(le,"LI",{});var jqe=s(p4);Y7e=n(jqe,"STRONG",{});var r$t=s(Y7e);CMr=r(r$t,"albert"),r$t.forEach(t),wMr=r(jqe," \u2014 "),nJ=n(jqe,"A",{href:!0});var t$t=s(nJ);AMr=r(t$t,"TFAlbertForPreTraining"),t$t.forEach(t),LMr=r(jqe," (ALBERT model)"),jqe.forEach(t),yMr=i(le),_4=n(le,"LI",{});var Dqe=s(_4);K7e=n(Dqe,"STRONG",{});var a$t=s(K7e);xMr=r(a$t,"bart"),a$t.forEach(t),$Mr=r(Dqe," \u2014 "),sJ=n(Dqe,"A",{href:!0});var n$t=s(sJ);kMr=r(n$t,"TFBartForConditionalGeneration"),n$t.forEach(t),SMr=r(Dqe," (BART model)"),Dqe.forEach(t),RMr=i(le),u4=n(le,"LI",{});var Gqe=s(u4);Z7e=n(Gqe,"STRONG",{});var s$t=s(Z7e);PMr=r(s$t,"bert"),s$t.forEach(t),BMr=r(Gqe," \u2014 "),lJ=n(Gqe,"A",{href:!0});var l$t=s(lJ);IMr=r(l$t,"TFBertForPreTraining"),l$t.forEach(t),NMr=r(Gqe," (BERT model)"),Gqe.forEach(t),qMr=i(le),b4=n(le,"LI",{});var Oqe=s(b4);e8e=n(Oqe,"STRONG",{});var i$t=s(e8e);jMr=r(i$t,"camembert"),i$t.forEach(t),DMr=r(Oqe," \u2014 "),iJ=n(Oqe,"A",{href:!0});var d$t=s(iJ);GMr=r(d$t,"TFCamembertForMaskedLM"),d$t.forEach(t),OMr=r(Oqe," (CamemBERT model)"),Oqe.forEach(t),VMr=i(le),v4=n(le,"LI",{});var Vqe=s(v4);o8e=n(Vqe,"STRONG",{});var c$t=s(o8e);XMr=r(c$t,"ctrl"),c$t.forEach(t),zMr=r(Vqe," \u2014 "),dJ=n(Vqe,"A",{href:!0});var f$t=s(dJ);QMr=r(f$t,"TFCTRLLMHeadModel"),f$t.forEach(t),WMr=r(Vqe," (CTRL model)"),Vqe.forEach(t),HMr=i(le),F4=n(le,"LI",{});var Xqe=s(F4);r8e=n(Xqe,"STRONG",{});var m$t=s(r8e);UMr=r(m$t,"distilbert"),m$t.forEach(t),JMr=r(Xqe," \u2014 "),cJ=n(Xqe,"A",{href:!0});var g$t=s(cJ);YMr=r(g$t,"TFDistilBertForMaskedLM"),g$t.forEach(t),KMr=r(Xqe," (DistilBERT model)"),Xqe.forEach(t),ZMr=i(le),T4=n(le,"LI",{});var zqe=s(T4);t8e=n(zqe,"STRONG",{});var h$t=s(t8e);e4r=r(h$t,"electra"),h$t.forEach(t),o4r=r(zqe," \u2014 "),fJ=n(zqe,"A",{href:!0});var p$t=s(fJ);r4r=r(p$t,"TFElectraForPreTraining"),p$t.forEach(t),t4r=r(zqe," (ELECTRA model)"),zqe.forEach(t),a4r=i(le),M4=n(le,"LI",{});var Qqe=s(M4);a8e=n(Qqe,"STRONG",{});var _$t=s(a8e);n4r=r(_$t,"flaubert"),_$t.forEach(t),s4r=r(Qqe," \u2014 "),mJ=n(Qqe,"A",{href:!0});var u$t=s(mJ);l4r=r(u$t,"TFFlaubertWithLMHeadModel"),u$t.forEach(t),i4r=r(Qqe," (FlauBERT model)"),Qqe.forEach(t),d4r=i(le),E4=n(le,"LI",{});var Wqe=s(E4);n8e=n(Wqe,"STRONG",{});var b$t=s(n8e);c4r=r(b$t,"funnel"),b$t.forEach(t),f4r=r(Wqe," \u2014 "),gJ=n(Wqe,"A",{href:!0});var v$t=s(gJ);m4r=r(v$t,"TFFunnelForPreTraining"),v$t.forEach(t),g4r=r(Wqe," (Funnel Transformer model)"),Wqe.forEach(t),h4r=i(le),C4=n(le,"LI",{});var Hqe=s(C4);s8e=n(Hqe,"STRONG",{});var F$t=s(s8e);p4r=r(F$t,"gpt2"),F$t.forEach(t),_4r=r(Hqe," \u2014 "),hJ=n(Hqe,"A",{href:!0});var T$t=s(hJ);u4r=r(T$t,"TFGPT2LMHeadModel"),T$t.forEach(t),b4r=r(Hqe," (OpenAI GPT-2 model)"),Hqe.forEach(t),v4r=i(le),w4=n(le,"LI",{});var Uqe=s(w4);l8e=n(Uqe,"STRONG",{});var M$t=s(l8e);F4r=r(M$t,"layoutlm"),M$t.forEach(t),T4r=r(Uqe," \u2014 "),pJ=n(Uqe,"A",{href:!0});var E$t=s(pJ);M4r=r(E$t,"TFLayoutLMForMaskedLM"),E$t.forEach(t),E4r=r(Uqe," (LayoutLM model)"),Uqe.forEach(t),C4r=i(le),A4=n(le,"LI",{});var Jqe=s(A4);i8e=n(Jqe,"STRONG",{});var C$t=s(i8e);w4r=r(C$t,"lxmert"),C$t.forEach(t),A4r=r(Jqe," \u2014 "),_J=n(Jqe,"A",{href:!0});var w$t=s(_J);L4r=r(w$t,"TFLxmertForPreTraining"),w$t.forEach(t),y4r=r(Jqe," (LXMERT model)"),Jqe.forEach(t),x4r=i(le),L4=n(le,"LI",{});var Yqe=s(L4);d8e=n(Yqe,"STRONG",{});var A$t=s(d8e);$4r=r(A$t,"mobilebert"),A$t.forEach(t),k4r=r(Yqe," \u2014 "),uJ=n(Yqe,"A",{href:!0});var L$t=s(uJ);S4r=r(L$t,"TFMobileBertForPreTraining"),L$t.forEach(t),R4r=r(Yqe," (MobileBERT model)"),Yqe.forEach(t),P4r=i(le),y4=n(le,"LI",{});var Kqe=s(y4);c8e=n(Kqe,"STRONG",{});var y$t=s(c8e);B4r=r(y$t,"mpnet"),y$t.forEach(t),I4r=r(Kqe," \u2014 "),bJ=n(Kqe,"A",{href:!0});var x$t=s(bJ);N4r=r(x$t,"TFMPNetForMaskedLM"),x$t.forEach(t),q4r=r(Kqe," (MPNet model)"),Kqe.forEach(t),j4r=i(le),x4=n(le,"LI",{});var Zqe=s(x4);f8e=n(Zqe,"STRONG",{});var $$t=s(f8e);D4r=r($$t,"openai-gpt"),$$t.forEach(t),G4r=r(Zqe," \u2014 "),vJ=n(Zqe,"A",{href:!0});var k$t=s(vJ);O4r=r(k$t,"TFOpenAIGPTLMHeadModel"),k$t.forEach(t),V4r=r(Zqe," (OpenAI GPT model)"),Zqe.forEach(t),X4r=i(le),$4=n(le,"LI",{});var eje=s($4);m8e=n(eje,"STRONG",{});var S$t=s(m8e);z4r=r(S$t,"roberta"),S$t.forEach(t),Q4r=r(eje," \u2014 "),FJ=n(eje,"A",{href:!0});var R$t=s(FJ);W4r=r(R$t,"TFRobertaForMaskedLM"),R$t.forEach(t),H4r=r(eje," (RoBERTa model)"),eje.forEach(t),U4r=i(le),k4=n(le,"LI",{});var oje=s(k4);g8e=n(oje,"STRONG",{});var P$t=s(g8e);J4r=r(P$t,"t5"),P$t.forEach(t),Y4r=r(oje," \u2014 "),TJ=n(oje,"A",{href:!0});var B$t=s(TJ);K4r=r(B$t,"TFT5ForConditionalGeneration"),B$t.forEach(t),Z4r=r(oje," (T5 model)"),oje.forEach(t),eEr=i(le),S4=n(le,"LI",{});var rje=s(S4);h8e=n(rje,"STRONG",{});var I$t=s(h8e);oEr=r(I$t,"tapas"),I$t.forEach(t),rEr=r(rje," \u2014 "),MJ=n(rje,"A",{href:!0});var N$t=s(MJ);tEr=r(N$t,"TFTapasForMaskedLM"),N$t.forEach(t),aEr=r(rje," (TAPAS model)"),rje.forEach(t),nEr=i(le),R4=n(le,"LI",{});var tje=s(R4);p8e=n(tje,"STRONG",{});var q$t=s(p8e);sEr=r(q$t,"transfo-xl"),q$t.forEach(t),lEr=r(tje," \u2014 "),EJ=n(tje,"A",{href:!0});var j$t=s(EJ);iEr=r(j$t,"TFTransfoXLLMHeadModel"),j$t.forEach(t),dEr=r(tje," (Transformer-XL model)"),tje.forEach(t),cEr=i(le),P4=n(le,"LI",{});var aje=s(P4);_8e=n(aje,"STRONG",{});var D$t=s(_8e);fEr=r(D$t,"vit_mae"),D$t.forEach(t),mEr=r(aje," \u2014 "),CJ=n(aje,"A",{href:!0});var G$t=s(CJ);gEr=r(G$t,"TFViTMAEForPreTraining"),G$t.forEach(t),hEr=r(aje," (ViTMAE model)"),aje.forEach(t),pEr=i(le),B4=n(le,"LI",{});var nje=s(B4);u8e=n(nje,"STRONG",{});var O$t=s(u8e);_Er=r(O$t,"xlm"),O$t.forEach(t),uEr=r(nje," \u2014 "),wJ=n(nje,"A",{href:!0});var V$t=s(wJ);bEr=r(V$t,"TFXLMWithLMHeadModel"),V$t.forEach(t),vEr=r(nje," (XLM model)"),nje.forEach(t),FEr=i(le),I4=n(le,"LI",{});var sje=s(I4);b8e=n(sje,"STRONG",{});var X$t=s(b8e);TEr=r(X$t,"xlm-roberta"),X$t.forEach(t),MEr=r(sje," \u2014 "),AJ=n(sje,"A",{href:!0});var z$t=s(AJ);EEr=r(z$t,"TFXLMRobertaForMaskedLM"),z$t.forEach(t),CEr=r(sje," (XLM-RoBERTa model)"),sje.forEach(t),wEr=i(le),N4=n(le,"LI",{});var lje=s(N4);v8e=n(lje,"STRONG",{});var Q$t=s(v8e);AEr=r(Q$t,"xlnet"),Q$t.forEach(t),LEr=r(lje," \u2014 "),LJ=n(lje,"A",{href:!0});var W$t=s(LJ);yEr=r(W$t,"TFXLNetLMHeadModel"),W$t.forEach(t),xEr=r(lje," (XLNet model)"),lje.forEach(t),le.forEach(t),$Er=i($l),T(q4.$$.fragment,$l),$l.forEach(t),xl.forEach(t),UXe=i(f),fc=n(f,"H2",{class:!0});var tWe=s(fc);j4=n(tWe,"A",{id:!0,class:!0,href:!0});var H$t=s(j4);F8e=n(H$t,"SPAN",{});var U$t=s(F8e);T(Y9.$$.fragment,U$t),U$t.forEach(t),H$t.forEach(t),kEr=i(tWe),T8e=n(tWe,"SPAN",{});var J$t=s(T8e);SEr=r(J$t,"TFAutoModelForCausalLM"),J$t.forEach(t),tWe.forEach(t),JXe=i(f),rr=n(f,"DIV",{class:!0});var kl=s(rr);T(K9.$$.fragment,kl),REr=i(kl),mc=n(kl,"P",{});var Mte=s(mc);PEr=r(Mte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),yJ=n(Mte,"A",{href:!0});var Y$t=s(yJ);BEr=r(Y$t,"from_pretrained()"),Y$t.forEach(t),IEr=r(Mte," class method or the "),xJ=n(Mte,"A",{href:!0});var K$t=s(xJ);NEr=r(K$t,"from_config()"),K$t.forEach(t),qEr=r(Mte,` class
method.`),Mte.forEach(t),jEr=i(kl),Z9=n(kl,"P",{});var aWe=s(Z9);DEr=r(aWe,"This class cannot be instantiated directly using "),M8e=n(aWe,"CODE",{});var Z$t=s(M8e);GEr=r(Z$t,"__init__()"),Z$t.forEach(t),OEr=r(aWe," (throws an error)."),aWe.forEach(t),VEr=i(kl),Pt=n(kl,"DIV",{class:!0});var t6=s(Pt);T(ex.$$.fragment,t6),XEr=i(t6),E8e=n(t6,"P",{});var ekt=s(E8e);zEr=r(ekt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),ekt.forEach(t),QEr=i(t6),gc=n(t6,"P",{});var Ete=s(gc);WEr=r(Ete,`Note:
Loading a model from its configuration file does `),C8e=n(Ete,"STRONG",{});var okt=s(C8e);HEr=r(okt,"not"),okt.forEach(t),UEr=r(Ete,` load the model weights. It only affects the
model\u2019s configuration. Use `),$J=n(Ete,"A",{href:!0});var rkt=s($J);JEr=r(rkt,"from_pretrained()"),rkt.forEach(t),YEr=r(Ete," to load the model weights."),Ete.forEach(t),KEr=i(t6),T(D4.$$.fragment,t6),t6.forEach(t),ZEr=i(kl),$r=n(kl,"DIV",{class:!0});var Sl=s($r);T(ox.$$.fragment,Sl),eCr=i(Sl),w8e=n(Sl,"P",{});var tkt=s(w8e);oCr=r(tkt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),tkt.forEach(t),rCr=i(Sl),ln=n(Sl,"P",{});var a6=s(ln);tCr=r(a6,"The model class to instantiate is selected based on the "),A8e=n(a6,"CODE",{});var akt=s(A8e);aCr=r(akt,"model_type"),akt.forEach(t),nCr=r(a6,` property of the config object (either
passed as an argument or loaded from `),L8e=n(a6,"CODE",{});var nkt=s(L8e);sCr=r(nkt,"pretrained_model_name_or_path"),nkt.forEach(t),lCr=r(a6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y8e=n(a6,"CODE",{});var skt=s(y8e);iCr=r(skt,"pretrained_model_name_or_path"),skt.forEach(t),dCr=r(a6,":"),a6.forEach(t),cCr=i(Sl),Me=n(Sl,"UL",{});var Ce=s(Me);G4=n(Ce,"LI",{});var ije=s(G4);x8e=n(ije,"STRONG",{});var lkt=s(x8e);fCr=r(lkt,"bert"),lkt.forEach(t),mCr=r(ije," \u2014 "),kJ=n(ije,"A",{href:!0});var ikt=s(kJ);gCr=r(ikt,"TFBertLMHeadModel"),ikt.forEach(t),hCr=r(ije," (BERT model)"),ije.forEach(t),pCr=i(Ce),O4=n(Ce,"LI",{});var dje=s(O4);$8e=n(dje,"STRONG",{});var dkt=s($8e);_Cr=r(dkt,"camembert"),dkt.forEach(t),uCr=r(dje," \u2014 "),SJ=n(dje,"A",{href:!0});var ckt=s(SJ);bCr=r(ckt,"TFCamembertForCausalLM"),ckt.forEach(t),vCr=r(dje," (CamemBERT model)"),dje.forEach(t),FCr=i(Ce),V4=n(Ce,"LI",{});var cje=s(V4);k8e=n(cje,"STRONG",{});var fkt=s(k8e);TCr=r(fkt,"ctrl"),fkt.forEach(t),MCr=r(cje," \u2014 "),RJ=n(cje,"A",{href:!0});var mkt=s(RJ);ECr=r(mkt,"TFCTRLLMHeadModel"),mkt.forEach(t),CCr=r(cje," (CTRL model)"),cje.forEach(t),wCr=i(Ce),X4=n(Ce,"LI",{});var fje=s(X4);S8e=n(fje,"STRONG",{});var gkt=s(S8e);ACr=r(gkt,"gpt2"),gkt.forEach(t),LCr=r(fje," \u2014 "),PJ=n(fje,"A",{href:!0});var hkt=s(PJ);yCr=r(hkt,"TFGPT2LMHeadModel"),hkt.forEach(t),xCr=r(fje," (OpenAI GPT-2 model)"),fje.forEach(t),$Cr=i(Ce),z4=n(Ce,"LI",{});var mje=s(z4);R8e=n(mje,"STRONG",{});var pkt=s(R8e);kCr=r(pkt,"gptj"),pkt.forEach(t),SCr=r(mje," \u2014 "),BJ=n(mje,"A",{href:!0});var _kt=s(BJ);RCr=r(_kt,"TFGPTJForCausalLM"),_kt.forEach(t),PCr=r(mje," (GPT-J model)"),mje.forEach(t),BCr=i(Ce),Q4=n(Ce,"LI",{});var gje=s(Q4);P8e=n(gje,"STRONG",{});var ukt=s(P8e);ICr=r(ukt,"openai-gpt"),ukt.forEach(t),NCr=r(gje," \u2014 "),IJ=n(gje,"A",{href:!0});var bkt=s(IJ);qCr=r(bkt,"TFOpenAIGPTLMHeadModel"),bkt.forEach(t),jCr=r(gje," (OpenAI GPT model)"),gje.forEach(t),DCr=i(Ce),W4=n(Ce,"LI",{});var hje=s(W4);B8e=n(hje,"STRONG",{});var vkt=s(B8e);GCr=r(vkt,"opt"),vkt.forEach(t),OCr=r(hje," \u2014 "),NJ=n(hje,"A",{href:!0});var Fkt=s(NJ);VCr=r(Fkt,"TFOPTForCausalLM"),Fkt.forEach(t),XCr=r(hje," (OPT model)"),hje.forEach(t),zCr=i(Ce),H4=n(Ce,"LI",{});var pje=s(H4);I8e=n(pje,"STRONG",{});var Tkt=s(I8e);QCr=r(Tkt,"rembert"),Tkt.forEach(t),WCr=r(pje," \u2014 "),qJ=n(pje,"A",{href:!0});var Mkt=s(qJ);HCr=r(Mkt,"TFRemBertForCausalLM"),Mkt.forEach(t),UCr=r(pje," (RemBERT model)"),pje.forEach(t),JCr=i(Ce),U4=n(Ce,"LI",{});var _je=s(U4);N8e=n(_je,"STRONG",{});var Ekt=s(N8e);YCr=r(Ekt,"roberta"),Ekt.forEach(t),KCr=r(_je," \u2014 "),jJ=n(_je,"A",{href:!0});var Ckt=s(jJ);ZCr=r(Ckt,"TFRobertaForCausalLM"),Ckt.forEach(t),e3r=r(_je," (RoBERTa model)"),_je.forEach(t),o3r=i(Ce),J4=n(Ce,"LI",{});var uje=s(J4);q8e=n(uje,"STRONG",{});var wkt=s(q8e);r3r=r(wkt,"roformer"),wkt.forEach(t),t3r=r(uje," \u2014 "),DJ=n(uje,"A",{href:!0});var Akt=s(DJ);a3r=r(Akt,"TFRoFormerForCausalLM"),Akt.forEach(t),n3r=r(uje," (RoFormer model)"),uje.forEach(t),s3r=i(Ce),Y4=n(Ce,"LI",{});var bje=s(Y4);j8e=n(bje,"STRONG",{});var Lkt=s(j8e);l3r=r(Lkt,"transfo-xl"),Lkt.forEach(t),i3r=r(bje," \u2014 "),GJ=n(bje,"A",{href:!0});var ykt=s(GJ);d3r=r(ykt,"TFTransfoXLLMHeadModel"),ykt.forEach(t),c3r=r(bje," (Transformer-XL model)"),bje.forEach(t),f3r=i(Ce),K4=n(Ce,"LI",{});var vje=s(K4);D8e=n(vje,"STRONG",{});var xkt=s(D8e);m3r=r(xkt,"xlm"),xkt.forEach(t),g3r=r(vje," \u2014 "),OJ=n(vje,"A",{href:!0});var $kt=s(OJ);h3r=r($kt,"TFXLMWithLMHeadModel"),$kt.forEach(t),p3r=r(vje," (XLM model)"),vje.forEach(t),_3r=i(Ce),Z4=n(Ce,"LI",{});var Fje=s(Z4);G8e=n(Fje,"STRONG",{});var kkt=s(G8e);u3r=r(kkt,"xlnet"),kkt.forEach(t),b3r=r(Fje," \u2014 "),VJ=n(Fje,"A",{href:!0});var Skt=s(VJ);v3r=r(Skt,"TFXLNetLMHeadModel"),Skt.forEach(t),F3r=r(Fje," (XLNet model)"),Fje.forEach(t),Ce.forEach(t),T3r=i(Sl),T(eE.$$.fragment,Sl),Sl.forEach(t),kl.forEach(t),YXe=i(f),hc=n(f,"H2",{class:!0});var nWe=s(hc);oE=n(nWe,"A",{id:!0,class:!0,href:!0});var Rkt=s(oE);O8e=n(Rkt,"SPAN",{});var Pkt=s(O8e);T(rx.$$.fragment,Pkt),Pkt.forEach(t),Rkt.forEach(t),M3r=i(nWe),V8e=n(nWe,"SPAN",{});var Bkt=s(V8e);E3r=r(Bkt,"TFAutoModelForImageClassification"),Bkt.forEach(t),nWe.forEach(t),KXe=i(f),tr=n(f,"DIV",{class:!0});var Rl=s(tr);T(tx.$$.fragment,Rl),C3r=i(Rl),pc=n(Rl,"P",{});var Cte=s(pc);w3r=r(Cte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),XJ=n(Cte,"A",{href:!0});var Ikt=s(XJ);A3r=r(Ikt,"from_pretrained()"),Ikt.forEach(t),L3r=r(Cte," class method or the "),zJ=n(Cte,"A",{href:!0});var Nkt=s(zJ);y3r=r(Nkt,"from_config()"),Nkt.forEach(t),x3r=r(Cte,` class
method.`),Cte.forEach(t),$3r=i(Rl),ax=n(Rl,"P",{});var sWe=s(ax);k3r=r(sWe,"This class cannot be instantiated directly using "),X8e=n(sWe,"CODE",{});var qkt=s(X8e);S3r=r(qkt,"__init__()"),qkt.forEach(t),R3r=r(sWe," (throws an error)."),sWe.forEach(t),P3r=i(Rl),Bt=n(Rl,"DIV",{class:!0});var n6=s(Bt);T(nx.$$.fragment,n6),B3r=i(n6),z8e=n(n6,"P",{});var jkt=s(z8e);I3r=r(jkt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),jkt.forEach(t),N3r=i(n6),_c=n(n6,"P",{});var wte=s(_c);q3r=r(wte,`Note:
Loading a model from its configuration file does `),Q8e=n(wte,"STRONG",{});var Dkt=s(Q8e);j3r=r(Dkt,"not"),Dkt.forEach(t),D3r=r(wte,` load the model weights. It only affects the
model\u2019s configuration. Use `),QJ=n(wte,"A",{href:!0});var Gkt=s(QJ);G3r=r(Gkt,"from_pretrained()"),Gkt.forEach(t),O3r=r(wte," to load the model weights."),wte.forEach(t),V3r=i(n6),T(rE.$$.fragment,n6),n6.forEach(t),X3r=i(Rl),kr=n(Rl,"DIV",{class:!0});var Pl=s(kr);T(sx.$$.fragment,Pl),z3r=i(Pl),W8e=n(Pl,"P",{});var Okt=s(W8e);Q3r=r(Okt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Okt.forEach(t),W3r=i(Pl),dn=n(Pl,"P",{});var s6=s(dn);H3r=r(s6,"The model class to instantiate is selected based on the "),H8e=n(s6,"CODE",{});var Vkt=s(H8e);U3r=r(Vkt,"model_type"),Vkt.forEach(t),J3r=r(s6,` property of the config object (either
passed as an argument or loaded from `),U8e=n(s6,"CODE",{});var Xkt=s(U8e);Y3r=r(Xkt,"pretrained_model_name_or_path"),Xkt.forEach(t),K3r=r(s6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J8e=n(s6,"CODE",{});var zkt=s(J8e);Z3r=r(zkt,"pretrained_model_name_or_path"),zkt.forEach(t),e5r=r(s6,":"),s6.forEach(t),o5r=i(Pl),tt=n(Pl,"UL",{});var Bl=s(tt);tE=n(Bl,"LI",{});var Tje=s(tE);Y8e=n(Tje,"STRONG",{});var Qkt=s(Y8e);r5r=r(Qkt,"convnext"),Qkt.forEach(t),t5r=r(Tje," \u2014 "),WJ=n(Tje,"A",{href:!0});var Wkt=s(WJ);a5r=r(Wkt,"TFConvNextForImageClassification"),Wkt.forEach(t),n5r=r(Tje," (ConvNeXT model)"),Tje.forEach(t),s5r=i(Bl),aE=n(Bl,"LI",{});var Mje=s(aE);K8e=n(Mje,"STRONG",{});var Hkt=s(K8e);l5r=r(Hkt,"data2vec-vision"),Hkt.forEach(t),i5r=r(Mje," \u2014 "),HJ=n(Mje,"A",{href:!0});var Ukt=s(HJ);d5r=r(Ukt,"TFData2VecVisionForImageClassification"),Ukt.forEach(t),c5r=r(Mje," (Data2VecVision model)"),Mje.forEach(t),f5r=i(Bl),nE=n(Bl,"LI",{});var Eje=s(nE);Z8e=n(Eje,"STRONG",{});var Jkt=s(Z8e);m5r=r(Jkt,"regnet"),Jkt.forEach(t),g5r=r(Eje," \u2014 "),UJ=n(Eje,"A",{href:!0});var Ykt=s(UJ);h5r=r(Ykt,"TFRegNetForImageClassification"),Ykt.forEach(t),p5r=r(Eje," (RegNet model)"),Eje.forEach(t),_5r=i(Bl),sE=n(Bl,"LI",{});var Cje=s(sE);eMe=n(Cje,"STRONG",{});var Kkt=s(eMe);u5r=r(Kkt,"swin"),Kkt.forEach(t),b5r=r(Cje," \u2014 "),JJ=n(Cje,"A",{href:!0});var Zkt=s(JJ);v5r=r(Zkt,"TFSwinForImageClassification"),Zkt.forEach(t),F5r=r(Cje," (Swin Transformer model)"),Cje.forEach(t),T5r=i(Bl),lE=n(Bl,"LI",{});var wje=s(lE);oMe=n(wje,"STRONG",{});var eSt=s(oMe);M5r=r(eSt,"vit"),eSt.forEach(t),E5r=r(wje," \u2014 "),YJ=n(wje,"A",{href:!0});var oSt=s(YJ);C5r=r(oSt,"TFViTForImageClassification"),oSt.forEach(t),w5r=r(wje," (ViT model)"),wje.forEach(t),Bl.forEach(t),A5r=i(Pl),T(iE.$$.fragment,Pl),Pl.forEach(t),Rl.forEach(t),ZXe=i(f),uc=n(f,"H2",{class:!0});var lWe=s(uc);dE=n(lWe,"A",{id:!0,class:!0,href:!0});var rSt=s(dE);rMe=n(rSt,"SPAN",{});var tSt=s(rMe);T(lx.$$.fragment,tSt),tSt.forEach(t),rSt.forEach(t),L5r=i(lWe),tMe=n(lWe,"SPAN",{});var aSt=s(tMe);y5r=r(aSt,"TFAutoModelForMaskedLM"),aSt.forEach(t),lWe.forEach(t),eze=i(f),ar=n(f,"DIV",{class:!0});var Il=s(ar);T(ix.$$.fragment,Il),x5r=i(Il),bc=n(Il,"P",{});var Ate=s(bc);$5r=r(Ate,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),KJ=n(Ate,"A",{href:!0});var nSt=s(KJ);k5r=r(nSt,"from_pretrained()"),nSt.forEach(t),S5r=r(Ate," class method or the "),ZJ=n(Ate,"A",{href:!0});var sSt=s(ZJ);R5r=r(sSt,"from_config()"),sSt.forEach(t),P5r=r(Ate,` class
method.`),Ate.forEach(t),B5r=i(Il),dx=n(Il,"P",{});var iWe=s(dx);I5r=r(iWe,"This class cannot be instantiated directly using "),aMe=n(iWe,"CODE",{});var lSt=s(aMe);N5r=r(lSt,"__init__()"),lSt.forEach(t),q5r=r(iWe," (throws an error)."),iWe.forEach(t),j5r=i(Il),It=n(Il,"DIV",{class:!0});var l6=s(It);T(cx.$$.fragment,l6),D5r=i(l6),nMe=n(l6,"P",{});var iSt=s(nMe);G5r=r(iSt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),iSt.forEach(t),O5r=i(l6),vc=n(l6,"P",{});var Lte=s(vc);V5r=r(Lte,`Note:
Loading a model from its configuration file does `),sMe=n(Lte,"STRONG",{});var dSt=s(sMe);X5r=r(dSt,"not"),dSt.forEach(t),z5r=r(Lte,` load the model weights. It only affects the
model\u2019s configuration. Use `),eY=n(Lte,"A",{href:!0});var cSt=s(eY);Q5r=r(cSt,"from_pretrained()"),cSt.forEach(t),W5r=r(Lte," to load the model weights."),Lte.forEach(t),H5r=i(l6),T(cE.$$.fragment,l6),l6.forEach(t),U5r=i(Il),Sr=n(Il,"DIV",{class:!0});var Nl=s(Sr);T(fx.$$.fragment,Nl),J5r=i(Nl),lMe=n(Nl,"P",{});var fSt=s(lMe);Y5r=r(fSt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),fSt.forEach(t),K5r=i(Nl),cn=n(Nl,"P",{});var i6=s(cn);Z5r=r(i6,"The model class to instantiate is selected based on the "),iMe=n(i6,"CODE",{});var mSt=s(iMe);e0r=r(mSt,"model_type"),mSt.forEach(t),o0r=r(i6,` property of the config object (either
passed as an argument or loaded from `),dMe=n(i6,"CODE",{});var gSt=s(dMe);r0r=r(gSt,"pretrained_model_name_or_path"),gSt.forEach(t),t0r=r(i6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cMe=n(i6,"CODE",{});var hSt=s(cMe);a0r=r(hSt,"pretrained_model_name_or_path"),hSt.forEach(t),n0r=r(i6,":"),i6.forEach(t),s0r=i(Nl),ie=n(Nl,"UL",{});var fe=s(ie);fE=n(fe,"LI",{});var Aje=s(fE);fMe=n(Aje,"STRONG",{});var pSt=s(fMe);l0r=r(pSt,"albert"),pSt.forEach(t),i0r=r(Aje," \u2014 "),oY=n(Aje,"A",{href:!0});var _St=s(oY);d0r=r(_St,"TFAlbertForMaskedLM"),_St.forEach(t),c0r=r(Aje," (ALBERT model)"),Aje.forEach(t),f0r=i(fe),mE=n(fe,"LI",{});var Lje=s(mE);mMe=n(Lje,"STRONG",{});var uSt=s(mMe);m0r=r(uSt,"bert"),uSt.forEach(t),g0r=r(Lje," \u2014 "),rY=n(Lje,"A",{href:!0});var bSt=s(rY);h0r=r(bSt,"TFBertForMaskedLM"),bSt.forEach(t),p0r=r(Lje," (BERT model)"),Lje.forEach(t),_0r=i(fe),gE=n(fe,"LI",{});var yje=s(gE);gMe=n(yje,"STRONG",{});var vSt=s(gMe);u0r=r(vSt,"camembert"),vSt.forEach(t),b0r=r(yje," \u2014 "),tY=n(yje,"A",{href:!0});var FSt=s(tY);v0r=r(FSt,"TFCamembertForMaskedLM"),FSt.forEach(t),F0r=r(yje," (CamemBERT model)"),yje.forEach(t),T0r=i(fe),hE=n(fe,"LI",{});var xje=s(hE);hMe=n(xje,"STRONG",{});var TSt=s(hMe);M0r=r(TSt,"convbert"),TSt.forEach(t),E0r=r(xje," \u2014 "),aY=n(xje,"A",{href:!0});var MSt=s(aY);C0r=r(MSt,"TFConvBertForMaskedLM"),MSt.forEach(t),w0r=r(xje," (ConvBERT model)"),xje.forEach(t),A0r=i(fe),pE=n(fe,"LI",{});var $je=s(pE);pMe=n($je,"STRONG",{});var ESt=s(pMe);L0r=r(ESt,"deberta"),ESt.forEach(t),y0r=r($je," \u2014 "),nY=n($je,"A",{href:!0});var CSt=s(nY);x0r=r(CSt,"TFDebertaForMaskedLM"),CSt.forEach(t),$0r=r($je," (DeBERTa model)"),$je.forEach(t),k0r=i(fe),_E=n(fe,"LI",{});var kje=s(_E);_Me=n(kje,"STRONG",{});var wSt=s(_Me);S0r=r(wSt,"deberta-v2"),wSt.forEach(t),R0r=r(kje," \u2014 "),sY=n(kje,"A",{href:!0});var ASt=s(sY);P0r=r(ASt,"TFDebertaV2ForMaskedLM"),ASt.forEach(t),B0r=r(kje," (DeBERTa-v2 model)"),kje.forEach(t),I0r=i(fe),uE=n(fe,"LI",{});var Sje=s(uE);uMe=n(Sje,"STRONG",{});var LSt=s(uMe);N0r=r(LSt,"distilbert"),LSt.forEach(t),q0r=r(Sje," \u2014 "),lY=n(Sje,"A",{href:!0});var ySt=s(lY);j0r=r(ySt,"TFDistilBertForMaskedLM"),ySt.forEach(t),D0r=r(Sje," (DistilBERT model)"),Sje.forEach(t),G0r=i(fe),bE=n(fe,"LI",{});var Rje=s(bE);bMe=n(Rje,"STRONG",{});var xSt=s(bMe);O0r=r(xSt,"electra"),xSt.forEach(t),V0r=r(Rje," \u2014 "),iY=n(Rje,"A",{href:!0});var $St=s(iY);X0r=r($St,"TFElectraForMaskedLM"),$St.forEach(t),z0r=r(Rje," (ELECTRA model)"),Rje.forEach(t),Q0r=i(fe),vE=n(fe,"LI",{});var Pje=s(vE);vMe=n(Pje,"STRONG",{});var kSt=s(vMe);W0r=r(kSt,"flaubert"),kSt.forEach(t),H0r=r(Pje," \u2014 "),dY=n(Pje,"A",{href:!0});var SSt=s(dY);U0r=r(SSt,"TFFlaubertWithLMHeadModel"),SSt.forEach(t),J0r=r(Pje," (FlauBERT model)"),Pje.forEach(t),Y0r=i(fe),FE=n(fe,"LI",{});var Bje=s(FE);FMe=n(Bje,"STRONG",{});var RSt=s(FMe);K0r=r(RSt,"funnel"),RSt.forEach(t),Z0r=r(Bje," \u2014 "),cY=n(Bje,"A",{href:!0});var PSt=s(cY);ewr=r(PSt,"TFFunnelForMaskedLM"),PSt.forEach(t),owr=r(Bje," (Funnel Transformer model)"),Bje.forEach(t),rwr=i(fe),TE=n(fe,"LI",{});var Ije=s(TE);TMe=n(Ije,"STRONG",{});var BSt=s(TMe);twr=r(BSt,"layoutlm"),BSt.forEach(t),awr=r(Ije," \u2014 "),fY=n(Ije,"A",{href:!0});var ISt=s(fY);nwr=r(ISt,"TFLayoutLMForMaskedLM"),ISt.forEach(t),swr=r(Ije," (LayoutLM model)"),Ije.forEach(t),lwr=i(fe),ME=n(fe,"LI",{});var Nje=s(ME);MMe=n(Nje,"STRONG",{});var NSt=s(MMe);iwr=r(NSt,"longformer"),NSt.forEach(t),dwr=r(Nje," \u2014 "),mY=n(Nje,"A",{href:!0});var qSt=s(mY);cwr=r(qSt,"TFLongformerForMaskedLM"),qSt.forEach(t),fwr=r(Nje," (Longformer model)"),Nje.forEach(t),mwr=i(fe),EE=n(fe,"LI",{});var qje=s(EE);EMe=n(qje,"STRONG",{});var jSt=s(EMe);gwr=r(jSt,"mobilebert"),jSt.forEach(t),hwr=r(qje," \u2014 "),gY=n(qje,"A",{href:!0});var DSt=s(gY);pwr=r(DSt,"TFMobileBertForMaskedLM"),DSt.forEach(t),_wr=r(qje," (MobileBERT model)"),qje.forEach(t),uwr=i(fe),CE=n(fe,"LI",{});var jje=s(CE);CMe=n(jje,"STRONG",{});var GSt=s(CMe);bwr=r(GSt,"mpnet"),GSt.forEach(t),vwr=r(jje," \u2014 "),hY=n(jje,"A",{href:!0});var OSt=s(hY);Fwr=r(OSt,"TFMPNetForMaskedLM"),OSt.forEach(t),Twr=r(jje," (MPNet model)"),jje.forEach(t),Mwr=i(fe),wE=n(fe,"LI",{});var Dje=s(wE);wMe=n(Dje,"STRONG",{});var VSt=s(wMe);Ewr=r(VSt,"rembert"),VSt.forEach(t),Cwr=r(Dje," \u2014 "),pY=n(Dje,"A",{href:!0});var XSt=s(pY);wwr=r(XSt,"TFRemBertForMaskedLM"),XSt.forEach(t),Awr=r(Dje," (RemBERT model)"),Dje.forEach(t),Lwr=i(fe),AE=n(fe,"LI",{});var Gje=s(AE);AMe=n(Gje,"STRONG",{});var zSt=s(AMe);ywr=r(zSt,"roberta"),zSt.forEach(t),xwr=r(Gje," \u2014 "),_Y=n(Gje,"A",{href:!0});var QSt=s(_Y);$wr=r(QSt,"TFRobertaForMaskedLM"),QSt.forEach(t),kwr=r(Gje," (RoBERTa model)"),Gje.forEach(t),Swr=i(fe),LE=n(fe,"LI",{});var Oje=s(LE);LMe=n(Oje,"STRONG",{});var WSt=s(LMe);Rwr=r(WSt,"roformer"),WSt.forEach(t),Pwr=r(Oje," \u2014 "),uY=n(Oje,"A",{href:!0});var HSt=s(uY);Bwr=r(HSt,"TFRoFormerForMaskedLM"),HSt.forEach(t),Iwr=r(Oje," (RoFormer model)"),Oje.forEach(t),Nwr=i(fe),yE=n(fe,"LI",{});var Vje=s(yE);yMe=n(Vje,"STRONG",{});var USt=s(yMe);qwr=r(USt,"tapas"),USt.forEach(t),jwr=r(Vje," \u2014 "),bY=n(Vje,"A",{href:!0});var JSt=s(bY);Dwr=r(JSt,"TFTapasForMaskedLM"),JSt.forEach(t),Gwr=r(Vje," (TAPAS model)"),Vje.forEach(t),Owr=i(fe),xE=n(fe,"LI",{});var Xje=s(xE);xMe=n(Xje,"STRONG",{});var YSt=s(xMe);Vwr=r(YSt,"xlm"),YSt.forEach(t),Xwr=r(Xje," \u2014 "),vY=n(Xje,"A",{href:!0});var KSt=s(vY);zwr=r(KSt,"TFXLMWithLMHeadModel"),KSt.forEach(t),Qwr=r(Xje," (XLM model)"),Xje.forEach(t),Wwr=i(fe),$E=n(fe,"LI",{});var zje=s($E);$Me=n(zje,"STRONG",{});var ZSt=s($Me);Hwr=r(ZSt,"xlm-roberta"),ZSt.forEach(t),Uwr=r(zje," \u2014 "),FY=n(zje,"A",{href:!0});var eRt=s(FY);Jwr=r(eRt,"TFXLMRobertaForMaskedLM"),eRt.forEach(t),Ywr=r(zje," (XLM-RoBERTa model)"),zje.forEach(t),fe.forEach(t),Kwr=i(Nl),T(kE.$$.fragment,Nl),Nl.forEach(t),Il.forEach(t),oze=i(f),Fc=n(f,"H2",{class:!0});var dWe=s(Fc);SE=n(dWe,"A",{id:!0,class:!0,href:!0});var oRt=s(SE);kMe=n(oRt,"SPAN",{});var rRt=s(kMe);T(mx.$$.fragment,rRt),rRt.forEach(t),oRt.forEach(t),Zwr=i(dWe),SMe=n(dWe,"SPAN",{});var tRt=s(SMe);eAr=r(tRt,"TFAutoModelForSeq2SeqLM"),tRt.forEach(t),dWe.forEach(t),rze=i(f),nr=n(f,"DIV",{class:!0});var ql=s(nr);T(gx.$$.fragment,ql),oAr=i(ql),Tc=n(ql,"P",{});var yte=s(Tc);rAr=r(yte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),TY=n(yte,"A",{href:!0});var aRt=s(TY);tAr=r(aRt,"from_pretrained()"),aRt.forEach(t),aAr=r(yte," class method or the "),MY=n(yte,"A",{href:!0});var nRt=s(MY);nAr=r(nRt,"from_config()"),nRt.forEach(t),sAr=r(yte,` class
method.`),yte.forEach(t),lAr=i(ql),hx=n(ql,"P",{});var cWe=s(hx);iAr=r(cWe,"This class cannot be instantiated directly using "),RMe=n(cWe,"CODE",{});var sRt=s(RMe);dAr=r(sRt,"__init__()"),sRt.forEach(t),cAr=r(cWe," (throws an error)."),cWe.forEach(t),fAr=i(ql),Nt=n(ql,"DIV",{class:!0});var d6=s(Nt);T(px.$$.fragment,d6),mAr=i(d6),PMe=n(d6,"P",{});var lRt=s(PMe);gAr=r(lRt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),lRt.forEach(t),hAr=i(d6),Mc=n(d6,"P",{});var xte=s(Mc);pAr=r(xte,`Note:
Loading a model from its configuration file does `),BMe=n(xte,"STRONG",{});var iRt=s(BMe);_Ar=r(iRt,"not"),iRt.forEach(t),uAr=r(xte,` load the model weights. It only affects the
model\u2019s configuration. Use `),EY=n(xte,"A",{href:!0});var dRt=s(EY);bAr=r(dRt,"from_pretrained()"),dRt.forEach(t),vAr=r(xte," to load the model weights."),xte.forEach(t),FAr=i(d6),T(RE.$$.fragment,d6),d6.forEach(t),TAr=i(ql),Rr=n(ql,"DIV",{class:!0});var jl=s(Rr);T(_x.$$.fragment,jl),MAr=i(jl),IMe=n(jl,"P",{});var cRt=s(IMe);EAr=r(cRt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),cRt.forEach(t),CAr=i(jl),fn=n(jl,"P",{});var c6=s(fn);wAr=r(c6,"The model class to instantiate is selected based on the "),NMe=n(c6,"CODE",{});var fRt=s(NMe);AAr=r(fRt,"model_type"),fRt.forEach(t),LAr=r(c6,` property of the config object (either
passed as an argument or loaded from `),qMe=n(c6,"CODE",{});var mRt=s(qMe);yAr=r(mRt,"pretrained_model_name_or_path"),mRt.forEach(t),xAr=r(c6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jMe=n(c6,"CODE",{});var gRt=s(jMe);$Ar=r(gRt,"pretrained_model_name_or_path"),gRt.forEach(t),kAr=r(c6,":"),c6.forEach(t),SAr=i(jl),ye=n(jl,"UL",{});var Ie=s(ye);PE=n(Ie,"LI",{});var Qje=s(PE);DMe=n(Qje,"STRONG",{});var hRt=s(DMe);RAr=r(hRt,"bart"),hRt.forEach(t),PAr=r(Qje," \u2014 "),CY=n(Qje,"A",{href:!0});var pRt=s(CY);BAr=r(pRt,"TFBartForConditionalGeneration"),pRt.forEach(t),IAr=r(Qje," (BART model)"),Qje.forEach(t),NAr=i(Ie),BE=n(Ie,"LI",{});var Wje=s(BE);GMe=n(Wje,"STRONG",{});var _Rt=s(GMe);qAr=r(_Rt,"blenderbot"),_Rt.forEach(t),jAr=r(Wje," \u2014 "),wY=n(Wje,"A",{href:!0});var uRt=s(wY);DAr=r(uRt,"TFBlenderbotForConditionalGeneration"),uRt.forEach(t),GAr=r(Wje," (Blenderbot model)"),Wje.forEach(t),OAr=i(Ie),IE=n(Ie,"LI",{});var Hje=s(IE);OMe=n(Hje,"STRONG",{});var bRt=s(OMe);VAr=r(bRt,"blenderbot-small"),bRt.forEach(t),XAr=r(Hje," \u2014 "),AY=n(Hje,"A",{href:!0});var vRt=s(AY);zAr=r(vRt,"TFBlenderbotSmallForConditionalGeneration"),vRt.forEach(t),QAr=r(Hje," (BlenderbotSmall model)"),Hje.forEach(t),WAr=i(Ie),NE=n(Ie,"LI",{});var Uje=s(NE);VMe=n(Uje,"STRONG",{});var FRt=s(VMe);HAr=r(FRt,"encoder-decoder"),FRt.forEach(t),UAr=r(Uje," \u2014 "),LY=n(Uje,"A",{href:!0});var TRt=s(LY);JAr=r(TRt,"TFEncoderDecoderModel"),TRt.forEach(t),YAr=r(Uje," (Encoder decoder model)"),Uje.forEach(t),KAr=i(Ie),qE=n(Ie,"LI",{});var Jje=s(qE);XMe=n(Jje,"STRONG",{});var MRt=s(XMe);ZAr=r(MRt,"led"),MRt.forEach(t),e6r=r(Jje," \u2014 "),yY=n(Jje,"A",{href:!0});var ERt=s(yY);o6r=r(ERt,"TFLEDForConditionalGeneration"),ERt.forEach(t),r6r=r(Jje," (LED model)"),Jje.forEach(t),t6r=i(Ie),jE=n(Ie,"LI",{});var Yje=s(jE);zMe=n(Yje,"STRONG",{});var CRt=s(zMe);a6r=r(CRt,"marian"),CRt.forEach(t),n6r=r(Yje," \u2014 "),xY=n(Yje,"A",{href:!0});var wRt=s(xY);s6r=r(wRt,"TFMarianMTModel"),wRt.forEach(t),l6r=r(Yje," (Marian model)"),Yje.forEach(t),i6r=i(Ie),DE=n(Ie,"LI",{});var Kje=s(DE);QMe=n(Kje,"STRONG",{});var ARt=s(QMe);d6r=r(ARt,"mbart"),ARt.forEach(t),c6r=r(Kje," \u2014 "),$Y=n(Kje,"A",{href:!0});var LRt=s($Y);f6r=r(LRt,"TFMBartForConditionalGeneration"),LRt.forEach(t),m6r=r(Kje," (mBART model)"),Kje.forEach(t),g6r=i(Ie),GE=n(Ie,"LI",{});var Zje=s(GE);WMe=n(Zje,"STRONG",{});var yRt=s(WMe);h6r=r(yRt,"mt5"),yRt.forEach(t),p6r=r(Zje," \u2014 "),kY=n(Zje,"A",{href:!0});var xRt=s(kY);_6r=r(xRt,"TFMT5ForConditionalGeneration"),xRt.forEach(t),u6r=r(Zje," (MT5 model)"),Zje.forEach(t),b6r=i(Ie),OE=n(Ie,"LI",{});var eDe=s(OE);HMe=n(eDe,"STRONG",{});var $Rt=s(HMe);v6r=r($Rt,"pegasus"),$Rt.forEach(t),F6r=r(eDe," \u2014 "),SY=n(eDe,"A",{href:!0});var kRt=s(SY);T6r=r(kRt,"TFPegasusForConditionalGeneration"),kRt.forEach(t),M6r=r(eDe," (Pegasus model)"),eDe.forEach(t),E6r=i(Ie),VE=n(Ie,"LI",{});var oDe=s(VE);UMe=n(oDe,"STRONG",{});var SRt=s(UMe);C6r=r(SRt,"t5"),SRt.forEach(t),w6r=r(oDe," \u2014 "),RY=n(oDe,"A",{href:!0});var RRt=s(RY);A6r=r(RRt,"TFT5ForConditionalGeneration"),RRt.forEach(t),L6r=r(oDe," (T5 model)"),oDe.forEach(t),Ie.forEach(t),y6r=i(jl),T(XE.$$.fragment,jl),jl.forEach(t),ql.forEach(t),tze=i(f),Ec=n(f,"H2",{class:!0});var fWe=s(Ec);zE=n(fWe,"A",{id:!0,class:!0,href:!0});var PRt=s(zE);JMe=n(PRt,"SPAN",{});var BRt=s(JMe);T(ux.$$.fragment,BRt),BRt.forEach(t),PRt.forEach(t),x6r=i(fWe),YMe=n(fWe,"SPAN",{});var IRt=s(YMe);$6r=r(IRt,"TFAutoModelForSequenceClassification"),IRt.forEach(t),fWe.forEach(t),aze=i(f),sr=n(f,"DIV",{class:!0});var Dl=s(sr);T(bx.$$.fragment,Dl),k6r=i(Dl),Cc=n(Dl,"P",{});var $te=s(Cc);S6r=r($te,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),PY=n($te,"A",{href:!0});var NRt=s(PY);R6r=r(NRt,"from_pretrained()"),NRt.forEach(t),P6r=r($te," class method or the "),BY=n($te,"A",{href:!0});var qRt=s(BY);B6r=r(qRt,"from_config()"),qRt.forEach(t),I6r=r($te,` class
method.`),$te.forEach(t),N6r=i(Dl),vx=n(Dl,"P",{});var mWe=s(vx);q6r=r(mWe,"This class cannot be instantiated directly using "),KMe=n(mWe,"CODE",{});var jRt=s(KMe);j6r=r(jRt,"__init__()"),jRt.forEach(t),D6r=r(mWe," (throws an error)."),mWe.forEach(t),G6r=i(Dl),qt=n(Dl,"DIV",{class:!0});var f6=s(qt);T(Fx.$$.fragment,f6),O6r=i(f6),ZMe=n(f6,"P",{});var DRt=s(ZMe);V6r=r(DRt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),DRt.forEach(t),X6r=i(f6),wc=n(f6,"P",{});var kte=s(wc);z6r=r(kte,`Note:
Loading a model from its configuration file does `),e4e=n(kte,"STRONG",{});var GRt=s(e4e);Q6r=r(GRt,"not"),GRt.forEach(t),W6r=r(kte,` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=n(kte,"A",{href:!0});var ORt=s(IY);H6r=r(ORt,"from_pretrained()"),ORt.forEach(t),U6r=r(kte," to load the model weights."),kte.forEach(t),J6r=i(f6),T(QE.$$.fragment,f6),f6.forEach(t),Y6r=i(Dl),Pr=n(Dl,"DIV",{class:!0});var Gl=s(Pr);T(Tx.$$.fragment,Gl),K6r=i(Gl),o4e=n(Gl,"P",{});var VRt=s(o4e);Z6r=r(VRt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),VRt.forEach(t),eLr=i(Gl),mn=n(Gl,"P",{});var m6=s(mn);oLr=r(m6,"The model class to instantiate is selected based on the "),r4e=n(m6,"CODE",{});var XRt=s(r4e);rLr=r(XRt,"model_type"),XRt.forEach(t),tLr=r(m6,` property of the config object (either
passed as an argument or loaded from `),t4e=n(m6,"CODE",{});var zRt=s(t4e);aLr=r(zRt,"pretrained_model_name_or_path"),zRt.forEach(t),nLr=r(m6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a4e=n(m6,"CODE",{});var QRt=s(a4e);sLr=r(QRt,"pretrained_model_name_or_path"),QRt.forEach(t),lLr=r(m6,":"),m6.forEach(t),iLr=i(Gl),te=n(Gl,"UL",{});var ne=s(te);WE=n(ne,"LI",{});var rDe=s(WE);n4e=n(rDe,"STRONG",{});var WRt=s(n4e);dLr=r(WRt,"albert"),WRt.forEach(t),cLr=r(rDe," \u2014 "),NY=n(rDe,"A",{href:!0});var HRt=s(NY);fLr=r(HRt,"TFAlbertForSequenceClassification"),HRt.forEach(t),mLr=r(rDe," (ALBERT model)"),rDe.forEach(t),gLr=i(ne),HE=n(ne,"LI",{});var tDe=s(HE);s4e=n(tDe,"STRONG",{});var URt=s(s4e);hLr=r(URt,"bert"),URt.forEach(t),pLr=r(tDe," \u2014 "),qY=n(tDe,"A",{href:!0});var JRt=s(qY);_Lr=r(JRt,"TFBertForSequenceClassification"),JRt.forEach(t),uLr=r(tDe," (BERT model)"),tDe.forEach(t),bLr=i(ne),UE=n(ne,"LI",{});var aDe=s(UE);l4e=n(aDe,"STRONG",{});var YRt=s(l4e);vLr=r(YRt,"camembert"),YRt.forEach(t),FLr=r(aDe," \u2014 "),jY=n(aDe,"A",{href:!0});var KRt=s(jY);TLr=r(KRt,"TFCamembertForSequenceClassification"),KRt.forEach(t),MLr=r(aDe," (CamemBERT model)"),aDe.forEach(t),ELr=i(ne),JE=n(ne,"LI",{});var nDe=s(JE);i4e=n(nDe,"STRONG",{});var ZRt=s(i4e);CLr=r(ZRt,"convbert"),ZRt.forEach(t),wLr=r(nDe," \u2014 "),DY=n(nDe,"A",{href:!0});var ePt=s(DY);ALr=r(ePt,"TFConvBertForSequenceClassification"),ePt.forEach(t),LLr=r(nDe," (ConvBERT model)"),nDe.forEach(t),yLr=i(ne),YE=n(ne,"LI",{});var sDe=s(YE);d4e=n(sDe,"STRONG",{});var oPt=s(d4e);xLr=r(oPt,"ctrl"),oPt.forEach(t),$Lr=r(sDe," \u2014 "),GY=n(sDe,"A",{href:!0});var rPt=s(GY);kLr=r(rPt,"TFCTRLForSequenceClassification"),rPt.forEach(t),SLr=r(sDe," (CTRL model)"),sDe.forEach(t),RLr=i(ne),KE=n(ne,"LI",{});var lDe=s(KE);c4e=n(lDe,"STRONG",{});var tPt=s(c4e);PLr=r(tPt,"deberta"),tPt.forEach(t),BLr=r(lDe," \u2014 "),OY=n(lDe,"A",{href:!0});var aPt=s(OY);ILr=r(aPt,"TFDebertaForSequenceClassification"),aPt.forEach(t),NLr=r(lDe," (DeBERTa model)"),lDe.forEach(t),qLr=i(ne),ZE=n(ne,"LI",{});var iDe=s(ZE);f4e=n(iDe,"STRONG",{});var nPt=s(f4e);jLr=r(nPt,"deberta-v2"),nPt.forEach(t),DLr=r(iDe," \u2014 "),VY=n(iDe,"A",{href:!0});var sPt=s(VY);GLr=r(sPt,"TFDebertaV2ForSequenceClassification"),sPt.forEach(t),OLr=r(iDe," (DeBERTa-v2 model)"),iDe.forEach(t),VLr=i(ne),eC=n(ne,"LI",{});var dDe=s(eC);m4e=n(dDe,"STRONG",{});var lPt=s(m4e);XLr=r(lPt,"distilbert"),lPt.forEach(t),zLr=r(dDe," \u2014 "),XY=n(dDe,"A",{href:!0});var iPt=s(XY);QLr=r(iPt,"TFDistilBertForSequenceClassification"),iPt.forEach(t),WLr=r(dDe," (DistilBERT model)"),dDe.forEach(t),HLr=i(ne),oC=n(ne,"LI",{});var cDe=s(oC);g4e=n(cDe,"STRONG",{});var dPt=s(g4e);ULr=r(dPt,"electra"),dPt.forEach(t),JLr=r(cDe," \u2014 "),zY=n(cDe,"A",{href:!0});var cPt=s(zY);YLr=r(cPt,"TFElectraForSequenceClassification"),cPt.forEach(t),KLr=r(cDe," (ELECTRA model)"),cDe.forEach(t),ZLr=i(ne),rC=n(ne,"LI",{});var fDe=s(rC);h4e=n(fDe,"STRONG",{});var fPt=s(h4e);eyr=r(fPt,"flaubert"),fPt.forEach(t),oyr=r(fDe," \u2014 "),QY=n(fDe,"A",{href:!0});var mPt=s(QY);ryr=r(mPt,"TFFlaubertForSequenceClassification"),mPt.forEach(t),tyr=r(fDe," (FlauBERT model)"),fDe.forEach(t),ayr=i(ne),tC=n(ne,"LI",{});var mDe=s(tC);p4e=n(mDe,"STRONG",{});var gPt=s(p4e);nyr=r(gPt,"funnel"),gPt.forEach(t),syr=r(mDe," \u2014 "),WY=n(mDe,"A",{href:!0});var hPt=s(WY);lyr=r(hPt,"TFFunnelForSequenceClassification"),hPt.forEach(t),iyr=r(mDe," (Funnel Transformer model)"),mDe.forEach(t),dyr=i(ne),aC=n(ne,"LI",{});var gDe=s(aC);_4e=n(gDe,"STRONG",{});var pPt=s(_4e);cyr=r(pPt,"gpt2"),pPt.forEach(t),fyr=r(gDe," \u2014 "),HY=n(gDe,"A",{href:!0});var _Pt=s(HY);myr=r(_Pt,"TFGPT2ForSequenceClassification"),_Pt.forEach(t),gyr=r(gDe," (OpenAI GPT-2 model)"),gDe.forEach(t),hyr=i(ne),nC=n(ne,"LI",{});var hDe=s(nC);u4e=n(hDe,"STRONG",{});var uPt=s(u4e);pyr=r(uPt,"gptj"),uPt.forEach(t),_yr=r(hDe," \u2014 "),UY=n(hDe,"A",{href:!0});var bPt=s(UY);uyr=r(bPt,"TFGPTJForSequenceClassification"),bPt.forEach(t),byr=r(hDe," (GPT-J model)"),hDe.forEach(t),vyr=i(ne),sC=n(ne,"LI",{});var pDe=s(sC);b4e=n(pDe,"STRONG",{});var vPt=s(b4e);Fyr=r(vPt,"layoutlm"),vPt.forEach(t),Tyr=r(pDe," \u2014 "),JY=n(pDe,"A",{href:!0});var FPt=s(JY);Myr=r(FPt,"TFLayoutLMForSequenceClassification"),FPt.forEach(t),Eyr=r(pDe," (LayoutLM model)"),pDe.forEach(t),Cyr=i(ne),lC=n(ne,"LI",{});var _De=s(lC);v4e=n(_De,"STRONG",{});var TPt=s(v4e);wyr=r(TPt,"longformer"),TPt.forEach(t),Ayr=r(_De," \u2014 "),YY=n(_De,"A",{href:!0});var MPt=s(YY);Lyr=r(MPt,"TFLongformerForSequenceClassification"),MPt.forEach(t),yyr=r(_De," (Longformer model)"),_De.forEach(t),xyr=i(ne),iC=n(ne,"LI",{});var uDe=s(iC);F4e=n(uDe,"STRONG",{});var EPt=s(F4e);$yr=r(EPt,"mobilebert"),EPt.forEach(t),kyr=r(uDe," \u2014 "),KY=n(uDe,"A",{href:!0});var CPt=s(KY);Syr=r(CPt,"TFMobileBertForSequenceClassification"),CPt.forEach(t),Ryr=r(uDe," (MobileBERT model)"),uDe.forEach(t),Pyr=i(ne),dC=n(ne,"LI",{});var bDe=s(dC);T4e=n(bDe,"STRONG",{});var wPt=s(T4e);Byr=r(wPt,"mpnet"),wPt.forEach(t),Iyr=r(bDe," \u2014 "),ZY=n(bDe,"A",{href:!0});var APt=s(ZY);Nyr=r(APt,"TFMPNetForSequenceClassification"),APt.forEach(t),qyr=r(bDe," (MPNet model)"),bDe.forEach(t),jyr=i(ne),cC=n(ne,"LI",{});var vDe=s(cC);M4e=n(vDe,"STRONG",{});var LPt=s(M4e);Dyr=r(LPt,"openai-gpt"),LPt.forEach(t),Gyr=r(vDe," \u2014 "),eK=n(vDe,"A",{href:!0});var yPt=s(eK);Oyr=r(yPt,"TFOpenAIGPTForSequenceClassification"),yPt.forEach(t),Vyr=r(vDe," (OpenAI GPT model)"),vDe.forEach(t),Xyr=i(ne),fC=n(ne,"LI",{});var FDe=s(fC);E4e=n(FDe,"STRONG",{});var xPt=s(E4e);zyr=r(xPt,"rembert"),xPt.forEach(t),Qyr=r(FDe," \u2014 "),oK=n(FDe,"A",{href:!0});var $Pt=s(oK);Wyr=r($Pt,"TFRemBertForSequenceClassification"),$Pt.forEach(t),Hyr=r(FDe," (RemBERT model)"),FDe.forEach(t),Uyr=i(ne),mC=n(ne,"LI",{});var TDe=s(mC);C4e=n(TDe,"STRONG",{});var kPt=s(C4e);Jyr=r(kPt,"roberta"),kPt.forEach(t),Yyr=r(TDe," \u2014 "),rK=n(TDe,"A",{href:!0});var SPt=s(rK);Kyr=r(SPt,"TFRobertaForSequenceClassification"),SPt.forEach(t),Zyr=r(TDe," (RoBERTa model)"),TDe.forEach(t),e9r=i(ne),gC=n(ne,"LI",{});var MDe=s(gC);w4e=n(MDe,"STRONG",{});var RPt=s(w4e);o9r=r(RPt,"roformer"),RPt.forEach(t),r9r=r(MDe," \u2014 "),tK=n(MDe,"A",{href:!0});var PPt=s(tK);t9r=r(PPt,"TFRoFormerForSequenceClassification"),PPt.forEach(t),a9r=r(MDe," (RoFormer model)"),MDe.forEach(t),n9r=i(ne),hC=n(ne,"LI",{});var EDe=s(hC);A4e=n(EDe,"STRONG",{});var BPt=s(A4e);s9r=r(BPt,"tapas"),BPt.forEach(t),l9r=r(EDe," \u2014 "),aK=n(EDe,"A",{href:!0});var IPt=s(aK);i9r=r(IPt,"TFTapasForSequenceClassification"),IPt.forEach(t),d9r=r(EDe," (TAPAS model)"),EDe.forEach(t),c9r=i(ne),pC=n(ne,"LI",{});var CDe=s(pC);L4e=n(CDe,"STRONG",{});var NPt=s(L4e);f9r=r(NPt,"transfo-xl"),NPt.forEach(t),m9r=r(CDe," \u2014 "),nK=n(CDe,"A",{href:!0});var qPt=s(nK);g9r=r(qPt,"TFTransfoXLForSequenceClassification"),qPt.forEach(t),h9r=r(CDe," (Transformer-XL model)"),CDe.forEach(t),p9r=i(ne),_C=n(ne,"LI",{});var wDe=s(_C);y4e=n(wDe,"STRONG",{});var jPt=s(y4e);_9r=r(jPt,"xlm"),jPt.forEach(t),u9r=r(wDe," \u2014 "),sK=n(wDe,"A",{href:!0});var DPt=s(sK);b9r=r(DPt,"TFXLMForSequenceClassification"),DPt.forEach(t),v9r=r(wDe," (XLM model)"),wDe.forEach(t),F9r=i(ne),uC=n(ne,"LI",{});var ADe=s(uC);x4e=n(ADe,"STRONG",{});var GPt=s(x4e);T9r=r(GPt,"xlm-roberta"),GPt.forEach(t),M9r=r(ADe," \u2014 "),lK=n(ADe,"A",{href:!0});var OPt=s(lK);E9r=r(OPt,"TFXLMRobertaForSequenceClassification"),OPt.forEach(t),C9r=r(ADe," (XLM-RoBERTa model)"),ADe.forEach(t),w9r=i(ne),bC=n(ne,"LI",{});var LDe=s(bC);$4e=n(LDe,"STRONG",{});var VPt=s($4e);A9r=r(VPt,"xlnet"),VPt.forEach(t),L9r=r(LDe," \u2014 "),iK=n(LDe,"A",{href:!0});var XPt=s(iK);y9r=r(XPt,"TFXLNetForSequenceClassification"),XPt.forEach(t),x9r=r(LDe," (XLNet model)"),LDe.forEach(t),ne.forEach(t),$9r=i(Gl),T(vC.$$.fragment,Gl),Gl.forEach(t),Dl.forEach(t),nze=i(f),Ac=n(f,"H2",{class:!0});var gWe=s(Ac);FC=n(gWe,"A",{id:!0,class:!0,href:!0});var zPt=s(FC);k4e=n(zPt,"SPAN",{});var QPt=s(k4e);T(Mx.$$.fragment,QPt),QPt.forEach(t),zPt.forEach(t),k9r=i(gWe),S4e=n(gWe,"SPAN",{});var WPt=s(S4e);S9r=r(WPt,"TFAutoModelForMultipleChoice"),WPt.forEach(t),gWe.forEach(t),sze=i(f),lr=n(f,"DIV",{class:!0});var Ol=s(lr);T(Ex.$$.fragment,Ol),R9r=i(Ol),Lc=n(Ol,"P",{});var Ste=s(Lc);P9r=r(Ste,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),dK=n(Ste,"A",{href:!0});var HPt=s(dK);B9r=r(HPt,"from_pretrained()"),HPt.forEach(t),I9r=r(Ste," class method or the "),cK=n(Ste,"A",{href:!0});var UPt=s(cK);N9r=r(UPt,"from_config()"),UPt.forEach(t),q9r=r(Ste,` class
method.`),Ste.forEach(t),j9r=i(Ol),Cx=n(Ol,"P",{});var hWe=s(Cx);D9r=r(hWe,"This class cannot be instantiated directly using "),R4e=n(hWe,"CODE",{});var JPt=s(R4e);G9r=r(JPt,"__init__()"),JPt.forEach(t),O9r=r(hWe," (throws an error)."),hWe.forEach(t),V9r=i(Ol),jt=n(Ol,"DIV",{class:!0});var g6=s(jt);T(wx.$$.fragment,g6),X9r=i(g6),P4e=n(g6,"P",{});var YPt=s(P4e);z9r=r(YPt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),YPt.forEach(t),Q9r=i(g6),yc=n(g6,"P",{});var Rte=s(yc);W9r=r(Rte,`Note:
Loading a model from its configuration file does `),B4e=n(Rte,"STRONG",{});var KPt=s(B4e);H9r=r(KPt,"not"),KPt.forEach(t),U9r=r(Rte,` load the model weights. It only affects the
model\u2019s configuration. Use `),fK=n(Rte,"A",{href:!0});var ZPt=s(fK);J9r=r(ZPt,"from_pretrained()"),ZPt.forEach(t),Y9r=r(Rte," to load the model weights."),Rte.forEach(t),K9r=i(g6),T(TC.$$.fragment,g6),g6.forEach(t),Z9r=i(Ol),Br=n(Ol,"DIV",{class:!0});var Vl=s(Br);T(Ax.$$.fragment,Vl),exr=i(Vl),I4e=n(Vl,"P",{});var eBt=s(I4e);oxr=r(eBt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),eBt.forEach(t),rxr=i(Vl),gn=n(Vl,"P",{});var h6=s(gn);txr=r(h6,"The model class to instantiate is selected based on the "),N4e=n(h6,"CODE",{});var oBt=s(N4e);axr=r(oBt,"model_type"),oBt.forEach(t),nxr=r(h6,` property of the config object (either
passed as an argument or loaded from `),q4e=n(h6,"CODE",{});var rBt=s(q4e);sxr=r(rBt,"pretrained_model_name_or_path"),rBt.forEach(t),lxr=r(h6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j4e=n(h6,"CODE",{});var tBt=s(j4e);ixr=r(tBt,"pretrained_model_name_or_path"),tBt.forEach(t),dxr=r(h6,":"),h6.forEach(t),cxr=i(Vl),_e=n(Vl,"UL",{});var Fe=s(_e);MC=n(Fe,"LI",{});var yDe=s(MC);D4e=n(yDe,"STRONG",{});var aBt=s(D4e);fxr=r(aBt,"albert"),aBt.forEach(t),mxr=r(yDe," \u2014 "),mK=n(yDe,"A",{href:!0});var nBt=s(mK);gxr=r(nBt,"TFAlbertForMultipleChoice"),nBt.forEach(t),hxr=r(yDe," (ALBERT model)"),yDe.forEach(t),pxr=i(Fe),EC=n(Fe,"LI",{});var xDe=s(EC);G4e=n(xDe,"STRONG",{});var sBt=s(G4e);_xr=r(sBt,"bert"),sBt.forEach(t),uxr=r(xDe," \u2014 "),gK=n(xDe,"A",{href:!0});var lBt=s(gK);bxr=r(lBt,"TFBertForMultipleChoice"),lBt.forEach(t),vxr=r(xDe," (BERT model)"),xDe.forEach(t),Fxr=i(Fe),CC=n(Fe,"LI",{});var $De=s(CC);O4e=n($De,"STRONG",{});var iBt=s(O4e);Txr=r(iBt,"camembert"),iBt.forEach(t),Mxr=r($De," \u2014 "),hK=n($De,"A",{href:!0});var dBt=s(hK);Exr=r(dBt,"TFCamembertForMultipleChoice"),dBt.forEach(t),Cxr=r($De," (CamemBERT model)"),$De.forEach(t),wxr=i(Fe),wC=n(Fe,"LI",{});var kDe=s(wC);V4e=n(kDe,"STRONG",{});var cBt=s(V4e);Axr=r(cBt,"convbert"),cBt.forEach(t),Lxr=r(kDe," \u2014 "),pK=n(kDe,"A",{href:!0});var fBt=s(pK);yxr=r(fBt,"TFConvBertForMultipleChoice"),fBt.forEach(t),xxr=r(kDe," (ConvBERT model)"),kDe.forEach(t),$xr=i(Fe),AC=n(Fe,"LI",{});var SDe=s(AC);X4e=n(SDe,"STRONG",{});var mBt=s(X4e);kxr=r(mBt,"distilbert"),mBt.forEach(t),Sxr=r(SDe," \u2014 "),_K=n(SDe,"A",{href:!0});var gBt=s(_K);Rxr=r(gBt,"TFDistilBertForMultipleChoice"),gBt.forEach(t),Pxr=r(SDe," (DistilBERT model)"),SDe.forEach(t),Bxr=i(Fe),LC=n(Fe,"LI",{});var RDe=s(LC);z4e=n(RDe,"STRONG",{});var hBt=s(z4e);Ixr=r(hBt,"electra"),hBt.forEach(t),Nxr=r(RDe," \u2014 "),uK=n(RDe,"A",{href:!0});var pBt=s(uK);qxr=r(pBt,"TFElectraForMultipleChoice"),pBt.forEach(t),jxr=r(RDe," (ELECTRA model)"),RDe.forEach(t),Dxr=i(Fe),yC=n(Fe,"LI",{});var PDe=s(yC);Q4e=n(PDe,"STRONG",{});var _Bt=s(Q4e);Gxr=r(_Bt,"flaubert"),_Bt.forEach(t),Oxr=r(PDe," \u2014 "),bK=n(PDe,"A",{href:!0});var uBt=s(bK);Vxr=r(uBt,"TFFlaubertForMultipleChoice"),uBt.forEach(t),Xxr=r(PDe," (FlauBERT model)"),PDe.forEach(t),zxr=i(Fe),xC=n(Fe,"LI",{});var BDe=s(xC);W4e=n(BDe,"STRONG",{});var bBt=s(W4e);Qxr=r(bBt,"funnel"),bBt.forEach(t),Wxr=r(BDe," \u2014 "),vK=n(BDe,"A",{href:!0});var vBt=s(vK);Hxr=r(vBt,"TFFunnelForMultipleChoice"),vBt.forEach(t),Uxr=r(BDe," (Funnel Transformer model)"),BDe.forEach(t),Jxr=i(Fe),$C=n(Fe,"LI",{});var IDe=s($C);H4e=n(IDe,"STRONG",{});var FBt=s(H4e);Yxr=r(FBt,"longformer"),FBt.forEach(t),Kxr=r(IDe," \u2014 "),FK=n(IDe,"A",{href:!0});var TBt=s(FK);Zxr=r(TBt,"TFLongformerForMultipleChoice"),TBt.forEach(t),e$r=r(IDe," (Longformer model)"),IDe.forEach(t),o$r=i(Fe),kC=n(Fe,"LI",{});var NDe=s(kC);U4e=n(NDe,"STRONG",{});var MBt=s(U4e);r$r=r(MBt,"mobilebert"),MBt.forEach(t),t$r=r(NDe," \u2014 "),TK=n(NDe,"A",{href:!0});var EBt=s(TK);a$r=r(EBt,"TFMobileBertForMultipleChoice"),EBt.forEach(t),n$r=r(NDe," (MobileBERT model)"),NDe.forEach(t),s$r=i(Fe),SC=n(Fe,"LI",{});var qDe=s(SC);J4e=n(qDe,"STRONG",{});var CBt=s(J4e);l$r=r(CBt,"mpnet"),CBt.forEach(t),i$r=r(qDe," \u2014 "),MK=n(qDe,"A",{href:!0});var wBt=s(MK);d$r=r(wBt,"TFMPNetForMultipleChoice"),wBt.forEach(t),c$r=r(qDe," (MPNet model)"),qDe.forEach(t),f$r=i(Fe),RC=n(Fe,"LI",{});var jDe=s(RC);Y4e=n(jDe,"STRONG",{});var ABt=s(Y4e);m$r=r(ABt,"rembert"),ABt.forEach(t),g$r=r(jDe," \u2014 "),EK=n(jDe,"A",{href:!0});var LBt=s(EK);h$r=r(LBt,"TFRemBertForMultipleChoice"),LBt.forEach(t),p$r=r(jDe," (RemBERT model)"),jDe.forEach(t),_$r=i(Fe),PC=n(Fe,"LI",{});var DDe=s(PC);K4e=n(DDe,"STRONG",{});var yBt=s(K4e);u$r=r(yBt,"roberta"),yBt.forEach(t),b$r=r(DDe," \u2014 "),CK=n(DDe,"A",{href:!0});var xBt=s(CK);v$r=r(xBt,"TFRobertaForMultipleChoice"),xBt.forEach(t),F$r=r(DDe," (RoBERTa model)"),DDe.forEach(t),T$r=i(Fe),BC=n(Fe,"LI",{});var GDe=s(BC);Z4e=n(GDe,"STRONG",{});var $Bt=s(Z4e);M$r=r($Bt,"roformer"),$Bt.forEach(t),E$r=r(GDe," \u2014 "),wK=n(GDe,"A",{href:!0});var kBt=s(wK);C$r=r(kBt,"TFRoFormerForMultipleChoice"),kBt.forEach(t),w$r=r(GDe," (RoFormer model)"),GDe.forEach(t),A$r=i(Fe),IC=n(Fe,"LI",{});var ODe=s(IC);eEe=n(ODe,"STRONG",{});var SBt=s(eEe);L$r=r(SBt,"xlm"),SBt.forEach(t),y$r=r(ODe," \u2014 "),AK=n(ODe,"A",{href:!0});var RBt=s(AK);x$r=r(RBt,"TFXLMForMultipleChoice"),RBt.forEach(t),$$r=r(ODe," (XLM model)"),ODe.forEach(t),k$r=i(Fe),NC=n(Fe,"LI",{});var VDe=s(NC);oEe=n(VDe,"STRONG",{});var PBt=s(oEe);S$r=r(PBt,"xlm-roberta"),PBt.forEach(t),R$r=r(VDe," \u2014 "),LK=n(VDe,"A",{href:!0});var BBt=s(LK);P$r=r(BBt,"TFXLMRobertaForMultipleChoice"),BBt.forEach(t),B$r=r(VDe," (XLM-RoBERTa model)"),VDe.forEach(t),I$r=i(Fe),qC=n(Fe,"LI",{});var XDe=s(qC);rEe=n(XDe,"STRONG",{});var IBt=s(rEe);N$r=r(IBt,"xlnet"),IBt.forEach(t),q$r=r(XDe," \u2014 "),yK=n(XDe,"A",{href:!0});var NBt=s(yK);j$r=r(NBt,"TFXLNetForMultipleChoice"),NBt.forEach(t),D$r=r(XDe," (XLNet model)"),XDe.forEach(t),Fe.forEach(t),G$r=i(Vl),T(jC.$$.fragment,Vl),Vl.forEach(t),Ol.forEach(t),lze=i(f),xc=n(f,"H2",{class:!0});var pWe=s(xc);DC=n(pWe,"A",{id:!0,class:!0,href:!0});var qBt=s(DC);tEe=n(qBt,"SPAN",{});var jBt=s(tEe);T(Lx.$$.fragment,jBt),jBt.forEach(t),qBt.forEach(t),O$r=i(pWe),aEe=n(pWe,"SPAN",{});var DBt=s(aEe);V$r=r(DBt,"TFAutoModelForNextSentencePrediction"),DBt.forEach(t),pWe.forEach(t),ize=i(f),ir=n(f,"DIV",{class:!0});var Xl=s(ir);T(yx.$$.fragment,Xl),X$r=i(Xl),$c=n(Xl,"P",{});var Pte=s($c);z$r=r(Pte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),xK=n(Pte,"A",{href:!0});var GBt=s(xK);Q$r=r(GBt,"from_pretrained()"),GBt.forEach(t),W$r=r(Pte," class method or the "),$K=n(Pte,"A",{href:!0});var OBt=s($K);H$r=r(OBt,"from_config()"),OBt.forEach(t),U$r=r(Pte,` class
method.`),Pte.forEach(t),J$r=i(Xl),xx=n(Xl,"P",{});var _We=s(xx);Y$r=r(_We,"This class cannot be instantiated directly using "),nEe=n(_We,"CODE",{});var VBt=s(nEe);K$r=r(VBt,"__init__()"),VBt.forEach(t),Z$r=r(_We," (throws an error)."),_We.forEach(t),ekr=i(Xl),Dt=n(Xl,"DIV",{class:!0});var p6=s(Dt);T($x.$$.fragment,p6),okr=i(p6),sEe=n(p6,"P",{});var XBt=s(sEe);rkr=r(XBt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),XBt.forEach(t),tkr=i(p6),kc=n(p6,"P",{});var Bte=s(kc);akr=r(Bte,`Note:
Loading a model from its configuration file does `),lEe=n(Bte,"STRONG",{});var zBt=s(lEe);nkr=r(zBt,"not"),zBt.forEach(t),skr=r(Bte,` load the model weights. It only affects the
model\u2019s configuration. Use `),kK=n(Bte,"A",{href:!0});var QBt=s(kK);lkr=r(QBt,"from_pretrained()"),QBt.forEach(t),ikr=r(Bte," to load the model weights."),Bte.forEach(t),dkr=i(p6),T(GC.$$.fragment,p6),p6.forEach(t),ckr=i(Xl),Ir=n(Xl,"DIV",{class:!0});var zl=s(Ir);T(kx.$$.fragment,zl),fkr=i(zl),iEe=n(zl,"P",{});var WBt=s(iEe);mkr=r(WBt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),WBt.forEach(t),gkr=i(zl),hn=n(zl,"P",{});var _6=s(hn);hkr=r(_6,"The model class to instantiate is selected based on the "),dEe=n(_6,"CODE",{});var HBt=s(dEe);pkr=r(HBt,"model_type"),HBt.forEach(t),_kr=r(_6,` property of the config object (either
passed as an argument or loaded from `),cEe=n(_6,"CODE",{});var UBt=s(cEe);ukr=r(UBt,"pretrained_model_name_or_path"),UBt.forEach(t),bkr=r(_6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fEe=n(_6,"CODE",{});var JBt=s(fEe);vkr=r(JBt,"pretrained_model_name_or_path"),JBt.forEach(t),Fkr=r(_6,":"),_6.forEach(t),Tkr=i(zl),Sx=n(zl,"UL",{});var uWe=s(Sx);OC=n(uWe,"LI",{});var zDe=s(OC);mEe=n(zDe,"STRONG",{});var YBt=s(mEe);Mkr=r(YBt,"bert"),YBt.forEach(t),Ekr=r(zDe," \u2014 "),SK=n(zDe,"A",{href:!0});var KBt=s(SK);Ckr=r(KBt,"TFBertForNextSentencePrediction"),KBt.forEach(t),wkr=r(zDe," (BERT model)"),zDe.forEach(t),Akr=i(uWe),VC=n(uWe,"LI",{});var QDe=s(VC);gEe=n(QDe,"STRONG",{});var ZBt=s(gEe);Lkr=r(ZBt,"mobilebert"),ZBt.forEach(t),ykr=r(QDe," \u2014 "),RK=n(QDe,"A",{href:!0});var eIt=s(RK);xkr=r(eIt,"TFMobileBertForNextSentencePrediction"),eIt.forEach(t),$kr=r(QDe," (MobileBERT model)"),QDe.forEach(t),uWe.forEach(t),kkr=i(zl),T(XC.$$.fragment,zl),zl.forEach(t),Xl.forEach(t),dze=i(f),Sc=n(f,"H2",{class:!0});var bWe=s(Sc);zC=n(bWe,"A",{id:!0,class:!0,href:!0});var oIt=s(zC);hEe=n(oIt,"SPAN",{});var rIt=s(hEe);T(Rx.$$.fragment,rIt),rIt.forEach(t),oIt.forEach(t),Skr=i(bWe),pEe=n(bWe,"SPAN",{});var tIt=s(pEe);Rkr=r(tIt,"TFAutoModelForTableQuestionAnswering"),tIt.forEach(t),bWe.forEach(t),cze=i(f),dr=n(f,"DIV",{class:!0});var Ql=s(dr);T(Px.$$.fragment,Ql),Pkr=i(Ql),Rc=n(Ql,"P",{});var Ite=s(Rc);Bkr=r(Ite,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),PK=n(Ite,"A",{href:!0});var aIt=s(PK);Ikr=r(aIt,"from_pretrained()"),aIt.forEach(t),Nkr=r(Ite," class method or the "),BK=n(Ite,"A",{href:!0});var nIt=s(BK);qkr=r(nIt,"from_config()"),nIt.forEach(t),jkr=r(Ite,` class
method.`),Ite.forEach(t),Dkr=i(Ql),Bx=n(Ql,"P",{});var vWe=s(Bx);Gkr=r(vWe,"This class cannot be instantiated directly using "),_Ee=n(vWe,"CODE",{});var sIt=s(_Ee);Okr=r(sIt,"__init__()"),sIt.forEach(t),Vkr=r(vWe," (throws an error)."),vWe.forEach(t),Xkr=i(Ql),Gt=n(Ql,"DIV",{class:!0});var u6=s(Gt);T(Ix.$$.fragment,u6),zkr=i(u6),uEe=n(u6,"P",{});var lIt=s(uEe);Qkr=r(lIt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),lIt.forEach(t),Wkr=i(u6),Pc=n(u6,"P",{});var Nte=s(Pc);Hkr=r(Nte,`Note:
Loading a model from its configuration file does `),bEe=n(Nte,"STRONG",{});var iIt=s(bEe);Ukr=r(iIt,"not"),iIt.forEach(t),Jkr=r(Nte,` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=n(Nte,"A",{href:!0});var dIt=s(IK);Ykr=r(dIt,"from_pretrained()"),dIt.forEach(t),Kkr=r(Nte," to load the model weights."),Nte.forEach(t),Zkr=i(u6),T(QC.$$.fragment,u6),u6.forEach(t),eSr=i(Ql),Nr=n(Ql,"DIV",{class:!0});var Wl=s(Nr);T(Nx.$$.fragment,Wl),oSr=i(Wl),vEe=n(Wl,"P",{});var cIt=s(vEe);rSr=r(cIt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),cIt.forEach(t),tSr=i(Wl),pn=n(Wl,"P",{});var b6=s(pn);aSr=r(b6,"The model class to instantiate is selected based on the "),FEe=n(b6,"CODE",{});var fIt=s(FEe);nSr=r(fIt,"model_type"),fIt.forEach(t),sSr=r(b6,` property of the config object (either
passed as an argument or loaded from `),TEe=n(b6,"CODE",{});var mIt=s(TEe);lSr=r(mIt,"pretrained_model_name_or_path"),mIt.forEach(t),iSr=r(b6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MEe=n(b6,"CODE",{});var gIt=s(MEe);dSr=r(gIt,"pretrained_model_name_or_path"),gIt.forEach(t),cSr=r(b6,":"),b6.forEach(t),fSr=i(Wl),EEe=n(Wl,"UL",{});var hIt=s(EEe);WC=n(hIt,"LI",{});var WDe=s(WC);CEe=n(WDe,"STRONG",{});var pIt=s(CEe);mSr=r(pIt,"tapas"),pIt.forEach(t),gSr=r(WDe," \u2014 "),NK=n(WDe,"A",{href:!0});var _It=s(NK);hSr=r(_It,"TFTapasForQuestionAnswering"),_It.forEach(t),pSr=r(WDe," (TAPAS model)"),WDe.forEach(t),hIt.forEach(t),_Sr=i(Wl),T(HC.$$.fragment,Wl),Wl.forEach(t),Ql.forEach(t),fze=i(f),Bc=n(f,"H2",{class:!0});var FWe=s(Bc);UC=n(FWe,"A",{id:!0,class:!0,href:!0});var uIt=s(UC);wEe=n(uIt,"SPAN",{});var bIt=s(wEe);T(qx.$$.fragment,bIt),bIt.forEach(t),uIt.forEach(t),uSr=i(FWe),AEe=n(FWe,"SPAN",{});var vIt=s(AEe);bSr=r(vIt,"TFAutoModelForTokenClassification"),vIt.forEach(t),FWe.forEach(t),mze=i(f),cr=n(f,"DIV",{class:!0});var Hl=s(cr);T(jx.$$.fragment,Hl),vSr=i(Hl),Ic=n(Hl,"P",{});var qte=s(Ic);FSr=r(qte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),qK=n(qte,"A",{href:!0});var FIt=s(qK);TSr=r(FIt,"from_pretrained()"),FIt.forEach(t),MSr=r(qte," class method or the "),jK=n(qte,"A",{href:!0});var TIt=s(jK);ESr=r(TIt,"from_config()"),TIt.forEach(t),CSr=r(qte,` class
method.`),qte.forEach(t),wSr=i(Hl),Dx=n(Hl,"P",{});var TWe=s(Dx);ASr=r(TWe,"This class cannot be instantiated directly using "),LEe=n(TWe,"CODE",{});var MIt=s(LEe);LSr=r(MIt,"__init__()"),MIt.forEach(t),ySr=r(TWe," (throws an error)."),TWe.forEach(t),xSr=i(Hl),Ot=n(Hl,"DIV",{class:!0});var v6=s(Ot);T(Gx.$$.fragment,v6),$Sr=i(v6),yEe=n(v6,"P",{});var EIt=s(yEe);kSr=r(EIt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),EIt.forEach(t),SSr=i(v6),Nc=n(v6,"P",{});var jte=s(Nc);RSr=r(jte,`Note:
Loading a model from its configuration file does `),xEe=n(jte,"STRONG",{});var CIt=s(xEe);PSr=r(CIt,"not"),CIt.forEach(t),BSr=r(jte,` load the model weights. It only affects the
model\u2019s configuration. Use `),DK=n(jte,"A",{href:!0});var wIt=s(DK);ISr=r(wIt,"from_pretrained()"),wIt.forEach(t),NSr=r(jte," to load the model weights."),jte.forEach(t),qSr=i(v6),T(JC.$$.fragment,v6),v6.forEach(t),jSr=i(Hl),qr=n(Hl,"DIV",{class:!0});var Ul=s(qr);T(Ox.$$.fragment,Ul),DSr=i(Ul),$Ee=n(Ul,"P",{});var AIt=s($Ee);GSr=r(AIt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),AIt.forEach(t),OSr=i(Ul),_n=n(Ul,"P",{});var F6=s(_n);VSr=r(F6,"The model class to instantiate is selected based on the "),kEe=n(F6,"CODE",{});var LIt=s(kEe);XSr=r(LIt,"model_type"),LIt.forEach(t),zSr=r(F6,` property of the config object (either
passed as an argument or loaded from `),SEe=n(F6,"CODE",{});var yIt=s(SEe);QSr=r(yIt,"pretrained_model_name_or_path"),yIt.forEach(t),WSr=r(F6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),REe=n(F6,"CODE",{});var xIt=s(REe);HSr=r(xIt,"pretrained_model_name_or_path"),xIt.forEach(t),USr=r(F6,":"),F6.forEach(t),JSr=i(Ul),de=n(Ul,"UL",{});var me=s(de);YC=n(me,"LI",{});var HDe=s(YC);PEe=n(HDe,"STRONG",{});var $It=s(PEe);YSr=r($It,"albert"),$It.forEach(t),KSr=r(HDe," \u2014 "),GK=n(HDe,"A",{href:!0});var kIt=s(GK);ZSr=r(kIt,"TFAlbertForTokenClassification"),kIt.forEach(t),eRr=r(HDe," (ALBERT model)"),HDe.forEach(t),oRr=i(me),KC=n(me,"LI",{});var UDe=s(KC);BEe=n(UDe,"STRONG",{});var SIt=s(BEe);rRr=r(SIt,"bert"),SIt.forEach(t),tRr=r(UDe," \u2014 "),OK=n(UDe,"A",{href:!0});var RIt=s(OK);aRr=r(RIt,"TFBertForTokenClassification"),RIt.forEach(t),nRr=r(UDe," (BERT model)"),UDe.forEach(t),sRr=i(me),ZC=n(me,"LI",{});var JDe=s(ZC);IEe=n(JDe,"STRONG",{});var PIt=s(IEe);lRr=r(PIt,"camembert"),PIt.forEach(t),iRr=r(JDe," \u2014 "),VK=n(JDe,"A",{href:!0});var BIt=s(VK);dRr=r(BIt,"TFCamembertForTokenClassification"),BIt.forEach(t),cRr=r(JDe," (CamemBERT model)"),JDe.forEach(t),fRr=i(me),e3=n(me,"LI",{});var YDe=s(e3);NEe=n(YDe,"STRONG",{});var IIt=s(NEe);mRr=r(IIt,"convbert"),IIt.forEach(t),gRr=r(YDe," \u2014 "),XK=n(YDe,"A",{href:!0});var NIt=s(XK);hRr=r(NIt,"TFConvBertForTokenClassification"),NIt.forEach(t),pRr=r(YDe," (ConvBERT model)"),YDe.forEach(t),_Rr=i(me),o3=n(me,"LI",{});var KDe=s(o3);qEe=n(KDe,"STRONG",{});var qIt=s(qEe);uRr=r(qIt,"deberta"),qIt.forEach(t),bRr=r(KDe," \u2014 "),zK=n(KDe,"A",{href:!0});var jIt=s(zK);vRr=r(jIt,"TFDebertaForTokenClassification"),jIt.forEach(t),FRr=r(KDe," (DeBERTa model)"),KDe.forEach(t),TRr=i(me),r3=n(me,"LI",{});var ZDe=s(r3);jEe=n(ZDe,"STRONG",{});var DIt=s(jEe);MRr=r(DIt,"deberta-v2"),DIt.forEach(t),ERr=r(ZDe," \u2014 "),QK=n(ZDe,"A",{href:!0});var GIt=s(QK);CRr=r(GIt,"TFDebertaV2ForTokenClassification"),GIt.forEach(t),wRr=r(ZDe," (DeBERTa-v2 model)"),ZDe.forEach(t),ARr=i(me),t3=n(me,"LI",{});var eGe=s(t3);DEe=n(eGe,"STRONG",{});var OIt=s(DEe);LRr=r(OIt,"distilbert"),OIt.forEach(t),yRr=r(eGe," \u2014 "),WK=n(eGe,"A",{href:!0});var VIt=s(WK);xRr=r(VIt,"TFDistilBertForTokenClassification"),VIt.forEach(t),$Rr=r(eGe," (DistilBERT model)"),eGe.forEach(t),kRr=i(me),a3=n(me,"LI",{});var oGe=s(a3);GEe=n(oGe,"STRONG",{});var XIt=s(GEe);SRr=r(XIt,"electra"),XIt.forEach(t),RRr=r(oGe," \u2014 "),HK=n(oGe,"A",{href:!0});var zIt=s(HK);PRr=r(zIt,"TFElectraForTokenClassification"),zIt.forEach(t),BRr=r(oGe," (ELECTRA model)"),oGe.forEach(t),IRr=i(me),n3=n(me,"LI",{});var rGe=s(n3);OEe=n(rGe,"STRONG",{});var QIt=s(OEe);NRr=r(QIt,"flaubert"),QIt.forEach(t),qRr=r(rGe," \u2014 "),UK=n(rGe,"A",{href:!0});var WIt=s(UK);jRr=r(WIt,"TFFlaubertForTokenClassification"),WIt.forEach(t),DRr=r(rGe," (FlauBERT model)"),rGe.forEach(t),GRr=i(me),s3=n(me,"LI",{});var tGe=s(s3);VEe=n(tGe,"STRONG",{});var HIt=s(VEe);ORr=r(HIt,"funnel"),HIt.forEach(t),VRr=r(tGe," \u2014 "),JK=n(tGe,"A",{href:!0});var UIt=s(JK);XRr=r(UIt,"TFFunnelForTokenClassification"),UIt.forEach(t),zRr=r(tGe," (Funnel Transformer model)"),tGe.forEach(t),QRr=i(me),l3=n(me,"LI",{});var aGe=s(l3);XEe=n(aGe,"STRONG",{});var JIt=s(XEe);WRr=r(JIt,"layoutlm"),JIt.forEach(t),HRr=r(aGe," \u2014 "),YK=n(aGe,"A",{href:!0});var YIt=s(YK);URr=r(YIt,"TFLayoutLMForTokenClassification"),YIt.forEach(t),JRr=r(aGe," (LayoutLM model)"),aGe.forEach(t),YRr=i(me),i3=n(me,"LI",{});var nGe=s(i3);zEe=n(nGe,"STRONG",{});var KIt=s(zEe);KRr=r(KIt,"longformer"),KIt.forEach(t),ZRr=r(nGe," \u2014 "),KK=n(nGe,"A",{href:!0});var ZIt=s(KK);ePr=r(ZIt,"TFLongformerForTokenClassification"),ZIt.forEach(t),oPr=r(nGe," (Longformer model)"),nGe.forEach(t),rPr=i(me),d3=n(me,"LI",{});var sGe=s(d3);QEe=n(sGe,"STRONG",{});var eNt=s(QEe);tPr=r(eNt,"mobilebert"),eNt.forEach(t),aPr=r(sGe," \u2014 "),ZK=n(sGe,"A",{href:!0});var oNt=s(ZK);nPr=r(oNt,"TFMobileBertForTokenClassification"),oNt.forEach(t),sPr=r(sGe," (MobileBERT model)"),sGe.forEach(t),lPr=i(me),c3=n(me,"LI",{});var lGe=s(c3);WEe=n(lGe,"STRONG",{});var rNt=s(WEe);iPr=r(rNt,"mpnet"),rNt.forEach(t),dPr=r(lGe," \u2014 "),eZ=n(lGe,"A",{href:!0});var tNt=s(eZ);cPr=r(tNt,"TFMPNetForTokenClassification"),tNt.forEach(t),fPr=r(lGe," (MPNet model)"),lGe.forEach(t),mPr=i(me),f3=n(me,"LI",{});var iGe=s(f3);HEe=n(iGe,"STRONG",{});var aNt=s(HEe);gPr=r(aNt,"rembert"),aNt.forEach(t),hPr=r(iGe," \u2014 "),oZ=n(iGe,"A",{href:!0});var nNt=s(oZ);pPr=r(nNt,"TFRemBertForTokenClassification"),nNt.forEach(t),_Pr=r(iGe," (RemBERT model)"),iGe.forEach(t),uPr=i(me),m3=n(me,"LI",{});var dGe=s(m3);UEe=n(dGe,"STRONG",{});var sNt=s(UEe);bPr=r(sNt,"roberta"),sNt.forEach(t),vPr=r(dGe," \u2014 "),rZ=n(dGe,"A",{href:!0});var lNt=s(rZ);FPr=r(lNt,"TFRobertaForTokenClassification"),lNt.forEach(t),TPr=r(dGe," (RoBERTa model)"),dGe.forEach(t),MPr=i(me),g3=n(me,"LI",{});var cGe=s(g3);JEe=n(cGe,"STRONG",{});var iNt=s(JEe);EPr=r(iNt,"roformer"),iNt.forEach(t),CPr=r(cGe," \u2014 "),tZ=n(cGe,"A",{href:!0});var dNt=s(tZ);wPr=r(dNt,"TFRoFormerForTokenClassification"),dNt.forEach(t),APr=r(cGe," (RoFormer model)"),cGe.forEach(t),LPr=i(me),h3=n(me,"LI",{});var fGe=s(h3);YEe=n(fGe,"STRONG",{});var cNt=s(YEe);yPr=r(cNt,"xlm"),cNt.forEach(t),xPr=r(fGe," \u2014 "),aZ=n(fGe,"A",{href:!0});var fNt=s(aZ);$Pr=r(fNt,"TFXLMForTokenClassification"),fNt.forEach(t),kPr=r(fGe," (XLM model)"),fGe.forEach(t),SPr=i(me),p3=n(me,"LI",{});var mGe=s(p3);KEe=n(mGe,"STRONG",{});var mNt=s(KEe);RPr=r(mNt,"xlm-roberta"),mNt.forEach(t),PPr=r(mGe," \u2014 "),nZ=n(mGe,"A",{href:!0});var gNt=s(nZ);BPr=r(gNt,"TFXLMRobertaForTokenClassification"),gNt.forEach(t),IPr=r(mGe," (XLM-RoBERTa model)"),mGe.forEach(t),NPr=i(me),_3=n(me,"LI",{});var gGe=s(_3);ZEe=n(gGe,"STRONG",{});var hNt=s(ZEe);qPr=r(hNt,"xlnet"),hNt.forEach(t),jPr=r(gGe," \u2014 "),sZ=n(gGe,"A",{href:!0});var pNt=s(sZ);DPr=r(pNt,"TFXLNetForTokenClassification"),pNt.forEach(t),GPr=r(gGe," (XLNet model)"),gGe.forEach(t),me.forEach(t),OPr=i(Ul),T(u3.$$.fragment,Ul),Ul.forEach(t),Hl.forEach(t),gze=i(f),qc=n(f,"H2",{class:!0});var MWe=s(qc);b3=n(MWe,"A",{id:!0,class:!0,href:!0});var _Nt=s(b3);eCe=n(_Nt,"SPAN",{});var uNt=s(eCe);T(Vx.$$.fragment,uNt),uNt.forEach(t),_Nt.forEach(t),VPr=i(MWe),oCe=n(MWe,"SPAN",{});var bNt=s(oCe);XPr=r(bNt,"TFAutoModelForQuestionAnswering"),bNt.forEach(t),MWe.forEach(t),hze=i(f),fr=n(f,"DIV",{class:!0});var Jl=s(fr);T(Xx.$$.fragment,Jl),zPr=i(Jl),jc=n(Jl,"P",{});var Dte=s(jc);QPr=r(Dte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),lZ=n(Dte,"A",{href:!0});var vNt=s(lZ);WPr=r(vNt,"from_pretrained()"),vNt.forEach(t),HPr=r(Dte," class method or the "),iZ=n(Dte,"A",{href:!0});var FNt=s(iZ);UPr=r(FNt,"from_config()"),FNt.forEach(t),JPr=r(Dte,` class
method.`),Dte.forEach(t),YPr=i(Jl),zx=n(Jl,"P",{});var EWe=s(zx);KPr=r(EWe,"This class cannot be instantiated directly using "),rCe=n(EWe,"CODE",{});var TNt=s(rCe);ZPr=r(TNt,"__init__()"),TNt.forEach(t),eBr=r(EWe," (throws an error)."),EWe.forEach(t),oBr=i(Jl),Vt=n(Jl,"DIV",{class:!0});var T6=s(Vt);T(Qx.$$.fragment,T6),rBr=i(T6),tCe=n(T6,"P",{});var MNt=s(tCe);tBr=r(MNt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),MNt.forEach(t),aBr=i(T6),Dc=n(T6,"P",{});var Gte=s(Dc);nBr=r(Gte,`Note:
Loading a model from its configuration file does `),aCe=n(Gte,"STRONG",{});var ENt=s(aCe);sBr=r(ENt,"not"),ENt.forEach(t),lBr=r(Gte,` load the model weights. It only affects the
model\u2019s configuration. Use `),dZ=n(Gte,"A",{href:!0});var CNt=s(dZ);iBr=r(CNt,"from_pretrained()"),CNt.forEach(t),dBr=r(Gte," to load the model weights."),Gte.forEach(t),cBr=i(T6),T(v3.$$.fragment,T6),T6.forEach(t),fBr=i(Jl),jr=n(Jl,"DIV",{class:!0});var Yl=s(jr);T(Wx.$$.fragment,Yl),mBr=i(Yl),nCe=n(Yl,"P",{});var wNt=s(nCe);gBr=r(wNt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),wNt.forEach(t),hBr=i(Yl),un=n(Yl,"P",{});var M6=s(un);pBr=r(M6,"The model class to instantiate is selected based on the "),sCe=n(M6,"CODE",{});var ANt=s(sCe);_Br=r(ANt,"model_type"),ANt.forEach(t),uBr=r(M6,` property of the config object (either
passed as an argument or loaded from `),lCe=n(M6,"CODE",{});var LNt=s(lCe);bBr=r(LNt,"pretrained_model_name_or_path"),LNt.forEach(t),vBr=r(M6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iCe=n(M6,"CODE",{});var yNt=s(iCe);FBr=r(yNt,"pretrained_model_name_or_path"),yNt.forEach(t),TBr=r(M6,":"),M6.forEach(t),MBr=i(Yl),ce=n(Yl,"UL",{});var ge=s(ce);F3=n(ge,"LI",{});var hGe=s(F3);dCe=n(hGe,"STRONG",{});var xNt=s(dCe);EBr=r(xNt,"albert"),xNt.forEach(t),CBr=r(hGe," \u2014 "),cZ=n(hGe,"A",{href:!0});var $Nt=s(cZ);wBr=r($Nt,"TFAlbertForQuestionAnswering"),$Nt.forEach(t),ABr=r(hGe," (ALBERT model)"),hGe.forEach(t),LBr=i(ge),T3=n(ge,"LI",{});var pGe=s(T3);cCe=n(pGe,"STRONG",{});var kNt=s(cCe);yBr=r(kNt,"bert"),kNt.forEach(t),xBr=r(pGe," \u2014 "),fZ=n(pGe,"A",{href:!0});var SNt=s(fZ);$Br=r(SNt,"TFBertForQuestionAnswering"),SNt.forEach(t),kBr=r(pGe," (BERT model)"),pGe.forEach(t),SBr=i(ge),M3=n(ge,"LI",{});var _Ge=s(M3);fCe=n(_Ge,"STRONG",{});var RNt=s(fCe);RBr=r(RNt,"camembert"),RNt.forEach(t),PBr=r(_Ge," \u2014 "),mZ=n(_Ge,"A",{href:!0});var PNt=s(mZ);BBr=r(PNt,"TFCamembertForQuestionAnswering"),PNt.forEach(t),IBr=r(_Ge," (CamemBERT model)"),_Ge.forEach(t),NBr=i(ge),E3=n(ge,"LI",{});var uGe=s(E3);mCe=n(uGe,"STRONG",{});var BNt=s(mCe);qBr=r(BNt,"convbert"),BNt.forEach(t),jBr=r(uGe," \u2014 "),gZ=n(uGe,"A",{href:!0});var INt=s(gZ);DBr=r(INt,"TFConvBertForQuestionAnswering"),INt.forEach(t),GBr=r(uGe," (ConvBERT model)"),uGe.forEach(t),OBr=i(ge),C3=n(ge,"LI",{});var bGe=s(C3);gCe=n(bGe,"STRONG",{});var NNt=s(gCe);VBr=r(NNt,"deberta"),NNt.forEach(t),XBr=r(bGe," \u2014 "),hZ=n(bGe,"A",{href:!0});var qNt=s(hZ);zBr=r(qNt,"TFDebertaForQuestionAnswering"),qNt.forEach(t),QBr=r(bGe," (DeBERTa model)"),bGe.forEach(t),WBr=i(ge),w3=n(ge,"LI",{});var vGe=s(w3);hCe=n(vGe,"STRONG",{});var jNt=s(hCe);HBr=r(jNt,"deberta-v2"),jNt.forEach(t),UBr=r(vGe," \u2014 "),pZ=n(vGe,"A",{href:!0});var DNt=s(pZ);JBr=r(DNt,"TFDebertaV2ForQuestionAnswering"),DNt.forEach(t),YBr=r(vGe," (DeBERTa-v2 model)"),vGe.forEach(t),KBr=i(ge),A3=n(ge,"LI",{});var FGe=s(A3);pCe=n(FGe,"STRONG",{});var GNt=s(pCe);ZBr=r(GNt,"distilbert"),GNt.forEach(t),eIr=r(FGe," \u2014 "),_Z=n(FGe,"A",{href:!0});var ONt=s(_Z);oIr=r(ONt,"TFDistilBertForQuestionAnswering"),ONt.forEach(t),rIr=r(FGe," (DistilBERT model)"),FGe.forEach(t),tIr=i(ge),L3=n(ge,"LI",{});var TGe=s(L3);_Ce=n(TGe,"STRONG",{});var VNt=s(_Ce);aIr=r(VNt,"electra"),VNt.forEach(t),nIr=r(TGe," \u2014 "),uZ=n(TGe,"A",{href:!0});var XNt=s(uZ);sIr=r(XNt,"TFElectraForQuestionAnswering"),XNt.forEach(t),lIr=r(TGe," (ELECTRA model)"),TGe.forEach(t),iIr=i(ge),y3=n(ge,"LI",{});var MGe=s(y3);uCe=n(MGe,"STRONG",{});var zNt=s(uCe);dIr=r(zNt,"flaubert"),zNt.forEach(t),cIr=r(MGe," \u2014 "),bZ=n(MGe,"A",{href:!0});var QNt=s(bZ);fIr=r(QNt,"TFFlaubertForQuestionAnsweringSimple"),QNt.forEach(t),mIr=r(MGe," (FlauBERT model)"),MGe.forEach(t),gIr=i(ge),x3=n(ge,"LI",{});var EGe=s(x3);bCe=n(EGe,"STRONG",{});var WNt=s(bCe);hIr=r(WNt,"funnel"),WNt.forEach(t),pIr=r(EGe," \u2014 "),vZ=n(EGe,"A",{href:!0});var HNt=s(vZ);_Ir=r(HNt,"TFFunnelForQuestionAnswering"),HNt.forEach(t),uIr=r(EGe," (Funnel Transformer model)"),EGe.forEach(t),bIr=i(ge),$3=n(ge,"LI",{});var CGe=s($3);vCe=n(CGe,"STRONG",{});var UNt=s(vCe);vIr=r(UNt,"gptj"),UNt.forEach(t),FIr=r(CGe," \u2014 "),FZ=n(CGe,"A",{href:!0});var JNt=s(FZ);TIr=r(JNt,"TFGPTJForQuestionAnswering"),JNt.forEach(t),MIr=r(CGe," (GPT-J model)"),CGe.forEach(t),EIr=i(ge),k3=n(ge,"LI",{});var wGe=s(k3);FCe=n(wGe,"STRONG",{});var YNt=s(FCe);CIr=r(YNt,"longformer"),YNt.forEach(t),wIr=r(wGe," \u2014 "),TZ=n(wGe,"A",{href:!0});var KNt=s(TZ);AIr=r(KNt,"TFLongformerForQuestionAnswering"),KNt.forEach(t),LIr=r(wGe," (Longformer model)"),wGe.forEach(t),yIr=i(ge),S3=n(ge,"LI",{});var AGe=s(S3);TCe=n(AGe,"STRONG",{});var ZNt=s(TCe);xIr=r(ZNt,"mobilebert"),ZNt.forEach(t),$Ir=r(AGe," \u2014 "),MZ=n(AGe,"A",{href:!0});var eqt=s(MZ);kIr=r(eqt,"TFMobileBertForQuestionAnswering"),eqt.forEach(t),SIr=r(AGe," (MobileBERT model)"),AGe.forEach(t),RIr=i(ge),R3=n(ge,"LI",{});var LGe=s(R3);MCe=n(LGe,"STRONG",{});var oqt=s(MCe);PIr=r(oqt,"mpnet"),oqt.forEach(t),BIr=r(LGe," \u2014 "),EZ=n(LGe,"A",{href:!0});var rqt=s(EZ);IIr=r(rqt,"TFMPNetForQuestionAnswering"),rqt.forEach(t),NIr=r(LGe," (MPNet model)"),LGe.forEach(t),qIr=i(ge),P3=n(ge,"LI",{});var yGe=s(P3);ECe=n(yGe,"STRONG",{});var tqt=s(ECe);jIr=r(tqt,"rembert"),tqt.forEach(t),DIr=r(yGe," \u2014 "),CZ=n(yGe,"A",{href:!0});var aqt=s(CZ);GIr=r(aqt,"TFRemBertForQuestionAnswering"),aqt.forEach(t),OIr=r(yGe," (RemBERT model)"),yGe.forEach(t),VIr=i(ge),B3=n(ge,"LI",{});var xGe=s(B3);CCe=n(xGe,"STRONG",{});var nqt=s(CCe);XIr=r(nqt,"roberta"),nqt.forEach(t),zIr=r(xGe," \u2014 "),wZ=n(xGe,"A",{href:!0});var sqt=s(wZ);QIr=r(sqt,"TFRobertaForQuestionAnswering"),sqt.forEach(t),WIr=r(xGe," (RoBERTa model)"),xGe.forEach(t),HIr=i(ge),I3=n(ge,"LI",{});var $Ge=s(I3);wCe=n($Ge,"STRONG",{});var lqt=s(wCe);UIr=r(lqt,"roformer"),lqt.forEach(t),JIr=r($Ge," \u2014 "),AZ=n($Ge,"A",{href:!0});var iqt=s(AZ);YIr=r(iqt,"TFRoFormerForQuestionAnswering"),iqt.forEach(t),KIr=r($Ge," (RoFormer model)"),$Ge.forEach(t),ZIr=i(ge),N3=n(ge,"LI",{});var kGe=s(N3);ACe=n(kGe,"STRONG",{});var dqt=s(ACe);eNr=r(dqt,"xlm"),dqt.forEach(t),oNr=r(kGe," \u2014 "),LZ=n(kGe,"A",{href:!0});var cqt=s(LZ);rNr=r(cqt,"TFXLMForQuestionAnsweringSimple"),cqt.forEach(t),tNr=r(kGe," (XLM model)"),kGe.forEach(t),aNr=i(ge),q3=n(ge,"LI",{});var SGe=s(q3);LCe=n(SGe,"STRONG",{});var fqt=s(LCe);nNr=r(fqt,"xlm-roberta"),fqt.forEach(t),sNr=r(SGe," \u2014 "),yZ=n(SGe,"A",{href:!0});var mqt=s(yZ);lNr=r(mqt,"TFXLMRobertaForQuestionAnswering"),mqt.forEach(t),iNr=r(SGe," (XLM-RoBERTa model)"),SGe.forEach(t),dNr=i(ge),j3=n(ge,"LI",{});var RGe=s(j3);yCe=n(RGe,"STRONG",{});var gqt=s(yCe);cNr=r(gqt,"xlnet"),gqt.forEach(t),fNr=r(RGe," \u2014 "),xZ=n(RGe,"A",{href:!0});var hqt=s(xZ);mNr=r(hqt,"TFXLNetForQuestionAnsweringSimple"),hqt.forEach(t),gNr=r(RGe," (XLNet model)"),RGe.forEach(t),ge.forEach(t),hNr=i(Yl),T(D3.$$.fragment,Yl),Yl.forEach(t),Jl.forEach(t),pze=i(f),Gc=n(f,"H2",{class:!0});var CWe=s(Gc);G3=n(CWe,"A",{id:!0,class:!0,href:!0});var pqt=s(G3);xCe=n(pqt,"SPAN",{});var _qt=s(xCe);T(Hx.$$.fragment,_qt),_qt.forEach(t),pqt.forEach(t),pNr=i(CWe),$Ce=n(CWe,"SPAN",{});var uqt=s($Ce);_Nr=r(uqt,"TFAutoModelForVision2Seq"),uqt.forEach(t),CWe.forEach(t),_ze=i(f),mr=n(f,"DIV",{class:!0});var Kl=s(mr);T(Ux.$$.fragment,Kl),uNr=i(Kl),Oc=n(Kl,"P",{});var Ote=s(Oc);bNr=r(Ote,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),$Z=n(Ote,"A",{href:!0});var bqt=s($Z);vNr=r(bqt,"from_pretrained()"),bqt.forEach(t),FNr=r(Ote," class method or the "),kZ=n(Ote,"A",{href:!0});var vqt=s(kZ);TNr=r(vqt,"from_config()"),vqt.forEach(t),MNr=r(Ote,` class
method.`),Ote.forEach(t),ENr=i(Kl),Jx=n(Kl,"P",{});var wWe=s(Jx);CNr=r(wWe,"This class cannot be instantiated directly using "),kCe=n(wWe,"CODE",{});var Fqt=s(kCe);wNr=r(Fqt,"__init__()"),Fqt.forEach(t),ANr=r(wWe," (throws an error)."),wWe.forEach(t),LNr=i(Kl),Xt=n(Kl,"DIV",{class:!0});var E6=s(Xt);T(Yx.$$.fragment,E6),yNr=i(E6),SCe=n(E6,"P",{});var Tqt=s(SCe);xNr=r(Tqt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Tqt.forEach(t),$Nr=i(E6),Vc=n(E6,"P",{});var Vte=s(Vc);kNr=r(Vte,`Note:
Loading a model from its configuration file does `),RCe=n(Vte,"STRONG",{});var Mqt=s(RCe);SNr=r(Mqt,"not"),Mqt.forEach(t),RNr=r(Vte,` load the model weights. It only affects the
model\u2019s configuration. Use `),SZ=n(Vte,"A",{href:!0});var Eqt=s(SZ);PNr=r(Eqt,"from_pretrained()"),Eqt.forEach(t),BNr=r(Vte," to load the model weights."),Vte.forEach(t),INr=i(E6),T(O3.$$.fragment,E6),E6.forEach(t),NNr=i(Kl),Dr=n(Kl,"DIV",{class:!0});var Zl=s(Dr);T(Kx.$$.fragment,Zl),qNr=i(Zl),PCe=n(Zl,"P",{});var Cqt=s(PCe);jNr=r(Cqt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Cqt.forEach(t),DNr=i(Zl),bn=n(Zl,"P",{});var C6=s(bn);GNr=r(C6,"The model class to instantiate is selected based on the "),BCe=n(C6,"CODE",{});var wqt=s(BCe);ONr=r(wqt,"model_type"),wqt.forEach(t),VNr=r(C6,` property of the config object (either
passed as an argument or loaded from `),ICe=n(C6,"CODE",{});var Aqt=s(ICe);XNr=r(Aqt,"pretrained_model_name_or_path"),Aqt.forEach(t),zNr=r(C6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NCe=n(C6,"CODE",{});var Lqt=s(NCe);QNr=r(Lqt,"pretrained_model_name_or_path"),Lqt.forEach(t),WNr=r(C6,":"),C6.forEach(t),HNr=i(Zl),qCe=n(Zl,"UL",{});var yqt=s(qCe);V3=n(yqt,"LI",{});var PGe=s(V3);jCe=n(PGe,"STRONG",{});var xqt=s(jCe);UNr=r(xqt,"vision-encoder-decoder"),xqt.forEach(t),JNr=r(PGe," \u2014 "),RZ=n(PGe,"A",{href:!0});var $qt=s(RZ);YNr=r($qt,"TFVisionEncoderDecoderModel"),$qt.forEach(t),KNr=r(PGe," (Vision Encoder decoder model)"),PGe.forEach(t),yqt.forEach(t),ZNr=i(Zl),T(X3.$$.fragment,Zl),Zl.forEach(t),Kl.forEach(t),uze=i(f),Xc=n(f,"H2",{class:!0});var AWe=s(Xc);z3=n(AWe,"A",{id:!0,class:!0,href:!0});var kqt=s(z3);DCe=n(kqt,"SPAN",{});var Sqt=s(DCe);T(Zx.$$.fragment,Sqt),Sqt.forEach(t),kqt.forEach(t),eqr=i(AWe),GCe=n(AWe,"SPAN",{});var Rqt=s(GCe);oqr=r(Rqt,"TFAutoModelForSpeechSeq2Seq"),Rqt.forEach(t),AWe.forEach(t),bze=i(f),gr=n(f,"DIV",{class:!0});var ei=s(gr);T(e$.$$.fragment,ei),rqr=i(ei),zc=n(ei,"P",{});var Xte=s(zc);tqr=r(Xte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),PZ=n(Xte,"A",{href:!0});var Pqt=s(PZ);aqr=r(Pqt,"from_pretrained()"),Pqt.forEach(t),nqr=r(Xte," class method or the "),BZ=n(Xte,"A",{href:!0});var Bqt=s(BZ);sqr=r(Bqt,"from_config()"),Bqt.forEach(t),lqr=r(Xte,` class
method.`),Xte.forEach(t),iqr=i(ei),o$=n(ei,"P",{});var LWe=s(o$);dqr=r(LWe,"This class cannot be instantiated directly using "),OCe=n(LWe,"CODE",{});var Iqt=s(OCe);cqr=r(Iqt,"__init__()"),Iqt.forEach(t),fqr=r(LWe," (throws an error)."),LWe.forEach(t),mqr=i(ei),zt=n(ei,"DIV",{class:!0});var w6=s(zt);T(r$.$$.fragment,w6),gqr=i(w6),VCe=n(w6,"P",{});var Nqt=s(VCe);hqr=r(Nqt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Nqt.forEach(t),pqr=i(w6),Qc=n(w6,"P",{});var zte=s(Qc);_qr=r(zte,`Note:
Loading a model from its configuration file does `),XCe=n(zte,"STRONG",{});var qqt=s(XCe);uqr=r(qqt,"not"),qqt.forEach(t),bqr=r(zte,` load the model weights. It only affects the
model\u2019s configuration. Use `),IZ=n(zte,"A",{href:!0});var jqt=s(IZ);vqr=r(jqt,"from_pretrained()"),jqt.forEach(t),Fqr=r(zte," to load the model weights."),zte.forEach(t),Tqr=i(w6),T(Q3.$$.fragment,w6),w6.forEach(t),Mqr=i(ei),Gr=n(ei,"DIV",{class:!0});var oi=s(Gr);T(t$.$$.fragment,oi),Eqr=i(oi),zCe=n(oi,"P",{});var Dqt=s(zCe);Cqr=r(Dqt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Dqt.forEach(t),wqr=i(oi),vn=n(oi,"P",{});var A6=s(vn);Aqr=r(A6,"The model class to instantiate is selected based on the "),QCe=n(A6,"CODE",{});var Gqt=s(QCe);Lqr=r(Gqt,"model_type"),Gqt.forEach(t),yqr=r(A6,` property of the config object (either
passed as an argument or loaded from `),WCe=n(A6,"CODE",{});var Oqt=s(WCe);xqr=r(Oqt,"pretrained_model_name_or_path"),Oqt.forEach(t),$qr=r(A6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HCe=n(A6,"CODE",{});var Vqt=s(HCe);kqr=r(Vqt,"pretrained_model_name_or_path"),Vqt.forEach(t),Sqr=r(A6,":"),A6.forEach(t),Rqr=i(oi),UCe=n(oi,"UL",{});var Xqt=s(UCe);W3=n(Xqt,"LI",{});var BGe=s(W3);JCe=n(BGe,"STRONG",{});var zqt=s(JCe);Pqr=r(zqt,"speech_to_text"),zqt.forEach(t),Bqr=r(BGe," \u2014 "),NZ=n(BGe,"A",{href:!0});var Qqt=s(NZ);Iqr=r(Qqt,"TFSpeech2TextForConditionalGeneration"),Qqt.forEach(t),Nqr=r(BGe," (Speech2Text model)"),BGe.forEach(t),Xqt.forEach(t),qqr=i(oi),T(H3.$$.fragment,oi),oi.forEach(t),ei.forEach(t),vze=i(f),Wc=n(f,"H2",{class:!0});var yWe=s(Wc);U3=n(yWe,"A",{id:!0,class:!0,href:!0});var Wqt=s(U3);YCe=n(Wqt,"SPAN",{});var Hqt=s(YCe);T(a$.$$.fragment,Hqt),Hqt.forEach(t),Wqt.forEach(t),jqr=i(yWe),KCe=n(yWe,"SPAN",{});var Uqt=s(KCe);Dqr=r(Uqt,"FlaxAutoModel"),Uqt.forEach(t),yWe.forEach(t),Fze=i(f),hr=n(f,"DIV",{class:!0});var ri=s(hr);T(n$.$$.fragment,ri),Gqr=i(ri),Hc=n(ri,"P",{});var Qte=s(Hc);Oqr=r(Qte,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),qZ=n(Qte,"A",{href:!0});var Jqt=s(qZ);Vqr=r(Jqt,"from_pretrained()"),Jqt.forEach(t),Xqr=r(Qte," class method or the "),jZ=n(Qte,"A",{href:!0});var Yqt=s(jZ);zqr=r(Yqt,"from_config()"),Yqt.forEach(t),Qqr=r(Qte,` class
method.`),Qte.forEach(t),Wqr=i(ri),s$=n(ri,"P",{});var xWe=s(s$);Hqr=r(xWe,"This class cannot be instantiated directly using "),ZCe=n(xWe,"CODE",{});var Kqt=s(ZCe);Uqr=r(Kqt,"__init__()"),Kqt.forEach(t),Jqr=r(xWe," (throws an error)."),xWe.forEach(t),Yqr=i(ri),Qt=n(ri,"DIV",{class:!0});var L6=s(Qt);T(l$.$$.fragment,L6),Kqr=i(L6),e3e=n(L6,"P",{});var Zqt=s(e3e);Zqr=r(Zqt,"Instantiates one of the base model classes of the library from a configuration."),Zqt.forEach(t),ejr=i(L6),Uc=n(L6,"P",{});var Wte=s(Uc);ojr=r(Wte,`Note:
Loading a model from its configuration file does `),o3e=n(Wte,"STRONG",{});var ejt=s(o3e);rjr=r(ejt,"not"),ejt.forEach(t),tjr=r(Wte,` load the model weights. It only affects the
model\u2019s configuration. Use `),DZ=n(Wte,"A",{href:!0});var ojt=s(DZ);ajr=r(ojt,"from_pretrained()"),ojt.forEach(t),njr=r(Wte," to load the model weights."),Wte.forEach(t),sjr=i(L6),T(J3.$$.fragment,L6),L6.forEach(t),ljr=i(ri),Or=n(ri,"DIV",{class:!0});var ti=s(Or);T(i$.$$.fragment,ti),ijr=i(ti),r3e=n(ti,"P",{});var rjt=s(r3e);djr=r(rjt,"Instantiate one of the base model classes of the library from a pretrained model."),rjt.forEach(t),cjr=i(ti),Fn=n(ti,"P",{});var y6=s(Fn);fjr=r(y6,"The model class to instantiate is selected based on the "),t3e=n(y6,"CODE",{});var tjt=s(t3e);mjr=r(tjt,"model_type"),tjt.forEach(t),gjr=r(y6,` property of the config object (either
passed as an argument or loaded from `),a3e=n(y6,"CODE",{});var ajt=s(a3e);hjr=r(ajt,"pretrained_model_name_or_path"),ajt.forEach(t),pjr=r(y6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n3e=n(y6,"CODE",{});var njt=s(n3e);_jr=r(njt,"pretrained_model_name_or_path"),njt.forEach(t),ujr=r(y6,":"),y6.forEach(t),bjr=i(ti),oe=n(ti,"UL",{});var ae=s(oe);Y3=n(ae,"LI",{});var IGe=s(Y3);s3e=n(IGe,"STRONG",{});var sjt=s(s3e);vjr=r(sjt,"albert"),sjt.forEach(t),Fjr=r(IGe," \u2014 "),GZ=n(IGe,"A",{href:!0});var ljt=s(GZ);Tjr=r(ljt,"FlaxAlbertModel"),ljt.forEach(t),Mjr=r(IGe," (ALBERT model)"),IGe.forEach(t),Ejr=i(ae),K3=n(ae,"LI",{});var NGe=s(K3);l3e=n(NGe,"STRONG",{});var ijt=s(l3e);Cjr=r(ijt,"bart"),ijt.forEach(t),wjr=r(NGe," \u2014 "),OZ=n(NGe,"A",{href:!0});var djt=s(OZ);Ajr=r(djt,"FlaxBartModel"),djt.forEach(t),Ljr=r(NGe," (BART model)"),NGe.forEach(t),yjr=i(ae),Z3=n(ae,"LI",{});var qGe=s(Z3);i3e=n(qGe,"STRONG",{});var cjt=s(i3e);xjr=r(cjt,"beit"),cjt.forEach(t),$jr=r(qGe," \u2014 "),VZ=n(qGe,"A",{href:!0});var fjt=s(VZ);kjr=r(fjt,"FlaxBeitModel"),fjt.forEach(t),Sjr=r(qGe," (BEiT model)"),qGe.forEach(t),Rjr=i(ae),e5=n(ae,"LI",{});var jGe=s(e5);d3e=n(jGe,"STRONG",{});var mjt=s(d3e);Pjr=r(mjt,"bert"),mjt.forEach(t),Bjr=r(jGe," \u2014 "),XZ=n(jGe,"A",{href:!0});var gjt=s(XZ);Ijr=r(gjt,"FlaxBertModel"),gjt.forEach(t),Njr=r(jGe," (BERT model)"),jGe.forEach(t),qjr=i(ae),o5=n(ae,"LI",{});var DGe=s(o5);c3e=n(DGe,"STRONG",{});var hjt=s(c3e);jjr=r(hjt,"big_bird"),hjt.forEach(t),Djr=r(DGe," \u2014 "),zZ=n(DGe,"A",{href:!0});var pjt=s(zZ);Gjr=r(pjt,"FlaxBigBirdModel"),pjt.forEach(t),Ojr=r(DGe," (BigBird model)"),DGe.forEach(t),Vjr=i(ae),r5=n(ae,"LI",{});var GGe=s(r5);f3e=n(GGe,"STRONG",{});var _jt=s(f3e);Xjr=r(_jt,"blenderbot"),_jt.forEach(t),zjr=r(GGe," \u2014 "),QZ=n(GGe,"A",{href:!0});var ujt=s(QZ);Qjr=r(ujt,"FlaxBlenderbotModel"),ujt.forEach(t),Wjr=r(GGe," (Blenderbot model)"),GGe.forEach(t),Hjr=i(ae),t5=n(ae,"LI",{});var OGe=s(t5);m3e=n(OGe,"STRONG",{});var bjt=s(m3e);Ujr=r(bjt,"blenderbot-small"),bjt.forEach(t),Jjr=r(OGe," \u2014 "),WZ=n(OGe,"A",{href:!0});var vjt=s(WZ);Yjr=r(vjt,"FlaxBlenderbotSmallModel"),vjt.forEach(t),Kjr=r(OGe," (BlenderbotSmall model)"),OGe.forEach(t),Zjr=i(ae),a5=n(ae,"LI",{});var VGe=s(a5);g3e=n(VGe,"STRONG",{});var Fjt=s(g3e);eDr=r(Fjt,"clip"),Fjt.forEach(t),oDr=r(VGe," \u2014 "),HZ=n(VGe,"A",{href:!0});var Tjt=s(HZ);rDr=r(Tjt,"FlaxCLIPModel"),Tjt.forEach(t),tDr=r(VGe," (CLIP model)"),VGe.forEach(t),aDr=i(ae),n5=n(ae,"LI",{});var XGe=s(n5);h3e=n(XGe,"STRONG",{});var Mjt=s(h3e);nDr=r(Mjt,"distilbert"),Mjt.forEach(t),sDr=r(XGe," \u2014 "),UZ=n(XGe,"A",{href:!0});var Ejt=s(UZ);lDr=r(Ejt,"FlaxDistilBertModel"),Ejt.forEach(t),iDr=r(XGe," (DistilBERT model)"),XGe.forEach(t),dDr=i(ae),s5=n(ae,"LI",{});var zGe=s(s5);p3e=n(zGe,"STRONG",{});var Cjt=s(p3e);cDr=r(Cjt,"electra"),Cjt.forEach(t),fDr=r(zGe," \u2014 "),JZ=n(zGe,"A",{href:!0});var wjt=s(JZ);mDr=r(wjt,"FlaxElectraModel"),wjt.forEach(t),gDr=r(zGe," (ELECTRA model)"),zGe.forEach(t),hDr=i(ae),l5=n(ae,"LI",{});var QGe=s(l5);_3e=n(QGe,"STRONG",{});var Ajt=s(_3e);pDr=r(Ajt,"gpt2"),Ajt.forEach(t),_Dr=r(QGe," \u2014 "),YZ=n(QGe,"A",{href:!0});var Ljt=s(YZ);uDr=r(Ljt,"FlaxGPT2Model"),Ljt.forEach(t),bDr=r(QGe," (OpenAI GPT-2 model)"),QGe.forEach(t),vDr=i(ae),i5=n(ae,"LI",{});var WGe=s(i5);u3e=n(WGe,"STRONG",{});var yjt=s(u3e);FDr=r(yjt,"gpt_neo"),yjt.forEach(t),TDr=r(WGe," \u2014 "),KZ=n(WGe,"A",{href:!0});var xjt=s(KZ);MDr=r(xjt,"FlaxGPTNeoModel"),xjt.forEach(t),EDr=r(WGe," (GPT Neo model)"),WGe.forEach(t),CDr=i(ae),d5=n(ae,"LI",{});var HGe=s(d5);b3e=n(HGe,"STRONG",{});var $jt=s(b3e);wDr=r($jt,"gptj"),$jt.forEach(t),ADr=r(HGe," \u2014 "),ZZ=n(HGe,"A",{href:!0});var kjt=s(ZZ);LDr=r(kjt,"FlaxGPTJModel"),kjt.forEach(t),yDr=r(HGe," (GPT-J model)"),HGe.forEach(t),xDr=i(ae),c5=n(ae,"LI",{});var UGe=s(c5);v3e=n(UGe,"STRONG",{});var Sjt=s(v3e);$Dr=r(Sjt,"longt5"),Sjt.forEach(t),kDr=r(UGe," \u2014 "),eee=n(UGe,"A",{href:!0});var Rjt=s(eee);SDr=r(Rjt,"FlaxLongT5Model"),Rjt.forEach(t),RDr=r(UGe," (LongT5 model)"),UGe.forEach(t),PDr=i(ae),f5=n(ae,"LI",{});var JGe=s(f5);F3e=n(JGe,"STRONG",{});var Pjt=s(F3e);BDr=r(Pjt,"marian"),Pjt.forEach(t),IDr=r(JGe," \u2014 "),oee=n(JGe,"A",{href:!0});var Bjt=s(oee);NDr=r(Bjt,"FlaxMarianModel"),Bjt.forEach(t),qDr=r(JGe," (Marian model)"),JGe.forEach(t),jDr=i(ae),m5=n(ae,"LI",{});var YGe=s(m5);T3e=n(YGe,"STRONG",{});var Ijt=s(T3e);DDr=r(Ijt,"mbart"),Ijt.forEach(t),GDr=r(YGe," \u2014 "),ree=n(YGe,"A",{href:!0});var Njt=s(ree);ODr=r(Njt,"FlaxMBartModel"),Njt.forEach(t),VDr=r(YGe," (mBART model)"),YGe.forEach(t),XDr=i(ae),g5=n(ae,"LI",{});var KGe=s(g5);M3e=n(KGe,"STRONG",{});var qjt=s(M3e);zDr=r(qjt,"mt5"),qjt.forEach(t),QDr=r(KGe," \u2014 "),tee=n(KGe,"A",{href:!0});var jjt=s(tee);WDr=r(jjt,"FlaxMT5Model"),jjt.forEach(t),HDr=r(KGe," (MT5 model)"),KGe.forEach(t),UDr=i(ae),h5=n(ae,"LI",{});var ZGe=s(h5);E3e=n(ZGe,"STRONG",{});var Djt=s(E3e);JDr=r(Djt,"opt"),Djt.forEach(t),YDr=r(ZGe," \u2014 "),aee=n(ZGe,"A",{href:!0});var Gjt=s(aee);KDr=r(Gjt,"FlaxOPTModel"),Gjt.forEach(t),ZDr=r(ZGe," (OPT model)"),ZGe.forEach(t),eGr=i(ae),p5=n(ae,"LI",{});var eOe=s(p5);C3e=n(eOe,"STRONG",{});var Ojt=s(C3e);oGr=r(Ojt,"pegasus"),Ojt.forEach(t),rGr=r(eOe," \u2014 "),nee=n(eOe,"A",{href:!0});var Vjt=s(nee);tGr=r(Vjt,"FlaxPegasusModel"),Vjt.forEach(t),aGr=r(eOe," (Pegasus model)"),eOe.forEach(t),nGr=i(ae),_5=n(ae,"LI",{});var oOe=s(_5);w3e=n(oOe,"STRONG",{});var Xjt=s(w3e);sGr=r(Xjt,"roberta"),Xjt.forEach(t),lGr=r(oOe," \u2014 "),see=n(oOe,"A",{href:!0});var zjt=s(see);iGr=r(zjt,"FlaxRobertaModel"),zjt.forEach(t),dGr=r(oOe," (RoBERTa model)"),oOe.forEach(t),cGr=i(ae),u5=n(ae,"LI",{});var rOe=s(u5);A3e=n(rOe,"STRONG",{});var Qjt=s(A3e);fGr=r(Qjt,"roformer"),Qjt.forEach(t),mGr=r(rOe," \u2014 "),lee=n(rOe,"A",{href:!0});var Wjt=s(lee);gGr=r(Wjt,"FlaxRoFormerModel"),Wjt.forEach(t),hGr=r(rOe," (RoFormer model)"),rOe.forEach(t),pGr=i(ae),b5=n(ae,"LI",{});var tOe=s(b5);L3e=n(tOe,"STRONG",{});var Hjt=s(L3e);_Gr=r(Hjt,"t5"),Hjt.forEach(t),uGr=r(tOe," \u2014 "),iee=n(tOe,"A",{href:!0});var Ujt=s(iee);bGr=r(Ujt,"FlaxT5Model"),Ujt.forEach(t),vGr=r(tOe," (T5 model)"),tOe.forEach(t),FGr=i(ae),v5=n(ae,"LI",{});var aOe=s(v5);y3e=n(aOe,"STRONG",{});var Jjt=s(y3e);TGr=r(Jjt,"vision-text-dual-encoder"),Jjt.forEach(t),MGr=r(aOe," \u2014 "),dee=n(aOe,"A",{href:!0});var Yjt=s(dee);EGr=r(Yjt,"FlaxVisionTextDualEncoderModel"),Yjt.forEach(t),CGr=r(aOe," (VisionTextDualEncoder model)"),aOe.forEach(t),wGr=i(ae),F5=n(ae,"LI",{});var nOe=s(F5);x3e=n(nOe,"STRONG",{});var Kjt=s(x3e);AGr=r(Kjt,"vit"),Kjt.forEach(t),LGr=r(nOe," \u2014 "),cee=n(nOe,"A",{href:!0});var Zjt=s(cee);yGr=r(Zjt,"FlaxViTModel"),Zjt.forEach(t),xGr=r(nOe," (ViT model)"),nOe.forEach(t),$Gr=i(ae),T5=n(ae,"LI",{});var sOe=s(T5);$3e=n(sOe,"STRONG",{});var eDt=s($3e);kGr=r(eDt,"wav2vec2"),eDt.forEach(t),SGr=r(sOe," \u2014 "),fee=n(sOe,"A",{href:!0});var oDt=s(fee);RGr=r(oDt,"FlaxWav2Vec2Model"),oDt.forEach(t),PGr=r(sOe," (Wav2Vec2 model)"),sOe.forEach(t),BGr=i(ae),M5=n(ae,"LI",{});var lOe=s(M5);k3e=n(lOe,"STRONG",{});var rDt=s(k3e);IGr=r(rDt,"xglm"),rDt.forEach(t),NGr=r(lOe," \u2014 "),mee=n(lOe,"A",{href:!0});var tDt=s(mee);qGr=r(tDt,"FlaxXGLMModel"),tDt.forEach(t),jGr=r(lOe," (XGLM model)"),lOe.forEach(t),DGr=i(ae),E5=n(ae,"LI",{});var iOe=s(E5);S3e=n(iOe,"STRONG",{});var aDt=s(S3e);GGr=r(aDt,"xlm-roberta"),aDt.forEach(t),OGr=r(iOe," \u2014 "),gee=n(iOe,"A",{href:!0});var nDt=s(gee);VGr=r(nDt,"FlaxXLMRobertaModel"),nDt.forEach(t),XGr=r(iOe," (XLM-RoBERTa model)"),iOe.forEach(t),ae.forEach(t),zGr=i(ti),T(C5.$$.fragment,ti),ti.forEach(t),ri.forEach(t),Tze=i(f),Jc=n(f,"H2",{class:!0});var $We=s(Jc);w5=n($We,"A",{id:!0,class:!0,href:!0});var sDt=s(w5);R3e=n(sDt,"SPAN",{});var lDt=s(R3e);T(d$.$$.fragment,lDt),lDt.forEach(t),sDt.forEach(t),QGr=i($We),P3e=n($We,"SPAN",{});var iDt=s(P3e);WGr=r(iDt,"FlaxAutoModelForCausalLM"),iDt.forEach(t),$We.forEach(t),Mze=i(f),pr=n(f,"DIV",{class:!0});var ai=s(pr);T(c$.$$.fragment,ai),HGr=i(ai),Yc=n(ai,"P",{});var Hte=s(Yc);UGr=r(Hte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),hee=n(Hte,"A",{href:!0});var dDt=s(hee);JGr=r(dDt,"from_pretrained()"),dDt.forEach(t),YGr=r(Hte," class method or the "),pee=n(Hte,"A",{href:!0});var cDt=s(pee);KGr=r(cDt,"from_config()"),cDt.forEach(t),ZGr=r(Hte,` class
method.`),Hte.forEach(t),eOr=i(ai),f$=n(ai,"P",{});var kWe=s(f$);oOr=r(kWe,"This class cannot be instantiated directly using "),B3e=n(kWe,"CODE",{});var fDt=s(B3e);rOr=r(fDt,"__init__()"),fDt.forEach(t),tOr=r(kWe," (throws an error)."),kWe.forEach(t),aOr=i(ai),Wt=n(ai,"DIV",{class:!0});var x6=s(Wt);T(m$.$$.fragment,x6),nOr=i(x6),I3e=n(x6,"P",{});var mDt=s(I3e);sOr=r(mDt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),mDt.forEach(t),lOr=i(x6),Kc=n(x6,"P",{});var Ute=s(Kc);iOr=r(Ute,`Note:
Loading a model from its configuration file does `),N3e=n(Ute,"STRONG",{});var gDt=s(N3e);dOr=r(gDt,"not"),gDt.forEach(t),cOr=r(Ute,` load the model weights. It only affects the
model\u2019s configuration. Use `),_ee=n(Ute,"A",{href:!0});var hDt=s(_ee);fOr=r(hDt,"from_pretrained()"),hDt.forEach(t),mOr=r(Ute," to load the model weights."),Ute.forEach(t),gOr=i(x6),T(A5.$$.fragment,x6),x6.forEach(t),hOr=i(ai),Vr=n(ai,"DIV",{class:!0});var ni=s(Vr);T(g$.$$.fragment,ni),pOr=i(ni),q3e=n(ni,"P",{});var pDt=s(q3e);_Or=r(pDt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),pDt.forEach(t),uOr=i(ni),Tn=n(ni,"P",{});var $6=s(Tn);bOr=r($6,"The model class to instantiate is selected based on the "),j3e=n($6,"CODE",{});var _Dt=s(j3e);vOr=r(_Dt,"model_type"),_Dt.forEach(t),FOr=r($6,` property of the config object (either
passed as an argument or loaded from `),D3e=n($6,"CODE",{});var uDt=s(D3e);TOr=r(uDt,"pretrained_model_name_or_path"),uDt.forEach(t),MOr=r($6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G3e=n($6,"CODE",{});var bDt=s(G3e);EOr=r(bDt,"pretrained_model_name_or_path"),bDt.forEach(t),COr=r($6,":"),$6.forEach(t),wOr=i(ni),xe=n(ni,"UL",{});var Ne=s(xe);L5=n(Ne,"LI",{});var dOe=s(L5);O3e=n(dOe,"STRONG",{});var vDt=s(O3e);AOr=r(vDt,"bart"),vDt.forEach(t),LOr=r(dOe," \u2014 "),uee=n(dOe,"A",{href:!0});var FDt=s(uee);yOr=r(FDt,"FlaxBartForCausalLM"),FDt.forEach(t),xOr=r(dOe," (BART model)"),dOe.forEach(t),$Or=i(Ne),y5=n(Ne,"LI",{});var cOe=s(y5);V3e=n(cOe,"STRONG",{});var TDt=s(V3e);kOr=r(TDt,"bert"),TDt.forEach(t),SOr=r(cOe," \u2014 "),bee=n(cOe,"A",{href:!0});var MDt=s(bee);ROr=r(MDt,"FlaxBertForCausalLM"),MDt.forEach(t),POr=r(cOe," (BERT model)"),cOe.forEach(t),BOr=i(Ne),x5=n(Ne,"LI",{});var fOe=s(x5);X3e=n(fOe,"STRONG",{});var EDt=s(X3e);IOr=r(EDt,"big_bird"),EDt.forEach(t),NOr=r(fOe," \u2014 "),vee=n(fOe,"A",{href:!0});var CDt=s(vee);qOr=r(CDt,"FlaxBigBirdForCausalLM"),CDt.forEach(t),jOr=r(fOe," (BigBird model)"),fOe.forEach(t),DOr=i(Ne),$5=n(Ne,"LI",{});var mOe=s($5);z3e=n(mOe,"STRONG",{});var wDt=s(z3e);GOr=r(wDt,"electra"),wDt.forEach(t),OOr=r(mOe," \u2014 "),Fee=n(mOe,"A",{href:!0});var ADt=s(Fee);VOr=r(ADt,"FlaxElectraForCausalLM"),ADt.forEach(t),XOr=r(mOe," (ELECTRA model)"),mOe.forEach(t),zOr=i(Ne),k5=n(Ne,"LI",{});var gOe=s(k5);Q3e=n(gOe,"STRONG",{});var LDt=s(Q3e);QOr=r(LDt,"gpt2"),LDt.forEach(t),WOr=r(gOe," \u2014 "),Tee=n(gOe,"A",{href:!0});var yDt=s(Tee);HOr=r(yDt,"FlaxGPT2LMHeadModel"),yDt.forEach(t),UOr=r(gOe," (OpenAI GPT-2 model)"),gOe.forEach(t),JOr=i(Ne),S5=n(Ne,"LI",{});var hOe=s(S5);W3e=n(hOe,"STRONG",{});var xDt=s(W3e);YOr=r(xDt,"gpt_neo"),xDt.forEach(t),KOr=r(hOe," \u2014 "),Mee=n(hOe,"A",{href:!0});var $Dt=s(Mee);ZOr=r($Dt,"FlaxGPTNeoForCausalLM"),$Dt.forEach(t),eVr=r(hOe," (GPT Neo model)"),hOe.forEach(t),oVr=i(Ne),R5=n(Ne,"LI",{});var pOe=s(R5);H3e=n(pOe,"STRONG",{});var kDt=s(H3e);rVr=r(kDt,"gptj"),kDt.forEach(t),tVr=r(pOe," \u2014 "),Eee=n(pOe,"A",{href:!0});var SDt=s(Eee);aVr=r(SDt,"FlaxGPTJForCausalLM"),SDt.forEach(t),nVr=r(pOe," (GPT-J model)"),pOe.forEach(t),sVr=i(Ne),P5=n(Ne,"LI",{});var _Oe=s(P5);U3e=n(_Oe,"STRONG",{});var RDt=s(U3e);lVr=r(RDt,"opt"),RDt.forEach(t),iVr=r(_Oe," \u2014 "),Cee=n(_Oe,"A",{href:!0});var PDt=s(Cee);dVr=r(PDt,"FlaxOPTForCausalLM"),PDt.forEach(t),cVr=r(_Oe," (OPT model)"),_Oe.forEach(t),fVr=i(Ne),B5=n(Ne,"LI",{});var uOe=s(B5);J3e=n(uOe,"STRONG",{});var BDt=s(J3e);mVr=r(BDt,"roberta"),BDt.forEach(t),gVr=r(uOe," \u2014 "),wee=n(uOe,"A",{href:!0});var IDt=s(wee);hVr=r(IDt,"FlaxRobertaForCausalLM"),IDt.forEach(t),pVr=r(uOe," (RoBERTa model)"),uOe.forEach(t),_Vr=i(Ne),I5=n(Ne,"LI",{});var bOe=s(I5);Y3e=n(bOe,"STRONG",{});var NDt=s(Y3e);uVr=r(NDt,"xglm"),NDt.forEach(t),bVr=r(bOe," \u2014 "),Aee=n(bOe,"A",{href:!0});var qDt=s(Aee);vVr=r(qDt,"FlaxXGLMForCausalLM"),qDt.forEach(t),FVr=r(bOe," (XGLM model)"),bOe.forEach(t),Ne.forEach(t),TVr=i(ni),T(N5.$$.fragment,ni),ni.forEach(t),ai.forEach(t),Eze=i(f),Zc=n(f,"H2",{class:!0});var SWe=s(Zc);q5=n(SWe,"A",{id:!0,class:!0,href:!0});var jDt=s(q5);K3e=n(jDt,"SPAN",{});var DDt=s(K3e);T(h$.$$.fragment,DDt),DDt.forEach(t),jDt.forEach(t),MVr=i(SWe),Z3e=n(SWe,"SPAN",{});var GDt=s(Z3e);EVr=r(GDt,"FlaxAutoModelForPreTraining"),GDt.forEach(t),SWe.forEach(t),Cze=i(f),_r=n(f,"DIV",{class:!0});var si=s(_r);T(p$.$$.fragment,si),CVr=i(si),ef=n(si,"P",{});var Jte=s(ef);wVr=r(Jte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Lee=n(Jte,"A",{href:!0});var ODt=s(Lee);AVr=r(ODt,"from_pretrained()"),ODt.forEach(t),LVr=r(Jte," class method or the "),yee=n(Jte,"A",{href:!0});var VDt=s(yee);yVr=r(VDt,"from_config()"),VDt.forEach(t),xVr=r(Jte,` class
method.`),Jte.forEach(t),$Vr=i(si),_$=n(si,"P",{});var RWe=s(_$);kVr=r(RWe,"This class cannot be instantiated directly using "),e5e=n(RWe,"CODE",{});var XDt=s(e5e);SVr=r(XDt,"__init__()"),XDt.forEach(t),RVr=r(RWe," (throws an error)."),RWe.forEach(t),PVr=i(si),Ht=n(si,"DIV",{class:!0});var k6=s(Ht);T(u$.$$.fragment,k6),BVr=i(k6),o5e=n(k6,"P",{});var zDt=s(o5e);IVr=r(zDt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),zDt.forEach(t),NVr=i(k6),of=n(k6,"P",{});var Yte=s(of);qVr=r(Yte,`Note:
Loading a model from its configuration file does `),r5e=n(Yte,"STRONG",{});var QDt=s(r5e);jVr=r(QDt,"not"),QDt.forEach(t),DVr=r(Yte,` load the model weights. It only affects the
model\u2019s configuration. Use `),xee=n(Yte,"A",{href:!0});var WDt=s(xee);GVr=r(WDt,"from_pretrained()"),WDt.forEach(t),OVr=r(Yte," to load the model weights."),Yte.forEach(t),VVr=i(k6),T(j5.$$.fragment,k6),k6.forEach(t),XVr=i(si),Xr=n(si,"DIV",{class:!0});var li=s(Xr);T(b$.$$.fragment,li),zVr=i(li),t5e=n(li,"P",{});var HDt=s(t5e);QVr=r(HDt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),HDt.forEach(t),WVr=i(li),Mn=n(li,"P",{});var S6=s(Mn);HVr=r(S6,"The model class to instantiate is selected based on the "),a5e=n(S6,"CODE",{});var UDt=s(a5e);UVr=r(UDt,"model_type"),UDt.forEach(t),JVr=r(S6,` property of the config object (either
passed as an argument or loaded from `),n5e=n(S6,"CODE",{});var JDt=s(n5e);YVr=r(JDt,"pretrained_model_name_or_path"),JDt.forEach(t),KVr=r(S6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s5e=n(S6,"CODE",{});var YDt=s(s5e);ZVr=r(YDt,"pretrained_model_name_or_path"),YDt.forEach(t),eXr=r(S6,":"),S6.forEach(t),oXr=i(li),Ee=n(li,"UL",{});var we=s(Ee);D5=n(we,"LI",{});var vOe=s(D5);l5e=n(vOe,"STRONG",{});var KDt=s(l5e);rXr=r(KDt,"albert"),KDt.forEach(t),tXr=r(vOe," \u2014 "),$ee=n(vOe,"A",{href:!0});var ZDt=s($ee);aXr=r(ZDt,"FlaxAlbertForPreTraining"),ZDt.forEach(t),nXr=r(vOe," (ALBERT model)"),vOe.forEach(t),sXr=i(we),G5=n(we,"LI",{});var FOe=s(G5);i5e=n(FOe,"STRONG",{});var eGt=s(i5e);lXr=r(eGt,"bart"),eGt.forEach(t),iXr=r(FOe," \u2014 "),kee=n(FOe,"A",{href:!0});var oGt=s(kee);dXr=r(oGt,"FlaxBartForConditionalGeneration"),oGt.forEach(t),cXr=r(FOe," (BART model)"),FOe.forEach(t),fXr=i(we),O5=n(we,"LI",{});var TOe=s(O5);d5e=n(TOe,"STRONG",{});var rGt=s(d5e);mXr=r(rGt,"bert"),rGt.forEach(t),gXr=r(TOe," \u2014 "),See=n(TOe,"A",{href:!0});var tGt=s(See);hXr=r(tGt,"FlaxBertForPreTraining"),tGt.forEach(t),pXr=r(TOe," (BERT model)"),TOe.forEach(t),_Xr=i(we),V5=n(we,"LI",{});var MOe=s(V5);c5e=n(MOe,"STRONG",{});var aGt=s(c5e);uXr=r(aGt,"big_bird"),aGt.forEach(t),bXr=r(MOe," \u2014 "),Ree=n(MOe,"A",{href:!0});var nGt=s(Ree);vXr=r(nGt,"FlaxBigBirdForPreTraining"),nGt.forEach(t),FXr=r(MOe," (BigBird model)"),MOe.forEach(t),TXr=i(we),X5=n(we,"LI",{});var EOe=s(X5);f5e=n(EOe,"STRONG",{});var sGt=s(f5e);MXr=r(sGt,"electra"),sGt.forEach(t),EXr=r(EOe," \u2014 "),Pee=n(EOe,"A",{href:!0});var lGt=s(Pee);CXr=r(lGt,"FlaxElectraForPreTraining"),lGt.forEach(t),wXr=r(EOe," (ELECTRA model)"),EOe.forEach(t),AXr=i(we),z5=n(we,"LI",{});var COe=s(z5);m5e=n(COe,"STRONG",{});var iGt=s(m5e);LXr=r(iGt,"longt5"),iGt.forEach(t),yXr=r(COe," \u2014 "),Bee=n(COe,"A",{href:!0});var dGt=s(Bee);xXr=r(dGt,"FlaxLongT5ForConditionalGeneration"),dGt.forEach(t),$Xr=r(COe," (LongT5 model)"),COe.forEach(t),kXr=i(we),Q5=n(we,"LI",{});var wOe=s(Q5);g5e=n(wOe,"STRONG",{});var cGt=s(g5e);SXr=r(cGt,"mbart"),cGt.forEach(t),RXr=r(wOe," \u2014 "),Iee=n(wOe,"A",{href:!0});var fGt=s(Iee);PXr=r(fGt,"FlaxMBartForConditionalGeneration"),fGt.forEach(t),BXr=r(wOe," (mBART model)"),wOe.forEach(t),IXr=i(we),W5=n(we,"LI",{});var AOe=s(W5);h5e=n(AOe,"STRONG",{});var mGt=s(h5e);NXr=r(mGt,"mt5"),mGt.forEach(t),qXr=r(AOe," \u2014 "),Nee=n(AOe,"A",{href:!0});var gGt=s(Nee);jXr=r(gGt,"FlaxMT5ForConditionalGeneration"),gGt.forEach(t),DXr=r(AOe," (MT5 model)"),AOe.forEach(t),GXr=i(we),H5=n(we,"LI",{});var LOe=s(H5);p5e=n(LOe,"STRONG",{});var hGt=s(p5e);OXr=r(hGt,"roberta"),hGt.forEach(t),VXr=r(LOe," \u2014 "),qee=n(LOe,"A",{href:!0});var pGt=s(qee);XXr=r(pGt,"FlaxRobertaForMaskedLM"),pGt.forEach(t),zXr=r(LOe," (RoBERTa model)"),LOe.forEach(t),QXr=i(we),U5=n(we,"LI",{});var yOe=s(U5);_5e=n(yOe,"STRONG",{});var _Gt=s(_5e);WXr=r(_Gt,"roformer"),_Gt.forEach(t),HXr=r(yOe," \u2014 "),jee=n(yOe,"A",{href:!0});var uGt=s(jee);UXr=r(uGt,"FlaxRoFormerForMaskedLM"),uGt.forEach(t),JXr=r(yOe," (RoFormer model)"),yOe.forEach(t),YXr=i(we),J5=n(we,"LI",{});var xOe=s(J5);u5e=n(xOe,"STRONG",{});var bGt=s(u5e);KXr=r(bGt,"t5"),bGt.forEach(t),ZXr=r(xOe," \u2014 "),Dee=n(xOe,"A",{href:!0});var vGt=s(Dee);ezr=r(vGt,"FlaxT5ForConditionalGeneration"),vGt.forEach(t),ozr=r(xOe," (T5 model)"),xOe.forEach(t),rzr=i(we),Y5=n(we,"LI",{});var $Oe=s(Y5);b5e=n($Oe,"STRONG",{});var FGt=s(b5e);tzr=r(FGt,"wav2vec2"),FGt.forEach(t),azr=r($Oe," \u2014 "),Gee=n($Oe,"A",{href:!0});var TGt=s(Gee);nzr=r(TGt,"FlaxWav2Vec2ForPreTraining"),TGt.forEach(t),szr=r($Oe," (Wav2Vec2 model)"),$Oe.forEach(t),lzr=i(we),K5=n(we,"LI",{});var kOe=s(K5);v5e=n(kOe,"STRONG",{});var MGt=s(v5e);izr=r(MGt,"xlm-roberta"),MGt.forEach(t),dzr=r(kOe," \u2014 "),Oee=n(kOe,"A",{href:!0});var EGt=s(Oee);czr=r(EGt,"FlaxXLMRobertaForMaskedLM"),EGt.forEach(t),fzr=r(kOe," (XLM-RoBERTa model)"),kOe.forEach(t),we.forEach(t),mzr=i(li),T(Z5.$$.fragment,li),li.forEach(t),si.forEach(t),wze=i(f),rf=n(f,"H2",{class:!0});var PWe=s(rf);e0=n(PWe,"A",{id:!0,class:!0,href:!0});var CGt=s(e0);F5e=n(CGt,"SPAN",{});var wGt=s(F5e);T(v$.$$.fragment,wGt),wGt.forEach(t),CGt.forEach(t),gzr=i(PWe),T5e=n(PWe,"SPAN",{});var AGt=s(T5e);hzr=r(AGt,"FlaxAutoModelForMaskedLM"),AGt.forEach(t),PWe.forEach(t),Aze=i(f),ur=n(f,"DIV",{class:!0});var ii=s(ur);T(F$.$$.fragment,ii),pzr=i(ii),tf=n(ii,"P",{});var Kte=s(tf);_zr=r(Kte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Vee=n(Kte,"A",{href:!0});var LGt=s(Vee);uzr=r(LGt,"from_pretrained()"),LGt.forEach(t),bzr=r(Kte," class method or the "),Xee=n(Kte,"A",{href:!0});var yGt=s(Xee);vzr=r(yGt,"from_config()"),yGt.forEach(t),Fzr=r(Kte,` class
method.`),Kte.forEach(t),Tzr=i(ii),T$=n(ii,"P",{});var BWe=s(T$);Mzr=r(BWe,"This class cannot be instantiated directly using "),M5e=n(BWe,"CODE",{});var xGt=s(M5e);Ezr=r(xGt,"__init__()"),xGt.forEach(t),Czr=r(BWe," (throws an error)."),BWe.forEach(t),wzr=i(ii),Ut=n(ii,"DIV",{class:!0});var R6=s(Ut);T(M$.$$.fragment,R6),Azr=i(R6),E5e=n(R6,"P",{});var $Gt=s(E5e);Lzr=r($Gt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),$Gt.forEach(t),yzr=i(R6),af=n(R6,"P",{});var Zte=s(af);xzr=r(Zte,`Note:
Loading a model from its configuration file does `),C5e=n(Zte,"STRONG",{});var kGt=s(C5e);$zr=r(kGt,"not"),kGt.forEach(t),kzr=r(Zte,` load the model weights. It only affects the
model\u2019s configuration. Use `),zee=n(Zte,"A",{href:!0});var SGt=s(zee);Szr=r(SGt,"from_pretrained()"),SGt.forEach(t),Rzr=r(Zte," to load the model weights."),Zte.forEach(t),Pzr=i(R6),T(o0.$$.fragment,R6),R6.forEach(t),Bzr=i(ii),zr=n(ii,"DIV",{class:!0});var di=s(zr);T(E$.$$.fragment,di),Izr=i(di),w5e=n(di,"P",{});var RGt=s(w5e);Nzr=r(RGt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),RGt.forEach(t),qzr=i(di),En=n(di,"P",{});var P6=s(En);jzr=r(P6,"The model class to instantiate is selected based on the "),A5e=n(P6,"CODE",{});var PGt=s(A5e);Dzr=r(PGt,"model_type"),PGt.forEach(t),Gzr=r(P6,` property of the config object (either
passed as an argument or loaded from `),L5e=n(P6,"CODE",{});var BGt=s(L5e);Ozr=r(BGt,"pretrained_model_name_or_path"),BGt.forEach(t),Vzr=r(P6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y5e=n(P6,"CODE",{});var IGt=s(y5e);Xzr=r(IGt,"pretrained_model_name_or_path"),IGt.forEach(t),zzr=r(P6,":"),P6.forEach(t),Qzr=i(di),$e=n(di,"UL",{});var qe=s($e);r0=n(qe,"LI",{});var SOe=s(r0);x5e=n(SOe,"STRONG",{});var NGt=s(x5e);Wzr=r(NGt,"albert"),NGt.forEach(t),Hzr=r(SOe," \u2014 "),Qee=n(SOe,"A",{href:!0});var qGt=s(Qee);Uzr=r(qGt,"FlaxAlbertForMaskedLM"),qGt.forEach(t),Jzr=r(SOe," (ALBERT model)"),SOe.forEach(t),Yzr=i(qe),t0=n(qe,"LI",{});var ROe=s(t0);$5e=n(ROe,"STRONG",{});var jGt=s($5e);Kzr=r(jGt,"bart"),jGt.forEach(t),Zzr=r(ROe," \u2014 "),Wee=n(ROe,"A",{href:!0});var DGt=s(Wee);eQr=r(DGt,"FlaxBartForConditionalGeneration"),DGt.forEach(t),oQr=r(ROe," (BART model)"),ROe.forEach(t),rQr=i(qe),a0=n(qe,"LI",{});var POe=s(a0);k5e=n(POe,"STRONG",{});var GGt=s(k5e);tQr=r(GGt,"bert"),GGt.forEach(t),aQr=r(POe," \u2014 "),Hee=n(POe,"A",{href:!0});var OGt=s(Hee);nQr=r(OGt,"FlaxBertForMaskedLM"),OGt.forEach(t),sQr=r(POe," (BERT model)"),POe.forEach(t),lQr=i(qe),n0=n(qe,"LI",{});var BOe=s(n0);S5e=n(BOe,"STRONG",{});var VGt=s(S5e);iQr=r(VGt,"big_bird"),VGt.forEach(t),dQr=r(BOe," \u2014 "),Uee=n(BOe,"A",{href:!0});var XGt=s(Uee);cQr=r(XGt,"FlaxBigBirdForMaskedLM"),XGt.forEach(t),fQr=r(BOe," (BigBird model)"),BOe.forEach(t),mQr=i(qe),s0=n(qe,"LI",{});var IOe=s(s0);R5e=n(IOe,"STRONG",{});var zGt=s(R5e);gQr=r(zGt,"distilbert"),zGt.forEach(t),hQr=r(IOe," \u2014 "),Jee=n(IOe,"A",{href:!0});var QGt=s(Jee);pQr=r(QGt,"FlaxDistilBertForMaskedLM"),QGt.forEach(t),_Qr=r(IOe," (DistilBERT model)"),IOe.forEach(t),uQr=i(qe),l0=n(qe,"LI",{});var NOe=s(l0);P5e=n(NOe,"STRONG",{});var WGt=s(P5e);bQr=r(WGt,"electra"),WGt.forEach(t),vQr=r(NOe," \u2014 "),Yee=n(NOe,"A",{href:!0});var HGt=s(Yee);FQr=r(HGt,"FlaxElectraForMaskedLM"),HGt.forEach(t),TQr=r(NOe," (ELECTRA model)"),NOe.forEach(t),MQr=i(qe),i0=n(qe,"LI",{});var qOe=s(i0);B5e=n(qOe,"STRONG",{});var UGt=s(B5e);EQr=r(UGt,"mbart"),UGt.forEach(t),CQr=r(qOe," \u2014 "),Kee=n(qOe,"A",{href:!0});var JGt=s(Kee);wQr=r(JGt,"FlaxMBartForConditionalGeneration"),JGt.forEach(t),AQr=r(qOe," (mBART model)"),qOe.forEach(t),LQr=i(qe),d0=n(qe,"LI",{});var jOe=s(d0);I5e=n(jOe,"STRONG",{});var YGt=s(I5e);yQr=r(YGt,"roberta"),YGt.forEach(t),xQr=r(jOe," \u2014 "),Zee=n(jOe,"A",{href:!0});var KGt=s(Zee);$Qr=r(KGt,"FlaxRobertaForMaskedLM"),KGt.forEach(t),kQr=r(jOe," (RoBERTa model)"),jOe.forEach(t),SQr=i(qe),c0=n(qe,"LI",{});var DOe=s(c0);N5e=n(DOe,"STRONG",{});var ZGt=s(N5e);RQr=r(ZGt,"roformer"),ZGt.forEach(t),PQr=r(DOe," \u2014 "),eoe=n(DOe,"A",{href:!0});var eOt=s(eoe);BQr=r(eOt,"FlaxRoFormerForMaskedLM"),eOt.forEach(t),IQr=r(DOe," (RoFormer model)"),DOe.forEach(t),NQr=i(qe),f0=n(qe,"LI",{});var GOe=s(f0);q5e=n(GOe,"STRONG",{});var oOt=s(q5e);qQr=r(oOt,"xlm-roberta"),oOt.forEach(t),jQr=r(GOe," \u2014 "),ooe=n(GOe,"A",{href:!0});var rOt=s(ooe);DQr=r(rOt,"FlaxXLMRobertaForMaskedLM"),rOt.forEach(t),GQr=r(GOe," (XLM-RoBERTa model)"),GOe.forEach(t),qe.forEach(t),OQr=i(di),T(m0.$$.fragment,di),di.forEach(t),ii.forEach(t),Lze=i(f),nf=n(f,"H2",{class:!0});var IWe=s(nf);g0=n(IWe,"A",{id:!0,class:!0,href:!0});var tOt=s(g0);j5e=n(tOt,"SPAN",{});var aOt=s(j5e);T(C$.$$.fragment,aOt),aOt.forEach(t),tOt.forEach(t),VQr=i(IWe),D5e=n(IWe,"SPAN",{});var nOt=s(D5e);XQr=r(nOt,"FlaxAutoModelForSeq2SeqLM"),nOt.forEach(t),IWe.forEach(t),yze=i(f),br=n(f,"DIV",{class:!0});var ci=s(br);T(w$.$$.fragment,ci),zQr=i(ci),sf=n(ci,"P",{});var eae=s(sf);QQr=r(eae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),roe=n(eae,"A",{href:!0});var sOt=s(roe);WQr=r(sOt,"from_pretrained()"),sOt.forEach(t),HQr=r(eae," class method or the "),toe=n(eae,"A",{href:!0});var lOt=s(toe);UQr=r(lOt,"from_config()"),lOt.forEach(t),JQr=r(eae,` class
method.`),eae.forEach(t),YQr=i(ci),A$=n(ci,"P",{});var NWe=s(A$);KQr=r(NWe,"This class cannot be instantiated directly using "),G5e=n(NWe,"CODE",{});var iOt=s(G5e);ZQr=r(iOt,"__init__()"),iOt.forEach(t),eWr=r(NWe," (throws an error)."),NWe.forEach(t),oWr=i(ci),Jt=n(ci,"DIV",{class:!0});var B6=s(Jt);T(L$.$$.fragment,B6),rWr=i(B6),O5e=n(B6,"P",{});var dOt=s(O5e);tWr=r(dOt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),dOt.forEach(t),aWr=i(B6),lf=n(B6,"P",{});var oae=s(lf);nWr=r(oae,`Note:
Loading a model from its configuration file does `),V5e=n(oae,"STRONG",{});var cOt=s(V5e);sWr=r(cOt,"not"),cOt.forEach(t),lWr=r(oae,` load the model weights. It only affects the
model\u2019s configuration. Use `),aoe=n(oae,"A",{href:!0});var fOt=s(aoe);iWr=r(fOt,"from_pretrained()"),fOt.forEach(t),dWr=r(oae," to load the model weights."),oae.forEach(t),cWr=i(B6),T(h0.$$.fragment,B6),B6.forEach(t),fWr=i(ci),Qr=n(ci,"DIV",{class:!0});var fi=s(Qr);T(y$.$$.fragment,fi),mWr=i(fi),X5e=n(fi,"P",{});var mOt=s(X5e);gWr=r(mOt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),mOt.forEach(t),hWr=i(fi),Cn=n(fi,"P",{});var I6=s(Cn);pWr=r(I6,"The model class to instantiate is selected based on the "),z5e=n(I6,"CODE",{});var gOt=s(z5e);_Wr=r(gOt,"model_type"),gOt.forEach(t),uWr=r(I6,` property of the config object (either
passed as an argument or loaded from `),Q5e=n(I6,"CODE",{});var hOt=s(Q5e);bWr=r(hOt,"pretrained_model_name_or_path"),hOt.forEach(t),vWr=r(I6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W5e=n(I6,"CODE",{});var pOt=s(W5e);FWr=r(pOt,"pretrained_model_name_or_path"),pOt.forEach(t),TWr=r(I6,":"),I6.forEach(t),MWr=i(fi),ke=n(fi,"UL",{});var je=s(ke);p0=n(je,"LI",{});var OOe=s(p0);H5e=n(OOe,"STRONG",{});var _Ot=s(H5e);EWr=r(_Ot,"bart"),_Ot.forEach(t),CWr=r(OOe," \u2014 "),noe=n(OOe,"A",{href:!0});var uOt=s(noe);wWr=r(uOt,"FlaxBartForConditionalGeneration"),uOt.forEach(t),AWr=r(OOe," (BART model)"),OOe.forEach(t),LWr=i(je),_0=n(je,"LI",{});var VOe=s(_0);U5e=n(VOe,"STRONG",{});var bOt=s(U5e);yWr=r(bOt,"blenderbot"),bOt.forEach(t),xWr=r(VOe," \u2014 "),soe=n(VOe,"A",{href:!0});var vOt=s(soe);$Wr=r(vOt,"FlaxBlenderbotForConditionalGeneration"),vOt.forEach(t),kWr=r(VOe," (Blenderbot model)"),VOe.forEach(t),SWr=i(je),u0=n(je,"LI",{});var XOe=s(u0);J5e=n(XOe,"STRONG",{});var FOt=s(J5e);RWr=r(FOt,"blenderbot-small"),FOt.forEach(t),PWr=r(XOe," \u2014 "),loe=n(XOe,"A",{href:!0});var TOt=s(loe);BWr=r(TOt,"FlaxBlenderbotSmallForConditionalGeneration"),TOt.forEach(t),IWr=r(XOe," (BlenderbotSmall model)"),XOe.forEach(t),NWr=i(je),b0=n(je,"LI",{});var zOe=s(b0);Y5e=n(zOe,"STRONG",{});var MOt=s(Y5e);qWr=r(MOt,"encoder-decoder"),MOt.forEach(t),jWr=r(zOe," \u2014 "),ioe=n(zOe,"A",{href:!0});var EOt=s(ioe);DWr=r(EOt,"FlaxEncoderDecoderModel"),EOt.forEach(t),GWr=r(zOe," (Encoder decoder model)"),zOe.forEach(t),OWr=i(je),v0=n(je,"LI",{});var QOe=s(v0);K5e=n(QOe,"STRONG",{});var COt=s(K5e);VWr=r(COt,"longt5"),COt.forEach(t),XWr=r(QOe," \u2014 "),doe=n(QOe,"A",{href:!0});var wOt=s(doe);zWr=r(wOt,"FlaxLongT5ForConditionalGeneration"),wOt.forEach(t),QWr=r(QOe," (LongT5 model)"),QOe.forEach(t),WWr=i(je),F0=n(je,"LI",{});var WOe=s(F0);Z5e=n(WOe,"STRONG",{});var AOt=s(Z5e);HWr=r(AOt,"marian"),AOt.forEach(t),UWr=r(WOe," \u2014 "),coe=n(WOe,"A",{href:!0});var LOt=s(coe);JWr=r(LOt,"FlaxMarianMTModel"),LOt.forEach(t),YWr=r(WOe," (Marian model)"),WOe.forEach(t),KWr=i(je),T0=n(je,"LI",{});var HOe=s(T0);e0e=n(HOe,"STRONG",{});var yOt=s(e0e);ZWr=r(yOt,"mbart"),yOt.forEach(t),eHr=r(HOe," \u2014 "),foe=n(HOe,"A",{href:!0});var xOt=s(foe);oHr=r(xOt,"FlaxMBartForConditionalGeneration"),xOt.forEach(t),rHr=r(HOe," (mBART model)"),HOe.forEach(t),tHr=i(je),M0=n(je,"LI",{});var UOe=s(M0);o0e=n(UOe,"STRONG",{});var $Ot=s(o0e);aHr=r($Ot,"mt5"),$Ot.forEach(t),nHr=r(UOe," \u2014 "),moe=n(UOe,"A",{href:!0});var kOt=s(moe);sHr=r(kOt,"FlaxMT5ForConditionalGeneration"),kOt.forEach(t),lHr=r(UOe," (MT5 model)"),UOe.forEach(t),iHr=i(je),E0=n(je,"LI",{});var JOe=s(E0);r0e=n(JOe,"STRONG",{});var SOt=s(r0e);dHr=r(SOt,"pegasus"),SOt.forEach(t),cHr=r(JOe," \u2014 "),goe=n(JOe,"A",{href:!0});var ROt=s(goe);fHr=r(ROt,"FlaxPegasusForConditionalGeneration"),ROt.forEach(t),mHr=r(JOe," (Pegasus model)"),JOe.forEach(t),gHr=i(je),C0=n(je,"LI",{});var YOe=s(C0);t0e=n(YOe,"STRONG",{});var POt=s(t0e);hHr=r(POt,"t5"),POt.forEach(t),pHr=r(YOe," \u2014 "),hoe=n(YOe,"A",{href:!0});var BOt=s(hoe);_Hr=r(BOt,"FlaxT5ForConditionalGeneration"),BOt.forEach(t),uHr=r(YOe," (T5 model)"),YOe.forEach(t),je.forEach(t),bHr=i(fi),T(w0.$$.fragment,fi),fi.forEach(t),ci.forEach(t),xze=i(f),df=n(f,"H2",{class:!0});var qWe=s(df);A0=n(qWe,"A",{id:!0,class:!0,href:!0});var IOt=s(A0);a0e=n(IOt,"SPAN",{});var NOt=s(a0e);T(x$.$$.fragment,NOt),NOt.forEach(t),IOt.forEach(t),vHr=i(qWe),n0e=n(qWe,"SPAN",{});var qOt=s(n0e);FHr=r(qOt,"FlaxAutoModelForSequenceClassification"),qOt.forEach(t),qWe.forEach(t),$ze=i(f),vr=n(f,"DIV",{class:!0});var mi=s(vr);T($$.$$.fragment,mi),THr=i(mi),cf=n(mi,"P",{});var rae=s(cf);MHr=r(rae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),poe=n(rae,"A",{href:!0});var jOt=s(poe);EHr=r(jOt,"from_pretrained()"),jOt.forEach(t),CHr=r(rae," class method or the "),_oe=n(rae,"A",{href:!0});var DOt=s(_oe);wHr=r(DOt,"from_config()"),DOt.forEach(t),AHr=r(rae,` class
method.`),rae.forEach(t),LHr=i(mi),k$=n(mi,"P",{});var jWe=s(k$);yHr=r(jWe,"This class cannot be instantiated directly using "),s0e=n(jWe,"CODE",{});var GOt=s(s0e);xHr=r(GOt,"__init__()"),GOt.forEach(t),$Hr=r(jWe," (throws an error)."),jWe.forEach(t),kHr=i(mi),Yt=n(mi,"DIV",{class:!0});var N6=s(Yt);T(S$.$$.fragment,N6),SHr=i(N6),l0e=n(N6,"P",{});var OOt=s(l0e);RHr=r(OOt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),OOt.forEach(t),PHr=i(N6),ff=n(N6,"P",{});var tae=s(ff);BHr=r(tae,`Note:
Loading a model from its configuration file does `),i0e=n(tae,"STRONG",{});var VOt=s(i0e);IHr=r(VOt,"not"),VOt.forEach(t),NHr=r(tae,` load the model weights. It only affects the
model\u2019s configuration. Use `),uoe=n(tae,"A",{href:!0});var XOt=s(uoe);qHr=r(XOt,"from_pretrained()"),XOt.forEach(t),jHr=r(tae," to load the model weights."),tae.forEach(t),DHr=i(N6),T(L0.$$.fragment,N6),N6.forEach(t),GHr=i(mi),Wr=n(mi,"DIV",{class:!0});var gi=s(Wr);T(R$.$$.fragment,gi),OHr=i(gi),d0e=n(gi,"P",{});var zOt=s(d0e);VHr=r(zOt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),zOt.forEach(t),XHr=i(gi),wn=n(gi,"P",{});var q6=s(wn);zHr=r(q6,"The model class to instantiate is selected based on the "),c0e=n(q6,"CODE",{});var QOt=s(c0e);QHr=r(QOt,"model_type"),QOt.forEach(t),WHr=r(q6,` property of the config object (either
passed as an argument or loaded from `),f0e=n(q6,"CODE",{});var WOt=s(f0e);HHr=r(WOt,"pretrained_model_name_or_path"),WOt.forEach(t),UHr=r(q6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m0e=n(q6,"CODE",{});var HOt=s(m0e);JHr=r(HOt,"pretrained_model_name_or_path"),HOt.forEach(t),YHr=r(q6,":"),q6.forEach(t),KHr=i(gi),Se=n(gi,"UL",{});var De=s(Se);y0=n(De,"LI",{});var KOe=s(y0);g0e=n(KOe,"STRONG",{});var UOt=s(g0e);ZHr=r(UOt,"albert"),UOt.forEach(t),eUr=r(KOe," \u2014 "),boe=n(KOe,"A",{href:!0});var JOt=s(boe);oUr=r(JOt,"FlaxAlbertForSequenceClassification"),JOt.forEach(t),rUr=r(KOe," (ALBERT model)"),KOe.forEach(t),tUr=i(De),x0=n(De,"LI",{});var ZOe=s(x0);h0e=n(ZOe,"STRONG",{});var YOt=s(h0e);aUr=r(YOt,"bart"),YOt.forEach(t),nUr=r(ZOe," \u2014 "),voe=n(ZOe,"A",{href:!0});var KOt=s(voe);sUr=r(KOt,"FlaxBartForSequenceClassification"),KOt.forEach(t),lUr=r(ZOe," (BART model)"),ZOe.forEach(t),iUr=i(De),$0=n(De,"LI",{});var eVe=s($0);p0e=n(eVe,"STRONG",{});var ZOt=s(p0e);dUr=r(ZOt,"bert"),ZOt.forEach(t),cUr=r(eVe," \u2014 "),Foe=n(eVe,"A",{href:!0});var eVt=s(Foe);fUr=r(eVt,"FlaxBertForSequenceClassification"),eVt.forEach(t),mUr=r(eVe," (BERT model)"),eVe.forEach(t),gUr=i(De),k0=n(De,"LI",{});var oVe=s(k0);_0e=n(oVe,"STRONG",{});var oVt=s(_0e);hUr=r(oVt,"big_bird"),oVt.forEach(t),pUr=r(oVe," \u2014 "),Toe=n(oVe,"A",{href:!0});var rVt=s(Toe);_Ur=r(rVt,"FlaxBigBirdForSequenceClassification"),rVt.forEach(t),uUr=r(oVe," (BigBird model)"),oVe.forEach(t),bUr=i(De),S0=n(De,"LI",{});var rVe=s(S0);u0e=n(rVe,"STRONG",{});var tVt=s(u0e);vUr=r(tVt,"distilbert"),tVt.forEach(t),FUr=r(rVe," \u2014 "),Moe=n(rVe,"A",{href:!0});var aVt=s(Moe);TUr=r(aVt,"FlaxDistilBertForSequenceClassification"),aVt.forEach(t),MUr=r(rVe," (DistilBERT model)"),rVe.forEach(t),EUr=i(De),R0=n(De,"LI",{});var tVe=s(R0);b0e=n(tVe,"STRONG",{});var nVt=s(b0e);CUr=r(nVt,"electra"),nVt.forEach(t),wUr=r(tVe," \u2014 "),Eoe=n(tVe,"A",{href:!0});var sVt=s(Eoe);AUr=r(sVt,"FlaxElectraForSequenceClassification"),sVt.forEach(t),LUr=r(tVe," (ELECTRA model)"),tVe.forEach(t),yUr=i(De),P0=n(De,"LI",{});var aVe=s(P0);v0e=n(aVe,"STRONG",{});var lVt=s(v0e);xUr=r(lVt,"mbart"),lVt.forEach(t),$Ur=r(aVe," \u2014 "),Coe=n(aVe,"A",{href:!0});var iVt=s(Coe);kUr=r(iVt,"FlaxMBartForSequenceClassification"),iVt.forEach(t),SUr=r(aVe," (mBART model)"),aVe.forEach(t),RUr=i(De),B0=n(De,"LI",{});var nVe=s(B0);F0e=n(nVe,"STRONG",{});var dVt=s(F0e);PUr=r(dVt,"roberta"),dVt.forEach(t),BUr=r(nVe," \u2014 "),woe=n(nVe,"A",{href:!0});var cVt=s(woe);IUr=r(cVt,"FlaxRobertaForSequenceClassification"),cVt.forEach(t),NUr=r(nVe," (RoBERTa model)"),nVe.forEach(t),qUr=i(De),I0=n(De,"LI",{});var sVe=s(I0);T0e=n(sVe,"STRONG",{});var fVt=s(T0e);jUr=r(fVt,"roformer"),fVt.forEach(t),DUr=r(sVe," \u2014 "),Aoe=n(sVe,"A",{href:!0});var mVt=s(Aoe);GUr=r(mVt,"FlaxRoFormerForSequenceClassification"),mVt.forEach(t),OUr=r(sVe," (RoFormer model)"),sVe.forEach(t),VUr=i(De),N0=n(De,"LI",{});var lVe=s(N0);M0e=n(lVe,"STRONG",{});var gVt=s(M0e);XUr=r(gVt,"xlm-roberta"),gVt.forEach(t),zUr=r(lVe," \u2014 "),Loe=n(lVe,"A",{href:!0});var hVt=s(Loe);QUr=r(hVt,"FlaxXLMRobertaForSequenceClassification"),hVt.forEach(t),WUr=r(lVe," (XLM-RoBERTa model)"),lVe.forEach(t),De.forEach(t),HUr=i(gi),T(q0.$$.fragment,gi),gi.forEach(t),mi.forEach(t),kze=i(f),mf=n(f,"H2",{class:!0});var DWe=s(mf);j0=n(DWe,"A",{id:!0,class:!0,href:!0});var pVt=s(j0);E0e=n(pVt,"SPAN",{});var _Vt=s(E0e);T(P$.$$.fragment,_Vt),_Vt.forEach(t),pVt.forEach(t),UUr=i(DWe),C0e=n(DWe,"SPAN",{});var uVt=s(C0e);JUr=r(uVt,"FlaxAutoModelForQuestionAnswering"),uVt.forEach(t),DWe.forEach(t),Sze=i(f),Fr=n(f,"DIV",{class:!0});var hi=s(Fr);T(B$.$$.fragment,hi),YUr=i(hi),gf=n(hi,"P",{});var aae=s(gf);KUr=r(aae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),yoe=n(aae,"A",{href:!0});var bVt=s(yoe);ZUr=r(bVt,"from_pretrained()"),bVt.forEach(t),eJr=r(aae," class method or the "),xoe=n(aae,"A",{href:!0});var vVt=s(xoe);oJr=r(vVt,"from_config()"),vVt.forEach(t),rJr=r(aae,` class
method.`),aae.forEach(t),tJr=i(hi),I$=n(hi,"P",{});var GWe=s(I$);aJr=r(GWe,"This class cannot be instantiated directly using "),w0e=n(GWe,"CODE",{});var FVt=s(w0e);nJr=r(FVt,"__init__()"),FVt.forEach(t),sJr=r(GWe," (throws an error)."),GWe.forEach(t),lJr=i(hi),Kt=n(hi,"DIV",{class:!0});var j6=s(Kt);T(N$.$$.fragment,j6),iJr=i(j6),A0e=n(j6,"P",{});var TVt=s(A0e);dJr=r(TVt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),TVt.forEach(t),cJr=i(j6),hf=n(j6,"P",{});var nae=s(hf);fJr=r(nae,`Note:
Loading a model from its configuration file does `),L0e=n(nae,"STRONG",{});var MVt=s(L0e);mJr=r(MVt,"not"),MVt.forEach(t),gJr=r(nae,` load the model weights. It only affects the
model\u2019s configuration. Use `),$oe=n(nae,"A",{href:!0});var EVt=s($oe);hJr=r(EVt,"from_pretrained()"),EVt.forEach(t),pJr=r(nae," to load the model weights."),nae.forEach(t),_Jr=i(j6),T(D0.$$.fragment,j6),j6.forEach(t),uJr=i(hi),Hr=n(hi,"DIV",{class:!0});var pi=s(Hr);T(q$.$$.fragment,pi),bJr=i(pi),y0e=n(pi,"P",{});var CVt=s(y0e);vJr=r(CVt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),CVt.forEach(t),FJr=i(pi),An=n(pi,"P",{});var D6=s(An);TJr=r(D6,"The model class to instantiate is selected based on the "),x0e=n(D6,"CODE",{});var wVt=s(x0e);MJr=r(wVt,"model_type"),wVt.forEach(t),EJr=r(D6,` property of the config object (either
passed as an argument or loaded from `),$0e=n(D6,"CODE",{});var AVt=s($0e);CJr=r(AVt,"pretrained_model_name_or_path"),AVt.forEach(t),wJr=r(D6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k0e=n(D6,"CODE",{});var LVt=s(k0e);AJr=r(LVt,"pretrained_model_name_or_path"),LVt.forEach(t),LJr=r(D6,":"),D6.forEach(t),yJr=i(pi),Re=n(pi,"UL",{});var Ge=s(Re);G0=n(Ge,"LI",{});var iVe=s(G0);S0e=n(iVe,"STRONG",{});var yVt=s(S0e);xJr=r(yVt,"albert"),yVt.forEach(t),$Jr=r(iVe," \u2014 "),koe=n(iVe,"A",{href:!0});var xVt=s(koe);kJr=r(xVt,"FlaxAlbertForQuestionAnswering"),xVt.forEach(t),SJr=r(iVe," (ALBERT model)"),iVe.forEach(t),RJr=i(Ge),O0=n(Ge,"LI",{});var dVe=s(O0);R0e=n(dVe,"STRONG",{});var $Vt=s(R0e);PJr=r($Vt,"bart"),$Vt.forEach(t),BJr=r(dVe," \u2014 "),Soe=n(dVe,"A",{href:!0});var kVt=s(Soe);IJr=r(kVt,"FlaxBartForQuestionAnswering"),kVt.forEach(t),NJr=r(dVe," (BART model)"),dVe.forEach(t),qJr=i(Ge),V0=n(Ge,"LI",{});var cVe=s(V0);P0e=n(cVe,"STRONG",{});var SVt=s(P0e);jJr=r(SVt,"bert"),SVt.forEach(t),DJr=r(cVe," \u2014 "),Roe=n(cVe,"A",{href:!0});var RVt=s(Roe);GJr=r(RVt,"FlaxBertForQuestionAnswering"),RVt.forEach(t),OJr=r(cVe," (BERT model)"),cVe.forEach(t),VJr=i(Ge),X0=n(Ge,"LI",{});var fVe=s(X0);B0e=n(fVe,"STRONG",{});var PVt=s(B0e);XJr=r(PVt,"big_bird"),PVt.forEach(t),zJr=r(fVe," \u2014 "),Poe=n(fVe,"A",{href:!0});var BVt=s(Poe);QJr=r(BVt,"FlaxBigBirdForQuestionAnswering"),BVt.forEach(t),WJr=r(fVe," (BigBird model)"),fVe.forEach(t),HJr=i(Ge),z0=n(Ge,"LI",{});var mVe=s(z0);I0e=n(mVe,"STRONG",{});var IVt=s(I0e);UJr=r(IVt,"distilbert"),IVt.forEach(t),JJr=r(mVe," \u2014 "),Boe=n(mVe,"A",{href:!0});var NVt=s(Boe);YJr=r(NVt,"FlaxDistilBertForQuestionAnswering"),NVt.forEach(t),KJr=r(mVe," (DistilBERT model)"),mVe.forEach(t),ZJr=i(Ge),Q0=n(Ge,"LI",{});var gVe=s(Q0);N0e=n(gVe,"STRONG",{});var qVt=s(N0e);eYr=r(qVt,"electra"),qVt.forEach(t),oYr=r(gVe," \u2014 "),Ioe=n(gVe,"A",{href:!0});var jVt=s(Ioe);rYr=r(jVt,"FlaxElectraForQuestionAnswering"),jVt.forEach(t),tYr=r(gVe," (ELECTRA model)"),gVe.forEach(t),aYr=i(Ge),W0=n(Ge,"LI",{});var hVe=s(W0);q0e=n(hVe,"STRONG",{});var DVt=s(q0e);nYr=r(DVt,"mbart"),DVt.forEach(t),sYr=r(hVe," \u2014 "),Noe=n(hVe,"A",{href:!0});var GVt=s(Noe);lYr=r(GVt,"FlaxMBartForQuestionAnswering"),GVt.forEach(t),iYr=r(hVe," (mBART model)"),hVe.forEach(t),dYr=i(Ge),H0=n(Ge,"LI",{});var pVe=s(H0);j0e=n(pVe,"STRONG",{});var OVt=s(j0e);cYr=r(OVt,"roberta"),OVt.forEach(t),fYr=r(pVe," \u2014 "),qoe=n(pVe,"A",{href:!0});var VVt=s(qoe);mYr=r(VVt,"FlaxRobertaForQuestionAnswering"),VVt.forEach(t),gYr=r(pVe," (RoBERTa model)"),pVe.forEach(t),hYr=i(Ge),U0=n(Ge,"LI",{});var _Ve=s(U0);D0e=n(_Ve,"STRONG",{});var XVt=s(D0e);pYr=r(XVt,"roformer"),XVt.forEach(t),_Yr=r(_Ve," \u2014 "),joe=n(_Ve,"A",{href:!0});var zVt=s(joe);uYr=r(zVt,"FlaxRoFormerForQuestionAnswering"),zVt.forEach(t),bYr=r(_Ve," (RoFormer model)"),_Ve.forEach(t),vYr=i(Ge),J0=n(Ge,"LI",{});var uVe=s(J0);G0e=n(uVe,"STRONG",{});var QVt=s(G0e);FYr=r(QVt,"xlm-roberta"),QVt.forEach(t),TYr=r(uVe," \u2014 "),Doe=n(uVe,"A",{href:!0});var WVt=s(Doe);MYr=r(WVt,"FlaxXLMRobertaForQuestionAnswering"),WVt.forEach(t),EYr=r(uVe," (XLM-RoBERTa model)"),uVe.forEach(t),Ge.forEach(t),CYr=i(pi),T(Y0.$$.fragment,pi),pi.forEach(t),hi.forEach(t),Rze=i(f),pf=n(f,"H2",{class:!0});var OWe=s(pf);K0=n(OWe,"A",{id:!0,class:!0,href:!0});var HVt=s(K0);O0e=n(HVt,"SPAN",{});var UVt=s(O0e);T(j$.$$.fragment,UVt),UVt.forEach(t),HVt.forEach(t),wYr=i(OWe),V0e=n(OWe,"SPAN",{});var JVt=s(V0e);AYr=r(JVt,"FlaxAutoModelForTokenClassification"),JVt.forEach(t),OWe.forEach(t),Pze=i(f),Tr=n(f,"DIV",{class:!0});var _i=s(Tr);T(D$.$$.fragment,_i),LYr=i(_i),_f=n(_i,"P",{});var sae=s(_f);yYr=r(sae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Goe=n(sae,"A",{href:!0});var YVt=s(Goe);xYr=r(YVt,"from_pretrained()"),YVt.forEach(t),$Yr=r(sae," class method or the "),Ooe=n(sae,"A",{href:!0});var KVt=s(Ooe);kYr=r(KVt,"from_config()"),KVt.forEach(t),SYr=r(sae,` class
method.`),sae.forEach(t),RYr=i(_i),G$=n(_i,"P",{});var VWe=s(G$);PYr=r(VWe,"This class cannot be instantiated directly using "),X0e=n(VWe,"CODE",{});var ZVt=s(X0e);BYr=r(ZVt,"__init__()"),ZVt.forEach(t),IYr=r(VWe," (throws an error)."),VWe.forEach(t),NYr=i(_i),Zt=n(_i,"DIV",{class:!0});var G6=s(Zt);T(O$.$$.fragment,G6),qYr=i(G6),z0e=n(G6,"P",{});var eXt=s(z0e);jYr=r(eXt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),eXt.forEach(t),DYr=i(G6),uf=n(G6,"P",{});var lae=s(uf);GYr=r(lae,`Note:
Loading a model from its configuration file does `),Q0e=n(lae,"STRONG",{});var oXt=s(Q0e);OYr=r(oXt,"not"),oXt.forEach(t),VYr=r(lae,` load the model weights. It only affects the
model\u2019s configuration. Use `),Voe=n(lae,"A",{href:!0});var rXt=s(Voe);XYr=r(rXt,"from_pretrained()"),rXt.forEach(t),zYr=r(lae," to load the model weights."),lae.forEach(t),QYr=i(G6),T(Z0.$$.fragment,G6),G6.forEach(t),WYr=i(_i),Ur=n(_i,"DIV",{class:!0});var ui=s(Ur);T(V$.$$.fragment,ui),HYr=i(ui),W0e=n(ui,"P",{});var tXt=s(W0e);UYr=r(tXt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),tXt.forEach(t),JYr=i(ui),Ln=n(ui,"P",{});var O6=s(Ln);YYr=r(O6,"The model class to instantiate is selected based on the "),H0e=n(O6,"CODE",{});var aXt=s(H0e);KYr=r(aXt,"model_type"),aXt.forEach(t),ZYr=r(O6,` property of the config object (either
passed as an argument or loaded from `),U0e=n(O6,"CODE",{});var nXt=s(U0e);eKr=r(nXt,"pretrained_model_name_or_path"),nXt.forEach(t),oKr=r(O6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J0e=n(O6,"CODE",{});var sXt=s(J0e);rKr=r(sXt,"pretrained_model_name_or_path"),sXt.forEach(t),tKr=r(O6,":"),O6.forEach(t),aKr=i(ui),Ve=n(ui,"UL",{});var To=s(Ve);ew=n(To,"LI",{});var bVe=s(ew);Y0e=n(bVe,"STRONG",{});var lXt=s(Y0e);nKr=r(lXt,"albert"),lXt.forEach(t),sKr=r(bVe," \u2014 "),Xoe=n(bVe,"A",{href:!0});var iXt=s(Xoe);lKr=r(iXt,"FlaxAlbertForTokenClassification"),iXt.forEach(t),iKr=r(bVe," (ALBERT model)"),bVe.forEach(t),dKr=i(To),ow=n(To,"LI",{});var vVe=s(ow);K0e=n(vVe,"STRONG",{});var dXt=s(K0e);cKr=r(dXt,"bert"),dXt.forEach(t),fKr=r(vVe," \u2014 "),zoe=n(vVe,"A",{href:!0});var cXt=s(zoe);mKr=r(cXt,"FlaxBertForTokenClassification"),cXt.forEach(t),gKr=r(vVe," (BERT model)"),vVe.forEach(t),hKr=i(To),rw=n(To,"LI",{});var FVe=s(rw);Z0e=n(FVe,"STRONG",{});var fXt=s(Z0e);pKr=r(fXt,"big_bird"),fXt.forEach(t),_Kr=r(FVe," \u2014 "),Qoe=n(FVe,"A",{href:!0});var mXt=s(Qoe);uKr=r(mXt,"FlaxBigBirdForTokenClassification"),mXt.forEach(t),bKr=r(FVe," (BigBird model)"),FVe.forEach(t),vKr=i(To),tw=n(To,"LI",{});var TVe=s(tw);ewe=n(TVe,"STRONG",{});var gXt=s(ewe);FKr=r(gXt,"distilbert"),gXt.forEach(t),TKr=r(TVe," \u2014 "),Woe=n(TVe,"A",{href:!0});var hXt=s(Woe);MKr=r(hXt,"FlaxDistilBertForTokenClassification"),hXt.forEach(t),EKr=r(TVe," (DistilBERT model)"),TVe.forEach(t),CKr=i(To),aw=n(To,"LI",{});var MVe=s(aw);owe=n(MVe,"STRONG",{});var pXt=s(owe);wKr=r(pXt,"electra"),pXt.forEach(t),AKr=r(MVe," \u2014 "),Hoe=n(MVe,"A",{href:!0});var _Xt=s(Hoe);LKr=r(_Xt,"FlaxElectraForTokenClassification"),_Xt.forEach(t),yKr=r(MVe," (ELECTRA model)"),MVe.forEach(t),xKr=i(To),nw=n(To,"LI",{});var EVe=s(nw);rwe=n(EVe,"STRONG",{});var uXt=s(rwe);$Kr=r(uXt,"roberta"),uXt.forEach(t),kKr=r(EVe," \u2014 "),Uoe=n(EVe,"A",{href:!0});var bXt=s(Uoe);SKr=r(bXt,"FlaxRobertaForTokenClassification"),bXt.forEach(t),RKr=r(EVe," (RoBERTa model)"),EVe.forEach(t),PKr=i(To),sw=n(To,"LI",{});var CVe=s(sw);twe=n(CVe,"STRONG",{});var vXt=s(twe);BKr=r(vXt,"roformer"),vXt.forEach(t),IKr=r(CVe," \u2014 "),Joe=n(CVe,"A",{href:!0});var FXt=s(Joe);NKr=r(FXt,"FlaxRoFormerForTokenClassification"),FXt.forEach(t),qKr=r(CVe," (RoFormer model)"),CVe.forEach(t),jKr=i(To),lw=n(To,"LI",{});var wVe=s(lw);awe=n(wVe,"STRONG",{});var TXt=s(awe);DKr=r(TXt,"xlm-roberta"),TXt.forEach(t),GKr=r(wVe," \u2014 "),Yoe=n(wVe,"A",{href:!0});var MXt=s(Yoe);OKr=r(MXt,"FlaxXLMRobertaForTokenClassification"),MXt.forEach(t),VKr=r(wVe," (XLM-RoBERTa model)"),wVe.forEach(t),To.forEach(t),XKr=i(ui),T(iw.$$.fragment,ui),ui.forEach(t),_i.forEach(t),Bze=i(f),bf=n(f,"H2",{class:!0});var XWe=s(bf);dw=n(XWe,"A",{id:!0,class:!0,href:!0});var EXt=s(dw);nwe=n(EXt,"SPAN",{});var CXt=s(nwe);T(X$.$$.fragment,CXt),CXt.forEach(t),EXt.forEach(t),zKr=i(XWe),swe=n(XWe,"SPAN",{});var wXt=s(swe);QKr=r(wXt,"FlaxAutoModelForMultipleChoice"),wXt.forEach(t),XWe.forEach(t),Ize=i(f),Mr=n(f,"DIV",{class:!0});var bi=s(Mr);T(z$.$$.fragment,bi),WKr=i(bi),vf=n(bi,"P",{});var iae=s(vf);HKr=r(iae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Koe=n(iae,"A",{href:!0});var AXt=s(Koe);UKr=r(AXt,"from_pretrained()"),AXt.forEach(t),JKr=r(iae," class method or the "),Zoe=n(iae,"A",{href:!0});var LXt=s(Zoe);YKr=r(LXt,"from_config()"),LXt.forEach(t),KKr=r(iae,` class
method.`),iae.forEach(t),ZKr=i(bi),Q$=n(bi,"P",{});var zWe=s(Q$);eZr=r(zWe,"This class cannot be instantiated directly using "),lwe=n(zWe,"CODE",{});var yXt=s(lwe);oZr=r(yXt,"__init__()"),yXt.forEach(t),rZr=r(zWe," (throws an error)."),zWe.forEach(t),tZr=i(bi),ea=n(bi,"DIV",{class:!0});var V6=s(ea);T(W$.$$.fragment,V6),aZr=i(V6),iwe=n(V6,"P",{});var xXt=s(iwe);nZr=r(xXt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),xXt.forEach(t),sZr=i(V6),Ff=n(V6,"P",{});var dae=s(Ff);lZr=r(dae,`Note:
Loading a model from its configuration file does `),dwe=n(dae,"STRONG",{});var $Xt=s(dwe);iZr=r($Xt,"not"),$Xt.forEach(t),dZr=r(dae,` load the model weights. It only affects the
model\u2019s configuration. Use `),ere=n(dae,"A",{href:!0});var kXt=s(ere);cZr=r(kXt,"from_pretrained()"),kXt.forEach(t),fZr=r(dae," to load the model weights."),dae.forEach(t),mZr=i(V6),T(cw.$$.fragment,V6),V6.forEach(t),gZr=i(bi),Jr=n(bi,"DIV",{class:!0});var vi=s(Jr);T(H$.$$.fragment,vi),hZr=i(vi),cwe=n(vi,"P",{});var SXt=s(cwe);pZr=r(SXt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),SXt.forEach(t),_Zr=i(vi),yn=n(vi,"P",{});var X6=s(yn);uZr=r(X6,"The model class to instantiate is selected based on the "),fwe=n(X6,"CODE",{});var RXt=s(fwe);bZr=r(RXt,"model_type"),RXt.forEach(t),vZr=r(X6,` property of the config object (either
passed as an argument or loaded from `),mwe=n(X6,"CODE",{});var PXt=s(mwe);FZr=r(PXt,"pretrained_model_name_or_path"),PXt.forEach(t),TZr=r(X6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gwe=n(X6,"CODE",{});var BXt=s(gwe);MZr=r(BXt,"pretrained_model_name_or_path"),BXt.forEach(t),EZr=r(X6,":"),X6.forEach(t),CZr=i(vi),Xe=n(vi,"UL",{});var Mo=s(Xe);fw=n(Mo,"LI",{});var AVe=s(fw);hwe=n(AVe,"STRONG",{});var IXt=s(hwe);wZr=r(IXt,"albert"),IXt.forEach(t),AZr=r(AVe," \u2014 "),ore=n(AVe,"A",{href:!0});var NXt=s(ore);LZr=r(NXt,"FlaxAlbertForMultipleChoice"),NXt.forEach(t),yZr=r(AVe," (ALBERT model)"),AVe.forEach(t),xZr=i(Mo),mw=n(Mo,"LI",{});var LVe=s(mw);pwe=n(LVe,"STRONG",{});var qXt=s(pwe);$Zr=r(qXt,"bert"),qXt.forEach(t),kZr=r(LVe," \u2014 "),rre=n(LVe,"A",{href:!0});var jXt=s(rre);SZr=r(jXt,"FlaxBertForMultipleChoice"),jXt.forEach(t),RZr=r(LVe," (BERT model)"),LVe.forEach(t),PZr=i(Mo),gw=n(Mo,"LI",{});var yVe=s(gw);_we=n(yVe,"STRONG",{});var DXt=s(_we);BZr=r(DXt,"big_bird"),DXt.forEach(t),IZr=r(yVe," \u2014 "),tre=n(yVe,"A",{href:!0});var GXt=s(tre);NZr=r(GXt,"FlaxBigBirdForMultipleChoice"),GXt.forEach(t),qZr=r(yVe," (BigBird model)"),yVe.forEach(t),jZr=i(Mo),hw=n(Mo,"LI",{});var xVe=s(hw);uwe=n(xVe,"STRONG",{});var OXt=s(uwe);DZr=r(OXt,"distilbert"),OXt.forEach(t),GZr=r(xVe," \u2014 "),are=n(xVe,"A",{href:!0});var VXt=s(are);OZr=r(VXt,"FlaxDistilBertForMultipleChoice"),VXt.forEach(t),VZr=r(xVe," (DistilBERT model)"),xVe.forEach(t),XZr=i(Mo),pw=n(Mo,"LI",{});var $Ve=s(pw);bwe=n($Ve,"STRONG",{});var XXt=s(bwe);zZr=r(XXt,"electra"),XXt.forEach(t),QZr=r($Ve," \u2014 "),nre=n($Ve,"A",{href:!0});var zXt=s(nre);WZr=r(zXt,"FlaxElectraForMultipleChoice"),zXt.forEach(t),HZr=r($Ve," (ELECTRA model)"),$Ve.forEach(t),UZr=i(Mo),_w=n(Mo,"LI",{});var kVe=s(_w);vwe=n(kVe,"STRONG",{});var QXt=s(vwe);JZr=r(QXt,"roberta"),QXt.forEach(t),YZr=r(kVe," \u2014 "),sre=n(kVe,"A",{href:!0});var WXt=s(sre);KZr=r(WXt,"FlaxRobertaForMultipleChoice"),WXt.forEach(t),ZZr=r(kVe," (RoBERTa model)"),kVe.forEach(t),eet=i(Mo),uw=n(Mo,"LI",{});var SVe=s(uw);Fwe=n(SVe,"STRONG",{});var HXt=s(Fwe);oet=r(HXt,"roformer"),HXt.forEach(t),ret=r(SVe," \u2014 "),lre=n(SVe,"A",{href:!0});var UXt=s(lre);tet=r(UXt,"FlaxRoFormerForMultipleChoice"),UXt.forEach(t),aet=r(SVe," (RoFormer model)"),SVe.forEach(t),net=i(Mo),bw=n(Mo,"LI",{});var RVe=s(bw);Twe=n(RVe,"STRONG",{});var JXt=s(Twe);set=r(JXt,"xlm-roberta"),JXt.forEach(t),iet=r(RVe," \u2014 "),ire=n(RVe,"A",{href:!0});var YXt=s(ire);det=r(YXt,"FlaxXLMRobertaForMultipleChoice"),YXt.forEach(t),cet=r(RVe," (XLM-RoBERTa model)"),RVe.forEach(t),Mo.forEach(t),fet=i(vi),T(vw.$$.fragment,vi),vi.forEach(t),bi.forEach(t),Nze=i(f),Tf=n(f,"H2",{class:!0});var QWe=s(Tf);Fw=n(QWe,"A",{id:!0,class:!0,href:!0});var KXt=s(Fw);Mwe=n(KXt,"SPAN",{});var ZXt=s(Mwe);T(U$.$$.fragment,ZXt),ZXt.forEach(t),KXt.forEach(t),met=i(QWe),Ewe=n(QWe,"SPAN",{});var ezt=s(Ewe);get=r(ezt,"FlaxAutoModelForNextSentencePrediction"),ezt.forEach(t),QWe.forEach(t),qze=i(f),Er=n(f,"DIV",{class:!0});var Fi=s(Er);T(J$.$$.fragment,Fi),het=i(Fi),Mf=n(Fi,"P",{});var cae=s(Mf);pet=r(cae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),dre=n(cae,"A",{href:!0});var ozt=s(dre);_et=r(ozt,"from_pretrained()"),ozt.forEach(t),uet=r(cae," class method or the "),cre=n(cae,"A",{href:!0});var rzt=s(cre);bet=r(rzt,"from_config()"),rzt.forEach(t),vet=r(cae,` class
method.`),cae.forEach(t),Fet=i(Fi),Y$=n(Fi,"P",{});var WWe=s(Y$);Tet=r(WWe,"This class cannot be instantiated directly using "),Cwe=n(WWe,"CODE",{});var tzt=s(Cwe);Met=r(tzt,"__init__()"),tzt.forEach(t),Eet=r(WWe," (throws an error)."),WWe.forEach(t),Cet=i(Fi),oa=n(Fi,"DIV",{class:!0});var z6=s(oa);T(K$.$$.fragment,z6),wet=i(z6),wwe=n(z6,"P",{});var azt=s(wwe);Aet=r(azt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),azt.forEach(t),Let=i(z6),Ef=n(z6,"P",{});var fae=s(Ef);yet=r(fae,`Note:
Loading a model from its configuration file does `),Awe=n(fae,"STRONG",{});var nzt=s(Awe);xet=r(nzt,"not"),nzt.forEach(t),$et=r(fae,` load the model weights. It only affects the
model\u2019s configuration. Use `),fre=n(fae,"A",{href:!0});var szt=s(fre);ket=r(szt,"from_pretrained()"),szt.forEach(t),Set=r(fae," to load the model weights."),fae.forEach(t),Ret=i(z6),T(Tw.$$.fragment,z6),z6.forEach(t),Pet=i(Fi),Yr=n(Fi,"DIV",{class:!0});var Ti=s(Yr);T(Z$.$$.fragment,Ti),Bet=i(Ti),Lwe=n(Ti,"P",{});var lzt=s(Lwe);Iet=r(lzt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),lzt.forEach(t),Net=i(Ti),xn=n(Ti,"P",{});var Q6=s(xn);qet=r(Q6,"The model class to instantiate is selected based on the "),ywe=n(Q6,"CODE",{});var izt=s(ywe);jet=r(izt,"model_type"),izt.forEach(t),Det=r(Q6,` property of the config object (either
passed as an argument or loaded from `),xwe=n(Q6,"CODE",{});var dzt=s(xwe);Get=r(dzt,"pretrained_model_name_or_path"),dzt.forEach(t),Oet=r(Q6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$we=n(Q6,"CODE",{});var czt=s($we);Vet=r(czt,"pretrained_model_name_or_path"),czt.forEach(t),Xet=r(Q6,":"),Q6.forEach(t),zet=i(Ti),kwe=n(Ti,"UL",{});var fzt=s(kwe);Mw=n(fzt,"LI",{});var PVe=s(Mw);Swe=n(PVe,"STRONG",{});var mzt=s(Swe);Qet=r(mzt,"bert"),mzt.forEach(t),Wet=r(PVe," \u2014 "),mre=n(PVe,"A",{href:!0});var gzt=s(mre);Het=r(gzt,"FlaxBertForNextSentencePrediction"),gzt.forEach(t),Uet=r(PVe," (BERT model)"),PVe.forEach(t),fzt.forEach(t),Jet=i(Ti),T(Ew.$$.fragment,Ti),Ti.forEach(t),Fi.forEach(t),jze=i(f),Cf=n(f,"H2",{class:!0});var HWe=s(Cf);Cw=n(HWe,"A",{id:!0,class:!0,href:!0});var hzt=s(Cw);Rwe=n(hzt,"SPAN",{});var pzt=s(Rwe);T(ek.$$.fragment,pzt),pzt.forEach(t),hzt.forEach(t),Yet=i(HWe),Pwe=n(HWe,"SPAN",{});var _zt=s(Pwe);Ket=r(_zt,"FlaxAutoModelForImageClassification"),_zt.forEach(t),HWe.forEach(t),Dze=i(f),Cr=n(f,"DIV",{class:!0});var Mi=s(Cr);T(ok.$$.fragment,Mi),Zet=i(Mi),wf=n(Mi,"P",{});var mae=s(wf);eot=r(mae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),gre=n(mae,"A",{href:!0});var uzt=s(gre);oot=r(uzt,"from_pretrained()"),uzt.forEach(t),rot=r(mae," class method or the "),hre=n(mae,"A",{href:!0});var bzt=s(hre);tot=r(bzt,"from_config()"),bzt.forEach(t),aot=r(mae,` class
method.`),mae.forEach(t),not=i(Mi),rk=n(Mi,"P",{});var UWe=s(rk);sot=r(UWe,"This class cannot be instantiated directly using "),Bwe=n(UWe,"CODE",{});var vzt=s(Bwe);lot=r(vzt,"__init__()"),vzt.forEach(t),iot=r(UWe," (throws an error)."),UWe.forEach(t),dot=i(Mi),ra=n(Mi,"DIV",{class:!0});var W6=s(ra);T(tk.$$.fragment,W6),cot=i(W6),Iwe=n(W6,"P",{});var Fzt=s(Iwe);fot=r(Fzt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Fzt.forEach(t),mot=i(W6),Af=n(W6,"P",{});var gae=s(Af);got=r(gae,`Note:
Loading a model from its configuration file does `),Nwe=n(gae,"STRONG",{});var Tzt=s(Nwe);hot=r(Tzt,"not"),Tzt.forEach(t),pot=r(gae,` load the model weights. It only affects the
model\u2019s configuration. Use `),pre=n(gae,"A",{href:!0});var Mzt=s(pre);_ot=r(Mzt,"from_pretrained()"),Mzt.forEach(t),uot=r(gae," to load the model weights."),gae.forEach(t),bot=i(W6),T(ww.$$.fragment,W6),W6.forEach(t),vot=i(Mi),Kr=n(Mi,"DIV",{class:!0});var Ei=s(Kr);T(ak.$$.fragment,Ei),Fot=i(Ei),qwe=n(Ei,"P",{});var Ezt=s(qwe);Tot=r(Ezt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Ezt.forEach(t),Mot=i(Ei),$n=n(Ei,"P",{});var H6=s($n);Eot=r(H6,"The model class to instantiate is selected based on the "),jwe=n(H6,"CODE",{});var Czt=s(jwe);Cot=r(Czt,"model_type"),Czt.forEach(t),wot=r(H6,` property of the config object (either
passed as an argument or loaded from `),Dwe=n(H6,"CODE",{});var wzt=s(Dwe);Aot=r(wzt,"pretrained_model_name_or_path"),wzt.forEach(t),Lot=r(H6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gwe=n(H6,"CODE",{});var Azt=s(Gwe);yot=r(Azt,"pretrained_model_name_or_path"),Azt.forEach(t),xot=r(H6,":"),H6.forEach(t),$ot=i(Ei),nk=n(Ei,"UL",{});var JWe=s(nk);Aw=n(JWe,"LI",{});var BVe=s(Aw);Owe=n(BVe,"STRONG",{});var Lzt=s(Owe);kot=r(Lzt,"beit"),Lzt.forEach(t),Sot=r(BVe," \u2014 "),_re=n(BVe,"A",{href:!0});var yzt=s(_re);Rot=r(yzt,"FlaxBeitForImageClassification"),yzt.forEach(t),Pot=r(BVe," (BEiT model)"),BVe.forEach(t),Bot=i(JWe),Lw=n(JWe,"LI",{});var IVe=s(Lw);Vwe=n(IVe,"STRONG",{});var xzt=s(Vwe);Iot=r(xzt,"vit"),xzt.forEach(t),Not=r(IVe," \u2014 "),ure=n(IVe,"A",{href:!0});var $zt=s(ure);qot=r($zt,"FlaxViTForImageClassification"),$zt.forEach(t),jot=r(IVe," (ViT model)"),IVe.forEach(t),JWe.forEach(t),Dot=i(Ei),T(yw.$$.fragment,Ei),Ei.forEach(t),Mi.forEach(t),Gze=i(f),Lf=n(f,"H2",{class:!0});var YWe=s(Lf);xw=n(YWe,"A",{id:!0,class:!0,href:!0});var kzt=s(xw);Xwe=n(kzt,"SPAN",{});var Szt=s(Xwe);T(sk.$$.fragment,Szt),Szt.forEach(t),kzt.forEach(t),Got=i(YWe),zwe=n(YWe,"SPAN",{});var Rzt=s(zwe);Oot=r(Rzt,"FlaxAutoModelForVision2Seq"),Rzt.forEach(t),YWe.forEach(t),Oze=i(f),wr=n(f,"DIV",{class:!0});var Ci=s(wr);T(lk.$$.fragment,Ci),Vot=i(Ci),yf=n(Ci,"P",{});var hae=s(yf);Xot=r(hae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),bre=n(hae,"A",{href:!0});var Pzt=s(bre);zot=r(Pzt,"from_pretrained()"),Pzt.forEach(t),Qot=r(hae," class method or the "),vre=n(hae,"A",{href:!0});var Bzt=s(vre);Wot=r(Bzt,"from_config()"),Bzt.forEach(t),Hot=r(hae,` class
method.`),hae.forEach(t),Uot=i(Ci),ik=n(Ci,"P",{});var KWe=s(ik);Jot=r(KWe,"This class cannot be instantiated directly using "),Qwe=n(KWe,"CODE",{});var Izt=s(Qwe);Yot=r(Izt,"__init__()"),Izt.forEach(t),Kot=r(KWe," (throws an error)."),KWe.forEach(t),Zot=i(Ci),ta=n(Ci,"DIV",{class:!0});var U6=s(ta);T(dk.$$.fragment,U6),ert=i(U6),Wwe=n(U6,"P",{});var Nzt=s(Wwe);ort=r(Nzt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Nzt.forEach(t),rrt=i(U6),xf=n(U6,"P",{});var pae=s(xf);trt=r(pae,`Note:
Loading a model from its configuration file does `),Hwe=n(pae,"STRONG",{});var qzt=s(Hwe);art=r(qzt,"not"),qzt.forEach(t),nrt=r(pae,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fre=n(pae,"A",{href:!0});var jzt=s(Fre);srt=r(jzt,"from_pretrained()"),jzt.forEach(t),lrt=r(pae," to load the model weights."),pae.forEach(t),irt=i(U6),T($w.$$.fragment,U6),U6.forEach(t),drt=i(Ci),Zr=n(Ci,"DIV",{class:!0});var wi=s(Zr);T(ck.$$.fragment,wi),crt=i(wi),Uwe=n(wi,"P",{});var Dzt=s(Uwe);frt=r(Dzt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Dzt.forEach(t),mrt=i(wi),kn=n(wi,"P",{});var J6=s(kn);grt=r(J6,"The model class to instantiate is selected based on the "),Jwe=n(J6,"CODE",{});var Gzt=s(Jwe);hrt=r(Gzt,"model_type"),Gzt.forEach(t),prt=r(J6,` property of the config object (either
passed as an argument or loaded from `),Ywe=n(J6,"CODE",{});var Ozt=s(Ywe);_rt=r(Ozt,"pretrained_model_name_or_path"),Ozt.forEach(t),urt=r(J6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Kwe=n(J6,"CODE",{});var Vzt=s(Kwe);brt=r(Vzt,"pretrained_model_name_or_path"),Vzt.forEach(t),vrt=r(J6,":"),J6.forEach(t),Frt=i(wi),Zwe=n(wi,"UL",{});var Xzt=s(Zwe);kw=n(Xzt,"LI",{});var NVe=s(kw);eAe=n(NVe,"STRONG",{});var zzt=s(eAe);Trt=r(zzt,"vision-encoder-decoder"),zzt.forEach(t),Mrt=r(NVe," \u2014 "),Tre=n(NVe,"A",{href:!0});var Qzt=s(Tre);Ert=r(Qzt,"FlaxVisionEncoderDecoderModel"),Qzt.forEach(t),Crt=r(NVe," (Vision Encoder decoder model)"),NVe.forEach(t),Xzt.forEach(t),wrt=i(wi),T(Sw.$$.fragment,wi),wi.forEach(t),Ci.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(KWt)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(Rn,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.AutoConfig"),c(Bn,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.AutoModel"),c(In,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.AutoTokenizer"),c(Si,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertModel"),c(Nf,"id","extending-the-auto-classes"),c(Nf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Nf,"href","#extending-the-auto-classes"),c(Ri,"class","relative group"),c(jf,"id","transformers.AutoConfig"),c(jf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(jf,"href","#transformers.AutoConfig"),c(Pi,"class","relative group"),c(NS,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(qS,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertConfig"),c(jS,"href","/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartConfig"),c(DS,"href","/docs/transformers/pr_17281/en/model_doc/beit#transformers.BeitConfig"),c(GS,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertConfig"),c(OS,"href","/docs/transformers/pr_17281/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(VS,"href","/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdConfig"),c(XS,"href","/docs/transformers/pr_17281/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(zS,"href","/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(QS,"href","/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(WS,"href","/docs/transformers/pr_17281/en/model_doc/bloom#transformers.BloomConfig"),c(HS,"href","/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertConfig"),c(US,"href","/docs/transformers/pr_17281/en/model_doc/canine#transformers.CanineConfig"),c(JS,"href","/docs/transformers/pr_17281/en/model_doc/clip#transformers.CLIPConfig"),c(YS,"href","/docs/transformers/pr_17281/en/model_doc/codegen#transformers.CodeGenConfig"),c(KS,"href","/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertConfig"),c(ZS,"href","/docs/transformers/pr_17281/en/model_doc/convnext#transformers.ConvNextConfig"),c(eR,"href","/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.CTRLConfig"),c(oR,"href","/docs/transformers/pr_17281/en/model_doc/cvt#transformers.CvtConfig"),c(rR,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(tR,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(aR,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(nR,"href","/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaConfig"),c(sR,"href","/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(lR,"href","/docs/transformers/pr_17281/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(iR,"href","/docs/transformers/pr_17281/en/model_doc/deformable_detr#transformers.DeformableDetrConfig"),c(dR,"href","/docs/transformers/pr_17281/en/model_doc/deit#transformers.DeiTConfig"),c(cR,"href","/docs/transformers/pr_17281/en/model_doc/detr#transformers.DetrConfig"),c(fR,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertConfig"),c(mR,"href","/docs/transformers/pr_17281/en/model_doc/dpr#transformers.DPRConfig"),c(gR,"href","/docs/transformers/pr_17281/en/model_doc/dpt#transformers.DPTConfig"),c(hR,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraConfig"),c(pR,"href","/docs/transformers/pr_17281/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(_R,"href","/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertConfig"),c(uR,"href","/docs/transformers/pr_17281/en/model_doc/flava#transformers.FlavaConfig"),c(bR,"href","/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetConfig"),c(vR,"href","/docs/transformers/pr_17281/en/model_doc/fsmt#transformers.FSMTConfig"),c(FR,"href","/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelConfig"),c(TR,"href","/docs/transformers/pr_17281/en/model_doc/glpn#transformers.GLPNConfig"),c(MR,"href","/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2Config"),c(ER,"href","/docs/transformers/pr_17281/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(CR,"href","/docs/transformers/pr_17281/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(wR,"href","/docs/transformers/pr_17281/en/model_doc/gptj#transformers.GPTJConfig"),c(AR,"href","/docs/transformers/pr_17281/en/model_doc/groupvit#transformers.GroupViTConfig"),c(LR,"href","/docs/transformers/pr_17281/en/model_doc/hubert#transformers.HubertConfig"),c(yR,"href","/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertConfig"),c(xR,"href","/docs/transformers/pr_17281/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c($R,"href","/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(kR,"href","/docs/transformers/pr_17281/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(SR,"href","/docs/transformers/pr_17281/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(RR,"href","/docs/transformers/pr_17281/en/model_doc/led#transformers.LEDConfig"),c(PR,"href","/docs/transformers/pr_17281/en/model_doc/levit#transformers.LevitConfig"),c(BR,"href","/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerConfig"),c(IR,"href","/docs/transformers/pr_17281/en/model_doc/longt5#transformers.LongT5Config"),c(NR,"href","/docs/transformers/pr_17281/en/model_doc/luke#transformers.LukeConfig"),c(qR,"href","/docs/transformers/pr_17281/en/model_doc/lxmert#transformers.LxmertConfig"),c(jR,"href","/docs/transformers/pr_17281/en/model_doc/m2m_100#transformers.M2M100Config"),c(DR,"href","/docs/transformers/pr_17281/en/model_doc/marian#transformers.MarianConfig"),c(GR,"href","/docs/transformers/pr_17281/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(OR,"href","/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartConfig"),c(VR,"href","/docs/transformers/pr_17281/en/model_doc/mctct#transformers.MCTCTConfig"),c(XR,"href","/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(zR,"href","/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(QR,"href","/docs/transformers/pr_17281/en/model_doc/mobilevit#transformers.MobileViTConfig"),c(WR,"href","/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetConfig"),c(HR,"href","/docs/transformers/pr_17281/en/model_doc/mt5#transformers.MT5Config"),c(UR,"href","/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpConfig"),c(JR,"href","/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaConfig"),c(YR,"href","/docs/transformers/pr_17281/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(KR,"href","/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(ZR,"href","/docs/transformers/pr_17281/en/model_doc/opt#transformers.OPTConfig"),c(eP,"href","/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.PegasusConfig"),c(oP,"href","/docs/transformers/pr_17281/en/model_doc/perceiver#transformers.PerceiverConfig"),c(rP,"href","/docs/transformers/pr_17281/en/model_doc/plbart#transformers.PLBartConfig"),c(tP,"href","/docs/transformers/pr_17281/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(aP,"href","/docs/transformers/pr_17281/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(nP,"href","/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(sP,"href","/docs/transformers/pr_17281/en/model_doc/rag#transformers.RagConfig"),c(lP,"href","/docs/transformers/pr_17281/en/model_doc/realm#transformers.RealmConfig"),c(iP,"href","/docs/transformers/pr_17281/en/model_doc/reformer#transformers.ReformerConfig"),c(dP,"href","/docs/transformers/pr_17281/en/model_doc/regnet#transformers.RegNetConfig"),c(cP,"href","/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertConfig"),c(fP,"href","/docs/transformers/pr_17281/en/model_doc/resnet#transformers.ResNetConfig"),c(mP,"href","/docs/transformers/pr_17281/en/model_doc/retribert#transformers.RetriBertConfig"),c(gP,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaConfig"),c(hP,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerConfig"),c(pP,"href","/docs/transformers/pr_17281/en/model_doc/segformer#transformers.SegformerConfig"),c(_P,"href","/docs/transformers/pr_17281/en/model_doc/sew#transformers.SEWConfig"),c(uP,"href","/docs/transformers/pr_17281/en/model_doc/sew-d#transformers.SEWDConfig"),c(bP,"href","/docs/transformers/pr_17281/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(vP,"href","/docs/transformers/pr_17281/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(FP,"href","/docs/transformers/pr_17281/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(TP,"href","/docs/transformers/pr_17281/en/model_doc/splinter#transformers.SplinterConfig"),c(MP,"href","/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(EP,"href","/docs/transformers/pr_17281/en/model_doc/swin#transformers.SwinConfig"),c(CP,"href","/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5Config"),c(wP,"href","/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasConfig"),c(AP,"href","/docs/transformers/pr_17281/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(LP,"href","/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(yP,"href","/docs/transformers/pr_17281/en/model_doc/trocr#transformers.TrOCRConfig"),c(xP,"href","/docs/transformers/pr_17281/en/model_doc/unispeech#transformers.UniSpeechConfig"),c($P,"href","/docs/transformers/pr_17281/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(kP,"href","/docs/transformers/pr_17281/en/model_doc/van#transformers.VanConfig"),c(SP,"href","/docs/transformers/pr_17281/en/model_doc/vilt#transformers.ViltConfig"),c(RP,"href","/docs/transformers/pr_17281/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(PP,"href","/docs/transformers/pr_17281/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(BP,"href","/docs/transformers/pr_17281/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(IP,"href","/docs/transformers/pr_17281/en/model_doc/vit#transformers.ViTConfig"),c(NP,"href","/docs/transformers/pr_17281/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(qP,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(jP,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(DP,"href","/docs/transformers/pr_17281/en/model_doc/wavlm#transformers.WavLMConfig"),c(GP,"href","/docs/transformers/pr_17281/en/model_doc/xglm#transformers.XGLMConfig"),c(OP,"href","/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMConfig"),c(VP,"href","/docs/transformers/pr_17281/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(XP,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(zP,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(QP,"href","/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetConfig"),c(WP,"href","/docs/transformers/pr_17281/en/model_doc/yolos#transformers.YolosConfig"),c(HP,"href","/docs/transformers/pr_17281/en/model_doc/yoso#transformers.YosoConfig"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Kg,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zg,"id","transformers.AutoTokenizer"),c(Zg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Zg,"href","#transformers.AutoTokenizer"),c(Ii,"class","relative group"),c(UP,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(JP,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertTokenizer"),c(YP,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(KP,"href","/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartTokenizer"),c(ZP,"href","/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartTokenizerFast"),c(eB,"href","/docs/transformers/pr_17281/en/model_doc/barthez#transformers.BarthezTokenizer"),c(oB,"href","/docs/transformers/pr_17281/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(rB,"href","/docs/transformers/pr_17281/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(tB,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertTokenizer"),c(aB,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertTokenizerFast"),c(nB,"href","/docs/transformers/pr_17281/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(sB,"href","/docs/transformers/pr_17281/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(lB,"href","/docs/transformers/pr_17281/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(iB,"href","/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(dB,"href","/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(cB,"href","/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(fB,"href","/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(mB,"href","/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(gB,"href","/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(hB,"href","/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(pB,"href","/docs/transformers/pr_17281/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(_B,"href","/docs/transformers/pr_17281/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(uB,"href","/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertTokenizer"),c(bB,"href","/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(vB,"href","/docs/transformers/pr_17281/en/model_doc/canine#transformers.CanineTokenizer"),c(FB,"href","/docs/transformers/pr_17281/en/model_doc/clip#transformers.CLIPTokenizer"),c(TB,"href","/docs/transformers/pr_17281/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(MB,"href","/docs/transformers/pr_17281/en/model_doc/codegen#transformers.CodeGenTokenizer"),c(EB,"href","/docs/transformers/pr_17281/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),c(CB,"href","/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(wB,"href","/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(AB,"href","/docs/transformers/pr_17281/en/model_doc/cpm#transformers.CpmTokenizer"),c(LB,"href","/docs/transformers/pr_17281/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(yB,"href","/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(xB,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaTokenizer"),c($B,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(kB,"href","/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaTokenizer"),c(SB,"href","/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(RB,"href","/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(PB,"href","/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(BB,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(IB,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(NB,"href","/docs/transformers/pr_17281/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(qB,"href","/docs/transformers/pr_17281/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(jB,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraTokenizer"),c(DB,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(GB,"href","/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(OB,"href","/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetTokenizer"),c(VB,"href","/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(XB,"href","/docs/transformers/pr_17281/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(zB,"href","/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelTokenizer"),c(QB,"href","/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(WB,"href","/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(HB,"href","/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(UB,"href","/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(JB,"href","/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(YB,"href","/docs/transformers/pr_17281/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(KB,"href","/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(ZB,"href","/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(eI,"href","/docs/transformers/pr_17281/en/model_doc/clip#transformers.CLIPTokenizer"),c(oI,"href","/docs/transformers/pr_17281/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(rI,"href","/docs/transformers/pr_17281/en/model_doc/herbert#transformers.HerbertTokenizer"),c(tI,"href","/docs/transformers/pr_17281/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(aI,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(nI,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaTokenizer"),c(sI,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(lI,"href","/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(iI,"href","/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(dI,"href","/docs/transformers/pr_17281/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(cI,"href","/docs/transformers/pr_17281/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(fI,"href","/docs/transformers/pr_17281/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(mI,"href","/docs/transformers/pr_17281/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(gI,"href","/docs/transformers/pr_17281/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(hI,"href","/docs/transformers/pr_17281/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(pI,"href","/docs/transformers/pr_17281/en/model_doc/led#transformers.LEDTokenizer"),c(_I,"href","/docs/transformers/pr_17281/en/model_doc/led#transformers.LEDTokenizerFast"),c(uI,"href","/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerTokenizer"),c(bI,"href","/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(vI,"href","/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5Tokenizer"),c(FI,"href","/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5TokenizerFast"),c(TI,"href","/docs/transformers/pr_17281/en/model_doc/luke#transformers.LukeTokenizer"),c(MI,"href","/docs/transformers/pr_17281/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(EI,"href","/docs/transformers/pr_17281/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(CI,"href","/docs/transformers/pr_17281/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(wI,"href","/docs/transformers/pr_17281/en/model_doc/marian#transformers.MarianTokenizer"),c(AI,"href","/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartTokenizer"),c(LI,"href","/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(yI,"href","/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(xI,"href","/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c($I,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertTokenizer"),c(kI,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertTokenizerFast"),c(SI,"href","/docs/transformers/pr_17281/en/model_doc/mluke#transformers.MLukeTokenizer"),c(RI,"href","/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(PI,"href","/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(BI,"href","/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(II,"href","/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(NI,"href","/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5Tokenizer"),c(qI,"href","/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5TokenizerFast"),c(jI,"href","/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpTokenizer"),c(DI,"href","/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpTokenizerFast"),c(GI,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertTokenizer"),c(OI,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertTokenizerFast"),c(VI,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertTokenizer"),c(XI,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(zI,"href","/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(QI,"href","/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(WI,"href","/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(HI,"href","/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(UI,"href","/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(JI,"href","/docs/transformers/pr_17281/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(YI,"href","/docs/transformers/pr_17281/en/model_doc/phobert#transformers.PhobertTokenizer"),c(KI,"href","/docs/transformers/pr_17281/en/model_doc/plbart#transformers.PLBartTokenizer"),c(ZI,"href","/docs/transformers/pr_17281/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(eN,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertTokenizer"),c(oN,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertTokenizerFast"),c(rN,"href","/docs/transformers/pr_17281/en/model_doc/rag#transformers.RagTokenizer"),c(tN,"href","/docs/transformers/pr_17281/en/model_doc/realm#transformers.RealmTokenizer"),c(aN,"href","/docs/transformers/pr_17281/en/model_doc/realm#transformers.RealmTokenizerFast"),c(nN,"href","/docs/transformers/pr_17281/en/model_doc/reformer#transformers.ReformerTokenizer"),c(sN,"href","/docs/transformers/pr_17281/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(lN,"href","/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertTokenizer"),c(iN,"href","/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(dN,"href","/docs/transformers/pr_17281/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(cN,"href","/docs/transformers/pr_17281/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(fN,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaTokenizer"),c(mN,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(gN,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(hN,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(pN,"href","/docs/transformers/pr_17281/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(_N,"href","/docs/transformers/pr_17281/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(uN,"href","/docs/transformers/pr_17281/en/model_doc/splinter#transformers.SplinterTokenizer"),c(bN,"href","/docs/transformers/pr_17281/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(vN,"href","/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(FN,"href","/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(TN,"href","/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5Tokenizer"),c(MN,"href","/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5TokenizerFast"),c(EN,"href","/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasTokenizer"),c(CN,"href","/docs/transformers/pr_17281/en/model_doc/tapex#transformers.TapexTokenizer"),c(wN,"href","/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(AN,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertTokenizer"),c(LN,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertTokenizerFast"),c(yN,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertTokenizer"),c(xN,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertTokenizerFast"),c($N,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(kN,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(SN,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(RN,"href","/docs/transformers/pr_17281/en/model_doc/xglm#transformers.XGLMTokenizer"),c(PN,"href","/docs/transformers/pr_17281/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(BN,"href","/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMTokenizer"),c(IN,"href","/docs/transformers/pr_17281/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(NN,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(qN,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(jN,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaTokenizer"),c(DN,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(GN,"href","/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(ON,"href","/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(VN,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertTokenizer"),c(XN,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ph,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bh,"id","transformers.AutoFeatureExtractor"),c(Bh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Bh,"href","#transformers.AutoFeatureExtractor"),c(Ni,"class","relative group"),c(zN,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(QN,"href","/docs/transformers/pr_17281/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(WN,"href","/docs/transformers/pr_17281/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(HN,"href","/docs/transformers/pr_17281/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(UN,"href","/docs/transformers/pr_17281/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(JN,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(YN,"href","/docs/transformers/pr_17281/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(KN,"href","/docs/transformers/pr_17281/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(ZN,"href","/docs/transformers/pr_17281/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(eq,"href","/docs/transformers/pr_17281/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(oq,"href","/docs/transformers/pr_17281/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(rq,"href","/docs/transformers/pr_17281/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(tq,"href","/docs/transformers/pr_17281/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(aq,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(nq,"href","/docs/transformers/pr_17281/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(sq,"href","/docs/transformers/pr_17281/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(lq,"href","/docs/transformers/pr_17281/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(iq,"href","/docs/transformers/pr_17281/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(dq,"href","/docs/transformers/pr_17281/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(cq,"href","/docs/transformers/pr_17281/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(fq,"href","/docs/transformers/pr_17281/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor"),c(mq,"href","/docs/transformers/pr_17281/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(gq,"href","/docs/transformers/pr_17281/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(hq,"href","/docs/transformers/pr_17281/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(pq,"href","/docs/transformers/pr_17281/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(_q,"href","/docs/transformers/pr_17281/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(uq,"href","/docs/transformers/pr_17281/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(bq,"href","/docs/transformers/pr_17281/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(vq,"href","/docs/transformers/pr_17281/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(Fq,"href","/docs/transformers/pr_17281/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(Tq,"href","/docs/transformers/pr_17281/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(Mq,"href","/docs/transformers/pr_17281/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(Eq,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(Cq,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(wq,"href","/docs/transformers/pr_17281/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vp,"id","transformers.AutoProcessor"),c(vp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(vp,"href","#transformers.AutoProcessor"),c(qi,"class","relative group"),c(Aq,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(Lq,"href","/docs/transformers/pr_17281/en/model_doc/clip#transformers.CLIPProcessor"),c(yq,"href","/docs/transformers/pr_17281/en/model_doc/clip#transformers.CLIPProcessor"),c(xq,"href","/docs/transformers/pr_17281/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c($q,"href","/docs/transformers/pr_17281/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(kq,"href","/docs/transformers/pr_17281/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(Sq,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Rq,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Pq,"href","/docs/transformers/pr_17281/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(Bq,"href","/docs/transformers/pr_17281/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(Iq,"href","/docs/transformers/pr_17281/en/model_doc/trocr#transformers.TrOCRProcessor"),c(Nq,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(qq,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(jq,"href","/docs/transformers/pr_17281/en/model_doc/vilt#transformers.ViltProcessor"),c(Dq,"href","/docs/transformers/pr_17281/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(Gq,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Oq,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Vq,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Dp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Gp,"id","transformers.AutoModel"),c(Gp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Gp,"href","#transformers.AutoModel"),c(Di,"class","relative group"),c(Xq,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zq,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Qq,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wq,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertModel"),c(Hq,"href","/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartModel"),c(Uq,"href","/docs/transformers/pr_17281/en/model_doc/beit#transformers.BeitModel"),c(Jq,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertModel"),c(Yq,"href","/docs/transformers/pr_17281/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(Kq,"href","/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdModel"),c(Zq,"href","/docs/transformers/pr_17281/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(ej,"href","/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(oj,"href","/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(rj,"href","/docs/transformers/pr_17281/en/model_doc/bloom#transformers.BloomModel"),c(tj,"href","/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertModel"),c(aj,"href","/docs/transformers/pr_17281/en/model_doc/canine#transformers.CanineModel"),c(nj,"href","/docs/transformers/pr_17281/en/model_doc/clip#transformers.CLIPModel"),c(sj,"href","/docs/transformers/pr_17281/en/model_doc/codegen#transformers.CodeGenModel"),c(lj,"href","/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertModel"),c(ij,"href","/docs/transformers/pr_17281/en/model_doc/convnext#transformers.ConvNextModel"),c(dj,"href","/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.CTRLModel"),c(cj,"href","/docs/transformers/pr_17281/en/model_doc/cvt#transformers.CvtModel"),c(fj,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(mj,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(gj,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(hj,"href","/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaModel"),c(pj,"href","/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(_j,"href","/docs/transformers/pr_17281/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(uj,"href","/docs/transformers/pr_17281/en/model_doc/deit#transformers.DeiTModel"),c(bj,"href","/docs/transformers/pr_17281/en/model_doc/detr#transformers.DetrModel"),c(vj,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertModel"),c(Fj,"href","/docs/transformers/pr_17281/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(Tj,"href","/docs/transformers/pr_17281/en/model_doc/dpt#transformers.DPTModel"),c(Mj,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraModel"),c(Ej,"href","/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertModel"),c(Cj,"href","/docs/transformers/pr_17281/en/model_doc/flava#transformers.FlavaModel"),c(wj,"href","/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetModel"),c(Aj,"href","/docs/transformers/pr_17281/en/model_doc/fsmt#transformers.FSMTModel"),c(Lj,"href","/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelModel"),c(yj,"href","/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelBaseModel"),c(xj,"href","/docs/transformers/pr_17281/en/model_doc/glpn#transformers.GLPNModel"),c($j,"href","/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2Model"),c(kj,"href","/docs/transformers/pr_17281/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(Sj,"href","/docs/transformers/pr_17281/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(Rj,"href","/docs/transformers/pr_17281/en/model_doc/gptj#transformers.GPTJModel"),c(Pj,"href","/docs/transformers/pr_17281/en/model_doc/groupvit#transformers.GroupViTModel"),c(Bj,"href","/docs/transformers/pr_17281/en/model_doc/hubert#transformers.HubertModel"),c(Ij,"href","/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertModel"),c(Nj,"href","/docs/transformers/pr_17281/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(qj,"href","/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(jj,"href","/docs/transformers/pr_17281/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(Dj,"href","/docs/transformers/pr_17281/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(Gj,"href","/docs/transformers/pr_17281/en/model_doc/led#transformers.LEDModel"),c(Oj,"href","/docs/transformers/pr_17281/en/model_doc/levit#transformers.LevitModel"),c(Vj,"href","/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerModel"),c(Xj,"href","/docs/transformers/pr_17281/en/model_doc/longt5#transformers.LongT5Model"),c(zj,"href","/docs/transformers/pr_17281/en/model_doc/luke#transformers.LukeModel"),c(Qj,"href","/docs/transformers/pr_17281/en/model_doc/lxmert#transformers.LxmertModel"),c(Wj,"href","/docs/transformers/pr_17281/en/model_doc/m2m_100#transformers.M2M100Model"),c(Hj,"href","/docs/transformers/pr_17281/en/model_doc/marian#transformers.MarianModel"),c(Uj,"href","/docs/transformers/pr_17281/en/model_doc/maskformer#transformers.MaskFormerModel"),c(Jj,"href","/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartModel"),c(Yj,"href","/docs/transformers/pr_17281/en/model_doc/mctct#transformers.MCTCTModel"),c(Kj,"href","/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(Zj,"href","/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertModel"),c(eD,"href","/docs/transformers/pr_17281/en/model_doc/mobilevit#transformers.MobileViTModel"),c(oD,"href","/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetModel"),c(rD,"href","/docs/transformers/pr_17281/en/model_doc/mt5#transformers.MT5Model"),c(tD,"href","/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpModel"),c(aD,"href","/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaModel"),c(nD,"href","/docs/transformers/pr_17281/en/model_doc/nystromformer#transformers.NystromformerModel"),c(sD,"href","/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(lD,"href","/docs/transformers/pr_17281/en/model_doc/opt#transformers.OPTModel"),c(iD,"href","/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.PegasusModel"),c(dD,"href","/docs/transformers/pr_17281/en/model_doc/perceiver#transformers.PerceiverModel"),c(cD,"href","/docs/transformers/pr_17281/en/model_doc/plbart#transformers.PLBartModel"),c(fD,"href","/docs/transformers/pr_17281/en/model_doc/poolformer#transformers.PoolFormerModel"),c(mD,"href","/docs/transformers/pr_17281/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(gD,"href","/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertModel"),c(hD,"href","/docs/transformers/pr_17281/en/model_doc/reformer#transformers.ReformerModel"),c(pD,"href","/docs/transformers/pr_17281/en/model_doc/regnet#transformers.RegNetModel"),c(_D,"href","/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertModel"),c(uD,"href","/docs/transformers/pr_17281/en/model_doc/resnet#transformers.ResNetModel"),c(bD,"href","/docs/transformers/pr_17281/en/model_doc/retribert#transformers.RetriBertModel"),c(vD,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaModel"),c(FD,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerModel"),c(TD,"href","/docs/transformers/pr_17281/en/model_doc/segformer#transformers.SegformerModel"),c(MD,"href","/docs/transformers/pr_17281/en/model_doc/sew#transformers.SEWModel"),c(ED,"href","/docs/transformers/pr_17281/en/model_doc/sew-d#transformers.SEWDModel"),c(CD,"href","/docs/transformers/pr_17281/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(wD,"href","/docs/transformers/pr_17281/en/model_doc/splinter#transformers.SplinterModel"),c(AD,"href","/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(LD,"href","/docs/transformers/pr_17281/en/model_doc/swin#transformers.SwinModel"),c(yD,"href","/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5Model"),c(xD,"href","/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasModel"),c($D,"href","/docs/transformers/pr_17281/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(kD,"href","/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(SD,"href","/docs/transformers/pr_17281/en/model_doc/unispeech#transformers.UniSpeechModel"),c(RD,"href","/docs/transformers/pr_17281/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(PD,"href","/docs/transformers/pr_17281/en/model_doc/van#transformers.VanModel"),c(BD,"href","/docs/transformers/pr_17281/en/model_doc/vilt#transformers.ViltModel"),c(ID,"href","/docs/transformers/pr_17281/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(ND,"href","/docs/transformers/pr_17281/en/model_doc/visual_bert#transformers.VisualBertModel"),c(qD,"href","/docs/transformers/pr_17281/en/model_doc/vit#transformers.ViTModel"),c(jD,"href","/docs/transformers/pr_17281/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(DD,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(GD,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(OD,"href","/docs/transformers/pr_17281/en/model_doc/wavlm#transformers.WavLMModel"),c(VD,"href","/docs/transformers/pr_17281/en/model_doc/xglm#transformers.XGLMModel"),c(XD,"href","/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMModel"),c(zD,"href","/docs/transformers/pr_17281/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(QD,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(WD,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(HD,"href","/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetModel"),c(UD,"href","/docs/transformers/pr_17281/en/model_doc/yolos#transformers.YolosModel"),c(JD,"href","/docs/transformers/pr_17281/en/model_doc/yoso#transformers.YosoModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wu,"id","transformers.AutoModelForPreTraining"),c(Wu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Wu,"href","#transformers.AutoModelForPreTraining"),c(Vi,"class","relative group"),c(YD,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KD,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ZD,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eG,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertForPreTraining"),c(oG,"href","/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(rG,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertForPreTraining"),c(tG,"href","/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(aG,"href","/docs/transformers/pr_17281/en/model_doc/bloom#transformers.BloomForCausalLM"),c(nG,"href","/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(sG,"href","/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(lG,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(iG,"href","/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(dG,"href","/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(cG,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(fG,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraForPreTraining"),c(mG,"href","/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(gG,"href","/docs/transformers/pr_17281/en/model_doc/flava#transformers.FlavaForPreTraining"),c(hG,"href","/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetForPreTraining"),c(pG,"href","/docs/transformers/pr_17281/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(_G,"href","/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(uG,"href","/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(bG,"href","/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(vG,"href","/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(FG,"href","/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(TG,"href","/docs/transformers/pr_17281/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(MG,"href","/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(EG,"href","/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(CG,"href","/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(wG,"href","/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(AG,"href","/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(LG,"href","/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(yG,"href","/docs/transformers/pr_17281/en/model_doc/retribert#transformers.RetriBertModel"),c(xG,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c($G,"href","/docs/transformers/pr_17281/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(kG,"href","/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(SG,"href","/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(RG,"href","/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(PG,"href","/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(BG,"href","/docs/transformers/pr_17281/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(IG,"href","/docs/transformers/pr_17281/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(NG,"href","/docs/transformers/pr_17281/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(qG,"href","/docs/transformers/pr_17281/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(jG,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(DG,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(GG,"href","/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(OG,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(VG,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(XG,"href","/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(O1,"id","transformers.AutoModelForCausalLM"),c(O1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(O1,"href","#transformers.AutoModelForCausalLM"),c(Qi,"class","relative group"),c(zG,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QG,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WG,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HG,"href","/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartForCausalLM"),c(UG,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertLMHeadModel"),c(JG,"href","/docs/transformers/pr_17281/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(YG,"href","/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(KG,"href","/docs/transformers/pr_17281/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(ZG,"href","/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(eO,"href","/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(oO,"href","/docs/transformers/pr_17281/en/model_doc/bloom#transformers.BloomForCausalLM"),c(rO,"href","/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(tO,"href","/docs/transformers/pr_17281/en/model_doc/codegen#transformers.CodeGenForCausalLM"),c(aO,"href","/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(nO,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(sO,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraForCausalLM"),c(lO,"href","/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(iO,"href","/docs/transformers/pr_17281/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(dO,"href","/docs/transformers/pr_17281/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(cO,"href","/docs/transformers/pr_17281/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(fO,"href","/docs/transformers/pr_17281/en/model_doc/marian#transformers.MarianForCausalLM"),c(mO,"href","/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartForCausalLM"),c(gO,"href","/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(hO,"href","/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpForCausalLM"),c(pO,"href","/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(_O,"href","/docs/transformers/pr_17281/en/model_doc/opt#transformers.OPTForCausalLM"),c(uO,"href","/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(bO,"href","/docs/transformers/pr_17281/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(vO,"href","/docs/transformers/pr_17281/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(FO,"href","/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(TO,"href","/docs/transformers/pr_17281/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(MO,"href","/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(EO,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(CO,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(wO,"href","/docs/transformers/pr_17281/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(AO,"href","/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(LO,"href","/docs/transformers/pr_17281/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(yO,"href","/docs/transformers/pr_17281/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(xO,"href","/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c($O,"href","/docs/transformers/pr_17281/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(kO,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(SO,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(RO,"href","/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(S2,"id","transformers.AutoModelForMaskedLM"),c(S2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(S2,"href","#transformers.AutoModelForMaskedLM"),c(Ui,"class","relative group"),c(PO,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BO,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IO,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NO,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(qO,"href","/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(jO,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertForMaskedLM"),c(DO,"href","/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(GO,"href","/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(OO,"href","/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(VO,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(XO,"href","/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(zO,"href","/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(QO,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(WO,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(HO,"href","/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(UO,"href","/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(JO,"href","/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(YO,"href","/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(KO,"href","/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(ZO,"href","/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(eV,"href","/docs/transformers/pr_17281/en/model_doc/luke#transformers.LukeForMaskedLM"),c(oV,"href","/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(rV,"href","/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(tV,"href","/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(aV,"href","/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(nV,"href","/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(sV,"href","/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(lV,"href","/docs/transformers/pr_17281/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(iV,"href","/docs/transformers/pr_17281/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(dV,"href","/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(cV,"href","/docs/transformers/pr_17281/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(fV,"href","/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(mV,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(gV,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(hV,"href","/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(pV,"href","/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(_V,"href","/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(uV,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(bV,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(vV,"href","/docs/transformers/pr_17281/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fb,"id","transformers.AutoModelForSeq2SeqLM"),c(Fb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Fb,"href","#transformers.AutoModelForSeq2SeqLM"),c(Ki,"class","relative group"),c(FV,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TV,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MV,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EV,"href","/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(CV,"href","/docs/transformers/pr_17281/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(wV,"href","/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(AV,"href","/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(LV,"href","/docs/transformers/pr_17281/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(yV,"href","/docs/transformers/pr_17281/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(xV,"href","/docs/transformers/pr_17281/en/model_doc/led#transformers.LEDForConditionalGeneration"),c($V,"href","/docs/transformers/pr_17281/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(kV,"href","/docs/transformers/pr_17281/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(SV,"href","/docs/transformers/pr_17281/en/model_doc/marian#transformers.MarianMTModel"),c(RV,"href","/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(PV,"href","/docs/transformers/pr_17281/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(BV,"href","/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(IV,"href","/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(NV,"href","/docs/transformers/pr_17281/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(qV,"href","/docs/transformers/pr_17281/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(jV,"href","/docs/transformers/pr_17281/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(DV,"href","/docs/transformers/pr_17281/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ob,"id","transformers.AutoModelForSequenceClassification"),c(Ob,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ob,"href","#transformers.AutoModelForSequenceClassification"),c(od,"class","relative group"),c(GV,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OV,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VV,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XV,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(zV,"href","/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartForSequenceClassification"),c(QV,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertForSequenceClassification"),c(WV,"href","/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(HV,"href","/docs/transformers/pr_17281/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(UV,"href","/docs/transformers/pr_17281/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(JV,"href","/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(YV,"href","/docs/transformers/pr_17281/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(KV,"href","/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(ZV,"href","/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(eX,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(oX,"href","/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(rX,"href","/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(tX,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(aX,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(nX,"href","/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(sX,"href","/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(lX,"href","/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(iX,"href","/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(dX,"href","/docs/transformers/pr_17281/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(cX,"href","/docs/transformers/pr_17281/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(fX,"href","/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(mX,"href","/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(gX,"href","/docs/transformers/pr_17281/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(hX,"href","/docs/transformers/pr_17281/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(pX,"href","/docs/transformers/pr_17281/en/model_doc/led#transformers.LEDForSequenceClassification"),c(_X,"href","/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(uX,"href","/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(bX,"href","/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(vX,"href","/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(FX,"href","/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(TX,"href","/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpForSequenceClassification"),c(MX,"href","/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(EX,"href","/docs/transformers/pr_17281/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(CX,"href","/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(wX,"href","/docs/transformers/pr_17281/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(AX,"href","/docs/transformers/pr_17281/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(LX,"href","/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(yX,"href","/docs/transformers/pr_17281/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(xX,"href","/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c($X,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(kX,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(SX,"href","/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(RX,"href","/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(PX,"href","/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(BX,"href","/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(IX,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(NX,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(qX,"href","/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(jX,"href","/docs/transformers/pr_17281/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ov,"id","transformers.AutoModelForMultipleChoice"),c(Ov,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ov,"href","#transformers.AutoModelForMultipleChoice"),c(ad,"class","relative group"),c(DX,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(GX,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(OX,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VX,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(XX,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertForMultipleChoice"),c(zX,"href","/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(QX,"href","/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(WX,"href","/docs/transformers/pr_17281/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(HX,"href","/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(UX,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(JX,"href","/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(YX,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(KX,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(ZX,"href","/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(ez,"href","/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(oz,"href","/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(rz,"href","/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(tz,"href","/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(az,"href","/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(nz,"href","/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(sz,"href","/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(lz,"href","/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c(iz,"href","/docs/transformers/pr_17281/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(dz,"href","/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(cz,"href","/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(fz,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(mz,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(gz,"href","/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(hz,"href","/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(pz,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(_z,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(uz,"href","/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(bz,"href","/docs/transformers/pr_17281/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(MF,"id","transformers.AutoModelForNextSentencePrediction"),c(MF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(MF,"href","#transformers.AutoModelForNextSentencePrediction"),c(ld,"class","relative group"),c(vz,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Fz,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Tz,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mz,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(Ez,"href","/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(Cz,"href","/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(wz,"href","/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(Az,"href","/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(Lz,"href","/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SF,"id","transformers.AutoModelForTokenClassification"),c(SF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(SF,"href","#transformers.AutoModelForTokenClassification"),c(cd,"class","relative group"),c(yz,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xz,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($z,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kz,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(Sz,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertForTokenClassification"),c(Rz,"href","/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(Pz,"href","/docs/transformers/pr_17281/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(Bz,"href","/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(Iz,"href","/docs/transformers/pr_17281/en/model_doc/canine#transformers.CanineForTokenClassification"),c(Nz,"href","/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(qz,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(jz,"href","/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(Dz,"href","/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(Gz,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(Oz,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(Vz,"href","/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(Xz,"href","/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(zz,"href","/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(Qz,"href","/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(Wz,"href","/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(Hz,"href","/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(Uz,"href","/docs/transformers/pr_17281/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(Jz,"href","/docs/transformers/pr_17281/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(Yz,"href","/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(Kz,"href","/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(Zz,"href","/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(eQ,"href","/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(oQ,"href","/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c(rQ,"href","/docs/transformers/pr_17281/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(tQ,"href","/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(aQ,"href","/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(nQ,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(sQ,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(lQ,"href","/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(iQ,"href","/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(dQ,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(cQ,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(fQ,"href","/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(mQ,"href","/docs/transformers/pr_17281/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bT,"id","transformers.AutoModelForQuestionAnswering"),c(bT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bT,"href","#transformers.AutoModelForQuestionAnswering"),c(gd,"class","relative group"),c(gQ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hQ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pQ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_Q,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(uQ,"href","/docs/transformers/pr_17281/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(bQ,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(vQ,"href","/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(FQ,"href","/docs/transformers/pr_17281/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(TQ,"href","/docs/transformers/pr_17281/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(MQ,"href","/docs/transformers/pr_17281/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(EQ,"href","/docs/transformers/pr_17281/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(CQ,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(wQ,"href","/docs/transformers/pr_17281/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(AQ,"href","/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(LQ,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(yQ,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(xQ,"href","/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c($Q,"href","/docs/transformers/pr_17281/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(kQ,"href","/docs/transformers/pr_17281/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(SQ,"href","/docs/transformers/pr_17281/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(RQ,"href","/docs/transformers/pr_17281/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(PQ,"href","/docs/transformers/pr_17281/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(BQ,"href","/docs/transformers/pr_17281/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(IQ,"href","/docs/transformers/pr_17281/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(NQ,"href","/docs/transformers/pr_17281/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(qQ,"href","/docs/transformers/pr_17281/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(jQ,"href","/docs/transformers/pr_17281/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(DQ,"href","/docs/transformers/pr_17281/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(GQ,"href","/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(OQ,"href","/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(VQ,"href","/docs/transformers/pr_17281/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),c(XQ,"href","/docs/transformers/pr_17281/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(zQ,"href","/docs/transformers/pr_17281/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(QQ,"href","/docs/transformers/pr_17281/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(WQ,"href","/docs/transformers/pr_17281/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(HQ,"href","/docs/transformers/pr_17281/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(UQ,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(JQ,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(YQ,"href","/docs/transformers/pr_17281/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(KQ,"href","/docs/transformers/pr_17281/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(ZQ,"href","/docs/transformers/pr_17281/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(eW,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(oW,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(rW,"href","/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(tW,"href","/docs/transformers/pr_17281/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(c7,"id","transformers.AutoModelForTableQuestionAnswering"),c(c7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(c7,"href","#transformers.AutoModelForTableQuestionAnswering"),c(_d,"class","relative group"),c(aW,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nW,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sW,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lW,"href","/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(p7,"id","transformers.AutoModelForImageClassification"),c(p7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(p7,"href","#transformers.AutoModelForImageClassification"),c(vd,"class","relative group"),c(iW,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dW,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cW,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fW,"href","/docs/transformers/pr_17281/en/model_doc/beit#transformers.BeitForImageClassification"),c(mW,"href","/docs/transformers/pr_17281/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(gW,"href","/docs/transformers/pr_17281/en/model_doc/cvt#transformers.CvtForImageClassification"),c(hW,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(pW,"href","/docs/transformers/pr_17281/en/model_doc/deit#transformers.DeiTForImageClassification"),c(_W,"href","/docs/transformers/pr_17281/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(uW,"href","/docs/transformers/pr_17281/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(bW,"href","/docs/transformers/pr_17281/en/model_doc/levit#transformers.LevitForImageClassification"),c(vW,"href","/docs/transformers/pr_17281/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(FW,"href","/docs/transformers/pr_17281/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),c(TW,"href","/docs/transformers/pr_17281/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(MW,"href","/docs/transformers/pr_17281/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(EW,"href","/docs/transformers/pr_17281/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(CW,"href","/docs/transformers/pr_17281/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(wW,"href","/docs/transformers/pr_17281/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(AW,"href","/docs/transformers/pr_17281/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(LW,"href","/docs/transformers/pr_17281/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(yW,"href","/docs/transformers/pr_17281/en/model_doc/swin#transformers.SwinForImageClassification"),c(xW,"href","/docs/transformers/pr_17281/en/model_doc/van#transformers.VanForImageClassification"),c($W,"href","/docs/transformers/pr_17281/en/model_doc/vit#transformers.ViTForImageClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(S7,"id","transformers.AutoModelForVision2Seq"),c(S7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(S7,"href","#transformers.AutoModelForVision2Seq"),c(Md,"class","relative group"),c(kW,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(SW,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(RW,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PW,"href","/docs/transformers/pr_17281/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(N7,"id","transformers.AutoModelForVisualQuestionAnswering"),c(N7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N7,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(wd,"class","relative group"),c(BW,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(IW,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(NW,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qW,"href","/docs/transformers/pr_17281/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(O7,"id","transformers.AutoModelForAudioClassification"),c(O7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(O7,"href","#transformers.AutoModelForAudioClassification"),c(yd,"class","relative group"),c(jW,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(DW,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(GW,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OW,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(VW,"href","/docs/transformers/pr_17281/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(XW,"href","/docs/transformers/pr_17281/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(zW,"href","/docs/transformers/pr_17281/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(QW,"href","/docs/transformers/pr_17281/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(WW,"href","/docs/transformers/pr_17281/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(HW,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(UW,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(JW,"href","/docs/transformers/pr_17281/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(o8,"id","transformers.AutoModelForAudioFrameClassification"),c(o8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(o8,"href","#transformers.AutoModelForAudioFrameClassification"),c(kd,"class","relative group"),c(YW,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KW,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ZW,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eH,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(oH,"href","/docs/transformers/pr_17281/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(rH,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(tH,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(aH,"href","/docs/transformers/pr_17281/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(c8,"id","transformers.AutoModelForCTC"),c(c8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(c8,"href","#transformers.AutoModelForCTC"),c(Pd,"class","relative group"),c(nH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iH,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(dH,"href","/docs/transformers/pr_17281/en/model_doc/hubert#transformers.HubertForCTC"),c(cH,"href","/docs/transformers/pr_17281/en/model_doc/mctct#transformers.MCTCTForCTC"),c(fH,"href","/docs/transformers/pr_17281/en/model_doc/sew#transformers.SEWForCTC"),c(mH,"href","/docs/transformers/pr_17281/en/model_doc/sew-d#transformers.SEWDForCTC"),c(gH,"href","/docs/transformers/pr_17281/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(hH,"href","/docs/transformers/pr_17281/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(pH,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(_H,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(uH,"href","/docs/transformers/pr_17281/en/model_doc/wavlm#transformers.WavLMForCTC"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C8,"id","transformers.AutoModelForSpeechSeq2Seq"),c(C8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C8,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Nd,"class","relative group"),c(bH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(FH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TH,"href","/docs/transformers/pr_17281/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(MH,"href","/docs/transformers/pr_17281/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($8,"id","transformers.AutoModelForAudioXVector"),c($8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($8,"href","#transformers.AutoModelForAudioXVector"),c(Dd,"class","relative group"),c(EH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AH,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(LH,"href","/docs/transformers/pr_17281/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(yH,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(xH,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c($H,"href","/docs/transformers/pr_17281/en/model_doc/wavlm#transformers.WavLMForXVector"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(j8,"id","transformers.AutoModelForMaskedImageModeling"),c(j8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(j8,"href","#transformers.AutoModelForMaskedImageModeling"),c(Vd,"class","relative group"),c(kH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(SH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(RH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PH,"href","/docs/transformers/pr_17281/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(BH,"href","/docs/transformers/pr_17281/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(IH,"href","/docs/transformers/pr_17281/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Q8,"id","transformers.AutoModelForObjectDetection"),c(Q8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Q8,"href","#transformers.AutoModelForObjectDetection"),c(Wd,"class","relative group"),c(NH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DH,"href","/docs/transformers/pr_17281/en/model_doc/detr#transformers.DetrForObjectDetection"),c(GH,"href","/docs/transformers/pr_17281/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(K8,"id","transformers.AutoModelForImageSegmentation"),c(K8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(K8,"href","#transformers.AutoModelForImageSegmentation"),c(Jd,"class","relative group"),c(OH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(VH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(XH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zH,"href","/docs/transformers/pr_17281/en/model_doc/detr#transformers.DetrForSegmentation"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tM,"id","transformers.AutoModelForSemanticSegmentation"),c(tM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(tM,"href","#transformers.AutoModelForSemanticSegmentation"),c(Zd,"class","relative group"),c(QH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(WH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(HH,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UH,"href","/docs/transformers/pr_17281/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(JH,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(YH,"href","/docs/transformers/pr_17281/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(KH,"href","/docs/transformers/pr_17281/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),c(ZH,"href","/docs/transformers/pr_17281/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mM,"id","transformers.AutoModelForInstanceSegmentation"),c(mM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mM,"href","#transformers.AutoModelForInstanceSegmentation"),c(rc,"class","relative group"),c(eU,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oU,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rU,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tU,"href","/docs/transformers/pr_17281/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uM,"id","transformers.TFAutoModel"),c(uM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uM,"href","#transformers.TFAutoModel"),c(nc,"class","relative group"),c(aU,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nU,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sU,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lU,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.TFAlbertModel"),c(iU,"href","/docs/transformers/pr_17281/en/model_doc/bart#transformers.TFBartModel"),c(dU,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.TFBertModel"),c(cU,"href","/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(fU,"href","/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(mU,"href","/docs/transformers/pr_17281/en/model_doc/camembert#transformers.TFCamembertModel"),c(gU,"href","/docs/transformers/pr_17281/en/model_doc/clip#transformers.TFCLIPModel"),c(hU,"href","/docs/transformers/pr_17281/en/model_doc/convbert#transformers.TFConvBertModel"),c(pU,"href","/docs/transformers/pr_17281/en/model_doc/convnext#transformers.TFConvNextModel"),c(_U,"href","/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.TFCTRLModel"),c(uU,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(bU,"href","/docs/transformers/pr_17281/en/model_doc/deberta#transformers.TFDebertaModel"),c(vU,"href","/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(FU,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(TU,"href","/docs/transformers/pr_17281/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(MU,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.TFElectraModel"),c(EU,"href","/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(CU,"href","/docs/transformers/pr_17281/en/model_doc/funnel#transformers.TFFunnelModel"),c(wU,"href","/docs/transformers/pr_17281/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(AU,"href","/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.TFGPT2Model"),c(LU,"href","/docs/transformers/pr_17281/en/model_doc/gptj#transformers.TFGPTJModel"),c(yU,"href","/docs/transformers/pr_17281/en/model_doc/hubert#transformers.TFHubertModel"),c(xU,"href","/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c($U,"href","/docs/transformers/pr_17281/en/model_doc/led#transformers.TFLEDModel"),c(kU,"href","/docs/transformers/pr_17281/en/model_doc/longformer#transformers.TFLongformerModel"),c(SU,"href","/docs/transformers/pr_17281/en/model_doc/lxmert#transformers.TFLxmertModel"),c(RU,"href","/docs/transformers/pr_17281/en/model_doc/marian#transformers.TFMarianModel"),c(PU,"href","/docs/transformers/pr_17281/en/model_doc/mbart#transformers.TFMBartModel"),c(BU,"href","/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(IU,"href","/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.TFMPNetModel"),c(NU,"href","/docs/transformers/pr_17281/en/model_doc/mt5#transformers.TFMT5Model"),c(qU,"href","/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(jU,"href","/docs/transformers/pr_17281/en/model_doc/opt#transformers.TFOPTModel"),c(DU,"href","/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.TFPegasusModel"),c(GU,"href","/docs/transformers/pr_17281/en/model_doc/regnet#transformers.TFRegNetModel"),c(OU,"href","/docs/transformers/pr_17281/en/model_doc/rembert#transformers.TFRemBertModel"),c(VU,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.TFRobertaModel"),c(XU,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.TFRoFormerModel"),c(zU,"href","/docs/transformers/pr_17281/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(QU,"href","/docs/transformers/pr_17281/en/model_doc/swin#transformers.TFSwinModel"),c(WU,"href","/docs/transformers/pr_17281/en/model_doc/t5#transformers.TFT5Model"),c(HU,"href","/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TFTapasModel"),c(UU,"href","/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(JU,"href","/docs/transformers/pr_17281/en/model_doc/vit#transformers.TFViTModel"),c(YU,"href","/docs/transformers/pr_17281/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(KU,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(ZU,"href","/docs/transformers/pr_17281/en/model_doc/xlm#transformers.TFXLMModel"),c(eJ,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(oJ,"href","/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.TFXLNetModel"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(g4,"id","transformers.TFAutoModelForPreTraining"),c(g4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(g4,"href","#transformers.TFAutoModelForPreTraining"),c(ic,"class","relative group"),c(rJ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tJ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aJ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nJ,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(sJ,"href","/docs/transformers/pr_17281/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(lJ,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.TFBertForPreTraining"),c(iJ,"href","/docs/transformers/pr_17281/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(dJ,"href","/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(cJ,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(fJ,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(mJ,"href","/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(gJ,"href","/docs/transformers/pr_17281/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(hJ,"href","/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(pJ,"href","/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(_J,"href","/docs/transformers/pr_17281/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(uJ,"href","/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(bJ,"href","/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(vJ,"href","/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(FJ,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(TJ,"href","/docs/transformers/pr_17281/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(MJ,"href","/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(EJ,"href","/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(CJ,"href","/docs/transformers/pr_17281/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(wJ,"href","/docs/transformers/pr_17281/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(AJ,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(LJ,"href","/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(j4,"id","transformers.TFAutoModelForCausalLM"),c(j4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(j4,"href","#transformers.TFAutoModelForCausalLM"),c(fc,"class","relative group"),c(yJ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xJ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($J,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kJ,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(SJ,"href","/docs/transformers/pr_17281/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(RJ,"href","/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(PJ,"href","/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(BJ,"href","/docs/transformers/pr_17281/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(IJ,"href","/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(NJ,"href","/docs/transformers/pr_17281/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(qJ,"href","/docs/transformers/pr_17281/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(jJ,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(DJ,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(GJ,"href","/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(OJ,"href","/docs/transformers/pr_17281/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(VJ,"href","/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oE,"id","transformers.TFAutoModelForImageClassification"),c(oE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oE,"href","#transformers.TFAutoModelForImageClassification"),c(hc,"class","relative group"),c(XJ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zJ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(QJ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WJ,"href","/docs/transformers/pr_17281/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(HJ,"href","/docs/transformers/pr_17281/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(UJ,"href","/docs/transformers/pr_17281/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),c(JJ,"href","/docs/transformers/pr_17281/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(YJ,"href","/docs/transformers/pr_17281/en/model_doc/vit#transformers.TFViTForImageClassification"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dE,"id","transformers.TFAutoModelForMaskedLM"),c(dE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dE,"href","#transformers.TFAutoModelForMaskedLM"),c(uc,"class","relative group"),c(KJ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZJ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eY,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oY,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(rY,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(tY,"href","/docs/transformers/pr_17281/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(aY,"href","/docs/transformers/pr_17281/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(nY,"href","/docs/transformers/pr_17281/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(sY,"href","/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(lY,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(iY,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(dY,"href","/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(cY,"href","/docs/transformers/pr_17281/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(fY,"href","/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(mY,"href","/docs/transformers/pr_17281/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(gY,"href","/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(hY,"href","/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(pY,"href","/docs/transformers/pr_17281/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(_Y,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(uY,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(bY,"href","/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(vY,"href","/docs/transformers/pr_17281/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(FY,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SE,"id","transformers.TFAutoModelForSeq2SeqLM"),c(SE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(SE,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(Fc,"class","relative group"),c(TY,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(MY,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(EY,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CY,"href","/docs/transformers/pr_17281/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(wY,"href","/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(AY,"href","/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(LY,"href","/docs/transformers/pr_17281/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(yY,"href","/docs/transformers/pr_17281/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(xY,"href","/docs/transformers/pr_17281/en/model_doc/marian#transformers.TFMarianMTModel"),c($Y,"href","/docs/transformers/pr_17281/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(kY,"href","/docs/transformers/pr_17281/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(SY,"href","/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(RY,"href","/docs/transformers/pr_17281/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zE,"id","transformers.TFAutoModelForSequenceClassification"),c(zE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zE,"href","#transformers.TFAutoModelForSequenceClassification"),c(Ec,"class","relative group"),c(PY,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BY,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IY,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NY,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(qY,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(jY,"href","/docs/transformers/pr_17281/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(DY,"href","/docs/transformers/pr_17281/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(GY,"href","/docs/transformers/pr_17281/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(OY,"href","/docs/transformers/pr_17281/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(VY,"href","/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(XY,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(zY,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(QY,"href","/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(WY,"href","/docs/transformers/pr_17281/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(HY,"href","/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(UY,"href","/docs/transformers/pr_17281/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(JY,"href","/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(YY,"href","/docs/transformers/pr_17281/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(KY,"href","/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(ZY,"href","/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(eK,"href","/docs/transformers/pr_17281/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(oK,"href","/docs/transformers/pr_17281/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(rK,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(tK,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(aK,"href","/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(nK,"href","/docs/transformers/pr_17281/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(sK,"href","/docs/transformers/pr_17281/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(lK,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(iK,"href","/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FC,"id","transformers.TFAutoModelForMultipleChoice"),c(FC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(FC,"href","#transformers.TFAutoModelForMultipleChoice"),c(Ac,"class","relative group"),c(dK,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(cK,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(fK,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mK,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(gK,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(hK,"href","/docs/transformers/pr_17281/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(pK,"href","/docs/transformers/pr_17281/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(_K,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(uK,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(bK,"href","/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(vK,"href","/docs/transformers/pr_17281/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(FK,"href","/docs/transformers/pr_17281/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(TK,"href","/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(MK,"href","/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(EK,"href","/docs/transformers/pr_17281/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(CK,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(wK,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(AK,"href","/docs/transformers/pr_17281/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(LK,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(yK,"href","/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DC,"id","transformers.TFAutoModelForNextSentencePrediction"),c(DC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DC,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(xc,"class","relative group"),c(xK,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($K,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kK,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SK,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(RK,"href","/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zC,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(zC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zC,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(Sc,"class","relative group"),c(PK,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BK,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IK,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NK,"href","/docs/transformers/pr_17281/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UC,"id","transformers.TFAutoModelForTokenClassification"),c(UC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(UC,"href","#transformers.TFAutoModelForTokenClassification"),c(Bc,"class","relative group"),c(qK,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jK,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DK,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GK,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(OK,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(VK,"href","/docs/transformers/pr_17281/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(XK,"href","/docs/transformers/pr_17281/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(zK,"href","/docs/transformers/pr_17281/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(QK,"href","/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(WK,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(HK,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(UK,"href","/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(JK,"href","/docs/transformers/pr_17281/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(YK,"href","/docs/transformers/pr_17281/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(KK,"href","/docs/transformers/pr_17281/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(ZK,"href","/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(eZ,"href","/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(oZ,"href","/docs/transformers/pr_17281/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(rZ,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(tZ,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(aZ,"href","/docs/transformers/pr_17281/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(nZ,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(sZ,"href","/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(b3,"id","transformers.TFAutoModelForQuestionAnswering"),c(b3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(b3,"href","#transformers.TFAutoModelForQuestionAnswering"),c(qc,"class","relative group"),c(lZ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iZ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dZ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cZ,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(fZ,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(mZ,"href","/docs/transformers/pr_17281/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(gZ,"href","/docs/transformers/pr_17281/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(hZ,"href","/docs/transformers/pr_17281/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(pZ,"href","/docs/transformers/pr_17281/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(_Z,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(uZ,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(bZ,"href","/docs/transformers/pr_17281/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(vZ,"href","/docs/transformers/pr_17281/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(FZ,"href","/docs/transformers/pr_17281/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(TZ,"href","/docs/transformers/pr_17281/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(MZ,"href","/docs/transformers/pr_17281/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(EZ,"href","/docs/transformers/pr_17281/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(CZ,"href","/docs/transformers/pr_17281/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(wZ,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(AZ,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(LZ,"href","/docs/transformers/pr_17281/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(yZ,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(xZ,"href","/docs/transformers/pr_17281/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(G3,"id","transformers.TFAutoModelForVision2Seq"),c(G3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(G3,"href","#transformers.TFAutoModelForVision2Seq"),c(Gc,"class","relative group"),c($Z,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kZ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SZ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RZ,"href","/docs/transformers/pr_17281/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(z3,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(z3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(z3,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(Xc,"class","relative group"),c(PZ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BZ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IZ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NZ,"href","/docs/transformers/pr_17281/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(U3,"id","transformers.FlaxAutoModel"),c(U3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(U3,"href","#transformers.FlaxAutoModel"),c(Wc,"class","relative group"),c(qZ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jZ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DZ,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GZ,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.FlaxAlbertModel"),c(OZ,"href","/docs/transformers/pr_17281/en/model_doc/bart#transformers.FlaxBartModel"),c(VZ,"href","/docs/transformers/pr_17281/en/model_doc/beit#transformers.FlaxBeitModel"),c(XZ,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.FlaxBertModel"),c(zZ,"href","/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(QZ,"href","/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(WZ,"href","/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(HZ,"href","/docs/transformers/pr_17281/en/model_doc/clip#transformers.FlaxCLIPModel"),c(UZ,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(JZ,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.FlaxElectraModel"),c(YZ,"href","/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(KZ,"href","/docs/transformers/pr_17281/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(ZZ,"href","/docs/transformers/pr_17281/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(eee,"href","/docs/transformers/pr_17281/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(oee,"href","/docs/transformers/pr_17281/en/model_doc/marian#transformers.FlaxMarianModel"),c(ree,"href","/docs/transformers/pr_17281/en/model_doc/mbart#transformers.FlaxMBartModel"),c(tee,"href","/docs/transformers/pr_17281/en/model_doc/mt5#transformers.FlaxMT5Model"),c(aee,"href","/docs/transformers/pr_17281/en/model_doc/opt#transformers.FlaxOPTModel"),c(nee,"href","/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(see,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(lee,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(iee,"href","/docs/transformers/pr_17281/en/model_doc/t5#transformers.FlaxT5Model"),c(dee,"href","/docs/transformers/pr_17281/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(cee,"href","/docs/transformers/pr_17281/en/model_doc/vit#transformers.FlaxViTModel"),c(fee,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(mee,"href","/docs/transformers/pr_17281/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(gee,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(w5,"id","transformers.FlaxAutoModelForCausalLM"),c(w5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w5,"href","#transformers.FlaxAutoModelForCausalLM"),c(Jc,"class","relative group"),c(hee,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pee,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_ee,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uee,"href","/docs/transformers/pr_17281/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(bee,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(vee,"href","/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(Fee,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(Tee,"href","/docs/transformers/pr_17281/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(Mee,"href","/docs/transformers/pr_17281/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(Eee,"href","/docs/transformers/pr_17281/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(Cee,"href","/docs/transformers/pr_17281/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(wee,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(Aee,"href","/docs/transformers/pr_17281/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(q5,"id","transformers.FlaxAutoModelForPreTraining"),c(q5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(q5,"href","#transformers.FlaxAutoModelForPreTraining"),c(Zc,"class","relative group"),c(Lee,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yee,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xee,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($ee,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(kee,"href","/docs/transformers/pr_17281/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(See,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(Ree,"href","/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(Pee,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(Bee,"href","/docs/transformers/pr_17281/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(Iee,"href","/docs/transformers/pr_17281/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Nee,"href","/docs/transformers/pr_17281/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(qee,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(jee,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(Dee,"href","/docs/transformers/pr_17281/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Gee,"href","/docs/transformers/pr_17281/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(Oee,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(e0,"id","transformers.FlaxAutoModelForMaskedLM"),c(e0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(e0,"href","#transformers.FlaxAutoModelForMaskedLM"),c(rf,"class","relative group"),c(Vee,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xee,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zee,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qee,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(Wee,"href","/docs/transformers/pr_17281/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(Hee,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(Uee,"href","/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(Jee,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(Yee,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(Kee,"href","/docs/transformers/pr_17281/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Zee,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(eoe,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(ooe,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(g0,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(g0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(g0,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(nf,"class","relative group"),c(roe,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(toe,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aoe,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(noe,"href","/docs/transformers/pr_17281/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(soe,"href","/docs/transformers/pr_17281/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(loe,"href","/docs/transformers/pr_17281/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(ioe,"href","/docs/transformers/pr_17281/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(doe,"href","/docs/transformers/pr_17281/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(coe,"href","/docs/transformers/pr_17281/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(foe,"href","/docs/transformers/pr_17281/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(moe,"href","/docs/transformers/pr_17281/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(goe,"href","/docs/transformers/pr_17281/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(hoe,"href","/docs/transformers/pr_17281/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(A0,"id","transformers.FlaxAutoModelForSequenceClassification"),c(A0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(A0,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(df,"class","relative group"),c(poe,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_oe,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(uoe,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(boe,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(voe,"href","/docs/transformers/pr_17281/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(Foe,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(Toe,"href","/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(Moe,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(Eoe,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(Coe,"href","/docs/transformers/pr_17281/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(woe,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(Aoe,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(Loe,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(j0,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(j0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(j0,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(mf,"class","relative group"),c(yoe,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xoe,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($oe,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(koe,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(Soe,"href","/docs/transformers/pr_17281/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(Roe,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(Poe,"href","/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(Boe,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(Ioe,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(Noe,"href","/docs/transformers/pr_17281/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(qoe,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(joe,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(Doe,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(K0,"id","transformers.FlaxAutoModelForTokenClassification"),c(K0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(K0,"href","#transformers.FlaxAutoModelForTokenClassification"),c(pf,"class","relative group"),c(Goe,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ooe,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Voe,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xoe,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(zoe,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(Qoe,"href","/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(Woe,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(Hoe,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(Uoe,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(Joe,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(Yoe,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dw,"id","transformers.FlaxAutoModelForMultipleChoice"),c(dw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dw,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(bf,"class","relative group"),c(Koe,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zoe,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ere,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ore,"href","/docs/transformers/pr_17281/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(rre,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(tre,"href","/docs/transformers/pr_17281/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(are,"href","/docs/transformers/pr_17281/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(nre,"href","/docs/transformers/pr_17281/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(sre,"href","/docs/transformers/pr_17281/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(lre,"href","/docs/transformers/pr_17281/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(ire,"href","/docs/transformers/pr_17281/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fw,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(Fw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Fw,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(Tf,"class","relative group"),c(dre,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(cre,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(fre,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mre,"href","/docs/transformers/pr_17281/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cw,"id","transformers.FlaxAutoModelForImageClassification"),c(Cw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Cw,"href","#transformers.FlaxAutoModelForImageClassification"),c(Cf,"class","relative group"),c(gre,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hre,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pre,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_re,"href","/docs/transformers/pr_17281/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(ure,"href","/docs/transformers/pr_17281/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xw,"id","transformers.FlaxAutoModelForVision2Seq"),c(xw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xw,"href","#transformers.FlaxAutoModelForVision2Seq"),c(Lf,"class","relative group"),c(bre,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vre,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Fre,"href","/docs/transformers/pr_17281/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tre,"href","/docs/transformers/pr_17281/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,u){e(document.head,g),b(f,v,u),b(f,p,u),e(p,m),e(m,_),M(d,_,null),e(p,h),e(p,Eo),e(Eo,Ai),b(f,Rf,u),b(f,st,u),e(st,Li),e(st,yi),e(yi,Y6),e(st,Pf),b(f,Oe,u),b(f,Qe,u),e(Qe,xi),e(Qe,Rn),e(Rn,K6),e(Qe,Pn),e(Qe,Bn),e(Bn,Z6),e(Qe,$i),e(Qe,In),e(In,eL),e(Qe,ki),b(f,Bf,u),M(ka,f,u),b(f,We,u),b(f,Ae,u),e(Ae,kS),e(Ae,Si),e(Si,SS),e(Ae,RS),b(f,Co,u),b(f,Sa,u),e(Sa,PS),e(Sa,If),e(If,BS),e(Sa,ZWe),b(f,qVe,u),b(f,Ri,u),e(Ri,Nf),e(Nf,_ae),M(oL,_ae,null),e(Ri,eHe),e(Ri,uae),e(uae,oHe),b(f,jVe,u),b(f,Nn,u),e(Nn,rHe),e(Nn,bae),e(bae,tHe),e(Nn,aHe),e(Nn,vae),e(vae,nHe),e(Nn,sHe),b(f,DVe,u),M(rL,f,u),b(f,GVe,u),b(f,IS,u),e(IS,lHe),b(f,OVe,u),M(qf,f,u),b(f,VVe,u),b(f,Pi,u),e(Pi,jf),e(jf,Fae),M(tL,Fae,null),e(Pi,iHe),e(Pi,Tae),e(Tae,dHe),b(f,XVe,u),b(f,wo,u),M(aL,wo,null),e(wo,cHe),e(wo,nL),e(nL,fHe),e(nL,NS),e(NS,mHe),e(nL,gHe),e(wo,hHe),e(wo,sL),e(sL,pHe),e(sL,Mae),e(Mae,_He),e(sL,uHe),e(wo,bHe),e(wo,Ar),M(lL,Ar,null),e(Ar,vHe),e(Ar,Eae),e(Eae,FHe),e(Ar,THe),e(Ar,Bi),e(Bi,MHe),e(Bi,Cae),e(Cae,EHe),e(Bi,CHe),e(Bi,wae),e(wae,wHe),e(Bi,AHe),e(Ar,LHe),e(Ar,A),e(A,Df),e(Df,Aae),e(Aae,yHe),e(Df,xHe),e(Df,qS),e(qS,$He),e(Df,kHe),e(A,SHe),e(A,Gf),e(Gf,Lae),e(Lae,RHe),e(Gf,PHe),e(Gf,jS),e(jS,BHe),e(Gf,IHe),e(A,NHe),e(A,Of),e(Of,yae),e(yae,qHe),e(Of,jHe),e(Of,DS),e(DS,DHe),e(Of,GHe),e(A,OHe),e(A,Vf),e(Vf,xae),e(xae,VHe),e(Vf,XHe),e(Vf,GS),e(GS,zHe),e(Vf,QHe),e(A,WHe),e(A,Xf),e(Xf,$ae),e($ae,HHe),e(Xf,UHe),e(Xf,OS),e(OS,JHe),e(Xf,YHe),e(A,KHe),e(A,zf),e(zf,kae),e(kae,ZHe),e(zf,eUe),e(zf,VS),e(VS,oUe),e(zf,rUe),e(A,tUe),e(A,Qf),e(Qf,Sae),e(Sae,aUe),e(Qf,nUe),e(Qf,XS),e(XS,sUe),e(Qf,lUe),e(A,iUe),e(A,Wf),e(Wf,Rae),e(Rae,dUe),e(Wf,cUe),e(Wf,zS),e(zS,fUe),e(Wf,mUe),e(A,gUe),e(A,Hf),e(Hf,Pae),e(Pae,hUe),e(Hf,pUe),e(Hf,QS),e(QS,_Ue),e(Hf,uUe),e(A,bUe),e(A,Uf),e(Uf,Bae),e(Bae,vUe),e(Uf,FUe),e(Uf,WS),e(WS,TUe),e(Uf,MUe),e(A,EUe),e(A,Jf),e(Jf,Iae),e(Iae,CUe),e(Jf,wUe),e(Jf,HS),e(HS,AUe),e(Jf,LUe),e(A,yUe),e(A,Yf),e(Yf,Nae),e(Nae,xUe),e(Yf,$Ue),e(Yf,US),e(US,kUe),e(Yf,SUe),e(A,RUe),e(A,Kf),e(Kf,qae),e(qae,PUe),e(Kf,BUe),e(Kf,JS),e(JS,IUe),e(Kf,NUe),e(A,qUe),e(A,Zf),e(Zf,jae),e(jae,jUe),e(Zf,DUe),e(Zf,YS),e(YS,GUe),e(Zf,OUe),e(A,VUe),e(A,em),e(em,Dae),e(Dae,XUe),e(em,zUe),e(em,KS),e(KS,QUe),e(em,WUe),e(A,HUe),e(A,om),e(om,Gae),e(Gae,UUe),e(om,JUe),e(om,ZS),e(ZS,YUe),e(om,KUe),e(A,ZUe),e(A,rm),e(rm,Oae),e(Oae,eJe),e(rm,oJe),e(rm,eR),e(eR,rJe),e(rm,tJe),e(A,aJe),e(A,tm),e(tm,Vae),e(Vae,nJe),e(tm,sJe),e(tm,oR),e(oR,lJe),e(tm,iJe),e(A,dJe),e(A,am),e(am,Xae),e(Xae,cJe),e(am,fJe),e(am,rR),e(rR,mJe),e(am,gJe),e(A,hJe),e(A,nm),e(nm,zae),e(zae,pJe),e(nm,_Je),e(nm,tR),e(tR,uJe),e(nm,bJe),e(A,vJe),e(A,sm),e(sm,Qae),e(Qae,FJe),e(sm,TJe),e(sm,aR),e(aR,MJe),e(sm,EJe),e(A,CJe),e(A,lm),e(lm,Wae),e(Wae,wJe),e(lm,AJe),e(lm,nR),e(nR,LJe),e(lm,yJe),e(A,xJe),e(A,im),e(im,Hae),e(Hae,$Je),e(im,kJe),e(im,sR),e(sR,SJe),e(im,RJe),e(A,PJe),e(A,dm),e(dm,Uae),e(Uae,BJe),e(dm,IJe),e(dm,lR),e(lR,NJe),e(dm,qJe),e(A,jJe),e(A,cm),e(cm,Jae),e(Jae,DJe),e(cm,GJe),e(cm,iR),e(iR,OJe),e(cm,VJe),e(A,XJe),e(A,fm),e(fm,Yae),e(Yae,zJe),e(fm,QJe),e(fm,dR),e(dR,WJe),e(fm,HJe),e(A,UJe),e(A,mm),e(mm,Kae),e(Kae,JJe),e(mm,YJe),e(mm,cR),e(cR,KJe),e(mm,ZJe),e(A,eYe),e(A,gm),e(gm,Zae),e(Zae,oYe),e(gm,rYe),e(gm,fR),e(fR,tYe),e(gm,aYe),e(A,nYe),e(A,hm),e(hm,ene),e(ene,sYe),e(hm,lYe),e(hm,mR),e(mR,iYe),e(hm,dYe),e(A,cYe),e(A,pm),e(pm,one),e(one,fYe),e(pm,mYe),e(pm,gR),e(gR,gYe),e(pm,hYe),e(A,pYe),e(A,_m),e(_m,rne),e(rne,_Ye),e(_m,uYe),e(_m,hR),e(hR,bYe),e(_m,vYe),e(A,FYe),e(A,um),e(um,tne),e(tne,TYe),e(um,MYe),e(um,pR),e(pR,EYe),e(um,CYe),e(A,wYe),e(A,bm),e(bm,ane),e(ane,AYe),e(bm,LYe),e(bm,_R),e(_R,yYe),e(bm,xYe),e(A,$Ye),e(A,vm),e(vm,nne),e(nne,kYe),e(vm,SYe),e(vm,uR),e(uR,RYe),e(vm,PYe),e(A,BYe),e(A,Fm),e(Fm,sne),e(sne,IYe),e(Fm,NYe),e(Fm,bR),e(bR,qYe),e(Fm,jYe),e(A,DYe),e(A,Tm),e(Tm,lne),e(lne,GYe),e(Tm,OYe),e(Tm,vR),e(vR,VYe),e(Tm,XYe),e(A,zYe),e(A,Mm),e(Mm,ine),e(ine,QYe),e(Mm,WYe),e(Mm,FR),e(FR,HYe),e(Mm,UYe),e(A,JYe),e(A,Em),e(Em,dne),e(dne,YYe),e(Em,KYe),e(Em,TR),e(TR,ZYe),e(Em,eKe),e(A,oKe),e(A,Cm),e(Cm,cne),e(cne,rKe),e(Cm,tKe),e(Cm,MR),e(MR,aKe),e(Cm,nKe),e(A,sKe),e(A,wm),e(wm,fne),e(fne,lKe),e(wm,iKe),e(wm,ER),e(ER,dKe),e(wm,cKe),e(A,fKe),e(A,Am),e(Am,mne),e(mne,mKe),e(Am,gKe),e(Am,CR),e(CR,hKe),e(Am,pKe),e(A,_Ke),e(A,Lm),e(Lm,gne),e(gne,uKe),e(Lm,bKe),e(Lm,wR),e(wR,vKe),e(Lm,FKe),e(A,TKe),e(A,ym),e(ym,hne),e(hne,MKe),e(ym,EKe),e(ym,AR),e(AR,CKe),e(ym,wKe),e(A,AKe),e(A,xm),e(xm,pne),e(pne,LKe),e(xm,yKe),e(xm,LR),e(LR,xKe),e(xm,$Ke),e(A,kKe),e(A,$m),e($m,_ne),e(_ne,SKe),e($m,RKe),e($m,yR),e(yR,PKe),e($m,BKe),e(A,IKe),e(A,km),e(km,une),e(une,NKe),e(km,qKe),e(km,xR),e(xR,jKe),e(km,DKe),e(A,GKe),e(A,Sm),e(Sm,bne),e(bne,OKe),e(Sm,VKe),e(Sm,$R),e($R,XKe),e(Sm,zKe),e(A,QKe),e(A,Rm),e(Rm,vne),e(vne,WKe),e(Rm,HKe),e(Rm,kR),e(kR,UKe),e(Rm,JKe),e(A,YKe),e(A,Pm),e(Pm,Fne),e(Fne,KKe),e(Pm,ZKe),e(Pm,SR),e(SR,eZe),e(Pm,oZe),e(A,rZe),e(A,Bm),e(Bm,Tne),e(Tne,tZe),e(Bm,aZe),e(Bm,RR),e(RR,nZe),e(Bm,sZe),e(A,lZe),e(A,Im),e(Im,Mne),e(Mne,iZe),e(Im,dZe),e(Im,PR),e(PR,cZe),e(Im,fZe),e(A,mZe),e(A,Nm),e(Nm,Ene),e(Ene,gZe),e(Nm,hZe),e(Nm,BR),e(BR,pZe),e(Nm,_Ze),e(A,uZe),e(A,qm),e(qm,Cne),e(Cne,bZe),e(qm,vZe),e(qm,IR),e(IR,FZe),e(qm,TZe),e(A,MZe),e(A,jm),e(jm,wne),e(wne,EZe),e(jm,CZe),e(jm,NR),e(NR,wZe),e(jm,AZe),e(A,LZe),e(A,Dm),e(Dm,Ane),e(Ane,yZe),e(Dm,xZe),e(Dm,qR),e(qR,$Ze),e(Dm,kZe),e(A,SZe),e(A,Gm),e(Gm,Lne),e(Lne,RZe),e(Gm,PZe),e(Gm,jR),e(jR,BZe),e(Gm,IZe),e(A,NZe),e(A,Om),e(Om,yne),e(yne,qZe),e(Om,jZe),e(Om,DR),e(DR,DZe),e(Om,GZe),e(A,OZe),e(A,Vm),e(Vm,xne),e(xne,VZe),e(Vm,XZe),e(Vm,GR),e(GR,zZe),e(Vm,QZe),e(A,WZe),e(A,Xm),e(Xm,$ne),e($ne,HZe),e(Xm,UZe),e(Xm,OR),e(OR,JZe),e(Xm,YZe),e(A,KZe),e(A,zm),e(zm,kne),e(kne,ZZe),e(zm,eeo),e(zm,VR),e(VR,oeo),e(zm,reo),e(A,teo),e(A,Qm),e(Qm,Sne),e(Sne,aeo),e(Qm,neo),e(Qm,XR),e(XR,seo),e(Qm,leo),e(A,ieo),e(A,Wm),e(Wm,Rne),e(Rne,deo),e(Wm,ceo),e(Wm,zR),e(zR,feo),e(Wm,meo),e(A,geo),e(A,Hm),e(Hm,Pne),e(Pne,heo),e(Hm,peo),e(Hm,QR),e(QR,_eo),e(Hm,ueo),e(A,beo),e(A,Um),e(Um,Bne),e(Bne,veo),e(Um,Feo),e(Um,WR),e(WR,Teo),e(Um,Meo),e(A,Eeo),e(A,Jm),e(Jm,Ine),e(Ine,Ceo),e(Jm,weo),e(Jm,HR),e(HR,Aeo),e(Jm,Leo),e(A,yeo),e(A,Ym),e(Ym,Nne),e(Nne,xeo),e(Ym,$eo),e(Ym,UR),e(UR,keo),e(Ym,Seo),e(A,Reo),e(A,Km),e(Km,qne),e(qne,Peo),e(Km,Beo),e(Km,JR),e(JR,Ieo),e(Km,Neo),e(A,qeo),e(A,Zm),e(Zm,jne),e(jne,jeo),e(Zm,Deo),e(Zm,YR),e(YR,Geo),e(Zm,Oeo),e(A,Veo),e(A,eg),e(eg,Dne),e(Dne,Xeo),e(eg,zeo),e(eg,KR),e(KR,Qeo),e(eg,Weo),e(A,Heo),e(A,og),e(og,Gne),e(Gne,Ueo),e(og,Jeo),e(og,ZR),e(ZR,Yeo),e(og,Keo),e(A,Zeo),e(A,rg),e(rg,One),e(One,eoo),e(rg,ooo),e(rg,eP),e(eP,roo),e(rg,too),e(A,aoo),e(A,tg),e(tg,Vne),e(Vne,noo),e(tg,soo),e(tg,oP),e(oP,loo),e(tg,ioo),e(A,doo),e(A,ag),e(ag,Xne),e(Xne,coo),e(ag,foo),e(ag,rP),e(rP,moo),e(ag,goo),e(A,hoo),e(A,ng),e(ng,zne),e(zne,poo),e(ng,_oo),e(ng,tP),e(tP,uoo),e(ng,boo),e(A,voo),e(A,sg),e(sg,Qne),e(Qne,Foo),e(sg,Too),e(sg,aP),e(aP,Moo),e(sg,Eoo),e(A,Coo),e(A,lg),e(lg,Wne),e(Wne,woo),e(lg,Aoo),e(lg,nP),e(nP,Loo),e(lg,yoo),e(A,xoo),e(A,ig),e(ig,Hne),e(Hne,$oo),e(ig,koo),e(ig,sP),e(sP,Soo),e(ig,Roo),e(A,Poo),e(A,dg),e(dg,Une),e(Une,Boo),e(dg,Ioo),e(dg,lP),e(lP,Noo),e(dg,qoo),e(A,joo),e(A,cg),e(cg,Jne),e(Jne,Doo),e(cg,Goo),e(cg,iP),e(iP,Ooo),e(cg,Voo),e(A,Xoo),e(A,fg),e(fg,Yne),e(Yne,zoo),e(fg,Qoo),e(fg,dP),e(dP,Woo),e(fg,Hoo),e(A,Uoo),e(A,mg),e(mg,Kne),e(Kne,Joo),e(mg,Yoo),e(mg,cP),e(cP,Koo),e(mg,Zoo),e(A,ero),e(A,gg),e(gg,Zne),e(Zne,oro),e(gg,rro),e(gg,fP),e(fP,tro),e(gg,aro),e(A,nro),e(A,hg),e(hg,ese),e(ese,sro),e(hg,lro),e(hg,mP),e(mP,iro),e(hg,dro),e(A,cro),e(A,pg),e(pg,ose),e(ose,fro),e(pg,mro),e(pg,gP),e(gP,gro),e(pg,hro),e(A,pro),e(A,_g),e(_g,rse),e(rse,_ro),e(_g,uro),e(_g,hP),e(hP,bro),e(_g,vro),e(A,Fro),e(A,ug),e(ug,tse),e(tse,Tro),e(ug,Mro),e(ug,pP),e(pP,Ero),e(ug,Cro),e(A,wro),e(A,bg),e(bg,ase),e(ase,Aro),e(bg,Lro),e(bg,_P),e(_P,yro),e(bg,xro),e(A,$ro),e(A,vg),e(vg,nse),e(nse,kro),e(vg,Sro),e(vg,uP),e(uP,Rro),e(vg,Pro),e(A,Bro),e(A,Fg),e(Fg,sse),e(sse,Iro),e(Fg,Nro),e(Fg,bP),e(bP,qro),e(Fg,jro),e(A,Dro),e(A,Tg),e(Tg,lse),e(lse,Gro),e(Tg,Oro),e(Tg,vP),e(vP,Vro),e(Tg,Xro),e(A,zro),e(A,Mg),e(Mg,ise),e(ise,Qro),e(Mg,Wro),e(Mg,FP),e(FP,Hro),e(Mg,Uro),e(A,Jro),e(A,Eg),e(Eg,dse),e(dse,Yro),e(Eg,Kro),e(Eg,TP),e(TP,Zro),e(Eg,eto),e(A,oto),e(A,Cg),e(Cg,cse),e(cse,rto),e(Cg,tto),e(Cg,MP),e(MP,ato),e(Cg,nto),e(A,sto),e(A,wg),e(wg,fse),e(fse,lto),e(wg,ito),e(wg,EP),e(EP,dto),e(wg,cto),e(A,fto),e(A,Ag),e(Ag,mse),e(mse,mto),e(Ag,gto),e(Ag,CP),e(CP,hto),e(Ag,pto),e(A,_to),e(A,Lg),e(Lg,gse),e(gse,uto),e(Lg,bto),e(Lg,wP),e(wP,vto),e(Lg,Fto),e(A,Tto),e(A,yg),e(yg,hse),e(hse,Mto),e(yg,Eto),e(yg,AP),e(AP,Cto),e(yg,wto),e(A,Ato),e(A,xg),e(xg,pse),e(pse,Lto),e(xg,yto),e(xg,LP),e(LP,xto),e(xg,$to),e(A,kto),e(A,$g),e($g,_se),e(_se,Sto),e($g,Rto),e($g,yP),e(yP,Pto),e($g,Bto),e(A,Ito),e(A,kg),e(kg,use),e(use,Nto),e(kg,qto),e(kg,xP),e(xP,jto),e(kg,Dto),e(A,Gto),e(A,Sg),e(Sg,bse),e(bse,Oto),e(Sg,Vto),e(Sg,$P),e($P,Xto),e(Sg,zto),e(A,Qto),e(A,Rg),e(Rg,vse),e(vse,Wto),e(Rg,Hto),e(Rg,kP),e(kP,Uto),e(Rg,Jto),e(A,Yto),e(A,Pg),e(Pg,Fse),e(Fse,Kto),e(Pg,Zto),e(Pg,SP),e(SP,eao),e(Pg,oao),e(A,rao),e(A,Bg),e(Bg,Tse),e(Tse,tao),e(Bg,aao),e(Bg,RP),e(RP,nao),e(Bg,sao),e(A,lao),e(A,Ig),e(Ig,Mse),e(Mse,iao),e(Ig,dao),e(Ig,PP),e(PP,cao),e(Ig,fao),e(A,mao),e(A,Ng),e(Ng,Ese),e(Ese,gao),e(Ng,hao),e(Ng,BP),e(BP,pao),e(Ng,_ao),e(A,uao),e(A,qg),e(qg,Cse),e(Cse,bao),e(qg,vao),e(qg,IP),e(IP,Fao),e(qg,Tao),e(A,Mao),e(A,jg),e(jg,wse),e(wse,Eao),e(jg,Cao),e(jg,NP),e(NP,wao),e(jg,Aao),e(A,Lao),e(A,Dg),e(Dg,Ase),e(Ase,yao),e(Dg,xao),e(Dg,qP),e(qP,$ao),e(Dg,kao),e(A,Sao),e(A,Gg),e(Gg,Lse),e(Lse,Rao),e(Gg,Pao),e(Gg,jP),e(jP,Bao),e(Gg,Iao),e(A,Nao),e(A,Og),e(Og,yse),e(yse,qao),e(Og,jao),e(Og,DP),e(DP,Dao),e(Og,Gao),e(A,Oao),e(A,Vg),e(Vg,xse),e(xse,Vao),e(Vg,Xao),e(Vg,GP),e(GP,zao),e(Vg,Qao),e(A,Wao),e(A,Xg),e(Xg,$se),e($se,Hao),e(Xg,Uao),e(Xg,OP),e(OP,Jao),e(Xg,Yao),e(A,Kao),e(A,zg),e(zg,kse),e(kse,Zao),e(zg,eno),e(zg,VP),e(VP,ono),e(zg,rno),e(A,tno),e(A,Qg),e(Qg,Sse),e(Sse,ano),e(Qg,nno),e(Qg,XP),e(XP,sno),e(Qg,lno),e(A,ino),e(A,Wg),e(Wg,Rse),e(Rse,dno),e(Wg,cno),e(Wg,zP),e(zP,fno),e(Wg,mno),e(A,gno),e(A,Hg),e(Hg,Pse),e(Pse,hno),e(Hg,pno),e(Hg,QP),e(QP,_no),e(Hg,uno),e(A,bno),e(A,Ug),e(Ug,Bse),e(Bse,vno),e(Ug,Fno),e(Ug,WP),e(WP,Tno),e(Ug,Mno),e(A,Eno),e(A,Jg),e(Jg,Ise),e(Ise,Cno),e(Jg,wno),e(Jg,HP),e(HP,Ano),e(Jg,Lno),e(Ar,yno),M(Yg,Ar,null),e(wo,xno),e(wo,Kg),M(iL,Kg,null),e(Kg,$no),e(Kg,Nse),e(Nse,kno),b(f,zVe,u),b(f,Ii,u),e(Ii,Zg),e(Zg,qse),M(dL,qse,null),e(Ii,Sno),e(Ii,jse),e(jse,Rno),b(f,QVe,u),b(f,Ao,u),M(cL,Ao,null),e(Ao,Pno),e(Ao,fL),e(fL,Bno),e(fL,UP),e(UP,Ino),e(fL,Nno),e(Ao,qno),e(Ao,mL),e(mL,jno),e(mL,Dse),e(Dse,Dno),e(mL,Gno),e(Ao,Ono),e(Ao,Lr),M(gL,Lr,null),e(Lr,Vno),e(Lr,Gse),e(Gse,Xno),e(Lr,zno),e(Lr,Ra),e(Ra,Qno),e(Ra,Ose),e(Ose,Wno),e(Ra,Hno),e(Ra,Vse),e(Vse,Uno),e(Ra,Jno),e(Ra,Xse),e(Xse,Yno),e(Ra,Kno),e(Lr,Zno),e(Lr,k),e(k,qn),e(qn,zse),e(zse,eso),e(qn,oso),e(qn,JP),e(JP,rso),e(qn,tso),e(qn,YP),e(YP,aso),e(qn,nso),e(k,sso),e(k,jn),e(jn,Qse),e(Qse,lso),e(jn,iso),e(jn,KP),e(KP,dso),e(jn,cso),e(jn,ZP),e(ZP,fso),e(jn,mso),e(k,gso),e(k,Dn),e(Dn,Wse),e(Wse,hso),e(Dn,pso),e(Dn,eB),e(eB,_so),e(Dn,uso),e(Dn,oB),e(oB,bso),e(Dn,vso),e(k,Fso),e(k,eh),e(eh,Hse),e(Hse,Tso),e(eh,Mso),e(eh,rB),e(rB,Eso),e(eh,Cso),e(k,wso),e(k,Gn),e(Gn,Use),e(Use,Aso),e(Gn,Lso),e(Gn,tB),e(tB,yso),e(Gn,xso),e(Gn,aB),e(aB,$so),e(Gn,kso),e(k,Sso),e(k,oh),e(oh,Jse),e(Jse,Rso),e(oh,Pso),e(oh,nB),e(nB,Bso),e(oh,Iso),e(k,Nso),e(k,rh),e(rh,Yse),e(Yse,qso),e(rh,jso),e(rh,sB),e(sB,Dso),e(rh,Gso),e(k,Oso),e(k,th),e(th,Kse),e(Kse,Vso),e(th,Xso),e(th,lB),e(lB,zso),e(th,Qso),e(k,Wso),e(k,On),e(On,Zse),e(Zse,Hso),e(On,Uso),e(On,iB),e(iB,Jso),e(On,Yso),e(On,dB),e(dB,Kso),e(On,Zso),e(k,elo),e(k,Vn),e(Vn,ele),e(ele,olo),e(Vn,rlo),e(Vn,cB),e(cB,tlo),e(Vn,alo),e(Vn,fB),e(fB,nlo),e(Vn,slo),e(k,llo),e(k,Xn),e(Xn,ole),e(ole,ilo),e(Xn,dlo),e(Xn,mB),e(mB,clo),e(Xn,flo),e(Xn,gB),e(gB,mlo),e(Xn,glo),e(k,hlo),e(k,ah),e(ah,rle),e(rle,plo),e(ah,_lo),e(ah,hB),e(hB,ulo),e(ah,blo),e(k,vlo),e(k,nh),e(nh,tle),e(tle,Flo),e(nh,Tlo),e(nh,pB),e(pB,Mlo),e(nh,Elo),e(k,Clo),e(k,sh),e(sh,ale),e(ale,wlo),e(sh,Alo),e(sh,_B),e(_B,Llo),e(sh,ylo),e(k,xlo),e(k,zn),e(zn,nle),e(nle,$lo),e(zn,klo),e(zn,uB),e(uB,Slo),e(zn,Rlo),e(zn,bB),e(bB,Plo),e(zn,Blo),e(k,Ilo),e(k,lh),e(lh,sle),e(sle,Nlo),e(lh,qlo),e(lh,vB),e(vB,jlo),e(lh,Dlo),e(k,Glo),e(k,Qn),e(Qn,lle),e(lle,Olo),e(Qn,Vlo),e(Qn,FB),e(FB,Xlo),e(Qn,zlo),e(Qn,TB),e(TB,Qlo),e(Qn,Wlo),e(k,Hlo),e(k,Wn),e(Wn,ile),e(ile,Ulo),e(Wn,Jlo),e(Wn,MB),e(MB,Ylo),e(Wn,Klo),e(Wn,EB),e(EB,Zlo),e(Wn,eio),e(k,oio),e(k,Hn),e(Hn,dle),e(dle,rio),e(Hn,tio),e(Hn,CB),e(CB,aio),e(Hn,nio),e(Hn,wB),e(wB,sio),e(Hn,lio),e(k,iio),e(k,Un),e(Un,cle),e(cle,dio),e(Un,cio),e(Un,AB),e(AB,fio),e(Un,mio),e(Un,LB),e(LB,gio),e(Un,hio),e(k,pio),e(k,ih),e(ih,fle),e(fle,_io),e(ih,uio),e(ih,yB),e(yB,bio),e(ih,vio),e(k,Fio),e(k,Jn),e(Jn,mle),e(mle,Tio),e(Jn,Mio),e(Jn,xB),e(xB,Eio),e(Jn,Cio),e(Jn,$B),e($B,wio),e(Jn,Aio),e(k,Lio),e(k,Yn),e(Yn,gle),e(gle,yio),e(Yn,xio),e(Yn,kB),e(kB,$io),e(Yn,kio),e(Yn,SB),e(SB,Sio),e(Yn,Rio),e(k,Pio),e(k,Kn),e(Kn,hle),e(hle,Bio),e(Kn,Iio),e(Kn,RB),e(RB,Nio),e(Kn,qio),e(Kn,PB),e(PB,jio),e(Kn,Dio),e(k,Gio),e(k,Zn),e(Zn,ple),e(ple,Oio),e(Zn,Vio),e(Zn,BB),e(BB,Xio),e(Zn,zio),e(Zn,IB),e(IB,Qio),e(Zn,Wio),e(k,Hio),e(k,es),e(es,_le),e(_le,Uio),e(es,Jio),e(es,NB),e(NB,Yio),e(es,Kio),e(es,qB),e(qB,Zio),e(es,edo),e(k,odo),e(k,os),e(os,ule),e(ule,rdo),e(os,tdo),e(os,jB),e(jB,ado),e(os,ndo),e(os,DB),e(DB,sdo),e(os,ldo),e(k,ido),e(k,dh),e(dh,ble),e(ble,ddo),e(dh,cdo),e(dh,GB),e(GB,fdo),e(dh,mdo),e(k,gdo),e(k,rs),e(rs,vle),e(vle,hdo),e(rs,pdo),e(rs,OB),e(OB,_do),e(rs,udo),e(rs,VB),e(VB,bdo),e(rs,vdo),e(k,Fdo),e(k,ch),e(ch,Fle),e(Fle,Tdo),e(ch,Mdo),e(ch,XB),e(XB,Edo),e(ch,Cdo),e(k,wdo),e(k,ts),e(ts,Tle),e(Tle,Ado),e(ts,Ldo),e(ts,zB),e(zB,ydo),e(ts,xdo),e(ts,QB),e(QB,$do),e(ts,kdo),e(k,Sdo),e(k,as),e(as,Mle),e(Mle,Rdo),e(as,Pdo),e(as,WB),e(WB,Bdo),e(as,Ido),e(as,HB),e(HB,Ndo),e(as,qdo),e(k,jdo),e(k,ns),e(ns,Ele),e(Ele,Ddo),e(ns,Gdo),e(ns,UB),e(UB,Odo),e(ns,Vdo),e(ns,JB),e(JB,Xdo),e(ns,zdo),e(k,Qdo),e(k,fh),e(fh,Cle),e(Cle,Wdo),e(fh,Hdo),e(fh,YB),e(YB,Udo),e(fh,Jdo),e(k,Ydo),e(k,ss),e(ss,wle),e(wle,Kdo),e(ss,Zdo),e(ss,KB),e(KB,eco),e(ss,oco),e(ss,ZB),e(ZB,rco),e(ss,tco),e(k,aco),e(k,ls),e(ls,Ale),e(Ale,nco),e(ls,sco),e(ls,eI),e(eI,lco),e(ls,ico),e(ls,oI),e(oI,dco),e(ls,cco),e(k,fco),e(k,is),e(is,Lle),e(Lle,mco),e(is,gco),e(is,rI),e(rI,hco),e(is,pco),e(is,tI),e(tI,_co),e(is,uco),e(k,bco),e(k,mh),e(mh,yle),e(yle,vco),e(mh,Fco),e(mh,aI),e(aI,Tco),e(mh,Mco),e(k,Eco),e(k,ds),e(ds,xle),e(xle,Cco),e(ds,wco),e(ds,nI),e(nI,Aco),e(ds,Lco),e(ds,sI),e(sI,yco),e(ds,xco),e(k,$co),e(k,cs),e(cs,$le),e($le,kco),e(cs,Sco),e(cs,lI),e(lI,Rco),e(cs,Pco),e(cs,iI),e(iI,Bco),e(cs,Ico),e(k,Nco),e(k,fs),e(fs,kle),e(kle,qco),e(fs,jco),e(fs,dI),e(dI,Dco),e(fs,Gco),e(fs,cI),e(cI,Oco),e(fs,Vco),e(k,Xco),e(k,ms),e(ms,Sle),e(Sle,zco),e(ms,Qco),e(ms,fI),e(fI,Wco),e(ms,Hco),e(ms,mI),e(mI,Uco),e(ms,Jco),e(k,Yco),e(k,gs),e(gs,Rle),e(Rle,Kco),e(gs,Zco),e(gs,gI),e(gI,efo),e(gs,ofo),e(gs,hI),e(hI,rfo),e(gs,tfo),e(k,afo),e(k,hs),e(hs,Ple),e(Ple,nfo),e(hs,sfo),e(hs,pI),e(pI,lfo),e(hs,ifo),e(hs,_I),e(_I,dfo),e(hs,cfo),e(k,ffo),e(k,ps),e(ps,Ble),e(Ble,mfo),e(ps,gfo),e(ps,uI),e(uI,hfo),e(ps,pfo),e(ps,bI),e(bI,_fo),e(ps,ufo),e(k,bfo),e(k,_s),e(_s,Ile),e(Ile,vfo),e(_s,Ffo),e(_s,vI),e(vI,Tfo),e(_s,Mfo),e(_s,FI),e(FI,Efo),e(_s,Cfo),e(k,wfo),e(k,gh),e(gh,Nle),e(Nle,Afo),e(gh,Lfo),e(gh,TI),e(TI,yfo),e(gh,xfo),e(k,$fo),e(k,us),e(us,qle),e(qle,kfo),e(us,Sfo),e(us,MI),e(MI,Rfo),e(us,Pfo),e(us,EI),e(EI,Bfo),e(us,Ifo),e(k,Nfo),e(k,hh),e(hh,jle),e(jle,qfo),e(hh,jfo),e(hh,CI),e(CI,Dfo),e(hh,Gfo),e(k,Ofo),e(k,ph),e(ph,Dle),e(Dle,Vfo),e(ph,Xfo),e(ph,wI),e(wI,zfo),e(ph,Qfo),e(k,Wfo),e(k,bs),e(bs,Gle),e(Gle,Hfo),e(bs,Ufo),e(bs,AI),e(AI,Jfo),e(bs,Yfo),e(bs,LI),e(LI,Kfo),e(bs,Zfo),e(k,emo),e(k,vs),e(vs,Ole),e(Ole,omo),e(vs,rmo),e(vs,yI),e(yI,tmo),e(vs,amo),e(vs,xI),e(xI,nmo),e(vs,smo),e(k,lmo),e(k,Fs),e(Fs,Vle),e(Vle,imo),e(Fs,dmo),e(Fs,$I),e($I,cmo),e(Fs,fmo),e(Fs,kI),e(kI,mmo),e(Fs,gmo),e(k,hmo),e(k,_h),e(_h,Xle),e(Xle,pmo),e(_h,_mo),e(_h,SI),e(SI,umo),e(_h,bmo),e(k,vmo),e(k,Ts),e(Ts,zle),e(zle,Fmo),e(Ts,Tmo),e(Ts,RI),e(RI,Mmo),e(Ts,Emo),e(Ts,PI),e(PI,Cmo),e(Ts,wmo),e(k,Amo),e(k,Ms),e(Ms,Qle),e(Qle,Lmo),e(Ms,ymo),e(Ms,BI),e(BI,xmo),e(Ms,$mo),e(Ms,II),e(II,kmo),e(Ms,Smo),e(k,Rmo),e(k,Es),e(Es,Wle),e(Wle,Pmo),e(Es,Bmo),e(Es,NI),e(NI,Imo),e(Es,Nmo),e(Es,qI),e(qI,qmo),e(Es,jmo),e(k,Dmo),e(k,Cs),e(Cs,Hle),e(Hle,Gmo),e(Cs,Omo),e(Cs,jI),e(jI,Vmo),e(Cs,Xmo),e(Cs,DI),e(DI,zmo),e(Cs,Qmo),e(k,Wmo),e(k,ws),e(ws,Ule),e(Ule,Hmo),e(ws,Umo),e(ws,GI),e(GI,Jmo),e(ws,Ymo),e(ws,OI),e(OI,Kmo),e(ws,Zmo),e(k,ego),e(k,As),e(As,Jle),e(Jle,ogo),e(As,rgo),e(As,VI),e(VI,tgo),e(As,ago),e(As,XI),e(XI,ngo),e(As,sgo),e(k,lgo),e(k,Ls),e(Ls,Yle),e(Yle,igo),e(Ls,dgo),e(Ls,zI),e(zI,cgo),e(Ls,fgo),e(Ls,QI),e(QI,mgo),e(Ls,ggo),e(k,hgo),e(k,uh),e(uh,Kle),e(Kle,pgo),e(uh,_go),e(uh,WI),e(WI,ugo),e(uh,bgo),e(k,vgo),e(k,ys),e(ys,Zle),e(Zle,Fgo),e(ys,Tgo),e(ys,HI),e(HI,Mgo),e(ys,Ego),e(ys,UI),e(UI,Cgo),e(ys,wgo),e(k,Ago),e(k,bh),e(bh,eie),e(eie,Lgo),e(bh,ygo),e(bh,JI),e(JI,xgo),e(bh,$go),e(k,kgo),e(k,vh),e(vh,oie),e(oie,Sgo),e(vh,Rgo),e(vh,YI),e(YI,Pgo),e(vh,Bgo),e(k,Igo),e(k,Fh),e(Fh,rie),e(rie,Ngo),e(Fh,qgo),e(Fh,KI),e(KI,jgo),e(Fh,Dgo),e(k,Ggo),e(k,Th),e(Th,tie),e(tie,Ogo),e(Th,Vgo),e(Th,ZI),e(ZI,Xgo),e(Th,zgo),e(k,Qgo),e(k,xs),e(xs,aie),e(aie,Wgo),e(xs,Hgo),e(xs,eN),e(eN,Ugo),e(xs,Jgo),e(xs,oN),e(oN,Ygo),e(xs,Kgo),e(k,Zgo),e(k,Mh),e(Mh,nie),e(nie,eho),e(Mh,oho),e(Mh,rN),e(rN,rho),e(Mh,tho),e(k,aho),e(k,$s),e($s,sie),e(sie,nho),e($s,sho),e($s,tN),e(tN,lho),e($s,iho),e($s,aN),e(aN,dho),e($s,cho),e(k,fho),e(k,ks),e(ks,lie),e(lie,mho),e(ks,gho),e(ks,nN),e(nN,hho),e(ks,pho),e(ks,sN),e(sN,_ho),e(ks,uho),e(k,bho),e(k,Ss),e(Ss,iie),e(iie,vho),e(Ss,Fho),e(Ss,lN),e(lN,Tho),e(Ss,Mho),e(Ss,iN),e(iN,Eho),e(Ss,Cho),e(k,who),e(k,Rs),e(Rs,die),e(die,Aho),e(Rs,Lho),e(Rs,dN),e(dN,yho),e(Rs,xho),e(Rs,cN),e(cN,$ho),e(Rs,kho),e(k,Sho),e(k,Ps),e(Ps,cie),e(cie,Rho),e(Ps,Pho),e(Ps,fN),e(fN,Bho),e(Ps,Iho),e(Ps,mN),e(mN,Nho),e(Ps,qho),e(k,jho),e(k,Bs),e(Bs,fie),e(fie,Dho),e(Bs,Gho),e(Bs,gN),e(gN,Oho),e(Bs,Vho),e(Bs,hN),e(hN,Xho),e(Bs,zho),e(k,Qho),e(k,Eh),e(Eh,mie),e(mie,Who),e(Eh,Hho),e(Eh,pN),e(pN,Uho),e(Eh,Jho),e(k,Yho),e(k,Ch),e(Ch,gie),e(gie,Kho),e(Ch,Zho),e(Ch,_N),e(_N,epo),e(Ch,opo),e(k,rpo),e(k,Is),e(Is,hie),e(hie,tpo),e(Is,apo),e(Is,uN),e(uN,npo),e(Is,spo),e(Is,bN),e(bN,lpo),e(Is,ipo),e(k,dpo),e(k,Ns),e(Ns,pie),e(pie,cpo),e(Ns,fpo),e(Ns,vN),e(vN,mpo),e(Ns,gpo),e(Ns,FN),e(FN,hpo),e(Ns,ppo),e(k,_po),e(k,qs),e(qs,_ie),e(_ie,upo),e(qs,bpo),e(qs,TN),e(TN,vpo),e(qs,Fpo),e(qs,MN),e(MN,Tpo),e(qs,Mpo),e(k,Epo),e(k,wh),e(wh,uie),e(uie,Cpo),e(wh,wpo),e(wh,EN),e(EN,Apo),e(wh,Lpo),e(k,ypo),e(k,Ah),e(Ah,bie),e(bie,xpo),e(Ah,$po),e(Ah,CN),e(CN,kpo),e(Ah,Spo),e(k,Rpo),e(k,Lh),e(Lh,vie),e(vie,Ppo),e(Lh,Bpo),e(Lh,wN),e(wN,Ipo),e(Lh,Npo),e(k,qpo),e(k,js),e(js,Fie),e(Fie,jpo),e(js,Dpo),e(js,AN),e(AN,Gpo),e(js,Opo),e(js,LN),e(LN,Vpo),e(js,Xpo),e(k,zpo),e(k,Ds),e(Ds,Tie),e(Tie,Qpo),e(Ds,Wpo),e(Ds,yN),e(yN,Hpo),e(Ds,Upo),e(Ds,xN),e(xN,Jpo),e(Ds,Ypo),e(k,Kpo),e(k,yh),e(yh,Mie),e(Mie,Zpo),e(yh,e_o),e(yh,$N),e($N,o_o),e(yh,r_o),e(k,t_o),e(k,xh),e(xh,Eie),e(Eie,a_o),e(xh,n_o),e(xh,kN),e(kN,s_o),e(xh,l_o),e(k,i_o),e(k,$h),e($h,Cie),e(Cie,d_o),e($h,c_o),e($h,SN),e(SN,f_o),e($h,m_o),e(k,g_o),e(k,Gs),e(Gs,wie),e(wie,h_o),e(Gs,p_o),e(Gs,RN),e(RN,__o),e(Gs,u_o),e(Gs,PN),e(PN,b_o),e(Gs,v_o),e(k,F_o),e(k,kh),e(kh,Aie),e(Aie,T_o),e(kh,M_o),e(kh,BN),e(BN,E_o),e(kh,C_o),e(k,w_o),e(k,Sh),e(Sh,Lie),e(Lie,A_o),e(Sh,L_o),e(Sh,IN),e(IN,y_o),e(Sh,x_o),e(k,$_o),e(k,Os),e(Os,yie),e(yie,k_o),e(Os,S_o),e(Os,NN),e(NN,R_o),e(Os,P_o),e(Os,qN),e(qN,B_o),e(Os,I_o),e(k,N_o),e(k,Vs),e(Vs,xie),e(xie,q_o),e(Vs,j_o),e(Vs,jN),e(jN,D_o),e(Vs,G_o),e(Vs,DN),e(DN,O_o),e(Vs,V_o),e(k,X_o),e(k,Xs),e(Xs,$ie),e($ie,z_o),e(Xs,Q_o),e(Xs,GN),e(GN,W_o),e(Xs,H_o),e(Xs,ON),e(ON,U_o),e(Xs,J_o),e(k,Y_o),e(k,zs),e(zs,kie),e(kie,K_o),e(zs,Z_o),e(zs,VN),e(VN,euo),e(zs,ouo),e(zs,XN),e(XN,ruo),e(zs,tuo),e(Lr,auo),M(Rh,Lr,null),e(Ao,nuo),e(Ao,Ph),M(hL,Ph,null),e(Ph,suo),e(Ph,Sie),e(Sie,luo),b(f,WVe,u),b(f,Ni,u),e(Ni,Bh),e(Bh,Rie),M(pL,Rie,null),e(Ni,iuo),e(Ni,Pie),e(Pie,duo),b(f,HVe,u),b(f,Lo,u),M(_L,Lo,null),e(Lo,cuo),e(Lo,uL),e(uL,fuo),e(uL,zN),e(zN,muo),e(uL,guo),e(Lo,huo),e(Lo,bL),e(bL,puo),e(bL,Bie),e(Bie,_uo),e(bL,uuo),e(Lo,buo),e(Lo,He),M(vL,He,null),e(He,vuo),e(He,Iie),e(Iie,Fuo),e(He,Tuo),e(He,Pa),e(Pa,Muo),e(Pa,Nie),e(Nie,Euo),e(Pa,Cuo),e(Pa,qie),e(qie,wuo),e(Pa,Auo),e(Pa,jie),e(jie,Luo),e(Pa,yuo),e(He,xuo),e(He,Y),e(Y,Ih),e(Ih,Die),e(Die,$uo),e(Ih,kuo),e(Ih,QN),e(QN,Suo),e(Ih,Ruo),e(Y,Puo),e(Y,Nh),e(Nh,Gie),e(Gie,Buo),e(Nh,Iuo),e(Nh,WN),e(WN,Nuo),e(Nh,quo),e(Y,juo),e(Y,qh),e(qh,Oie),e(Oie,Duo),e(qh,Guo),e(qh,HN),e(HN,Ouo),e(qh,Vuo),e(Y,Xuo),e(Y,jh),e(jh,Vie),e(Vie,zuo),e(jh,Quo),e(jh,UN),e(UN,Wuo),e(jh,Huo),e(Y,Uuo),e(Y,Dh),e(Dh,Xie),e(Xie,Juo),e(Dh,Yuo),e(Dh,JN),e(JN,Kuo),e(Dh,Zuo),e(Y,e1o),e(Y,Gh),e(Gh,zie),e(zie,o1o),e(Gh,r1o),e(Gh,YN),e(YN,t1o),e(Gh,a1o),e(Y,n1o),e(Y,Oh),e(Oh,Qie),e(Qie,s1o),e(Oh,l1o),e(Oh,KN),e(KN,i1o),e(Oh,d1o),e(Y,c1o),e(Y,Vh),e(Vh,Wie),e(Wie,f1o),e(Vh,m1o),e(Vh,ZN),e(ZN,g1o),e(Vh,h1o),e(Y,p1o),e(Y,Xh),e(Xh,Hie),e(Hie,_1o),e(Xh,u1o),e(Xh,eq),e(eq,b1o),e(Xh,v1o),e(Y,F1o),e(Y,zh),e(zh,Uie),e(Uie,T1o),e(zh,M1o),e(zh,oq),e(oq,E1o),e(zh,C1o),e(Y,w1o),e(Y,Qh),e(Qh,Jie),e(Jie,A1o),e(Qh,L1o),e(Qh,rq),e(rq,y1o),e(Qh,x1o),e(Y,$1o),e(Y,Wh),e(Wh,Yie),e(Yie,k1o),e(Wh,S1o),e(Wh,tq),e(tq,R1o),e(Wh,P1o),e(Y,B1o),e(Y,Hh),e(Hh,Kie),e(Kie,I1o),e(Hh,N1o),e(Hh,aq),e(aq,q1o),e(Hh,j1o),e(Y,D1o),e(Y,Uh),e(Uh,Zie),e(Zie,G1o),e(Uh,O1o),e(Uh,nq),e(nq,V1o),e(Uh,X1o),e(Y,z1o),e(Y,Jh),e(Jh,ede),e(ede,Q1o),e(Jh,W1o),e(Jh,sq),e(sq,H1o),e(Jh,U1o),e(Y,J1o),e(Y,Yh),e(Yh,ode),e(ode,Y1o),e(Yh,K1o),e(Yh,lq),e(lq,Z1o),e(Yh,e2o),e(Y,o2o),e(Y,Kh),e(Kh,rde),e(rde,r2o),e(Kh,t2o),e(Kh,iq),e(iq,a2o),e(Kh,n2o),e(Y,s2o),e(Y,Zh),e(Zh,tde),e(tde,l2o),e(Zh,i2o),e(Zh,dq),e(dq,d2o),e(Zh,c2o),e(Y,f2o),e(Y,ep),e(ep,ade),e(ade,m2o),e(ep,g2o),e(ep,cq),e(cq,h2o),e(ep,p2o),e(Y,_2o),e(Y,op),e(op,nde),e(nde,u2o),e(op,b2o),e(op,fq),e(fq,v2o),e(op,F2o),e(Y,T2o),e(Y,rp),e(rp,sde),e(sde,M2o),e(rp,E2o),e(rp,mq),e(mq,C2o),e(rp,w2o),e(Y,A2o),e(Y,tp),e(tp,lde),e(lde,L2o),e(tp,y2o),e(tp,gq),e(gq,x2o),e(tp,$2o),e(Y,k2o),e(Y,ap),e(ap,ide),e(ide,S2o),e(ap,R2o),e(ap,hq),e(hq,P2o),e(ap,B2o),e(Y,I2o),e(Y,np),e(np,dde),e(dde,N2o),e(np,q2o),e(np,pq),e(pq,j2o),e(np,D2o),e(Y,G2o),e(Y,sp),e(sp,cde),e(cde,O2o),e(sp,V2o),e(sp,_q),e(_q,X2o),e(sp,z2o),e(Y,Q2o),e(Y,lp),e(lp,fde),e(fde,W2o),e(lp,H2o),e(lp,uq),e(uq,U2o),e(lp,J2o),e(Y,Y2o),e(Y,ip),e(ip,mde),e(mde,K2o),e(ip,Z2o),e(ip,bq),e(bq,ebo),e(ip,obo),e(Y,rbo),e(Y,dp),e(dp,gde),e(gde,tbo),e(dp,abo),e(dp,vq),e(vq,nbo),e(dp,sbo),e(Y,lbo),e(Y,cp),e(cp,hde),e(hde,ibo),e(cp,dbo),e(cp,Fq),e(Fq,cbo),e(cp,fbo),e(Y,mbo),e(Y,fp),e(fp,pde),e(pde,gbo),e(fp,hbo),e(fp,Tq),e(Tq,pbo),e(fp,_bo),e(Y,ubo),e(Y,mp),e(mp,_de),e(_de,bbo),e(mp,vbo),e(mp,Mq),e(Mq,Fbo),e(mp,Tbo),e(Y,Mbo),e(Y,gp),e(gp,ude),e(ude,Ebo),e(gp,Cbo),e(gp,Eq),e(Eq,wbo),e(gp,Abo),e(Y,Lbo),e(Y,hp),e(hp,bde),e(bde,ybo),e(hp,xbo),e(hp,Cq),e(Cq,$bo),e(hp,kbo),e(Y,Sbo),e(Y,pp),e(pp,vde),e(vde,Rbo),e(pp,Pbo),e(pp,wq),e(wq,Bbo),e(pp,Ibo),e(He,Nbo),M(_p,He,null),e(He,qbo),M(up,He,null),e(Lo,jbo),e(Lo,bp),M(FL,bp,null),e(bp,Dbo),e(bp,Fde),e(Fde,Gbo),b(f,UVe,u),b(f,qi,u),e(qi,vp),e(vp,Tde),M(TL,Tde,null),e(qi,Obo),e(qi,Mde),e(Mde,Vbo),b(f,JVe,u),b(f,yo,u),M(ML,yo,null),e(yo,Xbo),e(yo,EL),e(EL,zbo),e(EL,Aq),e(Aq,Qbo),e(EL,Wbo),e(yo,Hbo),e(yo,CL),e(CL,Ubo),e(CL,Ede),e(Ede,Jbo),e(CL,Ybo),e(yo,Kbo),e(yo,Ue),M(wL,Ue,null),e(Ue,Zbo),e(Ue,Cde),e(Cde,evo),e(Ue,ovo),e(Ue,ji),e(ji,rvo),e(ji,wde),e(wde,tvo),e(ji,avo),e(ji,Ade),e(Ade,nvo),e(ji,svo),e(Ue,lvo),e(Ue,he),e(he,Fp),e(Fp,Lde),e(Lde,ivo),e(Fp,dvo),e(Fp,Lq),e(Lq,cvo),e(Fp,fvo),e(he,mvo),e(he,Tp),e(Tp,yde),e(yde,gvo),e(Tp,hvo),e(Tp,xde),e(xde,pvo),e(Tp,_vo),e(he,uvo),e(he,Mp),e(Mp,$de),e($de,bvo),e(Mp,vvo),e(Mp,yq),e(yq,Fvo),e(Mp,Tvo),e(he,Mvo),e(he,Ep),e(Ep,kde),e(kde,Evo),e(Ep,Cvo),e(Ep,xq),e(xq,wvo),e(Ep,Avo),e(he,Lvo),e(he,Cp),e(Cp,Sde),e(Sde,yvo),e(Cp,xvo),e(Cp,$q),e($q,$vo),e(Cp,kvo),e(he,Svo),e(he,wp),e(wp,Rde),e(Rde,Rvo),e(wp,Pvo),e(wp,kq),e(kq,Bvo),e(wp,Ivo),e(he,Nvo),e(he,Ap),e(Ap,Pde),e(Pde,qvo),e(Ap,jvo),e(Ap,Sq),e(Sq,Dvo),e(Ap,Gvo),e(he,Ovo),e(he,Lp),e(Lp,Bde),e(Bde,Vvo),e(Lp,Xvo),e(Lp,Rq),e(Rq,zvo),e(Lp,Qvo),e(he,Wvo),e(he,yp),e(yp,Ide),e(Ide,Hvo),e(yp,Uvo),e(yp,Pq),e(Pq,Jvo),e(yp,Yvo),e(he,Kvo),e(he,xp),e(xp,Nde),e(Nde,Zvo),e(xp,eFo),e(xp,Bq),e(Bq,oFo),e(xp,rFo),e(he,tFo),e(he,$p),e($p,qde),e(qde,aFo),e($p,nFo),e($p,Iq),e(Iq,sFo),e($p,lFo),e(he,iFo),e(he,kp),e(kp,jde),e(jde,dFo),e(kp,cFo),e(kp,Nq),e(Nq,fFo),e(kp,mFo),e(he,gFo),e(he,Sp),e(Sp,Dde),e(Dde,hFo),e(Sp,pFo),e(Sp,qq),e(qq,_Fo),e(Sp,uFo),e(he,bFo),e(he,Rp),e(Rp,Gde),e(Gde,vFo),e(Rp,FFo),e(Rp,jq),e(jq,TFo),e(Rp,MFo),e(he,EFo),e(he,Pp),e(Pp,Ode),e(Ode,CFo),e(Pp,wFo),e(Pp,Dq),e(Dq,AFo),e(Pp,LFo),e(he,yFo),e(he,Bp),e(Bp,Vde),e(Vde,xFo),e(Bp,$Fo),e(Bp,Gq),e(Gq,kFo),e(Bp,SFo),e(he,RFo),e(he,Ip),e(Ip,Xde),e(Xde,PFo),e(Ip,BFo),e(Ip,Oq),e(Oq,IFo),e(Ip,NFo),e(he,qFo),e(he,Np),e(Np,zde),e(zde,jFo),e(Np,DFo),e(Np,Vq),e(Vq,GFo),e(Np,OFo),e(Ue,VFo),M(qp,Ue,null),e(Ue,XFo),M(jp,Ue,null),e(yo,zFo),e(yo,Dp),M(AL,Dp,null),e(Dp,QFo),e(Dp,Qde),e(Qde,WFo),b(f,YVe,u),b(f,Di,u),e(Di,Gp),e(Gp,Wde),M(LL,Wde,null),e(Di,HFo),e(Di,Hde),e(Hde,UFo),b(f,KVe,u),b(f,xo,u),M(yL,xo,null),e(xo,JFo),e(xo,Gi),e(Gi,YFo),e(Gi,Xq),e(Xq,KFo),e(Gi,ZFo),e(Gi,zq),e(zq,eTo),e(Gi,oTo),e(xo,rTo),e(xo,xL),e(xL,tTo),e(xL,Ude),e(Ude,aTo),e(xL,nTo),e(xo,sTo),e(xo,lt),M($L,lt,null),e(lt,lTo),e(lt,Jde),e(Jde,iTo),e(lt,dTo),e(lt,Oi),e(Oi,cTo),e(Oi,Yde),e(Yde,fTo),e(Oi,mTo),e(Oi,Qq),e(Qq,gTo),e(Oi,hTo),e(lt,pTo),M(Op,lt,null),e(xo,_To),e(xo,Je),M(kL,Je,null),e(Je,uTo),e(Je,Kde),e(Kde,bTo),e(Je,vTo),e(Je,Ba),e(Ba,FTo),e(Ba,Zde),e(Zde,TTo),e(Ba,MTo),e(Ba,ece),e(ece,ETo),e(Ba,CTo),e(Ba,oce),e(oce,wTo),e(Ba,ATo),e(Je,LTo),e(Je,y),e(y,Vp),e(Vp,rce),e(rce,yTo),e(Vp,xTo),e(Vp,Wq),e(Wq,$To),e(Vp,kTo),e(y,STo),e(y,Xp),e(Xp,tce),e(tce,RTo),e(Xp,PTo),e(Xp,Hq),e(Hq,BTo),e(Xp,ITo),e(y,NTo),e(y,zp),e(zp,ace),e(ace,qTo),e(zp,jTo),e(zp,Uq),e(Uq,DTo),e(zp,GTo),e(y,OTo),e(y,Qp),e(Qp,nce),e(nce,VTo),e(Qp,XTo),e(Qp,Jq),e(Jq,zTo),e(Qp,QTo),e(y,WTo),e(y,Wp),e(Wp,sce),e(sce,HTo),e(Wp,UTo),e(Wp,Yq),e(Yq,JTo),e(Wp,YTo),e(y,KTo),e(y,Hp),e(Hp,lce),e(lce,ZTo),e(Hp,e7o),e(Hp,Kq),e(Kq,o7o),e(Hp,r7o),e(y,t7o),e(y,Up),e(Up,ice),e(ice,a7o),e(Up,n7o),e(Up,Zq),e(Zq,s7o),e(Up,l7o),e(y,i7o),e(y,Jp),e(Jp,dce),e(dce,d7o),e(Jp,c7o),e(Jp,ej),e(ej,f7o),e(Jp,m7o),e(y,g7o),e(y,Yp),e(Yp,cce),e(cce,h7o),e(Yp,p7o),e(Yp,oj),e(oj,_7o),e(Yp,u7o),e(y,b7o),e(y,Kp),e(Kp,fce),e(fce,v7o),e(Kp,F7o),e(Kp,rj),e(rj,T7o),e(Kp,M7o),e(y,E7o),e(y,Zp),e(Zp,mce),e(mce,C7o),e(Zp,w7o),e(Zp,tj),e(tj,A7o),e(Zp,L7o),e(y,y7o),e(y,e_),e(e_,gce),e(gce,x7o),e(e_,$7o),e(e_,aj),e(aj,k7o),e(e_,S7o),e(y,R7o),e(y,o_),e(o_,hce),e(hce,P7o),e(o_,B7o),e(o_,nj),e(nj,I7o),e(o_,N7o),e(y,q7o),e(y,r_),e(r_,pce),e(pce,j7o),e(r_,D7o),e(r_,sj),e(sj,G7o),e(r_,O7o),e(y,V7o),e(y,t_),e(t_,_ce),e(_ce,X7o),e(t_,z7o),e(t_,lj),e(lj,Q7o),e(t_,W7o),e(y,H7o),e(y,a_),e(a_,uce),e(uce,U7o),e(a_,J7o),e(a_,ij),e(ij,Y7o),e(a_,K7o),e(y,Z7o),e(y,n_),e(n_,bce),e(bce,e8o),e(n_,o8o),e(n_,dj),e(dj,r8o),e(n_,t8o),e(y,a8o),e(y,s_),e(s_,vce),e(vce,n8o),e(s_,s8o),e(s_,cj),e(cj,l8o),e(s_,i8o),e(y,d8o),e(y,l_),e(l_,Fce),e(Fce,c8o),e(l_,f8o),e(l_,fj),e(fj,m8o),e(l_,g8o),e(y,h8o),e(y,i_),e(i_,Tce),e(Tce,p8o),e(i_,_8o),e(i_,mj),e(mj,u8o),e(i_,b8o),e(y,v8o),e(y,d_),e(d_,Mce),e(Mce,F8o),e(d_,T8o),e(d_,gj),e(gj,M8o),e(d_,E8o),e(y,C8o),e(y,c_),e(c_,Ece),e(Ece,w8o),e(c_,A8o),e(c_,hj),e(hj,L8o),e(c_,y8o),e(y,x8o),e(y,f_),e(f_,Cce),e(Cce,$8o),e(f_,k8o),e(f_,pj),e(pj,S8o),e(f_,R8o),e(y,P8o),e(y,m_),e(m_,wce),e(wce,B8o),e(m_,I8o),e(m_,_j),e(_j,N8o),e(m_,q8o),e(y,j8o),e(y,g_),e(g_,Ace),e(Ace,D8o),e(g_,G8o),e(g_,uj),e(uj,O8o),e(g_,V8o),e(y,X8o),e(y,h_),e(h_,Lce),e(Lce,z8o),e(h_,Q8o),e(h_,bj),e(bj,W8o),e(h_,H8o),e(y,U8o),e(y,p_),e(p_,yce),e(yce,J8o),e(p_,Y8o),e(p_,vj),e(vj,K8o),e(p_,Z8o),e(y,eMo),e(y,__),e(__,xce),e(xce,oMo),e(__,rMo),e(__,Fj),e(Fj,tMo),e(__,aMo),e(y,nMo),e(y,u_),e(u_,$ce),e($ce,sMo),e(u_,lMo),e(u_,Tj),e(Tj,iMo),e(u_,dMo),e(y,cMo),e(y,b_),e(b_,kce),e(kce,fMo),e(b_,mMo),e(b_,Mj),e(Mj,gMo),e(b_,hMo),e(y,pMo),e(y,v_),e(v_,Sce),e(Sce,_Mo),e(v_,uMo),e(v_,Ej),e(Ej,bMo),e(v_,vMo),e(y,FMo),e(y,F_),e(F_,Rce),e(Rce,TMo),e(F_,MMo),e(F_,Cj),e(Cj,EMo),e(F_,CMo),e(y,wMo),e(y,T_),e(T_,Pce),e(Pce,AMo),e(T_,LMo),e(T_,wj),e(wj,yMo),e(T_,xMo),e(y,$Mo),e(y,M_),e(M_,Bce),e(Bce,kMo),e(M_,SMo),e(M_,Aj),e(Aj,RMo),e(M_,PMo),e(y,BMo),e(y,Qs),e(Qs,Ice),e(Ice,IMo),e(Qs,NMo),e(Qs,Lj),e(Lj,qMo),e(Qs,jMo),e(Qs,yj),e(yj,DMo),e(Qs,GMo),e(y,OMo),e(y,E_),e(E_,Nce),e(Nce,VMo),e(E_,XMo),e(E_,xj),e(xj,zMo),e(E_,QMo),e(y,WMo),e(y,C_),e(C_,qce),e(qce,HMo),e(C_,UMo),e(C_,$j),e($j,JMo),e(C_,YMo),e(y,KMo),e(y,w_),e(w_,jce),e(jce,ZMo),e(w_,e4o),e(w_,kj),e(kj,o4o),e(w_,r4o),e(y,t4o),e(y,A_),e(A_,Dce),e(Dce,a4o),e(A_,n4o),e(A_,Sj),e(Sj,s4o),e(A_,l4o),e(y,i4o),e(y,L_),e(L_,Gce),e(Gce,d4o),e(L_,c4o),e(L_,Rj),e(Rj,f4o),e(L_,m4o),e(y,g4o),e(y,y_),e(y_,Oce),e(Oce,h4o),e(y_,p4o),e(y_,Pj),e(Pj,_4o),e(y_,u4o),e(y,b4o),e(y,x_),e(x_,Vce),e(Vce,v4o),e(x_,F4o),e(x_,Bj),e(Bj,T4o),e(x_,M4o),e(y,E4o),e(y,$_),e($_,Xce),e(Xce,C4o),e($_,w4o),e($_,Ij),e(Ij,A4o),e($_,L4o),e(y,y4o),e(y,k_),e(k_,zce),e(zce,x4o),e(k_,$4o),e(k_,Nj),e(Nj,k4o),e(k_,S4o),e(y,R4o),e(y,S_),e(S_,Qce),e(Qce,P4o),e(S_,B4o),e(S_,qj),e(qj,I4o),e(S_,N4o),e(y,q4o),e(y,R_),e(R_,Wce),e(Wce,j4o),e(R_,D4o),e(R_,jj),e(jj,G4o),e(R_,O4o),e(y,V4o),e(y,P_),e(P_,Hce),e(Hce,X4o),e(P_,z4o),e(P_,Dj),e(Dj,Q4o),e(P_,W4o),e(y,H4o),e(y,B_),e(B_,Uce),e(Uce,U4o),e(B_,J4o),e(B_,Gj),e(Gj,Y4o),e(B_,K4o),e(y,Z4o),e(y,I_),e(I_,Jce),e(Jce,eEo),e(I_,oEo),e(I_,Oj),e(Oj,rEo),e(I_,tEo),e(y,aEo),e(y,N_),e(N_,Yce),e(Yce,nEo),e(N_,sEo),e(N_,Vj),e(Vj,lEo),e(N_,iEo),e(y,dEo),e(y,q_),e(q_,Kce),e(Kce,cEo),e(q_,fEo),e(q_,Xj),e(Xj,mEo),e(q_,gEo),e(y,hEo),e(y,j_),e(j_,Zce),e(Zce,pEo),e(j_,_Eo),e(j_,zj),e(zj,uEo),e(j_,bEo),e(y,vEo),e(y,D_),e(D_,efe),e(efe,FEo),e(D_,TEo),e(D_,Qj),e(Qj,MEo),e(D_,EEo),e(y,CEo),e(y,G_),e(G_,ofe),e(ofe,wEo),e(G_,AEo),e(G_,Wj),e(Wj,LEo),e(G_,yEo),e(y,xEo),e(y,O_),e(O_,rfe),e(rfe,$Eo),e(O_,kEo),e(O_,Hj),e(Hj,SEo),e(O_,REo),e(y,PEo),e(y,V_),e(V_,tfe),e(tfe,BEo),e(V_,IEo),e(V_,Uj),e(Uj,NEo),e(V_,qEo),e(y,jEo),e(y,X_),e(X_,afe),e(afe,DEo),e(X_,GEo),e(X_,Jj),e(Jj,OEo),e(X_,VEo),e(y,XEo),e(y,z_),e(z_,nfe),e(nfe,zEo),e(z_,QEo),e(z_,Yj),e(Yj,WEo),e(z_,HEo),e(y,UEo),e(y,Q_),e(Q_,sfe),e(sfe,JEo),e(Q_,YEo),e(Q_,Kj),e(Kj,KEo),e(Q_,ZEo),e(y,eCo),e(y,W_),e(W_,lfe),e(lfe,oCo),e(W_,rCo),e(W_,Zj),e(Zj,tCo),e(W_,aCo),e(y,nCo),e(y,H_),e(H_,ife),e(ife,sCo),e(H_,lCo),e(H_,eD),e(eD,iCo),e(H_,dCo),e(y,cCo),e(y,U_),e(U_,dfe),e(dfe,fCo),e(U_,mCo),e(U_,oD),e(oD,gCo),e(U_,hCo),e(y,pCo),e(y,J_),e(J_,cfe),e(cfe,_Co),e(J_,uCo),e(J_,rD),e(rD,bCo),e(J_,vCo),e(y,FCo),e(y,Y_),e(Y_,ffe),e(ffe,TCo),e(Y_,MCo),e(Y_,tD),e(tD,ECo),e(Y_,CCo),e(y,wCo),e(y,K_),e(K_,mfe),e(mfe,ACo),e(K_,LCo),e(K_,aD),e(aD,yCo),e(K_,xCo),e(y,$Co),e(y,Z_),e(Z_,gfe),e(gfe,kCo),e(Z_,SCo),e(Z_,nD),e(nD,RCo),e(Z_,PCo),e(y,BCo),e(y,eu),e(eu,hfe),e(hfe,ICo),e(eu,NCo),e(eu,sD),e(sD,qCo),e(eu,jCo),e(y,DCo),e(y,ou),e(ou,pfe),e(pfe,GCo),e(ou,OCo),e(ou,lD),e(lD,VCo),e(ou,XCo),e(y,zCo),e(y,ru),e(ru,_fe),e(_fe,QCo),e(ru,WCo),e(ru,iD),e(iD,HCo),e(ru,UCo),e(y,JCo),e(y,tu),e(tu,ufe),e(ufe,YCo),e(tu,KCo),e(tu,dD),e(dD,ZCo),e(tu,e3o),e(y,o3o),e(y,au),e(au,bfe),e(bfe,r3o),e(au,t3o),e(au,cD),e(cD,a3o),e(au,n3o),e(y,s3o),e(y,nu),e(nu,vfe),e(vfe,l3o),e(nu,i3o),e(nu,fD),e(fD,d3o),e(nu,c3o),e(y,f3o),e(y,su),e(su,Ffe),e(Ffe,m3o),e(su,g3o),e(su,mD),e(mD,h3o),e(su,p3o),e(y,_3o),e(y,lu),e(lu,Tfe),e(Tfe,u3o),e(lu,b3o),e(lu,gD),e(gD,v3o),e(lu,F3o),e(y,T3o),e(y,iu),e(iu,Mfe),e(Mfe,M3o),e(iu,E3o),e(iu,hD),e(hD,C3o),e(iu,w3o),e(y,A3o),e(y,du),e(du,Efe),e(Efe,L3o),e(du,y3o),e(du,pD),e(pD,x3o),e(du,$3o),e(y,k3o),e(y,cu),e(cu,Cfe),e(Cfe,S3o),e(cu,R3o),e(cu,_D),e(_D,P3o),e(cu,B3o),e(y,I3o),e(y,fu),e(fu,wfe),e(wfe,N3o),e(fu,q3o),e(fu,uD),e(uD,j3o),e(fu,D3o),e(y,G3o),e(y,mu),e(mu,Afe),e(Afe,O3o),e(mu,V3o),e(mu,bD),e(bD,X3o),e(mu,z3o),e(y,Q3o),e(y,gu),e(gu,Lfe),e(Lfe,W3o),e(gu,H3o),e(gu,vD),e(vD,U3o),e(gu,J3o),e(y,Y3o),e(y,hu),e(hu,yfe),e(yfe,K3o),e(hu,Z3o),e(hu,FD),e(FD,e5o),e(hu,o5o),e(y,r5o),e(y,pu),e(pu,xfe),e(xfe,t5o),e(pu,a5o),e(pu,TD),e(TD,n5o),e(pu,s5o),e(y,l5o),e(y,_u),e(_u,$fe),e($fe,i5o),e(_u,d5o),e(_u,MD),e(MD,c5o),e(_u,f5o),e(y,m5o),e(y,uu),e(uu,kfe),e(kfe,g5o),e(uu,h5o),e(uu,ED),e(ED,p5o),e(uu,_5o),e(y,u5o),e(y,bu),e(bu,Sfe),e(Sfe,b5o),e(bu,v5o),e(bu,CD),e(CD,F5o),e(bu,T5o),e(y,M5o),e(y,vu),e(vu,Rfe),e(Rfe,E5o),e(vu,C5o),e(vu,wD),e(wD,w5o),e(vu,A5o),e(y,L5o),e(y,Fu),e(Fu,Pfe),e(Pfe,y5o),e(Fu,x5o),e(Fu,AD),e(AD,$5o),e(Fu,k5o),e(y,S5o),e(y,Tu),e(Tu,Bfe),e(Bfe,R5o),e(Tu,P5o),e(Tu,LD),e(LD,B5o),e(Tu,I5o),e(y,N5o),e(y,Mu),e(Mu,Ife),e(Ife,q5o),e(Mu,j5o),e(Mu,yD),e(yD,D5o),e(Mu,G5o),e(y,O5o),e(y,Eu),e(Eu,Nfe),e(Nfe,V5o),e(Eu,X5o),e(Eu,xD),e(xD,z5o),e(Eu,Q5o),e(y,W5o),e(y,Cu),e(Cu,qfe),e(qfe,H5o),e(Cu,U5o),e(Cu,$D),e($D,J5o),e(Cu,Y5o),e(y,K5o),e(y,wu),e(wu,jfe),e(jfe,Z5o),e(wu,e0o),e(wu,kD),e(kD,o0o),e(wu,r0o),e(y,t0o),e(y,Au),e(Au,Dfe),e(Dfe,a0o),e(Au,n0o),e(Au,SD),e(SD,s0o),e(Au,l0o),e(y,i0o),e(y,Lu),e(Lu,Gfe),e(Gfe,d0o),e(Lu,c0o),e(Lu,RD),e(RD,f0o),e(Lu,m0o),e(y,g0o),e(y,yu),e(yu,Ofe),e(Ofe,h0o),e(yu,p0o),e(yu,PD),e(PD,_0o),e(yu,u0o),e(y,b0o),e(y,xu),e(xu,Vfe),e(Vfe,v0o),e(xu,F0o),e(xu,BD),e(BD,T0o),e(xu,M0o),e(y,E0o),e(y,$u),e($u,Xfe),e(Xfe,C0o),e($u,w0o),e($u,ID),e(ID,A0o),e($u,L0o),e(y,y0o),e(y,ku),e(ku,zfe),e(zfe,x0o),e(ku,$0o),e(ku,ND),e(ND,k0o),e(ku,S0o),e(y,R0o),e(y,Su),e(Su,Qfe),e(Qfe,P0o),e(Su,B0o),e(Su,qD),e(qD,I0o),e(Su,N0o),e(y,q0o),e(y,Ru),e(Ru,Wfe),e(Wfe,j0o),e(Ru,D0o),e(Ru,jD),e(jD,G0o),e(Ru,O0o),e(y,V0o),e(y,Pu),e(Pu,Hfe),e(Hfe,X0o),e(Pu,z0o),e(Pu,DD),e(DD,Q0o),e(Pu,W0o),e(y,H0o),e(y,Bu),e(Bu,Ufe),e(Ufe,U0o),e(Bu,J0o),e(Bu,GD),e(GD,Y0o),e(Bu,K0o),e(y,Z0o),e(y,Iu),e(Iu,Jfe),e(Jfe,ewo),e(Iu,owo),e(Iu,OD),e(OD,rwo),e(Iu,two),e(y,awo),e(y,Nu),e(Nu,Yfe),e(Yfe,nwo),e(Nu,swo),e(Nu,VD),e(VD,lwo),e(Nu,iwo),e(y,dwo),e(y,qu),e(qu,Kfe),e(Kfe,cwo),e(qu,fwo),e(qu,XD),e(XD,mwo),e(qu,gwo),e(y,hwo),e(y,ju),e(ju,Zfe),e(Zfe,pwo),e(ju,_wo),e(ju,zD),e(zD,uwo),e(ju,bwo),e(y,vwo),e(y,Du),e(Du,eme),e(eme,Fwo),e(Du,Two),e(Du,QD),e(QD,Mwo),e(Du,Ewo),e(y,Cwo),e(y,Gu),e(Gu,ome),e(ome,wwo),e(Gu,Awo),e(Gu,WD),e(WD,Lwo),e(Gu,ywo),e(y,xwo),e(y,Ou),e(Ou,rme),e(rme,$wo),e(Ou,kwo),e(Ou,HD),e(HD,Swo),e(Ou,Rwo),e(y,Pwo),e(y,Vu),e(Vu,tme),e(tme,Bwo),e(Vu,Iwo),e(Vu,UD),e(UD,Nwo),e(Vu,qwo),e(y,jwo),e(y,Xu),e(Xu,ame),e(ame,Dwo),e(Xu,Gwo),e(Xu,JD),e(JD,Owo),e(Xu,Vwo),e(Je,Xwo),e(Je,zu),e(zu,zwo),e(zu,nme),e(nme,Qwo),e(zu,Wwo),e(zu,sme),e(sme,Hwo),e(Je,Uwo),M(Qu,Je,null),b(f,ZVe,u),b(f,Vi,u),e(Vi,Wu),e(Wu,lme),M(SL,lme,null),e(Vi,Jwo),e(Vi,ime),e(ime,Ywo),b(f,eXe,u),b(f,$o,u),M(RL,$o,null),e($o,Kwo),e($o,Xi),e(Xi,Zwo),e(Xi,YD),e(YD,eAo),e(Xi,oAo),e(Xi,KD),e(KD,rAo),e(Xi,tAo),e($o,aAo),e($o,PL),e(PL,nAo),e(PL,dme),e(dme,sAo),e(PL,lAo),e($o,iAo),e($o,it),M(BL,it,null),e(it,dAo),e(it,cme),e(cme,cAo),e(it,fAo),e(it,zi),e(zi,mAo),e(zi,fme),e(fme,gAo),e(zi,hAo),e(zi,ZD),e(ZD,pAo),e(zi,_Ao),e(it,uAo),M(Hu,it,null),e($o,bAo),e($o,Ye),M(IL,Ye,null),e(Ye,vAo),e(Ye,mme),e(mme,FAo),e(Ye,TAo),e(Ye,Ia),e(Ia,MAo),e(Ia,gme),e(gme,EAo),e(Ia,CAo),e(Ia,hme),e(hme,wAo),e(Ia,AAo),e(Ia,pme),e(pme,LAo),e(Ia,yAo),e(Ye,xAo),e(Ye,G),e(G,Uu),e(Uu,_me),e(_me,$Ao),e(Uu,kAo),e(Uu,eG),e(eG,SAo),e(Uu,RAo),e(G,PAo),e(G,Ju),e(Ju,ume),e(ume,BAo),e(Ju,IAo),e(Ju,oG),e(oG,NAo),e(Ju,qAo),e(G,jAo),e(G,Yu),e(Yu,bme),e(bme,DAo),e(Yu,GAo),e(Yu,rG),e(rG,OAo),e(Yu,VAo),e(G,XAo),e(G,Ku),e(Ku,vme),e(vme,zAo),e(Ku,QAo),e(Ku,tG),e(tG,WAo),e(Ku,HAo),e(G,UAo),e(G,Zu),e(Zu,Fme),e(Fme,JAo),e(Zu,YAo),e(Zu,aG),e(aG,KAo),e(Zu,ZAo),e(G,e6o),e(G,e1),e(e1,Tme),e(Tme,o6o),e(e1,r6o),e(e1,nG),e(nG,t6o),e(e1,a6o),e(G,n6o),e(G,o1),e(o1,Mme),e(Mme,s6o),e(o1,l6o),e(o1,sG),e(sG,i6o),e(o1,d6o),e(G,c6o),e(G,r1),e(r1,Eme),e(Eme,f6o),e(r1,m6o),e(r1,lG),e(lG,g6o),e(r1,h6o),e(G,p6o),e(G,t1),e(t1,Cme),e(Cme,_6o),e(t1,u6o),e(t1,iG),e(iG,b6o),e(t1,v6o),e(G,F6o),e(G,a1),e(a1,wme),e(wme,T6o),e(a1,M6o),e(a1,dG),e(dG,E6o),e(a1,C6o),e(G,w6o),e(G,n1),e(n1,Ame),e(Ame,A6o),e(n1,L6o),e(n1,cG),e(cG,y6o),e(n1,x6o),e(G,$6o),e(G,s1),e(s1,Lme),e(Lme,k6o),e(s1,S6o),e(s1,fG),e(fG,R6o),e(s1,P6o),e(G,B6o),e(G,l1),e(l1,yme),e(yme,I6o),e(l1,N6o),e(l1,mG),e(mG,q6o),e(l1,j6o),e(G,D6o),e(G,i1),e(i1,xme),e(xme,G6o),e(i1,O6o),e(i1,gG),e(gG,V6o),e(i1,X6o),e(G,z6o),e(G,d1),e(d1,$me),e($me,Q6o),e(d1,W6o),e(d1,hG),e(hG,H6o),e(d1,U6o),e(G,J6o),e(G,c1),e(c1,kme),e(kme,Y6o),e(c1,K6o),e(c1,pG),e(pG,Z6o),e(c1,eLo),e(G,oLo),e(G,f1),e(f1,Sme),e(Sme,rLo),e(f1,tLo),e(f1,_G),e(_G,aLo),e(f1,nLo),e(G,sLo),e(G,m1),e(m1,Rme),e(Rme,lLo),e(m1,iLo),e(m1,uG),e(uG,dLo),e(m1,cLo),e(G,fLo),e(G,g1),e(g1,Pme),e(Pme,mLo),e(g1,gLo),e(g1,bG),e(bG,hLo),e(g1,pLo),e(G,_Lo),e(G,h1),e(h1,Bme),e(Bme,uLo),e(h1,bLo),e(h1,vG),e(vG,vLo),e(h1,FLo),e(G,TLo),e(G,p1),e(p1,Ime),e(Ime,MLo),e(p1,ELo),e(p1,FG),e(FG,CLo),e(p1,wLo),e(G,ALo),e(G,_1),e(_1,Nme),e(Nme,LLo),e(_1,yLo),e(_1,TG),e(TG,xLo),e(_1,$Lo),e(G,kLo),e(G,u1),e(u1,qme),e(qme,SLo),e(u1,RLo),e(u1,MG),e(MG,PLo),e(u1,BLo),e(G,ILo),e(G,b1),e(b1,jme),e(jme,NLo),e(b1,qLo),e(b1,EG),e(EG,jLo),e(b1,DLo),e(G,GLo),e(G,v1),e(v1,Dme),e(Dme,OLo),e(v1,VLo),e(v1,CG),e(CG,XLo),e(v1,zLo),e(G,QLo),e(G,F1),e(F1,Gme),e(Gme,WLo),e(F1,HLo),e(F1,wG),e(wG,ULo),e(F1,JLo),e(G,YLo),e(G,T1),e(T1,Ome),e(Ome,KLo),e(T1,ZLo),e(T1,AG),e(AG,eyo),e(T1,oyo),e(G,ryo),e(G,M1),e(M1,Vme),e(Vme,tyo),e(M1,ayo),e(M1,LG),e(LG,nyo),e(M1,syo),e(G,lyo),e(G,E1),e(E1,Xme),e(Xme,iyo),e(E1,dyo),e(E1,yG),e(yG,cyo),e(E1,fyo),e(G,myo),e(G,C1),e(C1,zme),e(zme,gyo),e(C1,hyo),e(C1,xG),e(xG,pyo),e(C1,_yo),e(G,uyo),e(G,w1),e(w1,Qme),e(Qme,byo),e(w1,vyo),e(w1,$G),e($G,Fyo),e(w1,Tyo),e(G,Myo),e(G,A1),e(A1,Wme),e(Wme,Eyo),e(A1,Cyo),e(A1,kG),e(kG,wyo),e(A1,Ayo),e(G,Lyo),e(G,L1),e(L1,Hme),e(Hme,yyo),e(L1,xyo),e(L1,SG),e(SG,$yo),e(L1,kyo),e(G,Syo),e(G,y1),e(y1,Ume),e(Ume,Ryo),e(y1,Pyo),e(y1,RG),e(RG,Byo),e(y1,Iyo),e(G,Nyo),e(G,x1),e(x1,Jme),e(Jme,qyo),e(x1,jyo),e(x1,PG),e(PG,Dyo),e(x1,Gyo),e(G,Oyo),e(G,$1),e($1,Yme),e(Yme,Vyo),e($1,Xyo),e($1,BG),e(BG,zyo),e($1,Qyo),e(G,Wyo),e(G,k1),e(k1,Kme),e(Kme,Hyo),e(k1,Uyo),e(k1,IG),e(IG,Jyo),e(k1,Yyo),e(G,Kyo),e(G,S1),e(S1,Zme),e(Zme,Zyo),e(S1,e9o),e(S1,NG),e(NG,o9o),e(S1,r9o),e(G,t9o),e(G,R1),e(R1,ege),e(ege,a9o),e(R1,n9o),e(R1,qG),e(qG,s9o),e(R1,l9o),e(G,i9o),e(G,P1),e(P1,oge),e(oge,d9o),e(P1,c9o),e(P1,jG),e(jG,f9o),e(P1,m9o),e(G,g9o),e(G,B1),e(B1,rge),e(rge,h9o),e(B1,p9o),e(B1,DG),e(DG,_9o),e(B1,u9o),e(G,b9o),e(G,I1),e(I1,tge),e(tge,v9o),e(I1,F9o),e(I1,GG),e(GG,T9o),e(I1,M9o),e(G,E9o),e(G,N1),e(N1,age),e(age,C9o),e(N1,w9o),e(N1,OG),e(OG,A9o),e(N1,L9o),e(G,y9o),e(G,q1),e(q1,nge),e(nge,x9o),e(q1,$9o),e(q1,VG),e(VG,k9o),e(q1,S9o),e(G,R9o),e(G,j1),e(j1,sge),e(sge,P9o),e(j1,B9o),e(j1,XG),e(XG,I9o),e(j1,N9o),e(Ye,q9o),e(Ye,D1),e(D1,j9o),e(D1,lge),e(lge,D9o),e(D1,G9o),e(D1,ige),e(ige,O9o),e(Ye,V9o),M(G1,Ye,null),b(f,oXe,u),b(f,Qi,u),e(Qi,O1),e(O1,dge),M(NL,dge,null),e(Qi,X9o),e(Qi,cge),e(cge,z9o),b(f,rXe,u),b(f,ko,u),M(qL,ko,null),e(ko,Q9o),e(ko,Wi),e(Wi,W9o),e(Wi,zG),e(zG,H9o),e(Wi,U9o),e(Wi,QG),e(QG,J9o),e(Wi,Y9o),e(ko,K9o),e(ko,jL),e(jL,Z9o),e(jL,fge),e(fge,exo),e(jL,oxo),e(ko,rxo),e(ko,dt),M(DL,dt,null),e(dt,txo),e(dt,mge),e(mge,axo),e(dt,nxo),e(dt,Hi),e(Hi,sxo),e(Hi,gge),e(gge,lxo),e(Hi,ixo),e(Hi,WG),e(WG,dxo),e(Hi,cxo),e(dt,fxo),M(V1,dt,null),e(ko,mxo),e(ko,Ke),M(GL,Ke,null),e(Ke,gxo),e(Ke,hge),e(hge,hxo),e(Ke,pxo),e(Ke,Na),e(Na,_xo),e(Na,pge),e(pge,uxo),e(Na,bxo),e(Na,_ge),e(_ge,vxo),e(Na,Fxo),e(Na,uge),e(uge,Txo),e(Na,Mxo),e(Ke,Exo),e(Ke,z),e(z,X1),e(X1,bge),e(bge,Cxo),e(X1,wxo),e(X1,HG),e(HG,Axo),e(X1,Lxo),e(z,yxo),e(z,z1),e(z1,vge),e(vge,xxo),e(z1,$xo),e(z1,UG),e(UG,kxo),e(z1,Sxo),e(z,Rxo),e(z,Q1),e(Q1,Fge),e(Fge,Pxo),e(Q1,Bxo),e(Q1,JG),e(JG,Ixo),e(Q1,Nxo),e(z,qxo),e(z,W1),e(W1,Tge),e(Tge,jxo),e(W1,Dxo),e(W1,YG),e(YG,Gxo),e(W1,Oxo),e(z,Vxo),e(z,H1),e(H1,Mge),e(Mge,Xxo),e(H1,zxo),e(H1,KG),e(KG,Qxo),e(H1,Wxo),e(z,Hxo),e(z,U1),e(U1,Ege),e(Ege,Uxo),e(U1,Jxo),e(U1,ZG),e(ZG,Yxo),e(U1,Kxo),e(z,Zxo),e(z,J1),e(J1,Cge),e(Cge,e$o),e(J1,o$o),e(J1,eO),e(eO,r$o),e(J1,t$o),e(z,a$o),e(z,Y1),e(Y1,wge),e(wge,n$o),e(Y1,s$o),e(Y1,oO),e(oO,l$o),e(Y1,i$o),e(z,d$o),e(z,K1),e(K1,Age),e(Age,c$o),e(K1,f$o),e(K1,rO),e(rO,m$o),e(K1,g$o),e(z,h$o),e(z,Z1),e(Z1,Lge),e(Lge,p$o),e(Z1,_$o),e(Z1,tO),e(tO,u$o),e(Z1,b$o),e(z,v$o),e(z,e2),e(e2,yge),e(yge,F$o),e(e2,T$o),e(e2,aO),e(aO,M$o),e(e2,E$o),e(z,C$o),e(z,o2),e(o2,xge),e(xge,w$o),e(o2,A$o),e(o2,nO),e(nO,L$o),e(o2,y$o),e(z,x$o),e(z,r2),e(r2,$ge),e($ge,$$o),e(r2,k$o),e(r2,sO),e(sO,S$o),e(r2,R$o),e(z,P$o),e(z,t2),e(t2,kge),e(kge,B$o),e(t2,I$o),e(t2,lO),e(lO,N$o),e(t2,q$o),e(z,j$o),e(z,a2),e(a2,Sge),e(Sge,D$o),e(a2,G$o),e(a2,iO),e(iO,O$o),e(a2,V$o),e(z,X$o),e(z,n2),e(n2,Rge),e(Rge,z$o),e(n2,Q$o),e(n2,dO),e(dO,W$o),e(n2,H$o),e(z,U$o),e(z,s2),e(s2,Pge),e(Pge,J$o),e(s2,Y$o),e(s2,cO),e(cO,K$o),e(s2,Z$o),e(z,eko),e(z,l2),e(l2,Bge),e(Bge,oko),e(l2,rko),e(l2,fO),e(fO,tko),e(l2,ako),e(z,nko),e(z,i2),e(i2,Ige),e(Ige,sko),e(i2,lko),e(i2,mO),e(mO,iko),e(i2,dko),e(z,cko),e(z,d2),e(d2,Nge),e(Nge,fko),e(d2,mko),e(d2,gO),e(gO,gko),e(d2,hko),e(z,pko),e(z,c2),e(c2,qge),e(qge,_ko),e(c2,uko),e(c2,hO),e(hO,bko),e(c2,vko),e(z,Fko),e(z,f2),e(f2,jge),e(jge,Tko),e(f2,Mko),e(f2,pO),e(pO,Eko),e(f2,Cko),e(z,wko),e(z,m2),e(m2,Dge),e(Dge,Ako),e(m2,Lko),e(m2,_O),e(_O,yko),e(m2,xko),e(z,$ko),e(z,g2),e(g2,Gge),e(Gge,kko),e(g2,Sko),e(g2,uO),e(uO,Rko),e(g2,Pko),e(z,Bko),e(z,h2),e(h2,Oge),e(Oge,Iko),e(h2,Nko),e(h2,bO),e(bO,qko),e(h2,jko),e(z,Dko),e(z,p2),e(p2,Vge),e(Vge,Gko),e(p2,Oko),e(p2,vO),e(vO,Vko),e(p2,Xko),e(z,zko),e(z,_2),e(_2,Xge),e(Xge,Qko),e(_2,Wko),e(_2,FO),e(FO,Hko),e(_2,Uko),e(z,Jko),e(z,u2),e(u2,zge),e(zge,Yko),e(u2,Kko),e(u2,TO),e(TO,Zko),e(u2,eSo),e(z,oSo),e(z,b2),e(b2,Qge),e(Qge,rSo),e(b2,tSo),e(b2,MO),e(MO,aSo),e(b2,nSo),e(z,sSo),e(z,v2),e(v2,Wge),e(Wge,lSo),e(v2,iSo),e(v2,EO),e(EO,dSo),e(v2,cSo),e(z,fSo),e(z,F2),e(F2,Hge),e(Hge,mSo),e(F2,gSo),e(F2,CO),e(CO,hSo),e(F2,pSo),e(z,_So),e(z,T2),e(T2,Uge),e(Uge,uSo),e(T2,bSo),e(T2,wO),e(wO,vSo),e(T2,FSo),e(z,TSo),e(z,M2),e(M2,Jge),e(Jge,MSo),e(M2,ESo),e(M2,AO),e(AO,CSo),e(M2,wSo),e(z,ASo),e(z,E2),e(E2,Yge),e(Yge,LSo),e(E2,ySo),e(E2,LO),e(LO,xSo),e(E2,$So),e(z,kSo),e(z,C2),e(C2,Kge),e(Kge,SSo),e(C2,RSo),e(C2,yO),e(yO,PSo),e(C2,BSo),e(z,ISo),e(z,w2),e(w2,Zge),e(Zge,NSo),e(w2,qSo),e(w2,xO),e(xO,jSo),e(w2,DSo),e(z,GSo),e(z,A2),e(A2,ehe),e(ehe,OSo),e(A2,VSo),e(A2,$O),e($O,XSo),e(A2,zSo),e(z,QSo),e(z,L2),e(L2,ohe),e(ohe,WSo),e(L2,HSo),e(L2,kO),e(kO,USo),e(L2,JSo),e(z,YSo),e(z,y2),e(y2,rhe),e(rhe,KSo),e(y2,ZSo),e(y2,SO),e(SO,eRo),e(y2,oRo),e(z,rRo),e(z,x2),e(x2,the),e(the,tRo),e(x2,aRo),e(x2,RO),e(RO,nRo),e(x2,sRo),e(Ke,lRo),e(Ke,$2),e($2,iRo),e($2,ahe),e(ahe,dRo),e($2,cRo),e($2,nhe),e(nhe,fRo),e(Ke,mRo),M(k2,Ke,null),b(f,tXe,u),b(f,Ui,u),e(Ui,S2),e(S2,she),M(OL,she,null),e(Ui,gRo),e(Ui,lhe),e(lhe,hRo),b(f,aXe,u),b(f,So,u),M(VL,So,null),e(So,pRo),e(So,Ji),e(Ji,_Ro),e(Ji,PO),e(PO,uRo),e(Ji,bRo),e(Ji,BO),e(BO,vRo),e(Ji,FRo),e(So,TRo),e(So,XL),e(XL,MRo),e(XL,ihe),e(ihe,ERo),e(XL,CRo),e(So,wRo),e(So,ct),M(zL,ct,null),e(ct,ARo),e(ct,dhe),e(dhe,LRo),e(ct,yRo),e(ct,Yi),e(Yi,xRo),e(Yi,che),e(che,$Ro),e(Yi,kRo),e(Yi,IO),e(IO,SRo),e(Yi,RRo),e(ct,PRo),M(R2,ct,null),e(So,BRo),e(So,Ze),M(QL,Ze,null),e(Ze,IRo),e(Ze,fhe),e(fhe,NRo),e(Ze,qRo),e(Ze,qa),e(qa,jRo),e(qa,mhe),e(mhe,DRo),e(qa,GRo),e(qa,ghe),e(ghe,ORo),e(qa,VRo),e(qa,hhe),e(hhe,XRo),e(qa,zRo),e(Ze,QRo),e(Ze,W),e(W,P2),e(P2,phe),e(phe,WRo),e(P2,HRo),e(P2,NO),e(NO,URo),e(P2,JRo),e(W,YRo),e(W,B2),e(B2,_he),e(_he,KRo),e(B2,ZRo),e(B2,qO),e(qO,ePo),e(B2,oPo),e(W,rPo),e(W,I2),e(I2,uhe),e(uhe,tPo),e(I2,aPo),e(I2,jO),e(jO,nPo),e(I2,sPo),e(W,lPo),e(W,N2),e(N2,bhe),e(bhe,iPo),e(N2,dPo),e(N2,DO),e(DO,cPo),e(N2,fPo),e(W,mPo),e(W,q2),e(q2,vhe),e(vhe,gPo),e(q2,hPo),e(q2,GO),e(GO,pPo),e(q2,_Po),e(W,uPo),e(W,j2),e(j2,Fhe),e(Fhe,bPo),e(j2,vPo),e(j2,OO),e(OO,FPo),e(j2,TPo),e(W,MPo),e(W,D2),e(D2,The),e(The,EPo),e(D2,CPo),e(D2,VO),e(VO,wPo),e(D2,APo),e(W,LPo),e(W,G2),e(G2,Mhe),e(Mhe,yPo),e(G2,xPo),e(G2,XO),e(XO,$Po),e(G2,kPo),e(W,SPo),e(W,O2),e(O2,Ehe),e(Ehe,RPo),e(O2,PPo),e(O2,zO),e(zO,BPo),e(O2,IPo),e(W,NPo),e(W,V2),e(V2,Che),e(Che,qPo),e(V2,jPo),e(V2,QO),e(QO,DPo),e(V2,GPo),e(W,OPo),e(W,X2),e(X2,whe),e(whe,VPo),e(X2,XPo),e(X2,WO),e(WO,zPo),e(X2,QPo),e(W,WPo),e(W,z2),e(z2,Ahe),e(Ahe,HPo),e(z2,UPo),e(z2,HO),e(HO,JPo),e(z2,YPo),e(W,KPo),e(W,Q2),e(Q2,Lhe),e(Lhe,ZPo),e(Q2,eBo),e(Q2,UO),e(UO,oBo),e(Q2,rBo),e(W,tBo),e(W,W2),e(W2,yhe),e(yhe,aBo),e(W2,nBo),e(W2,JO),e(JO,sBo),e(W2,lBo),e(W,iBo),e(W,H2),e(H2,xhe),e(xhe,dBo),e(H2,cBo),e(H2,YO),e(YO,fBo),e(H2,mBo),e(W,gBo),e(W,U2),e(U2,$he),e($he,hBo),e(U2,pBo),e(U2,KO),e(KO,_Bo),e(U2,uBo),e(W,bBo),e(W,J2),e(J2,khe),e(khe,vBo),e(J2,FBo),e(J2,ZO),e(ZO,TBo),e(J2,MBo),e(W,EBo),e(W,Y2),e(Y2,She),e(She,CBo),e(Y2,wBo),e(Y2,eV),e(eV,ABo),e(Y2,LBo),e(W,yBo),e(W,K2),e(K2,Rhe),e(Rhe,xBo),e(K2,$Bo),e(K2,oV),e(oV,kBo),e(K2,SBo),e(W,RBo),e(W,Z2),e(Z2,Phe),e(Phe,PBo),e(Z2,BBo),e(Z2,rV),e(rV,IBo),e(Z2,NBo),e(W,qBo),e(W,eb),e(eb,Bhe),e(Bhe,jBo),e(eb,DBo),e(eb,tV),e(tV,GBo),e(eb,OBo),e(W,VBo),e(W,ob),e(ob,Ihe),e(Ihe,XBo),e(ob,zBo),e(ob,aV),e(aV,QBo),e(ob,WBo),e(W,HBo),e(W,rb),e(rb,Nhe),e(Nhe,UBo),e(rb,JBo),e(rb,nV),e(nV,YBo),e(rb,KBo),e(W,ZBo),e(W,tb),e(tb,qhe),e(qhe,eIo),e(tb,oIo),e(tb,sV),e(sV,rIo),e(tb,tIo),e(W,aIo),e(W,ab),e(ab,jhe),e(jhe,nIo),e(ab,sIo),e(ab,lV),e(lV,lIo),e(ab,iIo),e(W,dIo),e(W,nb),e(nb,Dhe),e(Dhe,cIo),e(nb,fIo),e(nb,iV),e(iV,mIo),e(nb,gIo),e(W,hIo),e(W,sb),e(sb,Ghe),e(Ghe,pIo),e(sb,_Io),e(sb,dV),e(dV,uIo),e(sb,bIo),e(W,vIo),e(W,lb),e(lb,Ohe),e(Ohe,FIo),e(lb,TIo),e(lb,cV),e(cV,MIo),e(lb,EIo),e(W,CIo),e(W,ib),e(ib,Vhe),e(Vhe,wIo),e(ib,AIo),e(ib,fV),e(fV,LIo),e(ib,yIo),e(W,xIo),e(W,db),e(db,Xhe),e(Xhe,$Io),e(db,kIo),e(db,mV),e(mV,SIo),e(db,RIo),e(W,PIo),e(W,cb),e(cb,zhe),e(zhe,BIo),e(cb,IIo),e(cb,gV),e(gV,NIo),e(cb,qIo),e(W,jIo),e(W,fb),e(fb,Qhe),e(Qhe,DIo),e(fb,GIo),e(fb,hV),e(hV,OIo),e(fb,VIo),e(W,XIo),e(W,mb),e(mb,Whe),e(Whe,zIo),e(mb,QIo),e(mb,pV),e(pV,WIo),e(mb,HIo),e(W,UIo),e(W,gb),e(gb,Hhe),e(Hhe,JIo),e(gb,YIo),e(gb,Uhe),e(Uhe,KIo),e(gb,ZIo),e(W,eNo),e(W,hb),e(hb,Jhe),e(Jhe,oNo),e(hb,rNo),e(hb,_V),e(_V,tNo),e(hb,aNo),e(W,nNo),e(W,pb),e(pb,Yhe),e(Yhe,sNo),e(pb,lNo),e(pb,uV),e(uV,iNo),e(pb,dNo),e(W,cNo),e(W,_b),e(_b,Khe),e(Khe,fNo),e(_b,mNo),e(_b,bV),e(bV,gNo),e(_b,hNo),e(W,pNo),e(W,ub),e(ub,Zhe),e(Zhe,_No),e(ub,uNo),e(ub,vV),e(vV,bNo),e(ub,vNo),e(Ze,FNo),e(Ze,bb),e(bb,TNo),e(bb,epe),e(epe,MNo),e(bb,ENo),e(bb,ope),e(ope,CNo),e(Ze,wNo),M(vb,Ze,null),b(f,nXe,u),b(f,Ki,u),e(Ki,Fb),e(Fb,rpe),M(WL,rpe,null),e(Ki,ANo),e(Ki,tpe),e(tpe,LNo),b(f,sXe,u),b(f,Ro,u),M(HL,Ro,null),e(Ro,yNo),e(Ro,Zi),e(Zi,xNo),e(Zi,FV),e(FV,$No),e(Zi,kNo),e(Zi,TV),e(TV,SNo),e(Zi,RNo),e(Ro,PNo),e(Ro,UL),e(UL,BNo),e(UL,ape),e(ape,INo),e(UL,NNo),e(Ro,qNo),e(Ro,ft),M(JL,ft,null),e(ft,jNo),e(ft,npe),e(npe,DNo),e(ft,GNo),e(ft,ed),e(ed,ONo),e(ed,spe),e(spe,VNo),e(ed,XNo),e(ed,MV),e(MV,zNo),e(ed,QNo),e(ft,WNo),M(Tb,ft,null),e(Ro,HNo),e(Ro,eo),M(YL,eo,null),e(eo,UNo),e(eo,lpe),e(lpe,JNo),e(eo,YNo),e(eo,ja),e(ja,KNo),e(ja,ipe),e(ipe,ZNo),e(ja,eqo),e(ja,dpe),e(dpe,oqo),e(ja,rqo),e(ja,cpe),e(cpe,tqo),e(ja,aqo),e(eo,nqo),e(eo,pe),e(pe,Mb),e(Mb,fpe),e(fpe,sqo),e(Mb,lqo),e(Mb,EV),e(EV,iqo),e(Mb,dqo),e(pe,cqo),e(pe,Eb),e(Eb,mpe),e(mpe,fqo),e(Eb,mqo),e(Eb,CV),e(CV,gqo),e(Eb,hqo),e(pe,pqo),e(pe,Cb),e(Cb,gpe),e(gpe,_qo),e(Cb,uqo),e(Cb,wV),e(wV,bqo),e(Cb,vqo),e(pe,Fqo),e(pe,wb),e(wb,hpe),e(hpe,Tqo),e(wb,Mqo),e(wb,AV),e(AV,Eqo),e(wb,Cqo),e(pe,wqo),e(pe,Ab),e(Ab,ppe),e(ppe,Aqo),e(Ab,Lqo),e(Ab,LV),e(LV,yqo),e(Ab,xqo),e(pe,$qo),e(pe,Lb),e(Lb,_pe),e(_pe,kqo),e(Lb,Sqo),e(Lb,yV),e(yV,Rqo),e(Lb,Pqo),e(pe,Bqo),e(pe,yb),e(yb,upe),e(upe,Iqo),e(yb,Nqo),e(yb,xV),e(xV,qqo),e(yb,jqo),e(pe,Dqo),e(pe,xb),e(xb,bpe),e(bpe,Gqo),e(xb,Oqo),e(xb,$V),e($V,Vqo),e(xb,Xqo),e(pe,zqo),e(pe,$b),e($b,vpe),e(vpe,Qqo),e($b,Wqo),e($b,kV),e(kV,Hqo),e($b,Uqo),e(pe,Jqo),e(pe,kb),e(kb,Fpe),e(Fpe,Yqo),e(kb,Kqo),e(kb,SV),e(SV,Zqo),e(kb,ejo),e(pe,ojo),e(pe,Sb),e(Sb,Tpe),e(Tpe,rjo),e(Sb,tjo),e(Sb,RV),e(RV,ajo),e(Sb,njo),e(pe,sjo),e(pe,Rb),e(Rb,Mpe),e(Mpe,ljo),e(Rb,ijo),e(Rb,PV),e(PV,djo),e(Rb,cjo),e(pe,fjo),e(pe,Pb),e(Pb,Epe),e(Epe,mjo),e(Pb,gjo),e(Pb,BV),e(BV,hjo),e(Pb,pjo),e(pe,_jo),e(pe,Bb),e(Bb,Cpe),e(Cpe,ujo),e(Bb,bjo),e(Bb,IV),e(IV,vjo),e(Bb,Fjo),e(pe,Tjo),e(pe,Ib),e(Ib,wpe),e(wpe,Mjo),e(Ib,Ejo),e(Ib,NV),e(NV,Cjo),e(Ib,wjo),e(pe,Ajo),e(pe,Nb),e(Nb,Ape),e(Ape,Ljo),e(Nb,yjo),e(Nb,qV),e(qV,xjo),e(Nb,$jo),e(pe,kjo),e(pe,qb),e(qb,Lpe),e(Lpe,Sjo),e(qb,Rjo),e(qb,jV),e(jV,Pjo),e(qb,Bjo),e(pe,Ijo),e(pe,jb),e(jb,ype),e(ype,Njo),e(jb,qjo),e(jb,DV),e(DV,jjo),e(jb,Djo),e(eo,Gjo),e(eo,Db),e(Db,Ojo),e(Db,xpe),e(xpe,Vjo),e(Db,Xjo),e(Db,$pe),e($pe,zjo),e(eo,Qjo),M(Gb,eo,null),b(f,lXe,u),b(f,od,u),e(od,Ob),e(Ob,kpe),M(KL,kpe,null),e(od,Wjo),e(od,Spe),e(Spe,Hjo),b(f,iXe,u),b(f,Po,u),M(ZL,Po,null),e(Po,Ujo),e(Po,rd),e(rd,Jjo),e(rd,GV),e(GV,Yjo),e(rd,Kjo),e(rd,OV),e(OV,Zjo),e(rd,eDo),e(Po,oDo),e(Po,ey),e(ey,rDo),e(ey,Rpe),e(Rpe,tDo),e(ey,aDo),e(Po,nDo),e(Po,mt),M(oy,mt,null),e(mt,sDo),e(mt,Ppe),e(Ppe,lDo),e(mt,iDo),e(mt,td),e(td,dDo),e(td,Bpe),e(Bpe,cDo),e(td,fDo),e(td,VV),e(VV,mDo),e(td,gDo),e(mt,hDo),M(Vb,mt,null),e(Po,pDo),e(Po,oo),M(ry,oo,null),e(oo,_Do),e(oo,Ipe),e(Ipe,uDo),e(oo,bDo),e(oo,Da),e(Da,vDo),e(Da,Npe),e(Npe,FDo),e(Da,TDo),e(Da,qpe),e(qpe,MDo),e(Da,EDo),e(Da,jpe),e(jpe,CDo),e(Da,wDo),e(oo,ADo),e(oo,N),e(N,Xb),e(Xb,Dpe),e(Dpe,LDo),e(Xb,yDo),e(Xb,XV),e(XV,xDo),e(Xb,$Do),e(N,kDo),e(N,zb),e(zb,Gpe),e(Gpe,SDo),e(zb,RDo),e(zb,zV),e(zV,PDo),e(zb,BDo),e(N,IDo),e(N,Qb),e(Qb,Ope),e(Ope,NDo),e(Qb,qDo),e(Qb,QV),e(QV,jDo),e(Qb,DDo),e(N,GDo),e(N,Wb),e(Wb,Vpe),e(Vpe,ODo),e(Wb,VDo),e(Wb,WV),e(WV,XDo),e(Wb,zDo),e(N,QDo),e(N,Hb),e(Hb,Xpe),e(Xpe,WDo),e(Hb,HDo),e(Hb,HV),e(HV,UDo),e(Hb,JDo),e(N,YDo),e(N,Ub),e(Ub,zpe),e(zpe,KDo),e(Ub,ZDo),e(Ub,UV),e(UV,eGo),e(Ub,oGo),e(N,rGo),e(N,Jb),e(Jb,Qpe),e(Qpe,tGo),e(Jb,aGo),e(Jb,JV),e(JV,nGo),e(Jb,sGo),e(N,lGo),e(N,Yb),e(Yb,Wpe),e(Wpe,iGo),e(Yb,dGo),e(Yb,YV),e(YV,cGo),e(Yb,fGo),e(N,mGo),e(N,Kb),e(Kb,Hpe),e(Hpe,gGo),e(Kb,hGo),e(Kb,KV),e(KV,pGo),e(Kb,_Go),e(N,uGo),e(N,Zb),e(Zb,Upe),e(Upe,bGo),e(Zb,vGo),e(Zb,ZV),e(ZV,FGo),e(Zb,TGo),e(N,MGo),e(N,ev),e(ev,Jpe),e(Jpe,EGo),e(ev,CGo),e(ev,eX),e(eX,wGo),e(ev,AGo),e(N,LGo),e(N,ov),e(ov,Ype),e(Ype,yGo),e(ov,xGo),e(ov,oX),e(oX,$Go),e(ov,kGo),e(N,SGo),e(N,rv),e(rv,Kpe),e(Kpe,RGo),e(rv,PGo),e(rv,rX),e(rX,BGo),e(rv,IGo),e(N,NGo),e(N,tv),e(tv,Zpe),e(Zpe,qGo),e(tv,jGo),e(tv,tX),e(tX,DGo),e(tv,GGo),e(N,OGo),e(N,av),e(av,e_e),e(e_e,VGo),e(av,XGo),e(av,aX),e(aX,zGo),e(av,QGo),e(N,WGo),e(N,nv),e(nv,o_e),e(o_e,HGo),e(nv,UGo),e(nv,nX),e(nX,JGo),e(nv,YGo),e(N,KGo),e(N,sv),e(sv,r_e),e(r_e,ZGo),e(sv,eOo),e(sv,sX),e(sX,oOo),e(sv,rOo),e(N,tOo),e(N,lv),e(lv,t_e),e(t_e,aOo),e(lv,nOo),e(lv,lX),e(lX,sOo),e(lv,lOo),e(N,iOo),e(N,iv),e(iv,a_e),e(a_e,dOo),e(iv,cOo),e(iv,iX),e(iX,fOo),e(iv,mOo),e(N,gOo),e(N,dv),e(dv,n_e),e(n_e,hOo),e(dv,pOo),e(dv,dX),e(dX,_Oo),e(dv,uOo),e(N,bOo),e(N,cv),e(cv,s_e),e(s_e,vOo),e(cv,FOo),e(cv,cX),e(cX,TOo),e(cv,MOo),e(N,EOo),e(N,fv),e(fv,l_e),e(l_e,COo),e(fv,wOo),e(fv,fX),e(fX,AOo),e(fv,LOo),e(N,yOo),e(N,mv),e(mv,i_e),e(i_e,xOo),e(mv,$Oo),e(mv,mX),e(mX,kOo),e(mv,SOo),e(N,ROo),e(N,gv),e(gv,d_e),e(d_e,POo),e(gv,BOo),e(gv,gX),e(gX,IOo),e(gv,NOo),e(N,qOo),e(N,hv),e(hv,c_e),e(c_e,jOo),e(hv,DOo),e(hv,hX),e(hX,GOo),e(hv,OOo),e(N,VOo),e(N,pv),e(pv,f_e),e(f_e,XOo),e(pv,zOo),e(pv,pX),e(pX,QOo),e(pv,WOo),e(N,HOo),e(N,_v),e(_v,m_e),e(m_e,UOo),e(_v,JOo),e(_v,_X),e(_X,YOo),e(_v,KOo),e(N,ZOo),e(N,uv),e(uv,g_e),e(g_e,eVo),e(uv,oVo),e(uv,uX),e(uX,rVo),e(uv,tVo),e(N,aVo),e(N,bv),e(bv,h_e),e(h_e,nVo),e(bv,sVo),e(bv,bX),e(bX,lVo),e(bv,iVo),e(N,dVo),e(N,vv),e(vv,p_e),e(p_e,cVo),e(vv,fVo),e(vv,vX),e(vX,mVo),e(vv,gVo),e(N,hVo),e(N,Fv),e(Fv,__e),e(__e,pVo),e(Fv,_Vo),e(Fv,FX),e(FX,uVo),e(Fv,bVo),e(N,vVo),e(N,Tv),e(Tv,u_e),e(u_e,FVo),e(Tv,TVo),e(Tv,TX),e(TX,MVo),e(Tv,EVo),e(N,CVo),e(N,Mv),e(Mv,b_e),e(b_e,wVo),e(Mv,AVo),e(Mv,MX),e(MX,LVo),e(Mv,yVo),e(N,xVo),e(N,Ev),e(Ev,v_e),e(v_e,$Vo),e(Ev,kVo),e(Ev,EX),e(EX,SVo),e(Ev,RVo),e(N,PVo),e(N,Cv),e(Cv,F_e),e(F_e,BVo),e(Cv,IVo),e(Cv,CX),e(CX,NVo),e(Cv,qVo),e(N,jVo),e(N,wv),e(wv,T_e),e(T_e,DVo),e(wv,GVo),e(wv,wX),e(wX,OVo),e(wv,VVo),e(N,XVo),e(N,Av),e(Av,M_e),e(M_e,zVo),e(Av,QVo),e(Av,AX),e(AX,WVo),e(Av,HVo),e(N,UVo),e(N,Lv),e(Lv,E_e),e(E_e,JVo),e(Lv,YVo),e(Lv,LX),e(LX,KVo),e(Lv,ZVo),e(N,eXo),e(N,yv),e(yv,C_e),e(C_e,oXo),e(yv,rXo),e(yv,yX),e(yX,tXo),e(yv,aXo),e(N,nXo),e(N,xv),e(xv,w_e),e(w_e,sXo),e(xv,lXo),e(xv,xX),e(xX,iXo),e(xv,dXo),e(N,cXo),e(N,$v),e($v,A_e),e(A_e,fXo),e($v,mXo),e($v,$X),e($X,gXo),e($v,hXo),e(N,pXo),e(N,kv),e(kv,L_e),e(L_e,_Xo),e(kv,uXo),e(kv,kX),e(kX,bXo),e(kv,vXo),e(N,FXo),e(N,Sv),e(Sv,y_e),e(y_e,TXo),e(Sv,MXo),e(Sv,SX),e(SX,EXo),e(Sv,CXo),e(N,wXo),e(N,Rv),e(Rv,x_e),e(x_e,AXo),e(Rv,LXo),e(Rv,RX),e(RX,yXo),e(Rv,xXo),e(N,$Xo),e(N,Pv),e(Pv,$_e),e($_e,kXo),e(Pv,SXo),e(Pv,PX),e(PX,RXo),e(Pv,PXo),e(N,BXo),e(N,Bv),e(Bv,k_e),e(k_e,IXo),e(Bv,NXo),e(Bv,BX),e(BX,qXo),e(Bv,jXo),e(N,DXo),e(N,Iv),e(Iv,S_e),e(S_e,GXo),e(Iv,OXo),e(Iv,IX),e(IX,VXo),e(Iv,XXo),e(N,zXo),e(N,Nv),e(Nv,R_e),e(R_e,QXo),e(Nv,WXo),e(Nv,NX),e(NX,HXo),e(Nv,UXo),e(N,JXo),e(N,qv),e(qv,P_e),e(P_e,YXo),e(qv,KXo),e(qv,qX),e(qX,ZXo),e(qv,ezo),e(N,ozo),e(N,jv),e(jv,B_e),e(B_e,rzo),e(jv,tzo),e(jv,jX),e(jX,azo),e(jv,nzo),e(oo,szo),e(oo,Dv),e(Dv,lzo),e(Dv,I_e),e(I_e,izo),e(Dv,dzo),e(Dv,N_e),e(N_e,czo),e(oo,fzo),M(Gv,oo,null),b(f,dXe,u),b(f,ad,u),e(ad,Ov),e(Ov,q_e),M(ty,q_e,null),e(ad,mzo),e(ad,j_e),e(j_e,gzo),b(f,cXe,u),b(f,Bo,u),M(ay,Bo,null),e(Bo,hzo),e(Bo,nd),e(nd,pzo),e(nd,DX),e(DX,_zo),e(nd,uzo),e(nd,GX),e(GX,bzo),e(nd,vzo),e(Bo,Fzo),e(Bo,ny),e(ny,Tzo),e(ny,D_e),e(D_e,Mzo),e(ny,Ezo),e(Bo,Czo),e(Bo,gt),M(sy,gt,null),e(gt,wzo),e(gt,G_e),e(G_e,Azo),e(gt,Lzo),e(gt,sd),e(sd,yzo),e(sd,O_e),e(O_e,xzo),e(sd,$zo),e(sd,OX),e(OX,kzo),e(sd,Szo),e(gt,Rzo),M(Vv,gt,null),e(Bo,Pzo),e(Bo,ro),M(ly,ro,null),e(ro,Bzo),e(ro,V_e),e(V_e,Izo),e(ro,Nzo),e(ro,Ga),e(Ga,qzo),e(Ga,X_e),e(X_e,jzo),e(Ga,Dzo),e(Ga,z_e),e(z_e,Gzo),e(Ga,Ozo),e(Ga,Q_e),e(Q_e,Vzo),e(Ga,Xzo),e(ro,zzo),e(ro,Z),e(Z,Xv),e(Xv,W_e),e(W_e,Qzo),e(Xv,Wzo),e(Xv,VX),e(VX,Hzo),e(Xv,Uzo),e(Z,Jzo),e(Z,zv),e(zv,H_e),e(H_e,Yzo),e(zv,Kzo),e(zv,XX),e(XX,Zzo),e(zv,eQo),e(Z,oQo),e(Z,Qv),e(Qv,U_e),e(U_e,rQo),e(Qv,tQo),e(Qv,zX),e(zX,aQo),e(Qv,nQo),e(Z,sQo),e(Z,Wv),e(Wv,J_e),e(J_e,lQo),e(Wv,iQo),e(Wv,QX),e(QX,dQo),e(Wv,cQo),e(Z,fQo),e(Z,Hv),e(Hv,Y_e),e(Y_e,mQo),e(Hv,gQo),e(Hv,WX),e(WX,hQo),e(Hv,pQo),e(Z,_Qo),e(Z,Uv),e(Uv,K_e),e(K_e,uQo),e(Uv,bQo),e(Uv,HX),e(HX,vQo),e(Uv,FQo),e(Z,TQo),e(Z,Jv),e(Jv,Z_e),e(Z_e,MQo),e(Jv,EQo),e(Jv,UX),e(UX,CQo),e(Jv,wQo),e(Z,AQo),e(Z,Yv),e(Yv,eue),e(eue,LQo),e(Yv,yQo),e(Yv,JX),e(JX,xQo),e(Yv,$Qo),e(Z,kQo),e(Z,Kv),e(Kv,oue),e(oue,SQo),e(Kv,RQo),e(Kv,YX),e(YX,PQo),e(Kv,BQo),e(Z,IQo),e(Z,Zv),e(Zv,rue),e(rue,NQo),e(Zv,qQo),e(Zv,KX),e(KX,jQo),e(Zv,DQo),e(Z,GQo),e(Z,eF),e(eF,tue),e(tue,OQo),e(eF,VQo),e(eF,ZX),e(ZX,XQo),e(eF,zQo),e(Z,QQo),e(Z,oF),e(oF,aue),e(aue,WQo),e(oF,HQo),e(oF,ez),e(ez,UQo),e(oF,JQo),e(Z,YQo),e(Z,rF),e(rF,nue),e(nue,KQo),e(rF,ZQo),e(rF,oz),e(oz,eWo),e(rF,oWo),e(Z,rWo),e(Z,tF),e(tF,sue),e(sue,tWo),e(tF,aWo),e(tF,rz),e(rz,nWo),e(tF,sWo),e(Z,lWo),e(Z,aF),e(aF,lue),e(lue,iWo),e(aF,dWo),e(aF,tz),e(tz,cWo),e(aF,fWo),e(Z,mWo),e(Z,nF),e(nF,iue),e(iue,gWo),e(nF,hWo),e(nF,az),e(az,pWo),e(nF,_Wo),e(Z,uWo),e(Z,sF),e(sF,due),e(due,bWo),e(sF,vWo),e(sF,nz),e(nz,FWo),e(sF,TWo),e(Z,MWo),e(Z,lF),e(lF,cue),e(cue,EWo),e(lF,CWo),e(lF,sz),e(sz,wWo),e(lF,AWo),e(Z,LWo),e(Z,iF),e(iF,fue),e(fue,yWo),e(iF,xWo),e(iF,lz),e(lz,$Wo),e(iF,kWo),e(Z,SWo),e(Z,dF),e(dF,mue),e(mue,RWo),e(dF,PWo),e(dF,iz),e(iz,BWo),e(dF,IWo),e(Z,NWo),e(Z,cF),e(cF,gue),e(gue,qWo),e(cF,jWo),e(cF,dz),e(dz,DWo),e(cF,GWo),e(Z,OWo),e(Z,fF),e(fF,hue),e(hue,VWo),e(fF,XWo),e(fF,cz),e(cz,zWo),e(fF,QWo),e(Z,WWo),e(Z,mF),e(mF,pue),e(pue,HWo),e(mF,UWo),e(mF,fz),e(fz,JWo),e(mF,YWo),e(Z,KWo),e(Z,gF),e(gF,_ue),e(_ue,ZWo),e(gF,eHo),e(gF,mz),e(mz,oHo),e(gF,rHo),e(Z,tHo),e(Z,hF),e(hF,uue),e(uue,aHo),e(hF,nHo),e(hF,gz),e(gz,sHo),e(hF,lHo),e(Z,iHo),e(Z,pF),e(pF,bue),e(bue,dHo),e(pF,cHo),e(pF,hz),e(hz,fHo),e(pF,mHo),e(Z,gHo),e(Z,_F),e(_F,vue),e(vue,hHo),e(_F,pHo),e(_F,pz),e(pz,_Ho),e(_F,uHo),e(Z,bHo),e(Z,uF),e(uF,Fue),e(Fue,vHo),e(uF,FHo),e(uF,_z),e(_z,THo),e(uF,MHo),e(Z,EHo),e(Z,bF),e(bF,Tue),e(Tue,CHo),e(bF,wHo),e(bF,uz),e(uz,AHo),e(bF,LHo),e(Z,yHo),e(Z,vF),e(vF,Mue),e(Mue,xHo),e(vF,$Ho),e(vF,bz),e(bz,kHo),e(vF,SHo),e(ro,RHo),e(ro,FF),e(FF,PHo),e(FF,Eue),e(Eue,BHo),e(FF,IHo),e(FF,Cue),e(Cue,NHo),e(ro,qHo),M(TF,ro,null),b(f,fXe,u),b(f,ld,u),e(ld,MF),e(MF,wue),M(iy,wue,null),e(ld,jHo),e(ld,Aue),e(Aue,DHo),b(f,mXe,u),b(f,Io,u),M(dy,Io,null),e(Io,GHo),e(Io,id),e(id,OHo),e(id,vz),e(vz,VHo),e(id,XHo),e(id,Fz),e(Fz,zHo),e(id,QHo),e(Io,WHo),e(Io,cy),e(cy,HHo),e(cy,Lue),e(Lue,UHo),e(cy,JHo),e(Io,YHo),e(Io,ht),M(fy,ht,null),e(ht,KHo),e(ht,yue),e(yue,ZHo),e(ht,eUo),e(ht,dd),e(dd,oUo),e(dd,xue),e(xue,rUo),e(dd,tUo),e(dd,Tz),e(Tz,aUo),e(dd,nUo),e(ht,sUo),M(EF,ht,null),e(Io,lUo),e(Io,to),M(my,to,null),e(to,iUo),e(to,$ue),e($ue,dUo),e(to,cUo),e(to,Oa),e(Oa,fUo),e(Oa,kue),e(kue,mUo),e(Oa,gUo),e(Oa,Sue),e(Sue,hUo),e(Oa,pUo),e(Oa,Rue),e(Rue,_Uo),e(Oa,uUo),e(to,bUo),e(to,No),e(No,CF),e(CF,Pue),e(Pue,vUo),e(CF,FUo),e(CF,Mz),e(Mz,TUo),e(CF,MUo),e(No,EUo),e(No,wF),e(wF,Bue),e(Bue,CUo),e(wF,wUo),e(wF,Ez),e(Ez,AUo),e(wF,LUo),e(No,yUo),e(No,AF),e(AF,Iue),e(Iue,xUo),e(AF,$Uo),e(AF,Cz),e(Cz,kUo),e(AF,SUo),e(No,RUo),e(No,LF),e(LF,Nue),e(Nue,PUo),e(LF,BUo),e(LF,wz),e(wz,IUo),e(LF,NUo),e(No,qUo),e(No,yF),e(yF,que),e(que,jUo),e(yF,DUo),e(yF,Az),e(Az,GUo),e(yF,OUo),e(No,VUo),e(No,xF),e(xF,jue),e(jue,XUo),e(xF,zUo),e(xF,Lz),e(Lz,QUo),e(xF,WUo),e(to,HUo),e(to,$F),e($F,UUo),e($F,Due),e(Due,JUo),e($F,YUo),e($F,Gue),e(Gue,KUo),e(to,ZUo),M(kF,to,null),b(f,gXe,u),b(f,cd,u),e(cd,SF),e(SF,Oue),M(gy,Oue,null),e(cd,eJo),e(cd,Vue),e(Vue,oJo),b(f,hXe,u),b(f,qo,u),M(hy,qo,null),e(qo,rJo),e(qo,fd),e(fd,tJo),e(fd,yz),e(yz,aJo),e(fd,nJo),e(fd,xz),e(xz,sJo),e(fd,lJo),e(qo,iJo),e(qo,py),e(py,dJo),e(py,Xue),e(Xue,cJo),e(py,fJo),e(qo,mJo),e(qo,pt),M(_y,pt,null),e(pt,gJo),e(pt,zue),e(zue,hJo),e(pt,pJo),e(pt,md),e(md,_Jo),e(md,Que),e(Que,uJo),e(md,bJo),e(md,$z),e($z,vJo),e(md,FJo),e(pt,TJo),M(RF,pt,null),e(qo,MJo),e(qo,ao),M(uy,ao,null),e(ao,EJo),e(ao,Wue),e(Wue,CJo),e(ao,wJo),e(ao,Va),e(Va,AJo),e(Va,Hue),e(Hue,LJo),e(Va,yJo),e(Va,Uue),e(Uue,xJo),e(Va,$Jo),e(Va,Jue),e(Jue,kJo),e(Va,SJo),e(ao,RJo),e(ao,U),e(U,PF),e(PF,Yue),e(Yue,PJo),e(PF,BJo),e(PF,kz),e(kz,IJo),e(PF,NJo),e(U,qJo),e(U,BF),e(BF,Kue),e(Kue,jJo),e(BF,DJo),e(BF,Sz),e(Sz,GJo),e(BF,OJo),e(U,VJo),e(U,IF),e(IF,Zue),e(Zue,XJo),e(IF,zJo),e(IF,Rz),e(Rz,QJo),e(IF,WJo),e(U,HJo),e(U,NF),e(NF,e1e),e(e1e,UJo),e(NF,JJo),e(NF,Pz),e(Pz,YJo),e(NF,KJo),e(U,ZJo),e(U,qF),e(qF,o1e),e(o1e,eYo),e(qF,oYo),e(qF,Bz),e(Bz,rYo),e(qF,tYo),e(U,aYo),e(U,jF),e(jF,r1e),e(r1e,nYo),e(jF,sYo),e(jF,Iz),e(Iz,lYo),e(jF,iYo),e(U,dYo),e(U,DF),e(DF,t1e),e(t1e,cYo),e(DF,fYo),e(DF,Nz),e(Nz,mYo),e(DF,gYo),e(U,hYo),e(U,GF),e(GF,a1e),e(a1e,pYo),e(GF,_Yo),e(GF,qz),e(qz,uYo),e(GF,bYo),e(U,vYo),e(U,OF),e(OF,n1e),e(n1e,FYo),e(OF,TYo),e(OF,jz),e(jz,MYo),e(OF,EYo),e(U,CYo),e(U,VF),e(VF,s1e),e(s1e,wYo),e(VF,AYo),e(VF,Dz),e(Dz,LYo),e(VF,yYo),e(U,xYo),e(U,XF),e(XF,l1e),e(l1e,$Yo),e(XF,kYo),e(XF,Gz),e(Gz,SYo),e(XF,RYo),e(U,PYo),e(U,zF),e(zF,i1e),e(i1e,BYo),e(zF,IYo),e(zF,Oz),e(Oz,NYo),e(zF,qYo),e(U,jYo),e(U,QF),e(QF,d1e),e(d1e,DYo),e(QF,GYo),e(QF,Vz),e(Vz,OYo),e(QF,VYo),e(U,XYo),e(U,WF),e(WF,c1e),e(c1e,zYo),e(WF,QYo),e(WF,Xz),e(Xz,WYo),e(WF,HYo),e(U,UYo),e(U,HF),e(HF,f1e),e(f1e,JYo),e(HF,YYo),e(HF,zz),e(zz,KYo),e(HF,ZYo),e(U,eKo),e(U,UF),e(UF,m1e),e(m1e,oKo),e(UF,rKo),e(UF,Qz),e(Qz,tKo),e(UF,aKo),e(U,nKo),e(U,JF),e(JF,g1e),e(g1e,sKo),e(JF,lKo),e(JF,Wz),e(Wz,iKo),e(JF,dKo),e(U,cKo),e(U,YF),e(YF,h1e),e(h1e,fKo),e(YF,mKo),e(YF,Hz),e(Hz,gKo),e(YF,hKo),e(U,pKo),e(U,KF),e(KF,p1e),e(p1e,_Ko),e(KF,uKo),e(KF,Uz),e(Uz,bKo),e(KF,vKo),e(U,FKo),e(U,ZF),e(ZF,_1e),e(_1e,TKo),e(ZF,MKo),e(ZF,Jz),e(Jz,EKo),e(ZF,CKo),e(U,wKo),e(U,eT),e(eT,u1e),e(u1e,AKo),e(eT,LKo),e(eT,Yz),e(Yz,yKo),e(eT,xKo),e(U,$Ko),e(U,oT),e(oT,b1e),e(b1e,kKo),e(oT,SKo),e(oT,Kz),e(Kz,RKo),e(oT,PKo),e(U,BKo),e(U,rT),e(rT,v1e),e(v1e,IKo),e(rT,NKo),e(rT,Zz),e(Zz,qKo),e(rT,jKo),e(U,DKo),e(U,tT),e(tT,F1e),e(F1e,GKo),e(tT,OKo),e(tT,eQ),e(eQ,VKo),e(tT,XKo),e(U,zKo),e(U,aT),e(aT,T1e),e(T1e,QKo),e(aT,WKo),e(aT,oQ),e(oQ,HKo),e(aT,UKo),e(U,JKo),e(U,nT),e(nT,M1e),e(M1e,YKo),e(nT,KKo),e(nT,rQ),e(rQ,ZKo),e(nT,eZo),e(U,oZo),e(U,sT),e(sT,E1e),e(E1e,rZo),e(sT,tZo),e(sT,tQ),e(tQ,aZo),e(sT,nZo),e(U,sZo),e(U,lT),e(lT,C1e),e(C1e,lZo),e(lT,iZo),e(lT,aQ),e(aQ,dZo),e(lT,cZo),e(U,fZo),e(U,iT),e(iT,w1e),e(w1e,mZo),e(iT,gZo),e(iT,nQ),e(nQ,hZo),e(iT,pZo),e(U,_Zo),e(U,dT),e(dT,A1e),e(A1e,uZo),e(dT,bZo),e(dT,sQ),e(sQ,vZo),e(dT,FZo),e(U,TZo),e(U,cT),e(cT,L1e),e(L1e,MZo),e(cT,EZo),e(cT,lQ),e(lQ,CZo),e(cT,wZo),e(U,AZo),e(U,fT),e(fT,y1e),e(y1e,LZo),e(fT,yZo),e(fT,iQ),e(iQ,xZo),e(fT,$Zo),e(U,kZo),e(U,mT),e(mT,x1e),e(x1e,SZo),e(mT,RZo),e(mT,dQ),e(dQ,PZo),e(mT,BZo),e(U,IZo),e(U,gT),e(gT,$1e),e($1e,NZo),e(gT,qZo),e(gT,cQ),e(cQ,jZo),e(gT,DZo),e(U,GZo),e(U,hT),e(hT,k1e),e(k1e,OZo),e(hT,VZo),e(hT,fQ),e(fQ,XZo),e(hT,zZo),e(U,QZo),e(U,pT),e(pT,S1e),e(S1e,WZo),e(pT,HZo),e(pT,mQ),e(mQ,UZo),e(pT,JZo),e(ao,YZo),e(ao,_T),e(_T,KZo),e(_T,R1e),e(R1e,ZZo),e(_T,eer),e(_T,P1e),e(P1e,oer),e(ao,rer),M(uT,ao,null),b(f,pXe,u),b(f,gd,u),e(gd,bT),e(bT,B1e),M(by,B1e,null),e(gd,ter),e(gd,I1e),e(I1e,aer),b(f,_Xe,u),b(f,jo,u),M(vy,jo,null),e(jo,ner),e(jo,hd),e(hd,ser),e(hd,gQ),e(gQ,ler),e(hd,ier),e(hd,hQ),e(hQ,der),e(hd,cer),e(jo,fer),e(jo,Fy),e(Fy,mer),e(Fy,N1e),e(N1e,ger),e(Fy,her),e(jo,per),e(jo,_t),M(Ty,_t,null),e(_t,_er),e(_t,q1e),e(q1e,uer),e(_t,ber),e(_t,pd),e(pd,ver),e(pd,j1e),e(j1e,Fer),e(pd,Ter),e(pd,pQ),e(pQ,Mer),e(pd,Eer),e(_t,Cer),M(vT,_t,null),e(jo,wer),e(jo,no),M(My,no,null),e(no,Aer),e(no,D1e),e(D1e,Ler),e(no,yer),e(no,Xa),e(Xa,xer),e(Xa,G1e),e(G1e,$er),e(Xa,ker),e(Xa,O1e),e(O1e,Ser),e(Xa,Rer),e(Xa,V1e),e(V1e,Per),e(Xa,Ber),e(no,Ier),e(no,V),e(V,FT),e(FT,X1e),e(X1e,Ner),e(FT,qer),e(FT,_Q),e(_Q,jer),e(FT,Der),e(V,Ger),e(V,TT),e(TT,z1e),e(z1e,Oer),e(TT,Ver),e(TT,uQ),e(uQ,Xer),e(TT,zer),e(V,Qer),e(V,MT),e(MT,Q1e),e(Q1e,Wer),e(MT,Her),e(MT,bQ),e(bQ,Uer),e(MT,Jer),e(V,Yer),e(V,ET),e(ET,W1e),e(W1e,Ker),e(ET,Zer),e(ET,vQ),e(vQ,eor),e(ET,oor),e(V,ror),e(V,CT),e(CT,H1e),e(H1e,tor),e(CT,aor),e(CT,FQ),e(FQ,nor),e(CT,sor),e(V,lor),e(V,wT),e(wT,U1e),e(U1e,ior),e(wT,dor),e(wT,TQ),e(TQ,cor),e(wT,mor),e(V,gor),e(V,AT),e(AT,J1e),e(J1e,hor),e(AT,por),e(AT,MQ),e(MQ,_or),e(AT,uor),e(V,bor),e(V,LT),e(LT,Y1e),e(Y1e,vor),e(LT,For),e(LT,EQ),e(EQ,Tor),e(LT,Mor),e(V,Eor),e(V,yT),e(yT,K1e),e(K1e,Cor),e(yT,wor),e(yT,CQ),e(CQ,Aor),e(yT,Lor),e(V,yor),e(V,xT),e(xT,Z1e),e(Z1e,xor),e(xT,$or),e(xT,wQ),e(wQ,kor),e(xT,Sor),e(V,Ror),e(V,$T),e($T,e2e),e(e2e,Por),e($T,Bor),e($T,AQ),e(AQ,Ior),e($T,Nor),e(V,qor),e(V,kT),e(kT,o2e),e(o2e,jor),e(kT,Dor),e(kT,LQ),e(LQ,Gor),e(kT,Oor),e(V,Vor),e(V,ST),e(ST,r2e),e(r2e,Xor),e(ST,zor),e(ST,yQ),e(yQ,Qor),e(ST,Wor),e(V,Hor),e(V,RT),e(RT,t2e),e(t2e,Uor),e(RT,Jor),e(RT,xQ),e(xQ,Yor),e(RT,Kor),e(V,Zor),e(V,PT),e(PT,a2e),e(a2e,err),e(PT,orr),e(PT,$Q),e($Q,rrr),e(PT,trr),e(V,arr),e(V,BT),e(BT,n2e),e(n2e,nrr),e(BT,srr),e(BT,kQ),e(kQ,lrr),e(BT,irr),e(V,drr),e(V,IT),e(IT,s2e),e(s2e,crr),e(IT,frr),e(IT,SQ),e(SQ,mrr),e(IT,grr),e(V,hrr),e(V,NT),e(NT,l2e),e(l2e,prr),e(NT,_rr),e(NT,RQ),e(RQ,urr),e(NT,brr),e(V,vrr),e(V,qT),e(qT,i2e),e(i2e,Frr),e(qT,Trr),e(qT,PQ),e(PQ,Mrr),e(qT,Err),e(V,Crr),e(V,jT),e(jT,d2e),e(d2e,wrr),e(jT,Arr),e(jT,BQ),e(BQ,Lrr),e(jT,yrr),e(V,xrr),e(V,DT),e(DT,c2e),e(c2e,$rr),e(DT,krr),e(DT,IQ),e(IQ,Srr),e(DT,Rrr),e(V,Prr),e(V,GT),e(GT,f2e),e(f2e,Brr),e(GT,Irr),e(GT,NQ),e(NQ,Nrr),e(GT,qrr),e(V,jrr),e(V,OT),e(OT,m2e),e(m2e,Drr),e(OT,Grr),e(OT,qQ),e(qQ,Orr),e(OT,Vrr),e(V,Xrr),e(V,VT),e(VT,g2e),e(g2e,zrr),e(VT,Qrr),e(VT,jQ),e(jQ,Wrr),e(VT,Hrr),e(V,Urr),e(V,XT),e(XT,h2e),e(h2e,Jrr),e(XT,Yrr),e(XT,DQ),e(DQ,Krr),e(XT,Zrr),e(V,etr),e(V,zT),e(zT,p2e),e(p2e,otr),e(zT,rtr),e(zT,GQ),e(GQ,ttr),e(zT,atr),e(V,ntr),e(V,QT),e(QT,_2e),e(_2e,str),e(QT,ltr),e(QT,OQ),e(OQ,itr),e(QT,dtr),e(V,ctr),e(V,WT),e(WT,u2e),e(u2e,ftr),e(WT,mtr),e(WT,VQ),e(VQ,gtr),e(WT,htr),e(V,ptr),e(V,HT),e(HT,b2e),e(b2e,_tr),e(HT,utr),e(HT,XQ),e(XQ,btr),e(HT,vtr),e(V,Ftr),e(V,UT),e(UT,v2e),e(v2e,Ttr),e(UT,Mtr),e(UT,zQ),e(zQ,Etr),e(UT,Ctr),e(V,wtr),e(V,JT),e(JT,F2e),e(F2e,Atr),e(JT,Ltr),e(JT,QQ),e(QQ,ytr),e(JT,xtr),e(V,$tr),e(V,YT),e(YT,T2e),e(T2e,ktr),e(YT,Str),e(YT,WQ),e(WQ,Rtr),e(YT,Ptr),e(V,Btr),e(V,KT),e(KT,M2e),e(M2e,Itr),e(KT,Ntr),e(KT,HQ),e(HQ,qtr),e(KT,jtr),e(V,Dtr),e(V,ZT),e(ZT,E2e),e(E2e,Gtr),e(ZT,Otr),e(ZT,UQ),e(UQ,Vtr),e(ZT,Xtr),e(V,ztr),e(V,e7),e(e7,C2e),e(C2e,Qtr),e(e7,Wtr),e(e7,JQ),e(JQ,Htr),e(e7,Utr),e(V,Jtr),e(V,o7),e(o7,w2e),e(w2e,Ytr),e(o7,Ktr),e(o7,YQ),e(YQ,Ztr),e(o7,ear),e(V,oar),e(V,r7),e(r7,A2e),e(A2e,rar),e(r7,tar),e(r7,KQ),e(KQ,aar),e(r7,nar),e(V,sar),e(V,t7),e(t7,L2e),e(L2e,lar),e(t7,iar),e(t7,ZQ),e(ZQ,dar),e(t7,car),e(V,far),e(V,a7),e(a7,y2e),e(y2e,mar),e(a7,gar),e(a7,eW),e(eW,har),e(a7,par),e(V,_ar),e(V,n7),e(n7,x2e),e(x2e,uar),e(n7,bar),e(n7,oW),e(oW,Far),e(n7,Tar),e(V,Mar),e(V,s7),e(s7,$2e),e($2e,Ear),e(s7,Car),e(s7,rW),e(rW,war),e(s7,Aar),e(V,Lar),e(V,l7),e(l7,k2e),e(k2e,yar),e(l7,xar),e(l7,tW),e(tW,$ar),e(l7,kar),e(no,Sar),e(no,i7),e(i7,Rar),e(i7,S2e),e(S2e,Par),e(i7,Bar),e(i7,R2e),e(R2e,Iar),e(no,Nar),M(d7,no,null),b(f,uXe,u),b(f,_d,u),e(_d,c7),e(c7,P2e),M(Ey,P2e,null),e(_d,qar),e(_d,B2e),e(B2e,jar),b(f,bXe,u),b(f,Do,u),M(Cy,Do,null),e(Do,Dar),e(Do,ud),e(ud,Gar),e(ud,aW),e(aW,Oar),e(ud,Var),e(ud,nW),e(nW,Xar),e(ud,zar),e(Do,Qar),e(Do,wy),e(wy,War),e(wy,I2e),e(I2e,Har),e(wy,Uar),e(Do,Jar),e(Do,ut),M(Ay,ut,null),e(ut,Yar),e(ut,N2e),e(N2e,Kar),e(ut,Zar),e(ut,bd),e(bd,enr),e(bd,q2e),e(q2e,onr),e(bd,rnr),e(bd,sW),e(sW,tnr),e(bd,anr),e(ut,nnr),M(f7,ut,null),e(Do,snr),e(Do,so),M(Ly,so,null),e(so,lnr),e(so,j2e),e(j2e,inr),e(so,dnr),e(so,za),e(za,cnr),e(za,D2e),e(D2e,fnr),e(za,mnr),e(za,G2e),e(G2e,gnr),e(za,hnr),e(za,O2e),e(O2e,pnr),e(za,_nr),e(so,unr),e(so,V2e),e(V2e,m7),e(m7,X2e),e(X2e,bnr),e(m7,vnr),e(m7,lW),e(lW,Fnr),e(m7,Tnr),e(so,Mnr),e(so,g7),e(g7,Enr),e(g7,z2e),e(z2e,Cnr),e(g7,wnr),e(g7,Q2e),e(Q2e,Anr),e(so,Lnr),M(h7,so,null),b(f,vXe,u),b(f,vd,u),e(vd,p7),e(p7,W2e),M(yy,W2e,null),e(vd,ynr),e(vd,H2e),e(H2e,xnr),b(f,FXe,u),b(f,Go,u),M(xy,Go,null),e(Go,$nr),e(Go,Fd),e(Fd,knr),e(Fd,iW),e(iW,Snr),e(Fd,Rnr),e(Fd,dW),e(dW,Pnr),e(Fd,Bnr),e(Go,Inr),e(Go,$y),e($y,Nnr),e($y,U2e),e(U2e,qnr),e($y,jnr),e(Go,Dnr),e(Go,bt),M(ky,bt,null),e(bt,Gnr),e(bt,J2e),e(J2e,Onr),e(bt,Vnr),e(bt,Td),e(Td,Xnr),e(Td,Y2e),e(Y2e,znr),e(Td,Qnr),e(Td,cW),e(cW,Wnr),e(Td,Hnr),e(bt,Unr),M(_7,bt,null),e(Go,Jnr),e(Go,lo),M(Sy,lo,null),e(lo,Ynr),e(lo,K2e),e(K2e,Knr),e(lo,Znr),e(lo,Qa),e(Qa,esr),e(Qa,Z2e),e(Z2e,osr),e(Qa,rsr),e(Qa,ebe),e(ebe,tsr),e(Qa,asr),e(Qa,obe),e(obe,nsr),e(Qa,ssr),e(lo,lsr),e(lo,ve),e(ve,u7),e(u7,rbe),e(rbe,isr),e(u7,dsr),e(u7,fW),e(fW,csr),e(u7,fsr),e(ve,msr),e(ve,b7),e(b7,tbe),e(tbe,gsr),e(b7,hsr),e(b7,mW),e(mW,psr),e(b7,_sr),e(ve,usr),e(ve,v7),e(v7,abe),e(abe,bsr),e(v7,vsr),e(v7,gW),e(gW,Fsr),e(v7,Tsr),e(ve,Msr),e(ve,F7),e(F7,nbe),e(nbe,Esr),e(F7,Csr),e(F7,hW),e(hW,wsr),e(F7,Asr),e(ve,Lsr),e(ve,Ws),e(Ws,sbe),e(sbe,ysr),e(Ws,xsr),e(Ws,pW),e(pW,$sr),e(Ws,ksr),e(Ws,_W),e(_W,Ssr),e(Ws,Rsr),e(ve,Psr),e(ve,T7),e(T7,lbe),e(lbe,Bsr),e(T7,Isr),e(T7,uW),e(uW,Nsr),e(T7,qsr),e(ve,jsr),e(ve,Hs),e(Hs,ibe),e(ibe,Dsr),e(Hs,Gsr),e(Hs,bW),e(bW,Osr),e(Hs,Vsr),e(Hs,vW),e(vW,Xsr),e(Hs,zsr),e(ve,Qsr),e(ve,M7),e(M7,dbe),e(dbe,Wsr),e(M7,Hsr),e(M7,FW),e(FW,Usr),e(M7,Jsr),e(ve,Ysr),e(ve,vt),e(vt,cbe),e(cbe,Ksr),e(vt,Zsr),e(vt,TW),e(TW,elr),e(vt,olr),e(vt,MW),e(MW,rlr),e(vt,tlr),e(vt,EW),e(EW,alr),e(vt,nlr),e(ve,slr),e(ve,E7),e(E7,fbe),e(fbe,llr),e(E7,ilr),e(E7,CW),e(CW,dlr),e(E7,clr),e(ve,flr),e(ve,C7),e(C7,mbe),e(mbe,mlr),e(C7,glr),e(C7,wW),e(wW,hlr),e(C7,plr),e(ve,_lr),e(ve,w7),e(w7,gbe),e(gbe,ulr),e(w7,blr),e(w7,AW),e(AW,vlr),e(w7,Flr),e(ve,Tlr),e(ve,A7),e(A7,hbe),e(hbe,Mlr),e(A7,Elr),e(A7,LW),e(LW,Clr),e(A7,wlr),e(ve,Alr),e(ve,L7),e(L7,pbe),e(pbe,Llr),e(L7,ylr),e(L7,yW),e(yW,xlr),e(L7,$lr),e(ve,klr),e(ve,y7),e(y7,_be),e(_be,Slr),e(y7,Rlr),e(y7,xW),e(xW,Plr),e(y7,Blr),e(ve,Ilr),e(ve,x7),e(x7,ube),e(ube,Nlr),e(x7,qlr),e(x7,$W),e($W,jlr),e(x7,Dlr),e(lo,Glr),e(lo,$7),e($7,Olr),e($7,bbe),e(bbe,Vlr),e($7,Xlr),e($7,vbe),e(vbe,zlr),e(lo,Qlr),M(k7,lo,null),b(f,TXe,u),b(f,Md,u),e(Md,S7),e(S7,Fbe),M(Ry,Fbe,null),e(Md,Wlr),e(Md,Tbe),e(Tbe,Hlr),b(f,MXe,u),b(f,Oo,u),M(Py,Oo,null),e(Oo,Ulr),e(Oo,Ed),e(Ed,Jlr),e(Ed,kW),e(kW,Ylr),e(Ed,Klr),e(Ed,SW),e(SW,Zlr),e(Ed,eir),e(Oo,oir),e(Oo,By),e(By,rir),e(By,Mbe),e(Mbe,tir),e(By,air),e(Oo,nir),e(Oo,Ft),M(Iy,Ft,null),e(Ft,sir),e(Ft,Ebe),e(Ebe,lir),e(Ft,iir),e(Ft,Cd),e(Cd,dir),e(Cd,Cbe),e(Cbe,cir),e(Cd,fir),e(Cd,RW),e(RW,mir),e(Cd,gir),e(Ft,hir),M(R7,Ft,null),e(Oo,pir),e(Oo,io),M(Ny,io,null),e(io,_ir),e(io,wbe),e(wbe,uir),e(io,bir),e(io,Wa),e(Wa,vir),e(Wa,Abe),e(Abe,Fir),e(Wa,Tir),e(Wa,Lbe),e(Lbe,Mir),e(Wa,Eir),e(Wa,ybe),e(ybe,Cir),e(Wa,wir),e(io,Air),e(io,xbe),e(xbe,P7),e(P7,$be),e($be,Lir),e(P7,yir),e(P7,PW),e(PW,xir),e(P7,$ir),e(io,kir),e(io,B7),e(B7,Sir),e(B7,kbe),e(kbe,Rir),e(B7,Pir),e(B7,Sbe),e(Sbe,Bir),e(io,Iir),M(I7,io,null),b(f,EXe,u),b(f,wd,u),e(wd,N7),e(N7,Rbe),M(qy,Rbe,null),e(wd,Nir),e(wd,Pbe),e(Pbe,qir),b(f,CXe,u),b(f,Vo,u),M(jy,Vo,null),e(Vo,jir),e(Vo,Ad),e(Ad,Dir),e(Ad,BW),e(BW,Gir),e(Ad,Oir),e(Ad,IW),e(IW,Vir),e(Ad,Xir),e(Vo,zir),e(Vo,Dy),e(Dy,Qir),e(Dy,Bbe),e(Bbe,Wir),e(Dy,Hir),e(Vo,Uir),e(Vo,Tt),M(Gy,Tt,null),e(Tt,Jir),e(Tt,Ibe),e(Ibe,Yir),e(Tt,Kir),e(Tt,Ld),e(Ld,Zir),e(Ld,Nbe),e(Nbe,edr),e(Ld,odr),e(Ld,NW),e(NW,rdr),e(Ld,tdr),e(Tt,adr),M(q7,Tt,null),e(Vo,ndr),e(Vo,co),M(Oy,co,null),e(co,sdr),e(co,qbe),e(qbe,ldr),e(co,idr),e(co,Ha),e(Ha,ddr),e(Ha,jbe),e(jbe,cdr),e(Ha,fdr),e(Ha,Dbe),e(Dbe,mdr),e(Ha,gdr),e(Ha,Gbe),e(Gbe,hdr),e(Ha,pdr),e(co,_dr),e(co,Obe),e(Obe,j7),e(j7,Vbe),e(Vbe,udr),e(j7,bdr),e(j7,qW),e(qW,vdr),e(j7,Fdr),e(co,Tdr),e(co,D7),e(D7,Mdr),e(D7,Xbe),e(Xbe,Edr),e(D7,Cdr),e(D7,zbe),e(zbe,wdr),e(co,Adr),M(G7,co,null),b(f,wXe,u),b(f,yd,u),e(yd,O7),e(O7,Qbe),M(Vy,Qbe,null),e(yd,Ldr),e(yd,Wbe),e(Wbe,ydr),b(f,AXe,u),b(f,Xo,u),M(Xy,Xo,null),e(Xo,xdr),e(Xo,xd),e(xd,$dr),e(xd,jW),e(jW,kdr),e(xd,Sdr),e(xd,DW),e(DW,Rdr),e(xd,Pdr),e(Xo,Bdr),e(Xo,zy),e(zy,Idr),e(zy,Hbe),e(Hbe,Ndr),e(zy,qdr),e(Xo,jdr),e(Xo,Mt),M(Qy,Mt,null),e(Mt,Ddr),e(Mt,Ube),e(Ube,Gdr),e(Mt,Odr),e(Mt,$d),e($d,Vdr),e($d,Jbe),e(Jbe,Xdr),e($d,zdr),e($d,GW),e(GW,Qdr),e($d,Wdr),e(Mt,Hdr),M(V7,Mt,null),e(Xo,Udr),e(Xo,fo),M(Wy,fo,null),e(fo,Jdr),e(fo,Ybe),e(Ybe,Ydr),e(fo,Kdr),e(fo,Ua),e(Ua,Zdr),e(Ua,Kbe),e(Kbe,ecr),e(Ua,ocr),e(Ua,Zbe),e(Zbe,rcr),e(Ua,tcr),e(Ua,eve),e(eve,acr),e(Ua,ncr),e(fo,scr),e(fo,Pe),e(Pe,X7),e(X7,ove),e(ove,lcr),e(X7,icr),e(X7,OW),e(OW,dcr),e(X7,ccr),e(Pe,fcr),e(Pe,z7),e(z7,rve),e(rve,mcr),e(z7,gcr),e(z7,VW),e(VW,hcr),e(z7,pcr),e(Pe,_cr),e(Pe,Q7),e(Q7,tve),e(tve,ucr),e(Q7,bcr),e(Q7,XW),e(XW,vcr),e(Q7,Fcr),e(Pe,Tcr),e(Pe,W7),e(W7,ave),e(ave,Mcr),e(W7,Ecr),e(W7,zW),e(zW,Ccr),e(W7,wcr),e(Pe,Acr),e(Pe,H7),e(H7,nve),e(nve,Lcr),e(H7,ycr),e(H7,QW),e(QW,xcr),e(H7,$cr),e(Pe,kcr),e(Pe,U7),e(U7,sve),e(sve,Scr),e(U7,Rcr),e(U7,WW),e(WW,Pcr),e(U7,Bcr),e(Pe,Icr),e(Pe,J7),e(J7,lve),e(lve,Ncr),e(J7,qcr),e(J7,HW),e(HW,jcr),e(J7,Dcr),e(Pe,Gcr),e(Pe,Y7),e(Y7,ive),e(ive,Ocr),e(Y7,Vcr),e(Y7,UW),e(UW,Xcr),e(Y7,zcr),e(Pe,Qcr),e(Pe,K7),e(K7,dve),e(dve,Wcr),e(K7,Hcr),e(K7,JW),e(JW,Ucr),e(K7,Jcr),e(fo,Ycr),e(fo,Z7),e(Z7,Kcr),e(Z7,cve),e(cve,Zcr),e(Z7,efr),e(Z7,fve),e(fve,ofr),e(fo,rfr),M(e8,fo,null),b(f,LXe,u),b(f,kd,u),e(kd,o8),e(o8,mve),M(Hy,mve,null),e(kd,tfr),e(kd,gve),e(gve,afr),b(f,yXe,u),b(f,zo,u),M(Uy,zo,null),e(zo,nfr),e(zo,Sd),e(Sd,sfr),e(Sd,YW),e(YW,lfr),e(Sd,ifr),e(Sd,KW),e(KW,dfr),e(Sd,cfr),e(zo,ffr),e(zo,Jy),e(Jy,mfr),e(Jy,hve),e(hve,gfr),e(Jy,hfr),e(zo,pfr),e(zo,Et),M(Yy,Et,null),e(Et,_fr),e(Et,pve),e(pve,ufr),e(Et,bfr),e(Et,Rd),e(Rd,vfr),e(Rd,_ve),e(_ve,Ffr),e(Rd,Tfr),e(Rd,ZW),e(ZW,Mfr),e(Rd,Efr),e(Et,Cfr),M(r8,Et,null),e(zo,wfr),e(zo,mo),M(Ky,mo,null),e(mo,Afr),e(mo,uve),e(uve,Lfr),e(mo,yfr),e(mo,Ja),e(Ja,xfr),e(Ja,bve),e(bve,$fr),e(Ja,kfr),e(Ja,vve),e(vve,Sfr),e(Ja,Rfr),e(Ja,Fve),e(Fve,Pfr),e(Ja,Bfr),e(mo,Ifr),e(mo,et),e(et,t8),e(t8,Tve),e(Tve,Nfr),e(t8,qfr),e(t8,eH),e(eH,jfr),e(t8,Dfr),e(et,Gfr),e(et,a8),e(a8,Mve),e(Mve,Ofr),e(a8,Vfr),e(a8,oH),e(oH,Xfr),e(a8,zfr),e(et,Qfr),e(et,n8),e(n8,Eve),e(Eve,Wfr),e(n8,Hfr),e(n8,rH),e(rH,Ufr),e(n8,Jfr),e(et,Yfr),e(et,s8),e(s8,Cve),e(Cve,Kfr),e(s8,Zfr),e(s8,tH),e(tH,emr),e(s8,omr),e(et,rmr),e(et,l8),e(l8,wve),e(wve,tmr),e(l8,amr),e(l8,aH),e(aH,nmr),e(l8,smr),e(mo,lmr),e(mo,i8),e(i8,imr),e(i8,Ave),e(Ave,dmr),e(i8,cmr),e(i8,Lve),e(Lve,fmr),e(mo,mmr),M(d8,mo,null),b(f,xXe,u),b(f,Pd,u),e(Pd,c8),e(c8,yve),M(Zy,yve,null),e(Pd,gmr),e(Pd,xve),e(xve,hmr),b(f,$Xe,u),b(f,Qo,u),M(e9,Qo,null),e(Qo,pmr),e(Qo,Bd),e(Bd,_mr),e(Bd,nH),e(nH,umr),e(Bd,bmr),e(Bd,sH),e(sH,vmr),e(Bd,Fmr),e(Qo,Tmr),e(Qo,o9),e(o9,Mmr),e(o9,$ve),e($ve,Emr),e(o9,Cmr),e(Qo,wmr),e(Qo,Ct),M(r9,Ct,null),e(Ct,Amr),e(Ct,kve),e(kve,Lmr),e(Ct,ymr),e(Ct,Id),e(Id,xmr),e(Id,Sve),e(Sve,$mr),e(Id,kmr),e(Id,lH),e(lH,Smr),e(Id,Rmr),e(Ct,Pmr),M(f8,Ct,null),e(Qo,Bmr),e(Qo,go),M(t9,go,null),e(go,Imr),e(go,Rve),e(Rve,Nmr),e(go,qmr),e(go,Ya),e(Ya,jmr),e(Ya,Pve),e(Pve,Dmr),e(Ya,Gmr),e(Ya,Bve),e(Bve,Omr),e(Ya,Vmr),e(Ya,Ive),e(Ive,Xmr),e(Ya,zmr),e(go,Qmr),e(go,Le),e(Le,m8),e(m8,Nve),e(Nve,Wmr),e(m8,Hmr),e(m8,iH),e(iH,Umr),e(m8,Jmr),e(Le,Ymr),e(Le,g8),e(g8,qve),e(qve,Kmr),e(g8,Zmr),e(g8,dH),e(dH,egr),e(g8,ogr),e(Le,rgr),e(Le,h8),e(h8,jve),e(jve,tgr),e(h8,agr),e(h8,cH),e(cH,ngr),e(h8,sgr),e(Le,lgr),e(Le,p8),e(p8,Dve),e(Dve,igr),e(p8,dgr),e(p8,fH),e(fH,cgr),e(p8,fgr),e(Le,mgr),e(Le,_8),e(_8,Gve),e(Gve,ggr),e(_8,hgr),e(_8,mH),e(mH,pgr),e(_8,_gr),e(Le,ugr),e(Le,u8),e(u8,Ove),e(Ove,bgr),e(u8,vgr),e(u8,gH),e(gH,Fgr),e(u8,Tgr),e(Le,Mgr),e(Le,b8),e(b8,Vve),e(Vve,Egr),e(b8,Cgr),e(b8,hH),e(hH,wgr),e(b8,Agr),e(Le,Lgr),e(Le,v8),e(v8,Xve),e(Xve,ygr),e(v8,xgr),e(v8,pH),e(pH,$gr),e(v8,kgr),e(Le,Sgr),e(Le,F8),e(F8,zve),e(zve,Rgr),e(F8,Pgr),e(F8,_H),e(_H,Bgr),e(F8,Igr),e(Le,Ngr),e(Le,T8),e(T8,Qve),e(Qve,qgr),e(T8,jgr),e(T8,uH),e(uH,Dgr),e(T8,Ggr),e(go,Ogr),e(go,M8),e(M8,Vgr),e(M8,Wve),e(Wve,Xgr),e(M8,zgr),e(M8,Hve),e(Hve,Qgr),e(go,Wgr),M(E8,go,null),b(f,kXe,u),b(f,Nd,u),e(Nd,C8),e(C8,Uve),M(a9,Uve,null),e(Nd,Hgr),e(Nd,Jve),e(Jve,Ugr),b(f,SXe,u),b(f,Wo,u),M(n9,Wo,null),e(Wo,Jgr),e(Wo,qd),e(qd,Ygr),e(qd,bH),e(bH,Kgr),e(qd,Zgr),e(qd,vH),e(vH,ehr),e(qd,ohr),e(Wo,rhr),e(Wo,s9),e(s9,thr),e(s9,Yve),e(Yve,ahr),e(s9,nhr),e(Wo,shr),e(Wo,wt),M(l9,wt,null),e(wt,lhr),e(wt,Kve),e(Kve,ihr),e(wt,dhr),e(wt,jd),e(jd,chr),e(jd,Zve),e(Zve,fhr),e(jd,mhr),e(jd,FH),e(FH,ghr),e(jd,hhr),e(wt,phr),M(w8,wt,null),e(Wo,_hr),e(Wo,ho),M(i9,ho,null),e(ho,uhr),e(ho,eFe),e(eFe,bhr),e(ho,vhr),e(ho,Ka),e(Ka,Fhr),e(Ka,oFe),e(oFe,Thr),e(Ka,Mhr),e(Ka,rFe),e(rFe,Ehr),e(Ka,Chr),e(Ka,tFe),e(tFe,whr),e(Ka,Ahr),e(ho,Lhr),e(ho,d9),e(d9,A8),e(A8,aFe),e(aFe,yhr),e(A8,xhr),e(A8,TH),e(TH,$hr),e(A8,khr),e(d9,Shr),e(d9,L8),e(L8,nFe),e(nFe,Rhr),e(L8,Phr),e(L8,MH),e(MH,Bhr),e(L8,Ihr),e(ho,Nhr),e(ho,y8),e(y8,qhr),e(y8,sFe),e(sFe,jhr),e(y8,Dhr),e(y8,lFe),e(lFe,Ghr),e(ho,Ohr),M(x8,ho,null),b(f,RXe,u),b(f,Dd,u),e(Dd,$8),e($8,iFe),M(c9,iFe,null),e(Dd,Vhr),e(Dd,dFe),e(dFe,Xhr),b(f,PXe,u),b(f,Ho,u),M(f9,Ho,null),e(Ho,zhr),e(Ho,Gd),e(Gd,Qhr),e(Gd,EH),e(EH,Whr),e(Gd,Hhr),e(Gd,CH),e(CH,Uhr),e(Gd,Jhr),e(Ho,Yhr),e(Ho,m9),e(m9,Khr),e(m9,cFe),e(cFe,Zhr),e(m9,epr),e(Ho,opr),e(Ho,At),M(g9,At,null),e(At,rpr),e(At,fFe),e(fFe,tpr),e(At,apr),e(At,Od),e(Od,npr),e(Od,mFe),e(mFe,spr),e(Od,lpr),e(Od,wH),e(wH,ipr),e(Od,dpr),e(At,cpr),M(k8,At,null),e(Ho,fpr),e(Ho,po),M(h9,po,null),e(po,mpr),e(po,gFe),e(gFe,gpr),e(po,hpr),e(po,Za),e(Za,ppr),e(Za,hFe),e(hFe,_pr),e(Za,upr),e(Za,pFe),e(pFe,bpr),e(Za,vpr),e(Za,_Fe),e(_Fe,Fpr),e(Za,Tpr),e(po,Mpr),e(po,ot),e(ot,S8),e(S8,uFe),e(uFe,Epr),e(S8,Cpr),e(S8,AH),e(AH,wpr),e(S8,Apr),e(ot,Lpr),e(ot,R8),e(R8,bFe),e(bFe,ypr),e(R8,xpr),e(R8,LH),e(LH,$pr),e(R8,kpr),e(ot,Spr),e(ot,P8),e(P8,vFe),e(vFe,Rpr),e(P8,Ppr),e(P8,yH),e(yH,Bpr),e(P8,Ipr),e(ot,Npr),e(ot,B8),e(B8,FFe),e(FFe,qpr),e(B8,jpr),e(B8,xH),e(xH,Dpr),e(B8,Gpr),e(ot,Opr),e(ot,I8),e(I8,TFe),e(TFe,Vpr),e(I8,Xpr),e(I8,$H),e($H,zpr),e(I8,Qpr),e(po,Wpr),e(po,N8),e(N8,Hpr),e(N8,MFe),e(MFe,Upr),e(N8,Jpr),e(N8,EFe),e(EFe,Ypr),e(po,Kpr),M(q8,po,null),b(f,BXe,u),b(f,Vd,u),e(Vd,j8),e(j8,CFe),M(p9,CFe,null),e(Vd,Zpr),e(Vd,wFe),e(wFe,e_r),b(f,IXe,u),b(f,Uo,u),M(_9,Uo,null),e(Uo,o_r),e(Uo,Xd),e(Xd,r_r),e(Xd,kH),e(kH,t_r),e(Xd,a_r),e(Xd,SH),e(SH,n_r),e(Xd,s_r),e(Uo,l_r),e(Uo,u9),e(u9,i_r),e(u9,AFe),e(AFe,d_r),e(u9,c_r),e(Uo,f_r),e(Uo,Lt),M(b9,Lt,null),e(Lt,m_r),e(Lt,LFe),e(LFe,g_r),e(Lt,h_r),e(Lt,zd),e(zd,p_r),e(zd,yFe),e(yFe,__r),e(zd,u_r),e(zd,RH),e(RH,b_r),e(zd,v_r),e(Lt,F_r),M(D8,Lt,null),e(Uo,T_r),e(Uo,_o),M(v9,_o,null),e(_o,M_r),e(_o,xFe),e(xFe,E_r),e(_o,C_r),e(_o,en),e(en,w_r),e(en,$Fe),e($Fe,A_r),e(en,L_r),e(en,kFe),e(kFe,y_r),e(en,x_r),e(en,SFe),e(SFe,$_r),e(en,k_r),e(_o,S_r),e(_o,Qd),e(Qd,G8),e(G8,RFe),e(RFe,R_r),e(G8,P_r),e(G8,PH),e(PH,B_r),e(G8,I_r),e(Qd,N_r),e(Qd,O8),e(O8,PFe),e(PFe,q_r),e(O8,j_r),e(O8,BH),e(BH,D_r),e(O8,G_r),e(Qd,O_r),e(Qd,V8),e(V8,BFe),e(BFe,V_r),e(V8,X_r),e(V8,IH),e(IH,z_r),e(V8,Q_r),e(_o,W_r),e(_o,X8),e(X8,H_r),e(X8,IFe),e(IFe,U_r),e(X8,J_r),e(X8,NFe),e(NFe,Y_r),e(_o,K_r),M(z8,_o,null),b(f,NXe,u),b(f,Wd,u),e(Wd,Q8),e(Q8,qFe),M(F9,qFe,null),e(Wd,Z_r),e(Wd,jFe),e(jFe,eur),b(f,qXe,u),b(f,Jo,u),M(T9,Jo,null),e(Jo,our),e(Jo,Hd),e(Hd,rur),e(Hd,NH),e(NH,tur),e(Hd,aur),e(Hd,qH),e(qH,nur),e(Hd,sur),e(Jo,lur),e(Jo,M9),e(M9,iur),e(M9,DFe),e(DFe,dur),e(M9,cur),e(Jo,fur),e(Jo,yt),M(E9,yt,null),e(yt,mur),e(yt,GFe),e(GFe,gur),e(yt,hur),e(yt,Ud),e(Ud,pur),e(Ud,OFe),e(OFe,_ur),e(Ud,uur),e(Ud,jH),e(jH,bur),e(Ud,vur),e(yt,Fur),M(W8,yt,null),e(Jo,Tur),e(Jo,uo),M(C9,uo,null),e(uo,Mur),e(uo,VFe),e(VFe,Eur),e(uo,Cur),e(uo,on),e(on,wur),e(on,XFe),e(XFe,Aur),e(on,Lur),e(on,zFe),e(zFe,yur),e(on,xur),e(on,QFe),e(QFe,$ur),e(on,kur),e(uo,Sur),e(uo,w9),e(w9,H8),e(H8,WFe),e(WFe,Rur),e(H8,Pur),e(H8,DH),e(DH,Bur),e(H8,Iur),e(w9,Nur),e(w9,U8),e(U8,HFe),e(HFe,qur),e(U8,jur),e(U8,GH),e(GH,Dur),e(U8,Gur),e(uo,Our),e(uo,J8),e(J8,Vur),e(J8,UFe),e(UFe,Xur),e(J8,zur),e(J8,JFe),e(JFe,Qur),e(uo,Wur),M(Y8,uo,null),b(f,jXe,u),b(f,Jd,u),e(Jd,K8),e(K8,YFe),M(A9,YFe,null),e(Jd,Hur),e(Jd,KFe),e(KFe,Uur),b(f,DXe,u),b(f,Yo,u),M(L9,Yo,null),e(Yo,Jur),e(Yo,Yd),e(Yd,Yur),e(Yd,OH),e(OH,Kur),e(Yd,Zur),e(Yd,VH),e(VH,e1r),e(Yd,o1r),e(Yo,r1r),e(Yo,y9),e(y9,t1r),e(y9,ZFe),e(ZFe,a1r),e(y9,n1r),e(Yo,s1r),e(Yo,xt),M(x9,xt,null),e(xt,l1r),e(xt,eTe),e(eTe,i1r),e(xt,d1r),e(xt,Kd),e(Kd,c1r),e(Kd,oTe),e(oTe,f1r),e(Kd,m1r),e(Kd,XH),e(XH,g1r),e(Kd,h1r),e(xt,p1r),M(Z8,xt,null),e(Yo,_1r),e(Yo,bo),M($9,bo,null),e(bo,u1r),e(bo,rTe),e(rTe,b1r),e(bo,v1r),e(bo,rn),e(rn,F1r),e(rn,tTe),e(tTe,T1r),e(rn,M1r),e(rn,aTe),e(aTe,E1r),e(rn,C1r),e(rn,nTe),e(nTe,w1r),e(rn,A1r),e(bo,L1r),e(bo,sTe),e(sTe,eM),e(eM,lTe),e(lTe,y1r),e(eM,x1r),e(eM,zH),e(zH,$1r),e(eM,k1r),e(bo,S1r),e(bo,oM),e(oM,R1r),e(oM,iTe),e(iTe,P1r),e(oM,B1r),e(oM,dTe),e(dTe,I1r),e(bo,N1r),M(rM,bo,null),b(f,GXe,u),b(f,Zd,u),e(Zd,tM),e(tM,cTe),M(k9,cTe,null),e(Zd,q1r),e(Zd,fTe),e(fTe,j1r),b(f,OXe,u),b(f,Ko,u),M(S9,Ko,null),e(Ko,D1r),e(Ko,ec),e(ec,G1r),e(ec,QH),e(QH,O1r),e(ec,V1r),e(ec,WH),e(WH,X1r),e(ec,z1r),e(Ko,Q1r),e(Ko,R9),e(R9,W1r),e(R9,mTe),e(mTe,H1r),e(R9,U1r),e(Ko,J1r),e(Ko,$t),M(P9,$t,null),e($t,Y1r),e($t,gTe),e(gTe,K1r),e($t,Z1r),e($t,oc),e(oc,e2r),e(oc,hTe),e(hTe,o2r),e(oc,r2r),e(oc,HH),e(HH,t2r),e(oc,a2r),e($t,n2r),M(aM,$t,null),e(Ko,s2r),e(Ko,vo),M(B9,vo,null),e(vo,l2r),e(vo,pTe),e(pTe,i2r),e(vo,d2r),e(vo,tn),e(tn,c2r),e(tn,_Te),e(_Te,f2r),e(tn,m2r),e(tn,uTe),e(uTe,g2r),e(tn,h2r),e(tn,bTe),e(bTe,p2r),e(tn,_2r),e(vo,u2r),e(vo,rt),e(rt,nM),e(nM,vTe),e(vTe,b2r),e(nM,v2r),e(nM,UH),e(UH,F2r),e(nM,T2r),e(rt,M2r),e(rt,sM),e(sM,FTe),e(FTe,E2r),e(sM,C2r),e(sM,JH),e(JH,w2r),e(sM,A2r),e(rt,L2r),e(rt,lM),e(lM,TTe),e(TTe,y2r),e(lM,x2r),e(lM,YH),e(YH,$2r),e(lM,k2r),e(rt,S2r),e(rt,iM),e(iM,MTe),e(MTe,R2r),e(iM,P2r),e(iM,KH),e(KH,B2r),e(iM,I2r),e(rt,N2r),e(rt,dM),e(dM,ETe),e(ETe,q2r),e(dM,j2r),e(dM,ZH),e(ZH,D2r),e(dM,G2r),e(vo,O2r),e(vo,cM),e(cM,V2r),e(cM,CTe),e(CTe,X2r),e(cM,z2r),e(cM,wTe),e(wTe,Q2r),e(vo,W2r),M(fM,vo,null),b(f,VXe,u),b(f,rc,u),e(rc,mM),e(mM,ATe),M(I9,ATe,null),e(rc,H2r),e(rc,LTe),e(LTe,U2r),b(f,XXe,u),b(f,Zo,u),M(N9,Zo,null),e(Zo,J2r),e(Zo,tc),e(tc,Y2r),e(tc,eU),e(eU,K2r),e(tc,Z2r),e(tc,oU),e(oU,ebr),e(tc,obr),e(Zo,rbr),e(Zo,q9),e(q9,tbr),e(q9,yTe),e(yTe,abr),e(q9,nbr),e(Zo,sbr),e(Zo,kt),M(j9,kt,null),e(kt,lbr),e(kt,xTe),e(xTe,ibr),e(kt,dbr),e(kt,ac),e(ac,cbr),e(ac,$Te),e($Te,fbr),e(ac,mbr),e(ac,rU),e(rU,gbr),e(ac,hbr),e(kt,pbr),M(gM,kt,null),e(Zo,_br),e(Zo,Fo),M(D9,Fo,null),e(Fo,ubr),e(Fo,kTe),e(kTe,bbr),e(Fo,vbr),e(Fo,an),e(an,Fbr),e(an,STe),e(STe,Tbr),e(an,Mbr),e(an,RTe),e(RTe,Ebr),e(an,Cbr),e(an,PTe),e(PTe,wbr),e(an,Abr),e(Fo,Lbr),e(Fo,BTe),e(BTe,hM),e(hM,ITe),e(ITe,ybr),e(hM,xbr),e(hM,tU),e(tU,$br),e(hM,kbr),e(Fo,Sbr),e(Fo,pM),e(pM,Rbr),e(pM,NTe),e(NTe,Pbr),e(pM,Bbr),e(pM,qTe),e(qTe,Ibr),e(Fo,Nbr),M(_M,Fo,null),b(f,zXe,u),b(f,nc,u),e(nc,uM),e(uM,jTe),M(G9,jTe,null),e(nc,qbr),e(nc,DTe),e(DTe,jbr),b(f,QXe,u),b(f,er,u),M(O9,er,null),e(er,Dbr),e(er,sc),e(sc,Gbr),e(sc,aU),e(aU,Obr),e(sc,Vbr),e(sc,nU),e(nU,Xbr),e(sc,zbr),e(er,Qbr),e(er,V9),e(V9,Wbr),e(V9,GTe),e(GTe,Hbr),e(V9,Ubr),e(er,Jbr),e(er,St),M(X9,St,null),e(St,Ybr),e(St,OTe),e(OTe,Kbr),e(St,Zbr),e(St,lc),e(lc,evr),e(lc,VTe),e(VTe,ovr),e(lc,rvr),e(lc,sU),e(sU,tvr),e(lc,avr),e(St,nvr),M(bM,St,null),e(er,svr),e(er,yr),M(z9,yr,null),e(yr,lvr),e(yr,XTe),e(XTe,ivr),e(yr,dvr),e(yr,nn),e(nn,cvr),e(nn,zTe),e(zTe,fvr),e(nn,mvr),e(nn,QTe),e(QTe,gvr),e(nn,hvr),e(nn,WTe),e(WTe,pvr),e(nn,_vr),e(yr,uvr),e(yr,j),e(j,vM),e(vM,HTe),e(HTe,bvr),e(vM,vvr),e(vM,lU),e(lU,Fvr),e(vM,Tvr),e(j,Mvr),e(j,FM),e(FM,UTe),e(UTe,Evr),e(FM,Cvr),e(FM,iU),e(iU,wvr),e(FM,Avr),e(j,Lvr),e(j,TM),e(TM,JTe),e(JTe,yvr),e(TM,xvr),e(TM,dU),e(dU,$vr),e(TM,kvr),e(j,Svr),e(j,MM),e(MM,YTe),e(YTe,Rvr),e(MM,Pvr),e(MM,cU),e(cU,Bvr),e(MM,Ivr),e(j,Nvr),e(j,EM),e(EM,KTe),e(KTe,qvr),e(EM,jvr),e(EM,fU),e(fU,Dvr),e(EM,Gvr),e(j,Ovr),e(j,CM),e(CM,ZTe),e(ZTe,Vvr),e(CM,Xvr),e(CM,mU),e(mU,zvr),e(CM,Qvr),e(j,Wvr),e(j,wM),e(wM,e7e),e(e7e,Hvr),e(wM,Uvr),e(wM,gU),e(gU,Jvr),e(wM,Yvr),e(j,Kvr),e(j,AM),e(AM,o7e),e(o7e,Zvr),e(AM,eFr),e(AM,hU),e(hU,oFr),e(AM,rFr),e(j,tFr),e(j,LM),e(LM,r7e),e(r7e,aFr),e(LM,nFr),e(LM,pU),e(pU,sFr),e(LM,lFr),e(j,iFr),e(j,yM),e(yM,t7e),e(t7e,dFr),e(yM,cFr),e(yM,_U),e(_U,fFr),e(yM,mFr),e(j,gFr),e(j,xM),e(xM,a7e),e(a7e,hFr),e(xM,pFr),e(xM,uU),e(uU,_Fr),e(xM,uFr),e(j,bFr),e(j,$M),e($M,n7e),e(n7e,vFr),e($M,FFr),e($M,bU),e(bU,TFr),e($M,MFr),e(j,EFr),e(j,kM),e(kM,s7e),e(s7e,CFr),e(kM,wFr),e(kM,vU),e(vU,AFr),e(kM,LFr),e(j,yFr),e(j,SM),e(SM,l7e),e(l7e,xFr),e(SM,$Fr),e(SM,FU),e(FU,kFr),e(SM,SFr),e(j,RFr),e(j,RM),e(RM,i7e),e(i7e,PFr),e(RM,BFr),e(RM,TU),e(TU,IFr),e(RM,NFr),e(j,qFr),e(j,PM),e(PM,d7e),e(d7e,jFr),e(PM,DFr),e(PM,MU),e(MU,GFr),e(PM,OFr),e(j,VFr),e(j,BM),e(BM,c7e),e(c7e,XFr),e(BM,zFr),e(BM,EU),e(EU,QFr),e(BM,WFr),e(j,HFr),e(j,Us),e(Us,f7e),e(f7e,UFr),e(Us,JFr),e(Us,CU),e(CU,YFr),e(Us,KFr),e(Us,wU),e(wU,ZFr),e(Us,eTr),e(j,oTr),e(j,IM),e(IM,m7e),e(m7e,rTr),e(IM,tTr),e(IM,AU),e(AU,aTr),e(IM,nTr),e(j,sTr),e(j,NM),e(NM,g7e),e(g7e,lTr),e(NM,iTr),e(NM,LU),e(LU,dTr),e(NM,cTr),e(j,fTr),e(j,qM),e(qM,h7e),e(h7e,mTr),e(qM,gTr),e(qM,yU),e(yU,hTr),e(qM,pTr),e(j,_Tr),e(j,jM),e(jM,p7e),e(p7e,uTr),e(jM,bTr),e(jM,xU),e(xU,vTr),e(jM,FTr),e(j,TTr),e(j,DM),e(DM,_7e),e(_7e,MTr),e(DM,ETr),e(DM,$U),e($U,CTr),e(DM,wTr),e(j,ATr),e(j,GM),e(GM,u7e),e(u7e,LTr),e(GM,yTr),e(GM,kU),e(kU,xTr),e(GM,$Tr),e(j,kTr),e(j,OM),e(OM,b7e),e(b7e,STr),e(OM,RTr),e(OM,SU),e(SU,PTr),e(OM,BTr),e(j,ITr),e(j,VM),e(VM,v7e),e(v7e,NTr),e(VM,qTr),e(VM,RU),e(RU,jTr),e(VM,DTr),e(j,GTr),e(j,XM),e(XM,F7e),e(F7e,OTr),e(XM,VTr),e(XM,PU),e(PU,XTr),e(XM,zTr),e(j,QTr),e(j,zM),e(zM,T7e),e(T7e,WTr),e(zM,HTr),e(zM,BU),e(BU,UTr),e(zM,JTr),e(j,YTr),e(j,QM),e(QM,M7e),e(M7e,KTr),e(QM,ZTr),e(QM,IU),e(IU,e7r),e(QM,o7r),e(j,r7r),e(j,WM),e(WM,E7e),e(E7e,t7r),e(WM,a7r),e(WM,NU),e(NU,n7r),e(WM,s7r),e(j,l7r),e(j,HM),e(HM,C7e),e(C7e,i7r),e(HM,d7r),e(HM,qU),e(qU,c7r),e(HM,f7r),e(j,m7r),e(j,UM),e(UM,w7e),e(w7e,g7r),e(UM,h7r),e(UM,jU),e(jU,p7r),e(UM,_7r),e(j,u7r),e(j,JM),e(JM,A7e),e(A7e,b7r),e(JM,v7r),e(JM,DU),e(DU,F7r),e(JM,T7r),e(j,M7r),e(j,YM),e(YM,L7e),e(L7e,E7r),e(YM,C7r),e(YM,GU),e(GU,w7r),e(YM,A7r),e(j,L7r),e(j,KM),e(KM,y7e),e(y7e,y7r),e(KM,x7r),e(KM,OU),e(OU,$7r),e(KM,k7r),e(j,S7r),e(j,ZM),e(ZM,x7e),e(x7e,R7r),e(ZM,P7r),e(ZM,VU),e(VU,B7r),e(ZM,I7r),e(j,N7r),e(j,e4),e(e4,$7e),e($7e,q7r),e(e4,j7r),e(e4,XU),e(XU,D7r),e(e4,G7r),e(j,O7r),e(j,o4),e(o4,k7e),e(k7e,V7r),e(o4,X7r),e(o4,zU),e(zU,z7r),e(o4,Q7r),e(j,W7r),e(j,r4),e(r4,S7e),e(S7e,H7r),e(r4,U7r),e(r4,QU),e(QU,J7r),e(r4,Y7r),e(j,K7r),e(j,t4),e(t4,R7e),e(R7e,Z7r),e(t4,e8r),e(t4,WU),e(WU,o8r),e(t4,r8r),e(j,t8r),e(j,a4),e(a4,P7e),e(P7e,a8r),e(a4,n8r),e(a4,HU),e(HU,s8r),e(a4,l8r),e(j,i8r),e(j,n4),e(n4,B7e),e(B7e,d8r),e(n4,c8r),e(n4,UU),e(UU,f8r),e(n4,m8r),e(j,g8r),e(j,s4),e(s4,I7e),e(I7e,h8r),e(s4,p8r),e(s4,JU),e(JU,_8r),e(s4,u8r),e(j,b8r),e(j,l4),e(l4,N7e),e(N7e,v8r),e(l4,F8r),e(l4,YU),e(YU,T8r),e(l4,M8r),e(j,E8r),e(j,i4),e(i4,q7e),e(q7e,C8r),e(i4,w8r),e(i4,KU),e(KU,A8r),e(i4,L8r),e(j,y8r),e(j,d4),e(d4,j7e),e(j7e,x8r),e(d4,$8r),e(d4,ZU),e(ZU,k8r),e(d4,S8r),e(j,R8r),e(j,c4),e(c4,D7e),e(D7e,P8r),e(c4,B8r),e(c4,eJ),e(eJ,I8r),e(c4,N8r),e(j,q8r),e(j,f4),e(f4,G7e),e(G7e,j8r),e(f4,D8r),e(f4,oJ),e(oJ,G8r),e(f4,O8r),e(yr,V8r),M(m4,yr,null),b(f,WXe,u),b(f,ic,u),e(ic,g4),e(g4,O7e),M(Q9,O7e,null),e(ic,X8r),e(ic,V7e),e(V7e,z8r),b(f,HXe,u),b(f,or,u),M(W9,or,null),e(or,Q8r),e(or,dc),e(dc,W8r),e(dc,rJ),e(rJ,H8r),e(dc,U8r),e(dc,tJ),e(tJ,J8r),e(dc,Y8r),e(or,K8r),e(or,H9),e(H9,Z8r),e(H9,X7e),e(X7e,eMr),e(H9,oMr),e(or,rMr),e(or,Rt),M(U9,Rt,null),e(Rt,tMr),e(Rt,z7e),e(z7e,aMr),e(Rt,nMr),e(Rt,cc),e(cc,sMr),e(cc,Q7e),e(Q7e,lMr),e(cc,iMr),e(cc,aJ),e(aJ,dMr),e(cc,cMr),e(Rt,fMr),M(h4,Rt,null),e(or,mMr),e(or,xr),M(J9,xr,null),e(xr,gMr),e(xr,W7e),e(W7e,hMr),e(xr,pMr),e(xr,sn),e(sn,_Mr),e(sn,H7e),e(H7e,uMr),e(sn,bMr),e(sn,U7e),e(U7e,vMr),e(sn,FMr),e(sn,J7e),e(J7e,TMr),e(sn,MMr),e(xr,EMr),e(xr,se),e(se,p4),e(p4,Y7e),e(Y7e,CMr),e(p4,wMr),e(p4,nJ),e(nJ,AMr),e(p4,LMr),e(se,yMr),e(se,_4),e(_4,K7e),e(K7e,xMr),e(_4,$Mr),e(_4,sJ),e(sJ,kMr),e(_4,SMr),e(se,RMr),e(se,u4),e(u4,Z7e),e(Z7e,PMr),e(u4,BMr),e(u4,lJ),e(lJ,IMr),e(u4,NMr),e(se,qMr),e(se,b4),e(b4,e8e),e(e8e,jMr),e(b4,DMr),e(b4,iJ),e(iJ,GMr),e(b4,OMr),e(se,VMr),e(se,v4),e(v4,o8e),e(o8e,XMr),e(v4,zMr),e(v4,dJ),e(dJ,QMr),e(v4,WMr),e(se,HMr),e(se,F4),e(F4,r8e),e(r8e,UMr),e(F4,JMr),e(F4,cJ),e(cJ,YMr),e(F4,KMr),e(se,ZMr),e(se,T4),e(T4,t8e),e(t8e,e4r),e(T4,o4r),e(T4,fJ),e(fJ,r4r),e(T4,t4r),e(se,a4r),e(se,M4),e(M4,a8e),e(a8e,n4r),e(M4,s4r),e(M4,mJ),e(mJ,l4r),e(M4,i4r),e(se,d4r),e(se,E4),e(E4,n8e),e(n8e,c4r),e(E4,f4r),e(E4,gJ),e(gJ,m4r),e(E4,g4r),e(se,h4r),e(se,C4),e(C4,s8e),e(s8e,p4r),e(C4,_4r),e(C4,hJ),e(hJ,u4r),e(C4,b4r),e(se,v4r),e(se,w4),e(w4,l8e),e(l8e,F4r),e(w4,T4r),e(w4,pJ),e(pJ,M4r),e(w4,E4r),e(se,C4r),e(se,A4),e(A4,i8e),e(i8e,w4r),e(A4,A4r),e(A4,_J),e(_J,L4r),e(A4,y4r),e(se,x4r),e(se,L4),e(L4,d8e),e(d8e,$4r),e(L4,k4r),e(L4,uJ),e(uJ,S4r),e(L4,R4r),e(se,P4r),e(se,y4),e(y4,c8e),e(c8e,B4r),e(y4,I4r),e(y4,bJ),e(bJ,N4r),e(y4,q4r),e(se,j4r),e(se,x4),e(x4,f8e),e(f8e,D4r),e(x4,G4r),e(x4,vJ),e(vJ,O4r),e(x4,V4r),e(se,X4r),e(se,$4),e($4,m8e),e(m8e,z4r),e($4,Q4r),e($4,FJ),e(FJ,W4r),e($4,H4r),e(se,U4r),e(se,k4),e(k4,g8e),e(g8e,J4r),e(k4,Y4r),e(k4,TJ),e(TJ,K4r),e(k4,Z4r),e(se,eEr),e(se,S4),e(S4,h8e),e(h8e,oEr),e(S4,rEr),e(S4,MJ),e(MJ,tEr),e(S4,aEr),e(se,nEr),e(se,R4),e(R4,p8e),e(p8e,sEr),e(R4,lEr),e(R4,EJ),e(EJ,iEr),e(R4,dEr),e(se,cEr),e(se,P4),e(P4,_8e),e(_8e,fEr),e(P4,mEr),e(P4,CJ),e(CJ,gEr),e(P4,hEr),e(se,pEr),e(se,B4),e(B4,u8e),e(u8e,_Er),e(B4,uEr),e(B4,wJ),e(wJ,bEr),e(B4,vEr),e(se,FEr),e(se,I4),e(I4,b8e),e(b8e,TEr),e(I4,MEr),e(I4,AJ),e(AJ,EEr),e(I4,CEr),e(se,wEr),e(se,N4),e(N4,v8e),e(v8e,AEr),e(N4,LEr),e(N4,LJ),e(LJ,yEr),e(N4,xEr),e(xr,$Er),M(q4,xr,null),b(f,UXe,u),b(f,fc,u),e(fc,j4),e(j4,F8e),M(Y9,F8e,null),e(fc,kEr),e(fc,T8e),e(T8e,SEr),b(f,JXe,u),b(f,rr,u),M(K9,rr,null),e(rr,REr),e(rr,mc),e(mc,PEr),e(mc,yJ),e(yJ,BEr),e(mc,IEr),e(mc,xJ),e(xJ,NEr),e(mc,qEr),e(rr,jEr),e(rr,Z9),e(Z9,DEr),e(Z9,M8e),e(M8e,GEr),e(Z9,OEr),e(rr,VEr),e(rr,Pt),M(ex,Pt,null),e(Pt,XEr),e(Pt,E8e),e(E8e,zEr),e(Pt,QEr),e(Pt,gc),e(gc,WEr),e(gc,C8e),e(C8e,HEr),e(gc,UEr),e(gc,$J),e($J,JEr),e(gc,YEr),e(Pt,KEr),M(D4,Pt,null),e(rr,ZEr),e(rr,$r),M(ox,$r,null),e($r,eCr),e($r,w8e),e(w8e,oCr),e($r,rCr),e($r,ln),e(ln,tCr),e(ln,A8e),e(A8e,aCr),e(ln,nCr),e(ln,L8e),e(L8e,sCr),e(ln,lCr),e(ln,y8e),e(y8e,iCr),e(ln,dCr),e($r,cCr),e($r,Me),e(Me,G4),e(G4,x8e),e(x8e,fCr),e(G4,mCr),e(G4,kJ),e(kJ,gCr),e(G4,hCr),e(Me,pCr),e(Me,O4),e(O4,$8e),e($8e,_Cr),e(O4,uCr),e(O4,SJ),e(SJ,bCr),e(O4,vCr),e(Me,FCr),e(Me,V4),e(V4,k8e),e(k8e,TCr),e(V4,MCr),e(V4,RJ),e(RJ,ECr),e(V4,CCr),e(Me,wCr),e(Me,X4),e(X4,S8e),e(S8e,ACr),e(X4,LCr),e(X4,PJ),e(PJ,yCr),e(X4,xCr),e(Me,$Cr),e(Me,z4),e(z4,R8e),e(R8e,kCr),e(z4,SCr),e(z4,BJ),e(BJ,RCr),e(z4,PCr),e(Me,BCr),e(Me,Q4),e(Q4,P8e),e(P8e,ICr),e(Q4,NCr),e(Q4,IJ),e(IJ,qCr),e(Q4,jCr),e(Me,DCr),e(Me,W4),e(W4,B8e),e(B8e,GCr),e(W4,OCr),e(W4,NJ),e(NJ,VCr),e(W4,XCr),e(Me,zCr),e(Me,H4),e(H4,I8e),e(I8e,QCr),e(H4,WCr),e(H4,qJ),e(qJ,HCr),e(H4,UCr),e(Me,JCr),e(Me,U4),e(U4,N8e),e(N8e,YCr),e(U4,KCr),e(U4,jJ),e(jJ,ZCr),e(U4,e3r),e(Me,o3r),e(Me,J4),e(J4,q8e),e(q8e,r3r),e(J4,t3r),e(J4,DJ),e(DJ,a3r),e(J4,n3r),e(Me,s3r),e(Me,Y4),e(Y4,j8e),e(j8e,l3r),e(Y4,i3r),e(Y4,GJ),e(GJ,d3r),e(Y4,c3r),e(Me,f3r),e(Me,K4),e(K4,D8e),e(D8e,m3r),e(K4,g3r),e(K4,OJ),e(OJ,h3r),e(K4,p3r),e(Me,_3r),e(Me,Z4),e(Z4,G8e),e(G8e,u3r),e(Z4,b3r),e(Z4,VJ),e(VJ,v3r),e(Z4,F3r),e($r,T3r),M(eE,$r,null),b(f,YXe,u),b(f,hc,u),e(hc,oE),e(oE,O8e),M(rx,O8e,null),e(hc,M3r),e(hc,V8e),e(V8e,E3r),b(f,KXe,u),b(f,tr,u),M(tx,tr,null),e(tr,C3r),e(tr,pc),e(pc,w3r),e(pc,XJ),e(XJ,A3r),e(pc,L3r),e(pc,zJ),e(zJ,y3r),e(pc,x3r),e(tr,$3r),e(tr,ax),e(ax,k3r),e(ax,X8e),e(X8e,S3r),e(ax,R3r),e(tr,P3r),e(tr,Bt),M(nx,Bt,null),e(Bt,B3r),e(Bt,z8e),e(z8e,I3r),e(Bt,N3r),e(Bt,_c),e(_c,q3r),e(_c,Q8e),e(Q8e,j3r),e(_c,D3r),e(_c,QJ),e(QJ,G3r),e(_c,O3r),e(Bt,V3r),M(rE,Bt,null),e(tr,X3r),e(tr,kr),M(sx,kr,null),e(kr,z3r),e(kr,W8e),e(W8e,Q3r),e(kr,W3r),e(kr,dn),e(dn,H3r),e(dn,H8e),e(H8e,U3r),e(dn,J3r),e(dn,U8e),e(U8e,Y3r),e(dn,K3r),e(dn,J8e),e(J8e,Z3r),e(dn,e5r),e(kr,o5r),e(kr,tt),e(tt,tE),e(tE,Y8e),e(Y8e,r5r),e(tE,t5r),e(tE,WJ),e(WJ,a5r),e(tE,n5r),e(tt,s5r),e(tt,aE),e(aE,K8e),e(K8e,l5r),e(aE,i5r),e(aE,HJ),e(HJ,d5r),e(aE,c5r),e(tt,f5r),e(tt,nE),e(nE,Z8e),e(Z8e,m5r),e(nE,g5r),e(nE,UJ),e(UJ,h5r),e(nE,p5r),e(tt,_5r),e(tt,sE),e(sE,eMe),e(eMe,u5r),e(sE,b5r),e(sE,JJ),e(JJ,v5r),e(sE,F5r),e(tt,T5r),e(tt,lE),e(lE,oMe),e(oMe,M5r),e(lE,E5r),e(lE,YJ),e(YJ,C5r),e(lE,w5r),e(kr,A5r),M(iE,kr,null),b(f,ZXe,u),b(f,uc,u),e(uc,dE),e(dE,rMe),M(lx,rMe,null),e(uc,L5r),e(uc,tMe),e(tMe,y5r),b(f,eze,u),b(f,ar,u),M(ix,ar,null),e(ar,x5r),e(ar,bc),e(bc,$5r),e(bc,KJ),e(KJ,k5r),e(bc,S5r),e(bc,ZJ),e(ZJ,R5r),e(bc,P5r),e(ar,B5r),e(ar,dx),e(dx,I5r),e(dx,aMe),e(aMe,N5r),e(dx,q5r),e(ar,j5r),e(ar,It),M(cx,It,null),e(It,D5r),e(It,nMe),e(nMe,G5r),e(It,O5r),e(It,vc),e(vc,V5r),e(vc,sMe),e(sMe,X5r),e(vc,z5r),e(vc,eY),e(eY,Q5r),e(vc,W5r),e(It,H5r),M(cE,It,null),e(ar,U5r),e(ar,Sr),M(fx,Sr,null),e(Sr,J5r),e(Sr,lMe),e(lMe,Y5r),e(Sr,K5r),e(Sr,cn),e(cn,Z5r),e(cn,iMe),e(iMe,e0r),e(cn,o0r),e(cn,dMe),e(dMe,r0r),e(cn,t0r),e(cn,cMe),e(cMe,a0r),e(cn,n0r),e(Sr,s0r),e(Sr,ie),e(ie,fE),e(fE,fMe),e(fMe,l0r),e(fE,i0r),e(fE,oY),e(oY,d0r),e(fE,c0r),e(ie,f0r),e(ie,mE),e(mE,mMe),e(mMe,m0r),e(mE,g0r),e(mE,rY),e(rY,h0r),e(mE,p0r),e(ie,_0r),e(ie,gE),e(gE,gMe),e(gMe,u0r),e(gE,b0r),e(gE,tY),e(tY,v0r),e(gE,F0r),e(ie,T0r),e(ie,hE),e(hE,hMe),e(hMe,M0r),e(hE,E0r),e(hE,aY),e(aY,C0r),e(hE,w0r),e(ie,A0r),e(ie,pE),e(pE,pMe),e(pMe,L0r),e(pE,y0r),e(pE,nY),e(nY,x0r),e(pE,$0r),e(ie,k0r),e(ie,_E),e(_E,_Me),e(_Me,S0r),e(_E,R0r),e(_E,sY),e(sY,P0r),e(_E,B0r),e(ie,I0r),e(ie,uE),e(uE,uMe),e(uMe,N0r),e(uE,q0r),e(uE,lY),e(lY,j0r),e(uE,D0r),e(ie,G0r),e(ie,bE),e(bE,bMe),e(bMe,O0r),e(bE,V0r),e(bE,iY),e(iY,X0r),e(bE,z0r),e(ie,Q0r),e(ie,vE),e(vE,vMe),e(vMe,W0r),e(vE,H0r),e(vE,dY),e(dY,U0r),e(vE,J0r),e(ie,Y0r),e(ie,FE),e(FE,FMe),e(FMe,K0r),e(FE,Z0r),e(FE,cY),e(cY,ewr),e(FE,owr),e(ie,rwr),e(ie,TE),e(TE,TMe),e(TMe,twr),e(TE,awr),e(TE,fY),e(fY,nwr),e(TE,swr),e(ie,lwr),e(ie,ME),e(ME,MMe),e(MMe,iwr),e(ME,dwr),e(ME,mY),e(mY,cwr),e(ME,fwr),e(ie,mwr),e(ie,EE),e(EE,EMe),e(EMe,gwr),e(EE,hwr),e(EE,gY),e(gY,pwr),e(EE,_wr),e(ie,uwr),e(ie,CE),e(CE,CMe),e(CMe,bwr),e(CE,vwr),e(CE,hY),e(hY,Fwr),e(CE,Twr),e(ie,Mwr),e(ie,wE),e(wE,wMe),e(wMe,Ewr),e(wE,Cwr),e(wE,pY),e(pY,wwr),e(wE,Awr),e(ie,Lwr),e(ie,AE),e(AE,AMe),e(AMe,ywr),e(AE,xwr),e(AE,_Y),e(_Y,$wr),e(AE,kwr),e(ie,Swr),e(ie,LE),e(LE,LMe),e(LMe,Rwr),e(LE,Pwr),e(LE,uY),e(uY,Bwr),e(LE,Iwr),e(ie,Nwr),e(ie,yE),e(yE,yMe),e(yMe,qwr),e(yE,jwr),e(yE,bY),e(bY,Dwr),e(yE,Gwr),e(ie,Owr),e(ie,xE),e(xE,xMe),e(xMe,Vwr),e(xE,Xwr),e(xE,vY),e(vY,zwr),e(xE,Qwr),e(ie,Wwr),e(ie,$E),e($E,$Me),e($Me,Hwr),e($E,Uwr),e($E,FY),e(FY,Jwr),e($E,Ywr),e(Sr,Kwr),M(kE,Sr,null),b(f,oze,u),b(f,Fc,u),e(Fc,SE),e(SE,kMe),M(mx,kMe,null),e(Fc,Zwr),e(Fc,SMe),e(SMe,eAr),b(f,rze,u),b(f,nr,u),M(gx,nr,null),e(nr,oAr),e(nr,Tc),e(Tc,rAr),e(Tc,TY),e(TY,tAr),e(Tc,aAr),e(Tc,MY),e(MY,nAr),e(Tc,sAr),e(nr,lAr),e(nr,hx),e(hx,iAr),e(hx,RMe),e(RMe,dAr),e(hx,cAr),e(nr,fAr),e(nr,Nt),M(px,Nt,null),e(Nt,mAr),e(Nt,PMe),e(PMe,gAr),e(Nt,hAr),e(Nt,Mc),e(Mc,pAr),e(Mc,BMe),e(BMe,_Ar),e(Mc,uAr),e(Mc,EY),e(EY,bAr),e(Mc,vAr),e(Nt,FAr),M(RE,Nt,null),e(nr,TAr),e(nr,Rr),M(_x,Rr,null),e(Rr,MAr),e(Rr,IMe),e(IMe,EAr),e(Rr,CAr),e(Rr,fn),e(fn,wAr),e(fn,NMe),e(NMe,AAr),e(fn,LAr),e(fn,qMe),e(qMe,yAr),e(fn,xAr),e(fn,jMe),e(jMe,$Ar),e(fn,kAr),e(Rr,SAr),e(Rr,ye),e(ye,PE),e(PE,DMe),e(DMe,RAr),e(PE,PAr),e(PE,CY),e(CY,BAr),e(PE,IAr),e(ye,NAr),e(ye,BE),e(BE,GMe),e(GMe,qAr),e(BE,jAr),e(BE,wY),e(wY,DAr),e(BE,GAr),e(ye,OAr),e(ye,IE),e(IE,OMe),e(OMe,VAr),e(IE,XAr),e(IE,AY),e(AY,zAr),e(IE,QAr),e(ye,WAr),e(ye,NE),e(NE,VMe),e(VMe,HAr),e(NE,UAr),e(NE,LY),e(LY,JAr),e(NE,YAr),e(ye,KAr),e(ye,qE),e(qE,XMe),e(XMe,ZAr),e(qE,e6r),e(qE,yY),e(yY,o6r),e(qE,r6r),e(ye,t6r),e(ye,jE),e(jE,zMe),e(zMe,a6r),e(jE,n6r),e(jE,xY),e(xY,s6r),e(jE,l6r),e(ye,i6r),e(ye,DE),e(DE,QMe),e(QMe,d6r),e(DE,c6r),e(DE,$Y),e($Y,f6r),e(DE,m6r),e(ye,g6r),e(ye,GE),e(GE,WMe),e(WMe,h6r),e(GE,p6r),e(GE,kY),e(kY,_6r),e(GE,u6r),e(ye,b6r),e(ye,OE),e(OE,HMe),e(HMe,v6r),e(OE,F6r),e(OE,SY),e(SY,T6r),e(OE,M6r),e(ye,E6r),e(ye,VE),e(VE,UMe),e(UMe,C6r),e(VE,w6r),e(VE,RY),e(RY,A6r),e(VE,L6r),e(Rr,y6r),M(XE,Rr,null),b(f,tze,u),b(f,Ec,u),e(Ec,zE),e(zE,JMe),M(ux,JMe,null),e(Ec,x6r),e(Ec,YMe),e(YMe,$6r),b(f,aze,u),b(f,sr,u),M(bx,sr,null),e(sr,k6r),e(sr,Cc),e(Cc,S6r),e(Cc,PY),e(PY,R6r),e(Cc,P6r),e(Cc,BY),e(BY,B6r),e(Cc,I6r),e(sr,N6r),e(sr,vx),e(vx,q6r),e(vx,KMe),e(KMe,j6r),e(vx,D6r),e(sr,G6r),e(sr,qt),M(Fx,qt,null),e(qt,O6r),e(qt,ZMe),e(ZMe,V6r),e(qt,X6r),e(qt,wc),e(wc,z6r),e(wc,e4e),e(e4e,Q6r),e(wc,W6r),e(wc,IY),e(IY,H6r),e(wc,U6r),e(qt,J6r),M(QE,qt,null),e(sr,Y6r),e(sr,Pr),M(Tx,Pr,null),e(Pr,K6r),e(Pr,o4e),e(o4e,Z6r),e(Pr,eLr),e(Pr,mn),e(mn,oLr),e(mn,r4e),e(r4e,rLr),e(mn,tLr),e(mn,t4e),e(t4e,aLr),e(mn,nLr),e(mn,a4e),e(a4e,sLr),e(mn,lLr),e(Pr,iLr),e(Pr,te),e(te,WE),e(WE,n4e),e(n4e,dLr),e(WE,cLr),e(WE,NY),e(NY,fLr),e(WE,mLr),e(te,gLr),e(te,HE),e(HE,s4e),e(s4e,hLr),e(HE,pLr),e(HE,qY),e(qY,_Lr),e(HE,uLr),e(te,bLr),e(te,UE),e(UE,l4e),e(l4e,vLr),e(UE,FLr),e(UE,jY),e(jY,TLr),e(UE,MLr),e(te,ELr),e(te,JE),e(JE,i4e),e(i4e,CLr),e(JE,wLr),e(JE,DY),e(DY,ALr),e(JE,LLr),e(te,yLr),e(te,YE),e(YE,d4e),e(d4e,xLr),e(YE,$Lr),e(YE,GY),e(GY,kLr),e(YE,SLr),e(te,RLr),e(te,KE),e(KE,c4e),e(c4e,PLr),e(KE,BLr),e(KE,OY),e(OY,ILr),e(KE,NLr),e(te,qLr),e(te,ZE),e(ZE,f4e),e(f4e,jLr),e(ZE,DLr),e(ZE,VY),e(VY,GLr),e(ZE,OLr),e(te,VLr),e(te,eC),e(eC,m4e),e(m4e,XLr),e(eC,zLr),e(eC,XY),e(XY,QLr),e(eC,WLr),e(te,HLr),e(te,oC),e(oC,g4e),e(g4e,ULr),e(oC,JLr),e(oC,zY),e(zY,YLr),e(oC,KLr),e(te,ZLr),e(te,rC),e(rC,h4e),e(h4e,eyr),e(rC,oyr),e(rC,QY),e(QY,ryr),e(rC,tyr),e(te,ayr),e(te,tC),e(tC,p4e),e(p4e,nyr),e(tC,syr),e(tC,WY),e(WY,lyr),e(tC,iyr),e(te,dyr),e(te,aC),e(aC,_4e),e(_4e,cyr),e(aC,fyr),e(aC,HY),e(HY,myr),e(aC,gyr),e(te,hyr),e(te,nC),e(nC,u4e),e(u4e,pyr),e(nC,_yr),e(nC,UY),e(UY,uyr),e(nC,byr),e(te,vyr),e(te,sC),e(sC,b4e),e(b4e,Fyr),e(sC,Tyr),e(sC,JY),e(JY,Myr),e(sC,Eyr),e(te,Cyr),e(te,lC),e(lC,v4e),e(v4e,wyr),e(lC,Ayr),e(lC,YY),e(YY,Lyr),e(lC,yyr),e(te,xyr),e(te,iC),e(iC,F4e),e(F4e,$yr),e(iC,kyr),e(iC,KY),e(KY,Syr),e(iC,Ryr),e(te,Pyr),e(te,dC),e(dC,T4e),e(T4e,Byr),e(dC,Iyr),e(dC,ZY),e(ZY,Nyr),e(dC,qyr),e(te,jyr),e(te,cC),e(cC,M4e),e(M4e,Dyr),e(cC,Gyr),e(cC,eK),e(eK,Oyr),e(cC,Vyr),e(te,Xyr),e(te,fC),e(fC,E4e),e(E4e,zyr),e(fC,Qyr),e(fC,oK),e(oK,Wyr),e(fC,Hyr),e(te,Uyr),e(te,mC),e(mC,C4e),e(C4e,Jyr),e(mC,Yyr),e(mC,rK),e(rK,Kyr),e(mC,Zyr),e(te,e9r),e(te,gC),e(gC,w4e),e(w4e,o9r),e(gC,r9r),e(gC,tK),e(tK,t9r),e(gC,a9r),e(te,n9r),e(te,hC),e(hC,A4e),e(A4e,s9r),e(hC,l9r),e(hC,aK),e(aK,i9r),e(hC,d9r),e(te,c9r),e(te,pC),e(pC,L4e),e(L4e,f9r),e(pC,m9r),e(pC,nK),e(nK,g9r),e(pC,h9r),e(te,p9r),e(te,_C),e(_C,y4e),e(y4e,_9r),e(_C,u9r),e(_C,sK),e(sK,b9r),e(_C,v9r),e(te,F9r),e(te,uC),e(uC,x4e),e(x4e,T9r),e(uC,M9r),e(uC,lK),e(lK,E9r),e(uC,C9r),e(te,w9r),e(te,bC),e(bC,$4e),e($4e,A9r),e(bC,L9r),e(bC,iK),e(iK,y9r),e(bC,x9r),e(Pr,$9r),M(vC,Pr,null),b(f,nze,u),b(f,Ac,u),e(Ac,FC),e(FC,k4e),M(Mx,k4e,null),e(Ac,k9r),e(Ac,S4e),e(S4e,S9r),b(f,sze,u),b(f,lr,u),M(Ex,lr,null),e(lr,R9r),e(lr,Lc),e(Lc,P9r),e(Lc,dK),e(dK,B9r),e(Lc,I9r),e(Lc,cK),e(cK,N9r),e(Lc,q9r),e(lr,j9r),e(lr,Cx),e(Cx,D9r),e(Cx,R4e),e(R4e,G9r),e(Cx,O9r),e(lr,V9r),e(lr,jt),M(wx,jt,null),e(jt,X9r),e(jt,P4e),e(P4e,z9r),e(jt,Q9r),e(jt,yc),e(yc,W9r),e(yc,B4e),e(B4e,H9r),e(yc,U9r),e(yc,fK),e(fK,J9r),e(yc,Y9r),e(jt,K9r),M(TC,jt,null),e(lr,Z9r),e(lr,Br),M(Ax,Br,null),e(Br,exr),e(Br,I4e),e(I4e,oxr),e(Br,rxr),e(Br,gn),e(gn,txr),e(gn,N4e),e(N4e,axr),e(gn,nxr),e(gn,q4e),e(q4e,sxr),e(gn,lxr),e(gn,j4e),e(j4e,ixr),e(gn,dxr),e(Br,cxr),e(Br,_e),e(_e,MC),e(MC,D4e),e(D4e,fxr),e(MC,mxr),e(MC,mK),e(mK,gxr),e(MC,hxr),e(_e,pxr),e(_e,EC),e(EC,G4e),e(G4e,_xr),e(EC,uxr),e(EC,gK),e(gK,bxr),e(EC,vxr),e(_e,Fxr),e(_e,CC),e(CC,O4e),e(O4e,Txr),e(CC,Mxr),e(CC,hK),e(hK,Exr),e(CC,Cxr),e(_e,wxr),e(_e,wC),e(wC,V4e),e(V4e,Axr),e(wC,Lxr),e(wC,pK),e(pK,yxr),e(wC,xxr),e(_e,$xr),e(_e,AC),e(AC,X4e),e(X4e,kxr),e(AC,Sxr),e(AC,_K),e(_K,Rxr),e(AC,Pxr),e(_e,Bxr),e(_e,LC),e(LC,z4e),e(z4e,Ixr),e(LC,Nxr),e(LC,uK),e(uK,qxr),e(LC,jxr),e(_e,Dxr),e(_e,yC),e(yC,Q4e),e(Q4e,Gxr),e(yC,Oxr),e(yC,bK),e(bK,Vxr),e(yC,Xxr),e(_e,zxr),e(_e,xC),e(xC,W4e),e(W4e,Qxr),e(xC,Wxr),e(xC,vK),e(vK,Hxr),e(xC,Uxr),e(_e,Jxr),e(_e,$C),e($C,H4e),e(H4e,Yxr),e($C,Kxr),e($C,FK),e(FK,Zxr),e($C,e$r),e(_e,o$r),e(_e,kC),e(kC,U4e),e(U4e,r$r),e(kC,t$r),e(kC,TK),e(TK,a$r),e(kC,n$r),e(_e,s$r),e(_e,SC),e(SC,J4e),e(J4e,l$r),e(SC,i$r),e(SC,MK),e(MK,d$r),e(SC,c$r),e(_e,f$r),e(_e,RC),e(RC,Y4e),e(Y4e,m$r),e(RC,g$r),e(RC,EK),e(EK,h$r),e(RC,p$r),e(_e,_$r),e(_e,PC),e(PC,K4e),e(K4e,u$r),e(PC,b$r),e(PC,CK),e(CK,v$r),e(PC,F$r),e(_e,T$r),e(_e,BC),e(BC,Z4e),e(Z4e,M$r),e(BC,E$r),e(BC,wK),e(wK,C$r),e(BC,w$r),e(_e,A$r),e(_e,IC),e(IC,eEe),e(eEe,L$r),e(IC,y$r),e(IC,AK),e(AK,x$r),e(IC,$$r),e(_e,k$r),e(_e,NC),e(NC,oEe),e(oEe,S$r),e(NC,R$r),e(NC,LK),e(LK,P$r),e(NC,B$r),e(_e,I$r),e(_e,qC),e(qC,rEe),e(rEe,N$r),e(qC,q$r),e(qC,yK),e(yK,j$r),e(qC,D$r),e(Br,G$r),M(jC,Br,null),b(f,lze,u),b(f,xc,u),e(xc,DC),e(DC,tEe),M(Lx,tEe,null),e(xc,O$r),e(xc,aEe),e(aEe,V$r),b(f,ize,u),b(f,ir,u),M(yx,ir,null),e(ir,X$r),e(ir,$c),e($c,z$r),e($c,xK),e(xK,Q$r),e($c,W$r),e($c,$K),e($K,H$r),e($c,U$r),e(ir,J$r),e(ir,xx),e(xx,Y$r),e(xx,nEe),e(nEe,K$r),e(xx,Z$r),e(ir,ekr),e(ir,Dt),M($x,Dt,null),e(Dt,okr),e(Dt,sEe),e(sEe,rkr),e(Dt,tkr),e(Dt,kc),e(kc,akr),e(kc,lEe),e(lEe,nkr),e(kc,skr),e(kc,kK),e(kK,lkr),e(kc,ikr),e(Dt,dkr),M(GC,Dt,null),e(ir,ckr),e(ir,Ir),M(kx,Ir,null),e(Ir,fkr),e(Ir,iEe),e(iEe,mkr),e(Ir,gkr),e(Ir,hn),e(hn,hkr),e(hn,dEe),e(dEe,pkr),e(hn,_kr),e(hn,cEe),e(cEe,ukr),e(hn,bkr),e(hn,fEe),e(fEe,vkr),e(hn,Fkr),e(Ir,Tkr),e(Ir,Sx),e(Sx,OC),e(OC,mEe),e(mEe,Mkr),e(OC,Ekr),e(OC,SK),e(SK,Ckr),e(OC,wkr),e(Sx,Akr),e(Sx,VC),e(VC,gEe),e(gEe,Lkr),e(VC,ykr),e(VC,RK),e(RK,xkr),e(VC,$kr),e(Ir,kkr),M(XC,Ir,null),b(f,dze,u),b(f,Sc,u),e(Sc,zC),e(zC,hEe),M(Rx,hEe,null),e(Sc,Skr),e(Sc,pEe),e(pEe,Rkr),b(f,cze,u),b(f,dr,u),M(Px,dr,null),e(dr,Pkr),e(dr,Rc),e(Rc,Bkr),e(Rc,PK),e(PK,Ikr),e(Rc,Nkr),e(Rc,BK),e(BK,qkr),e(Rc,jkr),e(dr,Dkr),e(dr,Bx),e(Bx,Gkr),e(Bx,_Ee),e(_Ee,Okr),e(Bx,Vkr),e(dr,Xkr),e(dr,Gt),M(Ix,Gt,null),e(Gt,zkr),e(Gt,uEe),e(uEe,Qkr),e(Gt,Wkr),e(Gt,Pc),e(Pc,Hkr),e(Pc,bEe),e(bEe,Ukr),e(Pc,Jkr),e(Pc,IK),e(IK,Ykr),e(Pc,Kkr),e(Gt,Zkr),M(QC,Gt,null),e(dr,eSr),e(dr,Nr),M(Nx,Nr,null),e(Nr,oSr),e(Nr,vEe),e(vEe,rSr),e(Nr,tSr),e(Nr,pn),e(pn,aSr),e(pn,FEe),e(FEe,nSr),e(pn,sSr),e(pn,TEe),e(TEe,lSr),e(pn,iSr),e(pn,MEe),e(MEe,dSr),e(pn,cSr),e(Nr,fSr),e(Nr,EEe),e(EEe,WC),e(WC,CEe),e(CEe,mSr),e(WC,gSr),e(WC,NK),e(NK,hSr),e(WC,pSr),e(Nr,_Sr),M(HC,Nr,null),b(f,fze,u),b(f,Bc,u),e(Bc,UC),e(UC,wEe),M(qx,wEe,null),e(Bc,uSr),e(Bc,AEe),e(AEe,bSr),b(f,mze,u),b(f,cr,u),M(jx,cr,null),e(cr,vSr),e(cr,Ic),e(Ic,FSr),e(Ic,qK),e(qK,TSr),e(Ic,MSr),e(Ic,jK),e(jK,ESr),e(Ic,CSr),e(cr,wSr),e(cr,Dx),e(Dx,ASr),e(Dx,LEe),e(LEe,LSr),e(Dx,ySr),e(cr,xSr),e(cr,Ot),M(Gx,Ot,null),e(Ot,$Sr),e(Ot,yEe),e(yEe,kSr),e(Ot,SSr),e(Ot,Nc),e(Nc,RSr),e(Nc,xEe),e(xEe,PSr),e(Nc,BSr),e(Nc,DK),e(DK,ISr),e(Nc,NSr),e(Ot,qSr),M(JC,Ot,null),e(cr,jSr),e(cr,qr),M(Ox,qr,null),e(qr,DSr),e(qr,$Ee),e($Ee,GSr),e(qr,OSr),e(qr,_n),e(_n,VSr),e(_n,kEe),e(kEe,XSr),e(_n,zSr),e(_n,SEe),e(SEe,QSr),e(_n,WSr),e(_n,REe),e(REe,HSr),e(_n,USr),e(qr,JSr),e(qr,de),e(de,YC),e(YC,PEe),e(PEe,YSr),e(YC,KSr),e(YC,GK),e(GK,ZSr),e(YC,eRr),e(de,oRr),e(de,KC),e(KC,BEe),e(BEe,rRr),e(KC,tRr),e(KC,OK),e(OK,aRr),e(KC,nRr),e(de,sRr),e(de,ZC),e(ZC,IEe),e(IEe,lRr),e(ZC,iRr),e(ZC,VK),e(VK,dRr),e(ZC,cRr),e(de,fRr),e(de,e3),e(e3,NEe),e(NEe,mRr),e(e3,gRr),e(e3,XK),e(XK,hRr),e(e3,pRr),e(de,_Rr),e(de,o3),e(o3,qEe),e(qEe,uRr),e(o3,bRr),e(o3,zK),e(zK,vRr),e(o3,FRr),e(de,TRr),e(de,r3),e(r3,jEe),e(jEe,MRr),e(r3,ERr),e(r3,QK),e(QK,CRr),e(r3,wRr),e(de,ARr),e(de,t3),e(t3,DEe),e(DEe,LRr),e(t3,yRr),e(t3,WK),e(WK,xRr),e(t3,$Rr),e(de,kRr),e(de,a3),e(a3,GEe),e(GEe,SRr),e(a3,RRr),e(a3,HK),e(HK,PRr),e(a3,BRr),e(de,IRr),e(de,n3),e(n3,OEe),e(OEe,NRr),e(n3,qRr),e(n3,UK),e(UK,jRr),e(n3,DRr),e(de,GRr),e(de,s3),e(s3,VEe),e(VEe,ORr),e(s3,VRr),e(s3,JK),e(JK,XRr),e(s3,zRr),e(de,QRr),e(de,l3),e(l3,XEe),e(XEe,WRr),e(l3,HRr),e(l3,YK),e(YK,URr),e(l3,JRr),e(de,YRr),e(de,i3),e(i3,zEe),e(zEe,KRr),e(i3,ZRr),e(i3,KK),e(KK,ePr),e(i3,oPr),e(de,rPr),e(de,d3),e(d3,QEe),e(QEe,tPr),e(d3,aPr),e(d3,ZK),e(ZK,nPr),e(d3,sPr),e(de,lPr),e(de,c3),e(c3,WEe),e(WEe,iPr),e(c3,dPr),e(c3,eZ),e(eZ,cPr),e(c3,fPr),e(de,mPr),e(de,f3),e(f3,HEe),e(HEe,gPr),e(f3,hPr),e(f3,oZ),e(oZ,pPr),e(f3,_Pr),e(de,uPr),e(de,m3),e(m3,UEe),e(UEe,bPr),e(m3,vPr),e(m3,rZ),e(rZ,FPr),e(m3,TPr),e(de,MPr),e(de,g3),e(g3,JEe),e(JEe,EPr),e(g3,CPr),e(g3,tZ),e(tZ,wPr),e(g3,APr),e(de,LPr),e(de,h3),e(h3,YEe),e(YEe,yPr),e(h3,xPr),e(h3,aZ),e(aZ,$Pr),e(h3,kPr),e(de,SPr),e(de,p3),e(p3,KEe),e(KEe,RPr),e(p3,PPr),e(p3,nZ),e(nZ,BPr),e(p3,IPr),e(de,NPr),e(de,_3),e(_3,ZEe),e(ZEe,qPr),e(_3,jPr),e(_3,sZ),e(sZ,DPr),e(_3,GPr),e(qr,OPr),M(u3,qr,null),b(f,gze,u),b(f,qc,u),e(qc,b3),e(b3,eCe),M(Vx,eCe,null),e(qc,VPr),e(qc,oCe),e(oCe,XPr),b(f,hze,u),b(f,fr,u),M(Xx,fr,null),e(fr,zPr),e(fr,jc),e(jc,QPr),e(jc,lZ),e(lZ,WPr),e(jc,HPr),e(jc,iZ),e(iZ,UPr),e(jc,JPr),e(fr,YPr),e(fr,zx),e(zx,KPr),e(zx,rCe),e(rCe,ZPr),e(zx,eBr),e(fr,oBr),e(fr,Vt),M(Qx,Vt,null),e(Vt,rBr),e(Vt,tCe),e(tCe,tBr),e(Vt,aBr),e(Vt,Dc),e(Dc,nBr),e(Dc,aCe),e(aCe,sBr),e(Dc,lBr),e(Dc,dZ),e(dZ,iBr),e(Dc,dBr),e(Vt,cBr),M(v3,Vt,null),e(fr,fBr),e(fr,jr),M(Wx,jr,null),e(jr,mBr),e(jr,nCe),e(nCe,gBr),e(jr,hBr),e(jr,un),e(un,pBr),e(un,sCe),e(sCe,_Br),e(un,uBr),e(un,lCe),e(lCe,bBr),e(un,vBr),e(un,iCe),e(iCe,FBr),e(un,TBr),e(jr,MBr),e(jr,ce),e(ce,F3),e(F3,dCe),e(dCe,EBr),e(F3,CBr),e(F3,cZ),e(cZ,wBr),e(F3,ABr),e(ce,LBr),e(ce,T3),e(T3,cCe),e(cCe,yBr),e(T3,xBr),e(T3,fZ),e(fZ,$Br),e(T3,kBr),e(ce,SBr),e(ce,M3),e(M3,fCe),e(fCe,RBr),e(M3,PBr),e(M3,mZ),e(mZ,BBr),e(M3,IBr),e(ce,NBr),e(ce,E3),e(E3,mCe),e(mCe,qBr),e(E3,jBr),e(E3,gZ),e(gZ,DBr),e(E3,GBr),e(ce,OBr),e(ce,C3),e(C3,gCe),e(gCe,VBr),e(C3,XBr),e(C3,hZ),e(hZ,zBr),e(C3,QBr),e(ce,WBr),e(ce,w3),e(w3,hCe),e(hCe,HBr),e(w3,UBr),e(w3,pZ),e(pZ,JBr),e(w3,YBr),e(ce,KBr),e(ce,A3),e(A3,pCe),e(pCe,ZBr),e(A3,eIr),e(A3,_Z),e(_Z,oIr),e(A3,rIr),e(ce,tIr),e(ce,L3),e(L3,_Ce),e(_Ce,aIr),e(L3,nIr),e(L3,uZ),e(uZ,sIr),e(L3,lIr),e(ce,iIr),e(ce,y3),e(y3,uCe),e(uCe,dIr),e(y3,cIr),e(y3,bZ),e(bZ,fIr),e(y3,mIr),e(ce,gIr),e(ce,x3),e(x3,bCe),e(bCe,hIr),e(x3,pIr),e(x3,vZ),e(vZ,_Ir),e(x3,uIr),e(ce,bIr),e(ce,$3),e($3,vCe),e(vCe,vIr),e($3,FIr),e($3,FZ),e(FZ,TIr),e($3,MIr),e(ce,EIr),e(ce,k3),e(k3,FCe),e(FCe,CIr),e(k3,wIr),e(k3,TZ),e(TZ,AIr),e(k3,LIr),e(ce,yIr),e(ce,S3),e(S3,TCe),e(TCe,xIr),e(S3,$Ir),e(S3,MZ),e(MZ,kIr),e(S3,SIr),e(ce,RIr),e(ce,R3),e(R3,MCe),e(MCe,PIr),e(R3,BIr),e(R3,EZ),e(EZ,IIr),e(R3,NIr),e(ce,qIr),e(ce,P3),e(P3,ECe),e(ECe,jIr),e(P3,DIr),e(P3,CZ),e(CZ,GIr),e(P3,OIr),e(ce,VIr),e(ce,B3),e(B3,CCe),e(CCe,XIr),e(B3,zIr),e(B3,wZ),e(wZ,QIr),e(B3,WIr),e(ce,HIr),e(ce,I3),e(I3,wCe),e(wCe,UIr),e(I3,JIr),e(I3,AZ),e(AZ,YIr),e(I3,KIr),e(ce,ZIr),e(ce,N3),e(N3,ACe),e(ACe,eNr),e(N3,oNr),e(N3,LZ),e(LZ,rNr),e(N3,tNr),e(ce,aNr),e(ce,q3),e(q3,LCe),e(LCe,nNr),e(q3,sNr),e(q3,yZ),e(yZ,lNr),e(q3,iNr),e(ce,dNr),e(ce,j3),e(j3,yCe),e(yCe,cNr),e(j3,fNr),e(j3,xZ),e(xZ,mNr),e(j3,gNr),e(jr,hNr),M(D3,jr,null),b(f,pze,u),b(f,Gc,u),e(Gc,G3),e(G3,xCe),M(Hx,xCe,null),e(Gc,pNr),e(Gc,$Ce),e($Ce,_Nr),b(f,_ze,u),b(f,mr,u),M(Ux,mr,null),e(mr,uNr),e(mr,Oc),e(Oc,bNr),e(Oc,$Z),e($Z,vNr),e(Oc,FNr),e(Oc,kZ),e(kZ,TNr),e(Oc,MNr),e(mr,ENr),e(mr,Jx),e(Jx,CNr),e(Jx,kCe),e(kCe,wNr),e(Jx,ANr),e(mr,LNr),e(mr,Xt),M(Yx,Xt,null),e(Xt,yNr),e(Xt,SCe),e(SCe,xNr),e(Xt,$Nr),e(Xt,Vc),e(Vc,kNr),e(Vc,RCe),e(RCe,SNr),e(Vc,RNr),e(Vc,SZ),e(SZ,PNr),e(Vc,BNr),e(Xt,INr),M(O3,Xt,null),e(mr,NNr),e(mr,Dr),M(Kx,Dr,null),e(Dr,qNr),e(Dr,PCe),e(PCe,jNr),e(Dr,DNr),e(Dr,bn),e(bn,GNr),e(bn,BCe),e(BCe,ONr),e(bn,VNr),e(bn,ICe),e(ICe,XNr),e(bn,zNr),e(bn,NCe),e(NCe,QNr),e(bn,WNr),e(Dr,HNr),e(Dr,qCe),e(qCe,V3),e(V3,jCe),e(jCe,UNr),e(V3,JNr),e(V3,RZ),e(RZ,YNr),e(V3,KNr),e(Dr,ZNr),M(X3,Dr,null),b(f,uze,u),b(f,Xc,u),e(Xc,z3),e(z3,DCe),M(Zx,DCe,null),e(Xc,eqr),e(Xc,GCe),e(GCe,oqr),b(f,bze,u),b(f,gr,u),M(e$,gr,null),e(gr,rqr),e(gr,zc),e(zc,tqr),e(zc,PZ),e(PZ,aqr),e(zc,nqr),e(zc,BZ),e(BZ,sqr),e(zc,lqr),e(gr,iqr),e(gr,o$),e(o$,dqr),e(o$,OCe),e(OCe,cqr),e(o$,fqr),e(gr,mqr),e(gr,zt),M(r$,zt,null),e(zt,gqr),e(zt,VCe),e(VCe,hqr),e(zt,pqr),e(zt,Qc),e(Qc,_qr),e(Qc,XCe),e(XCe,uqr),e(Qc,bqr),e(Qc,IZ),e(IZ,vqr),e(Qc,Fqr),e(zt,Tqr),M(Q3,zt,null),e(gr,Mqr),e(gr,Gr),M(t$,Gr,null),e(Gr,Eqr),e(Gr,zCe),e(zCe,Cqr),e(Gr,wqr),e(Gr,vn),e(vn,Aqr),e(vn,QCe),e(QCe,Lqr),e(vn,yqr),e(vn,WCe),e(WCe,xqr),e(vn,$qr),e(vn,HCe),e(HCe,kqr),e(vn,Sqr),e(Gr,Rqr),e(Gr,UCe),e(UCe,W3),e(W3,JCe),e(JCe,Pqr),e(W3,Bqr),e(W3,NZ),e(NZ,Iqr),e(W3,Nqr),e(Gr,qqr),M(H3,Gr,null),b(f,vze,u),b(f,Wc,u),e(Wc,U3),e(U3,YCe),M(a$,YCe,null),e(Wc,jqr),e(Wc,KCe),e(KCe,Dqr),b(f,Fze,u),b(f,hr,u),M(n$,hr,null),e(hr,Gqr),e(hr,Hc),e(Hc,Oqr),e(Hc,qZ),e(qZ,Vqr),e(Hc,Xqr),e(Hc,jZ),e(jZ,zqr),e(Hc,Qqr),e(hr,Wqr),e(hr,s$),e(s$,Hqr),e(s$,ZCe),e(ZCe,Uqr),e(s$,Jqr),e(hr,Yqr),e(hr,Qt),M(l$,Qt,null),e(Qt,Kqr),e(Qt,e3e),e(e3e,Zqr),e(Qt,ejr),e(Qt,Uc),e(Uc,ojr),e(Uc,o3e),e(o3e,rjr),e(Uc,tjr),e(Uc,DZ),e(DZ,ajr),e(Uc,njr),e(Qt,sjr),M(J3,Qt,null),e(hr,ljr),e(hr,Or),M(i$,Or,null),e(Or,ijr),e(Or,r3e),e(r3e,djr),e(Or,cjr),e(Or,Fn),e(Fn,fjr),e(Fn,t3e),e(t3e,mjr),e(Fn,gjr),e(Fn,a3e),e(a3e,hjr),e(Fn,pjr),e(Fn,n3e),e(n3e,_jr),e(Fn,ujr),e(Or,bjr),e(Or,oe),e(oe,Y3),e(Y3,s3e),e(s3e,vjr),e(Y3,Fjr),e(Y3,GZ),e(GZ,Tjr),e(Y3,Mjr),e(oe,Ejr),e(oe,K3),e(K3,l3e),e(l3e,Cjr),e(K3,wjr),e(K3,OZ),e(OZ,Ajr),e(K3,Ljr),e(oe,yjr),e(oe,Z3),e(Z3,i3e),e(i3e,xjr),e(Z3,$jr),e(Z3,VZ),e(VZ,kjr),e(Z3,Sjr),e(oe,Rjr),e(oe,e5),e(e5,d3e),e(d3e,Pjr),e(e5,Bjr),e(e5,XZ),e(XZ,Ijr),e(e5,Njr),e(oe,qjr),e(oe,o5),e(o5,c3e),e(c3e,jjr),e(o5,Djr),e(o5,zZ),e(zZ,Gjr),e(o5,Ojr),e(oe,Vjr),e(oe,r5),e(r5,f3e),e(f3e,Xjr),e(r5,zjr),e(r5,QZ),e(QZ,Qjr),e(r5,Wjr),e(oe,Hjr),e(oe,t5),e(t5,m3e),e(m3e,Ujr),e(t5,Jjr),e(t5,WZ),e(WZ,Yjr),e(t5,Kjr),e(oe,Zjr),e(oe,a5),e(a5,g3e),e(g3e,eDr),e(a5,oDr),e(a5,HZ),e(HZ,rDr),e(a5,tDr),e(oe,aDr),e(oe,n5),e(n5,h3e),e(h3e,nDr),e(n5,sDr),e(n5,UZ),e(UZ,lDr),e(n5,iDr),e(oe,dDr),e(oe,s5),e(s5,p3e),e(p3e,cDr),e(s5,fDr),e(s5,JZ),e(JZ,mDr),e(s5,gDr),e(oe,hDr),e(oe,l5),e(l5,_3e),e(_3e,pDr),e(l5,_Dr),e(l5,YZ),e(YZ,uDr),e(l5,bDr),e(oe,vDr),e(oe,i5),e(i5,u3e),e(u3e,FDr),e(i5,TDr),e(i5,KZ),e(KZ,MDr),e(i5,EDr),e(oe,CDr),e(oe,d5),e(d5,b3e),e(b3e,wDr),e(d5,ADr),e(d5,ZZ),e(ZZ,LDr),e(d5,yDr),e(oe,xDr),e(oe,c5),e(c5,v3e),e(v3e,$Dr),e(c5,kDr),e(c5,eee),e(eee,SDr),e(c5,RDr),e(oe,PDr),e(oe,f5),e(f5,F3e),e(F3e,BDr),e(f5,IDr),e(f5,oee),e(oee,NDr),e(f5,qDr),e(oe,jDr),e(oe,m5),e(m5,T3e),e(T3e,DDr),e(m5,GDr),e(m5,ree),e(ree,ODr),e(m5,VDr),e(oe,XDr),e(oe,g5),e(g5,M3e),e(M3e,zDr),e(g5,QDr),e(g5,tee),e(tee,WDr),e(g5,HDr),e(oe,UDr),e(oe,h5),e(h5,E3e),e(E3e,JDr),e(h5,YDr),e(h5,aee),e(aee,KDr),e(h5,ZDr),e(oe,eGr),e(oe,p5),e(p5,C3e),e(C3e,oGr),e(p5,rGr),e(p5,nee),e(nee,tGr),e(p5,aGr),e(oe,nGr),e(oe,_5),e(_5,w3e),e(w3e,sGr),e(_5,lGr),e(_5,see),e(see,iGr),e(_5,dGr),e(oe,cGr),e(oe,u5),e(u5,A3e),e(A3e,fGr),e(u5,mGr),e(u5,lee),e(lee,gGr),e(u5,hGr),e(oe,pGr),e(oe,b5),e(b5,L3e),e(L3e,_Gr),e(b5,uGr),e(b5,iee),e(iee,bGr),e(b5,vGr),e(oe,FGr),e(oe,v5),e(v5,y3e),e(y3e,TGr),e(v5,MGr),e(v5,dee),e(dee,EGr),e(v5,CGr),e(oe,wGr),e(oe,F5),e(F5,x3e),e(x3e,AGr),e(F5,LGr),e(F5,cee),e(cee,yGr),e(F5,xGr),e(oe,$Gr),e(oe,T5),e(T5,$3e),e($3e,kGr),e(T5,SGr),e(T5,fee),e(fee,RGr),e(T5,PGr),e(oe,BGr),e(oe,M5),e(M5,k3e),e(k3e,IGr),e(M5,NGr),e(M5,mee),e(mee,qGr),e(M5,jGr),e(oe,DGr),e(oe,E5),e(E5,S3e),e(S3e,GGr),e(E5,OGr),e(E5,gee),e(gee,VGr),e(E5,XGr),e(Or,zGr),M(C5,Or,null),b(f,Tze,u),b(f,Jc,u),e(Jc,w5),e(w5,R3e),M(d$,R3e,null),e(Jc,QGr),e(Jc,P3e),e(P3e,WGr),b(f,Mze,u),b(f,pr,u),M(c$,pr,null),e(pr,HGr),e(pr,Yc),e(Yc,UGr),e(Yc,hee),e(hee,JGr),e(Yc,YGr),e(Yc,pee),e(pee,KGr),e(Yc,ZGr),e(pr,eOr),e(pr,f$),e(f$,oOr),e(f$,B3e),e(B3e,rOr),e(f$,tOr),e(pr,aOr),e(pr,Wt),M(m$,Wt,null),e(Wt,nOr),e(Wt,I3e),e(I3e,sOr),e(Wt,lOr),e(Wt,Kc),e(Kc,iOr),e(Kc,N3e),e(N3e,dOr),e(Kc,cOr),e(Kc,_ee),e(_ee,fOr),e(Kc,mOr),e(Wt,gOr),M(A5,Wt,null),e(pr,hOr),e(pr,Vr),M(g$,Vr,null),e(Vr,pOr),e(Vr,q3e),e(q3e,_Or),e(Vr,uOr),e(Vr,Tn),e(Tn,bOr),e(Tn,j3e),e(j3e,vOr),e(Tn,FOr),e(Tn,D3e),e(D3e,TOr),e(Tn,MOr),e(Tn,G3e),e(G3e,EOr),e(Tn,COr),e(Vr,wOr),e(Vr,xe),e(xe,L5),e(L5,O3e),e(O3e,AOr),e(L5,LOr),e(L5,uee),e(uee,yOr),e(L5,xOr),e(xe,$Or),e(xe,y5),e(y5,V3e),e(V3e,kOr),e(y5,SOr),e(y5,bee),e(bee,ROr),e(y5,POr),e(xe,BOr),e(xe,x5),e(x5,X3e),e(X3e,IOr),e(x5,NOr),e(x5,vee),e(vee,qOr),e(x5,jOr),e(xe,DOr),e(xe,$5),e($5,z3e),e(z3e,GOr),e($5,OOr),e($5,Fee),e(Fee,VOr),e($5,XOr),e(xe,zOr),e(xe,k5),e(k5,Q3e),e(Q3e,QOr),e(k5,WOr),e(k5,Tee),e(Tee,HOr),e(k5,UOr),e(xe,JOr),e(xe,S5),e(S5,W3e),e(W3e,YOr),e(S5,KOr),e(S5,Mee),e(Mee,ZOr),e(S5,eVr),e(xe,oVr),e(xe,R5),e(R5,H3e),e(H3e,rVr),e(R5,tVr),e(R5,Eee),e(Eee,aVr),e(R5,nVr),e(xe,sVr),e(xe,P5),e(P5,U3e),e(U3e,lVr),e(P5,iVr),e(P5,Cee),e(Cee,dVr),e(P5,cVr),e(xe,fVr),e(xe,B5),e(B5,J3e),e(J3e,mVr),e(B5,gVr),e(B5,wee),e(wee,hVr),e(B5,pVr),e(xe,_Vr),e(xe,I5),e(I5,Y3e),e(Y3e,uVr),e(I5,bVr),e(I5,Aee),e(Aee,vVr),e(I5,FVr),e(Vr,TVr),M(N5,Vr,null),b(f,Eze,u),b(f,Zc,u),e(Zc,q5),e(q5,K3e),M(h$,K3e,null),e(Zc,MVr),e(Zc,Z3e),e(Z3e,EVr),b(f,Cze,u),b(f,_r,u),M(p$,_r,null),e(_r,CVr),e(_r,ef),e(ef,wVr),e(ef,Lee),e(Lee,AVr),e(ef,LVr),e(ef,yee),e(yee,yVr),e(ef,xVr),e(_r,$Vr),e(_r,_$),e(_$,kVr),e(_$,e5e),e(e5e,SVr),e(_$,RVr),e(_r,PVr),e(_r,Ht),M(u$,Ht,null),e(Ht,BVr),e(Ht,o5e),e(o5e,IVr),e(Ht,NVr),e(Ht,of),e(of,qVr),e(of,r5e),e(r5e,jVr),e(of,DVr),e(of,xee),e(xee,GVr),e(of,OVr),e(Ht,VVr),M(j5,Ht,null),e(_r,XVr),e(_r,Xr),M(b$,Xr,null),e(Xr,zVr),e(Xr,t5e),e(t5e,QVr),e(Xr,WVr),e(Xr,Mn),e(Mn,HVr),e(Mn,a5e),e(a5e,UVr),e(Mn,JVr),e(Mn,n5e),e(n5e,YVr),e(Mn,KVr),e(Mn,s5e),e(s5e,ZVr),e(Mn,eXr),e(Xr,oXr),e(Xr,Ee),e(Ee,D5),e(D5,l5e),e(l5e,rXr),e(D5,tXr),e(D5,$ee),e($ee,aXr),e(D5,nXr),e(Ee,sXr),e(Ee,G5),e(G5,i5e),e(i5e,lXr),e(G5,iXr),e(G5,kee),e(kee,dXr),e(G5,cXr),e(Ee,fXr),e(Ee,O5),e(O5,d5e),e(d5e,mXr),e(O5,gXr),e(O5,See),e(See,hXr),e(O5,pXr),e(Ee,_Xr),e(Ee,V5),e(V5,c5e),e(c5e,uXr),e(V5,bXr),e(V5,Ree),e(Ree,vXr),e(V5,FXr),e(Ee,TXr),e(Ee,X5),e(X5,f5e),e(f5e,MXr),e(X5,EXr),e(X5,Pee),e(Pee,CXr),e(X5,wXr),e(Ee,AXr),e(Ee,z5),e(z5,m5e),e(m5e,LXr),e(z5,yXr),e(z5,Bee),e(Bee,xXr),e(z5,$Xr),e(Ee,kXr),e(Ee,Q5),e(Q5,g5e),e(g5e,SXr),e(Q5,RXr),e(Q5,Iee),e(Iee,PXr),e(Q5,BXr),e(Ee,IXr),e(Ee,W5),e(W5,h5e),e(h5e,NXr),e(W5,qXr),e(W5,Nee),e(Nee,jXr),e(W5,DXr),e(Ee,GXr),e(Ee,H5),e(H5,p5e),e(p5e,OXr),e(H5,VXr),e(H5,qee),e(qee,XXr),e(H5,zXr),e(Ee,QXr),e(Ee,U5),e(U5,_5e),e(_5e,WXr),e(U5,HXr),e(U5,jee),e(jee,UXr),e(U5,JXr),e(Ee,YXr),e(Ee,J5),e(J5,u5e),e(u5e,KXr),e(J5,ZXr),e(J5,Dee),e(Dee,ezr),e(J5,ozr),e(Ee,rzr),e(Ee,Y5),e(Y5,b5e),e(b5e,tzr),e(Y5,azr),e(Y5,Gee),e(Gee,nzr),e(Y5,szr),e(Ee,lzr),e(Ee,K5),e(K5,v5e),e(v5e,izr),e(K5,dzr),e(K5,Oee),e(Oee,czr),e(K5,fzr),e(Xr,mzr),M(Z5,Xr,null),b(f,wze,u),b(f,rf,u),e(rf,e0),e(e0,F5e),M(v$,F5e,null),e(rf,gzr),e(rf,T5e),e(T5e,hzr),b(f,Aze,u),b(f,ur,u),M(F$,ur,null),e(ur,pzr),e(ur,tf),e(tf,_zr),e(tf,Vee),e(Vee,uzr),e(tf,bzr),e(tf,Xee),e(Xee,vzr),e(tf,Fzr),e(ur,Tzr),e(ur,T$),e(T$,Mzr),e(T$,M5e),e(M5e,Ezr),e(T$,Czr),e(ur,wzr),e(ur,Ut),M(M$,Ut,null),e(Ut,Azr),e(Ut,E5e),e(E5e,Lzr),e(Ut,yzr),e(Ut,af),e(af,xzr),e(af,C5e),e(C5e,$zr),e(af,kzr),e(af,zee),e(zee,Szr),e(af,Rzr),e(Ut,Pzr),M(o0,Ut,null),e(ur,Bzr),e(ur,zr),M(E$,zr,null),e(zr,Izr),e(zr,w5e),e(w5e,Nzr),e(zr,qzr),e(zr,En),e(En,jzr),e(En,A5e),e(A5e,Dzr),e(En,Gzr),e(En,L5e),e(L5e,Ozr),e(En,Vzr),e(En,y5e),e(y5e,Xzr),e(En,zzr),e(zr,Qzr),e(zr,$e),e($e,r0),e(r0,x5e),e(x5e,Wzr),e(r0,Hzr),e(r0,Qee),e(Qee,Uzr),e(r0,Jzr),e($e,Yzr),e($e,t0),e(t0,$5e),e($5e,Kzr),e(t0,Zzr),e(t0,Wee),e(Wee,eQr),e(t0,oQr),e($e,rQr),e($e,a0),e(a0,k5e),e(k5e,tQr),e(a0,aQr),e(a0,Hee),e(Hee,nQr),e(a0,sQr),e($e,lQr),e($e,n0),e(n0,S5e),e(S5e,iQr),e(n0,dQr),e(n0,Uee),e(Uee,cQr),e(n0,fQr),e($e,mQr),e($e,s0),e(s0,R5e),e(R5e,gQr),e(s0,hQr),e(s0,Jee),e(Jee,pQr),e(s0,_Qr),e($e,uQr),e($e,l0),e(l0,P5e),e(P5e,bQr),e(l0,vQr),e(l0,Yee),e(Yee,FQr),e(l0,TQr),e($e,MQr),e($e,i0),e(i0,B5e),e(B5e,EQr),e(i0,CQr),e(i0,Kee),e(Kee,wQr),e(i0,AQr),e($e,LQr),e($e,d0),e(d0,I5e),e(I5e,yQr),e(d0,xQr),e(d0,Zee),e(Zee,$Qr),e(d0,kQr),e($e,SQr),e($e,c0),e(c0,N5e),e(N5e,RQr),e(c0,PQr),e(c0,eoe),e(eoe,BQr),e(c0,IQr),e($e,NQr),e($e,f0),e(f0,q5e),e(q5e,qQr),e(f0,jQr),e(f0,ooe),e(ooe,DQr),e(f0,GQr),e(zr,OQr),M(m0,zr,null),b(f,Lze,u),b(f,nf,u),e(nf,g0),e(g0,j5e),M(C$,j5e,null),e(nf,VQr),e(nf,D5e),e(D5e,XQr),b(f,yze,u),b(f,br,u),M(w$,br,null),e(br,zQr),e(br,sf),e(sf,QQr),e(sf,roe),e(roe,WQr),e(sf,HQr),e(sf,toe),e(toe,UQr),e(sf,JQr),e(br,YQr),e(br,A$),e(A$,KQr),e(A$,G5e),e(G5e,ZQr),e(A$,eWr),e(br,oWr),e(br,Jt),M(L$,Jt,null),e(Jt,rWr),e(Jt,O5e),e(O5e,tWr),e(Jt,aWr),e(Jt,lf),e(lf,nWr),e(lf,V5e),e(V5e,sWr),e(lf,lWr),e(lf,aoe),e(aoe,iWr),e(lf,dWr),e(Jt,cWr),M(h0,Jt,null),e(br,fWr),e(br,Qr),M(y$,Qr,null),e(Qr,mWr),e(Qr,X5e),e(X5e,gWr),e(Qr,hWr),e(Qr,Cn),e(Cn,pWr),e(Cn,z5e),e(z5e,_Wr),e(Cn,uWr),e(Cn,Q5e),e(Q5e,bWr),e(Cn,vWr),e(Cn,W5e),e(W5e,FWr),e(Cn,TWr),e(Qr,MWr),e(Qr,ke),e(ke,p0),e(p0,H5e),e(H5e,EWr),e(p0,CWr),e(p0,noe),e(noe,wWr),e(p0,AWr),e(ke,LWr),e(ke,_0),e(_0,U5e),e(U5e,yWr),e(_0,xWr),e(_0,soe),e(soe,$Wr),e(_0,kWr),e(ke,SWr),e(ke,u0),e(u0,J5e),e(J5e,RWr),e(u0,PWr),e(u0,loe),e(loe,BWr),e(u0,IWr),e(ke,NWr),e(ke,b0),e(b0,Y5e),e(Y5e,qWr),e(b0,jWr),e(b0,ioe),e(ioe,DWr),e(b0,GWr),e(ke,OWr),e(ke,v0),e(v0,K5e),e(K5e,VWr),e(v0,XWr),e(v0,doe),e(doe,zWr),e(v0,QWr),e(ke,WWr),e(ke,F0),e(F0,Z5e),e(Z5e,HWr),e(F0,UWr),e(F0,coe),e(coe,JWr),e(F0,YWr),e(ke,KWr),e(ke,T0),e(T0,e0e),e(e0e,ZWr),e(T0,eHr),e(T0,foe),e(foe,oHr),e(T0,rHr),e(ke,tHr),e(ke,M0),e(M0,o0e),e(o0e,aHr),e(M0,nHr),e(M0,moe),e(moe,sHr),e(M0,lHr),e(ke,iHr),e(ke,E0),e(E0,r0e),e(r0e,dHr),e(E0,cHr),e(E0,goe),e(goe,fHr),e(E0,mHr),e(ke,gHr),e(ke,C0),e(C0,t0e),e(t0e,hHr),e(C0,pHr),e(C0,hoe),e(hoe,_Hr),e(C0,uHr),e(Qr,bHr),M(w0,Qr,null),b(f,xze,u),b(f,df,u),e(df,A0),e(A0,a0e),M(x$,a0e,null),e(df,vHr),e(df,n0e),e(n0e,FHr),b(f,$ze,u),b(f,vr,u),M($$,vr,null),e(vr,THr),e(vr,cf),e(cf,MHr),e(cf,poe),e(poe,EHr),e(cf,CHr),e(cf,_oe),e(_oe,wHr),e(cf,AHr),e(vr,LHr),e(vr,k$),e(k$,yHr),e(k$,s0e),e(s0e,xHr),e(k$,$Hr),e(vr,kHr),e(vr,Yt),M(S$,Yt,null),e(Yt,SHr),e(Yt,l0e),e(l0e,RHr),e(Yt,PHr),e(Yt,ff),e(ff,BHr),e(ff,i0e),e(i0e,IHr),e(ff,NHr),e(ff,uoe),e(uoe,qHr),e(ff,jHr),e(Yt,DHr),M(L0,Yt,null),e(vr,GHr),e(vr,Wr),M(R$,Wr,null),e(Wr,OHr),e(Wr,d0e),e(d0e,VHr),e(Wr,XHr),e(Wr,wn),e(wn,zHr),e(wn,c0e),e(c0e,QHr),e(wn,WHr),e(wn,f0e),e(f0e,HHr),e(wn,UHr),e(wn,m0e),e(m0e,JHr),e(wn,YHr),e(Wr,KHr),e(Wr,Se),e(Se,y0),e(y0,g0e),e(g0e,ZHr),e(y0,eUr),e(y0,boe),e(boe,oUr),e(y0,rUr),e(Se,tUr),e(Se,x0),e(x0,h0e),e(h0e,aUr),e(x0,nUr),e(x0,voe),e(voe,sUr),e(x0,lUr),e(Se,iUr),e(Se,$0),e($0,p0e),e(p0e,dUr),e($0,cUr),e($0,Foe),e(Foe,fUr),e($0,mUr),e(Se,gUr),e(Se,k0),e(k0,_0e),e(_0e,hUr),e(k0,pUr),e(k0,Toe),e(Toe,_Ur),e(k0,uUr),e(Se,bUr),e(Se,S0),e(S0,u0e),e(u0e,vUr),e(S0,FUr),e(S0,Moe),e(Moe,TUr),e(S0,MUr),e(Se,EUr),e(Se,R0),e(R0,b0e),e(b0e,CUr),e(R0,wUr),e(R0,Eoe),e(Eoe,AUr),e(R0,LUr),e(Se,yUr),e(Se,P0),e(P0,v0e),e(v0e,xUr),e(P0,$Ur),e(P0,Coe),e(Coe,kUr),e(P0,SUr),e(Se,RUr),e(Se,B0),e(B0,F0e),e(F0e,PUr),e(B0,BUr),e(B0,woe),e(woe,IUr),e(B0,NUr),e(Se,qUr),e(Se,I0),e(I0,T0e),e(T0e,jUr),e(I0,DUr),e(I0,Aoe),e(Aoe,GUr),e(I0,OUr),e(Se,VUr),e(Se,N0),e(N0,M0e),e(M0e,XUr),e(N0,zUr),e(N0,Loe),e(Loe,QUr),e(N0,WUr),e(Wr,HUr),M(q0,Wr,null),b(f,kze,u),b(f,mf,u),e(mf,j0),e(j0,E0e),M(P$,E0e,null),e(mf,UUr),e(mf,C0e),e(C0e,JUr),b(f,Sze,u),b(f,Fr,u),M(B$,Fr,null),e(Fr,YUr),e(Fr,gf),e(gf,KUr),e(gf,yoe),e(yoe,ZUr),e(gf,eJr),e(gf,xoe),e(xoe,oJr),e(gf,rJr),e(Fr,tJr),e(Fr,I$),e(I$,aJr),e(I$,w0e),e(w0e,nJr),e(I$,sJr),e(Fr,lJr),e(Fr,Kt),M(N$,Kt,null),e(Kt,iJr),e(Kt,A0e),e(A0e,dJr),e(Kt,cJr),e(Kt,hf),e(hf,fJr),e(hf,L0e),e(L0e,mJr),e(hf,gJr),e(hf,$oe),e($oe,hJr),e(hf,pJr),e(Kt,_Jr),M(D0,Kt,null),e(Fr,uJr),e(Fr,Hr),M(q$,Hr,null),e(Hr,bJr),e(Hr,y0e),e(y0e,vJr),e(Hr,FJr),e(Hr,An),e(An,TJr),e(An,x0e),e(x0e,MJr),e(An,EJr),e(An,$0e),e($0e,CJr),e(An,wJr),e(An,k0e),e(k0e,AJr),e(An,LJr),e(Hr,yJr),e(Hr,Re),e(Re,G0),e(G0,S0e),e(S0e,xJr),e(G0,$Jr),e(G0,koe),e(koe,kJr),e(G0,SJr),e(Re,RJr),e(Re,O0),e(O0,R0e),e(R0e,PJr),e(O0,BJr),e(O0,Soe),e(Soe,IJr),e(O0,NJr),e(Re,qJr),e(Re,V0),e(V0,P0e),e(P0e,jJr),e(V0,DJr),e(V0,Roe),e(Roe,GJr),e(V0,OJr),e(Re,VJr),e(Re,X0),e(X0,B0e),e(B0e,XJr),e(X0,zJr),e(X0,Poe),e(Poe,QJr),e(X0,WJr),e(Re,HJr),e(Re,z0),e(z0,I0e),e(I0e,UJr),e(z0,JJr),e(z0,Boe),e(Boe,YJr),e(z0,KJr),e(Re,ZJr),e(Re,Q0),e(Q0,N0e),e(N0e,eYr),e(Q0,oYr),e(Q0,Ioe),e(Ioe,rYr),e(Q0,tYr),e(Re,aYr),e(Re,W0),e(W0,q0e),e(q0e,nYr),e(W0,sYr),e(W0,Noe),e(Noe,lYr),e(W0,iYr),e(Re,dYr),e(Re,H0),e(H0,j0e),e(j0e,cYr),e(H0,fYr),e(H0,qoe),e(qoe,mYr),e(H0,gYr),e(Re,hYr),e(Re,U0),e(U0,D0e),e(D0e,pYr),e(U0,_Yr),e(U0,joe),e(joe,uYr),e(U0,bYr),e(Re,vYr),e(Re,J0),e(J0,G0e),e(G0e,FYr),e(J0,TYr),e(J0,Doe),e(Doe,MYr),e(J0,EYr),e(Hr,CYr),M(Y0,Hr,null),b(f,Rze,u),b(f,pf,u),e(pf,K0),e(K0,O0e),M(j$,O0e,null),e(pf,wYr),e(pf,V0e),e(V0e,AYr),b(f,Pze,u),b(f,Tr,u),M(D$,Tr,null),e(Tr,LYr),e(Tr,_f),e(_f,yYr),e(_f,Goe),e(Goe,xYr),e(_f,$Yr),e(_f,Ooe),e(Ooe,kYr),e(_f,SYr),e(Tr,RYr),e(Tr,G$),e(G$,PYr),e(G$,X0e),e(X0e,BYr),e(G$,IYr),e(Tr,NYr),e(Tr,Zt),M(O$,Zt,null),e(Zt,qYr),e(Zt,z0e),e(z0e,jYr),e(Zt,DYr),e(Zt,uf),e(uf,GYr),e(uf,Q0e),e(Q0e,OYr),e(uf,VYr),e(uf,Voe),e(Voe,XYr),e(uf,zYr),e(Zt,QYr),M(Z0,Zt,null),e(Tr,WYr),e(Tr,Ur),M(V$,Ur,null),e(Ur,HYr),e(Ur,W0e),e(W0e,UYr),e(Ur,JYr),e(Ur,Ln),e(Ln,YYr),e(Ln,H0e),e(H0e,KYr),e(Ln,ZYr),e(Ln,U0e),e(U0e,eKr),e(Ln,oKr),e(Ln,J0e),e(J0e,rKr),e(Ln,tKr),e(Ur,aKr),e(Ur,Ve),e(Ve,ew),e(ew,Y0e),e(Y0e,nKr),e(ew,sKr),e(ew,Xoe),e(Xoe,lKr),e(ew,iKr),e(Ve,dKr),e(Ve,ow),e(ow,K0e),e(K0e,cKr),e(ow,fKr),e(ow,zoe),e(zoe,mKr),e(ow,gKr),e(Ve,hKr),e(Ve,rw),e(rw,Z0e),e(Z0e,pKr),e(rw,_Kr),e(rw,Qoe),e(Qoe,uKr),e(rw,bKr),e(Ve,vKr),e(Ve,tw),e(tw,ewe),e(ewe,FKr),e(tw,TKr),e(tw,Woe),e(Woe,MKr),e(tw,EKr),e(Ve,CKr),e(Ve,aw),e(aw,owe),e(owe,wKr),e(aw,AKr),e(aw,Hoe),e(Hoe,LKr),e(aw,yKr),e(Ve,xKr),e(Ve,nw),e(nw,rwe),e(rwe,$Kr),e(nw,kKr),e(nw,Uoe),e(Uoe,SKr),e(nw,RKr),e(Ve,PKr),e(Ve,sw),e(sw,twe),e(twe,BKr),e(sw,IKr),e(sw,Joe),e(Joe,NKr),e(sw,qKr),e(Ve,jKr),e(Ve,lw),e(lw,awe),e(awe,DKr),e(lw,GKr),e(lw,Yoe),e(Yoe,OKr),e(lw,VKr),e(Ur,XKr),M(iw,Ur,null),b(f,Bze,u),b(f,bf,u),e(bf,dw),e(dw,nwe),M(X$,nwe,null),e(bf,zKr),e(bf,swe),e(swe,QKr),b(f,Ize,u),b(f,Mr,u),M(z$,Mr,null),e(Mr,WKr),e(Mr,vf),e(vf,HKr),e(vf,Koe),e(Koe,UKr),e(vf,JKr),e(vf,Zoe),e(Zoe,YKr),e(vf,KKr),e(Mr,ZKr),e(Mr,Q$),e(Q$,eZr),e(Q$,lwe),e(lwe,oZr),e(Q$,rZr),e(Mr,tZr),e(Mr,ea),M(W$,ea,null),e(ea,aZr),e(ea,iwe),e(iwe,nZr),e(ea,sZr),e(ea,Ff),e(Ff,lZr),e(Ff,dwe),e(dwe,iZr),e(Ff,dZr),e(Ff,ere),e(ere,cZr),e(Ff,fZr),e(ea,mZr),M(cw,ea,null),e(Mr,gZr),e(Mr,Jr),M(H$,Jr,null),e(Jr,hZr),e(Jr,cwe),e(cwe,pZr),e(Jr,_Zr),e(Jr,yn),e(yn,uZr),e(yn,fwe),e(fwe,bZr),e(yn,vZr),e(yn,mwe),e(mwe,FZr),e(yn,TZr),e(yn,gwe),e(gwe,MZr),e(yn,EZr),e(Jr,CZr),e(Jr,Xe),e(Xe,fw),e(fw,hwe),e(hwe,wZr),e(fw,AZr),e(fw,ore),e(ore,LZr),e(fw,yZr),e(Xe,xZr),e(Xe,mw),e(mw,pwe),e(pwe,$Zr),e(mw,kZr),e(mw,rre),e(rre,SZr),e(mw,RZr),e(Xe,PZr),e(Xe,gw),e(gw,_we),e(_we,BZr),e(gw,IZr),e(gw,tre),e(tre,NZr),e(gw,qZr),e(Xe,jZr),e(Xe,hw),e(hw,uwe),e(uwe,DZr),e(hw,GZr),e(hw,are),e(are,OZr),e(hw,VZr),e(Xe,XZr),e(Xe,pw),e(pw,bwe),e(bwe,zZr),e(pw,QZr),e(pw,nre),e(nre,WZr),e(pw,HZr),e(Xe,UZr),e(Xe,_w),e(_w,vwe),e(vwe,JZr),e(_w,YZr),e(_w,sre),e(sre,KZr),e(_w,ZZr),e(Xe,eet),e(Xe,uw),e(uw,Fwe),e(Fwe,oet),e(uw,ret),e(uw,lre),e(lre,tet),e(uw,aet),e(Xe,net),e(Xe,bw),e(bw,Twe),e(Twe,set),e(bw,iet),e(bw,ire),e(ire,det),e(bw,cet),e(Jr,fet),M(vw,Jr,null),b(f,Nze,u),b(f,Tf,u),e(Tf,Fw),e(Fw,Mwe),M(U$,Mwe,null),e(Tf,met),e(Tf,Ewe),e(Ewe,get),b(f,qze,u),b(f,Er,u),M(J$,Er,null),e(Er,het),e(Er,Mf),e(Mf,pet),e(Mf,dre),e(dre,_et),e(Mf,uet),e(Mf,cre),e(cre,bet),e(Mf,vet),e(Er,Fet),e(Er,Y$),e(Y$,Tet),e(Y$,Cwe),e(Cwe,Met),e(Y$,Eet),e(Er,Cet),e(Er,oa),M(K$,oa,null),e(oa,wet),e(oa,wwe),e(wwe,Aet),e(oa,Let),e(oa,Ef),e(Ef,yet),e(Ef,Awe),e(Awe,xet),e(Ef,$et),e(Ef,fre),e(fre,ket),e(Ef,Set),e(oa,Ret),M(Tw,oa,null),e(Er,Pet),e(Er,Yr),M(Z$,Yr,null),e(Yr,Bet),e(Yr,Lwe),e(Lwe,Iet),e(Yr,Net),e(Yr,xn),e(xn,qet),e(xn,ywe),e(ywe,jet),e(xn,Det),e(xn,xwe),e(xwe,Get),e(xn,Oet),e(xn,$we),e($we,Vet),e(xn,Xet),e(Yr,zet),e(Yr,kwe),e(kwe,Mw),e(Mw,Swe),e(Swe,Qet),e(Mw,Wet),e(Mw,mre),e(mre,Het),e(Mw,Uet),e(Yr,Jet),M(Ew,Yr,null),b(f,jze,u),b(f,Cf,u),e(Cf,Cw),e(Cw,Rwe),M(ek,Rwe,null),e(Cf,Yet),e(Cf,Pwe),e(Pwe,Ket),b(f,Dze,u),b(f,Cr,u),M(ok,Cr,null),e(Cr,Zet),e(Cr,wf),e(wf,eot),e(wf,gre),e(gre,oot),e(wf,rot),e(wf,hre),e(hre,tot),e(wf,aot),e(Cr,not),e(Cr,rk),e(rk,sot),e(rk,Bwe),e(Bwe,lot),e(rk,iot),e(Cr,dot),e(Cr,ra),M(tk,ra,null),e(ra,cot),e(ra,Iwe),e(Iwe,fot),e(ra,mot),e(ra,Af),e(Af,got),e(Af,Nwe),e(Nwe,hot),e(Af,pot),e(Af,pre),e(pre,_ot),e(Af,uot),e(ra,bot),M(ww,ra,null),e(Cr,vot),e(Cr,Kr),M(ak,Kr,null),e(Kr,Fot),e(Kr,qwe),e(qwe,Tot),e(Kr,Mot),e(Kr,$n),e($n,Eot),e($n,jwe),e(jwe,Cot),e($n,wot),e($n,Dwe),e(Dwe,Aot),e($n,Lot),e($n,Gwe),e(Gwe,yot),e($n,xot),e(Kr,$ot),e(Kr,nk),e(nk,Aw),e(Aw,Owe),e(Owe,kot),e(Aw,Sot),e(Aw,_re),e(_re,Rot),e(Aw,Pot),e(nk,Bot),e(nk,Lw),e(Lw,Vwe),e(Vwe,Iot),e(Lw,Not),e(Lw,ure),e(ure,qot),e(Lw,jot),e(Kr,Dot),M(yw,Kr,null),b(f,Gze,u),b(f,Lf,u),e(Lf,xw),e(xw,Xwe),M(sk,Xwe,null),e(Lf,Got),e(Lf,zwe),e(zwe,Oot),b(f,Oze,u),b(f,wr,u),M(lk,wr,null),e(wr,Vot),e(wr,yf),e(yf,Xot),e(yf,bre),e(bre,zot),e(yf,Qot),e(yf,vre),e(vre,Wot),e(yf,Hot),e(wr,Uot),e(wr,ik),e(ik,Jot),e(ik,Qwe),e(Qwe,Yot),e(ik,Kot),e(wr,Zot),e(wr,ta),M(dk,ta,null),e(ta,ert),e(ta,Wwe),e(Wwe,ort),e(ta,rrt),e(ta,xf),e(xf,trt),e(xf,Hwe),e(Hwe,art),e(xf,nrt),e(xf,Fre),e(Fre,srt),e(xf,lrt),e(ta,irt),M($w,ta,null),e(wr,drt),e(wr,Zr),M(ck,Zr,null),e(Zr,crt),e(Zr,Uwe),e(Uwe,frt),e(Zr,mrt),e(Zr,kn),e(kn,grt),e(kn,Jwe),e(Jwe,hrt),e(kn,prt),e(kn,Ywe),e(Ywe,_rt),e(kn,urt),e(kn,Kwe),e(Kwe,brt),e(kn,vrt),e(Zr,Frt),e(Zr,Zwe),e(Zwe,kw),e(kw,eAe),e(eAe,Trt),e(kw,Mrt),e(kw,Tre),e(Tre,Ert),e(kw,Crt),e(Zr,wrt),M(Sw,Zr,null),Vze=!0},p(f,[u]){const fk={};u&2&&(fk.$$scope={dirty:u,ctx:f}),qf.$set(fk);const oAe={};u&2&&(oAe.$$scope={dirty:u,ctx:f}),Yg.$set(oAe);const rAe={};u&2&&(rAe.$$scope={dirty:u,ctx:f}),Rh.$set(rAe);const tAe={};u&2&&(tAe.$$scope={dirty:u,ctx:f}),_p.$set(tAe);const mk={};u&2&&(mk.$$scope={dirty:u,ctx:f}),up.$set(mk);const aAe={};u&2&&(aAe.$$scope={dirty:u,ctx:f}),qp.$set(aAe);const Sn={};u&2&&(Sn.$$scope={dirty:u,ctx:f}),jp.$set(Sn);const nAe={};u&2&&(nAe.$$scope={dirty:u,ctx:f}),Op.$set(nAe);const sAe={};u&2&&(sAe.$$scope={dirty:u,ctx:f}),Qu.$set(sAe);const lAe={};u&2&&(lAe.$$scope={dirty:u,ctx:f}),Hu.$set(lAe);const gk={};u&2&&(gk.$$scope={dirty:u,ctx:f}),G1.$set(gk);const iAe={};u&2&&(iAe.$$scope={dirty:u,ctx:f}),V1.$set(iAe);const hk={};u&2&&(hk.$$scope={dirty:u,ctx:f}),k2.$set(hk);const dAe={};u&2&&(dAe.$$scope={dirty:u,ctx:f}),R2.$set(dAe);const pk={};u&2&&(pk.$$scope={dirty:u,ctx:f}),vb.$set(pk);const cAe={};u&2&&(cAe.$$scope={dirty:u,ctx:f}),Tb.$set(cAe);const fAe={};u&2&&(fAe.$$scope={dirty:u,ctx:f}),Gb.$set(fAe);const mAe={};u&2&&(mAe.$$scope={dirty:u,ctx:f}),Vb.$set(mAe);const $f={};u&2&&($f.$$scope={dirty:u,ctx:f}),Gv.$set($f);const gAe={};u&2&&(gAe.$$scope={dirty:u,ctx:f}),Vv.$set(gAe);const hAe={};u&2&&(hAe.$$scope={dirty:u,ctx:f}),TF.$set(hAe);const pAe={};u&2&&(pAe.$$scope={dirty:u,ctx:f}),EF.$set(pAe);const _k={};u&2&&(_k.$$scope={dirty:u,ctx:f}),kF.$set(_k);const _Ae={};u&2&&(_Ae.$$scope={dirty:u,ctx:f}),RF.$set(_Ae);const uAe={};u&2&&(uAe.$$scope={dirty:u,ctx:f}),uT.$set(uAe);const bAe={};u&2&&(bAe.$$scope={dirty:u,ctx:f}),vT.$set(bAe);const at={};u&2&&(at.$$scope={dirty:u,ctx:f}),d7.$set(at);const uk={};u&2&&(uk.$$scope={dirty:u,ctx:f}),f7.$set(uk);const vAe={};u&2&&(vAe.$$scope={dirty:u,ctx:f}),h7.$set(vAe);const bk={};u&2&&(bk.$$scope={dirty:u,ctx:f}),_7.$set(bk);const FAe={};u&2&&(FAe.$$scope={dirty:u,ctx:f}),k7.$set(FAe);const nt={};u&2&&(nt.$$scope={dirty:u,ctx:f}),R7.$set(nt);const TAe={};u&2&&(TAe.$$scope={dirty:u,ctx:f}),I7.$set(TAe);const kf={};u&2&&(kf.$$scope={dirty:u,ctx:f}),q7.$set(kf);const MAe={};u&2&&(MAe.$$scope={dirty:u,ctx:f}),G7.$set(MAe);const EAe={};u&2&&(EAe.$$scope={dirty:u,ctx:f}),V7.$set(EAe);const L={};u&2&&(L.$$scope={dirty:u,ctx:f}),e8.$set(L);const Rw={};u&2&&(Rw.$$scope={dirty:u,ctx:f}),r8.$set(Rw);const CAe={};u&2&&(CAe.$$scope={dirty:u,ctx:f}),d8.$set(CAe);const wAe={};u&2&&(wAe.$$scope={dirty:u,ctx:f}),f8.$set(wAe);const Pw={};u&2&&(Pw.$$scope={dirty:u,ctx:f}),E8.$set(Pw);const AAe={};u&2&&(AAe.$$scope={dirty:u,ctx:f}),w8.$set(AAe);const LAe={};u&2&&(LAe.$$scope={dirty:u,ctx:f}),x8.$set(LAe);const Bw={};u&2&&(Bw.$$scope={dirty:u,ctx:f}),k8.$set(Bw);const yAe={};u&2&&(yAe.$$scope={dirty:u,ctx:f}),q8.$set(yAe);const xAe={};u&2&&(xAe.$$scope={dirty:u,ctx:f}),D8.$set(xAe);const Iw={};u&2&&(Iw.$$scope={dirty:u,ctx:f}),z8.$set(Iw);const $Ae={};u&2&&($Ae.$$scope={dirty:u,ctx:f}),W8.$set($Ae);const kAe={};u&2&&(kAe.$$scope={dirty:u,ctx:f}),Y8.$set(kAe);const Nw={};u&2&&(Nw.$$scope={dirty:u,ctx:f}),Z8.$set(Nw);const SAe={};u&2&&(SAe.$$scope={dirty:u,ctx:f}),rM.$set(SAe);const RAe={};u&2&&(RAe.$$scope={dirty:u,ctx:f}),aM.$set(RAe);const qw={};u&2&&(qw.$$scope={dirty:u,ctx:f}),fM.$set(qw);const PAe={};u&2&&(PAe.$$scope={dirty:u,ctx:f}),gM.$set(PAe);const BAe={};u&2&&(BAe.$$scope={dirty:u,ctx:f}),_M.$set(BAe);const jw={};u&2&&(jw.$$scope={dirty:u,ctx:f}),bM.$set(jw);const IAe={};u&2&&(IAe.$$scope={dirty:u,ctx:f}),m4.$set(IAe);const NAe={};u&2&&(NAe.$$scope={dirty:u,ctx:f}),h4.$set(NAe);const Dw={};u&2&&(Dw.$$scope={dirty:u,ctx:f}),q4.$set(Dw);const qAe={};u&2&&(qAe.$$scope={dirty:u,ctx:f}),D4.$set(qAe);const jAe={};u&2&&(jAe.$$scope={dirty:u,ctx:f}),eE.$set(jAe);const Gw={};u&2&&(Gw.$$scope={dirty:u,ctx:f}),rE.$set(Gw);const DAe={};u&2&&(DAe.$$scope={dirty:u,ctx:f}),iE.$set(DAe);const GAe={};u&2&&(GAe.$$scope={dirty:u,ctx:f}),cE.$set(GAe);const Ow={};u&2&&(Ow.$$scope={dirty:u,ctx:f}),kE.$set(Ow);const OAe={};u&2&&(OAe.$$scope={dirty:u,ctx:f}),RE.$set(OAe);const VAe={};u&2&&(VAe.$$scope={dirty:u,ctx:f}),XE.$set(VAe);const Vw={};u&2&&(Vw.$$scope={dirty:u,ctx:f}),QE.$set(Vw);const XAe={};u&2&&(XAe.$$scope={dirty:u,ctx:f}),vC.$set(XAe);const zAe={};u&2&&(zAe.$$scope={dirty:u,ctx:f}),TC.$set(zAe);const Xw={};u&2&&(Xw.$$scope={dirty:u,ctx:f}),jC.$set(Xw);const QAe={};u&2&&(QAe.$$scope={dirty:u,ctx:f}),GC.$set(QAe);const WAe={};u&2&&(WAe.$$scope={dirty:u,ctx:f}),XC.$set(WAe);const zw={};u&2&&(zw.$$scope={dirty:u,ctx:f}),QC.$set(zw);const HAe={};u&2&&(HAe.$$scope={dirty:u,ctx:f}),HC.$set(HAe);const UAe={};u&2&&(UAe.$$scope={dirty:u,ctx:f}),JC.$set(UAe);const Qw={};u&2&&(Qw.$$scope={dirty:u,ctx:f}),u3.$set(Qw);const JAe={};u&2&&(JAe.$$scope={dirty:u,ctx:f}),v3.$set(JAe);const YAe={};u&2&&(YAe.$$scope={dirty:u,ctx:f}),D3.$set(YAe);const Ww={};u&2&&(Ww.$$scope={dirty:u,ctx:f}),O3.$set(Ww);const KAe={};u&2&&(KAe.$$scope={dirty:u,ctx:f}),X3.$set(KAe);const ZAe={};u&2&&(ZAe.$$scope={dirty:u,ctx:f}),Q3.$set(ZAe);const Hw={};u&2&&(Hw.$$scope={dirty:u,ctx:f}),H3.$set(Hw);const e6e={};u&2&&(e6e.$$scope={dirty:u,ctx:f}),J3.$set(e6e);const o6e={};u&2&&(o6e.$$scope={dirty:u,ctx:f}),C5.$set(o6e);const Uw={};u&2&&(Uw.$$scope={dirty:u,ctx:f}),A5.$set(Uw);const r6e={};u&2&&(r6e.$$scope={dirty:u,ctx:f}),N5.$set(r6e);const t6e={};u&2&&(t6e.$$scope={dirty:u,ctx:f}),j5.$set(t6e);const Jw={};u&2&&(Jw.$$scope={dirty:u,ctx:f}),Z5.$set(Jw);const a6e={};u&2&&(a6e.$$scope={dirty:u,ctx:f}),o0.$set(a6e);const n6e={};u&2&&(n6e.$$scope={dirty:u,ctx:f}),m0.$set(n6e);const Yw={};u&2&&(Yw.$$scope={dirty:u,ctx:f}),h0.$set(Yw);const s6e={};u&2&&(s6e.$$scope={dirty:u,ctx:f}),w0.$set(s6e);const l6e={};u&2&&(l6e.$$scope={dirty:u,ctx:f}),L0.$set(l6e);const Kw={};u&2&&(Kw.$$scope={dirty:u,ctx:f}),q0.$set(Kw);const i6e={};u&2&&(i6e.$$scope={dirty:u,ctx:f}),D0.$set(i6e);const d6e={};u&2&&(d6e.$$scope={dirty:u,ctx:f}),Y0.$set(d6e);const Zw={};u&2&&(Zw.$$scope={dirty:u,ctx:f}),Z0.$set(Zw);const c6e={};u&2&&(c6e.$$scope={dirty:u,ctx:f}),iw.$set(c6e);const f6e={};u&2&&(f6e.$$scope={dirty:u,ctx:f}),cw.$set(f6e);const eA={};u&2&&(eA.$$scope={dirty:u,ctx:f}),vw.$set(eA);const m6e={};u&2&&(m6e.$$scope={dirty:u,ctx:f}),Tw.$set(m6e);const g6e={};u&2&&(g6e.$$scope={dirty:u,ctx:f}),Ew.$set(g6e);const oA={};u&2&&(oA.$$scope={dirty:u,ctx:f}),ww.$set(oA);const h6e={};u&2&&(h6e.$$scope={dirty:u,ctx:f}),yw.$set(h6e);const p6e={};u&2&&(p6e.$$scope={dirty:u,ctx:f}),$w.$set(p6e);const rA={};u&2&&(rA.$$scope={dirty:u,ctx:f}),Sw.$set(rA)},i(f){Vze||(E(d.$$.fragment,f),E(ka.$$.fragment,f),E(oL.$$.fragment,f),E(rL.$$.fragment,f),E(qf.$$.fragment,f),E(tL.$$.fragment,f),E(aL.$$.fragment,f),E(lL.$$.fragment,f),E(Yg.$$.fragment,f),E(iL.$$.fragment,f),E(dL.$$.fragment,f),E(cL.$$.fragment,f),E(gL.$$.fragment,f),E(Rh.$$.fragment,f),E(hL.$$.fragment,f),E(pL.$$.fragment,f),E(_L.$$.fragment,f),E(vL.$$.fragment,f),E(_p.$$.fragment,f),E(up.$$.fragment,f),E(FL.$$.fragment,f),E(TL.$$.fragment,f),E(ML.$$.fragment,f),E(wL.$$.fragment,f),E(qp.$$.fragment,f),E(jp.$$.fragment,f),E(AL.$$.fragment,f),E(LL.$$.fragment,f),E(yL.$$.fragment,f),E($L.$$.fragment,f),E(Op.$$.fragment,f),E(kL.$$.fragment,f),E(Qu.$$.fragment,f),E(SL.$$.fragment,f),E(RL.$$.fragment,f),E(BL.$$.fragment,f),E(Hu.$$.fragment,f),E(IL.$$.fragment,f),E(G1.$$.fragment,f),E(NL.$$.fragment,f),E(qL.$$.fragment,f),E(DL.$$.fragment,f),E(V1.$$.fragment,f),E(GL.$$.fragment,f),E(k2.$$.fragment,f),E(OL.$$.fragment,f),E(VL.$$.fragment,f),E(zL.$$.fragment,f),E(R2.$$.fragment,f),E(QL.$$.fragment,f),E(vb.$$.fragment,f),E(WL.$$.fragment,f),E(HL.$$.fragment,f),E(JL.$$.fragment,f),E(Tb.$$.fragment,f),E(YL.$$.fragment,f),E(Gb.$$.fragment,f),E(KL.$$.fragment,f),E(ZL.$$.fragment,f),E(oy.$$.fragment,f),E(Vb.$$.fragment,f),E(ry.$$.fragment,f),E(Gv.$$.fragment,f),E(ty.$$.fragment,f),E(ay.$$.fragment,f),E(sy.$$.fragment,f),E(Vv.$$.fragment,f),E(ly.$$.fragment,f),E(TF.$$.fragment,f),E(iy.$$.fragment,f),E(dy.$$.fragment,f),E(fy.$$.fragment,f),E(EF.$$.fragment,f),E(my.$$.fragment,f),E(kF.$$.fragment,f),E(gy.$$.fragment,f),E(hy.$$.fragment,f),E(_y.$$.fragment,f),E(RF.$$.fragment,f),E(uy.$$.fragment,f),E(uT.$$.fragment,f),E(by.$$.fragment,f),E(vy.$$.fragment,f),E(Ty.$$.fragment,f),E(vT.$$.fragment,f),E(My.$$.fragment,f),E(d7.$$.fragment,f),E(Ey.$$.fragment,f),E(Cy.$$.fragment,f),E(Ay.$$.fragment,f),E(f7.$$.fragment,f),E(Ly.$$.fragment,f),E(h7.$$.fragment,f),E(yy.$$.fragment,f),E(xy.$$.fragment,f),E(ky.$$.fragment,f),E(_7.$$.fragment,f),E(Sy.$$.fragment,f),E(k7.$$.fragment,f),E(Ry.$$.fragment,f),E(Py.$$.fragment,f),E(Iy.$$.fragment,f),E(R7.$$.fragment,f),E(Ny.$$.fragment,f),E(I7.$$.fragment,f),E(qy.$$.fragment,f),E(jy.$$.fragment,f),E(Gy.$$.fragment,f),E(q7.$$.fragment,f),E(Oy.$$.fragment,f),E(G7.$$.fragment,f),E(Vy.$$.fragment,f),E(Xy.$$.fragment,f),E(Qy.$$.fragment,f),E(V7.$$.fragment,f),E(Wy.$$.fragment,f),E(e8.$$.fragment,f),E(Hy.$$.fragment,f),E(Uy.$$.fragment,f),E(Yy.$$.fragment,f),E(r8.$$.fragment,f),E(Ky.$$.fragment,f),E(d8.$$.fragment,f),E(Zy.$$.fragment,f),E(e9.$$.fragment,f),E(r9.$$.fragment,f),E(f8.$$.fragment,f),E(t9.$$.fragment,f),E(E8.$$.fragment,f),E(a9.$$.fragment,f),E(n9.$$.fragment,f),E(l9.$$.fragment,f),E(w8.$$.fragment,f),E(i9.$$.fragment,f),E(x8.$$.fragment,f),E(c9.$$.fragment,f),E(f9.$$.fragment,f),E(g9.$$.fragment,f),E(k8.$$.fragment,f),E(h9.$$.fragment,f),E(q8.$$.fragment,f),E(p9.$$.fragment,f),E(_9.$$.fragment,f),E(b9.$$.fragment,f),E(D8.$$.fragment,f),E(v9.$$.fragment,f),E(z8.$$.fragment,f),E(F9.$$.fragment,f),E(T9.$$.fragment,f),E(E9.$$.fragment,f),E(W8.$$.fragment,f),E(C9.$$.fragment,f),E(Y8.$$.fragment,f),E(A9.$$.fragment,f),E(L9.$$.fragment,f),E(x9.$$.fragment,f),E(Z8.$$.fragment,f),E($9.$$.fragment,f),E(rM.$$.fragment,f),E(k9.$$.fragment,f),E(S9.$$.fragment,f),E(P9.$$.fragment,f),E(aM.$$.fragment,f),E(B9.$$.fragment,f),E(fM.$$.fragment,f),E(I9.$$.fragment,f),E(N9.$$.fragment,f),E(j9.$$.fragment,f),E(gM.$$.fragment,f),E(D9.$$.fragment,f),E(_M.$$.fragment,f),E(G9.$$.fragment,f),E(O9.$$.fragment,f),E(X9.$$.fragment,f),E(bM.$$.fragment,f),E(z9.$$.fragment,f),E(m4.$$.fragment,f),E(Q9.$$.fragment,f),E(W9.$$.fragment,f),E(U9.$$.fragment,f),E(h4.$$.fragment,f),E(J9.$$.fragment,f),E(q4.$$.fragment,f),E(Y9.$$.fragment,f),E(K9.$$.fragment,f),E(ex.$$.fragment,f),E(D4.$$.fragment,f),E(ox.$$.fragment,f),E(eE.$$.fragment,f),E(rx.$$.fragment,f),E(tx.$$.fragment,f),E(nx.$$.fragment,f),E(rE.$$.fragment,f),E(sx.$$.fragment,f),E(iE.$$.fragment,f),E(lx.$$.fragment,f),E(ix.$$.fragment,f),E(cx.$$.fragment,f),E(cE.$$.fragment,f),E(fx.$$.fragment,f),E(kE.$$.fragment,f),E(mx.$$.fragment,f),E(gx.$$.fragment,f),E(px.$$.fragment,f),E(RE.$$.fragment,f),E(_x.$$.fragment,f),E(XE.$$.fragment,f),E(ux.$$.fragment,f),E(bx.$$.fragment,f),E(Fx.$$.fragment,f),E(QE.$$.fragment,f),E(Tx.$$.fragment,f),E(vC.$$.fragment,f),E(Mx.$$.fragment,f),E(Ex.$$.fragment,f),E(wx.$$.fragment,f),E(TC.$$.fragment,f),E(Ax.$$.fragment,f),E(jC.$$.fragment,f),E(Lx.$$.fragment,f),E(yx.$$.fragment,f),E($x.$$.fragment,f),E(GC.$$.fragment,f),E(kx.$$.fragment,f),E(XC.$$.fragment,f),E(Rx.$$.fragment,f),E(Px.$$.fragment,f),E(Ix.$$.fragment,f),E(QC.$$.fragment,f),E(Nx.$$.fragment,f),E(HC.$$.fragment,f),E(qx.$$.fragment,f),E(jx.$$.fragment,f),E(Gx.$$.fragment,f),E(JC.$$.fragment,f),E(Ox.$$.fragment,f),E(u3.$$.fragment,f),E(Vx.$$.fragment,f),E(Xx.$$.fragment,f),E(Qx.$$.fragment,f),E(v3.$$.fragment,f),E(Wx.$$.fragment,f),E(D3.$$.fragment,f),E(Hx.$$.fragment,f),E(Ux.$$.fragment,f),E(Yx.$$.fragment,f),E(O3.$$.fragment,f),E(Kx.$$.fragment,f),E(X3.$$.fragment,f),E(Zx.$$.fragment,f),E(e$.$$.fragment,f),E(r$.$$.fragment,f),E(Q3.$$.fragment,f),E(t$.$$.fragment,f),E(H3.$$.fragment,f),E(a$.$$.fragment,f),E(n$.$$.fragment,f),E(l$.$$.fragment,f),E(J3.$$.fragment,f),E(i$.$$.fragment,f),E(C5.$$.fragment,f),E(d$.$$.fragment,f),E(c$.$$.fragment,f),E(m$.$$.fragment,f),E(A5.$$.fragment,f),E(g$.$$.fragment,f),E(N5.$$.fragment,f),E(h$.$$.fragment,f),E(p$.$$.fragment,f),E(u$.$$.fragment,f),E(j5.$$.fragment,f),E(b$.$$.fragment,f),E(Z5.$$.fragment,f),E(v$.$$.fragment,f),E(F$.$$.fragment,f),E(M$.$$.fragment,f),E(o0.$$.fragment,f),E(E$.$$.fragment,f),E(m0.$$.fragment,f),E(C$.$$.fragment,f),E(w$.$$.fragment,f),E(L$.$$.fragment,f),E(h0.$$.fragment,f),E(y$.$$.fragment,f),E(w0.$$.fragment,f),E(x$.$$.fragment,f),E($$.$$.fragment,f),E(S$.$$.fragment,f),E(L0.$$.fragment,f),E(R$.$$.fragment,f),E(q0.$$.fragment,f),E(P$.$$.fragment,f),E(B$.$$.fragment,f),E(N$.$$.fragment,f),E(D0.$$.fragment,f),E(q$.$$.fragment,f),E(Y0.$$.fragment,f),E(j$.$$.fragment,f),E(D$.$$.fragment,f),E(O$.$$.fragment,f),E(Z0.$$.fragment,f),E(V$.$$.fragment,f),E(iw.$$.fragment,f),E(X$.$$.fragment,f),E(z$.$$.fragment,f),E(W$.$$.fragment,f),E(cw.$$.fragment,f),E(H$.$$.fragment,f),E(vw.$$.fragment,f),E(U$.$$.fragment,f),E(J$.$$.fragment,f),E(K$.$$.fragment,f),E(Tw.$$.fragment,f),E(Z$.$$.fragment,f),E(Ew.$$.fragment,f),E(ek.$$.fragment,f),E(ok.$$.fragment,f),E(tk.$$.fragment,f),E(ww.$$.fragment,f),E(ak.$$.fragment,f),E(yw.$$.fragment,f),E(sk.$$.fragment,f),E(lk.$$.fragment,f),E(dk.$$.fragment,f),E($w.$$.fragment,f),E(ck.$$.fragment,f),E(Sw.$$.fragment,f),Vze=!0)},o(f){C(d.$$.fragment,f),C(ka.$$.fragment,f),C(oL.$$.fragment,f),C(rL.$$.fragment,f),C(qf.$$.fragment,f),C(tL.$$.fragment,f),C(aL.$$.fragment,f),C(lL.$$.fragment,f),C(Yg.$$.fragment,f),C(iL.$$.fragment,f),C(dL.$$.fragment,f),C(cL.$$.fragment,f),C(gL.$$.fragment,f),C(Rh.$$.fragment,f),C(hL.$$.fragment,f),C(pL.$$.fragment,f),C(_L.$$.fragment,f),C(vL.$$.fragment,f),C(_p.$$.fragment,f),C(up.$$.fragment,f),C(FL.$$.fragment,f),C(TL.$$.fragment,f),C(ML.$$.fragment,f),C(wL.$$.fragment,f),C(qp.$$.fragment,f),C(jp.$$.fragment,f),C(AL.$$.fragment,f),C(LL.$$.fragment,f),C(yL.$$.fragment,f),C($L.$$.fragment,f),C(Op.$$.fragment,f),C(kL.$$.fragment,f),C(Qu.$$.fragment,f),C(SL.$$.fragment,f),C(RL.$$.fragment,f),C(BL.$$.fragment,f),C(Hu.$$.fragment,f),C(IL.$$.fragment,f),C(G1.$$.fragment,f),C(NL.$$.fragment,f),C(qL.$$.fragment,f),C(DL.$$.fragment,f),C(V1.$$.fragment,f),C(GL.$$.fragment,f),C(k2.$$.fragment,f),C(OL.$$.fragment,f),C(VL.$$.fragment,f),C(zL.$$.fragment,f),C(R2.$$.fragment,f),C(QL.$$.fragment,f),C(vb.$$.fragment,f),C(WL.$$.fragment,f),C(HL.$$.fragment,f),C(JL.$$.fragment,f),C(Tb.$$.fragment,f),C(YL.$$.fragment,f),C(Gb.$$.fragment,f),C(KL.$$.fragment,f),C(ZL.$$.fragment,f),C(oy.$$.fragment,f),C(Vb.$$.fragment,f),C(ry.$$.fragment,f),C(Gv.$$.fragment,f),C(ty.$$.fragment,f),C(ay.$$.fragment,f),C(sy.$$.fragment,f),C(Vv.$$.fragment,f),C(ly.$$.fragment,f),C(TF.$$.fragment,f),C(iy.$$.fragment,f),C(dy.$$.fragment,f),C(fy.$$.fragment,f),C(EF.$$.fragment,f),C(my.$$.fragment,f),C(kF.$$.fragment,f),C(gy.$$.fragment,f),C(hy.$$.fragment,f),C(_y.$$.fragment,f),C(RF.$$.fragment,f),C(uy.$$.fragment,f),C(uT.$$.fragment,f),C(by.$$.fragment,f),C(vy.$$.fragment,f),C(Ty.$$.fragment,f),C(vT.$$.fragment,f),C(My.$$.fragment,f),C(d7.$$.fragment,f),C(Ey.$$.fragment,f),C(Cy.$$.fragment,f),C(Ay.$$.fragment,f),C(f7.$$.fragment,f),C(Ly.$$.fragment,f),C(h7.$$.fragment,f),C(yy.$$.fragment,f),C(xy.$$.fragment,f),C(ky.$$.fragment,f),C(_7.$$.fragment,f),C(Sy.$$.fragment,f),C(k7.$$.fragment,f),C(Ry.$$.fragment,f),C(Py.$$.fragment,f),C(Iy.$$.fragment,f),C(R7.$$.fragment,f),C(Ny.$$.fragment,f),C(I7.$$.fragment,f),C(qy.$$.fragment,f),C(jy.$$.fragment,f),C(Gy.$$.fragment,f),C(q7.$$.fragment,f),C(Oy.$$.fragment,f),C(G7.$$.fragment,f),C(Vy.$$.fragment,f),C(Xy.$$.fragment,f),C(Qy.$$.fragment,f),C(V7.$$.fragment,f),C(Wy.$$.fragment,f),C(e8.$$.fragment,f),C(Hy.$$.fragment,f),C(Uy.$$.fragment,f),C(Yy.$$.fragment,f),C(r8.$$.fragment,f),C(Ky.$$.fragment,f),C(d8.$$.fragment,f),C(Zy.$$.fragment,f),C(e9.$$.fragment,f),C(r9.$$.fragment,f),C(f8.$$.fragment,f),C(t9.$$.fragment,f),C(E8.$$.fragment,f),C(a9.$$.fragment,f),C(n9.$$.fragment,f),C(l9.$$.fragment,f),C(w8.$$.fragment,f),C(i9.$$.fragment,f),C(x8.$$.fragment,f),C(c9.$$.fragment,f),C(f9.$$.fragment,f),C(g9.$$.fragment,f),C(k8.$$.fragment,f),C(h9.$$.fragment,f),C(q8.$$.fragment,f),C(p9.$$.fragment,f),C(_9.$$.fragment,f),C(b9.$$.fragment,f),C(D8.$$.fragment,f),C(v9.$$.fragment,f),C(z8.$$.fragment,f),C(F9.$$.fragment,f),C(T9.$$.fragment,f),C(E9.$$.fragment,f),C(W8.$$.fragment,f),C(C9.$$.fragment,f),C(Y8.$$.fragment,f),C(A9.$$.fragment,f),C(L9.$$.fragment,f),C(x9.$$.fragment,f),C(Z8.$$.fragment,f),C($9.$$.fragment,f),C(rM.$$.fragment,f),C(k9.$$.fragment,f),C(S9.$$.fragment,f),C(P9.$$.fragment,f),C(aM.$$.fragment,f),C(B9.$$.fragment,f),C(fM.$$.fragment,f),C(I9.$$.fragment,f),C(N9.$$.fragment,f),C(j9.$$.fragment,f),C(gM.$$.fragment,f),C(D9.$$.fragment,f),C(_M.$$.fragment,f),C(G9.$$.fragment,f),C(O9.$$.fragment,f),C(X9.$$.fragment,f),C(bM.$$.fragment,f),C(z9.$$.fragment,f),C(m4.$$.fragment,f),C(Q9.$$.fragment,f),C(W9.$$.fragment,f),C(U9.$$.fragment,f),C(h4.$$.fragment,f),C(J9.$$.fragment,f),C(q4.$$.fragment,f),C(Y9.$$.fragment,f),C(K9.$$.fragment,f),C(ex.$$.fragment,f),C(D4.$$.fragment,f),C(ox.$$.fragment,f),C(eE.$$.fragment,f),C(rx.$$.fragment,f),C(tx.$$.fragment,f),C(nx.$$.fragment,f),C(rE.$$.fragment,f),C(sx.$$.fragment,f),C(iE.$$.fragment,f),C(lx.$$.fragment,f),C(ix.$$.fragment,f),C(cx.$$.fragment,f),C(cE.$$.fragment,f),C(fx.$$.fragment,f),C(kE.$$.fragment,f),C(mx.$$.fragment,f),C(gx.$$.fragment,f),C(px.$$.fragment,f),C(RE.$$.fragment,f),C(_x.$$.fragment,f),C(XE.$$.fragment,f),C(ux.$$.fragment,f),C(bx.$$.fragment,f),C(Fx.$$.fragment,f),C(QE.$$.fragment,f),C(Tx.$$.fragment,f),C(vC.$$.fragment,f),C(Mx.$$.fragment,f),C(Ex.$$.fragment,f),C(wx.$$.fragment,f),C(TC.$$.fragment,f),C(Ax.$$.fragment,f),C(jC.$$.fragment,f),C(Lx.$$.fragment,f),C(yx.$$.fragment,f),C($x.$$.fragment,f),C(GC.$$.fragment,f),C(kx.$$.fragment,f),C(XC.$$.fragment,f),C(Rx.$$.fragment,f),C(Px.$$.fragment,f),C(Ix.$$.fragment,f),C(QC.$$.fragment,f),C(Nx.$$.fragment,f),C(HC.$$.fragment,f),C(qx.$$.fragment,f),C(jx.$$.fragment,f),C(Gx.$$.fragment,f),C(JC.$$.fragment,f),C(Ox.$$.fragment,f),C(u3.$$.fragment,f),C(Vx.$$.fragment,f),C(Xx.$$.fragment,f),C(Qx.$$.fragment,f),C(v3.$$.fragment,f),C(Wx.$$.fragment,f),C(D3.$$.fragment,f),C(Hx.$$.fragment,f),C(Ux.$$.fragment,f),C(Yx.$$.fragment,f),C(O3.$$.fragment,f),C(Kx.$$.fragment,f),C(X3.$$.fragment,f),C(Zx.$$.fragment,f),C(e$.$$.fragment,f),C(r$.$$.fragment,f),C(Q3.$$.fragment,f),C(t$.$$.fragment,f),C(H3.$$.fragment,f),C(a$.$$.fragment,f),C(n$.$$.fragment,f),C(l$.$$.fragment,f),C(J3.$$.fragment,f),C(i$.$$.fragment,f),C(C5.$$.fragment,f),C(d$.$$.fragment,f),C(c$.$$.fragment,f),C(m$.$$.fragment,f),C(A5.$$.fragment,f),C(g$.$$.fragment,f),C(N5.$$.fragment,f),C(h$.$$.fragment,f),C(p$.$$.fragment,f),C(u$.$$.fragment,f),C(j5.$$.fragment,f),C(b$.$$.fragment,f),C(Z5.$$.fragment,f),C(v$.$$.fragment,f),C(F$.$$.fragment,f),C(M$.$$.fragment,f),C(o0.$$.fragment,f),C(E$.$$.fragment,f),C(m0.$$.fragment,f),C(C$.$$.fragment,f),C(w$.$$.fragment,f),C(L$.$$.fragment,f),C(h0.$$.fragment,f),C(y$.$$.fragment,f),C(w0.$$.fragment,f),C(x$.$$.fragment,f),C($$.$$.fragment,f),C(S$.$$.fragment,f),C(L0.$$.fragment,f),C(R$.$$.fragment,f),C(q0.$$.fragment,f),C(P$.$$.fragment,f),C(B$.$$.fragment,f),C(N$.$$.fragment,f),C(D0.$$.fragment,f),C(q$.$$.fragment,f),C(Y0.$$.fragment,f),C(j$.$$.fragment,f),C(D$.$$.fragment,f),C(O$.$$.fragment,f),C(Z0.$$.fragment,f),C(V$.$$.fragment,f),C(iw.$$.fragment,f),C(X$.$$.fragment,f),C(z$.$$.fragment,f),C(W$.$$.fragment,f),C(cw.$$.fragment,f),C(H$.$$.fragment,f),C(vw.$$.fragment,f),C(U$.$$.fragment,f),C(J$.$$.fragment,f),C(K$.$$.fragment,f),C(Tw.$$.fragment,f),C(Z$.$$.fragment,f),C(Ew.$$.fragment,f),C(ek.$$.fragment,f),C(ok.$$.fragment,f),C(tk.$$.fragment,f),C(ww.$$.fragment,f),C(ak.$$.fragment,f),C(yw.$$.fragment,f),C(sk.$$.fragment,f),C(lk.$$.fragment,f),C(dk.$$.fragment,f),C($w.$$.fragment,f),C(ck.$$.fragment,f),C(Sw.$$.fragment,f),Vze=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(Rf),f&&t(st),f&&t(Oe),f&&t(Qe),f&&t(Bf),w(ka,f),f&&t(We),f&&t(Ae),f&&t(Co),f&&t(Sa),f&&t(qVe),f&&t(Ri),w(oL),f&&t(jVe),f&&t(Nn),f&&t(DVe),w(rL,f),f&&t(GVe),f&&t(IS),f&&t(OVe),w(qf,f),f&&t(VVe),f&&t(Pi),w(tL),f&&t(XVe),f&&t(wo),w(aL),w(lL),w(Yg),w(iL),f&&t(zVe),f&&t(Ii),w(dL),f&&t(QVe),f&&t(Ao),w(cL),w(gL),w(Rh),w(hL),f&&t(WVe),f&&t(Ni),w(pL),f&&t(HVe),f&&t(Lo),w(_L),w(vL),w(_p),w(up),w(FL),f&&t(UVe),f&&t(qi),w(TL),f&&t(JVe),f&&t(yo),w(ML),w(wL),w(qp),w(jp),w(AL),f&&t(YVe),f&&t(Di),w(LL),f&&t(KVe),f&&t(xo),w(yL),w($L),w(Op),w(kL),w(Qu),f&&t(ZVe),f&&t(Vi),w(SL),f&&t(eXe),f&&t($o),w(RL),w(BL),w(Hu),w(IL),w(G1),f&&t(oXe),f&&t(Qi),w(NL),f&&t(rXe),f&&t(ko),w(qL),w(DL),w(V1),w(GL),w(k2),f&&t(tXe),f&&t(Ui),w(OL),f&&t(aXe),f&&t(So),w(VL),w(zL),w(R2),w(QL),w(vb),f&&t(nXe),f&&t(Ki),w(WL),f&&t(sXe),f&&t(Ro),w(HL),w(JL),w(Tb),w(YL),w(Gb),f&&t(lXe),f&&t(od),w(KL),f&&t(iXe),f&&t(Po),w(ZL),w(oy),w(Vb),w(ry),w(Gv),f&&t(dXe),f&&t(ad),w(ty),f&&t(cXe),f&&t(Bo),w(ay),w(sy),w(Vv),w(ly),w(TF),f&&t(fXe),f&&t(ld),w(iy),f&&t(mXe),f&&t(Io),w(dy),w(fy),w(EF),w(my),w(kF),f&&t(gXe),f&&t(cd),w(gy),f&&t(hXe),f&&t(qo),w(hy),w(_y),w(RF),w(uy),w(uT),f&&t(pXe),f&&t(gd),w(by),f&&t(_Xe),f&&t(jo),w(vy),w(Ty),w(vT),w(My),w(d7),f&&t(uXe),f&&t(_d),w(Ey),f&&t(bXe),f&&t(Do),w(Cy),w(Ay),w(f7),w(Ly),w(h7),f&&t(vXe),f&&t(vd),w(yy),f&&t(FXe),f&&t(Go),w(xy),w(ky),w(_7),w(Sy),w(k7),f&&t(TXe),f&&t(Md),w(Ry),f&&t(MXe),f&&t(Oo),w(Py),w(Iy),w(R7),w(Ny),w(I7),f&&t(EXe),f&&t(wd),w(qy),f&&t(CXe),f&&t(Vo),w(jy),w(Gy),w(q7),w(Oy),w(G7),f&&t(wXe),f&&t(yd),w(Vy),f&&t(AXe),f&&t(Xo),w(Xy),w(Qy),w(V7),w(Wy),w(e8),f&&t(LXe),f&&t(kd),w(Hy),f&&t(yXe),f&&t(zo),w(Uy),w(Yy),w(r8),w(Ky),w(d8),f&&t(xXe),f&&t(Pd),w(Zy),f&&t($Xe),f&&t(Qo),w(e9),w(r9),w(f8),w(t9),w(E8),f&&t(kXe),f&&t(Nd),w(a9),f&&t(SXe),f&&t(Wo),w(n9),w(l9),w(w8),w(i9),w(x8),f&&t(RXe),f&&t(Dd),w(c9),f&&t(PXe),f&&t(Ho),w(f9),w(g9),w(k8),w(h9),w(q8),f&&t(BXe),f&&t(Vd),w(p9),f&&t(IXe),f&&t(Uo),w(_9),w(b9),w(D8),w(v9),w(z8),f&&t(NXe),f&&t(Wd),w(F9),f&&t(qXe),f&&t(Jo),w(T9),w(E9),w(W8),w(C9),w(Y8),f&&t(jXe),f&&t(Jd),w(A9),f&&t(DXe),f&&t(Yo),w(L9),w(x9),w(Z8),w($9),w(rM),f&&t(GXe),f&&t(Zd),w(k9),f&&t(OXe),f&&t(Ko),w(S9),w(P9),w(aM),w(B9),w(fM),f&&t(VXe),f&&t(rc),w(I9),f&&t(XXe),f&&t(Zo),w(N9),w(j9),w(gM),w(D9),w(_M),f&&t(zXe),f&&t(nc),w(G9),f&&t(QXe),f&&t(er),w(O9),w(X9),w(bM),w(z9),w(m4),f&&t(WXe),f&&t(ic),w(Q9),f&&t(HXe),f&&t(or),w(W9),w(U9),w(h4),w(J9),w(q4),f&&t(UXe),f&&t(fc),w(Y9),f&&t(JXe),f&&t(rr),w(K9),w(ex),w(D4),w(ox),w(eE),f&&t(YXe),f&&t(hc),w(rx),f&&t(KXe),f&&t(tr),w(tx),w(nx),w(rE),w(sx),w(iE),f&&t(ZXe),f&&t(uc),w(lx),f&&t(eze),f&&t(ar),w(ix),w(cx),w(cE),w(fx),w(kE),f&&t(oze),f&&t(Fc),w(mx),f&&t(rze),f&&t(nr),w(gx),w(px),w(RE),w(_x),w(XE),f&&t(tze),f&&t(Ec),w(ux),f&&t(aze),f&&t(sr),w(bx),w(Fx),w(QE),w(Tx),w(vC),f&&t(nze),f&&t(Ac),w(Mx),f&&t(sze),f&&t(lr),w(Ex),w(wx),w(TC),w(Ax),w(jC),f&&t(lze),f&&t(xc),w(Lx),f&&t(ize),f&&t(ir),w(yx),w($x),w(GC),w(kx),w(XC),f&&t(dze),f&&t(Sc),w(Rx),f&&t(cze),f&&t(dr),w(Px),w(Ix),w(QC),w(Nx),w(HC),f&&t(fze),f&&t(Bc),w(qx),f&&t(mze),f&&t(cr),w(jx),w(Gx),w(JC),w(Ox),w(u3),f&&t(gze),f&&t(qc),w(Vx),f&&t(hze),f&&t(fr),w(Xx),w(Qx),w(v3),w(Wx),w(D3),f&&t(pze),f&&t(Gc),w(Hx),f&&t(_ze),f&&t(mr),w(Ux),w(Yx),w(O3),w(Kx),w(X3),f&&t(uze),f&&t(Xc),w(Zx),f&&t(bze),f&&t(gr),w(e$),w(r$),w(Q3),w(t$),w(H3),f&&t(vze),f&&t(Wc),w(a$),f&&t(Fze),f&&t(hr),w(n$),w(l$),w(J3),w(i$),w(C5),f&&t(Tze),f&&t(Jc),w(d$),f&&t(Mze),f&&t(pr),w(c$),w(m$),w(A5),w(g$),w(N5),f&&t(Eze),f&&t(Zc),w(h$),f&&t(Cze),f&&t(_r),w(p$),w(u$),w(j5),w(b$),w(Z5),f&&t(wze),f&&t(rf),w(v$),f&&t(Aze),f&&t(ur),w(F$),w(M$),w(o0),w(E$),w(m0),f&&t(Lze),f&&t(nf),w(C$),f&&t(yze),f&&t(br),w(w$),w(L$),w(h0),w(y$),w(w0),f&&t(xze),f&&t(df),w(x$),f&&t($ze),f&&t(vr),w($$),w(S$),w(L0),w(R$),w(q0),f&&t(kze),f&&t(mf),w(P$),f&&t(Sze),f&&t(Fr),w(B$),w(N$),w(D0),w(q$),w(Y0),f&&t(Rze),f&&t(pf),w(j$),f&&t(Pze),f&&t(Tr),w(D$),w(O$),w(Z0),w(V$),w(iw),f&&t(Bze),f&&t(bf),w(X$),f&&t(Ize),f&&t(Mr),w(z$),w(W$),w(cw),w(H$),w(vw),f&&t(Nze),f&&t(Tf),w(U$),f&&t(qze),f&&t(Er),w(J$),w(K$),w(Tw),w(Z$),w(Ew),f&&t(jze),f&&t(Cf),w(ek),f&&t(Dze),f&&t(Cr),w(ok),w(tk),w(ww),w(ak),w(yw),f&&t(Gze),f&&t(Lf),w(sk),f&&t(Oze),f&&t(wr),w(lk),w(dk),w($w),w(ck),w(Sw)}}}const KWt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function ZWt($){return Yzt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class sHt extends Wzt{constructor(g){super();Hzt(this,g,ZWt,YWt,Uzt,{})}}export{sHt as default,KWt as metadata};
