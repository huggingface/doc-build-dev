import{S as Ca,i as qa,s as Ta,F as gt,e as p,c as m,a as d,d as s,b as k,g as h,G as o,Q as us,Y as rc,H as $t,I as vt,J as bt,q as j,o as A,v as ur,X as cr,O as Qu,P as Hu,f as dc,L as ee,w as y,x as N,y as M,B as D,k as w,m as E,n as Se,p as ye,Z as uc,l as Me,t as c,h as f,j as cc,W as _c,N as cs,K as fc,M as hc}from"../chunks/vendor-hf-doc-builder.js";import{T as Aa,C as H}from"../chunks/CodeBlock-hf-doc-builder.js";import{Y as Ju}from"../chunks/Youtube-hf-doc-builder.js";import{I as ht}from"../chunks/IconCopyLink-hf-doc-builder.js";import{F as ja,M as $e}from"../chunks/Markdown-hf-doc-builder.js";function gc(u){let e,n,t,l,i,r;const g=u[7].default,_=gt(g,u,u[6],null);return{c(){e=p("div"),n=p("ul"),_&&_.c(),this.h()},l(v){e=m(v,"DIV",{class:!0});var q=d(e);n=m(q,"UL",{class:!0});var I=d(n);_&&_.l(I),I.forEach(s),q.forEach(s),this.h()},h(){k(n,"class","min-w-full w-auto"),k(e,"class",t="absolute top-full mt-1 min-w-full w-auto bg-white rounded-xl overflow-hidden shadow-lg z-10 border border-gray-100 "+(u[2]==="right"?"right-0":"left-0")+" "+u[0])},m(v,q){h(v,e,q),o(e,n),_&&_.m(n,null),u[8](e),l=!0,i||(r=us(e,"click",function(){rc(u[1])&&u[1].apply(this,arguments)}),i=!0)},p(v,[q]){u=v,_&&_.p&&(!l||q&64)&&$t(_,g,u,u[6],l?bt(g,u[6],q,null):vt(u[6]),null),(!l||q&5&&t!==(t="absolute top-full mt-1 min-w-full w-auto bg-white rounded-xl overflow-hidden shadow-lg z-10 border border-gray-100 "+(u[2]==="right"?"right-0":"left-0")+" "+u[0]))&&k(e,"class",t)},i(v){l||(j(_,v),l=!0)},o(v){A(_,v),l=!1},d(v){v&&s(e),_&&_.d(v),u[8](null),i=!1,r()}}}function $c(u,e,n){let{$$slots:t={},$$scope:l}=e,{classNames:i=""}=e,{dropdownElement:r=void 0}=e,{forceAlignement:g=void 0}=e,{onClose:_}=e,v=g!=null?g:"left",q;ur(()=>{var P,S;if(document.addEventListener("click",I),!g){const z=document.documentElement.clientWidth,C=(q==null?void 0:q.getBoundingClientRect())||{},b=(P=C.left)!=null?P:0,T=(S=C.width)!=null?S:0;n(2,v=b+T>z?"right":"left")}return()=>{document.removeEventListener("click",I)}});function I(P){const S=P.target;S!==r&&!(r==null?void 0:r.contains(S))&&_()}function F(P){cr[P?"unshift":"push"](()=>{q=P,n(3,q)})}return u.$$set=P=>{"classNames"in P&&n(0,i=P.classNames),"dropdownElement"in P&&n(4,r=P.dropdownElement),"forceAlignement"in P&&n(5,g=P.forceAlignement),"onClose"in P&&n(1,_=P.onClose),"$$scope"in P&&n(6,l=P.$$scope)},[i,_,v,q,r,g,l,t,F]}class vc extends Ca{constructor(e){super();qa(this,e,$c,gc,Ta,{classNames:0,dropdownElement:4,forceAlignement:5,onClose:1})}}function bc(u){let e,n;return{c(){e=Qu("svg"),n=Qu("path"),this.h()},l(t){e=Hu(t,"svg",{class:!0,xmlns:!0,"xmlns:xlink":!0,"aria-hidden":!0,focusable:!0,role:!0,width:!0,height:!0,preserveAspectRatio:!0,viewBox:!0,style:!0});var l=d(e);n=Hu(l,"path",{d:!0,fill:!0}),d(n).forEach(s),l.forEach(s),this.h()},h(){k(n,"d","M7 10l5 5l5-5z"),k(n,"fill","currentColor"),k(e,"class",u[0]),k(e,"xmlns","http://www.w3.org/2000/svg"),k(e,"xmlns:xlink","http://www.w3.org/1999/xlink"),k(e,"aria-hidden","true"),k(e,"focusable","false"),k(e,"role","img"),k(e,"width","1em"),k(e,"height","1em"),k(e,"preserveAspectRatio","xMidYMid meet"),k(e,"viewBox","0 0 24 24"),dc(e,"transform","rotate(360deg)")},m(t,l){h(t,e,l),o(e,n)},p(t,[l]){l&1&&k(e,"class",t[0])},i:ee,o:ee,d(t){t&&s(e)}}}function kc(u,e,n){let{classNames:t=""}=e;return u.$$set=l=>{"classNames"in l&&n(0,t=l.classNames)},[t]}class zc extends Ca{constructor(e){super();qa(this,e,kc,bc,Ta,{classNames:0})}}const wc=u=>({}),Vu=u=>({}),Ec=u=>({}),Wu=u=>({});function jc(u){let e,n,t,l,i,r=u[2]&&Yu(u),g=u[10]&&Ku();return{c(){r&&r.c(),e=w(),n=c(u[4]),t=w(),g&&g.c(),l=Me()},l(_){r&&r.l(_),e=E(_),n=f(_,u[4]),t=E(_),g&&g.l(_),l=Me()},m(_,v){r&&r.m(_,v),h(_,e,v),h(_,n,v),h(_,t,v),g&&g.m(_,v),h(_,l,v),i=!0},p(_,v){_[2]?r?(r.p(_,v),v&4&&j(r,1)):(r=Yu(_),r.c(),j(r,1),r.m(e.parentNode,e)):r&&(Se(),A(r,1,1,()=>{r=null}),ye()),(!i||v&16)&&cc(n,_[4]),_[10]?g?v&1024&&j(g,1):(g=Ku(),g.c(),j(g,1),g.m(l.parentNode,l)):g&&(Se(),A(g,1,1,()=>{g=null}),ye())},i(_){i||(j(r),j(g),i=!0)},o(_){A(r),A(g),i=!1},d(_){r&&r.d(_),_&&s(e),_&&s(n),_&&s(t),g&&g.d(_),_&&s(l)}}}function Ac(u){let e;const n=u[14].button,t=gt(n,u,u[18],Wu);return{c(){t&&t.c()},l(l){t&&t.l(l)},m(l,i){t&&t.m(l,i),e=!0},p(l,i){t&&t.p&&(!e||i&262144)&&$t(t,n,l,l[18],e?bt(n,l[18],i,Ec):vt(l[18]),Wu)},i(l){e||(j(t,l),e=!0)},o(l){A(t,l),e=!1},d(l){t&&t.d(l)}}}function Yu(u){let e,n,t;var l=u[2];function i(r){return{props:{classNames:"mr-1.5 "+r[3]}}}return l&&(e=new l(i(u))),{c(){e&&y(e.$$.fragment),n=Me()},l(r){e&&N(e.$$.fragment,r),n=Me()},m(r,g){e&&M(e,r,g),h(r,n,g),t=!0},p(r,g){const _={};if(g&8&&(_.classNames="mr-1.5 "+r[3]),l!==(l=r[2])){if(e){Se();const v=e;A(v.$$.fragment,1,0,()=>{D(v,1)}),ye()}l?(e=new l(i(r)),y(e.$$.fragment),j(e.$$.fragment,1),M(e,n.parentNode,n)):e=null}else l&&e.$set(_)},i(r){t||(e&&j(e.$$.fragment,r),t=!0)},o(r){e&&A(e.$$.fragment,r),t=!1},d(r){r&&s(n),e&&D(e,r)}}}function Ku(u){let e,n;return e=new zc({props:{classNames:"-mr-1 text-gray-500"}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function Zu(u){let e,n;return e=new vc({props:{classNames:u[6]+" "+(u[9]?"v2-dropdown-menu hidden":""),dropdownElement:u[11],forceAlignement:u[5],onClose:u[16],$$slots:{default:[Cc]},$$scope:{ctx:u}}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p(t,l){const i={};l&576&&(i.classNames=t[6]+" "+(t[9]?"v2-dropdown-menu hidden":"")),l&2048&&(i.dropdownElement=t[11]),l&32&&(i.forceAlignement=t[5]),l&4096&&(i.onClose=t[16]),l&262144&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function Cc(u){let e;const n=u[14].menu,t=gt(n,u,u[18],Vu);return{c(){t&&t.c()},l(l){t&&t.l(l)},m(l,i){t&&t.m(l,i),e=!0},p(l,i){t&&t.p&&(!e||i&262144)&&$t(t,n,l,l[18],e?bt(n,l[18],i,wc):vt(l[18]),Vu)},i(l){e||(j(t,l),e=!0)},o(l){A(t,l),e=!1},d(l){t&&t.d(l)}}}function qc(u){let e,n,t,l,i,r,g,_,v,q,I;const F=[Ac,jc],P=[];function S(C,b){return C[13].button?0:1}t=S(u),l=P[t]=F[t](u);let z=(u[12]||u[9])&&Zu(u);return{c(){e=p("div"),n=p("button"),l.c(),r=w(),z&&z.c(),this.h()},l(C){e=m(C,"DIV",{class:!0,"selected-value":!0});var b=d(e);n=m(b,"BUTTON",{class:!0,type:!0});var T=d(n);l.l(T),T.forEach(s),r=E(b),z&&z.l(b),b.forEach(s),this.h()},h(){k(n,"class",i=""+u[1]+" "+(u[7]?"":"cursor-pointer w-full btn text-sm")+" "+(u[9]?"v2-dropdown-button":"")),k(n,"type","button"),k(e,"class",g="relative "+u[0]+" "+(u[9]?"v2-dropdown":"")),k(e,"selected-value",_=u[8]||void 0)},m(C,b){h(C,e,b),o(e,n),P[t].m(n,null),o(e,r),z&&z.m(e,null),u[17](e),v=!0,q||(I=us(n,"click",u[15]),q=!0)},p(C,[b]){let T=t;t=S(C),t===T?P[t].p(C,b):(Se(),A(P[T],1,1,()=>{P[T]=null}),ye(),l=P[t],l?l.p(C,b):(l=P[t]=F[t](C),l.c()),j(l,1),l.m(n,null)),(!v||b&642&&i!==(i=""+C[1]+" "+(C[7]?"":"cursor-pointer w-full btn text-sm")+" "+(C[9]?"v2-dropdown-button":"")))&&k(n,"class",i),C[12]||C[9]?z?(z.p(C,b),b&4608&&j(z,1)):(z=Zu(C),z.c(),j(z,1),z.m(e,null)):z&&(Se(),A(z,1,1,()=>{z=null}),ye()),(!v||b&513&&g!==(g="relative "+C[0]+" "+(C[9]?"v2-dropdown":"")))&&k(e,"class",g),(!v||b&256&&_!==(_=C[8]||void 0))&&k(e,"selected-value",_)},i(C){v||(j(l),j(z),v=!0)},o(C){A(l),A(z),v=!1},d(C){C&&s(e),P[t].d(),z&&z.d(),u[17](null),q=!1,I()}}}function Tc(u,e,n){let{$$slots:t={},$$scope:l}=e;const i=uc(t);let{classNames:r=""}=e,{btnClassNames:g=""}=e,{btnIcon:_=void 0}=e,{btnIconClassNames:v=""}=e,{btnLabel:q=""}=e,{forceMenuAlignement:I=void 0}=e,{menuClassNames:F=""}=e,{noBtnClass:P=void 0}=e,{selectedValue:S=void 0}=e,{useDeprecatedJS:z=!0}=e,{withBtnCaret:C=!1}=e,b,T=!1;const R=()=>n(12,T=!T),G=()=>n(12,T=!1);function V(U){cr[U?"unshift":"push"](()=>{b=U,n(11,b)})}return u.$$set=U=>{"classNames"in U&&n(0,r=U.classNames),"btnClassNames"in U&&n(1,g=U.btnClassNames),"btnIcon"in U&&n(2,_=U.btnIcon),"btnIconClassNames"in U&&n(3,v=U.btnIconClassNames),"btnLabel"in U&&n(4,q=U.btnLabel),"forceMenuAlignement"in U&&n(5,I=U.forceMenuAlignement),"menuClassNames"in U&&n(6,F=U.menuClassNames),"noBtnClass"in U&&n(7,P=U.noBtnClass),"selectedValue"in U&&n(8,S=U.selectedValue),"useDeprecatedJS"in U&&n(9,z=U.useDeprecatedJS),"withBtnCaret"in U&&n(10,C=U.withBtnCaret),"$$scope"in U&&n(18,l=U.$$scope)},[r,g,_,v,q,I,F,P,S,z,C,b,T,i,t,R,G,V,l]}class pc extends Ca{constructor(e){super();qa(this,e,Tc,qc,Ta,{classNames:0,btnClassNames:1,btnIcon:2,btnIconClassNames:3,btnLabel:4,forceMenuAlignement:5,menuClassNames:6,noBtnClass:7,selectedValue:8,useDeprecatedJS:9,withBtnCaret:10})}}function Pc(u){let e,n,t,l=u[5]&&Xu(u);return{c(){l&&l.c(),e=w(),n=c(u[7])},l(i){l&&l.l(i),e=E(i),n=f(i,u[7])},m(i,r){l&&l.m(i,r),h(i,e,r),h(i,n,r),t=!0},p(i,r){i[5]?l?(l.p(i,r),r&32&&j(l,1)):(l=Xu(i),l.c(),j(l,1),l.m(e.parentNode,e)):l&&(Se(),A(l,1,1,()=>{l=null}),ye()),(!t||r&128)&&cc(n,i[7])},i(i){t||(j(l),t=!0)},o(i){A(l),t=!1},d(i){l&&l.d(i),i&&s(e),i&&s(n)}}}function Sc(u){let e;const n=u[15].default,t=gt(n,u,u[14],null);return{c(){t&&t.c()},l(l){t&&t.l(l)},m(l,i){t&&t.m(l,i),e=!0},p(l,i){t&&t.p&&(!e||i&16384)&&$t(t,n,l,l[14],e?bt(n,l[14],i,null):vt(l[14]),null)},i(l){e||(j(t,l),e=!0)},o(l){A(t,l),e=!1},d(l){t&&t.d(l)}}}function Xu(u){let e,n,t;var l=u[5];function i(r){return{props:{classNames:"mr-1.5 "+r[6]}}}return l&&(e=new l(i(u))),{c(){e&&y(e.$$.fragment),n=Me()},l(r){e&&N(e.$$.fragment,r),n=Me()},m(r,g){e&&M(e,r,g),h(r,n,g),t=!0},p(r,g){const _={};if(g&64&&(_.classNames="mr-1.5 "+r[6]),l!==(l=r[5])){if(e){Se();const v=e;A(v.$$.fragment,1,0,()=>{D(v,1)}),ye()}l?(e=new l(i(r)),y(e.$$.fragment),j(e.$$.fragment,1),M(e,n.parentNode,n)):e=null}else l&&e.$set(_)},i(r){t||(e&&j(e.$$.fragment,r),t=!0)},o(r){e&&A(e.$$.fragment,r),t=!1},d(r){r&&s(n),e&&D(e,r)}}}function yc(u){let e,n,t,l,i,r,g,_,v,q;const I=[Sc,Pc],F=[];function P(S,z){return S[13].default?0:1}return t=P(u),l=F[t]=I[t](u),{c(){e=p("li"),n=p("a"),l.c(),this.h()},l(S){e=m(S,"LI",{});var z=d(e);n=m(z,"A",{class:!0,"data-label":!0,"data-url":!0,"data-value":!0,href:!0,rel:!0,target:!0});var C=d(n);l.l(C),C.forEach(s),z.forEach(s),this.h()},h(){k(n,"class",i="flex items-center hover:bg-gray-50 dark:hover:bg-gray-800 cursor-pointer px-3 py-1.5 whitespace-nowrap "+u[0]+" "+(u[9]?"hover:underline":"")+" "+(u[12]?"v2-dropdown-entry":"")),k(n,"data-label",u[1]),k(n,"data-url",u[2]),k(n,"data-value",u[3]),k(n,"href",u[4]),k(n,"rel",r=u[8]?"nofollow":void 0),k(n,"target",g=u[11]?"_blank":void 0)},m(S,z){h(S,e,z),o(e,n),F[t].m(n,null),_=!0,v||(q=us(n,"click",function(){rc(u[10])&&u[10].apply(this,arguments)}),v=!0)},p(S,[z]){u=S;let C=t;t=P(u),t===C?F[t].p(u,z):(Se(),A(F[C],1,1,()=>{F[C]=null}),ye(),l=F[t],l?l.p(u,z):(l=F[t]=I[t](u),l.c()),j(l,1),l.m(n,null)),(!_||z&4609&&i!==(i="flex items-center hover:bg-gray-50 dark:hover:bg-gray-800 cursor-pointer px-3 py-1.5 whitespace-nowrap "+u[0]+" "+(u[9]?"hover:underline":"")+" "+(u[12]?"v2-dropdown-entry":"")))&&k(n,"class",i),(!_||z&2)&&k(n,"data-label",u[1]),(!_||z&4)&&k(n,"data-url",u[2]),(!_||z&8)&&k(n,"data-value",u[3]),(!_||z&16)&&k(n,"href",u[4]),(!_||z&256&&r!==(r=u[8]?"nofollow":void 0))&&k(n,"rel",r),(!_||z&2048&&g!==(g=u[11]?"_blank":void 0))&&k(n,"target",g)},i(S){_||(j(l),_=!0)},o(S){A(l),_=!1},d(S){S&&s(e),F[t].d(),v=!1,q()}}}function Mc(u,e,n){let{$$slots:t={},$$scope:l}=e;const i=uc(t);let{classNames:r=""}=e,{dataLabel:g=void 0}=e,{dataUrl:_=void 0}=e,{dataValue:v=void 0}=e,{href:q=void 0}=e,{icon:I=void 0}=e,{iconClassNames:F=""}=e,{label:P=""}=e,{noFollow:S=!1}=e,{underline:z=!1}=e,{onClick:C=()=>{}}=e,{targetBlank:b=!1}=e,{useDeprecatedJS:T=!0}=e;return u.$$set=R=>{"classNames"in R&&n(0,r=R.classNames),"dataLabel"in R&&n(1,g=R.dataLabel),"dataUrl"in R&&n(2,_=R.dataUrl),"dataValue"in R&&n(3,v=R.dataValue),"href"in R&&n(4,q=R.href),"icon"in R&&n(5,I=R.icon),"iconClassNames"in R&&n(6,F=R.iconClassNames),"label"in R&&n(7,P=R.label),"noFollow"in R&&n(8,S=R.noFollow),"underline"in R&&n(9,z=R.underline),"onClick"in R&&n(10,C=R.onClick),"targetBlank"in R&&n(11,b=R.targetBlank),"useDeprecatedJS"in R&&n(12,T=R.useDeprecatedJS),"$$scope"in R&&n(14,l=R.$$scope)},[r,g,_,v,q,I,F,P,S,z,C,b,T,i,l,t]}class mc extends Ca{constructor(e){super();qa(this,e,Mc,yc,Ta,{classNames:0,dataLabel:1,dataUrl:2,dataValue:3,href:4,icon:5,iconClassNames:6,label:7,noFollow:8,underline:9,onClick:10,targetBlank:11,useDeprecatedJS:12})}}const{window:Dc}=_c,Nc=u=>({}),xu=u=>({slot:"button"});function ec(u,e,n){const t=u.slice();return t[11]=e[n].label,t[12]=e[n].value,t}const Fc=u=>({}),tc=u=>({slot:"menu"}),Ic=u=>({}),ac=u=>({slot:"button"});function lc(u,e,n){const t=u.slice();return t[11]=e[n].label,t[12]=e[n].value,t}const Oc=u=>({}),oc=u=>({slot:"menu"});function Lc(u){let e,n;return e=new pc({props:{btnLabel:"",classNames:"colab-dropdown",noBtnClass:!0,useDeprecatedJS:!1,$$slots:{menu:[Qc],button:[Bc]},$$scope:{ctx:u}}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p(t,l){const i={};l&1024&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function Rc(u){let e,n,t;return{c(){e=p("a"),n=p("img"),this.h()},l(l){e=m(l,"A",{href:!0,target:!0});var i=d(e);n=m(i,"IMG",{alt:!0,class:!0,src:!0}),i.forEach(s),this.h()},h(){k(n,"alt","Open In Colab"),k(n,"class","!m-0"),cs(n.src,t="https://colab.research.google.com/assets/colab-badge.svg")||k(n,"src",t),k(e,"href",u[2][0].value),k(e,"target","_blank")},m(l,i){h(l,e,i),o(e,n)},p:ee,i:ee,o:ee,d(l){l&&s(e)}}}function Uc(u){let e,n;return{c(){e=p("img"),this.h()},l(t){e=m(t,"IMG",{alt:!0,class:!0,src:!0}),this.h()},h(){k(e,"alt","Open In Colab"),k(e,"class","!m-0"),cs(e.src,n="https://colab.research.google.com/assets/colab-badge.svg")||k(e,"src",n)},m(t,l){h(t,e,l)},d(t){t&&s(e)}}}function Bc(u){let e;const n=u[6].default,t=gt(n,u,u[10],ac),l=t||Uc();return{c(){l&&l.c()},l(i){l&&l.l(i)},m(i,r){l&&l.m(i,r),e=!0},p(i,r){t&&t.p&&(!e||r&1024)&&$t(t,n,i,i[10],e?bt(n,i[10],r,Ic):vt(i[10]),ac)},i(i){e||(j(l,i),e=!0)},o(i){A(l,i),e=!1},d(i){l&&l.d(i)}}}function sc(u){let e,n;function t(){return u[7](u[12])}return e=new mc({props:{classNames:"text-sm !no-underline",iconClassNames:"text-gray-500",label:u[11],onClick:t,useDeprecatedJS:!1}}),{c(){y(e.$$.fragment)},l(l){N(e.$$.fragment,l)},m(l,i){M(e,l,i),n=!0},p(l,i){u=l},i(l){n||(j(e.$$.fragment,l),n=!0)},o(l){A(e.$$.fragment,l),n=!1},d(l){D(e,l)}}}function Gc(u){let e,n,t=u[2],l=[];for(let r=0;r<t.length;r+=1)l[r]=sc(lc(u,t,r));const i=r=>A(l[r],1,1,()=>{l[r]=null});return{c(){for(let r=0;r<l.length;r+=1)l[r].c();e=Me()},l(r){for(let g=0;g<l.length;g+=1)l[g].l(r);e=Me()},m(r,g){for(let _=0;_<l.length;_+=1)l[_].m(r,g);h(r,e,g),n=!0},p(r,g){if(g&4){t=r[2];let _;for(_=0;_<t.length;_+=1){const v=lc(r,t,_);l[_]?(l[_].p(v,g),j(l[_],1)):(l[_]=sc(v),l[_].c(),j(l[_],1),l[_].m(e.parentNode,e))}for(Se(),_=t.length;_<l.length;_+=1)i(_);ye()}},i(r){if(!n){for(let g=0;g<t.length;g+=1)j(l[g]);n=!0}},o(r){l=l.filter(Boolean);for(let g=0;g<l.length;g+=1)A(l[g]);n=!1},d(r){fc(l,r),r&&s(e)}}}function Qc(u){let e;const n=u[6].default,t=gt(n,u,u[10],oc),l=t||Gc(u);return{c(){l&&l.c()},l(i){l&&l.l(i)},m(i,r){l&&l.m(i,r),e=!0},p(i,r){t&&t.p&&(!e||r&1024)&&$t(t,n,i,i[10],e?bt(n,i[10],r,Oc):vt(i[10]),oc)},i(i){e||(j(l,i),e=!0)},o(i){A(l,i),e=!1},d(i){l&&l.d(i)}}}function Hc(u){let e,n;return e=new pc({props:{btnLabel:"",classNames:"colab-dropdown",noBtnClass:!0,useDeprecatedJS:!1,$$slots:{menu:[Kc],button:[Wc]},$$scope:{ctx:u}}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p(t,l){const i={};l&1024&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function Jc(u){let e,n,t;return{c(){e=p("a"),n=p("img"),this.h()},l(l){e=m(l,"A",{href:!0,target:!0});var i=d(e);n=m(i,"IMG",{alt:!0,class:!0,src:!0}),i.forEach(s),this.h()},h(){k(n,"alt","Open In Studio Lab"),k(n,"class","!m-0"),cs(n.src,t="https://studiolab.sagemaker.aws/studiolab.svg")||k(n,"src",t),k(e,"href",u[3][0].value),k(e,"target","_blank")},m(l,i){h(l,e,i),o(e,n)},p:ee,i:ee,o:ee,d(l){l&&s(e)}}}function Vc(u){let e,n;return{c(){e=p("img"),this.h()},l(t){e=m(t,"IMG",{alt:!0,class:!0,src:!0}),this.h()},h(){k(e,"alt","Open In Studio Lab"),k(e,"class","!m-0"),cs(e.src,n="https://studiolab.sagemaker.aws/studiolab.svg")||k(e,"src",n)},m(t,l){h(t,e,l)},d(t){t&&s(e)}}}function Wc(u){let e;const n=u[6].default,t=gt(n,u,u[10],xu),l=t||Vc();return{c(){l&&l.c()},l(i){l&&l.l(i)},m(i,r){l&&l.m(i,r),e=!0},p(i,r){t&&t.p&&(!e||r&1024)&&$t(t,n,i,i[10],e?bt(n,i[10],r,Nc):vt(i[10]),xu)},i(i){e||(j(l,i),e=!0)},o(i){A(l,i),e=!1},d(i){l&&l.d(i)}}}function nc(u){let e,n;function t(){return u[8](u[12])}return e=new mc({props:{classNames:"text-sm !no-underline",iconClassNames:"text-gray-500",label:u[11],onClick:t,useDeprecatedJS:!1}}),{c(){y(e.$$.fragment)},l(l){N(e.$$.fragment,l)},m(l,i){M(e,l,i),n=!0},p(l,i){u=l},i(l){n||(j(e.$$.fragment,l),n=!0)},o(l){A(e.$$.fragment,l),n=!1},d(l){D(e,l)}}}function Yc(u){let e,n,t=u[3],l=[];for(let r=0;r<t.length;r+=1)l[r]=nc(ec(u,t,r));const i=r=>A(l[r],1,1,()=>{l[r]=null});return{c(){for(let r=0;r<l.length;r+=1)l[r].c();e=Me()},l(r){for(let g=0;g<l.length;g+=1)l[g].l(r);e=Me()},m(r,g){for(let _=0;_<l.length;_+=1)l[_].m(r,g);h(r,e,g),n=!0},p(r,g){if(g&8){t=r[3];let _;for(_=0;_<t.length;_+=1){const v=ec(r,t,_);l[_]?(l[_].p(v,g),j(l[_],1)):(l[_]=nc(v),l[_].c(),j(l[_],1),l[_].m(e.parentNode,e))}for(Se(),_=t.length;_<l.length;_+=1)i(_);ye()}},i(r){if(!n){for(let g=0;g<t.length;g+=1)j(l[g]);n=!0}},o(r){l=l.filter(Boolean);for(let g=0;g<l.length;g+=1)A(l[g]);n=!1},d(r){fc(l,r),r&&s(e)}}}function Kc(u){let e;const n=u[6].default,t=gt(n,u,u[10],tc),l=t||Yc(u);return{c(){l&&l.c()},l(i){l&&l.l(i)},m(i,r){l&&l.m(i,r),e=!0},p(i,r){t&&t.p&&(!e||r&1024)&&$t(t,n,i,i[10],e?bt(n,i[10],r,Fc):vt(i[10]),tc)},i(i){e||(j(l,i),e=!0)},o(i){A(l,i),e=!1},d(i){l&&l.d(i)}}}function Zc(u){let e,n,t,l,i,r,g,_,v,q;const I=[Rc,Lc],F=[];function P(b,T){return b[2].length===1?0:1}n=P(u),t=F[n]=I[n](u);const S=[Jc,Hc],z=[];function C(b,T){return b[3].length===1?0:1}return i=C(u),r=z[i]=S[i](u),{c(){e=p("div"),t.c(),l=w(),r.c(),this.h()},l(b){e=m(b,"DIV",{class:!0});var T=d(e);t.l(T),l=E(T),r.l(T),T.forEach(s),this.h()},h(){k(e,"class",g="flex space-x-1 "+u[0])},m(b,T){h(b,e,T),F[n].m(e,null),o(e,l),z[i].m(e,null),u[9](e),_=!0,v||(q=us(Dc,"resize",u[4]),v=!0)},p(b,[T]){t.p(b,T),r.p(b,T),(!_||T&1&&g!==(g="flex space-x-1 "+b[0]))&&k(e,"class",g)},i(b){_||(j(t),j(r),_=!0)},o(b){A(t),A(r),_=!1},d(b){b&&s(e),F[n].d(),z[i].d(),u[9](null),v=!1,q()}}}function ic(u){window.open(u)}function Xc(u,e,n){let{$$slots:t={},$$scope:l}=e,{options:i=[]}=e,{classNames:r=""}=e,g;const _=i.filter(S=>S.value.includes("colab.research.google.com")),v=i.filter(S=>S.value.includes("studiolab.sagemaker.aws"));function q(){const S=document.querySelector(".prose-doc h1"),z=document.querySelector(".prose-doc h1 > span");if(S&&z){const{width:C}=S.getBoundingClientRect(),{width:b}=z.getBoundingClientRect();let T=0;for(let G=0;G<g.children.length;G++)T+=g.children.item(G).clientWidth;const R=20;C-b<T+R?g.classList.remove("absolute"):g.classList.add("absolute")}}ur(()=>{q()});const I=S=>ic(S),F=S=>ic(S);function P(S){cr[S?"unshift":"push"](()=>{g=S,n(1,g)})}return u.$$set=S=>{"options"in S&&n(5,i=S.options),"classNames"in S&&n(0,r=S.classNames),"$$scope"in S&&n(10,l=S.$$scope)},[r,g,_,v,q,i,t,I,F,P,l]}class xc extends Ca{constructor(e){super();qa(this,e,Xc,Zc,Ta,{options:5,classNames:0})}}function ef(u){let e,n;return{c(){e=p("p"),n=c(`Tutti gli esempi di codice presenti in questa documentazione hanno un pulsante in alto a sinistra che permette di selezionare tra PyTorch e TensorFlow. Se
questo non \xE8 presente, ci si aspetta che il codice funzioni per entrambi i backend senza alcun cambiamento.`)},l(t){e=m(t,"P",{});var l=d(e);n=f(l,`Tutti gli esempi di codice presenti in questa documentazione hanno un pulsante in alto a sinistra che permette di selezionare tra PyTorch e TensorFlow. Se
questo non \xE8 presente, ci si aspetta che il codice funzioni per entrambi i backend senza alcun cambiamento.`),l.forEach(s)},m(t,l){h(t,e,l),o(e,n)},d(t){t&&s(e)}}}function tf(u){let e,n,t,l,i,r,g,_;return{c(){e=p("p"),n=c("Per maggiori dettagli legati alla "),t=p("code"),l=c("pipeline()"),i=c(" e ai compiti ad essa associati, fai riferimento alla documentazione "),r=p("a"),g=c("qui"),_=c("."),this.h()},l(v){e=m(v,"P",{});var q=d(e);n=f(q,"Per maggiori dettagli legati alla "),t=m(q,"CODE",{});var I=d(t);l=f(I,"pipeline()"),I.forEach(s),i=f(q," e ai compiti ad essa associati, fai riferimento alla documentazione "),r=m(q,"A",{href:!0});var F=d(r);g=f(F,"qui"),F.forEach(s),_=f(q,"."),q.forEach(s),this.h()},h(){k(r,"href","./main_classes/pipelines")},m(v,q){h(v,e,q),o(e,n),o(e,t),o(t,l),o(e,i),o(e,r),o(r,g),o(e,_)},d(v){v&&s(e)}}}function af(u){let e,n;return e=new H({props:{code:"pip install torch",highlighted:"pip install torch"}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p:ee,i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function lf(u){let e,n;return e=new $e({props:{$$slots:{default:[af]},$$scope:{ctx:u}}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function of(u){let e,n;return e=new H({props:{code:"pip install tensorflow",highlighted:"pip install tensorflow"}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p:ee,i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function sf(u){let e,n;return e=new $e({props:{$$slots:{default:[of]},$$scope:{ctx:u}}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function nf(u){let e,n,t,l,i,r,g,_,v,q,I,F,P,S;return P=new H({props:{code:`from transformers import AutoTokenizer, AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),{c(){e=p("p"),n=c("Usa "),t=p("code"),l=c("AutoModelForSequenceClassification"),i=c(" e "),r=p("code"),g=c("AutoTokenizer"),_=c(" per caricare il modello pre-allenato e il suo tokenizer associato (maggiori informazioni su una "),v=p("code"),q=c("AutoClass"),I=c(" in seguito):"),F=w(),y(P.$$.fragment)},l(z){e=m(z,"P",{});var C=d(e);n=f(C,"Usa "),t=m(C,"CODE",{});var b=d(t);l=f(b,"AutoModelForSequenceClassification"),b.forEach(s),i=f(C," e "),r=m(C,"CODE",{});var T=d(r);g=f(T,"AutoTokenizer"),T.forEach(s),_=f(C," per caricare il modello pre-allenato e il suo tokenizer associato (maggiori informazioni su una "),v=m(C,"CODE",{});var R=d(v);q=f(R,"AutoClass"),R.forEach(s),I=f(C," in seguito):"),C.forEach(s),F=E(z),N(P.$$.fragment,z)},m(z,C){h(z,e,C),o(e,n),o(e,t),o(t,l),o(e,i),o(e,r),o(r,g),o(e,_),o(e,v),o(v,q),o(e,I),h(z,F,C),M(P,z,C),S=!0},p:ee,i(z){S||(j(P.$$.fragment,z),S=!0)},o(z){A(P.$$.fragment,z),S=!1},d(z){z&&s(e),z&&s(F),D(P,z)}}}function rf(u){let e,n;return e=new $e({props:{$$slots:{default:[nf]},$$scope:{ctx:u}}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function uf(u){let e,n,t,l,i,r,g,_,v,q,I,F,P,S;return P=new H({props:{code:`from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),{c(){e=p("p"),n=c("Usa "),t=p("code"),l=c("TFAutoModelForSequenceClassification"),i=c(" e "),r=p("code"),g=c("AutoTokenizer"),_=c(" per caricare il modello pre-allenato e il suo tokenizer associato (maggiori informazioni su una "),v=p("code"),q=c("TFAutoClass"),I=c(" in seguito):"),F=w(),y(P.$$.fragment)},l(z){e=m(z,"P",{});var C=d(e);n=f(C,"Usa "),t=m(C,"CODE",{});var b=d(t);l=f(b,"TFAutoModelForSequenceClassification"),b.forEach(s),i=f(C," e "),r=m(C,"CODE",{});var T=d(r);g=f(T,"AutoTokenizer"),T.forEach(s),_=f(C," per caricare il modello pre-allenato e il suo tokenizer associato (maggiori informazioni su una "),v=m(C,"CODE",{});var R=d(v);q=f(R,"TFAutoClass"),R.forEach(s),I=f(C," in seguito):"),C.forEach(s),F=E(z),N(P.$$.fragment,z)},m(z,C){h(z,e,C),o(e,n),o(e,t),o(t,l),o(e,i),o(e,r),o(r,g),o(e,_),o(e,v),o(v,q),o(e,I),h(z,F,C),M(P,z,C),S=!0},p:ee,i(z){S||(j(P.$$.fragment,z),S=!0)},o(z){A(P.$$.fragment,z),S=!1},d(z){z&&s(e),z&&s(F),D(P,z)}}}function cf(u){let e,n;return e=new $e({props:{$$slots:{default:[uf]},$$scope:{ctx:u}}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function ff(u){let e,n;return e=new H({props:{code:`pt_batch = tokenizer(
    ["Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.", "Speriamo te non la odierai."],
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="pt",
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.&quot;</span>, <span class="hljs-string">&quot;Speriamo te non la odierai.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;pt&quot;</span>,
<span class="hljs-meta">... </span>)`}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p:ee,i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function pf(u){let e,n;return e=new $e({props:{$$slots:{default:[ff]},$$scope:{ctx:u}}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function mf(u){let e,n;return e=new H({props:{code:`tf_batch = tokenizer(
    ["Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.", "Speriamo te non la odierai."],
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="tf",
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.&quot;</span>, <span class="hljs-string">&quot;Speriamo te non la odierai.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;tf&quot;</span>,
<span class="hljs-meta">... </span>)`}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p:ee,i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function df(u){let e,n;return e=new $e({props:{$$slots:{default:[mf]},$$scope:{ctx:u}}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function _f(u){let e,n,t,l,i,r,g,_;return{c(){e=p("p"),n=c("Guarda il "),t=p("a"),l=c("task summary"),i=c(" per sapere quale classe di "),r=p("code"),g=c("AutoModel"),_=c(" utilizzare per quale compito."),this.h()},l(v){e=m(v,"P",{});var q=d(e);n=f(q,"Guarda il "),t=m(q,"A",{href:!0});var I=d(t);l=f(I,"task summary"),I.forEach(s),i=f(q," per sapere quale classe di "),r=m(q,"CODE",{});var F=d(r);g=f(F,"AutoModel"),F.forEach(s),_=f(q," utilizzare per quale compito."),q.forEach(s),this.h()},h(){k(t,"href","./task_summary")},m(v,q){h(v,e,q),o(e,n),o(e,t),o(t,l),o(e,i),o(e,r),o(r,g),o(e,_)},d(v){v&&s(e)}}}function hf(u){let e,n,t,l,i,r,g,_,v,q,I,F,P,S,z,C,b,T,R,G,V,U,ae,Y,J,te,K,Z,de,se,he,ne,le,ie,ge,L,B,re;return C=new H({props:{code:`from transformers import AutoModelForSequenceClassification

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`}}),T=new Aa({props:{$$slots:{default:[_f]},$$scope:{ctx:u}}}),te=new H({props:{code:"pt_outputs = pt_model(**pt_batch)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_outputs = pt_model(**pt_batch)'}}),B=new H({props:{code:`from torch import nn

pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)
print(pt_predictions)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn

<span class="hljs-meta">&gt;&gt;&gt; </span>pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(pt_predictions)
tensor([[<span class="hljs-number">0.0041</span>, <span class="hljs-number">0.0037</span>, <span class="hljs-number">0.0203</span>, <span class="hljs-number">0.2005</span>, <span class="hljs-number">0.7713</span>],
        [<span class="hljs-number">0.3766</span>, <span class="hljs-number">0.3292</span>, <span class="hljs-number">0.1832</span>, <span class="hljs-number">0.0558</span>, <span class="hljs-number">0.0552</span>]], grad_fn=&lt;SoftmaxBackward0&gt;)`}}),{c(){e=p("p"),n=c("\u{1F917} Transformers fornisce un metodo semplice e unificato per caricare istanze pre-allenate. Questo significa che puoi caricare un "),t=p("code"),l=c("AutoModel"),i=c(" come caricheresti un "),r=p("code"),g=c("AutoTokenizer"),_=c(". L\u2019unica differenza \xE8 selezionare l\u2019"),v=p("code"),q=c("AutoModel"),I=c(" corretto per il compito di interesse. Dato che stai facendo classificazione di testi, o sequenze, carica "),F=p("code"),P=c("AutoModelForSequenceClassification"),S=c(":"),z=w(),y(C.$$.fragment),b=w(),y(T.$$.fragment),R=w(),G=p("p"),V=c("Ora puoi passare il tuo lotto di input pre-processati direttamente al modello. Devi solo spacchettare il dizionario aggiungendo "),U=p("code"),ae=c("**"),Y=c(":"),J=w(),y(te.$$.fragment),K=w(),Z=p("p"),de=c("Il modello produrr\xE0 le attivazioni finali nell\u2019attributo "),se=p("code"),he=c("logits"),ne=c(". Applica la funzione softmax a "),le=p("code"),ie=c("logits"),ge=c(" per ottenere le probabilit\xE0:"),L=w(),y(B.$$.fragment)},l(O){e=m(O,"P",{});var Q=d(e);n=f(Q,"\u{1F917} Transformers fornisce un metodo semplice e unificato per caricare istanze pre-allenate. Questo significa che puoi caricare un "),t=m(Q,"CODE",{});var ce=d(t);l=f(ce,"AutoModel"),ce.forEach(s),i=f(Q," come caricheresti un "),r=m(Q,"CODE",{});var De=d(r);g=f(De,"AutoTokenizer"),De.forEach(s),_=f(Q,". L\u2019unica differenza \xE8 selezionare l\u2019"),v=m(Q,"CODE",{});var _e=d(v);q=f(_e,"AutoModel"),_e.forEach(s),I=f(Q," corretto per il compito di interesse. Dato che stai facendo classificazione di testi, o sequenze, carica "),F=m(Q,"CODE",{});var ve=d(F);P=f(ve,"AutoModelForSequenceClassification"),ve.forEach(s),S=f(Q,":"),Q.forEach(s),z=E(O),N(C.$$.fragment,O),b=E(O),N(T.$$.fragment,O),R=E(O),G=m(O,"P",{});var ue=d(G);V=f(ue,"Ora puoi passare il tuo lotto di input pre-processati direttamente al modello. Devi solo spacchettare il dizionario aggiungendo "),U=m(ue,"CODE",{});var Be=d(U);ae=f(Be,"**"),Be.forEach(s),Y=f(ue,":"),ue.forEach(s),J=E(O),N(te.$$.fragment,O),K=E(O),Z=m(O,"P",{});var be=d(Z);de=f(be,"Il modello produrr\xE0 le attivazioni finali nell\u2019attributo "),se=m(be,"CODE",{});var ea=d(se);he=f(ea,"logits"),ea.forEach(s),ne=f(be,". Applica la funzione softmax a "),le=m(be,"CODE",{});var kt=d(le);ie=f(kt,"logits"),kt.forEach(s),ge=f(be," per ottenere le probabilit\xE0:"),be.forEach(s),L=E(O),N(B.$$.fragment,O)},m(O,Q){h(O,e,Q),o(e,n),o(e,t),o(t,l),o(e,i),o(e,r),o(r,g),o(e,_),o(e,v),o(v,q),o(e,I),o(e,F),o(F,P),o(e,S),h(O,z,Q),M(C,O,Q),h(O,b,Q),M(T,O,Q),h(O,R,Q),h(O,G,Q),o(G,V),o(G,U),o(U,ae),o(G,Y),h(O,J,Q),M(te,O,Q),h(O,K,Q),h(O,Z,Q),o(Z,de),o(Z,se),o(se,he),o(Z,ne),o(Z,le),o(le,ie),o(Z,ge),h(O,L,Q),M(B,O,Q),re=!0},p(O,Q){const ce={};Q&2&&(ce.$$scope={dirty:Q,ctx:O}),T.$set(ce)},i(O){re||(j(C.$$.fragment,O),j(T.$$.fragment,O),j(te.$$.fragment,O),j(B.$$.fragment,O),re=!0)},o(O){A(C.$$.fragment,O),A(T.$$.fragment,O),A(te.$$.fragment,O),A(B.$$.fragment,O),re=!1},d(O){O&&s(e),O&&s(z),D(C,O),O&&s(b),D(T,O),O&&s(R),O&&s(G),O&&s(J),D(te,O),O&&s(K),O&&s(Z),O&&s(L),D(B,O)}}}function gf(u){let e,n;return e=new $e({props:{$$slots:{default:[hf]},$$scope:{ctx:u}}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function $f(u){let e,n,t,l,i,r,g,_;return{c(){e=p("p"),n=c("Guarda il "),t=p("a"),l=c("task summary"),i=c(" per sapere quale classe di "),r=p("code"),g=c("AutoModel"),_=c(" utilizzare per quale compito."),this.h()},l(v){e=m(v,"P",{});var q=d(e);n=f(q,"Guarda il "),t=m(q,"A",{href:!0});var I=d(t);l=f(I,"task summary"),I.forEach(s),i=f(q," per sapere quale classe di "),r=m(q,"CODE",{});var F=d(r);g=f(F,"AutoModel"),F.forEach(s),_=f(q," utilizzare per quale compito."),q.forEach(s),this.h()},h(){k(t,"href","./task_summary")},m(v,q){h(v,e,q),o(e,n),o(e,t),o(t,l),o(e,i),o(e,r),o(r,g),o(e,_)},d(v){v&&s(e)}}}function vf(u){let e,n,t,l,i,r,g,_,v,q,I,F,P,S,z,C,b,T,R,G,V,U,ae,Y,J,te,K,Z,de,se,he,ne,le,ie,ge;return C=new H({props:{code:`from transformers import TFAutoModelForSequenceClassification

nome_del_modello = "nlptown/bert-base-multilingual-uncased-sentiment"
tf_model = TFAutoModelForSequenceClassification.from_pretrained(nome_del_modello)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>nome_del_modello = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(nome_del_modello)`}}),T=new Aa({props:{$$slots:{default:[$f]},$$scope:{ctx:u}}}),ae=new H({props:{code:"tf_outputs = tf_model(tf_batch)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_outputs = tf_model(tf_batch)'}}),ie=new H({props:{code:`import tensorflow as tf

tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-1)
tf_predictions`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions`}}),{c(){e=p("p"),n=c("\u{1F917} Transformers fornisce un metodo semplice e unificato per caricare istanze pre-allenate. Questo significa che puoi caricare un "),t=p("code"),l=c("TFAutoModel"),i=c(" come caricheresti un "),r=p("code"),g=c("AutoTokenizer"),_=c(". L\u2019unica differenza \xE8 selezionare il "),v=p("code"),q=c("TFAutoModel"),I=c(" corretto per il compito di interesse. Dato che stai facendo classificazione di testi, o sequenze, carica "),F=p("code"),P=c("TFAutoModelForSequenceClassification"),S=c(":"),z=w(),y(C.$$.fragment),b=w(),y(T.$$.fragment),R=w(),G=p("p"),V=c("Ora puoi passare il tuo lotto di input pre-processati direttamente al modello passando le chiavi del dizionario al tensore:"),U=w(),y(ae.$$.fragment),Y=w(),J=p("p"),te=c("Il modello produrr\xE0 le attivazioni finali nell\u2019attributo "),K=p("code"),Z=c("logits"),de=c(". Applica la funzione softmax a "),se=p("code"),he=c("logits"),ne=c(" per ottenere le probabilit\xE0:"),le=w(),y(ie.$$.fragment)},l(L){e=m(L,"P",{});var B=d(e);n=f(B,"\u{1F917} Transformers fornisce un metodo semplice e unificato per caricare istanze pre-allenate. Questo significa che puoi caricare un "),t=m(B,"CODE",{});var re=d(t);l=f(re,"TFAutoModel"),re.forEach(s),i=f(B," come caricheresti un "),r=m(B,"CODE",{});var O=d(r);g=f(O,"AutoTokenizer"),O.forEach(s),_=f(B,". L\u2019unica differenza \xE8 selezionare il "),v=m(B,"CODE",{});var Q=d(v);q=f(Q,"TFAutoModel"),Q.forEach(s),I=f(B," corretto per il compito di interesse. Dato che stai facendo classificazione di testi, o sequenze, carica "),F=m(B,"CODE",{});var ce=d(F);P=f(ce,"TFAutoModelForSequenceClassification"),ce.forEach(s),S=f(B,":"),B.forEach(s),z=E(L),N(C.$$.fragment,L),b=E(L),N(T.$$.fragment,L),R=E(L),G=m(L,"P",{});var De=d(G);V=f(De,"Ora puoi passare il tuo lotto di input pre-processati direttamente al modello passando le chiavi del dizionario al tensore:"),De.forEach(s),U=E(L),N(ae.$$.fragment,L),Y=E(L),J=m(L,"P",{});var _e=d(J);te=f(_e,"Il modello produrr\xE0 le attivazioni finali nell\u2019attributo "),K=m(_e,"CODE",{});var ve=d(K);Z=f(ve,"logits"),ve.forEach(s),de=f(_e,". Applica la funzione softmax a "),se=m(_e,"CODE",{});var ue=d(se);he=f(ue,"logits"),ue.forEach(s),ne=f(_e," per ottenere le probabilit\xE0:"),_e.forEach(s),le=E(L),N(ie.$$.fragment,L)},m(L,B){h(L,e,B),o(e,n),o(e,t),o(t,l),o(e,i),o(e,r),o(r,g),o(e,_),o(e,v),o(v,q),o(e,I),o(e,F),o(F,P),o(e,S),h(L,z,B),M(C,L,B),h(L,b,B),M(T,L,B),h(L,R,B),h(L,G,B),o(G,V),h(L,U,B),M(ae,L,B),h(L,Y,B),h(L,J,B),o(J,te),o(J,K),o(K,Z),o(J,de),o(J,se),o(se,he),o(J,ne),h(L,le,B),M(ie,L,B),ge=!0},p(L,B){const re={};B&2&&(re.$$scope={dirty:B,ctx:L}),T.$set(re)},i(L){ge||(j(C.$$.fragment,L),j(T.$$.fragment,L),j(ae.$$.fragment,L),j(ie.$$.fragment,L),ge=!0)},o(L){A(C.$$.fragment,L),A(T.$$.fragment,L),A(ae.$$.fragment,L),A(ie.$$.fragment,L),ge=!1},d(L){L&&s(e),L&&s(z),D(C,L),L&&s(b),D(T,L),L&&s(R),L&&s(G),L&&s(U),D(ae,L),L&&s(Y),L&&s(J),L&&s(le),D(ie,L)}}}function bf(u){let e,n;return e=new $e({props:{$$slots:{default:[vf]},$$scope:{ctx:u}}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function kf(u){let e,n,t,l,i;return{c(){e=p("p"),n=c("Tutti i modelli di \u{1F917} Transformers (PyTorch e TensorFlow) restituiscono i tensori "),t=p("em"),l=c("prima"),i=c(` della funzione finale
di attivazione (come la softmax) perch\xE9 la funzione di attivazione finale viene spesso unita a quella di perdita.`)},l(r){e=m(r,"P",{});var g=d(e);n=f(g,"Tutti i modelli di \u{1F917} Transformers (PyTorch e TensorFlow) restituiscono i tensori "),t=m(g,"EM",{});var _=d(t);l=f(_,"prima"),_.forEach(s),i=f(g,` della funzione finale
di attivazione (come la softmax) perch\xE9 la funzione di attivazione finale viene spesso unita a quella di perdita.`),g.forEach(s)},m(r,g){h(r,e,g),o(e,n),o(e,t),o(t,l),o(e,i)},d(r){r&&s(e)}}}function zf(u){let e,n,t,l,i;return{c(){e=p("p"),n=c(`Gli output del modello di \u{1F917} Transformers sono delle dataclasses speciali in modo che i loro attributi vengano auto-completati all\u2019interno di un IDE.
Gli output del modello si comportano anche come una tupla o un dizionario (ad esempio, puoi indicizzare con un intero, una slice o una stringa) nel qual caso gli attributi che sono `),t=p("code"),l=c("None"),i=c(" vengono ignorati.")},l(r){e=m(r,"P",{});var g=d(e);n=f(g,`Gli output del modello di \u{1F917} Transformers sono delle dataclasses speciali in modo che i loro attributi vengano auto-completati all\u2019interno di un IDE.
Gli output del modello si comportano anche come una tupla o un dizionario (ad esempio, puoi indicizzare con un intero, una slice o una stringa) nel qual caso gli attributi che sono `),t=m(g,"CODE",{});var _=d(t);l=f(_,"None"),_.forEach(s),i=f(g," vengono ignorati."),g.forEach(s)},m(r,g){h(r,e,g),o(e,n),o(e,t),o(t,l),o(e,i)},d(r){r&&s(e)}}}function wf(u){let e,n,t,l,i,r,g,_,v,q,I,F,P,S,z,C;return g=new H({props:{code:`pt_save_directory = "./pt_save_pretrained"
tokenizer.save_pretrained(pt_save_directory)
pt_model.save_pretrained(pt_save_directory)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_save_directory = <span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.save_pretrained(pt_save_directory)`}}),z=new H({props:{code:'pt_model = AutoModelForSequenceClassification.from_pretrained("./pt_save_pretrained")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>)'}}),{c(){e=p("p"),n=c("Una volta completato il fine-tuning del tuo modello, puoi salvarlo con il suo tokenizer utilizzando "),t=p("code"),l=c("PreTrainedModel.save_pretrained()"),i=c(":"),r=w(),y(g.$$.fragment),_=w(),v=p("p"),q=c("Quando desideri utilizzare il tuo modello nuovamente, puoi ri-caricarlo con "),I=p("code"),F=c("PreTrainedModel.from_pretrained()"),P=c(":"),S=w(),y(z.$$.fragment)},l(b){e=m(b,"P",{});var T=d(e);n=f(T,"Una volta completato il fine-tuning del tuo modello, puoi salvarlo con il suo tokenizer utilizzando "),t=m(T,"CODE",{});var R=d(t);l=f(R,"PreTrainedModel.save_pretrained()"),R.forEach(s),i=f(T,":"),T.forEach(s),r=E(b),N(g.$$.fragment,b),_=E(b),v=m(b,"P",{});var G=d(v);q=f(G,"Quando desideri utilizzare il tuo modello nuovamente, puoi ri-caricarlo con "),I=m(G,"CODE",{});var V=d(I);F=f(V,"PreTrainedModel.from_pretrained()"),V.forEach(s),P=f(G,":"),G.forEach(s),S=E(b),N(z.$$.fragment,b)},m(b,T){h(b,e,T),o(e,n),o(e,t),o(t,l),o(e,i),h(b,r,T),M(g,b,T),h(b,_,T),h(b,v,T),o(v,q),o(v,I),o(I,F),o(v,P),h(b,S,T),M(z,b,T),C=!0},p:ee,i(b){C||(j(g.$$.fragment,b),j(z.$$.fragment,b),C=!0)},o(b){A(g.$$.fragment,b),A(z.$$.fragment,b),C=!1},d(b){b&&s(e),b&&s(r),D(g,b),b&&s(_),b&&s(v),b&&s(S),D(z,b)}}}function Ef(u){let e,n;return e=new $e({props:{$$slots:{default:[wf]},$$scope:{ctx:u}}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function jf(u){let e,n,t,l,i,r,g,_,v,q,I,F,P,S,z,C;return g=new H({props:{code:`tf_save_directory = "./tf_save_pretrained"
tokenizer.save_pretrained(tf_save_directory)
tf_model.save_pretrained(tf_save_directory)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_save_directory = <span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.save_pretrained(tf_save_directory)`}}),z=new H({props:{code:'tf_model = TFAutoModelForSequenceClassification.from_pretrained("./tf_save_pretrained")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>)'}}),{c(){e=p("p"),n=c("Una volta completato il fine-tuning del tuo modello, puoi salvarlo con il suo tokenizer utilizzando "),t=p("code"),l=c("TFPreTrainedModel.save_pretrained()"),i=c(":"),r=w(),y(g.$$.fragment),_=w(),v=p("p"),q=c("Quando desideri utilizzare il tuo modello nuovamente, puoi ri-caricarlo con "),I=p("code"),F=c("TFPreTrainedModel.from_pretrained()"),P=c(":"),S=w(),y(z.$$.fragment)},l(b){e=m(b,"P",{});var T=d(e);n=f(T,"Una volta completato il fine-tuning del tuo modello, puoi salvarlo con il suo tokenizer utilizzando "),t=m(T,"CODE",{});var R=d(t);l=f(R,"TFPreTrainedModel.save_pretrained()"),R.forEach(s),i=f(T,":"),T.forEach(s),r=E(b),N(g.$$.fragment,b),_=E(b),v=m(b,"P",{});var G=d(v);q=f(G,"Quando desideri utilizzare il tuo modello nuovamente, puoi ri-caricarlo con "),I=m(G,"CODE",{});var V=d(I);F=f(V,"TFPreTrainedModel.from_pretrained()"),V.forEach(s),P=f(G,":"),G.forEach(s),S=E(b),N(z.$$.fragment,b)},m(b,T){h(b,e,T),o(e,n),o(e,t),o(t,l),o(e,i),h(b,r,T),M(g,b,T),h(b,_,T),h(b,v,T),o(v,q),o(v,I),o(I,F),o(v,P),h(b,S,T),M(z,b,T),C=!0},p:ee,i(b){C||(j(g.$$.fragment,b),j(z.$$.fragment,b),C=!0)},o(b){A(g.$$.fragment,b),A(z.$$.fragment,b),C=!1},d(b){b&&s(e),b&&s(r),D(g,b),b&&s(_),b&&s(v),b&&s(S),D(z,b)}}}function Af(u){let e,n;return e=new $e({props:{$$slots:{default:[jf]},$$scope:{ctx:u}}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function Cf(u){let e,n;return e=new H({props:{code:`from transformers import AutoModel

tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=<span class="hljs-literal">True</span>)`}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p:ee,i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function qf(u){let e,n;return e=new $e({props:{$$slots:{default:[Cf]},$$scope:{ctx:u}}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function Tf(u){let e,n;return e=new H({props:{code:`from transformers import TFAutoModel

tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=<span class="hljs-literal">True</span>)`}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p:ee,i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function Pf(u){let e,n;return e=new $e({props:{$$slots:{default:[Tf]},$$scope:{ctx:u}}}),{c(){y(e.$$.fragment)},l(t){N(e.$$.fragment,t)},m(t,l){M(e,t,l),n=!0},p(t,l){const i={};l&2&&(i.$$scope={dirty:l,ctx:t}),e.$set(i)},i(t){n||(j(e.$$.fragment,t),n=!0)},o(t){A(e.$$.fragment,t),n=!1},d(t){D(e,t)}}}function Sf(u){let e,n,t,l,i,r,g,_,v,q,I,F,P,S,z,C,b,T,R,G,V,U,ae,Y,J,te,K,Z,de,se,he,ne,le,ie,ge,L,B,re,O,Q,ce,De,_e,ve,ue,Be,be,ea,kt,W,Pa,fs,ps,Sa,ms,ds,ya,_s,hs,Ma,gs,$s,Da,vs,bs,Na,ks,zs,Fa,ws,Es,Ia,js,Ol,zt,Oa,As,Cs,Ll,ke,La,qs,Ts,Ra,Ps,Ss,Ua,ys,Rl,wt,Ba,Ms,Ds,Ul,Ge,Ga,Ns,Fs,Qa,Is,Bl,Qe,Gl,Ne,He,Ha,Et,Os,Ja,Ls,Ql,Je,Rs,Va,Us,Bs,Hl,ta,Gs,Jl,Ve,Vl,We,Qs,Wa,Hs,Js,Wl,jt,Yl,ze,Vs,At,Ws,Ys,Ya,Ks,Zs,Kl,Ct,Zl,Ye,Xs,Ka,xs,en,Xl,qt,xl,we,tn,Za,an,ln,Tt,on,sn,eo,Pt,to,Ke,nn,Xa,rn,un,ao,St,lo,Ee,cn,yt,fn,pn,Mt,mn,dn,oo,Dt,so,Ze,_n,xa,hn,gn,no,Nt,io,aa,$n,ro,Ft,uo,Xe,vn,la,bn,kn,co,Fe,xe,el,It,zn,tl,wn,fo,fe,En,al,jn,An,Ot,Cn,qn,ll,Tn,Pn,Lt,Sn,yn,po,Rt,mo,et,_o,je,Mn,ol,Dn,Nn,sl,Fn,In,ho,Ut,go,Ae,On,oa,Ln,Rn,sa,Un,Bn,$o,Ie,tt,nl,Bt,Gn,il,Qn,vo,Gt,bo,X,Hn,rl,Jn,Vn,ul,Wn,Yn,cl,Kn,Zn,na,Xn,xn,fl,ei,ti,pl,ai,li,ko,Ce,oi,ml,si,ni,dl,ii,ri,zo,Oe,at,_l,Qt,ui,hl,ci,wo,qe,fi,gl,pi,mi,ia,di,_i,Eo,lt,hi,$l,gi,$i,jo,Ht,Ao,ot,vi,vl,bi,ki,Co,ra,zi,qo,Jt,To,ua,wi,Po,st,ca,fa,Ei,ji,Ai,pa,ma,Ci,qi,So,nt,Ti,bl,Pi,Si,yo,it,Mo,rt,yi,da,Mi,Di,Do,Le,ut,kl,Vt,Ni,zl,Fi,No,ct,Fo,ft,Io,x,Ii,Wt,wl,Oi,Li,Yt,El,Ri,Ui,jl,Bi,Gi,Al,Qi,Hi,Kt,Ji,Vi,_a,Wi,Yi,Oo,pt,Lo,Re,mt,Cl,Zt,Ki,ql,Zi,Ro,dt,Uo,Te,Xi,Tl,xi,er,Pl,tr,ar,Bo,_t,Go;return r=new ht({}),I=new xc({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/quicktour.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/tensorflow/quicktour.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/quicktour.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/tensorflow/quicktour.ipynb"}]}}),U=new Aa({props:{$$slots:{default:[ef]},$$scope:{ctx:u}}}),K=new ht({}),B=new Ju({props:{id:"tiZFewofSLM"}}),Qe=new Aa({props:{$$slots:{default:[tf]},$$scope:{ctx:u}}}),Et=new ht({}),Ve=new ja({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[sf],pytorch:[lf]},$$scope:{ctx:u}}}),jt=new H({props:{code:`from transformers import pipeline

classificatore = pipeline("sentiment-analysis", model="MilaNLProc/feel-it-italian-sentiment")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>classificatore = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>, model=<span class="hljs-string">&quot;MilaNLProc/feel-it-italian-sentiment&quot;</span>)`}}),Ct=new H({props:{code:'classificatore("Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.")',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classificatore(<span class="hljs-string">&quot;Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;positive&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9997</span>}]`}}),qt=new H({props:{code:`risultati = classificatore(
    ["Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.", "Speriamo te non la odierai."]
)
for risultato in risultati:
    print(f"etichetta: {risultato['label']}, con punteggio: {round(risultato['score'], 4)}")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>risultati = classificatore(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.&quot;</span>, <span class="hljs-string">&quot;Speriamo te non la odierai.&quot;</span>]
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> risultato <span class="hljs-keyword">in</span> risultati:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;etichetta: <span class="hljs-subst">{risultato[<span class="hljs-string">&#x27;label&#x27;</span>]}</span>, con punteggio: <span class="hljs-subst">{<span class="hljs-built_in">round</span>(risultato[<span class="hljs-string">&#x27;score&#x27;</span>], <span class="hljs-number">4</span>)}</span>&quot;</span>)
etichetta: positive, con punteggio: <span class="hljs-number">0.9998</span>
etichetta: negative, con punteggio: <span class="hljs-number">0.9998</span>`}}),Pt=new H({props:{code:"pip install datasets ",highlighted:"pip install datasets "}}),St=new H({props:{code:`import torch
from transformers import pipeline

riconoscitore_vocale = pipeline(
    "automatic-speech-recognition", model="radiogroup-crits/wav2vec2-xls-r-1b-italian-doc4lm-5gram"
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>riconoscitore_vocale = pipeline(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;automatic-speech-recognition&quot;</span>, model=<span class="hljs-string">&quot;radiogroup-crits/wav2vec2-xls-r-1b-italian-doc4lm-5gram&quot;</span>
<span class="hljs-meta">... </span>)`}}),Dt=new H({props:{code:`from datasets import load_dataset, Audio

dataset = load_dataset("PolyAI/minds14", name="it-IT", split="train")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, name=<span class="hljs-string">&quot;it-IT&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`}}),Nt=new H({props:{code:'dataset = dataset.cast_column("audio", Audio(sampling_rate=riconoscitore_vocale.feature_extractor.sampling_rate))',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=riconoscitore_vocale.feature_extractor.sampling_rate))'}}),Ft=new H({props:{code:`risultato = riconoscitore_vocale(dataset[:4]["audio"])
print([d["text"] for d in risultato])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>risultato = riconoscitore_vocale(dataset[:<span class="hljs-number">4</span>][<span class="hljs-string">&quot;audio&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>([d[<span class="hljs-string">&quot;text&quot;</span>] <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> risultato])
[<span class="hljs-string">&#x27;dovrei caricare dei soldi sul mio conto corrente&#x27;</span>, <span class="hljs-string">&#x27;buongiorno e senza vorrei depositare denaro sul mio conto corrente come devo fare per cortesia&#x27;</span>, <span class="hljs-string">&#x27;s\xEC salve vorrei depositare del denaro sul mio conto&#x27;</span>, <span class="hljs-string">&#x27;e buon pomeriggio vorrei depositare dei soldi sul mio conto bancario volleo sapere come posso fare se e posso farlo online ed un altro conto o andandoo tramite bancomut&#x27;</span>]`}}),It=new ht({}),Rt=new H({props:{code:'model_name = "nlptown/bert-base-multilingual-uncased-sentiment"',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>'}}),et=new ja({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[cf],pytorch:[rf]},$$scope:{ctx:u}}}),Ut=new H({props:{code:`classifier = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
classifier("Nous sommes tr\xE8s heureux de vous pr\xE9senter la biblioth\xE8que \u{1F917} Transformers.")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>, model=model, tokenizer=tokenizer)
<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;Nous sommes tr\xE8s heureux de vous pr\xE9senter la biblioth\xE8que \u{1F917} Transformers.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;5 stars&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.7273</span>}]`}}),Bt=new ht({}),Gt=new Ju({props:{id:"AhChOFRegn4"}}),Qt=new ht({}),Ht=new H({props:{code:`from transformers import AutoTokenizer

nome_del_modello = "nlptown/bert-base-multilingual-uncased-sentiment"
tokenizer = AutoTokenizer.from_pretrained(nome_del_modello)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>nome_del_modello = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(nome_del_modello)`}}),Jt=new H({props:{code:`encoding = tokenizer("Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.")
print(encoding)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>encoding = tokenizer(<span class="hljs-string">&quot;Siamo molto felici di mostrarti la libreria \u{1F917} Transformers.&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoding)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">56821</span>, <span class="hljs-number">10132</span>, <span class="hljs-number">14407</span>, <span class="hljs-number">13019</span>, <span class="hljs-number">13007</span>, <span class="hljs-number">10120</span>, <span class="hljs-number">47201</span>, <span class="hljs-number">10330</span>, <span class="hljs-number">10106</span>, <span class="hljs-number">91686</span>, <span class="hljs-number">100</span>, <span class="hljs-number">58263</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>],
<span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
<span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),it=new ja({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[df],pytorch:[pf]},$$scope:{ctx:u}}}),Vt=new ht({}),ct=new ja({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[bf],pytorch:[gf]},$$scope:{ctx:u}}}),ft=new Aa({props:{$$slots:{default:[kf]},$$scope:{ctx:u}}}),pt=new Aa({props:{$$slots:{default:[zf]},$$scope:{ctx:u}}}),Zt=new ht({}),dt=new ja({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Af],pytorch:[Ef]},$$scope:{ctx:u}}}),_t=new ja({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Pf],pytorch:[qf]},$$scope:{ctx:u}}}),{c(){e=p("meta"),n=w(),t=p("h1"),l=p("a"),i=p("span"),y(r.$$.fragment),g=w(),_=p("span"),v=c("Quick tour"),q=w(),y(I.$$.fragment),F=w(),P=p("p"),S=c("Entra in azione con \u{1F917} Transformers! Inizia utilizzando "),z=p("code"),C=c("pipeline()"),b=c(" per un\u2019inferenza veloce, carica un modello pre-allenato e un tokenizer con una "),T=p("a"),R=c("AutoClass"),G=c(" per risolvere i tuoi compiti legati a testo, immagini o audio."),V=w(),y(U.$$.fragment),ae=w(),Y=p("h2"),J=p("a"),te=p("span"),y(K.$$.fragment),Z=w(),de=p("span"),se=c("Pipeline"),he=w(),ne=p("p"),le=p("code"),ie=c("pipeline()"),ge=c(" \xE8 il modo pi\xF9 semplice per utilizzare un modello pre-allenato per un dato compito."),L=w(),y(B.$$.fragment),re=w(),O=p("p"),Q=c("La "),ce=p("code"),De=c("pipeline()"),_e=c(" supporta molti compiti comuni:"),ve=w(),ue=p("p"),Be=p("strong"),be=c("Testo"),ea=c(":"),kt=w(),W=p("ul"),Pa=p("li"),fs=c("Analisi del Sentimento (Sentiment Analysis, in inglese): classifica la polarit\xE0 di un testo dato."),ps=w(),Sa=p("li"),ms=c("Generazione del Testo (Text Generation, in inglese): genera del testo a partire da un dato input."),ds=w(),ya=p("li"),_s=c("Riconoscimento di Entit\xE0 (Name Entity Recognition o NER, in inglese): etichetta ogni parola con l\u2019entit\xE0 che questa rappresenta (persona, data, luogo, ecc.)."),hs=w(),Ma=p("li"),gs=c("Rispondere a Domande (Question answering, in inglese): estrae la risposta da un contesto, dato del contesto e una domanda."),$s=w(),Da=p("li"),vs=c("Riempimento di Maschere (Fill-mask, in inglese): riempie gli spazi mancanti in un testo che ha parole mascherate."),bs=w(),Na=p("li"),ks=c("Riassumere (Summarization, in inglese): genera una sintesi di una lunga sequenza di testo o di un documento."),zs=w(),Fa=p("li"),ws=c("Traduzione (Translation, in inglese): traduce un testo in un\u2019altra lingua."),Es=w(),Ia=p("li"),js=c("Estrazione di Caratteristiche (Feature Extraction, in inglese): crea un tensore che rappresenta un testo."),Ol=w(),zt=p("p"),Oa=p("strong"),As=c("Immagini"),Cs=c(":"),Ll=w(),ke=p("ul"),La=p("li"),qs=c("Classificazione di Immagini (Image Classification, in inglese): classifica un\u2019immagine."),Ts=w(),Ra=p("li"),Ps=c("Segmentazione di Immagini (Image Segmentation, in inglese): classifica ogni pixel di un\u2019immagine."),Ss=w(),Ua=p("li"),ys=c("Rilevazione di Oggetti (Object Detection, in inglese): rileva oggetti all\u2019interno di un\u2019immagine."),Rl=w(),wt=p("p"),Ba=p("strong"),Ms=c("Audio"),Ds=c(":"),Ul=w(),Ge=p("ul"),Ga=p("li"),Ns=c("Classificazione di Audio (Audio Classification, in inglese): assegna un\u2019etichetta ad un segmento di audio dato."),Fs=w(),Qa=p("li"),Is=c("Riconoscimento Vocale Automatico (Automatic Speech Recognition o ASR, in inglese): trascrive il contenuto di un audio dato in un testo."),Bl=w(),y(Qe.$$.fragment),Gl=w(),Ne=p("h3"),He=p("a"),Ha=p("span"),y(Et.$$.fragment),Os=w(),Ja=p("span"),Ls=c("Utilizzo della Pipeline"),Ql=w(),Je=p("p"),Rs=c("Nel seguente esempio, utilizzerai la "),Va=p("code"),Us=c("pipeline()"),Bs=c(" per l\u2019analisi del sentimento."),Hl=w(),ta=p("p"),Gs=c("Installa le seguenti dipendenze se non lo hai gi\xE0 fatto:"),Jl=w(),y(Ve.$$.fragment),Vl=w(),We=p("p"),Qs=c("Importa "),Wa=p("code"),Hs=c("pipeline()"),Js=c(" e specifica il compito che vuoi completare:"),Wl=w(),y(jt.$$.fragment),Yl=w(),ze=p("p"),Vs=c("La pipeline scarica e salva il "),At=p("a"),Ws=c("modello pre-allenato"),Ys=c(" e il tokenizer per l\u2019analisi del sentimento. Se non avessimo scelto un modello, la pipeline ne avrebbe scelto uno di default. Ora puoi utilizzare il "),Ya=p("code"),Ks=c("classifier"),Zs=c(" sul tuo testo obiettivo:"),Kl=w(),y(Ct.$$.fragment),Zl=w(),Ye=p("p"),Xs=c("Per pi\xF9 di una frase, passa una lista di frasi alla "),Ka=p("code"),xs=c("pipeline()"),en=c(" la quale restituir\xE0 una lista di dizionari:"),Xl=w(),y(qt.$$.fragment),xl=w(),we=p("p"),tn=c("La "),Za=p("code"),an=c("pipeline()"),ln=c(" pu\xF2 anche iterare su un dataset intero. Inizia installando la libreria "),Tt=p("a"),on=c("\u{1F917} Datasets"),sn=c(":"),eo=w(),y(Pt.$$.fragment),to=w(),Ke=p("p"),nn=c("Crea una "),Xa=p("code"),rn=c("pipeline()"),un=c(" con il compito che vuoi risolvere e con il modello che vuoi utilizzare."),ao=w(),y(St.$$.fragment),lo=w(),Ee=p("p"),cn=c("Poi, carica un dataset (vedi \u{1F917} Datasets "),yt=p("a"),fn=c("Quick Start"),pn=c(" per maggiori dettagli) sul quale vuoi iterare. Per esempio, carichiamo il dataset "),Mt=p("a"),mn=c("MInDS-14"),dn=c(":"),oo=w(),y(Dt.$$.fragment),so=w(),Ze=p("p"),_n=c("Dobbiamo assicurarci che la frequenza di campionamento del set di dati corrisponda alla frequenza di campionamento con cui \xE8 stato addestrato "),xa=p("code"),hn=c("radiogroup-crits/wav2vec2-xls-r-1b-italian-doc4lm-5gram"),gn=c("."),no=w(),y(Nt.$$.fragment),io=w(),aa=p("p"),$n=c(`I file audio vengono caricati automaticamente e ri-campionati quando chiamiamo la colonna \u201Caudio\u201D.
Estraiamo i vettori delle forme d\u2019onda grezze delle prime 4 osservazioni e passiamoli come lista alla pipeline:`),ro=w(),y(Ft.$$.fragment),uo=w(),Xe=p("p"),vn=c("Per un dataset pi\xF9 grande dove gli input sono di dimensione maggiore (come nel parlato/audio o nella visione), dovrai passare un generatore al posto di una lista che carica tutti gli input in memoria. Guarda la "),la=p("a"),bn=c("documentazione della pipeline"),kn=c(" per maggiori informazioni."),co=w(),Fe=p("h3"),xe=p("a"),el=p("span"),y(It.$$.fragment),zn=w(),tl=p("span"),wn=c("Utilizzare un altro modello e tokenizer nella pipeline"),fo=w(),fe=p("p"),En=c("La "),al=p("code"),jn=c("pipeline()"),An=c(" pu\xF2 ospitare qualsiasi modello del "),Ot=p("a"),Cn=c("Model Hub"),qn=c(", rendendo semplice l\u2019adattamento della "),ll=p("code"),Tn=c("pipeline()"),Pn=c(" per altri casi d\u2019uso. Per esempio, se si vuole un modello capace di trattare testo in francese, usa i tag presenti nel Model Hub in modo da filtrare per ottenere un modello appropriato. Il miglior risultato filtrato restituisce un modello multi-lingua "),Lt=p("a"),Sn=c("BERT model"),yn=c(" fine-tuned per l\u2019analisi del sentimento. Ottimo, utilizziamo questo modello!"),po=w(),y(Rt.$$.fragment),mo=w(),y(et.$$.fragment),_o=w(),je=p("p"),Mn=c("Poi puoi specificare il modello e il tokenizer nella "),ol=p("code"),Dn=c("pipeline()"),Nn=c(", e applicare il "),sl=p("code"),Fn=c("classifier"),In=c(" sul tuo testo obiettivo:"),ho=w(),y(Ut.$$.fragment),go=w(),Ae=p("p"),On=c("Se non riesci a trovare un modello per il tuo caso d\u2019uso, dovrai fare fine-tuning di un modello pre-allenato sui tuoi dati. Dai un\u2019occhiata al nostro tutorial "),oa=p("a"),Ln=c("fine-tuning tutorial"),Rn=c(" per imparare come. Infine, dopo che hai completato il fine-tuning del tuo modello pre-allenato, considera per favore di condividerlo (vedi il tutorial "),sa=p("a"),Un=c("qui"),Bn=c(") con la comunit\xE0 sul Model Hub per democratizzare l\u2019NLP! \u{1F917}"),$o=w(),Ie=p("h2"),tt=p("a"),nl=p("span"),y(Bt.$$.fragment),Gn=w(),il=p("span"),Qn=c("AutoClass"),vo=w(),y(Gt.$$.fragment),bo=w(),X=p("p"),Hn=c("Al suo interno, le classi "),rl=p("code"),Jn=c("AutoModelForSequenceClassification"),Vn=c(" e "),ul=p("code"),Wn=c("AutoTokenizer"),Yn=c(" lavorano assieme per dare potere alla "),cl=p("code"),Kn=c("pipeline()"),Zn=c(". Una "),na=p("a"),Xn=c("AutoClass"),xn=c(" \xE8 una scorciatoia che automaticamente recupera l\u2019architettura di un modello pre-allenato a partire dal suo nome o path. Hai solo bisogno di selezionare la "),fl=p("code"),ei=c("AutoClass"),ti=c(" appropriata per il tuo compito e il suo tokenizer associato con "),pl=p("code"),ai=c("AutoTokenizer"),li=c("."),ko=w(),Ce=p("p"),oi=c("Ritorniamo al nostro esempio e vediamo come puoi utilizzare la "),ml=p("code"),si=c("AutoClass"),ni=c(" per replicare i risultati della "),dl=p("code"),ii=c("pipeline()"),ri=c("."),zo=w(),Oe=p("h3"),at=p("a"),_l=p("span"),y(Qt.$$.fragment),ui=w(),hl=p("span"),ci=c("AutoTokenizer"),wo=w(),qe=p("p"),fi=c("Un tokenizer \xE8 responsabile dell\u2019elaborazione del testo in modo da trasformarlo in un formato comprensibile dal modello. Per prima cosa, il tokenizer divider\xE0 il testo in parole chiamate "),gl=p("em"),pi=c("token"),mi=c(". Ci sono diverse regole che governano il processo di tokenizzazione, tra cui come dividere una parola e a quale livello (impara di pi\xF9 sulla tokenizzazione "),ia=p("a"),di=c("qui"),_i=c("). La cosa pi\xF9 importante da ricordare comunque \xE8 che hai bisogno di inizializzare il tokenizer con lo stesso nome del modello in modo da assicurarti che stai utilizzando le stesse regole di tokenizzazione con cui il modello \xE8 stato pre-allenato."),Eo=w(),lt=p("p"),hi=c("Carica un tokenizer con "),$l=p("code"),gi=c("AutoTokenizer"),$i=c(":"),jo=w(),y(Ht.$$.fragment),Ao=w(),ot=p("p"),vi=c("Dopodich\xE9, il tokenizer converte i token in numeri in modo da costruire un tensore come input del modello. Questo \xE8 conosciuto come il "),vl=p("em"),bi=c("vocabolario"),ki=c(" del modello."),Co=w(),ra=p("p"),zi=c("Passa il tuo testo al tokenizer:"),qo=w(),y(Jt.$$.fragment),To=w(),ua=p("p"),wi=c("Il tokenizer restituir\xE0 un dizionario contenente:"),Po=w(),st=p("ul"),ca=p("li"),fa=p("a"),Ei=c("input_ids"),ji=c(": rappresentazioni numeriche dei tuoi token."),Ai=w(),pa=p("li"),ma=p("a"),Ci=c("attention_mask"),qi=c(": indica quali token devono essere presi in considerazione."),So=w(),nt=p("p"),Ti=c("Come con la "),bl=p("code"),Pi=c("pipeline()"),Si=c(", il tokenizer accetter\xE0 una lista di input. In pi\xF9, il tokenizer pu\xF2 anche completare (pad, in inglese) e troncare il testo in modo da restituire un lotto (batch, in inglese) di lunghezza uniforme:"),yo=w(),y(it.$$.fragment),Mo=w(),rt=p("p"),yi=c("Leggi il tutorial sul "),da=p("a"),Mi=c("preproccesing"),Di=c(" per maggiori dettagli sulla tokenizzazione."),Do=w(),Le=p("h3"),ut=p("a"),kl=p("span"),y(Vt.$$.fragment),Ni=w(),zl=p("span"),Fi=c("AutoModel"),No=w(),y(ct.$$.fragment),Fo=w(),y(ft.$$.fragment),Io=w(),x=p("p"),Ii=c("I modelli sono "),Wt=p("a"),wl=p("code"),Oi=c("torch.nn.Module"),Li=c(" o "),Yt=p("a"),El=p("code"),Ri=c("tf.keras.Model"),Ui=c(" standard cos\xEC puoi utilizzarli all\u2019interno del tuo training loop usuale. Tuttavia, per rendere le cose pi\xF9 semplici, \u{1F917} Transformers fornisce una classe "),jl=p("code"),Bi=c("Trainer"),Gi=c(" per PyTorch che aggiunge delle funzionalit\xE0 per l\u2019allenamento distribuito, precisione mista, e altro ancora. Per TensorFlow, puoi utilizzare il metodo "),Al=p("code"),Qi=c("fit"),Hi=c(" di "),Kt=p("a"),Ji=c("Keras"),Vi=c(". Fai riferimento al "),_a=p("a"),Wi=c("tutorial per il training"),Yi=c(" per maggiori dettagli."),Oo=w(),y(pt.$$.fragment),Lo=w(),Re=p("h3"),mt=p("a"),Cl=p("span"),y(Zt.$$.fragment),Ki=w(),ql=p("span"),Zi=c("Salva un modello"),Ro=w(),y(dt.$$.fragment),Uo=w(),Te=p("p"),Xi=c("Una caratteristica particolarmente interessante di \u{1F917} Transformers \xE8 la sua abilit\xE0 di salvare un modello e ri-caricarlo sia come modello di PyTorch che di TensorFlow. I parametri "),Tl=p("code"),xi=c("from_pt"),er=c(" o "),Pl=p("code"),tr=c("from_tf"),ar=c(" possono convertire un modello da un framework all\u2019altro:"),Bo=w(),y(_t.$$.fragment),this.h()},l(a){const $=hc('[data-svelte="svelte-1phssyn"]',document.head);e=m($,"META",{name:!0,content:!0}),$.forEach(s),n=E(a),t=m(a,"H1",{class:!0});var Xt=d(t);l=m(Xt,"A",{id:!0,class:!0,href:!0});var Sl=d(l);i=m(Sl,"SPAN",{});var yl=d(i);N(r.$$.fragment,yl),yl.forEach(s),Sl.forEach(s),g=E(Xt),_=m(Xt,"SPAN",{});var Ml=d(_);v=f(Ml,"Quick tour"),Ml.forEach(s),Xt.forEach(s),q=E(a),N(I.$$.fragment,a),F=E(a),P=m(a,"P",{});var Ue=d(P);S=f(Ue,"Entra in azione con \u{1F917} Transformers! Inizia utilizzando "),z=m(Ue,"CODE",{});var Dl=d(z);C=f(Dl,"pipeline()"),Dl.forEach(s),b=f(Ue," per un\u2019inferenza veloce, carica un modello pre-allenato e un tokenizer con una "),T=m(Ue,"A",{href:!0});var Nl=d(T);R=f(Nl,"AutoClass"),Nl.forEach(s),G=f(Ue," per risolvere i tuoi compiti legati a testo, immagini o audio."),Ue.forEach(s),V=E(a),N(U.$$.fragment,a),ae=E(a),Y=m(a,"H2",{class:!0});var xt=d(Y);J=m(xt,"A",{id:!0,class:!0,href:!0});var Fl=d(J);te=m(Fl,"SPAN",{});var Il=d(te);N(K.$$.fragment,Il),Il.forEach(s),Fl.forEach(s),Z=E(xt),de=m(xt,"SPAN",{});var fr=d(de);se=f(fr,"Pipeline"),fr.forEach(s),xt.forEach(s),he=E(a),ne=m(a,"P",{});var lr=d(ne);le=m(lr,"CODE",{});var pr=d(le);ie=f(pr,"pipeline()"),pr.forEach(s),ge=f(lr," \xE8 il modo pi\xF9 semplice per utilizzare un modello pre-allenato per un dato compito."),lr.forEach(s),L=E(a),N(B.$$.fragment,a),re=E(a),O=m(a,"P",{});var Qo=d(O);Q=f(Qo,"La "),ce=m(Qo,"CODE",{});var mr=d(ce);De=f(mr,"pipeline()"),mr.forEach(s),_e=f(Qo," supporta molti compiti comuni:"),Qo.forEach(s),ve=E(a),ue=m(a,"P",{});var or=d(ue);Be=m(or,"STRONG",{});var dr=d(Be);be=f(dr,"Testo"),dr.forEach(s),ea=f(or,":"),or.forEach(s),kt=E(a),W=m(a,"UL",{});var oe=d(W);Pa=m(oe,"LI",{});var _r=d(Pa);fs=f(_r,"Analisi del Sentimento (Sentiment Analysis, in inglese): classifica la polarit\xE0 di un testo dato."),_r.forEach(s),ps=E(oe),Sa=m(oe,"LI",{});var hr=d(Sa);ms=f(hr,"Generazione del Testo (Text Generation, in inglese): genera del testo a partire da un dato input."),hr.forEach(s),ds=E(oe),ya=m(oe,"LI",{});var gr=d(ya);_s=f(gr,"Riconoscimento di Entit\xE0 (Name Entity Recognition o NER, in inglese): etichetta ogni parola con l\u2019entit\xE0 che questa rappresenta (persona, data, luogo, ecc.)."),gr.forEach(s),hs=E(oe),Ma=m(oe,"LI",{});var $r=d(Ma);gs=f($r,"Rispondere a Domande (Question answering, in inglese): estrae la risposta da un contesto, dato del contesto e una domanda."),$r.forEach(s),$s=E(oe),Da=m(oe,"LI",{});var vr=d(Da);vs=f(vr,"Riempimento di Maschere (Fill-mask, in inglese): riempie gli spazi mancanti in un testo che ha parole mascherate."),vr.forEach(s),bs=E(oe),Na=m(oe,"LI",{});var br=d(Na);ks=f(br,"Riassumere (Summarization, in inglese): genera una sintesi di una lunga sequenza di testo o di un documento."),br.forEach(s),zs=E(oe),Fa=m(oe,"LI",{});var kr=d(Fa);ws=f(kr,"Traduzione (Translation, in inglese): traduce un testo in un\u2019altra lingua."),kr.forEach(s),Es=E(oe),Ia=m(oe,"LI",{});var zr=d(Ia);js=f(zr,"Estrazione di Caratteristiche (Feature Extraction, in inglese): crea un tensore che rappresenta un testo."),zr.forEach(s),oe.forEach(s),Ol=E(a),zt=m(a,"P",{});var sr=d(zt);Oa=m(sr,"STRONG",{});var wr=d(Oa);As=f(wr,"Immagini"),wr.forEach(s),Cs=f(sr,":"),sr.forEach(s),Ll=E(a),ke=m(a,"UL",{});var ha=d(ke);La=m(ha,"LI",{});var Er=d(La);qs=f(Er,"Classificazione di Immagini (Image Classification, in inglese): classifica un\u2019immagine."),Er.forEach(s),Ts=E(ha),Ra=m(ha,"LI",{});var jr=d(Ra);Ps=f(jr,"Segmentazione di Immagini (Image Segmentation, in inglese): classifica ogni pixel di un\u2019immagine."),jr.forEach(s),Ss=E(ha),Ua=m(ha,"LI",{});var Ar=d(Ua);ys=f(Ar,"Rilevazione di Oggetti (Object Detection, in inglese): rileva oggetti all\u2019interno di un\u2019immagine."),Ar.forEach(s),ha.forEach(s),Rl=E(a),wt=m(a,"P",{});var nr=d(wt);Ba=m(nr,"STRONG",{});var Cr=d(Ba);Ms=f(Cr,"Audio"),Cr.forEach(s),Ds=f(nr,":"),nr.forEach(s),Ul=E(a),Ge=m(a,"UL",{});var Ho=d(Ge);Ga=m(Ho,"LI",{});var qr=d(Ga);Ns=f(qr,"Classificazione di Audio (Audio Classification, in inglese): assegna un\u2019etichetta ad un segmento di audio dato."),qr.forEach(s),Fs=E(Ho),Qa=m(Ho,"LI",{});var Tr=d(Qa);Is=f(Tr,"Riconoscimento Vocale Automatico (Automatic Speech Recognition o ASR, in inglese): trascrive il contenuto di un audio dato in un testo."),Tr.forEach(s),Ho.forEach(s),Bl=E(a),N(Qe.$$.fragment,a),Gl=E(a),Ne=m(a,"H3",{class:!0});var Jo=d(Ne);He=m(Jo,"A",{id:!0,class:!0,href:!0});var Pr=d(He);Ha=m(Pr,"SPAN",{});var Sr=d(Ha);N(Et.$$.fragment,Sr),Sr.forEach(s),Pr.forEach(s),Os=E(Jo),Ja=m(Jo,"SPAN",{});var yr=d(Ja);Ls=f(yr,"Utilizzo della Pipeline"),yr.forEach(s),Jo.forEach(s),Ql=E(a),Je=m(a,"P",{});var Vo=d(Je);Rs=f(Vo,"Nel seguente esempio, utilizzerai la "),Va=m(Vo,"CODE",{});var Mr=d(Va);Us=f(Mr,"pipeline()"),Mr.forEach(s),Bs=f(Vo," per l\u2019analisi del sentimento."),Vo.forEach(s),Hl=E(a),ta=m(a,"P",{});var Dr=d(ta);Gs=f(Dr,"Installa le seguenti dipendenze se non lo hai gi\xE0 fatto:"),Dr.forEach(s),Jl=E(a),N(Ve.$$.fragment,a),Vl=E(a),We=m(a,"P",{});var Wo=d(We);Qs=f(Wo,"Importa "),Wa=m(Wo,"CODE",{});var Nr=d(Wa);Hs=f(Nr,"pipeline()"),Nr.forEach(s),Js=f(Wo," e specifica il compito che vuoi completare:"),Wo.forEach(s),Wl=E(a),N(jt.$$.fragment,a),Yl=E(a),ze=m(a,"P",{});var ga=d(ze);Vs=f(ga,"La pipeline scarica e salva il "),At=m(ga,"A",{href:!0,rel:!0});var Fr=d(At);Ws=f(Fr,"modello pre-allenato"),Fr.forEach(s),Ys=f(ga," e il tokenizer per l\u2019analisi del sentimento. Se non avessimo scelto un modello, la pipeline ne avrebbe scelto uno di default. Ora puoi utilizzare il "),Ya=m(ga,"CODE",{});var Ir=d(Ya);Ks=f(Ir,"classifier"),Ir.forEach(s),Zs=f(ga," sul tuo testo obiettivo:"),ga.forEach(s),Kl=E(a),N(Ct.$$.fragment,a),Zl=E(a),Ye=m(a,"P",{});var Yo=d(Ye);Xs=f(Yo,"Per pi\xF9 di una frase, passa una lista di frasi alla "),Ka=m(Yo,"CODE",{});var Or=d(Ka);xs=f(Or,"pipeline()"),Or.forEach(s),en=f(Yo," la quale restituir\xE0 una lista di dizionari:"),Yo.forEach(s),Xl=E(a),N(qt.$$.fragment,a),xl=E(a),we=m(a,"P",{});var $a=d(we);tn=f($a,"La "),Za=m($a,"CODE",{});var Lr=d(Za);an=f(Lr,"pipeline()"),Lr.forEach(s),ln=f($a," pu\xF2 anche iterare su un dataset intero. Inizia installando la libreria "),Tt=m($a,"A",{href:!0,rel:!0});var Rr=d(Tt);on=f(Rr,"\u{1F917} Datasets"),Rr.forEach(s),sn=f($a,":"),$a.forEach(s),eo=E(a),N(Pt.$$.fragment,a),to=E(a),Ke=m(a,"P",{});var Ko=d(Ke);nn=f(Ko,"Crea una "),Xa=m(Ko,"CODE",{});var Ur=d(Xa);rn=f(Ur,"pipeline()"),Ur.forEach(s),un=f(Ko," con il compito che vuoi risolvere e con il modello che vuoi utilizzare."),Ko.forEach(s),ao=E(a),N(St.$$.fragment,a),lo=E(a),Ee=m(a,"P",{});var va=d(Ee);cn=f(va,"Poi, carica un dataset (vedi \u{1F917} Datasets "),yt=m(va,"A",{href:!0,rel:!0});var Br=d(yt);fn=f(Br,"Quick Start"),Br.forEach(s),pn=f(va," per maggiori dettagli) sul quale vuoi iterare. Per esempio, carichiamo il dataset "),Mt=m(va,"A",{href:!0,rel:!0});var Gr=d(Mt);mn=f(Gr,"MInDS-14"),Gr.forEach(s),dn=f(va,":"),va.forEach(s),oo=E(a),N(Dt.$$.fragment,a),so=E(a),Ze=m(a,"P",{});var Zo=d(Ze);_n=f(Zo,"Dobbiamo assicurarci che la frequenza di campionamento del set di dati corrisponda alla frequenza di campionamento con cui \xE8 stato addestrato "),xa=m(Zo,"CODE",{});var Qr=d(xa);hn=f(Qr,"radiogroup-crits/wav2vec2-xls-r-1b-italian-doc4lm-5gram"),Qr.forEach(s),gn=f(Zo,"."),Zo.forEach(s),no=E(a),N(Nt.$$.fragment,a),io=E(a),aa=m(a,"P",{});var Hr=d(aa);$n=f(Hr,`I file audio vengono caricati automaticamente e ri-campionati quando chiamiamo la colonna \u201Caudio\u201D.
Estraiamo i vettori delle forme d\u2019onda grezze delle prime 4 osservazioni e passiamoli come lista alla pipeline:`),Hr.forEach(s),ro=E(a),N(Ft.$$.fragment,a),uo=E(a),Xe=m(a,"P",{});var Xo=d(Xe);vn=f(Xo,"Per un dataset pi\xF9 grande dove gli input sono di dimensione maggiore (come nel parlato/audio o nella visione), dovrai passare un generatore al posto di una lista che carica tutti gli input in memoria. Guarda la "),la=m(Xo,"A",{href:!0});var Jr=d(la);bn=f(Jr,"documentazione della pipeline"),Jr.forEach(s),kn=f(Xo," per maggiori informazioni."),Xo.forEach(s),co=E(a),Fe=m(a,"H3",{class:!0});var xo=d(Fe);xe=m(xo,"A",{id:!0,class:!0,href:!0});var Vr=d(xe);el=m(Vr,"SPAN",{});var Wr=d(el);N(It.$$.fragment,Wr),Wr.forEach(s),Vr.forEach(s),zn=E(xo),tl=m(xo,"SPAN",{});var Yr=d(tl);wn=f(Yr,"Utilizzare un altro modello e tokenizer nella pipeline"),Yr.forEach(s),xo.forEach(s),fo=E(a),fe=m(a,"P",{});var Pe=d(fe);En=f(Pe,"La "),al=m(Pe,"CODE",{});var Kr=d(al);jn=f(Kr,"pipeline()"),Kr.forEach(s),An=f(Pe," pu\xF2 ospitare qualsiasi modello del "),Ot=m(Pe,"A",{href:!0,rel:!0});var Zr=d(Ot);Cn=f(Zr,"Model Hub"),Zr.forEach(s),qn=f(Pe,", rendendo semplice l\u2019adattamento della "),ll=m(Pe,"CODE",{});var Xr=d(ll);Tn=f(Xr,"pipeline()"),Xr.forEach(s),Pn=f(Pe," per altri casi d\u2019uso. Per esempio, se si vuole un modello capace di trattare testo in francese, usa i tag presenti nel Model Hub in modo da filtrare per ottenere un modello appropriato. Il miglior risultato filtrato restituisce un modello multi-lingua "),Lt=m(Pe,"A",{href:!0,rel:!0});var xr=d(Lt);Sn=f(xr,"BERT model"),xr.forEach(s),yn=f(Pe," fine-tuned per l\u2019analisi del sentimento. Ottimo, utilizziamo questo modello!"),Pe.forEach(s),po=E(a),N(Rt.$$.fragment,a),mo=E(a),N(et.$$.fragment,a),_o=E(a),je=m(a,"P",{});var ba=d(je);Mn=f(ba,"Poi puoi specificare il modello e il tokenizer nella "),ol=m(ba,"CODE",{});var eu=d(ol);Dn=f(eu,"pipeline()"),eu.forEach(s),Nn=f(ba,", e applicare il "),sl=m(ba,"CODE",{});var tu=d(sl);Fn=f(tu,"classifier"),tu.forEach(s),In=f(ba," sul tuo testo obiettivo:"),ba.forEach(s),ho=E(a),N(Ut.$$.fragment,a),go=E(a),Ae=m(a,"P",{});var ka=d(Ae);On=f(ka,"Se non riesci a trovare un modello per il tuo caso d\u2019uso, dovrai fare fine-tuning di un modello pre-allenato sui tuoi dati. Dai un\u2019occhiata al nostro tutorial "),oa=m(ka,"A",{href:!0});var au=d(oa);Ln=f(au,"fine-tuning tutorial"),au.forEach(s),Rn=f(ka," per imparare come. Infine, dopo che hai completato il fine-tuning del tuo modello pre-allenato, considera per favore di condividerlo (vedi il tutorial "),sa=m(ka,"A",{href:!0});var lu=d(sa);Un=f(lu,"qui"),lu.forEach(s),Bn=f(ka,") con la comunit\xE0 sul Model Hub per democratizzare l\u2019NLP! \u{1F917}"),ka.forEach(s),$o=E(a),Ie=m(a,"H2",{class:!0});var es=d(Ie);tt=m(es,"A",{id:!0,class:!0,href:!0});var ou=d(tt);nl=m(ou,"SPAN",{});var su=d(nl);N(Bt.$$.fragment,su),su.forEach(s),ou.forEach(s),Gn=E(es),il=m(es,"SPAN",{});var nu=d(il);Qn=f(nu,"AutoClass"),nu.forEach(s),es.forEach(s),vo=E(a),N(Gt.$$.fragment,a),bo=E(a),X=m(a,"P",{});var pe=d(X);Hn=f(pe,"Al suo interno, le classi "),rl=m(pe,"CODE",{});var iu=d(rl);Jn=f(iu,"AutoModelForSequenceClassification"),iu.forEach(s),Vn=f(pe," e "),ul=m(pe,"CODE",{});var ru=d(ul);Wn=f(ru,"AutoTokenizer"),ru.forEach(s),Yn=f(pe," lavorano assieme per dare potere alla "),cl=m(pe,"CODE",{});var uu=d(cl);Kn=f(uu,"pipeline()"),uu.forEach(s),Zn=f(pe,". Una "),na=m(pe,"A",{href:!0});var cu=d(na);Xn=f(cu,"AutoClass"),cu.forEach(s),xn=f(pe," \xE8 una scorciatoia che automaticamente recupera l\u2019architettura di un modello pre-allenato a partire dal suo nome o path. Hai solo bisogno di selezionare la "),fl=m(pe,"CODE",{});var fu=d(fl);ei=f(fu,"AutoClass"),fu.forEach(s),ti=f(pe," appropriata per il tuo compito e il suo tokenizer associato con "),pl=m(pe,"CODE",{});var pu=d(pl);ai=f(pu,"AutoTokenizer"),pu.forEach(s),li=f(pe,"."),pe.forEach(s),ko=E(a),Ce=m(a,"P",{});var za=d(Ce);oi=f(za,"Ritorniamo al nostro esempio e vediamo come puoi utilizzare la "),ml=m(za,"CODE",{});var mu=d(ml);si=f(mu,"AutoClass"),mu.forEach(s),ni=f(za," per replicare i risultati della "),dl=m(za,"CODE",{});var du=d(dl);ii=f(du,"pipeline()"),du.forEach(s),ri=f(za,"."),za.forEach(s),zo=E(a),Oe=m(a,"H3",{class:!0});var ts=d(Oe);at=m(ts,"A",{id:!0,class:!0,href:!0});var _u=d(at);_l=m(_u,"SPAN",{});var hu=d(_l);N(Qt.$$.fragment,hu),hu.forEach(s),_u.forEach(s),ui=E(ts),hl=m(ts,"SPAN",{});var gu=d(hl);ci=f(gu,"AutoTokenizer"),gu.forEach(s),ts.forEach(s),wo=E(a),qe=m(a,"P",{});var wa=d(qe);fi=f(wa,"Un tokenizer \xE8 responsabile dell\u2019elaborazione del testo in modo da trasformarlo in un formato comprensibile dal modello. Per prima cosa, il tokenizer divider\xE0 il testo in parole chiamate "),gl=m(wa,"EM",{});var $u=d(gl);pi=f($u,"token"),$u.forEach(s),mi=f(wa,". Ci sono diverse regole che governano il processo di tokenizzazione, tra cui come dividere una parola e a quale livello (impara di pi\xF9 sulla tokenizzazione "),ia=m(wa,"A",{href:!0});var vu=d(ia);di=f(vu,"qui"),vu.forEach(s),_i=f(wa,"). La cosa pi\xF9 importante da ricordare comunque \xE8 che hai bisogno di inizializzare il tokenizer con lo stesso nome del modello in modo da assicurarti che stai utilizzando le stesse regole di tokenizzazione con cui il modello \xE8 stato pre-allenato."),wa.forEach(s),Eo=E(a),lt=m(a,"P",{});var as=d(lt);hi=f(as,"Carica un tokenizer con "),$l=m(as,"CODE",{});var bu=d($l);gi=f(bu,"AutoTokenizer"),bu.forEach(s),$i=f(as,":"),as.forEach(s),jo=E(a),N(Ht.$$.fragment,a),Ao=E(a),ot=m(a,"P",{});var ls=d(ot);vi=f(ls,"Dopodich\xE9, il tokenizer converte i token in numeri in modo da costruire un tensore come input del modello. Questo \xE8 conosciuto come il "),vl=m(ls,"EM",{});var ku=d(vl);bi=f(ku,"vocabolario"),ku.forEach(s),ki=f(ls," del modello."),ls.forEach(s),Co=E(a),ra=m(a,"P",{});var zu=d(ra);zi=f(zu,"Passa il tuo testo al tokenizer:"),zu.forEach(s),qo=E(a),N(Jt.$$.fragment,a),To=E(a),ua=m(a,"P",{});var wu=d(ua);wi=f(wu,"Il tokenizer restituir\xE0 un dizionario contenente:"),wu.forEach(s),Po=E(a),st=m(a,"UL",{});var os=d(st);ca=m(os,"LI",{});var ir=d(ca);fa=m(ir,"A",{href:!0});var Eu=d(fa);Ei=f(Eu,"input_ids"),Eu.forEach(s),ji=f(ir,": rappresentazioni numeriche dei tuoi token."),ir.forEach(s),Ai=E(os),pa=m(os,"LI",{});var rr=d(pa);ma=m(rr,"A",{href:!0});var ju=d(ma);Ci=f(ju,"attention_mask"),ju.forEach(s),qi=f(rr,": indica quali token devono essere presi in considerazione."),rr.forEach(s),os.forEach(s),So=E(a),nt=m(a,"P",{});var ss=d(nt);Ti=f(ss,"Come con la "),bl=m(ss,"CODE",{});var Au=d(bl);Pi=f(Au,"pipeline()"),Au.forEach(s),Si=f(ss,", il tokenizer accetter\xE0 una lista di input. In pi\xF9, il tokenizer pu\xF2 anche completare (pad, in inglese) e troncare il testo in modo da restituire un lotto (batch, in inglese) di lunghezza uniforme:"),ss.forEach(s),yo=E(a),N(it.$$.fragment,a),Mo=E(a),rt=m(a,"P",{});var ns=d(rt);yi=f(ns,"Leggi il tutorial sul "),da=m(ns,"A",{href:!0});var Cu=d(da);Mi=f(Cu,"preproccesing"),Cu.forEach(s),Di=f(ns," per maggiori dettagli sulla tokenizzazione."),ns.forEach(s),Do=E(a),Le=m(a,"H3",{class:!0});var is=d(Le);ut=m(is,"A",{id:!0,class:!0,href:!0});var qu=d(ut);kl=m(qu,"SPAN",{});var Tu=d(kl);N(Vt.$$.fragment,Tu),Tu.forEach(s),qu.forEach(s),Ni=E(is),zl=m(is,"SPAN",{});var Pu=d(zl);Fi=f(Pu,"AutoModel"),Pu.forEach(s),is.forEach(s),No=E(a),N(ct.$$.fragment,a),Fo=E(a),N(ft.$$.fragment,a),Io=E(a),x=m(a,"P",{});var me=d(x);Ii=f(me,"I modelli sono "),Wt=m(me,"A",{href:!0,rel:!0});var Su=d(Wt);wl=m(Su,"CODE",{});var yu=d(wl);Oi=f(yu,"torch.nn.Module"),yu.forEach(s),Su.forEach(s),Li=f(me," o "),Yt=m(me,"A",{href:!0,rel:!0});var Mu=d(Yt);El=m(Mu,"CODE",{});var Du=d(El);Ri=f(Du,"tf.keras.Model"),Du.forEach(s),Mu.forEach(s),Ui=f(me," standard cos\xEC puoi utilizzarli all\u2019interno del tuo training loop usuale. Tuttavia, per rendere le cose pi\xF9 semplici, \u{1F917} Transformers fornisce una classe "),jl=m(me,"CODE",{});var Nu=d(jl);Bi=f(Nu,"Trainer"),Nu.forEach(s),Gi=f(me," per PyTorch che aggiunge delle funzionalit\xE0 per l\u2019allenamento distribuito, precisione mista, e altro ancora. Per TensorFlow, puoi utilizzare il metodo "),Al=m(me,"CODE",{});var Fu=d(Al);Qi=f(Fu,"fit"),Fu.forEach(s),Hi=f(me," di "),Kt=m(me,"A",{href:!0,rel:!0});var Iu=d(Kt);Ji=f(Iu,"Keras"),Iu.forEach(s),Vi=f(me,". Fai riferimento al "),_a=m(me,"A",{href:!0});var Ou=d(_a);Wi=f(Ou,"tutorial per il training"),Ou.forEach(s),Yi=f(me," per maggiori dettagli."),me.forEach(s),Oo=E(a),N(pt.$$.fragment,a),Lo=E(a),Re=m(a,"H3",{class:!0});var rs=d(Re);mt=m(rs,"A",{id:!0,class:!0,href:!0});var Lu=d(mt);Cl=m(Lu,"SPAN",{});var Ru=d(Cl);N(Zt.$$.fragment,Ru),Ru.forEach(s),Lu.forEach(s),Ki=E(rs),ql=m(rs,"SPAN",{});var Uu=d(ql);Zi=f(Uu,"Salva un modello"),Uu.forEach(s),rs.forEach(s),Ro=E(a),N(dt.$$.fragment,a),Uo=E(a),Te=m(a,"P",{});var Ea=d(Te);Xi=f(Ea,"Una caratteristica particolarmente interessante di \u{1F917} Transformers \xE8 la sua abilit\xE0 di salvare un modello e ri-caricarlo sia come modello di PyTorch che di TensorFlow. I parametri "),Tl=m(Ea,"CODE",{});var Bu=d(Tl);xi=f(Bu,"from_pt"),Bu.forEach(s),er=f(Ea," o "),Pl=m(Ea,"CODE",{});var Gu=d(Pl);tr=f(Gu,"from_tf"),Gu.forEach(s),ar=f(Ea," possono convertire un modello da un framework all\u2019altro:"),Ea.forEach(s),Bo=E(a),N(_t.$$.fragment,a),this.h()},h(){k(e,"name","hf:doc:metadata"),k(e,"content",JSON.stringify(yf)),k(l,"id","quick-tour"),k(l,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),k(l,"href","#quick-tour"),k(t,"class","relative group"),k(T,"href","./model_doc/auto"),k(J,"id","pipeline"),k(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),k(J,"href","#pipeline"),k(Y,"class","relative group"),k(He,"id","utilizzo-della-pipeline"),k(He,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),k(He,"href","#utilizzo-della-pipeline"),k(Ne,"class","relative group"),k(At,"href","https://huggingface.co/MilaNLProc/feel-it-italian-sentiment"),k(At,"rel","nofollow"),k(Tt,"href","https://huggingface.co/docs/datasets/"),k(Tt,"rel","nofollow"),k(yt,"href","https://huggingface.co/docs/datasets/quickstart.html"),k(yt,"rel","nofollow"),k(Mt,"href","https://huggingface.co/datasets/PolyAI/minds14"),k(Mt,"rel","nofollow"),k(la,"href","./main_classes/pipelines"),k(xe,"id","utilizzare-un-altro-modello-e-tokenizer-nella-pipeline"),k(xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),k(xe,"href","#utilizzare-un-altro-modello-e-tokenizer-nella-pipeline"),k(Fe,"class","relative group"),k(Ot,"href","https://huggingface.co/models"),k(Ot,"rel","nofollow"),k(Lt,"href","https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment"),k(Lt,"rel","nofollow"),k(oa,"href","./training"),k(sa,"href","./model_sharing"),k(tt,"id","autoclass"),k(tt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),k(tt,"href","#autoclass"),k(Ie,"class","relative group"),k(na,"href","./model_doc/auto"),k(at,"id","autotokenizer"),k(at,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),k(at,"href","#autotokenizer"),k(Oe,"class","relative group"),k(ia,"href","./tokenizer_summary"),k(fa,"href","./glossary#input-ids"),k(ma,"href",".glossary#attention-mask"),k(da,"href","./preprocessing"),k(ut,"id","automodel"),k(ut,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),k(ut,"href","#automodel"),k(Le,"class","relative group"),k(Wt,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),k(Wt,"rel","nofollow"),k(Yt,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),k(Yt,"rel","nofollow"),k(Kt,"href","https://keras.io/"),k(Kt,"rel","nofollow"),k(_a,"href","./training"),k(mt,"id","salva-un-modello"),k(mt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),k(mt,"href","#salva-un-modello"),k(Re,"class","relative group")},m(a,$){o(document.head,e),h(a,n,$),h(a,t,$),o(t,l),o(l,i),M(r,i,null),o(t,g),o(t,_),o(_,v),h(a,q,$),M(I,a,$),h(a,F,$),h(a,P,$),o(P,S),o(P,z),o(z,C),o(P,b),o(P,T),o(T,R),o(P,G),h(a,V,$),M(U,a,$),h(a,ae,$),h(a,Y,$),o(Y,J),o(J,te),M(K,te,null),o(Y,Z),o(Y,de),o(de,se),h(a,he,$),h(a,ne,$),o(ne,le),o(le,ie),o(ne,ge),h(a,L,$),M(B,a,$),h(a,re,$),h(a,O,$),o(O,Q),o(O,ce),o(ce,De),o(O,_e),h(a,ve,$),h(a,ue,$),o(ue,Be),o(Be,be),o(ue,ea),h(a,kt,$),h(a,W,$),o(W,Pa),o(Pa,fs),o(W,ps),o(W,Sa),o(Sa,ms),o(W,ds),o(W,ya),o(ya,_s),o(W,hs),o(W,Ma),o(Ma,gs),o(W,$s),o(W,Da),o(Da,vs),o(W,bs),o(W,Na),o(Na,ks),o(W,zs),o(W,Fa),o(Fa,ws),o(W,Es),o(W,Ia),o(Ia,js),h(a,Ol,$),h(a,zt,$),o(zt,Oa),o(Oa,As),o(zt,Cs),h(a,Ll,$),h(a,ke,$),o(ke,La),o(La,qs),o(ke,Ts),o(ke,Ra),o(Ra,Ps),o(ke,Ss),o(ke,Ua),o(Ua,ys),h(a,Rl,$),h(a,wt,$),o(wt,Ba),o(Ba,Ms),o(wt,Ds),h(a,Ul,$),h(a,Ge,$),o(Ge,Ga),o(Ga,Ns),o(Ge,Fs),o(Ge,Qa),o(Qa,Is),h(a,Bl,$),M(Qe,a,$),h(a,Gl,$),h(a,Ne,$),o(Ne,He),o(He,Ha),M(Et,Ha,null),o(Ne,Os),o(Ne,Ja),o(Ja,Ls),h(a,Ql,$),h(a,Je,$),o(Je,Rs),o(Je,Va),o(Va,Us),o(Je,Bs),h(a,Hl,$),h(a,ta,$),o(ta,Gs),h(a,Jl,$),M(Ve,a,$),h(a,Vl,$),h(a,We,$),o(We,Qs),o(We,Wa),o(Wa,Hs),o(We,Js),h(a,Wl,$),M(jt,a,$),h(a,Yl,$),h(a,ze,$),o(ze,Vs),o(ze,At),o(At,Ws),o(ze,Ys),o(ze,Ya),o(Ya,Ks),o(ze,Zs),h(a,Kl,$),M(Ct,a,$),h(a,Zl,$),h(a,Ye,$),o(Ye,Xs),o(Ye,Ka),o(Ka,xs),o(Ye,en),h(a,Xl,$),M(qt,a,$),h(a,xl,$),h(a,we,$),o(we,tn),o(we,Za),o(Za,an),o(we,ln),o(we,Tt),o(Tt,on),o(we,sn),h(a,eo,$),M(Pt,a,$),h(a,to,$),h(a,Ke,$),o(Ke,nn),o(Ke,Xa),o(Xa,rn),o(Ke,un),h(a,ao,$),M(St,a,$),h(a,lo,$),h(a,Ee,$),o(Ee,cn),o(Ee,yt),o(yt,fn),o(Ee,pn),o(Ee,Mt),o(Mt,mn),o(Ee,dn),h(a,oo,$),M(Dt,a,$),h(a,so,$),h(a,Ze,$),o(Ze,_n),o(Ze,xa),o(xa,hn),o(Ze,gn),h(a,no,$),M(Nt,a,$),h(a,io,$),h(a,aa,$),o(aa,$n),h(a,ro,$),M(Ft,a,$),h(a,uo,$),h(a,Xe,$),o(Xe,vn),o(Xe,la),o(la,bn),o(Xe,kn),h(a,co,$),h(a,Fe,$),o(Fe,xe),o(xe,el),M(It,el,null),o(Fe,zn),o(Fe,tl),o(tl,wn),h(a,fo,$),h(a,fe,$),o(fe,En),o(fe,al),o(al,jn),o(fe,An),o(fe,Ot),o(Ot,Cn),o(fe,qn),o(fe,ll),o(ll,Tn),o(fe,Pn),o(fe,Lt),o(Lt,Sn),o(fe,yn),h(a,po,$),M(Rt,a,$),h(a,mo,$),M(et,a,$),h(a,_o,$),h(a,je,$),o(je,Mn),o(je,ol),o(ol,Dn),o(je,Nn),o(je,sl),o(sl,Fn),o(je,In),h(a,ho,$),M(Ut,a,$),h(a,go,$),h(a,Ae,$),o(Ae,On),o(Ae,oa),o(oa,Ln),o(Ae,Rn),o(Ae,sa),o(sa,Un),o(Ae,Bn),h(a,$o,$),h(a,Ie,$),o(Ie,tt),o(tt,nl),M(Bt,nl,null),o(Ie,Gn),o(Ie,il),o(il,Qn),h(a,vo,$),M(Gt,a,$),h(a,bo,$),h(a,X,$),o(X,Hn),o(X,rl),o(rl,Jn),o(X,Vn),o(X,ul),o(ul,Wn),o(X,Yn),o(X,cl),o(cl,Kn),o(X,Zn),o(X,na),o(na,Xn),o(X,xn),o(X,fl),o(fl,ei),o(X,ti),o(X,pl),o(pl,ai),o(X,li),h(a,ko,$),h(a,Ce,$),o(Ce,oi),o(Ce,ml),o(ml,si),o(Ce,ni),o(Ce,dl),o(dl,ii),o(Ce,ri),h(a,zo,$),h(a,Oe,$),o(Oe,at),o(at,_l),M(Qt,_l,null),o(Oe,ui),o(Oe,hl),o(hl,ci),h(a,wo,$),h(a,qe,$),o(qe,fi),o(qe,gl),o(gl,pi),o(qe,mi),o(qe,ia),o(ia,di),o(qe,_i),h(a,Eo,$),h(a,lt,$),o(lt,hi),o(lt,$l),o($l,gi),o(lt,$i),h(a,jo,$),M(Ht,a,$),h(a,Ao,$),h(a,ot,$),o(ot,vi),o(ot,vl),o(vl,bi),o(ot,ki),h(a,Co,$),h(a,ra,$),o(ra,zi),h(a,qo,$),M(Jt,a,$),h(a,To,$),h(a,ua,$),o(ua,wi),h(a,Po,$),h(a,st,$),o(st,ca),o(ca,fa),o(fa,Ei),o(ca,ji),o(st,Ai),o(st,pa),o(pa,ma),o(ma,Ci),o(pa,qi),h(a,So,$),h(a,nt,$),o(nt,Ti),o(nt,bl),o(bl,Pi),o(nt,Si),h(a,yo,$),M(it,a,$),h(a,Mo,$),h(a,rt,$),o(rt,yi),o(rt,da),o(da,Mi),o(rt,Di),h(a,Do,$),h(a,Le,$),o(Le,ut),o(ut,kl),M(Vt,kl,null),o(Le,Ni),o(Le,zl),o(zl,Fi),h(a,No,$),M(ct,a,$),h(a,Fo,$),M(ft,a,$),h(a,Io,$),h(a,x,$),o(x,Ii),o(x,Wt),o(Wt,wl),o(wl,Oi),o(x,Li),o(x,Yt),o(Yt,El),o(El,Ri),o(x,Ui),o(x,jl),o(jl,Bi),o(x,Gi),o(x,Al),o(Al,Qi),o(x,Hi),o(x,Kt),o(Kt,Ji),o(x,Vi),o(x,_a),o(_a,Wi),o(x,Yi),h(a,Oo,$),M(pt,a,$),h(a,Lo,$),h(a,Re,$),o(Re,mt),o(mt,Cl),M(Zt,Cl,null),o(Re,Ki),o(Re,ql),o(ql,Zi),h(a,Ro,$),M(dt,a,$),h(a,Uo,$),h(a,Te,$),o(Te,Xi),o(Te,Tl),o(Tl,xi),o(Te,er),o(Te,Pl),o(Pl,tr),o(Te,ar),h(a,Bo,$),M(_t,a,$),Go=!0},p(a,[$]){const Xt={};$&2&&(Xt.$$scope={dirty:$,ctx:a}),U.$set(Xt);const Sl={};$&2&&(Sl.$$scope={dirty:$,ctx:a}),Qe.$set(Sl);const yl={};$&2&&(yl.$$scope={dirty:$,ctx:a}),Ve.$set(yl);const Ml={};$&2&&(Ml.$$scope={dirty:$,ctx:a}),et.$set(Ml);const Ue={};$&2&&(Ue.$$scope={dirty:$,ctx:a}),it.$set(Ue);const Dl={};$&2&&(Dl.$$scope={dirty:$,ctx:a}),ct.$set(Dl);const Nl={};$&2&&(Nl.$$scope={dirty:$,ctx:a}),ft.$set(Nl);const xt={};$&2&&(xt.$$scope={dirty:$,ctx:a}),pt.$set(xt);const Fl={};$&2&&(Fl.$$scope={dirty:$,ctx:a}),dt.$set(Fl);const Il={};$&2&&(Il.$$scope={dirty:$,ctx:a}),_t.$set(Il)},i(a){Go||(j(r.$$.fragment,a),j(I.$$.fragment,a),j(U.$$.fragment,a),j(K.$$.fragment,a),j(B.$$.fragment,a),j(Qe.$$.fragment,a),j(Et.$$.fragment,a),j(Ve.$$.fragment,a),j(jt.$$.fragment,a),j(Ct.$$.fragment,a),j(qt.$$.fragment,a),j(Pt.$$.fragment,a),j(St.$$.fragment,a),j(Dt.$$.fragment,a),j(Nt.$$.fragment,a),j(Ft.$$.fragment,a),j(It.$$.fragment,a),j(Rt.$$.fragment,a),j(et.$$.fragment,a),j(Ut.$$.fragment,a),j(Bt.$$.fragment,a),j(Gt.$$.fragment,a),j(Qt.$$.fragment,a),j(Ht.$$.fragment,a),j(Jt.$$.fragment,a),j(it.$$.fragment,a),j(Vt.$$.fragment,a),j(ct.$$.fragment,a),j(ft.$$.fragment,a),j(pt.$$.fragment,a),j(Zt.$$.fragment,a),j(dt.$$.fragment,a),j(_t.$$.fragment,a),Go=!0)},o(a){A(r.$$.fragment,a),A(I.$$.fragment,a),A(U.$$.fragment,a),A(K.$$.fragment,a),A(B.$$.fragment,a),A(Qe.$$.fragment,a),A(Et.$$.fragment,a),A(Ve.$$.fragment,a),A(jt.$$.fragment,a),A(Ct.$$.fragment,a),A(qt.$$.fragment,a),A(Pt.$$.fragment,a),A(St.$$.fragment,a),A(Dt.$$.fragment,a),A(Nt.$$.fragment,a),A(Ft.$$.fragment,a),A(It.$$.fragment,a),A(Rt.$$.fragment,a),A(et.$$.fragment,a),A(Ut.$$.fragment,a),A(Bt.$$.fragment,a),A(Gt.$$.fragment,a),A(Qt.$$.fragment,a),A(Ht.$$.fragment,a),A(Jt.$$.fragment,a),A(it.$$.fragment,a),A(Vt.$$.fragment,a),A(ct.$$.fragment,a),A(ft.$$.fragment,a),A(pt.$$.fragment,a),A(Zt.$$.fragment,a),A(dt.$$.fragment,a),A(_t.$$.fragment,a),Go=!1},d(a){s(e),a&&s(n),a&&s(t),D(r),a&&s(q),D(I,a),a&&s(F),a&&s(P),a&&s(V),D(U,a),a&&s(ae),a&&s(Y),D(K),a&&s(he),a&&s(ne),a&&s(L),D(B,a),a&&s(re),a&&s(O),a&&s(ve),a&&s(ue),a&&s(kt),a&&s(W),a&&s(Ol),a&&s(zt),a&&s(Ll),a&&s(ke),a&&s(Rl),a&&s(wt),a&&s(Ul),a&&s(Ge),a&&s(Bl),D(Qe,a),a&&s(Gl),a&&s(Ne),D(Et),a&&s(Ql),a&&s(Je),a&&s(Hl),a&&s(ta),a&&s(Jl),D(Ve,a),a&&s(Vl),a&&s(We),a&&s(Wl),D(jt,a),a&&s(Yl),a&&s(ze),a&&s(Kl),D(Ct,a),a&&s(Zl),a&&s(Ye),a&&s(Xl),D(qt,a),a&&s(xl),a&&s(we),a&&s(eo),D(Pt,a),a&&s(to),a&&s(Ke),a&&s(ao),D(St,a),a&&s(lo),a&&s(Ee),a&&s(oo),D(Dt,a),a&&s(so),a&&s(Ze),a&&s(no),D(Nt,a),a&&s(io),a&&s(aa),a&&s(ro),D(Ft,a),a&&s(uo),a&&s(Xe),a&&s(co),a&&s(Fe),D(It),a&&s(fo),a&&s(fe),a&&s(po),D(Rt,a),a&&s(mo),D(et,a),a&&s(_o),a&&s(je),a&&s(ho),D(Ut,a),a&&s(go),a&&s(Ae),a&&s($o),a&&s(Ie),D(Bt),a&&s(vo),D(Gt,a),a&&s(bo),a&&s(X),a&&s(ko),a&&s(Ce),a&&s(zo),a&&s(Oe),D(Qt),a&&s(wo),a&&s(qe),a&&s(Eo),a&&s(lt),a&&s(jo),D(Ht,a),a&&s(Ao),a&&s(ot),a&&s(Co),a&&s(ra),a&&s(qo),D(Jt,a),a&&s(To),a&&s(ua),a&&s(Po),a&&s(st),a&&s(So),a&&s(nt),a&&s(yo),D(it,a),a&&s(Mo),a&&s(rt),a&&s(Do),a&&s(Le),D(Vt),a&&s(No),D(ct,a),a&&s(Fo),D(ft,a),a&&s(Io),a&&s(x),a&&s(Oo),D(pt,a),a&&s(Lo),a&&s(Re),D(Zt),a&&s(Ro),D(dt,a),a&&s(Uo),a&&s(Te),a&&s(Bo),D(_t,a)}}}const yf={local:"quick-tour",sections:[{local:"pipeline",sections:[{local:"utilizzo-della-pipeline",title:"Utilizzo della Pipeline"},{local:"utilizzare-un-altro-modello-e-tokenizer-nella-pipeline",title:"Utilizzare un altro modello e tokenizer nella pipeline"}],title:"Pipeline"},{local:"autoclass",sections:[{local:"autotokenizer",title:"AutoTokenizer"},{local:"automodel",title:"AutoModel"},{local:"salva-un-modello",title:"Salva un modello"}],title:"AutoClass"}],title:"Quick tour"};function Mf(u){return ur(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Lf extends Ca{constructor(e){super();qa(this,e,Mf,Sf,Ta,{})}}export{Lf as default,yf as metadata};
